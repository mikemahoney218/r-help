From bgunter.4567 at gmail.com  Wed Mar  1 01:58:47 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Feb 2017 16:58:47 -0800
Subject: [R] Von Mises mixtures: mu and kappa?
In-Reply-To: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86F421@EX2010-MBX2.ds.strath.ac.uk>
References: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86CCD8@EX2010-MBX2.ds.strath.ac.uk>
	<CAGxFJbQn74BYsGe3sx_FCh-jJu783OW7syf9gf7uCOHg3_JEYA@mail.gmail.com>
	<614DB8CF3AC0E3418AE4E12A0C79FD6A5D86F421@EX2010-MBX2.ds.strath.ac.uk>
Message-ID: <CAGxFJbQVGuwEO6TZQd_JPWDjfmarz+UPxakrFNrv_RzFB5K=iw@mail.gmail.com>

If you believe that a fit to simulated data should give you parameter
estimates identical to those used for the simulation, then I suggest
that you stop posting and consult a local statistical expert: you
don't know what you're doing.

If I have misunderstood your post, then just ignore the above and
hopefully someone with greater understanding than I will be able to
help you.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 28, 2017 at 7:39 AM, Peter Mills <peter.mills at strath.ac.uk> wrote:
> Thank you Bert for the references. I have found mix.vmf as a possible alternative to movMF but am stuck with applying either to my application.
>
> Does anyone know why mix.vmf requires to 2 columns for x?
>
> For example when I use:
> gWD <- c(0.1, 1, 0.9, 0.7,0.3)
>> mix.vmf(gWD, 2)
>
> I get the error:
> ?Error in matrix(nrow = n, ncol = g) : non-numeric matrix extent?
>
> The following code works but I'm not sure how to adapt this to the application I require. What I need is to calculate the mixture parameters for a vector of directional data not a matrix. Could anyone suggest how I can do this?
>
> k <- c(1, 2)
> prob <- c(0.3, 0.4, 0.3)
> mu <- matrix(rnorm(4), ncol = 2)
> mu <- mu / sqrt( rowSums(mu^2) )
> x <- rmixvmf(10, prob, mu, k)$x
> mix.vmf(x, 3)
>
> With regards to my original post and using movMF I'm stuck with this also. I found the following from [1], I thought this was the answer however it seems to need some adjustment as it is not giving me the theta and kappa values I started with:
> kappa2 <- row_norms(y2$theta)
> mu2<-y2$theta/row_norms(y2$theta)
>
> [1] On lines 94 and 107 of ?v58i10.R: R example code from the paper ? available from https://www.jstatsoft.org/article/view/v058i10
>
> Any suggestion would be greatly appreciated as after a further week of researching this and trying code I still don't seem to have working code.
>
>
> Here is some code I am using as a testing example:
> ################################################
> ## Generate and fit a "small-mix" data set a la Banerjee et al.
> mu1 <- rbind(c(-0.251, -0.968),
>             c(0.399, 0.917))
> kappa1 <- c(4, 4)
> theta <- kappa1 * mu1
> alpha <- c(0.48, 0.52)
> ## Generate a sample of size n = 50 from the von Mises-Fisher mixture ## with the above parameters.
> set.seed(123)
> x <- rmovMF(50, theta, alpha)
> ## Fit a von Mises-Fisher mixture with the "right" number of components, ## using 10 EM runs.
> y2 <- movMF(x, 2, nruns = 10)
>
> kappa2 <- row_norms(y2$theta)
> mu2<-y2$theta/row_norms(y2$theta)
>
>
> mu3c <- lapply(y2, function(x) y2$theta / row_norms(y2$theta)) ################################################
>
> I don't understand why this doesn't give me the values of mu and kappa I started with. I have tried to adapted this code to have the same number of mu and kappa values but it doesn't work then as mu is know longer a matrix.
>
> I don't understand why both movMF and mix.vmf give both mu1 and mu2 values per kappa value. In other words for a Von Mises mixture with 3 mixtures (clusters) the code gives 6 mu values and 3 kappa values. I was expecting to get 3 preferred directions (mu).
>
> For example:
> mix.vmf(x, 3) gives
>
> $param
>                 mu1             mu2             kappa     probs
> Cluster 1 0.4985047 -0.8668870 12.281773 0.3571429
> Cluster 2 0.9490725  0.3150578 34.028465 0.2857143
> Cluster 3 0.1017800  0.9948069  4.182367 0.3571429
>
> Many thanks
> Peter
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: 14 February 2017 17:49
> To: Peter Mills
> Cc: r-help at r-project.org
> Subject: Re: [R] Von Mises mixtures: mu and kappa?
>
> Please search before posting!
>
> Searching "von mises mixture distributions" on rseek.org brought up what appeared to be several relevant hits. If none of these meet your needs, you should probably explain why not in a follow up post.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 14, 2017 at 8:55 AM, Peter Mills <peter.mills at strath.ac.uk> wrote:
>> Hello
>>
>> I am trying to calculate the values of the concentration parameters (kappa) and preferred direction (mu) for a Von Mises mixture model. I currently have some R code that gives me optimised values for the product of kappa and mu, but I'm not sure how to calculate them when both are unknown? How could I calculate mu and kappa from y2 if I didn't know either in the 1st place? I what to use movMF to give me values of kappa from some directional data where I don't know either kappa or mu.
>>
>>
>> ## Generate and fit a "small-mix" data set a la Banerjee et al.
>> mu <- rbind(c(-0.251, -0.968),
>>             c(0.399, 0.917))
>> kappa <- c(4, 4)
>>
>> theta <- kappa * mu
>> theta
>> alpha <- c(0.48, 0.52)
>>
>> ## Generate a sample of size n = 50 from the von Mises-Fisher mixture
>> ## with the above parameters.
>> set.seed(123)
>> x <- rmovMF(50, theta, alpha)
>> ## Fit a von Mises-Fisher mixture with the "right" number of
>> components, ## using 10 EM runs.
>> y2 <- movMF(x, 2, nruns = 10)
>>
>> Y2 gives
>>> y2
>> theta:
>>        [,1]      [,2]
>> 1  2.443225  5.259337
>> 2 -1.851384 -4.291278
>> alpha:
>> [1] 0.4823648 0.5176352
>> L:
>> [1] 24.98124
>>
>> How could I calculate kappa and mu if I didn't know either in the 1st place?
>>
>> Thanks
>> Peter
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From evan.kransdorf at gmail.com  Wed Mar  1 08:27:42 2017
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Tue, 28 Feb 2017 23:27:42 -0800
Subject: [R] Help with data.table
Message-ID: <CAKZWb7duK5FERhbSK4KAMfA=3KdAyeZrqUgpS2ash2R7mdpmEA@mail.gmail.com>

Hello,

I need some help with data.table. I am trying to use data.table to do a
binary search of a large table using 2 keys.

         KEY1 KEY2 PARAM1
row1 1         2        -0.031
row2  2       8         -0.456
row3 3       24        -7.86
row4 5       2          2.89

I set the keys:
#DT<-setkey(DT,KEY1,KEY2)

Then I want to obtain do a binary search using 2 vectors E1 and E2.
#temp<-DT[list(E1,E2),]

When I do this, temp is only for the first-first, second-second,
third-third values of E1 and E2. However, I want the result of a table
search from every combination of values in E1 and E2 (1-1, 1-2, 1-3, 2-1,
2-2, 2-3, 3-1, 3-2, 3-3).

Anyone with any ideas? Thanks very much,

Evan

	[[alternative HTML version deleted]]


From francois.morneau at ign.fr  Wed Mar  1 08:56:17 2017
From: francois.morneau at ign.fr (=?UTF-8?Q?Fran=c3=a7ois_Morneau?=)
Date: Wed, 1 Mar 2017 08:56:17 +0100
Subject: [R] Help with data.table
In-Reply-To: <CAKZWb7duK5FERhbSK4KAMfA=3KdAyeZrqUgpS2ash2R7mdpmEA@mail.gmail.com>
References: <CAKZWb7duK5FERhbSK4KAMfA=3KdAyeZrqUgpS2ash2R7mdpmEA@mail.gmail.com>
Message-ID: <483cba5f-0392-b721-3538-f390b5158993@ign.fr>

Hello,

Not sure but have you consider using :

expand.grid(E1, E2)

that will create a data.frame of all combinations of your two vectors 
and then use it for your search.

Best,

Fran?ois

Le 01/03/2017 ? 08:27, Evan Kransdorf a ?crit :
> Hello,
>
> I need some help with data.table. I am trying to use data.table to do a
> binary search of a large table using 2 keys.
>
>           KEY1 KEY2 PARAM1
> row1 1         2        -0.031
> row2  2       8         -0.456
> row3 3       24        -7.86
> row4 5       2          2.89
>
> I set the keys:
> #DT<-setkey(DT,KEY1,KEY2)
>
> Then I want to obtain do a binary search using 2 vectors E1 and E2.
> #temp<-DT[list(E1,E2),]
>
> When I do this, temp is only for the first-first, second-second,
> third-third values of E1 and E2. However, I want the result of a table
> search from every combination of values in E1 and E2 (1-1, 1-2, 1-3, 2-1,
> 2-2, 2-3, 3-1, 3-2, 3-3).
>
> Anyone with any ideas? Thanks very much,
>
> Evan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Wed Mar  1 10:17:48 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 1 Mar 2017 09:17:48 +0000
Subject: [R] Metafor multilevel metaregression: total variance increases
 when moderator added?
In-Reply-To: <e11690197623435188b90b26facf151f@UM-MAIL3216.unimaas.nl>
References: <31A98C8B8E62D84982441B63A46937D76CEE7DDB@FHSDB2D11-1.csu.mcmaster.ca>
	<e11690197623435188b90b26facf151f@UM-MAIL3216.unimaas.nl>
Message-ID: <ed11cd15-21ce-cec7-364b-e74e3c33c2be@dewey.myzen.co.uk>

Dear Laura

If you are unable for some reason to share the data why not incorporate 
the output into an e-mail (and please turn of HTML as it mangles 
everything). Putting the plots from profiling somewhere we can read them 
would be a useful addition.

This looks at first glance one of those situations where sadly one has 
insufficient data for the models one would like to fit. We feel your pain.

On 28/02/2017 12:54, Viechtbauer Wolfgang (SP) wrote:
> Very difficult to diagnose what is going on without actually seeing the data. But as I said on CV: Depending on the data, the variance components may not be estimated precisely, so negative values for those kinds of pseudo-R^2 statistics are quite possible. In fact, if a particular moderator is actually unrelated to the outcomes, then in roughly 50% of the cases, the pseudo-R^2 statistic will be negative.
>
> See also:
>
> Lopez-Lopez, J. A., Marin-Martinez, F., Sanchez-Meca, J., Van den Noortgate, W., & Viechtbauer, W. (2014). Estimation of the predictive power of the model in mixed-effects meta-regression: A simulation study. British Journal of Mathematical and Statistical Psychology, 67(1), 30-48.
>
> We only examined the standard mixed-effects meta-regression model with a single moderator, but found that the pseudo-R^2 statistic can be all over the place unless k is quite large.
>
> Now you seem to have a larger number of estimates (170), but these are nested in 'only' 26 studies. So, I suspect that the estimate-level variance component is estimated fairly precisely, but not the study-level variance component. You may want to examine the profile plots (with the profile() function) and/or get (profile-likelihood) CIs of the variance components (using the confint() function). Probably the CI for the study-level variance component is quite wide.
>
> Best,
> Wolfgang
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From naresh_gurbuxani at hotmail.com  Wed Mar  1 13:09:33 2017
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Wed, 1 Mar 2017 12:09:33 +0000
Subject: [R] where is .emacs file?
Message-ID: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>


I am trying to install ESS so that it can be used when EMACS is launched from Mac Terminal. ?After running "make" from the directory where ESS files are saved, the instructions ask the following to be added to .emacs file:

(require 'ess-site)

But I cannot find .emacs file. 

I have already installed EMACS modified for ESS from Vincent Goulet's website.  In my EMACS application, ESS is available (verified by typing M-X ess-version).  

Thanks,
Naresh

From ulrik.stervbo at gmail.com  Wed Mar  1 13:28:34 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 01 Mar 2017 12:28:34 +0000
Subject: [R] where is .emacs file?
In-Reply-To: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>
References: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>
Message-ID: <CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>

Files starting with dots are hidden files on Mac. The emacs configuration
file .emacs should be in your home directory. You can list all files - also
the hidden ones - by `ls -a` in your console. I don't use Mac so I can't
tell you how to show hidden files in Finder.

If you still can't find the file, you might have better chances by asking
in some Emacs forum.

Alternatively you can use R-studio instead of emacs/ess.

HTH
Ulrik

On Wed, 1 Mar 2017 at 13:12 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>
wrote:


I am trying to install ESS so that it can be used when EMACS is launched
from Mac Terminal.  After running "make" from the directory where ESS files
are saved, the instructions ask the following to be added to .emacs file:

(require 'ess-site)

But I cannot find .emacs file.

I have already installed EMACS modified for ESS from Vincent Goulet's
website.  In my EMACS application, ESS is available (verified by typing M-X
ess-version).

Thanks,
Naresh
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From waser at frankenfoerder-fg.de  Wed Mar  1 14:28:32 2017
From: waser at frankenfoerder-fg.de (Wolfgang Waser)
Date: Wed, 1 Mar 2017 14:28:32 +0100
Subject: [R] How to select one value per row (different columns) from array
Message-ID: <b1555609-c51e-177a-a631-078e65030611@frankenfoerder-fg.de>

Dear all,

I have to pick one value per row from an array, but from row to row from
a different column. The column positions of the values for each row are
stored in a vector.

array: 999 rows, 48 columns

vector: 999 values (each between 1 and 48) indicating for each row which
value to pick from that row.

Is there a non-loop way to pick the 999 values from the array, probably
using some form of ?apply?


Thank you very much for help and suggestions!

Wolfgang


From pdalgd at gmail.com  Wed Mar  1 14:38:49 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 1 Mar 2017 14:38:49 +0100
Subject: [R] How to select one value per row (different columns) from
	array
In-Reply-To: <b1555609-c51e-177a-a631-078e65030611@frankenfoerder-fg.de>
References: <b1555609-c51e-177a-a631-078e65030611@frankenfoerder-fg.de>
Message-ID: <88F1E213-3565-4A38-B806-9DDDF6298642@gmail.com>


array[cbind(1:999,vector)]

-pd

On 01 Mar 2017, at 14:28 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:

> Dear all,
> 
> I have to pick one value per row from an array, but from row to row from
> a different column. The column positions of the values for each row are
> stored in a vector.
> 
> array: 999 rows, 48 columns
> 
> vector: 999 values (each between 1 and 48) indicating for each row which
> value to pick from that row.
> 
> Is there a non-loop way to pick the 999 values from the array, probably
> using some form of ?apply?
> 
> 
> Thank you very much for help and suggestions!
> 
> Wolfgang
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From naresh_gurbuxani at hotmail.com  Wed Mar  1 15:29:15 2017
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Wed, 1 Mar 2017 14:29:15 +0000
Subject: [R] where is .emacs file?
In-Reply-To: <CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>
References: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>,
	<CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>
Message-ID: <SN2PR18MB0751AAB1D3889D6061B3524EFA290@SN2PR18MB0751.namprd18.prod.outlook.com>

Thanks all for their suggestions.


While my Mac has .emacs.d directory, this does not seem to have any .emacs file.  Before creating a new .emacs file, I will reach out to  an Emacs forum.


Naresh


________________________________
From: Ulrik Stervbo <ulrik.stervbo at gmail.com>
Sent: Wednesday, March 1, 2017 7:28 AM
To: Naresh Gurbuxani; R-help at r-project.org
Subject: Re: [R] where is .emacs file?

Files starting with dots are hidden files on Mac. The emacs configuration file .emacs should be in your home directory. You can list all files - also the hidden ones - by `ls -a` in your console. I don't use Mac so I can't tell you how to show hidden files in Finder.

If you still can't find the file, you might have better chances by asking in some Emacs forum.

Alternatively you can use R-studio instead of emacs/ess.

HTH
Ulrik

On Wed, 1 Mar 2017 at 13:12 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com<mailto:naresh_gurbuxani at hotmail.com>> wrote:

I am trying to install ESS so that it can be used when EMACS is launched from Mac Terminal.  After running "make" from the directory where ESS files are saved, the instructions ask the following to be added to .emacs file:

(require 'ess-site)

But I cannot find .emacs file.

I have already installed EMACS modified for ESS from Vincent Goulet's website.  In my EMACS application, ESS is available (verified by typing M-X ess-version).

Thanks,
Naresh
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Wed Mar  1 15:38:15 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Wed, 1 Mar 2017 06:38:15 -0800
Subject: [R] How to select one value per row (different columns) from
	array
In-Reply-To: <88F1E213-3565-4A38-B806-9DDDF6298642@gmail.com>
References: <b1555609-c51e-177a-a631-078e65030611@frankenfoerder-fg.de>
	<88F1E213-3565-4A38-B806-9DDDF6298642@gmail.com>
Message-ID: <CAA99HCx2qNo38c-WZWEqZB1St4rx2HHSLQC9n9sGUcKfRfKq7g@mail.gmail.com>

Hello Wolfgang,

Building on Peter Dalgaard's code, are you just trying to take a sample of
a random column from each row? You don't need to use apply:

> array[cbind(1:nrow(array), sample.int(ncol(array), nrow(array),
replace=TRUE ))]

Just a general note, since you're sampling one-column-per-row from an array
with more rows than columns, you'll have to set replace=TRUE. However,
there may be other datasets where you have more columns than rows and never
want to sample each column more than once, in which case you would set
replace=FALSE.

Best Regards.



On Wed, Mar 1, 2017 at 5:38 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> array[cbind(1:999,vector)]
>
> -pd
>
> On 01 Mar 2017, at 14:28 , Wolfgang Waser <waser at frankenfoerder-fg.de>
> wrote:
>
> > Dear all,
> >
> > I have to pick one value per row from an array, but from row to row from
> > a different column. The column positions of the values for each row are
> > stored in a vector.
> >
> > array: 999 rows, 48 columns
> >
> > vector: 999 values (each between 1 and 48) indicating for each row which
> > value to pick from that row.
> >
> > Is there a non-loop way to pick the 999 values from the array, probably
> > using some form of ?apply?
> >
> >
> > Thank you very much for help and suggestions!
> >
> > Wolfgang
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From James.Yates at astrazeneca.com  Wed Mar  1 11:19:27 2017
From: James.Yates at astrazeneca.com (Yates, James W T)
Date: Wed, 1 Mar 2017 10:19:27 +0000
Subject: [R] Windows server 2012
Message-ID: <VI1PR04MB131117A6A1BDF2A0D298D667F2290@VI1PR04MB1311.eurprd04.prod.outlook.com>

Hello

I'm investigating installing R in a virtual machine environment. Does anyone have experience running R on windows server 2012?

Regards

James
________________________________

AstraZeneca UK Limited is a company incorporated in Engl...{{dropped:16}}


From allantanaka11 at yahoo.com  Wed Mar  1 11:51:40 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Wed, 1 Mar 2017 10:51:40 +0000 (UTC)
Subject: [R]  Error in model.frame.default(formula = formula, data = data,
 drop.unused.levels = TRUE, :    object is not a matrix
References: <1299844643.1037336.1488365500321.ref@mail.yahoo.com>
Message-ID: <1299844643.1037336.1488365500321@mail.yahoo.com>

Hi,?
I have encountered the following error, when running 'depmix' function, which I think?
has something to do with my data, and I cannot?understand why, even though i have converted my data into as.matrix()
See attached file?
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: aaa.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170301/9014e83e/attachment.txt>

From dwinsemius at comcast.net  Wed Mar  1 18:11:40 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Mar 2017 09:11:40 -0800
Subject: [R] where is .emacs file?
In-Reply-To: <CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>
References: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>
	<CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>
Message-ID: <B1FD8F48-39CD-4D14-9B34-E7FF0DAE86D6@comcast.net>


> On Mar 1, 2017, at 4:28 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Files starting with dots are hidden files on Mac. The emacs configuration
> file .emacs should be in your home directory. You can list all files - also
> the hidden ones - by `ls -a` in your console. I don't use Mac so I can't
> tell you how to show hidden files in Finder.

At an open Terminal console type:

defaults write com.apple.finder AppleShowAllFiles YES
killall Finder

The second line restarts your Finder.app so that the new settings can take effect. You will then have the responsibility of not deleting any of the system files which are now exposed, but this is how I run my machine.

-- 
David.
> 
> If you still can't find the file, you might have better chances by asking
> in some Emacs forum.
> 
> Alternatively you can use R-studio instead of emacs/ess.
> 
> HTH
> Ulrik
> 
> On Wed, 1 Mar 2017 at 13:12 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>
> wrote:
> 
> 
> I am trying to install ESS so that it can be used when EMACS is launched
> from Mac Terminal.  After running "make" from the directory where ESS files
> are saved, the instructions ask the following to be added to .emacs file:
> 
> (require 'ess-site)
> 
> But I cannot find .emacs file.
> 
> I have already installed EMACS modified for ESS from Vincent Goulet's
> website.  In my EMACS application, ESS is available (verified by typing M-X
> ess-version).
> 
> Thanks,
> Naresh
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Wed Mar  1 18:41:39 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 1 Mar 2017 18:41:39 +0100
Subject: [R] where is .emacs file?
In-Reply-To: <B1FD8F48-39CD-4D14-9B34-E7FF0DAE86D6@comcast.net>
References: <SN2PR18MB075127F1F3380D6A18C18905FA290@SN2PR18MB0751.namprd18.prod.outlook.com>
	<CAKVAULOKZVXhkJ=yycBY7sbEgcqihnDdQxRnWgdKRewjB81shQ@mail.gmail.com>
	<B1FD8F48-39CD-4D14-9B34-E7FF0DAE86D6@comcast.net>
Message-ID: <BA7F9E38-EF40-4F09-B678-BF733AC1ADFE@gmail.com>

This isn't the emacs help list...

Anyways, a less intrusive method is to start a Terminal and use ls -a. 

As far as I can tell, the stock emacs on Mac actually works with a .emacs.d directory into which you are supposed to drop .el files, rather than the monolithic .emacs file.

I see claims that it should be possible to use emacsclient with aquamacs, which would bypass the entire ESS install issue since aquamacs already has it, but I cant seem to make it work here.

-pd

On 01 Mar 2017, at 18:11 , David Winsemius <dwinsemius at comcast.net> wrote:

>> 
>> On Mar 1, 2017, at 4:28 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> 
>> Files starting with dots are hidden files on Mac. The emacs configuration
>> file .emacs should be in your home directory. You can list all files - also
>> the hidden ones - by `ls -a` in your console. I don't use Mac so I can't
>> tell you how to show hidden files in Finder.
> 
> At an open Terminal console type:
> 
> defaults write com.apple.finder AppleShowAllFiles YES
> killall Finder
> 
> The second line restarts your Finder.app so that the new settings can take effect. You will then have the responsibility of not deleting any of the system files which are now exposed, but this is how I run my machine.
> 
> -- 
> David.
>> 
>> If you still can't find the file, you might have better chances by asking
>> in some Emacs forum.
>> 
>> Alternatively you can use R-studio instead of emacs/ess.
>> 
>> HTH
>> Ulrik
>> 
>> On Wed, 1 Mar 2017 at 13:12 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>
>> wrote:
>> 
>> 
>> I am trying to install ESS so that it can be used when EMACS is launched
>> from Mac Terminal.  After running "make" from the directory where ESS files
>> are saved, the instructions ask the following to be added to .emacs file:
>> 
>> (require 'ess-site)
>> 
>> But I cannot find .emacs file.
>> 
>> I have already installed EMACS modified for ESS from Vincent Goulet's
>> website.  In my EMACS application, ESS is available (verified by typing M-X
>> ess-version).
>> 
>> Thanks,
>> Naresh
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ruipbarradas at sapo.pt  Wed Mar  1 19:37:51 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 01 Mar 2017 18:37:51 +0000
Subject: [R] Error in model.frame.default(formula = formula, data = data,
 drop.unused.levels = TRUE, :    object is not a matrix
In-Reply-To: <1299844643.1037336.1488365500321@mail.yahoo.com>
References: <1299844643.1037336.1488365500321.ref@mail.yahoo.com>
	<1299844643.1037336.1488365500321@mail.yahoo.com>
Message-ID: <58B714FF.9080206@sapo.pt>

Hello,

 >What is function logret? After loading the packages I've tried

?logret
No documentation for ?logret? in specified packages and libraries:
you could try ???logret?


Besides, how can you use a function logret(data1.ts, ...) and then do

depmix(logret ~ 1, ...)

Suddenly logret becomes a column in dataset deret.
Revise your code, please.
And in order for us to test it you should also post the output of the 
following command.

dput(head(data1, 30))  # paste the output of this in your next mail

Hope this helps,

Rui Barradas

Em 01-03-2017 10:51, Allan Tanaka escreveu:
> Hi,
> I have encountered the following error, when running 'depmix' function, which I think
> has something to do with my data, and I cannot understand why, even though i have converted my data into as.matrix()
> See attached file
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From abouelmakarim1962 at gmail.com  Wed Mar  1 18:57:23 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 1 Mar 2017 12:57:23 -0500
Subject: [R] Coefficient of Partial Determination
Message-ID: <CAE9stmcp=q1sxpypmLAG4sUx_LwXAOt_KTLiJfB5LG_Ki1DeKA@mail.gmail.com>

Dear All:

Can the *Coefficient of Partial Determination* in multiple linear
regression be computed in R? If so, could you please let me know how?


fullmodel <- lm(Price ~ Size + Lotsize + Bedrooms + Bathrooms)


*I found this in the internet, but I could find the package "rms"*

*library(rms)  # will also load Hmisc*

*fit <- ols(y ~ x1 + x2, data=bf.dat) *

*plt <- plot(anova(fit), what='partial R2')*

*plt*



Here is part of the data as an example:
---------------------------------------------------

 Taxes Bedrooms Bathrooms   Price Size Lotsize
   296        3         3  795000 2371    5850
   242        4         3  399000 2818    4000
   242        4         3  545000 3032    3060
   222        4         4  909000 3540    6650
   222        3         1  109900 1249    6360
   222        3         3  324900 1800    4160
   311        4         2  192900 1603    3880
   311        3         2  215000 1450    4160
   311        4         3  999000 3360    4800
   311        3         2  319000 1323    5500
   311        3         2  350000 1750    7200
   311        3         2  249000 1400    3000
   311        2         2  299000 1257    1700
   307        3         2  235900 1400    2880
   307        3         2  348000 1600    3600
   307        4         3  314000 1794    3185
   307        4         2  399000 1850    3300
   307        3         3  599000 2950    5200
   307        3         2  299000 1719    3450
   307        3         3  425000 1472    3986
   307        4         3 1100000 4168    4785
   307        3         3 1500000 3880    4510
   307        2         1  110000 1000    4000
   307        3         2  200000 1139    3934
   307        3         1  134900 1080    4960
   307        4         3  250000 2000    3000
   307        3         4  950000 1920    3800
   307        4         2  239950 1348    4960
   307        3         2  170000 1280    3000
   307        3         2  285000 2400    4500
   307        3         3  279000 1700    3500
   307        3         2  219000 1600    3500
   307        3         2  155000 1050    4000
   307        3         2  389000 1415    4500
   307        3         1  340000 1110    6360
   279        2         1   95000  797    4500
   279        2         2  140000 1100    4032
   279        3         3 1100000 2602    5170
   279        4         3  360000 2351    5400
   252        3         3  415000 1350    3150
   252        4         2  250000 1206    3745
   233        3         3  559000 2628    4520
   233        3         3  525000 2365    4640
   233        3         3  779000 2990    8580
   233        3         2  595000 1750    2000
   233        4         5 1150000 5500    2160
   233        3         2  550000 1852    3040
   233        3         2  500000 2100    3090
   233        4         3  279000 2580    4960
   233        4         2  375000 1963    3350
   243        3         3  330000 1900    5300
   243        3         3  199000 1450    4100
   243        2         2  165000 1000    9166
   243        4         3 1399000 6500    4040
   469        3         2  255000 1218    3630
   226        2         2  325000  893    3620



Thank you very much for your help and support

abou
______________________
AbouEl-Makarim Aboueissa, PhD
University of Southern Maine
Department of Mathematics and Statistics

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar  1 21:17:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Mar 2017 12:17:05 -0800
Subject: [R] Coefficient of Partial Determination
In-Reply-To: <CAE9stmcp=q1sxpypmLAG4sUx_LwXAOt_KTLiJfB5LG_Ki1DeKA@mail.gmail.com>
References: <CAE9stmcp=q1sxpypmLAG4sUx_LwXAOt_KTLiJfB5LG_Ki1DeKA@mail.gmail.com>
Message-ID: <2D57509E-17B2-4C3F-96B0-52F3E629BDBA@comcast.net>


> On Mar 1, 2017, at 9:57 AM, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
> 
> Dear All:
> 
> Can the *Coefficient of Partial Determination* in multiple linear
> regression be computed in R? If so, could you please let me know how?
> 
> 
> fullmodel <- lm(Price ~ Size + Lotsize + Bedrooms + Bathrooms)

Partial R^2's should just be a simple calculation of a ratio of sums of squares. After searching on that 'fullmodel" construction I see that a similar problem was posed for college coursework:

houses = read.csv("http://home.cc.umanitoba.ca/~godwinrt/3180/data/houseprice.csv")

(Homework is not considered on-topic for r-help.)

Perhaps you need to learn to search:

sos::findFn("coefficient of partial determination")

... finds one.

sos::findFn("partial R^2")

... finds both that one and another

Code can be found searching the archives:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+coefficient+of+partial+determination

This had a particularly compact and well commented example:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+coefficient+of+partial+determination#query:list%3Aorg.r-project.r-help%20coefficient%20of%20partial%20determination+page:1+mid:s7gcefsew5cce46q+state:results

> 
> 
> *I found this in the internet, but I could find the package "rms"*

I'm assuming you meant to type "couldn't", although that is rather surprising since it is a well-established and respected package:

https://cran.r-project.org/web/packages/rms/index.html


> 
> *library(rms)  # will also load Hmisc*
> 
> *fit <- ols(y ~ x1 + x2, data=bf.dat) *
> 
> *plt <- plot(anova(fit), what='partial R2')*

The asterisks would need to be removed but generally you will also need to use a call to `datadist` and `options` when using the rms/Hmisc suite of functions. The book that supports that package is excellent.

Hope this helps;
David.


> 
> *plt*
> 
> 
> 
> Here is part of the data as an example:
> ---------------------------------------------------
> 
> Taxes Bedrooms Bathrooms   Price Size Lotsize
>   296        3         3  795000 2371    5850
>   242        4         3  399000 2818    4000
>   242        4         3  545000 3032    3060
>   222        4         4  909000 3540    6650
>   222        3         1  109900 1249    6360
>   222        3         3  324900 1800    4160
>   311        4         2  192900 1603    3880
>   311        3         2  215000 1450    4160
>   311        4         3  999000 3360    4800
>   311        3         2  319000 1323    5500
>   311        3         2  350000 1750    7200
>   311        3         2  249000 1400    3000
>   311        2         2  299000 1257    1700
>   307        3         2  235900 1400    2880
>   307        3         2  348000 1600    3600
>   307        4         3  314000 1794    3185
>   307        4         2  399000 1850    3300
>   307        3         3  599000 2950    5200
>   307        3         2  299000 1719    3450
>   307        3         3  425000 1472    3986
>   307        4         3 1100000 4168    4785
>   307        3         3 1500000 3880    4510
>   307        2         1  110000 1000    4000
>   307        3         2  200000 1139    3934
>   307        3         1  134900 1080    4960
>   307        4         3  250000 2000    3000
>   307        3         4  950000 1920    3800
>   307        4         2  239950 1348    4960
>   307        3         2  170000 1280    3000
>   307        3         2  285000 2400    4500
>   307        3         3  279000 1700    3500
>   307        3         2  219000 1600    3500
>   307        3         2  155000 1050    4000
>   307        3         2  389000 1415    4500
>   307        3         1  340000 1110    6360
>   279        2         1   95000  797    4500
>   279        2         2  140000 1100    4032
>   279        3         3 1100000 2602    5170
>   279        4         3  360000 2351    5400
>   252        3         3  415000 1350    3150
>   252        4         2  250000 1206    3745
>   233        3         3  559000 2628    4520
>   233        3         3  525000 2365    4640
>   233        3         3  779000 2990    8580
>   233        3         2  595000 1750    2000
>   233        4         5 1150000 5500    2160
>   233        3         2  550000 1852    3040
>   233        3         2  500000 2100    3090
>   233        4         3  279000 2580    4960
>   233        4         2  375000 1963    3350
>   243        3         3  330000 1900    5300
>   243        3         3  199000 1450    4100
>   243        2         2  165000 1000    9166
>   243        4         3 1399000 6500    4040
>   469        3         2  255000 1218    3630
>   226        2         2  325000  893    3620
> 
> 
> 
> Thank you very much for your help and support
> 
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> University of Southern Maine
> Department of Mathematics and Statistics
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From waser at frankenfoerder-fg.de  Wed Mar  1 21:23:01 2017
From: waser at frankenfoerder-fg.de (Wolfgang Waser)
Date: Wed, 01 Mar 2017 21:23:01 +0100
Subject: [R] How to select one value per row (different columns) from
	array
In-Reply-To: <CAA99HCx2qNo38c-WZWEqZB1St4rx2HHSLQC9n9sGUcKfRfKq7g@mail.gmail.com>
References: <b1555609-c51e-177a-a631-078e65030611@frankenfoerder-fg.de>
	<88F1E213-3565-4A38-B806-9DDDF6298642@gmail.com>
	<CAA99HCx2qNo38c-WZWEqZB1St4rx2HHSLQC9n9sGUcKfRfKq7g@mail.gmail.com>
Message-ID: <031FE138-21F7-4866-A8E5-CE29C011FD9D@frankenfoerder-fg.de>

Thank you very much indeed. PD's code is exactly what I was looking for, and unfortunately it is so obvious, that I could kick myself for not thinking of it in  the first place, as I feared would happen.
WM: thanks for the additional suggestion. I'll check it in detail to see how my codes can benefit from it.

As a general note, I would like to express my gratitude for all contributors for their very fast and most helpful replies. For me it always made a huge difference to a) spending frustrating hours looking for the solution, knowing it is there but not finding it, and therefore b) having to work around it in a most inelegant manner.
Thanks again!

On 1 March 2017 15:38:15 CET, William Michels <wjm1 at caa.columbia.edu> wrote:
>Hello Wolfgang,
>
>Building on Peter Dalgaard's code, are you just trying to take a sample
>of
>a random column from each row? You don't need to use apply:
>
>> array[cbind(1:nrow(array), sample.int(ncol(array), nrow(array),
>replace=TRUE ))]
>
>Just a general note, since you're sampling one-column-per-row from an
>array
>with more rows than columns, you'll have to set replace=TRUE. However,
>there may be other datasets where you have more columns than rows and
>never
>want to sample each column more than once, in which case you would set
>replace=FALSE.
>
>Best Regards.
>
>
>
>On Wed, Mar 1, 2017 at 5:38 AM, peter dalgaard <pdalgd at gmail.com>
>wrote:
>
>>
>> array[cbind(1:999,vector)]
>>
>> -pd
>>
>> On 01 Mar 2017, at 14:28 , Wolfgang Waser
><waser at frankenfoerder-fg.de>
>> wrote:
>>
>> > Dear all,
>> >
>> > I have to pick one value per row from an array, but from row to row
>from
>> > a different column. The column positions of the values for each row
>are
>> > stored in a vector.
>> >
>> > array: 999 rows, 48 columns
>> >
>> > vector: 999 values (each between 1 and 48) indicating for each row
>which
>> > value to pick from that row.
>> >
>> > Is there a non-loop way to pick the 999 values from the array,
>probably
>> > using some form of ?apply?
>> >
>> >
>> > Thank you very much for help and suggestions!
>> >
>> > Wolfgang
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my touchy-wipy-thing. Please excuse the typos.
	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Wed Mar  1 21:31:20 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 1 Mar 2017 20:31:20 +0000
Subject: [R] Coefficient of Partial Determination
In-Reply-To: <CAE9stmcp=q1sxpypmLAG4sUx_LwXAOt_KTLiJfB5LG_Ki1DeKA@mail.gmail.com>
References: <CAE9stmcp=q1sxpypmLAG4sUx_LwXAOt_KTLiJfB5LG_Ki1DeKA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E94AAC@WAXMXOLYMB025.WAX.wa.lcl>

The rms and Hmisc packages can be found on CRAN.  Just run install packages from the console menu.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AbouEl-
> Makarim Aboueissa
> Sent: Wednesday, March 01, 2017 9:57 AM
> To: R-help at r-project.org
> Subject: [R] Coefficient of Partial Determination
> 
> Dear All:
> 
> Can the *Coefficient of Partial Determination* in multiple linear
> regression be computed in R? If so, could you please let me know how?
> 
> 
> fullmodel <- lm(Price ~ Size + Lotsize + Bedrooms + Bathrooms)
> 
> 
> *I found this in the internet, but I could find the package "rms"*
> 
> *library(rms)  # will also load Hmisc*
> 
> *fit <- ols(y ~ x1 + x2, data=bf.dat) *
> 
> *plt <- plot(anova(fit), what='partial R2')*
> 
> *plt*
> 
> 
> 
> Here is part of the data as an example:
> ---------------------------------------------------
> 
>  Taxes Bedrooms Bathrooms   Price Size Lotsize
>    296        3         3  795000 2371    5850
>    242        4         3  399000 2818    4000
>    242        4         3  545000 3032    3060
>    222        4         4  909000 3540    6650
>    222        3         1  109900 1249    6360
>    222        3         3  324900 1800    4160
>    311        4         2  192900 1603    3880
>    311        3         2  215000 1450    4160
>    311        4         3  999000 3360    4800
>    311        3         2  319000 1323    5500
>    311        3         2  350000 1750    7200
>    311        3         2  249000 1400    3000
>    311        2         2  299000 1257    1700
>    307        3         2  235900 1400    2880
>    307        3         2  348000 1600    3600
>    307        4         3  314000 1794    3185
>    307        4         2  399000 1850    3300
>    307        3         3  599000 2950    5200
>    307        3         2  299000 1719    3450
>    307        3         3  425000 1472    3986
>    307        4         3 1100000 4168    4785
>    307        3         3 1500000 3880    4510
>    307        2         1  110000 1000    4000
>    307        3         2  200000 1139    3934
>    307        3         1  134900 1080    4960
>    307        4         3  250000 2000    3000
>    307        3         4  950000 1920    3800
>    307        4         2  239950 1348    4960
>    307        3         2  170000 1280    3000
>    307        3         2  285000 2400    4500
>    307        3         3  279000 1700    3500
>    307        3         2  219000 1600    3500
>    307        3         2  155000 1050    4000
>    307        3         2  389000 1415    4500
>    307        3         1  340000 1110    6360
>    279        2         1   95000  797    4500
>    279        2         2  140000 1100    4032
>    279        3         3 1100000 2602    5170
>    279        4         3  360000 2351    5400
>    252        3         3  415000 1350    3150
>    252        4         2  250000 1206    3745
>    233        3         3  559000 2628    4520
>    233        3         3  525000 2365    4640
>    233        3         3  779000 2990    8580
>    233        3         2  595000 1750    2000
>    233        4         5 1150000 5500    2160
>    233        3         2  550000 1852    3040
>    233        3         2  500000 2100    3090
>    233        4         3  279000 2580    4960
>    233        4         2  375000 1963    3350
>    243        3         3  330000 1900    5300
>    243        3         3  199000 1450    4100
>    243        2         2  165000 1000    9166
>    243        4         3 1399000 6500    4040
>    469        3         2  255000 1218    3630
>    226        2         2  325000  893    3620
> 
> 
> 
> Thank you very much for your help and support
> 
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> University of Southern Maine
> Department of Mathematics and Statistics
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fanjianling at gmail.com  Wed Mar  1 23:44:40 2017
From: fanjianling at gmail.com (Jianling Fan)
Date: Wed, 1 Mar 2017 16:44:40 -0600
Subject: [R] install problem from Github or downloaded file
Message-ID: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>

Hello everyone,

I can install packages from CRAN, but I got some problem for
installing packages from Github or downloaded package files. I got
this problem in recent weeks.

example:

> devtools::install_github('bart6114/artyfarty')
Downloading GitHub repo bart6114/artyfarty at master
from URL https://api.github.com/repos/bart6114/artyfarty/zipball/master
Error in utils::unzip(src, exdir = target) :
  cannot open file
'C:/Users/FanJ/AppData/Local/Temp/Rtmp6PonUm/devtools23184c742bf4/Bart6114-artyfarty-abf831d/R/helpers.R':
No such file or directory

so, I downloaded the package and try to install it from local folder:

> install.packages("C:/Users/FanJ/Downloads/artyfarty-master.zip", repos = NULL, type = "win.binary")
Error in install.packages : cannot open file
'C:/Users/FanJ/Documents/R/R-3.3.2/library/file2318185d1b3c/artyfarty-master/R/helpers.R':
No such file or directory

It seems R try to create an extra folder "file2318185d1b3c".

I googled this problem. some people said it is caused by TMP dir. But
that seems not my case:

> Sys.getenv(c("TMP","TEMP","TMPDIR"))
                                    TMP                                    TEMP
"C:\\Users\\FanJ\\AppData\\Local\\Temp" "C:\\Users\\FanJ\\AppData\\Local\\Temp"
                                 TMPDIR
"C:\\Users\\FanJ\\AppData\\Local\\Temp"

> .Options$unzip
[1] "internal"


> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] agricolae_1.2-4         Evapotranspiration_1.10 zoo_1.7-14
      dplyr_0.5.0
 [5] purrr_0.2.2             readr_1.0.0             tidyr_0.6.1
      tibble_1.2
 [9] ggplot2_2.2.1           tidyverse_1.1.1

loaded via a namespace (and not attached):
 [1] gtools_3.5.0      reshape2_1.4.2    splines_3.3.2     haven_1.0.0
      lattice_0.20-34   colorspace_1.3-2
 [7] expm_0.999-1      AlgDesign_1.1-7.3 withr_1.0.2
foreign_0.8-67    DBI_0.5-1         sp_1.2-4
[13] modelr_0.1.0      readxl_0.1.1      plyr_1.8.4
stringr_1.2.0     munsell_0.4.3     combinat_0.0-8
[19] gtable_0.2.0      rvest_0.3.2       devtools_1.12.0
memoise_1.0.0     coda_0.19-1       psych_1.6.12
[25] forcats_0.2.0     curl_2.3          parallel_3.3.2
spdep_0.6-11      broom_0.4.2       Rcpp_0.12.9
[31] scales_0.4.1      gdata_2.17.0      jsonlite_1.2
deldir_0.1-12     mnormt_1.5-5      digest_0.6.12
[37] klaR_0.6-12       hms_0.3           stringi_1.1.2
gmodels_2.16.2    grid_3.3.2        tools_3.3.2
[43] LearnBayes_2.15   magrittr_1.5      lazyeval_0.2.0
cluster_2.0.5     MASS_7.3-45       Matrix_1.2-8
[49] xml2_1.1.1        lubridate_1.6.0   assertthat_0.1    httr_1.2.1
      R6_2.2.0          boot_1.3-18
[55] git2r_0.18.0      nlme_3.1-131


Any suggestions?

Thanks a lot!!


From jdnewmil at dcn.davis.ca.us  Thu Mar  2 00:30:14 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Mar 2017 15:30:14 -0800
Subject: [R] install problem from Github or downloaded file
In-Reply-To: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>
References: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>
Message-ID: <E8904C9D-12ED-4323-8F1A-FF61E5E43AE3@dcn.davis.ca.us>

CRAN is notorious for being picky, performing hundreds of quality checks before allowing a package to be shared there. Has it occurred to you that "artyfarty", not having been through CRAN, might simply be broken?

Yes the directories you ask about are only present temporarily while the package is checked and moved into your package library, so they are "temporary" even though they are not in your TMP or TEMP directories. The missing file is almost certainly the R file, not the directory. 
-- 
Sent from my phone. Please excuse my brevity.

On March 1, 2017 2:44:40 PM PST, Jianling Fan <fanjianling at gmail.com> wrote:
>Hello everyone,
>
>I can install packages from CRAN, but I got some problem for
>installing packages from Github or downloaded package files. I got
>this problem in recent weeks.
>
>example:
>
>> devtools::install_github('bart6114/artyfarty')
>Downloading GitHub repo bart6114/artyfarty at master
>from URL https://api.github.com/repos/bart6114/artyfarty/zipball/master
>Error in utils::unzip(src, exdir = target) :
>  cannot open file
>'C:/Users/FanJ/AppData/Local/Temp/Rtmp6PonUm/devtools23184c742bf4/Bart6114-artyfarty-abf831d/R/helpers.R':
>No such file or directory
>
>so, I downloaded the package and try to install it from local folder:
>
>> install.packages("C:/Users/FanJ/Downloads/artyfarty-master.zip",
>repos = NULL, type = "win.binary")
>Error in install.packages : cannot open file
>'C:/Users/FanJ/Documents/R/R-3.3.2/library/file2318185d1b3c/artyfarty-master/R/helpers.R':
>No such file or directory
>
>It seems R try to create an extra folder "file2318185d1b3c".
>
>I googled this problem. some people said it is caused by TMP dir. But
>that seems not my case:
>
>> Sys.getenv(c("TMP","TEMP","TMPDIR"))
>                            TMP                                    TEMP
>"C:\\Users\\FanJ\\AppData\\Local\\Temp"
>"C:\\Users\\FanJ\\AppData\\Local\\Temp"
>                                 TMPDIR
>"C:\\Users\\FanJ\\AppData\\Local\\Temp"
>
>> .Options$unzip
>[1] "internal"
>
>
>> sessionInfo()
>R version 3.3.2 (2016-10-31)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>locale:
>[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>LC_MONETARY=English_Canada.1252
>[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
> [1] agricolae_1.2-4         Evapotranspiration_1.10 zoo_1.7-14
>      dplyr_0.5.0
> [5] purrr_0.2.2             readr_1.0.0             tidyr_0.6.1
>      tibble_1.2
> [9] ggplot2_2.2.1           tidyverse_1.1.1
>
>loaded via a namespace (and not attached):
> [1] gtools_3.5.0      reshape2_1.4.2    splines_3.3.2     haven_1.0.0
>      lattice_0.20-34   colorspace_1.3-2
> [7] expm_0.999-1      AlgDesign_1.1-7.3 withr_1.0.2
>foreign_0.8-67    DBI_0.5-1         sp_1.2-4
>[13] modelr_0.1.0      readxl_0.1.1      plyr_1.8.4
>stringr_1.2.0     munsell_0.4.3     combinat_0.0-8
>[19] gtable_0.2.0      rvest_0.3.2       devtools_1.12.0
>memoise_1.0.0     coda_0.19-1       psych_1.6.12
>[25] forcats_0.2.0     curl_2.3          parallel_3.3.2
>spdep_0.6-11      broom_0.4.2       Rcpp_0.12.9
>[31] scales_0.4.1      gdata_2.17.0      jsonlite_1.2
>deldir_0.1-12     mnormt_1.5-5      digest_0.6.12
>[37] klaR_0.6-12       hms_0.3           stringi_1.1.2
>gmodels_2.16.2    grid_3.3.2        tools_3.3.2
>[43] LearnBayes_2.15   magrittr_1.5      lazyeval_0.2.0
>cluster_2.0.5     MASS_7.3-45       Matrix_1.2-8
>[49] xml2_1.1.1        lubridate_1.6.0   assertthat_0.1    httr_1.2.1
>      R6_2.2.0          boot_1.3-18
>[55] git2r_0.18.0      nlme_3.1-131
>
>
>Any suggestions?
>
>Thanks a lot!!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Mar  2 02:07:55 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Mar 2017 17:07:55 -0800
Subject: [R] install problem from Github or downloaded file
In-Reply-To: <E8904C9D-12ED-4323-8F1A-FF61E5E43AE3@dcn.davis.ca.us>
References: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>
	<E8904C9D-12ED-4323-8F1A-FF61E5E43AE3@dcn.davis.ca.us>
Message-ID: <B7B98F5B-B722-4D98-A4DC-F3DA6F87696B@comcast.net>

Installation proceeded without error on a Mac ("El Cap") running R 3.3.2 using the first call to devtools::install_github. This is the DESCRIPTION file:

Package: artyfarty
Type: Package
Title: Themes for ggplot2
Version: 0.0.1
Authors at R: person("Bart","Smeets", email="bartsmeets86 at gmail.com", role=c("aut","cre"))
Description: A combination of ggplot2 themes, palettes and convenience functions.
License: MIT + file LICENSE
LazyData: TRUE
Imports: grid, tidyr, dplyr, ggplot2, grDevices, jsonlite, readbitmap
Suggests: knitr, rmarkdown, RColorBrewer, testthat
VignetteBuilder: knitr
RoxygenNote: 5.0.1
Author: Bart Smeets [aut, cre]
Maintainer: Bart Smeets <bartsmeets86 at gmail.com>
Built: R 3.3.2; ; 2017-03-02 01:00:59 UTC; unix
RemoteType: github
RemoteHost: https://api.github.com
RemoteRepo: artyfarty
RemoteUsername: bart6114
RemoteRef: master
RemoteSha: abf831d5c7cf092f5c402b903ad31196bda0a2f1
GithubRepo: artyfarty
GithubUsername: bart6114
GithubRef: master
GithubSHA1: abf831d5c7cf092f5c402b903ad31196bda0a2f1

So it has a Maintainer and you may want to contact him with a lot more detail about your setup than you have provided to this point.

-- 
David.

> On Mar 1, 2017, at 3:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> CRAN is notorious for being picky, performing hundreds of quality checks before allowing a package to be shared there. Has it occurred to you that "artyfarty", not having been through CRAN, might simply be broken?
> 
> Yes the directories you ask about are only present temporarily while the package is checked and moved into your package library, so they are "temporary" even though they are not in your TMP or TEMP directories. The missing file is almost certainly the R file, not the directory. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 1, 2017 2:44:40 PM PST, Jianling Fan <fanjianling at gmail.com> wrote:
>> Hello everyone,
>> 
>> I can install packages from CRAN, but I got some problem for
>> installing packages from Github or downloaded package files. I got
>> this problem in recent weeks.
>> 
>> example:
>> 
>>> devtools::install_github('bart6114/artyfarty')
>> Downloading GitHub repo bart6114/artyfarty at master
>> from URL https://api.github.com/repos/bart6114/artyfarty/zipball/master
>> Error in utils::unzip(src, exdir = target) :
>> cannot open file
>> 'C:/Users/FanJ/AppData/Local/Temp/Rtmp6PonUm/devtools23184c742bf4/Bart6114-artyfarty-abf831d/R/helpers.R':
>> No such file or directory
>> 
>> so, I downloaded the package and try to install it from local folder:
>> 
>>> install.packages("C:/Users/FanJ/Downloads/artyfarty-master.zip",
>> repos = NULL, type = "win.binary")
>> Error in install.packages : cannot open file
>> 'C:/Users/FanJ/Documents/R/R-3.3.2/library/file2318185d1b3c/artyfarty-master/R/helpers.R':
>> No such file or directory
>> 
>> It seems R try to create an extra folder "file2318185d1b3c".
>> 
>> I googled this problem. some people said it is caused by TMP dir. But
>> that seems not my case:
>> 
>>> Sys.getenv(c("TMP","TEMP","TMPDIR"))
>>                           TMP                                    TEMP
>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>                                TMPDIR
>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>> 
>>> .Options$unzip
>> [1] "internal"
>> 
>> 
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>> 
>> locale:
>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>> LC_MONETARY=English_Canada.1252
>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] agricolae_1.2-4         Evapotranspiration_1.10 zoo_1.7-14
>>     dplyr_0.5.0
>> [5] purrr_0.2.2             readr_1.0.0             tidyr_0.6.1
>>     tibble_1.2
>> [9] ggplot2_2.2.1           tidyverse_1.1.1
>> 
>> loaded via a namespace (and not attached):
>> [1] gtools_3.5.0      reshape2_1.4.2    splines_3.3.2     haven_1.0.0
>>     lattice_0.20-34   colorspace_1.3-2
>> [7] expm_0.999-1      AlgDesign_1.1-7.3 withr_1.0.2
>> foreign_0.8-67    DBI_0.5-1         sp_1.2-4
>> [13] modelr_0.1.0      readxl_0.1.1      plyr_1.8.4
>> stringr_1.2.0     munsell_0.4.3     combinat_0.0-8
>> [19] gtable_0.2.0      rvest_0.3.2       devtools_1.12.0
>> memoise_1.0.0     coda_0.19-1       psych_1.6.12
>> [25] forcats_0.2.0     curl_2.3          parallel_3.3.2
>> spdep_0.6-11      broom_0.4.2       Rcpp_0.12.9
>> [31] scales_0.4.1      gdata_2.17.0      jsonlite_1.2
>> deldir_0.1-12     mnormt_1.5-5      digest_0.6.12
>> [37] klaR_0.6-12       hms_0.3           stringi_1.1.2
>> gmodels_2.16.2    grid_3.3.2        tools_3.3.2
>> [43] LearnBayes_2.15   magrittr_1.5      lazyeval_0.2.0
>> cluster_2.0.5     MASS_7.3-45       Matrix_1.2-8
>> [49] xml2_1.1.1        lubridate_1.6.0   assertthat_0.1    httr_1.2.1
>>     R6_2.2.0          boot_1.3-18
>> [55] git2r_0.18.0      nlme_3.1-131
>> 
>> 
>> Any suggestions?
>> 
>> Thanks a lot!!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fanjianling at gmail.com  Thu Mar  2 02:44:54 2017
From: fanjianling at gmail.com (Jianling Fan)
Date: Wed, 1 Mar 2017 19:44:54 -0600
Subject: [R] install problem from Github or downloaded file
In-Reply-To: <B7B98F5B-B722-4D98-A4DC-F3DA6F87696B@comcast.net>
References: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>
	<E8904C9D-12ED-4323-8F1A-FF61E5E43AE3@dcn.davis.ca.us>
	<B7B98F5B-B722-4D98-A4DC-F3DA6F87696B@comcast.net>
Message-ID: <CAJ7mryKUJ0EdSY9KV-OVpnY0UhyDiTW-8-qHEXv=Px8pP53vfA@mail.gmail.com>

Thanks,

I also tried other packages from github and I got the same error. So I
think this should not be the probelm for the  "artyfarty" package.
There should be something wrong with my computer. I also uninstalled R
and re-installed it. The error happens again...

Thanks anyway.


On Wed, Mar 1, 2017 at 7:07 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> Installation proceeded without error on a Mac ("El Cap") running R 3.3.2 using the first call to devtools::install_github. This is the DESCRIPTION file:
>
> Package: artyfarty
> Type: Package
> Title: Themes for ggplot2
> Version: 0.0.1
> Authors at R: person("Bart","Smeets", email="bartsmeets86 at gmail.com", role=c("aut","cre"))
> Description: A combination of ggplot2 themes, palettes and convenience functions.
> License: MIT + file LICENSE
> LazyData: TRUE
> Imports: grid, tidyr, dplyr, ggplot2, grDevices, jsonlite, readbitmap
> Suggests: knitr, rmarkdown, RColorBrewer, testthat
> VignetteBuilder: knitr
> RoxygenNote: 5.0.1
> Author: Bart Smeets [aut, cre]
> Maintainer: Bart Smeets <bartsmeets86 at gmail.com>
> Built: R 3.3.2; ; 2017-03-02 01:00:59 UTC; unix
> RemoteType: github
> RemoteHost: https://api.github.com
> RemoteRepo: artyfarty
> RemoteUsername: bart6114
> RemoteRef: master
> RemoteSha: abf831d5c7cf092f5c402b903ad31196bda0a2f1
> GithubRepo: artyfarty
> GithubUsername: bart6114
> GithubRef: master
> GithubSHA1: abf831d5c7cf092f5c402b903ad31196bda0a2f1
>
> So it has a Maintainer and you may want to contact him with a lot more detail about your setup than you have provided to this point.
>
> --
> David.
>
>> On Mar 1, 2017, at 3:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> CRAN is notorious for being picky, performing hundreds of quality checks before allowing a package to be shared there. Has it occurred to you that "artyfarty", not having been through CRAN, might simply be broken?
>>
>> Yes the directories you ask about are only present temporarily while the package is checked and moved into your package library, so they are "temporary" even though they are not in your TMP or TEMP directories. The missing file is almost certainly the R file, not the directory.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 1, 2017 2:44:40 PM PST, Jianling Fan <fanjianling at gmail.com> wrote:
>>> Hello everyone,
>>>
>>> I can install packages from CRAN, but I got some problem for
>>> installing packages from Github or downloaded package files. I got
>>> this problem in recent weeks.
>>>
>>> example:
>>>
>>>> devtools::install_github('bart6114/artyfarty')
>>> Downloading GitHub repo bart6114/artyfarty at master
>>> from URL https://api.github.com/repos/bart6114/artyfarty/zipball/master
>>> Error in utils::unzip(src, exdir = target) :
>>> cannot open file
>>> 'C:/Users/FanJ/AppData/Local/Temp/Rtmp6PonUm/devtools23184c742bf4/Bart6114-artyfarty-abf831d/R/helpers.R':
>>> No such file or directory
>>>
>>> so, I downloaded the package and try to install it from local folder:
>>>
>>>> install.packages("C:/Users/FanJ/Downloads/artyfarty-master.zip",
>>> repos = NULL, type = "win.binary")
>>> Error in install.packages : cannot open file
>>> 'C:/Users/FanJ/Documents/R/R-3.3.2/library/file2318185d1b3c/artyfarty-master/R/helpers.R':
>>> No such file or directory
>>>
>>> It seems R try to create an extra folder "file2318185d1b3c".
>>>
>>> I googled this problem. some people said it is caused by TMP dir. But
>>> that seems not my case:
>>>
>>>> Sys.getenv(c("TMP","TEMP","TMPDIR"))
>>>                           TMP                                    TEMP
>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>>                                TMPDIR
>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>>
>>>> .Options$unzip
>>> [1] "internal"
>>>
>>>
>>>> sessionInfo()
>>> R version 3.3.2 (2016-10-31)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>
>>> locale:
>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>> LC_MONETARY=English_Canada.1252
>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] agricolae_1.2-4         Evapotranspiration_1.10 zoo_1.7-14
>>>     dplyr_0.5.0
>>> [5] purrr_0.2.2             readr_1.0.0             tidyr_0.6.1
>>>     tibble_1.2
>>> [9] ggplot2_2.2.1           tidyverse_1.1.1
>>>
>>> loaded via a namespace (and not attached):
>>> [1] gtools_3.5.0      reshape2_1.4.2    splines_3.3.2     haven_1.0.0
>>>     lattice_0.20-34   colorspace_1.3-2
>>> [7] expm_0.999-1      AlgDesign_1.1-7.3 withr_1.0.2
>>> foreign_0.8-67    DBI_0.5-1         sp_1.2-4
>>> [13] modelr_0.1.0      readxl_0.1.1      plyr_1.8.4
>>> stringr_1.2.0     munsell_0.4.3     combinat_0.0-8
>>> [19] gtable_0.2.0      rvest_0.3.2       devtools_1.12.0
>>> memoise_1.0.0     coda_0.19-1       psych_1.6.12
>>> [25] forcats_0.2.0     curl_2.3          parallel_3.3.2
>>> spdep_0.6-11      broom_0.4.2       Rcpp_0.12.9
>>> [31] scales_0.4.1      gdata_2.17.0      jsonlite_1.2
>>> deldir_0.1-12     mnormt_1.5-5      digest_0.6.12
>>> [37] klaR_0.6-12       hms_0.3           stringi_1.1.2
>>> gmodels_2.16.2    grid_3.3.2        tools_3.3.2
>>> [43] LearnBayes_2.15   magrittr_1.5      lazyeval_0.2.0
>>> cluster_2.0.5     MASS_7.3-45       Matrix_1.2-8
>>> [49] xml2_1.1.1        lubridate_1.6.0   assertthat_0.1    httr_1.2.1
>>>     R6_2.2.0          boot_1.3-18
>>> [55] git2r_0.18.0      nlme_3.1-131
>>>
>>>
>>> Any suggestions?
>>>
>>> Thanks a lot!!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Thu Mar  2 04:26:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Mar 2017 19:26:33 -0800
Subject: [R] install problem from Github or downloaded file
In-Reply-To: <CAJ7mryKUJ0EdSY9KV-OVpnY0UhyDiTW-8-qHEXv=Px8pP53vfA@mail.gmail.com>
References: <CAJ7mry+PLFu=fmVyTbL4uLCYRLbpXOufWtHhACVHp=Os1WohdA@mail.gmail.com>
	<E8904C9D-12ED-4323-8F1A-FF61E5E43AE3@dcn.davis.ca.us>
	<B7B98F5B-B722-4D98-A4DC-F3DA6F87696B@comcast.net>
	<CAJ7mryKUJ0EdSY9KV-OVpnY0UhyDiTW-8-qHEXv=Px8pP53vfA@mail.gmail.com>
Message-ID: <1F49FFA1-87E1-45F8-B502-4D23CD9F3984@comcast.net>


> On Mar 1, 2017, at 5:44 PM, Jianling Fan <fanjianling at gmail.com> wrote:
> 
> Thanks,
> 
> I also tried other packages from github and I got the same error. So I
> think this should not be the probelm for the  "artyfarty" package.
> There should be something wrong with my computer. I also uninstalled R
> and re-installed it. The error happens again...

What part of "contact [him] (or anyone to whom this question might be addressed)  with a lot more detail about your setup than you have provided to this point" have you failed to comprehend?

-- 
David "astonished" Winsemius


> 
> Thanks anyway.
> 
> 
> On Wed, Mar 1, 2017 at 7:07 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> Installation proceeded without error on a Mac ("El Cap") running R 3.3.2 using the first call to devtools::install_github. This is the DESCRIPTION file:
>> 
>> Package: artyfarty
>> Type: Package
>> Title: Themes for ggplot2
>> Version: 0.0.1
>> Authors at R: person("Bart","Smeets", email="bartsmeets86 at gmail.com", role=c("aut","cre"))
>> Description: A combination of ggplot2 themes, palettes and convenience functions.
>> License: MIT + file LICENSE
>> LazyData: TRUE
>> Imports: grid, tidyr, dplyr, ggplot2, grDevices, jsonlite, readbitmap
>> Suggests: knitr, rmarkdown, RColorBrewer, testthat
>> VignetteBuilder: knitr
>> RoxygenNote: 5.0.1
>> Author: Bart Smeets [aut, cre]
>> Maintainer: Bart Smeets <bartsmeets86 at gmail.com>
>> Built: R 3.3.2; ; 2017-03-02 01:00:59 UTC; unix
>> RemoteType: github
>> RemoteHost: https://api.github.com
>> RemoteRepo: artyfarty
>> RemoteUsername: bart6114
>> RemoteRef: master
>> RemoteSha: abf831d5c7cf092f5c402b903ad31196bda0a2f1
>> GithubRepo: artyfarty
>> GithubUsername: bart6114
>> GithubRef: master
>> GithubSHA1: abf831d5c7cf092f5c402b903ad31196bda0a2f1
>> 
>> So it has a Maintainer and you may want to contact him with a lot more detail about your setup than you have provided to this point.
>> 
>> --
>> David.
>> 
>>> On Mar 1, 2017, at 3:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> CRAN is notorious for being picky, performing hundreds of quality checks before allowing a package to be shared there. Has it occurred to you that "artyfarty", not having been through CRAN, might simply be broken?
>>> 
>>> Yes the directories you ask about are only present temporarily while the package is checked and moved into your package library, so they are "temporary" even though they are not in your TMP or TEMP directories. The missing file is almost certainly the R file, not the directory.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On March 1, 2017 2:44:40 PM PST, Jianling Fan <fanjianling at gmail.com> wrote:
>>>> Hello everyone,
>>>> 
>>>> I can install packages from CRAN, but I got some problem for
>>>> installing packages from Github or downloaded package files. I got
>>>> this problem in recent weeks.
>>>> 
>>>> example:
>>>> 
>>>>> devtools::install_github('bart6114/artyfarty')
>>>> Downloading GitHub repo bart6114/artyfarty at master
>>>> from URL https://api.github.com/repos/bart6114/artyfarty/zipball/master
>>>> Error in utils::unzip(src, exdir = target) :
>>>> cannot open file
>>>> 'C:/Users/FanJ/AppData/Local/Temp/Rtmp6PonUm/devtools23184c742bf4/Bart6114-artyfarty-abf831d/R/helpers.R':
>>>> No such file or directory
>>>> 
>>>> so, I downloaded the package and try to install it from local folder:
>>>> 
>>>>> install.packages("C:/Users/FanJ/Downloads/artyfarty-master.zip",
>>>> repos = NULL, type = "win.binary")
>>>> Error in install.packages : cannot open file
>>>> 'C:/Users/FanJ/Documents/R/R-3.3.2/library/file2318185d1b3c/artyfarty-master/R/helpers.R':
>>>> No such file or directory
>>>> 
>>>> It seems R try to create an extra folder "file2318185d1b3c".
>>>> 
>>>> I googled this problem. some people said it is caused by TMP dir. But
>>>> that seems not my case:
>>>> 
>>>>> Sys.getenv(c("TMP","TEMP","TMPDIR"))
>>>>                          TMP                                    TEMP
>>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>>>                               TMPDIR
>>>> "C:\\Users\\FanJ\\AppData\\Local\\Temp"
>>>> 
>>>>> .Options$unzip
>>>> [1] "internal"
>>>> 
>>>> 
>>>>> sessionInfo()
>>>> R version 3.3.2 (2016-10-31)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>> 
>>>> locale:
>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>> LC_MONETARY=English_Canada.1252
>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] agricolae_1.2-4         Evapotranspiration_1.10 zoo_1.7-14
>>>>    dplyr_0.5.0
>>>> [5] purrr_0.2.2             readr_1.0.0             tidyr_0.6.1
>>>>    tibble_1.2
>>>> [9] ggplot2_2.2.1           tidyverse_1.1.1
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] gtools_3.5.0      reshape2_1.4.2    splines_3.3.2     haven_1.0.0
>>>>    lattice_0.20-34   colorspace_1.3-2
>>>> [7] expm_0.999-1      AlgDesign_1.1-7.3 withr_1.0.2
>>>> foreign_0.8-67    DBI_0.5-1         sp_1.2-4
>>>> [13] modelr_0.1.0      readxl_0.1.1      plyr_1.8.4
>>>> stringr_1.2.0     munsell_0.4.3     combinat_0.0-8
>>>> [19] gtable_0.2.0      rvest_0.3.2       devtools_1.12.0
>>>> memoise_1.0.0     coda_0.19-1       psych_1.6.12
>>>> [25] forcats_0.2.0     curl_2.3          parallel_3.3.2
>>>> spdep_0.6-11      broom_0.4.2       Rcpp_0.12.9
>>>> [31] scales_0.4.1      gdata_2.17.0      jsonlite_1.2
>>>> deldir_0.1-12     mnormt_1.5-5      digest_0.6.12
>>>> [37] klaR_0.6-12       hms_0.3           stringi_1.1.2
>>>> gmodels_2.16.2    grid_3.3.2        tools_3.3.2
>>>> [43] LearnBayes_2.15   magrittr_1.5      lazyeval_0.2.0
>>>> cluster_2.0.5     MASS_7.3-45       Matrix_1.2-8
>>>> [49] xml2_1.1.1        lubridate_1.6.0   assertthat_0.1    httr_1.2.1
>>>>    R6_2.2.0          boot_1.3-18
>>>> [55] git2r_0.18.0      nlme_3.1-131
>>>> 
>>>> 
>>>> Any suggestions?
>>>> 
>>>> Thanks a lot!!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Thu Mar  2 08:29:50 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Mar 2017 07:29:50 +0000
Subject: [R] Error in model.frame.default(formula = formula, data = data,
 drop.unused.levels = TRUE, :    object is not a matrix
In-Reply-To: <1299844643.1037336.1488365500321@mail.yahoo.com>
References: <1299844643.1037336.1488365500321.ref@mail.yahoo.com>
	<1299844643.1037336.1488365500321@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18676@SRVEXCHCM301.precheza.cz>

Hi

what is result of

str(deret)

or

is.matrix(deret)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allan
> Tanaka
> Sent: Wednesday, March 1, 2017 11:52 AM
> To: r-help at r-project.org
> Subject: [R] Error in model.frame.default(formula = formula, data = data,
> drop.unused.levels = TRUE, : object is not a matrix
>
> Hi,
> I have encountered the following error, when running 'depmix' function,
> which I think has something to do with my data, and I cannot understand
> why, even though i have converted my data into as.matrix() See attached
> file

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From p_connolly at slingshot.co.nz  Thu Mar  2 09:22:40 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 2 Mar 2017 21:22:40 +1300
Subject: [R] What is se.fit in a glm predict list?
Message-ID: <20170302082239.GB22242@slingshot.co.nz>


I'm trying  to calculate a CI for predictions from a Poisson GLM object egg.glm.

Browse[2]> aa <- as.data.frame(predict(egg.glm, newdat, type = "response", se.fit = TRUE)[-3])
Browse[2]> bb <- as.data.frame(predict(egg.glm, newdat, se.fit = TRUE)[-3])
Browse[2]> aa
           fit       se.fit
1 6.144212e-07 0.0005114257
2 2.452632e+01 5.4657657443
3 1.440000e+01 2.5817126393
4 4.389796e+01 4.5533997800
5 3.820455e+01 4.4827326393
6 6.226667e+01 5.6589154967
Browse[2]> bb
         fit       se.fit
1 -14.302585 832.36979026
2   3.199747   0.22285311
3   2.667228   0.17928560
4   3.781868   0.10372691
5   3.642954   0.11733506
6   4.131426   0.09088194
Browse[2]> 

bb$fit is clearly log of aa$fit but just what is se.fit?  How do I use
it to get a CI which is calculated on the log scale?  The first one is
a bit messy since it is entirely from zeros.  Should I remove those or
would that be unnecessary?

TIA

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From pdalgd at gmail.com  Thu Mar  2 09:50:52 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Mar 2017 09:50:52 +0100
Subject: [R] What is se.fit in a glm predict list?
In-Reply-To: <20170302082239.GB22242@slingshot.co.nz>
References: <20170302082239.GB22242@slingshot.co.nz>
Message-ID: <56EC1C8F-061D-4BC1-9176-9E0E57FF9A92@gmail.com>

It comes from linearizing log(x) around the fitted value, derivative of log is 1/x, so
aa$se.fit/aa$fit == bb$se.fit

For diverged estimates, this gets dubious as the linearization only works in a neighborhood and for x not too close to the singularity of log() at zero.

-pd

> On 02 Mar 2017, at 09:22 , Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
> 
> 
> I'm trying  to calculate a CI for predictions from a Poisson GLM object egg.glm.
> 
> Browse[2]> aa <- as.data.frame(predict(egg.glm, newdat, type = "response", se.fit = TRUE)[-3])
> Browse[2]> bb <- as.data.frame(predict(egg.glm, newdat, se.fit = TRUE)[-3])
> Browse[2]> aa
>           fit       se.fit
> 1 6.144212e-07 0.0005114257
> 2 2.452632e+01 5.4657657443
> 3 1.440000e+01 2.5817126393
> 4 4.389796e+01 4.5533997800
> 5 3.820455e+01 4.4827326393
> 6 6.226667e+01 5.6589154967
> Browse[2]> bb
>         fit       se.fit
> 1 -14.302585 832.36979026
> 2   3.199747   0.22285311
> 3   2.667228   0.17928560
> 4   3.781868   0.10372691
> 5   3.642954   0.11733506
> 6   4.131426   0.09088194
> Browse[2]> 
> 
> bb$fit is clearly log of aa$fit but just what is se.fit?  How do I use
> it to get a CI which is calculated on the log scale?  The first one is
> a bit messy since it is entirely from zeros.  Should I remove those or
> would that be unnecessary?
> 
> TIA
> 
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>   ___    Patrick Connolly   
> {~._.~}                   Great minds discuss ideas    
> _( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
> (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chalabi.elahe at yahoo.de  Thu Mar  2 11:53:03 2017
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 2 Mar 2017 10:53:03 +0000 (UTC)
Subject: [R] Averaging without NAs
References: <1795862188.402029.1488451983069.ref@mail.yahoo.com>
Message-ID: <1795862188.402029.1488451983069@mail.yahoo.com>

Hi all,

The question seems easy but I could not find an answer for it. I have the following column in my data frame and I want to take average of the column excluding the number of NAs. 

$X2016.Q1 : int 47 53 75 97 NA NA 23 NA 43 NA ....

Does anyone know how to do that?
Thanks for any help 
Elahe


From chalabi.elahe at yahoo.de  Thu Mar  2 11:57:24 2017
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 2 Mar 2017 10:57:24 +0000 (UTC)
Subject: [R] Fw: Averaging without NAs
In-Reply-To: <1795862188.402029.1488451983069@mail.yahoo.com>
References: <1795862188.402029.1488451983069.ref@mail.yahoo.com>
	<1795862188.402029.1488451983069@mail.yahoo.com>
Message-ID: <1478680579.407473.1488452244588@mail.yahoo.com>



The question seems easy but I could not find an answer for it. I have the following column in my data frame and I want to take average of the column excluding the number of NAs. 

$X2016.Q1 : int 47 53 75 97 NA NA 23 NA 43 NA ....

Does anyone know how to do that?
Thanks for any help 
Elahe


From ulrik.stervbo at gmail.com  Thu Mar  2 12:09:20 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 02 Mar 2017 11:09:20 +0000
Subject: [R] Averaging without NAs
In-Reply-To: <1795862188.402029.1488451983069@mail.yahoo.com>
References: <1795862188.402029.1488451983069.ref@mail.yahoo.com>
	<1795862188.402029.1488451983069@mail.yahoo.com>
Message-ID: <CAKVAULPJbeFkM1BFNUM5O_XhzYmadzptVF4Sta-N6EYppMA5KA@mail.gmail.com>

Hi Elahe,

?mean

in particular the na.rm argument.

HTH
Ulrik

On Thu, 2 Mar 2017 at 11:55 ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
>
> The question seems easy but I could not find an answer for it. I have the
> following column in my data frame and I want to take average of the column
> excluding the number of NAs.
>
> $X2016.Q1 : int 47 53 75 97 NA NA 23 NA 43 NA ....
>
> Does anyone know how to do that?
> Thanks for any help
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Thu Mar  2 12:15:10 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 2 Mar 2017 12:15:10 +0100
Subject: [R] Averaging without NAs
In-Reply-To: <1795862188.402029.1488451983069@mail.yahoo.com>
References: <1795862188.402029.1488451983069.ref@mail.yahoo.com>
	<1795862188.402029.1488451983069@mail.yahoo.com>
Message-ID: <65B2AEB1-F2A3-4B33-8F64-992D23F69898@xs4all.nl>


> On 2 Mar 2017, at 11:53, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> 
> The question seems easy but I could not find an answer for it. I have the following column in my data frame and I want to take average of the column excluding the number of NAs. 
> 
> $X2016.Q1 : int 47 53 75 97 NA NA 23 NA 43 NA ....
> 
> Does anyone know how to do that?

Have you tried looking in the help for mean?

?mean

Berend Hasselman

> Thanks for any help 
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shivipmp82 at gmail.com  Thu Mar  2 13:00:21 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 2 Mar 2017 17:30:21 +0530
Subject: [R] Reading Multiple Files for Text Mining in R Using TM Package?
Message-ID: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>

Hi All ,

I am trying to read few csv files for some text mining assignment.

I have used this command to check the # of files in the working directory:

length(dir(path="D:/Shivi/R Project", all.files = TRUE))
This results to more than 220 approx.

I just need 3 files from these to use for the text mining purpose however
if i use:

docs<- Corpus(DirSource(directory = "D:/Shivi/R Project"))
this reads all the 220+ files

Please suggest how to achieve this feat. Have researched on stack overflow,
where they have used multiple read.csv statements to read multiple files
however do not find that very effective way.

Thank you.

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Thu Mar  2 13:39:49 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 2 Mar 2017 13:39:49 +0100
Subject: [R] xtable: Width of Columns
Message-ID: <OFFD1F8D6D.8AA9AF90-ONC12580D7.00454AB9-C12580D7.00459040@lotus.hawesko.de>

Hi All,

I have the following code in R Markdown document:

```{r, results = "asis", echo = FALSE}
library(xtable)
response <- as.data.frame(matrix(NA, 2, 2))
colnames(response) <- c("Anzahl", "Prozent")
rownames(response) <- c("gesamte R?cksendungen (brutto)  ",
                        "auswertbare Frageb?gen (netto)  ")
response[[1, 1]] <- 1
response[[1, 2]] <- 2.0
response[[2, 1]] <- 3
response[[2, 2]] <- 4.0

response_table <- xtable(
  response, 
  caption = "R?cklauf und R?cklaufquote",
  label = "Responsequote",
  display = c("s","d","f"),
  digits = 1,
  align = c("l", "c", "c") #  auto = TRUE
  )

print.xtable(
  response_table,
  type = "html",
  caption.placement = "top",
  format.args = list(
    big.mark = ".",
    decimal.mark = ","),
  size = 500,
  width = 100)
```

and would like to control the width of the columns. But columns width is 
always aligned to the content.

Is there a way to give the columns width, e.g. 25 characters, for all 
columns or for each column separately to get more spacing for the text and 
the borders of the table?

Kind regards

Georg

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Mar  2 14:03:49 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Mar 2017 13:03:49 +0000
Subject: [R] Reading Multiple Files for Text Mining in R Using TM
 Package?
In-Reply-To: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>
References: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18801@SRVEXCHCM301.precheza.cz>

Hi

Hmm, if you need only three files why not copy them to another directory and use the same command for reading them from that other directory.

You probably could do this from R itself however I am almost sure that doing this task by OS is far less complicated.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi
> Bhatia
> Sent: Thursday, March 2, 2017 1:00 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] Reading Multiple Files for Text Mining in R Using TM Package?
>
> Hi All ,
>
> I am trying to read few csv files for some text mining assignment.
>
> I have used this command to check the # of files in the working directory:
>
> length(dir(path="D:/Shivi/R Project", all.files = TRUE)) This results to more
> than 220 approx.
>
> I just need 3 files from these to use for the text mining purpose however if i
> use:
>
> docs<- Corpus(DirSource(directory = "D:/Shivi/R Project")) this reads all the
> 220+ files
>
> Please suggest how to achieve this feat. Have researched on stack overflow,
> where they have used multiple read.csv statements to read multiple files
> however do not find that very effective way.
>
> Thank you.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From shivipmp82 at gmail.com  Thu Mar  2 14:06:10 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 2 Mar 2017 18:36:10 +0530
Subject: [R] Reading Multiple Files for Text Mining in R Using TM
	Package?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18801@SRVEXCHCM301.precheza.cz>
References: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18801@SRVEXCHCM301.precheza.cz>
Message-ID: <CAB=p7Sqp7Xt23GHyDv-_ksv5=-kG-0xRFVFWH=GMXocLGMaoYg@mail.gmail.com>

Hi Pikal,

So i understand it correctly you are advising to temporarily change the
working directory using the setwd syntax.

Thanks, Shivi.

On Thu, Mar 2, 2017 at 6:33 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Hmm, if you need only three files why not copy them to another directory
> and use the same command for reading them from that other directory.
>
> You probably could do this from R itself however I am almost sure that
> doing this task by OS is far less complicated.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi
> > Bhatia
> > Sent: Thursday, March 2, 2017 1:00 PM
> > To: R-help <r-help at r-project.org>
> > Subject: [R] Reading Multiple Files for Text Mining in R Using TM
> Package?
> >
> > Hi All ,
> >
> > I am trying to read few csv files for some text mining assignment.
> >
> > I have used this command to check the # of files in the working
> directory:
> >
> > length(dir(path="D:/Shivi/R Project", all.files = TRUE)) This results to
> more
> > than 220 approx.
> >
> > I just need 3 files from these to use for the text mining purpose
> however if i
> > use:
> >
> > docs<- Corpus(DirSource(directory = "D:/Shivi/R Project")) this reads
> all the
> > 220+ files
> >
> > Please suggest how to achieve this feat. Have researched on stack
> overflow,
> > where they have used multiple read.csv statements to read multiple files
> > however do not find that very effective way.
> >
> > Thank you.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Mar  2 14:16:28 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Mar 2017 13:16:28 +0000
Subject: [R] Reading Multiple Files for Text Mining in R Using TM
 Package?
In-Reply-To: <CAB=p7Sqp7Xt23GHyDv-_ksv5=-kG-0xRFVFWH=GMXocLGMaoYg@mail.gmail.com>
References: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18801@SRVEXCHCM301.precheza.cz>
	<CAB=p7Sqp7Xt23GHyDv-_ksv5=-kG-0xRFVFWH=GMXocLGMaoYg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18827@SRVEXCHCM301.precheza.cz>

Well,

you read documents from

directory = "D:/Shivi/R Project"

and you say that you have 220+ files in this directory

If you move respective files into some working directory you could use let say

docs<- Corpus(DirSource(directory = "D:/Shivi/R Project/work"))

without need to use setwd.

But maybe I do not understand your problem corrrectly.

Cheers
Petr


From: Shivi Bhatia [mailto:shivipmp82 at gmail.com]
Sent: Thursday, March 2, 2017 2:06 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Reading Multiple Files for Text Mining in R Using TM Package?

Hi Pikal,

So i understand it correctly you are advising to temporarily change the working directory using the setwd syntax.

Thanks, Shivi.

On Thu, Mar 2, 2017 at 6:33 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Hmm, if you need only three files why not copy them to another directory and use the same command for reading them from that other directory.

You probably could do this from R itself however I am almost sure that doing this task by OS is far less complicated.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Shivi
> Bhatia
> Sent: Thursday, March 2, 2017 1:00 PM
> To: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Reading Multiple Files for Text Mining in R Using TM Package?
>
> Hi All ,
>
> I am trying to read few csv files for some text mining assignment.
>
> I have used this command to check the # of files in the working directory:
>
> length(dir(path="D:/Shivi/R Project", all.files = TRUE)) This results to more
> than 220 approx.
>
> I just need 3 files from these to use for the text mining purpose however if i
> use:
>
> docs<- Corpus(DirSource(directory = "D:/Shivi/R Project")) this reads all the
> 220+ files
>
> Please suggest how to achieve this feat. Have researched on stack overflow,
> where they have used multiple read.csv statements to read multiple files
> however do not find that very effective way.
>
> Thank you.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.




________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Thu Mar  2 14:29:21 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 2 Mar 2017 18:59:21 +0530
Subject: [R] Reading Multiple Files for Text Mining in R Using TM
	Package?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18827@SRVEXCHCM301.precheza.cz>
References: <CAB=p7SpvZCq-YSutNPKPNQw6XK7j+3BDVMNi=KCpXDJG0mfdoA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18801@SRVEXCHCM301.precheza.cz>
	<CAB=p7Sqp7Xt23GHyDv-_ksv5=-kG-0xRFVFWH=GMXocLGMaoYg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18827@SRVEXCHCM301.precheza.cz>
Message-ID: <CAB=p7SpvzwtFekhTFES-GoPeuG2iyeBuT96u+=xD2Ls_A0we3g@mail.gmail.com>

Thanks Pikal. This worked for me.

Regards, Shivi

On Thu, Mar 2, 2017 at 6:46 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Well,
>
>
>
> you read documents from
>
>
>
> directory = "D:/Shivi/R Project"
>
>
>
> and you say that you have 220+ files in this directory
>
>
>
> If you move respective files into some working directory you could use let
> say
>
>
>
> docs<- Corpus(DirSource(directory = "D:/Shivi/R Project/work"))
>
>
>
> without need to use setwd.
>
>
>
> But maybe I do not understand your problem corrrectly.
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* Shivi Bhatia [mailto:shivipmp82 at gmail.com]
> *Sent:* Thursday, March 2, 2017 2:06 PM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] Reading Multiple Files for Text Mining in R Using TM
> Package?
>
>
>
> Hi Pikal,
>
>
>
> So i understand it correctly you are advising to temporarily change the
> working directory using the setwd syntax.
>
>
>
> Thanks, Shivi.
>
>
>
> On Thu, Mar 2, 2017 at 6:33 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> Hmm, if you need only three files why not copy them to another directory
> and use the same command for reading them from that other directory.
>
> You probably could do this from R itself however I am almost sure that
> doing this task by OS is far less complicated.
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi
> > Bhatia
> > Sent: Thursday, March 2, 2017 1:00 PM
> > To: R-help <r-help at r-project.org>
> > Subject: [R] Reading Multiple Files for Text Mining in R Using TM
> Package?
> >
> > Hi All ,
> >
> > I am trying to read few csv files for some text mining assignment.
> >
> > I have used this command to check the # of files in the working
> directory:
> >
> > length(dir(path="D:/Shivi/R Project", all.files = TRUE)) This results to
> more
> > than 220 approx.
> >
> > I just need 3 files from these to use for the text mining purpose
> however if i
> > use:
> >
> > docs<- Corpus(DirSource(directory = "D:/Shivi/R Project")) this reads
> all the
> > 220+ files
> >
> > Please suggest how to achieve this feat. Have researched on stack
> overflow,
> > where they have used multiple read.csv statements to read multiple files
> > however do not find that very effective way.
> >
> > Thank you.
> >
>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From h.morgan at har.mrc.ac.uk  Thu Mar  2 14:37:53 2017
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Thu, 2 Mar 2017 13:37:53 +0000
Subject: [R] Problems outputting ggplot2 graphics to pdf
Message-ID: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>

Hi All,

I am having trouble outputting ggplot2 graphics to pdf as part of a
script.  It works if when I pipe the script into R or if I type the
commands directly into the terminal, but not if I load it using the
source(..) command.  In this case the outputted pdf is always size 3611,
and it fails to open with the error "This document contains no pages".

As an example I wrap the create pdf commands around the 1st example in
?ggplot:

$ cat test.R

library(ggplot2)

pdf("test.pdf")

df <- data.frame(
   gp = factor(rep(letters[1:3], each = 10)),
   y = rnorm(30)
)
ds <- plyr::ddply(df, "gp", plyr::summarise, mean = mean(y), sd = sd(y))
ggplot(df, aes(gp, y)) +
   geom_point() +
   geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)

dev.off()

Piping it into R works:

$ R --no-save < test.R

...

$ ll test.pdf

-rw-rw-r-- 1 user group 4842 Mar  2 13:18 test.pdf

This file opens fine and has a graphic.  If I repeat the process using
source():

$ R --no-save

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
...

 > source("test.R")
 >

$ ll test.pdf
-rw-rw-r-- 1 user group 3611 Mar  2 13:25 test.pdf

This file fails to open, and always has the size 3611.

Any help appreciated,

Hugh



This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm


From rmh at temple.edu  Thu Mar  2 14:42:50 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 2 Mar 2017 08:42:50 -0500
Subject: [R] Problems outputting ggplot2 graphics to pdf
In-Reply-To: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
References: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
Message-ID: <CAGx1TMADStkjCfdzDebT6qsTMMkigN_4067+owBvJWqE=sMsuA@mail.gmail.com>

You need the print() statement.  See FAQ  7.22 in file
system.file("../../doc/FAQ")


7.22 Why do lattice/trellis graphics not work?
==============================================

The most likely reason is that you forgot to tell R to display the
graph.  Lattice functions such as 'xyplot()' create a graph object, but
do not display it (the same is true of *ggplot2*
(https://CRAN.R-project.org/package=ggplot2) graphics, and Trellis
graphics in S-PLUS).  The 'print()' method for the graph object produces
the actual display.  When you use these functions interactively at the
command line, the result is automatically printed, but in 'source()' or
inside your own functions you will need an explicit 'print()' statement.

On Thu, Mar 2, 2017 at 8:37 AM, Hugh Morgan <h.morgan at har.mrc.ac.uk> wrote:
> Hi All,
>
> I am having trouble outputting ggplot2 graphics to pdf as part of a
> script.  It works if when I pipe the script into R or if I type the
> commands directly into the terminal, but not if I load it using the
> source(..) command.  In this case the outputted pdf is always size 3611,
> and it fails to open with the error "This document contains no pages".
>
> As an example I wrap the create pdf commands around the 1st example in
> ?ggplot:
>
> $ cat test.R
>
> library(ggplot2)
>
> pdf("test.pdf")
>
> df <- data.frame(
>   gp = factor(rep(letters[1:3], each = 10)),
>   y = rnorm(30)
> )
> ds <- plyr::ddply(df, "gp", plyr::summarise, mean = mean(y), sd = sd(y))
> ggplot(df, aes(gp, y)) +
>   geom_point() +
>   geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
>
> dev.off()
>
> Piping it into R works:
>
> $ R --no-save < test.R
>
> ...
>
> $ ll test.pdf
>
> -rw-rw-r-- 1 user group 4842 Mar  2 13:18 test.pdf
>
> This file opens fine and has a graphic.  If I repeat the process using
> source():
>
> $ R --no-save
>
> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> ...
>
>> source("test.R")
>>
>
> $ ll test.pdf
> -rw-rw-r-- 1 user group 3611 Mar  2 13:25 test.pdf
>
> This file fails to open, and always has the size 3611.
>
> Any help appreciated,
>
> Hugh
>
>
>
> This email may have a PROTECTIVE MARKING, for an explanation please see:
> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Mar  2 14:46:35 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 2 Mar 2017 08:46:35 -0500
Subject: [R] Problems outputting ggplot2 graphics to pdf
In-Reply-To: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
References: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
Message-ID: <6f76573e-9f2d-ff87-dc0d-e0cc8fcf916d@gmail.com>

On 02/03/2017 8:37 AM, Hugh Morgan wrote:
> Hi All,
>
> I am having trouble outputting ggplot2 graphics to pdf as part of a
> script.  It works if when I pipe the script into R or if I type the
> commands directly into the terminal, but not if I load it using the
> source(..) command.  In this case the outputted pdf is always size 3611,
> and it fails to open with the error "This document contains no pages".
>
> As an example I wrap the create pdf commands around the 1st example in
> ?ggplot:
>
> $ cat test.R
>
> library(ggplot2)
>
> pdf("test.pdf")
>
> df <- data.frame(
>    gp = factor(rep(letters[1:3], each = 10)),
>    y = rnorm(30)
> )
> ds <- plyr::ddply(df, "gp", plyr::summarise, mean = mean(y), sd = sd(y))
> ggplot(df, aes(gp, y)) +
>    geom_point() +
>    geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
>
> dev.off()
>
> Piping it into R works:
>
> $ R --no-save < test.R
>
> ...
>
> $ ll test.pdf
>
> -rw-rw-r-- 1 user group 4842 Mar  2 13:18 test.pdf
>
> This file opens fine and has a graphic.  If I repeat the process using
> source():
>
> $ R --no-save
>
> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> ...
>
>  > source("test.R")
>  >
>
> $ ll test.pdf
> -rw-rw-r-- 1 user group 3611 Mar  2 13:25 test.pdf
>
> This file fails to open, and always has the size 3611.
>
> Any help appreciated,

ggplot2 graphics only appear when they are printed.  By default 
source("test.R") won't print anything.  Set print.eval = TRUE (or echo = 
TRUE) to get it to print.

Duncan Murdoch


From h.morgan at har.mrc.ac.uk  Thu Mar  2 14:51:44 2017
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Thu, 2 Mar 2017 13:51:44 +0000
Subject: [R] Problems outputting ggplot2 graphics to pdf
In-Reply-To: <CAGx1TMADStkjCfdzDebT6qsTMMkigN_4067+owBvJWqE=sMsuA@mail.gmail.com>
References: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
	<CAGx1TMADStkjCfdzDebT6qsTMMkigN_4067+owBvJWqE=sMsuA@mail.gmail.com>
Message-ID: <4b1b8cfb-c8cb-f374-27c9-65e873189e32@har.mrc.ac.uk>

Thanks for the help.  My test script was changed with:

p <- ggplot(df, aes(gp, y)) +
   geom_point() +
   geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
print(p)

And this now works.

Cheers,

Hugh


On 02/03/17 13:42, Richard M. Heiberger wrote:
> You need the print() statement.  See FAQ  7.22 in file
> system.file("../../doc/FAQ")
>
>
> 7.22 Why do lattice/trellis graphics not work?
> ==============================================
>
> The most likely reason is that you forgot to tell R to display the
> graph.  Lattice functions such as 'xyplot()' create a graph object, but
> do not display it (the same is true of *ggplot2*
> (https://CRAN.R-project.org/package=ggplot2) graphics, and Trellis
> graphics in S-PLUS).  The 'print()' method for the graph object produces
> the actual display.  When you use these functions interactively at the
> command line, the result is automatically printed, but in 'source()' or
> inside your own functions you will need an explicit 'print()' statement.
>
> On Thu, Mar 2, 2017 at 8:37 AM, Hugh Morgan <h.morgan at har.mrc.ac.uk> wrote:
>> Hi All,
>>
>> I am having trouble outputting ggplot2 graphics to pdf as part of a
>> script.  It works if when I pipe the script into R or if I type the
>> commands directly into the terminal, but not if I load it using the
>> source(..) command.  In this case the outputted pdf is always size 3611,
>> and it fails to open with the error "This document contains no pages".
>>
>> As an example I wrap the create pdf commands around the 1st example in
>> ?ggplot:
>>
>> $ cat test.R
>>
>> library(ggplot2)
>>
>> pdf("test.pdf")
>>
>> df <- data.frame(
>>    gp = factor(rep(letters[1:3], each = 10)),
>>    y = rnorm(30)
>> )
>> ds <- plyr::ddply(df, "gp", plyr::summarise, mean = mean(y), sd = sd(y))
>> ggplot(df, aes(gp, y)) +
>>    geom_point() +
>>    geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
>>
>> dev.off()
>>
>> Piping it into R works:
>>
>> $ R --no-save < test.R
>>
>> ...
>>
>> $ ll test.pdf
>>
>> -rw-rw-r-- 1 user group 4842 Mar  2 13:18 test.pdf
>>
>> This file opens fine and has a graphic.  If I repeat the process using
>> source():
>>
>> $ R --no-save
>>
>> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
>> ...
>>
>>> source("test.R")
>>>
>> $ ll test.pdf
>> -rw-rw-r-- 1 user group 3611 Mar  2 13:25 test.pdf
>>
>> This file fails to open, and always has the size 3611.
>>
>> Any help appreciated,
>>
>> Hugh
>>
>>
>>
>> This email may have a PROTECTIVE MARKING, for an explanation please see:
>> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm


From paulbernal07 at gmail.com  Thu Mar  2 16:27:45 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 2 Mar 2017 10:27:45 -0500
Subject: [R] Problem with workspace and publishWebService function in RStudio
Message-ID: <CAMOcQfNMKsH8mEEkKKGg6-kAcLrVNmz_+qM=HPdXeBFjaEDqjg@mail.gmail.com>

Dear all,

I am trying to deploy an RStudio predictive model into Microsoft Azure
Machine Learning Studio (see code below), however, I keep getting two error
messages: (1)Error: could not find function "workspace", and (2) Error:
could not find function "publishWebService", I am wondering what could be
causing this.

This are the details of my installed RStudio:
> version
               _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          3.2
year           2016
month          10
day            31
svn rev        71607
language       R
version.string R version 3.3.2 (2016-10-31)
nickname       Sincere Pumpkin Patch

require(AzureML) || installed.packages("AzureML")

library(AzureML)

install.packages("curl")
install.packages("RJSONIO")
install.packages("uuid")
install.packages("jsonlite")
install.packages("codetools")
install.packages("base64enc")
install.packages("httr")
install.packages("data.table")
install.packages("df2json")
install.packages("rjson")

if(!require("devtools")) install.packages("devtools")
devtools::install_github("RevolutionAnalytics/azureml")

#loading required packages

library(curl)
library(RJSONIO)
library(uuid)
library(jsonlite)
library(codetools)
library(base64enc)
library(httr)
library(data.table)
library(df2json)
library(rjson)
library(devtools)

#devtools::install_github("Azure-MachineLearning-ClientLibrary-R"),
"Azure", subdir="AzureML")

wsID<-'##########'

authToken<-'###############'

w<-workspace(wsID,authToken)

add<-function(x,y){return(x+y)}

newService<-publishWebService(w,'add', 'add_datas', list('x' = 'int', 'y' =
'int'), list('z' = 'int'), wsID, authToken)

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Mar  2 17:03:44 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 02 Mar 2017 16:03:44 +0000
Subject: [R] Problems outputting ggplot2 graphics to pdf
In-Reply-To: <4b1b8cfb-c8cb-f374-27c9-65e873189e32@har.mrc.ac.uk>
References: <ec9563a0-5ccb-1865-2186-2a90b0be82c4@har.mrc.ac.uk>
	<CAGx1TMADStkjCfdzDebT6qsTMMkigN_4067+owBvJWqE=sMsuA@mail.gmail.com>
	<4b1b8cfb-c8cb-f374-27c9-65e873189e32@har.mrc.ac.uk>
Message-ID: <CAKVAULOqms4WVribntTfwo3DTFVPHK7GXZQh9xh7cNPyK+8Z6A@mail.gmail.com>

Hi Hugh,

I believe the recommended way of saving ggplots is through ggsave. It
defaults to take the latest plot displayed, but you can specify which plot
to save by passing the variable to the plot argument.

If you need to save multiple plots in one file, you have to create a
multipage plot using gridExtra::marrangeGrob.

Best wishes,
Ulrik

On Thu, 2 Mar 2017 at 14:53 Hugh Morgan <h.morgan at har.mrc.ac.uk> wrote:

> Thanks for the help.  My test script was changed with:
>
> p <- ggplot(df, aes(gp, y)) +
>    geom_point() +
>    geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
> print(p)
>
> And this now works.
>
> Cheers,
>
> Hugh
>
>
> On 02/03/17 13:42, Richard M. Heiberger wrote:
> > You need the print() statement.  See FAQ  7.22 in file
> > system.file("../../doc/FAQ")
> >
> >
> > 7.22 Why do lattice/trellis graphics not work?
> > ==============================================
> >
> > The most likely reason is that you forgot to tell R to display the
> > graph.  Lattice functions such as 'xyplot()' create a graph object, but
> > do not display it (the same is true of *ggplot2*
> > (https://CRAN.R-project.org/package=ggplot2) graphics, and Trellis
> > graphics in S-PLUS).  The 'print()' method for the graph object produces
> > the actual display.  When you use these functions interactively at the
> > command line, the result is automatically printed, but in 'source()' or
> > inside your own functions you will need an explicit 'print()' statement.
> >
> > On Thu, Mar 2, 2017 at 8:37 AM, Hugh Morgan <h.morgan at har.mrc.ac.uk>
> wrote:
> >> Hi All,
> >>
> >> I am having trouble outputting ggplot2 graphics to pdf as part of a
> >> script.  It works if when I pipe the script into R or if I type the
> >> commands directly into the terminal, but not if I load it using the
> >> source(..) command.  In this case the outputted pdf is always size 3611,
> >> and it fails to open with the error "This document contains no pages".
> >>
> >> As an example I wrap the create pdf commands around the 1st example in
> >> ?ggplot:
> >>
> >> $ cat test.R
> >>
> >> library(ggplot2)
> >>
> >> pdf("test.pdf")
> >>
> >> df <- data.frame(
> >>    gp = factor(rep(letters[1:3], each = 10)),
> >>    y = rnorm(30)
> >> )
> >> ds <- plyr::ddply(df, "gp", plyr::summarise, mean = mean(y), sd = sd(y))
> >> ggplot(df, aes(gp, y)) +
> >>    geom_point() +
> >>    geom_point(data = ds, aes(y = mean), colour = 'red', size = 3)
> >>
> >> dev.off()
> >>
> >> Piping it into R works:
> >>
> >> $ R --no-save < test.R
> >>
> >> ...
> >>
> >> $ ll test.pdf
> >>
> >> -rw-rw-r-- 1 user group 4842 Mar  2 13:18 test.pdf
> >>
> >> This file opens fine and has a graphic.  If I repeat the process using
> >> source():
> >>
> >> $ R --no-save
> >>
> >> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> >> ...
> >>
> >>> source("test.R")
> >>>
> >> $ ll test.pdf
> >> -rw-rw-r-- 1 user group 3611 Mar  2 13:25 test.pdf
> >>
> >> This file fails to open, and always has the size 3611.
> >>
> >> Any help appreciated,
> >>
> >> Hugh
> >>
> >>
> >>
> >> This email may have a PROTECTIVE MARKING, for an explanation please see:
> >>
> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>
> This email may have a PROTECTIVE MARKING, for an explanation please see:
> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar  2 17:08:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Mar 2017 08:08:21 -0800
Subject: [R] Problem with workspace and publishWebService function in
	RStudio
In-Reply-To: <CAMOcQfNMKsH8mEEkKKGg6-kAcLrVNmz_+qM=HPdXeBFjaEDqjg@mail.gmail.com>
References: <CAMOcQfNMKsH8mEEkKKGg6-kAcLrVNmz_+qM=HPdXeBFjaEDqjg@mail.gmail.com>
Message-ID: <CAGxFJbRKqWxPWXUeNCTeD6TDwjBvb=qexdVg_qDzKz1A9g15qQ@mail.gmail.com>

You seem to be confusing R and RStudio. The latter is an IDE + more
for the former, which is open source statistics and data analysis
software (+ more). The details you show above are for R, not RStudio.
They are entirely separate.

As this seems to be a non-CRAN rather special package, you may have to
contact the package maintainer. It sounds like you are missing
components or they are installed where the package can't find them. Of
course, this assumes that you have already carefully consulted the
package docs, some of which may be on github.

-- Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 2, 2017 at 7:27 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear all,
>
> I am trying to deploy an RStudio predictive model into Microsoft Azure
> Machine Learning Studio (see code below), however, I keep getting two error
> messages: (1)Error: could not find function "workspace", and (2) Error:
> could not find function "publishWebService", I am wondering what could be
> causing this.
>
> This are the details of my installed RStudio:
>> version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          3.2
> year           2016
> month          10
> day            31
> svn rev        71607
> language       R
> version.string R version 3.3.2 (2016-10-31)
> nickname       Sincere Pumpkin Patch
>
> require(AzureML) || installed.packages("AzureML")
>
> library(AzureML)
>
> install.packages("curl")
> install.packages("RJSONIO")
> install.packages("uuid")
> install.packages("jsonlite")
> install.packages("codetools")
> install.packages("base64enc")
> install.packages("httr")
> install.packages("data.table")
> install.packages("df2json")
> install.packages("rjson")
>
> if(!require("devtools")) install.packages("devtools")
> devtools::install_github("RevolutionAnalytics/azureml")
>
> #loading required packages
>
> library(curl)
> library(RJSONIO)
> library(uuid)
> library(jsonlite)
> library(codetools)
> library(base64enc)
> library(httr)
> library(data.table)
> library(df2json)
> library(rjson)
> library(devtools)
>
> #devtools::install_github("Azure-MachineLearning-ClientLibrary-R"),
> "Azure", subdir="AzureML")
>
> wsID<-'##########'
>
> authToken<-'###############'
>
> w<-workspace(wsID,authToken)
>
> add<-function(x,y){return(x+y)}
>
> newService<-publishWebService(w,'add', 'add_datas', list('x' = 'int', 'y' =
> 'int'), list('z' = 'int'), wsID, authToken)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From SWay at meco.com  Thu Mar  2 17:23:46 2017
From: SWay at meco.com (Shawn Way)
Date: Thu, 2 Mar 2017 16:23:46 +0000
Subject: [R] Extracting information from a tm corpus.
Message-ID: <7cbd769605304e64bff78e10bee61a25@CTC-HOU-EXMB-02.ctcloud.local>

I'm trying to use the tm package to extract text from a corpus of documents.  I'm able to read in a set of PDF's and get a corpus that is filtered to include all the documents that contain a term, for example, "hot water".  I'm also able to get a list of the documents using the names() function but I just cannot get a handle on getting the lines out of the corpus.

I would like to get a corpus that had just the filtered content out, ie the lines containing the term.

I can manage to do this using something like :

  library(tm)
  library(tidyverse)
  library(tidytext)
  library(stringr)
  cname <- file.path(".","pdfs")
  docs <- Corpus(DirSource(cname), readerControl=list(reader=readPDF))
  docs <- tm_map(docs, content_transformer(tolower))

  search.par <- c("18")
  docs_filtered <- docs %>%
      tm_filter(FUN=function(x) any(grep(search.par, content(x))))


content(docs_filtered[[1]])[grep(search.par,content(docs_filtered[[1]]))]

This gives me the lines that contain the term "18"  in corpus document 1.  Is there any way to do this for all the corpus documents?

What I would like is something that has the lines containing the search parameter in the corpus document to allow printing, at least to screen.

Thank you!

Shawn Way
???


From tungakantarci at gmail.com  Thu Mar  2 19:20:32 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Thu, 2 Mar 2017 19:20:32 +0100
Subject: [R] Selecting rows and columns of a data frame using relational
	operators
Message-ID: <CAMDpC=vxjOdGPyJNZvketohV5gwPkL3dKJz-whepiaVz8gYEGA@mail.gmail.com>

Thank you for all the helpful answers.

Tunga


From tungakantarci at gmail.com  Thu Mar  2 19:32:04 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Thu, 2 Mar 2017 19:32:04 +0100
Subject: [R] Selecting rows and columns of a data frame using relational
	operators
Message-ID: <CAMDpC=ush0ym5mAWkqbU=j-ga1vcmgNWae8KE7uURngXK-M-5w@mail.gmail.com>

Thank you for all the helpful answers.

Tunga


From andrejpfavia at gmail.com  Thu Mar  2 01:29:07 2017
From: andrejpfavia at gmail.com (Andrej Favia)
Date: Wed, 1 Mar 2017 19:29:07 -0500
Subject: [R] Looking to understand GPU acceleration in R
Message-ID: <CAENFiWBy4UjaHnFSmFUWcKuTai_ZKFnm9eU6JbGPX4PXwWsjGw@mail.gmail.com>

I am a casual user looking to learn about GPU acceleration in R... at a
"new to computers" level (do not use overly technical language with me as I
will not understand what you are saying).

I am on macOS Sierra with an Intel Iris Pro GPU.

1. Can someone produce any simple example in R that uses GPU processing for
my GPU?

2. Is there a way to use the GPU to do an iterative process, such as the
Euler method? This is the kind where, let's say

x <- 5
x <- sin(x) + 3 (or some other complicated recursion)

and repeat this until 10000 steps are reached.

	[[alternative HTML version deleted]]


From ngbolin91 at gmail.com  Thu Mar  2 12:01:16 2017
From: ngbolin91 at gmail.com (Ng Bo Lin)
Date: Thu, 2 Mar 2017 19:01:16 +0800
Subject: [R] Fw: Averaging without NAs
In-Reply-To: <1478680579.407473.1488452244588@mail.yahoo.com>
References: <1795862188.402029.1488451983069.ref@mail.yahoo.com>
	<1795862188.402029.1488451983069@mail.yahoo.com>
	<1478680579.407473.1488452244588@mail.yahoo.com>
Message-ID: <88AB3489-AA77-4E7F-B3E1-791D2F9C23BD@gmail.com>

Hi Elahe,

You can do so using the mean function, mean(), by specifying an additional argument, na.rm = TRUE. In this case, you specify that you wish to remove (rm) all NA values in the columns.

?> mean($X2016.Q1, na.rm = T).

By default, na.rm is set to FALSE, so mean() will return a NA value.

Hope this helps!

Regards,
Bo Lin
> On 2 Mar 2017, at 6:57 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> 
> 
> The question seems easy but I could not find an answer for it. I have the following column in my data frame and I want to take average of the column excluding the number of NAs. 
> 
> $X2016.Q1 : int 47 53 75 97 NA NA 23 NA 43 NA ....
> 
> Does anyone know how to do that?
> Thanks for any help 
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marcus at deltalima.org  Thu Mar  2 12:09:40 2017
From: marcus at deltalima.org (Marcus Hanisch)
Date: Thu, 02 Mar 2017 12:09:40 +0100
Subject: [R] Leave One Group Out with caret
Message-ID: <3fd11d24a7ce0a28c9a3b84005573fd2@deltalima.org>

In Social psychology we are working on a project where we try to predict 
relationship quality (outcome) by personality (features). Main goal is 
to contribute to better match people with have higher chances to have a 
happy long lasting romantic relationship. I would be very grateful if 
you could help me with this by answering the following question:

At the moment, in R the k-fold-cv randomly sorts rows of data/people 
into the folds. A couple is represented by two rows in the dataset 
(partner 1 and partner 2) which are of course not always equally happy 
in the relationship they have with each other. But nevertheless the 
relationship quality of partner 1 and partner 2 correlate, which means 
the cases are somehow dependent. How can I sort partners of one couple 
to the same fold (but still as two cases), so that the test sample is 
always completely independent to the trainings sample? How can I write a 
Leave One Group Out CS - command in R, as it exists in Python (which I 
unfortunately cannot perform with)?

Couples are identified by the same number in the row paarID.

Here is the processing part of the code in R from the situation:

library(caret)
outcome <- "RQ_continuaryScale"
variables <- colnames(dat)[use_covar_i]
model <- paste(variables, collapse=" + ")
model <- paste(outcome, '~', model, collapse=' ')
training_config <- trainControl(method="cv", number=5, repeats = 100)
fit <- train(as.formula(model), data=dat_nomiss, "glmnet", trControl = 
training_config)

Here is some Sampledata: 
https://github.com/topepo/caret/files/796416/Testdata_couples_1.csv.2.zip


I'm quite new to R and not a pro to the statistics topic. :(

I already tried carets LGOCV method, but the results are not that what i 
expected.

When I try following:

training_config <- trainControl(method="LGOCV", number=96, p=0.97)

then i just get a sample size of 188, but i need 190.

i hope i could describe my problem well for you. i am very thankful for 
any help and support.

Best regards!


From matthew.s.burgess at gmail.com  Thu Mar  2 14:46:13 2017
From: matthew.s.burgess at gmail.com (Matthew Burgess)
Date: Thu, 2 Mar 2017 13:46:13 +0000
Subject: [R] Why does residuals.coxph use naive.var?
Message-ID: <CAMOczyzkJHjF4xPY4ZDKiAdN=_HpWsuFKqEXNn-ktzYVzEnmmQ@mail.gmail.com>

Hi all,

I noticed that the scaled Schoenfeld residuals produced by
residuals.coxph(fit, type="scaledsch") were different from those returned
by cox.zph for a model where robust standard errors have been estimated.
Looking at the source code for both functions suggests this is because
residuals.coxph uses the naive variance to scale the Schoenfeld residuals
whereas cox.zph uses the robust version when it is available.

Lines 20-21 of the version of residuals.coxph currently on github:

vv <- drop(object$naive.var)
if (is.null(vv)) vv <- drop(object$var)

i.e. the naive variance is used even when a robust version is available.

Why is this the case? Have I missed something? Am I right in thinking that
using the robust variance is the better choice if the intention is to check
the proportional hazards assumption?

Here is a reproducible example using the heart data:

data(heart)
fit <- coxph(Surv(start, stop, event) ~ year + age + surgery + cluster(id),
data=jasa1)
# Should return True since both produce the scaled Schoenfeld residuals
all(residuals(fit, type='scaledsch') == cox.zph(fit)$y)

Thanks for your help.

	[[alternative HTML version deleted]]


From azmi0314 at yahoo.com  Thu Mar  2 17:57:17 2017
From: azmi0314 at yahoo.com (Azmi Muslun)
Date: Thu, 2 Mar 2017 16:57:17 +0000 (UTC)
Subject: [R] Tweedie Model in R software
References: <431905845.492882.1488473837879.ref@mail.yahoo.com>
Message-ID: <431905845.492882.1488473837879@mail.yahoo.com>

Dear all,I have data on monthly rainfall (about 40 years)and i am trying to fit a Tweedie model to the data in order to estimate a p value for each month. I have run the following R codes. data=subset(data,dataMonth=="Feb")out=tweedie.profile(dataMonth=="Feb")out=tweedie.profile(dataAmount~1,p.vec=seq(1,3.5,length=6),do.plot=TRUE,method="interpolation",do.smooth=TRUE,do.ci=TRUE)However this resulted into certain warning message. In tweedie.profile(data$Amount ~ 1, p.vec = seq(1, 3.5, length = 6),
  Confidence interval cannot be found: insufficient data to find left 
CI. I wanted to know how can I deal with this issue? Thanks  
Kindest Regards
 
	[[alternative HTML version deleted]]


From moinul95 at gmail.com  Thu Mar  2 22:49:36 2017
From: moinul95 at gmail.com (Moinul Islam)
Date: Thu, 2 Mar 2017 16:49:36 -0500
Subject: [R] swirl library loading problem
Message-ID: <CAEOAa7z4wOwG17VtvnJ_PTZTdHhaYc_wK9HGe26+WRsgu5q19w@mail.gmail.com>

I have installed swirl package using install.packages("swirl")

after that I tried to load library(swirl). It shows the following error.

Error in get(Info[i, 1], envir = env) :

cannot open file
'C:/Users/Moinul/Documents/R/win-library/3.3/digest/R/digest.rdb': No such
file or directory

Error: package or namespace load failed for ?swirl?

I am using Windows 8 and my R package is 3.3.2. I have also downloaded and
copied RCurl and Curl package in my R library C:\Program
Files\R\R-3.3.2\library and also in the location where swirl is installed
C:\Users\Moinul\Documents\R\win-library\3.3.

Please help me solving the problem

	[[alternative HTML version deleted]]


From emptican at gmail.com  Thu Mar  2 13:54:50 2017
From: emptican at gmail.com (SH)
Date: Thu, 2 Mar 2017 07:54:50 -0500
Subject: [R] R code helps needed!
Message-ID: <CALSKosDdqB1aamk=H1xVv7HR112fe+xHbRJNx++SdOwUGhQp=A@mail.gmail.com>

Hi

Although I posted this in stackoverflow yesterday, I am asking here to get
helps as soon as quickly.

I need help make code for mocking sampling environment. Here is my code
below:

First, I generated mock units with 1000 groups of 100 units. Each row is
considered as independent sample space.

unit <- 100 # Total units
bad.unit.rate <- .05 # Proportion of bad units
bad.unit.num <- ceiling(unit*bad.unit.rate) # Bad units
n.sim=1000
unit.group <- matrix(0, nrow=n.sim, ncol=unit)for(i in 1:n.sim){
    unit.group[i, ] <- sample(rep(0:1, c(unit-bad.unit.num, bad.unit.num)))}
dim(unit.group)

It gives 1000 by 100 groups

ss <- 44 # Selected sample size

44 out of 100 units will be selected and decision (pass or reject) will be
made based on sampling.

This below is decision code:

intercept <- rep(0, nrow(unit.group))
decision <- rep(0, nrow(unit.group))
set.seed(2017)for(i in 1:nrow(unit.group)){
    selected.unit <- sample(1:unit, ss)
    intercept[i] <- sum(unit.group[i,][selected.unit])
    decision[i] <- ifelse(intercept[i]==0, 'pass', 'reject')
    result <- cbind(intercept, decision)
    result}
dim(result)
head(result, 30)

> head(result, 30)
      intercept decision
 [1,] "1"       "reject"
 [2,] "2"       "reject"
 [3,] "3"       "reject"
 [4,] "0"       "pass"
 [5,] "3"       "reject"
 [6,] "2"       "reject"
 [7,] "3"       "reject"
 [8,] "5"       "reject"
 [9,] "3"       "reject"
[10,] "1"       "reject"
[11,] "1"       "reject"
[12,] "2"       "reject"
[13,] "2"       "reject"
[14,] "0"       "pass"
[15,] "3"       "reject"
[16,] "3"       "reject"
[17,] "2"       "reject"
[18,] "2"       "reject"
[19,] "1"       "reject"
[20,] "1"       "reject"
[21,] "2"       "reject"
[22,] "2"       "reject"

I was able to make a decision for each 1000 rows based on sampling as above.

Now, I want to make code for "second" decision option as follows. Assuming
the row number is in order of time or sequence, if 'intercept' value is 0
or 'decision' is 'pass' in the row 4 above, I want to skip any decision
next following 5 (or else) and to label as 'skip', not 'reject'. In the
example above, rows from 5 to 9 will be 'skip' than 'reject'. Also, rows
from 15 to 19 should be 'skip' instead of 'reject'. Although I tried to
make preliminary code with my post, I have no idea where to start. Could
anyone help me to make code? Any feedback will be greatly appreciated.

Thank you very much in advance!!!

Steve

	[[alternative HTML version deleted]]


From iiraji2007 at gmail.com  Thu Mar  2 21:25:15 2017
From: iiraji2007 at gmail.com (Ismail Raji)
Date: Thu, 2 Mar 2017 21:25:15 +0100
Subject: [R] optimal control
Message-ID: <CADfyT5Qn3_Dc4PcD5erzwvNkgv4tLcVxnpqHCFY9Nu-XsyRKYQ@mail.gmail.com>

Dear sir,
Please, kindly assist me with examples on how to use R for simulation of
optimal control problem in epidemiology.
Thank you.

Raji,Ismail  I

The federal polytechnic,Ado-ekiti
Dept of Maths & Statistics
Ekiti state
Nigeria

	[[alternative HTML version deleted]]


From jiucang at goraltrading.com  Thu Mar  2 16:35:49 2017
From: jiucang at goraltrading.com (Jiucang Hao)
Date: Thu, 2 Mar 2017 10:35:49 -0500
Subject: [R] R copies for no apparent reason
Message-ID: <00b801d2936a$ab923d30$02b6b790$@goraltrading.com>

Hi Everyone,

  

Some R function will make R copy the object AFTER the function call, like
nrow, while some others don't, like sum. For example the following code:

x = as.double(1:1e8)

system.time(x[1] <- 100)

y = sum(x)

system.time(x[1] <- 200)     ## Fast (takes 0s), after calling sum

foo = function(x) {

    return(sum(x))

}

y = foo(x)

system.time(x[1] <- 300)     ## Slow (takes 0.35s), after calling foo

Calling foo is NOT slow, because x isn't copied. However, changing x again
is very slow, as x is copied. My guess is that calling foo will leave a
reference to x, so when changing it after, R makes another copy.

Any one knows why R does this? Even when the function doesn't change x at
all? Thanks.

 

 

Regards,

JiuCang Hao


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Mar  2 23:42:13 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Mar 2017 09:42:13 +1100
Subject: [R] R code helps needed!
In-Reply-To: <CALSKosDdqB1aamk=H1xVv7HR112fe+xHbRJNx++SdOwUGhQp=A@mail.gmail.com>
References: <CALSKosDdqB1aamk=H1xVv7HR112fe+xHbRJNx++SdOwUGhQp=A@mail.gmail.com>
Message-ID: <CA+8X3fXaQtc=9_zatH60VvOneA7nVLEA1sjsRUemtki26O5Qtg@mail.gmail.com>

Hi Steve,
Try this:

result<-read.table(text=
   "intercept decision
 1       reject
 2       reject
 3       reject
 0       pass
 3       reject
 2       reject
 3       reject
 5       reject
 3       reject
 1       reject
 1       reject
 2       reject
 2       reject
 0       pass
 3       reject
 3       reject
 2       reject
 2       reject
 1       reject
 1       reject
 2       reject
 2       reject",
 header=TRUE,stringsAsFactors=FALSE)
passes<-which(result$intercept == 0)
skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
result$decision[skips]<-"skip"

Note that result$decision must be a character variable for this to
work.If it is a factor, convert it to character.

Jim


On Thu, Mar 2, 2017 at 11:54 PM, SH <emptican at gmail.com> wrote:
> Hi
>
> Although I posted this in stackoverflow yesterday, I am asking here to get
> helps as soon as quickly.
>
> I need help make code for mocking sampling environment. Here is my code
> below:
>
> First, I generated mock units with 1000 groups of 100 units. Each row is
> considered as independent sample space.
>
> unit <- 100 # Total units
> bad.unit.rate <- .05 # Proportion of bad units
> bad.unit.num <- ceiling(unit*bad.unit.rate) # Bad units
> n.sim=1000
> unit.group <- matrix(0, nrow=n.sim, ncol=unit)for(i in 1:n.sim){
>     unit.group[i, ] <- sample(rep(0:1, c(unit-bad.unit.num, bad.unit.num)))}
> dim(unit.group)
>
> It gives 1000 by 100 groups
>
> ss <- 44 # Selected sample size
>
> 44 out of 100 units will be selected and decision (pass or reject) will be
> made based on sampling.
>
> This below is decision code:
>
> intercept <- rep(0, nrow(unit.group))
> decision <- rep(0, nrow(unit.group))
> set.seed(2017)for(i in 1:nrow(unit.group)){
>     selected.unit <- sample(1:unit, ss)
>     intercept[i] <- sum(unit.group[i,][selected.unit])
>     decision[i] <- ifelse(intercept[i]==0, 'pass', 'reject')
>     result <- cbind(intercept, decision)
>     result}
> dim(result)
> head(result, 30)
>
>> head(result, 30)
>       intercept decision
>  [1,] "1"       "reject"
>  [2,] "2"       "reject"
>  [3,] "3"       "reject"
>  [4,] "0"       "pass"
>  [5,] "3"       "reject"
>  [6,] "2"       "reject"
>  [7,] "3"       "reject"
>  [8,] "5"       "reject"
>  [9,] "3"       "reject"
> [10,] "1"       "reject"
> [11,] "1"       "reject"
> [12,] "2"       "reject"
> [13,] "2"       "reject"
> [14,] "0"       "pass"
> [15,] "3"       "reject"
> [16,] "3"       "reject"
> [17,] "2"       "reject"
> [18,] "2"       "reject"
> [19,] "1"       "reject"
> [20,] "1"       "reject"
> [21,] "2"       "reject"
> [22,] "2"       "reject"
>
> I was able to make a decision for each 1000 rows based on sampling as above.
>
> Now, I want to make code for "second" decision option as follows. Assuming
> the row number is in order of time or sequence, if 'intercept' value is 0
> or 'decision' is 'pass' in the row 4 above, I want to skip any decision
> next following 5 (or else) and to label as 'skip', not 'reject'. In the
> example above, rows from 5 to 9 will be 'skip' than 'reject'. Also, rows
> from 15 to 19 should be 'skip' instead of 'reject'. Although I tried to
> make preliminary code with my post, I have no idea where to start. Could
> anyone help me to make code? Any feedback will be greatly appreciated.
>
> Thank you very much in advance!!!
>
> Steve
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar  3 00:11:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Mar 2017 15:11:25 -0800
Subject: [R] optimal control
In-Reply-To: <CADfyT5Qn3_Dc4PcD5erzwvNkgv4tLcVxnpqHCFY9Nu-XsyRKYQ@mail.gmail.com>
References: <CADfyT5Qn3_Dc4PcD5erzwvNkgv4tLcVxnpqHCFY9Nu-XsyRKYQ@mail.gmail.com>
Message-ID: <CAGxFJbS77wSaYgexz8uVNUXToaFWAjp_2m54AacNDapPAcVR=g@mail.gmail.com>

This is not a free consulting service, so no, no assistance.

Read the posting guide (linked below) to see what help you *may* get
on this list (if the volunteers who answer care to do so).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 2, 2017 at 12:25 PM, Ismail Raji <iiraji2007 at gmail.com> wrote:
> Dear sir,
> Please, kindly assist me with examples on how to use R for simulation of
> optimal control problem in epidemiology.
> Thank you.
>
> Raji,Ismail  I
>
> The federal polytechnic,Ado-ekiti
> Dept of Maths & Statistics
> Ekiti state
> Nigeria
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bianca12_domi at hotmail.com  Fri Mar  3 00:26:09 2017
From: bianca12_domi at hotmail.com (Biank M)
Date: Thu, 2 Mar 2017 23:26:09 +0000
Subject: [R] Differences between SPSS and R on probit analysis
In-Reply-To: <CAF8bMcZpH4Di_jzkyDDEE+tWfe=2obGwRLbhBLqmf3WSSiLBNw@mail.gmail.com>
References: <CY4PR06MB3014AC99A5B7ED03B5F762319A530@CY4PR06MB3014.namprd06.prod.outlook.com>
	<CAF8bMcZ3gOSepD1CyP4XTq09j1MH8m-YqsfgGeko058yrHF=2A@mail.gmail.com>,
	<CAF8bMcZpH4Di_jzkyDDEE+tWfe=2obGwRLbhBLqmf3WSSiLBNw@mail.gmail.com>
Message-ID: <CY4PR06MB30147B4373DDA000BB243E6B9A280@CY4PR06MB3014.namprd06.prod.outlook.com>


Yes I got the warning message from 'glm' and ignored it, I will never do it again.
On the other hand,  I think that including the 'weights' argument improved the results ( I don't get a warning message anymore) and now they are closer to the SPSS results, thought they are not exactly the same (as I expected).

Do you have any ideas on why this is happening or do you have an alternative function combination that would give me the same SPSS results?

Thank you very much for your help!

Bianca.

________________________________
De: William Dunlap <wdunlap at tibco.com>
Enviado: viernes, 24 de febrero de 2017 14:29
Para: Biank M
Cc: r-help at r-project.org
Asunto: Re: [R] Differences between SPSS and R on probit analysis

Another model specification equivalent to
    cbind(afflicted, total-afflicted) ~ ...
is the ratio you had accompanied by the total as the 'weights' argument
    afflicted/total ~ ..., weights=total
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Feb 24, 2017 at 12:01 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Did you not get a warning from glm, such as the following one?
>> fm1 <- glm(affected/total ~ log(dose), family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
> Warning message:
[[elided Hotmail spam]]
> Do not ignore warnings.
>
> The left hand side of the formula should a matrix containing the counts
> of the afflicted and non-afflicted:
>    cbind(affected, total-affected)
> not the fraction of the total that were afflicted.  Then you would get
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -6.8940     1.0780  -6.395 1.60e-10 ***
> log(dose)     0.9333     0.1344   6.944 3.82e-12 ***
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Feb 23, 2017 at 12:26 PM, Biank M <bianca12_domi at hotmail.com> wrote:
>> Hi,
>>
>> I'm working on the effects of alternative larvicides on Aedes aegypti. Right now, I am doing a binary mortality response with a single explanatory variable (dose) on 4 concentrations of one larvicide (+ control). Our university is fond of SPSS, and I have learned to conduct the basic probit model with it, including a natural logarithm transformation on my dosis data.
>> Not so long ago, I've started working with R, and through a combination of the 'glm' and 'dose.p' functions, I get the same slope and intercept, as well as LD50 calculations. Nevertheless, the standard errors and Z-scores calculated through the Probit model in SPSS comes out completely different in R. Additionally, the 95% confidence intervals for the LD50 come out very differently between the two programs. I really don't have a clue on how I am getting the same slopes, intercepts and LD50's, but totally different SE, Z, and 95% CI. Can anybody help me so I can get the same results in R??
>>
>> I'll pass you the script and hypothetical data:
>>
>> dose <- c(6000, 4500, 3000, 1500, 0)
>> total <- c(100, 100, 100, 100, 100)
>> affected <- c(91, 82, 69, 49, 0)
>>
>> finney71 <- data.frame(dose, total, affected)
>>
>> fm1 <- glm(affected/total ~ log(dose),
>> family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
>>
>> xp1 <- dose.p(fm1, p=c(0.5,0.9))
>> xp.ci <- xp1 + attr(xp1, "SE") %*% matrix(qnorm(1 - 0.05/2)*c(-1,1), nrow=1)
>> EAUS.Aa <- exp(cbind(xp1, attr(xp1, "SE"), xp.ci[,1], xp.ci[,2]))
>> dimnames(EAUS.Aa)[[2]] <- c("LD", "SE", "LCL","UCL")
>>
>> So, this is the regression results I get with R:
>> summary(fm1)
>>
>> Deviance Residuals:
>> 1 2 3 4
>> 0.06655 -0.02814 -0.06268 0.03474
>>
>> Coefficients:
>> Estimate Std. Error z value
>> (Intercept) -6.8940 10.7802 -0.640
>> log(dose) 0.9333 1.3441 0.694
>> Pr(>|z|)
>> (Intercept) 0.522
>> log(dose) 0.487
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>> Null deviance: 0.513878 on 3 degrees of freedom
>> Residual deviance: 0.010356 on 2 degrees of freedom
>> AIC: 6.5458
>>
>> Number of Fisher Scoring iterations: 5
>>
>> And the LD50 and CI transformed:
>>
>> print(EAUS.Aa)
>> LD SE LCL UCL
>> p = 0.5: 1614.444 3.207876 164.3822 15855.91
>> p = 0.9: 6373.473 3.764879 474.1600 85669.72
>>
>> These are the values I get on SPSS (just replacing the values on R output) :
>>
>> Coefficients:
>> Estimate Std. Error z value
>> (Intercept) -6.8940 1.082 -6.373
>> (dose) 2.149 0.311 6.918
>>
>> And the LD50 and CI transformed:
>>
>> LD LCL UCL
>> p = 0.5: 1614.444 1198.932 1953.120
>> p = 0.9: 6373.473 5145.767 9013.354
>>
>> So, please if somebody can help me with this, I'd be grateful. If working with those functions won't do it, I'll use another, the one you recommend.
>>
[[elided Hotmail spam]]
>>
>>
>> Best wishes,
>>
>> Bianca
>>
>>
>>
>> PD. I've already googled it but there's no satisfactory answer.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar  3 00:46:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Mar 2017 15:46:10 -0800
Subject: [R] R copies for no apparent reason
In-Reply-To: <00b801d2936a$ab923d30$02b6b790$@goraltrading.com>
References: <00b801d2936a$ab923d30$02b6b790$@goraltrading.com>
Message-ID: <CAGxFJbRjvrqoizoUkjKu_mjhEGJb4RqdrZNO7q6ToTHzT4r+iw@mail.gmail.com>

Your assumptions are wrong.

a full discussion and answer to your question can be found here:
http://adv-r.had.co.nz/memory.html

This *is* complex and probably off topic for this list.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 2, 2017 at 7:35 AM, Jiucang Hao <jiucang at goraltrading.com> wrote:
> Hi Everyone,
>
>
>
> Some R function will make R copy the object AFTER the function call, like
> nrow, while some others don't, like sum. For example the following code:
>
> x = as.double(1:1e8)
>
> system.time(x[1] <- 100)
>
> y = sum(x)
>
> system.time(x[1] <- 200)     ## Fast (takes 0s), after calling sum
>
> foo = function(x) {
>
>     return(sum(x))
>
> }
>
> y = foo(x)
>
> system.time(x[1] <- 300)     ## Slow (takes 0.35s), after calling foo
>
> Calling foo is NOT slow, because x isn't copied. However, changing x again
> is very slow, as x is copied. My guess is that calling foo will leave a
> reference to x, so when changing it after, R makes another copy.
>
> Any one knows why R does this? Even when the function doesn't change x at
> all? Thanks.
>
>
>
>
>
> Regards,
>
> JiuCang Hao
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Mar  3 10:37:24 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Mar 2017 10:37:24 +0100
Subject: [R] R copies for no apparent reason
In-Reply-To: <CAGxFJbRjvrqoizoUkjKu_mjhEGJb4RqdrZNO7q6ToTHzT4r+iw@mail.gmail.com>
References: <00b801d2936a$ab923d30$02b6b790$@goraltrading.com>
	<CAGxFJbRjvrqoizoUkjKu_mjhEGJb4RqdrZNO7q6ToTHzT4r+iw@mail.gmail.com>
Message-ID: <CCB68A25-B1FE-44CA-86CF-B66F408D32AA@gmail.com>

Right. A semi-short explanation is that R doesn't do full reference counting (*), hence copying happens when you modify an object that _at any previous point_ has been known by two or more names (incl. same name in different environments). 

In the present case, there has been local variable x inside foo(), and global variable x.

-pd

(*) ...yet. Luke Tierney has been working on this; I have temporarily forgotten how much of his work is included in released versions of R.

On 03 Mar 2017, at 00:46 , Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Your assumptions are wrong.
> 
> a full discussion and answer to your question can be found here:
> http://adv-r.had.co.nz/memory.html
> 
> This *is* complex and probably off topic for this list.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Mar 2, 2017 at 7:35 AM, Jiucang Hao <jiucang at goraltrading.com> wrote:
>> Hi Everyone,
>> 
>> 
>> 
>> Some R function will make R copy the object AFTER the function call, like
>> nrow, while some others don't, like sum. For example the following code:
>> 
>> x = as.double(1:1e8)
>> 
>> system.time(x[1] <- 100)
>> 
>> y = sum(x)
>> 
>> system.time(x[1] <- 200)     ## Fast (takes 0s), after calling sum
>> 
>> foo = function(x) {
>> 
>>    return(sum(x))
>> 
>> }
>> 
>> y = foo(x)
>> 
>> system.time(x[1] <- 300)     ## Slow (takes 0.35s), after calling foo
>> 
>> Calling foo is NOT slow, because x isn't copied. However, changing x again
>> is very slow, as x is copied. My guess is that calling foo will leave a
>> reference to x, so when changing it after, R makes another copy.
>> 
>> Any one knows why R does this? Even when the function doesn't change x at
>> all? Thanks.
>> 
>> 
>> 
>> 
>> 
>> Regards,
>> 
>> JiuCang Hao
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Fri Mar  3 11:00:03 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Mar 2017 10:00:03 +0000
Subject: [R] optimal control
In-Reply-To: <CADfyT5Qn3_Dc4PcD5erzwvNkgv4tLcVxnpqHCFY9Nu-XsyRKYQ@mail.gmail.com>
References: <CADfyT5Qn3_Dc4PcD5erzwvNkgv4tLcVxnpqHCFY9Nu-XsyRKYQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18BB7@SRVEXCHCM301.precheza.cz>

Hi

the concise summary about optimization can be found on CRAN Task View Optimization

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ismail Raji
> Sent: Thursday, March 2, 2017 9:25 PM
> To: r-help at r-project.org
> Subject: [R] optimal control
>
> Dear sir,
> Please, kindly assist me with examples on how to use R for simulation of
> optimal control problem in epidemiology.
> Thank you.
>
> Raji,Ismail  I
>
> The federal polytechnic,Ado-ekiti
> Dept of Maths & Statistics
> Ekiti state
> Nigeria
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Mar  3 11:02:47 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Mar 2017 10:02:47 +0000
Subject: [R] Looking to understand GPU acceleration in R
In-Reply-To: <CAENFiWBy4UjaHnFSmFUWcKuTai_ZKFnm9eU6JbGPX4PXwWsjGw@mail.gmail.com>
References: <CAENFiWBy4UjaHnFSmFUWcKuTai_ZKFnm9eU6JbGPX4PXwWsjGw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18BC7@SRVEXCHCM301.precheza.cz>

Hi

Did you look at

https://www.r-bloggers.com/r-gpu-programming-for-all-with-gpur/
http://www.r-tutor.com/gpu-computing

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Andrej
> Favia
> Sent: Thursday, March 2, 2017 1:29 AM
> To: r-help at r-project.org
> Subject: [R] Looking to understand GPU acceleration in R
>
> I am a casual user looking to learn about GPU acceleration in R... at a "new to
> computers" level (do not use overly technical language with me as I will not
> understand what you are saying).
>
> I am on macOS Sierra with an Intel Iris Pro GPU.
>
> 1. Can someone produce any simple example in R that uses GPU processing
> for my GPU?
>
> 2. Is there a way to use the GPU to do an iterative process, such as the Euler
> method? This is the kind where, let's say
>
> x <- 5
> x <- sin(x) + 3 (or some other complicated recursion)
>
> and repeat this until 10000 steps are reached.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lists at dewey.myzen.co.uk  Fri Mar  3 12:42:25 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 3 Mar 2017 11:42:25 +0000
Subject: [R] xtable: Width of Columns
In-Reply-To: <OFFD1F8D6D.8AA9AF90-ONC12580D7.00454AB9-C12580D7.00459040@lotus.hawesko.de>
References: <OFFD1F8D6D.8AA9AF90-ONC12580D7.00454AB9-C12580D7.00459040@lotus.hawesko.de>
Message-ID: <48661d76-ef06-0eec-43cc-9bc4b500a721@dewey.myzen.co.uk>

Does p{3cm} do what you want as an alignment?

On 02/03/2017 12:39, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I have the following code in R Markdown document:
>
> ```{r, results = "asis", echo = FALSE}
> library(xtable)
> response <- as.data.frame(matrix(NA, 2, 2))
> colnames(response) <- c("Anzahl", "Prozent")
> rownames(response) <- c("gesamte R?cksendungen (brutto)  ",
>                         "auswertbare Frageb?gen (netto)  ")
> response[[1, 1]] <- 1
> response[[1, 2]] <- 2.0
> response[[2, 1]] <- 3
> response[[2, 2]] <- 4.0
>
> response_table <- xtable(
>   response,
>   caption = "R?cklauf und R?cklaufquote",
>   label = "Responsequote",
>   display = c("s","d","f"),
>   digits = 1,
>   align = c("l", "c", "c") #  auto = TRUE
>   )
>
> print.xtable(
>   response_table,
>   type = "html",
>   caption.placement = "top",
>   format.args = list(
>     big.mark = ".",
>     decimal.mark = ","),
>   size = 500,
>   width = 100)
> ```
>
> and would like to control the width of the columns. But columns width is
> always aligned to the content.
>
> Is there a way to give the columns width, e.g. 25 characters, for all
> columns or for each column separately to get more spacing for the text and
> the borders of the table?
>
> Kind regards
>
> Georg
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From andrluis at ualberta.ca  Fri Mar  3 19:59:11 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Fri, 3 Mar 2017 11:59:11 -0700
Subject: [R] Heatmap help
Message-ID: <CAHxKz8as7YWhV03Fz3ixqzyH3NrDc4GEPr-MaACxHD7=_+qvTg@mail.gmail.com>

Dear all,

I was wondering if you could help me to construct a heat map, in which the
columns are sorted by sample type (A first and then B).
My reproducible example below runs, but the columns of the heatmap are not
organized in the way I would like because it has first sampleA, SampleB,
sampleA, and then sampleB.


A = matrix(rnorm(20), 5,8)
A
colnames(A) <- c ("Sample1.A", "Sample2.B", "Sample3.A", "Sample4.B",
"Sample5.A", "Sample6.B", "Sample7.A", "Sample8.B")
A
rownames(A) <- c ("protein1","protein2", "protein3", "protein4","protein5")
A

heatmap.2(A, dendrogram="col", Rowv = colnames(A), tracecol =
NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"), hclustfun =
function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
"Samples", margins = c(9,9), keysize = 1,
          main='Test')



?Thanks.

-- 
Andre

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Fri Mar  3 23:51:46 2017
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 3 Mar 2017 16:51:46 -0600
Subject: [R] ASReml-R lack of documentation
In-Reply-To: <20170227082951.GA22242@slingshot.co.nz>
References: <20170227082951.GA22242@slingshot.co.nz>
Message-ID: <CAKFxdiR_nvosN4R3+oDo=MMqmXRd2tBPUNZnP+WKrqxu12p4UA@mail.gmail.com>

Patrick,

The asreml (VSNi) forum seems to still be working with a few posts every
month:
https://www.vsni.co.uk/forum/viewforum.php?f=7

Kevin Wright


On Mon, Feb 27, 2017 at 2:29 AM, Patrick Connolly <
p_connolly at slingshot.co.nz> wrote:

> Has anyone had any success contacting VSNi, distributors of the
> non-free R package ASReml-R?  I tried posting a question on their
> forum page but the forum software seems to have a bug too.
>
> So I tried emailing their support address but with no success.  If
> anyone has had recent success with either, please let me know what you
> did to achieve it.
>
> Better still. if you have experience with predictions from
> asreml.binomial models, I have a question about a possible bug if
> you'd bee so kind.
>
> TIA
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Sat Mar  4 00:08:40 2017
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 3 Mar 2017 17:08:40 -0600
Subject: [R] About MC simulation of AR1 model in R
In-Reply-To: <615400.7ff2.158a9880402.Coremail.yzhlinscau@163.com>
References: <615400.7ff2.158a9880402.Coremail.yzhlinscau@163.com>
Message-ID: <CAKFxdiTcoW+aV1MO3ydSsv47GN8TWB6fevpvykBMxOsQ+EqQBA@mail.gmail.com>

Try this example to simulate AR1xAR1 variance structure.

Kevin Wright

library(mvtnorm)
library(asreml)
set.seed(300)
nr <- 10; nc <- 8 # number of rows and columns
colcor <- .9      # correlation for columns, rows
rowcor <- .1
sigAR <- diag(nr)
sigAR <- rowcor^ abs(row(sigAR) - col(sigAR))
sigAC <- diag(nc)
sigAC <- colcor ^ abs(row(sigAC) - col(sigAC))
sig <- 100 * kronecker(sigAR, sigAC) # scale 100 doesn't really matter

yy <- rmvnorm(1, mean=rep(0, nr*nc), sig)
dat <- data.frame(y=as.vector(yy), row=rep(1:nr, each=nc), col=rep(1:nc,
nr))
dat$row=factor(dat$row)
dat$col=factor(dat$col)
m1 <- asreml(y ~ 1, data=dat, rcov= ~ ar1(row):ar1(col))
summary(m1)$varcomp

##                 gamma   component   std.error    z.ratio    constraint
## R!variance 1.00000000 95.60247530 35.62104468  2.6838762      Positive
## R!row.cor  0.08306616  0.08306616  0.11421749  0.7272631 Unconstrained
## R!col.cor  0.91306348  0.91306348  0.03451116 26.4570518 Unconstrained


On Mon, Nov 28, 2016 at 12:03 AM, yz <yzhlinscau at 163.com> wrote:

> I want to run MC simulation of AR1(auto-regression) matrix in R, which
> would be as residuals in linear mixed model.
>
> AR1 matrix with the following character:
>
> ?r,?c is the auto-correlation parameter in the row and column direction.
>
> And I wrote one function in R ( under following). But I run the function,
> it seems only work  for the first Row auto-corr. When setting different a
> set of Row auto-corr values, the simulated dataset would change with the
> same value. But it did not work for the second column auto-corr parameter,
> even if setting different col atuo-corr, the simulated dataset seemd no
> changed in col auto-corr value that nearly is zero all the time. Would
> someone please help me  to find the questions that the R function codes
> somewhere got wrong? Thanks a lots.
>
> ####### simulation codes for AR1 model
> multi_norm <- function(data_num,Pr,Pc) {
>   require(MASS)
>  # data_num for row/col number; Pr for row auto-corr; Pc for colum
> auto-corr.
>
>   V <- matrix(data=NA, nrow=data_num, ncol=data_num)
>   R.mat=diag(data_num)
>   C.mat=diag(data_num)
>
>   set.seed(2016)
>   means <- runif(1, min=0, max=1)
>   means1=rep(means,data_num*data_num)
>
>   # variance
>   set.seed(2016)
>   var <- runif(1, min=0, max=1)
>
>   for (i in 1:data_num) {
>     # a two-level nested loop to generate AR matrix
>     for (j in 1:data_num) {
>       if (i == j) {
>         # covariances on the diagonal
>         V[i,j] <- 1 #varsmodule[i]
>       } else if(i<j){
>         # covariances
>         R.mat[i,j]<-  V[i,i]*(Pr^(j-i))
>         C.mat[i,j]<-  V[i,i]*(Pc^(j-i))
>       }else {R.mat[i,j]=R.mat[j,i];C.mat[i,j]=C.mat[j,i]}
>     }
>   }
>
>   V=var*kronecker(C.mat,R.mat)
>
>   # simulate multivariate normal distribution
>   # given means and covariance matrix
>   X <- t(mvrnorm(n = data_num, means1, V))
>   aam=X[1:data_num,]
>
>   aad=data.frame()
>   for(i in 1:data_num){
>     for(j in 1:data_num){
>       aad[j+data_num*(i-1),1]=i
>       aad[j+data_num*(i-1),2]=j
>       aad[j+data_num*(i-1),3]=aam[i,j]
>     }
>   }
>   names(aad)=c('Row','Col','y')
>   for(i in 1:2) aad[,i]=factor(aad[,i])
>
>   return(aad)
> }
>
> The simulation results as following:
>
> > aam=multi_norm(30,0.6,0.01)
> > mm2=asreml(y~1,rcov=~ar1(Row):ar1(Col),data=aam,trace=F,maxit=30)
> > summary(mm2)$varcomp
>                 gamma  component  std.error    z.ratio    constraint
> R!variance 1.00000000 0.16267855 0.01038210 15.6691353      Positive
> R!Row.cor  0.55811722 0.55811722 0.02734902 20.4072085 Unconstrained
> R!Col.cor  0.01735573 0.01735573 0.03368048  0.5153055 Unconstrained
> > aam=multi_norm(30,0.6,0.3)
> > mm2=asreml(y~1,rcov=~ar1(Row):ar1(Col),data=aam,trace=F,maxit=30)
> > summary(mm2)$varcomp
>                  gamma   component  std.error   z.ratio    constraint
> R!variance  1.00000000  0.17491494 0.01199393 14.583624      Positive
> R!Row.cor   0.62097328  0.62097328 0.02534858 24.497358 Unconstrained
> R!Col.cor  -0.03744104 -0.03744104 0.03380648 -1.107511 Unconstrained
> > aam=multi_norm(30,0.6,0.6)
> > mm2=asreml(y~1,rcov=~ar1(Row):ar1(Col),data=aam,trace=F,maxit=30)
> > summary(mm2)$varcomp
>                  gamma   component  std.error    z.ratio    constraint
> R!variance 1.000000000 0.180804271 0.01227539 14.7289994      Positive
> R!Row.cor  0.581797580 0.581797580 0.02861663 20.3307541 Unconstrained
> R!Col.cor  0.007598536 0.007598536 0.03448510  0.2203426 Unconstrained
>
> > aam=multi_norm(30,0.3,0.6)
> > mm2=asreml(y~1,rcov=~ar1(Row):ar1(Col),data=aam,trace=F,maxit=30)
> > summary(mm2)$varcomp
>                   gamma    component   std.error    z.ratio    constraint
> R!variance  1.000000000  0.177888691 0.008979462 19.8106171      Positive
> R!Row.cor   0.269572147  0.269572147 0.031823892  8.4707474 Unconstrained
> R!Col.cor  -0.004159379 -0.004159379 0.035830577 -0.1160846 Unconstrained
> > aam=multi_norm(30,0.9,0.6)
> > mm2=asreml(y~1,rcov=~ar1(Row):ar1(Col),data=aam,trace=F,maxit=30)
> > summary(mm2)$varcomp
>                 gamma  component  std.error    z.ratio    constraint
> R!variance 1.00000000 0.19194479 0.02674158  7.1777654      Positive
> R!Row.cor  0.91213667 0.91213667 0.01247011 73.1458677 Unconstrained
> R!Col.cor  0.01203907 0.01203907 0.03474589  0.3464891 Unconstrained
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sat Mar  4 13:03:35 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 4 Mar 2017 07:03:35 -0500
Subject: [R] > quit('no')\nError: cannot allocate vector of size 512 Kb
Message-ID: <CAOwvMDyzGEPiMr01MbT+nV9W0KAztxdmBpWDHN-t5ecHSe2ntQ@mail.gmail.com>

this one is cute

    [damico at rocks010 ~]$ ulimit -v 150000
    [damico at rocks010 ~]$ R

    R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
    Copyright (C) 2016 The R Foundation for Statistical Computing
    Platform: x86_64-redhat-linux-gnu (64-bit)

    R is free software and comes with ABSOLUTELY NO WARRANTY.
    You are welcome to redistribute it under certain conditions.
    Type 'license()' or 'licence()' for distribution details.

      Natural language support but running in an English locale

    R is a collaborative project with many contributors.
    Type 'contributors()' for more information and
    'citation()' on how to cite R or R packages in publications.

    Type 'demo()' for some demos, 'help()' for on-line help, or
    'help.start()' for an HTML browser interface to help.
    Type 'q()' to quit R.

    Error in dyn.load(file, DLLpath = DLLpath, ...) :
      unable to load shared object
'/usr/lib64/R/library/grDevices/libs/grDevices.so':
      /usr/lib64/R/library/grDevices/libs/grDevices.so: failed to map
segment from shared object
    Error in dyn.load(file, DLLpath = DLLpath, ...) :
      unable to load shared object
'/usr/lib64/R/library/grDevices/libs/grDevices.so':
      /usr/lib64/R/library/grDevices/libs/grDevices.so: failed to map
segment from shared object
    In addition: Warning message:
    package ?grDevices? in options("defaultPackages") was not found
    Error in dyn.load(file, DLLpath = DLLpath, ...) :
      unable to load shared object
'/usr/lib64/R/library/grDevices/libs/grDevices.so':
      /usr/lib64/R/library/grDevices/libs/grDevices.so: failed to map
segment from shared object
    In addition: Warning message:
    package ?graphics? in options("defaultPackages") was not found
    During startup - Warning message:
    package ?stats? in options("defaultPackages") was not found
    > quit('no')
    Error: cannot allocate vector of size 512 Kb
    > sessionInfo()
    Error: cannot allocate vector of size 512 Kb



separate session obviously

    > sessionInfo()
    R version 3.3.2 (2016-10-31)
    Platform: x86_64-redhat-linux-gnu (64-bit)
    Running under: Fedora 24 (Twenty Four)

    locale:
     [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
     [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
     [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
     [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
     [9] LC_ADDRESS=C               LC_TELEPHONE=C
    [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Sun Mar  5 00:44:28 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Sat, 4 Mar 2017 16:44:28 -0700
Subject: [R] Heatmap help
In-Reply-To: <87k284eo5w.fsf@connact.com>
References: <CAHxKz8as7YWhV03Fz3ixqzyH3NrDc4GEPr-MaACxHD7=_+qvTg@mail.gmail.com>
	<87k284eo5w.fsf@connact.com>
Message-ID: <CAHxKz8ZYYfhpP6vgah_P2edHC3PhfZa4BomA4wjHuXx1o0vg=A@mail.gmail.com>

Thanks, Patricia! I will do it by the rows, and your explanations were
great and easy to follow!

Thank you very much for your help and time.

Andre

On Mar 4, 2017 4:18 PM, "Patricia J. Hawkins" <phawkins at connact.com> wrote:

Hi, you have a couple of things going on here.  You can reorder your
matrix by creating an index like this:

> A_index=c(grep(".A", colnames(A)), grep(".B", colnames(A)))

and do this:

> heatmap.2(A[,A_index], dendrogram="col", Rowv = colnames(A)[A_index],
tracecol =
          NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"), hclustfun =
          function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
         "Samples", margins = c(9,9), keysize = 1,
          main='Test')

But you're constructing your dendrogram on the columns, so your columns
get reordered by mean weight.  (Also, you've misunderstood Rowv and Colv.)

However, if you force your columns to not reorder by setting
"Colv=FALSE", AND tell it to construct the dendrogram on the columns,
you get a warning, because that's contradictory:

> heatmap.2(A[,A_index], dendrogram="col", Colv = FALSE, tracecol =
NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"),
          hclustfun = function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
          "Samples", margins = c(9,9), keysize = 1, main='Test')
Warning message:
In heatmap.2(A[, A_index], dendrogram = "col", Colv = FALSE, tracecol =
NA,  :
  Discrepancy: Colv is FALSE, while dendrogram is `column'. Omitting column
dendogram.

Maybe you really meant to build your dendrogram on the rows, like this:

heatmap.2(A[,A_index], dendrogram="row", Colv = FALSE, tracecol =
NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"),
          hclustfun = function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
          "Samples", margins = c(9,9), keysize = 1, main='Test')

If that's not it, I suggest playing around with the examples in
?heatmap.2 since the documentation is kind of opaque, but the examples
are pretty good.

>>>>> "ALN" == Andr? Luis Neves <andrluis at ualberta.ca> writes:

ALN> Dear all,

ALN> I was wondering if you could help me to construct a heat map, in which
the
ALN> columns are sorted by sample type (A first and then B).
ALN> My reproducible example below runs, but the columns of the heatmap are
not
ALN> organized in the way I would like because it has first sampleA,
SampleB,
ALN> sampleA, and then sampleB.


ALN> A = matrix(rnorm(20), 5,8)
ALN> A
ALN> colnames(A) <- c ("Sample1.A", "Sample2.B", "Sample3.A", "Sample4.B",
ALN> "Sample5.A", "Sample6.B", "Sample7.A", "Sample8.B")
ALN> A
ALN> rownames(A) <- c ("protein1","protein2", "protein3",
"protein4","protein5")
ALN> A

ALN> heatmap.2(A, dendrogram="col", Rowv = colnames(A), tracecol =
ALN> NA,col=bluered(64), sub = "",
ALN>           distfun = function(y) dist(y, method = "euclidean"),
hclustfun =
ALN> function(y) hclust(y, method = "median"),
ALN>           scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes",
xlab =
ALN> "Samples", margins = c(9,9), keysize = 1,
ALN>           main='Test')



ALN> ?Thanks.

ALN> --
ALN> Andre

ALN>    [[alternative HTML version deleted]]

ALN> ______________________________________________
ALN> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
ALN> https://stat.ethz.ch/mailman/listinfo/r-help
ALN> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
ALN> and provide commented, minimal, self-contained, reproducible code.



--
Patricia J. Hawkins

	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Fri Mar  3 13:43:53 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Fri, 3 Mar 2017 12:43:53 +0000 (UTC)
Subject: [R] Error in curve 'expr' did not evaluate to an object of length
 'n'
References: <1449625709.291181.1488545033950.ref@mail.yahoo.com>
Message-ID: <1449625709.291181.1488545033950@mail.yahoo.com>

Please help. I try to re-produce R-script by plotting a set of functionWhen i running code: plot(Vectorize(running.acf.max))it gets the error message like this:?Error in curve(expr = x, from = from, to = to, xlim = xlim, ylab = ylab, ?:?? 'expr' did not evaluate to an object of length 'n'
Even though i have vectorized the function argument.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sample1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170303/88a27287/attachment.txt>

From emptican at gmail.com  Fri Mar  3 14:00:36 2017
From: emptican at gmail.com (SH)
Date: Fri, 3 Mar 2017 08:00:36 -0500
Subject: [R] R code helps needed!
In-Reply-To: <CA+8X3fXaQtc=9_zatH60VvOneA7nVLEA1sjsRUemtki26O5Qtg@mail.gmail.com>
References: <CALSKosDdqB1aamk=H1xVv7HR112fe+xHbRJNx++SdOwUGhQp=A@mail.gmail.com>
	<CA+8X3fXaQtc=9_zatH60VvOneA7nVLEA1sjsRUemtki26O5Qtg@mail.gmail.com>
Message-ID: <CALSKosDN10Wrmkb0MP+h2WvbS2biYipAMhMBAPjKg_=HY+w-qw@mail.gmail.com>

Hi Jim,

Thank you very much for replying back.

I think the data I presented have not many 'pass' than I thought.  The
purpose of the code is to skip sampling for 5 consecutive rows when a
previous row is found as 'pass'.  Thus, because the fourth row is
'pass', sampling will be skipped next five rows (i.e., from 5th to 9th
rows).  Therefore any 'pass' within next 5 rows after first 'pass' should
not affect 'skip'.  Could you try this?  Based on your code, I
guess 'return' function may be one I should search.  I haven't used it
before so I am not familiar with the function.  I made a new data set with
'expected.decision' column.  In the data set, once a 'pass' is found, the
next sampling starts 5 rows after.  For example, since the forth row is
'pass',  the next sampling starts at 10th row.  Although 6th row should be
'pass', I want to label them as 'skip' since no sampling is made.

The objective of the study is to investigate how many of 'reject' rows get
'skip' with a given sampling scheme, the rate of 'pass' because of skip
sampling which should be 'reject'.

Could you also try this data and give me your feedback?  Thanks again for
you helps!!!

Steve

result<-read.table(text=
    "intercept decision expected.decision
 1 reject reject
 2 reject reject
 3 reject reject
 0 pass pass
 3 reject skip
 0 pass skip
 3 reject skip
 5 reject skip
0 pass skip
 0 pass pass
3 reject skip
 1 reject skip
 0 pass skip
 0 pass skip
 2 reject skip
 1 reject reject
 0 pass pass
 3 reject skip
 0 pass skip
 2 reject skip
 0 pass skip
 1 reject skip
 2 reject reject
 2 reject reject
",
  header=TRUE,stringsAsFactors=FALSE)
 passes<-which(result$intercept == 0)
 skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
 result$decision[skips]<-"skip"
result



On Thu, Mar 2, 2017 at 5:42 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Steve,
> Try this:
>
> result<-read.table(text=
>    "intercept decision
>  1       reject
>  2       reject
>  3       reject
>  0       pass
>  3       reject
>  2       reject
>  3       reject
>  5       reject
>  3       reject
>  1       reject
>  1       reject
>  2       reject
>  2       reject
>  0       pass
>  3       reject
>  3       reject
>  2       reject
>  2       reject
>  1       reject
>  1       reject
>  2       reject
>  2       reject",
>  header=TRUE,stringsAsFactors=FALSE)
> passes<-which(result$intercept == 0)
> skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
> result$decision[skips]<-"skip"
>
> Note that result$decision must be a character variable for this to
> work.If it is a factor, convert it to character.
>
> Jim
>
>
> On Thu, Mar 2, 2017 at 11:54 PM, SH <emptican at gmail.com> wrote:
> > Hi
> >
> > Although I posted this in stackoverflow yesterday, I am asking here to
> get
> > helps as soon as quickly.
> >
> > I need help make code for mocking sampling environment. Here is my code
> > below:
> >
> > First, I generated mock units with 1000 groups of 100 units. Each row is
> > considered as independent sample space.
> >
> > unit <- 100 # Total units
> > bad.unit.rate <- .05 # Proportion of bad units
> > bad.unit.num <- ceiling(unit*bad.unit.rate) # Bad units
> > n.sim=1000
> > unit.group <- matrix(0, nrow=n.sim, ncol=unit)for(i in 1:n.sim){
> >     unit.group[i, ] <- sample(rep(0:1, c(unit-bad.unit.num,
> bad.unit.num)))}
> > dim(unit.group)
> >
> > It gives 1000 by 100 groups
> >
> > ss <- 44 # Selected sample size
> >
> > 44 out of 100 units will be selected and decision (pass or reject) will
> be
> > made based on sampling.
> >
> > This below is decision code:
> >
> > intercept <- rep(0, nrow(unit.group))
> > decision <- rep(0, nrow(unit.group))
> > set.seed(2017)for(i in 1:nrow(unit.group)){
> >     selected.unit <- sample(1:unit, ss)
> >     intercept[i] <- sum(unit.group[i,][selected.unit])
> >     decision[i] <- ifelse(intercept[i]==0, 'pass', 'reject')
> >     result <- cbind(intercept, decision)
> >     result}
> > dim(result)
> > head(result, 30)
> >
> >> head(result, 30)
> >       intercept decision
> >  [1,] "1"       "reject"
> >  [2,] "2"       "reject"
> >  [3,] "3"       "reject"
> >  [4,] "0"       "pass"
> >  [5,] "3"       "reject"
> >  [6,] "2"       "reject"
> >  [7,] "3"       "reject"
> >  [8,] "5"       "reject"
> >  [9,] "3"       "reject"
> > [10,] "1"       "reject"
> > [11,] "1"       "reject"
> > [12,] "2"       "reject"
> > [13,] "2"       "reject"
> > [14,] "0"       "pass"
> > [15,] "3"       "reject"
> > [16,] "3"       "reject"
> > [17,] "2"       "reject"
> > [18,] "2"       "reject"
> > [19,] "1"       "reject"
> > [20,] "1"       "reject"
> > [21,] "2"       "reject"
> > [22,] "2"       "reject"
> >
> > I was able to make a decision for each 1000 rows based on sampling as
> above.
> >
> > Now, I want to make code for "second" decision option as follows.
> Assuming
> > the row number is in order of time or sequence, if 'intercept' value is 0
> > or 'decision' is 'pass' in the row 4 above, I want to skip any decision
> > next following 5 (or else) and to label as 'skip', not 'reject'. In the
> > example above, rows from 5 to 9 will be 'skip' than 'reject'. Also, rows
> > from 15 to 19 should be 'skip' instead of 'reject'. Although I tried to
> > make preliminary code with my post, I have no idea where to start. Could
> > anyone help me to make code? Any feedback will be greatly appreciated.
> >
> > Thank you very much in advance!!!
> >
> > Steve
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From emptican at gmail.com  Fri Mar  3 16:31:06 2017
From: emptican at gmail.com (SH)
Date: Fri, 3 Mar 2017 10:31:06 -0500
Subject: [R] R code helps needed!
In-Reply-To: <CALSKosDN10Wrmkb0MP+h2WvbS2biYipAMhMBAPjKg_=HY+w-qw@mail.gmail.com>
References: <CALSKosDdqB1aamk=H1xVv7HR112fe+xHbRJNx++SdOwUGhQp=A@mail.gmail.com>
	<CA+8X3fXaQtc=9_zatH60VvOneA7nVLEA1sjsRUemtki26O5Qtg@mail.gmail.com>
	<CALSKosDN10Wrmkb0MP+h2WvbS2biYipAMhMBAPjKg_=HY+w-qw@mail.gmail.com>
Message-ID: <CALSKosAtVSRs4KoN51TdHn3-VVFN1Ugx0ZHGLAAG4_40REKEog@mail.gmail.com>

Hi Jim,

I added more codes besides your original ones.  I bet there should be
simpler way(s) to do this but this is the best I can think of.  Any
feedback from you and others will be highly appreciated.

Thanks a lot!

Steve

result<-read.table(text=
     "intercept decision expected.decision
 1 reject reject
 2 reject reject
 3 reject reject
 0 pass pass
 3 reject skip
 0 pass skip
 3 reject skip
 5 reject skip
 0 pass skip
 0 pass pass
 3 reject skip
 1 reject skip
 0 pass skip
 0 pass skip
 2 reject skip
 1 reject reject
 0 pass pass
 3 reject skip
 0 pass skip
 2 reject skip
 0 pass skip
 1 reject skip
 2 reject reject
 2 reject reject
",
 header=TRUE,stringsAsFactors=FALSE)
int <- result$intercept
int
# [1] 1 2 3 0 3 0 3 5 0 0 3 1 0 0 2 1 0 3 0 2 0 1 2 2
pass.theo <- which(int==0)
pass.theo
#[1]  4  6  9 10 13 14 17 19 21
lv1 <- int==0
lv1
# [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE
FALSE
#[13]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE
FALSE
pass.1st <- min(which(lv1==TRUE))
pass.1st
#[1] 4

m <- c(0:100)
 interval <- 6*m + pass.1st
 interval
# [1]   4  10  16  22  28  34  40  46  52  58  64  70  76  82  88  94 100
106
 #[19] 112 118 124 130 136 142 148 154 160 166 172 178 184 190 196 202 208
214
 #[37] 220 226 232 238 244 250 256 262 268 274 280 286 292 298 304 310 316
322
 #[55] 328 334 340 346 352 358 364 370 376 382 388 394 400 406 412 418 424
430
 #[73] 436 442 448 454 460 466 472 478 484 490 496 502 508 514 520 526 532
538
 #[91] 544 550 556 562 568 574 580 586 592 598 604
interval2 <- c(interval[interval<=length(int)], length(int))
interval2
#[1]  4 10 16 22 24
 pass.theo
#[1]  4  6  9 10 13 14 17 19 21

res <- as.list(NULL)
> for(i in 1:(length(interval2)-1)){
 res[[i]] <- min(pass.theo[pass.theo >= interval2[i] & pass.theo <
interval2[i+1]])
 res
 }
#Warning message:
#In min(pass.theo[pass.theo >= interval2[i] & pass.theo < interval2[i +  :
 # no non-missing arguments to min; returning Inf
res
#[[1]]
#[1] 4
#[[2]]
#[1] 10
#[[3]]
#[1] 17
#[[4]]
#[1] Inf

res <- unlist(res)
passes <- res[is.finite(res)]
passes
#[1]  4 10 17

skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
skips2 <- skips[skips<=length(int)]
new.decision <- result$decision
new.decision[skips2] <- 'skip'
new.decision
# [1] "reject" "reject" "reject" "pass"   "skip"   "skip"   "skip"
"skip"
 #[9] "skip"   "pass"   "skip"   "skip"   "skip"   "skip"   "skip"
"reject"
#[17] "pass"   "skip"   "skip"   "skip"   "skip"   "skip"   "reject"
"reject"
cbind(result, new.decision)
#   intercept decision expected.decision      new.decision
#1          1   reject            reject reject
#2          2   reject            reject reject
#3          3   reject            reject reject
#4          0     pass              pass   pass
#5          3   reject              skip   skip
#6          0     pass              skip   skip
#7          3   reject              skip   skip
#8          5   reject              skip   skip
#9          0     pass              skip   skip
#10         0     pass              pass   pass
#11         3   reject              skip   skip
#12         1   reject              skip   skip
#13         0     pass              skip   skip
#14         0     pass              skip   skip
#15         2   reject              skip   skip
#16         1   reject            reject reject
#17         0     pass              pass   pass
#18         3   reject              skip   skip
#19         0     pass              skip   skip
#20         2   reject              skip   skip
#21         0     pass              skip   skip
#22         1   reject              skip   skip
#23         2   reject            reject reject
#24         2   reject            reject reject


On Fri, Mar 3, 2017 at 8:00 AM, SH <emptican at gmail.com> wrote:

> Hi Jim,
>
> Thank you very much for replying back.
>
> I think the data I presented have not many 'pass' than I thought.  The
> purpose of the code is to skip sampling for 5 consecutive rows when a
> previous row is found as 'pass'.  Thus, because the fourth row is
> 'pass', sampling will be skipped next five rows (i.e., from 5th to 9th
> rows).  Therefore any 'pass' within next 5 rows after first 'pass' should
> not affect 'skip'.  Could you try this?  Based on your code, I
> guess 'return' function may be one I should search.  I haven't used it
> before so I am not familiar with the function.  I made a new data set with
> 'expected.decision' column.  In the data set, once a 'pass' is found, the
> next sampling starts 5 rows after.  For example, since the forth row is
> 'pass',  the next sampling starts at 10th row.  Although 6th row should be
> 'pass', I want to label them as 'skip' since no sampling is made.
>
> The objective of the study is to investigate how many of 'reject' rows get
> 'skip' with a given sampling scheme, the rate of 'pass' because of skip
> sampling which should be 'reject'.
>
> Could you also try this data and give me your feedback?  Thanks again for
> you helps!!!
>
> Steve
>
> result<-read.table(text=
>     "intercept decision expected.decision
>  1 reject reject
>  2 reject reject
>  3 reject reject
>  0 pass pass
>  3 reject skip
>  0 pass skip
>  3 reject skip
>  5 reject skip
> 0 pass skip
>  0 pass pass
> 3 reject skip
>  1 reject skip
>  0 pass skip
>  0 pass skip
>  2 reject skip
>  1 reject reject
>  0 pass pass
>  3 reject skip
>  0 pass skip
>  2 reject skip
>  0 pass skip
>  1 reject skip
>  2 reject reject
>  2 reject reject
> ",
>   header=TRUE,stringsAsFactors=FALSE)
>  passes<-which(result$intercept == 0)
>  skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
>  result$decision[skips]<-"skip"
> result
>
>
>
> On Thu, Mar 2, 2017 at 5:42 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Steve,
>> Try this:
>>
>> result<-read.table(text=
>>    "intercept decision
>>  1       reject
>>  2       reject
>>  3       reject
>>  0       pass
>>  3       reject
>>  2       reject
>>  3       reject
>>  5       reject
>>  3       reject
>>  1       reject
>>  1       reject
>>  2       reject
>>  2       reject
>>  0       pass
>>  3       reject
>>  3       reject
>>  2       reject
>>  2       reject
>>  1       reject
>>  1       reject
>>  2       reject
>>  2       reject",
>>  header=TRUE,stringsAsFactors=FALSE)
>> passes<-which(result$intercept == 0)
>> skips<-as.vector(sapply(passes,function(x) return(x+1:5)))
>> result$decision[skips]<-"skip"
>>
>> Note that result$decision must be a character variable for this to
>> work.If it is a factor, convert it to character.
>>
>> Jim
>>
>>
>> On Thu, Mar 2, 2017 at 11:54 PM, SH <emptican at gmail.com> wrote:
>> > Hi
>> >
>> > Although I posted this in stackoverflow yesterday, I am asking here to
>> get
>> > helps as soon as quickly.
>> >
>> > I need help make code for mocking sampling environment. Here is my code
>> > below:
>> >
>> > First, I generated mock units with 1000 groups of 100 units. Each row is
>> > considered as independent sample space.
>> >
>> > unit <- 100 # Total units
>> > bad.unit.rate <- .05 # Proportion of bad units
>> > bad.unit.num <- ceiling(unit*bad.unit.rate) # Bad units
>> > n.sim=1000
>> > unit.group <- matrix(0, nrow=n.sim, ncol=unit)for(i in 1:n.sim){
>> >     unit.group[i, ] <- sample(rep(0:1, c(unit-bad.unit.num,
>> bad.unit.num)))}
>> > dim(unit.group)
>> >
>> > It gives 1000 by 100 groups
>> >
>> > ss <- 44 # Selected sample size
>> >
>> > 44 out of 100 units will be selected and decision (pass or reject) will
>> be
>> > made based on sampling.
>> >
>> > This below is decision code:
>> >
>> > intercept <- rep(0, nrow(unit.group))
>> > decision <- rep(0, nrow(unit.group))
>> > set.seed(2017)for(i in 1:nrow(unit.group)){
>> >     selected.unit <- sample(1:unit, ss)
>> >     intercept[i] <- sum(unit.group[i,][selected.unit])
>> >     decision[i] <- ifelse(intercept[i]==0, 'pass', 'reject')
>> >     result <- cbind(intercept, decision)
>> >     result}
>> > dim(result)
>> > head(result, 30)
>> >
>> >> head(result, 30)
>> >       intercept decision
>> >  [1,] "1"       "reject"
>> >  [2,] "2"       "reject"
>> >  [3,] "3"       "reject"
>> >  [4,] "0"       "pass"
>> >  [5,] "3"       "reject"
>> >  [6,] "2"       "reject"
>> >  [7,] "3"       "reject"
>> >  [8,] "5"       "reject"
>> >  [9,] "3"       "reject"
>> > [10,] "1"       "reject"
>> > [11,] "1"       "reject"
>> > [12,] "2"       "reject"
>> > [13,] "2"       "reject"
>> > [14,] "0"       "pass"
>> > [15,] "3"       "reject"
>> > [16,] "3"       "reject"
>> > [17,] "2"       "reject"
>> > [18,] "2"       "reject"
>> > [19,] "1"       "reject"
>> > [20,] "1"       "reject"
>> > [21,] "2"       "reject"
>> > [22,] "2"       "reject"
>> >
>> > I was able to make a decision for each 1000 rows based on sampling as
>> above.
>> >
>> > Now, I want to make code for "second" decision option as follows.
>> Assuming
>> > the row number is in order of time or sequence, if 'intercept' value is
>> 0
>> > or 'decision' is 'pass' in the row 4 above, I want to skip any decision
>> > next following 5 (or else) and to label as 'skip', not 'reject'. In the
>> > example above, rows from 5 to 9 will be 'skip' than 'reject'. Also, rows
>> > from 15 to 19 should be 'skip' instead of 'reject'. Although I tried to
>> > make preliminary code with my post, I have no idea where to start. Could
>> > anyone help me to make code? Any feedback will be greatly appreciated.
>> >
>> > Thank you very much in advance!!!
>> >
>> > Steve
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From exponential at o2.pl  Fri Mar  3 18:59:49 2017
From: exponential at o2.pl (exponential)
Date: Fri, 3 Mar 2017 18:59:49 +0100
Subject: [R] =?utf-8?q?array_-_how_to_create_=22logical_expression=22_for_?=
	=?utf-8?q?subset_dynamically?=
Message-ID: <a96cc68a39fc43f6b55aec77d9f03d72@gwp>

Hi!   I&#39;ve tried on SO, but without success. Maybe you will be able to help.   I have the following array (I use 3-dimensional in this example for simplicity, but it can be 3+ dims - 10,11 or more):   a &lt;- c(&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;)  b &lt;- c(&#39;bb&#39;, &#39;bbb&#39;)  c &lt;- c(&#39;C&#39;, &#39;CC&#39;, &#39;CCC&#39;)   dimNa &lt;- list(&#39;a&#39; = a, &#39;b&#39; = b, &#39;c&#39; = c)   outputArray &lt;- array(NA,  ??????????????? unname(sapply(dimNa, function(x) length(x), simplify = T)),  ??????????????? unname(dimNa))   I can subset it using name from one dimension manually, like:   &gt; outputArray[,&#39;bb&#39;,]  ??? C CC CCC  a1 NA NA? NA  a2 NA NA? NA  a3 NA NA? NA   or   &gt; outputArray[,,&#39;CCC&#39;]  ?? bb bbb  a1 NA? NA  a2 NA? NA  a3 NA? NA   I would like to write a function which subsets particular named element from one dimension (I mean I don&#39;t expect one dimension as a result by slicing using one named element, if that makes sense). Something like ?   myfunc &lt;- function(inputArray, namedElement)   thus I can call it (using above example):   myfunc(outputArray, &#39;bb&#39;)   or?   myfunc(outputArray, &#39;CCC&#39;)   to get identical as above results.   I know how to deal with finding to which dimension &#34;namedElement&#34; belongs (in my case all names are?unique).   The question is how to subset it from the array? One idea is to construct what is inside [ ] (in example:?,&#39;bb&#39;, or?,,&#39;CCC&#39;). I&#39;ve tried something like this:?   inputDims &lt;- &#34;,,&#39;CCC&#39;&#34;   outputArray[parse(text=inputDi   But this doesn&#39;t work. Maybe different approach should be used...   Any ideas are welcome:)!   Cheers!

	[[alternative HTML version deleted]]


From laomeng_3 at 163.com  Sat Mar  4 07:39:52 2017
From: laomeng_3 at 163.com (laomeng_3)
Date: Sat, 4 Mar 2017 14:39:52 +0800 (GMT+08:00)
Subject: [R] how to draw the confidence interval
Message-ID: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>

hi all
I have a question about drawing the confidence interval .

For instance,if I want to sample 100 times,and each time,the sample size is 10,and  the mean and sd is 15 and 1 respectively .I want to draw the 100 confidence intervals(as the attachment) .Which function should be used to draw the confidence interval ?

Many thanks!



????????

From nikhilraj768 at gmail.com  Sat Mar  4 08:43:23 2017
From: nikhilraj768 at gmail.com (Nikhil Raj)
Date: Sat, 4 Mar 2017 13:13:23 +0530
Subject: [R] regarding a problem in R
Message-ID: <CAOXZGt7RXx8B_29wwTUa+WT9QgmkcXx3Yd1WomKOa5QjSZXgpg@mail.gmail.com>

hello Team R,
i have been using R for statistical analysis of phylogeny and i have
installed the required packages phangorn and phytools but whenever i give
the command "pml.fit" the program stops and it appears thatb r for windows
GUI has stopped etc..
previously i thought it was a fault in my computer but it appears to happen
the same when i give the command in any other computer.
can i get a solution for this i have tried it on windows 10 and older
versions can it be fixed?
and also can you please send me the the commands for performing SH test of
phylogeny using phangorn if possible.
please do reply

thank you

	[[alternative HTML version deleted]]


From tomas.przc at gmail.com  Sat Mar  4 14:54:13 2017
From: tomas.przc at gmail.com (=?UTF-8?B?VG9tw6FzIFDDqXJleiBDLg==?=)
Date: Sat, 4 Mar 2017 10:54:13 -0300
Subject: [R] List raster files
Message-ID: <CAL_BooeVf2K_tS4rN+JKWAWxX1Mb-V2vqNANedM4NPdF+1R6=w@mail.gmail.com>

I am working with raster images of modis of the satellites aqua and terra
and I need to combine the images by its day and year (originally in Julian
day). However, for the earth I have 6031 images and for aqua 5277. I want
to know how to create an object that selects the images for both folders
with their same date and then create a loop after.
Thank you

	[[alternative HTML version deleted]]


From nikhilraj768 at gmail.com  Sat Mar  4 18:59:48 2017
From: nikhilraj768 at gmail.com (Nikhil Raj)
Date: Sat, 4 Mar 2017 23:29:48 +0530
Subject: [R] (no subject)
Message-ID: <CAOXZGt7hpthzRBRGz5xjNsj+0yFYQP1DOjr+Oa09V1ryQR2_vw@mail.gmail.com>

hello Team R,
i have been using R for statistical analysis of phylogeny and i have
installed the required packages phangorn and phytools but whenever i give
the command "pml.fit" the program stops and it appears thatb r for windows
GUI has stopped etc..
previously i thought it was a fault in my computer but it appears to happen
the same when i give the command in any other computer.
can i get a solution for this i have tried it on windows 10 and older
versions can it be fixed?
and also can you please send me the the commands for performing SH test of
phylogeny using phangorn if possible.
please do reply

thank you

	[[alternative HTML version deleted]]


From nikhilraj768 at gmail.com  Sat Mar  4 19:00:48 2017
From: nikhilraj768 at gmail.com (Nikhil Raj)
Date: Sat, 4 Mar 2017 23:30:48 +0530
Subject: [R] help
Message-ID: <CAOXZGt5DdCRsWEC4UdpgqMQcOecUHjfociqqfVBbfDeDsTA7Hw@mail.gmail.com>

hello Team R,
i have been using R for statistical analysis of phylogeny and i have
installed the required packages phangorn and phytools but whenever i give
the command "pml.fit" the program stops and it appears thatb r for windows
GUI has stopped etc..
previously i thought it was a fault in my computer but it appears to happen
the same when i give the command in any other computer.
can i get a solution for this i have tried it on windows 10 and older
versions can it be fixed?
and also can you please send me the the commands for performing SH test of
phylogeny using phangorn if possible.
please do reply

thank you

	[[alternative HTML version deleted]]


From phawkins at connact.com  Sat Mar  4 22:18:35 2017
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sat, 04 Mar 2017 16:18:35 -0500
Subject: [R] Heatmap help
In-Reply-To: <CAHxKz8as7YWhV03Fz3ixqzyH3NrDc4GEPr-MaACxHD7=_+qvTg@mail.gmail.com>
	(=?utf-8?Q?=22Andr=C3=A9?= Luis Neves"'s message of "Fri, 3 Mar 2017
	11:59:11 -0700")
References: <CAHxKz8as7YWhV03Fz3ixqzyH3NrDc4GEPr-MaACxHD7=_+qvTg@mail.gmail.com>
Message-ID: <87k284eo5w.fsf@connact.com>

Hi, you have a couple of things going on here.  You can reorder your
matrix by creating an index like this:

> A_index=c(grep(".A", colnames(A)), grep(".B", colnames(A)))

and do this:

> heatmap.2(A[,A_index], dendrogram="col", Rowv = colnames(A)[A_index], tracecol =
          NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"), hclustfun =
          function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
         "Samples", margins = c(9,9), keysize = 1,
          main='Test')

But you're constructing your dendrogram on the columns, so your columns
get reordered by mean weight.  (Also, you've misunderstood Rowv and Colv.)

However, if you force your columns to not reorder by setting
"Colv=FALSE", AND tell it to construct the dendrogram on the columns,
you get a warning, because that's contradictory:

> heatmap.2(A[,A_index], dendrogram="col", Colv = FALSE, tracecol = NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"),  
          hclustfun = function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
          "Samples", margins = c(9,9), keysize = 1, main='Test')
Warning message:
In heatmap.2(A[, A_index], dendrogram = "col", Colv = FALSE, tracecol = NA,  :
  Discrepancy: Colv is FALSE, while dendrogram is `column'. Omitting column dendogram.

Maybe you really meant to build your dendrogram on the rows, like this:

heatmap.2(A[,A_index], dendrogram="row", Colv = FALSE, tracecol = NA,col=bluered(64), sub = "",
          distfun = function(y) dist(y, method = "euclidean"),  
          hclustfun = function(y) hclust(y, method = "median"),
          scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
          "Samples", margins = c(9,9), keysize = 1, main='Test')

If that's not it, I suggest playing around with the examples in
?heatmap.2 since the documentation is kind of opaque, but the examples
are pretty good.

>>>>> "ALN" == Andr? Luis Neves <andrluis at ualberta.ca> writes:

ALN> Dear all,

ALN> I was wondering if you could help me to construct a heat map, in which the
ALN> columns are sorted by sample type (A first and then B).
ALN> My reproducible example below runs, but the columns of the heatmap are not
ALN> organized in the way I would like because it has first sampleA, SampleB,
ALN> sampleA, and then sampleB.


ALN> A = matrix(rnorm(20), 5,8)
ALN> A
ALN> colnames(A) <- c ("Sample1.A", "Sample2.B", "Sample3.A", "Sample4.B",
ALN> "Sample5.A", "Sample6.B", "Sample7.A", "Sample8.B")
ALN> A
ALN> rownames(A) <- c ("protein1","protein2", "protein3", "protein4","protein5")
ALN> A

ALN> heatmap.2(A, dendrogram="col", Rowv = colnames(A), tracecol =
ALN> NA,col=bluered(64), sub = "",
ALN>           distfun = function(y) dist(y, method = "euclidean"), hclustfun =
ALN> function(y) hclust(y, method = "median"),
ALN>           scale = "row",cexCol = 1, cexRow = 0.9, ylab = "Enzymes", xlab =
ALN> "Samples", margins = c(9,9), keysize = 1,
ALN>           main='Test')



ALN> ?Thanks.

ALN> -- 
ALN> Andre

ALN> 	[[alternative HTML version deleted]]

ALN> ______________________________________________
ALN> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
ALN> https://stat.ethz.ch/mailman/listinfo/r-help
ALN> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
ALN> and provide commented, minimal, self-contained, reproducible code.



-- 
Patricia J. Hawkins


From burhan.mohamedali at icloud.com  Sun Mar  5 00:56:03 2017
From: burhan.mohamedali at icloud.com (Burhan Mohamedali)
Date: Sat, 4 Mar 2017 17:56:03 -0600
Subject: [R]  Text cutoff in legends
Message-ID: <66174ADD-43D1-439C-8C54-3DB129446550@icloud.com>

R adds cut tea e

Excuse my brevity;to  this message is sent from my iPhonequ


From ibrahim.salman92 at gmail.com  Sun Mar  5 08:20:05 2017
From: ibrahim.salman92 at gmail.com (Ibrahim Salman)
Date: Sun, 5 Mar 2017 09:20:05 +0200
Subject: [R] AED package
Message-ID: <CAHOO4v=xGE6jbsSMrit=gHCH2zyjpQUzaQSBD062ptvXgsHZTg@mail.gmail.com>

Dear all,

I am trying to run corvif command in R and apparently it needs AED package.
Does anyone know where can I find this package ?

Thanks a lot,
Ibrahim



--




Ibrahim N. Salman ?
Master Student
Prof. Yael Lubin's Lab
Mitrani Department of Desert Ecology
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84900, Israel

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Mar  5 23:47:37 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 6 Mar 2017 11:47:37 +1300
Subject: [R] [FORGED]  how to draw the confidence interval
In-Reply-To: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
Message-ID: <f51269f5-f627-9982-d6aa-63f00de1305f@auckland.ac.nz>

On 04/03/17 19:39, laomeng_3 wrote:
> hi all I have a question about drawing the confidence interval .
>
> For instance,if I want to sample 100 times,and each time,the sample
> size is 10,and the mean and sd is 15 and 1 respectively .I want to draw
> the 100 confidence intervals(as the attachment) .Which function should
> be used to draw the confidence interval ?

This list does not answer questions about homework.

(BTW, no attachment came through; only a *very* limited range of file 
types is permitted for attachments).

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sun Mar  5 23:49:23 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 6 Mar 2017 11:49:23 +1300
Subject: [R] array - how to create "logical expression" for subset
 dynamically
In-Reply-To: <a96cc68a39fc43f6b55aec77d9f03d72@gwp>
References: <a96cc68a39fc43f6b55aec77d9f03d72@gwp>
Message-ID: <987e413d-a8ce-bf16-6f85-8445a715775f@auckland.ac.nz>

On 04/03/17 06:59, exponential wrote:
> Hi! I&#39;ve tried on SO, but without success. Maybe you will be
> able
to help. I have the following array (I use 3-dimensional in this example
for simplicity, but it can be 3+ dims - 10,11 or more): a &lt;-
c(&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;) b &lt;- c(&#39;bb&#39;,
&#39;bbb&#39;) c &lt;- c(&#39;C&#39;, &#39;CC&#39;, &#39;CCC&#39;) dimNa
&lt;- list(&#39;a&#39; = a, &#39;b&#39; = b, &#39;c&#39; = c)
outputArray &lt;- array(NA, unname(sapply(dimNa, function(x) length(x),
simplify = T)), unname(dimNa)) I can subset it using name from one
dimension manually, like: &gt; outputArray[,&#39;bb&#39;,] C CC CCC a1
NA NA NA a2 NA NA NA a3 NA NA NA or &gt; outputArray[,,&#39;CCC&#39;] bb
bbb a1 NA NA a2 NA NA a3 NA NA I would like to write a function which
subsets particular named element from one dimension (I mean I don&#39;t
expect one dimension as a result by slicing using one named element, if
that makes sense). Something like myfunc &lt;- function(inputArray,
namedElement) thus I can call it (using above example):
myfunc(outputArray, &#39;bb&#39;) or myfunc(outputArray, &#39;CCC&#39;)
to get identical as above results. I know how to deal with finding to
which dimension &#34;namedElement&#34; belongs (in my case all names are
unique). The question is how to subset it from the array? One idea is to
construct what is inside [ ] (in example: ,&#39;bb&#39;, or
,,&#39;CCC&#39;). I&#39;ve tried something like this: inputDims &lt;-
&#34;,,&#39;CCC&#39;&#34; outputArray[parse(text=inputDi But this
doesn&#39;t work. Maybe different approach should be used... Any ideas
are welcome:)! Cheers!


DO NOT post in HTML.  Your mail was an incomprehensible mess.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sun Mar  5 23:53:03 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 6 Mar 2017 11:53:03 +1300
Subject: [R] [FORGED]  AED package
In-Reply-To: <CAHOO4v=xGE6jbsSMrit=gHCH2zyjpQUzaQSBD062ptvXgsHZTg@mail.gmail.com>
References: <CAHOO4v=xGE6jbsSMrit=gHCH2zyjpQUzaQSBD062ptvXgsHZTg@mail.gmail.com>
Message-ID: <e0211a30-f108-eaf5-19b4-1a72adf45d84@auckland.ac.nz>

On 05/03/17 20:20, Ibrahim Salman wrote:
> Dear all,
>
> I am trying to run corvif command in R and apparently it needs AED package.
> Does anyone know where can I find this package ?

Have you ever heard of "Google"?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sun Mar  5 23:55:00 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 6 Mar 2017 11:55:00 +1300
Subject: [R] [FORGED] Error in curve 'expr' did not evaluate to an
 object of length 'n'
In-Reply-To: <1449625709.291181.1488545033950@mail.yahoo.com>
References: <1449625709.291181.1488545033950.ref@mail.yahoo.com>
	<1449625709.291181.1488545033950@mail.yahoo.com>
Message-ID: <4af79295-bc71-ff15-500f-0024c3bc5c76@auckland.ac.nz>

On 04/03/17 01:43, Allan Tanaka wrote:
> Please help. I try to re-produce R-script by plotting a set of functionWhen i running code: plot(Vectorize(running.acf.max))it gets the error message like this: Error in curve(expr = x, from = from, to = to, xlim = xlim, ylab = ylab,  :   'expr' did not evaluate to an object of length 'n'
> Even though i have vectorized the function argument.

Your example is not reproducible.  We do not have the file 
EURJPY.m14401.csv.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rbaer at atsu.edu  Mon Mar  6 00:18:28 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 5 Mar 2017 17:18:28 -0600
Subject: [R] List raster files
In-Reply-To: <CAL_BooeVf2K_tS4rN+JKWAWxX1Mb-V2vqNANedM4NPdF+1R6=w@mail.gmail.com>
References: <CAL_BooeVf2K_tS4rN+JKWAWxX1Mb-V2vqNANedM4NPdF+1R6=w@mail.gmail.com>
Message-ID: <b7883f31-469d-0557-008c-9a29a3fe921e@atsu.edu>

On 3/4/2017 7:54 AM, Tom?s P?rez C. wrote:
> I am working with raster images of modis of the satellites aqua and terra
> and I need to combine the images by its day and year (originally in Julian
> day). However, for the earth I have 6031 images and for aqua 5277. I want
> to know how to create an object that selects the images for both folders
> with their same date and then create a loop after.
> Thank you
You will need to provide more information on how where date information 
is stored and how the files are organized to get any useful response.  
If you are using file time stamps, I'm guessing some system info might 
be useful.  Please read the posting guide and see what you can do to 
help the list help you.




>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Mar  6 00:39:33 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 5 Mar 2017 15:39:33 -0800
Subject: [R] Error in curve 'expr' did not evaluate to an object of
	length 'n'
In-Reply-To: <1449625709.291181.1488545033950@mail.yahoo.com>
References: <1449625709.291181.1488545033950.ref@mail.yahoo.com>
	<1449625709.291181.1488545033950@mail.yahoo.com>
Message-ID: <CAF8bMcYJz3L+8_9nJqdQtxevZA+m+7vjF6+m=n+vfBmCTYwF1g@mail.gmail.com>

You define a function called running.acf.max and then call
    plot(running.acf.max)
R's plot, when given a function f, makes a plot of f(x) vs. x
by calling curve().

Did you mean to plot the result of running.acf.max with its
default arguments?  That would be done with
    plot(running.acf.max())

There are several other problems with this code.  E.g., you have
  running.acf.max <-
  function (data = returns, window = 100, nlags = 5, plot = T, main = "")
  {
      clevel <- qnorm(0.5 + 0.95/2)/sqrt(window)
      series <- rollapply(data = returns, window, align = "right",
          by = 1, function(w) {
          ...

You should have data=data in the call to rollapply so it depends
on the 'data' argument to running.acf.max.

Use traceback() after an error to see where the error came from.



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 3, 2017 at 4:43 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> Please help. I try to re-produce R-script by plotting a set of functionWhen i running code: plot(Vectorize(running.acf.max))it gets the error message like this: Error in curve(expr = x, from = from, to = to, xlim = xlim, ylab = ylab,  :   'expr' did not evaluate to an object of length 'n'
> Even though i have vectorized the function argument.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Mar  6 00:43:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 5 Mar 2017 15:43:37 -0800
Subject: [R] array - how to create "logical expression" for subset
	dynamically
In-Reply-To: <a96cc68a39fc43f6b55aec77d9f03d72@gwp>
References: <a96cc68a39fc43f6b55aec77d9f03d72@gwp>
Message-ID: <CAGxFJbRJ8k-NEeESv=GCDE2A57B5u_XCUxKYdLqMDY3mjKOzPQ@mail.gmail.com>

A great example of why you need to read and follow the posting guide
-- this is a plain text list: NO HTML.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 3, 2017 at 9:59 AM, exponential <exponential at o2.pl> wrote:
> Hi!   I&#39;ve tried on SO, but without success. Maybe you will be able to help.   I have the following array (I use 3-dimensional in this example for simplicity, but it can be 3+ dims - 10,11 or more):   a &lt;- c(&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;)  b &lt;- c(&#39;bb&#39;, &#39;bbb&#39;)  c &lt;- c(&#39;C&#39;, &#39;CC&#39;, &#39;CCC&#39;)   dimNa &lt;- list(&#39;a&#39; = a, &#39;b&#39; = b, &#39;c&#39; = c)   outputArray &lt;- array(NA,                  unname(sapply(dimNa, function(x) length(x), simplify = T)),                  unname(dimNa))   I can subset it using name from one dimension manually, like:   &gt; outputArray[,&#39;bb&#39;,]      C CC CCC  a1 NA NA  NA  a2 NA NA  NA  a3 NA NA  NA   or   &gt; outputArray[,,&#39;CCC&#39;]     bb bbb  a1 NA  NA  a2 NA  NA  a3 NA  NA   I would like to write a function which subsets particular named element from one dimension (I mean I don&#39;t expect one dimension as a result by slicing using one named element, if that makes sense). Something like     myfunc &lt;- function(inputArray, namedElement)   thus I can call it (using above example):   myfunc(outputArray, &#39;bb&#39;)   or    myfunc(outputArray, &#39;CCC&#39;)   to get identical as above results.   I know how to deal with finding to which dimension &#34;namedElement&#34; belongs (in my case all names are unique).   The question is how to subset it from the array? One idea is to construct what is inside [ ] (in example: ,&#39;bb&#39;, or ,,&#39;CCC&#39;). I&#39;ve tried something like this:    inputDims &lt;- &#34;,,&#39;CCC&#39;&#34;   outputArray[parse(text=inputDi   But this doesn&#39;t work. Maybe different approach should be used...   Any ideas are welcome:)!   Cheers!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Mar  6 00:49:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 5 Mar 2017 15:49:58 -0800
Subject: [R] (no subject)
In-Reply-To: <CAOXZGt7hpthzRBRGz5xjNsj+0yFYQP1DOjr+Oa09V1ryQR2_vw@mail.gmail.com>
References: <CAOXZGt7hpthzRBRGz5xjNsj+0yFYQP1DOjr+Oa09V1ryQR2_vw@mail.gmail.com>
Message-ID: <CAGxFJbRKkaeGfvN-NJ-9JB+HqdC6Z6-yR8AyrNGKndHH0H0rdQ@mail.gmail.com>

Well, this is your 3rd post to appear here with no replies. At what
point will you stop posting and realize that no one here is able or
willing to answer your almost incomprehensible post?

However, you might try to contact the package maintainer to see if
this is a bug ( -- you **have the latest version of the package**, do
you not?).

As for providing free consulting help .... lots of luck with that!
Read the posting guide to learn what sort of help you can expect here.

cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 4, 2017 at 9:59 AM, Nikhil Raj <nikhilraj768 at gmail.com> wrote:
> hello Team R,
> i have been using R for statistical analysis of phylogeny and i have
> installed the required packages phangorn and phytools but whenever i give
> the command "pml.fit" the program stops and it appears thatb r for windows
> GUI has stopped etc..
> previously i thought it was a fault in my computer but it appears to happen
> the same when i give the command in any other computer.
> can i get a solution for this i have tried it on windows 10 and older
> versions can it be fixed?
> and also can you please send me the the commands for performing SH test of
> phylogeny using phangorn if possible.
> please do reply
>
> thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Mar  6 01:59:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Mar 2017 11:59:44 +1100
Subject: [R] Text cutoff in legends
In-Reply-To: <66174ADD-43D1-439C-8C54-3DB129446550@icloud.com>
References: <66174ADD-43D1-439C-8C54-3DB129446550@icloud.com>
Message-ID: <CA+8X3fWUQpUQKUnBwfgX5BQqVRAs0WhiGTW=oG7vB4WxOrkfhQ@mail.gmail.com>

Hi Burhan,
I think you may have set records in both obscurity and brevity (watch
out, Jeff). Undeterred, I will guess that you have positioned the
legend so that it runs off the plot. Try adding the "xpd=TRUE"
argument to the call to legend.

Jim


On Sun, Mar 5, 2017 at 10:56 AM, Burhan Mohamedali
<burhan.mohamedali at icloud.com> wrote:
> R adds cut tea e
>
> Excuse my brevity;to  this message is sent from my iPhonequ
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Mar  6 05:48:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 5 Mar 2017 20:48:05 -0800
Subject: [R] help
In-Reply-To: <CAOXZGt5DdCRsWEC4UdpgqMQcOecUHjfociqqfVBbfDeDsTA7Hw@mail.gmail.com>
References: <CAOXZGt5DdCRsWEC4UdpgqMQcOecUHjfociqqfVBbfDeDsTA7Hw@mail.gmail.com>
Message-ID: <3701AD9C-987A-470D-AD1B-3C1DDB9FA970@comcast.net>


> On Mar 4, 2017, at 10:00 AM, Nikhil Raj <nikhilraj768 at gmail.com> wrote:
> 
> hello Team R,
> i have been using R for statistical analysis of phylogeny and i have
> installed the required packages phangorn and phytools but whenever i give
> the command "pml.fit" the program stops and it appears thatb r for windows
> GUI has stopped etc..

What does it mean to `give the command "pml.fit"`?

(R is a functional language so it doesn't really have "commands". It is a language where function names are entered followed by a left-parenthesis, followed by arguments and closed by a right parenthesis. This then returns a value to the read-eval-print loop and if that expression has an assignment operator to its left then the value would be stored in a data object.)


> previously i thought it was a fault in my computer but it appears to happen
> the same when i give the command in any other computer.
> can i get a solution for this i have tried it on windows 10 and older
> versions can it be fixed?
> and also can you please send me the the commands for performing SH test of
> phylogeny using phangorn if possible.

Most packages have help pages where sample code appears at the bottom of the page for a particular function. This particular function appears designed as "internal" meaning that you should have followed the See Also links at the bottom of its page.


> please do reply

And do, sir or madam, read the posting guide reference below.

> 
> thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From laomeng_3 at 163.com  Mon Mar  6 07:35:40 2017
From: laomeng_3 at 163.com (laomeng_3)
Date: Mon, 6 Mar 2017 14:35:40 +0800 (GMT+08:00)
Subject: [R] [FORGED]  how to draw the confidence interval
In-Reply-To: <f51269f5-f627-9982-d6aa-63f00de1305f@auckland.ac.nz>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
	<f51269f5-f627-9982-d6aa-63f00de1305f@auckland.ac.nz>
Message-ID: <188e04fb.daf3.15aa254a42f.Coremail.laomeng_3@163.com>

this is not homework,just a case which I made by myself.


????????????????



On 2017-03-06 06:47 , Rolf Turner Wrote:

On 04/03/17 19:39, laomeng_3 wrote:
> hi all I have a question about drawing the confidence interval .
>
> For instance,if I want to sample 100 times,and each time,the sample
> size is 10,and the mean and sd is 15 and 1 respectively .I want to draw
> the 100 confidence intervals(as the attachment) .Which function should
> be used to draw the confidence interval ?

This list does not answer questions about homework.

(BTW, no attachment came through; only a *very* limited range of file
types is permitted for attachments).

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Mon Mar  6 09:03:07 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Mon, 6 Mar 2017 00:03:07 -0800
Subject: [R] [FORGED] how to draw the confidence interval
In-Reply-To: <188e04fb.daf3.15aa254a42f.Coremail.laomeng_3@163.com>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
	<f51269f5-f627-9982-d6aa-63f00de1305f@auckland.ac.nz>
	<188e04fb.daf3.15aa254a42f.Coremail.laomeng_3@163.com>
Message-ID: <6f267077-82a4-beb7-b32c-79620167ca7b@gmail.com>

On 3/5/2017 10:35 PM, laomeng_3 wrote:
> this is not homework,just a case which I made by myself.
> 
> 
> ??????????????
> 
> 
> 
> On 2017-03-06 06:47 , Rolf Turner Wrote:
> 
> On 04/03/17 19:39, laomeng_3 wrote:
>> hi all I have a question about drawing the confidence interval .
>>
>> For instance,if I want to sample 100 times,and each time,the sample
>> size is 10,and the mean and sd is 15 and 1 respectively .I want to draw
>> the 100 confidence intervals(as the attachment) .Which function should
>> be used to draw the confidence interval ?
> 
> This list does not answer questions about homework.
> 
> (BTW, no attachment came through; only a *very* limited range of file
> types is permitted for attachments).
> 
> cheers,
> 
> Rolf Turner
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

As was pointed out your attachment didn't make it to the list, so we 
don't know what you want plotted, and your problem statement wasn't 
clear (at least to me).

Usually, it you want help on this list, you should provide a 
reproducible example.  In your case, at least show us what you tried. 
If you provide code to generate your random samples, and then describe 
what you want, e.g. "plot sample means and standard errors estimated 
from the samples,"  we can play along at home.  Then you may get some 
usable help.

You could also Google something like "R plot means and standard errors".


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From r.turner at auckland.ac.nz  Mon Mar  6 09:08:26 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 6 Mar 2017 21:08:26 +1300
Subject: [R] [FORGED]  how to draw the confidence interval
In-Reply-To: <188e04fb.daf3.15aa254a42f.Coremail.laomeng_3@163.com>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
	<f51269f5-f627-9982-d6aa-63f00de1305f@auckland.ac.nz>
	<188e04fb.daf3.15aa254a42f.Coremail.laomeng_3@163.com>
Message-ID: <f17bf2b7-74c1-206e-fef2-2e4a0319c98e@auckland.ac.nz>

On 06/03/17 19:35, laomeng_3 wrote:

> this is not homework, just a case which I made by myself.

Be that as it may, if you are going to use R you should learn something 
about using R, rather than treating it as a magical black box.

There is, as far as I know (not really very far!) no currently existing 
function to "draw the confidence intervals".  (Well, actually there is 
probably one out there somewhere.  There is so *much* out there.  But 
finding it is probably more effort than rolling your own.)

It is actually very easy to roll your own --- I think I could do it in 5 
or 10 minutes.  But I am *NOT* going to.  (a) I am not going to do your 
work for you, even if it's not homework, and (b) you will *learn* 
something by figuring out how to do it yourself.

Hint:  Read up on the functions lines() and segments().  And maybe 
arrows().  The function abline() might be of use as well.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On 2017-03-06 06:47 , Rolf Turner <mailto:r.turner at auckland.ac.nz> Wrote:
>
>     On 04/03/17 19:39, laomeng_3 wrote:
>     > hi all I have a question about drawing the confidence interval .
>     >
>     > For instance,if I want to sample 100 times,and each time,the sample
>     > size is 10,and the mean and sd is 15 and 1 respectively .I want to
>     draw
>     > the 100 confidence intervals(as the attachment) .Which function
>     should
>     > be used to draw the confidence interval ?
>
>     This list does not answer questions about homework.
>
>     (BTW, no attachment came through; only a *very* limited range of file
>     types is permitted for attachments).


From drjimlemon at gmail.com  Mon Mar  6 11:19:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Mar 2017 21:19:58 +1100
Subject: [R] how to draw the confidence interval
In-Reply-To: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
Message-ID: <CA+8X3fVkPVxBqA6fGQLrA2oQ7RU0mbv07CWGaVX7_nf=udaqVA@mail.gmail.com>

Hi laomeng,
If you know how to plot the means and calculate the standard
deviations, perhaps look at the "dispersion" function in the plotrix
package.

Jim


On Sat, Mar 4, 2017 at 5:39 PM, laomeng_3 <laomeng_3 at 163.com> wrote:
> hi all
> I have a question about drawing the confidence interval .
>
> For instance,if I want to sample 100 times,and each time,the sample size is 10,and  the mean and sd is 15 and 1 respectively .I want to draw the 100 confidence intervals(as the attachment) .Which function should be used to draw the confidence interval ?
>
> Many thanks!
>
>
>
> ????????
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd.mes at cbs.dk  Mon Mar  6 11:11:38 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 6 Mar 2017 10:11:38 +0000
Subject: [R]   R 3.3.3 is released
Message-ID: <E4C6331F-1EAD-4647-8957-BBF51B337C76@cbs.dk>

The build system rolled up R-3.3.3.tar.gz (codename "Another Canoe") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.3.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the checksums for the freshly created files, in case you wish
to check that they are uncorrupted. As a new feature, we also include SHA-256 checksums.

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 342856fe28ac8af7c8d48db1f6dde8e2
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 3edf7e6a206a1303ed50979fb21d2ab7
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 2437014ef40641cdc9673e89c040b7a8
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f80d02e7ba9729a927e1c9cf7b435b32
MD5 (VERSION-INFO.dcf) = c643e0eb5a8e98b034f76287c574be32
MD5 (R-3/R-3.3.2.tar.gz) = 2437014ef40641cdc9673e89c040b7a8

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 342856fe28ac8af7c8d48db1f6dde8e2
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 51ca42f97f9efecfc5c4e241cf607c35
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 0ac211ec15e813a24f8f4a5a634029a4
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = 048b912c6ada20a96fc7f5b513d7b4a3
MD5 (R-3/R-3.3.3.tar.gz) = 0ac211ec15e813a24f8f4a5a634029a4

SHA-256:

6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
d5f349070096413e0e18c4f5ad2d9c8b3e2df5ea7c06489a28288fc3606cf1ff  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
ef585a2da9074252b83a1dc29bbc16de08ca007486f451bb0e2e1d45fea6ea4e  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
a9c4dec8a4a2660f99dbf13a10eda5b7ad72a970d4fbcc982dfaf870949d4c1d  NEWS.2
5ab768053a275084618fb669b4fbaadcc39158998a87e8465323829590bcfc6c  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
d4d6573ba536a53ca649e83f47ba52e85cc3747e5cf6524e71ea145828a31e18  VERSION-INFO.dcf
5ab768053a275084618fb669b4fbaadcc39158998a87e8465323829590bcfc6c  R-3/R-3.3.3.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 3.3.3:

  NEW FEATURES:

    * Changes when redirection of a http:// URL to a https:// URL is
      encountered:

        * The internal methods of download.file() and url() now report
          that they cannot follow this (rather than failing silently).

        * (Unix-alike) download.file(method = "auto") (the default)
          re-tries with method = "libcurl".

        * (Unix-alike) url(method = "default") with an explicit open
          argument re-tries with method = "libcurl".  This covers many
          of the usages, e.g. readLines() with a URL argument.

  INSTALLATION on a UNIX-ALIKE:

    * The configure check for the zlib version is now robust to
      versions longer than 5 characters, including 1.2.11.

  UTILITIES:

    * Environmental variable _R_CHECK_TESTS_NLINES_ controls how R CMD
      check reports failing tests (see SS8 of the 'R Internals' manual).

  DEPRECATED AND DEFUNCT:

    * (C-level Native routine registration.)  The undocumented styles
      field of the components of R_CMethodDef and R_FortranMethodDef is
      deprecated.

  BUG FIXES:

    * vapply(x, *) now works with long vectors x.  (PR#17174)

    * isS3method("is.na.data.frame") and similar are correct now.
      (PR#17171)

    * grepRaw(<long>, <short>, fixed = TRUE) now works, thanks to a
      patch by Mikko Korpela.  (PR#17132)

    * Package installation into a library where the package exists
      _via_ symbolic link now should work wherever Sys.readlink()
      works, resolving PR#16725.

    * "Cincinnati" was missing an "n" in the precip dataset.

    * Fix buffer overflow vulnerability in pdf() when loading an
      encoding file.  Reported by Talos (TALOS-2016-0227).

    * getDLLRegisteredRoutines() now produces its warning correctly
      when multiple DLLs match, thanks to Matt Dowle's PR#17184.

    * Sys.timezone() now returns non-NA also on platforms such as
      Ubuntu 14.04.5 LTS, thanks to Mikko Korpela's PR#17186.

    * format(x) for an illegal "POSIXlt" object x no longer segfaults.

    * methods(f) now also works for f "(" or "{".

    * (Windows only) dir.create() did not check the length of the path
      to create, and so could overflow a buffer and crash R.
      (PR#17206)

    * On some systems, very small hexadecimal numbers in hex notation
      would underflow to zero.  (PR#17199)

    * pmin() and pmax() now work again for ordered factors and 0-length
      S3 classed objects, thanks to Suharto Anggono's PR#17195 and
      PR#17200.

    * bug.report() did not do any validity checking on a package's
      BugReports field.  It now ignores an empty field, removes leading
      whitespace and only attempts to open http:// and https:// URLs,
      falling back to emailing the maintainer.

    * Bandwidth selectors bw.ucv() and bw.SJ() gave incorrect answers
      or incorrectly reported an error (because of integer overflow)
      for inputs longer than 46341.  Similarly for bw.bcv() at length
      5793.

      Another possible integer overflow is checked and may result in an
      error report (rather than an incorrect result) for much longer
      inputs (millions for a smooth distribution).

    * findMethod() failed if the active signature had expanded beyond
      what a particular package used. (Example with packages XR and
      XRJulia on CRAN.)

    * qbeta() underflowed too early in some very asymmetric cases.
      (PR#17178)

    * R CMD Rd2pdf had problems with packages with non-ASCII titles in
      .Rd files (usually the titles were omitted).


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From lists at dewey.myzen.co.uk  Mon Mar  6 12:23:25 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 6 Mar 2017 11:23:25 +0000
Subject: [R] Antwort: Re:  xtable: Width of Columns
In-Reply-To: <OF4C973837.0EF870BE-ONC12580DB.002A4E29-C12580DB.002A9BB1@lotus.hawesko.de>
References: <OFFD1F8D6D.8AA9AF90-ONC12580D7.00454AB9-C12580D7.00459040@lotus.hawesko.de>
	<48661d76-ef06-0eec-43cc-9bc4b500a721@dewey.myzen.co.uk>
	<OF4C973837.0EF870BE-ONC12580DB.002A4E29-C12580DB.002A9BB1@lotus.hawesko.de>
Message-ID: <79d128d5-dc16-0895-bf0a-42e45b148471@dewey.myzen.co.uk>



On 06/03/2017 07:45, G.Maubach at weinwolf.de wrote:
> Hi Michael,
>
> thank for you answer.
>
> Where do I have to put the code snippet "p(3cm)"? Is it neither an
> official argument to xtable() nor to print.xtable().
>

 From the help about the align argument:

Character vector of length equal to the number of columns of the 
resulting table, indicating the alignment of the corresponding columns. 
Also, "|" may be used to produce vertical lines between columns in LaTeX 
tables, but these are effectively ignored when considering the required 
length of the supplied vector. If a character vector of length one is 
supplied, it is split as strsplit(align, "")[[1]] before processing. 
Since the row names are printed in the first column, the length of align 
is one greater than ncol(x) if x is a data.frame. Use "l", "r", and "c" 
to denote left, right, and center alignment, respectively. Use "p{3cm}" 
etc. for a LaTeX column of the specified width. For HTML output the "p" 
alignment is interpreted as "l", ignoring the width request. Default 
depends on the class of x.

> Could you give me a hint?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:        Michael Dewey <lists at dewey.myzen.co.uk>
> An:        G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:        03.03.2017 12:41
> Betreff:        Re: [R] xtable: Width of Columns
> ------------------------------------------------------------------------
>
>
>
> Does p{3cm} do what you want as an alignment?
>
> On 02/03/2017 12:39, G.Maubach at weinwolf.de wrote:
>> Hi All,
>>
>> I have the following code in R Markdown document:
>>
>> ```{r, results = "asis", echo = FALSE}
>> library(xtable)
>> response <- as.data.frame(matrix(NA, 2, 2))
>> colnames(response) <- c("Anzahl", "Prozent")
>> rownames(response) <- c("gesamte R?cksendungen (brutto)  ",
>>                         "auswertbare Frageb?gen (netto)  ")
>> response[[1, 1]] <- 1
>> response[[1, 2]] <- 2.0
>> response[[2, 1]] <- 3
>> response[[2, 2]] <- 4.0
>>
>> response_table <- xtable(
>>   response,
>>   caption = "R?cklauf und R?cklaufquote",
>>   label = "Responsequote",
>>   display = c("s","d","f"),
>>   digits = 1,
>>   align = c("l", "c", "c") #  auto = TRUE
>>   )
>>
>> print.xtable(
>>   response_table,
>>   type = "html",
>>   caption.placement = "top",
>>   format.args = list(
>>     big.mark = ".",
>>     decimal.mark = ","),
>>   size = 500,
>>   width = 100)
>> ```
>>
>> and would like to control the width of the columns. But columns width is
>> always aligned to the content.
>>
>> Is there a way to give the columns width, e.g. 25 characters, for all
>> columns or for each column separately to get more spacing for the text and
>> the borders of the table?
>>
>> Kind regards
>>
>> Georg
>>
>>                  [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tomas.sieger at seznam.cz  Fri Mar  3 14:56:00 2017
From: tomas.sieger at seznam.cz (Tomas Sieger)
Date: Fri, 3 Mar 2017 14:56:00 +0100
Subject: [R] [R-pkgs] new packages idendro and idendr0
Message-ID: <CA+HzfA5CYqGqqh+y6B14a7NviZq72Xbya1JzfBK2wkfLrEsLHw@mail.gmail.com>

Dear all,
 let me please announce two new R packages for interactive dendrogram
exploration: idendro and idendr0.

idendro [1] enables useRs to inspect hierarchical clustering dendrograms
interactively: to select and color clusters, to zoom and pan the
dendrogram, and to visualize the clustered data not only in a built-in heat
map, but also in any interactive plot implemented in the cranvas [2]
package.

A lightweight version idendr0 [3] with reduced dependencies is also
available. This version is suited for those who have no cranvas (and its
dependencies, namely the qtbase and qtpaint packages) installed. idendr0 is
implemented using base R graphics embedded in a Tcl/Tk GUI, and can be
integrated with GGobi dynamic interactive graphics made available to R
using the rggobi package [4].

A comprehensive description of the idendr0 package is available as a recent
JSS paper: https://www.jstatsoft.org/article/view/v076i10, and also as
vignettes to the packages.

[1] https://github.com/tsieger/idendro
[2] https://github.com/ggobi/cranvas
[3] https://cran.r-project.org/package=idendr0
[4] https://cran.r-project.org/package=rggobi

Best regards,
 Tomas Sieger

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From srutisudha80 at gmail.com  Mon Mar  6 15:34:03 2017
From: srutisudha80 at gmail.com (srutisudha mohanty)
Date: Mon, 6 Mar 2017 20:04:03 +0530
Subject: [R] regarding trouble in installation of gdalutils package in R
	3.3.2
Message-ID: <CAEzcM-Kr-9X1v+mzM0OA=T3a21CDsEfaL2wfjk-MRo-aNnu++w@mail.gmail.com>

Hello
I am trying to install gdalutils package in R 3.3.2 and Rstudio 1.0.136 ,
but some error is happening and it is unable to install. can you help me
out ?


Thanks !!

Regards
Sruti

	[[alternative HTML version deleted]]


From adamo.dahmani at gmail.com  Mon Mar  6 16:12:24 2017
From: adamo.dahmani at gmail.com (Adamo Dahmani)
Date: Mon, 6 Mar 2017 10:12:24 -0500
Subject: [R] Help installing R-3.3.2
Message-ID: <CAChzjKrrDOh5YRbEHLrmXQfYC03NNPRs5tANOjXBq-VDimFv9w@mail.gmail.com>

Hi,

I am trying to install R-3.3.2 in my user account. I have already installed
all needed libraries.

I run this command :

./configure 'LDFLAGS=-R$HOME/software/bzip2-1.0.6/
-R$HOME/software/zlib-1.2.11 -L$HOME/software/bzip2-1.0.6
-L$HOME/software/zlib-1.2.11 -L$HOME/software/xz-5.2.3/bin/lib/
-R$HOME/software/xz-5.2.3/bin/lib
-L$HOME/software/pcre-8.40/build/lib-R$HOME/software/pcre-8.40/build/lib'
CFLAGS='-I$HOME/software/bzip2-1.0.6/ -I$HOME/software/zlib-1.2.11/
-I/$HOME/software/xz-5.2.3/bin/include/
-I$HOME/software/pcre-8.40/build/include' --without-recommended-packages

I am getting this error:

checking for XDR support... yes
checking for inflateInit2_ in -lz... yes
checking zlib.h usability... yes
checking zlib.h presence... yes
checking for zlib.h... yes
checking if zlib version >= 1.2.5... no
checking whether zlib support suffices... configure: error: zlib library
and headers are required

Can you help?

Many Tanks,
Mohamed

	[[alternative HTML version deleted]]


From peter.thuresson at umea.se  Mon Mar  6 17:18:46 2017
From: peter.thuresson at umea.se (Peter Thuresson)
Date: Mon, 6 Mar 2017 16:18:46 +0000
Subject: [R] Matrix
Message-ID: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>

Hello,

Is there a function in R which can transform, let say a vector:

c(1:4)

to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
I want the output below from the vector above, like this:

p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)

matrix(p,7,4)

best regards / Peter

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Mar  6 18:37:05 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 6 Mar 2017 17:37:05 +0000
Subject: [R] regarding trouble in installation of gdalutils package in R
 3.3.2
In-Reply-To: <CAEzcM-Kr-9X1v+mzM0OA=T3a21CDsEfaL2wfjk-MRo-aNnu++w@mail.gmail.com>
References: <CAEzcM-Kr-9X1v+mzM0OA=T3a21CDsEfaL2wfjk-MRo-aNnu++w@mail.gmail.com>
Message-ID: <EDAF401C-7BF5-4ED2-947E-9CC27A9254CD@llnl.gov>

Probably should take this question to the R-sig-geo mailing list.

And you will need to tell people exactly what command(s) you used, and the exact resulting error message.

Possibly you will have to ask for help from Rstudio, if it turns out the cause somehow has to do with Rstudio; I have no idea how likely that is.

Also, please send plain text email to R mailing lists, not html.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 3/6/17, 6:34 AM, "R-help on behalf of srutisudha mohanty" <r-help-bounces at r-project.org on behalf of srutisudha80 at gmail.com> wrote:

    Hello
    I am trying to install gdalutils package in R 3.3.2 and Rstudio 1.0.136 ,
    but some error is happening and it is unable to install. can you help me
    out ?
    
    
    Thanks !!
    
    Regards
    Sruti
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From macqueen1 at llnl.gov  Mon Mar  6 18:46:28 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 6 Mar 2017 17:46:28 +0000
Subject: [R] Matrix
Message-ID: <D41FDC27-CF87-4393-830F-C58D45B272CF@llnl.gov>

How about this:

p0 <- 1:4

matrix( c( rep( c(p0, rep(0, 4)) , times=3) , p0) , 7, 4)

Of course, it would take some effort to generalize it to different lengths for p0.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 3/6/17, 8:18 AM, "R-help on behalf of Peter Thuresson" <r-help-bounces at r-project.org on behalf of peter.thuresson at umea.se> wrote:

    Hello,
    
    Is there a function in R which can transform, let say a vector:
    
    c(1:4)
    
    to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
    I want the output below from the vector above, like this:
    
    p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
    
    matrix(p,7,4)
    
    best regards / Peter
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From ruipbarradas at sapo.pt  Mon Mar  6 18:57:12 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 06 Mar 2017 17:57:12 +0000
Subject: [R] Matrix
In-Reply-To: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
References: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
Message-ID: <58BDA2F8.7000209@sapo.pt>

Hello,

Try the following.

proj <- function(x){
	n <- length(x)
	y <- numeric(n)
	z <- rep(c(x, y), times = n)
	z <- z[-((length(z) - n + 1):length(z))]
	matrix(z, ncol = n)
}

proj(1:4)
proj(1:5)

Hope this helps,

Rui Barradas

Em 06-03-2017 16:18, Peter Thuresson escreveu:
> Hello,
>
> Is there a function in R which can transform, let say a vector:
>
> c(1:4)
>
> to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
> I want the output below from the vector above, like this:
>
> p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>
> matrix(p,7,4)
>
> best regards / Peter
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gchappi at gmail.com  Mon Mar  6 19:04:35 2017
From: gchappi at gmail.com (Hans-Peter Suter)
Date: Mon, 6 Mar 2017 19:04:35 +0100
Subject: [R] Any reason not to use RUnit any longer?
Message-ID: <CANJoV3Pr5rLedgRghxnbgNSWdA8YvWguHRfVSNbL-3m_3HU3EA@mail.gmail.com>

Hello,

I see that quite some packages nowadays use testthat and that RUnit doesn't
have recent updates. On the other hand Rccp, fTrading and others (still)
test with RUnit.

My old code uses RUnit and I would prefer to keep it that way unless there
is an important reason to switch to testthat. If it makes a difference, I
do _not_ use roxygen and stay close to R-exts standards (ok, a testing
framework I'd like to have).

Thanks for any advise / opinions,

Hans-Peter

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar  6 20:00:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Mar 2017 11:00:20 -0800
Subject: [R] Matrix
In-Reply-To: <D41FDC27-CF87-4393-830F-C58D45B272CF@llnl.gov>
References: <D41FDC27-CF87-4393-830F-C58D45B272CF@llnl.gov>
Message-ID: <CAGxFJbS=uhAACuNjfLmg2rATOABkqUb+Xxq6xSQ8-31r6Fu1Jg@mail.gmail.com>

Clever, Don.

Here's a more explicit approach that generalizes (if I haven't made
any dumb errors):

x <- c(1:5,10:12)
## generate vector of indices by outer and %%
i <- seq_along(x)
nc <- 4 ## number of columns desired
## get subscripting indices via outer() and %%
indx <- outer(i,rev(i),"+") %% (length(x))[,seq_len(nc)]+1
matrix(x[indx],ncol = nc)

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 6, 2017 at 9:46 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> How about this:
>
> p0 <- 1:4
>
> matrix( c( rep( c(p0, rep(0, 4)) , times=3) , p0) , 7, 4)
>
> Of course, it would take some effort to generalize it to different lengths for p0.
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
> On 3/6/17, 8:18 AM, "R-help on behalf of Peter Thuresson" <r-help-bounces at r-project.org on behalf of peter.thuresson at umea.se> wrote:
>
>     Hello,
>
>     Is there a function in R which can transform, let say a vector:
>
>     c(1:4)
>
>     to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
>     I want the output below from the vector above, like this:
>
>     p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>
>     matrix(p,7,4)
>
>     best regards / Peter
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Mar  6 20:05:13 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Mar 2017 20:05:13 +0100
Subject: [R] Help installing R-3.3.2
In-Reply-To: <CAChzjKrrDOh5YRbEHLrmXQfYC03NNPRs5tANOjXBq-VDimFv9w@mail.gmail.com>
References: <CAChzjKrrDOh5YRbEHLrmXQfYC03NNPRs5tANOjXBq-VDimFv9w@mail.gmail.com>
Message-ID: <80FB7F18-9266-40AD-8790-CD0050CD2AA7@gmail.com>

Try 3.3.3, it has

 INSTALLATION on a UNIX-ALIKE:

   * The configure check for the zlib version is now robust to
     versions longer than 5 characters, including 1.2.11.

-pd

> On 06 Mar 2017, at 16:12 , Adamo Dahmani <adamo.dahmani at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to install R-3.3.2 in my user account. I have already installed
> all needed libraries.
> 
> I run this command :
> 
> ./configure 'LDFLAGS=-R$HOME/software/bzip2-1.0.6/
> -R$HOME/software/zlib-1.2.11 -L$HOME/software/bzip2-1.0.6
> -L$HOME/software/zlib-1.2.11 -L$HOME/software/xz-5.2.3/bin/lib/
> -R$HOME/software/xz-5.2.3/bin/lib
> -L$HOME/software/pcre-8.40/build/lib-R$HOME/software/pcre-8.40/build/lib'
> CFLAGS='-I$HOME/software/bzip2-1.0.6/ -I$HOME/software/zlib-1.2.11/
> -I/$HOME/software/xz-5.2.3/bin/include/
> -I$HOME/software/pcre-8.40/build/include' --without-recommended-packages
> 
> I am getting this error:
> 
> checking for XDR support... yes
> checking for inflateInit2_ in -lz... yes
> checking zlib.h usability... yes
> checking zlib.h presence... yes
> checking for zlib.h... yes
> checking if zlib version >= 1.2.5... no
> checking whether zlib support suffices... configure: error: zlib library
> and headers are required
> 
> Can you help?
> 
> Many Tanks,
> Mohamed
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter.4567 at gmail.com  Mon Mar  6 20:30:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Mar 2017 11:30:36 -0800
Subject: [R] Matrix
In-Reply-To: <CAGxFJbS=uhAACuNjfLmg2rATOABkqUb+Xxq6xSQ8-31r6Fu1Jg@mail.gmail.com>
References: <D41FDC27-CF87-4393-830F-C58D45B272CF@llnl.gov>
	<CAGxFJbS=uhAACuNjfLmg2rATOABkqUb+Xxq6xSQ8-31r6Fu1Jg@mail.gmail.com>
Message-ID: <CAGxFJbR0CaZV0bkOCLa259MEDPgyzssCmWAQwrAznSvzdGzoXw@mail.gmail.com>

Well, of course,  I *did* make a dumb error (again!!). Here's the
corrected version:

x <- c(1:5,10:12)
## generate vector of indices by outer and %%
i <- seq_along(x)
nc <- 4 ## number of columns desired
#### Corrected statement ####
indx <- (outer(i, rev(i-1),"+") %% length(x)) [,seq_len(nc)] +1
#####  Corrected statement

matrix(x[indx],ncol = nc)


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 6, 2017 at 11:00 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Clever, Don.
>
> Here's a more explicit approach that generalizes (if I haven't made
> any dumb errors):
>
> x <- c(1:5,10:12)
> ## generate vector of indices by outer and %%
> i <- seq_along(x)
> nc <- 4 ## number of columns desired
> ## get subscripting indices via outer() and %%
> indx <- outer(i,rev(i),"+") %% (length(x))[,seq_len(nc)]+1
> matrix(x[indx],ncol = nc)
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Mar 6, 2017 at 9:46 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> How about this:
>>
>> p0 <- 1:4
>>
>> matrix( c( rep( c(p0, rep(0, 4)) , times=3) , p0) , 7, 4)
>>
>> Of course, it would take some effort to generalize it to different lengths for p0.
>>
>> -Don
>>
>> --
>> Don MacQueen
>>
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>>
>>
>> On 3/6/17, 8:18 AM, "R-help on behalf of Peter Thuresson" <r-help-bounces at r-project.org on behalf of peter.thuresson at umea.se> wrote:
>>
>>     Hello,
>>
>>     Is there a function in R which can transform, let say a vector:
>>
>>     c(1:4)
>>
>>     to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
>>     I want the output below from the vector above, like this:
>>
>>     p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>>
>>     matrix(p,7,4)
>>
>>     best regards / Peter
>>
>>         [[alternative HTML version deleted]]
>>
>>     ______________________________________________
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From mrguilfoyle at gmail.com  Mon Mar  6 22:10:33 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Mon, 6 Mar 2017 21:10:33 +0000
Subject: [R] Matrix
In-Reply-To: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
References: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
Message-ID: <FE4179D9-C7C5-4293-AE29-DB59AD500551@gmail.com>

Effectively you want a circulant matrix but filled by column.

Example input vector and number of columns

x = c(1:8,19:20)
nc = 5

For the result you specifically describe, the following generalises for any vector and any arbitrary number of columns 'nc', padding with zeros as necessary.

matrix(c(rep(c(x,rep(0,nc)),nc-1),x), ncol=nc)


For the unpadded column circulant on the same inputs

nx = length(x)
ind = 1+ outer(0:(nx-1),0:(1-nc),'+') %% nx
matrix(x[ind], ncol=nc)


Cheers

> On 6 Mar 2017, at 16:18, Peter Thuresson <peter.thuresson at umea.se> wrote:
> 
> Hello,
> 
> Is there a function in R which can transform, let say a vector:
> 
> c(1:4)
> 
> to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
> I want the output below from the vector above, like this:
> 
> p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
> 
> matrix(p,7,4)
> 
> best regards / Peter
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henri.cann at gmail.com  Mon Mar  6 20:54:36 2017
From: henri.cann at gmail.com (Henry Cann)
Date: Mon, 6 Mar 2017 20:54:36 +0100
Subject: [R] Cannot create a visible Choropleth Legend - GISTools
Message-ID: <CACZ3g7JqCC9czP_cTXMnKAQ1EJCQRyuvsLGrsQ7GgrGgOwJpyA@mail.gmail.com>

I have combined two layers to create a shapefile which I am colouring using
the Choropleth function in GISTools. The problem I am having is that
despite having no other problems with my code including with the actual
mapping of the choropleth itself, nothing I can do, using choro.legend,
actually appears. I have checked I am plotting in the right pace using
locator().

My code is below. I have also attached my data and link to shapefile and
attached my data.
Many thanks in advance.
Henry
https://borders.ukdataservice.ac.uk/ukborders/easy_download/prebuilt/shape/infuse_dist_lyr_2011.zip

require(rgdal)
require(sp)
library(plyr)
library(dplyr)
library(RColorBrewer)
MyDataFile2 <- read.csv("reduced1.csv")
class(MyDataFile2)
coordinates(MyDataFile2)<-~X+Y
class(MyDataFile2)
writeOGR(MyDataFile2, "Folder", "File9", driver = "ESRI Shapefile")
Redefined2 <- readOGR(dsn="Folder", layer = "File9")
proj4string(Redefined2) <- CRS("+init=epsg:4326") # WGS 84
MyMap <-readOGR(".","infuse_dist_lyr_2011")
proj4string(MyMap)
MyMapb <- spTransform(MyMap, proj4string(Redefined2))
MyMapb at data <- mutate(MyMapb at data, id_poly =
as.numeric(rownames(MyMapb at data)))
Redefined2 at data <- mutate(Redefined2 at data, id_la =
as.numeric(rownames(Redefined2 at data)))
New <- over(Redefined2, MyMapb)
New <- mutate(New, id_la = as.numeric(rownames(New)))
New <- left_join(Redefined2 at data, New, by = c("id_la" = "id_la"))
New2 <- New %>% group_by(id_poly) %>%
dplyr::summarise(avgBrit = mean(Brtshns), SumBrit = sum(Brtshns),
nBrit = n()) %>%
arrange(id_poly)
MyMapb at data <- left_join(MyMapb at data, New2, by = c("id_poly" = "id_poly"))
View(MyMapb)
shape2 <- MyMapb[!is.na(MyMapb at data$avgBrit),]

myshading = auto.shading(shape2$avgBrit, n=7,
                     cols=brewer.pal(7, "Spectral"))
choropleth(shape2, shape2$avgBrit,shading=myshading)
choro.legend(48.4,-5.79, myshading,fmt="%4.1f",cex=0.8)

From bgunter.4567 at gmail.com  Mon Mar  6 23:14:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Mar 2017 14:14:19 -0800
Subject: [R] Cannot create a visible Choropleth Legend - GISTools
In-Reply-To: <CACZ3g7JqCC9czP_cTXMnKAQ1EJCQRyuvsLGrsQ7GgrGgOwJpyA@mail.gmail.com>
References: <CACZ3g7JqCC9czP_cTXMnKAQ1EJCQRyuvsLGrsQ7GgrGgOwJpyA@mail.gmail.com>
Message-ID: <CAGxFJbSvjNct60oHK8VB5Mm89x5wsZ32uwZtQcH62P2z4DFACw@mail.gmail.com>

Perhaps FAQ 7.16 ? (Are you sourcing the code?)

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 6, 2017 at 11:54 AM, Henry Cann <henri.cann at gmail.com> wrote:
> I have combined two layers to create a shapefile which I am colouring using
> the Choropleth function in GISTools. The problem I am having is that
> despite having no other problems with my code including with the actual
> mapping of the choropleth itself, nothing I can do, using choro.legend,
> actually appears. I have checked I am plotting in the right pace using
> locator().
>
> My code is below. I have also attached my data and link to shapefile and
> attached my data.
> Many thanks in advance.
> Henry
> https://borders.ukdataservice.ac.uk/ukborders/easy_download/prebuilt/shape/infuse_dist_lyr_2011.zip
>
> require(rgdal)
> require(sp)
> library(plyr)
> library(dplyr)
> library(RColorBrewer)
> MyDataFile2 <- read.csv("reduced1.csv")
> class(MyDataFile2)
> coordinates(MyDataFile2)<-~X+Y
> class(MyDataFile2)
> writeOGR(MyDataFile2, "Folder", "File9", driver = "ESRI Shapefile")
> Redefined2 <- readOGR(dsn="Folder", layer = "File9")
> proj4string(Redefined2) <- CRS("+init=epsg:4326") # WGS 84
> MyMap <-readOGR(".","infuse_dist_lyr_2011")
> proj4string(MyMap)
> MyMapb <- spTransform(MyMap, proj4string(Redefined2))
> MyMapb at data <- mutate(MyMapb at data, id_poly =
> as.numeric(rownames(MyMapb at data)))
> Redefined2 at data <- mutate(Redefined2 at data, id_la =
> as.numeric(rownames(Redefined2 at data)))
> New <- over(Redefined2, MyMapb)
> New <- mutate(New, id_la = as.numeric(rownames(New)))
> New <- left_join(Redefined2 at data, New, by = c("id_la" = "id_la"))
> New2 <- New %>% group_by(id_poly) %>%
> dplyr::summarise(avgBrit = mean(Brtshns), SumBrit = sum(Brtshns),
> nBrit = n()) %>%
> arrange(id_poly)
> MyMapb at data <- left_join(MyMapb at data, New2, by = c("id_poly" = "id_poly"))
> View(MyMapb)
> shape2 <- MyMapb[!is.na(MyMapb at data$avgBrit),]
>
> myshading = auto.shading(shape2$avgBrit, n=7,
>                      cols=brewer.pal(7, "Spectral"))
> choropleth(shape2, shape2$avgBrit,shading=myshading)
> choro.legend(48.4,-5.79, myshading,fmt="%4.1f",cex=0.8)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Tue Mar  7 00:25:48 2017
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 6 Mar 2017 23:25:48 +0000
Subject: [R] Revolutions blog: February 2017 Roundup
Message-ID: <CY1PR0301MB21052583557C61B86B03E71AC82C0@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of February:

Public policy researchers use R to predict neighbourhoods in US cities
subject to gentrification:
http://blog.revolutionanalytics.com/2017/02/forecasting-gentrification.html

The ggraph package provides a grammar-of-graphics framework for
visualizing directed and undirected graphs:
http://blog.revolutionanalytics.com/2017/02/ggraph-ggplot-for-graphs.html

Facebook has open-sourced the "prophet" package they use for
forecasting time series at scale:
http://blog.revolutionanalytics.com/2017/02/facebook-prophet.html

A preview of features coming soon to R Tools for Visual Studio 1.0:
http://blog.revolutionanalytics.com/2017/02/preview-r-tools-for-visual-studio-10.html

On the differences between using Excel and R for data analysis:
http://blog.revolutionanalytics.com/2017/02/the-difference-between-r-and-excel.html

A data scientist suggests a "Gloom Index" for identifying the most
depressing songs by the band Radiohead:
http://blog.revolutionanalytics.com/2017/02/finding-radioheads-most-depressing-song-with-r.html

Catterplots is a package that replaces scatterplot points with
cats. Tufte would not approve:
http://blog.revolutionanalytics.com/2017/02/catterplots-plots-with-cats.html

A collection of tips on using Microsoft R Server from the support
team:
http://blog.revolutionanalytics.com/2017/02/six-articles-on-using-r-with-sql-server.html

A summary of the many improvements slated for R 3.4.0:
http://blog.revolutionanalytics.com/2017/02/preview-r-340.html

R code using the RevoScaleR package to classify a large database of
galaxy images in SQL Server:
http://blog.revolutionanalytics.com/2017/02/sql-server-galaxy.html

A review of four deep learning packages for R: MXNet, darch, deepnet
and h2o:
http://blog.revolutionanalytics.com/2017/02/deep-learning-in-r.html

An update on more than a dozen projects and community initiatives
funded by R Consortium grants:
http://blog.revolutionanalytics.com/2017/02/update-on-r-consortium-projects.html

R has overtaken SAS for Statistics job listings on indeed.com:
http://blog.revolutionanalytics.com/2017/02/job-trends-for-r-and-python.html

ModernDive is a free online textbook on Statistics and data science:
using R: http://blog.revolutionanalytics.com/2017/02/moderndive.html

A solution (with R code) for modeling customer churn in the retail
industry using SQL Server R Services:
http://blog.revolutionanalytics.com/2017/02/retail-applications-with-microsoft-r.html

The superheat package provides enhanced heatmap graphics for R:
http://blog.revolutionanalytics.com/2017/02/superheat-supercharged-heatmaps-for-r.html

The fst package provides a new serialization format for R data focused
on performance:
http://blog.revolutionanalytics.com/2017/02/fst-fast-serialization-of-r-data-frames.html

Thomas Dinsmore reflects on major events in the R Project and for
Microsoft in 2016:
http://blog.revolutionanalytics.com/2017/02/the-year-in-r.html

And some general interest stories (not necassarily related to R):
* A big drain
  http://blog.revolutionanalytics.com/2017/02/because-its-friday-looking-down-the-glory-hole.html
* 'Vous' vs 'tu'
  http://blog.revolutionanalytics.com/2017/02/because-its-friday-et-tu.html
* A remembrance of the late Hans Rosling
  http://blog.revolutionanalytics.com/2017/02/because-its-friday-remembering-hans-rosling.html
* Ten Meter Tower, a short film
  http://blog.revolutionanalytics.com/2017/02/because-its-friday-jump.html

As always, thanks for the comments and please keep sending suggestions
to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From tmad109 at aucklanduni.ac.nz  Tue Mar  7 02:16:16 2017
From: tmad109 at aucklanduni.ac.nz (Thilini Maddegoda Vidanelage)
Date: Tue, 7 Mar 2017 14:16:16 +1300
Subject: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910 COLUMNs)
Message-ID: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>

Hi,
I am analyzing a huge excel table with OTUs. In the table, I have 2910
columns and 365 rows.Each column represents one individual (n=2910). Rows
represent microbial species (n=365).
I have the total of all OTUs of microbial species under each column. Then I
need to get the percentages of each species in each individual.I started to
do this in excel but I have to repeat this for 2910 times which is going to
be very time-consuming.  I am sure there should be a smart way to do this
and just wondering whether there is any R script to do this.Any help is
much appreciated.
Many thanks, Thilini

*Thilini Jayasinghe*
PhD Candidate
Liggins Institute
The University of Auckland
Building 503/201, 85 Park Road, Grafton, Auckland 2023
Mobile: +64 220211604
Email: tmad109 at aucklanduni.ac.nz

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Mar  7 07:46:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Mar 2017 22:46:30 -0800
Subject: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910
	COLUMNs)
In-Reply-To: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
References: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
Message-ID: <75375E85-E9C9-417E-80F3-74252FA499DB@dcn.davis.ca.us>

If your problem really requires genetics jargon to be expressed, then perhaps you should be asking it in a forum where more of the participants are likely to understand it... like the Bioconductor help forum?

https://www.bioconductor.org/help/support/

The Posting Guide mentioned in the footer has quite a lot of helpful context for the kinds of questions that are appropriate here... I recommend reading it.
-- 
Sent from my phone. Please excuse my brevity.

On March 6, 2017 5:16:16 PM PST, Thilini Maddegoda Vidanelage <tmad109 at aucklanduni.ac.nz> wrote:
>Hi,
>I am analyzing a huge excel table with OTUs. In the table, I have 2910
>columns and 365 rows.Each column represents one individual (n=2910).
>Rows
>represent microbial species (n=365).
>I have the total of all OTUs of microbial species under each column.
>Then I
>need to get the percentages of each species in each individual.I
>started to
>do this in excel but I have to repeat this for 2910 times which is
>going to
>be very time-consuming.  I am sure there should be a smart way to do
>this
>and just wondering whether there is any R script to do this.Any help is
>much appreciated.
>Many thanks, Thilini
>
>*Thilini Jayasinghe*
>PhD Candidate
>Liggins Institute
>The University of Auckland
>Building 503/201, 85 Park Road, Grafton, Auckland 2023
>Mobile: +64 220211604
>Email: tmad109 at aucklanduni.ac.nz
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Mon Mar  6 18:24:50 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 6 Mar 2017 12:24:50 -0500
Subject: [R] Matrix
In-Reply-To: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
References: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
Message-ID: <CAGx1TMDsQRZbZfJek_CsUXdy-7vA-CGVxT49z7z_U3nezYYXNA@mail.gmail.com>

## 1.
## This could be captured into a function

tmp <- matrix(0, 7, 4)
tmp
diag(tmp) <- 1
diag(tmp[-1,]) <- 2
diag(tmp[-(1:2),]) <- 3
diag(tmp[-(1:3),]) <- 4
tmp


## 2.
v <- 1:4
v2 <- c(v, rep(0, length(v)))
## this generates a warning that can safely be ignored (or turned off)
matrix(v2, length(v2)-1, length(v))

On Mon, Mar 6, 2017 at 11:18 AM, Peter Thuresson
<peter.thuresson at umea.se> wrote:
> Hello,
>
> Is there a function in R which can transform, let say a vector:
>
> c(1:4)
>
> to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
> I want the output below from the vector above, like this:
>
> p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>
> matrix(p,7,4)
>
> best regards / Peter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar  7 09:24:09 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Mar 2017 19:24:09 +1100
Subject: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910
	COLUMNs)
In-Reply-To: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
References: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
Message-ID: <CA+8X3fW9XWcnTLcUPK8a6GOygsDoETML=nnY+xCxOC+c3YRJzg@mail.gmail.com>

Hi Thilini,
It is fairly simple in R once you have imported the data. Say you have
a data frame obtained by exporting the Excel table to CSV and then
importing it with "read.csv". I'm not sure whether you have a number
in each cell or just a 0/1 absent/present value, but it may not
matter. Assume the data frame is named "tjdf"

for(column in 1:dim(tjdf)[2])
 tjdf[,paste("pct",column,sep="")]<-100*tjdf[,column]/sum(tjdf[,column])

Alternatively, you could create a new data frame with just the percentages.

Jim


On Tue, Mar 7, 2017 at 12:16 PM, Thilini Maddegoda Vidanelage
<tmad109 at aucklanduni.ac.nz> wrote:
> Hi,
> I am analyzing a huge excel table with OTUs. In the table, I have 2910
> columns and 365 rows.Each column represents one individual (n=2910). Rows
> represent microbial species (n=365).
> I have the total of all OTUs of microbial species under each column. Then I
> need to get the percentages of each species in each individual.I started to
> do this in excel but I have to repeat this for 2910 times which is going to
> be very time-consuming.  I am sure there should be a smart way to do this
> and just wondering whether there is any R script to do this.Any help is
> much appreciated.
> Many thanks, Thilini
>
> *Thilini Jayasinghe*
> PhD Candidate
> Liggins Institute
> The University of Auckland
> Building 503/201, 85 Park Road, Grafton, Auckland 2023
> Mobile: +64 220211604
> Email: tmad109 at aucklanduni.ac.nz
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Tue Mar  7 14:20:55 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 7 Mar 2017 08:20:55 -0500
Subject: [R] Matrix
In-Reply-To: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
References: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
Message-ID: <CAP01uR=4TUmZN8KM2YH5PtKWwZWDNZX5gm5qtHe=3GsXU1O-tw@mail.gmail.com>

Assuming that the input is x <- 1:4, try this one-liner:

> embed(c(0*x[-1], x, 0*x[-1]), 4)
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    1    0    0
[3,]    3    2    1    0
[4,]    4    3    2    1
[5,]    0    4    3    2
[6,]    0    0    4    3
[7,]    0    0    0    4

On Mon, Mar 6, 2017 at 11:18 AM, Peter Thuresson
<peter.thuresson at umea.se> wrote:
> Hello,
>
> Is there a function in R which can transform, let say a vector:
>
> c(1:4)
>
> to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
> I want the output below from the vector above, like this:
>
> p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>
> matrix(p,7,4)
>

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dcarlson at tamu.edu  Tue Mar  7 14:41:31 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 7 Mar 2017 13:41:31 +0000
Subject: [R] FOR TAKING PERCENTAGES of OTUS in each column
	(n=2910	COLUMNs)
In-Reply-To: <CA+8X3fW9XWcnTLcUPK8a6GOygsDoETML=nnY+xCxOC+c3YRJzg@mail.gmail.com>
References: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
	<CA+8X3fW9XWcnTLcUPK8a6GOygsDoETML=nnY+xCxOC+c3YRJzg@mail.gmail.com>
Message-ID: <ac42fa400fd14ee1bed5b835b764f85d@exch-2p-mbx-w2.ads.tamu.edu>

If you read your data into R, it is simple to compute the percentages. Use Save As in Excel to save your data as a .csv (comma separated variables) file. Then use read.csv() to create a data frame in R as Jim indicated. Put it in the default directory that R is using (this depends on what operating system you are using). Then import the file with

raw_data <- read.csv("YourData.csv")

You may need to add some arguments in read.csv() depending on if you have column headings or not. Blank fields in Excel will be interpreted as missing values, not zeros, but you did not give us any of your data (even just the first 10, rows and columns) so it is impossible to be more specific. Once you have the data frame (and have replaced the missing values with zeros if necessary), the process is simple:

pct_data <- prop.table(as.matrix(raw_data), 2) * 100

will produce a matrix with percentages down each column and store it as a matrix object (variable) called pct_data. R uses different methods to store different kinds of data. The read.csv() function creates a data frame which can handle a mixture of character and numeric data, but the prop.table() function only accepts a matrix of numeric data and returns a matrix of numeric data. The data you described is all numeric so it is easy to switch the data frame to a matrix (and then back again if you want). If you are going to use R, you will need to spend some time reading about how it works, but as you can see, that time invested will make some operations much simpler than Excel and will allow you to conduct analyses that Excel does not even attempt. 

You can get details on these three functions by running the following commands in R:

?read.csv
?prop.table
?as.matrix

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Tuesday, March 7, 2017 2:24 AM
To: Thilini Maddegoda Vidanelage <tmad109 at aucklanduni.ac.nz>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910 COLUMNs)

Hi Thilini,
It is fairly simple in R once you have imported the data. Say you have
a data frame obtained by exporting the Excel table to CSV and then
importing it with "read.csv". I'm not sure whether you have a number
in each cell or just a 0/1 absent/present value, but it may not
matter. Assume the data frame is named "tjdf"

for(column in 1:dim(tjdf)[2])
 tjdf[,paste("pct",column,sep="")]<-100*tjdf[,column]/sum(tjdf[,column])

Alternatively, you could create a new data frame with just the percentages.

Jim


On Tue, Mar 7, 2017 at 12:16 PM, Thilini Maddegoda Vidanelage
<tmad109 at aucklanduni.ac.nz> wrote:
> Hi,
> I am analyzing a huge excel table with OTUs. In the table, I have 2910
> columns and 365 rows.Each column represents one individual (n=2910). Rows
> represent microbial species (n=365).
> I have the total of all OTUs of microbial species under each column. Then I
> need to get the percentages of each species in each individual.I started to
> do this in excel but I have to repeat this for 2910 times which is going to
> be very time-consuming.  I am sure there should be a smart way to do this
> and just wondering whether there is any R script to do this.Any help is
> much appreciated.
> Many thanks, Thilini
>
> *Thilini Jayasinghe*
> PhD Candidate
> Liggins Institute
> The University of Auckland
> Building 503/201, 85 Park Road, Grafton, Auckland 2023
> Mobile: +64 220211604
> Email: tmad109 at aucklanduni.ac.nz
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Tue Mar  7 15:00:40 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 7 Mar 2017 09:00:40 -0500
Subject: [R] Problems installing devtools from github
Message-ID: <CAMOcQfPmvhhLuLFQoDkLb1VyBjGiGqEEus0=-m0oQ6gTC28HaA@mail.gmail.com>

Dear all,

I was using R version 3.3.2 to install devtools and some other packages in
order to create models and generate a web service that can be seen in the
Microsoft Azure Machine Learning Studio environment.

Now, since Azure works with CRAN R version 3.1.0, I decided to download
this R version and retry the following command:

# Install devtools
if(!require("devtools")) install.packages("devtools")
devtools::install_github("RevolutionAnalytics/azureml")

however, I got the following error:

> devtools::install_github("RevolutionAnalytics/azureml")
Downloading GitHub repo RevolutionAnalytics/azureml at master
from URL
https://api.github.com/repos/RevolutionAnalytics/azureml/zipball/master
Installing AzureML
Error in `_digest`(c(list(repos, type), lapply(`_additional`, function(x)
eval(x[[2L]],  :
  object 'digest_impl' not found
>
> devtools::install_github("RevolutionAnalytics/azureml")
Downloading GitHub repo RevolutionAnalytics/azureml at master
from URL
https://api.github.com/repos/RevolutionAnalytics/azureml/zipball/master
Installing AzureML
Error in `_digest`(c(list(repos, type), lapply(`_additional`, function(x)
eval(x[[2L]],  :
  object 'digest_impl' not found

Does anybody know what does this error mean and how to handle it?

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From edd at debian.org  Tue Mar  7 16:06:04 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Mar 2017 09:06:04 -0600
Subject: [R] Any reason not to use RUnit any longer?
In-Reply-To: <CANJoV3Pr5rLedgRghxnbgNSWdA8YvWguHRfVSNbL-3m_3HU3EA@mail.gmail.com>
References: <CANJoV3Pr5rLedgRghxnbgNSWdA8YvWguHRfVSNbL-3m_3HU3EA@mail.gmail.com>
Message-ID: <22718.52316.842737.233815@max.eddelbuettel.com>


On 6 March 2017 at 19:04, Hans-Peter Suter wrote:
| I see that quite some packages nowadays use testthat and that RUnit doesn't
| have recent updates. On the other hand Rccp, fTrading and others (still)
| test with RUnit.

RUnit is alive and well, look at

      https://cran.r-project.org/package=RUnit
      https://cran.r-project.org/web/checks/check_results_RUnit.html

which shows all its checks are clean.  It also has a new maintainer in Roman
Zenka (who too has code that uses it) so I would not be worried.
 
| My old code uses RUnit and I would prefer to keep it that way unless there
| is an important reason to switch to testthat. If it makes a difference, I
| do _not_ use roxygen and stay close to R-exts standards (ok, a testing
| framework I'd like to have).

There is no offically sanctioned package in WRE for this as far as I know.

If you run 'make check' on R itself, all the package in base R check via
.Rout.save files -- which makes sense as we want no / few external
dependencies at this level.

In short, you are free to use what you prefer.  I still use RUnit too.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dcarlson at tamu.edu  Tue Mar  7 16:46:45 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 7 Mar 2017 15:46:45 +0000
Subject: [R] Matrix
In-Reply-To: <CAP01uR=4TUmZN8KM2YH5PtKWwZWDNZX5gm5qtHe=3GsXU1O-tw@mail.gmail.com>
References: <C9E6D9118357E9478E14591F14BFDCD002487FD80E@ECHTELION.ad.umea.se>
	<CAP01uR=4TUmZN8KM2YH5PtKWwZWDNZX5gm5qtHe=3GsXU1O-tw@mail.gmail.com>
Message-ID: <3a4396222bb249bdab8ce7d18a3d9cc2@exch-2p-mbx-w2.ads.tamu.edu>

Change the "4" in embed(c(0*x[-1], x, 0*x[-1]), 4) to length(x) and it will generalize to other length vectors. This solution is not as compact, but it illustrates a relatively obscure R function:

> x <- 1:4
> ncol <- length(x)
> zeros <- rep(0, ncol - 1)
> toeplitz(c(zeros, x, zeros))[-(1:(ncol-1)), 1:ncol]
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    1    0    0
[3,]    3    2    1    0
[4,]    4    3    2    1
[5,]    0    4    3    2
[6,]    0    0    4    3
[7,]    0    0    0    4

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gabor Grothendieck
Sent: Tuesday, March 7, 2017 7:21 AM
To: Peter Thuresson <peter.thuresson at umea.se>
Cc: R-help at r-project.org
Subject: Re: [R] Matrix

Assuming that the input is x <- 1:4, try this one-liner:

> embed(c(0*x[-1], x, 0*x[-1]), 4)
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    1    0    0
[3,]    3    2    1    0
[4,]    4    3    2    1
[5,]    0    4    3    2
[6,]    0    0    4    3
[7,]    0    0    0    4

On Mon, Mar 6, 2017 at 11:18 AM, Peter Thuresson
<peter.thuresson at umea.se> wrote:
> Hello,
>
> Is there a function in R which can transform, let say a vector:
>
> c(1:4)
>
> to a matrix where the vector is repeated but "projected" +1 one step down for every (new) column.
> I want the output below from the vector above, like this:
>
> p<-c(1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4,0,0,0,0,1,2,3,4)
>
> matrix(p,7,4)
>

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Mar  7 16:46:51 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Mar 2017 07:46:51 -0800
Subject: [R] Cannot create a visible Choropleth Legend - GISTools
In-Reply-To: <CACZ3g7Kj_HG79LLwjEd43FpFEsssUMBqdrLKy=ecUj99C2j2kA@mail.gmail.com>
References: <CACZ3g7JqCC9czP_cTXMnKAQ1EJCQRyuvsLGrsQ7GgrGgOwJpyA@mail.gmail.com>
	<CAGxFJbSvjNct60oHK8VB5Mm89x5wsZ32uwZtQcH62P2z4DFACw@mail.gmail.com>
	<CACZ3g7Kj_HG79LLwjEd43FpFEsssUMBqdrLKy=ecUj99C2j2kA@mail.gmail.com>
Message-ID: <CAGxFJbTG58mGiBZ6eF=cq0fT8FDc6e9XQFMCNGPaLBae0xyscg@mail.gmail.com>

Did you look at the FAQ?

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 7, 2017 at 1:35 AM, Henry Cann <henri.cann at gmail.com> wrote:
> Apologies Bert, not sure I follow the question?
> The code is sort of pieced together from different thinks I've tried. Due to
> projection issues I've tried various different ways of carrying out a
> spatial join. Most of the code is based around making the join easier e.g by
> recreating unique identifiers in both shape files.
>
> Have had a look at 7.16 (thanks for suggestion) DOn't believe it applies
> because choro.legend usually outputs straight onto the plot area (I have
> tried this with other code.)
>
> I tested my same code with a different shapefile and had the same issue so I
> conclude it's probably a by-product of something in my code?
>
> On 6 March 2017 at 23:14, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Perhaps FAQ 7.16 ? (Are you sourcing the code?)
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Mar 6, 2017 at 11:54 AM, Henry Cann <henri.cann at gmail.com> wrote:
>> > I have combined two layers to create a shapefile which I am colouring
>> > using
>> > the Choropleth function in GISTools. The problem I am having is that
>> > despite having no other problems with my code including with the actual
>> > mapping of the choropleth itself, nothing I can do, using choro.legend,
>> > actually appears. I have checked I am plotting in the right pace using
>> > locator().
>> >
>> > My code is below. I have also attached my data and link to shapefile and
>> > attached my data.
>> > Many thanks in advance.
>> > Henry
>> >
>> > https://borders.ukdataservice.ac.uk/ukborders/easy_download/prebuilt/shape/infuse_dist_lyr_2011.zip
>> >
>> > require(rgdal)
>> > require(sp)
>> > library(plyr)
>> > library(dplyr)
>> > library(RColorBrewer)
>> > MyDataFile2 <- read.csv("reduced1.csv")
>> > class(MyDataFile2)
>> > coordinates(MyDataFile2)<-~X+Y
>> > class(MyDataFile2)
>> > writeOGR(MyDataFile2, "Folder", "File9", driver = "ESRI Shapefile")
>> > Redefined2 <- readOGR(dsn="Folder", layer = "File9")
>> > proj4string(Redefined2) <- CRS("+init=epsg:4326") # WGS 84
>> > MyMap <-readOGR(".","infuse_dist_lyr_2011")
>> > proj4string(MyMap)
>> > MyMapb <- spTransform(MyMap, proj4string(Redefined2))
>> > MyMapb at data <- mutate(MyMapb at data, id_poly =
>> > as.numeric(rownames(MyMapb at data)))
>> > Redefined2 at data <- mutate(Redefined2 at data, id_la =
>> > as.numeric(rownames(Redefined2 at data)))
>> > New <- over(Redefined2, MyMapb)
>> > New <- mutate(New, id_la = as.numeric(rownames(New)))
>> > New <- left_join(Redefined2 at data, New, by = c("id_la" = "id_la"))
>> > New2 <- New %>% group_by(id_poly) %>%
>> > dplyr::summarise(avgBrit = mean(Brtshns), SumBrit = sum(Brtshns),
>> > nBrit = n()) %>%
>> > arrange(id_poly)
>> > MyMapb at data <- left_join(MyMapb at data, New2, by = c("id_poly" =
>> > "id_poly"))
>> > View(MyMapb)
>> > shape2 <- MyMapb[!is.na(MyMapb at data$avgBrit),]
>> >
>> > myshading = auto.shading(shape2$avgBrit, n=7,
>> >                      cols=brewer.pal(7, "Spectral"))
>> > choropleth(shape2, shape2$avgBrit,shading=myshading)
>> > choro.legend(48.4,-5.79, myshading,fmt="%4.1f",cex=0.8)
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From allantanaka11 at yahoo.com  Tue Mar  7 09:52:18 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Tue, 7 Mar 2017 08:52:18 +0000 (UTC)
Subject: [R]  HTTP status was '404 Not Found'
References: <747823713.209992.1488876738137.ref@mail.yahoo.com>
Message-ID: <747823713.209992.1488876738137@mail.yahoo.com>

HiSo I tried running the p but i'm stuck as i get the following error:?
In download.file(url, destfile, method = method, quiet = quiet) :? cannot open URL 'http://chart.yahoo.com/table.csv?s=DJI&a=2&b=13&c=2012&d=2&e=07&f=2017&g=d&q=q&y=0&z=DJI&x=.csv': HTTP status was '404 Not Found'

Here is the R code:
library(vars)library(tawny)library(quantmod)library(MASS)library(stats)library(DEoptim)library(sn)library(SkewHyperbolic)library(tseries)symbols<-getSymbols(c("^GSPC", "^DJI"))endDate <- Sys.Date()startDate <- endDate - as.difftime(52*5, unit="weeks")quoteType <- "Close"p <- do.call(cbind, lapply(symbols, get.hist.quote, start=startDate, end=endDate, ?quote=quoteType))

	[[alternative HTML version deleted]]


From dominic.schuhmacher at mathematik.uni-goettingen.de  Tue Mar  7 14:31:57 2017
From: dominic.schuhmacher at mathematik.uni-goettingen.de (Schuhmacher, Dominic)
Date: Tue, 7 Mar 2017 13:31:57 +0000
Subject: [R] Transport and Earth Mover's Distance
In-Reply-To: <20170307122932.GA2604@chicca2>
References: <20170307122932.GA2604@chicca2>
Message-ID: <74667735-11AE-405E-9F88-071AEF7E7F98@mathematik.uni-goettingen.de>

Dear Lorenzo,

The code you have attached (if you replace 00 by 50) generates two sets of 50 points each that are uniformly distributed on the unit square [0,1]^2 and then computes the Wasserstein-1 distance between them assuming that each point has mass 1/50. Do the following to get a plot of the optimal point assignment (the average of the line lengths is the Wasserstein-1 distance).

x <- pp(matrix(runif(100),50,2))
y <- pp(matrix(runif(100),50,2))
match <- transport(x,y,p=1)
plot(x,y,match)
wasserstein(x,y,p=1,match)

Currently the transport package only matches "objects" with the same total mass, i.e. point patterns (class pp) with equal numbers of points, weighted point patterns (class wpp) where e.g. the mass at each point is given by 1/(no. of points), and pixel grids (class pgrid) which are supposed to have the same total mass summed over all pixel values.

If you have no particular need for binning, check out the function pppdist in the R-package spatstat, which offers a more flexible way to deal with point patterns of different size. If you need to bin, check out transport.pgrid, but be aware that it does not do "incomplete transport", but will normalize both pixel grids to unit total mass if these masses are different.

Best regards,
Dominic



> Am 07.03.2017 um 13:29 schrieb Lorenzo Isella <lorenzo.isella at gmail.com>:
> 
> Dear All,
> From time to time I need to resort to the calculation of the earth
> mover' distance (see
> 
> https://en.wikipedia.org/wiki/Earth_mover's_distance and
> https://en.wikipedia.org/wiki/Wasserstein_metric .
> 
> In the past I used the package
> 
> https://r-forge.r-project.org/projects/earthmovdist/
> 
> which apparently is no longer available, but there is plenty of choice
> in R.
> 
> From the transport package, I found this example
> 
> set.seed(27)
> x <- pp(matrix(runif(100),50,2))
> y <- pp(matrix(runif(100),00,2))
> wasserstein(x,y,p=1)
> 
> but it is not 100% clear to me how to interpret it.
> Are x and y meant as histograms where the the center of each bin is
> provided and the total mass in the bins is automatically normalized to
> 1?
> 
> Essentially, my situation is that I have two univariate samples of unequal
> size. I would like to bin them and calculate the earth mover's
> distance between them.
> 
> I am not sure if this is what the example above does.
> Cheers
> 
> Lorenzo
> 
> 

------------------------------------
Prof. Dr. Dominic Schuhmacher
Institute for Mathematical Stochastics
University of Goettingen
Goldschmidtstrasse 7
D-37077 Goettingen
Germany

Phone: +49 (0)551 39172107
E-mail: dominic.schuhmacher at mathematik.uni-goettingen.de


From henri.cann at gmail.com  Tue Mar  7 10:35:35 2017
From: henri.cann at gmail.com (Henry Cann)
Date: Tue, 7 Mar 2017 10:35:35 +0100
Subject: [R] Cannot create a visible Choropleth Legend - GISTools
In-Reply-To: <CAGxFJbSvjNct60oHK8VB5Mm89x5wsZ32uwZtQcH62P2z4DFACw@mail.gmail.com>
References: <CACZ3g7JqCC9czP_cTXMnKAQ1EJCQRyuvsLGrsQ7GgrGgOwJpyA@mail.gmail.com>
	<CAGxFJbSvjNct60oHK8VB5Mm89x5wsZ32uwZtQcH62P2z4DFACw@mail.gmail.com>
Message-ID: <CACZ3g7Kj_HG79LLwjEd43FpFEsssUMBqdrLKy=ecUj99C2j2kA@mail.gmail.com>

Apologies Bert, not sure I follow the question?
The code is sort of pieced together from different thinks I've tried. Due
to projection issues I've tried various different ways of carrying out a
spatial join. Most of the code is based around making the join easier e.g
by recreating unique identifiers in both shape files.

Have had a look at 7.16 (thanks for suggestion) DOn't believe it applies
because choro.legend usually outputs straight onto the plot area (I have
tried this with other code.)

I tested my same code with a different shapefile and had the same issue so
I conclude it's probably a by-product of something in my code?

On 6 March 2017 at 23:14, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Perhaps FAQ 7.16 ? (Are you sourcing the code?)
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Mar 6, 2017 at 11:54 AM, Henry Cann <henri.cann at gmail.com> wrote:
> > I have combined two layers to create a shapefile which I am colouring
> using
> > the Choropleth function in GISTools. The problem I am having is that
> > despite having no other problems with my code including with the actual
> > mapping of the choropleth itself, nothing I can do, using choro.legend,
> > actually appears. I have checked I am plotting in the right pace using
> > locator().
> >
> > My code is below. I have also attached my data and link to shapefile and
> > attached my data.
> > Many thanks in advance.
> > Henry
> > https://borders.ukdataservice.ac.uk/ukborders/easy_download/
> prebuilt/shape/infuse_dist_lyr_2011.zip
> >
> > require(rgdal)
> > require(sp)
> > library(plyr)
> > library(dplyr)
> > library(RColorBrewer)
> > MyDataFile2 <- read.csv("reduced1.csv")
> > class(MyDataFile2)
> > coordinates(MyDataFile2)<-~X+Y
> > class(MyDataFile2)
> > writeOGR(MyDataFile2, "Folder", "File9", driver = "ESRI Shapefile")
> > Redefined2 <- readOGR(dsn="Folder", layer = "File9")
> > proj4string(Redefined2) <- CRS("+init=epsg:4326") # WGS 84
> > MyMap <-readOGR(".","infuse_dist_lyr_2011")
> > proj4string(MyMap)
> > MyMapb <- spTransform(MyMap, proj4string(Redefined2))
> > MyMapb at data <- mutate(MyMapb at data, id_poly =
> > as.numeric(rownames(MyMapb at data)))
> > Redefined2 at data <- mutate(Redefined2 at data, id_la =
> > as.numeric(rownames(Redefined2 at data)))
> > New <- over(Redefined2, MyMapb)
> > New <- mutate(New, id_la = as.numeric(rownames(New)))
> > New <- left_join(Redefined2 at data, New, by = c("id_la" = "id_la"))
> > New2 <- New %>% group_by(id_poly) %>%
> > dplyr::summarise(avgBrit = mean(Brtshns), SumBrit = sum(Brtshns),
> > nBrit = n()) %>%
> > arrange(id_poly)
> > MyMapb at data <- left_join(MyMapb at data, New2, by = c("id_poly" =
> "id_poly"))
> > View(MyMapb)
> > shape2 <- MyMapb[!is.na(MyMapb at data$avgBrit),]
> >
> > myshading = auto.shading(shape2$avgBrit, n=7,
> >                      cols=brewer.pal(7, "Spectral"))
> > choropleth(shape2, shape2$avgBrit,shading=myshading)
> > choro.legend(48.4,-5.79, myshading,fmt="%4.1f",cex=0.8)
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jainsk.iitkgp at gmail.com  Tue Mar  7 12:12:48 2017
From: jainsk.iitkgp at gmail.com (surendra jain)
Date: Tue, 7 Mar 2017 16:42:48 +0530
Subject: [R] Alternative to ggplot2 for R version 2.15.3
Message-ID: <CAA7RLY5p8CFetCm_0VR4WOHrfLe+JHSmOPqHqv_=VUnLR81w=Q@mail.gmail.com>

Dear all,

  I have an old Macbook and I have installed R version 2.15.3. But
ggplot2 is not available for this version of R. Can someone suggest me
an alternative to ggplot2 (for plotting using R) for Mac version
10.5.8.

Best Regards,
Surendra


From lorenzo.isella at gmail.com  Tue Mar  7 13:35:37 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 7 Mar 2017 13:35:37 +0100
Subject: [R] Earth Mover's Distance
Message-ID: <20170307123537.GB2604@chicca2>

Dear All,
>From time to time I need to resort to the calculation of the earth
mover' distance (see

https://en.wikipedia.org/wiki/Earth_mover's_distance and
https://en.wikipedia.org/wiki/Wasserstein_metric .

In the past I used the package

https://r-forge.r-project.org/projects/earthmovdist/

which apparently is no longer available, but there is plenty of choice
in R.

>From the transport package, I found this example

set.seed(27)
x <- pp(matrix(runif(100),50,2))
y <- pp(matrix(runif(100),00,2))
wasserstein(x,y,p=1)

but it is not 100% clear to me how to interpret it.
Are x and y meant as histograms where the the center of each bin is
provided and the total mass in the bins is automatically normalized to
1?

Essentially, my situation is that I have two univariate samples of unequal
size. I would like to bin them and calculate the earth mover's
distance between them.

I am not sure if this is what the example above does.
Cheers

Lorenzo


From lorenzo.isella at gmail.com  Tue Mar  7 14:27:33 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 7 Mar 2017 14:27:33 +0100
Subject: [R] Earth Mover's Distance
Message-ID: <20170307132733.GC2604@chicca2>

Dear All,
>From time to time I need to resort to the calculation of the earth
mover' distance (see

https://en.wikipedia.org/wiki/Earth_mover's_distance and
https://en.wikipedia.org/wiki/Wasserstein_metric .

In the past I used the package

https://r-forge.r-project.org/projects/earthmovdist/

which apparently is no longer available, but there is plenty of choice
in R.

>From the transport package, I found this example

set.seed(27)
x <- pp(matrix(runif(100),50,2))
y <- pp(matrix(runif(100),00,2))
wasserstein(x,y,p=1)

but it is not 100% clear to me how to interpret it.
Are x and y meant as histograms where the the center of each bin is
provided and the total mass in the bins is automatically normalized to
1?

Essentially, my situation is that I have two univariate samples of unequal
size. I would like to bin them and calculate the earth mover's
distance between them.

I am not sure if this is what the example above does.
Cheers

Lorenzo


From lorenzo.isella at gmail.com  Tue Mar  7 16:32:04 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 7 Mar 2017 16:32:04 +0100
Subject: [R] Transport and Earth Mover's Distance
In-Reply-To: <74667735-11AE-405E-9F88-071AEF7E7F98@mathematik.uni-goettingen.de>
References: <20170307122932.GA2604@chicca2>
	<74667735-11AE-405E-9F88-071AEF7E7F98@mathematik.uni-goettingen.de>
Message-ID: <20170307153204.GE2604@chicca2>

Dear Dominic,
Thanks a lot for the quick reply.
Just a few questions to make sure I got it all right (I now understand that
transport and spatstat in particular can do much more than I need
right now).
Essentially I am after the Wasserstein distance between univariate
distributions (and it would be great if I can extend it to the
case of two distributions with a different bin structure).

1) two distributions with the same bins (I identify each bin by the
central point in the bin).

n_bin <- 11 # number of bins

bin_structure <- seq(10, by=1, len=n_bin)

set.seed(1234)

x_counts <- rpois(n_bin, 10)
y_counts <- rpois(n_bin, 10)

x <- pp(as.matrix(cbind(bin_structure, x_counts)))
y <- pp(as.matrix(cbind(bin_structure, y_counts)))


match <- transport(x,y,p=1)
plot(x,y,match)
wasserstein_dist <- wasserstein(x,y,p=1,match)


2) Now I do not have the same bin structure


y2 <- pp(as.matrix(cbind(bin_structure+2, y_counts)))


match <- transport(x,y2,p=1)
plot(x,y2,match)
wasserstein_dist2 <- wasserstein(x,y2,p=1,match)


Do 1) and 2) make sense?

>
>If you have no particular need for binning, check out the function
>pppdist in the R-package spatstat, which offers a more flexible way
>to deal with point patterns of different size.


Well, this is not clear, but possibly very important for me.
My raw data consists of 2 univariate samples of unequal length.

suppose that

x<-rnorm(100)

and

y<-rnorm(90)

Is there a way to define the Wasserstein distance between them without
going through the binning procedure?



Many thanks!

Lorenzo


From murdoch.duncan at gmail.com  Tue Mar  7 18:15:58 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 7 Mar 2017 12:15:58 -0500
Subject: [R] Alternative to ggplot2 for R version 2.15.3
In-Reply-To: <CAA7RLY5p8CFetCm_0VR4WOHrfLe+JHSmOPqHqv_=VUnLR81w=Q@mail.gmail.com>
References: <CAA7RLY5p8CFetCm_0VR4WOHrfLe+JHSmOPqHqv_=VUnLR81w=Q@mail.gmail.com>
Message-ID: <26095b21-7d3c-c584-b18b-eb1f81946f09@gmail.com>

On 07/03/2017 6:12 AM, surendra jain wrote:
> Dear all,
>
>   I have an old Macbook and I have installed R version 2.15.3. But
> ggplot2 is not available for this version of R. Can someone suggest me
> an alternative to ggplot2 (for plotting using R) for Mac version
> 10.5.8.
>

You will automatically have base graphics and lattice graphics 
installed, so you could use those.  They are very different from ggplot2 
(and from each other) so it won't be painless.

Or you could install an old version of ggplot2: R 2.15.3 came out in 
March 2013, so presumably some version of ggplot2 like 0.9.3.1 (which 
also came out that month) would work with it.

But the easiest thing might be to install a newer R version.  You'll 
find very little support for 2.15.3 nowadays.

Duncan Murdoch


From edd at debian.org  Tue Mar  7 18:36:56 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Mar 2017 11:36:56 -0600
Subject: [R] Earth Mover's Distance
In-Reply-To: <20170307132733.GC2604@chicca2>
References: <20170307132733.GC2604@chicca2>
Message-ID: <22718.61368.231120.164385@max.eddelbuettel.com>


The earthmovdist repo on R-Forge is alive and well.  Rainer and I simply
stopped doing work on it as the authors of the Emd-L1 library we use could
not get a liberal license for this.  Note the language in the source code
(src/emdL1.cpp) and please make sure YOUR use is in compliance.

But as I use R-Forge less than GitHub, I just brought the repo over to

    https://github.com/eddelbuettel/earthmovdist

and may make an update or two in the coming days to make it compliant with R
CMD check on R release and R devel, and in process may make the Rcpp use a
little more current...

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jdnewmil at dcn.davis.ca.us  Tue Mar  7 19:00:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 07 Mar 2017 10:00:40 -0800
Subject: [R] Alternative to ggplot2 for R version 2.15.3
In-Reply-To: <CAA7RLY5p8CFetCm_0VR4WOHrfLe+JHSmOPqHqv_=VUnLR81w=Q@mail.gmail.com>
References: <CAA7RLY5p8CFetCm_0VR4WOHrfLe+JHSmOPqHqv_=VUnLR81w=Q@mail.gmail.com>
Message-ID: <0FBF3E8C-7BD0-4BB6-8F24-9F0C5B78495B@dcn.davis.ca.us>

Lattice (comes with R).

Is it really necessary for you you use such an antiquated version of R just because your computer is old? (I don't use Macs, but that is not necessarily so for other operating systems.)
-- 
Sent from my phone. Please excuse my brevity.

On March 7, 2017 3:12:48 AM PST, surendra jain <jainsk.iitkgp at gmail.com> wrote:
>Dear all,
>
>  I have an old Macbook and I have installed R version 2.15.3. But
>ggplot2 is not available for this version of R. Can someone suggest me
>an alternative to ggplot2 (for plotting using R) for Mac version
>10.5.8.
>
>Best Regards,
>Surendra
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue Mar  7 19:45:01 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 7 Mar 2017 11:45:01 -0700
Subject: [R] About installing the lubridate package
Message-ID: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>

Hi R users,

I'd like to ask that where to find the 'lubridate' package for Mac Sierra?
I downloaded one version for OS X Mavericks binaries, but it does not work.

The error message is as below:
> install.packages("~/Downloads/lubridate_1.6.0.tar.gz", repos = NULL, type
= "source")
ERROR: dependency ?stringr? is not available for package ?lubridate?
* removing
?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/lubridate?
Warning in install.packages :
  installation of package
?/Users/qinghuan/Downloads/lubridate_1.6.0.tar.gz? had non-zero exit status

How to install the proper package? Thanks for your help.

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue Mar  7 19:54:29 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 7 Mar 2017 11:54:29 -0700
Subject: [R] About installing the lubridate package
In-Reply-To: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
References: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
Message-ID: <CAN5afy_pCOJDFGLRJGBPHRbDbOJD54jhJUOOtvJGyu3H-kWnMg@mail.gmail.com>

Or if there is another way to get 'yyyy', 'mm', and 'dd' from time variable
'dd-mm-yyyy'? Thanks very much.


On Tue, Mar 7, 2017 at 11:45 AM, lily li <chocold12 at gmail.com> wrote:

> Hi R users,
>
> I'd like to ask that where to find the 'lubridate' package for Mac Sierra?
> I downloaded one version for OS X Mavericks binaries, but it does not
> work.
>
> The error message is as below:
> > install.packages("~/Downloads/lubridate_1.6.0.tar.gz", repos = NULL,
> type = "source")
> ERROR: dependency ?stringr? is not available for package ?lubridate?
> * removing ?/Library/Frameworks/R.framework/Versions/3.3/
> Resources/library/lubridate?
> Warning in install.packages :
>   installation of package ?/Users/qinghuan/Downloads/lubridate_1.6.0.tar.gz?
> had non-zero exit status
>
> How to install the proper package? Thanks for your help.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar  7 20:14:42 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Mar 2017 11:14:42 -0800
Subject: [R] About installing the lubridate package
In-Reply-To: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
References: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
Message-ID: <CAGxFJbTOohg071-yKs9t8HmES2GQR8jP48fyNrdf0hSQZGvKBQ@mail.gmail.com>

Huh?

I just installed the Mavericks binary on my OSX Sierra without problems:

install.packages("lubridate", repos='https://cran.revolutionanalytics.com')

A google search would have found this essentially instantly!

As for native R functions for parsing dates: of course!

?strptime

Again, a google search would have found this (e.g. on "parse dates in
R"). Please make a minimal effort to search before posting such "where
do I find" queries here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 7, 2017 at 10:45 AM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I'd like to ask that where to find the 'lubridate' package for Mac Sierra?
> I downloaded one version for OS X Mavericks binaries, but it does not work.
>
> The error message is as below:
>> install.packages("~/Downloads/lubridate_1.6.0.tar.gz", repos = NULL, type
> = "source")
> ERROR: dependency ?stringr? is not available for package ?lubridate?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/lubridate?
> Warning in install.packages :
>   installation of package
> ?/Users/qinghuan/Downloads/lubridate_1.6.0.tar.gz? had non-zero exit status
>
> How to install the proper package? Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue Mar  7 20:18:55 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 7 Mar 2017 12:18:55 -0700
Subject: [R] About installing the lubridate package
In-Reply-To: <CAGxFJbTOohg071-yKs9t8HmES2GQR8jP48fyNrdf0hSQZGvKBQ@mail.gmail.com>
References: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
	<CAGxFJbTOohg071-yKs9t8HmES2GQR8jP48fyNrdf0hSQZGvKBQ@mail.gmail.com>
Message-ID: <CAN5afy9YnLE+6uoXb14aenaLrHaizKV+9YWazHt8bKX3jH16jQ@mail.gmail.com>

Thanks, Bert. This website is comprehensive. So for any kind of packages in
the future, can I just download from this website? I did a search from
google before.

On Tue, Mar 7, 2017 at 12:14 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Huh?
>
> I just installed the Mavericks binary on my OSX Sierra without problems:
>
> install.packages("lubridate", repos='https://cran.revolutionanalytics.com
> ')
>
> A google search would have found this essentially instantly!
>
> As for native R functions for parsing dates: of course!
>
> ?strptime
>
> Again, a google search would have found this (e.g. on "parse dates in
> R"). Please make a minimal effort to search before posting such "where
> do I find" queries here.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Mar 7, 2017 at 10:45 AM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> >
> > I'd like to ask that where to find the 'lubridate' package for Mac
> Sierra?
> > I downloaded one version for OS X Mavericks binaries, but it does not
> work.
> >
> > The error message is as below:
> >> install.packages("~/Downloads/lubridate_1.6.0.tar.gz", repos = NULL,
> type
> > = "source")
> > ERROR: dependency ?stringr? is not available for package ?lubridate?
> > * removing
> > ?/Library/Frameworks/R.framework/Versions/3.3/
> Resources/library/lubridate?
> > Warning in install.packages :
> >   installation of package
> > ?/Users/qinghuan/Downloads/lubridate_1.6.0.tar.gz? had non-zero exit
> status
> >
> > How to install the proper package? Thanks for your help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar  7 20:33:01 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Mar 2017 11:33:01 -0800
Subject: [R] About installing the lubridate package
In-Reply-To: <CAN5afy9YnLE+6uoXb14aenaLrHaizKV+9YWazHt8bKX3jH16jQ@mail.gmail.com>
References: <CAN5afy_V0Z8oC-gFo10AvvY39wvFDPuFHzEqOtJZKMgq1tagwQ@mail.gmail.com>
	<CAGxFJbTOohg071-yKs9t8HmES2GQR8jP48fyNrdf0hSQZGvKBQ@mail.gmail.com>
	<CAN5afy9YnLE+6uoXb14aenaLrHaizKV+9YWazHt8bKX3jH16jQ@mail.gmail.com>
Message-ID: <CAGxFJbQv_Ka_bmo4McpBYRnOV=dd-NyMXXD_FraBHsF80UGJaw@mail.gmail.com>

Please go to:

http://cran.r-project.org/

and start reading. In particular, how to download packages and other software.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 7, 2017 at 11:18 AM, lily li <chocold12 at gmail.com> wrote:
> Thanks, Bert. This website is comprehensive. So for any kind of packages in
> the future, can I just download from this website? I did a search from
> google before.
>
> On Tue, Mar 7, 2017 at 12:14 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Huh?
>>
>> I just installed the Mavericks binary on my OSX Sierra without problems:
>>
>> install.packages("lubridate",
>> repos='https://cran.revolutionanalytics.com')
>>
>> A google search would have found this essentially instantly!
>>
>> As for native R functions for parsing dates: of course!
>>
>> ?strptime
>>
>> Again, a google search would have found this (e.g. on "parse dates in
>> R"). Please make a minimal effort to search before posting such "where
>> do I find" queries here.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Mar 7, 2017 at 10:45 AM, lily li <chocold12 at gmail.com> wrote:
>> > Hi R users,
>> >
>> > I'd like to ask that where to find the 'lubridate' package for Mac
>> > Sierra?
>> > I downloaded one version for OS X Mavericks binaries, but it does not
>> > work.
>> >
>> > The error message is as below:
>> >> install.packages("~/Downloads/lubridate_1.6.0.tar.gz", repos = NULL,
>> >> type
>> > = "source")
>> > ERROR: dependency ?stringr? is not available for package ?lubridate?
>> > * removing
>> >
>> > ?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/lubridate?
>> > Warning in install.packages :
>> >   installation of package
>> > ?/Users/qinghuan/Downloads/lubridate_1.6.0.tar.gz? had non-zero exit
>> > status
>> >
>> > How to install the proper package? Thanks for your help.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From gchappi at gmail.com  Tue Mar  7 21:40:22 2017
From: gchappi at gmail.com (Hans-Peter Suter)
Date: Tue, 7 Mar 2017 21:40:22 +0100
Subject: [R] Any reason not to use RUnit any longer?
In-Reply-To: <22718.52316.842737.233815@max.eddelbuettel.com>
References: <CANJoV3Pr5rLedgRghxnbgNSWdA8YvWguHRfVSNbL-3m_3HU3EA@mail.gmail.com>
	<22718.52316.842737.233815@max.eddelbuettel.com>
Message-ID: <CANJoV3NYo5P-PpT30BaCe5Ou5Kdqv0icQQR+U4qud3ntHnEh6g@mail.gmail.com>

Thanks a lot for the feedback, Dirk and Mehmet,

My (large) test-code is in RUnit and so I'm glad to hear that it is fine.
RUnit worked very well for me and I do not have a reason to switch.

	[[alternative HTML version deleted]]


From cri.alessandro at gmail.com  Wed Mar  8 00:17:52 2017
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Tue, 7 Mar 2017 17:17:52 -0600
Subject: [R] modify additional parameters, glht and summary
Message-ID: <CAHhX7Wj=i2RvJKUdvJNXmNnzCtV71-akwGpiaj3XcJTZhBQ7cA@mail.gmail.com>

Hi all,

first of all, thanks a lot in advance for your help. I am running a
sequence of post-hoc tests with glht (mutcomp package), but the function
summary warns me that the algorithm ends with an error > abseps.

$ hr.ph <- glht(hr.lm, linfct = ph_conditional);
$ summary(hr.ph)

Warning messages:
1: In RET$pfunction("adjusted", ...) : Completion with error > abseps
2: In RET$pfunction("adjusted", ...) : Completion with error > abseps
3: In RET$pfunction("adjusted", ...) : Completion with error > abseps
4: In RET$pfunction("adjusted", ...) : Completion with error > abseps

I think it is a matter of modifying the parameters of the algorithm that
summary runs. Looking at the documentation, I could not find a way of
actually doing so. Do you have any suggestion? Also, how does one know the
default values of these algorithms?

Thanks a lot!

Cristiano

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Mar  8 04:19:35 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 7 Mar 2017 21:19:35 -0600
Subject: [R] HTTP status was '404 Not Found'
In-Reply-To: <747823713.209992.1488876738137@mail.yahoo.com>
References: <747823713.209992.1488876738137.ref@mail.yahoo.com>
	<747823713.209992.1488876738137@mail.yahoo.com>
Message-ID: <CAPPM_gRakvOhpN+6yS8N_es6p7Zo07oaaVYuMBnwx+OjvFh-rA@mail.gmail.com>

On Tue, Mar 7, 2017 at 2:52 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> HiSo I tried running the p but i'm stuck as i get the following error:
> In download.file(url, destfile, method = method, quiet = quiet) :  cannot open URL 'http://chart.yahoo.com/table.csv?s=DJI&a=2&b=13&c=2012&d=2&e=07&f=2017&g=d&q=q&y=0&z=DJI&x=.csv': HTTP status was '404 Not Found'
>
> Here is the R code:
> library(vars)library(tawny)library(quantmod)library(MASS)library(stats)library(DEoptim)library(sn)library(SkewHyperbolic)library(tseries)symbols<-getSymbols(c("^GSPC", "^DJI"))endDate <- Sys.Date()startDate <- endDate - as.difftime(52*5, unit="weeks")quoteType <- "Close"p <- do.call(cbind, lapply(symbols, get.hist.quote, start=startDate, end=endDate,  quote=quoteType))
>
Please try to post *minimal* reproducible examples.  Only two packages
are needed to run your code.

library(quantmod)
library(tseries)

symbols<-getSymbols(c("^GSPC", "^DJI"))
endDate <- Sys.Date()
startDate <- endDate - as.difftime(52*5, unit="weeks")
quoteType <- "Close"
p <- do.call(cbind, lapply(symbols, get.hist.quote,
  start=startDate, end=endDate,  quote=quoteType))

Your calls with get.hist.quote() are not what you expect.  Note that
the tickers you passed to getSymbols() are "^GSPC" and "^DJI".  But
those are not the objects that getSymbols() creates (or the adjusted
ticker symbols it returns), because they are not syntatically valid R
names (because they start with a circumflex).

So you call get.hist.quote() with tickers "GSPC" and "DJI", which are
not the S&P 500 and Dow Jones Industrial indexes, respectively.  The
GSPC data is not what you expect, and there's no data for DJI.

>         [[alternative HTML version deleted]]
>
Please follow the posting guide and do not post HTML.  The list server
does not like it and can mangle your message, as it did in this case.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From G.Maubach at weinwolf.de  Wed Mar  8 08:57:00 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 8 Mar 2017 08:57:00 +0100
Subject: [R] Follow-up:  RStudio: Place for Storing Options
In-Reply-To: <22702.37235.988957.574018@stat.math.ethz.ch>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
	<22684.34149.431821.945334@stat.math.ethz.ch>	<alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>
	<22702.37235.988957.574018@stat.math.ethz.ch>
Message-ID: <OF10183F64.C0956D86-ONC12580DD.002A7262-C12580DD.002BAB7A@lotus.hawesko.de>

Hi All,

I got a late reply from RStudio Support concerning the question where 
RStudio store options and configurations:

-- cut --

The post RStudio Config Files has a new comment. 
. . .
Unfortunately, it's unlikely that we'll be able to provide a programmatic 
R interface in the near future -- the way we lay out and store RStudio's 
client state does not make it as amenable to public consumption as we 
might hope.
That said, you can generally copy everything within that folder to a new 
machine (at the same relative path from the user home directory), and 
expect preferences to be respected + restored as you might expect.
. . .
--cut --

The result of the discussion is:

We can copy the complete RStudio directory for storing options and 
configurations under

%localappdata%\RStudio-Desktop or 
C:\Users\<username>\AppData\Local\RStudio-Desktop

and copy it completely to a new installation of RStudio.

A programmatic approach to edit RStudio options and configurations is not 
possible due to design decisions.

The purpose of the initial question was to find a way to save RStudio 
options and configurations, e g. on git/github or similar. This is 
possible by initialising the above given directory with git or similar.

An open question is what happens if a new RStudio release makes changes to 
the options and configurations. If the stored directory can be completely 
used would need additional clearification, i.e. for each new version.

Kind regards

Georg







Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An:     Jeff Newmiller <jdnewmil at dcn.davis.ca.us>, 
Kopie:  Martin Maechler <maechler at stat.math.ethz.ch>, 
<G.Maubach at weinwolf.de>, R-help mailing list <r-help at r-project.org>
Datum:  23.02.2017 08:37
Betreff:        Re: [R] RStudio: Place for Storing Options



>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Sat, 11 Feb 2017 08:09:36 -0800 writes:

    > For the record, then, Google listened to my incantation of
    > "rstudio configuration file" and the second result was:

    > 
https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State


    > RStudio Desktop is also open source, so you can download
    > the source code and look at the operating-system-specific
    > bits (for "where") if the above link goes out of date or
    > disappears.

Thanks a lot, Jeff!

And for the archives:  On reasonable OS's,  the hidden
directory/folder containing all the info is
                                  ~/.rstudio-desktop/
and if "things are broken" the recommendation is to rename that
   mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
and (zip and) send along with your e-mail to the experts for diagnosis.


    > On Thu, 9 Feb 2017, Martin Maechler wrote:

    >> 
    >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
    >>>>>>> Feb 2017 14:37:57 +0000 writes:
    >> 
    >> > Hi Georg, > maybe someone here knows, but I think you
    >> are more likely to get answers to > Rstudio related
    >> questions with RStudio support: >
    >> https://support.rstudio.com/hc/en-us
    >> 
    >> > Best, > Ulrik
    >> 
    >> Indeed, thank you, Ulrik.
    >> 
    >> In this special case, however, I'm quite sure many
    >> readers of R-help would be interested in the answer; so
    >> once you receive an answer, please post it (or a link to
    >> a public URL with it) here on R-help, thank you in
    >> advance.
    >> 
    >> We would like to be able to *save*, or sometimes *set* /
    >> *reset* such options "in a scripted manner", e.g. for
    >> controlled exam sessions.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
    >> wrote:
    >> 
    >> >> Hi All, >> I would like to make a backup of my RStudio
    >> IDE options I configure using >> "Tools/Global Options"
    >> from the menu bar. Searching the >> web did not reveal
    >> anything.
    >> 
    >> >> Can you tell me where RStudio IDE does store its
    >> configuration?
    >> 
    >> >> Kind regards >> Georg
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > 
---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    > 
---------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Mar  8 08:59:09 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 8 Mar 2017 08:59:09 +0100
Subject: [R] Follow-up: RStudio: Place for Storing Options (as plain text)
Message-ID: <OF687A59AE.205B3F09-ONC12580DD.002BBD09-C12580DD.002BDDBD@lotus.hawesko.de>

Hi All,

I got a late reply from RStudio Support concerning the question where 
RStudio store options and configurations:

-- cut --

The post RStudio Config Files has a new comment. 
. . .
Unfortunately, it's unlikely that we'll be able to provide a programmatic 
R interface in the near future -- the way we lay out and store RStudio's 
client state does not make it as amenable to public consumption as we 
might hope.
That said, you can generally copy everything within that folder to a new 
machine (at the same relative path from the user home directory), and 
expect preferences to be respected + restored as you might expect.
. . .
--cut --

The result of the discussion is:

We can copy the complete RStudio directory for storing options and 
configurations under

%localappdata%\RStudio-Desktop or 
C:\Users\<username>\AppData\Local\RStudio-Desktop

and copy it completely to a new installation of RStudio.

A programmatic approach to edit RStudio options and configurations is not 
possible due to design decisions.

The purpose of the initial question was to find a way to save RStudio 
options and configurations, e g. on git/github or similar. This is 
possible by initialising the above given directory with git or similar.

An open question is what happens if a new RStudio release makes changes to 
the options and configurations. If the stored directory can be completely 
used would need additional clearification, i.e. for each new version.

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An: 
Kopie:   <G.Maubach at weinwolf.de>,
Datum:  23.02.2017 08:37
Betreff:        Re: [R] RStudio: Place for Storing Options



>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Sat, 11 Feb 2017 08:09:36 -0800 writes:

    > For the record, then, Google listened to my incantation of
    > "rstudio configuration file" and the second result was:

    > 
https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State


    > RStudio Desktop is also open source, so you can download
    > the source code and look at the operating-system-specific
    > bits (for "where") if the above link goes out of date or
    > disappears.

Thanks a lot, Jeff!

And for the archives:  On reasonable OS's,  the hidden
directory/folder containing all the info is
                                  ~/.rstudio-desktop/
and if "things are broken" the recommendation is to rename that
   mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
and (zip and) send along with your e-mail to the experts for diagnosis.


    > On Thu, 9 Feb 2017, Martin Maechler wrote:

    >> 
    >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
    >>>>>>> Feb 2017 14:37:57 +0000 writes:
    >> 
    >> > Hi Georg, > maybe someone here knows, but I think you
    >> are more likely to get answers to > Rstudio related
    >> questions with RStudio support: >
    >> https://support.rstudio.com/hc/en-us
    >> 
    >> > Best, > Ulrik
    >> 
    >> Indeed, thank you, Ulrik.
    >> 
    >> In this special case, however, I'm quite sure many
    >> readers of R-help would be interested in the answer; so
    >> once you receive an answer, please post it (or a link to
    >> a public URL with it) here on R-help, thank you in
    >> advance.
    >> 
    >> We would like to be able to *save*, or sometimes *set* /
    >> *reset* such options "in a scripted manner", e.g. for
    >> controlled exam sessions.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
    >> wrote:
    >> 
    >> >> Hi All, >> I would like to make a backup of my RStudio
    >> IDE options I configure using >> "Tools/Global Options"
    >> from the menu bar. Searching the >> web did not reveal
    >> anything.
    >> 
    >> >> Can you tell me where RStudio IDE does store its
    >> configuration?
    >> 
    >> >> Kind regards >> Georg
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > 
---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    >


From dominic.schuhmacher at mathematik.uni-goettingen.de  Wed Mar  8 11:28:59 2017
From: dominic.schuhmacher at mathematik.uni-goettingen.de (Schuhmacher, Dominic)
Date: Wed, 8 Mar 2017 10:28:59 +0000
Subject: [R] Transport and Earth Mover's Distance
In-Reply-To: <20170307153204.GE2604@chicca2>
References: <20170307122932.GA2604@chicca2>
	<74667735-11AE-405E-9F88-071AEF7E7F98@mathematik.uni-goettingen.de>
	<20170307153204.GE2604@chicca2>
Message-ID: <312DC63A-779E-4059-BC29-FFBB38440916@mathematik.uni-goettingen.de>

Dear Lorenzo,

No, the code does not do what you are after. R-package transport is for point patterns and histograms in two and more dimensions. You have a distribution in one dimension.

> 1) two distributions with the same bins (I identify each bin by the
> central point in the bin).
> 
> n_bin <- 11 # number of bins
> 
> bin_structure <- seq(10, by=1, len=n_bin)
> 
> set.seed(1234)
> 
> x_counts <- rpois(n_bin, 10)
> y_counts <- rpois(n_bin, 10)
> 
> x <- pp(as.matrix(cbind(bin_structure, x_counts)))
# 11 points in two dimensions with x-coordinates bin_structure and y-coordinates x_counts 
> y <- pp(as.matrix(cbind(bin_structure, y_counts)))
# 11 points in two dimensions with x-coordinates bin_structure and y-coordinates y_counts 
> match <- transport(x,y,p=1)
# compute the optimal transport between the two point patterns (assuming mass 1 at each point), i.e. simply match the points in 2-d
> plot(x,y,match)
> wasserstein_dist <- wasserstein(x,y,p=1,match)

# the average distance by which points are moved.

You could trick transport into solving one-dimensional problems. But given that one-dimensional optimal transport is computationally simple, this would be highly inefficient. Depending on what you want to do with ?additional mass? (in your examples, you have count data with differing total counts), the following might be what you want:

x_prob <- x_counts/sum(x_counts)
y_prob <- y_counts/sum(y_counts)
sum(abs(cumsum(x_prob)-cumsum(y_prob)))

This gives the 1-Wasserstein distance between the probability histograms (i.e. the empirical distributions), assuming as in your example equally spaced-bins of width 1. You need the same bins for both samples, but you can treat your Example 2 by adding bins with count 0 to x_counts and y_counts.




>> 
>> If you have no particular need for binning, check out the function
>> pppdist in the R-package spatstat, which offers a more flexible way
>> to deal with point patterns of different size.
> 
> 
> Well, this is not clear, but possibly very important for me.
> My raw data consists of 2 univariate samples of unequal length.
> 
> suppose that
> 
> x<-rnorm(100)
> 
> and
> 
> y<-rnorm(90)
> 
> Is there a way to define the Wasserstein distance between them without
> going through the binning procedure?
> 
Define, yes: the 1-Wasserstein distance in one-dimension is the area between the empirical cumulative distribution functions. If the samples had the same lengths this could be directly computed by

mean(abs(sort(x)-sort(y)))

Otherwise this needs some lines of code. I will include it in the next version of the transport package (soon).

Best regards,
Dominic



> Am 07.03.2017 um 16:32 schrieb Lorenzo Isella <lorenzo.isella at gmail.com>:
> 
> Dear Dominic,
> Thanks a lot for the quick reply.
> Just a few questions to make sure I got it all right (I now understand that
> transport and spatstat in particular can do much more than I need
> right now).
> Essentially I am after the Wasserstein distance between univariate
> distributions (and it would be great if I can extend it to the
> case of two distributions with a different bin structure).
> 
> 1) two distributions with the same bins (I identify each bin by the
> central point in the bin).
> 
> n_bin <- 11 # number of bins
> 
> bin_structure <- seq(10, by=1, len=n_bin)
> 
> set.seed(1234)
> 
> x_counts <- rpois(n_bin, 10)
> y_counts <- rpois(n_bin, 10)
> 
> x <- pp(as.matrix(cbind(bin_structure, x_counts)))
> y <- pp(as.matrix(cbind(bin_structure, y_counts)))
> 
> 
> match <- transport(x,y,p=1)
> plot(x,y,match)
> wasserstein_dist <- wasserstein(x,y,p=1,match)
> 
> 
> 2) Now I do not have the same bin structure
> 
> 
> y2 <- pp(as.matrix(cbind(bin_structure+2, y_counts)))
> 
> 
> match <- transport(x,y2,p=1)
> plot(x,y2,match)
> wasserstein_dist2 <- wasserstein(x,y2,p=1,match)
> 
> 
> Do 1) and 2) make sense?
> 
>> 
>> If you have no particular need for binning, check out the function
>> pppdist in the R-package spatstat, which offers a more flexible way
>> to deal with point patterns of different size.
> 
> 
> Well, this is not clear, but possibly very important for me.
> My raw data consists of 2 univariate samples of unequal length.
> 
> suppose that
> 
> x<-rnorm(100)
> 
> and
> 
> y<-rnorm(90)
> 
> Is there a way to define the Wasserstein distance between them without
> going through the binning procedure?
> 
> 
> 
> Many thanks!
> 
> Lorenzo

------------------------------------
Prof. Dr. Dominic Schuhmacher
Institute for Mathematical Stochastics
University of Goettingen
Goldschmidtstrasse 7
D-37077 Goettingen
Germany

Phone: +49 (0)551 39172107
E-mail: dominic.schuhmacher at mathematik.uni-goettingen.de




From bgunter.4567 at gmail.com  Wed Mar  8 07:00:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Mar 2017 22:00:46 -0800
Subject: [R] [R-pkgs] New package on CRAN: remindR
Message-ID: <CAGxFJbQ_J+Qh_Bcq8T8sxhLWwcB_JRP=zQ5YrFAVCA9LkGp5+w@mail.gmail.com>

remindR is a simple, small package with essentially a single purpose:
to Insert/extract text "reminders" into/from function source code
comments or as the "comment" attribute of any object. The intent is
that the former could be handy in the course of program development to
remind one of e.g. argument requirements, to-do's, required options
settings, etc. The latter, which just wraps R's existing comment()
function, could also be used to provide information on objects or to
provide simple manual "tooltips" for users.

If interested, please have a look at the package vignette, which
provide a fuller explanation of how and why this might be useful and
how it works.

All feedback welcome: bgunter.4567 at gmail.com

-- Bert Gunter

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From chrishold at psyctc.org  Wed Mar  8 15:37:04 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Wed, 8 Mar 2017 14:37:04 +0000 (GMT)
Subject: [R] Has anyone created diagrammatic representations of Access/ODBC
 databases using R?
Message-ID: <163641910.7090758.1488983824901.JavaMail.zimbra@psyctc.org>

I have been on a fair old learning curve handling a fairly complex Access database with my beloved, if sometimes tantaslising, R. I've been using RODBC to do this and, despite the database not being all that well designed, the power of R and RODBC has been fantastic (of course). Huge thanks to R team and the RODBC team. 

Now I'd really like to generate some diagrammatic representations of the data structure: entity relationship models, UML representation ... anything like that would be wonderful. I can see three ways of approaching this and any one, two or three would be a huge help for me: 
1) something that reads the tables and any queries from an Access DB through RODBC and generates a map of them where the queries indicate the relationships between the tables 
2) something that reads through the global environment and any merge() commands in my code to see and map the data frames and how one was created by merges of others 
3) something that I use to spell out the structure textually and it takes this and maps it. 

I have done some searching around with Rseek and raw google and found two things. My #3 above is done by the CityPlot package but the mix of CSV and text files used to create the maps looks tough to learn. I suspect I ought to be able to use the package data.tree to do something along the lines I want and perhaps more easily than by learning the data structures behind CityPlot. Those are the only things I've found However, both those options look like learning curves that will take me time I can't justify for the plots. I'd love to have the plots but I know I can get on with the real work without them. 

However, it occurred to me that there may be someone on the list who may already have done something like this and might be willing to share their tools, tricks, experiences: hence this post! 

TIA, 


Chris 


	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Mar  8 16:27:08 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 8 Mar 2017 16:27:08 +0100
Subject: [R] Approach for Storing Result Data
Message-ID: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>

Hi All,

today I have a more general question concerning the approach of storing 
different values from the analysis of multiple variables.

My task is to compare distributions in a universe with distributions from 
the respondents using a whole bunch of variables. Comparison shall be done 
on relative frequencies (proportions).

I was thinking about the structure I should store the results in and came 
up with the following:

-- cut --

library(stringi)

# Result data frame
# Some sort of tidytidy data set where
# each value is stored as an identity.
# This way all values for all variables could be stored in
# one unique data structure.
# If an additional variable added for the name of the
# research one could also build result data set across
# surveys.
# Values for measure could be "number" for 'raw' values or
# "freq" for frequencies/counts.
# Values for unit could be "n" for 'numbers' and
# "%" for percentages.
d_test <- data.frame(
    group = rep(c("Universe", "Respondents"), each = 16),
    variable = rep("State", 32),
    value = rep(c(11.3,
                    12.7,
                    3.3,
                    5,
                    0.6,
                    8.1,
                    6.2,
                    5.8,
                    6.4,
                    14.5,
                    8.3,
                    0.3,
                    3.8,
                    2.5,
                    8.1,
                    3), 2),
    label = rep(c("Baden-Wuerttemberg",
                "Bayern",
                "Berlin",
                "Brandenburg",
                "Bremen",
                "Hamburg",
                "Hessen",
                "Mecklenburg-Vorpommern",
                "Niedersachsen",
                "Nordrhein-Westfalen",
                "Rheinland-Pfalz",
                "Saarland",
                "Sachsen",
                "Sachsen-Anhalt",
                "Schleswig-Holstein",
                "Thueringen"),2),
    measure = rep("freq", 32),
    unit = rep("%", 32),
    stringsAsFactors = FALSE
)

# This way the variables can be selected using simple
# value selection from Base R functionality.
data <- d_test[d_test$variable == "State" ,]

# And plot results for every variable.
ggplot(
  data = data,
  aes(
    x = label,
    y = value,
    fill = group)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_discrete(name = stringi::stri_trans_totitle(names(data)[1])) 
+
  scale_x_discrete(name = data$variable[1]) +
  scale_y_discrete(name = data$unit[1])

-- cut --

The reporting / presentation is done in R Markdown. I would load the 
result data set once at the beginning and running the comparisons as plots 
on each variable named in the results data set under "variable".

If I follow this approach for my customer relationship survey, do think I 
would face drawbacks or run into serious trouble?

I am interested in your opinion and open for other approaches and 
suggestions.

Kind regards

Georg


From dimitri.liakhovitski at gmail.com  Wed Mar  8 17:07:27 2017
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 8 Mar 2017 11:07:27 -0500
Subject: [R] Why is merge sorting even when sort = F?
Message-ID: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>

Hello!
I have a vector 'grades' and a data frame 'info':

grades2 <- data.frame(grade = c(1,2,2,3,1))
info <- data.frame(
  grade = 3:1,
  desc = c("Excellent", "Good", "Poor"),
  fail = c(F, F, T)
)

I want to get the info for all grades I have in info:

This solution resorts everything in the order of column 'grade':
merge(grades2, info, by = "grade", all.x = T, all.y = F)

Could you please explain why this solution also resorts - despite sort = FALSE?
merge(grades2, info, by = "grade", all.x = T, all.y = F, sort = FALSE)

Thanks a lot!
-- 
Dimitri Liakhovitski


From jdnewmil at dcn.davis.ca.us  Wed Mar  8 17:43:51 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Mar 2017 08:43:51 -0800
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
Message-ID: <F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>

Merging is not necessarily an order-preserving operation, but sorting can make the operation more efficient. The sort=TRUE argument forces the result to be sorted, but sort=FALSE is in not a promise that order will be preserved. (I think the imperfect sorting occurs when there are multiple keys but am not sure.) You can add columns to the input data that let you restore some semblance of the original ordering afterward, or you can roll your own possibly-less-efficient merge using match and indexing:

info[ match( grades2$grade, info$grade ), ]
-- 
Sent from my phone. Please excuse my brevity.

On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>Hello!
>I have a vector 'grades' and a data frame 'info':
>
>grades2 <- data.frame(grade = c(1,2,2,3,1))
>info <- data.frame(
>  grade = 3:1,
>  desc = c("Excellent", "Good", "Poor"),
>  fail = c(F, F, T)
>)
>
>I want to get the info for all grades I have in info:
>
>This solution resorts everything in the order of column 'grade':
>merge(grades2, info, by = "grade", all.x = T, all.y = F)
>
>Could you please explain why this solution also resorts - despite sort
>= FALSE?
>merge(grades2, info, by = "grade", all.x = T, all.y = F, sort = FALSE)
>
>Thanks a lot!


From bgunter.4567 at gmail.com  Wed Mar  8 17:44:17 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 8 Mar 2017 08:44:17 -0800
Subject: [R] Approach for Storing Result Data
In-Reply-To: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>
References: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>
Message-ID: <CAGxFJbRPKo_iAprQKSEbP-YKDZj4CogqGP1viPVPo7rMkY02Ow@mail.gmail.com>

This does not appear to be a legitimate topic for r-help: it is are
not a consulting service. Please see the posting guide.

Of course, others may disagree and reply. Wouldn't be the first time I'm wrong.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 8, 2017 at 7:27 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> today I have a more general question concerning the approach of storing
> different values from the analysis of multiple variables.
>
> My task is to compare distributions in a universe with distributions from
> the respondents using a whole bunch of variables. Comparison shall be done
> on relative frequencies (proportions).
>
> I was thinking about the structure I should store the results in and came
> up with the following:
>
> -- cut --
>
> library(stringi)
>
> # Result data frame
> # Some sort of tidytidy data set where
> # each value is stored as an identity.
> # This way all values for all variables could be stored in
> # one unique data structure.
> # If an additional variable added for the name of the
> # research one could also build result data set across
> # surveys.
> # Values for measure could be "number" for 'raw' values or
> # "freq" for frequencies/counts.
> # Values for unit could be "n" for 'numbers' and
> # "%" for percentages.
> d_test <- data.frame(
>     group = rep(c("Universe", "Respondents"), each = 16),
>     variable = rep("State", 32),
>     value = rep(c(11.3,
>                     12.7,
>                     3.3,
>                     5,
>                     0.6,
>                     8.1,
>                     6.2,
>                     5.8,
>                     6.4,
>                     14.5,
>                     8.3,
>                     0.3,
>                     3.8,
>                     2.5,
>                     8.1,
>                     3), 2),
>     label = rep(c("Baden-Wuerttemberg",
>                 "Bayern",
>                 "Berlin",
>                 "Brandenburg",
>                 "Bremen",
>                 "Hamburg",
>                 "Hessen",
>                 "Mecklenburg-Vorpommern",
>                 "Niedersachsen",
>                 "Nordrhein-Westfalen",
>                 "Rheinland-Pfalz",
>                 "Saarland",
>                 "Sachsen",
>                 "Sachsen-Anhalt",
>                 "Schleswig-Holstein",
>                 "Thueringen"),2),
>     measure = rep("freq", 32),
>     unit = rep("%", 32),
>     stringsAsFactors = FALSE
> )
>
> # This way the variables can be selected using simple
> # value selection from Base R functionality.
> data <- d_test[d_test$variable == "State" ,]
>
> # And plot results for every variable.
> ggplot(
>   data = data,
>   aes(
>     x = label,
>     y = value,
>     fill = group)) +
>   geom_bar(stat = "identity", position = "dodge") +
>   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
>   scale_fill_discrete(name = stringi::stri_trans_totitle(names(data)[1]))
> +
>   scale_x_discrete(name = data$variable[1]) +
>   scale_y_discrete(name = data$unit[1])
>
> -- cut --
>
> The reporting / presentation is done in R Markdown. I would load the
> result data set once at the beginning and running the comparisons as plots
> on each variable named in the results data set under "variable".
>
> If I follow this approach for my customer relationship survey, do think I
> would face drawbacks or run into serious trouble?
>
> I am interested in your opinion and open for other approaches and
> suggestions.
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Wed Mar  8 17:55:06 2017
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 8 Mar 2017 11:55:06 -0500
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
	<F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
Message-ID: <CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>

Thank you. I was just curious what sort=FALSE had no impact.
Wondering what it is there for then...

On Wed, Mar 8, 2017 at 11:43 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Merging is not necessarily an order-preserving operation, but sorting can make the operation more efficient. The sort=TRUE argument forces the result to be sorted, but sort=FALSE is in not a promise that order will be preserved. (I think the imperfect sorting occurs when there are multiple keys but am not sure.) You can add columns to the input data that let you restore some semblance of the original ordering afterward, or you can roll your own possibly-less-efficient merge using match and indexing:
>
> info[ match( grades2$grade, info$grade ), ]
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>Hello!
>>I have a vector 'grades' and a data frame 'info':
>>
>>grades2 <- data.frame(grade = c(1,2,2,3,1))
>>info <- data.frame(
>>  grade = 3:1,
>>  desc = c("Excellent", "Good", "Poor"),
>>  fail = c(F, F, T)
>>)
>>
>>I want to get the info for all grades I have in info:
>>
>>This solution resorts everything in the order of column 'grade':
>>merge(grades2, info, by = "grade", all.x = T, all.y = F)
>>
>>Could you please explain why this solution also resorts - despite sort
>>= FALSE?
>>merge(grades2, info, by = "grade", all.x = T, all.y = F, sort = FALSE)
>>
>>Thanks a lot!



-- 
Dimitri Liakhovitski


From jdnewmil at dcn.davis.ca.us  Wed Mar  8 17:55:26 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Mar 2017 08:55:26 -0800
Subject: [R] Approach for Storing Result Data
In-Reply-To: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>
References: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>
Message-ID: <E56F0397-66A0-415A-BDAC-6B3897ACD31E@dcn.davis.ca.us>

Seems pretty normal except that your one-by-one lookup process usually gets old eventually, and comparing results is much easier if you merge the study data with the lookup data all at once and then use aggregate() (or any of numerous equivalents from contributed packages) to collect results or color/linetype/panel/etc plotted graphical presentations with lattice or ggplot2.
-- 
Sent from my phone. Please excuse my brevity.

On March 8, 2017 7:27:08 AM PST, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>today I have a more general question concerning the approach of storing
>
>different values from the analysis of multiple variables.
>
>My task is to compare distributions in a universe with distributions
>from 
>the respondents using a whole bunch of variables. Comparison shall be
>done 
>on relative frequencies (proportions).
>
>I was thinking about the structure I should store the results in and
>came 
>up with the following:
>
>-- cut --
>
>library(stringi)
>
># Result data frame
># Some sort of tidytidy data set where
># each value is stored as an identity.
># This way all values for all variables could be stored in
># one unique data structure.
># If an additional variable added for the name of the
># research one could also build result data set across
># surveys.
># Values for measure could be "number" for 'raw' values or
># "freq" for frequencies/counts.
># Values for unit could be "n" for 'numbers' and
># "%" for percentages.
>d_test <- data.frame(
>    group = rep(c("Universe", "Respondents"), each = 16),
>    variable = rep("State", 32),
>    value = rep(c(11.3,
>                    12.7,
>                    3.3,
>                    5,
>                    0.6,
>                    8.1,
>                    6.2,
>                    5.8,
>                    6.4,
>                    14.5,
>                    8.3,
>                    0.3,
>                    3.8,
>                    2.5,
>                    8.1,
>                    3), 2),
>    label = rep(c("Baden-Wuerttemberg",
>                "Bayern",
>                "Berlin",
>                "Brandenburg",
>                "Bremen",
>                "Hamburg",
>                "Hessen",
>                "Mecklenburg-Vorpommern",
>                "Niedersachsen",
>                "Nordrhein-Westfalen",
>                "Rheinland-Pfalz",
>                "Saarland",
>                "Sachsen",
>                "Sachsen-Anhalt",
>                "Schleswig-Holstein",
>                "Thueringen"),2),
>    measure = rep("freq", 32),
>    unit = rep("%", 32),
>    stringsAsFactors = FALSE
>)
>
># This way the variables can be selected using simple
># value selection from Base R functionality.
>data <- d_test[d_test$variable == "State" ,]
>
># And plot results for every variable.
>ggplot(
>  data = data,
>  aes(
>    x = label,
>    y = value,
>    fill = group)) +
>  geom_bar(stat = "identity", position = "dodge") +
>  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
>scale_fill_discrete(name = stringi::stri_trans_totitle(names(data)[1]))
>
>+
>  scale_x_discrete(name = data$variable[1]) +
>  scale_y_discrete(name = data$unit[1])
>
>-- cut --
>
>The reporting / presentation is done in R Markdown. I would load the 
>result data set once at the beginning and running the comparisons as
>plots 
>on each variable named in the results data set under "variable".
>
>If I follow this approach for my customer relationship survey, do think
>I 
>would face drawbacks or run into serious trouble?
>
>I am interested in your opinion and open for other approaches and 
>suggestions.
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar  8 18:51:51 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Mar 2017 09:51:51 -0800
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
	<F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
	<CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
Message-ID: <9EBB20FE-E623-4E68-99B6-CD32328EDCE4@dcn.davis.ca.us>

If you are still wondering, try re-reading my answer. FALSE is more efficient, TRUE is sorted. Lack of sorting has nothing to do with preserving order.
-- 
Sent from my phone. Please excuse my brevity.

On March 8, 2017 8:55:06 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>Thank you. I was just curious what sort=FALSE had no impact.
>Wondering what it is there for then...
>
>On Wed, Mar 8, 2017 at 11:43 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Merging is not necessarily an order-preserving operation, but sorting
>can make the operation more efficient. The sort=TRUE argument forces
>the result to be sorted, but sort=FALSE is in not a promise that order
>will be preserved. (I think the imperfect sorting occurs when there are
>multiple keys but am not sure.) You can add columns to the input data
>that let you restore some semblance of the original ordering afterward,
>or you can roll your own possibly-less-efficient merge using match and
>indexing:
>>
>> info[ match( grades2$grade, info$grade ), ]
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski
><dimitri.liakhovitski at gmail.com> wrote:
>>>Hello!
>>>I have a vector 'grades' and a data frame 'info':
>>>
>>>grades2 <- data.frame(grade = c(1,2,2,3,1))
>>>info <- data.frame(
>>>  grade = 3:1,
>>>  desc = c("Excellent", "Good", "Poor"),
>>>  fail = c(F, F, T)
>>>)
>>>
>>>I want to get the info for all grades I have in info:
>>>
>>>This solution resorts everything in the order of column 'grade':
>>>merge(grades2, info, by = "grade", all.x = T, all.y = F)
>>>
>>>Could you please explain why this solution also resorts - despite
>sort
>>>= FALSE?
>>>merge(grades2, info, by = "grade", all.x = T, all.y = F, sort =
>FALSE)
>>>
>>>Thanks a lot!


From ruipbarradas at sapo.pt  Wed Mar  8 18:52:30 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 08 Mar 2017 17:52:30 +0000
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>	<F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
	<CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
Message-ID: <58C044DE.4020209@sapo.pt>

Hello,

If you need to preserve the order you can do it like this.

inx <- order(grades2$grade)
result <- merge(grades2, info, by = "grade", all.x = T, all.y = F, sort 
= FALSE)
result[order(inx), ]

Hope this helps,

Rui Barradas

Em 08-03-2017 16:55, Dimitri Liakhovitski escreveu:
> Thank you. I was just curious what sort=FALSE had no impact.
> Wondering what it is there for then...
>
> On Wed, Mar 8, 2017 at 11:43 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Merging is not necessarily an order-preserving operation, but sorting can make the operation more efficient. The sort=TRUE argument forces the result to be sorted, but sort=FALSE is in not a promise that order will be preserved. (I think the imperfect sorting occurs when there are multiple keys but am not sure.) You can add columns to the input data that let you restore some semblance of the original ordering afterward, or you can roll your own possibly-less-efficient merge using match and indexing:
>>
>> info[ match( grades2$grade, info$grade ), ]
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>> Hello!
>>> I have a vector 'grades' and a data frame 'info':
>>>
>>> grades2 <- data.frame(grade = c(1,2,2,3,1))
>>> info <- data.frame(
>>>   grade = 3:1,
>>>   desc = c("Excellent", "Good", "Poor"),
>>>   fail = c(F, F, T)
>>> )
>>>
>>> I want to get the info for all grades I have in info:
>>>
>>> This solution resorts everything in the order of column 'grade':
>>> merge(grades2, info, by = "grade", all.x = T, all.y = F)
>>>
>>> Could you please explain why this solution also resorts - despite sort
>>> = FALSE?
>>> merge(grades2, info, by = "grade", all.x = T, all.y = F, sort = FALSE)
>>>
>>> Thanks a lot!
>
>
>


From dimitri.liakhovitski at gmail.com  Wed Mar  8 19:45:23 2017
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 8 Mar 2017 13:45:23 -0500
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <9EBB20FE-E623-4E68-99B6-CD32328EDCE4@dcn.davis.ca.us>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
	<F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
	<CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
	<9EBB20FE-E623-4E68-99B6-CD32328EDCE4@dcn.davis.ca.us>
Message-ID: <CAN2xGJYCe42Gz8UO3FsZ1LLc=JdWSmafb1jAn5usRXRB6_qdAg@mail.gmail.com>

I understood your answer.
The point is that sort = TRUE that doesn't sort is plain confusing.
Instead, the option should have been something like efficient = TRUE
or FALSE. At least then no one would stupidly expect sort = TRUE to
sort and sort = FALSE to NOT sort.

On Wed, Mar 8, 2017 at 12:51 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> If you are still wondering, try re-reading my answer. FALSE is more efficient, TRUE is sorted. Lack of sorting has nothing to do with preserving order.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 8, 2017 8:55:06 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>Thank you. I was just curious what sort=FALSE had no impact.
>>Wondering what it is there for then...
>>
>>On Wed, Mar 8, 2017 at 11:43 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Merging is not necessarily an order-preserving operation, but sorting
>>can make the operation more efficient. The sort=TRUE argument forces
>>the result to be sorted, but sort=FALSE is in not a promise that order
>>will be preserved. (I think the imperfect sorting occurs when there are
>>multiple keys but am not sure.) You can add columns to the input data
>>that let you restore some semblance of the original ordering afterward,
>>or you can roll your own possibly-less-efficient merge using match and
>>indexing:
>>>
>>> info[ match( grades2$grade, info$grade ), ]
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski
>><dimitri.liakhovitski at gmail.com> wrote:
>>>>Hello!
>>>>I have a vector 'grades' and a data frame 'info':
>>>>
>>>>grades2 <- data.frame(grade = c(1,2,2,3,1))
>>>>info <- data.frame(
>>>>  grade = 3:1,
>>>>  desc = c("Excellent", "Good", "Poor"),
>>>>  fail = c(F, F, T)
>>>>)
>>>>
>>>>I want to get the info for all grades I have in info:
>>>>
>>>>This solution resorts everything in the order of column 'grade':
>>>>merge(grades2, info, by = "grade", all.x = T, all.y = F)
>>>>
>>>>Could you please explain why this solution also resorts - despite
>>sort
>>>>= FALSE?
>>>>merge(grades2, info, by = "grade", all.x = T, all.y = F, sort =
>>FALSE)
>>>>
>>>>Thanks a lot!



-- 
Dimitri Liakhovitski


From chrishold at psyctc.org  Wed Mar  8 23:28:00 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Wed, 8 Mar 2017 22:28:00 +0000 (GMT)
Subject: [R] Has anyone created diagrammatic representations of
 Access/ODBC databases using R?
In-Reply-To: <4178b8e1-f09c-c7e1-8d9e-8ea4ca981675@stat.auckland.ac.nz>
References: <163641910.7090758.1488983824901.JavaMail.zimbra@psyctc.org>
	<4178b8e1-f09c-c7e1-8d9e-8ea4ca981675@stat.auckland.ac.nz>
Message-ID: <1433490969.7205603.1489012080472.JavaMail.zimbra@psyctc.org>

Many thanks Paul, 

That looks very good and certainly the end result is absolutely along the lines I was hoping to find.  I will read that article thoroughly and it will clearly teach me a lot about the graphics you used there.  

I was really hoping that someone might have wrapped something like that up to create some higher level functions that might do that sort of thing _and_, (perhaps someone else!), might have written some things that collect information about Access database structures, and/or the connectedness of data frames created with merge statements that would generate the information in a form that lends itself.

I know I'm dreaming of the stars but, as you're showing, there are stellar people using R and it struck me that others might have had similar dreams and perhaps had put code together they might be willing to share!

Very best to you, and to all r-helpers!

Chris

----- Original Message -----
> From: "Paul Murrell" <paul at stat.auckland.ac.nz>
> To: "Chris Evans" <chrishold at psyctc.org>
> Sent: Wednesday, 8 March, 2017 19:34:25
> Subject: Re: [R] Has anyone created diagrammatic representations of Access/ODBC databases using R?

> Hi
> 
> Do you mean something like this ... ?
> 
> https://www.stat.auckland.ac.nz/~paul/R/Diagram/diagram.pdf
> 
> Paul
> 
> On 09/03/17 03:37, Chris Evans wrote:
>> I have been on a fair old learning curve handling a fairly complex
>> Access database with my beloved, if sometimes tantaslising, R. I've
>> been using RODBC to do this and, despite the database not being all
>> that well designed, the power of R and RODBC has been fantastic (of
>> course). Huge thanks to R team and the RODBC team.
>>
>> Now I'd really like to generate some diagrammatic representations of
>> the data structure: entity relationship models, UML representation
>> ... anything like that would be wonderful. I can see three ways of
>> approaching this and any one, two or three would be a huge help for
>> me: 1) something that reads the tables and any queries from an Access
>> DB through RODBC and generates a map of them where the queries
>> indicate the relationships between the tables 2) something that reads
>> through the global environment and any merge() commands in my code to
>> see and map the data frames and how one was created by merges of
>> others 3) something that I use to spell out the structure textually
>> and it takes this and maps it.
>>
>> I have done some searching around with Rseek and raw google and found
>> two things. My #3 above is done by the CityPlot package but the mix
>> of CSV and text files used to create the maps looks tough to learn. I
>> suspect I ought to be able to use the package data.tree to do
>> something along the lines I want and perhaps more easily than by
>> learning the data structures behind CityPlot. Those are the only
>> things I've found However, both those options look like learning
>> curves that will take me time I can't justify for the plots. I'd love
>> to have the plots but I know I can get on with the real work without
>> them.
>>
>> However, it occurred to me that there may be someone on the list who
>> may already have done something like this and might be willing to
>> share their tools, tricks, experiences: hence this post!
>>
>> TIA,
>>
>>
>> Chris
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>>
> 
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From tmad109 at aucklanduni.ac.nz  Tue Mar  7 23:38:21 2017
From: tmad109 at aucklanduni.ac.nz (Thilini Maddegoda Vidanelage)
Date: Wed, 8 Mar 2017 11:38:21 +1300
Subject: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910
	COLUMNs)
In-Reply-To: <ac42fa400fd14ee1bed5b835b764f85d@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAPPUJ6yOWH2mteJsJDY=XC7WVek19FddtT53BBDBh=Czz9c-Fg@mail.gmail.com>
	<CA+8X3fW9XWcnTLcUPK8a6GOygsDoETML=nnY+xCxOC+c3YRJzg@mail.gmail.com>
	<ac42fa400fd14ee1bed5b835b764f85d@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAPPUJ6yYtOUCx=6Pys9U2bNZzQCNRY3h3zGP4++8GJODcyhZmA@mail.gmail.com>

Dear all,
Thank you very much for all of your inputs. I finally managed to get a
table with the percentages using R. I'm definitely going to invest more
time to learn R. Thank you again for taking your valuable time to answer my
question. Really appreciate it.


*Thilini Jayasinghe*
PhD Candidate
Liggins Institute
The University of Auckland
Building 503/201, 85 Park Road, Grafton, Auckland 2023
Mobile: +64 220211604
Email: tmad109 at aucklanduni.ac.nz

On 8 March 2017 at 02:41, David L Carlson <dcarlson at tamu.edu> wrote:

> If you read your data into R, it is simple to compute the percentages. Use
> Save As in Excel to save your data as a .csv (comma separated variables)
> file. Then use read.csv() to create a data frame in R as Jim indicated. Put
> it in the default directory that R is using (this depends on what operating
> system you are using). Then import the file with
>
> raw_data <- read.csv("YourData.csv")
>
> You may need to add some arguments in read.csv() depending on if you have
> column headings or not. Blank fields in Excel will be interpreted as
> missing values, not zeros, but you did not give us any of your data (even
> just the first 10, rows and columns) so it is impossible to be more
> specific. Once you have the data frame (and have replaced the missing
> values with zeros if necessary), the process is simple:
>
> pct_data <- prop.table(as.matrix(raw_data), 2) * 100
>
> will produce a matrix with percentages down each column and store it as a
> matrix object (variable) called pct_data. R uses different methods to store
> different kinds of data. The read.csv() function creates a data frame which
> can handle a mixture of character and numeric data, but the prop.table()
> function only accepts a matrix of numeric data and returns a matrix of
> numeric data. The data you described is all numeric so it is easy to switch
> the data frame to a matrix (and then back again if you want). If you are
> going to use R, you will need to spend some time reading about how it
> works, but as you can see, that time invested will make some operations
> much simpler than Excel and will allow you to conduct analyses that Excel
> does not even attempt.
>
> You can get details on these three functions by running the following
> commands in R:
>
> ?read.csv
> ?prop.table
> ?as.matrix
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Tuesday, March 7, 2017 2:24 AM
> To: Thilini Maddegoda Vidanelage <tmad109 at aucklanduni.ac.nz>; r-help
> mailing list <r-help at r-project.org>
> Subject: Re: [R] FOR TAKING PERCENTAGES of OTUS in each column (n=2910
> COLUMNs)
>
> Hi Thilini,
> It is fairly simple in R once you have imported the data. Say you have
> a data frame obtained by exporting the Excel table to CSV and then
> importing it with "read.csv". I'm not sure whether you have a number
> in each cell or just a 0/1 absent/present value, but it may not
> matter. Assume the data frame is named "tjdf"
>
> for(column in 1:dim(tjdf)[2])
>  tjdf[,paste("pct",column,sep="")]<-100*tjdf[,column]/sum(tjdf[,column])
>
> Alternatively, you could create a new data frame with just the percentages.
>
> Jim
>
>
> On Tue, Mar 7, 2017 at 12:16 PM, Thilini Maddegoda Vidanelage
> <tmad109 at aucklanduni.ac.nz> wrote:
> > Hi,
> > I am analyzing a huge excel table with OTUs. In the table, I have 2910
> > columns and 365 rows.Each column represents one individual (n=2910). Rows
> > represent microbial species (n=365).
> > I have the total of all OTUs of microbial species under each column.
> Then I
> > need to get the percentages of each species in each individual.I started
> to
> > do this in excel but I have to repeat this for 2910 times which is going
> to
> > be very time-consuming.  I am sure there should be a smart way to do this
> > and just wondering whether there is any R script to do this.Any help is
> > much appreciated.
> > Many thanks, Thilini
> >
> > *Thilini Jayasinghe*
> > PhD Candidate
> > Liggins Institute
> > The University of Auckland
> > Building 503/201, 85 Park Road, Grafton, Auckland 2023
> > Mobile: +64 220211604
> > Email: tmad109 at aucklanduni.ac.nz
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From laomeng_3 at 163.com  Wed Mar  8 09:13:39 2017
From: laomeng_3 at 163.com (laomeng_3)
Date: Wed, 8 Mar 2017 16:13:39 +0800 (GMT+08:00)
Subject: [R] how to draw the confidence interval
In-Reply-To: <CA+8X3fVkPVxBqA6fGQLrA2oQ7RU0mbv07CWGaVX7_nf=udaqVA@mail.gmail.com>
References: <54672945.2521.15a980bc525.Coremail.laomeng_3@163.com>
	<CA+8X3fVkPVxBqA6fGQLrA2oQ7RU0mbv07CWGaVX7_nf=udaqVA@mail.gmail.com>
Message-ID: <35bf3829.f6d2.15aacfb11be.Coremail.laomeng_3@163.com>

thanks a lot.


????????



On 2017-03-06 18:19 , Jim Lemon Wrote:

Hi laomeng,
If you know how to plot the means and calculate the standard
deviations, perhaps look at the "dispersion" function in the plotrix
package.

Jim


On Sat, Mar 4, 2017 at 5:39 PM, laomeng_3 <laomeng_3 at 163.com> wrote:
> hi all
> I have a question about drawing the confidence interval .
>
> For instance,if I want to sample 100 times,and each time,the sample size is 10,and  the mean and sd is 15 and 1 respectively .I want to draw the 100 confidence intervals(as the attachment) .Which function should be used to draw the confidence interval ?
>
> Many thanks!
>
>
>
> ????????
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Wed Mar  8 15:14:25 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 8 Mar 2017 09:14:25 -0500
Subject: [R] Reverse the scoring of some Columns of a Data Set
Message-ID: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>

Dear All: goods morning

Is there is a way to reverse the scoring of the first three columns x1, x2,
and x3 and keep the original scores for the fourth column x4.


*Here is an example of the data set:*

x1 x2 x3 x4
2  5   4   4
1  1   1   6
1  2   1   6
2  3   2   4
1  2   1   6
1  3   1   6
2  2   2   5
2  1   1   6
2  2   4   5
5  5   2   1

I am expecting the output to be:
x1 x2 x3 x4
5  5   2   4
2  2   4   6
2  1   1   6
2  2   2   4
1  3   1   6
1  2   1   6
2  3   2   5
1  2   1   6
1  1   1   5
2  5   4   1



thank you very much for your help and support
abou
______________________
AbouEl-Makarim Aboueissa, PhD
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar  9 07:56:43 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Mar 2017 22:56:43 -0800
Subject: [R] Reverse the scoring of some Columns of a Data Set
In-Reply-To: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>
References: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>
Message-ID: <66C5F8EB-F4F7-42D3-B727-617E57A3E243@dcn.davis.ca.us>

Perhaps

dta <- cbind( dta[ rev( seq.int( nrow( dta ) ) ), 1:3 ], dta[ , 4, drop=FALSE ] )

?
-- 
Sent from my phone. Please excuse my brevity.

On March 8, 2017 6:14:25 AM PST, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
>Dear All: goods morning
>
>Is there is a way to reverse the scoring of the first three columns x1,
>x2,
>and x3 and keep the original scores for the fourth column x4.
>
>
>*Here is an example of the data set:*
>
>x1 x2 x3 x4
>2  5   4   4
>1  1   1   6
>1  2   1   6
>2  3   2   4
>1  2   1   6
>1  3   1   6
>2  2   2   5
>2  1   1   6
>2  2   4   5
>5  5   2   1
>
>I am expecting the output to be:
>x1 x2 x3 x4
>5  5   2   4
>2  2   4   6
>2  1   1   6
>2  2   2   4
>1  3   1   6
>1  2   1   6
>2  3   2   5
>1  2   1   6
>1  1   1   5
>2  5   4   1
>
>
>
>thank you very much for your help and support
>abou
>______________________
>AbouEl-Makarim Aboueissa, PhD
>Department of Mathematics and Statistics
>University of Southern Maine
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From djnordlund at gmail.com  Thu Mar  9 08:35:26 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Wed, 8 Mar 2017 23:35:26 -0800
Subject: [R] Reverse the scoring of some Columns of a Data Set
In-Reply-To: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>
References: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>
Message-ID: <86463c8f-c59e-f5f9-1867-d3cc4a3dd1aa@gmail.com>

On 3/8/2017 6:14 AM, AbouEl-Makarim Aboueissa wrote:
> Dear All: goods morning
> 
> Is there is a way to reverse the scoring of the first three columns x1, x2,
> and x3 and keep the original scores for the fourth column x4.
> 
> 
> *Here is an example of the data set:*
> 
> x1 x2 x3 x4
> 2  5   4   4
> 1  1   1   6
> 1  2   1   6
> 2  3   2   4
> 1  2   1   6
> 1  3   1   6
> 2  2   2   5
> 2  1   1   6
> 2  2   4   5
> 5  5   2   1
> 
> I am expecting the output to be:
> x1 x2 x3 x4
> 5  5   2   4
> 2  2   4   6
> 2  1   1   6
> 2  2   2   4
> 1  3   1   6
> 1  2   1   6
> 2  3   2   5
> 1  2   1   6
> 1  1   1   5
> 2  5   4   1
> 
> 
> 
> thank you very much for your help and support
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Department of Mathematics and Statistics
> University of Southern Maine
>

  If your data is in a data frame called df, you could do something like 
this:

df[,1:3] <- apply(df[,1:3], 2, function(x) x[length(x):1])


Hope this helps,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From G.Maubach at weinwolf.de  Thu Mar  9 10:02:56 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 9 Mar 2017 10:02:56 +0100
Subject: [R] Antwort: Re:  Approach for Storing Result Data
In-Reply-To: <CAGxFJbRPKo_iAprQKSEbP-YKDZj4CogqGP1viPVPo7rMkY02Ow@mail.gmail.com>
References: <OF0D4C999B.11DEE4EB-ONC12580DD.00541422-C12580DD.0054E1AF@lotus.hawesko.de>
	<CAGxFJbRPKo_iAprQKSEbP-YKDZj4CogqGP1viPVPo7rMkY02Ow@mail.gmail.com>
Message-ID: <OF55D2935B.B53B791F-ONC12580DE.00315A88-C12580DE.0031B54D@lotus.hawesko.de>

Hi Gunter,
Hi Jeff,
Hi Readers,

many thanks for your reply.

My questions seems to be a little off topic cause it is not about using 
the programming language itself but how to use it in a analytics context. 
It is about processes and approaches of how to do things in R from a 
conception point of view. That is a subject I don't see in the community 
but would help me a lot to enhance my work.

Do you know I place where these things are discussed?

Kind regards

Georg



Von:    Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
An:     r-help at r-project.org, G.Maubach at weinwolf.de, 
Datum:  08.03.2017 17:54
Betreff:        Re: [R] Approach for Storing Result Data



Seems pretty normal except that your one-by-one lookup process usually 
gets old eventually, and comparing results is much easier if you merge the 
study data with the lookup data all at once and then use aggregate() (or 
any of numerous equivalents from contributed packages) to collect results 
or color/linetype/panel/etc plotted graphical presentations with lattice 
or ggplot2.



Von:    Bert Gunter <bgunter.4567 at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  R-help <r-help at r-project.org>
Datum:  08.03.2017 17:43
Betreff:        Re: [R] Approach for Storing Result Data



This does not appear to be a legitimate topic for r-help: it is are
not a consulting service. Please see the posting guide.

Of course, others may disagree and reply. Wouldn't be the first time I'm 
wrong.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 8, 2017 at 7:27 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> today I have a more general question concerning the approach of storing
> different values from the analysis of multiple variables.
>
> My task is to compare distributions in a universe with distributions 
from
> the respondents using a whole bunch of variables. Comparison shall be 
done
> on relative frequencies (proportions).
>
> I was thinking about the structure I should store the results in and 
came
> up with the following:
>
> -- cut --
>
> library(stringi)
>
> # Result data frame
> # Some sort of tidytidy data set where
> # each value is stored as an identity.
> # This way all values for all variables could be stored in
> # one unique data structure.
> # If an additional variable added for the name of the
> # research one could also build result data set across
> # surveys.
> # Values for measure could be "number" for 'raw' values or
> # "freq" for frequencies/counts.
> # Values for unit could be "n" for 'numbers' and
> # "%" for percentages.
> d_test <- data.frame(
>     group = rep(c("Universe", "Respondents"), each = 16),
>     variable = rep("State", 32),
>     value = rep(c(11.3,
>                     12.7,
>                     3.3,
>                     5,
>                     0.6,
>                     8.1,
>                     6.2,
>                     5.8,
>                     6.4,
>                     14.5,
>                     8.3,
>                     0.3,
>                     3.8,
>                     2.5,
>                     8.1,
>                     3), 2),
>     label = rep(c("Baden-Wuerttemberg",
>                 "Bayern",
>                 "Berlin",
>                 "Brandenburg",
>                 "Bremen",
>                 "Hamburg",
>                 "Hessen",
>                 "Mecklenburg-Vorpommern",
>                 "Niedersachsen",
>                 "Nordrhein-Westfalen",
>                 "Rheinland-Pfalz",
>                 "Saarland",
>                 "Sachsen",
>                 "Sachsen-Anhalt",
>                 "Schleswig-Holstein",
>                 "Thueringen"),2),
>     measure = rep("freq", 32),
>     unit = rep("%", 32),
>     stringsAsFactors = FALSE
> )
>
> # This way the variables can be selected using simple
> # value selection from Base R functionality.
> data <- d_test[d_test$variable == "State" ,]
>
> # And plot results for every variable.
> ggplot(
>   data = data,
>   aes(
>     x = label,
>     y = value,
>     fill = group)) +
>   geom_bar(stat = "identity", position = "dodge") +
>   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
>   scale_fill_discrete(name = 
stringi::stri_trans_totitle(names(data)[1]))
> +
>   scale_x_discrete(name = data$variable[1]) +
>   scale_y_discrete(name = data$unit[1])
>
> -- cut --
>
> The reporting / presentation is done in R Markdown. I would load the
> result data set once at the beginning and running the comparisons as 
plots
> on each variable named in the results data set under "variable".
>
> If I follow this approach for my customer relationship survey, do think 
I
> would face drawbacks or run into serious trouble?
>
> I am interested in your opinion and open for other approaches and
> suggestions.
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nilesh.dighe at monsanto.com  Thu Mar  9 13:46:33 2017
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Thu, 9 Mar 2017 12:46:33 +0000
Subject: [R] Why is merge sorting even when sort = F?
In-Reply-To: <CAN2xGJYCe42Gz8UO3FsZ1LLc=JdWSmafb1jAn5usRXRB6_qdAg@mail.gmail.com>
References: <CAN2xGJbxgUF8kEngC03Z=-zrBP82BtjROt0k0F0KhYCd150LSA@mail.gmail.com>
	<F2A49145-C4A8-4114-87DE-8F98D237DA02@dcn.davis.ca.us>
	<CAN2xGJa39i_0pfD_sPpwQ1tYBPPgbZWo__gTf10-O5BzeexYcA@mail.gmail.com>
	<9EBB20FE-E623-4E68-99B6-CD32328EDCE4@dcn.davis.ca.us>
	<CAN2xGJYCe42Gz8UO3FsZ1LLc=JdWSmafb1jAn5usRXRB6_qdAg@mail.gmail.com>
Message-ID: <24156952D190E841BF8E66CB59FAB94A533C62F5@STLWEXMBXPRD12.na.ds.monsanto.com>

Using the "join" function from the plyr package preserves the data order 
library(plyr)
join(grades2, info, by="grade", type="left", match="all")

Nilesh
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
Sent: Wednesday, March 08, 2017 12:45 PM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] Why is merge sorting even when sort = F?

I understood your answer.
The point is that sort = TRUE that doesn't sort is plain confusing.
Instead, the option should have been something like efficient = TRUE or FALSE. At least then no one would stupidly expect sort = TRUE to sort and sort = FALSE to NOT sort.

On Wed, Mar 8, 2017 at 12:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> If you are still wondering, try re-reading my answer. FALSE is more efficient, TRUE is sorted. Lack of sorting has nothing to do with preserving order.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 8, 2017 8:55:06 AM PST, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>Thank you. I was just curious what sort=FALSE had no impact.
>>Wondering what it is there for then...
>>
>>On Wed, Mar 8, 2017 at 11:43 AM, Jeff Newmiller 
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Merging is not necessarily an order-preserving operation, but 
>>> sorting
>>can make the operation more efficient. The sort=TRUE argument forces 
>>the result to be sorted, but sort=FALSE is in not a promise that order 
>>will be preserved. (I think the imperfect sorting occurs when there 
>>are multiple keys but am not sure.) You can add columns to the input 
>>data that let you restore some semblance of the original ordering 
>>afterward, or you can roll your own possibly-less-efficient merge 
>>using match and
>>indexing:
>>>
>>> info[ match( grades2$grade, info$grade ), ]
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 8, 2017 8:07:27 AM PST, Dimitri Liakhovitski
>><dimitri.liakhovitski at gmail.com> wrote:
>>>>Hello!
>>>>I have a vector 'grades' and a data frame 'info':
>>>>
>>>>grades2 <- data.frame(grade = c(1,2,2,3,1)) info <- data.frame(
>>>>  grade = 3:1,
>>>>  desc = c("Excellent", "Good", "Poor"),
>>>>  fail = c(F, F, T)
>>>>)
>>>>
>>>>I want to get the info for all grades I have in info:
>>>>
>>>>This solution resorts everything in the order of column 'grade':
>>>>merge(grades2, info, by = "grade", all.x = T, all.y = F)
>>>>
>>>>Could you please explain why this solution also resorts - despite
>>sort
>>>>= FALSE?
>>>>merge(grades2, info, by = "grade", all.x = T, all.y = F, sort =
>>FALSE)
>>>>
>>>>Thanks a lot!



--
Dimitri Liakhovitski

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
This email and any attachments were sent from a Monsanto email account and may contain confidential and/or privileged information. If you are not the intended recipient, please contact the sender and delete this email and any attachments immediately. Any unauthorized use, including disclosing, printing, storing, copying or distributing this email, is prohibited. All emails and attachments sent to or from Monsanto email accounts may be subject to monitoring, reading, and archiving by Monsanto, including its affiliates and subsidiaries, as permitted by applicable law. Thank you.


From paulbernal07 at gmail.com  Thu Mar  9 16:48:29 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 9 Mar 2017 10:48:29 -0500
Subject: [R] Unable to Load package Rcmdr after installation
Message-ID: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>

Hello friends,

Has anyone experienced trouble when trying to load package Rcmdr? It was
working perfectly a couple of days ago, I don?t know why it isn?t working.

> library("Rcmdr")
Loading required package: splines
Loading required package: RcmdrMisc
Loading required package: car
Loading required package: sandwich
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?Hmisc?
Error: package ?RcmdrMisc? could not be loaded

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Mar  9 17:11:05 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 09 Mar 2017 16:11:05 +0000
Subject: [R] Unable to Load package Rcmdr after installation
In-Reply-To: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
References: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
Message-ID: <CAKVAULOdziKccH6z5MfvgbYdXQHfsV7h_+UP-wP4X-yoZRkZ+A@mail.gmail.com>

Hi Paul,

The error tells you, that the 'Hmisc' does not exist on your system. If you
install it, everything should work.

Use install.packages with dependencies = TRUE to avoid the problem of
missing packages.

HTH

Ulrik

On Thu, 9 Mar 2017 at 16:51 Paul Bernal <paulbernal07 at gmail.com> wrote:

Hello friends,

Has anyone experienced trouble when trying to load package Rcmdr? It was
working perfectly a couple of days ago, I don?t know why it isn?t working.

> library("Rcmdr")
Loading required package: splines
Loading required package: RcmdrMisc
Loading required package: car
Loading required package: sandwich
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?Hmisc?
Error: package ?RcmdrMisc? could not be loaded

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rotondor123 at hotmail.gr  Thu Mar  9 11:34:40 2017
From: rotondor123 at hotmail.gr (Dimitrios Mousenikas)
Date: Thu, 9 Mar 2017 10:34:40 +0000
Subject: [R] Problem with greek characters in R
Message-ID: <DB6P194MB013483532F6DEF49A6A95E349A210@DB6P194MB0134.EURP194.PROD.OUTLOOK.COM>

Hello,

My computer functions with the version of English windows 10. The problem that I face is that when I open an R file that includes Greek characters, with the program RGui, the text that appears does not make sense. The only way the problem can be solved is by setting Greek as a default language in Windows. Although I prefer as a default language English. 
I am looking forward for your response. 

Thank you in advance
Dimitrios Mousenikas


From jdnewmil at dcn.davis.ca.us  Thu Mar  9 17:33:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 09 Mar 2017 08:33:40 -0800
Subject: [R] Unable to Load package Rcmdr after installation
In-Reply-To: <CAKVAULOdziKccH6z5MfvgbYdXQHfsV7h_+UP-wP4X-yoZRkZ+A@mail.gmail.com>
References: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
	<CAKVAULOdziKccH6z5MfvgbYdXQHfsV7h_+UP-wP4X-yoZRkZ+A@mail.gmail.com>
Message-ID: <4E75F452-73F8-46AD-8B5F-E24D77769BDB@dcn.davis.ca.us>

To the question of why it used to work but now it doesn't, I have noticed that often when I update packages with dependencies but some error occurs during the update, some existing packages that used to work are removed and must be re-installed manually. I have not tried to make a reproducible example but the pattern of breaking depencies has been noticeable for the last year or so. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2017 8:11:05 AM PST, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>Hi Paul,
>
>The error tells you, that the 'Hmisc' does not exist on your system. If
>you
>install it, everything should work.
>
>Use install.packages with dependencies = TRUE to avoid the problem of
>missing packages.
>
>HTH
>
>Ulrik
>
>On Thu, 9 Mar 2017 at 16:51 Paul Bernal <paulbernal07 at gmail.com> wrote:
>
>Hello friends,
>
>Has anyone experienced trouble when trying to load package Rcmdr? It
>was
>working perfectly a couple of days ago, I don?t know why it isn?t
>working.
>
>> library("Rcmdr")
>Loading required package: splines
>Loading required package: RcmdrMisc
>Loading required package: car
>Loading required package: sandwich
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>versionCheck
>= vI[[j]]) :
>  there is no package called ?Hmisc?
>Error: package ?RcmdrMisc? could not be loaded
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cri.alessandro at gmail.com  Thu Mar  9 17:37:03 2017
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Thu, 9 Mar 2017 10:37:03 -0600
Subject: [R]  modify additional parameters, glht and summary
Message-ID: <CAHhX7Wi9hiek2x_Brs-mBS+YgCROPQxYVi+G-tHn5YpyunHpKA@mail.gmail.com>

Hi all,

first of all, thanks a lot in advance for your help. I am running a
sequence of post-hoc tests with glht (mutcomp package), but the function
summary warns me that the algorithm ends with an error > abseps.

$ hr.ph <- glht(hr.lm, linfct = ph_conditional);
$ summary(hr.ph)

Warning messages:
1: In RET$pfunction("adjusted", ...) : Completion with error > abseps
2: In RET$pfunction("adjusted", ...) : Completion with error > abseps
3: In RET$pfunction("adjusted", ...) : Completion with error > abseps
4: In RET$pfunction("adjusted", ...) : Completion with error > abseps

I think it is a matter of modifying the parameters of the algorithm that
summary runs. Looking at the documentation, I could not find a way of
actually doing so. Do you have any suggestion? Also, how does one know the
default values of these algorithms?

Thanks a lot!

Cristiano

	[[alternative HTML version deleted]]


From dominic.schuhmacher at mathematik.uni-goettingen.de  Thu Mar  9 17:44:27 2017
From: dominic.schuhmacher at mathematik.uni-goettingen.de (Schuhmacher, Dominic)
Date: Thu, 9 Mar 2017 16:44:27 +0000
Subject: [R] Transport and Earth Mover's Distance
In-Reply-To: <312DC63A-779E-4059-BC29-FFBB38440916@mathematik.uni-goettingen.de>
References: <20170307122932.GA2604@chicca2>
	<74667735-11AE-405E-9F88-071AEF7E7F98@mathematik.uni-goettingen.de>
	<20170307153204.GE2604@chicca2>
	<312DC63A-779E-4059-BC29-FFBB38440916@mathematik.uni-goettingen.de>
Message-ID: <0B026558-BDC0-425F-B7B0-D621FDC78AE0@mathematik.uni-goettingen.de>


> Am 08.03.2017 um 11:28 schrieb Schuhmacher, Dominic <dominic.schuhmacher at mathematik.uni-goettingen.de>:
> 
> ...
>>> 
>>> If you have no particular need for binning, check out the function
>>> pppdist in the R-package spatstat, which offers a more flexible way
>>> to deal with point patterns of different size.
>> 
>> 
>> Well, this is not clear, but possibly very important for me.
>> My raw data consists of 2 univariate samples of unequal length.
>> 
>> suppose that
>> 
>> x<-rnorm(100)
>> 
>> and
>> 
>> y<-rnorm(90)
>> 
>> Is there a way to define the Wasserstein distance between them without
>> going through the binning procedure?
>> 
> Define, yes: the 1-Wasserstein distance in one-dimension is the area between the empirical cumulative distribution functions. If the samples had the same lengths this could be directly computed by
> 
> mean(abs(sort(x)-sort(y)))
> 
> Otherwise this needs some lines of code. I will include it in the next version of the transport package (soon).
> 
> Best regards,
> Dominic
> 
> 
Following up on this earlier post: transport 0.8-2, which is on CRAN now, offers the possibility to compute the Wasserstein distance between univariate samples of differing lengths (more precisely their empirical distributions).

library(transport)
x <- rnorm(100)
y <- rnorm(90)
wasserstein1d(x,y) 

Cheers, Dominic


------------------------------------
Dominic Schuhmacher
Professor of Stochastics
University of Goettingen
http://www.dominic.schuhmacher.name


From jdnewmil at dcn.davis.ca.us  Thu Mar  9 17:48:47 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 09 Mar 2017 08:48:47 -0800
Subject: [R] Problem with greek characters in R
In-Reply-To: <DB6P194MB013483532F6DEF49A6A95E349A210@DB6P194MB0134.EURP194.PROD.OUTLOOK.COM>
References: <DB6P194MB013483532F6DEF49A6A95E349A210@DB6P194MB0134.EURP194.PROD.OUTLOOK.COM>
Message-ID: <0F7DC231-B6F4-4FDD-A9F4-E3B1EAC1414B@dcn.davis.ca.us>

The standard response is that RStudio is not R, and has its own forum or discussion areas on stackexchange.com. R has its own mechanisms for dealing with alternate character sets, so be clear when the problem is in the processing of such code by R versus the display of input or output files associated with your use of R. Using R or RGui (that are on topic here) can help you discern where the "problem" is. 

That said, Googling "RStudio character encoding" might lead to help with your immediate concern. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2017 2:34:40 AM PST, Dimitrios Mousenikas <rotondor123 at hotmail.gr> wrote:
>Hello,
>
>My computer functions with the version of English windows 10. The
>problem that I face is that when I open an R file that includes Greek
>characters, with the program RGui, the text that appears does not make
>sense. The only way the problem can be solved is by setting Greek as a
>default language in Windows. Although I prefer as a default language
>English. 
>I am looking forward for your response. 
>
>Thank you in advance
>Dimitrios Mousenikas
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Thu Mar  9 17:58:05 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 9 Mar 2017 16:58:05 +0000
Subject: [R] Reverse the scoring of some Columns of a Data Set
In-Reply-To: <86463c8f-c59e-f5f9-1867-d3cc4a3dd1aa@gmail.com>
References: <CAE9stmegLZB1f+OQtbVDFFQfE6ueXR1ezpi2EYkm5yXGkiQqUg@mail.gmail.com>
	<86463c8f-c59e-f5f9-1867-d3cc4a3dd1aa@gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E95E6D@WAXMXOLYMB025.WAX.wa.lcl>

Another alternative (which didn't work last night when I was tired and obviously doing something wrong) is to use the built-in function, rev():

df[,1:3] <- apply(df[,1:3], 2, rev)


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
> Nordlund
> Sent: Wednesday, March 08, 2017 11:35 PM
> To: AbouEl-Makarim Aboueissa; r-help at r-project.org
> Subject: Re: [R] Reverse the scoring of some Columns of a Data Set
> 
> On 3/8/2017 6:14 AM, AbouEl-Makarim Aboueissa wrote:
> > Dear All: goods morning
> >
> > Is there is a way to reverse the scoring of the first three columns
> x1, x2,
> > and x3 and keep the original scores for the fourth column x4.
> >
> >
> > *Here is an example of the data set:*
> >
> > x1 x2 x3 x4
> > 2  5   4   4
> > 1  1   1   6
> > 1  2   1   6
> > 2  3   2   4
> > 1  2   1   6
> > 1  3   1   6
> > 2  2   2   5
> > 2  1   1   6
> > 2  2   4   5
> > 5  5   2   1
> >
> > I am expecting the output to be:
> > x1 x2 x3 x4
> > 5  5   2   4
> > 2  2   4   6
> > 2  1   1   6
> > 2  2   2   4
> > 1  3   1   6
> > 1  2   1   6
> > 2  3   2   5
> > 1  2   1   6
> > 1  1   1   5
> > 2  5   4   1
> >
> >
> >
> > thank you very much for your help and support
> > abou
> > ______________________
> > AbouEl-Makarim Aboueissa, PhD
> > Department of Mathematics and Statistics
> > University of Southern Maine
> >
> 
>   If your data is in a data frame called df, you could do something like
> this:
> 
> df[,1:3] <- apply(df[,1:3], 2, function(x) x[length(x):1])
> 
> 
> Hope this helps,
> 
> Dan
> 
> --
> Daniel Nordlund
> Port Townsend, WA  USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Mar  9 19:13:01 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 9 Mar 2017 13:13:01 -0500
Subject: [R] Problem with greek characters in R
In-Reply-To: <0F7DC231-B6F4-4FDD-A9F4-E3B1EAC1414B@dcn.davis.ca.us>
References: <DB6P194MB013483532F6DEF49A6A95E349A210@DB6P194MB0134.EURP194.PROD.OUTLOOK.COM>
	<0F7DC231-B6F4-4FDD-A9F4-E3B1EAC1414B@dcn.davis.ca.us>
Message-ID: <CA+vqiLH7YpioNoWU39Cu5YVgx9SGZFM1BLMBMc9AJjmN+xPd1w@mail.gmail.com>

On Thu, Mar 9, 2017 at 11:48 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The standard response is that RStudio is not R, and has its own forum or discussion areas on stackexchange.com.

But the OP didn't mention RStudio, but rather RGui.

R has its own mechanisms for dealing with alternate character sets, so
be clear when the problem is in the processing of such code by R
versus the display of input or output files associated with your use
of R. Using R or RGui (that are on topic here) can help you discern
where the "problem" is.

Perhaps you can offer some advice in this regard, I've never been able
to figure it out. Ironically, that's one of the reasons I prefer to
use RStudio on Windows!

Best,
Ista

>
> That said, Googling "RStudio character encoding" might lead to help with your immediate concern.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 9, 2017 2:34:40 AM PST, Dimitrios Mousenikas <rotondor123 at hotmail.gr> wrote:
>>Hello,
>>
>>My computer functions with the version of English windows 10. The
>>problem that I face is that when I open an R file that includes Greek
>>characters, with the program RGui, the text that appears does not make
>>sense. The only way the problem can be solved is by setting Greek as a
>>default language in Windows. Although I prefer as a default language
>>English.
>>I am looking forward for your response.
>>
>>Thank you in advance
>>Dimitrios Mousenikas
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Thu Mar  9 20:11:05 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 9 Mar 2017 19:11:05 +0000
Subject: [R] Problem with greek characters in R
In-Reply-To: <CA+vqiLH7YpioNoWU39Cu5YVgx9SGZFM1BLMBMc9AJjmN+xPd1w@mail.gmail.com>
References: <DB6P194MB013483532F6DEF49A6A95E349A210@DB6P194MB0134.EURP194.PROD.OUTLOOK.COM>
	<0F7DC231-B6F4-4FDD-A9F4-E3B1EAC1414B@dcn.davis.ca.us>
	<CA+vqiLH7YpioNoWU39Cu5YVgx9SGZFM1BLMBMc9AJjmN+xPd1w@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E95F0E@WAXMXOLYMB025.WAX.wa.lcl>

Dimitrios,

You need to help us help you. You say you have a file that has Greek characters in it that you want to "open with the program RGui".
1. You need to provide us with a sample of the problem file.  Since we are talking about text here, you can create a file with just a few lines in it that contain the problematic text.  Give the file a '.txt' extension and then you can attach that to your next post to R-help.
2. What do mean by "open the file with RGui"?  Are you trying to source the file, or open it some other way?

If you provide some sample text, and describe in more detail what you are trying to do with it, someone may be able to offer a solution.


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


On March 9, 2017 2:34:40 AM PST, Dimitrios Mousenikas rotondor123 at hotmail.gr> wrote:
>Hello,
>
>My computer functions with the version of English windows 10. The
>problem that I face is that when I open an R file that includes Greek
>characters, with the program RGui, the text that appears does not make
>sense. The only way the problem can be solved is by setting Greek as a
>default language in Windows. Although I prefer as a default language
>English.
>I am looking forward for your response.
>
>Thank you in advance
>Dimitrios Mousenikas
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Scott.Waichler at pnnl.gov  Thu Mar  9 22:31:11 2017
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Thu, 9 Mar 2017 21:31:11 +0000
Subject: [R] how apply.monthly() in package xts works
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BA05011@EX10MBOX03.pnnl.gov>

Hi,  

I found that apply.monthly() in xts does not work as I expected in the case of a sparse timeseries:

my.dates <- as.Date(c("1992-06-01", "1992-06-24", "1992-06-30", "1993-06-22", "1994-06-07", "1995-06-08"))
my.xts <- xts(1:6, my.dates)
start(my.xts)  # "1992-06-24"
end(my.xts)  # "1995-06-08"
apply.monthly(my.xts, mean)
#           [,1]
# 1995-06-08 3.5

The endpoints it chooses are based on looking at the month (June) alone.  I was able to get a value for each (month, year) in the timeseries with the following use of aggregate():

my.months <- months(my.dates)
my.years <- years(my.dates)
df1 <- data.frame(x = coredata(my.xts), dates = my.dates, months = my.months, years = my.years)
df2 <- aggregate(df1[-c(3,4)], df1[c("months", "years")], mean)
xts(df2$x, df2$dates)
#            [,1]
# 1992-06-18    2
# 1993-06-22    4
# 1994-06-07    5
# 1995-06-08    6

Two questions:  
1) Is there a more elegant way to do this? 
2) Shouldn't the xts documentation discuss the problem of sparse data?

Regards,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA  USA


From josh.m.ulrich at gmail.com  Thu Mar  9 22:46:05 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 9 Mar 2017 15:46:05 -0600
Subject: [R] how apply.monthly() in package xts works
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BA05011@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BA05011@EX10MBOX03.pnnl.gov>
Message-ID: <CAPPM_gTnRJgTPn=1+StmMH4-5i3T1Dn4rgRBjchg9P1oedQieg@mail.gmail.com>

On Thu, Mar 9, 2017 at 3:31 PM, Waichler, Scott R
<Scott.Waichler at pnnl.gov> wrote:
> Hi,
>
> I found that apply.monthly() in xts does not work as I expected in the case of a sparse timeseries:
>
> my.dates <- as.Date(c("1992-06-01", "1992-06-24", "1992-06-30", "1993-06-22", "1994-06-07", "1995-06-08"))
> my.xts <- xts(1:6, my.dates)
> start(my.xts)  # "1992-06-24"
> end(my.xts)  # "1995-06-08"
> apply.monthly(my.xts, mean)
> #           [,1]
> # 1995-06-08 3.5
>
> The endpoints it chooses are based on looking at the month (June) alone.  I was able to get a value for each (month, year) in the timeseries with the following use of aggregate():
>
Thanks for the minimal, reproducible example!  This is clearly a bug.

> my.months <- months(my.dates)
> my.years <- years(my.dates)
> df1 <- data.frame(x = coredata(my.xts), dates = my.dates, months = my.months, years = my.years)
> df2 <- aggregate(df1[-c(3,4)], df1[c("months", "years")], mean)
> xts(df2$x, df2$dates)
> #            [,1]
> # 1992-06-18    2
> # 1993-06-22    4
> # 1994-06-07    5
> # 1995-06-08    6
>
> Two questions:
> 1) Is there a more elegant way to do this?

Create your own endpoints until endpoints() is fixed.  Here's a quick
hack, off the top of my head:

endpointsMonthHack <- function(x, on = "months", k = 1) {
  # yearmon index
  ymIndex <- as.yearmon(index(x))
  # month changes
  monthDiff <- c(0, diff(ymIndex))
  # locations in index
  locations <- which(monthDiff != 0)
  ep <- c(0, locations, nrow(x))
  unique(ep)
}

> 2) Shouldn't the xts documentation discuss the problem of sparse data?

No, because it shouldn't be a problem. :)

>
> Regards,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From josh.m.ulrich at gmail.com  Fri Mar 10 04:03:16 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 9 Mar 2017 21:03:16 -0600
Subject: [R] how apply.monthly() in package xts works
In-Reply-To: <CAPPM_gTnRJgTPn=1+StmMH4-5i3T1Dn4rgRBjchg9P1oedQieg@mail.gmail.com>
References: <074C83DAD4825242A20B2D83FDBCB8881BA05011@EX10MBOX03.pnnl.gov>
	<CAPPM_gTnRJgTPn=1+StmMH4-5i3T1Dn4rgRBjchg9P1oedQieg@mail.gmail.com>
Message-ID: <CAPPM_gSJjh=MEdB3n2bEOhVpZ3Z1jq-ri0YJ4MQRL7a8OJBh6g@mail.gmail.com>

On Thu, Mar 9, 2017 at 3:46 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Thu, Mar 9, 2017 at 3:31 PM, Waichler, Scott R
> <Scott.Waichler at pnnl.gov> wrote:
>> Hi,
>>
>> I found that apply.monthly() in xts does not work as I expected in the case of a sparse timeseries:
>>
>> my.dates <- as.Date(c("1992-06-01", "1992-06-24", "1992-06-30", "1993-06-22", "1994-06-07", "1995-06-08"))
>> my.xts <- xts(1:6, my.dates)
>> start(my.xts)  # "1992-06-24"
>> end(my.xts)  # "1995-06-08"
>> apply.monthly(my.xts, mean)
>> #           [,1]
>> # 1995-06-08 3.5
>>
>> The endpoints it chooses are based on looking at the month (June) alone.  I was able to get a value for each (month, year) in the timeseries with the following use of aggregate():
>>
> Thanks for the minimal, reproducible example!  This is clearly a bug.
>
Now formally documented as such:
https://github.com/joshuaulrich/xts/issues/169

>> my.months <- months(my.dates)
>> my.years <- years(my.dates)
>> df1 <- data.frame(x = coredata(my.xts), dates = my.dates, months = my.months, years = my.years)
>> df2 <- aggregate(df1[-c(3,4)], df1[c("months", "years")], mean)
>> xts(df2$x, df2$dates)
>> #            [,1]
>> # 1992-06-18    2
>> # 1993-06-22    4
>> # 1994-06-07    5
>> # 1995-06-08    6
>>
>> Two questions:
>> 1) Is there a more elegant way to do this?
>
> Create your own endpoints until endpoints() is fixed.  Here's a quick
> hack, off the top of my head:
>
> endpointsMonthHack <- function(x, on = "months", k = 1) {
>   # yearmon index
>   ymIndex <- as.yearmon(index(x))
>   # month changes
>   monthDiff <- c(0, diff(ymIndex))
>   # locations in index
>   locations <- which(monthDiff != 0)
>   ep <- c(0, locations, nrow(x))
>   unique(ep)
> }
>
The function above is wrong.  That's what I get for posting without
actually running the code.  Here's a function that's actually tested
(only on this example though):

endpointsMonthHack <- function(x, on = "months", k = 1) {
  # yearmon index
  ymIndex <- as.yearmon(index(x))
  # month change locations
  locations <- which(diff(ymIndex) != 0)
  # endpoints
  ep <- c(0, locations, nrow(x))
  unique(ep)
}


>> 2) Shouldn't the xts documentation discuss the problem of sparse data?
>
> No, because it shouldn't be a problem. :)
>
>>
>> Regards,
>> Scott Waichler
>> Pacific Northwest National Laboratory
>> Richland, WA  USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2017 | www.rinfinance.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From j.liu.31 at student.rug.nl  Thu Mar  9 22:10:00 2017
From: j.liu.31 at student.rug.nl (Liu, J.)
Date: Thu, 9 Mar 2017 22:10:00 +0100
Subject: [R] R2WinBUGS Error
Message-ID: <CADOR4-0=sFJgcAm_R+eX_+MkFojOUTjfKfCKWnuwKHsex3NnJA@mail.gmail.com>

Hi,

I'm trying to run R2WinBUGS using the R code below (Thinkpad Yoga 260,
Win8, system x86_64, mingw32, R version 3.3.1). It worked fine for several
times but then one error began to pop up in every run: command #Bugs:set
cannot be executed (is greyed out). I've been trying for more than one week
but still can't figure out where is the problem. It would be great if
someone could help me with this. Thanks in advance!

Kind regards,
JLiu

Here's the code:

sink("mod1.txt")
cat("
    model {

    for( k in 1 : n ) {
    for( i in 1 : n - 1 ) {
    for( j in i + 1 : n ) {
    y[k , i , j] ~ dbern(p[k , i , j])
    y[k , j , i] ~ dbern(p[k , j , i])
    logit(p[k , i , j]) <- mu + a[i] + b[j] + g[k] + ab[i , j] + ag[i , k]
+ ag[j , k]
    logit(p[k , j , i]) <- mu + a[j] + b[i] + g[k] + ab[j , i] + ag[j , k]
+ ag[i , k]
    }
    }
    }

    # Compute difference ab[1,2] - ab[2,1] for Figure 3 of the paper
    dif12 <- ab[1 , 2] - ab[2 , 1]

    # Prior for the overall mean effect mu
    mu ~ dnorm(0, 1)

    # Tri-normal prior for actor, partner, rater effects (a, b, g)
    # with zero-sum constraints
    for( i in 1 : n ) {
    a[i] <- a1[i , 1] - mean(a1[ , 1])
    b[i] <- a1[i , 2] - mean(a1[ , 2])
    g[i] <- a1[i , 3] - mean(a1[ , 3])

    # without zero-sum constraints will make the code run faster
    # for( i in 1 : n ) {
    # a[i] <- a1[i,1]
    # b[i] <- a1[i,2]
    # g[i] <- a1[i,3]

    a1[i , 1:3] ~ dmnorm(zero[1:3], S1[ , ])
    }

    # Wishart prior for precision matrix S1 = Sigma_1-inverse
    # degrees of freedom nu = 3
    # Om1 = nu*Identity Matrix is provided in the data list
    S1[1:3 , 1:3] ~ dwish(Om1[1:3 , 1:3], 3)
    Sig1[1:3 , 1:3] <- inverse(S1[1:3 , 1:3])

    # Compute the correlations and the variances for the main effects
    rho1 <- Sig1[1 , 2] / sqrt(Sig1[1 , 1] * Sig1[2 , 2])
    rho2 <- Sig1[1 , 3] / sqrt(Sig1[1 , 1] * Sig1[3 , 3])
    rho3 <- Sig1[2 , 3] / sqrt(Sig1[3 , 3] * Sig1[2 , 2])
    sig.a <- Sig1[1 , 1]
    sig.b <- Sig1[2 , 2]
    sig.g <- Sig1[3 , 3]

    # Standard deviation values are reported in the paper (Table 2)
    sd.a <- sqrt(sig.a)
    sd.b <- sqrt(sig.b)
    sd.g <- sqrt(sig.g)
    # A vector of zero's is needed for the mean values of some vectors
    for( i in 1 : 4 ) {
    zero[i] <- 0
    }

    # Priors for interaction effects ab_ij and ag_ij in equation (3) of the
paper
    for( i in 1 : n ) {
    # alpha_beta[i,i] is not defined in the model, just put  =0
    ab[i , i] <- 0

    # del[i] = personal bias of subject i in reporting his tendency to
establish friendship ties
    # The posterior distribution of del[i]'s is shown as boxplots in Figure
3 of the paper.
    # Side-by-side boxplots are created using Inference -> Compare menu in
WinBUGS

    del[i] <- ag[i , i] - ag.mean[i]
    ag.mean[i] <- (sum(ag[i , ]) - ag[i , i]) / (n - 1)
    ag[i , i] ~ dnorm(0, tau.ag)
    }

    # Generate 4 pair-wise interaction parameters as Normal_4 with
precision matrix S2
    for( i in 1 : n - 1 ) {
    for( j in i + 1 : n ) {
    ab[i , j] <- a2[i , j , 1]
    ab[j , i] <- a2[i , j , 2]
    ag[i , j] <- a2[i , j , 3]
    ag[j , i] <- a2[i , j , 4]
    a2[i , j , 1:4] ~ dmnorm(zero[1:4], S2[ , ])
    }
    }

    # Get the precision matrix of interaction parameters from the var-cov
matrix Sig_2 in the paper
    # Note that we don't use Inv-Wishart prior for this precision matrix
    S2[1:4 , 1:4] <- inverse(Sig2[1:4 , 1:4])

    # Now build the var-cov matrix Sig2 from variances and correlations
(phi's) in equation (7)

    phi1 ~ dunif(-0.99, 0.99)
    phi2 ~ dunif(-0.99, 0.99)
    phi3 ~ dunif(-0.99, 0.99)
    phi4 ~ dunif(-0.99, 0.99)

    # Compute two detrminants in equations (9-10) in the paper
    det1 <-  1 -  phi1 * phi1 - phi2 * phi2 - phi3 * phi3 + 2 * phi1 * phi2
* phi3
    det2 <-  1 -  phi1 * phi1 - 2 * phi2 * phi2 - 2 * phi3 * phi3 - phi4 *
phi4 + 4 * phi1 * phi2 * phi3
    + 4 * phi2 * phi3 * phi4 + phi1 * phi1 * phi4 * phi4 - 2 * phi2 * phi2
* phi3 * phi3
    - 2 * phi1 * phi3 * phi3 * phi4 - 2 * phi1 * phi2 * phi2 * phi4 + phi2
* phi2 * phi2 * phi2
    + phi3 * phi3 * phi3 * phi3

    # Check if determinants are positive
    cons1 <- step(det1)
    cons2 <- step(det2)

    # Zeros trick
    O1 <- 0
    O2 <- 0
    q1 <- 1 - cons1
    q2 <- 1 - cons2
    O1 ~ dbern(q1)
    O2 ~ dbern(q2)

    # Inverse Gamma priors for variance parameters sig.ab, sig.ag
    tau.ab ~ dgamma(100, 10)
    tau.ag ~ dgamma(100, 10)
    sig.ab <- 1 / tau.ab
    sig.ag <- 1 / tau.ag

    # Standard deviations sd.ab and sd.ag are reported in the paper (Table
2)
    sd.ab <- sqrt(sig.ab)
    sd.ag <- sqrt(sig.ag)
    Sig2[1 , 1] <- sig.ab
    Sig2[3 , 3] <- sig.ag
    Sig2[2 , 2] <- Sig2[1,1]
    Sig2[4 , 4] <- Sig2[3 , 3]

    # Create the off-diagonal entries of Sig2
    # If the generated set of phi1, phi2, phi3 and phi4 values don't have
both det1 > 0
    # and det2 > 0, the off-diagonal elements of Sig2 are all set equal to
zero
    Sig2[1,2] <- cons1*cons2*sig.ab*phi1
    Sig2[2 , 1] <- Sig2[1,2]
    Sig2[1 , 3] <- cons1*cons2*sqrt(sig.ab * sig.ag) * phi2
    Sig2[3 , 1] <- Sig2[1 , 3]
    Sig2[1 , 4] <- cons1*cons2*sqrt(sig.ab * sig.ag) * phi3
    Sig2[4 , 1] <- Sig2[1 , 4]
    Sig2[2 , 3] <- cons1*cons2*sqrt(sig.ab * sig.ag) * phi3
    Sig2[3 , 2] <- Sig2[2 , 3]
    Sig2[2 , 4] <- cons1*cons2*sqrt(sig.ab * sig.ag) * phi2
    Sig2[4 , 2] <-  Sig2[2 , 4]
    Sig2[3 , 4] <- cons1*cons2*sig.ag * phi4
    Sig2[4 , 3] <- Sig2[3 , 4]
    #############################################################

    # Predict the network for studying the model fit using residuals
    # for Model Selection (Section 3 of the paper)
    for( k in 1 : n ) {
    for( i in 1 : n - 1 ) {
    for( j in i + 1 : n ) {
    y.pred[k , i , j] ~ dbern(p[k , i , j])
    y.pred[k , j , i] ~ dbern(p[k , j , i])

    # How often we get wrong predictions? Compute residual e[k,i,j]
    e[k , i , j] <- abs(y[k , i , j] - y.pred[k , i , j])
    e[k , j , i] <- abs(y[k , j , i] - y.pred[k , j , i])
    }
    }
    }

    # Put diagonal residuals equal to zero. This is needed for computing
the sum() function
    for( k in 1 : n ) {
    for( i in 1 : n ) {
    e[k , i , i] <- 0
    }
    }
    # Compute epd = the total number of incorrect predictions, equation
(13) of the paper
    epd <- sum(e[,,])

    } # End of model


    ", fill = TRUE)
sink()

# read data as a whole three-dimension matrix
nr <- 21 # netowrk F
X <- "Kr"
network <- array(NA, dim=c(nr, nr, nr))
for(n in 1:nr){
  network[,,n] = as.matrix(read.table(paste0("C:/R/internship/network",X,
"/Sheet", n, ".txt")))
}

y = structure(.Data=network)
n = 21
Om1=structure(.Data=c(3,0,0,0,3,0,0,0,3), .Dim = c(3,3))
data = list(n=n, Om1=Om1, y=y)


params = c("mu", "a1", "S1", "Sig1", "a2", "S2", "sig2", "phi1", "phi2",
"phi3", "phi4","tau.ab", "tau.ag")

inits1 <- function () {list(mu = 0, tau.ab=1,tau.ag=1,
                            phi1=0.1,phi2=0.3,phi3=-0.4,phi4=0.1,
                            S1=structure(.Data=c(1,0,0,0,1,0,0,0,1), .Dim =
c(3,3)))
}

inits2 <- function () {list(mu = -5.0, tau.ab=10,tau.ag=10,
                           phi1=0,phi2=0,phi3=0.2,phi4=-0.3,
                           S1=structure(.Data=c(10,0,0,0,10,0,0,0,10), .Dim
= c(3,3)))
  }
inits3 <- function () {list(mu = 2.0, tau.ab=5,tau.ag=10,
                            phi1=0.3,phi2=-0.4,phi3=0.4,phi4=0,
                            S1=structure(.Data=c(5,0,0,0,5,0,0,0,5), .Dim =
c(3,3)))
  }

inits <- function () {list(inits1, inits2, inits3)}

nc <- 1      #number of MCMC chains to run
ni <- 4000  #number of samples for each chain
nb <- 2000   #number of samples to discard as burn-in
nt <- 1      #thinning rate, increase this to reduce autocorrelation

bugs.out <- bugs(data=data, inits=inits1, parameters.to.save=params,
model.file="mod1.txt",
                 n.chains=nc, n.iter=ni, n.burnin=nb, n.thin=nt,
debug=FALSE, DIC=TRUE,
                 bugs.directory = "C:/winBUGS/WinBUGS14",
working.directory=getwd())

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Fri Mar 10 03:56:13 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 9 Mar 2017 21:56:13 -0500
Subject: [R] matrix merge, or something else?
Message-ID: <cff92bba-120b-9ec9-f644-a3812ba88aef@gmail.com>

Suppose I have the following two matrices, both with same number of rows 
(3), but different number of columns (3 in test1, 4 in test2).

test1 <- matrix(c(1,1,0,1,0,-1,-1,-1,0),3,3,byrow=T);
test2 <- matrix( rep( 0, len=12), nrow = 3)

I label the rows and columns of the two matrices as follows:

rownames(test1) <- c("row1","row2","row3")
rownames(test2) <- c("row1","row2","row3")

colnames(test1) <- c("a","b","d")
colnames(test2) <- c("a","b","c","d")

So, if we look at the matrices, we see

test1

              a  b  d
row1   1  1  0
row2   1  0 -1
row3  -1 -1  0


test2

             a b c d
row1  0 0 0 0
row2  0 0 0 0
row3  0 0 0 0

So, we see that while both matrices have the same rows, the matrix test1 
has a subset of the columns of test2. In test1, there is no column for 
'c' -- have columns for 'a', 'b', 'd'.

Now, what I want to do is this -- take the information from each column 
in test1, and substitute it into the same row/column in test2. The end 
result should be a matrix that looks like:

             a  b  c  d
row1  1  1  0  0
row2  1  0  0 -1
row3 -1 -1 0   0

My initial though  was some sort of merge by row and column, with some 
funky sort of intersection, but I couldn't figure out how to get that to 
work.

Any suggestions/pointers to the obvious most appreciated.


From eva.leunissen at gmail.com  Fri Mar 10 05:14:30 2017
From: eva.leunissen at gmail.com (Eva Maria Leunissen)
Date: Fri, 10 Mar 2017 17:14:30 +1300
Subject: [R] Negative binomial GAMM using 'by' in factor interactions
Message-ID: <CAFSxBJ55tACzszOeRFWXRKqVTnR2XtqD7j-1S-tc2DGjPYAHUQ@mail.gmail.com>

I am using a GAMM to model my data (this is as far as I know the only way I
can use the negative binomial distribution AND a correlation structure
within the model).

I measured animal detections (including zero detections) per hour at 3
different locations in an area. location is a factor in my model and the
other possible explanatory variables are environmental variables and level
of disturbance.

I'm expecting the response to be different at the 3 different locations for
each variable so have been modelling the terms as interactions with each of
the 3 factor levels of location using the 'by' argument in the 'ti'
smoothing term, as well as 'location' as a variable by itself. Does it make
sense to include the main effect as well as the interaction term? for
example for including the variable 'windspeed': if including the term
ti(windspeed, by=location), is it necessary to also include s(windspeed)?
or would it only make sense to inlcude them in separate models only and
compare the models?

As far as I understand the 'by' argument calculates a separate smooth for
each of the factor levels, so if the effect was the same at each location
it wouldn't hurt to use the 'ti' smooth with the 'by' argument if the
effect of the variable was the same at each location.

The issue I'm having is that by including both terms and then doing model
selection gives me many very similar models within a deltaAIC of 6 of the
best model, where the differences lie in the inclusion of main effects when
the 'interaction' is also there. The inclusion of the interaction term
gives bigger changes in AIC compared to the inclusion of the main effect.

This brings me to my other question. Is it possible to compare GAMMs with a
negative binomial family using AIC? e.g. using AIC(mod$lme). If not, what
is the best way to compare them?

Thank you very much for your time

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Fri Mar 10 05:16:39 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 9 Mar 2017 23:16:39 -0500
Subject: [R] concatenating range of columns in dataframe
Message-ID: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>

Suppose I have the following data frame (call it df):

Trt   y1  y2  y3  y4
A1A   1    0    0    1
A1B  1    1    0    0
A1 C   0   1    0   1
A1D   1    1    1   1

What I want to do is concatenate columns y1  -> y4 into a contiguous 
string (which I'll call df$conc), so that the final df looks like

Trt      Conc
A1A   1001
A1B   1100
A1C  0101
A1D   1111


Now, if my initial dataframe was simply

  1   0  0  1
  1   1  0  0
   0  1  0  1
   1  1  1  1

then apply(df,1,paste,collapse="") does the trick, more or less.

But once I have a Trt column, this approach yields

A1A1001
A1B1100
A1C0101
A1D1111

I need to maintain the space between Trt, and the other columns. So, I'm 
trying to concatenate a subset of columns in the data frame, but I don't 
want to have to do something like create a cahracter vector of the 
column names to do it (e.g., c("y1","y2","y3","y4"). Doing a few by hand 
that way is easy, but not if you  have dozens to hundreds of columns to 
work with.

  Ideally, I'd like to be able to say

"concatenate df[,2:4], get rid of the spaces, pipe the concatenated 
columns to a new named column, and drop the original columns from the 
final df.

Heuristically,

df$conc <- concatenate df[,2:4] # making a new, 5th column in df
df[,2:4] <- NULL   # to drop original columns 2 -> 4

Suggestions/pointers to the obvious appreciated.

Thanks in advance!


From jdnewmil at dcn.davis.ca.us  Fri Mar 10 07:26:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 09 Mar 2017 22:26:01 -0800
Subject: [R] matrix merge, or something else?
In-Reply-To: <cff92bba-120b-9ec9-f644-a3812ba88aef@gmail.com>
References: <cff92bba-120b-9ec9-f644-a3812ba88aef@gmail.com>
Message-ID: <E42E43E7-6EB0-4701-B6F6-43315F9C9849@dcn.davis.ca.us>

test2[ , colnames( test1 ) ] <- test1
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2017 6:56:13 PM PST, Evan Cooch <evan.cooch at gmail.com> wrote:
>Suppose I have the following two matrices, both with same number of
>rows 
>(3), but different number of columns (3 in test1, 4 in test2).
>
>test1 <- matrix(c(1,1,0,1,0,-1,-1,-1,0),3,3,byrow=T);
>test2 <- matrix( rep( 0, len=12), nrow = 3)
>
>I label the rows and columns of the two matrices as follows:
>
>rownames(test1) <- c("row1","row2","row3")
>rownames(test2) <- c("row1","row2","row3")
>
>colnames(test1) <- c("a","b","d")
>colnames(test2) <- c("a","b","c","d")
>
>So, if we look at the matrices, we see
>
>test1
>
>              a  b  d
>row1   1  1  0
>row2   1  0 -1
>row3  -1 -1  0
>
>
>test2
>
>             a b c d
>row1  0 0 0 0
>row2  0 0 0 0
>row3  0 0 0 0
>
>So, we see that while both matrices have the same rows, the matrix
>test1 
>has a subset of the columns of test2. In test1, there is no column for 
>'c' -- have columns for 'a', 'b', 'd'.
>
>Now, what I want to do is this -- take the information from each column
>
>in test1, and substitute it into the same row/column in test2. The end 
>result should be a matrix that looks like:
>
>             a  b  c  d
>row1  1  1  0  0
>row2  1  0  0 -1
>row3 -1 -1 0   0
>
>My initial though  was some sort of merge by row and column, with some 
>funky sort of intersection, but I couldn't figure out how to get that
>to 
>work.
>
>Any suggestions/pointers to the obvious most appreciated.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Mar 10 07:48:05 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Mar 2017 17:48:05 +1100
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
Message-ID: <CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>

Hi Evan,
How about this:

df2<-data.frame(Trt=df[,1],Conc=apply(df[,2:5],1,paste,sep="",collapse=""))

Jim

On Fri, Mar 10, 2017 at 3:16 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
> Suppose I have the following data frame (call it df):
>
> Trt   y1  y2  y3  y4
> A1A   1    0    0    1
> A1B  1    1    0    0
> A1 C   0   1    0   1
> A1D   1    1    1   1
>
> What I want to do is concatenate columns y1  -> y4 into a contiguous string
> (which I'll call df$conc), so that the final df looks like
>
> Trt      Conc
> A1A   1001
> A1B   1100
> A1C  0101
> A1D   1111
>
>
> Now, if my initial dataframe was simply
>
>  1   0  0  1
>  1   1  0  0
>   0  1  0  1
>   1  1  1  1
>
> then apply(df,1,paste,collapse="") does the trick, more or less.
>
> But once I have a Trt column, this approach yields
>
> A1A1001
> A1B1100
> A1C0101
> A1D1111
>
> I need to maintain the space between Trt, and the other columns. So, I'm
> trying to concatenate a subset of columns in the data frame, but I don't
> want to have to do something like create a cahracter vector of the column
> names to do it (e.g., c("y1","y2","y3","y4"). Doing a few by hand that way
> is easy, but not if you  have dozens to hundreds of columns to work with.
>
>  Ideally, I'd like to be able to say
>
> "concatenate df[,2:4], get rid of the spaces, pipe the concatenated columns
> to a new named column, and drop the original columns from the final df.
>
> Heuristically,
>
> df$conc <- concatenate df[,2:4] # making a new, 5th column in df
> df[,2:4] <- NULL   # to drop original columns 2 -> 4
>
> Suggestions/pointers to the obvious appreciated.
>
> Thanks in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 10 08:10:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Mar 2017 23:10:04 -0800
Subject: [R] Negative binomial GAMM using 'by' in factor interactions
In-Reply-To: <CAFSxBJ55tACzszOeRFWXRKqVTnR2XtqD7j-1S-tc2DGjPYAHUQ@mail.gmail.com>
References: <CAFSxBJ55tACzszOeRFWXRKqVTnR2XtqD7j-1S-tc2DGjPYAHUQ@mail.gmail.com>
Message-ID: <CAGxFJbT3q8YnBMdOA=uvpdNp6nxmYfSoTDJMOjmHbca5B1Ki6g@mail.gmail.com>

Your queries appear to concern statistical issues. This list is about
R programming and related; statistical issues are typically OT here.
stats.stackexchange.com or a local statistical expert are probably
better places to seek statistical advice.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 9, 2017 at 8:14 PM, Eva Maria Leunissen
<eva.leunissen at gmail.com> wrote:
> I am using a GAMM to model my data (this is as far as I know the only way I
> can use the negative binomial distribution AND a correlation structure
> within the model).
>
> I measured animal detections (including zero detections) per hour at 3
> different locations in an area. location is a factor in my model and the
> other possible explanatory variables are environmental variables and level
> of disturbance.
>
> I'm expecting the response to be different at the 3 different locations for
> each variable so have been modelling the terms as interactions with each of
> the 3 factor levels of location using the 'by' argument in the 'ti'
> smoothing term, as well as 'location' as a variable by itself. Does it make
> sense to include the main effect as well as the interaction term? for
> example for including the variable 'windspeed': if including the term
> ti(windspeed, by=location), is it necessary to also include s(windspeed)?
> or would it only make sense to inlcude them in separate models only and
> compare the models?
>
> As far as I understand the 'by' argument calculates a separate smooth for
> each of the factor levels, so if the effect was the same at each location
> it wouldn't hurt to use the 'ti' smooth with the 'by' argument if the
> effect of the variable was the same at each location.
>
> The issue I'm having is that by including both terms and then doing model
> selection gives me many very similar models within a deltaAIC of 6 of the
> best model, where the differences lie in the inclusion of main effects when
> the 'interaction' is also there. The inclusion of the interaction term
> gives bigger changes in AIC compared to the inclusion of the main effect.
>
> This brings me to my other question. Is it possible to compare GAMMs with a
> negative binomial family using AIC? e.g. using AIC(mod$lme). If not, what
> is the best way to compare them?
>
> Thank you very much for your time
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 10 08:23:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Mar 2017 23:23:45 -0800
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
Message-ID: <CAGxFJbTTTZb=1deCiTgrRVW4oK1C0MWp4AF-Z+eVBF-gM12WOw@mail.gmail.com>

I think you need to spend some time with an R tutorial or two,
especially with regard to indexing.

Unless I have misunderstood (apologies if I have),

df$Conc <- apply(df[,-1],1,paste,collapse="")

does it.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 9, 2017 at 8:16 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
> Suppose I have the following data frame (call it df):
>
> Trt   y1  y2  y3  y4
> A1A   1    0    0    1
> A1B  1    1    0    0
> A1 C   0   1    0   1
> A1D   1    1    1   1
>
> What I want to do is concatenate columns y1  -> y4 into a contiguous string
> (which I'll call df$conc), so that the final df looks like
>
> Trt      Conc
> A1A   1001
> A1B   1100
> A1C  0101
> A1D   1111
>
>
> Now, if my initial dataframe was simply
>
>  1   0  0  1
>  1   1  0  0
>   0  1  0  1
>   1  1  1  1
>
> then apply(df,1,paste,collapse="") does the trick, more or less.
>
> But once I have a Trt column, this approach yields
>
> A1A1001
> A1B1100
> A1C0101
> A1D1111
>
> I need to maintain the space between Trt, and the other columns. So, I'm
> trying to concatenate a subset of columns in the data frame, but I don't
> want to have to do something like create a cahracter vector of the column
> names to do it (e.g., c("y1","y2","y3","y4"). Doing a few by hand that way
> is easy, but not if you  have dozens to hundreds of columns to work with.
>
>  Ideally, I'd like to be able to say
>
> "concatenate df[,2:4], get rid of the spaces, pipe the concatenated columns
> to a new named column, and drop the original columns from the final df.
>
> Heuristically,
>
> df$conc <- concatenate df[,2:4] # making a new, 5th column in df
> df[,2:4] <- NULL   # to drop original columns 2 -> 4
>
> Suggestions/pointers to the obvious appreciated.
>
> Thanks in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Fri Mar 10 08:24:31 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 10 Mar 2017 07:24:31 +0000
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
	<CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>
Message-ID: <CAKVAULMNoJ5zVDaj5u3UBix_AQ8YYR76nibBXBD-Mq5d6b-QZA@mail.gmail.com>

Hi Evan,

the unite function of the tidyr package achieves the same as Jim suggested,
but in perhaps a slightly more readable manner.

Ulrik

On Fri, 10 Mar 2017 at 07:50 Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Evan,
> How about this:
>
> df2<-data.frame(Trt=df[,1],Conc=apply(df[,2:5],1,paste,sep="",collapse=""))
>
> Jim
>
> On Fri, Mar 10, 2017 at 3:16 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
> > Suppose I have the following data frame (call it df):
> >
> > Trt   y1  y2  y3  y4
> > A1A   1    0    0    1
> > A1B  1    1    0    0
> > A1 C   0   1    0   1
> > A1D   1    1    1   1
> >
> > What I want to do is concatenate columns y1  -> y4 into a contiguous
> string
> > (which I'll call df$conc), so that the final df looks like
> >
> > Trt      Conc
> > A1A   1001
> > A1B   1100
> > A1C  0101
> > A1D   1111
> >
> >
> > Now, if my initial dataframe was simply
> >
> >  1   0  0  1
> >  1   1  0  0
> >   0  1  0  1
> >   1  1  1  1
> >
> > then apply(df,1,paste,collapse="") does the trick, more or less.
> >
> > But once I have a Trt column, this approach yields
> >
> > A1A1001
> > A1B1100
> > A1C0101
> > A1D1111
> >
> > I need to maintain the space between Trt, and the other columns. So, I'm
> > trying to concatenate a subset of columns in the data frame, but I don't
> > want to have to do something like create a cahracter vector of the column
> > names to do it (e.g., c("y1","y2","y3","y4"). Doing a few by hand that
> way
> > is easy, but not if you  have dozens to hundreds of columns to work with.
> >
> >  Ideally, I'd like to be able to say
> >
> > "concatenate df[,2:4], get rid of the spaces, pipe the concatenated
> columns
> > to a new named column, and drop the original columns from the final df.
> >
> > Heuristically,
> >
> > df$conc <- concatenate df[,2:4] # making a new, 5th column in df
> > df[,2:4] <- NULL   # to drop original columns 2 -> 4
> >
> > Suggestions/pointers to the obvious appreciated.
> >
> > Thanks in advance!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Mar 10 08:29:38 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 10 Mar 2017 07:29:38 +0000
Subject: [R] restructuring data frame
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1A2E3@SRVEXCHCM301.precheza.cz>

Dear all

I have some data with following structure in data frame.

dput(evid[1:2,c(2:4)])

evid <- structure(list(V2 = c("test vodivosti kalcin?tu", "impregnace anatasov? pasty rozpra?ovac? su??rna"
), V3 = c("03.03.2017", "17.03.2017"), V4 = c("EICHLER V?ra;#125",
"HO???LKOV? Jarmila;#119;#BERN?T Miroslav;#122;#OSTR?IL Marek;#60"
)), .Names = c("V2", "V3", "V4"), row.names = 9:10, class = "data.frame")

Each row in V4 column contain names followed by ;#xxx. I would like to separate them like that

mena <- liche(unlist(strsplit(evid[2,4], ";#")))

here is function liche

liche <- function (x)
{
    indices <- seq(along = x)
    x[indices%%2 == 1]
}

and repeat each respective row of data frame for separated names like following (which is only for one row)

temp<-evid[2,][rep(seq_len(nrow(evid[2,])), length(mena)),-4]
cbind(temp, mena)
           V1                                              V2         V3
10   NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.1 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.2 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
                V5            V6         V7               mena
10   OSTR?IL Marek OSTR?IL Marek 1kalcinace HO???LKOV? Jarmila
10.1 OSTR?IL Marek OSTR?IL Marek 1kalcinace    BERN?T Miroslav
10.2 OSTR?IL Marek OSTR?IL Marek 1kalcinace      OSTR?IL Marek

I probably could do it for each row in cycle (the data frame is not big) but I wonder if somebody knows any more elegant/easy/effective solution for such task.

Best regards

Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From ulrik.stervbo at gmail.com  Fri Mar 10 08:31:41 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 10 Mar 2017 07:31:41 +0000
Subject: [R] Unable to Load package Rcmdr after installation
In-Reply-To: <58c19383.85981f0a.34f19.d40b@mx.google.com>
References: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
	<58c19383.85981f0a.34f19.d40b@mx.google.com>
Message-ID: <CAKVAULPTgUdCXF4Kqci0u3q6XUtppy5D-EZFjQThk2y717dFEA@mail.gmail.com>

Hi Paul,

what fails and how? What did you do from the time the package worked until
is didn't? Did you update packages? Which packages are you trying to load?

Best
Ulrik

On Thu, 9 Mar 2017 at 18:40 paulbernal07 at gmail.com <paulbernal07 at gmail.com>
wrote:

> Thanks Ulrik, but the thing is that I tried installing adn loading tve
> Hmisc package but wasn't able to do that either.
>
>
> -------- Mensaje original --------
> Asunto: Re: [R] Unable to Load package Rcmdr after installation
> De: Ulrik Stervbo
> Para: Paul Bernal ,r-help at r-project.org
> CC:
>
>
> Hi Paul,
>
> The error tells you, that the 'Hmisc' does not exist on your system. If
> you install it, everything should work.
>
> Use install.packages with dependencies = TRUE to avoid the problem of
> missing packages.
>
> HTH
>
> Ulrik
>
> On Thu, 9 Mar 2017 at 16:51 Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Hello friends,
>
> Has anyone experienced trouble when trying to load package Rcmdr? It was
> working perfectly a couple of days ago, I don?t know why it isn?t working.
>
> > library("Rcmdr")
> Loading required package: splines
> Loading required package: RcmdrMisc
> Loading required package: car
> Loading required package: sandwich
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?Hmisc?
> Error: package ?RcmdrMisc? could not be loaded
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Mar 10 10:25:33 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 10 Mar 2017 09:25:33 +0000
Subject: [R] restructuring data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1A2E3@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1A2E3@SRVEXCHCM301.precheza.cz>
Message-ID: <CAKVAULP6HoD-2-u12CzajQ9iUk1iauER_N51=SA5Vqx1sUyUgA@mail.gmail.com>

Hi Petr,

maybe

library("splitstackshape")
cSplit(evid, "V4", "#", direction = "long")

or

library("tidyr")
separate_rows(evid, V4, sep = "#")

is helpful.

Best,
Ulrik

On Fri, 10 Mar 2017 at 08:32 PIKAL Petr <petr.pikal at precheza.cz> wrote:

Dear all

I have some data with following structure in data frame.

dput(evid[1:2,c(2:4)])

evid <- structure(list(V2 = c("test vodivosti kalcin?tu", "impregnace
anatasov? pasty rozpra?ovac? su??rna"
), V3 = c("03.03.2017", "17.03.2017"), V4 = c("EICHLER V?ra;#125",
"HO???LKOV? Jarmila;#119;#BERN?T Miroslav;#122;#OSTR?IL Marek;#60"
)), .Names = c("V2", "V3", "V4"), row.names = 9:10, class = "data.frame")

Each row in V4 column contain names followed by ;#xxx. I would like to
separate them like that

mena <- liche(unlist(strsplit(evid[2,4], ";#")))

here is function liche

liche <- function (x)
{
    indices <- seq(along = x)
    x[indices%%2 == 1]
}

and repeat each respective row of data frame for separated names like
following (which is only for one row)

temp<-evid[2,][rep(seq_len(nrow(evid[2,])), length(mena)),-4]
cbind(temp, mena)
           V1                                              V2         V3
10   NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.1 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.2 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
                V5            V6         V7               mena
10   OSTR?IL Marek OSTR?IL Marek 1kalcinace HO???LKOV? Jarmila
10.1 OSTR?IL Marek OSTR?IL Marek 1kalcinace    BERN?T Miroslav
10.2 OSTR?IL Marek OSTR?IL Marek 1kalcinace      OSTR?IL Marek

I probably could do it for each row in cycle (the data frame is not big)
but I wonder if somebody knows any more elegant/easy/effective solution for
such task.

Best regards

Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its
sender. Delete the contents of this e-mail with all attachments and its
copies from your system.
If you are not the intended recipient of this e-mail, you are not
authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage
caused by modifications of the e-mail or by delay with transfer of the
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately
accept such offer; The sender of this e-mail (offer) excludes any
acceptance of the offer on the part of the recipient containing any
amendment or variation.
- the sender insists on that the respective contract is concluded only upon
an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter
into any contracts on behalf of the company except for cases in which
he/she is expressly authorized to do so in writing, and such authorization
or power of attorney is submitted to the recipient or the person
represented by the recipient, or the existence of such authorization is
known to the recipient of the person represented by the recipient.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From denis.francisci at gmail.com  Fri Mar 10 11:44:43 2017
From: denis.francisci at gmail.com (Denis Francisci)
Date: Fri, 10 Mar 2017 11:44:43 +0100
Subject: [R] problem with PCA
Message-ID: <CAJMcJMC+JmZwc6sGD+e5FJ+9knixvERXMkP0DkvPtu+CUbdN-w@mail.gmail.com>

Hi all.
I'm newbie in PCA by I don't understand a behaviour of R.
I have this data matrix:

>mx_fus
  height diam  hole  weight
1    2.3  3.5  1.1   18
2    2.0  3.5  0.9   17
3    3.8  4.3  0.7   34
4    2.1  3.4  0.9   15
5    2.3  3.8  1.0   19
6    2.2  3.8  1.0   19
7    3.2  4.4  0.9   34
8    3.0  4.3  1.0   30
9    2.8  3.9  0.9   21
10   3.3  4.2  1.1   33
11   2.3  3.9  0.9   25
12   2.3  3.3  0.5   17
13   0.9  2.4  0.4   10
14   1.4  2.4  0.5   10
15   2.2  3.6  0.7   22
16   2.9  3.8  0.8   30
17   2.9  3.5  0.6   27
18   2.3  3.5  0.5   24
19   1.8  2.3  0.5   29
20   1.4  2.5  0.6   34
21   0.8  2.3  0.6   21
22   1.8  2.4  0.6   23
23   1.5  2.2  0.6    7
24   0.9  1.7  0.4   14
25   2.1  2.2  0.5   25
26   1.3  2.4  0.6   33
27   1.3  2.7  0.4   39
28   0.5  2.2  0.5   13
29   1.4  4.2  0.8   23
30   1.6  2.0  0.4   30
31   1.4  2.2  0.6   25
32   1.8  2.5  0.6   28
33   1.4  2.6  0.6   41
34   1.6  2.3  0.3   32
35   1.6  2.5  0.5   41
36   2.8  2.9  0.8   47
37   0.6  2.5  0.8   21
38   1.6  2.8  0.7   13
39   1.7  3.3  0.8   17
40   1.6  3.9  1.9   20
41   1.4  4.7  0.9   26
42   1.2  4.2  0.7   21
43   3.5  4.2  0.9   47
44   2.3  3.6  0.7   24
45   2.3  3.4  0.4   21
46   1.9  2.6  0.7   14
47   1.9  3.0  0.7   15
48   2.7  3.7  0.9   26
49   3.0  3.8  0.7   35
50   1.2  2.0  0.7    5
51   1.6  2.5  0.5   15
52   1.3  2.6  0.5   16
53   2.5  3.9  0.9   32
54   0.9  3.3  0.6    9
55   1.8  2.4  0.5   17
56   2.4  3.7  1.1   30
57   2.1  3.5  1.1   22
58   2.6  3.9  1.0   38
59   2.6  3.6  1.0   27
60   2.6  4.1  1.0   34
61   2.9  3.6  0.8   32
62   2.6  3.3  0.7   22
63   1.8  2.5  0.7   26
64   3.0  2.8  1.3    2
65   0.5  2.2  0.4    3
66   1.9  3.4  0.7   14
67   1.4  3.8  0.9   18
68   2.0  4.0  1.0   30
69   3.1  4.0  1.3   21
70   2.5  4.0  0.8   19
71   2.5  4.5  1.0   20
72   1.8  3.5  1.4   18
73   2.1  3.5  1.4   25
74   1.5  2.6  0.5    9
75   2.8  3.2  1.2   16
76   1.0  5.0  0.3   32
77   0.3  5.8  0.5   56
78   0.5  1.5  0.2    1
79   0.7  1.4  0.2    1
80   0.5  1.3  0.2    1
81   0.7  3.3  0.4    7
82   1.9  4.7  1.0   24
83   3.1  4.2  0.9   49
84   2.8  3.6  0.7   28
85   2.7  3.2  0.7   29
86   3.0  4.0  0.9   36
87   1.7  2.7  0.7   14
88   1.5  2.9  0.7   18
89   2.9  3.5  0.7   30
90   3.0  3.4  0.8   30
91   2.0  2.8  0.5   14
92   2.4  3.5  0.7   24
93   0.8  4.1  0.6   12
94   1.7  2.5  0.5   23
95   1.4  2.4  0.8   31
96   1.5  2.7  0.4   20
97   2.6  3.7  0.6   31
98   2.6  3.0  0.6   18
99   2.5  5.0  0.7   40
100  2.5  3.7  0.5   30
101  2.4  2.9  0.7   17
102  2.3  3.0  0.5   15
103  2.2  3.3  0.6   19
104  1.5  2.1  0.5    5
105  2.0  2.2  0.5   10
106  2.6  3.5  0.6   26
107  2.3  3.0  0.6   15
108  2.5  4.5  0.7   40
109  2.1  3.1  0.5   15
110  1.3  2.1  0.8   14
111  0.8  2.5  0.2    5
112  0.6  3.1  0.7    8

I perform a PCA in R

>pca<-prcomp(mx_fus,scale=TRUE)
>biplot(pca, choices = c(1,2), cex=0.7)

The biplot put the arrows of diam and height very near on the first
component axis.
So I understand that these 2 variables are well represented in the PC1 and
they are correlated each other.
But if I test the correlation, the value o correlation coefficient is low

>cor(mx_fus[,1],mx_fus[,2])
0.4828185

Why the plot says a thing and correlation function says the opposite?
Two near arrows don't represent a strong correlation between the 2
variables (as I read in some manuals), but only with the component axis?

Than's in advance

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Fri Mar 10 11:52:39 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 10 Mar 2017 11:52:39 +0100
Subject: [R] "found 4 marked UTF-8 strings" during check of package... but
	where !
Message-ID: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>

Dear members,

I want submit to CRAN a new version of a package that I maintain. When I 
check locally "as-cran" no note or error are reported but the link after 
submission reports several notes and one warning:

For example:

using R Under development (unstable) (2017-03-05 r72309)
using platform: x86_64-apple-darwin16.4.0 (64-bit)
using session charset: UTF-8
...
checking extension type ... Package
this is package ?embryogrowth? version ?6.4?
package encoding: UTF-8
...
checking data for non-ASCII characters ... NOTE
   Note: found 4 marked UTF-8 strings

I have the same with
using R version 3.3.0 (2016-05-03)
using platform: x86_64-apple-darwin13.4.0 (64-bit)

but not with some others such as r-devel-linux-x86_64-debian-gcc

Based on the message, "Note: found 4 marked UTF-8 strings", it seems 
that "4 marked UTF-8 strings" are present in the package and it is a 
problem...

Is there any solution to know in which file?

Thanks
Marc


From ajdamico at gmail.com  Fri Mar 10 13:23:48 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 10 Mar 2017 07:23:48 -0500
Subject: [R] first readline() instance getting skipped on windows with R
	3.3.3
Message-ID: <CAOwvMDxtEq1oaDvW88me=VD24X-6cf3e1dg0y9L+7msJXiWGQg@mail.gmail.com>

hi, i'm curious if anyone else has noticed a change in behavior of
readline()?

i have a function in an R package that calls readline() here:

https://github.com/ajdamico/lodown/blob/master/R/mics.R#L126

after upgrading to 3.3.3, the function appeared to start ignoring that
readline() call.  my function runs some internet and plotting commands, so
i might be doing something wrong here.  i figured out that i can work
around the problem by adding an empty readline("") call earlier in the same
function.. so readline() is just getting skipped at the first occurrence
for some reason.  this line works around the problem, which seems odd:

https://github.com/ajdamico/lodown/blob/master/R/mics.R#L94


i've been unsuccessful reproducing this more succinctly.  latest R news
indicates lots of changes to this function:
https://cran.r-project.org/doc/manuals/r-release/NEWS.html


here's my extSoftVersion() and sessionInfo()

thanks!


> extSoftVersion()
                     zlib                     bzlib
xz                      PCRE
ICU                       TRE                     iconv
readline
                  "1.2.8"      "1.0.6, 6-Sept-2010"
"5.0.8"         "8.38 2015-11-23"                    "55.1" "TRE 0.8.0
R_fixes (BSD)"               "win_iconv"                        ""






> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
base

other attached packages:
[1] survey_3.31-5   survival_2.40-1 Matrix_1.2-7.1  lodown_0.1.0

loaded via a namespace (and not attached):
[1] httr_1.2.1      R6_2.2.0        curl_2.3        splines_3.3.3
jpeg_0.1-8      jsonlite_1.1    lattice_0.20-34

	[[alternative HTML version deleted]]


From paul.fronteri at gmail.com  Fri Mar 10 08:58:49 2017
From: paul.fronteri at gmail.com (=?UTF-8?Q?Paul_Anthony_Front=C3=A9ri?=)
Date: Fri, 10 Mar 2017 08:58:49 +0100
Subject: [R] write.xlsx
Message-ID: <CAMtDb69BGeSkUe8SYABO77QAe9vfnB-HzA6_zkOHTUhhvHnUdg@mail.gmail.com>

Hey.

I am trying to append a sheet to an existing file using write.xlsx, see
code under:

write.xlsx(x = data1,file = filename,sheetName = "data1", asTable = FALSE,
col.names = T,row.names = F,append = F)
write.xlsx(x = data2,file = filename,sheetName = "data2", asTable = FALSE,
col.names = T,row.names = F,append = T)

However, when using the last line does it not append it to the file, but
overwrite the file. Meaning that the file, which I have have called:

filename <- "test.xlsx"

only includes one sheet - data2. The first data sheet is not there. Why
does not append work with write.xlsx?

Paul

	[[alternative HTML version deleted]]


From vpapathanasiou at hotmail.com  Fri Mar 10 12:22:31 2017
From: vpapathanasiou at hotmail.com (Vasillis Papathanasiou)
Date: Fri, 10 Mar 2017 11:22:31 +0000
Subject: [R] Interpretation of lme results with intercorrelation between
 fixed factors
Message-ID: <DB4PR01MB382584C4A1FA891BDFBEB3FCB200@DB4PR01MB382.eurprd01.prod.exchangelabs.com>

I?m running a mixed model analysis with 2 fixed factors that are intercorrelated using the lme function and I?m having difficulties in interpreting the results.
As I?m quite novice I?ll try to use a very simple example.

My model is lme(Y~A*B). A has 3 levels (1, 2 and 3) and B has 2 levels (I and II).
My results are something like this:



P statistic

B:II

P=0.01

A:2

P=0.01

A:3

P=0.09

II*2

P=0.61

II*3

P=0.031


My question is as follows. I understand that R keeps a level of each factor and reports any statistical differences to it. So in this example it reports that II is different than I and 2 against 3. However when it comes to the intercorrelation, what does it report? Does it compare II*2 and II*3 to II*1 and if so what happens with I*2 and I*3? Or does it compare II*2 to I*2 and II*3 to I*3 and if so what happens to I*1 and II*1?

Thank you


Vasillis


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Mar 10 14:49:05 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 10 Mar 2017 13:49:05 +0000
Subject: [R] write.xlsx
In-Reply-To: <CAMtDb69BGeSkUe8SYABO77QAe9vfnB-HzA6_zkOHTUhhvHnUdg@mail.gmail.com>
References: <CAMtDb69BGeSkUe8SYABO77QAe9vfnB-HzA6_zkOHTUhhvHnUdg@mail.gmail.com>
Message-ID: <e8c61b4a-4433-111e-8cd1-8b483a7137f4@dewey.myzen.co.uk>

Dear Paul

Have you defined a variable T or F somewhere?
Rather than look to find out why not replace T by TRUE and F by FALSE 
and see if that solves your problem.

On 10/03/2017 07:58, Paul Anthony Front?ri wrote:
> Hey.
>
> I am trying to append a sheet to an existing file using write.xlsx, see
> code under:
>
> write.xlsx(x = data1,file = filename,sheetName = "data1", asTable = FALSE,
> col.names = T,row.names = F,append = F)
> write.xlsx(x = data2,file = filename,sheetName = "data2", asTable = FALSE,
> col.names = T,row.names = F,append = T)
>
> However, when using the last line does it not append it to the file, but
> overwrite the file. Meaning that the file, which I have have called:
>
> filename <- "test.xlsx"
>
> only includes one sheet - data2. The first data sheet is not there. Why
> does not append work with write.xlsx?
>
> Paul
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From petr.pikal at precheza.cz  Fri Mar 10 14:56:41 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 10 Mar 2017 13:56:41 +0000
Subject: [R] restructuring data frame
In-Reply-To: <CAKVAULP6HoD-2-u12CzajQ9iUk1iauER_N51=SA5Vqx1sUyUgA@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1A2E3@SRVEXCHCM301.precheza.cz>
	<CAKVAULP6HoD-2-u12CzajQ9iUk1iauER_N51=SA5Vqx1sUyUgA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1A77A@SRVEXCHCM301.precheza.cz>

Thanks Ulrik.

separate_rows is interesting, but it results in data frame with rows with offending numbers stored in V4 variable.

> separate_rows(evid, V4, sep = ";#")
                                               V2         V3                 V4
1                        test vodivosti kalcin?tu 03.03.2017       EICHLER V?ra
2                        test vodivosti kalcin?tu 03.03.2017                125
3 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017 HO???LKOV? Jarmila
4 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017                119
5 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017    BERN?T Miroslav
6 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017                122
7 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017      OSTR?IL Marek
8 impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017                 60

I could get rid of them and select only odd rows by
evid[liche(1:nrow(evid)),]

So it is easier than my solution, which is slight expansion of my first attempt, using my convenience function liche for selecting only odd values.

mena<-lapply(strsplit(evid[,3], ";#"), liche)
temp <- evid[rep(seq_len(nrow(evid)),  unlist(lapply(mena, length))),-3]
cbind(temp, mena=unlist(mena))

Cheers
Petr


From: Ulrik Stervbo [mailto:ulrik.stervbo at gmail.com]
Sent: Friday, March 10, 2017 10:26 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: Re: [R] restructuring data frame

Hi Petr,
maybe

library("splitstackshape")
cSplit(evid, "V4", "#", direction = "long")

or

library("tidyr")
separate_rows(evid, V4, sep = "#")

is helpful.

Best,
Ulrik

On Fri, 10 Mar 2017 at 08:32 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Dear all

I have some data with following structure in data frame.

dput(evid[1:2,c(2:4)])

evid <- structure(list(V2 = c("test vodivosti kalcin?tu", "impregnace anatasov? pasty rozpra?ovac? su??rna"
), V3 = c("03.03.2017", "17.03.2017"), V4 = c("EICHLER V?ra;#125",
"HO???LKOV? Jarmila;#119;#BERN?T Miroslav;#122;#OSTR?IL Marek;#60"
)), .Names = c("V2", "V3", "V4"), row.names = 9:10, class = "data.frame")

Each row in V4 column contain names followed by ;#xxx. I would like to separate them like that

mena <- liche(unlist(strsplit(evid[2,4], ";#")))

here is function liche

liche <- function (x)
{
    indices <- seq(along = x)
    x[indices%%2 == 1]
}

and repeat each respective row of data frame for separated names like following (which is only for one row)

temp<-evid[2,][rep(seq_len(nrow(evid[2,])), length(mena)),-4]
cbind(temp, mena)
           V1                                              V2         V3
10   NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.1 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
10.2 NEPRAVDA impregnace anatasov? pasty rozpra?ovac? su??rna 17.03.2017
                V5            V6         V7               mena
10   OSTR?IL Marek OSTR?IL Marek 1kalcinace HO???LKOV? Jarmila
10.1 OSTR?IL Marek OSTR?IL Marek 1kalcinace    BERN?T Miroslav
10.2 OSTR?IL Marek OSTR?IL Marek 1kalcinace      OSTR?IL Marek

I probably could do it for each row in cycle (the data frame is not big) but I wonder if somebody knows any more elegant/easy/effective solution for such task.

Best regards

Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Fri Mar 10 14:57:10 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 10 Mar 2017 08:57:10 -0500
Subject: [R] "found 4 marked UTF-8 strings" during check of package...
 but where !
In-Reply-To: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
References: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
Message-ID: <eb4b31ec-9ace-27d8-df08-7037edd570f3@yorku.ca>

Try:

tools:::showNonASCIIfile(file)

On 3/10/2017 5:52 AM, Marc Girondot via R-help wrote:
> Based on the message, "Note: found 4 marked UTF-8 strings", it seems
> that "4 marked UTF-8 strings" are present in the package and it is a
> problem...
>
> Is there any solution to know in which file?


From jfox at mcmaster.ca  Fri Mar 10 15:17:29 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 10 Mar 2017 14:17:29 +0000
Subject: [R] Unable to Load package Rcmdr after installation
In-Reply-To: <CAKVAULPTgUdCXF4Kqci0u3q6XUtppy5D-EZFjQThk2y717dFEA@mail.gmail.com>
References: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
	<58c19383.85981f0a.34f19.d40b@mx.google.com>
	<CAKVAULPTgUdCXF4Kqci0u3q6XUtppy5D-EZFjQThk2y717dFEA@mail.gmail.com>
Message-ID: <D4E81E32.5695%jfox@mcmaster.ca>

Dear Paul,

It would be easier to help you if you provided more information, both
about your computer system and about what exactly you did.

With respect to the former, you can report the output of Sys.info() and
sessionInfo(). With respect to the latter, did install.packages('Hmisc')
succeed? If so, what happens when you issue the library(Hmisc) command?
What CRAN mirror are you using?

Best,
 John

-------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: http://socserv.mcmaster.ca/jfox/




On 2017-03-10, 2:31 AM, "R-help on behalf of Ulrik Stervbo"
<r-help-bounces at r-project.org on behalf of ulrik.stervbo at gmail.com> wrote:

>Hi Paul,
>
>what fails and how? What did you do from the time the package worked until
>is didn't? Did you update packages? Which packages are you trying to load?
>
>Best
>Ulrik
>
>On Thu, 9 Mar 2017 at 18:40 paulbernal07 at gmail.com
><paulbernal07 at gmail.com>
>wrote:
>
>> Thanks Ulrik, but the thing is that I tried installing adn loading tve
>> Hmisc package but wasn't able to do that either.
>>
>>
>> -------- Mensaje original --------
>> Asunto: Re: [R] Unable to Load package Rcmdr after installation
>> De: Ulrik Stervbo
>> Para: Paul Bernal ,r-help at r-project.org
>> CC:
>>
>>
>> Hi Paul,
>>
>> The error tells you, that the 'Hmisc' does not exist on your system. If
>> you install it, everything should work.
>>
>> Use install.packages with dependencies = TRUE to avoid the problem of
>> missing packages.
>>
>> HTH
>>
>> Ulrik
>>
>> On Thu, 9 Mar 2017 at 16:51 Paul Bernal <paulbernal07 at gmail.com> wrote:
>>
>> Hello friends,
>>
>> Has anyone experienced trouble when trying to load package Rcmdr? It was
>> working perfectly a couple of days ago, I don?t know why it isn?t
>>working.
>>
>> > library("Rcmdr")
>> Loading required package: splines
>> Loading required package: RcmdrMisc
>> Loading required package: car
>> Loading required package: sandwich
>> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>>versionCheck
>> = vI[[j]]) :
>>   there is no package called ?Hmisc?
>> Error: package ?RcmdrMisc? could not be loaded
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Mar 10 15:24:53 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Mar 2017 06:24:53 -0800
Subject: [R] "found 4 marked UTF-8 strings" during check of package...
 but where !
In-Reply-To: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
References: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
Message-ID: <712dc385-40b5-52a7-603f-4eb385a57616@gmail.com>

On 10/03/2017 2:52 AM, Marc Girondot via R-help wrote:
> Dear members,
>
> I want submit to CRAN a new version of a package that I maintain. When I
> check locally "as-cran" no note or error are reported but the link after
> submission reports several notes and one warning:
>
> For example:
>
> using R Under development (unstable) (2017-03-05 r72309)
> using platform: x86_64-apple-darwin16.4.0 (64-bit)
> using session charset: UTF-8
> ...
> checking extension type ... Package
> this is package ?embryogrowth? version ?6.4?
> package encoding: UTF-8
> ...
> checking data for non-ASCII characters ... NOTE
>    Note: found 4 marked UTF-8 strings
>
> I have the same with
> using R version 3.3.0 (2016-05-03)
> using platform: x86_64-apple-darwin13.4.0 (64-bit)
>
> but not with some others such as r-devel-linux-x86_64-debian-gcc
>
> Based on the message, "Note: found 4 marked UTF-8 strings", it seems
> that "4 marked UTF-8 strings" are present in the package and it is a
> problem...
>
> Is there any solution to know in which file?

It's one containing an object coming from your data directory.

R won't give more detail than that, but if you still can't guess, you 
could get some idea by debugging the check code:

debug(tools:::.check_package_datasets)
tools:::.check_package_datasets(pkg)

where pkg contains the path to the package source code.  That function 
does the checking one variable at a time.

Duncan Murdoch


From paulbernal07 at gmail.com  Fri Mar 10 15:33:44 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 10 Mar 2017 09:33:44 -0500
Subject: [R] Unable to Load package Rcmdr after installation
In-Reply-To: <D4E81E32.5695%jfox@mcmaster.ca>
References: <CAMOcQfO9rmGaYq=PHshimpp54f-P5TxznqLK60kQ+XkYAfkZ=A@mail.gmail.com>
	<58c19383.85981f0a.34f19.d40b@mx.google.com>
	<CAKVAULPTgUdCXF4Kqci0u3q6XUtppy5D-EZFjQThk2y717dFEA@mail.gmail.com>
	<D4E81E32.5695%jfox@mcmaster.ca>
Message-ID: <CAMOcQfPPxmJi7PRTMQGRTruEpmcBcBeEeyHt6xPSx-zYEtctQA@mail.gmail.com>

Dear John,

Hope you are doing great. Thank you for your kind reply. Fortunately yes, I
was able to solve the issue.

I believe that the issue was due to the fact that I had several R versions
installed on my computer, and, when browsing through the folders, I noticed
that there were some packages that had been previously installed and needed
to be removed.

I also unistalled all R versions that I had and reinstalled it, installed,
updated and loaded package "Hmisc" and everything worked great from there
on.

Again, thank you so much for your valuable support,

Best of regards and have an awesome day,

Paul

2017-03-10 9:17 GMT-05:00 Fox, John <jfox at mcmaster.ca>:

> Dear Paul,
>
> It would be easier to help you if you provided more information, both
> about your computer system and about what exactly you did.
>
> With respect to the former, you can report the output of Sys.info() and
> sessionInfo(). With respect to the latter, did install.packages('Hmisc')
> succeed? If so, what happens when you issue the library(Hmisc) command?
> What CRAN mirror are you using?
>
> Best,
>  John
>
> -------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> Web: http://socserv.mcmaster.ca/jfox/
>
>
>
>
> On 2017-03-10, 2:31 AM, "R-help on behalf of Ulrik Stervbo"
> <r-help-bounces at r-project.org on behalf of ulrik.stervbo at gmail.com> wrote:
>
> >Hi Paul,
> >
> >what fails and how? What did you do from the time the package worked until
> >is didn't? Did you update packages? Which packages are you trying to load?
> >
> >Best
> >Ulrik
> >
> >On Thu, 9 Mar 2017 at 18:40 paulbernal07 at gmail.com
> ><paulbernal07 at gmail.com>
> >wrote:
> >
> >> Thanks Ulrik, but the thing is that I tried installing adn loading tve
> >> Hmisc package but wasn't able to do that either.
> >>
> >>
> >> -------- Mensaje original --------
> >> Asunto: Re: [R] Unable to Load package Rcmdr after installation
> >> De: Ulrik Stervbo
> >> Para: Paul Bernal ,r-help at r-project.org
> >> CC:
> >>
> >>
> >> Hi Paul,
> >>
> >> The error tells you, that the 'Hmisc' does not exist on your system. If
> >> you install it, everything should work.
> >>
> >> Use install.packages with dependencies = TRUE to avoid the problem of
> >> missing packages.
> >>
> >> HTH
> >>
> >> Ulrik
> >>
> >> On Thu, 9 Mar 2017 at 16:51 Paul Bernal <paulbernal07 at gmail.com> wrote:
> >>
> >> Hello friends,
> >>
> >> Has anyone experienced trouble when trying to load package Rcmdr? It was
> >> working perfectly a couple of days ago, I don?t know why it isn?t
> >>working.
> >>
> >> > library("Rcmdr")
> >> Loading required package: splines
> >> Loading required package: RcmdrMisc
> >> Loading required package: car
> >> Loading required package: sandwich
> >> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> >>versionCheck
> >> = vI[[j]]) :
> >>   there is no package called ?Hmisc?
> >> Error: package ?RcmdrMisc? could not be loaded
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Fri Mar 10 15:45:14 2017
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 10 Mar 2017 09:45:14 -0500
Subject: [R] heat maps with qplot
Message-ID: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>

 Hi all;

The followings are my R codes for heat maps in ggplot2. I need to specify
the font size for the y-axis (x-axis works) as well as font size for label
y and x too. Your help highly appreciated.

Thanks,

Greg

qplot(x=Var1, y=Var2, data=melt(cor(a, use="p")), fill=value, geom="tile") +
 scale_fill_gradient2(limits=c(-1, 1))+
 ylab('Super pathways') +
 xlab('Significant Metabolites in Super pathways for DI') +
 theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6))

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Mar 10 15:49:30 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 10 Mar 2017 14:49:30 +0000
Subject: [R] problem with PCA
In-Reply-To: <CAJMcJMC+JmZwc6sGD+e5FJ+9knixvERXMkP0DkvPtu+CUbdN-w@mail.gmail.com>
References: <CAJMcJMC+JmZwc6sGD+e5FJ+9knixvERXMkP0DkvPtu+CUbdN-w@mail.gmail.com>
Message-ID: <023ddc217f1d44f483feb489c6e8da5e@exch-2p-mbx-w2.ads.tamu.edu>

This is more a question about principal components analysis than about R. You have 4 variables and they are moderately correlated with one another (weight and hole are only .2). When the data consist of measurements, this usually suggests that the overall size of the object is being partly measured by each variable. In your case object size is measured by the first principle component (PC1) with larger objects having more negative scores so larger objects are on the left and smaller ones are on the right of the biplot. 

The biplot can only display 2 of the 4 dimensions of your data at one time. In the first 2 dimensions, diam and height are close together, but in the 3rd dimension (PC3), they are on opposite sides of the component. If you plot different pairs of dimensions (e.g. 1 with 3 or 2 with 3, see below), the arrows will look different because you are looking from different directions.

> pca
Standard deviations:
[1] 1.5264292 0.8950379 0.7233671 0.5879295

Rotation:
              PC1         PC2         PC3        PC4
height -0.5210224 -0.06545193  0.80018012 -0.2897646
diam   -0.5473677  0.06309163 -0.57146893 -0.6081376
hole   -0.4598646 -0.70952862 -0.17476677  0.5045297
weight -0.4663141  0.69878797 -0.05090785  0.5400508

> biplot(pca, choices=c(1, 3))
> biplot(pca, choices=c(2, 3))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Denis Francisci
Sent: Friday, March 10, 2017 4:45 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] problem with PCA

Hi all.
I'm newbie in PCA by I don't understand a behaviour of R.
I have this data matrix:

>mx_fus
  height diam  hole  weight
1    2.3  3.5  1.1   18
2    2.0  3.5  0.9   17
3    3.8  4.3  0.7   34
4    2.1  3.4  0.9   15
5    2.3  3.8  1.0   19
6    2.2  3.8  1.0   19
7    3.2  4.4  0.9   34
8    3.0  4.3  1.0   30
9    2.8  3.9  0.9   21
10   3.3  4.2  1.1   33
11   2.3  3.9  0.9   25
12   2.3  3.3  0.5   17
13   0.9  2.4  0.4   10
14   1.4  2.4  0.5   10
15   2.2  3.6  0.7   22
16   2.9  3.8  0.8   30
17   2.9  3.5  0.6   27
18   2.3  3.5  0.5   24
19   1.8  2.3  0.5   29
20   1.4  2.5  0.6   34
21   0.8  2.3  0.6   21
22   1.8  2.4  0.6   23
23   1.5  2.2  0.6    7
24   0.9  1.7  0.4   14
25   2.1  2.2  0.5   25
26   1.3  2.4  0.6   33
27   1.3  2.7  0.4   39
28   0.5  2.2  0.5   13
29   1.4  4.2  0.8   23
30   1.6  2.0  0.4   30
31   1.4  2.2  0.6   25
32   1.8  2.5  0.6   28
33   1.4  2.6  0.6   41
34   1.6  2.3  0.3   32
35   1.6  2.5  0.5   41
36   2.8  2.9  0.8   47
37   0.6  2.5  0.8   21
38   1.6  2.8  0.7   13
39   1.7  3.3  0.8   17
40   1.6  3.9  1.9   20
41   1.4  4.7  0.9   26
42   1.2  4.2  0.7   21
43   3.5  4.2  0.9   47
44   2.3  3.6  0.7   24
45   2.3  3.4  0.4   21
46   1.9  2.6  0.7   14
47   1.9  3.0  0.7   15
48   2.7  3.7  0.9   26
49   3.0  3.8  0.7   35
50   1.2  2.0  0.7    5
51   1.6  2.5  0.5   15
52   1.3  2.6  0.5   16
53   2.5  3.9  0.9   32
54   0.9  3.3  0.6    9
55   1.8  2.4  0.5   17
56   2.4  3.7  1.1   30
57   2.1  3.5  1.1   22
58   2.6  3.9  1.0   38
59   2.6  3.6  1.0   27
60   2.6  4.1  1.0   34
61   2.9  3.6  0.8   32
62   2.6  3.3  0.7   22
63   1.8  2.5  0.7   26
64   3.0  2.8  1.3    2
65   0.5  2.2  0.4    3
66   1.9  3.4  0.7   14
67   1.4  3.8  0.9   18
68   2.0  4.0  1.0   30
69   3.1  4.0  1.3   21
70   2.5  4.0  0.8   19
71   2.5  4.5  1.0   20
72   1.8  3.5  1.4   18
73   2.1  3.5  1.4   25
74   1.5  2.6  0.5    9
75   2.8  3.2  1.2   16
76   1.0  5.0  0.3   32
77   0.3  5.8  0.5   56
78   0.5  1.5  0.2    1
79   0.7  1.4  0.2    1
80   0.5  1.3  0.2    1
81   0.7  3.3  0.4    7
82   1.9  4.7  1.0   24
83   3.1  4.2  0.9   49
84   2.8  3.6  0.7   28
85   2.7  3.2  0.7   29
86   3.0  4.0  0.9   36
87   1.7  2.7  0.7   14
88   1.5  2.9  0.7   18
89   2.9  3.5  0.7   30
90   3.0  3.4  0.8   30
91   2.0  2.8  0.5   14
92   2.4  3.5  0.7   24
93   0.8  4.1  0.6   12
94   1.7  2.5  0.5   23
95   1.4  2.4  0.8   31
96   1.5  2.7  0.4   20
97   2.6  3.7  0.6   31
98   2.6  3.0  0.6   18
99   2.5  5.0  0.7   40
100  2.5  3.7  0.5   30
101  2.4  2.9  0.7   17
102  2.3  3.0  0.5   15
103  2.2  3.3  0.6   19
104  1.5  2.1  0.5    5
105  2.0  2.2  0.5   10
106  2.6  3.5  0.6   26
107  2.3  3.0  0.6   15
108  2.5  4.5  0.7   40
109  2.1  3.1  0.5   15
110  1.3  2.1  0.8   14
111  0.8  2.5  0.2    5
112  0.6  3.1  0.7    8

I perform a PCA in R

>pca<-prcomp(mx_fus,scale=TRUE)
>biplot(pca, choices = c(1,2), cex=0.7)

The biplot put the arrows of diam and height very near on the first
component axis.
So I understand that these 2 variables are well represented in the PC1 and
they are correlated each other.
But if I test the correlation, the value o correlation coefficient is low

>cor(mx_fus[,1],mx_fus[,2])
0.4828185

Why the plot says a thing and correlation function says the opposite?
Two near arrows don't represent a strong correlation between the 2
variables (as I read in some manuals), but only with the component axis?

Than's in advance

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Fri Mar 10 16:08:37 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 10 Mar 2017 15:08:37 +0000
Subject: [R] heat maps with qplot
In-Reply-To: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>
References: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>
Message-ID: <CAKVAULOBpgESsSMbGskWx_RgQG9V5-EEWrbT9QrEGOk9RetXtg@mail.gmail.com>

Hi Greg,

?theme

You can use the axis.text and axis.title if y and x are to be identical, or
axis.text.x, axis.text.y, axis.title.x, axis.title.y if you need different
font size.

HTH
Ulrik

On Fri, 10 Mar 2017 at 15:47 greg holly <mak.hholly at gmail.com> wrote:

>  Hi all;
>
> The followings are my R codes for heat maps in ggplot2. I need to specify
> the font size for the y-axis (x-axis works) as well as font size for label
> y and x too. Your help highly appreciated.
>
> Thanks,
>
> Greg
>
> qplot(x=Var1, y=Var2, data=melt(cor(a, use="p")), fill=value, geom="tile")
> +
>  scale_fill_gradient2(limits=c(-1, 1))+
>  ylab('Super pathways') +
>  xlab('Significant Metabolites in Super pathways for DI') +
>  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Fri Mar 10 16:19:29 2017
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 10 Mar 2017 10:19:29 -0500
Subject: [R] heat maps with qplot
In-Reply-To: <CAKVAULOBpgESsSMbGskWx_RgQG9V5-EEWrbT9QrEGOk9RetXtg@mail.gmail.com>
References: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>
	<CAKVAULOBpgESsSMbGskWx_RgQG9V5-EEWrbT9QrEGOk9RetXtg@mail.gmail.com>
Message-ID: <CAM9Qe4gk-Mf-d6XNg0LFZrSh7buwdtd37hQ03H-vKhxidQD=CQ@mail.gmail.com>

Thanks Ulrik for this, This is my first experience in heat maps. Yours
advise for the theme would be appreciated.

Greg

On Fri, Mar 10, 2017 at 10:08 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Greg,
>
> ?theme
>
> You can use the axis.text and axis.title if y and x are to be identical,
> or axis.text.x, axis.text.y, axis.title.x, axis.title.y if you need
> different font size.
>
> HTH
> Ulrik
>
> On Fri, 10 Mar 2017 at 15:47 greg holly <mak.hholly at gmail.com> wrote:
>
>>  Hi all;
>>
>> The followings are my R codes for heat maps in ggplot2. I need to specify
>> the font size for the y-axis (x-axis works) as well as font size for label
>> y and x too. Your help highly appreciated.
>>
>> Thanks,
>>
>> Greg
>>
>> qplot(x=Var1, y=Var2, data=melt(cor(a, use="p")), fill=value,
>> geom="tile") +
>>  scale_fill_gradient2(limits=c(-1, 1))+
>>  ylab('Super pathways') +
>>  xlab('Significant Metabolites in Super pathways for DI') +
>>  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6))
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar 10 16:24:13 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 10 Mar 2017 07:24:13 -0800
Subject: [R] heat maps with qplot
In-Reply-To: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>
References: <CAM9Qe4gqtDJRWmphE3ejtp-3n4NFtgm2qnNwagXZs3HpEGF5yQ@mail.gmail.com>
Message-ID: <44EB04D8-1ACB-4395-94B4-F3DAFAEC6D18@dcn.davis.ca.us>

This could be as simple as looking at the parameter "axis.text.x" and thinking "maybe there is another parameter called axis.text.y that I could try" and reading the ggplot2 help pages for the theme and element_text functions. If not then you need to make your example complete enough (including just enough data to illustrate a problem) that we can run your code and see what you see and hopefully understand why you have a problem. 

Note that the Posting Guide warns you that this is a plain text mailing list, so any pretty HTML formatting or images you use to try to communicate your problem won't reach us and the HTML will very likely garble your example code so that it will no longer run, so please set your email program to send only plain text and illustrate your difficulty using R code. Look for "R reproducible example" in an Internet search engine for more help. 
-- 
Sent from my phone. Please excuse my brevity.

On March 10, 2017 6:45:14 AM PST, greg holly <mak.hholly at gmail.com> wrote:
> Hi all;
>
>The followings are my R codes for heat maps in ggplot2. I need to
>specify
>the font size for the y-axis (x-axis works) as well as font size for
>label
>y and x too. Your help highly appreciated.
>
>Thanks,
>
>Greg
>
>qplot(x=Var1, y=Var2, data=melt(cor(a, use="p")), fill=value,
>geom="tile") +
> scale_fill_gradient2(limits=c(-1, 1))+
> ylab('Super pathways') +
> xlab('Significant Metabolites in Super pathways for DI') +
> theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6))
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Fri Mar 10 17:06:25 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 10 Mar 2017 17:06:25 +0100
Subject: [R] display UTF8 characters in pdf
Message-ID: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>

Dear all,

I'd like to use some UTF-8 characters in a plot. Some of them are not
rendered with saving the plot as pdf. Any suggestions?

library(ggplot2)
symbols <- c("\U1F697", "\U00A9", "\U24DA", "\U00C1")
test <- data.frame(
  x = seq_along(symbols) %% ceiling(sqrt(length(symbols))),
  y = ceiling(seq_along(symbols) / ceiling(sqrt(length(symbols)))),
  symbol = symbols
)
p <- ggplot(test, aes(x = x, y = y, label = symbol)) + geom_text(size = 10)
p
ggsave(p, file = "test.png")
ggsave(p, file = "test.pdf")

The last command gives several similar warnings, all related to the symbols
which are not rendered properly:

Warning messages:
1: In grid.Call.graphics(L_text, as.graphicsAnnot(x$label),  ... :
  conversion failure on '??' in 'mbcsToSbcs': dot substituted for <f0>

I'm running R 3.3.2 under Ubuntu 16.04.1 and ggplot2 2.2.1

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Fri Mar 10 18:24:13 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 10 Mar 2017 22:54:13 +0530
Subject: [R] Error in .jcall
Message-ID: <CAB=p7SoF1mbu5u970EmM1E0UtAuuwmuM1arDK0ndAEh1TD8uoQ@mail.gmail.com>

Hi Team,
I am creating an n-gram analysis on a text mining data however receving the
error as:-

Error in .jcall("RWekaInterfaces", "[S", "tokenize", .jcast(tokenizer,  :
  java.lang.NullPointerException

I have used the function:
Ngramtok= function(x)NGramTokenizer(x, Weka_control(min=1, max=5))
 and then using this as below:-

ngram1= DocumentTermMatrix(cnt_reason,control = list(tokenize= Ngramtok)).

Checked stack overflow for the error here -
http://stackoverflow.com/questions/38605088/creating-ngrams-in-r where it
was advised to remove the blank rows but it did not help.

I have strangely used this earlier but it now not working now.

Please suggest.

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Fri Mar 10 19:21:29 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 10 Mar 2017 13:21:29 -0500
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
	<CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>
Message-ID: <5988a5b3-0b05-fb33-0900-b58f170b0a28@gmail.com>



On 3/10/2017 1:48 AM, Jim Lemon wrote:
> Hi Evan,
> How about this:
>
> df2<-data.frame(Trt=df[,1],Conc=apply(df[,2:5],1,paste,sep="",collapse=""))
>
> Jim
>
>


Thanks!


From evan.cooch at gmail.com  Fri Mar 10 19:22:00 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 10 Mar 2017 13:22:00 -0500
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <CAGxFJbTTTZb=1deCiTgrRVW4oK1C0MWp4AF-Z+eVBF-gM12WOw@mail.gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
	<CAGxFJbTTTZb=1deCiTgrRVW4oK1C0MWp4AF-Z+eVBF-gM12WOw@mail.gmail.com>
Message-ID: <d56e5e63-9eb0-3930-97e1-503ef9b6d9ff@gmail.com>



On 3/10/2017 2:23 AM, Bert Gunter wrote:
> I think you need to spend some time with an R tutorial or two,
> especially with regard to indexing.
>
> Unless I have misunderstood (apologies if I have),
>
> df$Conc <- apply(df[,-1],1,paste,collapse="")
>
> does it.
>
> -- Bert
>
>
\

Thanks -- sage advice.


From evan.cooch at gmail.com  Fri Mar 10 19:22:30 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 10 Mar 2017 13:22:30 -0500
Subject: [R] concatenating range of columns in dataframe
In-Reply-To: <CAKVAULMNoJ5zVDaj5u3UBix_AQ8YYR76nibBXBD-Mq5d6b-QZA@mail.gmail.com>
References: <04108573-eb43-7f5b-9ee1-d970e19211d2@gmail.com>
	<CA+8X3fXpdUScJK2aXjLXEb0L6kBAiNtLF+8F7aeXBdj4XAqVEQ@mail.gmail.com>
	<CAKVAULMNoJ5zVDaj5u3UBix_AQ8YYR76nibBXBD-Mq5d6b-QZA@mail.gmail.com>
Message-ID: <932ac92a-ed56-fd34-294e-26edc064eb2e@gmail.com>



On 3/10/2017 2:24 AM, Ulrik Stervbo wrote:
> Hi Evan,
>
> the unite function of the tidyr package achieves the same as Jim 
> suggested, but in perhaps a slightly more readable manner.
>
> Ulrik
>

I use perl for scripting, so readability isn't a big factor. ;-)

Thanks!


From evan.cooch at gmail.com  Fri Mar 10 19:23:23 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 10 Mar 2017 13:23:23 -0500
Subject: [R] matrix merge, or something else?
In-Reply-To: <E42E43E7-6EB0-4701-B6F6-43315F9C9849@dcn.davis.ca.us>
References: <cff92bba-120b-9ec9-f644-a3812ba88aef@gmail.com>
	<E42E43E7-6EB0-4701-B6F6-43315F9C9849@dcn.davis.ca.us>
Message-ID: <39d1e24e-051e-6cd8-6402-81f3be1daa8a@gmail.com>

Slick -- thanks.

On 3/10/2017 1:26 AM, Jeff Newmiller wrote:
> test2[ , colnames( test1 ) ] <- test1


From rtchiruka at gmail.com  Fri Mar 10 15:49:54 2017
From: rtchiruka at gmail.com (Rayt Chiruka)
Date: Fri, 10 Mar 2017 16:49:54 +0200
Subject: [R] plotting longitudinal data with ggplot
Message-ID: <CAGtiZ8yCZJ8qRaupRQA1MufzHJuBp9AS5tRyh4h8Mw8TMUwPAw@mail.gmail.com>

i am trying to convert a dataset from wide to long format using package
tidyr- (seems to have been done)

wen in try and plot the long dataset using ggplot i keep getting errors

here is the code





*library(tidyr) ht.long<-gather(ray.ht
<http://ray.ht>,age,height,X0:X84,factor_key =
TRUE) ht.long$ID<-factor(ht.long$ID)
ggplot(ht.long,aes(age,height,shape=ID))+geom_line()
ggplot(ht.long,aes(age,height))+
facet_wrap(~ID) + geom_line()*

the error i keep getting is the folowing.


*geom_path: Each group consists of only one observation. Do you need to
adjust the group aesthetic?*

a part of the dataset is shown below

ID X0 X4 X8 X12 X36 X48 X84
1 50 59 65 67 87 95 115
2 54 58 69 71 90 96 115
3 52 64 68 70 91 100 120
4 50 56 67 68 88 95 115
5 54 59 68 72 93 100 120

-- 
R T CHIRUKA
University of Fort Hare
Statistics Department
Box X 1314
Alice
5700
South Africa

	[[alternative HTML version deleted]]


From peter.thuresson at umea.se  Fri Mar 10 16:53:03 2017
From: peter.thuresson at umea.se (Peter Thuresson)
Date: Fri, 10 Mar 2017 15:53:03 +0000
Subject: [R] Forecasting and demography
Message-ID: <C9E6D9118357E9478E14591F14BFDCD002487FE508@ECHTELION.ad.umea.se>

Hello R users,

I wonder if anybody have some info about interesting forecastning population packages/books in R. It is specifically about demographics, i e models for handling fertility rates, mortality and migration etc, i'm interested.

Best regards/Peter

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Fri Mar 10 19:44:18 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 10 Mar 2017 19:44:18 +0100
Subject: [R] "found 4 marked UTF-8 strings" during check of package...
 but where !
In-Reply-To: <712dc385-40b5-52a7-603f-4eb385a57616@gmail.com>
References: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
	<712dc385-40b5-52a7-603f-4eb385a57616@gmail.com>
Message-ID: <d06f37a0-f604-f3a5-a61f-a088ae782252@yahoo.fr>

Thanks Duncan and Michael,

Indeed I have data file with utf-8 characters inside. In the 
DESCRIPTION, I have the line Encoding: UTF-8
but it seems to not be sufficient.
In each R page for these data, I have also :
#' @docType data
#' @encoding UTF-8

But I still have the notes during check when I try to submit the package 
in CRAN (not in local --as-cran check).

How I could "say" that these data have utf-8 characters inside?

Thanks
Marc


Le 10/03/2017 ? 15:24, Duncan Murdoch a ?crit :
> On 10/03/2017 2:52 AM, Marc Girondot via R-help wrote:
>> Dear members,
>>
>> I want submit to CRAN a new version of a package that I maintain. When I
>> check locally "as-cran" no note or error are reported but the link after
>> submission reports several notes and one warning:
>>
>> For example:
>>
>> using R Under development (unstable) (2017-03-05 r72309)
>> using platform: x86_64-apple-darwin16.4.0 (64-bit)
>> using session charset: UTF-8
>> ...
>> checking extension type ... Package
>> this is package ?embryogrowth? version ?6.4?
>> package encoding: UTF-8
>> ...
>> checking data for non-ASCII characters ... NOTE
>>    Note: found 4 marked UTF-8 strings
>>
>> I have the same with
>> using R version 3.3.0 (2016-05-03)
>> using platform: x86_64-apple-darwin13.4.0 (64-bit)
>>
>> but not with some others such as r-devel-linux-x86_64-debian-gcc
>>
>> Based on the message, "Note: found 4 marked UTF-8 strings", it seems
>> that "4 marked UTF-8 strings" are present in the package and it is a
>> problem...
>>
>> Is there any solution to know in which file?
>
> It's one containing an object coming from your data directory.
>
> R won't give more detail than that, but if you still can't guess, you 
> could get some idea by debugging the check code:
>
> debug(tools:::.check_package_datasets)
> tools:::.check_package_datasets(pkg)
>
> where pkg contains the path to the package source code.  That function 
> does the checking one variable at a time.
>
> Duncan Murdoch
>
>
>


From murdoch.duncan at gmail.com  Fri Mar 10 20:06:41 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Mar 2017 11:06:41 -0800
Subject: [R] "found 4 marked UTF-8 strings" during check of package...
 but where !
In-Reply-To: <d06f37a0-f604-f3a5-a61f-a088ae782252@yahoo.fr>
References: <67331f27-0c9b-2f6e-47c8-16e4688a76f0@yahoo.fr>
	<712dc385-40b5-52a7-603f-4eb385a57616@gmail.com>
	<d06f37a0-f604-f3a5-a61f-a088ae782252@yahoo.fr>
Message-ID: <66cd024c-ab9d-bcbb-99b8-4359f672e32d@gmail.com>

On 10/03/2017 10:44 AM, Marc Girondot via R-help wrote:
> Thanks Duncan and Michael,
>
> Indeed I have data file with utf-8 characters inside. In the
> DESCRIPTION, I have the line Encoding: UTF-8
> but it seems to not be sufficient.

That line describes how text files in your package are to be interpreted.

> In each R page for these data, I have also :
> #' @docType data
> #' @encoding UTF-8

R ignores those lines, but presumably you're running Roxygen2, which 
will use them when it produces the .Rd files for the help topics.  They 
have nothing to do with the data itself.

>
> But I still have the notes during check when I try to submit the package
> in CRAN (not in local --as-cran check).
>
> How I could "say" that these data have utf-8 characters inside?

If those are intentional, just say so when you submit to CRAN in the 
submission comments, but do read the comments about portability in 
section 1.6.3 of the Writing R Extensions manual.

Duncan Murdoch

P.S. This question doesn't belong in R-help, it belongs in 
R-package-devel.  If you have any followup questions, please post them 
there.


>
> Thanks
> Marc
>
>
> Le 10/03/2017 ? 15:24, Duncan Murdoch a ?crit :
>> On 10/03/2017 2:52 AM, Marc Girondot via R-help wrote:
>>> Dear members,
>>>
>>> I want submit to CRAN a new version of a package that I maintain. When I
>>> check locally "as-cran" no note or error are reported but the link after
>>> submission reports several notes and one warning:
>>>
>>> For example:
>>>
>>> using R Under development (unstable) (2017-03-05 r72309)
>>> using platform: x86_64-apple-darwin16.4.0 (64-bit)
>>> using session charset: UTF-8
>>> ...
>>> checking extension type ... Package
>>> this is package ?embryogrowth? version ?6.4?
>>> package encoding: UTF-8
>>> ...
>>> checking data for non-ASCII characters ... NOTE
>>>    Note: found 4 marked UTF-8 strings
>>>
>>> I have the same with
>>> using R version 3.3.0 (2016-05-03)
>>> using platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>
>>> but not with some others such as r-devel-linux-x86_64-debian-gcc
>>>
>>> Based on the message, "Note: found 4 marked UTF-8 strings", it seems
>>> that "4 marked UTF-8 strings" are present in the package and it is a
>>> problem...
>>>
>>> Is there any solution to know in which file?
>>
>> It's one containing an object coming from your data directory.
>>
>> R won't give more detail than that, but if you still can't guess, you
>> could get some idea by debugging the check code:
>>
>> debug(tools:::.check_package_datasets)
>> tools:::.check_package_datasets(pkg)
>>
>> where pkg contains the path to the package source code.  That function
>> does the checking one variable at a time.
>>
>> Duncan Murdoch
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Fri Mar 10 20:49:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Mar 2017 11:49:52 -0800
Subject: [R] Forecasting and demography
In-Reply-To: <C9E6D9118357E9478E14591F14BFDCD002487FE508@ECHTELION.ad.umea.se>
References: <C9E6D9118357E9478E14591F14BFDCD002487FE508@ECHTELION.ad.umea.se>
Message-ID: <CAGxFJbSzEH-T+MF1FYQgVYGrvopDJ9SQQJJjaGP8QA_XU85pSQ@mail.gmail.com>

Please search before such posting!

googling "R demography" immediately brought up the "demography"
package (including references therein, I'm sure).

"Forecasting population in R" brought up additional hits.

etc.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 10, 2017 at 7:53 AM, Peter Thuresson
<peter.thuresson at umea.se> wrote:
> Hello R users,
>
> I wonder if anybody have some info about interesting forecastning population packages/books in R. It is specifically about demographics, i e models for handling fertility rates, mortality and migration etc, i'm interested.
>
> Best regards/Peter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Fri Mar 10 21:13:05 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 10 Mar 2017 15:13:05 -0500
Subject: [R] display UTF8 characters in pdf
In-Reply-To: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
References: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
Message-ID: <CA+vqiLF73dOUc-KoV6J51G0Pa5iFwbJUjzbNXouTv7xuWfBLzQ@mail.gmail.com>

install.packages("emojifont")
library(emojifont)

... # plot as before.

Best,
Ista

On Fri, Mar 10, 2017 at 11:06 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear all,
>
> I'd like to use some UTF-8 characters in a plot. Some of them are not
> rendered with saving the plot as pdf. Any suggestions?
>
> library(ggplot2)
> symbols <- c("\U1F697", "\U00A9", "\U24DA", "\U00C1")
> test <- data.frame(
>   x = seq_along(symbols) %% ceiling(sqrt(length(symbols))),
>   y = ceiling(seq_along(symbols) / ceiling(sqrt(length(symbols)))),
>   symbol = symbols
> )
> p <- ggplot(test, aes(x = x, y = y, label = symbol)) + geom_text(size = 10)
> p
> ggsave(p, file = "test.png")
> ggsave(p, file = "test.pdf")
>
> The last command gives several similar warnings, all related to the symbols
> which are not rendered properly:
>
> Warning messages:
> 1: In grid.Call.graphics(L_text, as.graphicsAnnot(x$label),  ... :
>   conversion failure on '??' in 'mbcsToSbcs': dot substituted for <f0>
>
> I'm running R 3.3.2 under Ubuntu 16.04.1 and ggplot2 2.2.1
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Olivier.Crouzet at univ-nantes.fr  Fri Mar 10 21:22:02 2017
From: Olivier.Crouzet at univ-nantes.fr (Olivier CROUZET)
Date: Fri, 10 Mar 2017 21:22:02 +0100
Subject: [R] display UTF8 characters in pdf
In-Reply-To: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
References: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
Message-ID: <20170310211721.698836368b098bb39a3840d5@univ-nantes.fr>

Hi,

AFAICT, you need to use a Cairo device for being able to display some 
Unicode
characters in a plot.

 From my experience, the CairoPDF() from library(Cairo) does not work
(and I don't understand the difference with cairo_pdf()), but the
cairo_pdf() from grDevices does work perfectly well for this aim. As far
as I'm concerned, I use it with both ggplot2 and regular plots and it
does a perfect job. Here is a short example:

In an R console:

cairo_pdf(filename = "test.pdf")
plot(1,1,pch = "\u254")
dev.off()

Also, I use it with knitr and it works great. You just have to declare a
specific device ("cairo_pdf").

For example, in an RMarkdown document:

```{r ipaunicode, echo=TRUE, dev='cairo_pdf'}
plot(1, 1, pch = "\u254")
```

and in a LaTeX / knitr document as well:

<<ipaunicode, dev="cairo_pdf">>=
plot(1, 1, pch = "\u251")
@

Hope this helps.

Yours.
Olivier.

On Fri, 10 Mar
2017 17:06:25 +0100 Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> Dear all,
> 
> I'd like to use some UTF-8 characters in a plot. Some of them are not
> rendered with saving the plot as pdf. Any suggestions?
> 
> library(ggplot2)
> symbols <- c("\U1F697", "\U00A9", "\U24DA", "\U00C1")
> test <- data.frame(
>   x = seq_along(symbols) %% ceiling(sqrt(length(symbols))),
>   y = ceiling(seq_along(symbols) / ceiling(sqrt(length(symbols)))),
>   symbol = symbols
> )
> p <- ggplot(test, aes(x = x, y = y, label = symbol)) + geom_text(size
> = 10) p
> ggsave(p, file = "test.png")
> ggsave(p, file = "test.pdf")
> 
> The last command gives several similar warnings, all related to the
> symbols which are not rendered properly:
> 
> Warning messages:
> 1: In grid.Call.graphics(L_text, as.graphicsAnnot(x$label),  ... :
>   conversion failure on '??' in 'mbcsToSbcs': dot substituted for <f0>
> 
> I'm running R 3.3.2 under Ubuntu 16.04.1 and ggplot2 2.2.1
> 
> Best regards,
> 
> Thierry
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

-- 
   Olivier Crouzet, PhD
   /Assistant Professor/
   @LLING - Laboratoire de Linguistique de Nantes
     UMR6310 CNRS / Universit? de Nantes
   /Guest Researcher/
   @UMCG (University Medical Center Groningen)
     ENT department
     Reijksuniversiteit Groningen


From bgunter.4567 at gmail.com  Fri Mar 10 22:46:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Mar 2017 13:46:14 -0800
Subject: [R] New package: remindR
Message-ID: <CAGxFJbS+2ASj=07OTtzN7SSANYAFY7YKAtW+3VqWuMX=_iC5tw@mail.gmail.com>

Note: The following post to r-packages seems not to have made it to
r-help for some reason. So I am replicating it explicitly here.

-- Bert Gunter



remindR is a simple, small package with essentially a single purpose:
to Insert/extract text "reminders" into/from function source code
comments or as the "comment" attribute of any object. The intent is
that the former could be handy in the course of program development to
remind one of e.g. argument requirements, to-do's, required options
settings, etc. The latter, which just wraps R's existing comment()
function, could also be used to provide information on objects or to
provide simple manual "tooltips" for users.

If interested, please have a look at the package vignette, which
provide a fuller explanation of how and why this might be useful and
how it works.

All feedback welcome: bgunter.4567 at gmail.com


From bgunter.4567 at gmail.com  Fri Mar 10 23:05:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Mar 2017 14:05:55 -0800
Subject: [R] New package: remindR
In-Reply-To: <F74791A0-EBF2-4CF3-B571-88BFA862411B@me.com>
References: <CAGxFJbS+2ASj=07OTtzN7SSANYAFY7YKAtW+3VqWuMX=_iC5tw@mail.gmail.com>
	<F74791A0-EBF2-4CF3-B571-88BFA862411B@me.com>
Message-ID: <CAGxFJbRC0G7Hn966hQ78Szmb-Yisdmj-ZePRwzBqkr5Nwqn7ZQ@mail.gmail.com>

Thanks, Marc.

That is puzzling, as I did not. Ergo: my bad! However, I'm happy to be
wrong, and want to note publicly that I am, so people don't waste any
time wondering why. Hopefully, no harm done.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 10, 2017 at 1:57 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Bert,
>
> FYI, it did make it to R-Help, as I recall seeing it. It is here in the
> R-Help archive:
>
>   https://stat.ethz.ch/pipermail/r-help/2017-March/445325.html
>
> Regards,
>
> Marc
>
>
> On Mar 10, 2017, at 3:46 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Note: The following post to r-packages seems not to have made it to
> r-help for some reason. So I am replicating it explicitly here.
>
> -- Bert Gunter
>
>
>
> remindR is a simple, small package with essentially a single purpose:
> to Insert/extract text "reminders" into/from function source code
> comments or as the "comment" attribute of any object. The intent is
> that the former could be handy in the course of program development to
> remind one of e.g. argument requirements, to-do's, required options
> settings, etc. The latter, which just wraps R's existing comment()
> function, could also be used to provide information on objects or to
> provide simple manual "tooltips" for users.
>
> If interested, please have a look at the package vignette, which
> provide a fuller explanation of how and why this might be useful and
> how it works.
>
> All feedback welcome: bgunter.4567 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Sat Mar 11 03:09:41 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 10 Mar 2017 18:09:41 -0800
Subject: [R] Interpretation of lme results with intercorrelation between
	fixed factors
In-Reply-To: <DB4PR01MB382584C4A1FA891BDFBEB3FCB200@DB4PR01MB382.eurprd01.prod.exchangelabs.com>
References: <DB4PR01MB382584C4A1FA891BDFBEB3FCB200@DB4PR01MB382.eurprd01.prod.exchangelabs.com>
Message-ID: <D8A79952-973A-4FF4-9E1F-16DED53FEAD0@comcast.net>


> On Mar 10, 2017, at 3:22 AM, Vasillis Papathanasiou <vpapathanasiou at hotmail.com> wrote:
> 
> I?m running a mixed model analysis with 2 fixed factors that are intercorrelated using the lme function and I?m having difficulties in interpreting the results.
> As I?m quite novice I?ll try to use a very simple example.

I'm guessing this is perhaps the `lme` function in pkg:nlme. It's not really an appropriate question for rhelp in any event. See the Posting Guide (link below).

> 
> My model is lme(Y~A*B). A has 3 levels (1, 2 and 3) and B has 2 levels (I and II).
> My results are something like this:
> 

Better to include actual output. I think most statisticians would advise focussing on model comparisons rather than p-values of individual coefficients.

The experts hang out at:

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

... and they tend to be more welcoming for "interpretation" questions.

Or post to CrossValidated.com where this would be on topic. That group generally tries to avoid purely R questions, but your question is so devoid of actual R (no code and no actual output) that it would probably not be closed for that reason.

Best;
David.

> 


> 
> P statistic
> 
> B:II
> 
> P=0.01
> 
> A:2
> 
> P=0.01
> 
> A:3
> 
> P=0.09
> 
> II*2
> 
> P=0.61
> 
> II*3
> 
> P=0.031
> 
> 
> My question is as follows. I understand that R keeps a level of each factor and reports any statistical differences to it. So in this example it reports that II is different than I and 2 against 3. However when it comes to the intercorrelation, what does it report? Does it compare II*2 and II*3 to II*1 and if so what happens with I*2 and I*3? Or does it compare II*2 to I*2 and II*3 to I*3 and if so what happens to I*1 and II*1?
> 
> Thank you
> 
> 
> Vasillis
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From padmanabhan.vijayan at gmail.com  Sat Mar 11 05:12:13 2017
From: padmanabhan.vijayan at gmail.com (Vijayan Padmanabhan)
Date: Sat, 11 Mar 2017 09:42:13 +0530
Subject: [R] reading form data from pdf forms
Message-ID: <CAH7cWrTu_SfnKBnvaZc7Z-b_LaFJxKEshFzqX7fT_2TgmgMyaQ@mail.gmail.com>

Dear R-Help group
Is there any way that I can programmatically extract form field values from
a pdf form (either saved as pdf or fdf) in R?
I would wish to not be dependent on any Paid tool for this purpose.
Any guidance would be much appreciated.

Regards
VP

	[[alternative HTML version deleted]]


From fadeh2013 at gmail.com  Fri Mar 10 23:40:07 2017
From: fadeh2013 at gmail.com (Fadhah)
Date: Sat, 11 Mar 2017 08:40:07 +1000
Subject: [R] Help with lapply and tapply
Message-ID: <4A75088E-D4BF-4C80-9F6D-2A0535D479F6@gmail.com>

Dear all, 

Thank you in advance for your time and help. I quite new to R and face a problem with lapply and tapply functions. 
I simulated data and run the simulation 10 times to get 10 different simulated data. I have also built up my function and would like to apply this function to these 10 different data without repeating the code for 10 times. I now that we can use a loop family functions in R such as lapply or tapply functions. I tried both of them but both of them did not work. My data was stored as vector mode list. 

Here is my data:

library(VineCopula)
library(copula) 
Runs= 10 Saveas = vector(mode = "list", length = Runs) 
 pb <- txtProgressBar(min = 0, max = Runs, style = 3) 
for(j in 1:Runs){ 
 setTxtProgressBar(pb, j)
N=2000 
 dim=dim 
 U=runif(N, min=0,max=1) 
 X = matrix(NA, nrow=N, ncol=2)
inds <- U < 0.7 
 X[inds, ] <- rCopula(sum(inds), claytonCopula(1, dim=2)) 
 X[!inds, ] <- rCopula(N - sum(inds), frankCopula(4, dim=2)) 
Saveas[[j]] = X }
Then I built my function. I would like to apply this function to the 10 simulation run. That is I have 10 simulated data and would like to run my function to these data. I tried lapply and tapply function but I got  errors.
This is my function:

FUN1 <- EM_mixture_copula(data = Saveas[[j]],pi_1=pi_1,pi_2=pi_2,theta = theta,                Theta=Theta, tol = .00001, maxit = 1000)
Here is my tries with the errors that I got:

> result <- tapply(X,FUN1,simplify = T)
Error in tapply(X, FUN, simplify = T) : arguments must have same length.

> Result <? lapply(X,FUN1)
Error in get(as.character(FUN), mode = "function", envir = envir) : object 'F' of mode 'function' was not found.



Once I got the result, I would like to have a summary statistics of my function for each run. So, can I use 

Summary(result) ?

Any help, please?
Kinds regards, 
Fadhah

Sent from my iPhone
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 11 06:22:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Mar 2017 21:22:10 -0800
Subject: [R] Help with lapply and tapply
In-Reply-To: <4A75088E-D4BF-4C80-9F6D-2A0535D479F6@gmail.com>
References: <4A75088E-D4BF-4C80-9F6D-2A0535D479F6@gmail.com>
Message-ID: <CAGxFJbTXNsc_SpWhqCwEh5KqMSi78t1zbBgpJnaVFcYAFNj-Kg@mail.gmail.com>

In short, you really need to study the Help files carefully for both,
as you are using both tapply and lapply incorrectly. If that doesn't
work, I think you should spend some time with one of the many
excellent R tutorials on the web. You need to beef up your
understanding of the syntax.

But briefly:

1) the tapply call must be of the form tapply(x, fac, fun) where x is
atomic (i.e. a vector) and fac is a factor that splits x into groups.
You have obviously got the call all wrong.

2) And in the second, X must be a list or vector, not a matrix and the
function needs to have its elements as an argument, something like FUN
= function(x)FUN1(x, ... your other arguments...)

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 10, 2017 at 2:40 PM, Fadhah <fadeh2013 at gmail.com> wrote:
> Dear all,
>
> Thank you in advance for your time and help. I quite new to R and face a problem with lapply and tapply functions.
> I simulated data and run the simulation 10 times to get 10 different simulated data. I have also built up my function and would like to apply this function to these 10 different data without repeating the code for 10 times. I now that we can use a loop family functions in R such as lapply or tapply functions. I tried both of them but both of them did not work. My data was stored as vector mode list.
>
> Here is my data:
>
> library(VineCopula)
> library(copula)
> Runs= 10 Saveas = vector(mode = "list", length = Runs)
>  pb <- txtProgressBar(min = 0, max = Runs, style = 3)
> for(j in 1:Runs){
>  setTxtProgressBar(pb, j)
> N=2000
>  dim=dim
>  U=runif(N, min=0,max=1)
>  X = matrix(NA, nrow=N, ncol=2)
> inds <- U < 0.7
>  X[inds, ] <- rCopula(sum(inds), claytonCopula(1, dim=2))
>  X[!inds, ] <- rCopula(N - sum(inds), frankCopula(4, dim=2))
> Saveas[[j]] = X }
> Then I built my function. I would like to apply this function to the 10 simulation run. That is I have 10 simulated data and would like to run my function to these data. I tried lapply and tapply function but I got  errors.
> This is my function:
>
> FUN1 <- EM_mixture_copula(data = Saveas[[j]],pi_1=pi_1,pi_2=pi_2,theta = theta,                Theta=Theta, tol = .00001, maxit = 1000)
> Here is my tries with the errors that I got:
>
>> result <- tapply(X,FUN1,simplify = T)
> Error in tapply(X, FUN, simplify = T) : arguments must have same length.
>
>> Result <? lapply(X,FUN1)
> Error in get(as.character(FUN), mode = "function", envir = envir) : object 'F' of mode 'function' was not found.
>
>
>
> Once I got the result, I would like to have a summary statistics of my function for each run. So, can I use
>
> Summary(result) ?
>
> Any help, please?
> Kinds regards,
> Fadhah
>
> Sent from my iPhone
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From denis.francisci at gmail.com  Sat Mar 11 10:21:24 2017
From: denis.francisci at gmail.com (Denis Francisci)
Date: Sat, 11 Mar 2017 10:21:24 +0100
Subject: [R] problem with PCA
In-Reply-To: <023ddc217f1d44f483feb489c6e8da5e@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAJMcJMC+JmZwc6sGD+e5FJ+9knixvERXMkP0DkvPtu+CUbdN-w@mail.gmail.com>
	<023ddc217f1d44f483feb489c6e8da5e@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAJMcJMBQe=j2rpcemhnPzZKvvboOiRRK2SY0OimtJhuLtVD5mg@mail.gmail.com>

Thank you David for your answer.
If I understood the relative positions of variable arrows don't reflect the
coefficient of correlation of the original variables. In fact these
positions change if I use different PC axes.
But in some manual about PCA in R I read: "Pairs of variables that form
acute angles at the origin, close to 0?, should be highly and positively
correlated; variables close to right angles tend to have low correlation;
variables at obtuse angles, close to 180?, tend to have high negative
correlation".

And If I do a fictional test, it seems true:

tb<-data.frame(
  c(1,2,3,4,5,6,7,8,9), #orig data
  c(2,4,5,8,10,12,14,16,18),#strong positive correlation
  c(25,29,52,63,110,111,148,161,300),#weakly correlation
  c(-1,-2,-3,-4,-5,-6,-7,-8,-9),#strong negative correlation
  c(3,8,4,6,1,3,2,5,7)#not correlation
)
names(tb)<-c("orig","corr+","corr+2","corr-","random")

pca<-prcomp(as.matrix(tb),scale=T)
biplot(pca,choices = c(1,2))

On the first 2 PC the positions of arrows reflect perfectly the original
correlations.

My data behaviour differently, maybe because my original variables are not
strong correlated?

2017-03-10 15:49 GMT+01:00 David L Carlson <dcarlson at tamu.edu>:

> This is more a question about principal components analysis than about R.
> You have 4 variables and they are moderately correlated with one another
> (weight and hole are only .2). When the data consist of measurements, this
> usually suggests that the overall size of the object is being partly
> measured by each variable. In your case object size is measured by the
> first principle component (PC1) with larger objects having more negative
> scores so larger objects are on the left and smaller ones are on the right
> of the biplot.
>
> The biplot can only display 2 of the 4 dimensions of your data at one
> time. In the first 2 dimensions, diam and height are close together, but in
> the 3rd dimension (PC3), they are on opposite sides of the component. If
> you plot different pairs of dimensions (e.g. 1 with 3 or 2 with 3, see
> below), the arrows will look different because you are looking from
> different directions.
>
> > pca
> Standard deviations:
> [1] 1.5264292 0.8950379 0.7233671 0.5879295
>
> Rotation:
>               PC1         PC2         PC3        PC4
> height -0.5210224 -0.06545193  0.80018012 -0.2897646
> diam   -0.5473677  0.06309163 -0.57146893 -0.6081376
> hole   -0.4598646 -0.70952862 -0.17476677  0.5045297
> weight -0.4663141  0.69878797 -0.05090785  0.5400508
>
> > biplot(pca, choices=c(1, 3))
> > biplot(pca, choices=c(2, 3))
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Denis
> Francisci
> Sent: Friday, March 10, 2017 4:45 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] problem with PCA
>
> Hi all.
> I'm newbie in PCA by I don't understand a behaviour of R.
> I have this data matrix:
>
> >mx_fus
>   height diam  hole  weight
> 1    2.3  3.5  1.1   18
> 2    2.0  3.5  0.9   17
> 3    3.8  4.3  0.7   34
> 4    2.1  3.4  0.9   15
> 5    2.3  3.8  1.0   19
> 6    2.2  3.8  1.0   19
> 7    3.2  4.4  0.9   34
> 8    3.0  4.3  1.0   30
> 9    2.8  3.9  0.9   21
> 10   3.3  4.2  1.1   33
> 11   2.3  3.9  0.9   25
> 12   2.3  3.3  0.5   17
> 13   0.9  2.4  0.4   10
> 14   1.4  2.4  0.5   10
> 15   2.2  3.6  0.7   22
> 16   2.9  3.8  0.8   30
> 17   2.9  3.5  0.6   27
> 18   2.3  3.5  0.5   24
> 19   1.8  2.3  0.5   29
> 20   1.4  2.5  0.6   34
> 21   0.8  2.3  0.6   21
> 22   1.8  2.4  0.6   23
> 23   1.5  2.2  0.6    7
> 24   0.9  1.7  0.4   14
> 25   2.1  2.2  0.5   25
> 26   1.3  2.4  0.6   33
> 27   1.3  2.7  0.4   39
> 28   0.5  2.2  0.5   13
> 29   1.4  4.2  0.8   23
> 30   1.6  2.0  0.4   30
> 31   1.4  2.2  0.6   25
> 32   1.8  2.5  0.6   28
> 33   1.4  2.6  0.6   41
> 34   1.6  2.3  0.3   32
> 35   1.6  2.5  0.5   41
> 36   2.8  2.9  0.8   47
> 37   0.6  2.5  0.8   21
> 38   1.6  2.8  0.7   13
> 39   1.7  3.3  0.8   17
> 40   1.6  3.9  1.9   20
> 41   1.4  4.7  0.9   26
> 42   1.2  4.2  0.7   21
> 43   3.5  4.2  0.9   47
> 44   2.3  3.6  0.7   24
> 45   2.3  3.4  0.4   21
> 46   1.9  2.6  0.7   14
> 47   1.9  3.0  0.7   15
> 48   2.7  3.7  0.9   26
> 49   3.0  3.8  0.7   35
> 50   1.2  2.0  0.7    5
> 51   1.6  2.5  0.5   15
> 52   1.3  2.6  0.5   16
> 53   2.5  3.9  0.9   32
> 54   0.9  3.3  0.6    9
> 55   1.8  2.4  0.5   17
> 56   2.4  3.7  1.1   30
> 57   2.1  3.5  1.1   22
> 58   2.6  3.9  1.0   38
> 59   2.6  3.6  1.0   27
> 60   2.6  4.1  1.0   34
> 61   2.9  3.6  0.8   32
> 62   2.6  3.3  0.7   22
> 63   1.8  2.5  0.7   26
> 64   3.0  2.8  1.3    2
> 65   0.5  2.2  0.4    3
> 66   1.9  3.4  0.7   14
> 67   1.4  3.8  0.9   18
> 68   2.0  4.0  1.0   30
> 69   3.1  4.0  1.3   21
> 70   2.5  4.0  0.8   19
> 71   2.5  4.5  1.0   20
> 72   1.8  3.5  1.4   18
> 73   2.1  3.5  1.4   25
> 74   1.5  2.6  0.5    9
> 75   2.8  3.2  1.2   16
> 76   1.0  5.0  0.3   32
> 77   0.3  5.8  0.5   56
> 78   0.5  1.5  0.2    1
> 79   0.7  1.4  0.2    1
> 80   0.5  1.3  0.2    1
> 81   0.7  3.3  0.4    7
> 82   1.9  4.7  1.0   24
> 83   3.1  4.2  0.9   49
> 84   2.8  3.6  0.7   28
> 85   2.7  3.2  0.7   29
> 86   3.0  4.0  0.9   36
> 87   1.7  2.7  0.7   14
> 88   1.5  2.9  0.7   18
> 89   2.9  3.5  0.7   30
> 90   3.0  3.4  0.8   30
> 91   2.0  2.8  0.5   14
> 92   2.4  3.5  0.7   24
> 93   0.8  4.1  0.6   12
> 94   1.7  2.5  0.5   23
> 95   1.4  2.4  0.8   31
> 96   1.5  2.7  0.4   20
> 97   2.6  3.7  0.6   31
> 98   2.6  3.0  0.6   18
> 99   2.5  5.0  0.7   40
> 100  2.5  3.7  0.5   30
> 101  2.4  2.9  0.7   17
> 102  2.3  3.0  0.5   15
> 103  2.2  3.3  0.6   19
> 104  1.5  2.1  0.5    5
> 105  2.0  2.2  0.5   10
> 106  2.6  3.5  0.6   26
> 107  2.3  3.0  0.6   15
> 108  2.5  4.5  0.7   40
> 109  2.1  3.1  0.5   15
> 110  1.3  2.1  0.8   14
> 111  0.8  2.5  0.2    5
> 112  0.6  3.1  0.7    8
>
> I perform a PCA in R
>
> >pca<-prcomp(mx_fus,scale=TRUE)
> >biplot(pca, choices = c(1,2), cex=0.7)
>
> The biplot put the arrows of diam and height very near on the first
> component axis.
> So I understand that these 2 variables are well represented in the PC1 and
> they are correlated each other.
> But if I test the correlation, the value o correlation coefficient is low
>
> >cor(mx_fus[,1],mx_fus[,2])
> 0.4828185
>
> Why the plot says a thing and correlation function says the opposite?
> Two near arrows don't represent a strong correlation between the 2
> variables (as I read in some manuals), but only with the component axis?
>
> Than's in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Mar 11 10:50:06 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 11 Mar 2017 10:50:06 +0100
Subject: [R] write.xlsx
In-Reply-To: <e8c61b4a-4433-111e-8cd1-8b483a7137f4@dewey.myzen.co.uk>
References: <CAMtDb69BGeSkUe8SYABO77QAe9vfnB-HzA6_zkOHTUhhvHnUdg@mail.gmail.com>
	<e8c61b4a-4433-111e-8cd1-8b483a7137f4@dewey.myzen.co.uk>
Message-ID: <C8283A12-96E8-425D-9B9B-8555BFD8589B@gmail.com>

Also, this is from a package. Which? (AFAIR, there are at least two possibilities). What is is the docs? Does it even allow an append= argument?

-pd



> On 10 Mar 2017, at 14:49 , Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Dear Paul
> 
> Have you defined a variable T or F somewhere?
> Rather than look to find out why not replace T by TRUE and F by FALSE and see if that solves your problem.
> 
> On 10/03/2017 07:58, Paul Anthony Front?ri wrote:
>> Hey.
>> 
>> I am trying to append a sheet to an existing file using write.xlsx, see
>> code under:
>> 
>> write.xlsx(x = data1,file = filename,sheetName = "data1", asTable = FALSE,
>> col.names = T,row.names = F,append = F)
>> write.xlsx(x = data2,file = filename,sheetName = "data2", asTable = FALSE,
>> col.names = T,row.names = F,append = T)
>> 
>> However, when using the last line does it not append it to the file, but
>> overwrite the file. Meaning that the file, which I have have called:
>> 
>> filename <- "test.xlsx"
>> 
>> only includes one sheet - data2. The first data sheet is not there. Why
>> does not append work with write.xlsx?
>> 
>> Paul
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ulrik.stervbo at gmail.com  Sat Mar 11 11:16:57 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 11 Mar 2017 10:16:57 +0000
Subject: [R] reading form data from pdf forms
In-Reply-To: <CAH7cWrTu_SfnKBnvaZc7Z-b_LaFJxKEshFzqX7fT_2TgmgMyaQ@mail.gmail.com>
References: <CAH7cWrTu_SfnKBnvaZc7Z-b_LaFJxKEshFzqX7fT_2TgmgMyaQ@mail.gmail.com>
Message-ID: <CAKVAULPMN-0fxcgfucBYJCO7h3wDxDUEQt+XLG5=Jby5jDNJng@mail.gmail.com>

I don't know if there's a pure R option, but i believe pdftk can extract
the form data which you can then manipulate in R.

Best
Ulrik

On Sat, 11 Mar 2017, 05:14 Vijayan Padmanabhan, <
padmanabhan.vijayan at gmail.com> wrote:

> Dear R-Help group
> Is there any way that I can programmatically extract form field values from
> a pdf form (either saved as pdf or fdf) in R?
> I would wish to not be dependent on any Paid tool for this purpose.
> Any guidance would be much appreciated.
>
> Regards
> VP
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sat Mar 11 11:20:30 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 11 Mar 2017 10:20:30 +0000
Subject: [R] plotting longitudinal data with ggplot
In-Reply-To: <CAGtiZ8yCZJ8qRaupRQA1MufzHJuBp9AS5tRyh4h8Mw8TMUwPAw@mail.gmail.com>
References: <CAGtiZ8yCZJ8qRaupRQA1MufzHJuBp9AS5tRyh4h8Mw8TMUwPAw@mail.gmail.com>
Message-ID: <CAKVAULPB1N7Nd-ct18UrisQ7ieRW=gKPv5D5mmcYA1RKg8akAw@mail.gmail.com>

You need to set the aesthetic 'group' to something meaningful, probably ID
in this case.

HTH
Ulrik

On Fri, 10 Mar 2017, 19:30 Rayt Chiruka, <rtchiruka at gmail.com> wrote:

> i am trying to convert a dataset from wide to long format using package
> tidyr- (seems to have been done)
>
> wen in try and plot the long dataset using ggplot i keep getting errors
>
> here is the code
>
>
>
>
>
> *library(tidyr) ht.long<-gather(ray.ht
> <http://ray.ht>,age,height,X0:X84,factor_key =
> TRUE) ht.long$ID<-factor(ht.long$ID)
> ggplot(ht.long,aes(age,height,shape=ID))+geom_line()
> ggplot(ht.long,aes(age,height))+
> facet_wrap(~ID) + geom_line()*
>
> the error i keep getting is the folowing.
>
>
> *geom_path: Each group consists of only one observation. Do you need to
> adjust the group aesthetic?*
>
> a part of the dataset is shown below
>
> ID X0 X4 X8 X12 X36 X48 X84
> 1 50 59 65 67 87 95 115
> 2 54 58 69 71 90 96 115
> 3 52 64 68 70 91 100 120
> 4 50 56 67 68 88 95 115
> 5 54 59 68 72 93 100 120
>
> --
> R T CHIRUKA
> University of Fort Hare
> Statistics Department
> Box X 1314
> Alice
> 5700
> South Africa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Sat Mar 11 11:29:34 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Sat, 11 Mar 2017 02:29:34 -0800
Subject: [R] Help with lapply and tapply
In-Reply-To: <CAGxFJbTXNsc_SpWhqCwEh5KqMSi78t1zbBgpJnaVFcYAFNj-Kg@mail.gmail.com>
References: <4A75088E-D4BF-4C80-9F6D-2A0535D479F6@gmail.com>
	<CAGxFJbTXNsc_SpWhqCwEh5KqMSi78t1zbBgpJnaVFcYAFNj-Kg@mail.gmail.com>
Message-ID: <CACdH2ZbgCto8q3-fEchSAYsbY6SmPMhPJegtEUBH5id4Nav5iA@mail.gmail.com>

I think Bert's advice is sound.  Let me add a few, miscellaneous comments:

(1) Some people find "by" easier than "tapply".
(2) The "apply" function can, as I'm sure you (Bert) know, iterate
over a matrix.
(3) Hadley probably has better ways to do all of this (it's hard to keep up).

-- Mike


On Fri, Mar 10, 2017 at 9:22 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> In short, you really need to study the Help files carefully for both,
> as you are using both tapply and lapply incorrectly. If that doesn't
> work, I think you should spend some time with one of the many
> excellent R tutorials on the web. You need to beef up your
> understanding of the syntax.
>
> But briefly:
>
> 1) the tapply call must be of the form tapply(x, fac, fun) where x is
> atomic (i.e. a vector) and fac is a factor that splits x into groups.
> You have obviously got the call all wrong.
>
> 2) And in the second, X must be a list or vector, not a matrix and the
> function needs to have its elements as an argument, something like FUN
> = function(x)FUN1(x, ... your other arguments...)
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 10, 2017 at 2:40 PM, Fadhah <fadeh2013 at gmail.com> wrote:
>> Dear all,
>>
>> Thank you in advance for your time and help. I quite new to R and face a problem with lapply and tapply functions.
>> I simulated data and run the simulation 10 times to get 10 different simulated data. I have also built up my function and would like to apply this function to these 10 different data without repeating the code for 10 times. I now that we can use a loop family functions in R such as lapply or tapply functions. I tried both of them but both of them did not work. My data was stored as vector mode list.
>>
>> Here is my data:
>>
>> library(VineCopula)
>> library(copula)
>> Runs= 10 Saveas = vector(mode = "list", length = Runs)
>>  pb <- txtProgressBar(min = 0, max = Runs, style = 3)
>> for(j in 1:Runs){
>>  setTxtProgressBar(pb, j)
>> N=2000
>>  dim=dim
>>  U=runif(N, min=0,max=1)
>>  X = matrix(NA, nrow=N, ncol=2)
>> inds <- U < 0.7
>>  X[inds, ] <- rCopula(sum(inds), claytonCopula(1, dim=2))
>>  X[!inds, ] <- rCopula(N - sum(inds), frankCopula(4, dim=2))
>> Saveas[[j]] = X }
>> Then I built my function. I would like to apply this function to the 10 simulation run. That is I have 10 simulated data and would like to run my function to these data. I tried lapply and tapply function but I got  errors.
>> This is my function:
>>
>> FUN1 <- EM_mixture_copula(data = Saveas[[j]],pi_1=pi_1,pi_2=pi_2,theta = theta,                Theta=Theta, tol = .00001, maxit = 1000)
>> Here is my tries with the errors that I got:
>>
>>> result <- tapply(X,FUN1,simplify = T)
>> Error in tapply(X, FUN, simplify = T) : arguments must have same length.
>>
>>> Result <? lapply(X,FUN1)
>> Error in get(as.character(FUN), mode = "function", envir = envir) : object 'F' of mode 'function' was not found.
>>
>>
>>
>> Once I got the result, I would like to have a summary statistics of my function for each run. So, can I use
>>
>> Summary(result) ?
>>
>> Any help, please?
>> Kinds regards,
>> Fadhah
>>
>> Sent from my iPhone
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Mar 11 12:58:15 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 11 Mar 2017 11:58:15 +0000
Subject: [R] Help with lapply and tapply
In-Reply-To: <CACdH2ZbgCto8q3-fEchSAYsbY6SmPMhPJegtEUBH5id4Nav5iA@mail.gmail.com>
References: <4A75088E-D4BF-4C80-9F6D-2A0535D479F6@gmail.com>	<CAGxFJbTXNsc_SpWhqCwEh5KqMSi78t1zbBgpJnaVFcYAFNj-Kg@mail.gmail.com>
	<CACdH2ZbgCto8q3-fEchSAYsbY6SmPMhPJegtEUBH5id4Nav5iA@mail.gmail.com>
Message-ID: <58C3E657.4040304@sapo.pt>

Also, the OP's FUN1 is NOT a function. It's the result of a function 
call. A function would be

FUN1 <- function(x) EM_mixture_copula(...)

Hope this helps,

Rui Barradas

Em 11-03-2017 10:29, Michael Hannon escreveu:
> I think Bert's advice is sound.  Let me add a few, miscellaneous comments:
>
> (1) Some people find "by" easier than "tapply".
> (2) The "apply" function can, as I'm sure you (Bert) know, iterate
> over a matrix.
> (3) Hadley probably has better ways to do all of this (it's hard to keep up).
>
> -- Mike
>
>
> On Fri, Mar 10, 2017 at 9:22 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> In short, you really need to study the Help files carefully for both,
>> as you are using both tapply and lapply incorrectly. If that doesn't
>> work, I think you should spend some time with one of the many
>> excellent R tutorials on the web. You need to beef up your
>> understanding of the syntax.
>>
>> But briefly:
>>
>> 1) the tapply call must be of the form tapply(x, fac, fun) where x is
>> atomic (i.e. a vector) and fac is a factor that splits x into groups.
>> You have obviously got the call all wrong.
>>
>> 2) And in the second, X must be a list or vector, not a matrix and the
>> function needs to have its elements as an argument, something like FUN
>> = function(x)FUN1(x, ... your other arguments...)
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Mar 10, 2017 at 2:40 PM, Fadhah <fadeh2013 at gmail.com> wrote:
>>> Dear all,
>>>
>>> Thank you in advance for your time and help. I quite new to R and face a problem with lapply and tapply functions.
>>> I simulated data and run the simulation 10 times to get 10 different simulated data. I have also built up my function and would like to apply this function to these 10 different data without repeating the code for 10 times. I now that we can use a loop family functions in R such as lapply or tapply functions. I tried both of them but both of them did not work. My data was stored as vector mode list.
>>>
>>> Here is my data:
>>>
>>> library(VineCopula)
>>> library(copula)
>>> Runs= 10 Saveas = vector(mode = "list", length = Runs)
>>>   pb <- txtProgressBar(min = 0, max = Runs, style = 3)
>>> for(j in 1:Runs){
>>>   setTxtProgressBar(pb, j)
>>> N=2000
>>>   dim=dim
>>>   U=runif(N, min=0,max=1)
>>>   X = matrix(NA, nrow=N, ncol=2)
>>> inds <- U < 0.7
>>>   X[inds, ] <- rCopula(sum(inds), claytonCopula(1, dim=2))
>>>   X[!inds, ] <- rCopula(N - sum(inds), frankCopula(4, dim=2))
>>> Saveas[[j]] = X }
>>> Then I built my function. I would like to apply this function to the 10 simulation run. That is I have 10 simulated data and would like to run my function to these data. I tried lapply and tapply function but I got  errors.
>>> This is my function:
>>>
>>> FUN1 <- EM_mixture_copula(data = Saveas[[j]],pi_1=pi_1,pi_2=pi_2,theta = theta,                Theta=Theta, tol = .00001, maxit = 1000)
>>> Here is my tries with the errors that I got:
>>>
>>>> result <- tapply(X,FUN1,simplify = T)
>>> Error in tapply(X, FUN, simplify = T) : arguments must have same length.
>>>
>>>> Result <? lapply(X,FUN1)
>>> Error in get(as.character(FUN), mode = "function", envir = envir) : object 'F' of mode 'function' was not found.
>>>
>>>
>>>
>>> Once I got the result, I would like to have a summary statistics of my function for each run. So, can I use
>>>
>>> Summary(result) ?
>>>
>>> Any help, please?
>>> Kinds regards,
>>> Fadhah
>>>
>>> Sent from my iPhone
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From liushun.1 at qq.com  Sat Mar 11 06:24:17 2017
From: liushun.1 at qq.com (=?gb18030?B?wfXLsw==?=)
Date: Sat, 11 Mar 2017 13:24:17 +0800
Subject: [R] Linear Mixed-Effects Model
Message-ID: <tencent_487EF88947AB5E54187B854A@qq.com>

Dear R Help:
What does "lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" mean?
And
"lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" vs. "lmer(responce ~ factor1*factor2 + (factor1+factor2 | group1) + (factor1+factor2| group2), data)"?
And
Experiment includes 2 factors ,2 group structrues and 1 response,I want to use Mixed-Effects Model.How to express the full model with R
	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Sat Mar 11 15:59:31 2017
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Mar 2017 09:59:31 -0500
Subject: [R] find index in a list of list
Message-ID: <20170311095931.22915@web006.roc2.bluetie.com>

Hi all,

I have a list of lists like this :

mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))

I want to find the index of list in mylist where a = 11 and b  = "y"  , so I want to get 2 as a result

Thanks in advance


From ruipbarradas at sapo.pt  Sat Mar 11 16:06:26 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 11 Mar 2017 15:06:26 +0000
Subject: [R] find index in a list of list
In-Reply-To: <20170311095931.22915@web006.roc2.bluetie.com>
References: <20170311095931.22915@web006.roc2.bluetie.com>
Message-ID: <58C41272.6090201@sapo.pt>

Hello,

Something like this?

find <- list(a=11,b="y")
which(sapply(mylist, identical, find))

Hope this helps,

Rui Barradas


Em 11-03-2017 14:59, ce escreveu:
> Hi all,
>
> I have a list of lists like this :
>
> mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))
>
> I want to find the index of list in mylist where a = 11 and b  = "y"  , so I want to get 2 as a result
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zadig_1 at excite.com  Sat Mar 11 16:11:55 2017
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Mar 2017 10:11:55 -0500
Subject: [R] find index in a list of list
Message-ID: <20170311101155.23812@web001.roc2.bluetie.com>


Exactly. Thanks a lot, I was trying sapply with to result. 

-----Original Message-----
From: "Rui Barradas" [ruipbarradas at sapo.pt]
Date: 03/11/2017 10:06 AM
To: "ce" <zadig_1 at excite.com>, r-help at r-project.org
Subject: Re: [R] find index in a list of list

Hello,

Something like this?

find <- list(a=11,b="y")
which(sapply(mylist, identical, find))

Hope this helps,

Rui Barradas


Em 11-03-2017 14:59, ce escreveu:
> Hi all,
>
> I have a list of lists like this :
>
> mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))
>
> I want to find the index of list in mylist where a = 11 and b  = "y"  , so I want to get 2 as a result
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From padmanabhan.vijayan at gmail.com  Sat Mar 11 16:13:38 2017
From: padmanabhan.vijayan at gmail.com (Vijayan Padmanabhan)
Date: Sat, 11 Mar 2017 20:43:38 +0530
Subject: [R] field values from text file to dataframe
Message-ID: <CAH7cWrTSPTt_X1wAqaoPWnodKPGcPQ_SeHYd+WyARxmucaanMg@mail.gmail.com>

Dear r-help group
I have a text file which is a data dump of a pdf form as given below..
I want it to be converted into a data frame with field name as column names
and the field value as the row value for each field.
I might have different pdf forms with different field name value pairs to
process. so the script should not require reference to specific field names
in the extraction of data frame.
Where the field value for a given field is empty or where Field Value
doesn't appear.. the dataframe can record them as NA against that field
name column

Will someone know how to get this accomplished using R?


Regards
VP

---
FieldType: Choice
FieldName: P1
FieldFlags: 4849664
FieldValue: P1
FieldValueDefault: P1
FieldJustification: Left
FieldStateOption:
FieldStateOption: P1
---
FieldType: Choice
FieldName: P2
FieldFlags: 4849664
FieldValue:
FieldValueDefault: P2
FieldJustification: Left
FieldStateOption:
FieldStateOption: P2
---
FieldType: Choice
FieldName: P3
FieldFlags: 4849664
FieldValue:
FieldValueDefault: P3
FieldJustification: Left
FieldStateOption:
FieldStateOption: P3
---
FieldType: Choice
FieldName: P4
FieldFlags: 4849664
FieldValue: P2
FieldValueDefault: P2
FieldJustification: Left
FieldStateOption:
FieldStateOption: P2
---
FieldType: Choice
FieldName: P5
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P5
---
FieldType: Choice
FieldName: P6
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P6
---
FieldType: Choice
FieldName: P7
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P7
---
FieldType: Choice
FieldName: P8
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P8
---
FieldType: Choice
FieldName: P1IDS
FieldFlags: 4849664
FieldValue: 2
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P1PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P1IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P1PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P1IPU
FieldFlags: 4849664
FieldValue: 3
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P1PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P2PDS
FieldFlags: 71958528
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P3PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4IPU
FieldFlags: 4849664
FieldValue: 5
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P4PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P5PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault: 5
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P6PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P7PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault: 3
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault: 2
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P8PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12IDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P10PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P12PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11PPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11IPU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11PIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11IIU
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P11PDS
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: 1
FieldStateOption: 2
FieldStateOption: 3
FieldStateOption: 4
FieldStateOption: 5
---
FieldType: Choice
FieldName: P9
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P9
---
FieldType: Choice
FieldName: P11
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P9
---
FieldType: Choice
FieldName: P10
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P10
---
FieldType: Choice
FieldName: P12
FieldFlags: 4849664
FieldValue:
FieldValueDefault:
FieldJustification: Left
FieldStateOption:
FieldStateOption: P10
---
FieldType: Choice
FieldName: DD
FieldFlags: 4849664
FieldValue: 02
FieldValueDefault: 03
FieldJustification: Left
FieldStateOption:
FieldStateOption: 01
FieldStateOption: 02
FieldStateOption: 03
FieldStateOption: 04
FieldStateOption: 05
FieldStateOption: 06
FieldStateOption: 07
FieldStateOption: 08
FieldStateOption: 09
FieldStateOption: 10
FieldStateOption: 11
FieldStateOption: 12
FieldStateOption: 13
FieldStateOption: 14
FieldStateOption: 15
FieldStateOption: 16
FieldStateOption: 17
FieldStateOption: 18
FieldStateOption: 19
FieldStateOption: 20
FieldStateOption: 21
FieldStateOption: 22
FieldStateOption: 23
FieldStateOption: 24
FieldStateOption: 25
FieldStateOption: 26
FieldStateOption: 27
FieldStateOption: 28
FieldStateOption: 29
FieldStateOption: 30
FieldStateOption: 31
---
FieldType: Choice
FieldName: YY
FieldFlags: 4849664
FieldValue: 17
FieldValueDefault: 18
FieldJustification: Left
FieldStateOption: 15
FieldStateOption: 16
FieldStateOption: 17
FieldStateOption: 18
FieldStateOption: 19
FieldStateOption: 20
FieldStateOption: 21
FieldStateOption: 22
FieldStateOption: 23
FieldStateOption: 24
FieldStateOption: 25
---
FieldType: Choice
FieldName: MM
FieldFlags: 4325376
FieldValue: Jan
FieldValueDefault: Dec
FieldJustification: Left
FieldStateOption:
FieldStateOption: Apr
FieldStateOption: Aug
FieldStateOption: Dec
FieldStateOption: Feb
FieldStateOption: Jan
FieldStateOption: July
FieldStateOption: Jun
FieldStateOption: Mar
FieldStateOption: May
FieldStateOption: Nov
FieldStateOption: Oct
FieldStateOption: Sep
---
FieldType: Text
FieldName: Remark
FieldFlags: 4096
FieldJustification: Left
FieldMaxLength: 50
---
FieldType: Text
FieldName: StudyID
FieldFlags: 0
FieldValue: vijayan
FieldJustification: Left
---
FieldType: Text
FieldName: SubjID
FieldFlags: 0
FieldValue: 89841
FieldJustification: Left
---
FieldType: Text
FieldName: SubjName
FieldFlags: 0
FieldJustification: Left
---
FieldType: Button
FieldName: Button1
FieldFlags: 65536
FieldJustification: Left

	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Sat Mar 11 16:17:11 2017
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Mar 2017 10:17:11 -0500
Subject: [R] find index in a list of list
Message-ID: <20170311101711.2197@web001.roc2.bluetie.com>



Sorry I rejoiced  too soon. In fact original list is more complex like :

mylist <- list(list(a=10,b="x",c=1),list(a=11,b="y",c=2),list(a=12,b="z",c=5))

and I still need to find index of where a = 11 and b = "y"  and I have no c value , 

-----Original Message-----
From: "ce" [zadig_1 at excite.com]
Date: 03/11/2017 10:13 AM
To: r-help at r-project.org, "Rui Barradas" <ruipbarradas at sapo.pt>
Subject: Re: [R] find index in a list of list


Exactly. Thanks a lot, I was trying sapply with to result. 

-----Original Message-----
From: "Rui Barradas" [ruipbarradas at sapo.pt]
Date: 03/11/2017 10:06 AM
To: "ce" <zadig_1 at excite.com>, r-help at r-project.org
Subject: Re: [R] find index in a list of list

Hello,

Something like this?

find <- list(a=11,b="y")
which(sapply(mylist, identical, find))

Hope this helps,

Rui Barradas


Em 11-03-2017 14:59, ce escreveu:
> Hi all,
>
> I have a list of lists like this :
>
> mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))
>
> I want to find the index of list in mylist where a = 11 and b  = "y"  , so I want to get 2 as a result
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From danprec at hotmail.com  Sat Mar 11 16:37:29 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Sat, 11 Mar 2017 15:37:29 +0000
Subject: [R] nls fitting & plotting to data subsets defined by combinations
 of categorical variables
Message-ID: <MWHPR08MB2608CE3DE1F0B3A464086FD7A0230@MWHPR08MB2608.namprd08.prod.outlook.com>

Dear list, 

I want to apply the same nls function to different subsets of a larger
dataset. These subsets are defined as unique combinations of two
(categorical) variables, each one with two levels, so I should obtain 4
sets of parameters after fitting. 

I have managed to do it in a loop, creating different datasets for each
one of the sub-groups, and then applying the function to each one
independently and finally just merging all parameters in a single
dataset, but this seems pretty inefficient. 

I tried to use by and with, but they don't produce the expected result.
Rather, I get 4 sets of exactly the same parameters (?), so I know that
with/by are not actually doing anything, and the function is applied tothe dataset as a whole. 

Here is the call I tried to use:

test <- with(Data, by(Data, list(Type, Phase), function(x) nls(Response
~ k*exp(-((Duration-mu)^2)/(2*sigma^2)), start=c(mu=0,sigma=150,k=0.9),
upper=c(Inf, Inf, 1), algorithm="port", trace=T,
control=CSJ_FitControl)))

Also, I would like to plot the fitted distributions for each sub-group
in the same plot to be able to directly compare them. I figured that,
since I have the base nls function and the resulting parameters for
each subset (stored in a data frame), I should be able to enter these
on a ggplot call to get the 4 regressions lines plotted along with the
data, but I can't get that to work either. Or is it necessary to plot
this at the fitting stage (i.e. with the original data)?

Thanks for any suggestion   

From bgunter.4567 at gmail.com  Sat Mar 11 16:44:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Mar 2017 07:44:29 -0800
Subject: [R] Linear Mixed-Effects Model
In-Reply-To: <tencent_487EF88947AB5E54187B854A@qq.com>
References: <tencent_487EF88947AB5E54187B854A@qq.com>
Message-ID: <CAGxFJbQjAYTHf2WEnW-Gp6UQntCBhyPemBBZnEv5TAheFykqGw@mail.gmail.com>

Have you read the docs? Is this some kind of homework? -- this list
does not do homework. We expect minimal efforts at least on the part
of posters. We do not do tutorials here. I think you need to do some
reading on your own before posting further. Try posting on the
r-sig-mixed-models list to get or to be directed to such tutorials.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 10, 2017 at 9:24 PM, ?? <liushun.1 at qq.com> wrote:
> Dear R Help:
> What does "lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" mean?
> And
> "lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" vs. "lmer(responce ~ factor1*factor2 + (factor1+factor2 | group1) + (factor1+factor2| group2), data)"?
> And
> Experiment includes 2 factors ,2 group structrues and 1 response,I want to use Mixed-Effects Model.How to express the full model with R
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Sat Mar 11 16:47:58 2017
From: profjcnash at gmail.com (J C Nash)
Date: Sat, 11 Mar 2017 10:47:58 -0500
Subject: [R] nls fitting & plotting to data subsets defined by
 combinations of categorical variables
In-Reply-To: <MWHPR08MB2608CE3DE1F0B3A464086FD7A0230@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB2608CE3DE1F0B3A464086FD7A0230@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <2de7a58b-8baa-107a-cdbe-95bd271dadcb@gmail.com>

Given that nls() often gives failures of the "singular gradient" type, you may want to give package nlsr a try with the 
nlxb() function. It should be able to use analytic gradients on this expression, has bounds, and uses a Marquardt 
stabilized solver. It can still fail, but is more robust than nls().

I suspect that explicit looping is a safer way to proceed than trying to use by() within with(). Looping is not the slow 
part of this set of computations.

JN

On 2017-03-11 10:37 AM, DANIEL PRECIADO wrote:
> Dear list,
>
> I want to apply the same nls function to different subsets of a larger
> dataset. These subsets are defined as unique combinations of two
> (categorical) variables, each one with two levels, so I should obtain 4
> sets of parameters after fitting.
>
> I have managed to do it in a loop, creating different datasets for each
> one of the sub-groups, and then applying the function to each one
> independently and finally just merging all parameters in a single
> dataset, but this seems pretty inefficient.
>
> I tried to use by and with, but they don't produce the expected result.
> Rather, I get 4 sets of exactly the same parameters (?), so I know that
> with/by are not actually doing anything, and the function is applied tothe dataset as a whole.
>
> Here is the call I tried to use:
>
> test <- with(Data, by(Data, list(Type, Phase), function(x) nls(Response
> ~ k*exp(-((Duration-mu)^2)/(2*sigma^2)), start=c(mu=0,sigma=150,k=0.9),
> upper=c(Inf, Inf, 1), algorithm="port", trace=T,
> control=CSJ_FitControl)))
>
> Also, I would like to plot the fitted distributions for each sub-group
> in the same plot to be able to directly compare them. I figured that,
> since I have the base nls function and the resulting parameters for
> each subset (stored in a data frame), I should be able to enter these
> on a ggplot call to get the 4 regressions lines plotted along with the
> data, but I can't get that to work either. Or is it necessary to plot
> this at the fitting stage (i.e. with the original data)?
>
> Thanks for any suggestion
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Sat Mar 11 17:23:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Mar 2017 08:23:00 -0800
Subject: [R] find index in a list of list
In-Reply-To: <20170311101711.2197@web001.roc2.bluetie.com>
References: <20170311101711.2197@web001.roc2.bluetie.com>
Message-ID: <73523E4E-FAF4-4C50-B18B-86D6C1A5078F@dcn.davis.ca.us>

Since the offered solution already checks each top level element using the "identical" function, you just need a different comparison function, like perhaps:

mycompare <- function( x, y ) {
   identical( x[[ "a" ]], y[[ "a" ]] ) && identical( x[[ "b" ]], y[[ "b" ]] )
}

Note that your decision to store this data in a list of lists is making this search process much less computationally and syntactically efficient than it would be if you could fit your data into a data frame.
-- 
Sent from my phone. Please excuse my brevity.

On March 11, 2017 7:17:11 AM PST, ce <zadig_1 at excite.com> wrote:
>
>
>Sorry I rejoiced  too soon. In fact original list is more complex like
>:
>
>mylist <-
>list(list(a=10,b="x",c=1),list(a=11,b="y",c=2),list(a=12,b="z",c=5))
>
>and I still need to find index of where a = 11 and b = "y"  and I have
>no c value , 
>
>-----Original Message-----
>From: "ce" [zadig_1 at excite.com]
>Date: 03/11/2017 10:13 AM
>To: r-help at r-project.org, "Rui Barradas" <ruipbarradas at sapo.pt>
>Subject: Re: [R] find index in a list of list
>
>
>Exactly. Thanks a lot, I was trying sapply with to result. 
>
>-----Original Message-----
>From: "Rui Barradas" [ruipbarradas at sapo.pt]
>Date: 03/11/2017 10:06 AM
>To: "ce" <zadig_1 at excite.com>, r-help at r-project.org
>Subject: Re: [R] find index in a list of list
>
>Hello,
>
>Something like this?
>
>find <- list(a=11,b="y")
>which(sapply(mylist, identical, find))
>
>Hope this helps,
>
>Rui Barradas
>
>
>Em 11-03-2017 14:59, ce escreveu:
>> Hi all,
>>
>> I have a list of lists like this :
>>
>> mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))
>>
>> I want to find the index of list in mylist where a = 11 and b  = "y" 
>, so I want to get 2 as a result
>>
>> Thanks in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sat Mar 11 18:01:29 2017
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Mar 2017 12:01:29 -0500
Subject: [R] find index in a list of list
Message-ID: <20170311120129.5676@web006.roc2.bluetie.com>


Thank you both, indeed combining two solutions fixed my problem :

> which(sapply(mylist, mycompare,find))
[1] 2

I admit list of lists is not the optimal design,  it's out of my control but is there is not much data in it, so performance is not an  issue.
For the sake of R's honour I didn't want to use "for loop".

ce


-----Original Message-----
From: "Jeff Newmiller" [jdnewmil at dcn.davis.ca.us]
Date: 03/11/2017 11:23 AM
To: r-help at r-project.org, "ce" <zadig_1 at excite.com>, "Rui Barradas" <ruipbarradas at sapo.pt>
Subject: Re: [R] find index in a list of list

Since the offered solution already checks each top level element using the "identical" function, you just need a different comparison function, like perhaps:

mycompare <- function( x, y ) {
   identical( x[[ "a" ]], y[[ "a" ]] ) && identical( x[[ "b" ]], y[[ "b" ]] )
}

Note that your decision to store this data in a list of lists is making this search process much less computationally and syntactically efficient than it would be if you could fit your data into a data frame.
-- 
Sent from my phone. Please excuse my brevity.

On March 11, 2017 7:17:11 AM PST, ce <zadig_1 at excite.com> wrote:
>
>
>Sorry I rejoiced  too soon. In fact original list is more complex like
>:
>
>mylist <-
>list(list(a=10,b="x",c=1),list(a=11,b="y",c=2),list(a=12,b="z",c=5))
>
>and I still need to find index of where a = 11 and b = "y"  and I have
>no c value , 
>
>-----Original Message-----
>From: "ce" [zadig_1 at excite.com]
>Date: 03/11/2017 10:13 AM
>To: r-help at r-project.org, "Rui Barradas" <ruipbarradas at sapo.pt>
>Subject: Re: [R] find index in a list of list
>
>
>Exactly. Thanks a lot, I was trying sapply with to result. 
>
>-----Original Message-----
>From: "Rui Barradas" [ruipbarradas at sapo.pt]
>Date: 03/11/2017 10:06 AM
>To: "ce" <zadig_1 at excite.com>, r-help at r-project.org
>Subject: Re: [R] find index in a list of list
>
>Hello,
>
>Something like this?
>
>find <- list(a=11,b="y")
>which(sapply(mylist, identical, find))
>
>Hope this helps,
>
>Rui Barradas
>
>
>Em 11-03-2017 14:59, ce escreveu:
>> Hi all,
>>
>> I have a list of lists like this :
>>
>> mylist <- list(list(a=10,b="x"),list(a=11,b="y"),list(a=12,b="z"))
>>
>> I want to find the index of list in mylist where a = 11 and b  = "y" 
>, so I want to get 2 as a result
>>
>> Thanks in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Sat Mar 11 19:50:32 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 11 Mar 2017 11:50:32 -0700
Subject: [R] About error in the panel
Message-ID: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>

Hi R users,

I have a problem about using R studio. For example, there is a dataframe
that has many columns. I want to aggregated column X and column Y into
column Z. Column Z does not exist before the aggregation. I use the code
below:
df$Z = df$X + df$Y

However, it does not work in the top left panel in Rstudio, and has the
following warning message:
Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
  replacement has 0 rows, data has 34333

If I type the same code in the Console panel (bottom left panel), it works.
How to deal with this problem? Thanks.

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sat Mar 11 20:02:23 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 11 Mar 2017 12:02:23 -0700
Subject: [R] About error in the panel
In-Reply-To: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
Message-ID: <CAN5afy9NYd73=_UEytokcSFfNfYiMZV8T1zR60Ln_pfsELwCYg@mail.gmail.com>

More specifically,  it shows the following when I typed traceback():

3: stop(sprintf(ngettext(N, "replacement has %d row, data has %d",
       "replacement has %d rows, data has %d"), N, nrows), domain = NA)
2: `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0))
1: `$<-`(`*tmp*`, "Z", value = numeric(0))

I don't know what is the problem, as it works in the Console panel but not
in the top left panel. Thanks for your help.

On Sat, Mar 11, 2017 at 11:50 AM, lily li <chocold12 at gmail.com> wrote:

> Hi R users,
>
> I have a problem about using R studio. For example, there is a dataframe
> that has many columns. I want to aggregated column X and column Y into
> column Z. Column Z does not exist before the aggregation. I use the code
> below:
> df$Z = df$X + df$Y
>
> However, it does not work in the top left panel in Rstudio, and has the
> following warning message:
> Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
>   replacement has 0 rows, data has 34333
>
> If I type the same code in the Console panel (bottom left panel), it
> works. How to deal with this problem? Thanks.
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 11 20:12:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Mar 2017 11:12:03 -0800
Subject: [R] About error in the panel
In-Reply-To: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
Message-ID: <CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>

1. Not reproducible, hence impossible to say.

2. This is r-help. RStudio is totally separate and its own support page.

3. A guess: Use are sourcing the entire script in the editor panel
into R, and there is something screwed up there.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a problem about using R studio. For example, there is a dataframe
> that has many columns. I want to aggregated column X and column Y into
> column Z. Column Z does not exist before the aggregation. I use the code
> below:
> df$Z = df$X + df$Y
>
> However, it does not work in the top left panel in Rstudio, and has the
> following warning message:
> Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
>   replacement has 0 rows, data has 34333
>
> If I type the same code in the Console panel (bottom left panel), it works.
> How to deal with this problem? Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Sat Mar 11 20:14:05 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 11 Mar 2017 12:14:05 -0700
Subject: [R] About error in the panel
In-Reply-To: <CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
	<CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>
Message-ID: <CAN5afy9RYiF85+ao0na0RceRZScPRcyMg3jtpCLx2QJYtGr7QQ@mail.gmail.com>

Thanks for your reply. I thought anything about R questions can be posted
here.

About your third point, what does it mean? I did the same thing before for
other scripts, but this one does not work. Thanks again.

On Sat, Mar 11, 2017 at 12:12 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> 1. Not reproducible, hence impossible to say.
>
> 2. This is r-help. RStudio is totally separate and its own support page.
>
> 3. A guess: Use are sourcing the entire script in the editor panel
> into R, and there is something screwed up there.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> >
> > I have a problem about using R studio. For example, there is a dataframe
> > that has many columns. I want to aggregated column X and column Y into
> > column Z. Column Z does not exist before the aggregation. I use the code
> > below:
> > df$Z = df$X + df$Y
> >
> > However, it does not work in the top left panel in Rstudio, and has the
> > following warning message:
> > Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
> >   replacement has 0 rows, data has 34333
> >
> > If I type the same code in the Console panel (bottom left panel), it
> works.
> > How to deal with this problem? Thanks.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 11 20:18:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Mar 2017 11:18:08 -0800
Subject: [R] About error in the panel
In-Reply-To: <CAN5afy9RYiF85+ao0na0RceRZScPRcyMg3jtpCLx2QJYtGr7QQ@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
	<CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>
	<CAN5afy9RYiF85+ao0na0RceRZScPRcyMg3jtpCLx2QJYtGr7QQ@mail.gmail.com>
Message-ID: <CAGxFJbT=v_EsCkmtHQAn+FRiQ=2Eo44DDqPM9XWmNEecAGc8Cg@mail.gmail.com>

Typo, should be:

3. A guess: You are sourcing the entire script in the editor panel
into R, and there is something screwed up there.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 11, 2017 at 11:14 AM, lily li <chocold12 at gmail.com> wrote:
> Thanks for your reply. I thought anything about R questions can be posted
> here.
>
> About your third point, what does it mean? I did the same thing before for
> other scripts, but this one does not work. Thanks again.
>
> On Sat, Mar 11, 2017 at 12:12 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> 1. Not reproducible, hence impossible to say.
>>
>> 2. This is r-help. RStudio is totally separate and its own support page.
>>
>> 3. A guess: Use are sourcing the entire script in the editor panel
>> into R, and there is something screwed up there.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
>> > Hi R users,
>> >
>> > I have a problem about using R studio. For example, there is a dataframe
>> > that has many columns. I want to aggregated column X and column Y into
>> > column Z. Column Z does not exist before the aggregation. I use the code
>> > below:
>> > df$Z = df$X + df$Y
>> >
>> > However, it does not work in the top left panel in Rstudio, and has the
>> > following warning message:
>> > Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
>> >   replacement has 0 rows, data has 34333
>> >
>> > If I type the same code in the Console panel (bottom left panel), it
>> > works.
>> > How to deal with this problem? Thanks.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From chocold12 at gmail.com  Sat Mar 11 20:53:41 2017
From: chocold12 at gmail.com (lily li)
Date: Sat, 11 Mar 2017 12:53:41 -0700
Subject: [R] About error in the panel
In-Reply-To: <CAGxFJbT=v_EsCkmtHQAn+FRiQ=2Eo44DDqPM9XWmNEecAGc8Cg@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
	<CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>
	<CAN5afy9RYiF85+ao0na0RceRZScPRcyMg3jtpCLx2QJYtGr7QQ@mail.gmail.com>
	<CAGxFJbT=v_EsCkmtHQAn+FRiQ=2Eo44DDqPM9XWmNEecAGc8Cg@mail.gmail.com>
Message-ID: <CAN5afy9ep7o3AboexGqy_LXvy+PVz-H0TeQP=qnNQ2BSsEA2Lw@mail.gmail.com>

I think this is the problem. How to solve then?

On Sat, Mar 11, 2017 at 12:18 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Typo, should be:
>
> 3. A guess: You are sourcing the entire script in the editor panel
> into R, and there is something screwed up there.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Mar 11, 2017 at 11:14 AM, lily li <chocold12 at gmail.com> wrote:
> > Thanks for your reply. I thought anything about R questions can be posted
> > here.
> >
> > About your third point, what does it mean? I did the same thing before
> for
> > other scripts, but this one does not work. Thanks again.
> >
> > On Sat, Mar 11, 2017 at 12:12 PM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >>
> >> 1. Not reproducible, hence impossible to say.
> >>
> >> 2. This is r-help. RStudio is totally separate and its own support page.
> >>
> >> 3. A guess: Use are sourcing the entire script in the editor panel
> >> into R, and there is something screwed up there.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
> >> > Hi R users,
> >> >
> >> > I have a problem about using R studio. For example, there is a
> dataframe
> >> > that has many columns. I want to aggregated column X and column Y into
> >> > column Z. Column Z does not exist before the aggregation. I use the
> code
> >> > below:
> >> > df$Z = df$X + df$Y
> >> >
> >> > However, it does not work in the top left panel in Rstudio, and has
> the
> >> > following warning message:
> >> > Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
> >> >   replacement has 0 rows, data has 34333
> >> >
> >> > If I type the same code in the Console panel (bottom left panel), it
> >> > works.
> >> > How to deal with this problem? Thanks.
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Sat Mar 11 22:26:47 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 11 Mar 2017 21:26:47 +0000 (UTC)
Subject: [R] Override/Insert (Change) a value (default value) inside a
	function
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
Message-ID: <550301108.3544330.1489267607443@mail.yahoo.com>

Hi!, 

Lets I have a function form a package. 
The function is,  as an example, 

myplot <- function(x,y) { plot(x,y) }


Now I can use the function according to function's defined argument. 

x<- sort(runif(200))
y<- 1:200
myplot(x,y)

Now I want to input extra argument or override default value of plot inside the function myplot. 

If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I clearly understand , why it does not work . 
But in this situation how can i solve the problem ? 

I will be grateful if any one can help. 
Thanks in advance !!
 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 


From bretschr at xs4all.nl  Sat Mar 11 22:45:42 2017
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Sat, 11 Mar 2017 22:45:42 +0100
Subject: [R] Override/Insert (Change) a value (default value) inside a
	function
In-Reply-To: <550301108.3544330.1489267607443@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
Message-ID: <E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>

Dear Mohammad Tanvir Ahamed,


Re:

> Hi!, 
> 
> Lets I have a function form a package. 
> The function is,  as an example, 
> 
> myplot <- function(x,y) { plot(x,y) }
> 
> 
> Now I can use the function according to function's defined argument. 
> 
> x<- sort(runif(200))
> y<- 1:200
> myplot(x,y)
> 
> Now I want to input extra argument or override default value of plot inside the function myplot. 
> 
> If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I clearly understand , why it does not work . 
> But in this situation how can i solve the problem ? 
> 



That's where the three-dot argument is for.

See "Introduction to R", paragraph 10.4 The ??? argument.

Succes and
best regards,

Frank
---


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From r.turner at auckland.ac.nz  Sat Mar 11 22:46:21 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 12 Mar 2017 10:46:21 +1300
Subject: [R] [FORGED] Override/Insert (Change) a value (default value)
 inside a function
In-Reply-To: <550301108.3544330.1489267607443@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
Message-ID: <45a9dccf-e179-7ed5-7ed5-c60d06450c78@auckland.ac.nz>

On 12/03/17 10:26, Mohammad Tanvir Ahamed via R-help wrote:
> Hi!,
>
> Lets I have a function form a package.
> The function is,  as an example,
>
> myplot <- function(x,y) { plot(x,y) }
>
>
> Now I can use the function according to function's defined argument.
>
> x<- sort(runif(200))
> y<- 1:200
> myplot(x,y)
>
> Now I want to input extra argument or override default value of plot inside the function myplot.
>
> If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I clearly understand , why it does not work .
> But in this situation how can i solve the problem ?
>
> I will be grateful if any one can help.
> Thanks in advance !!

Learn about the "..." argument.  See e.g. section 10.4 of "An 
Introduction to R" (first item under R home page -> Documentation -> 
Manuals).

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Sat Mar 11 22:47:19 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Mar 2017 13:47:19 -0800
Subject: [R] About error in the panel
In-Reply-To: <CAN5afy9ep7o3AboexGqy_LXvy+PVz-H0TeQP=qnNQ2BSsEA2Lw@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
	<CAGxFJbQrkS3W5sHG7EwncmRBN7eG1ECvH22-ADRPiin-0Zq4Ag@mail.gmail.com>
	<CAN5afy9RYiF85+ao0na0RceRZScPRcyMg3jtpCLx2QJYtGr7QQ@mail.gmail.com>
	<CAGxFJbT=v_EsCkmtHQAn+FRiQ=2Eo44DDqPM9XWmNEecAGc8Cg@mail.gmail.com>
	<CAN5afy9ep7o3AboexGqy_LXvy+PVz-H0TeQP=qnNQ2BSsEA2Lw@mail.gmail.com>
Message-ID: <C7244A8D-F419-4BD3-A6C2-5EDB6BCB4C8E@dcn.davis.ca.us>

Copy one statement at a time into a new R session.  When you get an error you will know what you need to look at more closely. RStudio makes this easy with the Start New R Session menu option and using Ctrl-Enter in the editor.
-- 
Sent from my phone. Please excuse my brevity.

On March 11, 2017 11:53:41 AM PST, lily li <chocold12 at gmail.com> wrote:
>I think this is the problem. How to solve then?
>
>On Sat, Mar 11, 2017 at 12:18 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>> Typo, should be:
>>
>> 3. A guess: You are sourcing the entire script in the editor panel
>> into R, and there is something screwed up there.
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Mar 11, 2017 at 11:14 AM, lily li <chocold12 at gmail.com>
>wrote:
>> > Thanks for your reply. I thought anything about R questions can be
>posted
>> > here.
>> >
>> > About your third point, what does it mean? I did the same thing
>before
>> for
>> > other scripts, but this one does not work. Thanks again.
>> >
>> > On Sat, Mar 11, 2017 at 12:12 PM, Bert Gunter
><bgunter.4567 at gmail.com>
>> > wrote:
>> >>
>> >> 1. Not reproducible, hence impossible to say.
>> >>
>> >> 2. This is r-help. RStudio is totally separate and its own support
>page.
>> >>
>> >> 3. A guess: Use are sourcing the entire script in the editor panel
>> >> into R, and there is something screwed up there.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming
>along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com>
>wrote:
>> >> > Hi R users,
>> >> >
>> >> > I have a problem about using R studio. For example, there is a
>> dataframe
>> >> > that has many columns. I want to aggregated column X and column
>Y into
>> >> > column Z. Column Z does not exist before the aggregation. I use
>the
>> code
>> >> > below:
>> >> > df$Z = df$X + df$Y
>> >> >
>> >> > However, it does not work in the top left panel in Rstudio, and
>has
>> the
>> >> > following warning message:
>> >> > Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
>> >> >   replacement has 0 rows, data has 34333
>> >> >
>> >> > If I type the same code in the Console panel (bottom left
>panel), it
>> >> > works.
>> >> > How to deal with this problem? Thanks.
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >
>> >
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mashranga at yahoo.com  Sat Mar 11 23:11:39 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 11 Mar 2017 22:11:39 +0000 (UTC)
Subject: [R] Override/Insert (Change) a value (default value) inside a
 function
In-Reply-To: <E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
	<E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
Message-ID: <563611405.3586680.1489270299719@mail.yahoo.com>

Thanks for reply.
as I said , the function in the package is like 
myplot <- function(x,y) { plot(x,y) }

not like 
myplot <- function(x,y) { plot(x,y,...) }

And I cant change the function inside the package!! 

So , in this case how to solve the problem ? 
 Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Franklin Bretschneider <bretschr at xs4all.nl>
To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>; R-help groep <r-help at r-project.org>
Sent: Saturday, 11 March 2017, 22:45
Subject: Re: [R] Override/Insert (Change) a value (default value) inside a function

Dear Mohammad Tanvir Ahamed,



Re:

> Hi!, 
> 
> Lets I have a function form a package. 
> The function is,  as an example, 
> 
> myplot <- function(x,y) { plot(x,y) }
> 
> 
> Now I can use the function according to function's defined argument. 
> 
> x<- sort(runif(200))
> y<- 1:200
> myplot(x,y)
> 
> Now I want to input extra argument or override default value of plot inside the function myplot. 
> 
> If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I clearly understand , why it does not work . 
> But in this situation how can i solve the problem ? 
> 



That's where the three-dot argument is for.

See "Introduction to R", paragraph 10.4 The ??? argument.

Succes and
best regards,

Frank
---


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From wdunlap at tibco.com  Sat Mar 11 23:25:33 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 11 Mar 2017 14:25:33 -0800
Subject: [R] About error in the panel
In-Reply-To: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
References: <CAN5afy_BK1qk+rMjF0aT1bfJKdrwi6VRqTmyumdJV-ipfSGSiw@mail.gmail.com>
Message-ID: <CAF8bMcZ8GQB-XiGuLFgHNhBgvZB-T+ahnM8sDFMczJZqM6umxw@mail.gmail.com>

You will get this error if 'df' does not have columns named "X" and
"Y", so df$X or df$Y is NULL.  E.g.,
  > df <- data.frame(One=1:3, Two=11:13)
  > df$Three <- df$One + df$noSuchColumn
  Error in `$<-.data.frame`(`*tmp*`, "Three", value = numeric(0)) :
    replacement has 0 rows, data has 3

What does names(df) show in the different panels?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Mar 11, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a problem about using R studio. For example, there is a dataframe
> that has many columns. I want to aggregated column X and column Y into
> column Z. Column Z does not exist before the aggregation. I use the code
> below:
> df$Z = df$X + df$Y
>
> However, it does not work in the top left panel in Rstudio, and has the
> following warning message:
> Error in `$<-.data.frame`(`*tmp*`, "Z", value = numeric(0)) :
>   replacement has 0 rows, data has 34333
>
> If I type the same code in the Console panel (bottom left panel), it works.
> How to deal with this problem? Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Mar 11 23:52:22 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 12 Mar 2017 11:52:22 +1300
Subject: [R] Override/Insert (Change) a value (default value) inside a
 function
In-Reply-To: <563611405.3586680.1489270299719@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
	<E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
	<563611405.3586680.1489270299719@mail.yahoo.com>
Message-ID: <9eecffd3-8889-0dea-a6b9-3feca3eaeaeb@auckland.ac.nz>

On 12/03/17 11:11, Mohammad Tanvir Ahamed wrote:
> Thanks for reply.
> as I said , the function in the package is like
> myplot <- function(x,y) { plot(x,y) }
>
> not like
> myplot <- function(x,y) { plot(x,y,...) }
>
> And I cant change the function inside the package!!
>
> So , in this case how to solve the problem ?

As the problem is stated, you cannot solve it.

Depending on circumstances, there are various approaches that you could 
take.  One would be to get the package source, edit the "myplot" 
function so that it has a "..." argument, and then install the edited 
version.

Since we don't know your circumstances, nor what it is that you really 
need to accomplish (your description of the problem is very vague), it 
is difficult to make suggestions.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Sun Mar 12 01:37:04 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Mar 2017 16:37:04 -0800
Subject: [R] Override/Insert (Change) a value (default value) inside a
	function
In-Reply-To: <563611405.3586680.1489270299719@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
	<E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
	<563611405.3586680.1489270299719@mail.yahoo.com>
Message-ID: <E0C9FD58-086A-48DE-98C0-1781E94888B5@dcn.davis.ca.us>

You can't.  You can skip the package and roll your own functions if the package functions are not written to use ...
-- 
Sent from my phone. Please excuse my brevity.

On March 11, 2017 2:11:39 PM PST, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
>Thanks for reply.
>as I said , the function in the package is like 
>myplot <- function(x,y) { plot(x,y) }
>
>not like 
>myplot <- function(x,y) { plot(x,y,...) }
>
>And I cant change the function inside the package!! 
>
>So , in this case how to solve the problem ? 
> Tanvir Ahamed 
>G?teborg, Sweden   |  mashranga at yahoo.com 
>
>
>----- Original Message -----
>From: Franklin Bretschneider <bretschr at xs4all.nl>
>To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>; R-help groep
><r-help at r-project.org>
>Sent: Saturday, 11 March 2017, 22:45
>Subject: Re: [R] Override/Insert (Change) a value (default value)
>inside a function
>
>Dear Mohammad Tanvir Ahamed,
>
>
>
>Re:
>
>> Hi!, 
>> 
>> Lets I have a function form a package. 
>> The function is,  as an example, 
>> 
>> myplot <- function(x,y) { plot(x,y) }
>> 
>> 
>> Now I can use the function according to function's defined argument. 
>> 
>> x<- sort(runif(200))
>> y<- 1:200
>> myplot(x,y)
>> 
>> Now I want to input extra argument or override default value of plot
>inside the function myplot. 
>> 
>> If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I
>clearly understand , why it does not work . 
>> But in this situation how can i solve the problem ? 
>> 
>
>
>
>That's where the three-dot argument is for.
>
>See "Introduction to R", paragraph 10.4 The ??? argument.
>
>Succes and
>best regards,
>
>Frank
>---
>
>
>Franklin Bretschneider
>Dept of Biology
>Utrecht University
>bretschr at xs4all.nl
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Sun Mar 12 01:51:12 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sat, 11 Mar 2017 16:51:12 -0800
Subject: [R] Override/Insert (Change) a value (default value) inside a
	function
In-Reply-To: <563611405.3586680.1489270299719@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>
	<550301108.3544330.1489267607443@mail.yahoo.com>
	<E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
	<563611405.3586680.1489270299719@mail.yahoo.com>
Message-ID: <CA+hbrhUym+Z=828wq2r8Tf5rcqxxqKi=n+Y2f_BBV9=7rVXoPg@mail.gmail.com>

On Sat, Mar 11, 2017 at 2:11 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Thanks for reply.
> as I said , the function in the package is like
> myplot <- function(x,y) { plot(x,y) }
>
> not like
> myplot <- function(x,y) { plot(x,y,...) }
>
> And I cant change the function inside the package!!

The easiest solution __is__ to change the function inside the package.
If the license of the package allows it and your coding skills are up
to it, download the source of the package, make the necessary
modification in the code, and use that. If you make the modifications
so that they are useful for others, you could email the package
maintainer with your code and suggest that he/she incorporates it in
the package for wider release.

Peter


From ruipbarradas at sapo.pt  Sun Mar 12 10:33:26 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 12 Mar 2017 09:33:26 +0000
Subject: [R] Override/Insert (Change) a value (default value) inside a
 function
In-Reply-To: <563611405.3586680.1489270299719@mail.yahoo.com>
References: <550301108.3544330.1489267607443.ref@mail.yahoo.com>	<550301108.3544330.1489267607443@mail.yahoo.com>	<E3BD0D2B-04C3-4FEF-953D-8C4DA6B7328A@xs4all.nl>
	<563611405.3586680.1489270299719@mail.yahoo.com>
Message-ID: <58C515E6.7000802@sapo.pt>

Hello,

Just to add to what others have said, I believe you haven't understood 
the dots argument. Where you to change the function in the package and 
the correct form would be

myplot <- function(x,y, ...) { plot(x,y,...) }

Hope this helps,

Rui Barradas

Em 11-03-2017 22:11, Mohammad Tanvir Ahamed via R-help escreveu:
> Thanks for reply.
> as I said , the function in the package is like
> myplot <- function(x,y) { plot(x,y) }
>
> not like
> myplot <- function(x,y) { plot(x,y,...) }
>
> And I cant change the function inside the package!!
>
> So , in this case how to solve the problem ?
>   Tanvir Ahamed
> G?teborg, Sweden   |  mashranga at yahoo.com
>
>
> ----- Original Message -----
> From: Franklin Bretschneider <bretschr at xs4all.nl>
> To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>; R-help groep <r-help at r-project.org>
> Sent: Saturday, 11 March 2017, 22:45
> Subject: Re: [R] Override/Insert (Change) a value (default value) inside a function
>
> Dear Mohammad Tanvir Ahamed,
>
>
>
> Re:
>
>> Hi!,
>>
>> Lets I have a function form a package.
>> The function is,  as an example,
>>
>> myplot <- function(x,y) { plot(x,y) }
>>
>>
>> Now I can use the function according to function's defined argument.
>>
>> x<- sort(runif(200))
>> y<- 1:200
>> myplot(x,y)
>>
>> Now I want to input extra argument or override default value of plot inside the function myplot.
>>
>> If I use  myplot (x,y, col = "red", cex = 0.1 )  it does not work . I clearly understand , why it does not work .
>> But in this situation how can i solve the problem ?
>>
>
>
>
> That's where the three-dot argument is for.
>
> See "Introduction to R", paragraph 10.4 The ??? argument.
>
> Succes and
> best regards,
>
> Frank
> ---
>
>
> Franklin Bretschneider
> Dept of Biology
> Utrecht University
> bretschr at xs4all.nl
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hannah.hlx at gmail.com  Sun Mar 12 16:38:39 2017
From: hannah.hlx at gmail.com (li li)
Date: Sun, 12 Mar 2017 11:38:39 -0400
Subject: [R] nested structure for Ancova
Message-ID: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>

Hi All,
  I have a dataset which contains 4 variables: area, group, time, y,
Area is a factor that has two levels A and B, group is a factor that is
nested within area. There are four groups within each area.
y is the response variable, and time refers to different days.

  Below is the how data looks like.

  First, I fit separate ancova for each area (area A and B), For each area,
I obtained different regression lines for each group within that area.

  mod1 <- lm(y ~ month * group, data=two[two$area=="A"]

  mod2 <- lm(y ~ month * group, data=two[two$area=="B"]

 I want to fit the model at one time by using the nested structure

 mod3 <-  lm(y ~ -1+ month * (area/group), data=two)

I get different results using mod 3 from using mod1 and mod2.

  Can someone give some suggestion on this.  How can I specify the model in
R to simultaneously fit the model to get the same results as from mod1 and
mod2.

Thanks  very much!
    Hanna

> head(two[two$area=="A",])   group time         y area
79     1    3 -1.394327    A
80     1    6 -1.435485    A
81     1    9 -1.406497    A
82     1   12 -1.265848    A
83     1    0 -1.316768    A
84     1    6 -1.431292    A> head(two[two$area=="B",])  group time
     y area
1     1    0 -2.145581    B
2     1    0 -1.910543    B
3     1    0 -2.128632    B
4     1    3 -2.079442    B
5     1    3 -2.273026    B
6     1    6 -2.312635    B

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Mar 12 18:27:46 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 12 Mar 2017 17:27:46 +0000
Subject: [R] nested structure for Ancova
In-Reply-To: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>
References: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>
Message-ID: <870976b6-81a1-dbcd-2e04-d959ef3dc731@dewey.myzen.co.uk>

Dear Hannah

You say they are different (mod3 from mod1 and mod2) but in what way are 
the results different?

On 12/03/2017 15:38, li li wrote:
> Hi All,
>   I have a dataset which contains 4 variables: area, group, time, y,
> Area is a factor that has two levels A and B, group is a factor that is
> nested within area. There are four groups within each area.
> y is the response variable, and time refers to different days.
>
>   Below is the how data looks like.
>
>   First, I fit separate ancova for each area (area A and B), For each area,
> I obtained different regression lines for each group within that area.
>
>   mod1 <- lm(y ~ month * group, data=two[two$area=="A"]
>
>   mod2 <- lm(y ~ month * group, data=two[two$area=="B"]
>
>  I want to fit the model at one time by using the nested structure
>
>  mod3 <-  lm(y ~ -1+ month * (area/group), data=two)
>
> I get different results using mod 3 from using mod1 and mod2.
>
>   Can someone give some suggestion on this.  How can I specify the model in
> R to simultaneously fit the model to get the same results as from mod1 and
> mod2.
>
> Thanks  very much!
>     Hanna
>
>> head(two[two$area=="A",])   group time         y area
> 79     1    3 -1.394327    A
> 80     1    6 -1.435485    A
> 81     1    9 -1.406497    A
> 82     1   12 -1.265848    A
> 83     1    0 -1.316768    A
> 84     1    6 -1.431292    A> head(two[two$area=="B",])  group time
>      y area
> 1     1    0 -2.145581    B
> 2     1    0 -1.910543    B
> 3     1    0 -2.128632    B
> 4     1    3 -2.079442    B
> 5     1    3 -2.273026    B
> 6     1    6 -2.312635    B
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From rmh at temple.edu  Sun Mar 12 19:31:20 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 12 Mar 2017 18:31:20 +0000
Subject: [R] nested structure for Ancova
In-Reply-To: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>
References: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>
Message-ID: <CAGx1TMBbdqZq3CCWA3PEHUp9OqmJHKkn-dC8zy=twyRGrg8xvw@mail.gmail.com>

I think you need either

mod4 <- lm( y ~ -1 + area / (month*group), data=two)

mod5 <- lm( y ~ area / (month*group), data=two)

With either of those,  area:month and area:group and Residuals add up.


On Sun, Mar 12, 2017 at 10:39 li li <hannah.hlx at gmail.com> wrote:

> Hi All,
>   I have a dataset which contains 4 variables: area, group, time, y,
> Area is a factor that has two levels A and B, group is a factor that is
> nested within area. There are four groups within each area.
> y is the response variable, and time refers to different days.
>
>   Below is the how data looks like.
>
>   First, I fit separate ancova for each area (area A and B), For each area,
> I obtained different regression lines for each group within that area.
>
>   mod1 <- lm(y ~ month * group, data=two[two$area=="A"]
>
>   mod2 <- lm(y ~ month * group, data=two[two$area=="B"]
>
>  I want to fit the model at one time by using the nested structure
>
>  mod3 <-  lm(y ~ -1+ month * (area/group), data=two)
>
> I get different results using mod 3 from using mod1 and mod2.
>
>   Can someone give some suggestion on this.  How can I specify the model in
> R to simultaneously fit the model to get the same results as from mod1 and
> mod2.
>
> Thanks  very much!
>     Hanna
>
> > head(two[two$area=="A",])   group time         y area
> 79     1    3 -1.394327    A
> 80     1    6 -1.435485    A
> 81     1    9 -1.406497    A
> 82     1   12 -1.265848    A
> 83     1    0 -1.316768    A
> 84     1    6 -1.431292    A> head(two[two$area=="B",])  group time
>      y area
> 1     1    0 -2.145581    B
> 2     1    0 -1.910543    B
> 3     1    0 -2.128632    B
> 4     1    3 -2.079442    B
> 5     1    3 -2.273026    B
> 6     1    6 -2.312635    B
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Sun Mar 12 20:45:38 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 13 Mar 2017 08:45:38 +1300
Subject: [R] [FORGED]  display UTF8 characters in pdf
In-Reply-To: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
References: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
Message-ID: <aa9fe9fb-4a36-b4f8-2d3a-40c443fd407c@stat.auckland.ac.nz>

Hi

This does not help with a solution, but ...

The standard PDF device only does single-byte character sets (sbcs in 
the warning message).  The conversion from a multi-byte character set 
(mbcs), which is what UTF8 is, will only work if the characters map to a 
single-byte character set (things like ASCII, Latin1, etc).  The 
A-acute, probably the copyright sign, and maybe even the k-in-a-circle 
might survive the conversion, but a little drawing of a car does not.

Paul

On 11/03/2017 5:06 a.m., Thierry Onkelinx wrote:
> Dear all,
>
> I'd like to use some UTF-8 characters in a plot. Some of them are not
> rendered with saving the plot as pdf. Any suggestions?
>
> library(ggplot2)
> symbols <- c("\U1F697", "\U00A9", "\U24DA", "\U00C1")
> test <- data.frame(
>   x = seq_along(symbols) %% ceiling(sqrt(length(symbols))),
>   y = ceiling(seq_along(symbols) / ceiling(sqrt(length(symbols)))),
>   symbol = symbols
> )
> p <- ggplot(test, aes(x = x, y = y, label = symbol)) + geom_text(size = 10)
> p
> ggsave(p, file = "test.png")
> ggsave(p, file = "test.pdf")
>
> The last command gives several similar warnings, all related to the symbols
> which are not rendered properly:
>
> Warning messages:
> 1: In grid.Call.graphics(L_text, as.graphicsAnnot(x$label),  ... :
>   conversion failure on '??' in 'mbcsToSbcs': dot substituted for <f0>
>
> I'm running R 3.3.2 under Ubuntu 16.04.1 and ggplot2 2.2.1
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From thierry.onkelinx at inbo.be  Sun Mar 12 20:47:06 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 12 Mar 2017 20:47:06 +0100
Subject: [R] display UTF8 characters in pdf
In-Reply-To: <20170310211721.698836368b098bb39a3840d5@univ-nantes.fr>
References: <CAJuCY5w6UNQnNCMtAnOZt_YwhjXiRApbqpZxY9Q9bPv9iTqucQ@mail.gmail.com>
	<20170310211721.698836368b098bb39a3840d5@univ-nantes.fr>
Message-ID: <CAJuCY5yvZ9jG2eDMpuCPJLOfF5-HEELF_ESMzi1za=DYYaaYEg@mail.gmail.com>

Dear all,

Thanks to Ista and Olivier. The solution of Ista works for some characters
but not all. The solution of Olivier works, at least for the characters
that I've tried.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-03-10 21:22 GMT+01:00 Olivier CROUZET <Olivier.Crouzet at univ-nantes.fr>:

> Hi,
>
> AFAICT, you need to use a Cairo device for being able to display some
> Unicode
> characters in a plot.
>
> From my experience, the CairoPDF() from library(Cairo) does not work
> (and I don't understand the difference with cairo_pdf()), but the
> cairo_pdf() from grDevices does work perfectly well for this aim. As far
> as I'm concerned, I use it with both ggplot2 and regular plots and it
> does a perfect job. Here is a short example:
>
> In an R console:
>
> cairo_pdf(filename = "test.pdf")
> plot(1,1,pch = "\u254")
> dev.off()
>
> Also, I use it with knitr and it works great. You just have to declare a
> specific device ("cairo_pdf").
>
> For example, in an RMarkdown document:
>
> ```{r ipaunicode, echo=TRUE, dev='cairo_pdf'}
> plot(1, 1, pch = "\u254")
> ```
>
> and in a LaTeX / knitr document as well:
>
> <<ipaunicode, dev="cairo_pdf">>=
> plot(1, 1, pch = "\u251")
> @
>
> Hope this helps.
>
> Yours.
> Olivier.
>
> On Fri, 10 Mar
>
> 2017 17:06:25 +0100 Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>
> Dear all,
>>
>> I'd like to use some UTF-8 characters in a plot. Some of them are not
>> rendered with saving the plot as pdf. Any suggestions?
>>
>> library(ggplot2)
>> symbols <- c("\U1F697", "\U00A9", "\U24DA", "\U00C1")
>> test <- data.frame(
>>   x = seq_along(symbols) %% ceiling(sqrt(length(symbols))),
>>   y = ceiling(seq_along(symbols) / ceiling(sqrt(length(symbols)))),
>>   symbol = symbols
>> )
>> p <- ggplot(test, aes(x = x, y = y, label = symbol)) + geom_text(size
>> = 10) p
>> ggsave(p, file = "test.png")
>> ggsave(p, file = "test.pdf")
>>
>> The last command gives several similar warnings, all related to the
>> symbols which are not rendered properly:
>>
>> Warning messages:
>> 1: In grid.Call.graphics(L_text, as.graphicsAnnot(x$label),  ... :
>>   conversion failure on '??' in 'mbcsToSbcs': dot substituted for <f0>
>>
>> I'm running R 3.3.2 under Ubuntu 16.04.1 and ggplot2 2.2.1
>>
>> Best regards,
>>
>> Thierry
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for
>> Nature and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given
>> body of data. ~ John Tukey
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>>
>
> --
>   Olivier Crouzet, PhD
>   /Assistant Professor/
>   @LLING - Laboratoire de Linguistique de Nantes
>     UMR6310 CNRS / Universit? de Nantes
>   /Guest Researcher/
>   @UMCG (University Medical Center Groningen)
>     ENT department
>     Reijksuniversiteit Groningen
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sun Mar 12 22:26:44 2017
From: hannah.hlx at gmail.com (li li)
Date: Sun, 12 Mar 2017 17:26:44 -0400
Subject: [R] nested structure for Ancova
In-Reply-To: <CAGx1TMBbdqZq3CCWA3PEHUp9OqmJHKkn-dC8zy=twyRGrg8xvw@mail.gmail.com>
References: <CAHLnndZW0hXd=yH1ThcHQe1_AHNjvTpxwEvkpqrf91Ju6iY5GQ@mail.gmail.com>
	<CAGx1TMBbdqZq3CCWA3PEHUp9OqmJHKkn-dC8zy=twyRGrg8xvw@mail.gmail.com>
Message-ID: <CAHLnndaTjC_2N5biZCbYsapQya0_Q=vt6mpGBOEKExrnUkjh+g@mail.gmail.com>

Thanks so much, Richard. That  works.
 Hanna

2017-03-12 14:31 GMT-04:00 Richard M. Heiberger <rmh at temple.edu>:

> I think you need either
>
> mod4 <- lm( y ~ -1 + area / (month*group), data=two)
>
> mod5 <- lm( y ~ area / (month*group), data=two)
>
> With either of those,  area:month and area:group and Residuals add up.
>
>
> On Sun, Mar 12, 2017 at 10:39 li li <hannah.hlx at gmail.com> wrote:
>
>> Hi All,
>>   I have a dataset which contains 4 variables: area, group, time, y,
>> Area is a factor that has two levels A and B, group is a factor that is
>> nested within area. There are four groups within each area.
>> y is the response variable, and time refers to different days.
>>
>>   Below is the how data looks like.
>>
>>   First, I fit separate ancova for each area (area A and B), For each
>> area,
>> I obtained different regression lines for each group within that area.
>>
>>   mod1 <- lm(y ~ month * group, data=two[two$area=="A"]
>>
>>   mod2 <- lm(y ~ month * group, data=two[two$area=="B"]
>>
>>  I want to fit the model at one time by using the nested structure
>>
>>  mod3 <-  lm(y ~ -1+ month * (area/group), data=two)
>>
>> I get different results using mod 3 from using mod1 and mod2.
>>
>>   Can someone give some suggestion on this.  How can I specify the model
>> in
>> R to simultaneously fit the model to get the same results as from mod1 and
>> mod2.
>>
>> Thanks  very much!
>>     Hanna
>>
>> > head(two[two$area=="A",])   group time         y area
>> 79     1    3 -1.394327    A
>> 80     1    6 -1.435485    A
>> 81     1    9 -1.406497    A
>> 82     1   12 -1.265848    A
>> 83     1    0 -1.316768    A
>> 84     1    6 -1.431292    A> head(two[two$area=="B",])  group time
>>      y area
>> 1     1    0 -2.145581    B
>> 2     1    0 -1.910543    B
>> 3     1    0 -2.128632    B
>> 4     1    3 -2.079442    B
>> 5     1    3 -2.273026    B
>> 6     1    6 -2.312635    B
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Mon Mar 13 04:32:09 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 13 Mar 2017 11:32:09 +0800
Subject: [R] Extract student ID that match certain criteria
Message-ID: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>

Dear r-users,

I have this list of student ID,

dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012, AA14039,
AA15018, AA13234, AA13149, AA13282, AA13218)

and I would like to extract all student of ID AA14... only.

I search and tried substrt, subset and select but it fail.

 substr(FKASA$STUDENT_ID, 2, nchar(string1))
Error in nchar(string1) : 'nchar()' requires a character vector
> subset(FKASA, STUDENT_ID=="AA14" )
 [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM     KURSUS
 CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
 ACT_IM
[14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...

Thank you so much for your help.

How do I do it?
-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 13 04:51:47 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Mar 2017 20:51:47 -0700
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
References: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
Message-ID: <CAGxFJbQ6ursWrfBAgbSP=j91pSvO4dOhs4oWgEs9___gJ3i9QQ@mail.gmail.com>

1. Your code is incorrect. All entries are character strings and must be quoted.

2. See ?grep  and note in particular (in the "Value" section):

"grep(value = TRUE) returns a character vector containing the selected
elements of x (after coercion, preserving names but no other
attributes)."


3. While the fixed = TRUE option will work here, you may wish to learn
about "regular expressions", which can come in very handy for
character string manipulation tasks. ?regex in R has a terse, but I
have found comprehensible, discussion. There are many good gentler
tutorials on the web, also.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-users,
>
> I have this list of student ID,
>
> dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
> AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012, AA14039,
> AA15018, AA13234, AA13149, AA13282, AA13218)
>
> and I would like to extract all student of ID AA14... only.
>
> I search and tried substrt, subset and select but it fail.
>
>  substr(FKASA$STUDENT_ID, 2, nchar(string1))
> Error in nchar(string1) : 'nchar()' requires a character vector
>> subset(FKASA, STUDENT_ID=="AA14" )
>  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM     KURSUS
>  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>  ACT_IM
> [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>
> Thank you so much for your help.
>
> How do I do it?
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Mon Mar 13 05:37:08 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 13 Mar 2017 12:37:08 +0800
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CAGxFJbQ6ursWrfBAgbSP=j91pSvO4dOhs4oWgEs9___gJ3i9QQ@mail.gmail.com>
References: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
	<CAGxFJbQ6ursWrfBAgbSP=j91pSvO4dOhs4oWgEs9___gJ3i9QQ@mail.gmail.com>
Message-ID: <CANTvJZJDt5hJNxoNiYkg4h9rxsxDCYcUJrwb7t5eHtBBJqQf+Q@mail.gmail.com>

Hi Bert,

Thank you so much for your help.  However I don't really sure what is the
use of y values.  Can we do without it?

x <- as.character(FKASA$STUDENT_ID)
y <- c(1,786)
My.Data <- data.frame (x,y)

My.Data[grep("^AA14", My.Data$x), ]

I got the following data:

          x   y
1   AA14068   1
7   AA14090   1
11  AA14099   1
14  AA14012 786
15  AA14039   1
22  AA14251 786

On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> 1. Your code is incorrect. All entries are character strings and must be
> quoted.
>
> 2. See ?grep  and note in particular (in the "Value" section):
>
> "grep(value = TRUE) returns a character vector containing the selected
> elements of x (after coercion, preserving names but no other
> attributes)."
>
>
> 3. While the fixed = TRUE option will work here, you may wish to learn
> about "regular expressions", which can come in very handy for
> character string manipulation tasks. ?regex in R has a terse, but I
> have found comprehensible, discussion. There are many good gentler
> tutorials on the web, also.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> > Dear r-users,
> >
> > I have this list of student ID,
> >
> > dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
> > AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012, AA14039,
> > AA15018, AA13234, AA13149, AA13282, AA13218)
> >
> > and I would like to extract all student of ID AA14... only.
> >
> > I search and tried substrt, subset and select but it fail.
> >
> >  substr(FKASA$STUDENT_ID, 2, nchar(string1))
> > Error in nchar(string1) : 'nchar()' requires a character vector
> >> subset(FKASA, STUDENT_ID=="AA14" )
> >  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM     KURSUS
> >  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
> >  ACT_IM
> > [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
> >
> > Thank you so much for your help.
> >
> > How do I do it?
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Mon Mar 13 06:18:06 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 13 Mar 2017 13:18:06 +0800
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZJDt5hJNxoNiYkg4h9rxsxDCYcUJrwb7t5eHtBBJqQf+Q@mail.gmail.com>
References: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
	<CAGxFJbQ6ursWrfBAgbSP=j91pSvO4dOhs4oWgEs9___gJ3i9QQ@mail.gmail.com>
	<CANTvJZJDt5hJNxoNiYkg4h9rxsxDCYcUJrwb7t5eHtBBJqQf+Q@mail.gmail.com>
Message-ID: <CANTvJZL6-XGiC1KUU+feAV4o3u=zc2Jp=WdkAvRWPyqD6_+xig@mail.gmail.com>

Another question,

How do I extract ID based on the third and fourth letter:

I have for example, AA14004, AB15035, CB14024, PA14009, PA14009 etc

I would like to extract ID no. of AB14..., CB14..., PA14...

On Mon, Mar 13, 2017 at 12:37 PM, roslinazairimah zakaria <
roslinaump at gmail.com> wrote:

> Hi Bert,
>
> Thank you so much for your help.  However I don't really sure what is the
> use of y values.  Can we do without it?
>
> x <- as.character(FKASA$STUDENT_ID)
> y <- c(1,786)
> My.Data <- data.frame (x,y)
>
> My.Data[grep("^AA14", My.Data$x), ]
>
> I got the following data:
>
>           x   y
> 1   AA14068   1
> 7   AA14090   1
> 11  AA14099   1
> 14  AA14012 786
> 15  AA14039   1
> 22  AA14251 786
>
> On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> 1. Your code is incorrect. All entries are character strings and must be
>> quoted.
>>
>> 2. See ?grep  and note in particular (in the "Value" section):
>>
>> "grep(value = TRUE) returns a character vector containing the selected
>> elements of x (after coercion, preserving names but no other
>> attributes)."
>>
>>
>> 3. While the fixed = TRUE option will work here, you may wish to learn
>> about "regular expressions", which can come in very handy for
>> character string manipulation tasks. ?regex in R has a terse, but I
>> have found comprehensible, discussion. There are many good gentler
>> tutorials on the web, also.
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
>> <roslinaump at gmail.com> wrote:
>> > Dear r-users,
>> >
>> > I have this list of student ID,
>> >
>> > dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
>> > AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012, AA14039,
>> > AA15018, AA13234, AA13149, AA13282, AA13218)
>> >
>> > and I would like to extract all student of ID AA14... only.
>> >
>> > I search and tried substrt, subset and select but it fail.
>> >
>> >  substr(FKASA$STUDENT_ID, 2, nchar(string1))
>> > Error in nchar(string1) : 'nchar()' requires a character vector
>> >> subset(FKASA, STUDENT_ID=="AA14" )
>> >  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM     KURSUS
>> >  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>> >  ACT_IM
>> > [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>> >
>> > Thank you so much for your help.
>> >
>> > How do I do it?
>> > --
>> > *Roslinazairimah Zakaria*
>> > *Tel: +609-5492370; Fax. No.+609-5492766*
>> >
>> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> > roslinaump at gmail.com <roslinaump at gmail.com>*
>> > Faculty of Industrial Sciences & Technology
>> > University Malaysia Pahang
>> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
> <+60%209-549%202766>*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Mon Mar 13 09:06:20 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 13 Mar 2017 08:06:20 +0000
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZL6-XGiC1KUU+feAV4o3u=zc2Jp=WdkAvRWPyqD6_+xig@mail.gmail.com>
References: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
	<CAGxFJbQ6ursWrfBAgbSP=j91pSvO4dOhs4oWgEs9___gJ3i9QQ@mail.gmail.com>
	<CANTvJZJDt5hJNxoNiYkg4h9rxsxDCYcUJrwb7t5eHtBBJqQf+Q@mail.gmail.com>
	<CANTvJZL6-XGiC1KUU+feAV4o3u=zc2Jp=WdkAvRWPyqD6_+xig@mail.gmail.com>
Message-ID: <CAKVAULOHs4id93GePAtO3nnh=mEQmO-AaKvuAJg6vheiPFh2FA@mail.gmail.com>

Hi Roslinazairimah,

As Bert suggested, you should get acquainted with regular expressions. It
can be confusing at times, but pays off in the long run.

In your case, the pattern of "^[A-Z]{2}14.*" might work.

Best,
Ulrik

On Mon, 13 Mar 2017 at 06:20 roslinazairimah zakaria <roslinaump at gmail.com>
wrote:

> Another question,
>
> How do I extract ID based on the third and fourth letter:
>
> I have for example, AA14004, AB15035, CB14024, PA14009, PA14009 etc
>
> I would like to extract ID no. of AB14..., CB14..., PA14...
>
> On Mon, Mar 13, 2017 at 12:37 PM, roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
>
> > Hi Bert,
> >
> > Thank you so much for your help.  However I don't really sure what is the
> > use of y values.  Can we do without it?
> >
> > x <- as.character(FKASA$STUDENT_ID)
> > y <- c(1,786)
> > My.Data <- data.frame (x,y)
> >
> > My.Data[grep("^AA14", My.Data$x), ]
> >
> > I got the following data:
> >
> >           x   y
> > 1   AA14068   1
> > 7   AA14090   1
> > 11  AA14099   1
> > 14  AA14012 786
> > 15  AA14039   1
> > 22  AA14251 786
> >
> > On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> >> 1. Your code is incorrect. All entries are character strings and must be
> >> quoted.
> >>
> >> 2. See ?grep  and note in particular (in the "Value" section):
> >>
> >> "grep(value = TRUE) returns a character vector containing the selected
> >> elements of x (after coercion, preserving names but no other
> >> attributes)."
> >>
> >>
> >> 3. While the fixed = TRUE option will work here, you may wish to learn
> >> about "regular expressions", which can come in very handy for
> >> character string manipulation tasks. ?regex in R has a terse, but I
> >> have found comprehensible, discussion. There are many good gentler
> >> tutorials on the web, also.
> >>
> >>
> >> Cheers,
> >> Bert
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
> >> <roslinaump at gmail.com> wrote:
> >> > Dear r-users,
> >> >
> >> > I have this list of student ID,
> >> >
> >> > dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
> >> > AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012,
> AA14039,
> >> > AA15018, AA13234, AA13149, AA13282, AA13218)
> >> >
> >> > and I would like to extract all student of ID AA14... only.
> >> >
> >> > I search and tried substrt, subset and select but it fail.
> >> >
> >> >  substr(FKASA$STUDENT_ID, 2, nchar(string1))
> >> > Error in nchar(string1) : 'nchar()' requires a character vector
> >> >> subset(FKASA, STUDENT_ID=="AA14" )
> >> >  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM
>  KURSUS
> >> >  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
> >> >  ACT_IM
> >> > [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
> >> >
> >> > Thank you so much for your help.
> >> >
> >> > How do I do it?
> >> > --
> >> > *Roslinazairimah Zakaria*
> >> > *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
> <+60%209-549%202766>*
> >> >
> >> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> >> > roslinaump at gmail.com <roslinaump at gmail.com>*
> >> > Faculty of Industrial Sciences & Technology
> >> > University Malaysia Pahang
> >> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370 <+60%209-549%202370> <+60%209-549%202370>; Fax. No.
> +609-5492766 <+60%209-549%202766>
> > <+60%209-549%202766>*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
>
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
> <+60%209-549%202766>*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Mar 13 09:26:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Mar 2017 19:26:24 +1100
Subject: [R] field values from text file to dataframe
In-Reply-To: <CAH7cWrTSPTt_X1wAqaoPWnodKPGcPQ_SeHYd+WyARxmucaanMg@mail.gmail.com>
References: <CAH7cWrTSPTt_X1wAqaoPWnodKPGcPQ_SeHYd+WyARxmucaanMg@mail.gmail.com>
Message-ID: <CA+8X3fUcpASJLtn2=2M1F4O4J9Etaqhu=d=FDoY0_QjpwjGa9g@mail.gmail.com>

Hi Vijayan,
You have a bit of a problem with repeated field names. While you can
mangle the field names to do something like this, I don't see how you
are going to make sense of multiple "FieldStateOption" fields. The
strategy I would take is to collect all of the field names and then
set up rows with the unique field names, but the multiple field names
will make a mess of that.

Jim


On Sun, Mar 12, 2017 at 2:13 AM, Vijayan Padmanabhan
<padmanabhan.vijayan at gmail.com> wrote:
> Dear r-help group
> I have a text file which is a data dump of a pdf form as given below..
> I want it to be converted into a data frame with field name as column names
> and the field value as the row value for each field.
> I might have different pdf forms with different field name value pairs to
> process. so the script should not require reference to specific field names
> in the extraction of data frame.
> Where the field value for a given field is empty or where Field Value
> doesn't appear.. the dataframe can record them as NA against that field
> name column
>
> Will someone know how to get this accomplished using R?
>
>
> Regards
> VP
>
> ---
> FieldType: Choice
> FieldName: P1
> FieldFlags: 4849664
> FieldValue: P1
> FieldValueDefault: P1
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P1
> ---
> FieldType: Choice
> FieldName: P2
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault: P2
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P2
> ---
> FieldType: Choice
> FieldName: P3
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault: P3
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P3
> ---
> FieldType: Choice
> FieldName: P4
> FieldFlags: 4849664
> FieldValue: P2
> FieldValueDefault: P2
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P2
> ---
> FieldType: Choice
> FieldName: P5
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P5
> ---
> FieldType: Choice
> FieldName: P6
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P6
> ---
> FieldType: Choice
> FieldName: P7
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P7
> ---
> FieldType: Choice
> FieldName: P8
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P8
> ---
> FieldType: Choice
> FieldName: P1IDS
> FieldFlags: 4849664
> FieldValue: 2
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P1PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P1IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P1PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P1IPU
> FieldFlags: 4849664
> FieldValue: 3
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P1PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P2PDS
> FieldFlags: 71958528
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P3PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4IPU
> FieldFlags: 4849664
> FieldValue: 5
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P4PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P5PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault: 5
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P6PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P7PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault: 3
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault: 2
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P8PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12IDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P10PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P12PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11PPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11IPU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11PIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11IIU
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P11PDS
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 1
> FieldStateOption: 2
> FieldStateOption: 3
> FieldStateOption: 4
> FieldStateOption: 5
> ---
> FieldType: Choice
> FieldName: P9
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P9
> ---
> FieldType: Choice
> FieldName: P11
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P9
> ---
> FieldType: Choice
> FieldName: P10
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P10
> ---
> FieldType: Choice
> FieldName: P12
> FieldFlags: 4849664
> FieldValue:
> FieldValueDefault:
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: P10
> ---
> FieldType: Choice
> FieldName: DD
> FieldFlags: 4849664
> FieldValue: 02
> FieldValueDefault: 03
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: 01
> FieldStateOption: 02
> FieldStateOption: 03
> FieldStateOption: 04
> FieldStateOption: 05
> FieldStateOption: 06
> FieldStateOption: 07
> FieldStateOption: 08
> FieldStateOption: 09
> FieldStateOption: 10
> FieldStateOption: 11
> FieldStateOption: 12
> FieldStateOption: 13
> FieldStateOption: 14
> FieldStateOption: 15
> FieldStateOption: 16
> FieldStateOption: 17
> FieldStateOption: 18
> FieldStateOption: 19
> FieldStateOption: 20
> FieldStateOption: 21
> FieldStateOption: 22
> FieldStateOption: 23
> FieldStateOption: 24
> FieldStateOption: 25
> FieldStateOption: 26
> FieldStateOption: 27
> FieldStateOption: 28
> FieldStateOption: 29
> FieldStateOption: 30
> FieldStateOption: 31
> ---
> FieldType: Choice
> FieldName: YY
> FieldFlags: 4849664
> FieldValue: 17
> FieldValueDefault: 18
> FieldJustification: Left
> FieldStateOption: 15
> FieldStateOption: 16
> FieldStateOption: 17
> FieldStateOption: 18
> FieldStateOption: 19
> FieldStateOption: 20
> FieldStateOption: 21
> FieldStateOption: 22
> FieldStateOption: 23
> FieldStateOption: 24
> FieldStateOption: 25
> ---
> FieldType: Choice
> FieldName: MM
> FieldFlags: 4325376
> FieldValue: Jan
> FieldValueDefault: Dec
> FieldJustification: Left
> FieldStateOption:
> FieldStateOption: Apr
> FieldStateOption: Aug
> FieldStateOption: Dec
> FieldStateOption: Feb
> FieldStateOption: Jan
> FieldStateOption: July
> FieldStateOption: Jun
> FieldStateOption: Mar
> FieldStateOption: May
> FieldStateOption: Nov
> FieldStateOption: Oct
> FieldStateOption: Sep
> ---
> FieldType: Text
> FieldName: Remark
> FieldFlags: 4096
> FieldJustification: Left
> FieldMaxLength: 50
> ---
> FieldType: Text
> FieldName: StudyID
> FieldFlags: 0
> FieldValue: vijayan
> FieldJustification: Left
> ---
> FieldType: Text
> FieldName: SubjID
> FieldFlags: 0
> FieldValue: 89841
> FieldJustification: Left
> ---
> FieldType: Text
> FieldName: SubjName
> FieldFlags: 0
> FieldJustification: Left
> ---
> FieldType: Button
> FieldName: Button1
> FieldFlags: 65536
> FieldJustification: Left
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Mon Mar 13 10:46:48 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 13 Mar 2017 09:46:48 +0000
Subject: [R] field values from text file to dataframe
In-Reply-To: <CA+8X3fUcpASJLtn2=2M1F4O4J9Etaqhu=d=FDoY0_QjpwjGa9g@mail.gmail.com>
References: <CAH7cWrTSPTt_X1wAqaoPWnodKPGcPQ_SeHYd+WyARxmucaanMg@mail.gmail.com>
	<CA+8X3fUcpASJLtn2=2M1F4O4J9Etaqhu=d=FDoY0_QjpwjGa9g@mail.gmail.com>
Message-ID: <CAKVAULMd1w4FFuoKDi3OU8jeZaTF=YnAFkkap+O2QgTrTH8tkA@mail.gmail.com>

I imagine that the FieldStateOption is irrelevant, so you might be able to
create a data.frame like this:

library(tidyr)

fl <- readLines("pdf_dump.txt")

fl <- grep("FieldStateOption", fl, value = TRUE, invert = TRUE)

field_number <- vector(mode = "integer", length = length(fl))
tmpid <- 0
for(i in seq_along(1:length(fl))){
  if(fl[i] == "---"){
    tmpid <- tmpid + 1
  }
  field_number[i] <- tmpid
}

data.frame(field_number, file_line = fl) %>%
  subset(file_line != "---") %>%
  separate(file_line,into = c("field_name", "field_value")) %>%
  spread(key = "field_name", value = "field_value")

The field_number is there to make each row in the final data.frame unique
(without it, `spread` complains)

HTH,
Ulrik





On Mon, 13 Mar 2017 at 09:28 Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Vijayan,
> You have a bit of a problem with repeated field names. While you can
> mangle the field names to do something like this, I don't see how you
> are going to make sense of multiple "FieldStateOption" fields. The
> strategy I would take is to collect all of the field names and then
> set up rows with the unique field names, but the multiple field names
> will make a mess of that.
>
> Jim
>
>
> On Sun, Mar 12, 2017 at 2:13 AM, Vijayan Padmanabhan
> <padmanabhan.vijayan at gmail.com> wrote:
> > Dear r-help group
> > I have a text file which is a data dump of a pdf form as given below..
> > I want it to be converted into a data frame with field name as column
> names
> > and the field value as the row value for each field.
> > I might have different pdf forms with different field name value pairs to
> > process. so the script should not require reference to specific field
> names
> > in the extraction of data frame.
> > Where the field value for a given field is empty or where Field Value
> > doesn't appear.. the dataframe can record them as NA against that field
> > name column
> >
> > Will someone know how to get this accomplished using R?
> >
> >
> > Regards
> > VP
> >
> > ---
> > FieldType: Choice
> > FieldName: P1
> > FieldFlags: 4849664
> > FieldValue: P1
> > FieldValueDefault: P1
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P1
> > ---
> > FieldType: Choice
> > FieldName: P2
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault: P2
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P2
> > ---
> > FieldType: Choice
> > FieldName: P3
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault: P3
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P3
> > ---
> > FieldType: Choice
> > FieldName: P4
> > FieldFlags: 4849664
> > FieldValue: P2
> > FieldValueDefault: P2
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P2
> > ---
> > FieldType: Choice
> > FieldName: P5
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P5
> > ---
> > FieldType: Choice
> > FieldName: P6
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P6
> > ---
> > FieldType: Choice
> > FieldName: P7
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P7
> > ---
> > FieldType: Choice
> > FieldName: P8
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P8
> > ---
> > FieldType: Choice
> > FieldName: P1IDS
> > FieldFlags: 4849664
> > FieldValue: 2
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P1PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P1IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P1PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P1IPU
> > FieldFlags: 4849664
> > FieldValue: 3
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P1PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P2PDS
> > FieldFlags: 71958528
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P3PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4IPU
> > FieldFlags: 4849664
> > FieldValue: 5
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P4PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P5PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault: 5
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P6PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P7PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault: 3
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault: 2
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P8PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12IDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P10PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P12PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11PPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11IPU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11PIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11IIU
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P11PDS
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 1
> > FieldStateOption: 2
> > FieldStateOption: 3
> > FieldStateOption: 4
> > FieldStateOption: 5
> > ---
> > FieldType: Choice
> > FieldName: P9
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P9
> > ---
> > FieldType: Choice
> > FieldName: P11
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P9
> > ---
> > FieldType: Choice
> > FieldName: P10
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P10
> > ---
> > FieldType: Choice
> > FieldName: P12
> > FieldFlags: 4849664
> > FieldValue:
> > FieldValueDefault:
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: P10
> > ---
> > FieldType: Choice
> > FieldName: DD
> > FieldFlags: 4849664
> > FieldValue: 02
> > FieldValueDefault: 03
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: 01
> > FieldStateOption: 02
> > FieldStateOption: 03
> > FieldStateOption: 04
> > FieldStateOption: 05
> > FieldStateOption: 06
> > FieldStateOption: 07
> > FieldStateOption: 08
> > FieldStateOption: 09
> > FieldStateOption: 10
> > FieldStateOption: 11
> > FieldStateOption: 12
> > FieldStateOption: 13
> > FieldStateOption: 14
> > FieldStateOption: 15
> > FieldStateOption: 16
> > FieldStateOption: 17
> > FieldStateOption: 18
> > FieldStateOption: 19
> > FieldStateOption: 20
> > FieldStateOption: 21
> > FieldStateOption: 22
> > FieldStateOption: 23
> > FieldStateOption: 24
> > FieldStateOption: 25
> > FieldStateOption: 26
> > FieldStateOption: 27
> > FieldStateOption: 28
> > FieldStateOption: 29
> > FieldStateOption: 30
> > FieldStateOption: 31
> > ---
> > FieldType: Choice
> > FieldName: YY
> > FieldFlags: 4849664
> > FieldValue: 17
> > FieldValueDefault: 18
> > FieldJustification: Left
> > FieldStateOption: 15
> > FieldStateOption: 16
> > FieldStateOption: 17
> > FieldStateOption: 18
> > FieldStateOption: 19
> > FieldStateOption: 20
> > FieldStateOption: 21
> > FieldStateOption: 22
> > FieldStateOption: 23
> > FieldStateOption: 24
> > FieldStateOption: 25
> > ---
> > FieldType: Choice
> > FieldName: MM
> > FieldFlags: 4325376
> > FieldValue: Jan
> > FieldValueDefault: Dec
> > FieldJustification: Left
> > FieldStateOption:
> > FieldStateOption: Apr
> > FieldStateOption: Aug
> > FieldStateOption: Dec
> > FieldStateOption: Feb
> > FieldStateOption: Jan
> > FieldStateOption: July
> > FieldStateOption: Jun
> > FieldStateOption: Mar
> > FieldStateOption: May
> > FieldStateOption: Nov
> > FieldStateOption: Oct
> > FieldStateOption: Sep
> > ---
> > FieldType: Text
> > FieldName: Remark
> > FieldFlags: 4096
> > FieldJustification: Left
> > FieldMaxLength: 50
> > ---
> > FieldType: Text
> > FieldName: StudyID
> > FieldFlags: 0
> > FieldValue: vijayan
> > FieldJustification: Left
> > ---
> > FieldType: Text
> > FieldName: SubjID
> > FieldFlags: 0
> > FieldValue: 89841
> > FieldJustification: Left
> > ---
> > FieldType: Text
> > FieldName: SubjName
> > FieldFlags: 0
> > FieldJustification: Left
> > ---
> > FieldType: Button
> > FieldName: Button1
> > FieldFlags: 65536
> > FieldJustification: Left
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Mar 13 11:20:33 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Mar 2017 21:20:33 +1100
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
References: <CANTvJZLXrOkkeUdJn2D+bEtMjvRQx3+utCDZaYiTzid0tjKrsw@mail.gmail.com>
Message-ID: <CA+8X3fX4T_anFOL3DF0EK64UCzUdjU=Q6+MjoS-cuCSS=LGMdA@mail.gmail.com>

Hi Roslinazairimah,
What you seem to want is fairly simple:

dt<-c("AA14068","AA13194","AE11054","AA12251","AA13228",
  "AA13286","AA14090","AA13256","AA13260","AA13291",
  "AA14099","AA15071","AA13143","AA14012","AA14039",
  "AA15018","AA13234","AA13149","AA13282","AA13218")
dt[grep(pattern="AA14",dt)]
[1] "AA14068" "AA14090" "AA14099" "AA14012" "AA14039"

However, as others have suggested, you may want a more general
solution that involves a variable pattern.

Jim

On Mon, Mar 13, 2017 at 2:32 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-users,
>
> I have this list of student ID,
>
> dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286, AA14090,
> AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012, AA14039,
> AA15018, AA13234, AA13149, AA13282, AA13218)
>
> and I would like to extract all student of ID AA14... only.
>
> I search and tried substrt, subset and select but it fail.
>
>  substr(FKASA$STUDENT_ID, 2, nchar(string1))
> Error in nchar(string1) : 'nchar()' requires a character vector
>> subset(FKASA, STUDENT_ID=="AA14" )
>  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM     KURSUS
>  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>  ACT_IM
> [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>
> Thank you so much for your help.
>
> How do I do it?
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar 13 16:18:33 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 13 Mar 2017 15:18:33 +0000
Subject: [R] problem with PCA
In-Reply-To: <CAJMcJMBQe=j2rpcemhnPzZKvvboOiRRK2SY0OimtJhuLtVD5mg@mail.gmail.com>
References: <CAJMcJMC+JmZwc6sGD+e5FJ+9knixvERXMkP0DkvPtu+CUbdN-w@mail.gmail.com>
	<023ddc217f1d44f483feb489c6e8da5e@exch-2p-mbx-w2.ads.tamu.edu>
	<CAJMcJMBQe=j2rpcemhnPzZKvvboOiRRK2SY0OimtJhuLtVD5mg@mail.gmail.com>
Message-ID: <e0240115382649298e11499ed4a09fd3@exch-2p-mbx-w2.ads.tamu.edu>

The manual is talking about the angle between the variables in p dimensional space were p is the number of variables. The angle can appear differently in 2-dimensions depending on your viewing angle (which dimensions you are ignoring, think of how the 2-dimensional shadow of a 3-dimensional object changes as the sun moves across the sky). Imagine two vectors originating at the origin on a plane, one pointing northeast and one pointing southeast. Now rotate those vectors in a 3rd dimension by bringing the northeast vector toward you. As you do that the southeast vector will move away and the angle between the 2 will appear to decrease. When you have rotated 90 degrees toward you, the vectors will be on top of one another, their angle appears to have changed from 90 degrees to 0 degrees. 

As you indicated, in your first example, your variables are only moderately correlated. The first 2 components capture only 78 percent of the variation among the original 4 variables:

> summary(pca.mx_fus)
Importance of components:
                          PC1      PC2      PC3     PC4
Standard deviation     1.5264   0.8950   0.7234 0.58793
Proportion of Variance 0.5825   0.2003   0.1308 0.08642
Cumulative Proportion  0.5825 <<0.7828>> 0.9136 1.00000

In your second example, the variables are more highly correlated and the first 2 components capture almost 98 percent of the variation among the original 5 variables. As a result, plotting the first two variables gives you a better perspective on variation in the original 5 dimensions:

> summary(pca.tb)
Importance of components:
                          PC1      PC2       PC3     PC4       PC5
Standard deviation     1.9694   1.0063   0.32647 0.04681 3.868e-17
Proportion of Variance 0.7757   0.2025   0.02132 0.00044 0.000e+00
Cumulative Proportion  0.7757 <<0.9782>> 0.99956 1.00000 1.000e+00

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



From: Denis Francisci [mailto:denis.francisci at gmail.com] 
Sent: Saturday, March 11, 2017 3:21 AM
To: David L Carlson <dcarlson at tamu.edu>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] problem with PCA

Thank you David for your answer. 
If I understood the relative positions of variable arrows don't reflect the coefficient of correlation of the original variables. In fact these positions change if I use different PC axes.
But in some manual about PCA in R I read: "Pairs of variables that form acute angles at the origin, close to 0?, should be highly and positively correlated; variables close to right angles tend to have low correlation; variables at obtuse angles, close to 180?, tend to have high negative correlation".

And If I do a fictional test, it seems true:

tb<-data.frame(
? c(1,2,3,4,5,6,7,8,9), #orig data
? c(2,4,5,8,10,12,14,16,18),#strong positive correlation
? c(25,29,52,63,110,111,148,161,300),#weakly correlation
? c(-1,-2,-3,-4,-5,-6,-7,-8,-9),#strong negative correlation
? c(3,8,4,6,1,3,2,5,7)#not correlation
)
names(tb)<-c("orig","corr+","corr+2","corr-","random")

pca<-prcomp(as.matrix(tb),scale=T)
biplot(pca,choices = c(1,2))

On the first 2 PC the positions of arrows reflect perfectly the original correlations.

My data behaviour differently, maybe because my original variables are not strong correlated?

2017-03-10 15:49 GMT+01:00 David L Carlson <dcarlson at tamu.edu>:
This is more a question about principal components analysis than about R. You have 4 variables and they are moderately correlated with one another (weight and hole are only .2). When the data consist of measurements, this usually suggests that the overall size of the object is being partly measured by each variable. In your case object size is measured by the first principle component (PC1) with larger objects having more negative scores so larger objects are on the left and smaller ones are on the right of the biplot.

The biplot can only display 2 of the 4 dimensions of your data at one time. In the first 2 dimensions, diam and height are close together, but in the 3rd dimension (PC3), they are on opposite sides of the component. If you plot different pairs of dimensions (e.g. 1 with 3 or 2 with 3, see below), the arrows will look different because you are looking from different directions.

> pca
Standard deviations:
[1] 1.5264292 0.8950379 0.7233671 0.5879295

Rotation:
? ? ? ? ? ? ? PC1? ? ? ? ?PC2? ? ? ? ?PC3? ? ? ? PC4
height -0.5210224 -0.06545193? 0.80018012 -0.2897646
diam? ?-0.5473677? 0.06309163 -0.57146893 -0.6081376
hole? ?-0.4598646 -0.70952862 -0.17476677? 0.5045297
weight -0.4663141? 0.69878797 -0.05090785? 0.5400508

> biplot(pca, choices=c(1, 3))
> biplot(pca, choices=c(2, 3))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Denis Francisci
Sent: Friday, March 10, 2017 4:45 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] problem with PCA

Hi all.
I'm newbie in PCA by I don't understand a behaviour of R.
I have this data matrix:

>mx_fus
? height diam? hole? weight
1? ? 2.3? 3.5? 1.1? ?18
2? ? 2.0? 3.5? 0.9? ?17
3? ? 3.8? 4.3? 0.7? ?34
4? ? 2.1? 3.4? 0.9? ?15
5? ? 2.3? 3.8? 1.0? ?19
6? ? 2.2? 3.8? 1.0? ?19
7? ? 3.2? 4.4? 0.9? ?34
8? ? 3.0? 4.3? 1.0? ?30
9? ? 2.8? 3.9? 0.9? ?21
10? ?3.3? 4.2? 1.1? ?33
11? ?2.3? 3.9? 0.9? ?25
12? ?2.3? 3.3? 0.5? ?17
13? ?0.9? 2.4? 0.4? ?10
14? ?1.4? 2.4? 0.5? ?10
15? ?2.2? 3.6? 0.7? ?22
16? ?2.9? 3.8? 0.8? ?30
17? ?2.9? 3.5? 0.6? ?27
18? ?2.3? 3.5? 0.5? ?24
19? ?1.8? 2.3? 0.5? ?29
20? ?1.4? 2.5? 0.6? ?34
21? ?0.8? 2.3? 0.6? ?21
22? ?1.8? 2.4? 0.6? ?23
23? ?1.5? 2.2? 0.6? ? 7
24? ?0.9? 1.7? 0.4? ?14
25? ?2.1? 2.2? 0.5? ?25
26? ?1.3? 2.4? 0.6? ?33
27? ?1.3? 2.7? 0.4? ?39
28? ?0.5? 2.2? 0.5? ?13
29? ?1.4? 4.2? 0.8? ?23
30? ?1.6? 2.0? 0.4? ?30
31? ?1.4? 2.2? 0.6? ?25
32? ?1.8? 2.5? 0.6? ?28
33? ?1.4? 2.6? 0.6? ?41
34? ?1.6? 2.3? 0.3? ?32
35? ?1.6? 2.5? 0.5? ?41
36? ?2.8? 2.9? 0.8? ?47
37? ?0.6? 2.5? 0.8? ?21
38? ?1.6? 2.8? 0.7? ?13
39? ?1.7? 3.3? 0.8? ?17
40? ?1.6? 3.9? 1.9? ?20
41? ?1.4? 4.7? 0.9? ?26
42? ?1.2? 4.2? 0.7? ?21
43? ?3.5? 4.2? 0.9? ?47
44? ?2.3? 3.6? 0.7? ?24
45? ?2.3? 3.4? 0.4? ?21
46? ?1.9? 2.6? 0.7? ?14
47? ?1.9? 3.0? 0.7? ?15
48? ?2.7? 3.7? 0.9? ?26
49? ?3.0? 3.8? 0.7? ?35
50? ?1.2? 2.0? 0.7? ? 5
51? ?1.6? 2.5? 0.5? ?15
52? ?1.3? 2.6? 0.5? ?16
53? ?2.5? 3.9? 0.9? ?32
54? ?0.9? 3.3? 0.6? ? 9
55? ?1.8? 2.4? 0.5? ?17
56? ?2.4? 3.7? 1.1? ?30
57? ?2.1? 3.5? 1.1? ?22
58? ?2.6? 3.9? 1.0? ?38
59? ?2.6? 3.6? 1.0? ?27
60? ?2.6? 4.1? 1.0? ?34
61? ?2.9? 3.6? 0.8? ?32
62? ?2.6? 3.3? 0.7? ?22
63? ?1.8? 2.5? 0.7? ?26
64? ?3.0? 2.8? 1.3? ? 2
65? ?0.5? 2.2? 0.4? ? 3
66? ?1.9? 3.4? 0.7? ?14
67? ?1.4? 3.8? 0.9? ?18
68? ?2.0? 4.0? 1.0? ?30
69? ?3.1? 4.0? 1.3? ?21
70? ?2.5? 4.0? 0.8? ?19
71? ?2.5? 4.5? 1.0? ?20
72? ?1.8? 3.5? 1.4? ?18
73? ?2.1? 3.5? 1.4? ?25
74? ?1.5? 2.6? 0.5? ? 9
75? ?2.8? 3.2? 1.2? ?16
76? ?1.0? 5.0? 0.3? ?32
77? ?0.3? 5.8? 0.5? ?56
78? ?0.5? 1.5? 0.2? ? 1
79? ?0.7? 1.4? 0.2? ? 1
80? ?0.5? 1.3? 0.2? ? 1
81? ?0.7? 3.3? 0.4? ? 7
82? ?1.9? 4.7? 1.0? ?24
83? ?3.1? 4.2? 0.9? ?49
84? ?2.8? 3.6? 0.7? ?28
85? ?2.7? 3.2? 0.7? ?29
86? ?3.0? 4.0? 0.9? ?36
87? ?1.7? 2.7? 0.7? ?14
88? ?1.5? 2.9? 0.7? ?18
89? ?2.9? 3.5? 0.7? ?30
90? ?3.0? 3.4? 0.8? ?30
91? ?2.0? 2.8? 0.5? ?14
92? ?2.4? 3.5? 0.7? ?24
93? ?0.8? 4.1? 0.6? ?12
94? ?1.7? 2.5? 0.5? ?23
95? ?1.4? 2.4? 0.8? ?31
96? ?1.5? 2.7? 0.4? ?20
97? ?2.6? 3.7? 0.6? ?31
98? ?2.6? 3.0? 0.6? ?18
99? ?2.5? 5.0? 0.7? ?40
100? 2.5? 3.7? 0.5? ?30
101? 2.4? 2.9? 0.7? ?17
102? 2.3? 3.0? 0.5? ?15
103? 2.2? 3.3? 0.6? ?19
104? 1.5? 2.1? 0.5? ? 5
105? 2.0? 2.2? 0.5? ?10
106? 2.6? 3.5? 0.6? ?26
107? 2.3? 3.0? 0.6? ?15
108? 2.5? 4.5? 0.7? ?40
109? 2.1? 3.1? 0.5? ?15
110? 1.3? 2.1? 0.8? ?14
111? 0.8? 2.5? 0.2? ? 5
112? 0.6? 3.1? 0.7? ? 8

I perform a PCA in R

>pca<-prcomp(mx_fus,scale=TRUE)
>biplot(pca, choices = c(1,2), cex=0.7)

The biplot put the arrows of diam and height very near on the first
component axis.
So I understand that these 2 variables are well represented in the PC1 and
they are correlated each other.
But if I test the correlation, the value o correlation coefficient is low

>cor(mx_fus[,1],mx_fus[,2])
0.4828185

Why the plot says a thing and correlation function says the opposite?
Two near arrows don't represent a strong correlation between the 2
variables (as I read in some manuals), but only with the component axis?

Than's in advance
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gm at presans.com  Mon Mar 13 16:51:15 2017
From: gm at presans.com (Guillaume MULLER)
Date: Mon, 13 Mar 2017 16:51:15 +0100
Subject: [R] Error: memory exhausted (limit reached?)
Message-ID: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>

Hello everyone,

I was working on a DeepNet project at home, with an old PC with 4Gb RAM, running Ubuntu 16.04.

For efficiency reason, I stored my dataset as a csv file with write.csv and reloaded it at will with read.csv. I did it several time, everything was working fine.

This morning, at work, I wanted to use a more powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:

$ R
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)
Error: C stack usage  7970548 is too close to the limit


I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
$ ulimit -s
8192
$ ulimit -s $((100*$(ulimit -s)))
$ R --vanilla
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)

How is it possible that a machine with twice the RAM as the previous one cannot load my file? Also how is it possible that a 513MB file cannot be read on a machine with 8GB RAM?

Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug, but I don't know where to look for...

-----------------
FYI, my R version is:


16:05:12 R > version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          3.1
year           2016
month          06
day            21
svn rev        70800
language       R
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair

-----------------
For the sake of completeness, my Trainset is available at the following link, looks perfectly correct and loads perfectly @home but not @work...

https://mega.nz/#!1E9VHYKZ!isyoJEe6zoLdtC3efoZQreyxKP8sVJyvaiiLSEg4sBY

$ ls trainSetWhole.csv
-rw------- 1 guize guize 513M Mar  1 18:14 trainSetWhole.csv
$ head -n2 trainSetWhole.csv
"","i1","i2","i3","i4","i5","i6","i7","i8","i9","i10","i11","i12","i13","i14","i15","i16","i17","i18","i19","i20","i21","i22","i23","i24","i25","i26","i27","i28","i29","i30","i31","i32","i33","i34","i35","i36","i37","i38","i39","i40","i41","i42","i43","i44","i45","i46","i47","i48","i49","i50","i51","i52","i53","i54","i55","i56","i57","i58","i59","i60","i61","i62","i63","i64","i65","i66","i67","i68","i69","i70","i71","i72","i73","i74","i75","i76","i77","i78","i79","i80","i81","i82","i83","i84","i85","i86","i87","i88","i89","i90","i91","i92","i93","i94","i95","i96","i97","i98","i99","i100","i101","i102","i103","i104","i105","i106","i107","i108","i109","i110","i111","i112","i113","i114","i115","i116","i117","i118","i119","i120","i121","i122","i123","i124","i125","i126","i127","i128","i129","i130","i131","i132","i133","i134","i135","i136","i137","i138","i139","i140","c0","c1","c2","c3","c4","c5","c6","c7","c8","c9","cE","cH"
"1",-1.37446682201354e-17,2.26278846107692e-17,-1.27974510570192e-17,0.350805746453904,0.0689877720064749,3.96782166297516e-17,8.3747934622645e-17,-3.10693828550825e-17,-6.20727662108592e-17,3.50781139850846e-17,-7.43520083579608e-18,-2.01937105782818e-17,7.90527666844222e-17,0.00144287421147209,-1.88026404914112e-17,7.50553543898089e-17,-3.1156305544842e-17,3.33522787760855e-17,-8.2365725541805e-17,5.58356055978426e-17,-1.0212113811016e-17,2.03979863594455e-17,4.09717807934463e-17,0.0216467781249343,-3.44153670483002e-17,1.63751844321319e-17,0.0370002406507207,6.07678690807364e-18,-8.21680252405594e-17,4.44832722506604e-17,6.4069604073711e-17,-2.25481427040111e-17,4.03090616886684e-17,0.0326641123208996,-7.66887661628525e-17,2.74073501177539e-19,2.16820561358683e-17,4.48746042635995e-17,-1.09133528709867e-16,7.27192988615857e-17,3.12504939940947e-17,1.00863400203073e-17,-1.16417253776312e-17,0.000827131700928926,2.15591878205102e-17,-3.55400897372337e-17,-5.31549197577629e-17,6.36151166067713e-17,-3.98986076789542e-17,8.923132020282e-17,2.25307349483604e-17,1.12105833438192e-17,6.11627660475528e-17,0.00457304914240373,-4.40071366400508e-17,-2.44832622161246e-17,0.0421621636081912,2.46626049639688e-17,-9.62286119146992e-18,-1.88510143728912e-17,-1.04308238059585e-17,-2.93643045718137e-17,2.20818728169428e-17,-4.44567220452202e-17,-8.94603852191165e-17,-9.94874448913085e-18,0.0114804462249642,-9.35428456683928e-18,-1.80861616310379e-17,3.92469708878433e-17,-4.74071809520974e-17,-9.12321682896516e-18,-3.69120306784775e-17,0.13411638484663,-1.15868506960443e-16,-7.46389966104001e-17,0.015082205973855,6.53743919930211e-18,2.67372672961429e-17,-1.91214022579557e-17,-2.63284305395001e-18,4.36662713526659e-17,-1.32415731622945e-17,0.0917760638890958,-5.1463921187737e-17,-3.06212083550592e-17,0.020354034217623,1.42110160178925e-17,8.78127934370195e-18,1.10296552176504e-17,6.04875461249026e-18,-1.12907950679241e-16,6.41934790659652e-17,0.0635906532396394,-5.80721386923163e-17,2.60888831084575e-17,0.318234894813079,-2.64405232759225e-17,-3.83483045548365e-17,6.03901669028453e-17,-8.12491526717919e-17,-2.31961766473706e-17,2.49851938854807e-17,0.0666134385177111,0.277994494373684,0.757276941042661,-6.17404037289403e-18,7.89863674358793e-17,-7.67835382820615e-17,1.02140113616298e-17,1.52661784797379e-17,-9.56651701308766e-17,-3.02020715735595e-17,0.388119618133219,0.407682070148667,2.2374985383075e-18,1.11172424441548e-16,5.834694549909e-18,-6.98992457434969e-17,2.58373931894799e-17,1.77047896799026e-17,-1.32411436947046e-17,2.48508545648632e-17,0.00261698558797486,-4.74012929746027e-18,-6.88567774177344e-18,-1.42368729782461e-17,3.86907870454172e-18,-1.18115468072844e-16,5.8232650855203e-17,-6.19221175303288e-18,1.66357706932964e-17,6.39953697342706e-17,2.06819618922065e-17,1.12542559622211e-17,1.61613122517958e-17,-8.54903096963431e-18,-2.91678323773648e-17,-1.24859483206721e-16,7.55251863839618e-18,1,0,0,0,0,0,0,0,0,0,0,0


If anyone has an idea...

From tmad109 at aucklanduni.ac.nz  Mon Mar 13 06:52:34 2017
From: tmad109 at aucklanduni.ac.nz (Thilini Maddegoda Vidanelage)
Date: Mon, 13 Mar 2017 18:52:34 +1300
Subject: [R] Principle Coordinate Analysis of unweighted UniFrac distances
	on R
Message-ID: <CAPPUJ6xDwui1TT1aitvvhQ2sxnYCyrCXzEY+K5WEvzoKT4nwCw@mail.gmail.com>

Dear all,

First of all, I am so grateful if you can help me
in analyzing principle coordinate analysis of unweighted UniFrac distances
on R.


I am analyzing microbial species profile of an individual (BA) versus
reference population (HMP) and want to generate a PCoA graph to see whether
there any clusters of OTUs related to my samples.



In a table, I have OTUs (percentages) for 6 replicates of one subject (BA)
and 2910 reference subjects. Below is the format [it has only 9 subjects
(including 6 replicates of one subject and 3 reference subjects) in rows
and 5 microbial species in columns]. The second column shows the type of
sample whether it a BA or HMP.



SampleName

Group

g__Abiotrophia

g__Acetanaerobacterium

g__Acetatifactor

g__Acetivibrio

g__Acetobacter

1970_I

BA

0

0.038857

0.003473

0

0

1970_III

BA

0

0.035763

0

0

0

1970_IV

BA

0

0.021248

0

0

0

2016_I

BA

0

0.015537

0

0

0

2016_II

BA

0

0.02313

0

0

0

2016_III

BA

0

0.021606

0

0

0

X700110831

HMP

0

0

0

0

0

X700021898

HMP

0

0

0

0

0

X700113546

HMP

0

0

0

0

0



I have been trying to generate the graph for 5-6 days by looking at
different tutorials but  I am not succeeded in generating the graph that I
wanted yet. After doing some tutorials, I installed these packages such as
Ggplot2, dplyr, dendextend, RColorBrewer, vegan, GUniFrac, labdsv in R.

Is there anyone who can guide me in this or suggest a tutorial which helps
me to do the analysis step by step. I am a newbie to R.

Any help is much more appreciated.



Many thanks and best regards,
*Thilini Jayasinghe*
PhD Candidate
Liggins Institute
The University of Auckland
Building 503/201, 85 Park Road, Grafton, Auckland 2023
Mobile: +64 220211604
Email: tmad109 at aucklanduni.ac.nz

	[[alternative HTML version deleted]]


From liushun.1 at qq.com  Mon Mar 13 14:22:43 2017
From: liushun.1 at qq.com (=?gb18030?B?wfXLsw==?=)
Date: Mon, 13 Mar 2017 21:22:43 +0800
Subject: [R] =?gb18030?q?=BB=D8=B8=B4=A3=BA__Linear_Mixed-Effects_Model?=
In-Reply-To: <CAGxFJbQjAYTHf2WEnW-Gp6UQntCBhyPemBBZnEv5TAheFykqGw@mail.gmail.com>
References: <tencent_487EF88947AB5E54187B854A@qq.com>
	<CAGxFJbQjAYTHf2WEnW-Gp6UQntCBhyPemBBZnEv5TAheFykqGw@mail.gmail.com>
Message-ID: <tencent_6279086337F2B5FD1FA01BD0@qq.com>

Thank You



------------------ ???????? ------------------
??????: "Bert Gunter"<bgunter.4567 at gmail.com>; 
????????: 2017??3??11??(??????) ????11:44
??????: "????"<liushun.1 at qq.com>; 
????: "r-help"<r-help at r-project.org>; 
????: Re: [R] Linear Mixed-Effects Model



Have you read the docs? Is this some kind of homework? -- this list
does not do homework. We expect minimal efforts at least on the part
of posters. We do not do tutorials here. I think you need to do some
reading on your own before posting further. Try posting on the
r-sig-mixed-models list to get or to be directed to such tutorials.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 10, 2017 at 9:24 PM, ???? <liushun.1 at qq.com> wrote:
> Dear R Help:
> What does "lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" mean?
> And
> "lmer(responce ~ factor1*factor2 + (factor1*factor2 | group1) + (factor1*factor2| group2), data)" vs. "lmer(responce ~ factor1*factor2 + (factor1+factor2 | group1) + (factor1+factor2| group2), data)"?
> And
> Experiment includes 2 factors ,2 group structrues and 1 response,I want to use Mixed-Effects Model.How to express the full model with R
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From gm at presans.com  Mon Mar 13 16:51:15 2017
From: gm at presans.com (Guillaume MULLER)
Date: Mon, 13 Mar 2017 16:51:15 +0100
Subject: [R] Error: memory exhausted (limit reached?)
Message-ID: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>

Hello everyone,

I was working on a DeepNet project at home, with an old PC with 4Gb RAM, running Ubuntu 16.04.

For efficiency reason, I stored my dataset as a csv file with write.csv and reloaded it at will with read.csv. I did it several time, everything was working fine.

This morning, at work, I wanted to use a more powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:

$ R
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)
Error: C stack usage  7970548 is too close to the limit


I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
$ ulimit -s
8192
$ ulimit -s $((100*$(ulimit -s)))
$ R --vanilla
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)

How is it possible that a machine with twice the RAM as the previous one cannot load my file? Also how is it possible that a 513MB file cannot be read on a machine with 8GB RAM?

Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug, but I don't know where to look for...

-----------------
FYI, my R version is:


16:05:12 R > version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          3.1
year           2016
month          06
day            21
svn rev        70800
language       R
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair

-----------------
For the sake of completeness, my Trainset is available at the following link, looks perfectly correct and loads perfectly @home but not @work...

https://mega.nz/#!1E9VHYKZ!isyoJEe6zoLdtC3efoZQreyxKP8sVJyvaiiLSEg4sBY

$ ls trainSetWhole.csv
-rw------- 1 guize guize 513M Mar  1 18:14 trainSetWhole.csv
$ head -n2 trainSetWhole.csv
"","i1","i2","i3","i4","i5","i6","i7","i8","i9","i10","i11","i12","i13","i14","i15","i16","i17","i18","i19","i20","i21","i22","i23","i24","i25","i26","i27","i28","i29","i30","i31","i32","i33","i34","i35","i36","i37","i38","i39","i40","i41","i42","i43","i44","i45","i46","i47","i48","i49","i50","i51","i52","i53","i54","i55","i56","i57","i58","i59","i60","i61","i62","i63","i64","i65","i66","i67","i68","i69","i70","i71","i72","i73","i74","i75","i76","i77","i78","i79","i80","i81","i82","i83","i84","i85","i86","i87","i88","i89","i90","i91","i92","i93","i94","i95","i96","i97","i98","i99","i100","i101","i102","i103","i104","i105","i106","i107","i108","i109","i110","i111","i112","i113","i114","i115","i116","i117","i118","i119","i120","i121","i122","i123","i124","i125","i126","i127","i128","i129","i130","i131","i132","i133","i134","i135","i136","i137","i138","i139","i140","c0","c1","c2","c3","c4","c5","c6","c7","c8","c9","cE","cH"
"1",-1.37446682201354e-17,2.26278846107692e-17,-1.27974510570192e-17,0.350805746453904,0.0689877720064749,3.96782166297516e-17,8.3747934622645e-17,-3.10693828550825e-17,-6.20727662108592e-17,3.50781139850846e-17,-7.43520083579608e-18,-2.01937105782818e-17,7.90527666844222e-17,0.00144287421147209,-1.88026404914112e-17,7.50553543898089e-17,-3.1156305544842e-17,3.33522787760855e-17,-8.2365725541805e-17,5.58356055978426e-17,-1.0212113811016e-17,2.03979863594455e-17,4.09717807934463e-17,0.0216467781249343,-3.44153670483002e-17,1.63751844321319e-17,0.0370002406507207,6.07678690807364e-18,-8.21680252405594e-17,4.44832722506604e-17,6.4069604073711e-17,-2.25481427040111e-17,4.03090616886684e-17,0.0326641123208996,-7.66887661628525e-17,2.74073501177539e-19,2.16820561358683e-17,4.48746042635995e-17,-1.09133528709867e-16,7.27192988615857e-17,3.12504939940947e-17,1.00863400203073e-17,-1.16417253776312e-17,0.000827131700928926,2.15591878205102e-17,-3.55400897372337e-17,-5.31549197577629e-17,6.36151166067713e-17,-3.98986076789542e-17,8.923132020282e-17,2.25307349483604e-17,1.12105833438192e-17,6.11627660475528e-17,0.00457304914240373,-4.40071366400508e-17,-2.44832622161246e-17,0.0421621636081912,2.46626049639688e-17,-9.62286119146992e-18,-1.88510143728912e-17,-1.04308238059585e-17,-2.93643045718137e-17,2.20818728169428e-17,-4.44567220452202e-17,-8.94603852191165e-17,-9.94874448913085e-18,0.0114804462249642,-9.35428456683928e-18,-1.80861616310379e-17,3.92469708878433e-17,-4.74071809520974e-17,-9.12321682896516e-18,-3.69120306784775e-17,0.13411638484663,-1.15868506960443e-16,-7.46389966104001e-17,0.015082205973855,6.53743919930211e-18,2.67372672961429e-17,-1.91214022579557e-17,-2.63284305395001e-18,4.36662713526659e-17,-1.32415731622945e-17,0.0917760638890958,-5.1463921187737e-17,-3.06212083550592e-17,0.020354034217623,1.42110160178925e-17,8.78127934370195e-18,1.10296552176504e-17,6.04875461249026e-18,-1.12907950679241e-16,6.41934790659652e-17,0.0635906532396394,-5.80721386923163e-17,2.60888831084575e-17,0.318234894813079,-2.64405232759225e-17,-3.83483045548365e-17,6.03901669028453e-17,-8.12491526717919e-17,-2.31961766473706e-17,2.49851938854807e-17,0.0666134385177111,0.277994494373684,0.757276941042661,-6.17404037289403e-18,7.89863674358793e-17,-7.67835382820615e-17,1.02140113616298e-17,1.52661784797379e-17,-9.56651701308766e-17,-3.02020715735595e-17,0.388119618133219,0.407682070148667,2.2374985383075e-18,1.11172424441548e-16,5.834694549909e-18,-6.98992457434969e-17,2.58373931894799e-17,1.77047896799026e-17,-1.32411436947046e-17,2.48508545648632e-17,0.00261698558797486,-4.74012929746027e-18,-6.88567774177344e-18,-1.42368729782461e-17,3.86907870454172e-18,-1.18115468072844e-16,5.8232650855203e-17,-6.19221175303288e-18,1.66357706932964e-17,6.39953697342706e-17,2.06819618922065e-17,1.12542559622211e-17,1.61613122517958e-17,-8.54903096963431e-18,-2.91678323773648e-17,-1.24859483206721e-16,7.55251863839618e-18,1,0,0,0,0,0,0,0,0,0,0,0


If anyone has an idea...

From bgunter.4567 at gmail.com  Mon Mar 13 18:39:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 13 Mar 2017 10:39:49 -0700
Subject: [R] Principle Coordinate Analysis of unweighted UniFrac
 distances on R
In-Reply-To: <CAPPUJ6xDwui1TT1aitvvhQ2sxnYCyrCXzEY+K5WEvzoKT4nwCw@mail.gmail.com>
References: <CAPPUJ6xDwui1TT1aitvvhQ2sxnYCyrCXzEY+K5WEvzoKT4nwCw@mail.gmail.com>
Message-ID: <CAGxFJbQ4KEkniMinhtK1XUybrbOrmBg2g7D_s=_MpL_Nc_hFQg@mail.gmail.com>

Please read and follow the posting guide.

Plain text only + code that you tried + reproducible exam (google it).

In general, we do not do tutorials here, but someone may indeed be
able to refer you to one on the web. Googling "principal coordinates
analysis tutorial R" appeared to bring up relevant hits, including a
tutorial using the vegan package functionality.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 12, 2017 at 10:52 PM, Thilini Maddegoda Vidanelage
<tmad109 at aucklanduni.ac.nz> wrote:
> Dear all,
>
> First of all, I am so grateful if you can help me
> in analyzing principle coordinate analysis of unweighted UniFrac distances
> on R.
>
>
> I am analyzing microbial species profile of an individual (BA) versus
> reference population (HMP) and want to generate a PCoA graph to see whether
> there any clusters of OTUs related to my samples.
>
>
>
> In a table, I have OTUs (percentages) for 6 replicates of one subject (BA)
> and 2910 reference subjects. Below is the format [it has only 9 subjects
> (including 6 replicates of one subject and 3 reference subjects) in rows
> and 5 microbial species in columns]. The second column shows the type of
> sample whether it a BA or HMP.
>
>
>
> SampleName
>
> Group
>
> g__Abiotrophia
>
> g__Acetanaerobacterium
>
> g__Acetatifactor
>
> g__Acetivibrio
>
> g__Acetobacter
>
> 1970_I
>
> BA
>
> 0
>
> 0.038857
>
> 0.003473
>
> 0
>
> 0
>
> 1970_III
>
> BA
>
> 0
>
> 0.035763
>
> 0
>
> 0
>
> 0
>
> 1970_IV
>
> BA
>
> 0
>
> 0.021248
>
> 0
>
> 0
>
> 0
>
> 2016_I
>
> BA
>
> 0
>
> 0.015537
>
> 0
>
> 0
>
> 0
>
> 2016_II
>
> BA
>
> 0
>
> 0.02313
>
> 0
>
> 0
>
> 0
>
> 2016_III
>
> BA
>
> 0
>
> 0.021606
>
> 0
>
> 0
>
> 0
>
> X700110831
>
> HMP
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> X700021898
>
> HMP
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> X700113546
>
> HMP
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
>
>
> I have been trying to generate the graph for 5-6 days by looking at
> different tutorials but  I am not succeeded in generating the graph that I
> wanted yet. After doing some tutorials, I installed these packages such as
> Ggplot2, dplyr, dendextend, RColorBrewer, vegan, GUniFrac, labdsv in R.
>
> Is there anyone who can guide me in this or suggest a tutorial which helps
> me to do the analysis step by step. I am a newbie to R.
>
> Any help is much more appreciated.
>
>
>
> Many thanks and best regards,
> *Thilini Jayasinghe*
> PhD Candidate
> Liggins Institute
> The University of Auckland
> Building 503/201, 85 Park Road, Grafton, Auckland 2023
> Mobile: +64 220211604
> Email: tmad109 at aucklanduni.ac.nz
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Mon Mar 13 23:53:45 2017
From: valkremk at gmail.com (Val)
Date: Mon, 13 Mar 2017 17:53:45 -0500
Subject: [R] replace
Message-ID: <CAJOiR6Yd9yrhxqRv04=Cwh1RCyZzLy8=MhKLBxJRBza2epbHiw@mail.gmail.com>

HI all,

if first name  is  Alex then I want concatenate the second column to Alex
to produce Alex and  the second column value

DF1 <- read.table(header=TRUE, text='first YR
Alex    2001
Bob     2001
Cory    2001
Cory    2002
Bob     2002
Bob     2003
Alex    2002
Alex    2003
Alex    2004')


Output
data frame
DF2
Alex-2001   2001
Bob             2001
Cory            2001
Cory            2002
Bob             2002
Bob             2003
Alex-2002   2002
Alex-2003   2003
Alex-2004   2004

I tried this one but did not work.
DF1$first[DF1$first=="Alex"] <-  paste(DF1$first, DF1$YR, sep='-')

Thank you in advance

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Mar 14 00:33:16 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 13 Mar 2017 18:33:16 -0500
Subject: [R] replace
In-Reply-To: <CAJOiR6Yd9yrhxqRv04=Cwh1RCyZzLy8=MhKLBxJRBza2epbHiw@mail.gmail.com>
References: <CAJOiR6Yd9yrhxqRv04=Cwh1RCyZzLy8=MhKLBxJRBza2epbHiw@mail.gmail.com>
Message-ID: <370B7CC5-CE5B-4832-A7E5-96D8EDD96BF6@me.com>


> On Mar 13, 2017, at 5:53 PM, Val <valkremk at gmail.com> wrote:
> 
> HI all,
> 
> if first name  is  Alex then I want concatenate the second column to Alex
> to produce Alex and  the second column value
> 
> DF1 <- read.table(header=TRUE, text='first YR
> Alex    2001
> Bob     2001
> Cory    2001
> Cory    2002
> Bob     2002
> Bob     2003
> Alex    2002
> Alex    2003
> Alex    2004')
> 
> 
> Output
> data frame
> DF2
> Alex-2001   2001
> Bob             2001
> Cory            2001
> Cory            2002
> Bob             2002
> Bob             2003
> Alex-2002   2002
> Alex-2003   2003
> Alex-2004   2004
> 
> I tried this one but did not work.
> DF1$first[DF1$first=="Alex"] <-  paste(DF1$first, DF1$YR, sep='-')
> 
> Thank you in advance


Hi,

See ?ifelse and try this:

DF1$Comb <- ifelse(DF1$first == "Alex", 
                   paste(DF1$first, DF1$YR, sep = "-"), 
                   as.character(DF1$first))

> DF1
  first   YR      Comb
1  Alex 2001 Alex-2001
2   Bob 2001       Bob
3  Cory 2001      Cory
4  Cory 2002      Cory
5   Bob 2002       Bob
6   Bob 2003       Bob
7  Alex 2002 Alex-2002
8  Alex 2003 Alex-2003
9  Alex 2004 Alex-2004


Note the coercion of the second returned value to character, otherwise you get the numeric code associated with the factor levels of DF1$first.

I generally try to avoid overwriting the source data, or in this case, column, to preserve it for future use as may be needed.

Regards,

Marc Schwartz


From jszhao at yeah.net  Tue Mar 14 02:56:14 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Tue, 14 Mar 2017 09:56:14 +0800
Subject: [R] same column name in a data frame
Message-ID: <3b9ba91d-9736-11e1-095f-b3dd56e66cf5@yeah.net>

Hi there,

I happened to find the following code can generate a data frame with 
same column name.

 > x <- data.frame(a=c(1,2,3))
 > y <- data.frame(a=c(2,3,4))
 > z <- cbind(x,y)

However, in this case, one can not use the $ to extract the second 
column, right?

Is it possible to prevent the cbind() produce a data frame with same 
column name?

Best,
Jinsong


From sebastien.bihorel at cognigencorp.com  Tue Mar 14 03:44:47 2017
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Mon, 13 Mar 2017 22:44:47 -0400 (EDT)
Subject: [R] Reshaping from long to wide with duplicate idvar and timevar
Message-ID: <783565773.62736.1489459487170.JavaMail.zimbra@cognigencorp.com>

Hi,

I would like to reshape a data.frame from long to wide format. However, the reshape function does not seem to accept data containing rows with duplicate idvar and timevar. Building upon the ?reshape example:

summary(Indometh)
wide <- reshape(Indometh, v.names = "conc", idvar = "Subject",
  timevar = "time", direction = "wide")

Indometh2 <- rbind(Indometh, Indometh2[1,])
wide <- reshape(Indometh2, v.names = "conc", idvar = "Subject",
  timevar = "time", direction = "wide")

In the 2nd call, reshape drops the duplicate. In a real world, the process I am working on will handle data with unknown number of duplicates like the one I have manually create above.

One "brute force" way to circumvent this would be to pre-process the data, identify the rows with duplicate idvar/timevar combos, and add some suffixes to the idvar variable to make the rows unique. Then I would call reshape, and finally, I would post-process the data to remove the suffixes... This does not seem very elegant.

Is there a more efficient way to go about this?

Thank you


From r.turner at auckland.ac.nz  Tue Mar 14 03:43:38 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 14 Mar 2017 15:43:38 +1300
Subject: [R] [FORGED]  same column name in a data frame
In-Reply-To: <3b9ba91d-9736-11e1-095f-b3dd56e66cf5@yeah.net>
References: <3b9ba91d-9736-11e1-095f-b3dd56e66cf5@yeah.net>
Message-ID: <cbbfe2a3-432d-7513-01f9-33ce85592e8a@auckland.ac.nz>

On 14/03/17 14:56, Jinsong Zhao wrote:
> Hi there,
>
> I happened to find the following code can generate a data frame with
> same column name.
>
>> x <- data.frame(a=c(1,2,3))
>> y <- data.frame(a=c(2,3,4))
>> z <- cbind(x,y)
>
> However, in this case, one can not use the $ to extract the second
> column, right?
>
> Is it possible to prevent the cbind() produce a data frame with same
> column name?

No.

Why not either:

(a) Just make sure the names in "x" and "y" differ?

Or:

(b) Change the names of "z", e.g. names(z) <- c("clyde","irving")?

Or maybe names(z) <- make.unique(names(z)).

You could probably write a wrapper function for cbind() to automate (b) 
if you really want to.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From maechler at stat.math.ethz.ch  Tue Mar 14 09:03:59 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Mar 2017 09:03:59 +0100
Subject: [R] Principal Coordinate Analysis of unweighted UniFrac
	distances on R
In-Reply-To: <CAGxFJbQ4KEkniMinhtK1XUybrbOrmBg2g7D_s=_MpL_Nc_hFQg@mail.gmail.com>
References: <CAPPUJ6xDwui1TT1aitvvhQ2sxnYCyrCXzEY+K5WEvzoKT4nwCw@mail.gmail.com>
	<CAGxFJbQ4KEkniMinhtK1XUybrbOrmBg2g7D_s=_MpL_Nc_hFQg@mail.gmail.com>
Message-ID: <22727.41967.432483.815655@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Mon, 13 Mar 2017 10:39:49 -0700 writes:

    > Please read and follow the posting guide.  Plain text only
    > + code that you tried + reproducible exam (google it).

    > In general, we do not do tutorials here, but someone may
    > indeed be able to refer you to one on the web. Googling
    > "principal coordinates analysis tutorial R" appeared to
    > bring up relevant hits, including a tutorial using the
    > vegan package functionality.

    > Cheers, Bert Bert Gunter

    [....]

and *PLEASE* do spell it correctly : "principal",  *NOT* 'principle'
(I've corrected it in the 'Subject' as I don't want to create another
 google hit for the wrong spelling ...)

Martin Maechler


From petr.pikal at precheza.cz  Tue Mar 14 10:04:12 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 14 Mar 2017 09:04:12 +0000
Subject: [R] replace
In-Reply-To: <370B7CC5-CE5B-4832-A7E5-96D8EDD96BF6@me.com>
References: <CAJOiR6Yd9yrhxqRv04=Cwh1RCyZzLy8=MhKLBxJRBza2epbHiw@mail.gmail.com>
	<370B7CC5-CE5B-4832-A7E5-96D8EDD96BF6@me.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1AE08@SRVEXCHCM301.precheza.cz>

Hi

slightly different version without as.character

DF1$Comb <- ifelse(DF1$first=="Alex", paste(DF1$first, DF1$YR, sep="-"), paste(DF1$first, "", sep=""))
[1] "Alex-2001" "Bob"       "Cory"      "Cory"      "Bob"       "Bob"
[7] "Alex-2002" "Alex-2003" "Alex-2004"

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Schwartz
> Sent: Tuesday, March 14, 2017 12:33 AM
> To: Val <valkremk at gmail.com>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] replace
>
>
> > On Mar 13, 2017, at 5:53 PM, Val <valkremk at gmail.com> wrote:
> >
> > HI all,
> >
> > if first name  is  Alex then I want concatenate the second column to
> > Alex to produce Alex and  the second column value
> >
> > DF1 <- read.table(header=TRUE, text='first YR
> > Alex    2001
> > Bob     2001
> > Cory    2001
> > Cory    2002
> > Bob     2002
> > Bob     2003
> > Alex    2002
> > Alex    2003
> > Alex    2004')
> >
> >
> > Output
> > data frame
> > DF2
> > Alex-2001   2001
> > Bob             2001
> > Cory            2001
> > Cory            2002
> > Bob             2002
> > Bob             2003
> > Alex-2002   2002
> > Alex-2003   2003
> > Alex-2004   2004
> >
> > I tried this one but did not work.
> > DF1$first[DF1$first=="Alex"] <-  paste(DF1$first, DF1$YR, sep='-')
> >
> > Thank you in advance
>
>
> Hi,
>
> See ?ifelse and try this:
>
> DF1$Comb <- ifelse(DF1$first == "Alex",
>                    paste(DF1$first, DF1$YR, sep = "-"),
>                    as.character(DF1$first))
>
> > DF1
>   first   YR      Comb
> 1  Alex 2001 Alex-2001
> 2   Bob 2001       Bob
> 3  Cory 2001      Cory
> 4  Cory 2002      Cory
> 5   Bob 2002       Bob
> 6   Bob 2003       Bob
> 7  Alex 2002 Alex-2002
> 8  Alex 2003 Alex-2003
> 9  Alex 2004 Alex-2004
>
>
> Note the coercion of the second returned value to character, otherwise you
> get the numeric code associated with the factor levels of DF1$first.
>
> I generally try to avoid overwriting the source data, or in this case, column, to
> preserve it for future use as may be needed.
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Mar 14 10:20:14 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 14 Mar 2017 09:20:14 +0000
Subject: [R] Reshaping from long to wide with duplicate idvar and timevar
In-Reply-To: <783565773.62736.1489459487170.JavaMail.zimbra@cognigencorp.com>
References: <783565773.62736.1489459487170.JavaMail.zimbra@cognigencorp.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1AE2D@SRVEXCHCM301.precheza.cz>

Hi

You should specify what do you want with duplicated rows. If you wanted them to be averaged you can use dcast from reshape2 package.

> dcast(Indometh2,Subject~time, fun.aggregate=mean)
Using conc as value column: use value.var to override.
  Subject 0.25  0.5 0.75    1 1.25    2    3    4    5    6    8
1       1 1.50 0.94 0.78 0.48 0.37 0.19 0.12 0.11 0.08 0.07 0.05
2       4 1.85 1.39 1.02 0.89 0.59 0.40 0.16 0.11 0.10 0.07 0.07
3       2 2.03 1.63 0.71 0.70 0.64 0.36 0.32 0.20 0.25 0.12 0.08
4       5 2.05 1.04 0.81 0.39 0.30 0.23 0.13 0.11 0.08 0.10 0.06
5       6 2.31 1.44 1.03 0.84 0.64 0.42 0.24 0.17 0.13 0.10 0.09
6       3 2.72 1.49 1.16 0.80 0.80 0.39 0.22 0.12 0.11 0.08 0.08

You can see that dcast accepts those duplicated values

dcast(Indometh2,Subject~time)
Using conc as value column: use value.var to override.
Aggregation function missing: defaulting to length
  Subject 0.25 0.5 0.75 1 1.25 2 3 4 5 6 8
1       1    2   1    1 1    1 1 1 1 1 1 1
2       4    1   1    1 1    1 1 1 1 1 1 1
3       2    1   1    1 1    1 1 1 1 1 1 1
4       5    1   1    1 1    1 1 1 1 1 1 1
5       6    1   1    1 1    1 1 1 1 1 1 1
6       3    1   1    1 1    1 1 1 1 1 1 1

However you probably need to do what you suggested if you want to make those duplicated idvar and timevar to be unique.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sebastien
> Bihorel
> Sent: Tuesday, March 14, 2017 3:45 AM
> To: r-help at r-project.org
> Subject: [R] Reshaping from long to wide with duplicate idvar and timevar
>
> Hi,
>
> I would like to reshape a data.frame from long to wide format. However, the
> reshape function does not seem to accept data containing rows with
> duplicate idvar and timevar. Building upon the ?reshape example:
>
> summary(Indometh)
> wide <- reshape(Indometh, v.names = "conc", idvar = "Subject",
>   timevar = "time", direction = "wide")
>
> Indometh2 <- rbind(Indometh, Indometh2[1,])
> wide <- reshape(Indometh2, v.names = "conc", idvar = "Subject",
>   timevar = "time", direction = "wide")
>
> In the 2nd call, reshape drops the duplicate. In a real world, the process I am
> working on will handle data with unknown number of duplicates like the one
> I have manually create above.
>
> One "brute force" way to circumvent this would be to pre-process the data,
> identify the rows with duplicate idvar/timevar combos, and add some
> suffixes to the idvar variable to make the rows unique. Then I would call
> reshape, and finally, I would post-process the data to remove the suffixes...
> This does not seem very elegant.
>
> Is there a more efficient way to go about this?
>
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Tue Mar 14 14:42:39 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 14 Mar 2017 14:42:39 +0100
Subject: [R] [FORGED]  same column name in a data frame
In-Reply-To: <cbbfe2a3-432d-7513-01f9-33ce85592e8a@auckland.ac.nz>
References: <3b9ba91d-9736-11e1-095f-b3dd56e66cf5@yeah.net>
	<cbbfe2a3-432d-7513-01f9-33ce85592e8a@auckland.ac.nz>
Message-ID: <BD3C5CA1-4DF6-4573-9588-7DD646B49ED2@gmail.com>


> On 14 Mar 2017, at 03:43 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 14/03/17 14:56, Jinsong Zhao wrote:
>> Hi there,
>> 
>> I happened to find the following code can generate a data frame with
>> same column name.
>> 
>>> x <- data.frame(a=c(1,2,3))
>>> y <- data.frame(a=c(2,3,4))
>>> z <- cbind(x,y)
>> 
>> However, in this case, one can not use the $ to extract the second
>> column, right?
>> 
>> Is it possible to prevent the cbind() produce a data frame with same
>> column name?
> 
> No.
> 
> Why not either:
> 
> (a) Just make sure the names in "x" and "y" differ?
> 
> Or:
> 
> (b) Change the names of "z", e.g. names(z) <- c("clyde","irving")?
> 
> Or maybe names(z) <- make.unique(names(z)).
> 
> You could probably write a wrapper function for cbind() to automate (b) if you really want to.
> 

Yes, this is what it is, and I doubt anyone is likely to set out to change it. 

However, it is a bit of an oddity compared to the (often undesirable) pains the data.frame code goes through to ensure distinct _row_ names; e.g.,

> cbind(data.frame(a=1), data.frame(a=2))
  a a
1 1 2

but 

> rbind(data.frame(a=c(foo=1)), data.frame(a=c(foo=2)))
     a
foo  1
foo1 2

-pr


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Tue Mar 14 15:59:19 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Mar 2017 14:59:19 +0000
Subject: [R] [FORGED]  same column name in a data frame
In-Reply-To: <BD3C5CA1-4DF6-4573-9588-7DD646B49ED2@gmail.com>
References: <3b9ba91d-9736-11e1-095f-b3dd56e66cf5@yeah.net>
	<cbbfe2a3-432d-7513-01f9-33ce85592e8a@auckland.ac.nz>
	<BD3C5CA1-4DF6-4573-9588-7DD646B49ED2@gmail.com>
Message-ID: <7727ed6b73894228b476dcd63ab79913@exch-2p-mbx-w2.ads.tamu.edu>

How about just using data.frame(): instead of cbind():

> x <- data.frame(a=c(1,2,3))
> y <- data.frame(a=c(2,3,4))
> xy <- data.frame(x, y)
> str(xy)
'data.frame':   3 obs. of  2 variables:
 $ a  : num  1 2 3
 $ a.1: num  2 3 4
> xy$a
[1] 1 2 3
> xy$a.1
[1] 2 3 4

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter dalgaard
Sent: Tuesday, March 14, 2017 8:43 AM
To: Rolf Turner <r.turner at auckland.ac.nz>
Cc: r-help at r-project.org
Subject: Re: [R] [FORGED] same column name in a data frame


> On 14 Mar 2017, at 03:43 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 14/03/17 14:56, Jinsong Zhao wrote:
>> Hi there,
>> 
>> I happened to find the following code can generate a data frame with
>> same column name.
>> 
>>> x <- data.frame(a=c(1,2,3))
>>> y <- data.frame(a=c(2,3,4))
>>> z <- cbind(x,y)
>> 
>> However, in this case, one can not use the $ to extract the second
>> column, right?
>> 
>> Is it possible to prevent the cbind() produce a data frame with same
>> column name?
> 
> No.
> 
> Why not either:
> 
> (a) Just make sure the names in "x" and "y" differ?
> 
> Or:
> 
> (b) Change the names of "z", e.g. names(z) <- c("clyde","irving")?
> 
> Or maybe names(z) <- make.unique(names(z)).
> 
> You could probably write a wrapper function for cbind() to automate (b) if you really want to.
> 

Yes, this is what it is, and I doubt anyone is likely to set out to change it. 

However, it is a bit of an oddity compared to the (often undesirable) pains the data.frame code goes through to ensure distinct _row_ names; e.g.,

> cbind(data.frame(a=1), data.frame(a=2))
  a a
1 1 2

but 

> rbind(data.frame(a=c(foo=1)), data.frame(a=c(foo=2)))
     a
foo  1
foo1 2

-pr


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Tue Mar 14 15:57:58 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 14 Mar 2017 15:57:58 +0100
Subject: [R] GADM -- Download World Map for R
Message-ID: <20170314145758.GB1243@chicca2>

Dear All,
Please have a look at the snippet here

http://bit.ly/2mVS8me

This short code addresses precisely one of my needs: to superimpose a
network (created with the igraph library) to a geographical map.
Unlike the case of the example, where a single country is enough, I
need to have a world map in R to which superimpose the network.
Seen that I am far from an expert about plotting maps in R (you may
want to resort to a purely ggplot oriented solution for the map, but
then you need to translate your network into something ggplot
understands -- see http://bit.ly/2mVSOIk ).
For me it would be way simpler to follow the footsteps of the work
done in the previous link, but I cannot download from GADM a world
map.
Does anybody know how to achieve that?
Regards

Lorenzo


#######################################################?
library(raster)
library(igraph)
greece <- getData('GADM', country='GRC', level=1)
df<-data.frame("from" = c("Athens", "Iraklio", "Thessaloniki",
"Patra"), "to"= c("Thessaloniki", "Thessaloniki", "Athens",
"Iraklio"))
meta <- data.frame("name"=c("Athens", "Iraklio", "Thessaloniki",
"Patra"),
               "lon"=c(23.72800,25.13356,22.94090,21.73507),
	                      "lat"=c(37.98415,35.33349,40.63229,38.24628))
			      g <- graph.data.frame(df, directed=T,
			      vertices=meta)
			      lo <- as.matrix(meta[,2:3])
			      plot(greece)
			      plot(g, layout=lo, add = TRUE, rescale = FALSE)


From FarkasA at optimum-dosing-strategies.org  Tue Mar 14 12:37:08 2017
From: FarkasA at optimum-dosing-strategies.org (Andras Farkas)
Date: Tue, 14 Mar 2017 11:37:08 +0000 (UTC)
Subject: [R] extending lines for prediction intervals
References: <1319079256.5251576.1489491428924.ref@mail.yahoo.com>
Message-ID: <1319079256.5251576.1489491428924@mail.yahoo.com>



 
Dear All,

would you have some thoughts on how to extend the prediction interval lines to beyond the "range of data" modeled?



example:


y <-c(0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143,

0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978,0.383012,

0.3763665,0.3550609,0.2958678,0.3726571,0.3442298 

#,0.3403275,0.2973978 

)*100 

x <-seq(1,length(y),1) 


z<-c("07/01/2015","08/01/2015","09/01/2015","10/01/2015","11/01/2015",

"12/01/2015","01/01/2016","02/01/2016","03/01/2016","04/01/2016","05/01/2016",

"06/01/2016","07/01/2016","08/01/2016","09/01/2016","10/01/2016","11/01/2016",

"12/01/2016","01/01/2017","02/01/2017") 


fit <-lm(y~x) 


temp_var <- predict(fit, interval="prediction") 


new_df <- data.frame(cbind(x,y, temp_var)) 

#new_df$x<-factor(new_df$x, ordered = T) 


library(ggplot2) 

ggplot(new_df, aes(x,y))+ 

geom_point() + 

theme(panel.background = element_rect(fill = 'white', colour = 'black'))+ 

geom_line(aes(y=lwr), color = "black", linetype = "dashed",size=0.75)+ 

geom_line(aes(y=upr), color = "black", linetype = "dashed",size=0.75)+ 

scale_x_discrete(limits=z)+ 

theme(axis.text.x = element_text(angle = 45, hjust = 1))+ 

theme(panel.grid.major=element_line(colour = "grey"))+ 

lims(y=c(0,50))+ 

geom_smooth(method=lm, se=TRUE,fullrange=TRUE,fill="darkgrey",col="black")+labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 4), 

"Intercept =",signif(fit$coef[[1]],4 ), 

" Slope =",signif(fit$coef[[2]], 4) 

# " P =",signif(summary(fit)$coef[2,4], 3) 

))+ 

ggtitle("Consumption Over Time") + 

theme(plot.title = element_text(hjust = 0.5))+ 

labs(y="y",x="x")+ 

geom_point(shape=15,aes(x=c(7),y=new_df[,2][7]), color="black",cex=4)+ 

geom_point(shape=15,aes(x=c(8),y=new_df[,2][8]), color="black",cex=4)+ 

geom_point(shape=17,aes(x=c(19),y=0.3403275*100), color="black",cex=4)+ 

geom_point(shape=17,aes(x=c(20),y=0.2973978*100), color="black",cex=4) 



as you  will see the regresssion line and confidence interval is extended, but would also want to extend the prediction interval lines to the "same length"... Wonder if you have any insights to this question...



appreciate the help,



Andras Farkas


From gm at presans.com  Tue Mar 14 10:42:21 2017
From: gm at presans.com (Guillaume MULLER)
Date: Tue, 14 Mar 2017 10:42:21 +0100
Subject: [R] Fwd: Error: memory exhausted (limit reached?)
In-Reply-To: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>
References: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>
Message-ID: <8b9b5460-6cb4-6e57-04ce-54802c86d8c8@presans.com>

Hi again,

Sorry, I messed up, the link to the actual file is:
https://mega.nz/#!ZMs0TSRJ!47DCZCnE6_FnICUp8MVS2R9eY_GdVIyGZ5O9TiejHfc

FYI, it loads perfectly on 2 machines with Ubuntu 16.04 and R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"

But exceededs stack mem under Ubuntu 16.10's R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"


-------- Forwarded Message --------
Subject: Error: memory exhausted (limit reached?)
Date: Mon, 13 Mar 2017 16:51:15 +0100
From: Guillaume MULLER <gm at presans.com>
To: r-help at r-project.org

Hello everyone,

I was working on a DeepNet project at home, with an old PC with 4Gb RAM, running Ubuntu 16.04.

For efficiency reason, I stored my dataset as a csv file with write.csv and reloaded it at will with read.csv. I did it several time, everything was working fine.

This morning, at work, I wanted to use a more powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:

$ R
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)
Error: C stack usage  7970548 is too close to the limit


I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
$ ulimit -s
8192
$ ulimit -s $((100*$(ulimit -s)))
$ R --vanilla
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)

How is it possible that a machine with twice the RAM as the previous one cannot load my file? Also how is it possible that a 513MB file cannot be read on a machine with 8GB RAM?

Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug, but I don't know where to look for...

-----------------
FYI, my R version is:


16:05:12 R > version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          3.1
year           2016
month          06
day            21
svn rev        70800
language       R
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair

-----------------
For the sake of completeness, my Trainset is available at the following link, looks perfectly correct and loads perfectly @home but not @work...

https://mega.nz/#!1E9VHYKZ!isyoJEe6zoLdtC3efoZQreyxKP8sVJyvaiiLSEg4sBY

$ ls trainSetWhole.csv
-rw------- 1 guize guize 513M Mar  1 18:14 trainSetWhole.csv
$ head -n2 trainSetWhole.csv
"","i1","i2","i3","i4","i5","i6","i7","i8","i9","i10","i11","i12","i13","i14","i15","i16","i17","i18","i19","i20","i21","i22","i23","i24","i25","i26","i27","i28","i29","i30","i31","i32","i33","i34","i35","i36","i37","i38","i39","i40","i41","i42","i43","i44","i45","i46","i47","i48","i49","i50","i51","i52","i53","i54","i55","i56","i57","i58","i59","i60","i61","i62","i63","i64","i65","i66","i67","i68","i69","i70","i71","i72","i73","i74","i75","i76","i77","i78","i79","i80","i81","i82","i83","i84","i85","i86","i87","i88","i89","i90","i91","i92","i93","i94","i95","i96","i97","i98","i99","i100","i101","i102","i103","i104","i105","i106","i107","i108","i109","i110","i111","i112","i113","i114","i115","i116","i117","i118","i119","i120","i121","i122","i123","i124","i125","i126","i127","i128","i129","i130","i131","i132","i133","i134","i135","i136","i137","i138","i139","i140","c0","c1","c2","c3","c4","c5","c6","c7","c8","c9","cE","cH"
"1",-1.37446682201354e-17,2.26278846107692e-17,-1.27974510570192e-17,0.350805746453904,0.0689877720064749,3.96782166297516e-17,8.3747934622645e-17,-3.10693828550825e-17,-6.20727662108592e-17,3.50781139850846e-17,-7.43520083579608e-18,-2.01937105782818e-17,7.90527666844222e-17,0.00144287421147209,-1.88026404914112e-17,7.50553543898089e-17,-3.1156305544842e-17,3.33522787760855e-17,-8.2365725541805e-17,5.58356055978426e-17,-1.0212113811016e-17,2.03979863594455e-17,4.09717807934463e-17,0.0216467781249343,-3.44153670483002e-17,1.63751844321319e-17,0.0370002406507207,6.07678690807364e-18,-8.21680252405594e-17,4.44832722506604e-17,6.4069604073711e-17,-2.25481427040111e-17,4.03090616886684e-17,0.0326641123208996,-7.66887661628525e-17,2.74073501177539e-19,2.16820561358683e-17,4.48746042635995e-17,-1.09133528709867e-16,7.27192988615857e-17,3.12504939940947e-17,1.00863400203073e-17,-1.16417253776312e-17,0.000827131700928926,2.15591878205102e-17,-3.55400897372337e-17,-5.31549197577629e-17,6.36151166067713e-17,-3.98986076789542e-17,8.923132020282e-17,2.25307349483604e-17,1.12105833438192e-17,6.11627660475528e-17,0.00457304914240373,-4.40071366400508e-17,-2.44832622161246e-17,0.0421621636081912,2.46626049639688e-17,-9.62286119146992e-18,-1.88510143728912e-17,-1.04308238059585e-17,-2.93643045718137e-17,2.20818728169428e-17,-4.44567220452202e-17,-8.94603852191165e-17,-9.94874448913085e-18,0.0114804462249642,-9.35428456683928e-18,-1.80861616310379e-17,3.92469708878433e-17,-4.74071809520974e-17,-9.12321682896516e-18,-3.69120306784775e-17,0.13411638484663,-1.15868506960443e-16,-7.46389966104001e-17,0.015082205973855,6.53743919930211e-18,2.67372672961429e-17,-1.91214022579557e-17,-2.63284305395001e-18,4.36662713526659e-17,-1.32415731622945e-17,0.0917760638890958,-5.1463921187737e-17,-3.06212083550592e-17,0.020354034217623,1.42110160178925e-17,8.78127934370195e-18,1.10296552176504e-17,6.04875461249026e-18,-1.12907950679241e-16,6.41934790659652e-17,0.0635906532396394,-5.80721386923163e-17,2.60888831084575e-17,0.318234894813079,-2.64405232759225e-17,-3.83483045548365e-17,6.03901669028453e-17,-8.12491526717919e-17,-2.31961766473706e-17,2.49851938854807e-17,0.0666134385177111,0.277994494373684,0.757276941042661,-6.17404037289403e-18,7.89863674358793e-17,-7.67835382820615e-17,1.02140113616298e-17,1.52661784797379e-17,-9.56651701308766e-17,-3.02020715735595e-17,0.388119618133219,0.407682070148667,2.2374985383075e-18,1.11172424441548e-16,5.834694549909e-18,-6.98992457434969e-17,2.58373931894799e-17,1.77047896799026e-17,-1.32411436947046e-17,2.48508545648632e-17,0.00261698558797486,-4.74012929746027e-18,-6.88567774177344e-18,-1.42368729782461e-17,3.86907870454172e-18,-1.18115468072844e-16,5.8232650855203e-17,-6.19221175303288e-18,1.66357706932964e-17,6.39953697342706e-17,2.06819618922065e-17,1.12542559622211e-17,1.61613122517958e-17,-8.54903096963431e-18,-2.91678323773648e-17,-1.24859483206721e-16,7.55251863839618e-18,1,0,0,0,0,0,0,0,0,0,0,0


If anyone has an idea...

From kgsrinivasa at gmail.com  Tue Mar 14 16:58:47 2017
From: kgsrinivasa at gmail.com (Srinivasa K G)
Date: Tue, 14 Mar 2017 21:28:47 +0530
Subject: [R] Request for Permission to Use Screenshots of R Installation in
 our text book
Message-ID: <CACdx11WzM8xmU_bZ9pF4DYLDQ+JvuwJH1EcxrEfMrdo1bM48xw@mail.gmail.com>

Dear Sir/Madam,


We are in the process of developing a textbook on R and are writing to
request your permission to include certain screenshots relating to
installation of the package in our book to be published tentatively in May
2017. The description of our book is as follows*:*



*Title*: Statistical Programming in R

*Approx. no. of pages*: 400

*Approx. price*: ?395.00

*Publisher*: Oxford University Press

*Territory rights*: Worldwide



We would be grateful if we might have your gratis permission to use the
screenshots (see attachment) in the above-mentioned title, supporting
supplements and any derivatives, which are to be published worldwide by
Oxford University Press. This permission would be required to cover all
media (print and electronic), any future revisions or editions of the book
and supplements and any translations of it published by Oxford University
Press or its licensees (world rights). Subject to your permissions, we
would ensure to provide due acknowledgements as appropriate.



We are looking forward to your response at the earliest.

-- 
Dr. Srinivasa K G
Associate Professor
Department of Information Technology
Ch Brahm Prakash Government Engineering College
Jaffarpur, New Delhi - 110073
Mobile: 9731696526 / 9620262690

From kgsrinivasa at gmail.com  Tue Mar 14 17:03:26 2017
From: kgsrinivasa at gmail.com (Srinivasa K G)
Date: Tue, 14 Mar 2017 21:33:26 +0530
Subject: [R] Permission to use R Installation Screenshots and Datasets
Message-ID: <CACdx11Wg7Uosk587nxeBspLT=0NJ1o9V2JdBTKNs-4E5eo25qw@mail.gmail.com>

Dear Sir/Madam,

We are in the process of developing a textbook on R and are writing to
request your permission to include certain screenshots relating to
installation of the package in our book to be published tentatively in May
2017. The description of our book is as follows*:*



*Title*: Statistical Programming in R

*Approx. no. of pages*: 400

*Approx. price*: ?395.00

*Publisher*: Oxford University Press

*Territory rights*: Worldwide



We would be grateful if we might have your gratis permission to use the
screenshots (see attachment) in the above-mentioned title, supporting
supplements and any derivatives, which are to be published worldwide by
Oxford University Press. This permission would be required to cover all
media (print and electronic), any future revisions or editions of the book
and supplements and any translations of it published by Oxford University
Press or its licensees (world rights). Subject to your permissions, we
would ensure to provide due acknowledgements as appropriate.


We would also like to use the data sets (that are part and parcel of a
typical R package) to demonstrate problems and solutions in the book.


We are looking forward to your response at the earliest.


-- 
Dr. Srinivasa K G
Associate Professor
Department of Information Technology
Ch Brahm Prakash Government Engineering College
Jaffarpur, New Delhi - 110073
Mobile: 9731696526 / 9620262690

From motyocska at yahoo.com  Tue Mar 14 12:39:51 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 14 Mar 2017 11:39:51 +0000 (UTC)
Subject: [R] extend lines of prediction interval ggplot2
References: <150344070.5264877.1489491591594.ref@mail.yahoo.com>
Message-ID: <150344070.5264877.1489491591594@mail.yahoo.com>

Dear All, 

 would you have some thoughts on how to extend the prediction interval lines to beyond the "range of data"? 


example: 

y <-c(0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143, 
0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978,0.383012, 
0.3763665,0.3550609,0.2958678,0.3726571,0.3442298 
#,0.3403275,0.2973978 
)*100 
x <-seq(1,length(y),1) 

z<-c("07/01/2015","08/01/2015","09/01/2015","10/01/2015","11/01/2015", 
"12/01/2015","01/01/2016","02/01/2016","03/01/2016","04/01/2016","05/01/2016", 
"06/01/2016","07/01/2016","08/01/2016","09/01/2016","10/01/2016","11/01/2016", 
"12/01/2016","01/01/2017","02/01/2017") 

fit <-lm(y~x) 

temp_var <- predict(fit, interval="prediction") 

new_df <- data.frame(cbind(x,y, temp_var)) 
#new_df$x<-factor(new_df$x, ordered = T) 

library(ggplot2) 
ggplot(new_df, aes(x,y))+ 
geom_point() + 
theme(panel.background = element_rect(fill = 'white', colour = 'black'))+ 
geom_line(aes(y=lwr), color = "black", linetype = "dashed",size=0.75)+ 
geom_line(aes(y=upr), color = "black", linetype = "dashed",size=0.75)+ 
scale_x_discrete(limits=z)+ 
theme(axis.text.x = element_text(angle = 45, hjust = 1))+ 
theme(panel.grid.major=element_line(colour = "grey"))+ 
lims(y=c(0,50))+ 
geom_smooth(method=lm, se=TRUE,fullrange=TRUE,fill="darkgrey",col="black")+labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 4), 
"Intercept =",signif(fit$coef[[1]],4 ), 
" Slope =",signif(fit$coef[[2]], 4) 
# " P =",signif(summary(fit)$coef[2,4], 3) 
))+ 
ggtitle("Consumption Over Time") + 
theme(plot.title = element_text(hjust = 0.5))+ 
labs(y="y",x="x")+ 
geom_point(shape=15,aes(x=c(7),y=new_df[,2][7]), color="black",cex=4)+ 
geom_point(shape=15,aes(x=c(8),y=new_df[,2][8]), color="black",cex=4)+ 
geom_point(shape=17,aes(x=c(19),y=0.3403275*100), color="black",cex=4)+ 
geom_point(shape=17,aes(x=c(20),y=0.2973978*100), color="black",cex=4) 


as you  will see the regresssion line and confidence interval is extended, but would also want to extend the prediction interval lines to the "same length"... Wonder if you have any insights to this question... 


appreciate the help, 


Andras Farkas


From nospam at lisse.NA  Tue Mar 14 16:25:26 2017
From: nospam at lisse.NA (Dr Eberhard Lisse)
Date: Tue, 14 Mar 2017 16:25:26 +0100
Subject: [R] Determine IP address of gateway
Message-ID: <b7c9c9dc-9685-c794-9c76-a332f934b19c@lisse.NA>

Hi,

I want code to run on my laptop depending on what WiFi I am connected to
(ie internally I access MySQL without password, externally with
password). Currently I look for the gateway and then branch accordingly.

Is there any way of doing

gateway = system("netstat -r -f inet -n|grep default|awk '{print $2}'",
intern = T)

within R other than running it as a system() call?

greetings, el


From bgunter.4567 at gmail.com  Tue Mar 14 18:01:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Mar 2017 10:01:55 -0700
Subject: [R] Fwd: Error: memory exhausted (limit reached?)
In-Reply-To: <8b9b5460-6cb4-6e57-04ce-54802c86d8c8@presans.com>
References: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>
	<8b9b5460-6cb4-6e57-04ce-54802c86d8c8@presans.com>
Message-ID: <CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>

I suspect this is beyond the expertise of most participants of this
list. You might wish to post this on r-devel instead,where such
expertise is more likely to be found. However, that also may not be
the right place either; it's just the best I could think of.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 14, 2017 at 2:42 AM, Guillaume MULLER <gm at presans.com> wrote:
> Hi again,
>
> Sorry, I messed up, the link to the actual file is:
> https://mega.nz/#!ZMs0TSRJ!47DCZCnE6_FnICUp8MVS2R9eY_GdVIyGZ5O9TiejHfc
>
> FYI, it loads perfectly on 2 machines with Ubuntu 16.04 and R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
>
> But exceededs stack mem under Ubuntu 16.10's R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>
>
> -------- Forwarded Message --------
> Subject: Error: memory exhausted (limit reached?)
> Date: Mon, 13 Mar 2017 16:51:15 +0100
> From: Guillaume MULLER <gm at presans.com>
> To: r-help at r-project.org
>
> Hello everyone,
>
> I was working on a DeepNet project at home, with an old PC with 4Gb RAM, running Ubuntu 16.04.
>
> For efficiency reason, I stored my dataset as a csv file with write.csv and reloaded it at will with read.csv. I did it several time, everything was working fine.
>
> This morning, at work, I wanted to use a more powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:
>
> $ R
> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
> Error: memory exhausted (limit reached?)
> Error: C stack usage  7970548 is too close to the limit
>
>
> I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
> $ ulimit -s
> 8192
> $ ulimit -s $((100*$(ulimit -s)))
> $ R --vanilla
> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
> Error: memory exhausted (limit reached?)
>
> How is it possible that a machine with twice the RAM as the previous one cannot load my file? Also how is it possible that a 513MB file cannot be read on a machine with 8GB RAM?
>
> Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug, but I don't know where to look for...
>
> -----------------
> FYI, my R version is:
>
>
> 16:05:12 R > version
>                _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          3.1
> year           2016
> month          06
> day            21
> svn rev        70800
> language       R
> version.string R version 3.3.1 (2016-06-21)
> nickname       Bug in Your Hair
>
> -----------------
> For the sake of completeness, my Trainset is available at the following link, looks perfectly correct and loads perfectly @home but not @work...
>
> https://mega.nz/#!1E9VHYKZ!isyoJEe6zoLdtC3efoZQreyxKP8sVJyvaiiLSEg4sBY
>
> $ ls trainSetWhole.csv
> -rw------- 1 guize guize 513M Mar  1 18:14 trainSetWhole.csv
> $ head -n2 trainSetWhole.csv
> "","i1","i2","i3","i4","i5","i6","i7","i8","i9","i10","i11","i12","i13","i14","i15","i16","i17","i18","i19","i20","i21","i22","i23","i24","i25","i26","i27","i28","i29","i30","i31","i32","i33","i34","i35","i36","i37","i38","i39","i40","i41","i42","i43","i44","i45","i46","i47","i48","i49","i50","i51","i52","i53","i54","i55","i56","i57","i58","i59","i60","i61","i62","i63","i64","i65","i66","i67","i68","i69","i70","i71","i72","i73","i74","i75","i76","i77","i78","i79","i80","i81","i82","i83","i84","i85","i86","i87","i88","i89","i90","i91","i92","i93","i94","i95","i96","i97","i98","i99","i100","i101","i102","i103","i104","i105","i106","i107","i108","i109","i110","i111","i112","i113","i114","i115","i116","i117","i118","i119","i120","i121","i122","i123","i124","i125","i126","i127","i128","i129","i130","i131","i132","i133","i134","i135","i136","i137","i138","i139","i140","c0","c1","c2","c3","c4","c5","c6","c7","c8","c9","cE","cH"
> "1",-1.37446682201354e-17,2.26278846107692e-17,-1.27974510570192e-17,0.350805746453904,0.0689877720064749,3.96782166297516e-17,8.3747934622645e-17,-3.10693828550825e-17,-6.20727662108592e-17,3.50781139850846e-17,-7.43520083579608e-18,-2.01937105782818e-17,7.90527666844222e-17,0.00144287421147209,-1.88026404914112e-17,7.50553543898089e-17,-3.1156305544842e-17,3.33522787760855e-17,-8.2365725541805e-17,5.58356055978426e-17,-1.0212113811016e-17,2.03979863594455e-17,4.09717807934463e-17,0.0216467781249343,-3.44153670483002e-17,1.63751844321319e-17,0.0370002406507207,6.07678690807364e-18,-8.21680252405594e-17,4.44832722506604e-17,6.4069604073711e-17,-2.25481427040111e-17,4.03090616886684e-17,0.0326641123208996,-7.66887661628525e-17,2.74073501177539e-19,2.16820561358683e-17,4.48746042635995e-17,-1.09133528709867e-16,7.27192988615857e-17,3.12504939940947e-17,1.00863400203073e-17,-1.16417253776312e-17,0.000827131700928926,2.15591878205102e-17,-3.55400897372337e-17,-5.31549197577629e-!
>  17,6.36151166067713e-17,-3.98986076789542e-17,8.923132020282e-17,2.25307349483604e-17,1.12105833438192e-17,6.11627660475528e-17,0.00457304914240373,-4.40071366400508e-17,-2.44832622161246e-17,0.0421621636081912,2.46626049639688e-17,-9.62286119146992e-18,-1.88510143728912e-17,-1.04308238059585e-17,-2.93643045718137e-17,2.20818728169428e-17,-4.44567220452202e-17,-8.94603852191165e-17,-9.94874448913085e-18,0.0114804462249642,-9.35428456683928e-18,-1.80861616310379e-17,3.92469708878433e-17,-4.74071809520974e-17,-9.12321682896516e-18,-3.69120306784775e-17,0.13411638484663,-1.15868506960443e-16,-7.46389966104001e-17,0.015082205973855,6.53743919930211e-18,2.67372672961429e-17,-1.91214022579557e-17,-2.63284305395001e-18,4.36662713526659e-17,-1.32415731622945e-17,0.0917760638890958,-5.1463921187737e-17,-3.06212083550592e-17,0.020354034217623,1.42110160178925e-17,8.78127934370195e-18,1.10296552176504e-17,6.04875461249026e-18,-1.12907950679241e-16,6.41934790659652e-17,0.06359065323963!
>  94,-5.80721386923163e-17,2.60888831084575e-17,0.318234894813079,-2.644
> 05232759225e-17,-3.83483045548365e-17,6.03901669028453e-17,-8.12491526717919e-17,-2.31961766473706e-17,2.49851938854807e-17,0.0666134385177111,0.277994494373684,0.757276941042661,-6.17404037289403e-18,7.89863674358793e-17,-7.67835382820615e-17,1.02140113616298e-17,1.52661784797379e-17,-9.56651701308766e-17,-3.02020715735595e-17,0.388119618133219,0.407682070148667,2.2374985383075e-18,1.11172424441548e-16,5.834694549909e-18,-6.98992457434969e-17,2.58373931894799e-17,1.77047896799026e-17,-1.32411436947046e-17,2.48508545648632e-17,0.00261698558797486,-4.74012929746027e-18,-6.88567774177344e-18,-1.42368729782461e-17,3.86907870454172e-18,-1.18115468072844e-16,5.8232650855203e-17,-6.19221175303288e-18,1.66357706932964e-17,6.39953697342706e-17,2.06819618922065e-17,1.12542559622211e-17,1.61613122517958e-17,-8.54903096963431e-18,-2.91678323773648e-17,-1.24859483206721e-16,7.55251863839618e-18,1,0,0,0,0,0,0,0,0,0,0,0
>
>
> If anyone has an idea...
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Tue Mar 14 18:04:53 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 14 Mar 2017 12:04:53 -0500
Subject: [R] Fwd: Error: memory exhausted (limit reached?)
In-Reply-To: <CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>
References: <a84228ff-d4b8-5cd2-6333-f0c47ed084a1@presans.com>
	<8b9b5460-6cb4-6e57-04ce-54802c86d8c8@presans.com>
	<CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>
Message-ID: <2f8f0751-1e08-b967-5145-fab00c329dec@effectivedefense.org>



On 2017-03-14 12:01 PM, Bert Gunter wrote:
> I suspect this is beyond the expertise of most participants of this
> list. You might wish to post this on r-devel instead,where such
> expertise is more likely to be found. However, that also may not be
> the right place either; it's just the best I could think of.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Mar 14, 2017 at 2:42 AM, Guillaume MULLER <gm at presans.com> wrote:
>> Hi again,
>>
>> Sorry, I messed up, the link to the actual file is:
>> https://mega.nz/#!ZMs0TSRJ!47DCZCnE6_FnICUp8MVS2R9eY_GdVIyGZ5O9TiejHfc
>>
>> FYI, it loads perfectly on 2 machines with Ubuntu 16.04 and R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
>>
>> But exceededs stack mem under Ubuntu 16.10's R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"


       Did you try R 3.3.3?  Spencer Graves
>>
>> -------- Forwarded Message --------
>> Subject: Error: memory exhausted (limit reached?)
>> Date: Mon, 13 Mar 2017 16:51:15 +0100
>> From: Guillaume MULLER <gm at presans.com>
>> To: r-help at r-project.org
>>
>> Hello everyone,
>>
>> I was working on a DeepNet project at home, with an old PC with 4Gb RAM, running Ubuntu 16.04.
>>
>> For efficiency reason, I stored my dataset as a csv file with write.csv and reloaded it at will with read.csv. I did it several time, everything was working fine.
>>
>> This morning, at work, I wanted to use a more powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:
>>
>> $ R
>> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
>> Error: memory exhausted (limit reached?)
>> Error: C stack usage  7970548 is too close to the limit
>>
>>
>> I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
>> $ ulimit -s
>> 8192
>> $ ulimit -s $((100*$(ulimit -s)))
>> $ R --vanilla
>> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
>> Error: memory exhausted (limit reached?)
>>
>> How is it possible that a machine with twice the RAM as the previous one cannot load my file? Also how is it possible that a 513MB file cannot be read on a machine with 8GB RAM?
>>
>> Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug, but I don't know where to look for...
>>
>> -----------------
>> FYI, my R version is:
>>
>>
>> 16:05:12 R > version
>>                 _
>> platform       x86_64-pc-linux-gnu
>> arch           x86_64
>> os             linux-gnu
>> system         x86_64, linux-gnu
>> status
>> major          3
>> minor          3.1
>> year           2016
>> month          06
>> day            21
>> svn rev        70800
>> language       R
>> version.string R version 3.3.1 (2016-06-21)
>> nickname       Bug in Your Hair
>>
>> -----------------
>> For the sake of completeness, my Trainset is available at the following link, looks perfectly correct and loads perfectly @home but not @work...
>>
>> https://mega.nz/#!1E9VHYKZ!isyoJEe6zoLdtC3efoZQreyxKP8sVJyvaiiLSEg4sBY
>>
>> $ ls trainSetWhole.csv
>> -rw------- 1 guize guize 513M Mar  1 18:14 trainSetWhole.csv
>> $ head -n2 trainSetWhole.csv
>> "","i1","i2","i3","i4","i5","i6","i7","i8","i9","i10","i11","i12","i13","i14","i15","i16","i17","i18","i19","i20","i21","i22","i23","i24","i25","i26","i27","i28","i29","i30","i31","i32","i33","i34","i35","i36","i37","i38","i39","i40","i41","i42","i43","i44","i45","i46","i47","i48","i49","i50","i51","i52","i53","i54","i55","i56","i57","i58","i59","i60","i61","i62","i63","i64","i65","i66","i67","i68","i69","i70","i71","i72","i73","i74","i75","i76","i77","i78","i79","i80","i81","i82","i83","i84","i85","i86","i87","i88","i89","i90","i91","i92","i93","i94","i95","i96","i97","i98","i99","i100","i101","i102","i103","i104","i105","i106","i107","i108","i109","i110","i111","i112","i113","i114","i115","i116","i117","i118","i119","i120","i121","i122","i123","i124","i125","i126","i127","i128","i129","i130","i131","i132","i133","i134","i135","i136","i137","i138","i139","i140","c0","c1","c2","c3","c4","c5","c6","c7","c8","c9","cE","cH"
>> "1",-1.37446682201354e-17,2.26278846107692e-17,-1.27974510570192e-17,0.350805746453904,0.0689877720064749,3.96782166297516e-17,8.3747934622645e-17,-3.10693828550825e-17,-6.20727662108592e-17,3.50781139850846e-17,-7.43520083579608e-18,-2.01937105782818e-17,7.90527666844222e-17,0.00144287421147209,-1.88026404914112e-17,7.50553543898089e-17,-3.1156305544842e-17,3.33522787760855e-17,-8.2365725541805e-17,5.58356055978426e-17,-1.0212113811016e-17,2.03979863594455e-17,4.09717807934463e-17,0.0216467781249343,-3.44153670483002e-17,1.63751844321319e-17,0.0370002406507207,6.07678690807364e-18,-8.21680252405594e-17,4.44832722506604e-17,6.4069604073711e-17,-2.25481427040111e-17,4.03090616886684e-17,0.0326641123208996,-7.66887661628525e-17,2.74073501177539e-19,2.16820561358683e-17,4.48746042635995e-17,-1.09133528709867e-16,7.27192988615857e-17,3.12504939940947e-17,1.00863400203073e-17,-1.16417253776312e-17,0.000827131700928926,2.15591878205102e-17,-3.55400897372337e-17,-5.31549197577629!
>   e-!
>>   17,6.36151166067713e-17,-3.98986076789542e-17,8.923132020282e-17,2.25307349483604e-17,1.12105833438192e-17,6.11627660475528e-17,0.00457304914240373,-4.40071366400508e-17,-2.44832622161246e-17,0.0421621636081912,2.46626049639688e-17,-9.62286119146992e-18,-1.88510143728912e-17,-1.04308238059585e-17,-2.93643045718137e-17,2.20818728169428e-17,-4.44567220452202e-17,-8.94603852191165e-17,-9.94874448913085e-18,0.0114804462249642,-9.35428456683928e-18,-1.80861616310379e-17,3.92469708878433e-17,-4.74071809520974e-17,-9.12321682896516e-18,-3.69120306784775e-17,0.13411638484663,-1.15868506960443e-16,-7.46389966104001e-17,0.015082205973855,6.53743919930211e-18,2.67372672961429e-17,-1.91214022579557e-17,-2.63284305395001e-18,4.36662713526659e-17,-1.32415731622945e-17,0.0917760638890958,-5.1463921187737e-17,-3.06212083550592e-17,0.020354034217623,1.42110160178925e-17,8.78127934370195e-18,1.10296552176504e-17,6.04875461249026e-18,-1.12907950679241e-16,6.41934790659652e-17,0.063590653239!
>   63!
>>   94,-5.80721386923163e-17,2.60888831084575e-17,0.318234894813079,-2.644
>> 05232759225e-17,-3.83483045548365e-17,6.03901669028453e-17,-8.12491526717919e-17,-2.31961766473706e-17,2.49851938854807e-17,0.0666134385177111,0.277994494373684,0.757276941042661,-6.17404037289403e-18,7.89863674358793e-17,-7.67835382820615e-17,1.02140113616298e-17,1.52661784797379e-17,-9.56651701308766e-17,-3.02020715735595e-17,0.388119618133219,0.407682070148667,2.2374985383075e-18,1.11172424441548e-16,5.834694549909e-18,-6.98992457434969e-17,2.58373931894799e-17,1.77047896799026e-17,-1.32411436947046e-17,2.48508545648632e-17,0.00261698558797486,-4.74012929746027e-18,-6.88567774177344e-18,-1.42368729782461e-17,3.86907870454172e-18,-1.18115468072844e-16,5.8232650855203e-17,-6.19221175303288e-18,1.66357706932964e-17,6.39953697342706e-17,2.06819618922065e-17,1.12542559622211e-17,1.61613122517958e-17,-8.54903096963431e-18,-2.91678323773648e-17,-1.24859483206721e-16,7.55251863839618e-18,1,0,0,0,0,0,0,0,0,0,0,0
>>
>>
>> If anyone has an idea...
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matthias-gondan at gmx.de  Tue Mar 14 20:36:28 2017
From: matthias-gondan at gmx.de (matthias-gondan at gmx.de)
Date: Tue, 14 Mar 2017 20:36:28 +0100
Subject: [R] Quantiles with ordered categories
Message-ID: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>

Dear R users,

This works: 

quantile(1:10, probs=0.5)

This fails (obviously):

quantile(factor(1:10), probs=0.5)

But why do quantiles for ordered factors not work either?

quantile(ordered(1:10), probs=0.5)

Is it because interpolation (see the optional type argument) is not defined? Is there an elegant workaround?

Thank you.

Best wishes,

Matthias

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar 14 21:34:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Mar 2017 13:34:19 -0700
Subject: [R] Quantiles with ordered categories
In-Reply-To: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>
References: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>
Message-ID: <CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>

Inline.
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 14, 2017 at 12:36 PM,  <matthias-gondan at gmx.de> wrote:
> Dear R users,
>
> This works:
>
> quantile(1:10, probs=0.5)
>
> This fails (obviously):
>
> quantile(factor(1:10), probs=0.5)
>
> But why do quantiles for ordered factors not work either?
>
> quantile(ordered(1:10), probs=0.5)
>
> Is it because interpolation (see the optional type argument) is not defined?
Yes.


Is there an elegant workaround?
No. How can there be? By definition, all that is assumed by an ordered
factor is an ordering of the categories. How can you "interpolate" in
ordered(letters[1:3]) . ASAIK there is no "a.5"  .

-- Bert



>
> Thank you.
>
> Best wishes,
>
> Matthias
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matthias-gondan at gmx.de  Tue Mar 14 21:54:42 2017
From: matthias-gondan at gmx.de (matthias-gondan at gmx.de)
Date: Tue, 14 Mar 2017 21:54:42 +0100
Subject: [R] Quantiles with ordered categories
In-Reply-To: <CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>
References: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>
	<CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>
Message-ID: <0MMkgl-1cs04801bb-008Y8E@mail.gmx.com>

I found it:

quantile(ordered(1:10), probs=0.5, type=1) 

works, because type=1 seems to round up or down, whatever. The default option for is 7, which wants to interpolate, and then produces the error. 

Two options come to my mind:

- The error message could be improved.
- The default type could be 1 if the data is from ordered categories.
- Or both.

It is probably a little thing to fix, but I lack the skills to do this myself.

Best wishes,

Matthias

Von: Bert Gunter
Gesendet: Dienstag, 14. M?rz 2017 21:34
An: matthias-gondan at gmx.de
Cc: r-help at r-project.org
Betreff: Re: [R] Quantiles with ordered categories

Inline.
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 14, 2017 at 12:36 PM,  <matthias-gondan at gmx.de> wrote:
> Dear R users,
>
> This works:
>
> quantile(1:10, probs=0.5)
>
> This fails (obviously):
>
> quantile(factor(1:10), probs=0.5)
>
> But why do quantiles for ordered factors not work either?
>
> quantile(ordered(1:10), probs=0.5)
>
> Is it because interpolation (see the optional type argument) is not defined?
Yes.


Is there an elegant workaround?
No. How can there be? By definition, all that is assumed by an ordered
factor is an ordering of the categories. How can you "interpolate" in
ordered(letters[1:3]) . ASAIK there is no "a.5"  .

-- Bert



>
> Thank you.
>
> Best wishes,
>
> Matthias
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Mar 14 22:00:15 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 14 Mar 2017 14:00:15 -0700
Subject: [R] Quantiles with ordered categories
In-Reply-To: <CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>
References: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>
	<CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>
Message-ID: <CAF8bMcbZudgS-g8WD_mn5xfbRdu7_C+OuYmTjavqvECf2vVrVA@mail.gmail.com>

You could round the quantiles of the codes of the ordered factor to
come up with a reasonable result.  E.g.,

quantile.ordered <- function(x, ...)
ordered(levels(x)[as.integer(quantile(as.integer(x), ...))],
levels=levels(x))

> unCut <- log2(2:30)
> Cut <- cut(unCut, breaks=0:6, ordered_result=TRUE)
> quantile(unCut)
      0%      25%      50%      75%     100%
1.000000 3.169925 4.000000 4.523562 4.906891
> quantile(Cut)
[1] (0,1] (3,4] (3,4] (4,5] (4,5]
Levels: (0,1] < (1,2] < (2,3] < (3,4] < (4,5] < (5,6]


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Mar 14, 2017 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Inline.
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Mar 14, 2017 at 12:36 PM,  <matthias-gondan at gmx.de> wrote:
>> Dear R users,
>>
>> This works:
>>
>> quantile(1:10, probs=0.5)
>>
>> This fails (obviously):
>>
>> quantile(factor(1:10), probs=0.5)
>>
>> But why do quantiles for ordered factors not work either?
>>
>> quantile(ordered(1:10), probs=0.5)
>>
>> Is it because interpolation (see the optional type argument) is not defined?
> Yes.
>
>
> Is there an elegant workaround?
> No. How can there be? By definition, all that is assumed by an ordered
> factor is an ordering of the categories. How can you "interpolate" in
> ordered(letters[1:3]) . ASAIK there is no "a.5"  .
>
> -- Bert
>
>
>
>>
>> Thank you.
>>
>> Best wishes,
>>
>> Matthias
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar 14 23:21:54 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Mar 2017 09:21:54 +1100
Subject: [R] GADM -- Download World Map for R
In-Reply-To: <20170314145758.GB1243@chicca2>
References: <20170314145758.GB1243@chicca2>
Message-ID: <CA+8X3fX4QUAwJNJmuFwWq6D+QJPyLUjYu4zZP2Maq0WPbtQfkg@mail.gmail.com>

Hi Lorenzo,
See:

http://www.gadm.org/version2

Jim


On Wed, Mar 15, 2017 at 1:57 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> Please have a look at the snippet here
>
> http://bit.ly/2mVS8me
>
> This short code addresses precisely one of my needs: to superimpose a
> network (created with the igraph library) to a geographical map.
> Unlike the case of the example, where a single country is enough, I
> need to have a world map in R to which superimpose the network.
> Seen that I am far from an expert about plotting maps in R (you may
> want to resort to a purely ggplot oriented solution for the map, but
> then you need to translate your network into something ggplot
> understands -- see http://bit.ly/2mVSOIk ).
> For me it would be way simpler to follow the footsteps of the work
> done in the previous link, but I cannot download from GADM a world
> map.
> Does anybody know how to achieve that?
> Regards
>
> Lorenzo
>
>
> #######################################################?
> library(raster)
> library(igraph)
> greece <- getData('GADM', country='GRC', level=1)
> df<-data.frame("from" = c("Athens", "Iraklio", "Thessaloniki",
> "Patra"), "to"= c("Thessaloniki", "Thessaloniki", "Athens",
> "Iraklio"))
> meta <- data.frame("name"=c("Athens", "Iraklio", "Thessaloniki",
> "Patra"),
>               "lon"=c(23.72800,25.13356,22.94090,21.73507),
>                               "lat"=c(37.98415,35.33349,40.63229,38.24628))
>                               g <- graph.data.frame(df, directed=T,
>                               vertices=meta)
>                               lo <- as.matrix(meta[,2:3])
>                               plot(greece)
>                               plot(g, layout=lo, add = TRUE, rescale =
> FALSE)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 15 02:58:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Mar 2017 18:58:40 -0700
Subject: [R] extend lines of prediction interval ggplot2
In-Reply-To: <150344070.5264877.1489491591594@mail.yahoo.com>
References: <150344070.5264877.1489491591594.ref@mail.yahoo.com>
	<150344070.5264877.1489491591594@mail.yahoo.com>
Message-ID: <93DF9493-4124-4E1B-B8E7-D46DA84C4C90@dcn.davis.ca.us>

Define your new_df before you calculate temp_var, and give it to predict so predict doesn't start from your original x values. Add temp_var to new_df.

Read ?predict.lm.

Don't create matrices with cbind before creating data frames... data frames can have a variety of data storage modes (types) for the columns, matrices cannot. 

fit <-lm(y~x) 
new_df <- data.frame(x,y) 
new_df$temp_var <- predict(fit, newdata=new_df, interval="prediction") 

-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2017 4:39:51 AM PDT, Andras Farkas via R-help <r-help at r-project.org> wrote:
>Dear All, 
>
>would you have some thoughts on how to extend the prediction interval
>lines to beyond the "range of data"? 
>
>
>example: 
>
>y <-c(0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143, 
>0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978,0.383012, 
>0.3763665,0.3550609,0.2958678,0.3726571,0.3442298 
>#,0.3403275,0.2973978 
>)*100 
>x <-seq(1,length(y),1) 
>
>z<-c("07/01/2015","08/01/2015","09/01/2015","10/01/2015","11/01/2015", 
>"12/01/2015","01/01/2016","02/01/2016","03/01/2016","04/01/2016","05/01/2016",
>
>"06/01/2016","07/01/2016","08/01/2016","09/01/2016","10/01/2016","11/01/2016",
>
>"12/01/2016","01/01/2017","02/01/2017") 
>
>fit <-lm(y~x) 
>
>temp_var <- predict(fit, interval="prediction") 
>
>new_df <- data.frame(cbind(x,y, temp_var)) 
>#new_df$x<-factor(new_df$x, ordered = T) 
>
>library(ggplot2) 
>ggplot(new_df, aes(x,y))+ 
>geom_point() + 
>theme(panel.background = element_rect(fill = 'white', colour =
>'black'))+ 
>geom_line(aes(y=lwr), color = "black", linetype = "dashed",size=0.75)+ 
>geom_line(aes(y=upr), color = "black", linetype = "dashed",size=0.75)+ 
>scale_x_discrete(limits=z)+ 
>theme(axis.text.x = element_text(angle = 45, hjust = 1))+ 
>theme(panel.grid.major=element_line(colour = "grey"))+ 
>lims(y=c(0,50))+ 
>geom_smooth(method=lm,
>se=TRUE,fullrange=TRUE,fill="darkgrey",col="black")+labs(title =
>paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 4), 
>"Intercept =",signif(fit$coef[[1]],4 ), 
>" Slope =",signif(fit$coef[[2]], 4) 
># " P =",signif(summary(fit)$coef[2,4], 3) 
>))+ 
>ggtitle("Consumption Over Time") + 
>theme(plot.title = element_text(hjust = 0.5))+ 
>labs(y="y",x="x")+ 
>geom_point(shape=15,aes(x=c(7),y=new_df[,2][7]), color="black",cex=4)+ 
>geom_point(shape=15,aes(x=c(8),y=new_df[,2][8]), color="black",cex=4)+ 
>geom_point(shape=17,aes(x=c(19),y=0.3403275*100), color="black",cex=4)+
>
>geom_point(shape=17,aes(x=c(20),y=0.2973978*100), color="black",cex=4) 
>
>
>as you  will see the regresssion line and confidence interval is
>extended, but would also want to extend the prediction interval lines
>to the "same length"... Wonder if you have any insights to this
>question... 
>
>
>appreciate the help, 
>
>
>Andras Farkas
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 15 03:27:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Mar 2017 19:27:44 -0700
Subject: [R] Permission to use R Installation Screenshots and Datasets
In-Reply-To: <CACdx11Wg7Uosk587nxeBspLT=0NJ1o9V2JdBTKNs-4E5eo25qw@mail.gmail.com>
References: <CACdx11Wg7Uosk587nxeBspLT=0NJ1o9V2JdBTKNs-4E5eo25qw@mail.gmail.com>
Message-ID: <BF674DED-CFF4-43E7-81FD-1DCE78F0F4C3@dcn.davis.ca.us>

I am not sure there exists any one person who can grant you permission to use screen shots, but someone with more clue than I have may be able to clear this up with you. Regarding packages, copyright rests with the package authors, so use the maintainer() function to find out who you need to ask for that permission regarding each package you plan to refer to. Note that you should read the license associated with each element of the software that you will "quote" (including screen shots), and those licenses are indicated in the help files. You may find your answers there with no further emails at all, but you might need legal assistance to interpret the language. 

Do note that you really need to learn how to use the mailing list if you want recipients here to get your message. Read the Posting Guide, which warns you to send your email as plain text (not HTML formatted), and attachments are restricted to a very limited set of formats. Given the emails that you sent, if someone COULD grant you permission to show images, they did not receive any images to review so they currently don't know what you are talking about. 
-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2017 9:03:26 AM PDT, Srinivasa K G <kgsrinivasa at gmail.com> wrote:
>Dear Sir/Madam,
>
>We are in the process of developing a textbook on R and are writing to
>request your permission to include certain screenshots relating to
>installation of the package in our book to be published tentatively in
>May
>2017. The description of our book is as follows*:*
>
>
>
>*Title*: Statistical Programming in R
>
>*Approx. no. of pages*: 400
>
>*Approx. price*: ?395.00
>
>*Publisher*: Oxford University Press
>
>*Territory rights*: Worldwide
>
>
>
>We would be grateful if we might have your gratis permission to use the
>screenshots (see attachment) in the above-mentioned title, supporting
>supplements and any derivatives, which are to be published worldwide by
>Oxford University Press. This permission would be required to cover all
>media (print and electronic), any future revisions or editions of the
>book
>and supplements and any translations of it published by Oxford
>University
>Press or its licensees (world rights). Subject to your permissions, we
>would ensure to provide due acknowledgements as appropriate.
>
>
>We would also like to use the data sets (that are part and parcel of a
>typical R package) to demonstrate problems and solutions in the book.
>
>
>We are looking forward to your response at the earliest.
>
>
>-- 
>Dr. Srinivasa K G
>Associate Professor
>Department of Information Technology
>Ch Brahm Prakash Government Engineering College
>Jaffarpur, New Delhi - 110073
>Mobile: 9731696526 / 9620262690
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Wed Mar 15 06:21:23 2017
From: tmrsg11 at gmail.com (C W)
Date: Wed, 15 Mar 2017 01:21:23 -0400
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
Message-ID: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>

Dear list,

I am trying to use saveGIF() from library animation.
https://cran.r-project.org/web/packages/animation/animation.pdf

saveGIF() has dependency on package ImageMagick.

I got the following,
> install.packages("ImageMagick")
Warning in install.packages :
  package ?ImageMagick? is not available (for R version 3.3.2)

Does that mean I can't use saveGIF() anymore? It seems that this is the
only package capable in R.

Thank you in advance!

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Wed Mar 15 06:32:07 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 Mar 2017 22:32:07 -0700
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
Message-ID: <c7f1c489-f94e-efd9-a774-28a7e22caa58@fredhutch.org>

Hi,

ImageMagick is an external software that you need to install on your
system. It's not an *R* package so trying to install it with
install.packages() won't work.

Note the difference between things listed in the SystemRequirements
field (the animation package has many of these system requirements)
vs things listed in the Depends or Imports field. The former are
external softwares (typically standalone programs or system libraries).
The latter are R packages that can be found with available.packages()
and installed with install.packages().

H.


On 03/14/2017 10:21 PM, C W wrote:
> Dear list,
>
> I am trying to use saveGIF() from library animation.
> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_animation_animation.pdf&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=sLEnaUtX6fn9Y_qSSEHFl-W9OaFf4_3oSFFTpbvjAd4&s=4BYi2BW4av2AKvz57RFr0v7j-zxc2Z7AzHvutypbh_s&e=
>
> saveGIF() has dependency on package ImageMagick.
>
> I got the following,
>> install.packages("ImageMagick")
> Warning in install.packages :
>   package ?ImageMagick? is not available (for R version 3.3.2)
>
> Does that mean I can't use saveGIF() anymore? It seems that this is the
> only package capable in R.
>
> Thank you in advance!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=sLEnaUtX6fn9Y_qSSEHFl-W9OaFf4_3oSFFTpbvjAd4&s=_h7qcvAynH-5nBWCTLad-rzILkVVQe8Ymt5a0-DOGXY&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIGaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=sLEnaUtX6fn9Y_qSSEHFl-W9OaFf4_3oSFFTpbvjAd4&s=PliR-mnRNhRqRnpIX6OFVtcpBlOR2rBkBKtemPQ-NMw&e=
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bgunter.4567 at gmail.com  Wed Mar 15 06:32:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Mar 2017 22:32:25 -0700
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
Message-ID: <CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>

A google search on "ImageMagick Package R" brought this up, which
seems relevant:

https://cran.r-project.org/web/packages/magick/vignettes/intro.html

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 14, 2017 at 10:21 PM, C W <tmrsg11 at gmail.com> wrote:
> Dear list,
>
> I am trying to use saveGIF() from library animation.
> https://cran.r-project.org/web/packages/animation/animation.pdf
>
> saveGIF() has dependency on package ImageMagick.
>
> I got the following,
>> install.packages("ImageMagick")
> Warning in install.packages :
>   package ?ImageMagick? is not available (for R version 3.3.2)
>
> Does that mean I can't use saveGIF() anymore? It seems that this is the
> only package capable in R.
>
> Thank you in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c.puschmann at student.unsw.edu.au  Tue Mar 14 22:19:59 2017
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Tue, 14 Mar 2017 21:19:59 +0000
Subject: [R] Percent transformation
Message-ID: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>

Hello all,

I am having a problem of transforming decimals into percentage. Specifically, I get the following error message:

"Error in UseMethod("round_any") :
  no applicable method for 'round_any' applied to an object of class ?data.frame"

My code looks the following:

x <- sp[1:5,2:6]
x = percent(x)

My Data:

SD      D       N       A       SA






1

0.005769231

-0.14230769

0.071153846

0.09615385

-0.030769231

2

-0.057692308

-0.08461538

0.038461538

0.01923077

0.084615385

3

-0.076923077

-0.10384615

0.221153846

-0.04423077

0.003846154

4

-0.167307692

-0.13653846

-0.003846154

0.16153846

0.146153846

5

0.000000000

-0.01923077

0.011538462

0.21923077

-0.2115384

All help would be appreciated. Thank you.

Christoph




	[[alternative HTML version deleted]]


From p.northrop at ucl.ac.uk  Tue Mar 14 16:25:34 2017
From: p.northrop at ucl.ac.uk (Northrop, Paul)
Date: Tue, 14 Mar 2017 15:25:34 +0000
Subject: [R] [R-pkgs] New package: revdbayes
In-Reply-To: <HE1PR01MB14512E397444005C01E7A17FC0240@HE1PR01MB1451.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB14512E397444005C01E7A17FC0240@HE1PR01MB1451.eurprd01.prod.exchangelabs.com>
Message-ID: <HE1PR01MB1451A4219FB5DD33AAEB7B74C0240@HE1PR01MB1451.eurprd01.prod.exchangelabs.com>

Dear R users,


I am pleased to announce the release on CRAN of revdbayes 1.1.0 : Ratio-of-Uniforms Sampling for Bayesian Extreme Value Analysis (https://cran.r-project.org/package=revdbayes<https://cran.r-project.org/package=revdbayes>).


revdbayes performs random posterior sampling in univariate extreme value analyses.  It also produces posterior predictive checks, using the bayesplot package (https://cran.r-project.org/package=bayesplot), and posterior predictive inference for extreme quantities.


Please see the vignettes at https://cran.r-project.org/web/packages/revdbayes/vignettes/revdbayes-vignette.html and https://cran.r-project.org/web/packages/revdbayes/vignettes/revdbayes-predictive-vignette.html for details.


Any comments, suggestions or queries are gratefully received.


Best wishes


Paul


Dr Paul Northrop
Department of Statistical Science
University College London
Gower Street
London
WC1E 6BT
Tel: 020 7679 1869
Internal: 41869
E-mail: p.northrop at ucl.ac.uk
http://www.homepages.ucl.ac.uk/~ucakpjn/

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From willebert34 at gmail.com  Tue Mar 14 18:46:59 2017
From: willebert34 at gmail.com (Will Ebert)
Date: Tue, 14 Mar 2017 12:46:59 -0500
Subject: [R] Document Term Matrix will not maintain decimal places of
 numbers or capture all terms
Message-ID: <CANj2rB-2b5z-96jH_zoFWPr_GU7FirB4_29a-9ZpYzUPMhZBCg@mail.gmail.com>

Before I updated my version of RStudio (1.0.136), everything worked great.
With the update something has changed with Document Term Matrix in the 'tm'
package. I want to create a dtm, but with numbers. For instance if I have a
.csv with one column as shown below:

x1.0111.21123.35212.11

I want the column names in my term matrix to look like this:

1.01 11.21 123.35 212.111    0     0      00    1     0      00    0
  1      00    0     0      1

But instead it looks like this:

123 2120   00   01   00   1

Here's the code that used to work:

corpus = Corpus(VectorSource(x))
dtm = DocumentTermMatrix(corpus)
dtm_df = as.data.frame(as.matrix(dtm))

I have tried uninstalling everything and reinstalling, tried older versions
(Studio 0.99.489 & R 3.3.1), but I get the same results. I ask others to
test it out and it works for them. Also, I had someone download R, Rtools,
and RStudio to test this and they got the same results I did. I have no
idea what has happened and would greatly appreciate help on this matter as
it is extremely urgent.

Thanks in advance

Will

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Wed Mar 15 07:27:21 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 15 Mar 2017 07:27:21 +0100
Subject: [R] Percent transformation
In-Reply-To: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
References: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
Message-ID: <A34DF1B4-EBF7-45B2-8F85-10291DD0CAB9@xs4all.nl>


> On 14 Mar 2017, at 22:19, Christoph Puschmann <c.puschmann at student.unsw.edu.au> wrote:
> 
> Hello all,
> 
> I am having a problem of transforming decimals into percentage. Specifically, I get the following error message:
> 
> "Error in UseMethod("round_any") :
>  no applicable method for 'round_any' applied to an object of class ?data.frame"
> 

Did you read the Posting Guide.
DO NOT post in html.

Your data are mangled.

Your code is incomprehensible.
Reproducible example please.

Where does percent come from?

Berend Hasselman

> My code looks the following:
> 
> x <- sp[1:5,2:6]
> x = percent(x)
> 
> My Data:
> 
> SD      D       N       A       SA
> 
> 
> 
> 
> 
> 
> 1
> 
> 0.005769231
> 
> -0.14230769
> 
> 0.071153846
> 
> 0.09615385
> 
> -0.030769231
> 
> 2
> 
> -0.057692308
> 
> -0.08461538
> 
> 0.038461538
> 
> 0.01923077
> 
> 0.084615385
> 
> 3
> 
> -0.076923077
> 
> -0.10384615
> 
> 0.221153846
> 
> -0.04423077
> 
> 0.003846154
> 
> 4
> 
> -0.167307692
> 
> -0.13653846
> 
> -0.003846154
> 
> 0.16153846
> 
> 0.146153846
> 
> 5
> 
> 0.000000000
> 
> -0.01923077
> 
> 0.011538462
> 
> 0.21923077
> 
> -0.2115384
> 
> All help would be appreciated. Thank you.
> 
> Christoph
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Mar 15 07:27:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Mar 2017 23:27:56 -0700
Subject: [R] Percent transformation
In-Reply-To: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
References: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
Message-ID: <CAGxFJbRRg9-8xRDK0twih43ZBGfpEa6DmADX0riafavg6kFW4g@mail.gmail.com>

This looks like homework. If so, we don't do homework here. If not,
please read and follow the posting guide. In particular, plain text
email only.  The error message you received seems self explanatory.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 14, 2017 at 2:19 PM, Christoph Puschmann
<c.puschmann at student.unsw.edu.au> wrote:
> Hello all,
>
> I am having a problem of transforming decimals into percentage. Specifically, I get the following error message:
>
> "Error in UseMethod("round_any") :
>   no applicable method for 'round_any' applied to an object of class ?data.frame"
>
> My code looks the following:
>
> x <- sp[1:5,2:6]
> x = percent(x)
>
> My Data:
>
> SD      D       N       A       SA
>
>
>
>
>
>
> 1
>
> 0.005769231
>
> -0.14230769
>
> 0.071153846
>
> 0.09615385
>
> -0.030769231
>
> 2
>
> -0.057692308
>
> -0.08461538
>
> 0.038461538
>
> 0.01923077
>
> 0.084615385
>
> 3
>
> -0.076923077
>
> -0.10384615
>
> 0.221153846
>
> -0.04423077
>
> 0.003846154
>
> 4
>
> -0.167307692
>
> -0.13653846
>
> -0.003846154
>
> 0.16153846
>
> 0.146153846
>
> 5
>
> 0.000000000
>
> -0.01923077
>
> 0.011538462
>
> 0.21923077
>
> -0.2115384
>
> All help would be appreciated. Thank you.
>
> Christoph
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 15 07:32:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Mar 2017 23:32:21 -0700
Subject: [R] Percent transformation
In-Reply-To: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
References: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
Message-ID: <2ACC724D-CA6F-4582-B0D3-BD2785AF38CF@dcn.davis.ca.us>

Your x variable is a data frame. The scales::percent() function does not work on data frames. It might work on the individual columns in the data frame. You probably ought to re-read your preferred introduction to R material on the difference between data frames and the columns in data frames. 

Try

scales::percent( sp[[ 1 ]] )

Do beware that that function converts your numbers into character strings, unlike Excel. It is often more practical to simply multiply by 100 and forego the percent sign. 
-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2017 2:19:59 PM PDT, Christoph Puschmann <c.puschmann at student.unsw.edu.au> wrote:
>Hello all,
>
>I am having a problem of transforming decimals into percentage.
>Specifically, I get the following error message:
>
>"Error in UseMethod("round_any") :
>no applicable method for 'round_any' applied to an object of class
>?data.frame"
>
>My code looks the following:
>
>x <- sp[1:5,2:6]
>x = percent(x)
>
>My Data:
>
>SD      D       N       A       SA
>
>
>
>
>
>
>1
>
>0.005769231
>
>-0.14230769
>
>0.071153846
>
>0.09615385
>
>-0.030769231
>
>2
>
>-0.057692308
>
>-0.08461538
>
>0.038461538
>
>0.01923077
>
>0.084615385
>
>3
>
>-0.076923077
>
>-0.10384615
>
>0.221153846
>
>-0.04423077
>
>0.003846154
>
>4
>
>-0.167307692
>
>-0.13653846
>
>-0.003846154
>
>0.16153846
>
>0.146153846
>
>5
>
>0.000000000
>
>-0.01923077
>
>0.011538462
>
>0.21923077
>
>-0.2115384
>
>All help would be appreciated. Thank you.
>
>Christoph
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Ronald.Taylor at pnnl.gov  Tue Mar 14 22:53:39 2017
From: Ronald.Taylor at pnnl.gov (Taylor, Ronald C)
Date: Tue, 14 Mar 2017 21:53:39 +0000
Subject: [R] problem with sparkl_connect() in the sparklyr package for
 parallelizing R in the Spark environment - "Gateway in port (8880) did not
 respond"
Message-ID: <9630E5FD91504140A3479FBFBE1837B51BD47D3D@EX10MBOX03.pnnl.gov>

Hi folks,

I posted the message below as a new issue on the sparklyr web page at github over a week ago, but have not gotten any reply back. So  I am posting here, in the hope  somebody on this list can provide guidance. I really want to get R working in Spark on our local Linux cluster. Eager to get going, if I can get out of the gate. But have to get past this spark_connect() problem. Please see the below.

   - Ron Taylor


%%%%%%%%%%%%%

problem with spark_connect() using sparklyr on a Cloudera CDH 5.10.0 Hadoop cluster #534

 rtaylor24<https://github.com/rtaylor24> commented 8 days ago<https://github.com/rstudio/sparklyr/issues/534>
Hello folks,
I am trying to use sparklyr for the first time on a Hadoop cluster. I have used R with sparklyr on a "local" copy of Spark on my Mac laptop, but this is the first time that I am trying to run it as a "yarn-client" on a true cluster, to actually get some parallelization out of sparklyr use.
We have a small Linux cluster at our lab running Cloudera CDH 5.10.0. When I try to do the spark_connect() from an R session started on a command line on the Hadoop cluster's name (master) node, I get the same msg as in an earlier CLOSED issue. That is, my error msg is:
"Failed while connecting to sparklyr to port (8880) for sessionid (2423): Gateway in port (8880) did not respond."
I am thus reopening that issue here, since I still need help even after reading that older issue (#394<https://github.com/rstudio/sparklyr/issues/394>).
At bottom is the record of my R session on the Hadoop cluster's name node, with all the details that I can think of printed out to the screen.
I note that the version of Spark used by CDH is 1.6.0, which is different than what is in spark_home_dir (1.6.2). I cannot seem to change the spark_home_dir by setting SPARK_HOME to the Spark location used by the CDH distribution. spark_home_dir does not get altered by my setting of SPARK_HOME (as you can see below). So one question (perhaps the critical question?) is: how do I force sparklyr to connect to the Spark version being used by the CDH distribution?
As you can see at the Cloudera web page at
https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball_510.html
the 5.10.0 distribution has Spark 1.6.0, not 1.6.2. So I am trying to tell sparklyr code to use the Spark 1.6.0 distribution that is located here:
/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-submit
/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-shell
/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/lib/spark
and so I was trying to set SPARK_HOME as follows:
Sys.setenv(SPARK_HOME = "/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41")
Sys.getenv("SPARK_HOME")
[1] "/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41"
However! I note that part of the error msg (see bottom) says that the correct path was used to spark-submit:
"Path: /opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-submit"
So maybe sparklyr is indeed accessing the Spark 1.6.0 distribution as it should in the cluster, and the problem lies elsewhere??
One other note: there was an earlier version of sparklyr installed by support here on the Hadoop name node. I have bypassed that, installed the latest version of sparklyr (0.5.1) into
/people/rtaylor/Rpackages
as you can see below.
Would very much appreciate some guidance to get me over this initial hurdle.
*       Ron Taylor
      Pacific Northwest National Laboratory
      email: ronald.taylor at pnnl.gov<mailto:ronald.taylor at pnnl.gov>
%%%%%%%%%%%%%%
screen output from my failed run:
[rtaylor at bigdatann Rwork]$ R
R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
ls()
character(0)
(.packages())
[1] "stats" "graphics" "grDevices" "utils" "datasets" "methods"
[7] "base"
install.packages("sparklyr", lib="/people/rtaylor/Rpackages/")
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://cran.cnr.berkeley.edu/src/contrib/sparklyr_0.5.2.tar.gz'
Content type 'application/x-gzip' length 732806 bytes (715 KB)
==================================================
downloaded 715 KB
*       installing source package 'sparklyr' ...
      ** package 'sparklyr' successfully unpacked and MD5 sums checked
      ** R
      ** inst
      ** preparing package for lazy loading
      ** help
      *** installing help indices
      ** building package indices
      ** testing if installed package can be loaded
*       DONE (sparklyr)
The downloaded source packages are in
'/tmp/RtmpQUB4IE/downloaded_packages'
library(sparklyr, lib.loc="/people/rtaylor/Rpackages/")
(.packages())
[1] "sparklyr" "stats" "graphics" "grDevices" "utils" "datasets"
[7] "methods" "base"
sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux Workstation release 6.4 (Santiago)
locale:
[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8 LC_NAME=C
[9] LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
attached base packages:
[1] stats graphics grDevices utils datasets methods base
other attached packages:
[1] sparklyr_0.5.1
loaded via a namespace (and not attached):
[1] Rcpp_0.12.9 withr_1.0.2 digest_0.6.12 dplyr_0.5.0
[5] rprojroot_1.2 assertthat_0.1 rappdirs_0.3.1 R6_2.2.0
[9] jsonlite_1.2 DBI_0.5-1 backports_1.0.5 magrittr_1.5
[13] httr_1.2.1 config_0.2 tools_3.3.2 parallel_3.3.2
[17] yaml_2.1.14 base64enc_0.1-3 tcltk_3.3.2 tibble_1.2
Sys.getenv("JAVA_HOME")
[1] "/usr/java/latest"
spark_installed_versions()
spark hadoop dir
1 1.6.2 2.6 spark-1.6.2-bin-hadoop2.6
spark_home_dir()
[1] "/people/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6"
R.home(component = "home")
[1] "/share/apps/R/3.3.2/lib64/R"
path.expand("~")
[1] "/people/rtaylor"
Sys.setenv(SPARK_HOME = "/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41")
Sys.getenv("SPARK_HOME")
[1] "/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41"
spark_home_dir()
[1] "/people/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6"
ls()
character(0)
config <- spark_config()
ls()
[1] "config"
sc <- spark_connect(master = "yarn-client", config = config, version = "1.6.0")
Error in force(code) :
Failed while connecting to sparklyr to port (8880) for sessionid (2423): Gateway in port (8880) did not respond.
Path: /opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-submit
Parameters: --class, sparklyr.Backend, --jars, '/share/apps/R/3.3.2/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/share/apps/R/3.3.2/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/share/apps/R/3.3.2/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/share/apps/R/3.3.2/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 2423
---- Output Log ----
/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/../lib/spark/bin/spark-submit: line 27: /opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-class: No such file or directory
/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/../lib/spark/bin/spark-submit: line 27: exec: /opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/bin/spark-class: cannot execute: No such file or directory
---- Error Log ----
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Wed Mar 15 08:55:04 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 15 Mar 2017 08:55:04 +0100
Subject: [R] GADM -- Download World Map for R
In-Reply-To: <CA+8X3fX4QUAwJNJmuFwWq6D+QJPyLUjYu4zZP2Maq0WPbtQfkg@mail.gmail.com>
References: <20170314145758.GB1243@chicca2>
	<CA+8X3fX4QUAwJNJmuFwWq6D+QJPyLUjYu4zZP2Maq0WPbtQfkg@mail.gmail.com>
Message-ID: <20170315075504.GB1676@chicca>

Thanks, I had also seen that, but I was hoping to avoid dealing with
the shapefiles and to download the world map as a spatial polygon data
frame.
Cheers

Lorenzo

On Wed, Mar 15, 2017 at 09:21:54AM +1100, Jim Lemon wrote:
>Hi Lorenzo,
>See:
>
>http://www.gadm.org/version2
>
>Jim
>
>
>On Wed, Mar 15, 2017 at 1:57 AM, Lorenzo Isella
><lorenzo.isella at gmail.com> wrote:
>> Dear All,
>> Please have a look at the snippet here
>>
>> http://bit.ly/2mVS8me
>>
>> This short code addresses precisely one of my needs: to superimpose a
>> network (created with the igraph library) to a geographical map.
>> Unlike the case of the example, where a single country is enough, I
>> need to have a world map in R to which superimpose the network.
>> Seen that I am far from an expert about plotting maps in R (you may
>> want to resort to a purely ggplot oriented solution for the map, but
>> then you need to translate your network into something ggplot
>> understands -- see http://bit.ly/2mVSOIk ).
>> For me it would be way simpler to follow the footsteps of the work
>> done in the previous link, but I cannot download from GADM a world
>> map.
>> Does anybody know how to achieve that?
>> Regards
>>
>> Lorenzo
>>
>>
>> #######################################################?
>> library(raster)
>> library(igraph)
>> greece <- getData('GADM', country='GRC', level=1)
>> df<-data.frame("from" = c("Athens", "Iraklio", "Thessaloniki",
>> "Patra"), "to"= c("Thessaloniki", "Thessaloniki", "Athens",
>> "Iraklio"))
>> meta <- data.frame("name"=c("Athens", "Iraklio", "Thessaloniki",
>> "Patra"),
>>               "lon"=c(23.72800,25.13356,22.94090,21.73507),
>>                               "lat"=c(37.98415,35.33349,40.63229,38.24628))
>>                               g <- graph.data.frame(df, directed=T,
>>                               vertices=meta)
>>                               lo <- as.matrix(meta[,2:3])
>>                               plot(greece)
>>                               plot(g, layout=lo, add = TRUE, rescale =
>> FALSE)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From highstat at highstat.com  Wed Mar 15 10:14:35 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 15 Mar 2017 11:14:35 +0200
Subject: [R] Crete stats course
Message-ID: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>

There are a few remaining seats on the following course:



Course: Data exploration, regression, GLM & GAM with R

Where:  HCMR, Crete, Greece

When:   24-28 April 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

Introduction to Regression Models with Spatial and Temporal Correlation. 
8-12 May 2017. Genoa, Italy.
Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian 
approaches. 9-13 October 2017. Trondheim, Norway.
Introduction to Regression Models with Spatial and Temporal Correlation. 
23-27 October 2017. Southampton, UK
Data exploration, regression, GLM & GAM with introduction to R. 18-22 
September 2017. Edmonton, Canada.
Introduction to Regression Models with Spatial and Temporal Correlation. 
4-8 December 2017. Banff, Canada.







-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From marongiu.luigi at gmail.com  Wed Mar 15 10:22:30 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 15 Mar 2017 09:22:30 +0000
Subject: [R] add median value and standard deviation bar to lattice plot
Message-ID: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>

Dear all,
I am analyzing some multivariate data that is organized like this:
1st variable = cluster (A or B)
2nd variable = target (a, b, c, d, e)
3rd variable = type (blank, negative, positive)
4th variable = sample (the actual name of the sample)
5th variable = average (the actual reading -- please not that this is the
mean of different measures with an assumed normal distribution, but the
assumption might not always be true)
6th variable = stdev (the standard deviation associated with each reading)
7th variable = ll (lower limit that is average stdev)
8th variable = ul (upper limit that is average + stdev)

I am plotting the data using lattice's stripplot and I would need to add:
1. an error bar for each measurement. the bar should be possibly coloured
in light grey and semitransparent to reduce the noise of the plot.
2. a type-based median bar to show differences in measurements between
blanks, negative and positive samples within each panel.

How would I do that?
Many thanks,
Luigi

>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5,
54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69,
6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71,
87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
-27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)
useOuterStrips(
  strip = strip.custom(par.strip.text = list(cex = 0.75)),
  strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
  stripplot(
    average ~ type|target+cluster,
    my.data,
    groups = type,
    pch=1,
    jitter.data = TRUE,
    main = "Group-wise",
    xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
    col = c("grey", "green", "red"),
    par.settings = list(strip.background = list(col=c("paleturquoise",
"grey"))),
    scales = list(alternating = FALSE, x=list(draw=FALSE)),
    key = list(
      space = "top",
      columns = 3,
      text = list(c("Blank", "Negative", "Positive"), col="black"),
      rectangles = list(col=c("grey", "green", "red"))
    )
  )
)

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Mar 15 13:57:31 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 15 Mar 2017 07:57:31 -0500
Subject: [R] Getting the date out of R forecast funcion along with the
 forecasts as a data frame
Message-ID: <CAMOcQfNDSnoUcB4R5g+1ycn2hqWrPeGugWk0cbEQXefAnQoHoQ@mail.gmail.com>

Dear all,

I am currently generating forcasts using several different functions in
Azure Machine Learning Studio using the R script module (nnetar,
auto.arima, HoltWinters, ets, etc.).

However, I want to find a way to get the dates of the forecasts and put
those dates (along with the forecasts) in a data.frame format.

Whenever I transform the forecast function results into a data frame, the
date of the forecasts is lost, or seems like you cannot get the date of the
forecasts and make them part of the data frame containing the forecast
results.

I would like to manipulate the results in such a way that I can get the
following format:

Date              Forecast
Jan-2017       ######
Feb-2017       ######

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From xie at yihui.name  Wed Mar 15 13:58:11 2017
From: xie at yihui.name (Yihui Xie)
Date: Wed, 15 Mar 2017 07:58:11 -0500
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
	<CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>
Message-ID: <CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>

I'm the author of the animation package, and I do plan to switch to
the magick package in the future instead of using ImageMagick as a
system dependency.

Regards,
Yihui
--
https://yihui.name


On Wed, Mar 15, 2017 at 12:32 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> A google search on "ImageMagick Package R" brought this up, which
> seems relevant:
>
> https://cran.r-project.org/web/packages/magick/vignettes/intro.html
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Mar 14, 2017 at 10:21 PM, C W <tmrsg11 at gmail.com> wrote:
>> Dear list,
>>
>> I am trying to use saveGIF() from library animation.
>> https://cran.r-project.org/web/packages/animation/animation.pdf
>>
>> saveGIF() has dependency on package ImageMagick.
>>
>> I got the following,
>>> install.packages("ImageMagick")
>> Warning in install.packages :
>>   package ?ImageMagick? is not available (for R version 3.3.2)
>>
>> Does that mean I can't use saveGIF() anymore? It seems that this is the
>> only package capable in R.
>>
>> Thank you in advance!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Wed Mar 15 14:49:07 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 15 Mar 2017 21:49:07 +0800
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZLN4EUnLtiW8MjJhyTDrgyaJFeU6+bEhcHUYV9hsBf0NQ@mail.gmail.com>
References: <ef1h337w0ry677ursnkyk5kf.1489384064772@email.android.com>
	<CANTvJZLN4EUnLtiW8MjJhyTDrgyaJFeU6+bEhcHUYV9hsBf0NQ@mail.gmail.com>
Message-ID: <CANTvJZ+ef-dRdsVUQHfTmMLsPb+JcVqHWPSWDvFJQ_O_qXFGdA@mail.gmail.com>

Hi Caitlin,

I tried so many ways as suggested but unsuccessful...and I realise that I
need to filter the student ID and their CGPA, but if I change the ID into
character I lost the CGPA value.  It is easy to do in excel, however a bit
time consuming and trying to do in R.

I have these data:

dput(dt_all2)
structure(list(FAC_CODE = structure(c(2L, 2L, 2L, 4L, 1L, 1L,
4L, 7L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 1L, 2L, 5L, 6L), .Label = c("FKASA",
"FKEE", "FKKSA", "FKM", "FKP", "FSKKP", "FTK"), class = "factor"),
    STUDENT_ID = structure(c(9L, 6L, 7L, 17L, 2L, 3L, 18L, 19L,
    13L, 12L, 14L, 15L, 16L, 10L, 8L, 1L, 5L, 11L, 4L), .Label =
c("AA14068",
    "AB15103", "AB15124", "CC14107", "EA13043", "EB14059", "EB14073",
    "EB14101", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
    "KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
    ), class = "factor"), PROGRAM = structure(c(2L, 1L, 1L, 2L,
    1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L
    ), .Label = c("DIPLOMA", "IJAZAH SARJANA MUDA"), class = "factor"),
    CGPA = c(2.42, 3.27, 1.98, 2.85, 2.24, 3.01, 3.31, 2.88,
    3.61, 3.69, 3.2, 3.85, 3.63, 2.67, 2.35, 2.74, 1.96, 2.89,
    2.59)), .Names = c("FAC_CODE", "STUDENT_ID", "PROGRAM", "CGPA"
), class = "data.frame", row.names = c(NA, -19L))

and I want to filter my data as follows:

> dput(dt_all3)
structure(list(FAC_CODE = structure(c(2L, 2L, 4L, 4L, 5L, 1L,
6L, 3L, 3L, 3L, 3L, 3L, 2L), .Label = c("FKASA", "FKEE", "FKKSA",
"FKM", "FKP", "FTK"), class = "factor"), STUDENT_ID = structure(c(4L,
3L, 11L, 12L, 5L, 1L, 13L, 7L, 6L, 8L, 9L, 10L, 2L), .Label = c("AA14068",
"EA13043", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
"KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
), class = "factor"), PROGRAM = structure(c(1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "IJAZAH SARJANA MUDA", class =
"factor"),
    CGPA = c(2.67, 2.42, 2.85, 3.31, 2.89, 2.74, 2.88, 3.61,
    3.69, 3.2, 3.85, 3.63, 1.96)), .Names = c("FAC_CODE", "STUDENT_ID",
"PROGRAM", "CGPA"), class = "data.frame", row.names = c(NA, -13L
))

I would like to select the student id where the third and fourth value
represent the year they register data is eg. AA15..., AE14,... and I would
also to select their cgpa value.

Thank you.

On Mon, Mar 13, 2017 at 2:26 PM, roslinazairimah zakaria <
roslinaump at gmail.com> wrote:

> Thank you so much for your help.
>
> On Mon, Mar 13, 2017 at 1:52 PM, bioprogrammer <bioprogrammer at gmail.com>
> wrote:
>
>> Hi.
>>
>> I would use the "substr" function:
>>
>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/substr.html
>>
>> ...assuming you're working with character data.
>>
>> Another useful skill involves working with regular expressions.
>>
>> http://www.endmemo.com/program/R/grep.php
>>
>> http://regular-expressions.mobi/tutorial.html
>>
>> Hope these help :)
>>
>> ~Caitlin
>>
>>
>>
>>
>>
>> Sent from my T-Mobile 4G LTE Device
>>
>>
>> -------- Original message --------
>> From: roslinazairimah zakaria <roslinaump at gmail.com>
>> Date:03/12/2017 10:18 PM (GMT-07:00)
>> To: Bert Gunter <bgunter.4567 at gmail.com>
>> Cc: r-help mailing list <r-help at r-project.org>
>> Subject: Re: [R] Extract student ID that match certain criteria
>>
>> Another question,
>>
>> How do I extract ID based on the third and fourth letter:
>>
>> I have for example, AA14004, AB15035, CB14024, PA14009, PA14009 etc
>>
>> I would like to extract ID no. of AB14..., CB14..., PA14...
>>
>> On Mon, Mar 13, 2017 at 12:37 PM, roslinazairimah zakaria <
>> roslinaump at gmail.com> wrote:
>>
>> > Hi Bert,
>> >
>> > Thank you so much for your help.  However I don't really sure what is
>> the
>> > use of y values.  Can we do without it?
>> >
>> > x <- as.character(FKASA$STUDENT_ID)
>> > y <- c(1,786)
>> > My.Data <- data.frame (x,y)
>> >
>> > My.Data[grep("^AA14", My.Data$x), ]
>> >
>> > I got the following data:
>> >
>> >           x   y
>> > 1   AA14068   1
>> > 7   AA14090   1
>> > 11  AA14099   1
>> > 14  AA14012 786
>> > 15  AA14039   1
>> > 22  AA14251 786
>> >
>> > On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> > wrote:
>> >
>> >> 1. Your code is incorrect. All entries are character strings and must
>> be
>> >> quoted.
>> >>
>> >> 2. See ?grep  and note in particular (in the "Value" section):
>> >>
>> >> "grep(value = TRUE) returns a character vector containing the selected
>> >> elements of x (after coercion, preserving names but no other
>> >> attributes)."
>> >>
>> >>
>> >> 3. While the fixed = TRUE option will work here, you may wish to learn
>> >> about "regular expressions", which can come in very handy for
>> >> character string manipulation tasks. ?regex in R has a terse, but I
>> >> have found comprehensible, discussion. There are many good gentler
>> >> tutorials on the web, also.
>> >>
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
>> >> <roslinaump at gmail.com> wrote:
>> >> > Dear r-users,
>> >> >
>> >> > I have this list of student ID,
>> >> >
>> >> > dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286,
>> AA14090,
>> >> > AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012,
>> AA14039,
>> >> > AA15018, AA13234, AA13149, AA13282, AA13218)
>> >> >
>> >> > and I would like to extract all student of ID AA14... only.
>> >> >
>> >> > I search and tried substrt, subset and select but it fail.
>> >> >
>> >> >  substr(FKASA$STUDENT_ID, 2, nchar(string1))
>> >> > Error in nchar(string1) : 'nchar()' requires a character vector
>> >> >> subset(FKASA, STUDENT_ID=="AA14" )
>> >> >  [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM
>> KURSUS
>> >> >  CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>> >> >  ACT_IM
>> >> > [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>> >> >
>> >> > Thank you so much for your help.
>> >> >
>> >> > How do I do it?
>> >> > --
>> >> > *Roslinazairimah Zakaria*
>> >> > *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>> <+60%209-549%202766>*
>> >> >
>> >> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> >> > roslinaump at gmail.com <roslinaump at gmail.com>*
>> >> > Faculty of Industrial Sciences & Technology
>> >> > University Malaysia Pahang
>> >> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/posti
>> >> ng-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>> >
>> > --
>> > *Roslinazairimah Zakaria*
>> > *Tel: +609-5492370 <+60%209-549%202370> <+60%209-549%202370>; Fax. No.
>> +609-5492766 <+60%209-549%202766>
>> > <+60%209-549%202766>*
>> >
>> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> > roslinaump at gmail.com <roslinaump at gmail.com>*
>> > Faculty of Industrial Sciences & Technology
>> > University Malaysia Pahang
>> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >
>>
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>> <+60%209-549%202766>*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
> <+60%209-549%202766>*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 15 14:55:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 15 Mar 2017 06:55:42 -0700
Subject: [R] Getting the date out of R forecast funcion along with the
	forecasts as a data frame
In-Reply-To: <CAMOcQfNDSnoUcB4R5g+1ycn2hqWrPeGugWk0cbEQXefAnQoHoQ@mail.gmail.com>
References: <CAMOcQfNDSnoUcB4R5g+1ycn2hqWrPeGugWk0cbEQXefAnQoHoQ@mail.gmail.com>
Message-ID: <9A8407D6-B342-4C9A-9832-D9A0A9EC6CE7@dcn.davis.ca.us>

A) This is a support forum for R, a free software. It is your responsibility to confirm that your difficulties occur when that software is used, and confirm that knowledge by referencing the version you used (e.g. using the sessionInfo function) and not referencing proprietary software. 

B) Provide a minimal reproducible example (code and data)  that computes  what you do get and show what you thought you would get by contrast. This example should explicitly state which packages you are using, not offer hand waving lists of possible packages.  Google "R reproducible example" to learn more about how to do this. 

C) This is a plain text mailing list. This means that when you post your email in HTML format, we do not see what you saw, so you must send in plain text format if you want us to clearly understand you. This is a setting in your email program that can usually be set on a per-email or all sent emails basis. 

Please read the Posting Guide, which points out these and many other sage bits of advice. 

FWIW, most forecasting uses date/time as an INPUT,  so it is your responsibility to specify which dates/times you are interested in seeing results for.
-- 
Sent from my phone. Please excuse my brevity.

On March 15, 2017 5:57:31 AM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear all,
>
>I am currently generating forcasts using several different functions in
>Azure Machine Learning Studio using the R script module (nnetar,
>auto.arima, HoltWinters, ets, etc.).
>
>However, I want to find a way to get the dates of the forecasts and put
>those dates (along with the forecasts) in a data.frame format.
>
>Whenever I transform the forecast function results into a data frame,
>the
>date of the forecasts is lost, or seems like you cannot get the date of
>the
>forecasts and make them part of the data frame containing the forecast
>results.
>
>I would like to manipulate the results in such a way that I can get the
>following format:
>
>Date              Forecast
>Jan-2017       ######
>Feb-2017       ######
>
>Any help will be greatly appreciated,
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Mar 15 15:46:31 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 15 Mar 2017 14:46:31 +0000
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <CANTvJZ+ef-dRdsVUQHfTmMLsPb+JcVqHWPSWDvFJQ_O_qXFGdA@mail.gmail.com>
References: <ef1h337w0ry677ursnkyk5kf.1489384064772@email.android.com>	<CANTvJZLN4EUnLtiW8MjJhyTDrgyaJFeU6+bEhcHUYV9hsBf0NQ@mail.gmail.com>
	<CANTvJZ+ef-dRdsVUQHfTmMLsPb+JcVqHWPSWDvFJQ_O_qXFGdA@mail.gmail.com>
Message-ID: <58C953C7.9000808@sapo.pt>

Hello,

I believe your request is a bit confusing since you say you want to 
filter the student id but then you have many years in dt_all3 and only 
one program ("IJAZAH SARJANA MUDA"). So I've written two simple 
functions, one to filter by year and the other by program.


fun1 <- function(x, year){
	inx <- substr(x[["STUDENT_ID"]], 3, 4) == as.character(year)
	x[inx, ]
}

fun2 <- function(x, program){
	inx <- x[["PROGRAM"]] == program
	x[inx, ]
}

fun1(dt_all2, 14)  # filter by year = 14
fun2(dt_all2, "IJAZAH SARJANA MUDA")

Hope this helps,

Rui Barradas


Em 15-03-2017 13:49, roslinazairimah zakaria escreveu:
> Hi Caitlin,
>
> I tried so many ways as suggested but unsuccessful...and I realise that I
> need to filter the student ID and their CGPA, but if I change the ID into
> character I lost the CGPA value.  It is easy to do in excel, however a bit
> time consuming and trying to do in R.
>
> I have these data:
>
> dput(dt_all2)
> structure(list(FAC_CODE = structure(c(2L, 2L, 2L, 4L, 1L, 1L,
> 4L, 7L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 1L, 2L, 5L, 6L), .Label = c("FKASA",
> "FKEE", "FKKSA", "FKM", "FKP", "FSKKP", "FTK"), class = "factor"),
>      STUDENT_ID = structure(c(9L, 6L, 7L, 17L, 2L, 3L, 18L, 19L,
>      13L, 12L, 14L, 15L, 16L, 10L, 8L, 1L, 5L, 11L, 4L), .Label =
> c("AA14068",
>      "AB15103", "AB15124", "CC14107", "EA13043", "EB14059", "EB14073",
>      "EB14101", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
>      "KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
>      ), class = "factor"), PROGRAM = structure(c(2L, 1L, 1L, 2L,
>      1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L
>      ), .Label = c("DIPLOMA", "IJAZAH SARJANA MUDA"), class = "factor"),
>      CGPA = c(2.42, 3.27, 1.98, 2.85, 2.24, 3.01, 3.31, 2.88,
>      3.61, 3.69, 3.2, 3.85, 3.63, 2.67, 2.35, 2.74, 1.96, 2.89,
>      2.59)), .Names = c("FAC_CODE", "STUDENT_ID", "PROGRAM", "CGPA"
> ), class = "data.frame", row.names = c(NA, -19L))
>
> and I want to filter my data as follows:
>
>> dput(dt_all3)
> structure(list(FAC_CODE = structure(c(2L, 2L, 4L, 4L, 5L, 1L,
> 6L, 3L, 3L, 3L, 3L, 3L, 2L), .Label = c("FKASA", "FKEE", "FKKSA",
> "FKM", "FKP", "FTK"), class = "factor"), STUDENT_ID = structure(c(4L,
> 3L, 11L, 12L, 5L, 1L, 13L, 7L, 6L, 8L, 9L, 10L, 2L), .Label = c("AA14068",
> "EA13043", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
> "KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
> ), class = "factor"), PROGRAM = structure(c(1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "IJAZAH SARJANA MUDA", class =
> "factor"),
>      CGPA = c(2.67, 2.42, 2.85, 3.31, 2.89, 2.74, 2.88, 3.61,
>      3.69, 3.2, 3.85, 3.63, 1.96)), .Names = c("FAC_CODE", "STUDENT_ID",
> "PROGRAM", "CGPA"), class = "data.frame", row.names = c(NA, -13L
> ))
>
> I would like to select the student id where the third and fourth value
> represent the year they register data is eg. AA15..., AE14,... and I would
> also to select their cgpa value.
>
> Thank you.
>
> On Mon, Mar 13, 2017 at 2:26 PM, roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
>
>> Thank you so much for your help.
>>
>> On Mon, Mar 13, 2017 at 1:52 PM, bioprogrammer <bioprogrammer at gmail.com>
>> wrote:
>>
>>> Hi.
>>>
>>> I would use the "substr" function:
>>>
>>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/substr.html
>>>
>>> ...assuming you're working with character data.
>>>
>>> Another useful skill involves working with regular expressions.
>>>
>>> http://www.endmemo.com/program/R/grep.php
>>>
>>> http://regular-expressions.mobi/tutorial.html
>>>
>>> Hope these help :)
>>>
>>> ~Caitlin
>>>
>>>
>>>
>>>
>>>
>>> Sent from my T-Mobile 4G LTE Device
>>>
>>>
>>> -------- Original message --------
>>> From: roslinazairimah zakaria <roslinaump at gmail.com>
>>> Date:03/12/2017 10:18 PM (GMT-07:00)
>>> To: Bert Gunter <bgunter.4567 at gmail.com>
>>> Cc: r-help mailing list <r-help at r-project.org>
>>> Subject: Re: [R] Extract student ID that match certain criteria
>>>
>>> Another question,
>>>
>>> How do I extract ID based on the third and fourth letter:
>>>
>>> I have for example, AA14004, AB15035, CB14024, PA14009, PA14009 etc
>>>
>>> I would like to extract ID no. of AB14..., CB14..., PA14...
>>>
>>> On Mon, Mar 13, 2017 at 12:37 PM, roslinazairimah zakaria <
>>> roslinaump at gmail.com> wrote:
>>>
>>>> Hi Bert,
>>>>
>>>> Thank you so much for your help.  However I don't really sure what is
>>> the
>>>> use of y values.  Can we do without it?
>>>>
>>>> x <- as.character(FKASA$STUDENT_ID)
>>>> y <- c(1,786)
>>>> My.Data <- data.frame (x,y)
>>>>
>>>> My.Data[grep("^AA14", My.Data$x), ]
>>>>
>>>> I got the following data:
>>>>
>>>>            x   y
>>>> 1   AA14068   1
>>>> 7   AA14090   1
>>>> 11  AA14099   1
>>>> 14  AA14012 786
>>>> 15  AA14039   1
>>>> 22  AA14251 786
>>>>
>>>> On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>
>>>>> 1. Your code is incorrect. All entries are character strings and must
>>> be
>>>>> quoted.
>>>>>
>>>>> 2. See ?grep  and note in particular (in the "Value" section):
>>>>>
>>>>> "grep(value = TRUE) returns a character vector containing the selected
>>>>> elements of x (after coercion, preserving names but no other
>>>>> attributes)."
>>>>>
>>>>>
>>>>> 3. While the fixed = TRUE option will work here, you may wish to learn
>>>>> about "regular expressions", which can come in very handy for
>>>>> character string manipulation tasks. ?regex in R has a terse, but I
>>>>> have found comprehensible, discussion. There are many good gentler
>>>>> tutorials on the web, also.
>>>>>
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
>>>>> <roslinaump at gmail.com> wrote:
>>>>>> Dear r-users,
>>>>>>
>>>>>> I have this list of student ID,
>>>>>>
>>>>>> dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286,
>>> AA14090,
>>>>>> AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012,
>>> AA14039,
>>>>>> AA15018, AA13234, AA13149, AA13282, AA13218)
>>>>>>
>>>>>> and I would like to extract all student of ID AA14... only.
>>>>>>
>>>>>> I search and tried substrt, subset and select but it fail.
>>>>>>
>>>>>>   substr(FKASA$STUDENT_ID, 2, nchar(string1))
>>>>>> Error in nchar(string1) : 'nchar()' requires a character vector
>>>>>>> subset(FKASA, STUDENT_ID=="AA14" )
>>>>>>   [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM
>>> KURSUS
>>>>>>   CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>>>>>>   ACT_IM
>>>>>> [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>>>>>>
>>>>>> Thank you so much for your help.
>>>>>>
>>>>>> How do I do it?
>>>>>> --
>>>>>> *Roslinazairimah Zakaria*
>>>>>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>>> <+60%209-549%202766>*
>>>>>>
>>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>>>> Faculty of Industrial Sciences & Technology
>>>>>> University Malaysia Pahang
>>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> *Roslinazairimah Zakaria*
>>>> *Tel: +609-5492370 <+60%209-549%202370> <+60%209-549%202370>; Fax. No.
>>> +609-5492766 <+60%209-549%202766>
>>>> <+60%209-549%202766>*
>>>>
>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>> Faculty of Industrial Sciences & Technology
>>>> University Malaysia Pahang
>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>
>>>
>>>
>>>
>>> --
>>> *Roslinazairimah Zakaria*
>>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>>> <+60%209-549%202766>*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>> <+60%209-549%202766>*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>
>
>


From bgunter.4567 at gmail.com  Wed Mar 15 15:57:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Mar 2017 07:57:52 -0700
Subject: [R] Crete stats course
In-Reply-To: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
References: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
Message-ID: <CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>

Perhaps this has been asked and settled before, but while such courses
certainly might be of interest to those who read this list, they are
for profit, and therefore advertising them here does seem somewhat
inappropriate.

Please, I don't want to start a long discussion or war. Just slap me
down if I am wrong about this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 15, 2017 at 2:14 AM, Highland Statistics Ltd
<highstat at highstat.com> wrote:
> There are a few remaining seats on the following course:
>
>
>
> Course: Data exploration, regression, GLM & GAM with R
>
> Where:  HCMR, Crete, Greece
>
> When:   24-28 April 2017
>
> Course website: http://www.highstat.com/statscourse.htm
>
> Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf
>
>
> Kind regards,
>
> Alain Zuur
>
>
> Other open courses in 2017:
>
> Introduction to Regression Models with Spatial and Temporal Correlation.
> 8-12 May 2017. Genoa, Italy.
> Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian
> approaches. 9-13 October 2017. Trondheim, Norway.
> Introduction to Regression Models with Spatial and Temporal Correlation.
> 23-27 October 2017. Southampton, UK
> Data exploration, regression, GLM & GAM with introduction to R. 18-22
> September 2017. Edmonton, Canada.
> Introduction to Regression Models with Spatial and Temporal Correlation. 4-8
> December 2017. Banff, Canada.
>
>
>
>
>
>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Mar 15 16:18:21 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 15 Mar 2017 11:18:21 -0400
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
	<CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>
	<CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>
Message-ID: <c0c6c970-af81-195f-1a41-4464e3c4c6a0@gmail.com>

On 15/03/2017 8:58 AM, Yihui Xie wrote:
> I'm the author of the animation package, and I do plan to switch to
> the magick package in the future instead of using ImageMagick as a
> system dependency.

I did that in rgl (as a Suggests); it's very easy, as the functions 
mirror the command line options.

Duncan Murdoch

>
> Regards,
> Yihui
> --
> https://yihui.name
>
>
> On Wed, Mar 15, 2017 at 12:32 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> A google search on "ImageMagick Package R" brought this up, which
>> seems relevant:
>>
>> https://cran.r-project.org/web/packages/magick/vignettes/intro.html
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Mar 14, 2017 at 10:21 PM, C W <tmrsg11 at gmail.com> wrote:
>>> Dear list,
>>>
>>> I am trying to use saveGIF() from library animation.
>>> https://cran.r-project.org/web/packages/animation/animation.pdf
>>>
>>> saveGIF() has dependency on package ImageMagick.
>>>
>>> I got the following,
>>>> install.packages("ImageMagick")
>>> Warning in install.packages :
>>>   package ?ImageMagick? is not available (for R version 3.3.2)
>>>
>>> Does that mean I can't use saveGIF() anymore? It seems that this is the
>>> only package capable in R.
>>>
>>> Thank you in advance!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Wed Mar 15 16:50:19 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 15 Mar 2017 10:50:19 -0500
Subject: [R] How to get the date generated by the forecast function as
 another field in a data frame
Message-ID: <CAMOcQfOG=YB3TY-i=YKX64mYjyBgLvZ2d0v8Sk4Kpq159Vi9NQ@mail.gmail.com>

Dear all,

I am currently using R for windows Version 3.3.3 (I will provide the
sessionInfo() output below)

> library("Rcmdr")
Loading required package: splines
Loading required package: RcmdrMisc
Loading required package: car
Loading required package: sandwich

Rcmdr Version 2.3-2

> library(forecast)
>
> library(tseries)

    'tseries' version: 0.10-35

    'tseries' is a package for time series analysis and computational
    finance.

    See 'library(help="tseries")' for details.

> library(stats)
>
> library(stats4)
>
> Data<-read.csv("ContainerDataNEW.csv")
>
> TSData<-ts(Data[,1], start=c(1985,10), frequency=12)
>
> TSeriesModel1<-ets(TSData)
>
> TSSeriesModel1Forecast<-forecast(TSeriesModel1,h=24)

Now the output from forecasts is the following:

                Point Forecast    Lo 80    Hi 80       Lo 95           Hi 95
Apr 2017       67.62845 30.73747 104.5194 11.20856 124.0483
May 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Jun 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Jul 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Aug 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Sep 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Oct 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Nov 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Dec 2017       67.62845 30.73747 104.5194 11.20856 124.0483
Jan 2018       67.62845 30.73747 104.5194 11.20856 124.0483
Feb 2018       67.62845 30.73747 104.5194 11.20856 124.0483
Mar 2018       67.62845 30.73747 104.5194 11.20856 124.0483
Apr 2018       67.62845 30.73747 104.5194 11.20856 124.0483
May 2018       67.62845 30.73747 104.5194 11.20856 124.0483
Jun 2018       67.62845 30.73747 104.5194 11.20856 124.0483
Jul 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Aug 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Sep 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Oct 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Nov 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Dec 2018       67.62845 30.73747 104.5194 11.20856 124.0484
Jan 2019       67.62845 30.73747 104.5194 11.20856 124.0484
Feb 2019       67.62845 30.73747 104.5194 11.20856 124.0484
Mar 2019       67.62845 30.73747 104.5194 11.20856 124.0484

However, as you can see, the first "column" contains the dates for the
forecasts, but it appears as a field with no name.

What I would like to do is to get those dates, add them as an additional
column to the forecasts so that when I use the data.frame(Forecasts) I can
have a result in this fashion:

Date              Point Forecast    Lo 80         Hi 80       Lo 95
  Hi 95
Apr 2017       67.62845           30.73747 104.5194 11.20856     124.0483

Is there a way to do this?

Here is the sessionInfo() output:

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                  LC_TIME=English_United States.1252

attached base packages:
[1] stats4    splines   stats     graphics  grDevices utils     datasets
 methods   base

other attached packages:
[1] tseries_0.10-35 forecast_8.0    Rcmdr_2.3-2     RcmdrMisc_1.0-5
sandwich_2.3-4  car_2.1-3

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.7         lattice_0.20-34     tcltk2_1.2-11
class_7.3-14        zoo_1.7-13          lmtest_0.9-35       relimp_1.0-5
     assertthat_0.1      digest_0.6.11       R6_2.2.0            plyr_1.8.4

[12] acepack_1.4.1       MatrixModels_0.4-1  e1071_1.6-7         httr_1.2.1
         ggplot2_2.2.0       lazyeval_0.2.0      AzureML_0.2.13
 curl_2.2            uuid_0.1-2          readxl_0.1.1        minqa_1.2.4

[23] data.table_1.10.4   SparseM_1.74        fracdiff_1.4-2
 nloptr_1.0.4        rpart_4.1-10        Matrix_1.2-8        lme4_1.1-12
      stringr_1.1.0       foreign_0.8-67      munsell_0.4.3
base64enc_0.1-3
[34] mgcv_1.8-17         htmltools_0.3.5     tcltk_3.3.3
nnet_7.3-12         tibble_1.2          gridExtra_2.2.1     htmlTable_1.7
    quadprog_1.5-5      Hmisc_4.0-2         codetools_0.2-15
 XML_3.98-1.4
[45] MASS_7.3-45         grid_3.3.3          nlme_3.1-131
 jsonlite_1.1        gtable_0.2.0        magrittr_1.5        scales_0.4.1
     stringi_1.1.2       timeDate_3012.100   latticeExtra_0.6-28
Formula_1.2-1
[56] RColorBrewer_1.1-2  tools_3.3.3         abind_1.4-5
parallel_3.3.3      pbkrtest_0.4-6      survival_2.40-1
colorspace_1.3-0    cluster_2.0.5       miniCRAN_0.2.7      knitr_1.15
     quantreg_5.29
>

I have also attached the file that I used to train the model and generate
forecasts.

Any help will be greatly appreciated,

Best regards,

Paul

From ruipbarradas at sapo.pt  Wed Mar 15 17:05:08 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 15 Mar 2017 16:05:08 +0000
Subject: [R] How to get the date generated by the forecast function as
 another field in a data frame
In-Reply-To: <CAMOcQfOG=YB3TY-i=YKX64mYjyBgLvZ2d0v8Sk4Kpq159Vi9NQ@mail.gmail.com>
References: <CAMOcQfOG=YB3TY-i=YKX64mYjyBgLvZ2d0v8Sk4Kpq159Vi9NQ@mail.gmail.com>
Message-ID: <58C96634.30709@sapo.pt>

Hello,

Since we don't have access to file ContainerDataNEW.csv I cannot say for 
sure but it seems that those dates are the rownames so you could try

rownames(TSSeriesModel1Forecast)

and see what it gives. Or I might be completely mistaken.

Hope this helps,

Rui Barradas

Em 15-03-2017 15:50, Paul Bernal escreveu:
> Dear all,
>
> I am currently using R for windows Version 3.3.3 (I will provide the
> sessionInfo() output below)
>
>> library("Rcmdr")
> Loading required package: splines
> Loading required package: RcmdrMisc
> Loading required package: car
> Loading required package: sandwich
>
> Rcmdr Version 2.3-2
>
>> library(forecast)
>>
>> library(tseries)
>
>      'tseries' version: 0.10-35
>
>      'tseries' is a package for time series analysis and computational
>      finance.
>
>      See 'library(help="tseries")' for details.
>
>> library(stats)
>>
>> library(stats4)
>>
>> Data<-read.csv("ContainerDataNEW.csv")
>>
>> TSData<-ts(Data[,1], start=c(1985,10), frequency=12)
>>
>> TSeriesModel1<-ets(TSData)
>>
>> TSSeriesModel1Forecast<-forecast(TSeriesModel1,h=24)
>
> Now the output from forecasts is the following:
>
>                  Point Forecast    Lo 80    Hi 80       Lo 95           Hi 95
> Apr 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> May 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Jun 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Jul 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Aug 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Sep 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Oct 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Nov 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Dec 2017       67.62845 30.73747 104.5194 11.20856 124.0483
> Jan 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> Feb 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> Mar 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> Apr 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> May 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> Jun 2018       67.62845 30.73747 104.5194 11.20856 124.0483
> Jul 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Aug 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Sep 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Oct 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Nov 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Dec 2018       67.62845 30.73747 104.5194 11.20856 124.0484
> Jan 2019       67.62845 30.73747 104.5194 11.20856 124.0484
> Feb 2019       67.62845 30.73747 104.5194 11.20856 124.0484
> Mar 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>
> However, as you can see, the first "column" contains the dates for the
> forecasts, but it appears as a field with no name.
>
> What I would like to do is to get those dates, add them as an additional
> column to the forecasts so that when I use the data.frame(Forecasts) I can
> have a result in this fashion:
>
> Date              Point Forecast    Lo 80         Hi 80       Lo 95
>    Hi 95
> Apr 2017       67.62845           30.73747 104.5194 11.20856     124.0483
>
> Is there a way to do this?
>
> Here is the sessionInfo() output:
>
>> sessionInfo()
> R version 3.3.3 (2017-03-06)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8.1 x64 (build 9600)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>                    LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats4    splines   stats     graphics  grDevices utils     datasets
>   methods   base
>
> other attached packages:
> [1] tseries_0.10-35 forecast_8.0    Rcmdr_2.3-2     RcmdrMisc_1.0-5
> sandwich_2.3-4  car_2.1-3
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.7         lattice_0.20-34     tcltk2_1.2-11
> class_7.3-14        zoo_1.7-13          lmtest_0.9-35       relimp_1.0-5
>       assertthat_0.1      digest_0.6.11       R6_2.2.0            plyr_1.8.4
>
> [12] acepack_1.4.1       MatrixModels_0.4-1  e1071_1.6-7         httr_1.2.1
>           ggplot2_2.2.0       lazyeval_0.2.0      AzureML_0.2.13
>   curl_2.2            uuid_0.1-2          readxl_0.1.1        minqa_1.2.4
>
> [23] data.table_1.10.4   SparseM_1.74        fracdiff_1.4-2
>   nloptr_1.0.4        rpart_4.1-10        Matrix_1.2-8        lme4_1.1-12
>        stringr_1.1.0       foreign_0.8-67      munsell_0.4.3
> base64enc_0.1-3
> [34] mgcv_1.8-17         htmltools_0.3.5     tcltk_3.3.3
> nnet_7.3-12         tibble_1.2          gridExtra_2.2.1     htmlTable_1.7
>      quadprog_1.5-5      Hmisc_4.0-2         codetools_0.2-15
>   XML_3.98-1.4
> [45] MASS_7.3-45         grid_3.3.3          nlme_3.1-131
>   jsonlite_1.1        gtable_0.2.0        magrittr_1.5        scales_0.4.1
>       stringi_1.1.2       timeDate_3012.100   latticeExtra_0.6-28
> Formula_1.2-1
> [56] RColorBrewer_1.1-2  tools_3.3.3         abind_1.4-5
> parallel_3.3.3      pbkrtest_0.4-6      survival_2.40-1
> colorspace_1.3-0    cluster_2.0.5       miniCRAN_0.2.7      knitr_1.15
>       quantreg_5.29
>>
>
> I have also attached the file that I used to train the model and generate
> forecasts.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From highstat at highstat.com  Wed Mar 15 17:09:23 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 15 Mar 2017 18:09:23 +0200
Subject: [R] Crete stats course
In-Reply-To: <CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
References: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
	<CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
Message-ID: <4acd152d-3e05-93df-5276-770d4d932d08@highstat.com>


On 15/03/2017 16:57, Bert Gunter wrote:
> Perhaps this has been asked and settled before, but while such courses
> certainly might be of interest to those who read this list,
Bert,
>   they are
> for profit, and therefore advertising them here does seem somewhat
> inappropriate.
I don't want to be rude or funny, but the general guidelines for this 
mailing list state "Do your homework before posting". There is nowhere a 
statement on the general guidelines that state that you cannot make an 
announcement for a course (which by the way, introduces R to people who 
never have used R before)....be it for profit or not. And even if it 
would have such a statement, I don't think that a 'once per quarter' 
email about an R course does much harm.

Apologies to everyone else for filling up your mailbox. Bert....if you 
would like to discuss this further then please email me directly and I 
will send a summary to the list later.

Kind regards,

Alain

> Please, I don't want to start a long discussion or war. Just slap me
> down if I am wrong about this.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 15, 2017 at 2:14 AM, Highland Statistics Ltd
> <highstat at highstat.com> wrote:
>> There are a few remaining seats on the following course:
>>
>>
>>
>> Course: Data exploration, regression, GLM & GAM with R
>>
>> Where:  HCMR, Crete, Greece
>>
>> When:   24-28 April 2017
>>
>> Course website: http://www.highstat.com/statscourse.htm
>>
>> Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf
>>
>>
>> Kind regards,
>>
>> Alain Zuur
>>
>>
>> Other open courses in 2017:
>>
>> Introduction to Regression Models with Spatial and Temporal Correlation.
>> 8-12 May 2017. Genoa, Italy.
>> Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian
>> approaches. 9-13 October 2017. Trondheim, Norway.
>> Introduction to Regression Models with Spatial and Temporal Correlation.
>> 23-27 October 2017. Southampton, UK
>> Data exploration, regression, GLM & GAM with introduction to R. 18-22
>> September 2017. Edmonton, Canada.
>> Introduction to Regression Models with Spatial and Temporal Correlation. 4-8
>> December 2017. Banff, Canada.
>>
>>
>>
>>
>>
>>
>>
>> --
>> Dr. Alain F. Zuur
>>
>> First author of:
>> 1. Beginner's Guide to GAMM with R (2014).
>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>> 3. Beginner's Guide to GAM with R (2012).
>> 4. Zero Inflated Models and GLMM with R (2012).
>> 5. A Beginner's Guide to R (2009).
>> 6. Mixed effects models and extensions in ecology with R (2009).
>> 7. Analysing Ecological Data (2007).
>>
>> Highland Statistics Ltd.
>> 9 St Clair Wynd
>> UK - AB41 6DZ Newburgh
>> Tel:   0044 1358 788177
>> Email: highstat at highstat.com
>> URL:   www.highstat.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From paulbernal07 at gmail.com  Wed Mar 15 17:24:10 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 15 Mar 2017 11:24:10 -0500
Subject: [R] How to get the date generated by the forecast function as
 another field in a data frame
In-Reply-To: <58C96634.30709@sapo.pt>
References: <CAMOcQfOG=YB3TY-i=YKX64mYjyBgLvZ2d0v8Sk4Kpq159Vi9NQ@mail.gmail.com>
	<58C96634.30709@sapo.pt>
Message-ID: <CAMOcQfOdce0xU5z_aHZb33FJUkrdm72Ao1J4R7B8LGRf4DDLHQ@mail.gmail.com>

Hello Rui,

I have attached the .csv file, I will attach it again.

Please let me know if you can access it.

Cheers,

Paul

2017-03-15 11:05 GMT-05:00 Rui Barradas <ruipbarradas at sapo.pt>:

> Hello,
>
> Since we don't have access to file ContainerDataNEW.csv I cannot say for
> sure but it seems that those dates are the rownames so you could try
>
> rownames(TSSeriesModel1Forecast)
>
> and see what it gives. Or I might be completely mistaken.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 15-03-2017 15:50, Paul Bernal escreveu:
>
>> Dear all,
>>
>> I am currently using R for windows Version 3.3.3 (I will provide the
>> sessionInfo() output below)
>>
>> library("Rcmdr")
>>>
>> Loading required package: splines
>> Loading required package: RcmdrMisc
>> Loading required package: car
>> Loading required package: sandwich
>>
>> Rcmdr Version 2.3-2
>>
>> library(forecast)
>>>
>>> library(tseries)
>>>
>>
>>      'tseries' version: 0.10-35
>>
>>      'tseries' is a package for time series analysis and computational
>>      finance.
>>
>>      See 'library(help="tseries")' for details.
>>
>> library(stats)
>>>
>>> library(stats4)
>>>
>>> Data<-read.csv("ContainerDataNEW.csv")
>>>
>>> TSData<-ts(Data[,1], start=c(1985,10), frequency=12)
>>>
>>> TSeriesModel1<-ets(TSData)
>>>
>>> TSSeriesModel1Forecast<-forecast(TSeriesModel1,h=24)
>>>
>>
>> Now the output from forecasts is the following:
>>
>>                  Point Forecast    Lo 80    Hi 80       Lo 95
>>  Hi 95
>> Apr 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> May 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Jun 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Jul 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Aug 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Sep 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Oct 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Nov 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Dec 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>> Jan 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> Feb 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> Mar 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> Apr 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> May 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> Jun 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>> Jul 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Aug 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Sep 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Oct 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Nov 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Dec 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>> Jan 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>> Feb 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>> Mar 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>>
>> However, as you can see, the first "column" contains the dates for the
>> forecasts, but it appears as a field with no name.
>>
>> What I would like to do is to get those dates, add them as an additional
>> column to the forecasts so that when I use the data.frame(Forecasts) I can
>> have a result in this fashion:
>>
>> Date              Point Forecast    Lo 80         Hi 80       Lo 95
>>    Hi 95
>> Apr 2017       67.62845           30.73747 104.5194 11.20856     124.0483
>>
>> Is there a way to do this?
>>
>> Here is the sessionInfo() output:
>>
>> sessionInfo()
>>>
>> R version 3.3.3 (2017-03-06)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 8.1 x64 (build 9600)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>                    LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats4    splines   stats     graphics  grDevices utils     datasets
>>   methods   base
>>
>> other attached packages:
>> [1] tseries_0.10-35 forecast_8.0    Rcmdr_2.3-2     RcmdrMisc_1.0-5
>> sandwich_2.3-4  car_2.1-3
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.7         lattice_0.20-34     tcltk2_1.2-11
>> class_7.3-14        zoo_1.7-13          lmtest_0.9-35       relimp_1.0-5
>>       assertthat_0.1      digest_0.6.11       R6_2.2.0
>> plyr_1.8.4
>>
>> [12] acepack_1.4.1       MatrixModels_0.4-1  e1071_1.6-7
>>  httr_1.2.1
>>           ggplot2_2.2.0       lazyeval_0.2.0      AzureML_0.2.13
>>   curl_2.2            uuid_0.1-2          readxl_0.1.1        minqa_1.2.4
>>
>> [23] data.table_1.10.4   SparseM_1.74        fracdiff_1.4-2
>>   nloptr_1.0.4        rpart_4.1-10        Matrix_1.2-8        lme4_1.1-12
>>        stringr_1.1.0       foreign_0.8-67      munsell_0.4.3
>> base64enc_0.1-3
>> [34] mgcv_1.8-17         htmltools_0.3.5     tcltk_3.3.3
>> nnet_7.3-12         tibble_1.2          gridExtra_2.2.1     htmlTable_1.7
>>      quadprog_1.5-5      Hmisc_4.0-2         codetools_0.2-15
>>   XML_3.98-1.4
>> [45] MASS_7.3-45         grid_3.3.3          nlme_3.1-131
>>   jsonlite_1.1        gtable_0.2.0        magrittr_1.5        scales_0.4.1
>>       stringi_1.1.2       timeDate_3012.100   latticeExtra_0.6-28
>> Formula_1.2-1
>> [56] RColorBrewer_1.1-2  tools_3.3.3         abind_1.4-5
>> parallel_3.3.3      pbkrtest_0.4-6      survival_2.40-1
>> colorspace_1.3-0    cluster_2.0.5       miniCRAN_0.2.7      knitr_1.15
>>       quantreg_5.29
>>
>>>
>>>
>> I have also attached the file that I used to train the model and generate
>> forecasts.
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

From bgunter.4567 at gmail.com  Wed Mar 15 17:28:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Mar 2017 09:28:25 -0700
Subject: [R] add median value and standard deviation bar to lattice plot
In-Reply-To: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
Message-ID: <CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>

There may be a specific function that handles this for you, but to
roll your own, you need a custom panel.groups function, not the
default. You need to modify the panel function (which is
panel.superpose by default) to pass down the "col" argument to the
panel.segments call in the panel.groups function.

This should get you started:

useOuterStrips(
   strip = strip.custom(par.strip.text = list(cex = 0.75)),
   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
   stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
         panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
         panel.stripplot(x,y,col=col,...)
         m <- median(y)
         panel.segments(x0 = x[1] -.5, y0 = m,
                        x1 = x[1] +.5, y1 = m,
                        col=col, lwd=2
                        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background = list(col=c("paleturquoise",
                                                        "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
         space = "top",
         columns = 3,
         text = list(c("Blank", "Negative", "Positive"), col="black"),
         rectangles = list(col=c("grey", "green", "red"))
      )
   )
)

FWIW, I think adding 1 sd bars is a bad idea statistically.

And though it made no difference here, please post in pain text, not HTML.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 15, 2017 at 2:22 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I am analyzing some multivariate data that is organized like this:
> 1st variable = cluster (A or B)
> 2nd variable = target (a, b, c, d, e)
> 3rd variable = type (blank, negative, positive)
> 4th variable = sample (the actual name of the sample)
> 5th variable = average (the actual reading -- please not that this is the
> mean of different measures with an assumed normal distribution, but the
> assumption might not always be true)
> 6th variable = stdev (the standard deviation associated with each reading)
> 7th variable = ll (lower limit that is average stdev)
> 8th variable = ul (upper limit that is average + stdev)
>
> I am plotting the data using lattice's stripplot and I would need to add:
> 1. an error bar for each measurement. the bar should be possibly coloured
> in light grey and semitransparent to reduce the noise of the plot.
> 2. a type-based median bar to show differences in measurements between
> blanks, negative and positive samples within each panel.
>
> How would I do that?
> Many thanks,
> Luigi
>
>>>>
> cluster <- c(rep("A", 90), rep("B", 100))
> sample <- c(
>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
> "blank"), 5),
>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
> "cow-59", "blank"), 5)
> )
> type <- c(
>   rep(c("negative", "negative", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "blank"), 5),
>   rep(c("negative", "positive", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "positive", "positive", "blank"), 5)
> )
> target <- c(
> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
> )
> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
> 42, 47, 86, 100,
>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
> 33, 28, 31, 26, 23,
>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
> 58.5, 61, 62.5, 58,
>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
> 84, 95.5, 62, 82, 138,
>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
> 33, 37, 51, 44, 50, 54,
>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
> 68, 121, 80, 57,
>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
> 32, 184, 36, 45, 45, 44,
>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
> 79, 34, 74.5,
> 54, 49, 55, 56,
>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
> 33, 58, 51, 54,
>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
> 9.92, 4.59, 19, 7.96,
>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
> 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
> 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
> 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
> 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
> 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
> 9.92, 40.69,
> 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
> 64.9, 3.71,
> 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
> 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
> 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
> 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>                0.15, 1.28, 7.42, 71.15, 9.39)
> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
> 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
> -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
> 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
> 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
> 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
> 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
> 34.72, 42.58, -18.15, 39.61)
> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
> 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
> 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
> 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
> 169.69,
>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
> 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
> 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
> 143.71,
>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
> 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
> 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
> 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
> my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
> ul, stringsAsFactors = FALSE)
>
> library(lattice)
> library(latticeExtra)
> useOuterStrips(
>   strip = strip.custom(par.strip.text = list(cex = 0.75)),
>   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>   stripplot(
>     average ~ type|target+cluster,
>     my.data,
>     groups = type,
>     pch=1,
>     jitter.data = TRUE,
>     main = "Group-wise",
>     xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>     col = c("grey", "green", "red"),
>     par.settings = list(strip.background = list(col=c("paleturquoise",
> "grey"))),
>     scales = list(alternating = FALSE, x=list(draw=FALSE)),
>     key = list(
>       space = "top",
>       columns = 3,
>       text = list(c("Blank", "Negative", "Positive"), col="black"),
>       rectangles = list(col=c("grey", "green", "red"))
>     )
>   )
> )
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Wed Mar 15 18:12:10 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 15 Mar 2017 13:12:10 -0400
Subject: [R] Document Term Matrix will not maintain decimal places of
 numbers or capture all terms
In-Reply-To: <CANj2rB-2b5z-96jH_zoFWPr_GU7FirB4_29a-9ZpYzUPMhZBCg@mail.gmail.com>
References: <CANj2rB-2b5z-96jH_zoFWPr_GU7FirB4_29a-9ZpYzUPMhZBCg@mail.gmail.com>
Message-ID: <CAM_vjukS=LDCrHkVfZJ8PBkNguEbOTiVFgk1-FZZ3kFarLp1bg@mail.gmail.com>

This question is a strong argument for not posting in HTML. I at least
cannot make sense out of the example.

It's also a strong argument for providing a small reproducible example
using dput() to provide data.

Someone is more likely to be able to help if we don't have to guess
what you meant.

Sarah

On Tue, Mar 14, 2017 at 1:46 PM, Will Ebert <willebert34 at gmail.com> wrote:
> Before I updated my version of RStudio (1.0.136), everything worked great.
> With the update something has changed with Document Term Matrix in the 'tm'
> package. I want to create a dtm, but with numbers. For instance if I have a
> .csv with one column as shown below:
>
> x1.0111.21123.35212.11
>
> I want the column names in my term matrix to look like this:
>
> 1.01 11.21 123.35 212.111    0     0      00    1     0      00    0
>   1      00    0     0      1
>
> But instead it looks like this:
>
> 123 2120   00   01   00   1
>
> Here's the code that used to work:
>
> corpus = Corpus(VectorSource(x))
> dtm = DocumentTermMatrix(corpus)
> dtm_df = as.data.frame(as.matrix(dtm))
>
> I have tried uninstalling everything and reinstalling, tried older versions
> (Studio 0.99.489 & R 3.3.1), but I get the same results. I ask others to
> test it out and it works for them. Also, I had someone download R, Rtools,
> and RStudio to test this and they got the same results I did. I have no
> idea what has happened and would greatly appreciate help on this matter as
> it is extremely urgent.
>
> Thanks in advance
>
> Will
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From allantanaka11 at yahoo.com  Wed Mar 15 12:08:34 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Wed, 15 Mar 2017 11:08:34 +0000 (UTC)
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
Message-ID: <1994411336.523592.1489576114011@mail.yahoo.com>

The following is an example:

| Item_Identifier | Item_Weight |
| FDP10 | 19 |
| FDP10 |  |
| DRI11 | 8.26 |
| DRI11 |  |
| FDW12 | 8.315 |
| FDW12 |  |


The following is the one that i want to be. That is, filling NA values from the previous Non-NA values.
| Item_Identifier | Item_Weight |
| FDP10 | 19 |
| FDP10 | 19 |
| DRI11 | 8.26 |
| DRI11 | 8.26 |
| FDW12 | 8.315 |
| FDW12 | 8.315 |


My current code data frame:?train <- read.csv("Train.csv", header=T,sep = ",",na.strings = c(""," ",NA))


Some people suggest to use na.locf function but in my case, i don't have numeric unique values in my Item_Identifier coloumn but rather it's characters. Not sure what to solve this problem.


	[[alternative HTML version deleted]]


From art.tem.us at gmail.com  Wed Mar 15 15:56:14 2017
From: art.tem.us at gmail.com (Art U)
Date: Wed, 15 Mar 2017 10:56:14 -0400
Subject: [R] Correlated variables
Message-ID: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>

Hi,

I'm trying to create binary variable which distribution conditioned on
other variables. That is what I did,

x1=rnorm(n,0,1);
x2=rnorm(n,0,1);
x3=rnorm(n,0,1);
if(x1+x2-x3>0.25){
  t=rbinom(1, 1, prob=0.25)
}else{
  t=rbinom(1, 1, prob=0.5)
}

But I always get this the warning:

Warning message:In if (x1 + x2 - x3 > 0.5) { :
  the condition has length > 1 and only the first element will be used


Can I do this without using function "for"?

Thank you in advance.
Ariel
-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From l.leemann at essex.ac.uk  Wed Mar 15 16:32:39 2017
From: l.leemann at essex.ac.uk (Leemann, Lucas T)
Date: Wed, 15 Mar 2017 15:32:39 +0000
Subject: [R] mood.test/mood.medtest
Message-ID: <4B3E26DC-6274-46C9-8442-AA54DCD3B71A@essex.ac.uk>

Hello,

I was trying to test whether two medians are identical or not and used the function ?mood.test? from the ?stats" package. My co-author, a medical doctor, was trying to do the same in SPSS and had different results. 

I wanted to see whether there was a problem on my end and also used the function ?mood.medtest? from the ?RVAideMemoire? package. I find different results while I am under the impression that both functions claim to carry out the same test and have the same defaults. While my actual data is sensitive medical information, I provide simple code below for a reproducible example. 

library(RVAideMemoire)
set.seed(123)
a <- runif(100)
b <- runif(120,0.2,1.1)
indicator <- c(rep(0,100),rep(1,120))
x <- c(a,b)
mood.test(x ~ indicator)
mood.medtest(x ~ indicator)

Has anybody encounter this problem before or would be able to provide any insights?

Best wishes,
Lucas






From ashley.patton at aol.co.uk  Wed Mar 15 16:28:34 2017
From: ashley.patton at aol.co.uk (Ashley Patton)
Date: Wed, 15 Mar 2017 11:28:34 -0400
Subject: [R] Crete stats course
In-Reply-To: <CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
Message-ID: <15ad295c34e-40b-1bf0@webstg-m07.mail.aol.com>

True, but if I may put in my two pennies worth, for novices like me it is useful to know about these things.



-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com>
To: Highland Statistics Ltd <highstat at highstat.com>
CC: R-help <r-help at r-project.org>
Sent: Wed, 15 Mar 2017 14:59
Subject: Re: [R] Crete stats course

Perhaps this has been asked and settled before, but while such courses
certainly might be of interest to those who read this list, they are
for profit, and therefore advertising them here does seem somewhat
inappropriate.

Please, I don't want to start a long discussion or war. Just slap me
down if I am wrong about this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 15, 2017 at 2:14 AM, Highland Statistics Ltd
<highstat at highstat.com> wrote:
> There are a few remaining seats on the following course:
>
>
>
> Course: Data exploration, regression, GLM & GAM with R
>
> Where:  HCMR, Crete, Greece
>
> When:   24-28 April 2017
>
> Course website: http://www.highstat.com/statscourse.htm
>
> Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf
>
>
> Kind regards,
>
> Alain Zuur
>
>
> Other open courses in 2017:
>
> Introduction to Regression Models with Spatial and Temporal Correlation.
> 8-12 May 2017. Genoa, Italy.
> Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian
> approaches. 9-13 October 2017. Trondheim, Norway.
> Introduction to Regression Models with Spatial and Temporal Correlation.
> 23-27 October 2017. Southampton, UK
> Data exploration, regression, GLM & GAM with introduction to R. 18-22
> September 2017. Edmonton, Canada.
> Introduction to Regression Models with Spatial and Temporal Correlation. 4-8
> December 2017. Banff, Canada.
>
>
>
>
>
>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Wed Mar 15 18:27:46 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 15 Mar 2017 17:27:46 +0000
Subject: [R] Crete stats course
In-Reply-To: <4acd152d-3e05-93df-5276-770d4d932d08@highstat.com>
References: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
	<CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
	<4acd152d-3e05-93df-5276-770d4d932d08@highstat.com>
Message-ID: <f44f4fb2-d80a-a303-ca82-436840f33375@dewey.myzen.co.uk>

Well since you mention it the mailing list page says

The ?main? R mailing list, for discussion about problems and solutions 
using R, announcements (not covered by ?R-announce? or ?R-packages?, see 
above), about the availability of new functionality for R and 
documentation of R, comparison and compatibility with S-plus, and for 
the posting of nice examples and benchmarks.

Which suggests to me that announcements of courses are not covered by 
the terms and conditions.

On 15/03/2017 16:09, Highland Statistics Ltd wrote:
>
> On 15/03/2017 16:57, Bert Gunter wrote:
>> Perhaps this has been asked and settled before, but while such courses
>> certainly might be of interest to those who read this list,
> Bert,
>>   they are
>> for profit, and therefore advertising them here does seem somewhat
>> inappropriate.
> I don't want to be rude or funny, but the general guidelines for this
> mailing list state "Do your homework before posting". There is nowhere a
> statement on the general guidelines that state that you cannot make an
> announcement for a course (which by the way, introduces R to people who
> never have used R before)....be it for profit or not. And even if it
> would have such a statement, I don't think that a 'once per quarter'
> email about an R course does much harm.
>
> Apologies to everyone else for filling up your mailbox. Bert....if you
> would like to discuss this further then please email me directly and I
> will send a summary to the list later.
>
> Kind regards,
>
> Alain
>
>> Please, I don't want to start a long discussion or war. Just slap me
>> down if I am wrong about this.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Mar 15, 2017 at 2:14 AM, Highland Statistics Ltd
>> <highstat at highstat.com> wrote:
>>> There are a few remaining seats on the following course:
>>>
>>>
>>>
>>> Course: Data exploration, regression, GLM & GAM with R
>>>
>>> Where:  HCMR, Crete, Greece
>>>
>>> When:   24-28 April 2017
>>>
>>> Course website: http://www.highstat.com/statscourse.htm
>>>
>>> Course flyer:
>>> http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf
>>>
>>>
>>> Kind regards,
>>>
>>> Alain Zuur
>>>
>>>
>>> Other open courses in 2017:
>>>
>>> Introduction to Regression Models with Spatial and Temporal Correlation.
>>> 8-12 May 2017. Genoa, Italy.
>>> Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian
>>> approaches. 9-13 October 2017. Trondheim, Norway.
>>> Introduction to Regression Models with Spatial and Temporal Correlation.
>>> 23-27 October 2017. Southampton, UK
>>> Data exploration, regression, GLM & GAM with introduction to R. 18-22
>>> September 2017. Edmonton, Canada.
>>> Introduction to Regression Models with Spatial and Temporal
>>> Correlation. 4-8
>>> December 2017. Banff, Canada.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> Dr. Alain F. Zuur
>>>
>>> First author of:
>>> 1. Beginner's Guide to GAMM with R (2014).
>>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>>> 3. Beginner's Guide to GAM with R (2012).
>>> 4. Zero Inflated Models and GLMM with R (2012).
>>> 5. A Beginner's Guide to R (2009).
>>> 6. Mixed effects models and extensions in ecology with R (2009).
>>> 7. Analysing Ecological Data (2007).
>>>
>>> Highland Statistics Ltd.
>>> 9 St Clair Wynd
>>> UK - AB41 6DZ Newburgh
>>> Tel:   0044 1358 788177
>>> Email: highstat at highstat.com
>>> URL:   www.highstat.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tmrsg11 at gmail.com  Wed Mar 15 18:41:07 2017
From: tmrsg11 at gmail.com (C W)
Date: Wed, 15 Mar 2017 13:41:07 -0400
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
	<CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>
	<CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>
Message-ID: <CAE2FW2noQ4Ju7L5ZJ-cr+soyTPZ+dQRJw6r9P5yDZeyf7N7Quw@mail.gmail.com>

Thanks Herv?, Bert, and Yihui.

I installed ImageMagick using the Bert link provided.

I am still not able to produce gif.

The saveGIF() example, from
https://cran.r-project.org/web/packages/animation/animation.pdf

saveGIF({
 for (i in 1:10) plot(runif(10), ylim = 0:1)
})

However, my for loop is INSIDE plot, for example,
saveGIF({plot(-4:4, -4:4, type = "n")

for(i in 1:10){
  x[i] <- rnorm(1)
  y[i] <- rnorm(1)
  points(x[i], y[i])

}
})

Is this possible?


On Wed, Mar 15, 2017 at 8:58 AM, Yihui Xie <xie at yihui.name> wrote:

> I'm the author of the animation package, and I do plan to switch to
> the magick package in the future instead of using ImageMagick as a
> system dependency.
>
> Regards,
> Yihui
> --
> https://yihui.name
>
>
> On Wed, Mar 15, 2017 at 12:32 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > A google search on "ImageMagick Package R" brought this up, which
> > seems relevant:
> >
> > https://cran.r-project.org/web/packages/magick/vignettes/intro.html
> >
> > -- Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Mar 14, 2017 at 10:21 PM, C W <tmrsg11 at gmail.com> wrote:
> >> Dear list,
> >>
> >> I am trying to use saveGIF() from library animation.
> >> https://cran.r-project.org/web/packages/animation/animation.pdf
> >>
> >> saveGIF() has dependency on package ImageMagick.
> >>
> >> I got the following,
> >>> install.packages("ImageMagick")
> >> Warning in install.packages :
> >>   package ?ImageMagick? is not available (for R version 3.3.2)
> >>
> >> Does that mean I can't use saveGIF() anymore? It seems that this is the
> >> only package capable in R.
> >>
> >> Thank you in advance!
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Mar 15 19:07:46 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 15 Mar 2017 18:07:46 +0000
Subject: [R] Correlated variables
In-Reply-To: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>
References: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>
Message-ID: <d7b9f448b72143f685bf081863e49d69@exch-2p-mbx-w2.ads.tamu.edu>

You will have to use a for loop if you insist on using control statements such as if-else. You should really read up on the ifelse() function and vectorization in R:

> set.seed(42) # So your results will match these
> n <- 25
> x1 <- rnorm(n, 0, 1)
> x2 <- rnorm(n, 0, 1)
> x3 <- rnorm(n, 0, 1)
> prb <- ifelse(x1 + x2 - x3 > .25, .25, .5)
> prb
 [1] 0.25 0.50 0.50 0.25 0.50 0.50 0.25 0.25 0.25 0.50 0.50 0.25 0.50 0.50
[15] 0.25 0.50 0.50 0.50 0.50 0.50 0.25 0.50 0.25 0.25 0.25
> t <- rbinom(n, 1, prob=prb)
> t
 [1] 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0

?ifelse
?Control
?rbinom

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Art U
Sent: Wednesday, March 15, 2017 9:56 AM
To: r-help at r-project.org
Subject: [R] Correlated variables

Hi,

I'm trying to create binary variable which distribution conditioned on
other variables. That is what I did,

x1=rnorm(n,0,1);
x2=rnorm(n,0,1);
x3=rnorm(n,0,1);
if(x1+x2-x3>0.25){
  t=rbinom(1, 1, prob=0.25)
}else{
  t=rbinom(1, 1, prob=0.5)
}

But I always get this the warning:

Warning message:In if (x1 + x2 - x3 > 0.5) { :
  the condition has length > 1 and only the first element will be used


Can I do this without using function "for"?

Thank you in advance.
Ariel
-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From highstat at highstat.com  Wed Mar 15 19:14:13 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 15 Mar 2017 20:14:13 +0200
Subject: [R] Crete stats course
In-Reply-To: <f44f4fb2-d80a-a303-ca82-436840f33375@dewey.myzen.co.uk>
References: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
	<CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
	<4acd152d-3e05-93df-5276-770d4d932d08@highstat.com>
	<f44f4fb2-d80a-a303-ca82-436840f33375@dewey.myzen.co.uk>
Message-ID: <104461f7-b530-b8a7-ecc4-d83a2acb3c47@highstat.com>



> Well since you mention it the mailing list page says
>
> The ?main? R mailing list, for discussion about problems and solutions 
> using R, announcements (not covered by ?R-announce? or ?R-packages?, 
> see above), about the availability of new functionality for R and 
> documentation of R, comparison and compatibility with S-plus, and for 
> the posting of nice examples and benchmarks.
>
> Which suggests to me that announcements of courses are not covered by 
> the terms and conditions.

I see a comma after the word 'announcement'.  So..please clarify how an 
'announcement of courses' does not fall under 'announcement'.

The text describing the use of the mailing list wasn't written with "the 
expression of one thing is the exclusion of the other " in mind. There 
is a Latin expression for that.

For example, the word 'primarily" in the sentence  "The R mailing lists 
are primarily intended for questions and discussion about the R 
software."  doesn't mean that it cannot me used for a course 
announcement. Would it have said "exclusively" then it is a different 
story.


Expressio Unius Est Exclusio Alterius ......



Anyway.......let's not waste more time on this.

Alain




>
> On 15/03/2017 16:09, Highland Statistics Ltd wrote:
>>
>> On 15/03/2017 16:57, Bert Gunter wrote:
>>> Perhaps this has been asked and settled before, but while such courses
>>> certainly might be of interest to those who read this list,
>> Bert,
>>>   they are
>>> for profit, and therefore advertising them here does seem somewhat
>>> inappropriate.
>> I don't want to be rude or funny, but the general guidelines for this
>> mailing list state "Do your homework before posting". There is nowhere a
>> statement on the general guidelines that state that you cannot make an
>> announcement for a course (which by the way, introduces R to people who
>> never have used R before)....be it for profit or not. And even if it
>> would have such a statement, I don't think that a 'once per quarter'
>> email about an R course does much harm.
>>
>> Apologies to everyone else for filling up your mailbox. Bert....if you
>> would like to discuss this further then please email me directly and I
>> will send a summary to the list later.
>>
>> Kind regards,
>>
>> Alain
>>
>>> Please, I don't want to start a long discussion or war. Just slap me
>>> down if I am wrong about this.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Mar 15, 2017 at 2:14 AM, Highland Statistics Ltd
>>> <highstat at highstat.com> wrote:
>>>> There are a few remaining seats on the following course:
>>>>
>>>>
>>>>
>>>> Course: Data exploration, regression, GLM & GAM with R
>>>>
>>>> Where:  HCMR, Crete, Greece
>>>>
>>>> When:   24-28 April 2017
>>>>
>>>> Course website: http://www.highstat.com/statscourse.htm
>>>>
>>>> Course flyer:
>>>> http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf
>>>>
>>>>
>>>> Kind regards,
>>>>
>>>> Alain Zuur
>>>>
>>>>
>>>> Other open courses in 2017:
>>>>
>>>> Introduction to Regression Models with Spatial and Temporal 
>>>> Correlation.
>>>> 8-12 May 2017. Genoa, Italy.
>>>> Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian
>>>> approaches. 9-13 October 2017. Trondheim, Norway.
>>>> Introduction to Regression Models with Spatial and Temporal 
>>>> Correlation.
>>>> 23-27 October 2017. Southampton, UK
>>>> Data exploration, regression, GLM & GAM with introduction to R. 18-22
>>>> September 2017. Edmonton, Canada.
>>>> Introduction to Regression Models with Spatial and Temporal
>>>> Correlation. 4-8
>>>> December 2017. Banff, Canada.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> -- 
>>>> Dr. Alain F. Zuur
>>>>
>>>> First author of:
>>>> 1. Beginner's Guide to GAMM with R (2014).
>>>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>>>> 3. Beginner's Guide to GAM with R (2012).
>>>> 4. Zero Inflated Models and GLMM with R (2012).
>>>> 5. A Beginner's Guide to R (2009).
>>>> 6. Mixed effects models and extensions in ecology with R (2009).
>>>> 7. Analysing Ecological Data (2007).
>>>>
>>>> Highland Statistics Ltd.
>>>> 9 St Clair Wynd
>>>> UK - AB41 6DZ Newburgh
>>>> Tel:   0044 1358 788177
>>>> Email: highstat at highstat.com
>>>> URL:   www.highstat.com
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From wdunlap at tibco.com  Wed Mar 15 19:16:49 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Mar 2017 11:16:49 -0700
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
In-Reply-To: <1994411336.523592.1489576114011@mail.yahoo.com>
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
	<1994411336.523592.1489576114011@mail.yahoo.com>
Message-ID: <CAF8bMcaa0iKdJ8zRdAWFjRJ0ZXVQOcxZ+8VSLoWWRWma63oqZQ@mail.gmail.com>

You could use the following function

locf2 <- function(x, initial=NA, IS_BAD = is.na) {
    # Replace 'bad' values in 'x' with last previous non-bad value.
    # If no previous non-bad value, replace with 'initial'.
    stopifnot(is.function(IS_BAD))
    good <- !IS_BAD(x)
    stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
    i <- cumsum(good)
    x <- x[c(1,which(good))][i+1]
    x[i==0] <- initial
    x
}

as in

> locf2(c("", "A", "B", "", "", "C", ""), IS_BAD=function(x)x=="", initial="---")
[1] "---" "A"   "B"   "B"   "B"   "C"   "C"
> locf2(factor(c(NA,"Small","Medium",NA,"Large",NA,NA,NA,"Small")))
[1] <NA>   Small  Medium Medium Large  Large  Large  Large  Small
Levels: Large Medium Small
> locf2(c(12, NA, 10, 11, NA, NA))
[1] 12 12 10 11 11 11

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 15, 2017 at 4:08 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> The following is an example:
>
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 |  |
> | DRI11 | 8.26 |
> | DRI11 |  |
> | FDW12 | 8.315 |
> | FDW12 |  |
>
>
> The following is the one that i want to be. That is, filling NA values from the previous Non-NA values.
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 | 19 |
> | DRI11 | 8.26 |
> | DRI11 | 8.26 |
> | FDW12 | 8.315 |
> | FDW12 | 8.315 |
>
>
> My current code data frame: train <- read.csv("Train.csv", header=T,sep = ",",na.strings = c(""," ",NA))
>
>
> Some people suggest to use na.locf function but in my case, i don't have numeric unique values in my Item_Identifier coloumn but rather it's characters. Not sure what to solve this problem.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Wed Mar 15 19:51:31 2017
From: tmrsg11 at gmail.com (C W)
Date: Wed, 15 Mar 2017 14:51:31 -0400
Subject: [R] Is ImageMagick package not compatible with R 3.3.2?
In-Reply-To: <CAE2FW2noQ4Ju7L5ZJ-cr+soyTPZ+dQRJw6r9P5yDZeyf7N7Quw@mail.gmail.com>
References: <CAE2FW2=ajpru7b53uYV-5NkSQxfXoTC2R-zMuqUg9zjCaZPzug@mail.gmail.com>
	<CAGxFJbQAi-YwLi5Z2DPmMXUyAfEkehVg9k310HSWbEvMW3LJ7w@mail.gmail.com>
	<CANROs4ffnhK8ET0CtAELRm9WV1ECG0=9oH8jEiB8UMquxJ3-kw@mail.gmail.com>
	<CAE2FW2noQ4Ju7L5ZJ-cr+soyTPZ+dQRJw6r9P5yDZeyf7N7Quw@mail.gmail.com>
Message-ID: <CAE2FW2=e-_KfQyY_6ECBBa8jriR9AdCVX_TPnN1w9ZY+emdiDg@mail.gmail.com>

I figured it out.  You can first do,

saveGIF({
  for (j in 1:20){
    plot(-4:4, -4:4, type = "n")
    for(i in 1:10){
      x[i] <- rnorm(1)
      y[i] <- rnorm(1)
      points(x[i], y[i])
    }
  }
 })

It looks like you have to re-plot every time.


On Wed, Mar 15, 2017 at 1:41 PM, C W <tmrsg11 at gmail.com> wrote:

> Thanks Herv?, Bert, and Yihui.
>
> I installed ImageMagick using the Bert link provided.
>
> I am still not able to produce gif.
>
> The saveGIF() example, from https://cran.r-project.org/
> web/packages/animation/animation.pdf
>
> saveGIF({
>  for (i in 1:10) plot(runif(10), ylim = 0:1)
> })
>
> However, my for loop is INSIDE plot, for example,
> saveGIF({plot(-4:4, -4:4, type = "n")
>
> for(i in 1:10){
>   x[i] <- rnorm(1)
>   y[i] <- rnorm(1)
>   points(x[i], y[i])
>
> }
> })
>
> Is this possible?
>
>
> On Wed, Mar 15, 2017 at 8:58 AM, Yihui Xie <xie at yihui.name> wrote:
>
>> I'm the author of the animation package, and I do plan to switch to
>> the magick package in the future instead of using ImageMagick as a
>> system dependency.
>>
>> Regards,
>> Yihui
>> --
>> https://yihui.name
>>
>>
>> On Wed, Mar 15, 2017 at 12:32 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> > A google search on "ImageMagick Package R" brought this up, which
>> > seems relevant:
>> >
>> > https://cran.r-project.org/web/packages/magick/vignettes/intro.html
>> >
>> > -- Bert
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Tue, Mar 14, 2017 at 10:21 PM, C W <tmrsg11 at gmail.com> wrote:
>> >> Dear list,
>> >>
>> >> I am trying to use saveGIF() from library animation.
>> >> https://cran.r-project.org/web/packages/animation/animation.pdf
>> >>
>> >> saveGIF() has dependency on package ImageMagick.
>> >>
>> >> I got the following,
>> >>> install.packages("ImageMagick")
>> >> Warning in install.packages :
>> >>   package ?ImageMagick? is not available (for R version 3.3.2)
>> >>
>> >> Does that mean I can't use saveGIF() anymore? It seems that this is the
>> >> only package capable in R.
>> >>
>> >> Thank you in advance!
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Mar 15 20:13:33 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 16 Mar 2017 08:13:33 +1300
Subject: [R] [FORGED] Re:  Crete stats course
In-Reply-To: <CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
References: <248386f9-5529-275e-ab4a-9a44b0cf8dd7@highstat.com>
	<CAGxFJbQma=D2YjjaHK2E5wLPfENP-6bv+oBJs5LLKPRrzjH7gQ@mail.gmail.com>
Message-ID: <8fc348e0-07a2-e9cb-9cd8-4404631cd0ea@auckland.ac.nz>

On 16/03/17 03:57, Bert Gunter wrote:
> Perhaps this has been asked and settled before, but while such courses
> certainly might be of interest to those who read this list, they are
> for profit, and therefore advertising them here does seem somewhat
> inappropriate.
>
> Please, I don't want to start a long discussion or war. Just slap me
> down if I am wrong about this.


I have a *vague* recollection that it *has* been asked before and that 
there was a consensus, or a pronouncement from R core (or a combination 
of the two; or something like that) that such announcements were OK as 
long as they were reasonably brief and not overly frequent.  Or 
something like that.

It seems to me that the Highland Statistics ads fall within these 
vaguely remembered guidelines.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ruipbarradas at sapo.pt  Wed Mar 15 21:00:35 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 15 Mar 2017 20:00:35 +0000
Subject: [R] How to get the date generated by the forecast function as
 another field in a data frame
In-Reply-To: <CAMOcQfOdce0xU5z_aHZb33FJUkrdm72Ao1J4R7B8LGRf4DDLHQ@mail.gmail.com>
References: <CAMOcQfOG=YB3TY-i=YKX64mYjyBgLvZ2d0v8Sk4Kpq159Vi9NQ@mail.gmail.com>
	<58C96634.30709@sapo.pt>
	<CAMOcQfOdce0xU5z_aHZb33FJUkrdm72Ao1J4R7B8LGRf4DDLHQ@mail.gmail.com>
Message-ID: <58C99D63.7010001@sapo.pt>

Hello,

This does what you want.

rownames(as.data.frame(TSSeriesModel1Forecast))

Hope this helps,

Rui Barradas

Em 15-03-2017 16:24, Paul Bernal escreveu:
> Hello Rui,
>
> I have attached the .csv file, I will attach it again.
>
> Please let me know if you can access it.
>
> Cheers,
>
> Paul
>
> 2017-03-15 11:05 GMT-05:00 Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>>:
>
>     Hello,
>
>     Since we don't have access to file ContainerDataNEW.csv I cannot say
>     for sure but it seems that those dates are the rownames so you could try
>
>     rownames(TSSeriesModel1Forecast)
>
>     and see what it gives. Or I might be completely mistaken.
>
>     Hope this helps,
>
>     Rui Barradas
>
>
>     Em 15-03-2017 15:50, Paul Bernal escreveu:
>
>         Dear all,
>
>         I am currently using R for windows Version 3.3.3 (I will provide the
>         sessionInfo() output below)
>
>             library("Rcmdr")
>
>         Loading required package: splines
>         Loading required package: RcmdrMisc
>         Loading required package: car
>         Loading required package: sandwich
>
>         Rcmdr Version 2.3-2
>
>             library(forecast)
>
>             library(tseries)
>
>
>               'tseries' version: 0.10-35
>
>               'tseries' is a package for time series analysis and
>         computational
>               finance.
>
>               See 'library(help="tseries")' for details.
>
>             library(stats)
>
>             library(stats4)
>
>             Data<-read.csv("ContainerDataNEW.csv")
>
>             TSData<-ts(Data[,1], start=c(1985,10), frequency=12)
>
>             TSeriesModel1<-ets(TSData)
>
>             TSSeriesModel1Forecast<-forecast(TSeriesModel1,h=24)
>
>
>         Now the output from forecasts is the following:
>
>                           Point Forecast    Lo 80    Hi 80       Lo 95
>                   Hi 95
>         Apr 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         May 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Jun 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Jul 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Aug 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Sep 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Oct 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Nov 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Dec 2017       67.62845 30.73747 104.5194 11.20856 124.0483
>         Jan 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         Feb 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         Mar 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         Apr 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         May 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         Jun 2018       67.62845 30.73747 104.5194 11.20856 124.0483
>         Jul 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Aug 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Sep 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Oct 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Nov 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Dec 2018       67.62845 30.73747 104.5194 11.20856 124.0484
>         Jan 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>         Feb 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>         Mar 2019       67.62845 30.73747 104.5194 11.20856 124.0484
>
>         However, as you can see, the first "column" contains the dates
>         for the
>         forecasts, but it appears as a field with no name.
>
>         What I would like to do is to get those dates, add them as an
>         additional
>         column to the forecasts so that when I use the
>         data.frame(Forecasts) I can
>         have a result in this fashion:
>
>         Date              Point Forecast    Lo 80         Hi 80       Lo 95
>             Hi 95
>         Apr 2017       67.62845           30.73747 104.5194 11.20856
>           124.0483
>
>         Is there a way to do this?
>
>         Here is the sessionInfo() output:
>
>             sessionInfo()
>
>         R version 3.3.3 (2017-03-06)
>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>         Running under: Windows 8.1 x64 (build 9600)
>
>         locale:
>         [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>         States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>                             LC_TIME=English_United States.1252
>
>         attached base packages:
>         [1] stats4    splines   stats     graphics  grDevices utils
>           datasets
>            methods   base
>
>         other attached packages:
>         [1] tseries_0.10-35 forecast_8.0    Rcmdr_2.3-2     RcmdrMisc_1.0-5
>         sandwich_2.3-4  car_2.1-3
>
>         loaded via a namespace (and not attached):
>            [1] Rcpp_0.12.7         lattice_0.20-34     tcltk2_1.2-11
>         class_7.3-14        zoo_1.7-13          lmtest_0.9-35
>           relimp_1.0-5
>                assertthat_0.1      digest_0.6.11       R6_2.2.0
>            plyr_1.8.4
>
>         [12] acepack_1.4.1       MatrixModels_0.4-1  e1071_1.6-7
>           httr_1.2.1
>                    ggplot2_2.2.0       lazyeval_0.2.0      AzureML_0.2.13
>            curl_2.2            uuid_0.1-2          readxl_0.1.1
>         minqa_1.2.4
>
>         [23] data.table_1.10.4   SparseM_1.74        fracdiff_1.4-2
>            nloptr_1.0.4        rpart_4.1-10        Matrix_1.2-8
>         lme4_1.1-12
>                 stringr_1.1.0       foreign_0.8-67      munsell_0.4.3
>         base64enc_0.1-3
>         [34] mgcv_1.8-17         htmltools_0.3.5     tcltk_3.3.3
>         nnet_7.3-12         tibble_1.2          gridExtra_2.2.1
>           htmlTable_1.7
>               quadprog_1.5-5      Hmisc_4.0-2         codetools_0.2-15
>            XML_3.98-1.4
>         [45] MASS_7.3-45         grid_3.3.3          nlme_3.1-131
>            jsonlite_1.1        gtable_0.2.0        magrittr_1.5
>         scales_0.4.1
>                stringi_1.1.2       timeDate_3012.100   latticeExtra_0.6-28
>         Formula_1.2-1
>         [56] RColorBrewer_1.1-2  tools_3.3.3         abind_1.4-5
>         parallel_3.3.3      pbkrtest_0.4-6      survival_2.40-1
>         colorspace_1.3-0    cluster_2.0.5       miniCRAN_0.2.7
>         knitr_1.15
>                quantreg_5.29
>
>
>
>         I have also attached the file that I used to train the model and
>         generate
>         forecasts.
>
>         Any help will be greatly appreciated,
>
>         Best regards,
>
>         Paul
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Wed Mar 15 22:45:39 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Mar 2017 08:45:39 +1100
Subject: [R] Correlated variables
In-Reply-To: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>
References: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>
Message-ID: <CA+8X3fUejhk+84_puBupKh8hMVCyHA1v10CckhYmkP3yjmDmDQ@mail.gmail.com>

Hi Ariel,
It all depends upon n:

n<-2
x1=rnorm(n,0,1);
x2=rnorm(n,0,1);
x3=rnorm(n,0,1);
if(x1+x2-x3>0.25){
  t=rbinom(1, 1, prob=0.25)
}else{
  t=rbinom(1, 1, prob=0.5)
}
n<-1
x1=rnorm(n,0,1);
x2=rnorm(n,0,1);
x3=rnorm(n,0,1);
if(x1+x2-x3>0.25){
  t=rbinom(1, 1, prob=0.25)
}else{
  t=rbinom(1, 1, prob=0.5)
}

Jim


On Thu, Mar 16, 2017 at 1:56 AM, Art U <art.tem.us at gmail.com> wrote:
> Hi,
>
> I'm trying to create binary variable which distribution conditioned on
> other variables. That is what I did,
>
> x1=rnorm(n,0,1);
> x2=rnorm(n,0,1);
> x3=rnorm(n,0,1);
> if(x1+x2-x3>0.25){
>   t=rbinom(1, 1, prob=0.25)
> }else{
>   t=rbinom(1, 1, prob=0.5)
> }
>
> But I always get this the warning:
>
> Warning message:In if (x1 + x2 - x3 > 0.5) { :
>   the condition has length > 1 and only the first element will be used
>
>
> Can I do this without using function "for"?
>
> Thank you in advance.
> Ariel
> --
> *I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
> or plague*... *Whatever*. *No-one left to act normal for. No need to hide
> who I really am. It would be... freeing*. *...*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Wed Mar 15 23:34:18 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Thu, 16 Mar 2017 06:34:18 +0800
Subject: [R] Extract student ID that match certain criteria
In-Reply-To: <58C953C7.9000808@sapo.pt>
References: <ef1h337w0ry677ursnkyk5kf.1489384064772@email.android.com>
	<CANTvJZLN4EUnLtiW8MjJhyTDrgyaJFeU6+bEhcHUYV9hsBf0NQ@mail.gmail.com>
	<CANTvJZ+ef-dRdsVUQHfTmMLsPb+JcVqHWPSWDvFJQ_O_qXFGdA@mail.gmail.com>
	<58C953C7.9000808@sapo.pt>
Message-ID: <CANTvJZ+asMBVWN7JjOcf8PHoTz9mSGzJnCuf2zUzr28GEmBimg@mail.gmail.com>

Hi Rui,

Both functions work beautifully.

I really appreciate your help and others very much.

Thank you

On Wed, Mar 15, 2017 at 10:46 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I believe your request is a bit confusing since you say you want to filter
> the student id but then you have many years in dt_all3 and only one program
> ("IJAZAH SARJANA MUDA"). So I've written two simple functions, one to
> filter by year and the other by program.
>
>
> fun1 <- function(x, year){
>         inx <- substr(x[["STUDENT_ID"]], 3, 4) == as.character(year)
>         x[inx, ]
> }
>
> fun2 <- function(x, program){
>         inx <- x[["PROGRAM"]] == program
>         x[inx, ]
> }
>
> fun1(dt_all2, 14)  # filter by year = 14
> fun2(dt_all2, "IJAZAH SARJANA MUDA")
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 15-03-2017 13:49, roslinazairimah zakaria escreveu:
>
>> Hi Caitlin,
>>
>> I tried so many ways as suggested but unsuccessful...and I realise that I
>> need to filter the student ID and their CGPA, but if I change the ID into
>> character I lost the CGPA value.  It is easy to do in excel, however a bit
>> time consuming and trying to do in R.
>>
>> I have these data:
>>
>> dput(dt_all2)
>> structure(list(FAC_CODE = structure(c(2L, 2L, 2L, 4L, 1L, 1L,
>> 4L, 7L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 1L, 2L, 5L, 6L), .Label = c("FKASA",
>> "FKEE", "FKKSA", "FKM", "FKP", "FSKKP", "FTK"), class = "factor"),
>>      STUDENT_ID = structure(c(9L, 6L, 7L, 17L, 2L, 3L, 18L, 19L,
>>      13L, 12L, 14L, 15L, 16L, 10L, 8L, 1L, 5L, 11L, 4L), .Label =
>> c("AA14068",
>>      "AB15103", "AB15124", "CC14107", "EA13043", "EB14059", "EB14073",
>>      "EB14101", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
>>      "KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
>>      ), class = "factor"), PROGRAM = structure(c(2L, 1L, 1L, 2L,
>>      1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L
>>      ), .Label = c("DIPLOMA", "IJAZAH SARJANA MUDA"), class = "factor"),
>>      CGPA = c(2.42, 3.27, 1.98, 2.85, 2.24, 3.01, 3.31, 2.88,
>>      3.61, 3.69, 3.2, 3.85, 3.63, 2.67, 2.35, 2.74, 1.96, 2.89,
>>      2.59)), .Names = c("FAC_CODE", "STUDENT_ID", "PROGRAM", "CGPA"
>> ), class = "data.frame", row.names = c(NA, -19L))
>>
>> and I want to filter my data as follows:
>>
>> dput(dt_all3)
>>>
>> structure(list(FAC_CODE = structure(c(2L, 2L, 4L, 4L, 5L, 1L,
>> 6L, 3L, 3L, 3L, 3L, 3L, 2L), .Label = c("FKASA", "FKEE", "FKKSA",
>> "FKM", "FKP", "FTK"), class = "factor"), STUDENT_ID = structure(c(4L,
>> 3L, 11L, 12L, 5L, 1L, 13L, 7L, 6L, 8L, 9L, 10L, 2L), .Label = c("AA14068",
>> "EA13043", "EC14021", "EC15063", "FB14085", "KA13142", "KA13143",
>> "KA13156", "KE13034", "KE13046", "MA14071", "MA14115", "PA13048"
>> ), class = "factor"), PROGRAM = structure(c(1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "IJAZAH SARJANA MUDA", class =
>> "factor"),
>>      CGPA = c(2.67, 2.42, 2.85, 3.31, 2.89, 2.74, 2.88, 3.61,
>>      3.69, 3.2, 3.85, 3.63, 1.96)), .Names = c("FAC_CODE", "STUDENT_ID",
>> "PROGRAM", "CGPA"), class = "data.frame", row.names = c(NA, -13L
>> ))
>>
>> I would like to select the student id where the third and fourth value
>> represent the year they register data is eg. AA15..., AE14,... and I would
>> also to select their cgpa value.
>>
>> Thank you.
>>
>> On Mon, Mar 13, 2017 at 2:26 PM, roslinazairimah zakaria <
>> roslinaump at gmail.com> wrote:
>>
>> Thank you so much for your help.
>>>
>>> On Mon, Mar 13, 2017 at 1:52 PM, bioprogrammer <bioprogrammer at gmail.com>
>>> wrote:
>>>
>>> Hi.
>>>>
>>>> I would use the "substr" function:
>>>>
>>>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/substr.html
>>>>
>>>> ...assuming you're working with character data.
>>>>
>>>> Another useful skill involves working with regular expressions.
>>>>
>>>> http://www.endmemo.com/program/R/grep.php
>>>>
>>>> http://regular-expressions.mobi/tutorial.html
>>>>
>>>> Hope these help :)
>>>>
>>>> ~Caitlin
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Sent from my T-Mobile 4G LTE Device
>>>>
>>>>
>>>> -------- Original message --------
>>>> From: roslinazairimah zakaria <roslinaump at gmail.com>
>>>> Date:03/12/2017 10:18 PM (GMT-07:00)
>>>> To: Bert Gunter <bgunter.4567 at gmail.com>
>>>> Cc: r-help mailing list <r-help at r-project.org>
>>>> Subject: Re: [R] Extract student ID that match certain criteria
>>>>
>>>> Another question,
>>>>
>>>> How do I extract ID based on the third and fourth letter:
>>>>
>>>> I have for example, AA14004, AB15035, CB14024, PA14009, PA14009 etc
>>>>
>>>> I would like to extract ID no. of AB14..., CB14..., PA14...
>>>>
>>>> On Mon, Mar 13, 2017 at 12:37 PM, roslinazairimah zakaria <
>>>> roslinaump at gmail.com> wrote:
>>>>
>>>> Hi Bert,
>>>>>
>>>>> Thank you so much for your help.  However I don't really sure what is
>>>>>
>>>> the
>>>>
>>>>> use of y values.  Can we do without it?
>>>>>
>>>>> x <- as.character(FKASA$STUDENT_ID)
>>>>> y <- c(1,786)
>>>>> My.Data <- data.frame (x,y)
>>>>>
>>>>> My.Data[grep("^AA14", My.Data$x), ]
>>>>>
>>>>> I got the following data:
>>>>>
>>>>>            x   y
>>>>> 1   AA14068   1
>>>>> 7   AA14090   1
>>>>> 11  AA14099   1
>>>>> 14  AA14012 786
>>>>> 15  AA14039   1
>>>>> 22  AA14251 786
>>>>>
>>>>> On Mon, Mar 13, 2017 at 11:51 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> 1. Your code is incorrect. All entries are character strings and must
>>>>>>
>>>>> be
>>>>
>>>>> quoted.
>>>>>>
>>>>>> 2. See ?grep  and note in particular (in the "Value" section):
>>>>>>
>>>>>> "grep(value = TRUE) returns a character vector containing the selected
>>>>>> elements of x (after coercion, preserving names but no other
>>>>>> attributes)."
>>>>>>
>>>>>>
>>>>>> 3. While the fixed = TRUE option will work here, you may wish to learn
>>>>>> about "regular expressions", which can come in very handy for
>>>>>> character string manipulation tasks. ?regex in R has a terse, but I
>>>>>> have found comprehensible, discussion. There are many good gentler
>>>>>> tutorials on the web, also.
>>>>>>
>>>>>>
>>>>>> Cheers,
>>>>>> Bert
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Sun, Mar 12, 2017 at 8:32 PM, roslinazairimah zakaria
>>>>>> <roslinaump at gmail.com> wrote:
>>>>>>
>>>>>>> Dear r-users,
>>>>>>>
>>>>>>> I have this list of student ID,
>>>>>>>
>>>>>>> dt <- c(AA14068, AA13194, AE11054, AA12251, AA13228, AA13286,
>>>>>>>
>>>>>> AA14090,
>>>>
>>>>> AA13256, AA13260, AA13291, AA14099, AA15071, AA13143, AA14012,
>>>>>>>
>>>>>> AA14039,
>>>>
>>>>> AA15018, AA13234, AA13149, AA13282, AA13218)
>>>>>>>
>>>>>>> and I would like to extract all student of ID AA14... only.
>>>>>>>
>>>>>>> I search and tried substrt, subset and select but it fail.
>>>>>>>
>>>>>>>   substr(FKASA$STUDENT_ID, 2, nchar(string1))
>>>>>>> Error in nchar(string1) : 'nchar()' requires a character vector
>>>>>>>
>>>>>>>> subset(FKASA, STUDENT_ID=="AA14" )
>>>>>>>>
>>>>>>>   [1] FAC_CODE    FACULTY     STUDENT_ID  NAME        PROGRAM
>>>>>>>
>>>>>> KURSUS
>>>>
>>>>>   CGPA        ACT_SS      ACT_VAL     ACT_CS      ACT_LED     ACT_PS
>>>>>>>   ACT_IM
>>>>>>> [14] ACT_ENT     ACT_CRE     ACT_UNI     ACT_VOL...
>>>>>>>
>>>>>>> Thank you so much for your help.
>>>>>>>
>>>>>>> How do I do it?
>>>>>>> --
>>>>>>> *Roslinazairimah Zakaria*
>>>>>>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>>>>>>>
>>>>>> <+60%209-549%202766>*
>>>>
>>>>>
>>>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>>>>> Faculty of Industrial Sciences & Technology
>>>>>>> University Malaysia Pahang
>>>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>>>>
>>>>>> ng-guide.html
>>>>>>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> *Roslinazairimah Zakaria*
>>>>> *Tel: +609-5492370 <+60%209-549%202370> <+60%209-549%202370>; Fax. No.
>>>>>
>>>> +609-5492766 <+60%209-549%202766>
>>>>
>>>> <+60%209-549%202766>*
>>>>>
>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>>> Faculty of Industrial Sciences & Technology
>>>>> University Malaysia Pahang
>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> *Roslinazairimah Zakaria*
>>>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>>>> <+60%209-549%202766>*
>>>>
>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>> Faculty of Industrial Sciences & Technology
>>>> University Malaysia Pahang
>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>> --
>>> *Roslinazairimah Zakaria*
>>> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
>>> <+60%209-549%202766>*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>>
>>
>>
>>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Wed Mar 15 23:41:13 2017
From: valkremk at gmail.com (Val)
Date: Wed, 15 Mar 2017 17:41:13 -0500
Subject: [R] screen
Message-ID: <CAJOiR6bUsfZV+f6RMUn9pdRqQ476jqm4ao9b+O-oZ2rXHen72Q@mail.gmail.com>

HI all,

I have some data to be screened  based on the recording flag (obs).
Some family recorded properly (1) and others not (0).  Th 0 = improper
and 1 = proper

The recording  period starts week1.  All families may not start in the
same week in recording properly an observation,

  DF2 <- read.table(header=TRUE, text='family time obs
A  WEEK1 0
A  WEEK1 0
A  WEEK1 0
A  WEEK2 1
A  WEEK2 0
A  WEEK3 1
A  WEEK3 0
B  WEEK1 1
B  WEEK1 0
B  WEEK1 1
B  WEEK2 0
B  WEEK2 0
B  WEEK3 1
B  WEEK3 0
C  WEEK3 0
C  WEEK3 0
C  WEEK4 1
C  WEEK4 1')

Example, in week1  all records of family "A" are 0 (improper), but
starting the week2 they start recording proper (1) records as well.
Then I create a table that shows me the ratio of proper records to the
total records for each family within week. If the ratio is zero and
there is no prior proper recordings for that family then I want to
delete those records.

However,  once any family started showing proper records  as "1"  and
even if in the  the subsequent week the ratio is 0  then I want keep
that record for that family. Example records of week2 for family B

Here is the summary table

      WEEK1      WEEK2    WEEK3    WEEK4
A          0            0.5              0.5           .
B       0.33           0                0.5           .
C          .               .                 0            1

>From the above table
For A-  I want exclude all records of week1 and keep the rest. Because
they were not recording it propeller
For B-  Keep all records, as they stated recording properly from the beginning.
For C-  Keep only the week4 records because all records are  1's

Final and desired  result will be

A WEEK2 1
A WEEK2 0
A WEEK3 1
A WEEK3 0
B WEEK1 1
B WEEK1 0
B WEEK1 1
B WEEK2 0
B WEEK2 0
B WEEK3 1
B WEEK3 0
C WEEK4 1
C WEEK4 1


and the summary table looks like as follows

       WEEK1  WEEK2  WEEK3  WEEK4
A             .        0.5             0.5        .
B          0.33        0             0.5        .
C               .          .                 .        1

Thank you in advance


From dcarlson at tamu.edu  Wed Mar 15 19:28:26 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 15 Mar 2017 18:28:26 +0000
Subject: [R] Correlated variables
In-Reply-To: <CAKY_brHKbTB5tGd6KdLDYMEO-4ARGe-jLHgbhj+grmpw3B3bYw@mail.gmail.com>
References: <CAKY_brE9fCzNQ2ROLGmkcTthzEEYhcDH0aU97wP9GNKzZUhLCw@mail.gmail.com>
	<d7b9f448b72143f685bf081863e49d69@exch-2p-mbx-w2.ads.tamu.edu>
	<CAKY_brHKbTB5tGd6KdLDYMEO-4ARGe-jLHgbhj+grmpw3B3bYw@mail.gmail.com>
Message-ID: <fac37e0208db479f92407ac2fd3d9a3c@exch-2p-mbx-w2.ads.tamu.edu>

Don't put a function inside ifelse(). It will only be executed once and the value repeated. But rbinom() will accept a vector of probabilities so use ifelse() to create a vector of probabilities for rbinom():

> set.seed(42)
> x <- c(0, 1, 0, 1, 0)
# The next 3 will give different results each time, but
# all the 0 values will be the same and all the 1 values
# will be the same
> ifelse(x == 0, rbinom(1, 1, .5), rbinom(1, 1, .1))
[1] 1 1 1 1 1
> ifelse(x == 0, rbinom(1, 1, .5), rbinom(1, 1, .1))
[1] 0 0 0 0 0
> ifelse(x == 0, rbinom(1, 1, .5), rbinom(1, 1, .1))
[1] 1 0 1 0 1
> ifelse(x == 0, rbinom(1, 1, .5), rbinom(1, 1, .1))
[1] 1 0 1 0 1
# Now each value will vary
> prb <- ifelse(x == 0, .5, .1)
> rbinom(5, 1, prob=prb)
[1] 1 0 0 0 1
> rbinom(5, 1, prob=prb)
[1] 0 0 1 1 0
> rbinom(5, 1, prob=prb)
[1] 0 0 1 0 1
> rbinom(5, 1, prob=prb)
[1] 1 0 1 0 1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




From: Art U [mailto:art.tem.us at gmail.com] 
Sent: Wednesday, March 15, 2017 1:14 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Correlated variables

I have tried to use ifelse function, but its output in many runs gives vector of only zeros or ones, while usage of loops always provides diversity in vector.

On Wed, Mar 15, 2017 at 2:07 PM, David L Carlson <dcarlson at tamu.edu> wrote:
You will have to use a for loop if you insist on using control statements such as if-else. You should really read up on the ifelse() function and vectorization in R:

> set.seed(42) # So your results will match these
> n <- 25
> x1 <- rnorm(n, 0, 1)
> x2 <- rnorm(n, 0, 1)
> x3 <- rnorm(n, 0, 1)
> prb <- ifelse(x1 + x2 - x3 > .25, .25, .5)
> prb
?[1] 0.25 0.50 0.50 0.25 0.50 0.50 0.25 0.25 0.25 0.50 0.50 0.25 0.50 0.50
[15] 0.25 0.50 0.50 0.50 0.50 0.50 0.25 0.50 0.25 0.25 0.25
> t <- rbinom(n, 1, prob=prb)
> t
?[1] 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0

?ifelse
?Control
?rbinom

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Art U
Sent: Wednesday, March 15, 2017 9:56 AM
To: r-help at r-project.org
Subject: [R] Correlated variables

Hi,

I'm trying to create binary variable which distribution conditioned on
other variables. That is what I did,

x1=rnorm(n,0,1);
x2=rnorm(n,0,1);
x3=rnorm(n,0,1);
if(x1+x2-x3>0.25){
? t=rbinom(1, 1, prob=0.25)
}else{
? t=rbinom(1, 1, prob=0.5)
}

But I always get this the warning:

Warning message:In if (x1 + x2 - x3 > 0.5) { :
? the condition has length > 1 and only the first element will be used


Can I do this without using function "for"?

Thank you in advance.
Ariel
--
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
I like to pretend I'm alone. Completely alone. Maybe post-apocalypse or plague... Whatever. No-one left to act normal for. No need to hide who I really am. It would be... freeing. ...

From plessthanpointohfive at gmail.com  Thu Mar 16 01:45:10 2017
From: plessthanpointohfive at gmail.com (Jen)
Date: Thu, 16 Mar 2017 00:45:10 +0000
Subject: [R] force axis to extend
In-Reply-To: <e11fe790457547cb98433199defb6c63@cdc.gov>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
Message-ID: <CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>

Hi,  I'm creating a couple of mirrored bar plots.  Below is data and code
for one.

My problem is that I need the axis to go from -35 to 35 by 5.  I can't get
that to happen with the code below.  I need it so all my plots are on the
same scale.

How can I do that using barplot? For reasons, I can't use ggplot or
lattice.

Thanks,

Jen



df <- data.frame(matrix(c(
'18-29',        'Females',      23.221039,
'30-44',        'Females',      16.665565,
'45-59',        'Females',      7.173238,
'60+',  'Females',      4.275979,
'18-29',        'Males',        -22.008875,
'30-44',        'Males',        -15.592936,
'45-59',        'Males',        -7.312195,
'60+',  'Males',        -3.750173),
nrow=8, ncol=3, byrow=T,
dimnames=list(NULL, c("Age", "Sex", "Percent"))))

df$Percent <- as.numeric(as.character(df$Percent))

midf <- barplot(height = df$Percent[df$Sex == "Females"])

# distribution of men and women with solid fill

plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)

barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes = FALSE,
col="#b498ec", ylab="")

barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F,
col="#f8bb85", ylab="",
        names.arg=c("18-29", "30-44", "45-59", "60+"))

axis(side=2, at = seq(-35,35,by=5),
     labels=format(abs(seq(-35,35,by=5)), scientific=F),
     cex.axis=0.7)

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Mar 16 02:43:55 2017
From: hannah.hlx at gmail.com (li li)
Date: Wed, 15 Mar 2017 21:43:55 -0400
Subject: [R] Test individual slope for each factor level in ANCOVA
Message-ID: <CAHLnndaX8zCyzjpOG1ffZka+tRVpkH82N90LzjkvFsxeVTf_ZQ@mail.gmail.com>

Hi all,
   Consider the data set where there are a continuous response variable, a
continuous predictor "weeks" and a categorical variable "region" with five
levels "a", "b", "c",
"d", "e".
  I fit the ANCOVA model as follows. Here the reference level is region "a"
and there are 4 dummy variables. The interaction terms (in red below)
represent the slope
difference between each region and  the baseline region "a" and the
corresponding p-value is for testing whether this slope difference is zero.
Is there a way to directly test whether the slope corresponding to each
individual factor level is 0 or not, instead of testing the slope
difference from the baseline level?
  Thanks very much.
      Hanna






> mod <- lm(response ~ weeks*region,data)> summary(mod)
Call:
lm(formula = response ~ weeks * region, data = data)

Residuals:
     Min       1Q   Median       3Q      Max
-0.19228 -0.07433 -0.01283  0.04439  0.24544

Coefficients:
                Estimate Std. Error t value Pr(>|t|)
(Intercept)    1.2105556  0.0954567  12.682  1.2e-14 ***
weeks         -0.0213333  0.0147293  -1.448    0.156
regionb       -0.0257778  0.1349962  -0.191    0.850
regionc       -0.0344444  0.1349962  -0.255    0.800
regiond       -0.0754444  0.1349962  -0.559    0.580
regione       -0.1482222  0.1349962  -1.098    0.280    weeks:regionb
-0.0007222  0.0208304  -0.035    0.973
weeks:regionc -0.0017778  0.0208304  -0.085    0.932
weeks:regiond  0.0030000  0.0208304   0.144    0.886
weeks:regione  0.0301667  0.0208304   1.448    0.156    ---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.1082 on 35 degrees of freedom
Multiple R-squared:  0.2678,	Adjusted R-squared:  0.07946
F-statistic: 1.422 on 9 and 35 DF,  p-value: 0.2165

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Mar 16 03:09:09 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Mar 2017 13:09:09 +1100
Subject: [R] force axis to extend
In-Reply-To: <CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
	<CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
Message-ID: <CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>

Hi Jen,
It seems way too simple, but does this work?

axis(side=2,at=seq(-35,35,by=5),cex.axis=0.7)

You may want to consider using a pyramid plot for this.

Jim


On Thu, Mar 16, 2017 at 11:45 AM, Jen <plessthanpointohfive at gmail.com> wrote:
> Hi,  I'm creating a couple of mirrored bar plots.  Below is data and code
> for one.
>
> My problem is that I need the axis to go from -35 to 35 by 5.  I can't get
> that to happen with the code below.  I need it so all my plots are on the
> same scale.
>
> How can I do that using barplot? For reasons, I can't use ggplot or
> lattice.
>
> Thanks,
>
> Jen
>
>
>
> df <- data.frame(matrix(c(
> '18-29',        'Females',      23.221039,
> '30-44',        'Females',      16.665565,
> '45-59',        'Females',      7.173238,
> '60+',  'Females',      4.275979,
> '18-29',        'Males',        -22.008875,
> '30-44',        'Males',        -15.592936,
> '45-59',        'Males',        -7.312195,
> '60+',  'Males',        -3.750173),
> nrow=8, ncol=3, byrow=T,
> dimnames=list(NULL, c("Age", "Sex", "Percent"))))
>
> df$Percent <- as.numeric(as.character(df$Percent))
>
> midf <- barplot(height = df$Percent[df$Sex == "Females"])
>
> # distribution of men and women with solid fill
>
> plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)
>
> barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes = FALSE,
> col="#b498ec", ylab="")
>
> barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F,
> col="#f8bb85", ylab="",
>         names.arg=c("18-29", "30-44", "45-59", "60+"))
>
> axis(side=2, at = seq(-35,35,by=5),
>      labels=format(abs(seq(-35,35,by=5)), scientific=F),
>      cex.axis=0.7)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Thu Mar 16 09:38:03 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 16 Mar 2017 08:38:03 +0000
Subject: [R] add median value and standard deviation bar to lattice plot
In-Reply-To: <CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
	<CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>
Message-ID: <CAMk+s2TMae8RAk-aqA521rRW1ADvq1E3Gd3vRHDwbouHmakVFw@mail.gmail.com>

dear Bert,
thank you for the solution, it worked perfectly. However I still would
like to know how reliable are the dots that are plotted, that is why i
would like to have individual bars on each dot (if possible). the
standard deviation maybe is not the right tool and the confidence
interval is perhaps better, but the procedure should be the same: draw
an arrow from the lower to the upper limit. is that possible?
regards,
luigi

PS sorry for the formatting, usually plain text is my default; it
should have switched to html when i replied to a previous email but
the difference does not show up when i type...

On Wed, Mar 15, 2017 at 4:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> There may be a specific function that handles this for you, but to
> roll your own, you need a custom panel.groups function, not the
> default. You need to modify the panel function (which is
> panel.superpose by default) to pass down the "col" argument to the
> panel.segments call in the panel.groups function.
>
> This should get you started:
>
> useOuterStrips(
>    strip = strip.custom(par.strip.text = list(cex = 0.75)),
>    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>    stripplot(
>       average ~ type|target+cluster,
>       panel = function(x,y,col,...)
>          panel.superpose(x,y,col=col,...),
>       panel.groups = function(x,y,col,...){
>          panel.stripplot(x,y,col=col,...)
>          m <- median(y)
>          panel.segments(x0 = x[1] -.5, y0 = m,
>                         x1 = x[1] +.5, y1 = m,
>                         col=col, lwd=2
>                         )
>       },
>       my.data,
>       groups = type,
>       pch=1,
>       jitter.data = TRUE,
>       main = "Group-wise",
>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>       col = c("grey", "green", "red"),
>       par.settings = list(strip.background = list(col=c("paleturquoise",
>                                                         "grey"))),
>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>       key = list(
>          space = "top",
>          columns = 3,
>          text = list(c("Blank", "Negative", "Positive"), col="black"),
>          rectangles = list(col=c("grey", "green", "red"))
>       )
>    )
> )
>
> FWIW, I think adding 1 sd bars is a bad idea statistically.
>
> And though it made no difference here, please post in pain text, not HTML.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 15, 2017 at 2:22 AM, Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
>> Dear all,
>> I am analyzing some multivariate data that is organized like this:
>> 1st variable = cluster (A or B)
>> 2nd variable = target (a, b, c, d, e)
>> 3rd variable = type (blank, negative, positive)
>> 4th variable = sample (the actual name of the sample)
>> 5th variable = average (the actual reading -- please not that this is the
>> mean of different measures with an assumed normal distribution, but the
>> assumption might not always be true)
>> 6th variable = stdev (the standard deviation associated with each reading)
>> 7th variable = ll (lower limit that is average stdev)
>> 8th variable = ul (upper limit that is average + stdev)
>>
>> I am plotting the data using lattice's stripplot and I would need to add:
>> 1. an error bar for each measurement. the bar should be possibly coloured
>> in light grey and semitransparent to reduce the noise of the plot.
>> 2. a type-based median bar to show differences in measurements between
>> blanks, negative and positive samples within each panel.
>>
>> How would I do that?
>> Many thanks,
>> Luigi
>>
>>>>>
>> cluster <- c(rep("A", 90), rep("B", 100))
>> sample <- c(
>>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
>> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
>> "blank"), 5),
>>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
>> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
>> "cow-59", "blank"), 5)
>> )
>> type <- c(
>>   rep(c("negative", "negative", "negative", "negative", "negative",
>> "negative", "negative", "negative", "positive", "positive",
>>         "positive", "positive", "positive", "positive", "positive",
>> "positive", "positive", "blank"), 5),
>>   rep(c("negative", "positive", "negative", "negative", "negative",
>> "negative", "negative", "negative", "positive", "positive",
>>         "positive", "positive", "positive", "positive", "positive",
>> "positive", "positive", "positive", "positive", "blank"), 5)
>> )
>> target <- c(
>> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
>> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
>> )
>> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
>> 42, 47, 86, 100,
>>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
>> 33, 28, 31, 26, 23,
>>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
>> 58.5, 61, 62.5, 58,
>>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
>> 84, 95.5, 62, 82, 138,
>>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
>> 33, 37, 51, 44, 50, 54,
>>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
>> 68, 121, 80, 57,
>>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
>> 32, 184, 36, 45, 45, 44,
>>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
>> 79, 34, 74.5,
>> 54, 49, 55, 56,
>>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
>> 33, 58, 51, 54,
>>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
>> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
>> 9.92, 4.59, 19, 7.96,
>>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
>> 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
>> 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
>> 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
>> 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
>> 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
>> 9.92, 40.69,
>> 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
>> 64.9, 3.71,
>> 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
>> 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
>> 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
>> 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>>                0.15, 1.28, 7.42, 71.15, 9.39)
>> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
>> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
>> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
>> 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
>> -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
>>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
>> 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
>>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
>> 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
>> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
>> 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
>> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
>> 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
>>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
>> 34.72, 42.58, -18.15, 39.61)
>> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
>> 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
>> 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
>>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
>> 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
>> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
>> 169.69,
>>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
>> 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
>>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
>> 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
>>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
>> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
>> 143.71,
>>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
>> 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
>>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
>> 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
>>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
>> 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
>>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
>> my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
>> ul, stringsAsFactors = FALSE)
>>
>> library(lattice)
>> library(latticeExtra)
>> useOuterStrips(
>>   strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>   stripplot(
>>     average ~ type|target+cluster,
>>     my.data,
>>     groups = type,
>>     pch=1,
>>     jitter.data = TRUE,
>>     main = "Group-wise",
>>     xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>     col = c("grey", "green", "red"),
>>     par.settings = list(strip.background = list(col=c("paleturquoise",
>> "grey"))),
>>     scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>     key = list(
>>       space = "top",
>>       columns = 3,
>>       text = list(c("Blank", "Negative", "Positive"), col="black"),
>>       rectangles = list(col=c("grey", "green", "red"))
>>     )
>>   )
>> )
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Mar 16 09:59:08 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Mar 2017 08:59:08 +0000
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
In-Reply-To: <1994411336.523592.1489576114011@mail.yahoo.com>
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
	<1994411336.523592.1489576114011@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1B412@SRVEXCHCM301.precheza.cz>

Hi

why nonumeric values in data identifier matters?

Some toy data
dat<-data.frame(ie=rep(letters[1:3], each=3), iw=rnorm(9))
dat[c(2, 4,6, 9),2]<-NA
library(zoo)

ave(dat$iw, dat$ie, FUN=function(x) na.locf(x, na.rm=FALSE))

You can use ave together with na.locf to propagate nonumeric values only within identifiers

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allan
> Tanaka
> Sent: Wednesday, March 15, 2017 12:09 PM
> To: r-help at r-project.org
> Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
>
> The following is an example:
>
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 |  |
> | DRI11 | 8.26 |
> | DRI11 |  |
> | FDW12 | 8.315 |
> | FDW12 |  |
>
>
> The following is the one that i want to be. That is, filling NA values from the
> previous Non-NA values.
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 | 19 |
> | DRI11 | 8.26 |
> | DRI11 | 8.26 |
> | FDW12 | 8.315 |
> | FDW12 | 8.315 |
>
>
> My current code data frame: train <- read.csv("Train.csv", header=T,sep =
> ",",na.strings = c(""," ",NA))
>
>
> Some people suggest to use na.locf function but in my case, i don't have
> numeric unique values in my Item_Identifier coloumn but rather it's
> characters. Not sure what to solve this problem.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Thu Mar 16 10:09:04 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Mar 2017 10:09:04 +0100
Subject: [R] mood.test/mood.medtest
In-Reply-To: <4B3E26DC-6274-46C9-8442-AA54DCD3B71A@essex.ac.uk>
References: <4B3E26DC-6274-46C9-8442-AA54DCD3B71A@essex.ac.uk>
Message-ID: <148CC75B-6759-426D-8213-375BF285D316@gmail.com>


> On 15 Mar 2017, at 16:32 , Leemann, Lucas T <l.leemann at essex.ac.uk> wrote:
> 
> Hello,
> 
> I was trying to test whether two medians are identical or not and used the function ?mood.test? from the ?stats" package. My co-author, a medical doctor, was trying to do the same in SPSS and had different results.

stats::mood.test() is a test of scale, not medians, according to its documentation. 

mood.medtest() is a test for a common median, basically looking at a crosstable of observations above and below the joint median:

> M <- table(indicator, x > median(x))
> chisq.test(M)

	Pearson's Chi-squared test with Yates' continuity correction

data:  M
X-squared = 4.125, df = 1, p-value = 0.04225
> mood.medtest(x ~ indicator)

	Mood's median test

data:  x by indicator
X-squared = 4.125, df = 1, p-value = 0.04225

This might differ from SPSS output (which you do not cite) in details like Yates correction, use of exact test, etc.

-pd



> 
> I wanted to see whether there was a problem on my end and also used the function ?mood.medtest? from the ?RVAideMemoire? package. I find different results while I am under the impression that both functions claim to carry out the same test and have the same defaults. While my actual data is sensitive medical information, I provide simple code below for a reproducible example. 
> 
> library(RVAideMemoire)
> set.seed(123)
> a <- runif(100)
> b <- runif(120,0.2,1.1)
> indicator <- c(rep(0,100),rep(1,120))
> x <- c(a,b)
> mood.test(x ~ indicator)
> mood.medtest(x ~ indicator)
> 
> Has anybody encounter this problem before or would be able to provide any insights?
> 
> Best wishes,
> Lucas
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From haenlein at escpeurope.eu  Thu Mar 16 12:34:32 2017
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Thu, 16 Mar 2017 12:34:32 +0100
Subject: [R] Simulate data from Structural Equation Model
Message-ID: <CAOyz9G7xkAp8dnx_0c_ybX-ZiSyTL5usBfgLE3opSR=Cqp7RDg@mail.gmail.com>

Dear all,

I am looking for an R package or code that allows me to simulate data
consistent with a given structural equation model. Essentially my idea is
to define (a) the number of endogenous and exogenous latent variables, (b)
the strength of relationship between them and (c) the way of measurement
(number of indicators, distribution of indicators) and to obtain simulated
data consistent with this specification.

I know there is some literature on this topic (e.g., Mattson, S. (1997).
How to generate non-normal data for simulation of structural equation
models. Multivariate behavioral research, 32(4), 355 ? 373), but I do not
know whether some of these approaches have already been implanted in R and/
or whether better methods exist.

Any help would be very much appreciated,

Thanks,

Michael


Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Thu Mar 16 13:02:16 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 16 Mar 2017 12:02:16 +0000
Subject: [R] Test individual slope for each factor level in ANCOVA
In-Reply-To: <CAHLnndaX8zCyzjpOG1ffZka+tRVpkH82N90LzjkvFsxeVTf_ZQ@mail.gmail.com>
References: <CAHLnndaX8zCyzjpOG1ffZka+tRVpkH82N90LzjkvFsxeVTf_ZQ@mail.gmail.com>
Message-ID: <D4EFF5CA.5937%jfox@mcmaster.ca>

Dear Hanna,

You can test the slope in each non-reference group as a linear hypothesis.
You didn?t make the data available for your example, so here?s an example
using the linearHypothesis() function in the car package with the Moore
data set in the same package:

- - - snip - - -

> library(car)
> mod <- lm(conformity ~ fscore*partner.status, data=Moore)
> summary(mod)

Call:
lm(formula = conformity ~ fscore * partner.status, data = Moore)

Residuals:
    Min      1Q  Median      3Q     Max
-7.5296 -2.5984 -0.4473  2.0994 12.4704

Coefficients:
                          Estimate Std. Error t value Pr(>|t|)
(Intercept)               20.79348    3.26273   6.373 1.27e-07 ***
fscore                    -0.15110    0.07171  -2.107  0.04127 *
partner.statuslow        -15.53408    4.40045  -3.530  0.00104 **
fscore:partner.statuslow   0.26110    0.09700   2.692  0.01024 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 4.562 on 41 degrees of freedom
Multiple R-squared:  0.2942,	Adjusted R-squared:  0.2426
F-statistic: 5.698 on 3 and 41 DF,  p-value: 0.002347

> linearHypothesis(mod, "fscore + fscore:partner.statuslow")
Linear hypothesis test

Hypothesis:
fscore  + fscore:partner.statuslow = 0

Model 1: restricted model
Model 2: conformity ~ fscore * partner.status

  Res.Df    RSS Df Sum of Sq      F  Pr(>F)
1     42 912.45    
2     41 853.42  1    59.037 2.8363 0.09976 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

- - - snip - - -

In this case, there are just two levels for partner.status, but for a
multi-level factor you can simply perform more than one test.


I hope this helps,

 John

-------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: http://socserv.mcmaster.ca/jfox/




On 2017-03-15, 9:43 PM, "R-help on behalf of li li"
<r-help-bounces at r-project.org on behalf of hannah.hlx at gmail.com> wrote:

>Hi all,
>   Consider the data set where there are a continuous response variable, a
>continuous predictor "weeks" and a categorical variable "region" with five
>levels "a", "b", "c",
>"d", "e".
>  I fit the ANCOVA model as follows. Here the reference level is region
>"a"
>and there are 4 dummy variables. The interaction terms (in red below)
>represent the slope
>difference between each region and  the baseline region "a" and the
>corresponding p-value is for testing whether this slope difference is
>zero.
>Is there a way to directly test whether the slope corresponding to each
>individual factor level is 0 or not, instead of testing the slope
>difference from the baseline level?
>  Thanks very much.
>      Hanna
>
>
>
>
>
>
>> mod <- lm(response ~ weeks*region,data)> summary(mod)
>Call:
>lm(formula = response ~ weeks * region, data = data)
>
>Residuals:
>     Min       1Q   Median       3Q      Max
>-0.19228 -0.07433 -0.01283  0.04439  0.24544
>
>Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
>(Intercept)    1.2105556  0.0954567  12.682  1.2e-14 ***
>weeks         -0.0213333  0.0147293  -1.448    0.156
>regionb       -0.0257778  0.1349962  -0.191    0.850
>regionc       -0.0344444  0.1349962  -0.255    0.800
>regiond       -0.0754444  0.1349962  -0.559    0.580
>regione       -0.1482222  0.1349962  -1.098    0.280    weeks:regionb
>-0.0007222  0.0208304  -0.035    0.973
>weeks:regionc -0.0017778  0.0208304  -0.085    0.932
>weeks:regiond  0.0030000  0.0208304   0.144    0.886
>weeks:regione  0.0301667  0.0208304   1.448    0.156    ---
>Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>Residual standard error: 0.1082 on 35 degrees of freedom
>Multiple R-squared:  0.2678,	Adjusted R-squared:  0.07946
>F-statistic: 1.422 on 9 and 35 DF,  p-value: 0.2165
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tring at gvdnet.dk  Thu Mar 16 13:29:21 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Thu, 16 Mar 2017 13:29:21 +0100
Subject: [R] Simulate data from Structural Equation Model
Message-ID: <6b0d4c13-3814-efe4-f86d-4939f206eba2@gvdnet.dk>

Hi - running rseek.org
with
simulate structutral model data
seems to give some inputs?
BW
Troels


Den 16-03-2017 kl. 12:34 skrev Michael Haenlein:
> Dear all,
>
> I am looking for an R package or code that allows me to simulate data
> consistent with a given structural equation model. Essentially my idea is
> to define (a) the number of endogenous and exogenous latent variables, (b)
> the strength of relationship between them and (c) the way of measurement
> (number of indicators, distribution of indicators) and to obtain simulated
> data consistent with this specification.
>
> I know there is some literature on this topic (e.g., Mattson, S. (1997).
> How to generate non-normal data for simulation of structural equation
> models. Multivariate behavioral research, 32(4), 355 ? 373), but I do not
> know whether some of these approaches have already been implanted in R and/
> or whether better methods exist.
>
> Any help would be very much appreciated,
>
> Thanks,
>
> Michael
>
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Thu Mar 16 13:43:42 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 16 Mar 2017 07:43:42 -0500
Subject: [R] =?utf-8?q?How_to_get_the_transpose_of_R=C2=B4s_function_forec?=
	=?utf-8?q?ast_output_and_turn_it_into_a_data_frame?=
Message-ID: <CAMOcQfPx-c8Cn3ytqCswm3EDaZdbuHW2cVuybLq=PvNc8J0f=g@mail.gmail.com>

Dear all,

Hope you are doing great. Some R time series functions generate the
forecasts in an horizontal way, for example:

                2017     2018     2019    2020
forecast    12           15        35        75

but I?d like to have the output as follows:


Date      forecast
2017           12
2018           15
2019           35
2020           75

I tried using the t() function to get the transpose, but after taking the
transpose I was not able to turn it into a data frame.

Any help will be greatly appreciated,

Cheers,

Paul

	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Thu Mar 16 03:16:19 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Thu, 16 Mar 2017 02:16:19 +0000 (UTC)
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
In-Reply-To: <CAF8bMcaa0iKdJ8zRdAWFjRJ0ZXVQOcxZ+8VSLoWWRWma63oqZQ@mail.gmail.com>
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
	<1994411336.523592.1489576114011@mail.yahoo.com>
	<CAF8bMcaa0iKdJ8zRdAWFjRJ0ZXVQOcxZ+8VSLoWWRWma63oqZQ@mail.gmail.com>
Message-ID: <2101887076.1087342.1489630579078@mail.yahoo.com>

 Hi. Thanks for the function. My bad, after looking at the csv file, it seems that NA values come not only from previous Non-NA values but also from the next Non-NA values. Example:
| NCQ05 | 11.395 |
| NCQ05 | 11.395 |
| NCQ05 |  |
| NCQ06 |  |
| NCQ06 | 13 |
| NCQ06 | 13 |


If i use the function, then the blank row would be filled with 11.395, instead of filling with 11.395 and 13.
Does it mean that the function can be modified like this?
locf2 <- function(x, initial=NA, IS_BAD = is.na) {
? ? # Replace 'bad' values in 'x' with last previous non-bad value.
? ? # If no previous non-bad value, replace with 'initial'.
? ? stopifnot(is.function(IS_BAD))
? ? good <- !IS_BAD(x)
? ? stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
? ? i <- cumsum(good)
? ? x <- x[c(1,which(good))][i+1]
? ? x <- x[c(1,which(good))][i+2]
? ? x[i==0] <- initial
? ? x
}    On Thursday, 16 March 2017, 1:17, William Dunlap <wdunlap at tibco.com> wrote:
 

 You could use the following function

locf2 <- function(x, initial=NA, IS_BAD = is.na) {
? ? # Replace 'bad' values in 'x' with last previous non-bad value.
? ? # If no previous non-bad value, replace with 'initial'.
? ? stopifnot(is.function(IS_BAD))
? ? good <- !IS_BAD(x)
? ? stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
? ? i <- cumsum(good)
? ? x <- x[c(1,which(good))][i+1]
? ? x[i==0] <- initial
? ? x
}

as in

> locf2(c("", "A", "B", "", "", "C", ""), IS_BAD=function(x)x=="", initial="---")
[1] "---" "A"? "B"? "B"? "B"? "C"? "C"
> locf2(factor(c(NA,"Small","Medium",NA,"Large",NA,NA,NA,"Small")))
[1] <NA>? Small? Medium Medium Large? Large? Large? Large? Small
Levels: Large Medium Small
> locf2(c(12, NA, 10, 11, NA, NA))
[1] 12 12 10 11 11 11

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 15, 2017 at 4:08 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> The following is an example:
>
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 |? |
> | DRI11 | 8.26 |
> | DRI11 |? |
> | FDW12 | 8.315 |
> | FDW12 |? |
>
>
> The following is the one that i want to be. That is, filling NA values from the previous Non-NA values.
> | Item_Identifier | Item_Weight |
> | FDP10 | 19 |
> | FDP10 | 19 |
> | DRI11 | 8.26 |
> | DRI11 | 8.26 |
> | FDW12 | 8.315 |
> | FDW12 | 8.315 |
>
>
> My current code data frame: train <- read.csv("Train.csv", header=T,sep = ",",na.strings = c(""," ",NA))
>
>
> Some people suggest to use na.locf function but in my case, i don't have numeric unique values in my Item_Identifier coloumn but rather it's characters. Not sure what to solve this problem.
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 16 14:24:29 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Mar 2017 14:24:29 +0100
Subject: [R]
 =?utf-8?q?How_to_get_the_transpose_of_R=C2=B4s_function_forec?=
 =?utf-8?q?ast_output_and_turn_it_into_a_data_frame?=
In-Reply-To: <CAMOcQfPx-c8Cn3ytqCswm3EDaZdbuHW2cVuybLq=PvNc8J0f=g@mail.gmail.com>
References: <CAMOcQfPx-c8Cn3ytqCswm3EDaZdbuHW2cVuybLq=PvNc8J0f=g@mail.gmail.com>
Message-ID: <4CFFDFA4-C707-4154-807B-7B146EBABD62@gmail.com>

You're not giving us much to play with here. Reproducible example, please.

(Remember to send it to the list, not me.)

My immediate guess was cbind(), but without knowing the data structure, I can't tell for sure.

-pd

> On 16 Mar 2017, at 13:43 , Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear all,
> 
> Hope you are doing great. Some R time series functions generate the
> forecasts in an horizontal way, for example:
> 
>                2017     2018     2019    2020
> forecast    12           15        35        75
> 
> but I?d like to have the output as follows:
> 
> 
> Date      forecast
> 2017           12
> 2018           15
> 2019           35
> 2020           75
> 
> I tried using the t() function to get the transpose, but after taking the
> transpose I was not able to turn it into a data frame.
> 
> Any help will be greatly appreciated,
> 
> Cheers,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From plessthanpointohfive at gmail.com  Thu Mar 16 14:27:56 2017
From: plessthanpointohfive at gmail.com (Jen)
Date: Thu, 16 Mar 2017 13:27:56 +0000
Subject: [R] force axis to extend
In-Reply-To: <CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
	<CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
	<CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
Message-ID: <CAOxgQ=XB6n75pOiobmds-3zifej5SqPzah5cwgv3QOYvv6WK=w@mail.gmail.com>

Hi Jim,

Thanks for replying.

Unfortunately, that doesn't work.   The axis automatically scales to (-30,
25, by 5).

Jen



On Wed, Mar 15, 2017, 10:09 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Jen,
> It seems way too simple, but does this work?
>
> axis(side=2,at=seq(-35,35,by=5),cex.axis=0.7)
>
> You may want to consider using a pyramid plot for this.
>
> Jim
>
>
> On Thu, Mar 16, 2017 at 11:45 AM, Jen <plessthanpointohfive at gmail.com>
> wrote:
> > Hi,  I'm creating a couple of mirrored bar plots.  Below is data and code
> > for one.
> >
> > My problem is that I need the axis to go from -35 to 35 by 5.  I can't
> get
> > that to happen with the code below.  I need it so all my plots are on the
> > same scale.
> >
> > How can I do that using barplot? For reasons, I can't use ggplot or
> > lattice.
> >
> > Thanks,
> >
> > Jen
> >
> >
> >
> > df <- data.frame(matrix(c(
> > '18-29',        'Females',      23.221039,
> > '30-44',        'Females',      16.665565,
> > '45-59',        'Females',      7.173238,
> > '60+',  'Females',      4.275979,
> > '18-29',        'Males',        -22.008875,
> > '30-44',        'Males',        -15.592936,
> > '45-59',        'Males',        -7.312195,
> > '60+',  'Males',        -3.750173),
> > nrow=8, ncol=3, byrow=T,
> > dimnames=list(NULL, c("Age", "Sex", "Percent"))))
> >
> > df$Percent <- as.numeric(as.character(df$Percent))
> >
> > midf <- barplot(height = df$Percent[df$Sex == "Females"])
> >
> > # distribution of men and women with solid fill
> >
> > plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)
> >
> > barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes =
> FALSE,
> > col="#b498ec", ylab="")
> >
> > barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F,
> > col="#f8bb85", ylab="",
> >         names.arg=c("18-29", "30-44", "45-59", "60+"))
> >
> > axis(side=2, at = seq(-35,35,by=5),
> >      labels=format(abs(seq(-35,35,by=5)), scientific=F),
> >      cex.axis=0.7)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Mar 16 14:28:17 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 16 Mar 2017 13:28:17 +0000
Subject: [R] force axis to extend
In-Reply-To: <CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
	<CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
	<CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
Message-ID: <1562116fa850430ea227373ba702596d@exch-2p-mbx-w2.ads.tamu.edu>

Use

plot(NA, xlim=c(0, 5), ylim=c(-35, 35), type="n", axes=FALSE, ann=FALSE)

to set up the length of the y axis instead of your first plot command.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Wednesday, March 15, 2017 9:09 PM
To: Jen <plessthanpointohfive at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] force axis to extend

Hi Jen,
It seems way too simple, but does this work?

axis(side=2,at=seq(-35,35,by=5),cex.axis=0.7)

You may want to consider using a pyramid plot for this.

Jim


On Thu, Mar 16, 2017 at 11:45 AM, Jen <plessthanpointohfive at gmail.com> wrote:
> Hi,  I'm creating a couple of mirrored bar plots.  Below is data and code
> for one.
>
> My problem is that I need the axis to go from -35 to 35 by 5.  I can't get
> that to happen with the code below.  I need it so all my plots are on the
> same scale.
>
> How can I do that using barplot? For reasons, I can't use ggplot or
> lattice.
>
> Thanks,
>
> Jen
>
>
>
> df <- data.frame(matrix(c(
> '18-29',        'Females',      23.221039,
> '30-44',        'Females',      16.665565,
> '45-59',        'Females',      7.173238,
> '60+',  'Females',      4.275979,
> '18-29',        'Males',        -22.008875,
> '30-44',        'Males',        -15.592936,
> '45-59',        'Males',        -7.312195,
> '60+',  'Males',        -3.750173),
> nrow=8, ncol=3, byrow=T,
> dimnames=list(NULL, c("Age", "Sex", "Percent"))))
>
> df$Percent <- as.numeric(as.character(df$Percent))
>
> midf <- barplot(height = df$Percent[df$Sex == "Females"])
>
> # distribution of men and women with solid fill
>
> plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)
>
> barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes = FALSE,
> col="#b498ec", ylab="")
>
> barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F,
> col="#f8bb85", ylab="",
>         names.arg=c("18-29", "30-44", "45-59", "60+"))
>
> axis(side=2, at = seq(-35,35,by=5),
>      labels=format(abs(seq(-35,35,by=5)), scientific=F),
>      cex.axis=0.7)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Mar 16 14:38:33 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Mar 2017 13:38:33 +0000
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
In-Reply-To: <2101887076.1087342.1489630579078@mail.yahoo.com>
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
	<1994411336.523592.1489576114011@mail.yahoo.com>
	<CAF8bMcaa0iKdJ8zRdAWFjRJ0ZXVQOcxZ+8VSLoWWRWma63oqZQ@mail.gmail.com>
	<2101887076.1087342.1489630579078@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1B4F6@SRVEXCHCM301.precheza.cz>

Hi

You can achieve exactly what you want by using ave/na.locf twice

dat<-data.frame(ie=rep(letters[1:3], each=3), iw=rnorm(9))
dat[c(3, 4),2]<-NA
> dat
  ie          iw
1  a  1.07254438
2  a  0.53067188
3  a          NA
4  b          NA
5  b -0.09767088
6  b -1.02719060
7  c  2.35787246
8  c -0.07513048
9  c -0.17164728

dat$iw <- ave(dat$iw, dat$ie, FUN=function(x) na.locf(x, na.rm=FALSE))
dat$iw <- ave(dat$iw, dat$ie, FUN=function(x) na.locf(x, na.rm=FALSE, fromLast=TRUE))

> dat
  ie          iw
1  a  1.07254438
2  a  0.53067188
3  a  0.53067188
4  b -0.09767088
5  b -0.09767088
6  b -1.02719060
7  c  2.35787246
8  c -0.07513048
9  c -0.17164728
>

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allan
> Tanaka
> Sent: Thursday, March 16, 2017 3:16 AM
> To: William Dunlap <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] HELP ME: Fill NA Values from the previous Non-NA Values
>
>  Hi. Thanks for the function. My bad, after looking at the csv file, it seems that
> NA values come not only from previous Non-NA values but also from the
> next Non-NA values. Example:
> | NCQ05 | 11.395 |
> | NCQ05 | 11.395 |
> | NCQ05 |  |
> | NCQ06 |  |
> | NCQ06 | 13 |
> | NCQ06 | 13 |
>
>
> If i use the function, then the blank row would be filled with 11.395, instead
> of filling with 11.395 and 13.
> Does it mean that the function can be modified like this?
> locf2 <- function(x, initial=NA, IS_BAD = is.na) {
>     # Replace 'bad' values in 'x' with last previous non-bad value.
>     # If no previous non-bad value, replace with 'initial'.
>     stopifnot(is.function(IS_BAD))
>     good <- !IS_BAD(x)
>     stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
>     i <- cumsum(good)
>     x <- x[c(1,which(good))][i+1]
>     x <- x[c(1,which(good))][i+2]
>     x[i==0] <- initial
>     x
> }    On Thursday, 16 March 2017, 1:17, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>
>  You could use the following function
>
> locf2 <- function(x, initial=NA, IS_BAD = is.na) {
>     # Replace 'bad' values in 'x' with last previous non-bad value.
>     # If no previous non-bad value, replace with 'initial'.
>     stopifnot(is.function(IS_BAD))
>     good <- !IS_BAD(x)
>     stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
>     i <- cumsum(good)
>     x <- x[c(1,which(good))][i+1]
>     x[i==0] <- initial
>     x
> }
>
> as in
>
> > locf2(c("", "A", "B", "", "", "C", ""), IS_BAD=function(x)x=="",
> > initial="---")
> [1] "---" "A"  "B"  "B"  "B"  "C"  "C"
> > locf2(factor(c(NA,"Small","Medium",NA,"Large",NA,NA,NA,"Small")))
> [1] <NA>  Small  Medium Medium Large  Large  Large  Large  Small
> Levels: Large Medium Small
> > locf2(c(12, NA, 10, 11, NA, NA))
> [1] 12 12 10 11 11 11
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Mar 15, 2017 at 4:08 AM, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
> > The following is an example:
> >
> > | Item_Identifier | Item_Weight |
> > | FDP10 | 19 |
> > | FDP10 |  |
> > | DRI11 | 8.26 |
> > | DRI11 |  |
> > | FDW12 | 8.315 |
> > | FDW12 |  |
> >
> >
> > The following is the one that i want to be. That is, filling NA values from the
> previous Non-NA values.
> > | Item_Identifier | Item_Weight |
> > | FDP10 | 19 |
> > | FDP10 | 19 |
> > | DRI11 | 8.26 |
> > | DRI11 | 8.26 |
> > | FDW12 | 8.315 |
> > | FDW12 | 8.315 |
> >
> >
> > My current code data frame: train <- read.csv("Train.csv",
> > header=T,sep = ",",na.strings = c(""," ",NA))
> >
> >
> > Some people suggest to use na.locf function but in my case, i don't have
> numeric unique values in my Item_Identifier coloumn but rather it's
> characters. Not sure what to solve this problem.
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Thu Mar 16 14:39:02 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 16 Mar 2017 13:39:02 +0000
Subject: [R] force axis to extend
In-Reply-To: <CAOxgQ=XB6n75pOiobmds-3zifej5SqPzah5cwgv3QOYvv6WK=w@mail.gmail.com>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
	<CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
	<CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
	<CAOxgQ=XB6n75pOiobmds-3zifej5SqPzah5cwgv3QOYvv6WK=w@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E26724056F0B193D@GBTEDVPEXCMB04.corp.lgc-group.com>

> Unfortunately, that doesn't work.   The axis automatically scales to (-30,
> 25, by 5).

Your data do not extend to ?35 so the axis limits you have asked axis() for are outside the plot region. it is plot() that is (correctly) defaulting to the data range. if you want to override that to get a larger plot range, specify the y limits for the plot as part of the plot command:

plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F, ylim=c(-35, 35))

barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes = FALSE,
col="#b498ec", ylab="")

barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F, col="#f8bb85", ylab="",
        names.arg=c("18-29", "30-44", "45-59", "60+"))

axis(side=2, at = seq(-35,35,by=5),
     labels=format(abs(seq(-35,35,by=5)), scientific=F),
     cex.axis=0.7)
	#Axes now run to ?35

S Ellison
> 
> Jen
> 
> 
> 
> On Wed, Mar 15, 2017, 10:09 PM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> 
> > Hi Jen,
> > It seems way too simple, but does this work?
> >
> > axis(side=2,at=seq(-35,35,by=5),cex.axis=0.7)
> >
> > You may want to consider using a pyramid plot for this.
> >
> > Jim
> >
> >
> > On Thu, Mar 16, 2017 at 11:45 AM, Jen <plessthanpointohfive at gmail.com>
> > wrote:
> > > Hi,  I'm creating a couple of mirrored bar plots.  Below is data and
> > > code for one.
> > >
> > > My problem is that I need the axis to go from -35 to 35 by 5.  I
> > > can't
> > get
> > > that to happen with the code below.  I need it so all my plots are
> > > on the same scale.
> > >
> > > How can I do that using barplot? For reasons, I can't use ggplot or
> > > lattice.
> > >
> > > Thanks,
> > >
> > > Jen
> > >
> > >
> > >
> > > df <- data.frame(matrix(c(
> > > '18-29',        'Females',      23.221039,
> > > '30-44',        'Females',      16.665565,
> > > '45-59',        'Females',      7.173238,
> > > '60+',  'Females',      4.275979,
> > > '18-29',        'Males',        -22.008875,
> > > '30-44',        'Males',        -15.592936,
> > > '45-59',        'Males',        -7.312195,
> > > '60+',  'Males',        -3.750173),
> > > nrow=8, ncol=3, byrow=T,
> > > dimnames=list(NULL, c("Age", "Sex", "Percent"))))
> > >
> > > df$Percent <- as.numeric(as.character(df$Percent))
> > >
> > > midf <- barplot(height = df$Percent[df$Sex == "Females"])
> > >
> > > # distribution of men and women with solid fill
> > >
> > > plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)
> > >
> > > barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes =
> > FALSE,
> > > col="#b498ec", ylab="")
> > >
> > > barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes =
> > > F, col="#f8bb85", ylab="",
> > >         names.arg=c("18-29", "30-44", "45-59", "60+"))
> > >
> > > axis(side=2, at = seq(-35,35,by=5),
> > >      labels=format(abs(seq(-35,35,by=5)), scientific=F),
> > >      cex.axis=0.7)
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From plessthanpointohfive at gmail.com  Thu Mar 16 14:39:50 2017
From: plessthanpointohfive at gmail.com (Jen)
Date: Thu, 16 Mar 2017 13:39:50 +0000
Subject: [R] force axis to extend
In-Reply-To: <1562116fa850430ea227373ba702596d@exch-2p-mbx-w2.ads.tamu.edu>
References: <e11fe790457547cb98433199defb6c63@cdc.gov>
	<CAOxgQ=USK-_G9pLRSoQeJ=m33DH8uCHpAxiz-DuNvFzAZ95NkQ@mail.gmail.com>
	<CA+8X3fXy5iQma_cE226rLapv7u+1Fp5EUh27wL9rYQo75HfZeQ@mail.gmail.com>
	<1562116fa850430ea227373ba702596d@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAOxgQ=VD9j53i0Q_hZdufauS8t6JLkAa9z-eozwwo348fgay1A@mail.gmail.com>

Yay!  That worked!  Thanks so much!

Jen

On Thu, Mar 16, 2017, 9:28 AM David L Carlson <dcarlson at tamu.edu> wrote:

> Use
>
> plot(NA, xlim=c(0, 5), ylim=c(-35, 35), type="n", axes=FALSE, ann=FALSE)
>
> to set up the length of the y axis instead of your first plot command.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Wednesday, March 15, 2017 9:09 PM
> To: Jen <plessthanpointohfive at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] force axis to extend
>
> Hi Jen,
> It seems way too simple, but does this work?
>
> axis(side=2,at=seq(-35,35,by=5),cex.axis=0.7)
>
> You may want to consider using a pyramid plot for this.
>
> Jim
>
>
> On Thu, Mar 16, 2017 at 11:45 AM, Jen <plessthanpointohfive at gmail.com>
> wrote:
> > Hi,  I'm creating a couple of mirrored bar plots.  Below is data and code
> > for one.
> >
> > My problem is that I need the axis to go from -35 to 35 by 5.  I can't
> get
> > that to happen with the code below.  I need it so all my plots are on the
> > same scale.
> >
> > How can I do that using barplot? For reasons, I can't use ggplot or
> > lattice.
> >
> > Thanks,
> >
> > Jen
> >
> >
> >
> > df <- data.frame(matrix(c(
> > '18-29',        'Females',      23.221039,
> > '30-44',        'Females',      16.665565,
> > '45-59',        'Females',      7.173238,
> > '60+',  'Females',      4.275979,
> > '18-29',        'Males',        -22.008875,
> > '30-44',        'Males',        -15.592936,
> > '45-59',        'Males',        -7.312195,
> > '60+',  'Males',        -3.750173),
> > nrow=8, ncol=3, byrow=T,
> > dimnames=list(NULL, c("Age", "Sex", "Percent"))))
> >
> > df$Percent <- as.numeric(as.character(df$Percent))
> >
> > midf <- barplot(height = df$Percent[df$Sex == "Females"])
> >
> > # distribution of men and women with solid fill
> >
> > plot(c(0,5),range(df$Percent),type = "n", axes=FALSE, ann=F)
> >
> > barplot(height = df$Percent[df$Sex == "Females"], add = TRUE,axes =
> FALSE,
> > col="#b498ec", ylab="")
> >
> > barplot(height = df$Percent[df$Sex == "Males"], add = TRUE, axes = F,
> > col="#f8bb85", ylab="",
> >         names.arg=c("18-29", "30-44", "45-59", "60+"))
> >
> > axis(side=2, at = seq(-35,35,by=5),
> >      labels=format(abs(seq(-35,35,by=5)), scientific=F),
> >      cex.axis=0.7)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Mar 16 15:00:58 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 16 Mar 2017 14:00:58 +0000
Subject: [R] screen
In-Reply-To: <CAJOiR6bUsfZV+f6RMUn9pdRqQ476jqm4ao9b+O-oZ2rXHen72Q@mail.gmail.com>
References: <CAJOiR6bUsfZV+f6RMUn9pdRqQ476jqm4ao9b+O-oZ2rXHen72Q@mail.gmail.com>
Message-ID: <6e977af9671c4ba287a7483a08a680ac@exch-2p-mbx-w2.ads.tamu.edu>

Something like this?

> DF2.agg <- aggregate(DF2$obs, DF2[, c("family", "time")], mean)
> DF2.tbl <- xtabs(x~family+time, DF2.agg)
> DF2.tbl      time
family WEEK1 WEEK2 WEEK3 WEEK4
     A  0.00  0.50  0.50  0.00
     B  0.67  0.00  0.50  0.00
     C  0.00  0.00  0.00  1.00

You can get closer to the output in your example with this

> suppressWarnings(as.table(formatC(DF2.tbl, digits=2, width=4, zero.print=".")))
      time
family WEEK1 WEEK2 WEEK3 WEEK4
     A    .   0.5   0.5     . 
     B 0.67     .   0.5     . 
     C    .     .     .     1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
Sent: Wednesday, March 15, 2017 5:41 PM
To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] screen

HI all,

I have some data to be screened  based on the recording flag (obs).
Some family recorded properly (1) and others not (0).  Th 0 = improper
and 1 = proper

The recording  period starts week1.  All families may not start in the
same week in recording properly an observation,

  DF2 <- read.table(header=TRUE, text='family time obs
A  WEEK1 0
A  WEEK1 0
A  WEEK1 0
A  WEEK2 1
A  WEEK2 0
A  WEEK3 1
A  WEEK3 0
B  WEEK1 1
B  WEEK1 0
B  WEEK1 1
B  WEEK2 0
B  WEEK2 0
B  WEEK3 1
B  WEEK3 0
C  WEEK3 0
C  WEEK3 0
C  WEEK4 1
C  WEEK4 1')

Example, in week1  all records of family "A" are 0 (improper), but
starting the week2 they start recording proper (1) records as well.
Then I create a table that shows me the ratio of proper records to the
total records for each family within week. If the ratio is zero and
there is no prior proper recordings for that family then I want to
delete those records.

However,  once any family started showing proper records  as "1"  and
even if in the  the subsequent week the ratio is 0  then I want keep
that record for that family. Example records of week2 for family B

Here is the summary table

      WEEK1      WEEK2    WEEK3    WEEK4
A          0            0.5              0.5           .
B       0.33           0                0.5           .
C          .               .                 0            1

>From the above table
For A-  I want exclude all records of week1 and keep the rest. Because
they were not recording it propeller
For B-  Keep all records, as they stated recording properly from the beginning.
For C-  Keep only the week4 records because all records are  1's

Final and desired  result will be

A WEEK2 1
A WEEK2 0
A WEEK3 1
A WEEK3 0
B WEEK1 1
B WEEK1 0
B WEEK1 1
B WEEK2 0
B WEEK2 0
B WEEK3 1
B WEEK3 0
C WEEK4 1
C WEEK4 1


and the summary table looks like as follows

       WEEK1  WEEK2  WEEK3  WEEK4
A             .        0.5             0.5        .
B          0.33        0             0.5        .
C               .          .                 .        1

Thank you in advance

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Mar 16 15:41:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 16 Mar 2017 07:41:58 -0700
Subject: [R] add median value and standard deviation bar to lattice plot
In-Reply-To: <CAMk+s2TMae8RAk-aqA521rRW1ADvq1E3Gd3vRHDwbouHmakVFw@mail.gmail.com>
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
	<CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>
	<CAMk+s2TMae8RAk-aqA521rRW1ADvq1E3Gd3vRHDwbouHmakVFw@mail.gmail.com>
Message-ID: <CAGxFJbQzVZSRum=Pg2kBKTKYWJ3=M9ZfiMjck=FF33GysKEb3A@mail.gmail.com>

Just add whatever further code to decorate the groups as you like
within the panel.groups function. I believe I have given you
sufficient information in my code for you to do that if you study the
code carefully. Depending on what you decide to do -- which is
statistical and OT here (and not something I would offer specific
advice on remotely anyway) -- you may also have to pass down
additional arguments based on computations that you do with *all* the
data from *all* groups together.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 16, 2017 at 1:38 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> dear Bert,
> thank you for the solution, it worked perfectly. However I still would
> like to know how reliable are the dots that are plotted, that is why i
> would like to have individual bars on each dot (if possible). the
> standard deviation maybe is not the right tool and the confidence
> interval is perhaps better, but the procedure should be the same: draw
> an arrow from the lower to the upper limit. is that possible?
> regards,
> luigi
>
> PS sorry for the formatting, usually plain text is my default; it
> should have switched to html when i replied to a previous email but
> the difference does not show up when i type...
>
> On Wed, Mar 15, 2017 at 4:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> There may be a specific function that handles this for you, but to
>> roll your own, you need a custom panel.groups function, not the
>> default. You need to modify the panel function (which is
>> panel.superpose by default) to pass down the "col" argument to the
>> panel.segments call in the panel.groups function.
>>
>> This should get you started:
>>
>> useOuterStrips(
>>    strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>    stripplot(
>>       average ~ type|target+cluster,
>>       panel = function(x,y,col,...)
>>          panel.superpose(x,y,col=col,...),
>>       panel.groups = function(x,y,col,...){
>>          panel.stripplot(x,y,col=col,...)
>>          m <- median(y)
>>          panel.segments(x0 = x[1] -.5, y0 = m,
>>                         x1 = x[1] +.5, y1 = m,
>>                         col=col, lwd=2
>>                         )
>>       },
>>       my.data,
>>       groups = type,
>>       pch=1,
>>       jitter.data = TRUE,
>>       main = "Group-wise",
>>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>       col = c("grey", "green", "red"),
>>       par.settings = list(strip.background = list(col=c("paleturquoise",
>>                                                         "grey"))),
>>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>       key = list(
>>          space = "top",
>>          columns = 3,
>>          text = list(c("Blank", "Negative", "Positive"), col="black"),
>>          rectangles = list(col=c("grey", "green", "red"))
>>       )
>>    )
>> )
>>
>> FWIW, I think adding 1 sd bars is a bad idea statistically.
>>
>> And though it made no difference here, please post in pain text, not HTML.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Mar 15, 2017 at 2:22 AM, Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>> Dear all,
>>> I am analyzing some multivariate data that is organized like this:
>>> 1st variable = cluster (A or B)
>>> 2nd variable = target (a, b, c, d, e)
>>> 3rd variable = type (blank, negative, positive)
>>> 4th variable = sample (the actual name of the sample)
>>> 5th variable = average (the actual reading -- please not that this is the
>>> mean of different measures with an assumed normal distribution, but the
>>> assumption might not always be true)
>>> 6th variable = stdev (the standard deviation associated with each reading)
>>> 7th variable = ll (lower limit that is average stdev)
>>> 8th variable = ul (upper limit that is average + stdev)
>>>
>>> I am plotting the data using lattice's stripplot and I would need to add:
>>> 1. an error bar for each measurement. the bar should be possibly coloured
>>> in light grey and semitransparent to reduce the noise of the plot.
>>> 2. a type-based median bar to show differences in measurements between
>>> blanks, negative and positive samples within each panel.
>>>
>>> How would I do that?
>>> Many thanks,
>>> Luigi
>>>
>>>>>>
>>> cluster <- c(rep("A", 90), rep("B", 100))
>>> sample <- c(
>>>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
>>> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>>>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
>>> "blank"), 5),
>>>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
>>> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>>>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
>>> "cow-59", "blank"), 5)
>>> )
>>> type <- c(
>>>   rep(c("negative", "negative", "negative", "negative", "negative",
>>> "negative", "negative", "negative", "positive", "positive",
>>>         "positive", "positive", "positive", "positive", "positive",
>>> "positive", "positive", "blank"), 5),
>>>   rep(c("negative", "positive", "negative", "negative", "negative",
>>> "negative", "negative", "negative", "positive", "positive",
>>>         "positive", "positive", "positive", "positive", "positive",
>>> "positive", "positive", "positive", "positive", "blank"), 5)
>>> )
>>> target <- c(
>>> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
>>> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
>>> )
>>> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
>>> 42, 47, 86, 100,
>>>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
>>> 33, 28, 31, 26, 23,
>>>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
>>> 58.5, 61, 62.5, 58,
>>>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
>>> 84, 95.5, 62, 82, 138,
>>>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
>>> 33, 37, 51, 44, 50, 54,
>>>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
>>> 68, 121, 80, 57,
>>>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
>>> 32, 184, 36, 45, 45, 44,
>>>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
>>> 79, 34, 74.5,
>>> 54, 49, 55, 56,
>>>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
>>> 33, 58, 51, 54,
>>>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
>>> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
>>> 9.92, 4.59, 19, 7.96,
>>>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
>>> 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>>>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
>>> 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>>>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
>>> 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>>>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
>>> 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>>>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
>>> 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>>>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
>>> 9.92, 40.69,
>>> 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>>>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
>>> 64.9, 3.71,
>>> 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>>>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
>>> 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>>>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
>>> 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>>>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
>>> 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>>>                0.15, 1.28, 7.42, 71.15, 9.39)
>>> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
>>> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>>>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
>>> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>>>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
>>> 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>>>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
>>> -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
>>>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
>>> 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
>>>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
>>> 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>>>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
>>> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>>>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
>>> 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>>>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
>>> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>>>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
>>> 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
>>>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
>>> 34.72, 42.58, -18.15, 39.61)
>>> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
>>> 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>>>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
>>> 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
>>>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
>>> 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>>>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
>>> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
>>> 169.69,
>>>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
>>> 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
>>>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
>>> 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
>>>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
>>> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
>>> 143.71,
>>>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
>>> 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
>>>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
>>> 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
>>>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
>>> 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
>>>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
>>> my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
>>> ul, stringsAsFactors = FALSE)
>>>
>>> library(lattice)
>>> library(latticeExtra)
>>> useOuterStrips(
>>>   strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>>   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>>   stripplot(
>>>     average ~ type|target+cluster,
>>>     my.data,
>>>     groups = type,
>>>     pch=1,
>>>     jitter.data = TRUE,
>>>     main = "Group-wise",
>>>     xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>>     col = c("grey", "green", "red"),
>>>     par.settings = list(strip.background = list(col=c("paleturquoise",
>>> "grey"))),
>>>     scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>>     key = list(
>>>       space = "top",
>>>       columns = 3,
>>>       text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>       rectangles = list(col=c("grey", "green", "red"))
>>>     )
>>>   )
>>> )
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Mar 16 15:56:43 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 16 Mar 2017 14:56:43 +0000
Subject: [R] screen
In-Reply-To: <6e977af9671c4ba287a7483a08a680ac@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAJOiR6bUsfZV+f6RMUn9pdRqQ476jqm4ao9b+O-oZ2rXHen72Q@mail.gmail.com>
	<6e977af9671c4ba287a7483a08a680ac@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <5f22649a01274f52934c8f4f9305544a@exch-2p-mbx-w2.ads.tamu.edu>

Sorry. I focused on the table and not the record selection. Given the table this seems to be what you are looking for, but there may be an easier way:

> keep <- which(t(apply(DF2.tbl, 1, cumsum)) > .000001, arr.ind=TRUE)
> keep <- keep[order(keep[, 1], keep[, 2]), ]
> keep # These are the records you want to keep
  family time
A      1    2
A      1    3
A      1    4
B      2    1
B      2    2
B      2    3
B      2    4
C      3    4
# Now turn keep into a data.frame with factors: family and time
# so it matches DF2
> rownames(keep) <- NULL
> keep <- data.frame(keep)
> keep$family <- factor(keep$family, labels=levels(DF2$family))
> keep$time <- factor(keep$time, labels=levels(DF2$time))
> keep
  family  time
1      A WEEK2
2      A WEEK3
3      A WEEK4
4      B WEEK1
5      B WEEK2
6      B WEEK3
7      B WEEK4
8      C WEEK4
> DF2.new <- merge(DF2, keep)
> DF2.new
   family  time obs
1       A WEEK2   0
2       A WEEK2   1
3       A WEEK3   1
4       A WEEK3   0
5       B WEEK1   0
6       B WEEK1   1
7       B WEEK1   1
8       B WEEK2   0
9       B WEEK2   0
10      B WEEK3   1
11      B WEEK3   0
12      C WEEK4   1
13      C WEEK4   1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Thursday, March 16, 2017 9:01 AM
To: Val <valkremk at gmail.com>; r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] screen

Something like this?

> DF2.agg <- aggregate(DF2$obs, DF2[, c("family", "time")], mean)
> DF2.tbl <- xtabs(x~family+time, DF2.agg)
> DF2.tbl      time
family WEEK1 WEEK2 WEEK3 WEEK4
     A  0.00  0.50  0.50  0.00
     B  0.67  0.00  0.50  0.00
     C  0.00  0.00  0.00  1.00

You can get closer to the output in your example with this

> suppressWarnings(as.table(formatC(DF2.tbl, digits=2, width=4, zero.print=".")))
      time
family WEEK1 WEEK2 WEEK3 WEEK4
     A    .   0.5   0.5     . 
     B 0.67     .   0.5     . 
     C    .     .     .     1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
Sent: Wednesday, March 15, 2017 5:41 PM
To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] screen

HI all,

I have some data to be screened  based on the recording flag (obs).
Some family recorded properly (1) and others not (0).  Th 0 = improper
and 1 = proper

The recording  period starts week1.  All families may not start in the
same week in recording properly an observation,

  DF2 <- read.table(header=TRUE, text='family time obs
A  WEEK1 0
A  WEEK1 0
A  WEEK1 0
A  WEEK2 1
A  WEEK2 0
A  WEEK3 1
A  WEEK3 0
B  WEEK1 1
B  WEEK1 0
B  WEEK1 1
B  WEEK2 0
B  WEEK2 0
B  WEEK3 1
B  WEEK3 0
C  WEEK3 0
C  WEEK3 0
C  WEEK4 1
C  WEEK4 1')

Example, in week1  all records of family "A" are 0 (improper), but
starting the week2 they start recording proper (1) records as well.
Then I create a table that shows me the ratio of proper records to the
total records for each family within week. If the ratio is zero and
there is no prior proper recordings for that family then I want to
delete those records.

However,  once any family started showing proper records  as "1"  and
even if in the  the subsequent week the ratio is 0  then I want keep
that record for that family. Example records of week2 for family B

Here is the summary table

      WEEK1      WEEK2    WEEK3    WEEK4
A          0            0.5              0.5           .
B       0.33           0                0.5           .
C          .               .                 0            1

>From the above table
For A-  I want exclude all records of week1 and keep the rest. Because
they were not recording it propeller
For B-  Keep all records, as they stated recording properly from the beginning.
For C-  Keep only the week4 records because all records are  1's

Final and desired  result will be

A WEEK2 1
A WEEK2 0
A WEEK3 1
A WEEK3 0
B WEEK1 1
B WEEK1 0
B WEEK1 1
B WEEK2 0
B WEEK2 0
B WEEK3 1
B WEEK3 0
C WEEK4 1
C WEEK4 1


and the summary table looks like as follows

       WEEK1  WEEK2  WEEK3  WEEK4
A             .        0.5             0.5        .
B          0.33        0             0.5        .
C               .          .                 .        1

Thank you in advance

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Thu Mar 16 17:20:37 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 16 Mar 2017 17:20:37 +0100
Subject: [R] ggplot2: Adjusting title and labels
Message-ID: <OF6D3E88E6.5EE78B67-ONC12580E5.005985C1-C12580E5.0059C73C@lotus.hawesko.de>

Hi All,

I have a question to ggplot 2. My code is the following:

-- cut --

library(ggplot2)
library(scales)

df <-
  data.frame(group = c("Male", "Female", "Child"),
             value = c(25, 25, 50))

blank_theme <- theme_minimal() + theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  axis.text.x = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.ticks = element_blank(),
  plot.title = element_text(size = 4, face = "bold"))

ggplot(df, aes(x = "", y = value, fill = group)) +
  geom_bar(
    width = 1,
    stat = "identity") +
  coord_polar("y", start = 0) +
  scale_fill_brewer(
    name = "Gruppe",
    palette = "Blues") +
  blank_theme +
  geom_text(
    aes(
      y = c(10, 40, 75),
      label = scales::percent(value/100)),
    size = 5) +
  labs(title = "Pie Title")

-- cut --

Is there a way to give the position of the labels to the chunks of the pie 
in a generalized form instead of finding the value interatively by 
trial-n-error?

How can I adjust the title of the graph converning font height and postion 
(e. g. center)?

Kind regards

Georg


	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Mar 16 17:40:10 2017
From: hannah.hlx at gmail.com (li li)
Date: Thu, 16 Mar 2017 12:40:10 -0400
Subject: [R] Test individual slope for each factor level in ANCOVA
In-Reply-To: <D4EFF5CA.5937%jfox@mcmaster.ca>
References: <CAHLnndaX8zCyzjpOG1ffZka+tRVpkH82N90LzjkvFsxeVTf_ZQ@mail.gmail.com>
	<D4EFF5CA.5937%jfox@mcmaster.ca>
Message-ID: <CAHLnndYxz+PQ7ww99GNWPMRPpOK1GsVxrvXvW38ANBDnnDrr6A@mail.gmail.com>

Hi John. Thanks much for your help. It is great to know this.
  Hanna

2017-03-16 8:02 GMT-04:00 Fox, John <jfox at mcmaster.ca>:

> Dear Hanna,
>
> You can test the slope in each non-reference group as a linear hypothesis.
> You didn?t make the data available for your example, so here?s an example
> using the linearHypothesis() function in the car package with the Moore
> data set in the same package:
>
> - - - snip - - -
>
> > library(car)
> > mod <- lm(conformity ~ fscore*partner.status, data=Moore)
> > summary(mod)
>
> Call:
> lm(formula = conformity ~ fscore * partner.status, data = Moore)
>
> Residuals:
>     Min      1Q  Median      3Q     Max
> -7.5296 -2.5984 -0.4473  2.0994 12.4704
>
> Coefficients:
>                           Estimate Std. Error t value Pr(>|t|)
> (Intercept)               20.79348    3.26273   6.373 1.27e-07 ***
> fscore                    -0.15110    0.07171  -2.107  0.04127 *
> partner.statuslow        -15.53408    4.40045  -3.530  0.00104 **
> fscore:partner.statuslow   0.26110    0.09700   2.692  0.01024 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 4.562 on 41 degrees of freedom
> Multiple R-squared:  0.2942,    Adjusted R-squared:  0.2426
> F-statistic: 5.698 on 3 and 41 DF,  p-value: 0.002347
>
> > linearHypothesis(mod, "fscore + fscore:partner.statuslow")
> Linear hypothesis test
>
> Hypothesis:
> fscore  + fscore:partner.statuslow = 0
>
> Model 1: restricted model
> Model 2: conformity ~ fscore * partner.status
>
>   Res.Df    RSS Df Sum of Sq      F  Pr(>F)
> 1     42 912.45
> 2     41 853.42  1    59.037 2.8363 0.09976 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> - - - snip - - -
>
> In this case, there are just two levels for partner.status, but for a
> multi-level factor you can simply perform more than one test.
>
>
> I hope this helps,
>
>  John
>
> -------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> Web: http://socserv.mcmaster.ca/jfox/
>
>
>
>
> On 2017-03-15, 9:43 PM, "R-help on behalf of li li"
> <r-help-bounces at r-project.org on behalf of hannah.hlx at gmail.com> wrote:
>
> >Hi all,
> >   Consider the data set where there are a continuous response variable, a
> >continuous predictor "weeks" and a categorical variable "region" with five
> >levels "a", "b", "c",
> >"d", "e".
> >  I fit the ANCOVA model as follows. Here the reference level is region
> >"a"
> >and there are 4 dummy variables. The interaction terms (in red below)
> >represent the slope
> >difference between each region and  the baseline region "a" and the
> >corresponding p-value is for testing whether this slope difference is
> >zero.
> >Is there a way to directly test whether the slope corresponding to each
> >individual factor level is 0 or not, instead of testing the slope
> >difference from the baseline level?
> >  Thanks very much.
> >      Hanna
> >
> >
> >
> >
> >
> >
> >> mod <- lm(response ~ weeks*region,data)> summary(mod)
> >Call:
> >lm(formula = response ~ weeks * region, data = data)
> >
> >Residuals:
> >     Min       1Q   Median       3Q      Max
> >-0.19228 -0.07433 -0.01283  0.04439  0.24544
> >
> >Coefficients:
> >                Estimate Std. Error t value Pr(>|t|)
> >(Intercept)    1.2105556  0.0954567  12.682  1.2e-14 ***
> >weeks         -0.0213333  0.0147293  -1.448    0.156
> >regionb       -0.0257778  0.1349962  -0.191    0.850
> >regionc       -0.0344444  0.1349962  -0.255    0.800
> >regiond       -0.0754444  0.1349962  -0.559    0.580
> >regione       -0.1482222  0.1349962  -1.098    0.280    weeks:regionb
> >-0.0007222  0.0208304  -0.035    0.973
> >weeks:regionc -0.0017778  0.0208304  -0.085    0.932
> >weeks:regiond  0.0030000  0.0208304   0.144    0.886
> >weeks:regione  0.0301667  0.0208304   1.448    0.156    ---
> >Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >Residual standard error: 0.1082 on 35 degrees of freedom
> >Multiple R-squared:  0.2678,   Adjusted R-squared:  0.07946
> >F-statistic: 1.422 on 9 and 35 DF,  p-value: 0.2165
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Mar 16 18:25:29 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Mar 2017 18:25:29 +0100
Subject: [R] Quantiles with ordered categories
In-Reply-To: <0MMkgl-1cs04801bb-008Y8E@mail.gmx.com>
References: <0MFLhE-1d2Dhk1OBo-00EQRr@mail.gmx.com>
	<CAGxFJbTOysTEoLXUd4sM7H8i4j26hig-JibqD66OS+htnktJfA@mail.gmail.com>
	<0MMkgl-1cs04801bb-008Y8E@mail.gmx.com>
Message-ID: <22730.51849.439190.925935@stat.math.ethz.ch>

>>>>>   <matthias-gondan at gmx.de>
>>>>>     on Tue, 14 Mar 2017 21:54:42 +0100 writes:

    > I found it:
    > quantile(ordered(1:10), probs=0.5, type=1) 

    > works, because type=1 seems to round up or down, whatever. The default option for is 7, which wants to interpolate, and then produces the error. 

    > Two options come to my mind:

    > - The error message could be improved.
    > - The default type could be 1 if the data is from ordered categories.
    > - Or both.

Well, it is remarkable that nobody looks at the help page (or
the source code) of quantile() to be informed.

In 'Details' it has contained

    Types 1 and 3 can be used for class; "Date" and for ordered factors.

since Oct 15, 2009 ...

But I agree that the error message can be improved and have done
so now, so that instead of

    "factors are not allowed"

you now get

    "'type' must be 1 or 3 for ordered factors"


    > It is probably a little thing to fix, but I lack the skills to do this myself.

(Really? -- After seeing the change you will agree it was easy .. ?)


Thank you for the suggestion.

Best regards,

Martin Maechler
ETH Zurich


    > Best wishes,
    > Matthias


    > Von: Bert Gunter
    > Gesendet: Dienstag, 14. M?rz 2017 21:34
    > An: matthias-gondan at gmx.de
    > Cc: r-help at r-project.org
    > Betreff: Re: [R] Quantiles with ordered categories

    > Inline.
    > Bert Gunter

    > "The trouble with having an open mind is that people keep coming along
    > and sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


    > On Tue, Mar 14, 2017 at 12:36 PM,  <matthias-gondan at gmx.de> wrote:
    >> Dear R users,
    >> 
    >> This works:
    >> 
    >> quantile(1:10, probs=0.5)
    >> 
    >> This fails (obviously):
    >> 
    >> quantile(factor(1:10), probs=0.5)
    >> 
    >> But why do quantiles for ordered factors not work either?
    >> 
    >> quantile(ordered(1:10), probs=0.5)
    >> 
    >> Is it because interpolation (see the optional type argument) is not defined?
    > Yes.


    > Is there an elegant workaround?
    > No. How can there be? By definition, all that is assumed by an ordered
    > factor is an ordering of the categories. How can you "interpolate" in
    > ordered(letters[1:3]) . ASAIK there is no "a.5"  .

    > -- Bert



    >> 
    >> Thank you.
    >> 
    >> Best wishes,
    >> 
    >> Matthias
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.


    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From allantanaka11 at yahoo.com  Thu Mar 16 16:38:16 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Thu, 16 Mar 2017 15:38:16 +0000 (UTC)
Subject: [R] Error in roc.default(response, predictor, auc = TRUE,
 ...) :    No valid data provided.
References: <993317636.1497526.1489678696151.ref@mail.yahoo.com>
Message-ID: <993317636.1497526.1489678696151@mail.yahoo.com>

Check my fitted dimension:str(predict(mod, Test1))?
?Named num [1:2131] 402 2346 1995 2205 2895 ...?- attr(*, "names")= chr [1:2131] "1" "2" "4" "6" ...

So i want to see AUC score for my model being applied into Test1data after having splitting total data (Train) into Train 1 and Test 1, but i get the following error:Error in roc.default(response, predictor, auc = TRUE, ...) : ? ?No valid data provided.

Even trying this code also gives a malfunction:error<-sqrt((sum((Test1$Item_Outlet_Sales-preds)^2))/nrow(Test1)) ?
Error in Test1$Item_Outlet_Sales - preds :?? non-numeric argument to binary operator===================================================
Here is the code:
set.seed(1234)
split <- sample(1:nrow(Train),size=floor((nrow(Train)/4)*3))?Train1 <- Train[(split),]Test1 <- ?Train[-split,]outcomeName='Item_Outlet_Sales'predictorNames <- setdiff(names(Train1), outcomeName)mod <- lm(Item_Outlet_Sales ~ ., data=Train1)preds <- predict(mod, Test1[,predictorNames], se.fit = TRUE)print(auc(Test1[,outcomeName], preds$mod))
	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Thu Mar 16 16:48:19 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Thu, 16 Mar 2017 15:48:19 +0000 (UTC)
Subject: [R] HELP ME: Fill NA Values from the previous Non-NA Values
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1B4F6@SRVEXCHCM301.precheza.cz>
References: <1994411336.523592.1489576114011.ref@mail.yahoo.com>
	<1994411336.523592.1489576114011@mail.yahoo.com>
	<CAF8bMcaa0iKdJ8zRdAWFjRJ0ZXVQOcxZ+8VSLoWWRWma63oqZQ@mail.gmail.com>
	<2101887076.1087342.1489630579078@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1B4F6@SRVEXCHCM301.precheza.cz>
Message-ID: <1913883629.1470649.1489679299335@mail.yahoo.com>

Amazing! Thanks for your kindness. 

    On Thursday, 16 March 2017, 20:38, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 

 Hi

You can achieve exactly what you want by using ave/na.locf twice

dat<-data.frame(ie=rep(letters[1:3], each=3), iw=rnorm(9))
dat[c(3, 4),2]<-NA
> dat
? ie? ? ? ? ? iw
1? a? 1.07254438
2? a? 0.53067188
3? a? ? ? ? ? NA
4? b? ? ? ? ? NA
5? b -0.09767088
6? b -1.02719060
7? c? 2.35787246
8? c -0.07513048
9? c -0.17164728

dat$iw <- ave(dat$iw, dat$ie, FUN=function(x) na.locf(x, na.rm=FALSE))
dat$iw <- ave(dat$iw, dat$ie, FUN=function(x) na.locf(x, na.rm=FALSE, fromLast=TRUE))

> dat
? ie? ? ? ? ? iw
1? a? 1.07254438
2? a? 0.53067188
3? a? 0.53067188
4? b -0.09767088
5? b -0.09767088
6? b -1.02719060
7? c? 2.35787246
8? c -0.07513048
9? c -0.17164728
>

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allan
> Tanaka
> Sent: Thursday, March 16, 2017 3:16 AM
> To: William Dunlap <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] HELP ME: Fill NA Values from the previous Non-NA Values
>
>? Hi. Thanks for the function. My bad, after looking at the csv file, it seems that
> NA values come not only from previous Non-NA values but also from the
> next Non-NA values. Example:
> | NCQ05 | 11.395 |
> | NCQ05 | 11.395 |
> | NCQ05 |? |
> | NCQ06 |? |
> | NCQ06 | 13 |
> | NCQ06 | 13 |
>
>
> If i use the function, then the blank row would be filled with 11.395, instead
> of filling with 11.395 and 13.
> Does it mean that the function can be modified like this?
> locf2 <- function(x, initial=NA, IS_BAD = is.na) {
>? ? # Replace 'bad' values in 'x' with last previous non-bad value.
>? ? # If no previous non-bad value, replace with 'initial'.
>? ? stopifnot(is.function(IS_BAD))
>? ? good <- !IS_BAD(x)
>? ? stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
>? ? i <- cumsum(good)
>? ? x <- x[c(1,which(good))][i+1]
>? ? x <- x[c(1,which(good))][i+2]
>? ? x[i==0] <- initial
>? ? x
> }? ? On Thursday, 16 March 2017, 1:17, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>
>? You could use the following function
>
> locf2 <- function(x, initial=NA, IS_BAD = is.na) {
>? ? # Replace 'bad' values in 'x' with last previous non-bad value.
>? ? # If no previous non-bad value, replace with 'initial'.
>? ? stopifnot(is.function(IS_BAD))
>? ? good <- !IS_BAD(x)
>? ? stopifnot(is.logical(good), length(good) == length(x), !anyNA(good))
>? ? i <- cumsum(good)
>? ? x <- x[c(1,which(good))][i+1]
>? ? x[i==0] <- initial
>? ? x
> }
>
> as in
>
> > locf2(c("", "A", "B", "", "", "C", ""), IS_BAD=function(x)x=="",
> > initial="---")
> [1] "---" "A"? "B"? "B"? "B"? "C"? "C"
> > locf2(factor(c(NA,"Small","Medium",NA,"Large",NA,NA,NA,"Small")))
> [1] <NA>? Small? Medium Medium Large? Large? Large? Large? Small
> Levels: Large Medium Small
> > locf2(c(12, NA, 10, 11, NA, NA))
> [1] 12 12 10 11 11 11
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Mar 15, 2017 at 4:08 AM, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
> > The following is an example:
> >
> > | Item_Identifier | Item_Weight |
> > | FDP10 | 19 |
> > | FDP10 |? |
> > | DRI11 | 8.26 |
> > | DRI11 |? |
> > | FDW12 | 8.315 |
> > | FDW12 |? |
> >
> >
> > The following is the one that i want to be. That is, filling NA values from the
> previous Non-NA values.
> > | Item_Identifier | Item_Weight |
> > | FDP10 | 19 |
> > | FDP10 | 19 |
> > | DRI11 | 8.26 |
> > | DRI11 | 8.26 |
> > | FDW12 | 8.315 |
> > | FDW12 | 8.315 |
> >
> >
> > My current code data frame: train <- read.csv("Train.csv",
> > header=T,sep = ",",na.strings = c(""," ",NA))
> >
> >
> > Some people suggest to use na.locf function but in my case, i don't have
> numeric unique values in my Item_Identifier coloumn but rather it's
> characters. Not sure what to solve this problem.
> >
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


   
	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Thu Mar 16 16:16:29 2017
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 16 Mar 2017 12:16:29 -0300
Subject: [R] Display data by condition
Message-ID: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>

Hello,
I need to show the observations of a data set only if the earn more than
$5000 (fact is its name in the date set). I use this:

View(data[data$fact>5000])

The code above shows nothing. No error or message at all.
What am i doing wrong?
Thanks for your help and time.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Mar 16 18:47:20 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 16 Mar 2017 17:47:20 +0000
Subject: [R] Display data by condition
In-Reply-To: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
References: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
Message-ID: <58CACFA8.6050401@sapo.pt>

Hello,

Maybe you're missing a comma. (I'm assuming your dataset is a data.frame 
or a matrix.)
Try

View(data[data$fact>5000, ])

To give you a better answer you need to show us the output of

str(data)

And don't name your data 'data', it already is the name of an R function.
And post in plain text, not HTML.

Hope this helps,

Rui Barradas

Em 16-03-2017 15:16, Juan Ceccarelli Arias escreveu:
> Hello,
> I need to show the observations of a data set only if the earn more than
> $5000 (fact is its name in the date set). I use this:
>
> View(data[data$fact>5000])
>
> The code above shows nothing. No error or message at all.
> What am i doing wrong?
> Thanks for your help and time.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Thu Mar 16 19:04:12 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 16 Mar 2017 18:04:12 +0000
Subject: [R] ggplot2: Adjusting title and labels
In-Reply-To: <OF6D3E88E6.5EE78B67-ONC12580E5.005985C1-C12580E5.0059C73C@lotus.hawesko.de>
References: <OF6D3E88E6.5EE78B67-ONC12580E5.005985C1-C12580E5.0059C73C@lotus.hawesko.de>
Message-ID: <CAKVAULN7CLYxm3DffgHM08Jmt=VB3ufqwy8YEX8eFird1fDKpg@mail.gmail.com>

Hi Georg,

If you remove the coord_polar, you'll see that the optimal y-value for the
labels is between the upper and lower bound of the stacked bar-element.

I am not sure it is the most elegant solution, but you can calculate them
like this:

df <- data.frame(group = c("Male", "Female", "Child"),
             value = c(25, 25, 50))

# Order the data.frame to match that of the final plot
df <- df[order(df$group, decreasing = TRUE), ]
# Get the upper bound of the stacked bar element
df$upper <- cumsum(df$value)
# And the lower
df$lower <- c(0, df$upper[seq_along(1:(nrow(df) - 1))])

# Now calculate the position
df$label_pos <- (df$upper - df$lower)/2 + df$lower

# And plot
blank_theme <- theme_minimal() + theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  axis.text.x = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.ticks = element_blank(),
  plot.title = element_text(size = 4, face = "bold"))

ggplot(df, aes(x = "", y = value, fill = group)) +
  geom_bar(
    width = 1,
    stat = "identity")+
  # coord_polar("y", start = 0) +
  scale_fill_brewer(
    name = "Gruppe",
    palette = "Blues") +
  blank_theme +
  geom_text(
    aes(
      y = label_pos,
      label = scales::percent(value/100)),
    size = 5) +
  labs(title = "Pie Title")

HTH
Ulrik


On Thu, 16 Mar 2017 at 17:24 <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> I have a question to ggplot 2. My code is the following:
>
> -- cut --
>
> library(ggplot2)
> library(scales)
>
> df <-
>   data.frame(group = c("Male", "Female", "Child"),
>              value = c(25, 25, 50))
>
> blank_theme <- theme_minimal() + theme(
>   axis.title.x = element_blank(),
>   axis.title.y = element_blank(),
>   axis.text.x = element_blank(),
>   panel.border = element_blank(),
>   panel.grid = element_blank(),
>   axis.ticks = element_blank(),
>   plot.title = element_text(size = 4, face = "bold"))
>
> ggplot(df, aes(x = "", y = value, fill = group)) +
>   geom_bar(
>     width = 1,
>     stat = "identity") +
>   coord_polar("y", start = 0) +
>   scale_fill_brewer(
>     name = "Gruppe",
>     palette = "Blues") +
>   blank_theme +
>   geom_text(
>     aes(
>       y = c(10, 40, 75),
>       label = scales::percent(value/100)),
>     size = 5) +
>   labs(title = "Pie Title")
>
> -- cut --
>
> Is there a way to give the position of the labels to the chunks of the pie
> in a generalized form instead of finding the value interatively by
> trial-n-error?
>
> How can I adjust the title of the graph converning font height and postion
> (e. g. center)?
>
> Kind regards
>
> Georg
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Mar 16 19:26:17 2017
From: hannah.hlx at gmail.com (li li)
Date: Thu, 16 Mar 2017 14:26:17 -0400
Subject: [R] standard error for regression coefficients corresponding to
	factor levels
Message-ID: <CAHLnndY0Wp1JT4rHCH65wGdWT3txMcGWGtDNFdEk0hXoXc-tSw@mail.gmail.com>

Hi all,
  I have the following data called "data1". After fitting the ancova model
with different slopes and intercepts for each region, I calculated the
regression coefficients and the corresponding standard error. The standard
error (for intercept or for slope) are all the same for different regions.
Is there something wrong?
  I know the SE is related to (X^T X)^-1, where X is design matrix. So does
this happen whenever each factor level has the same set of values for
"week"?
     Thanks.
     Hanna



> mod <- lm(response ~ region*week, data1)> tmp <- coef(summary(mod))> res <- matrix(NA, 5,4)> res[1,1:2] <- tmp[1,1:2]> res[2:5,1] <- tmp[1,1]+tmp[2:5,1]> res[2:5,2] <- sqrt(tmp[2:5,2]^2-tmp[1,2]^2)> res[1,3:4] <- tmp[6,1:2]> res[2:5,3] <- tmp[6,1]+tmp[7:10,1]> res[2:5,4] <- sqrt(tmp[7:10,2]^2-tmp[6,2]^2)

> colnames(res) <- c("intercept", "intercept SE", "slope", "slope SE")> rownames(res) <- letters[1:5]> res   intercept intercept SE        slope   slope SE
a 0.18404464   0.08976301 -0.018629310 0.01385073
b 0.17605666   0.08976301 -0.022393789 0.01385073
c 0.16754130   0.08976301 -0.022367770 0.01385073
d 0.12554452   0.08976301 -0.017464385 0.01385073
e 0.06153256   0.08976301  0.007714685 0.01385073







> data1    week region     response
5      3      c  0.057325067
6      6      c  0.066723632
7      9      c -0.025317808
12     3      d  0.024692613
13     6      d  0.021761492
14     9      d -0.099820335
19     3      c  0.119559235
20     6      c -0.054456186
21     9      c  0.078811180
26     3      d  0.091667189
27     6      d -0.053400777
28     9      d  0.090754363
33     3      c  0.163818085
34     6      c  0.008959741
35     9      c -0.115410852
40     3      d  0.193920693
41     6      d -0.087738914
42     9      d  0.004987542
47     3      a  0.121332285
48     6      a -0.020202707
49     9      a  0.037295785
54     3      b  0.214304603
55     6      b -0.052346480
56     9      b  0.082501222
61     3      a  0.053540767
62     6      a -0.019182819
63     9      a -0.057629113
68     3      b  0.068592791
69     6      b -0.123298216
70     9      b -0.230671818
75     3      a  0.330741562
76     6      a  0.013902905
77     9      a  0.190620360
82     3      b  0.151002874
83     6      b  0.086177696
84     9      b  0.178982656
89     3      e  0.062974799
90     6      e  0.062035391
91     9      e  0.206200831
96     3      e  0.123102197
97     6      e  0.040181790
98     9      e  0.121332285
103    3      e  0.147557564
104    6      e  0.062035391
105    9      e  0.144965770

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 16 19:32:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 16 Mar 2017 11:32:42 -0700
Subject: [R] Display data by condition
In-Reply-To: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
References: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
Message-ID: <6DF9EB12-C54C-4B5D-820D-BFE35D588148@dcn.davis.ca.us>

Presuming "data" is a data frame because you have not provided a minimal reproducible example as requested in the Posting Guide... note also that "data" is the name of a function in base R, so that is a potentially troublesome variable name. 

 A data frame is a list of vectors. It can be indexed either as a one-dimensional object of length equal to the number of columns, or as a two-dimensional object. You are doing the former but giving a logical index appropriate for the number of rows in your data frame. Go re-read the Introduction to R document section on indexing to figure out where the comma goes.
-- 
Sent from my phone. Please excuse my brevity.

On March 16, 2017 8:16:29 AM PDT, Juan Ceccarelli Arias <jfca283 at gmail.com> wrote:
>Hello,
>I need to show the observations of a data set only if the earn more
>than
>$5000 (fact is its name in the date set). I use this:
>
>View(data[data$fact>5000])
>
>The code above shows nothing. No error or message at all.
>What am i doing wrong?
>Thanks for your help and time.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Thu Mar 16 19:34:01 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 16 Mar 2017 13:34:01 -0500
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
Message-ID: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>

Dear friends,

I am currently using R version 3.3.3 (64-bit) and used the following code
to generate forecasts:

> library(forecast)
>
> library(tseries)

    ?tseries? version: 0.10-35

    ?tseries? is a package for time series analysis and computational
finance.

    See ?library(help="tseries")? for details.


> DAT<-read.csv("TrainingData.csv")
>
> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>
> TSmodel<-nnetar(TSdata)
>
> TSmodelForecast<-forecast(TSmodel, h=24)
>
> TSmodelForecast

The problem is that the output comes in this fashion:

                Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
Sep   Oct
 2017        10      20      15      40     9         8         21     21
    19     18
 2018        34      15       7        6      10      11

The format I would like to have is the following:

Date                 Forecast
Jan-2017               10
Feb-2017               20
Mar-2017               15
Apr-2017                40
May-2017               9
Jun-2017                8
Jul-2017                 21
Aug-2017               21
Sep-2017               19
etc                          etc

Is there a way to make the results look like this?

Attached is a dataset as a reference.

Best regards,

Paul

From jholtman at gmail.com  Thu Mar 16 21:19:18 2017
From: jholtman at gmail.com (jim holtman)
Date: Thu, 16 Mar 2017 16:19:18 -0400
Subject: [R] Display data by condition
In-Reply-To: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
References: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
Message-ID: <CAAxdm-7czVSD4NeqApPddH5gwd9sU=QRA+hu33BzfWZ1x-An8Q@mail.gmail.com>

you are probably missing a comma:

View(data[data$fact > 5000, ])


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Mar 16, 2017 at 11:16 AM, Juan Ceccarelli Arias <jfca283 at gmail.com>
wrote:

> Hello,
> I need to show the observations of a data set only if the earn more than
> $5000 (fact is its name in the date set). I use this:
>
> View(data[data$fact>5000])
>
> The code above shows nothing. No error or message at all.
> What am i doing wrong?
> Thanks for your help and time.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alfonso.carfora at uniparthenope.it  Thu Mar 16 22:03:08 2017
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Thu, 16 Mar 2017 22:03:08 +0100
Subject: [R] coeftest with covariance matrix
Message-ID: <20170316220308.Horde.c9OeYVaa-zikzbl6QHzKMQ3@webmail.uniparthenope.it>

Hi all,


I want to ask you which is the difference between the specifyng and  
not specifyng the covariance matrix of the estimated coefficients when  
performing the coeftest command.

I'm estimating a VECM model and I want to test the significance of the  
short-run casual effects of the explanatory variables:

mod<-cajorls(ca.jo(data[,4:6], ecdet = "const", type="eigen", K=2,  
spec="longrun"))$rlm

The command:

coeftest(mod)

give me different results with respect to this one:

V<-vcovHC(mod)
coeftest(mod,V)


From drjimlemon at gmail.com  Thu Mar 16 22:09:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 17 Mar 2017 08:09:58 +1100
Subject: [R]
	=?utf-8?q?How_to_get_the_transpose_of_R=C2=B4s_function_forec?=
	=?utf-8?q?ast_output_and_turn_it_into_a_data_frame?=
In-Reply-To: <CAMOcQfPx-c8Cn3ytqCswm3EDaZdbuHW2cVuybLq=PvNc8J0f=g@mail.gmail.com>
References: <CAMOcQfPx-c8Cn3ytqCswm3EDaZdbuHW2cVuybLq=PvNc8J0f=g@mail.gmail.com>
Message-ID: <CA+8X3fX36BxStcbKJ_jCfp+1xz=w_j1cqYgW+-9cq+K26G8FfA@mail.gmail.com>

Hi Paul,
As Peter noted, without knowing the structure of the the object, only
a guess can be made. Mine is:

fdf<-data.frame(Date=names(forecast),forecast=forecast)

You may want to apply as.numeric to the names.

Jim



On Thu, Mar 16, 2017 at 11:43 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear all,
>
> Hope you are doing great. Some R time series functions generate the
> forecasts in an horizontal way, for example:
>
>                 2017     2018     2019    2020
> forecast    12           15        35        75
>
> but I?d like to have the output as follows:
>
>
> Date      forecast
> 2017           12
> 2018           15
> 2019           35
> 2020           75
>
> I tried using the t() function to get the transpose, but after taking the
> transpose I was not able to turn it into a data frame.
>
> Any help will be greatly appreciated,
>
> Cheers,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Thu Mar 16 22:31:49 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 16 Mar 2017 22:31:49 +0100 (CET)
Subject: [R] coeftest with covariance matrix
In-Reply-To: <20170316220308.Horde.c9OeYVaa-zikzbl6QHzKMQ3@webmail.uniparthenope.it>
References: <20170316220308.Horde.c9OeYVaa-zikzbl6QHzKMQ3@webmail.uniparthenope.it>
Message-ID: <alpine.DEB.2.20.1703162211070.29829@paninaro>


On Thu, 16 Mar 2017, alfonso.carfora at uniparthenope.it wrote:

> Hi all,
>
>
> I want to ask you which is the difference between the specifyng and not 
> specifyng the covariance matrix of the estimated coefficients when 
> performing the coeftest command.

coeftest(object, ...) computes Wald statistics for all coefficients. Hence 
coef(object) is used to extract the coefficients and then, by default, 
vcov(object) is used to extract the variance-covariance matrix. For lm() 
models this computes the "usual" covariance matrix estimate assuming 
homoskedastic and uncorelated errors.

When you supply coeftest(object, vcov = vcovHC) then a 
heteroscedasticity-consistent covariance matrix estimate is used (HC3 by 
default).

See vignette("sandwich", package = "sandwich") for more details.

> I'm estimating a VECM model and I want to test the significance of the 
> short-run casual effects of the explanatory variables:
>
> mod<-cajorls(ca.jo(data[,4:6], ecdet = "const", type="eigen", K=2, 
> spec="longrun"))$rlm
>
> The command:
>
> coeftest(mod)
>
> give me different results with respect to this one:
>
> V<-vcovHC(mod)
> coeftest(mod,V)
>
>


From david.paul at statmetrics.biz  Thu Mar 16 18:42:06 2017
From: david.paul at statmetrics.biz (David Paul)
Date: Thu, 16 Mar 2017 10:42:06 -0700
Subject: [R] propensity scores & imputation
Message-ID: <01dd01d29e7c$a369f810$ea3de830$@statmetrics.biz>

Hi,

 

Many thanks in advance for whatever advice / input I may receive.

 

I have a propensity score matching / data imputation question.  The purpose
of the propensity

score modeling is to put subjects from two different clinical trials on a
similar footing so that a key

clinical measurement from one study can be attributed / imputed to the other
study.  The goal is

NOT to directly compare the two studies, so this is a very atypical kind of
propensity score usage.

 

I am using lrm( ) to obtain estimated propensity scores, and my question to
this List is rather more 

philosophical than R-syntax.

 

 

Here is the data setup:

 

   a.frame
b.frame

   -----------
------------

   1. Represents  data from clinical trial A                            1.
Represents  data from clinical trial B

  2. Two arms, 'ACTIVE' and 'PLACEBO'                              2. Two
arms, 'ACTIVE' and 'PLACEBO'

   3. The active drug is the same as with Study B              3. The active
drug is the same as with Study A

   4. The trial design is very similar to Study B                    4. The
trial design is very similar to Study A

   5. One measurement is a clinical continuous                 5. Does NOT
have the clinical continuous measure

        measure obtained via laboratory assay                           that
is available in Study A

   6. Number of randomized subjects = 500                       6. Number of
randomized subjects = 5,000

   7. A subset of the baseline covariates (call it                 7. A
subset of the baseline covariates (call it

        a.subset.frame) has 100% commonality
b.subset.frame) has 100% commonality

        with b.subset.frame
with a.subset.frame

 
8. Primary endpoint is time-to-event

 

 

Here is the analysis setup:

 

I have separately split a.frame and b.frame into 'ACTIVE' and 'PLACEBO'
subjects.  

 

For the 'PLACEBO' subjects I have entered the a.subset.frame =
b.subset.frame baseline 

covariates into lrm( ).  The outcome variable is a factor variable
representing Study A = 'Y', 

so the estimated propensity scores are the estimated probabilities that a
'PLACEBO' subject is

from Study A.  I then, finally, used the %GREEDY algorithm (posted on Mayo
Clinic website)

in SAS to match 1-to-many where the Study A subjects are thought of as
'case' subjects and

the Study B subjects are thought of as 'control' subjects. [I know the
matching can be done

in R, I'm working on that now.]  The average number of Study B subjects
matched to a 

single Study A subject is approximately 5.

 

I have done a similar analysis for the 'ACTIVE' subjects.

 

 

 

Here is my question:

 

At the end, I will combine the Study B matched 'PLACEBO' and 'ACTIVE'
subjects and 

perform a Cox PH regression to compare 'PLACEBO' and 'ACTIVE' - there will
be no Study A 

subjects in this analysis.  I want to incorporate the clinical continuous
measurement "borrowed" 

from Study A as a covariate.  When doing this, how should I best take into
account the 

1-to-many matching?  Do I need to weight the Study B subjects, or can I
simply enter the 

matched Study B subjects into a Cox PH regression and ignore the 1-to-many
issue?

 

 

Kind Regards,

 

     David

 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: PGP.sig
Type: application/pgp-signature
Size: 842 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170316/5e4c6d3e/attachment.bin>

From jfca283 at gmail.com  Thu Mar 16 19:38:28 2017
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 16 Mar 2017 15:38:28 -0300
Subject: [R] Display data by condition
In-Reply-To: <6DF9EB12-C54C-4B5D-820D-BFE35D588148@dcn.davis.ca.us>
References: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
	<6DF9EB12-C54C-4B5D-820D-BFE35D588148@dcn.davis.ca.us>
Message-ID: <CALBYkjK13rRXzRhJ6X++wyZ+ykniMG-0N3eH6+5wtcZO6iODoA@mail.gmail.com>

Thank you both.
The issue was I didn't declare the database as a data frame and I also
forgot the comma...

ene=as.data.frame(data)
attach(ene)
View(ene[ene$fact>5000,])

The code listed did the trick I desired.
Again, thanks I can say the problem is solved.




On Thu, Mar 16, 2017 at 3:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Presuming "data" is a data frame because you have not provided a minimal
> reproducible example as requested in the Posting Guide... note also that
> "data" is the name of a function in base R, so that is a potentially
> troublesome variable name.
>
>  A data frame is a list of vectors. It can be indexed either as a
> one-dimensional object of length equal to the number of columns, or as a
> two-dimensional object. You are doing the former but giving a logical index
> appropriate for the number of rows in your data frame. Go re-read the
> Introduction to R document section on indexing to figure out where the
> comma goes.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 16, 2017 8:16:29 AM PDT, Juan Ceccarelli Arias <jfca283 at gmail.com>
> wrote:
> >Hello,
> >I need to show the observations of a data set only if the earn more
> >than
> >$5000 (fact is its name in the date set). I use this:
> >
> >View(data[data$fact>5000])
> >
> >The code above shows nothing. No error or message at all.
> >What am i doing wrong?
> >Thanks for your help and time.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Thu Mar 16 21:22:05 2017
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 16 Mar 2017 17:22:05 -0300
Subject: [R] Display data by condition
In-Reply-To: <CAAxdm-7czVSD4NeqApPddH5gwd9sU=QRA+hu33BzfWZ1x-An8Q@mail.gmail.com>
References: <CALBYkjLh9PctWQ-FBZbxwOpy0nDcwPJ7onpt+y4p+X=_CBy=XA@mail.gmail.com>
	<CAAxdm-7czVSD4NeqApPddH5gwd9sU=QRA+hu33BzfWZ1x-An8Q@mail.gmail.com>
Message-ID: <CALBYkj++ZY11DGTaFzzzmdK1TRUctFzv3SuY4_T1b8oTMPdsHw@mail.gmail.com>

Thanks, but I already solved it as you wrote it.
I was a missing comma.

On Thu, Mar 16, 2017 at 5:19 PM, jim holtman <jholtman at gmail.com> wrote:

> you are probably missing a comma:
>
> View(data[data$fact > 5000, ])
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Thu, Mar 16, 2017 at 11:16 AM, Juan Ceccarelli Arias <jfca283 at gmail.com
> > wrote:
>
>> Hello,
>> I need to show the observations of a data set only if the earn more than
>> $5000 (fact is its name in the date set). I use this:
>>
>> View(data[data$fact>5000])
>>
>> The code above shows nothing. No error or message at all.
>> What am i doing wrong?
>> Thanks for your help and time.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Mar 17 00:23:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 17 Mar 2017 10:23:53 +1100
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>
Message-ID: <CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>

Hi Paul,
It looks like the information that is printed is in:

TSModelForecast$mean

If str(TSModelForecast$mean) returns something like a list with two
components, you can probably use something like this:

paste(format(TSModelForecast$mean$Date,"%b-%Y"),
 TSModelForecast$mean$Forecast,sep="-",collapse="\n")

It also might be in TSModelForecast$fitted

Jim


On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear friends,
>
> I am currently using R version 3.3.3 (64-bit) and used the following code
> to generate forecasts:
>
>> library(forecast)
>>
>> library(tseries)
>
>     ?tseries? version: 0.10-35
>
>     ?tseries? is a package for time series analysis and computational
> finance.
>
>     See ?library(help="tseries")? for details.
>
>
>> DAT<-read.csv("TrainingData.csv")
>>
>> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>>
>> TSmodel<-nnetar(TSdata)
>>
>> TSmodelForecast<-forecast(TSmodel, h=24)
>>
>> TSmodelForecast
>
> The problem is that the output comes in this fashion:
>
>                 Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
> Sep   Oct
>  2017        10      20      15      40     9         8         21     21
>     19     18
>  2018        34      15       7        6      10      11
>
> The format I would like to have is the following:
>
> Date                 Forecast
> Jan-2017               10
> Feb-2017               20
> Mar-2017               15
> Apr-2017                40
> May-2017               9
> Jun-2017                8
> Jul-2017                 21
> Aug-2017               21
> Sep-2017               19
> etc                          etc
>
> Is there a way to make the results look like this?
>
> Attached is a dataset as a reference.
>
> Best regards,
>
> Paul
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Mar 17 00:41:31 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 17 Mar 2017 12:41:31 +1300
Subject: [R] [FORGED] standard error for regression coefficients
 corresponding to factor levels
In-Reply-To: <CAHLnndY0Wp1JT4rHCH65wGdWT3txMcGWGtDNFdEk0hXoXc-tSw@mail.gmail.com>
References: <CAHLnndY0Wp1JT4rHCH65wGdWT3txMcGWGtDNFdEk0hXoXc-tSw@mail.gmail.com>
Message-ID: <56c61009-7e06-9292-9880-2494a5d6e37b@auckland.ac.nz>


You have been posting to the R-help list long enough so that you should 
have learned by now *not* to post in html.  Your code is mangled so as 
to be unreadable.

A few comments:

(1) Your data frame "data1" seems to have a mysterious (and irrelevant?) 
column named "data1" as well.

(2) The covariance matrix of your coefficient estimates is indeed (as 
you hint) a constant multiple of (X^T X)^{-1}.  So do:

     X <- model.matrix(~response*week,data=data1)
     S <- solve(t(X)%*%X)
     print(S)

and you will see the same pattern of constancy that your results exhibit.

(3) You could get the results you want much more easily, without all the
fooling around buried in your (illegible) code, by doing:

     mod <- lm(response ~ (region - 1)/week,data=data1)
     summary(mod)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 17/03/17 07:26, li li wrote:
> Hi all,
>   I have the following data called "data1". After fitting the ancova model
> with different slopes and intercepts for each region, I calculated the
> regression coefficients and the corresponding standard error. The standard
> error (for intercept or for slope) are all the same for different regions.
> Is there something wrong?
>   I know the SE is related to (X^T X)^-1, where X is design matrix. So does
> this happen whenever each factor level has the same set of values for
> "week"?
>      Thanks.
>      Hanna
>
>
>
>> mod <- lm(response ~ region*week, data1)> tmp <- coef(summary(mod))> res <- matrix(NA, 5,4)> res[1,1:2] <- tmp[1,1:2]> res[2:5,1] <- tmp[1,1]+tmp[2:5,1]> res[2:5,2] <- sqrt(tmp[2:5,2]^2-tmp[1,2]^2)> res[1,3:4] <- tmp[6,1:2]> res[2:5,3] <- tmp[6,1]+tmp[7:10,1]> res[2:5,4] <- sqrt(tmp[7:10,2]^2-tmp[6,2]^2)
>
>> colnames(res) <- c("intercept", "intercept SE", "slope", "slope SE")> rownames(res) <- letters[1:5]> res   intercept intercept SE        slope   slope SE
> a 0.18404464   0.08976301 -0.018629310 0.01385073
> b 0.17605666   0.08976301 -0.022393789 0.01385073
> c 0.16754130   0.08976301 -0.022367770 0.01385073
> d 0.12554452   0.08976301 -0.017464385 0.01385073
> e 0.06153256   0.08976301  0.007714685 0.01385073
>
>
>
>
>
>
>
>> data1    week region     response
> 5      3      c  0.057325067
> 6      6      c  0.066723632
> 7      9      c -0.025317808
> 12     3      d  0.024692613
> 13     6      d  0.021761492
> 14     9      d -0.099820335
> 19     3      c  0.119559235
> 20     6      c -0.054456186
> 21     9      c  0.078811180
> 26     3      d  0.091667189
> 27     6      d -0.053400777
> 28     9      d  0.090754363
> 33     3      c  0.163818085
> 34     6      c  0.008959741
> 35     9      c -0.115410852
> 40     3      d  0.193920693
> 41     6      d -0.087738914
> 42     9      d  0.004987542
> 47     3      a  0.121332285
> 48     6      a -0.020202707
> 49     9      a  0.037295785
> 54     3      b  0.214304603
> 55     6      b -0.052346480
> 56     9      b  0.082501222
> 61     3      a  0.053540767
> 62     6      a -0.019182819
> 63     9      a -0.057629113
> 68     3      b  0.068592791
> 69     6      b -0.123298216
> 70     9      b -0.230671818
> 75     3      a  0.330741562
> 76     6      a  0.013902905
> 77     9      a  0.190620360
> 82     3      b  0.151002874
> 83     6      b  0.086177696
> 84     9      b  0.178982656
> 89     3      e  0.062974799
> 90     6      e  0.062035391
> 91     9      e  0.206200831
> 96     3      e  0.123102197
> 97     6      e  0.040181790
> 98     9      e  0.121332285
> 103    3      e  0.147557564
> 104    6      e  0.062035391
> 105    9      e  0.144965770
>
> 	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar 17 03:51:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 16 Mar 2017 19:51:03 -0700
Subject: [R] propensity scores & imputation
In-Reply-To: <01dd01d29e7c$a369f810$ea3de830$@statmetrics.biz>
References: <01dd01d29e7c$a369f810$ea3de830$@statmetrics.biz>
Message-ID: <CAGxFJbSM7VfyvFZLSb6Ebxf6gaVz26nkRWC4GrqU6OFdLGEkZw@mail.gmail.com>

Way out of bounds for this list (see the posting guide). Try posting
on stats.stackexchange.com instead.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 16, 2017 at 10:42 AM, David Paul <david.paul at statmetrics.biz> wrote:
> Hi,
>
>
>
> Many thanks in advance for whatever advice / input I may receive.
>
>
>
> I have a propensity score matching / data imputation question.  The purpose
> of the propensity
>
> score modeling is to put subjects from two different clinical trials on a
> similar footing so that a key
>
> clinical measurement from one study can be attributed / imputed to the other
> study.  The goal is
>
> NOT to directly compare the two studies, so this is a very atypical kind of
> propensity score usage.
>
>
>
> I am using lrm( ) to obtain estimated propensity scores, and my question to
> this List is rather more
>
> philosophical than R-syntax.
>
>
>
>
>
> Here is the data setup:
>
>
>
>    a.frame
> b.frame
>
>    -----------
> ------------
>
>    1. Represents  data from clinical trial A                            1.
> Represents  data from clinical trial B
>
>   2. Two arms, 'ACTIVE' and 'PLACEBO'                              2. Two
> arms, 'ACTIVE' and 'PLACEBO'
>
>    3. The active drug is the same as with Study B              3. The active
> drug is the same as with Study A
>
>    4. The trial design is very similar to Study B                    4. The
> trial design is very similar to Study A
>
>    5. One measurement is a clinical continuous                 5. Does NOT
> have the clinical continuous measure
>
>         measure obtained via laboratory assay                           that
> is available in Study A
>
>    6. Number of randomized subjects = 500                       6. Number of
> randomized subjects = 5,000
>
>    7. A subset of the baseline covariates (call it                 7. A
> subset of the baseline covariates (call it
>
>         a.subset.frame) has 100% commonality
> b.subset.frame) has 100% commonality
>
>         with b.subset.frame
> with a.subset.frame
>
>
> 8. Primary endpoint is time-to-event
>
>
>
>
>
> Here is the analysis setup:
>
>
>
> I have separately split a.frame and b.frame into 'ACTIVE' and 'PLACEBO'
> subjects.
>
>
>
> For the 'PLACEBO' subjects I have entered the a.subset.frame =
> b.subset.frame baseline
>
> covariates into lrm( ).  The outcome variable is a factor variable
> representing Study A = 'Y',
>
> so the estimated propensity scores are the estimated probabilities that a
> 'PLACEBO' subject is
>
> from Study A.  I then, finally, used the %GREEDY algorithm (posted on Mayo
> Clinic website)
>
> in SAS to match 1-to-many where the Study A subjects are thought of as
> 'case' subjects and
>
> the Study B subjects are thought of as 'control' subjects. [I know the
> matching can be done
>
> in R, I'm working on that now.]  The average number of Study B subjects
> matched to a
>
> single Study A subject is approximately 5.
>
>
>
> I have done a similar analysis for the 'ACTIVE' subjects.
>
>
>
>
>
>
>
> Here is my question:
>
>
>
> At the end, I will combine the Study B matched 'PLACEBO' and 'ACTIVE'
> subjects and
>
> perform a Cox PH regression to compare 'PLACEBO' and 'ACTIVE' - there will
> be no Study A
>
> subjects in this analysis.  I want to incorporate the clinical continuous
> measurement "borrowed"
>
> from Study A as a covariate.  When doing this, how should I best take into
> account the
>
> 1-to-many matching?  Do I need to weight the Study B subjects, or can I
> simply enter the
>
> matched Study B subjects into a Cox PH regression and ignore the 1-to-many
> issue?
>
>
>
>
>
> Kind Regards,
>
>
>
>      David
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david.paul at statmetrics.biz  Fri Mar 17 03:52:50 2017
From: david.paul at statmetrics.biz (David Paul)
Date: Thu, 16 Mar 2017 19:52:50 -0700
Subject: [R] propensity scores & imputation
In-Reply-To: <CAGxFJbSM7VfyvFZLSb6Ebxf6gaVz26nkRWC4GrqU6OFdLGEkZw@mail.gmail.com>
References: <01dd01d29e7c$a369f810$ea3de830$@statmetrics.biz>
	<CAGxFJbSM7VfyvFZLSb6Ebxf6gaVz26nkRWC4GrqU6OFdLGEkZw@mail.gmail.com>
Message-ID: <023f01d29ec9$9250f540$b6f2dfc0$@statmetrics.biz>

Hi Mr. Gunter,

Will do.  Thanks, I've not visited stats.stackexchange before.


Kind Regards,

	David

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, March 16, 2017 7:51 PM
To: david.paul at statmetrics.biz
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] propensity scores & imputation

Way out of bounds for this list (see the posting guide). Try posting on stats.stackexchange.com instead.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 16, 2017 at 10:42 AM, David Paul <david.paul at statmetrics.biz> wrote:
> Hi,
>
>
>
> Many thanks in advance for whatever advice / input I may receive.
>
>
>
> I have a propensity score matching / data imputation question.  The 
> purpose of the propensity
>
> score modeling is to put subjects from two different clinical trials 
> on a similar footing so that a key
>
> clinical measurement from one study can be attributed / imputed to the 
> other study.  The goal is
>
> NOT to directly compare the two studies, so this is a very atypical 
> kind of propensity score usage.
>
>
>
> I am using lrm( ) to obtain estimated propensity scores, and my 
> question to this List is rather more
>
> philosophical than R-syntax.
>
>
>
>
>
> Here is the data setup:
>
>
>
>    a.frame
> b.frame
>
>    -----------
> ------------
>
>    1. Represents  data from clinical trial A                            1.
> Represents  data from clinical trial B
>
>   2. Two arms, 'ACTIVE' and 'PLACEBO'                              2. Two
> arms, 'ACTIVE' and 'PLACEBO'
>
>    3. The active drug is the same as with Study B              3. The active
> drug is the same as with Study A
>
>    4. The trial design is very similar to Study B                    4. The
> trial design is very similar to Study A
>
>    5. One measurement is a clinical continuous                 5. Does NOT
> have the clinical continuous measure
>
>         measure obtained via laboratory assay                           that
> is available in Study A
>
>    6. Number of randomized subjects = 500                       6. Number of
> randomized subjects = 5,000
>
>    7. A subset of the baseline covariates (call it                 7. A
> subset of the baseline covariates (call it
>
>         a.subset.frame) has 100% commonality
> b.subset.frame) has 100% commonality
>
>         with b.subset.frame
> with a.subset.frame
>
>
> 8. Primary endpoint is time-to-event
>
>
>
>
>
> Here is the analysis setup:
>
>
>
> I have separately split a.frame and b.frame into 'ACTIVE' and 'PLACEBO'
> subjects.
>
>
>
> For the 'PLACEBO' subjects I have entered the a.subset.frame = 
> b.subset.frame baseline
>
> covariates into lrm( ).  The outcome variable is a factor variable 
> representing Study A = 'Y',
>
> so the estimated propensity scores are the estimated probabilities 
> that a 'PLACEBO' subject is
>
> from Study A.  I then, finally, used the %GREEDY algorithm (posted on 
> Mayo Clinic website)
>
> in SAS to match 1-to-many where the Study A subjects are thought of as 
> 'case' subjects and
>
> the Study B subjects are thought of as 'control' subjects. [I know the 
> matching can be done
>
> in R, I'm working on that now.]  The average number of Study B 
> subjects matched to a
>
> single Study A subject is approximately 5.
>
>
>
> I have done a similar analysis for the 'ACTIVE' subjects.
>
>
>
>
>
>
>
> Here is my question:
>
>
>
> At the end, I will combine the Study B matched 'PLACEBO' and 'ACTIVE'
> subjects and
>
> perform a Cox PH regression to compare 'PLACEBO' and 'ACTIVE' - there 
> will be no Study A
>
> subjects in this analysis.  I want to incorporate the clinical 
> continuous measurement "borrowed"
>
> from Study A as a covariate.  When doing this, how should I best take 
> into account the
>
> 1-to-many matching?  Do I need to weight the Study B subjects, or can 
> I simply enter the
>
> matched Study B subjects into a Cox PH regression and ignore the 
> 1-to-many issue?
>
>
>
>
>
> Kind Regards,
>
>
>
>      David
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: PGP.sig
Type: application/pgp-signature
Size: 842 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170316/29cecce8/attachment.bin>

From ross.chapman at ecogeonomix.com  Fri Mar 17 07:25:56 2017
From: ross.chapman at ecogeonomix.com (ross.chapman at ecogeonomix.com)
Date: Fri, 17 Mar 2017 17:25:56 +1100
Subject: [R] bnlearn impute problem
Message-ID: <004201d29ee7$566e5130$034af390$@ecogeonomix.com>

Hi all,

 

I am having a problem running the "impute" function from the bnlearn
package.

 

I have tried running the example in the documentation  as follows:

 

with.missing.data = gaussian.test

with.missing.data[sample(nrow(with.missing.data), 500), "F"] = NA

fitted = bn.fit(model2network("[A][B][E][G][C|A:B][D|B][F|A:D:E:G]"),

           gaussian.test)

 

imputed = impute(fitted, with.missing.data)

 

Which then returns the error message:

 

Error: could not find function "impute"

 

Can you please indicate what I am doing wrong here?

 

My R version is:

 

platform       x86_64-w64-mingw32          
arch           x86_64                      
os             mingw32                     
system         x86_64, mingw32             
status                                     
major          3                           
minor          3.1                         
year           2016                        
month          06                          
day            21                          
svn rev        70800                       
language       R                           
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair

 

My bnlearn version is 4.0.

 

Many thanks

 

Ross


	[[alternative HTML version deleted]]


From c.puschmann at student.unsw.edu.au  Fri Mar 17 01:41:41 2017
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Fri, 17 Mar 2017 00:41:41 +0000
Subject: [R] Percent transformation
In-Reply-To: <2ACC724D-CA6F-4582-B0D3-BD2785AF38CF@dcn.davis.ca.us>
References: <610A21D4-FDCC-4DBA-B11E-7514576D7EB3@ad.unsw.edu.au>
	<2ACC724D-CA6F-4582-B0D3-BD2785AF38CF@dcn.davis.ca.us>
Message-ID: <180D143F-9FAD-4415-BFEC-FE446FF0401D@ad.unsw.edu.au>

Dear All,

Thank you for helping me out.

First, I am sorry for adding a HTML element. I was not aware of it. I simply copy and pasted the output of mat_data from R studio.

Second, no it is not homework. It was part of a side project at work.

Third, thank you Jeff. Your comment was really productive. I discovered two alternatives:
1) mat_data = as.matrix(sapply(x[,2:ncol(x)], percent))
2) mat_data = as.matrix(sapply(x[,2:ncol(x)], as.numeric)*100)
    mat_data = round(mat_data,1)

Regards,

Christoph

> On 15 Mar 2017, at 5:32 pm, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Your x variable is a data frame. The scales::percent() function does not work on data frames. It might work on the individual columns in the data frame. You probably ought to re-read your preferred introduction to R material on the difference between data frames and the columns in data frames. 
> 
> Try
> 
> scales::percent( sp[[ 1 ]] )
> 
> Do beware that that function converts your numbers into character strings, unlike Excel. It is often more practical to simply multiply by 100 and forego the percent sign. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 14, 2017 2:19:59 PM PDT, Christoph Puschmann <c.puschmann at student.unsw.edu.au> wrote:
>> Hello all,
>> 
>> I am having a problem of transforming decimals into percentage.
>> Specifically, I get the following error message:
>> 
>> "Error in UseMethod("round_any") :
>> no applicable method for 'round_any' applied to an object of class
>> ?data.frame"
>> 
>> My code looks the following:
>> 
>> x <- sp[1:5,2:6]
>> x = percent(x)
>> 
>> My Data:
>> 
>> SD      D       N       A       SA
>> 
>> 
>> 
>> 
>> 
>> 
>> 1
>> 
>> 0.005769231
>> 
>> -0.14230769
>> 
>> 0.071153846
>> 
>> 0.09615385
>> 
>> -0.030769231
>> 
>> 2
>> 
>> -0.057692308
>> 
>> -0.08461538
>> 
>> 0.038461538
>> 
>> 0.01923077
>> 
>> 0.084615385
>> 
>> 3
>> 
>> -0.076923077
>> 
>> -0.10384615
>> 
>> 0.221153846
>> 
>> -0.04423077
>> 
>> 0.003846154
>> 
>> 4
>> 
>> -0.167307692
>> 
>> -0.13653846
>> 
>> -0.003846154
>> 
>> 0.16153846
>> 
>> 0.146153846
>> 
>> 5
>> 
>> 0.000000000
>> 
>> -0.01923077
>> 
>> 0.011538462
>> 
>> 0.21923077
>> 
>> -0.2115384
>> 
>> All help would be appreciated. Thank you.
>> 
>> Christoph
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Fri Mar 17 09:27:01 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 17 Mar 2017 08:27:01 +0000
Subject: [R] add median value and standard deviation bar to lattice plot
In-Reply-To: <CAGxFJbQzVZSRum=Pg2kBKTKYWJ3=M9ZfiMjck=FF33GysKEb3A@mail.gmail.com>
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
	<CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>
	<CAMk+s2TMae8RAk-aqA521rRW1ADvq1E3Gd3vRHDwbouHmakVFw@mail.gmail.com>
	<CAGxFJbQzVZSRum=Pg2kBKTKYWJ3=M9ZfiMjck=FF33GysKEb3A@mail.gmail.com>
Message-ID: <CAMk+s2SUQSgU871nKbgG5DrhwR_67o-G5nx8QNQEzGhfkhTp8Q@mail.gmail.com>

dear Bert,
the code as I read it draws 30 median lines, one for each cluster.
what I am looking for is a function that will plot 190 individual
confidence intervals, one for each measurement. would the code cover
even that instance?
regards
luigi

On Thu, Mar 16, 2017 at 2:41 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Just add whatever further code to decorate the groups as you like
> within the panel.groups function. I believe I have given you
> sufficient information in my code for you to do that if you study the
> code carefully. Depending on what you decide to do -- which is
> statistical and OT here (and not something I would offer specific
> advice on remotely anyway) -- you may also have to pass down
> additional arguments based on computations that you do with *all* the
> data from *all* groups together.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Mar 16, 2017 at 1:38 AM, Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
>> dear Bert,
>> thank you for the solution, it worked perfectly. However I still would
>> like to know how reliable are the dots that are plotted, that is why i
>> would like to have individual bars on each dot (if possible). the
>> standard deviation maybe is not the right tool and the confidence
>> interval is perhaps better, but the procedure should be the same: draw
>> an arrow from the lower to the upper limit. is that possible?
>> regards,
>> luigi
>>
>> PS sorry for the formatting, usually plain text is my default; it
>> should have switched to html when i replied to a previous email but
>> the difference does not show up when i type...
>>
>> On Wed, Mar 15, 2017 at 4:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> There may be a specific function that handles this for you, but to
>>> roll your own, you need a custom panel.groups function, not the
>>> default. You need to modify the panel function (which is
>>> panel.superpose by default) to pass down the "col" argument to the
>>> panel.segments call in the panel.groups function.
>>>
>>> This should get you started:
>>>
>>> useOuterStrips(
>>>    strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>>    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>>    stripplot(
>>>       average ~ type|target+cluster,
>>>       panel = function(x,y,col,...)
>>>          panel.superpose(x,y,col=col,...),
>>>       panel.groups = function(x,y,col,...){
>>>          panel.stripplot(x,y,col=col,...)
>>>          m <- median(y)
>>>          panel.segments(x0 = x[1] -.5, y0 = m,
>>>                         x1 = x[1] +.5, y1 = m,
>>>                         col=col, lwd=2
>>>                         )
>>>       },
>>>       my.data,
>>>       groups = type,
>>>       pch=1,
>>>       jitter.data = TRUE,
>>>       main = "Group-wise",
>>>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>>       col = c("grey", "green", "red"),
>>>       par.settings = list(strip.background = list(col=c("paleturquoise",
>>>                                                         "grey"))),
>>>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>>       key = list(
>>>          space = "top",
>>>          columns = 3,
>>>          text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>          rectangles = list(col=c("grey", "green", "red"))
>>>       )
>>>    )
>>> )
>>>
>>> FWIW, I think adding 1 sd bars is a bad idea statistically.
>>>
>>> And though it made no difference here, please post in pain text, not HTML.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Mar 15, 2017 at 2:22 AM, Luigi Marongiu
>>> <marongiu.luigi at gmail.com> wrote:
>>>> Dear all,
>>>> I am analyzing some multivariate data that is organized like this:
>>>> 1st variable = cluster (A or B)
>>>> 2nd variable = target (a, b, c, d, e)
>>>> 3rd variable = type (blank, negative, positive)
>>>> 4th variable = sample (the actual name of the sample)
>>>> 5th variable = average (the actual reading -- please not that this is the
>>>> mean of different measures with an assumed normal distribution, but the
>>>> assumption might not always be true)
>>>> 6th variable = stdev (the standard deviation associated with each reading)
>>>> 7th variable = ll (lower limit that is average stdev)
>>>> 8th variable = ul (upper limit that is average + stdev)
>>>>
>>>> I am plotting the data using lattice's stripplot and I would need to add:
>>>> 1. an error bar for each measurement. the bar should be possibly coloured
>>>> in light grey and semitransparent to reduce the noise of the plot.
>>>> 2. a type-based median bar to show differences in measurements between
>>>> blanks, negative and positive samples within each panel.
>>>>
>>>> How would I do that?
>>>> Many thanks,
>>>> Luigi
>>>>
>>>>>>>
>>>> cluster <- c(rep("A", 90), rep("B", 100))
>>>> sample <- c(
>>>>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
>>>> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>>>>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
>>>> "blank"), 5),
>>>>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
>>>> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>>>>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
>>>> "cow-59", "blank"), 5)
>>>> )
>>>> type <- c(
>>>>   rep(c("negative", "negative", "negative", "negative", "negative",
>>>> "negative", "negative", "negative", "positive", "positive",
>>>>         "positive", "positive", "positive", "positive", "positive",
>>>> "positive", "positive", "blank"), 5),
>>>>   rep(c("negative", "positive", "negative", "negative", "negative",
>>>> "negative", "negative", "negative", "positive", "positive",
>>>>         "positive", "positive", "positive", "positive", "positive",
>>>> "positive", "positive", "positive", "positive", "blank"), 5)
>>>> )
>>>> target <- c(
>>>> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
>>>> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
>>>> )
>>>> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
>>>> 42, 47, 86, 100,
>>>>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
>>>> 33, 28, 31, 26, 23,
>>>>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
>>>> 58.5, 61, 62.5, 58,
>>>>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
>>>> 84, 95.5, 62, 82, 138,
>>>>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
>>>> 33, 37, 51, 44, 50, 54,
>>>>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
>>>> 68, 121, 80, 57,
>>>>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
>>>> 32, 184, 36, 45, 45, 44,
>>>>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
>>>> 79, 34, 74.5,
>>>> 54, 49, 55, 56,
>>>>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
>>>> 33, 58, 51, 54,
>>>>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
>>>> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
>>>> 9.92, 4.59, 19, 7.96,
>>>>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
>>>> 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>>>>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
>>>> 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>>>>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
>>>> 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>>>>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
>>>> 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>>>>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
>>>> 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>>>>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
>>>> 9.92, 40.69,
>>>> 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>>>>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
>>>> 64.9, 3.71,
>>>> 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>>>>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
>>>> 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>>>>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
>>>> 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>>>>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
>>>> 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>>>>                0.15, 1.28, 7.42, 71.15, 9.39)
>>>> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
>>>> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>>>>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
>>>> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>>>>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
>>>> 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>>>>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
>>>> -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
>>>>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
>>>> 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
>>>>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
>>>> 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>>>>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
>>>> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>>>>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
>>>> 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>>>>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
>>>> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>>>>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
>>>> 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
>>>>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
>>>> 34.72, 42.58, -18.15, 39.61)
>>>> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
>>>> 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>>>>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
>>>> 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
>>>>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
>>>> 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>>>>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
>>>> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
>>>> 169.69,
>>>>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
>>>> 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
>>>>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
>>>> 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
>>>>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
>>>> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
>>>> 143.71,
>>>>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
>>>> 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
>>>>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
>>>> 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
>>>>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
>>>> 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
>>>>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
>>>> my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
>>>> ul, stringsAsFactors = FALSE)
>>>>
>>>> library(lattice)
>>>> library(latticeExtra)
>>>> useOuterStrips(
>>>>   strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>   stripplot(
>>>>     average ~ type|target+cluster,
>>>>     my.data,
>>>>     groups = type,
>>>>     pch=1,
>>>>     jitter.data = TRUE,
>>>>     main = "Group-wise",
>>>>     xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>>>     col = c("grey", "green", "red"),
>>>>     par.settings = list(strip.background = list(col=c("paleturquoise",
>>>> "grey"))),
>>>>     scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>>>     key = list(
>>>>       space = "top",
>>>>       columns = 3,
>>>>       text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>>       rectangles = list(col=c("grey", "green", "red"))
>>>>     )
>>>>   )
>>>> )
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Fri Mar 17 10:05:59 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Mar 2017 09:05:59 +0000
Subject: [R] [FORGED] standard error for regression coefficients
 corresponding to factor levels
In-Reply-To: <56c61009-7e06-9292-9880-2494a5d6e37b@auckland.ac.nz>
References: <CAHLnndY0Wp1JT4rHCH65wGdWT3txMcGWGtDNFdEk0hXoXc-tSw@mail.gmail.com>
	<56c61009-7e06-9292-9880-2494a5d6e37b@auckland.ac.nz>
Message-ID: <D4F11D76.45410%hdoran@air.org>

A slightly more ?R-ish? way of doing

S <- solve(t(X)%*%X)

Is to instead use

S <- solve(crossprod(X))

And the idea idea of inverting the SSCP matrix only and not actually
solving the linear system is not so great, which is why it is better to do
as Rolf is suggesting and get all things you need from lm, which uses
decompositions and not the algebraic representations for the solution to
the linear system.

On 3/16/17, 7:41 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

>
>You have been posting to the R-help list long enough so that you should
>have learned by now *not* to post in html.  Your code is mangled so as
>to be unreadable.
>
>A few comments:
>
>(1) Your data frame "data1" seems to have a mysterious (and irrelevant?)
>column named "data1" as well.
>
>(2) The covariance matrix of your coefficient estimates is indeed (as
>you hint) a constant multiple of (X^T X)^{-1}.  So do:
>
>     X <- model.matrix(~response*week,data=data1)
>     S <- solve(t(X)%*%X)
>     print(S)
>
>and you will see the same pattern of constancy that your results exhibit.
>
>(3) You could get the results you want much more easily, without all the
>fooling around buried in your (illegible) code, by doing:
>
>     mod <- lm(response ~ (region - 1)/week,data=data1)
>     summary(mod)
>
>cheers,
>
>Rolf Turner
>
>-- 
>Technical Editor ANZJS
>Department of Statistics
>University of Auckland
>Phone: +64-9-373-7599 ext. 88276
>
>On 17/03/17 07:26, li li wrote:
>> Hi all,
>>   I have the following data called "data1". After fitting the ancova
>>model
>> with different slopes and intercepts for each region, I calculated the
>> regression coefficients and the corresponding standard error. The
>>standard
>> error (for intercept or for slope) are all the same for different
>>regions.
>> Is there something wrong?
>>   I know the SE is related to (X^T X)^-1, where X is design matrix. So
>>does
>> this happen whenever each factor level has the same set of values for
>> "week"?
>>      Thanks.
>>      Hanna
>>
>>
>>
>>> mod <- lm(response ~ region*week, data1)> tmp <- coef(summary(mod))>
>>>res <- matrix(NA, 5,4)> res[1,1:2] <- tmp[1,1:2]> res[2:5,1] <-
>>>tmp[1,1]+tmp[2:5,1]> res[2:5,2] <- sqrt(tmp[2:5,2]^2-tmp[1,2]^2)>
>>>res[1,3:4] <- tmp[6,1:2]> res[2:5,3] <- tmp[6,1]+tmp[7:10,1]>
>>>res[2:5,4] <- sqrt(tmp[7:10,2]^2-tmp[6,2]^2)
>>
>>> colnames(res) <- c("intercept", "intercept SE", "slope", "slope SE")>
>>>rownames(res) <- letters[1:5]> res   intercept intercept SE
>>>slope   slope SE
>> a 0.18404464   0.08976301 -0.018629310 0.01385073
>> b 0.17605666   0.08976301 -0.022393789 0.01385073
>> c 0.16754130   0.08976301 -0.022367770 0.01385073
>> d 0.12554452   0.08976301 -0.017464385 0.01385073
>> e 0.06153256   0.08976301  0.007714685 0.01385073
>>
>>
>>
>>
>>
>>
>>
>>> data1    week region     response
>> 5      3      c  0.057325067
>> 6      6      c  0.066723632
>> 7      9      c -0.025317808
>> 12     3      d  0.024692613
>> 13     6      d  0.021761492
>> 14     9      d -0.099820335
>> 19     3      c  0.119559235
>> 20     6      c -0.054456186
>> 21     9      c  0.078811180
>> 26     3      d  0.091667189
>> 27     6      d -0.053400777
>> 28     9      d  0.090754363
>> 33     3      c  0.163818085
>> 34     6      c  0.008959741
>> 35     9      c -0.115410852
>> 40     3      d  0.193920693
>> 41     6      d -0.087738914
>> 42     9      d  0.004987542
>> 47     3      a  0.121332285
>> 48     6      a -0.020202707
>> 49     9      a  0.037295785
>> 54     3      b  0.214304603
>> 55     6      b -0.052346480
>> 56     9      b  0.082501222
>> 61     3      a  0.053540767
>> 62     6      a -0.019182819
>> 63     9      a -0.057629113
>> 68     3      b  0.068592791
>> 69     6      b -0.123298216
>> 70     9      b -0.230671818
>> 75     3      a  0.330741562
>> 76     6      a  0.013902905
>> 77     9      a  0.190620360
>> 82     3      b  0.151002874
>> 83     6      b  0.086177696
>> 84     9      b  0.178982656
>> 89     3      e  0.062974799
>> 90     6      e  0.062035391
>> 91     9      e  0.206200831
>> 96     3      e  0.123102197
>> 97     6      e  0.040181790
>> 98     9      e  0.121332285
>> 103    3      e  0.147557564
>> 104    6      e  0.062035391
>> 105    9      e  0.144965770
>>
>> 	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marco.scutari at gmail.com  Fri Mar 17 10:44:36 2017
From: marco.scutari at gmail.com (Marco Scutari)
Date: Fri, 17 Mar 2017 09:44:36 +0000
Subject: [R] bnlearn impute problem
In-Reply-To: <004201d29ee7$566e5130$034af390$@ecogeonomix.com>
References: <004201d29ee7$566e5130$034af390$@ecogeonomix.com>
Message-ID: <CA+RJqXUCgTRMqMXM1ODRj5mxa-auCgJd=7EWEPZVjVhEWc_ONQ@mail.gmail.com>

Dear Ross,

On 17 March 2017 at 06:25,  <ross.chapman at ecogeonomix.com> wrote:
> I am having a problem running the "impute" function from the bnlearn
> package.

I assume you referred to the online documentation instead of the
manuals that come with the package? I included impute() in bnlearn
4.1, so you will have to upgrade to use it.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From kevin.thorpe at utoronto.ca  Fri Mar 17 13:23:13 2017
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 17 Mar 2017 08:23:13 -0400
Subject: [R] Reversing table()
Message-ID: <4390131.CCuTsum1AT@sigma>

I am wondering if there is a way to undo the results of table().

For example if you had a table that looked like the result of table(x, y) or 
table(x, y, z) is there a simple/elegant way to reverse the process to get the 
"original" x, y and z vectors?

Thanks,

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From petr.pikal at precheza.cz  Fri Mar 17 14:15:01 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Mar 2017 13:15:01 +0000
Subject: [R] weird ggplot geom_segment behaviour
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>

Dear all

I try to limit geom segment plot by xlim and encounter weird behaviour.

Here is my data

> dput(temp)
temp <- structure(list(ukol = c("extern? kalcinace", "povrchov? ?prava UVS30",
"Testy mlet? UVS30", "zm?na koncentrace olejov?ch disperz?",
"Mlet? povrchov? upraven? UVS30", "mikronizace cg300"), start = structure(c(17245,
17203, 17252, 17257, 17238, 17224), class = "Date"), end = structure(c(17256,
17242, 17235, 17286, 17249, 17256), class = "Date"), pracovnik = c("BA?URA Richard",
"BA?URA Richard", "BA?URA Richard", "BA?URA Richard", "BA?URA Richard",
"BA?URA Richard")), .Names = c("ukol", "start", "end", "pracovnik"
), row.names = c(27L, 35L, 49L, 53L, 59L, 79L), class = "data.frame")

#and the code

library(ggplot2)
library(lubridate)

p <- ggplot(temp, aes(x=start, y=ukol, xend=end, yend=ukol))

#This code produces correct graph.

p+geom_segment(alpha=.4, size=3)+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#However for some reason I need to limit x axis and use xlim

p+geom_segment(alpha=.4, size=3)+xlim(c(today()-14, today()+14))+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#The code issues warning and prevents three segments to be drawn.
#Is it expected behaviour? Or it is a bug somewhere.

> sessionInfo()
R Under development (unstable) (2017-01-11 r71964)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250    LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C                          LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats     datasets  utils     grDevices graphics  methods   base

other attached packages:
[1] ggplot2_2.2.1   tidyr_0.6.1     readxl_0.1.1    lubridate_1.6.0 lattice_0.20-34 fun_0.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8      dplyr_0.5.0      assertthat_0.1   R6_2.2.0         grid_3.4.0       plyr_1.8.4       DBI_0.5-1        gtable_0.2.0     magrittr_1.5     scales_0.4.1     stringi_1.1.2
[12] lazyeval_0.2.0   tools_3.4.0      stringr_1.1.0    munsell_0.4.3    compiler_3.4.0   colorspace_1.3-2 tibble_1.2
>
Best regards
Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From thierry.onkelinx at inbo.be  Fri Mar 17 14:29:43 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 17 Mar 2017 14:29:43 +0100
Subject: [R] weird ggplot geom_segment behaviour
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
Message-ID: <CAJuCY5yc3USLLoJxqn8K7_W4sg+bV8bQRKX3naG-uDT+z2PNiA@mail.gmail.com>

Dear Petr,

Don't use xlim() but rather coord_cartesian(xlim = ...). See
https://rpubs.com/INBOstats/zoom_in

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-17 14:15 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
> Dear all
>
> I try to limit geom segment plot by xlim and encounter weird behaviour.
>
> Here is my data
>
>> dput(temp)
> temp <- structure(list(ukol = c("extern? kalcinace", "povrchov? ?prava UVS30",
> "Testy mlet? UVS30", "zm?na koncentrace olejov?ch disperz?",
> "Mlet? povrchov? upraven? UVS30", "mikronizace cg300"), start = structure(c(17245,
> 17203, 17252, 17257, 17238, 17224), class = "Date"), end = structure(c(17256,
> 17242, 17235, 17286, 17249, 17256), class = "Date"), pracovnik = c("BA?URA Richard",
> "BA?URA Richard", "BA?URA Richard", "BA?URA Richard", "BA?URA Richard",
> "BA?URA Richard")), .Names = c("ukol", "start", "end", "pracovnik"
> ), row.names = c(27L, 35L, 49L, 53L, 59L, 79L), class = "data.frame")
>
> #and the code
>
> library(ggplot2)
> library(lubridate)
>
> p <- ggplot(temp, aes(x=start, y=ukol, xend=end, yend=ukol))
>
> #This code produces correct graph.
>
> p+geom_segment(alpha=.4, size=3)+
> geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
>
> #However for some reason I need to limit x axis and use xlim
>
> p+geom_segment(alpha=.4, size=3)+xlim(c(today()-14, today()+14))+
> geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
>
> #The code issues warning and prevents three segments to be drawn.
> #Is it expected behaviour? Or it is a bug somewhere.
>
>> sessionInfo()
> R Under development (unstable) (2017-01-11 r71964)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
>
> locale:
> [1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250    LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C                          LC_TIME=Czech_Czech Republic.1250
>
> attached base packages:
> [1] stats     datasets  utils     grDevices graphics  methods   base
>
> other attached packages:
> [1] ggplot2_2.2.1   tidyr_0.6.1     readxl_0.1.1    lubridate_1.6.0 lattice_0.20-34 fun_0.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.8      dplyr_0.5.0      assertthat_0.1   R6_2.2.0         grid_3.4.0       plyr_1.8.4       DBI_0.5-1        gtable_0.2.0     magrittr_1.5     scales_0.4.1     stringi_1.1.2
> [12] lazyeval_0.2.0   tools_3.4.0      stringr_1.1.0    munsell_0.4.3    compiler_3.4.0   colorspace_1.3-2 tibble_1.2
>>
> Best regards
> Petr Pikal
>
> "Kdo v?dy mysl?, ?e se u??,
> bude vlasti chlouba.
> Kdo si mysl?, ?e dost um?,
> za??n? b?t trouba."
> Karel Havl??ek Borovsk?
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Mar 17 14:30:38 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Mar 2017 13:30:38 +0000
Subject: [R] Reversing table()
In-Reply-To: <4390131.CCuTsum1AT@sigma>
References: <4390131.CCuTsum1AT@sigma>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1CA12@SRVEXCHCM301.precheza.cz>

Is this what you want?

http://opensourceconnections.com/blog/2016/09/17/expanding-data-frequency-table-r-stata/

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin E.
> Thorpe
> Sent: Friday, March 17, 2017 1:23 PM
> To: r-help <r-help at stat.math.ethz.ch>
> Subject: [R] Reversing table()
>
> I am wondering if there is a way to undo the results of table().
>
> For example if you had a table that looked like the result of table(x, y) or
> table(x, y, z) is there a simple/elegant way to reverse the process to get the
> "original" x, y and z vectors?
>
> Thanks,
>
> Kevin
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka Shing
> Knowledge Institute of St. Michael's Hospital Assistant Professor, Dalla Lana
> School of Public Health University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From msharp at txbiomed.org  Fri Mar 17 14:35:09 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 17 Mar 2017 13:35:09 +0000
Subject: [R] Reversing table()
In-Reply-To: <4390131.CCuTsum1AT@sigma>
References: <4390131.CCuTsum1AT@sigma>
Message-ID: <63C9BEA6-FDCD-4164-A030-BFEC1BD4A882@TxBiomed.org>

Kevin,

The short answer is no.

The function table() takes in the vectors provided as arguments, counts the number of occurrences of each category by adding the integer 1L to a bin (one for each category or factor level), and at the end it returns the counts in each bin. Since it does not return the vectors, those values that went into the function do not survive the trip.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Mar 17, 2017, at 7:23 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
>
> I am wondering if there is a way to undo the results of table().
>
> For example if you had a table that looked like the result of table(x, y) or
> table(x, y, z) is there a simple/elegant way to reverse the process to get the
> "original" x, y and z vectors?
>
> Thanks,
>
> Kevin
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From petr.pikal at precheza.cz  Fri Mar 17 14:39:49 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Mar 2017 13:39:49 +0000
Subject: [R] weird ggplot geom_segment behaviour
In-Reply-To: <CAJuCY5yc3USLLoJxqn8K7_W4sg+bV8bQRKX3naG-uDT+z2PNiA@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
	<CAJuCY5yc3USLLoJxqn8K7_W4sg+bV8bQRKX3naG-uDT+z2PNiA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1CA27@SRVEXCHCM301.precheza.cz>

Dear Thierry

Thanks, works great. My bad, after your advice I went through help page for xlim and found, that this behaviour is quite clearly stated there. I focused on geom_segment where I did not (obviously) find any clue.

Best regards
Petr

> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Friday, March 17, 2017 2:30 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] weird ggplot geom_segment behaviour
>
> Dear Petr,
>
> Don't use xlim() but rather coord_cartesian(xlim = ...). See
> https://rpubs.com/INBOstats/zoom_in
>
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of
> anecdote is not data. ~ Roger Brinner The combination of some data and an
> aching desire for an answer does not ensure that a reasonable answer can be
> extracted from a given body of data. ~ John Tukey
>
>
> 2017-03-17 14:15 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
> > Dear all
> >
> > I try to limit geom segment plot by xlim and encounter weird behaviour.
> >
> > Here is my data
> >
> >> dput(temp)
> > temp <- structure(list(ukol = c("extern? kalcinace", "povrchov? ?prava
> > UVS30", "Testy mlet? UVS30", "zm?na koncentrace olejov?ch disperz?",
> > "Mlet? povrchov? upraven? UVS30", "mikronizace cg300"), start =
> > structure(c(17245, 17203, 17252, 17257, 17238, 17224), class =
> > "Date"), end = structure(c(17256, 17242, 17235, 17286, 17249, 17256),
> > class = "Date"), pracovnik = c("BA?URA Richard", "BA?URA Richard",
> > "BA?URA Richard", "BA?URA Richard", "BA?URA Richard", "BA?URA
> Richard")), .Names = c("ukol", "start", "end", "pracovnik"
> > ), row.names = c(27L, 35L, 49L, 53L, 59L, 79L), class = "data.frame")
> >
> > #and the code
> >
> > library(ggplot2)
> > library(lubridate)
> >
> > p <- ggplot(temp, aes(x=start, y=ukol, xend=end, yend=ukol))
> >
> > #This code produces correct graph.
> >
> > p+geom_segment(alpha=.4, size=3)+
> > geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
> >
> > #However for some reason I need to limit x axis and use xlim
> >
> > p+geom_segment(alpha=.4, size=3)+xlim(c(today()-14, today()+14))+
> > geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
> >
> > #The code issues warning and prevents three segments to be drawn.
> > #Is it expected behaviour? Or it is a bug somewhere.
> >
> >> sessionInfo()
> > R Under development (unstable) (2017-01-11 r71964)
> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10
> > x64 (build 10586)
> >
> > locale:
> > [1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech
> Republic.1250    LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
> LC_TIME=Czech_Czech Republic.1250
> >
> > attached base packages:
> > [1] stats     datasets  utils     grDevices graphics  methods   base
> >
> > other attached packages:
> > [1] ggplot2_2.2.1   tidyr_0.6.1     readxl_0.1.1    lubridate_1.6.0 lattice_0.20-
> 34 fun_0.1
> >
> > loaded via a namespace (and not attached):
> >  [1] Rcpp_0.12.8      dplyr_0.5.0      assertthat_0.1   R6_2.2.0         grid_3.4.0
> plyr_1.8.4       DBI_0.5-1        gtable_0.2.0     magrittr_1.5     scales_0.4.1
> stringi_1.1.2
> > [12] lazyeval_0.2.0   tools_3.4.0      stringr_1.1.0    munsell_0.4.3
> compiler_3.4.0   colorspace_1.3-2 tibble_1.2
> >>
> > Best regards
> > Petr Pikal
> >
> > "Kdo v?dy mysl?, ?e se u??,
> > bude vlasti chlouba.
> > Kdo si mysl?, ?e dost um?,
> > za??n? b?t trouba."
> > Karel Havl??ek Borovsk?
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy,
> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its copies
> from your system.
> > If you are not the intended recipient of this e-mail, you are not authorized
> to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> > - the sender insists on that the respective contract is concluded only upon
> an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which he/she
> is expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jrkrideau at yahoo.ca  Fri Mar 17 14:44:26 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 17 Mar 2017 13:44:26 +0000 (UTC)
Subject: [R] weird ggplot geom_segment behaviour
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
Message-ID: <1926785990.2128135.1489758266334@mail.yahoo.com>

Hi Petr,It "seems" to be linked to the =/- 14 days that you are using for the limits.

The code below should? restore one more bar. After that I don't know.

p2 <- p+geom_segment(alpha=.4, size=3)+xlim(c(today()-21, today()+21))+
? geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
p2 

    On Friday, March 17, 2017 9:16 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 

 Dear all

I try to limit geom segment plot by xlim and encounter weird behaviour.

Here is my data

> dput(temp)
temp <- structure(list(ukol = c("extern? kalcinace", "povrchov? ?prava UVS30",
"Testy mlet? UVS30", "zm?na koncentrace olejov?ch disperz?",
"Mlet? povrchov? upraven? UVS30", "mikronizace cg300"), start = structure(c(17245,
17203, 17252, 17257, 17238, 17224), class = "Date"), end = structure(c(17256,
17242, 17235, 17286, 17249, 17256), class = "Date"), pracovnik = c("BA?URA Richard",
"BA?URA Richard", "BA?URA Richard", "BA?URA Richard", "BA?URA Richard",
"BA?URA Richard")), .Names = c("ukol", "start", "end", "pracovnik"
), row.names = c(27L, 35L, 49L, 53L, 59L, 79L), class = "data.frame")

#and the code

library(ggplot2)
library(lubridate)

p <- ggplot(temp, aes(x=start, y=ukol, xend=end, yend=ukol))

#This code produces correct graph.

p+geom_segment(alpha=.4, size=3)+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#However for some reason I need to limit x axis and use xlim

p+geom_segment(alpha=.4, size=3)+xlim(c(today()-14, today()+14))+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#The code issues warning and prevents three segments to be drawn.
#Is it expected behaviour? Or it is a bug somewhere.

> sessionInfo()
R Under development (unstable) (2017-01-11 r71964)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250? LC_CTYPE=Czech_Czech Republic.1250? ? LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ? LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats? ? datasets? utils? ? grDevices graphics? methods? base

other attached packages:
[1] ggplot2_2.2.1? tidyr_0.6.1? ? readxl_0.1.1? ? lubridate_1.6.0 lattice_0.20-34 fun_0.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8? ? ? dplyr_0.5.0? ? ? assertthat_0.1? R6_2.2.0? ? ? ? grid_3.4.0? ? ? plyr_1.8.4? ? ? DBI_0.5-1? ? ? ? gtable_0.2.0? ? magrittr_1.5? ? scales_0.4.1? ? stringi_1.1.2
[12] lazyeval_0.2.0? tools_3.4.0? ? ? stringr_1.1.0? ? munsell_0.4.3? ? compiler_3.4.0? colorspace_1.3-2 tibble_1.2
>
Best regards
Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Mar 17 15:07:18 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Mar 2017 14:07:18 +0000
Subject: [R] weird ggplot geom_segment behaviour
In-Reply-To: <1926785990.2128135.1489758266334@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1C9BA@SRVEXCHCM301.precheza.cz>
	<1926785990.2128135.1489758266334@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1CA44@SRVEXCHCM301.precheza.cz>

Hi John

Thierry already pointed me to propper direction. The key for such ?zooming? is to use coord_cartesian(xlim ...) which is stated, as I finally found, in xlim help page.

Thanks
Petr


From: John Kane [mailto:jrkrideau at yahoo.ca]
Sent: Friday, March 17, 2017 2:44 PM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: Re: [R] weird ggplot geom_segment behaviour

Hi Petr,
It "seems" to be linked to the =/- 14 days that you are using for the limits.



The code below should  restore one more bar. After that I don't know.



p2 <- p+geom_segment(alpha=.4, size=3)+xlim(c(today()-21, today()+21))+
  geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)
p2

On Friday, March 17, 2017 9:16 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Dear all

I try to limit geom segment plot by xlim and encounter weird behaviour.

Here is my data

> dput(temp)
temp <- structure(list(ukol = c("extern? kalcinace", "povrchov? ?prava UVS30",
"Testy mlet? UVS30", "zm?na koncentrace olejov?ch disperz?",
"Mlet? povrchov? upraven? UVS30", "mikronizace cg300"), start = structure(c(17245,
17203, 17252, 17257, 17238, 17224), class = "Date"), end = structure(c(17256,
17242, 17235, 17286, 17249, 17256), class = "Date"), pracovnik = c("BA?URA Richard",
"BA?URA Richard", "BA?URA Richard", "BA?URA Richard", "BA?URA Richard",
"BA?URA Richard")), .Names = c("ukol", "start", "end", "pracovnik"
), row.names = c(27L, 35L, 49L, 53L, 59L, 79L), class = "data.frame")

#and the code

library(ggplot2)
library(lubridate)

p <- ggplot(temp, aes(x=start, y=ukol, xend=end, yend=ukol))

#This code produces correct graph.

p+geom_segment(alpha=.4, size=3)+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#However for some reason I need to limit x axis and use xlim

p+geom_segment(alpha=.4, size=3)+xlim(c(today()-14, today()+14))+
geom_vline(xintercept=as.numeric(today()), colour="pink", size=5)

#The code issues warning and prevents three segments to be drawn.
#Is it expected behaviour? Or it is a bug somewhere.

> sessionInfo()
R Under development (unstable) (2017-01-11 r71964)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250    LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C                          LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats    datasets  utils    grDevices graphics  methods  base

other attached packages:
[1] ggplot2_2.2.1  tidyr_0.6.1    readxl_0.1.1    lubridate_1.6.0 lattice_0.20-34 fun_0.1

loaded via a namespace (and not attached):
[1] Rcpp_0.12.8      dplyr_0.5.0      assertthat_0.1  R6_2.2.0        grid_3.4.0      plyr_1.8.4      DBI_0.5-1        gtable_0.2.0    magrittr_1.5    scales_0.4.1    stringi_1.1.2
[12] lazyeval_0.2.0  tools_3.4.0      stringr_1.1.0    munsell_0.4.3    compiler_3.4.0  colorspace_1.3-2 tibble_1.2
>
Best regards
Petr Pikal

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?




________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From HDoran at air.org  Fri Mar 17 15:44:37 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Mar 2017 14:44:37 +0000
Subject: [R] [FORGED] standard error for regression coefficients
 corresponding to factor levels
In-Reply-To: <D4F11D76.45410%hdoran@air.org>
References: <CAHLnndY0Wp1JT4rHCH65wGdWT3txMcGWGtDNFdEk0hXoXc-tSw@mail.gmail.com>
	<56c61009-7e06-9292-9880-2494a5d6e37b@auckland.ac.nz>
	<D4F11D76.45410%hdoran@air.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D21572@DC1VEX10MB01.air.org>

Just to do a better job in what is perhaps more "R-ish" w.r.t least squares calculations, here is perhaps a better example

ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group)

X <- model.matrix(lm.D9)
Xqr <- qr(X)
Q <- qr.Q(Xqr)
R <- qr.R(Xqr)


### this is same as just (X'X)^-1
 chol2inv(R)

### Compared to the prior way I mentioned

 solve(crossprod(X))

-----Original Message-----
From: Doran, Harold 
Sent: Friday, March 17, 2017 5:06 AM
To: Rolf Turner <r.turner at auckland.ac.nz>; li li <hannah.hlx at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] [FORGED] standard error for regression coefficients corresponding to factor levels

A slightly more ?R-ish? way of doing

S <- solve(t(X)%*%X)

Is to instead use

S <- solve(crossprod(X))

And the idea idea of inverting the SSCP matrix only and not actually solving the linear system is not so great, which is why it is better to do as Rolf is suggesting and get all things you need from lm, which uses decompositions and not the algebraic representations for the solution to the linear system.

On 3/16/17, 7:41 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

>
>You have been posting to the R-help list long enough so that you should 
>have learned by now *not* to post in html.  Your code is mangled so as 
>to be unreadable.
>
>A few comments:
>
>(1) Your data frame "data1" seems to have a mysterious (and 
>irrelevant?) column named "data1" as well.
>
>(2) The covariance matrix of your coefficient estimates is indeed (as 
>you hint) a constant multiple of (X^T X)^{-1}.  So do:
>
>     X <- model.matrix(~response*week,data=data1)
>     S <- solve(t(X)%*%X)
>     print(S)
>
>and you will see the same pattern of constancy that your results exhibit.
>
>(3) You could get the results you want much more easily, without all 
>the fooling around buried in your (illegible) code, by doing:
>
>     mod <- lm(response ~ (region - 1)/week,data=data1)
>     summary(mod)
>
>cheers,
>
>Rolf Turner
>
>--
>Technical Editor ANZJS
>Department of Statistics
>University of Auckland
>Phone: +64-9-373-7599 ext. 88276
>
>On 17/03/17 07:26, li li wrote:
>> Hi all,
>>   I have the following data called "data1". After fitting the ancova 
>>model  with different slopes and intercepts for each region, I 
>>calculated the  regression coefficients and the corresponding standard 
>>error. The standard  error (for intercept or for slope) are all the 
>>same for different regions.
>> Is there something wrong?
>>   I know the SE is related to (X^T X)^-1, where X is design matrix. 
>>So does  this happen whenever each factor level has the same set of 
>>values for  "week"?
>>      Thanks.
>>      Hanna
>>
>>
>>
>>> mod <- lm(response ~ region*week, data1)> tmp <- coef(summary(mod))> 
>>>res <- matrix(NA, 5,4)> res[1,1:2] <- tmp[1,1:2]> res[2:5,1] <- 
>>>tmp[1,1]+tmp[2:5,1]> res[2:5,2] <- sqrt(tmp[2:5,2]^2-tmp[1,2]^2)> 
>>>res[1,3:4] <- tmp[6,1:2]> res[2:5,3] <- tmp[6,1]+tmp[7:10,1]> 
>>>res[2:5,4] <- sqrt(tmp[7:10,2]^2-tmp[6,2]^2)
>>
>>> colnames(res) <- c("intercept", "intercept SE", "slope", "slope SE")>
>>>rownames(res) <- letters[1:5]> res   intercept intercept SE
>>>slope   slope SE
>> a 0.18404464   0.08976301 -0.018629310 0.01385073
>> b 0.17605666   0.08976301 -0.022393789 0.01385073
>> c 0.16754130   0.08976301 -0.022367770 0.01385073
>> d 0.12554452   0.08976301 -0.017464385 0.01385073
>> e 0.06153256   0.08976301  0.007714685 0.01385073
>>
>>
>>
>>
>>
>>
>>
>>> data1    week region     response
>> 5      3      c  0.057325067
>> 6      6      c  0.066723632
>> 7      9      c -0.025317808
>> 12     3      d  0.024692613
>> 13     6      d  0.021761492
>> 14     9      d -0.099820335
>> 19     3      c  0.119559235
>> 20     6      c -0.054456186
>> 21     9      c  0.078811180
>> 26     3      d  0.091667189
>> 27     6      d -0.053400777
>> 28     9      d  0.090754363
>> 33     3      c  0.163818085
>> 34     6      c  0.008959741
>> 35     9      c -0.115410852
>> 40     3      d  0.193920693
>> 41     6      d -0.087738914
>> 42     9      d  0.004987542
>> 47     3      a  0.121332285
>> 48     6      a -0.020202707
>> 49     9      a  0.037295785
>> 54     3      b  0.214304603
>> 55     6      b -0.052346480
>> 56     9      b  0.082501222
>> 61     3      a  0.053540767
>> 62     6      a -0.019182819
>> 63     9      a -0.057629113
>> 68     3      b  0.068592791
>> 69     6      b -0.123298216
>> 70     9      b -0.230671818
>> 75     3      a  0.330741562
>> 76     6      a  0.013902905
>> 77     9      a  0.190620360
>> 82     3      b  0.151002874
>> 83     6      b  0.086177696
>> 84     9      b  0.178982656
>> 89     3      e  0.062974799
>> 90     6      e  0.062035391
>> 91     9      e  0.206200831
>> 96     3      e  0.123102197
>> 97     6      e  0.040181790
>> 98     9      e  0.121332285
>> 103    3      e  0.147557564
>> 104    6      e  0.062035391
>> 105    9      e  0.144965770
>>
>> 	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 17 15:59:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Mar 2017 07:59:08 -0700
Subject: [R] add median value and standard deviation bar to lattice plot
In-Reply-To: <CAMk+s2SUQSgU871nKbgG5DrhwR_67o-G5nx8QNQEzGhfkhTp8Q@mail.gmail.com>
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
	<CAGxFJbTpeOZViFtL-V9rJSbksKTO+oDhM4+JJmZg0wE13Uv7DQ@mail.gmail.com>
	<CAMk+s2TMae8RAk-aqA521rRW1ADvq1E3Gd3vRHDwbouHmakVFw@mail.gmail.com>
	<CAGxFJbQzVZSRum=Pg2kBKTKYWJ3=M9ZfiMjck=FF33GysKEb3A@mail.gmail.com>
	<CAMk+s2SUQSgU871nKbgG5DrhwR_67o-G5nx8QNQEzGhfkhTp8Q@mail.gmail.com>
Message-ID: <CAGxFJbTyJrvSLRVFrLtz4jrhB9w9z5-b70KUA9r5CEGq3NhG6A@mail.gmail.com>

If I understand you correcty, I suggest you consult a local
statistician. Individual data points *cannot* have "confidence
intervals."  So you clearly need some statistical guidance, which is
not what this list is about.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 17, 2017 at 1:27 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> dear Bert,
> the code as I read it draws 30 median lines, one for each cluster.
> what I am looking for is a function that will plot 190 individual
> confidence intervals, one for each measurement. would the code cover
> even that instance?
> regards
> luigi
>
> On Thu, Mar 16, 2017 at 2:41 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Just add whatever further code to decorate the groups as you like
>> within the panel.groups function. I believe I have given you
>> sufficient information in my code for you to do that if you study the
>> code carefully. Depending on what you decide to do -- which is
>> statistical and OT here (and not something I would offer specific
>> advice on remotely anyway) -- you may also have to pass down
>> additional arguments based on computations that you do with *all* the
>> data from *all* groups together.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Mar 16, 2017 at 1:38 AM, Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>> dear Bert,
>>> thank you for the solution, it worked perfectly. However I still would
>>> like to know how reliable are the dots that are plotted, that is why i
>>> would like to have individual bars on each dot (if possible). the
>>> standard deviation maybe is not the right tool and the confidence
>>> interval is perhaps better, but the procedure should be the same: draw
>>> an arrow from the lower to the upper limit. is that possible?
>>> regards,
>>> luigi
>>>
>>> PS sorry for the formatting, usually plain text is my default; it
>>> should have switched to html when i replied to a previous email but
>>> the difference does not show up when i type...
>>>
>>> On Wed, Mar 15, 2017 at 4:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> There may be a specific function that handles this for you, but to
>>>> roll your own, you need a custom panel.groups function, not the
>>>> default. You need to modify the panel function (which is
>>>> panel.superpose by default) to pass down the "col" argument to the
>>>> panel.segments call in the panel.groups function.
>>>>
>>>> This should get you started:
>>>>
>>>> useOuterStrips(
>>>>    strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>    stripplot(
>>>>       average ~ type|target+cluster,
>>>>       panel = function(x,y,col,...)
>>>>          panel.superpose(x,y,col=col,...),
>>>>       panel.groups = function(x,y,col,...){
>>>>          panel.stripplot(x,y,col=col,...)
>>>>          m <- median(y)
>>>>          panel.segments(x0 = x[1] -.5, y0 = m,
>>>>                         x1 = x[1] +.5, y1 = m,
>>>>                         col=col, lwd=2
>>>>                         )
>>>>       },
>>>>       my.data,
>>>>       groups = type,
>>>>       pch=1,
>>>>       jitter.data = TRUE,
>>>>       main = "Group-wise",
>>>>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>>>       col = c("grey", "green", "red"),
>>>>       par.settings = list(strip.background = list(col=c("paleturquoise",
>>>>                                                         "grey"))),
>>>>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>>>       key = list(
>>>>          space = "top",
>>>>          columns = 3,
>>>>          text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>>          rectangles = list(col=c("grey", "green", "red"))
>>>>       )
>>>>    )
>>>> )
>>>>
>>>> FWIW, I think adding 1 sd bars is a bad idea statistically.
>>>>
>>>> And though it made no difference here, please post in pain text, not HTML.
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Wed, Mar 15, 2017 at 2:22 AM, Luigi Marongiu
>>>> <marongiu.luigi at gmail.com> wrote:
>>>>> Dear all,
>>>>> I am analyzing some multivariate data that is organized like this:
>>>>> 1st variable = cluster (A or B)
>>>>> 2nd variable = target (a, b, c, d, e)
>>>>> 3rd variable = type (blank, negative, positive)
>>>>> 4th variable = sample (the actual name of the sample)
>>>>> 5th variable = average (the actual reading -- please not that this is the
>>>>> mean of different measures with an assumed normal distribution, but the
>>>>> assumption might not always be true)
>>>>> 6th variable = stdev (the standard deviation associated with each reading)
>>>>> 7th variable = ll (lower limit that is average stdev)
>>>>> 8th variable = ul (upper limit that is average + stdev)
>>>>>
>>>>> I am plotting the data using lattice's stripplot and I would need to add:
>>>>> 1. an error bar for each measurement. the bar should be possibly coloured
>>>>> in light grey and semitransparent to reduce the noise of the plot.
>>>>> 2. a type-based median bar to show differences in measurements between
>>>>> blanks, negative and positive samples within each panel.
>>>>>
>>>>> How would I do that?
>>>>> Many thanks,
>>>>> Luigi
>>>>>
>>>>>>>>
>>>>> cluster <- c(rep("A", 90), rep("B", 100))
>>>>> sample <- c(
>>>>>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
>>>>> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>>>>>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
>>>>> "blank"), 5),
>>>>>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
>>>>> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>>>>>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
>>>>> "cow-59", "blank"), 5)
>>>>> )
>>>>> type <- c(
>>>>>   rep(c("negative", "negative", "negative", "negative", "negative",
>>>>> "negative", "negative", "negative", "positive", "positive",
>>>>>         "positive", "positive", "positive", "positive", "positive",
>>>>> "positive", "positive", "blank"), 5),
>>>>>   rep(c("negative", "positive", "negative", "negative", "negative",
>>>>> "negative", "negative", "negative", "positive", "positive",
>>>>>         "positive", "positive", "positive", "positive", "positive",
>>>>> "positive", "positive", "positive", "positive", "blank"), 5)
>>>>> )
>>>>> target <- c(
>>>>> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
>>>>> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
>>>>> )
>>>>> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128, 39,
>>>>> 42, 47, 86, 100,
>>>>>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
>>>>> 33, 28, 31, 26, 23,
>>>>>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
>>>>> 58.5, 61, 62.5, 58,
>>>>>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90, 73,
>>>>> 84, 95.5, 62, 82, 138,
>>>>>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45, 76,
>>>>> 33, 37, 51, 44, 50, 54,
>>>>>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212, 40,
>>>>> 68, 121, 80, 57,
>>>>>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186, 297,
>>>>> 32, 184, 36, 45, 45, 44,
>>>>>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
>>>>> 79, 34, 74.5,
>>>>> 54, 49, 55, 56,
>>>>>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
>>>>> 33, 58, 51, 54,
>>>>>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
>>>>> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72, 1.83,
>>>>> 9.92, 4.59, 19, 7.96,
>>>>>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42, 64.12,
>>>>> 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>>>>>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
>>>>> 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>>>>>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62, 70.26,
>>>>> 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>>>>>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
>>>>> 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>>>>>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41, 9.86,
>>>>> 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>>>>>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
>>>>> 9.92, 40.69,
>>>>> 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>>>>>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
>>>>> 64.9, 3.71,
>>>>> 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>>>>>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
>>>>> 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>>>>>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
>>>>> 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>>>>>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15, 1.08,
>>>>> 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>>>>>                0.15, 1.28, 7.42, 71.15, 9.39)
>>>>> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
>>>>> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>>>>>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
>>>>> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>>>>>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
>>>>> 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>>>>>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
>>>>> -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
>>>>>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
>>>>> 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
>>>>>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
>>>>> 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>>>>>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
>>>>> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>>>>>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
>>>>> 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>>>>>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
>>>>> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>>>>>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
>>>>> 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
>>>>>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
>>>>> 34.72, 42.58, -18.15, 39.61)
>>>>> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
>>>>> 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>>>>>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
>>>>> 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
>>>>>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
>>>>> 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>>>>>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
>>>>> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
>>>>> 169.69,
>>>>>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
>>>>> 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
>>>>>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
>>>>> 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
>>>>>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
>>>>> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
>>>>> 143.71,
>>>>>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
>>>>> 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
>>>>>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
>>>>> 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
>>>>>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
>>>>> 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
>>>>>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
>>>>> my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
>>>>> ul, stringsAsFactors = FALSE)
>>>>>
>>>>> library(lattice)
>>>>> library(latticeExtra)
>>>>> useOuterStrips(
>>>>>   strip = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>>   strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>>>>>   stripplot(
>>>>>     average ~ type|target+cluster,
>>>>>     my.data,
>>>>>     groups = type,
>>>>>     pch=1,
>>>>>     jitter.data = TRUE,
>>>>>     main = "Group-wise",
>>>>>     xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>>>>>     col = c("grey", "green", "red"),
>>>>>     par.settings = list(strip.background = list(col=c("paleturquoise",
>>>>> "grey"))),
>>>>>     scales = list(alternating = FALSE, x=list(draw=FALSE)),
>>>>>     key = list(
>>>>>       space = "top",
>>>>>       columns = 3,
>>>>>       text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>>>       rectangles = list(col=c("grey", "green", "red"))
>>>>>     )
>>>>>   )
>>>>> )
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From karl.schilling at uni-bonn.de  Fri Mar 17 16:05:35 2017
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Fri, 17 Mar 2017 16:05:35 +0100
Subject: [R] inadverted reordering of a df column when it is copied to
	another df
Message-ID: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>

Dear all:

I have two data.frames A and B of the same number of rows (about 
40,000). I realized that when I copy column x from data.frame A to B, 
the order of this column  gets changed. This seems to affect only values 
in rownumbers > ~ 35/36,000. It also happens in any of the following 
three approaches:

A$x <- B$x

x <- B$x (here, x is still in the correct order)
B$x <- x : now x is reordered

B <- cbind(A, B$x)

I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.

Any help would be appreciated.

Best regards

Karl Schilling


From thierry.onkelinx at inbo.be  Fri Mar 17 16:16:34 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 17 Mar 2017 16:16:34 +0100
Subject: [R] inadverted reordering of a df column when it is copied to
 another df
In-Reply-To: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
Message-ID: <CAJuCY5yOKn0zCVpOgj_uNHTo-hU0dHM7kP-XwKJTT_=t_P90Mw@mail.gmail.com>

Dear Karl,

This is hard to investigate without a reproducible example.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-17 16:05 GMT+01:00 Karl Schilling <karl.schilling at uni-bonn.de>:
> Dear all:
>
> I have two data.frames A and B of the same number of rows (about 40,000). I
> realized that when I copy column x from data.frame A to B, the order of this
> column  gets changed. This seems to affect only values in rownumbers > ~
> 35/36,000. It also happens in any of the following three approaches:
>
> A$x <- B$x
>
> x <- B$x (here, x is still in the correct order)
> B$x <- x : now x is reordered
>
> B <- cbind(A, B$x)
>
> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
>
> Any help would be appreciated.
>
> Best regards
>
> Karl Schilling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 17 16:33:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Mar 2017 08:33:50 -0700
Subject: [R] inadverted reordering of a df column when it is copied to
 another df
In-Reply-To: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
Message-ID: <CAGxFJbRmB1EcdjrS=19zgTzXmhrOeNSx7bqCm+kdXyjuOpAg8g@mail.gmail.com>

You are wrong. No reordering occurs.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 17, 2017 at 8:05 AM, Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
> Dear all:
>
> I have two data.frames A and B of the same number of rows (about 40,000). I
> realized that when I copy column x from data.frame A to B, the order of this
> column  gets changed. This seems to affect only values in rownumbers > ~
> 35/36,000. It also happens in any of the following three approaches:
>
> A$x <- B$x
>
> x <- B$x (here, x is still in the correct order)
> B$x <- x : now x is reordered
>
> B <- cbind(A, B$x)
>
> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
>
> Any help would be appreciated.
>
> Best regards
>
> Karl Schilling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Fri Mar 17 15:54:27 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 17 Mar 2017 10:54:27 -0400
Subject: [R] lagging over consecutive pairs of rows in dataframe
Message-ID: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>

Suppose I have a dataframe that looks like the following:

n=2
mydata <- data.frame(exp = rep(1:5,each=n), rslt = 
c(12,15,7,8,24,28,33,15,22,11))
mydata
    exp rslt
1    1   12
2    1   15
3    2    7
4    2    8
5    3   24
6    3   28
7    4   33
8    4   15
9    5   22
10   5   11

The variable 'exp' (for experiment') occurs in pairs over consecutive 
rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is 
the 'control', and the second is a 'treatment'. The rslt column is the 
result.

What I'm trying to do is create a subset of this dataframe that consists 
of the exp number, and the lagged difference between the 'control' and 
'treatment' result.  So, for exp=1, the difference is (15-12)=3. For 
exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is 
take mydata (above), and turn it into

      exp  diff
1   1      3
2   2      1
3   3      4
4   4      -18
5   5      -11

The basic 'trick' I can't figure out is how to create a lagged variable 
between the second row (record) for a given level of exp, and the first 
row for that exp.  This is easy to do in SAS (which I'm more familiar 
with), but I'm struggling with the equivalent in R. The brute force 
approach  I thought of is to simply split the dataframe into to (one 
even rows, one odd rows), merge by exp, and then calculate a difference. 
But this seems to require renaming the rslt column in the two new 
dataframes so they are different in the merge (say, rslt_cont n the odd 
dataframe, and rslt_trt in the even dataframe), allowing me to calculate 
a difference between the two.

While I suppose this would work, I'm wondering if I'm missing a more 
elegant 'in place' approach that doesn't require me to split the data 
frame and do every via a merge.

Suggestions/pointers to the obvious welcome. I've tried playing with 
lag, and some approaches using lag in the zoo package,  but haven't 
found the magic trick. The problem (meaning, what I can't figure out) 
seems to be conditioning the lag on the level of exp.

Many thanks...


mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y = c(6,17,26,37,44))



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar 17 17:58:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Mar 2017 09:58:58 -0700 (PDT)
Subject: [R] inadverted reordering of a df column when it is copied to
 another df
In-Reply-To: <CAGxFJbRmB1EcdjrS=19zgTzXmhrOeNSx7bqCm+kdXyjuOpAg8g@mail.gmail.com>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
	<CAGxFJbRmB1EcdjrS=19zgTzXmhrOeNSx7bqCm+kdXyjuOpAg8g@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1703170955080.43167@pedal.dcn.davis.ca.us>

Reprex confirming Bert:

A <- data.frame( y = 1L:40000L )
B <- data.frame( x = 1L:40000L )
A$x <- B$x
plot(B$x)

#' ![](http://i.imgur.com/cXSFsBh.png)

Care to demonstrate for us, Karl?

https://cran.r-project.org/web/packages/reprex/README.html

On Fri, 17 Mar 2017, Bert Gunter wrote:

> You are wrong. No reordering occurs.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 17, 2017 at 8:05 AM, Karl Schilling
> <karl.schilling at uni-bonn.de> wrote:
>> Dear all:
>>
>> I have two data.frames A and B of the same number of rows (about 40,000). I
>> realized that when I copy column x from data.frame A to B, the order of this
>> column  gets changed. This seems to affect only values in rownumbers > ~
>> 35/36,000. It also happens in any of the following three approaches:
>>
>> A$x <- B$x
>>
>> x <- B$x (here, x is still in the correct order)
>> B$x <- x : now x is reordered
>>
>> B <- cbind(A, B$x)
>>
>> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
>>
>> Any help would be appreciated.
>>
>> Best regards
>>
>> Karl Schilling
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ulrik.stervbo at gmail.com  Fri Mar 17 17:58:30 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 17 Mar 2017 16:58:30 +0000
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
Message-ID: <CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>

Hi Evan

you can easily do this by applying diff() to each exp group.

Either using dplyr:
library(dplyr)
mydata %>%
  group_by(exp) %>%
  summarise(difference = diff(rslt))

Or with base R
aggregate(mydata, by = list(group = mydata$exp), FUN = diff)

HTH
Ulrik


On Fri, 17 Mar 2017 at 17:34 Evan Cooch <evan.cooch at gmail.com> wrote:

> Suppose I have a dataframe that looks like the following:
>
> n=2
> mydata <- data.frame(exp = rep(1:5,each=n), rslt =
> c(12,15,7,8,24,28,33,15,22,11))
> mydata
>     exp rslt
> 1    1   12
> 2    1   15
> 3    2    7
> 4    2    8
> 5    3   24
> 6    3   28
> 7    4   33
> 8    4   15
> 9    5   22
> 10   5   11
>
> The variable 'exp' (for experiment') occurs in pairs over consecutive
> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is
> the 'control', and the second is a 'treatment'. The rslt column is the
> result.
>
> What I'm trying to do is create a subset of this dataframe that consists
> of the exp number, and the lagged difference between the 'control' and
> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For
> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is
> take mydata (above), and turn it into
>
>       exp  diff
> 1   1      3
> 2   2      1
> 3   3      4
> 4   4      -18
> 5   5      -11
>
> The basic 'trick' I can't figure out is how to create a lagged variable
> between the second row (record) for a given level of exp, and the first
> row for that exp.  This is easy to do in SAS (which I'm more familiar
> with), but I'm struggling with the equivalent in R. The brute force
> approach  I thought of is to simply split the dataframe into to (one
> even rows, one odd rows), merge by exp, and then calculate a difference.
> But this seems to require renaming the rslt column in the two new
> dataframes so they are different in the merge (say, rslt_cont n the odd
> dataframe, and rslt_trt in the even dataframe), allowing me to calculate
> a difference between the two.
>
> While I suppose this would work, I'm wondering if I'm missing a more
> elegant 'in place' approach that doesn't require me to split the data
> frame and do every via a merge.
>
> Suggestions/pointers to the obvious welcome. I've tried playing with
> lag, and some approaches using lag in the zoo package,  but haven't
> found the magic trick. The problem (meaning, what I can't figure out)
> seems to be conditioning the lag on the level of exp.
>
> Many thanks...
>
>
> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y =
> c(6,17,26,37,44))
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar 17 18:19:47 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Mar 2017 10:19:47 -0700
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
	<CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
Message-ID: <CAGxFJbTFx0iP9FbV_=j4J1smZnZEPkzXhSb0_=zsYui02KuHRg@mail.gmail.com>

Evan:

You misunderstand the concept of a lagged variable.

Ulrik:

Well, yes, that is certainly a general solution that works. However,
given the *specific* structure described by the OP, an even more
direct (maybe more efficient?) way to do it just uses (logical)
subscripting:

odds <-  (seq_len(nrow(mydata)) %% 2) == 1
newdat <-data.frame(mydata[odds,1 ],mydata[!odds,2] - mydata[odds,2])
names(newdat) <- names(mydata)

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 17, 2017 at 9:58 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Evan
>
> you can easily do this by applying diff() to each exp group.
>
> Either using dplyr:
> library(dplyr)
> mydata %>%
>   group_by(exp) %>%
>   summarise(difference = diff(rslt))
>
> Or with base R
> aggregate(mydata, by = list(group = mydata$exp), FUN = diff)
>
> HTH
> Ulrik
>
>
> On Fri, 17 Mar 2017 at 17:34 Evan Cooch <evan.cooch at gmail.com> wrote:
>
>> Suppose I have a dataframe that looks like the following:
>>
>> n=2
>> mydata <- data.frame(exp = rep(1:5,each=n), rslt =
>> c(12,15,7,8,24,28,33,15,22,11))
>> mydata
>>     exp rslt
>> 1    1   12
>> 2    1   15
>> 3    2    7
>> 4    2    8
>> 5    3   24
>> 6    3   28
>> 7    4   33
>> 8    4   15
>> 9    5   22
>> 10   5   11
>>
>> The variable 'exp' (for experiment') occurs in pairs over consecutive
>> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is
>> the 'control', and the second is a 'treatment'. The rslt column is the
>> result.
>>
>> What I'm trying to do is create a subset of this dataframe that consists
>> of the exp number, and the lagged difference between the 'control' and
>> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For
>> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is
>> take mydata (above), and turn it into
>>
>>       exp  diff
>> 1   1      3
>> 2   2      1
>> 3   3      4
>> 4   4      -18
>> 5   5      -11
>>
>> The basic 'trick' I can't figure out is how to create a lagged variable
>> between the second row (record) for a given level of exp, and the first
>> row for that exp.  This is easy to do in SAS (which I'm more familiar
>> with), but I'm struggling with the equivalent in R. The brute force
>> approach  I thought of is to simply split the dataframe into to (one
>> even rows, one odd rows), merge by exp, and then calculate a difference.
>> But this seems to require renaming the rslt column in the two new
>> dataframes so they are different in the merge (say, rslt_cont n the odd
>> dataframe, and rslt_trt in the even dataframe), allowing me to calculate
>> a difference between the two.
>>
>> While I suppose this would work, I'm wondering if I'm missing a more
>> elegant 'in place' approach that doesn't require me to split the data
>> frame and do every via a merge.
>>
>> Suggestions/pointers to the obvious welcome. I've tried playing with
>> lag, and some approaches using lag in the zoo package,  but haven't
>> found the magic trick. The problem (meaning, what I can't figure out)
>> seems to be conditioning the lag on the level of exp.
>>
>> Many thanks...
>>
>>
>> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y =
>> c(6,17,26,37,44))
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 17 18:51:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Mar 2017 10:51:32 -0700
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <eefc0427-5e4d-f1cf-05e4-6742b7d95e11@gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
	<CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
	<CAGxFJbTFx0iP9FbV_=j4J1smZnZEPkzXhSb0_=zsYui02KuHRg@mail.gmail.com>
	<eefc0427-5e4d-f1cf-05e4-6742b7d95e11@gmail.com>
Message-ID: <CAGxFJbR3ciRTF4ZcgCKYEe0Av+qFWTQtEUp4OfmBjSEX0v7zZA@mail.gmail.com>

Evan:

Yes, I stand partially corrected. You have the concept correct, but R
implements it differently than SAS.

I think what you want for your approach is diff():

evens <-  (seq_len(nrow(mydata)) %% 2) == 0
newdat <-data.frame(exp=mydata[evens,1 ],reslt= diff(mydata[,2])[evens[-1]])

... which seems neater to me than what I offered previously.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 17, 2017 at 10:25 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>
>
> On 3/17/2017 1:19 PM, Bert Gunter wrote:
>>
>> Evan:
>>
>> You misunderstand the concept of a lagged variable.
>
>
> Well, lag in R, perhaps (and by my own admission). In SAS, thats exactly how
> it works.:
>
> data test;
> input exp rslt;
> cards;
> <data in the data frame in OP>
>     *;
>
>
>     data test2; set test; by exp;
>     diff=rslt-lag(rslt);
>       if last.exp;
>
>>
>> Ulrik:
>>
>> Well, yes, that is certainly a general solution that works. However,
>> given the *specific* structure described by the OP, an even more
>> direct (maybe more efficient?) way to do it just uses (logical)
>> subscripting:
>>
>> odds <-  (seq_len(nrow(mydata)) %% 2) == 1
>> newdat <-data.frame(mydata[odds,1 ],mydata[!odds,2] - mydata[odds,2])
>> names(newdat) <- names(mydata)
>>
>
> Interesting - thanks!
>
>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Mar 17, 2017 at 9:58 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>> wrote:
>>>
>>> Hi Evan
>>>
>>> you can easily do this by applying diff() to each exp group.
>>>
>>> Either using dplyr:
>>> library(dplyr)
>>> mydata %>%
>>>    group_by(exp) %>%
>>>    summarise(difference = diff(rslt))
>>>
>>> Or with base R
>>> aggregate(mydata, by = list(group = mydata$exp), FUN = diff)
>>>
>>> HTH
>>> Ulrik
>>>
>>>
>>> On Fri, 17 Mar 2017 at 17:34 Evan Cooch <evan.cooch at gmail.com> wrote:
>>>
>>>> Suppose I have a dataframe that looks like the following:
>>>>
>>>> n=2
>>>> mydata <- data.frame(exp = rep(1:5,each=n), rslt =
>>>> c(12,15,7,8,24,28,33,15,22,11))
>>>> mydata
>>>>      exp rslt
>>>> 1    1   12
>>>> 2    1   15
>>>> 3    2    7
>>>> 4    2    8
>>>> 5    3   24
>>>> 6    3   28
>>>> 7    4   33
>>>> 8    4   15
>>>> 9    5   22
>>>> 10   5   11
>>>>
>>>> The variable 'exp' (for experiment') occurs in pairs over consecutive
>>>> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is
>>>> the 'control', and the second is a 'treatment'. The rslt column is the
>>>> result.
>>>>
>>>> What I'm trying to do is create a subset of this dataframe that consists
>>>> of the exp number, and the lagged difference between the 'control' and
>>>> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For
>>>> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is
>>>> take mydata (above), and turn it into
>>>>
>>>>        exp  diff
>>>> 1   1      3
>>>> 2   2      1
>>>> 3   3      4
>>>> 4   4      -18
>>>> 5   5      -11
>>>>
>>>> The basic 'trick' I can't figure out is how to create a lagged variable
>>>> between the second row (record) for a given level of exp, and the first
>>>> row for that exp.  This is easy to do in SAS (which I'm more familiar
>>>> with), but I'm struggling with the equivalent in R. The brute force
>>>> approach  I thought of is to simply split the dataframe into to (one
>>>> even rows, one odd rows), merge by exp, and then calculate a difference.
>>>> But this seems to require renaming the rslt column in the two new
>>>> dataframes so they are different in the merge (say, rslt_cont n the odd
>>>> dataframe, and rslt_trt in the even dataframe), allowing me to calculate
>>>> a difference between the two.
>>>>
>>>> While I suppose this would work, I'm wondering if I'm missing a more
>>>> elegant 'in place' approach that doesn't require me to split the data
>>>> frame and do every via a merge.
>>>>
>>>> Suggestions/pointers to the obvious welcome. I've tried playing with
>>>> lag, and some approaches using lag in the zoo package,  but haven't
>>>> found the magic trick. The problem (meaning, what I can't figure out)
>>>> seems to be conditioning the lag on the level of exp.
>>>>
>>>> Many thanks...
>>>>
>>>>
>>>> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y =
>>>> c(6,17,26,37,44))
>>>>
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>


From ruipbarradas at sapo.pt  Fri Mar 17 18:53:58 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 17 Mar 2017 17:53:58 +0000
Subject: [R] inadverted reordering of a df column when it is copied to
 another df
In-Reply-To: <alpine.BSF.2.00.1703170955080.43167@pedal.dcn.davis.ca.us>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>	<CAGxFJbRmB1EcdjrS=19zgTzXmhrOeNSx7bqCm+kdXyjuOpAg8g@mail.gmail.com>
	<alpine.BSF.2.00.1703170955080.43167@pedal.dcn.davis.ca.us>
Message-ID: <58CC22B6.3010406@sapo.pt>

Hello,

Not an answer to the OP's statement, but

 > class(1L:40000L)
[1] "integer"
 > class(1:40000)
[1] "integer"

When using m:n there's no need for mL  or nL.

Rui Barradas

Em 17-03-2017 16:58, Jeff Newmiller escreveu:
> Reprex confirming Bert:
>
> A <- data.frame( y = 1L:40000L )
> B <- data.frame( x = 1L:40000L )
> A$x <- B$x
> plot(B$x)
>
> #' ![](http://i.imgur.com/cXSFsBh.png)
>
> Care to demonstrate for us, Karl?
>
> https://cran.r-project.org/web/packages/reprex/README.html
>
> On Fri, 17 Mar 2017, Bert Gunter wrote:
>
>> You are wrong. No reordering occurs.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Mar 17, 2017 at 8:05 AM, Karl Schilling
>> <karl.schilling at uni-bonn.de> wrote:
>>> Dear all:
>>>
>>> I have two data.frames A and B of the same number of rows (about
>>> 40,000). I
>>> realized that when I copy column x from data.frame A to B, the order
>>> of this
>>> column  gets changed. This seems to affect only values in rownumbers > ~
>>> 35/36,000. It also happens in any of the following three approaches:
>>>
>>> A$x <- B$x
>>>
>>> x <- B$x (here, x is still in the correct order)
>>> B$x <- x : now x is reordered
>>>
>>> B <- cbind(A, B$x)
>>>
>>> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
>>>
>>> Any help would be appreciated.
>>>
>>> Best regards
>>>
>>> Karl Schilling
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Mar 17 19:41:44 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Mar 2017 11:41:44 -0700
Subject: [R] inadverted reordering of a df column when it is copied to
 another df
In-Reply-To: <58CC22B6.3010406@sapo.pt>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
	<CAGxFJbRmB1EcdjrS=19zgTzXmhrOeNSx7bqCm+kdXyjuOpAg8g@mail.gmail.com>
	<alpine.BSF.2.00.1703170955080.43167@pedal.dcn.davis.ca.us>
	<58CC22B6.3010406@sapo.pt>
Message-ID: <CAF8bMcbJ99pPjvNa4bT_=Y6M+WKD5Q9KY5xT9X15UQRzMxue=Q@mail.gmail.com>

But note that m:n does not always produce an integer sequence.  It does when
the output can be accurately represented as an integer sequence, it
does not care
if the inputs were integer or numeric.
  > class( (2^31-10):(2^31-2) )
  [1] "integer"
  > class( (2^31-10):(2^31) ) # biggest integer is as.integer(2^31-1)
  [1] "numeric"
  > str(1.7:3.7)
   num [1:3] 1.7 2.7 3.7
  > str(1.0:3.0)
   int [1:3] 1 2 3
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 17, 2017 at 10:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Not an answer to the OP's statement, but
>
>> class(1L:40000L)
> [1] "integer"
>> class(1:40000)
> [1] "integer"
>
> When using m:n there's no need for mL  or nL.
>
> Rui Barradas
>
> Em 17-03-2017 16:58, Jeff Newmiller escreveu:
>>
>> Reprex confirming Bert:
>>
>> A <- data.frame( y = 1L:40000L )
>> B <- data.frame( x = 1L:40000L )
>> A$x <- B$x
>> plot(B$x)
>>
>> #' ![](http://i.imgur.com/cXSFsBh.png)
>>
>> Care to demonstrate for us, Karl?
>>
>> https://cran.r-project.org/web/packages/reprex/README.html
>>
>> On Fri, 17 Mar 2017, Bert Gunter wrote:
>>
>>> You are wrong. No reordering occurs.
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Mar 17, 2017 at 8:05 AM, Karl Schilling
>>> <karl.schilling at uni-bonn.de> wrote:
>>>>
>>>> Dear all:
>>>>
>>>> I have two data.frames A and B of the same number of rows (about
>>>> 40,000). I
>>>> realized that when I copy column x from data.frame A to B, the order
>>>> of this
>>>> column  gets changed. This seems to affect only values in rownumbers > ~
>>>> 35/36,000. It also happens in any of the following three approaches:
>>>>
>>>> A$x <- B$x
>>>>
>>>> x <- B$x (here, x is still in the correct order)
>>>> B$x <- x : now x is reordered
>>>>
>>>> B <- cbind(A, B$x)
>>>>
>>>> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
>>>>
>>>> Any help would be appreciated.
>>>>
>>>> Best regards
>>>>
>>>> Karl Schilling
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From karl.schilling at uni-bonn.de  Fri Mar 17 21:39:28 2017
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Fri, 17 Mar 2017 21:39:28 +0100
Subject: [R] SOLVED: inadverted reordering of a df column when it is copied
 to another df
In-Reply-To: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
References: <a34e800f-d966-32aa-c7b2-4c234a8da321@uni-bonn.de>
Message-ID: <d6c59106-215e-f2b2-ffc6-aafb5358b6f3@uni-bonn.de>


Dear All:

it seems I have solved my reordering issue, and to thank all those who 
answered, I briefly list the mistake I made.

I stared out from some data.frame holding values x and a grouping 
factor. Actually, my factor was a number (but not numeric) which was, 
however, not ordered. So it would go something like 1 1 1 2 2 2 4 4 4 3 3 3.

Then I performed some calculation on subsets of x defined by this factor 
using by(x, factor, function).

I then converted the result from the list obtained to a data.frame, and 
from this data.frame I copied one column into my original data.frame. 
The point I apparently missed was that the list obtained using "by", was 
ordered based on the factor (i.e. 1,1,1,2,2,2,3,3,3,4,4,4), and the same 
was true for the df I generated from this list.

Thank you for all your input

Karl



On 17.03.2017 16:16, Thierry Onkelinx wrote:
 > Dear Karl,
 >
 > This is hard to investigate without a reproducible example.
 >
 > Best regards,
 > ir. Thierry Onkelinx
 > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
 > and Forest
 > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
 > Kliniekstraat 25
 > 1070 Anderlecht
 > Belgium
 >
 > To call in the statistician after the experiment is done may be no
 > more than asking him to perform a post-mortem examination: he may be
 > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
 > The plural of anecdote is not data. ~ Roger Brinner
 > The combination of some data and an aching desire for an answer does
 > not ensure that a reasonable answer can be extracted from a given body
 > of data. ~ John Tukey
 >
 >
 > 2017-03-17 16:05 GMT+01:00 Karl Schilling <karl.schilling at uni-bonn.de>:
 >> Dear all:
 >>
 >> I have two data.frames A and B of the same number of rows (about 
40,000). I
 >> realized that when I copy column x from data.frame A to B, the order 
of this
 >> column  gets changed. This seems to affect only values in rownumbers > ~
 >> 35/36,000. It also happens in any of the following three approaches:
 >>
 >> A$x <- B$x
 >>
 >> x <- B$x (here, x is still in the correct order)
 >> B$x <- x : now x is reordered
 >>
 >> B <- cbind(A, B$x)
 >>
 >> I am working with Windows7Pro/64bit, R 3.3.3, and RStudio 0.99.903.
 >>
 >> Any help would be appreciated.
 >>
 >> Best regards
 >>
 >> Karl Schilling
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.


-


From drjimlemon at gmail.com  Fri Mar 17 21:48:48 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 18 Mar 2017 07:48:48 +1100
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>
	<CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>
	<CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>
Message-ID: <CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>

Hi Paul,
When manipulating any R object, the first thing to ascertain is what it is:

class(TSmodelForecast)

should give you useful information.

str(TSmodelForecast)

should give you more. Because of the wealth of defined data structures
in R, it is difficult to manipulate them without this information. I
suspect that your output is something like a time series object, and
once that is known, it should not be too hard to display its contents
in the way you want.

Jim


On Sat, Mar 18, 2017 at 7:12 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear Jim,
>
> Hope you are doing great. I tried to do what you suggested but R send an
> error message saying that $ operator is invalid for atomic vectors.
>
> The format of the forecasts are as follows: forecasted years are as rows,
> and forecasted months are in columns what I want to do is to have two
> colums, one with the forecasted dates in (MMM-YYYY format) and the second
> column with the actual forecast results.
>
> The output that is giving me hard time is the forecast output from nnetar
> model.
>
> Thanks for your valuable support,
>
> Best of regards,
>
> Paul
>
>
> 2017-03-16 18:23 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Paul,
>> It looks like the information that is printed is in:
>>
>> TSModelForecast$mean
>>
>> If str(TSModelForecast$mean) returns something like a list with two
>> components, you can probably use something like this:
>>
>> paste(format(TSModelForecast$mean$Date,"%b-%Y"),
>>  TSModelForecast$mean$Forecast,sep="-",collapse="\n")
>>
>> It also might be in TSModelForecast$fitted
>>
>> Jim
>>
>>
>> On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> > Dear friends,
>> >
>> > I am currently using R version 3.3.3 (64-bit) and used the following
>> > code
>> > to generate forecasts:
>> >
>> >> library(forecast)
>> >>
>> >> library(tseries)
>> >
>> >     ?tseries? version: 0.10-35
>> >
>> >     ?tseries? is a package for time series analysis and computational
>> > finance.
>> >
>> >     See ?library(help="tseries")? for details.
>> >
>> >
>> >> DAT<-read.csv("TrainingData.csv")
>> >>
>> >> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>> >>
>> >> TSmodel<-nnetar(TSdata)
>> >>
>> >> TSmodelForecast<-forecast(TSmodel, h=24)
>> >>
>> >> TSmodelForecast
>> >
>> > The problem is that the output comes in this fashion:
>> >
>> >                 Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
>> > Sep   Oct
>> >  2017        10      20      15      40     9         8         21
>> > 21
>> >     19     18
>> >  2018        34      15       7        6      10      11
>> >
>> > The format I would like to have is the following:
>> >
>> > Date                 Forecast
>> > Jan-2017               10
>> > Feb-2017               20
>> > Mar-2017               15
>> > Apr-2017                40
>> > May-2017               9
>> > Jun-2017                8
>> > Jul-2017                 21
>> > Aug-2017               21
>> > Sep-2017               19
>> > etc                          etc
>> >
>> > Is there a way to make the results look like this?
>> >
>> > Attached is a dataset as a reference.
>> >
>> > Best regards,
>> >
>> > Paul
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From paulbernal07 at gmail.com  Fri Mar 17 22:23:08 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 17 Mar 2017 16:23:08 -0500
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>
	<CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>
	<CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>
	<CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
Message-ID: <CAMOcQfNjLHt6aYpgQeBwKiO3HH8CB2hxj8h5mWDo=JvU-Sy=9Q@mail.gmail.com>

Dear Jim,

Thank you for your valuable replies. So variable mf5 has the forecasts for
a fitted nnetar model.

Below is the class and the str(mf5) output. Maybe with this information I
am sharing with you, hopefully you can give me some more guidance.

Again, thank you so much!

> class(mf5)
[1] "forecast"
>
> str(mf5)
List of 16
 $ x        : Time-Series [1:377] from 1986 to 2017: 48 40 44 35 44 42 39
37 41 36 ...
 $ m        : num 12
 $ p        : num 25
 $ P        : num 1
 $ scalex   :List of 2
  ..$ center: num 38.1
  ..$ scale : num 10.9
 $ size     : num 13
 $ subset   : int [1:377] 1 2 3 4 5 6 7 8 9 10 ...
 $ model    :List of 20
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 5.83
  .. ..$ wts          : num [1:352] -1.081 2.199 0.734 1.358 1.115 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.246 0.439 -0.357 1.325 -0.195 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.0754 0.00853 -0.0242 -0.05026
0.0898 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.54
  .. ..$ wts          : num [1:352] -7.113 4.668 -0.801 -5.487 2.751 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.145 0.443 -0.401 1.286 -0.158 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.0258 0.0037 0.02 -0.0107 0.0528 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 1.1
  .. ..$ wts          : num [1:352] -2.24 -0.698 -0.243 -2.575 4.073 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.2466 0.2986 -0.4369 1.3053 -0.0965
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.07551 0.14845 0.056 -0.03027
-0.00844 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 1.8
  .. ..$ wts          : num [1:352] 0.427 1.89 -0.705 -3.121 -1.134 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.11 0.37 -0.38 1.25 -0.15 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.06113 0.07689 -0.00135 0.02279
0.04491 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.67
  .. ..$ wts          : num [1:352] -0.632 2.121 6.144 1.697 0.953 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.2228 0.4483 -0.3944 1.236 -0.0856
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.05171 -0.00123 0.01351 0.03908
-0.01928 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 1.8
  .. ..$ wts          : num [1:352] -0.919 -0.769 1.105 -0.444 4.516 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.0833 0.4158 -0.3748 1.3173 -0.082
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.08773 0.03123 -0.00616 -0.04231
-0.02296 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.65
  .. ..$ wts          : num [1:352] 2.03 -1.6 -1.91 -4.65 -3.03 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.199 0.447 -0.443 1.263 -0.138 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.02808 0.000236 0.061884 0.012432
0.033544 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 7.79
  .. ..$ wts          : num [1:352] -3.314 3.89 -6.355 0.842 4.491 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.171 0.462 -0.337 1.24 -0.128 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.000172 -0.014804 -0.044404 0.03475
0.023508 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.3
  .. ..$ wts          : num [1:352] 5.12 -2.27 2.25 4.02 -6.78 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.1137 0.4326 -0.4635 1.2762 -0.0999
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.05741 0.01451 0.08259 -0.00115
-0.00503 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.42
  .. ..$ wts          : num [1:352] 4.12 -1.78 2.89 4.28 2.57 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.0986 0.4599 -0.4425 1.2061 -0.1931
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.0724 -0.0128 0.0615 0.069 0.0882
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.81
  .. ..$ wts          : num [1:352] -1.207 -1.817 -3.409 -4.643 0.775 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.0905 0.5451 -0.4395 1.1706 -0.0989
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.08053 -0.09806 0.05853 0.10442
-0.00604 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 6.06
  .. ..$ wts          : num [1:352] 1.092 4.676 -0.514 1.13 1.276 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.1781 0.4221 -0.4852 1.2227 -0.0774
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.007 0.025 0.1043 0.0523 -0.0275
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 4.1
  .. ..$ wts          : num [1:352] -4.1 1.95 -5.39 6.06 -3.65 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.1674 0.4017 -0.3968 1.2474 -0.0835
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.00363 0.0454 0.01586 0.02764
-0.02148 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 1.22
  .. ..$ wts          : num [1:352] -2.5 1.43 2.96 -2.31 -1.18 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.1436 0.446 -0.4246 1.2081 -0.0853
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.02742 0.00101 0.04371 0.06697
-0.01964 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 0.858
  .. ..$ wts          : num [1:352] 2.6535 4.398 0.0444 4.9804 -0.6771 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.089 0.4388 -0.283 1.1308 -0.0592
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.0821 0.0083 -0.0979 0.1443 -0.0457
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.19
  .. ..$ wts          : num [1:352] 1.216 -4.28 -2.531 0.987 1.311 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.1548 0.4733 -0.3074 1.2065 -0.0909
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.0163 -0.0263 -0.0735 0.0685 -0.014
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.51
  .. ..$ wts          : num [1:352] -0.862 1.953 1.304 -0.273 1.033 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.141 0.492 -0.376 1.244 -0.101 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.02978 -0.04529 -0.00509 0.03066
-0.00362 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.02
  .. ..$ wts          : num [1:352] 6.78 -0.31 -1.04 -7.21 2.37 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.0302 0.4157 -0.3828 1.134 -0.1247
...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.14087 0.03136 0.00183 0.14107
0.01977 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 1.81
  .. ..$ wts          : num [1:352] 0.385 1.215 -2.217 -1.288 -1.172 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] 0.26023 0.47306 -0.31769 1.29285
-0.00974 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] -0.0892 -0.026 -0.0632 -0.0178
-0.0952 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..$ :List of 15
  .. ..$ n            : num [1:3] 25 13 1
  .. ..$ nunits       : int 40
  .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ nsunits      : num 39
  .. ..$ decay        : num 0
  .. ..$ entropy      : logi FALSE
  .. ..$ softmax      : logi FALSE
  .. ..$ censored     : logi FALSE
  .. ..$ value        : num 2.11
  .. ..$ wts          : num [1:352] 3.38 -2.75 -3.5 -1.13 -8.48 ...
  .. ..$ convergence  : int 1
  .. ..$ fitted.values: num [1:352, 1] -0.0863 0.4472 -0.3007 1.2226
-0.1176 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ residuals    : num [1:352, 1] 0.257314 -0.000178 -0.080274
0.052434 0.012663 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
linout = linout, trace = trace)
  .. ..- attr(*, "class")= chr "nnet"
  ..- attr(*, "class")= chr "nnetarmodels"
 $ nnetargs : list()
 $ fitted   : Time-Series [1:377] from 1986 to 2017: NA NA NA NA NA NA NA
NA NA NA ...
 $ residuals: Time-Series [1:377] from 1986 to 2017: NA NA NA NA NA NA NA
NA NA NA ...
 $ lags     : num [1:25] 1 2 3 4 5 6 7 8 9 10 ...
 $ series   : chr "TSDat"
 $ method   : chr "NNAR(25,1,13)[12]"
 $ call     : language nnetar(y = TSDat)
 $ mean     : Time-Series [1:24] from 2017 to 2019: 54.7 50.3 55.4 62.6
59.7 ...
 - attr(*, "class")= chr "forecast"
>


2017-03-17 15:48 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Paul,
> When manipulating any R object, the first thing to ascertain is what it is:
>
> class(TSmodelForecast)
>
> should give you useful information.
>
> str(TSmodelForecast)
>
> should give you more. Because of the wealth of defined data structures
> in R, it is difficult to manipulate them without this information. I
> suspect that your output is something like a time series object, and
> once that is known, it should not be too hard to display its contents
> in the way you want.
>
> Jim
>
>
> On Sat, Mar 18, 2017 at 7:12 AM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> > Dear Jim,
> >
> > Hope you are doing great. I tried to do what you suggested but R send an
> > error message saying that $ operator is invalid for atomic vectors.
> >
> > The format of the forecasts are as follows: forecasted years are as rows,
> > and forecasted months are in columns what I want to do is to have two
> > colums, one with the forecasted dates in (MMM-YYYY format) and the second
> > column with the actual forecast results.
> >
> > The output that is giving me hard time is the forecast output from nnetar
> > model.
> >
> > Thanks for your valuable support,
> >
> > Best of regards,
> >
> > Paul
> >
> >
> > 2017-03-16 18:23 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
> >>
> >> Hi Paul,
> >> It looks like the information that is printed is in:
> >>
> >> TSModelForecast$mean
> >>
> >> If str(TSModelForecast$mean) returns something like a list with two
> >> components, you can probably use something like this:
> >>
> >> paste(format(TSModelForecast$mean$Date,"%b-%Y"),
> >>  TSModelForecast$mean$Forecast,sep="-",collapse="\n")
> >>
> >> It also might be in TSModelForecast$fitted
> >>
> >> Jim
> >>
> >>
> >> On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com>
> >> wrote:
> >> > Dear friends,
> >> >
> >> > I am currently using R version 3.3.3 (64-bit) and used the following
> >> > code
> >> > to generate forecasts:
> >> >
> >> >> library(forecast)
> >> >>
> >> >> library(tseries)
> >> >
> >> >     ?tseries? version: 0.10-35
> >> >
> >> >     ?tseries? is a package for time series analysis and computational
> >> > finance.
> >> >
> >> >     See ?library(help="tseries")? for details.
> >> >
> >> >
> >> >> DAT<-read.csv("TrainingData.csv")
> >> >>
> >> >> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
> >> >>
> >> >> TSmodel<-nnetar(TSdata)
> >> >>
> >> >> TSmodelForecast<-forecast(TSmodel, h=24)
> >> >>
> >> >> TSmodelForecast
> >> >
> >> > The problem is that the output comes in this fashion:
> >> >
> >> >                 Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
> >> > Sep   Oct
> >> >  2017        10      20      15      40     9         8         21
> >> > 21
> >> >     19     18
> >> >  2018        34      15       7        6      10      11
> >> >
> >> > The format I would like to have is the following:
> >> >
> >> > Date                 Forecast
> >> > Jan-2017               10
> >> > Feb-2017               20
> >> > Mar-2017               15
> >> > Apr-2017                40
> >> > May-2017               9
> >> > Jun-2017                8
> >> > Jul-2017                 21
> >> > Aug-2017               21
> >> > Sep-2017               19
> >> > etc                          etc
> >> >
> >> > Is there a way to make the results look like this?
> >> >
> >> > Attached is a dataset as a reference.
> >> >
> >> > Best regards,
> >> >
> >> > Paul
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Mar 17 22:45:23 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 17 Mar 2017 21:45:23 +0000
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>	<CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>	<CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>
	<CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
Message-ID: <58CC58F3.4090703@sapo.pt>

Hello,

By running the code of the OP, I've come to the conclusion that 
print.forecast calls print.data.frame:

forecast:::print.forecast
function (x, ...)
{
     print(as.data.frame(x))
}
<bytecode: 0x0000000007ac9cd0>
<environment: namespace:forecast>

But I'm unable to get what the OP wants by call as.data.frame(...).
Here is the code with some made up data.

library(forecast)
library(tseries)

DAT <- data.frame(x = sample(100, 100, TRUE))

TSdata <- ts(DAT[,1], start=c(1994,10), frequency=12)
TSmodel <- nnetar(TSdata)
TSmodelForecast <- forecast(TSmodel, h=24)
TSmodelForecast

str(as.data.frame(TSmodelForecast))

Hope this helps,

Rui Barradas

Em 17-03-2017 20:48, Jim Lemon escreveu:
> Hi Paul,
> When manipulating any R object, the first thing to ascertain is what it is:
>
> class(TSmodelForecast)
>
> should give you useful information.
>
> str(TSmodelForecast)
>
> should give you more. Because of the wealth of defined data structures
> in R, it is difficult to manipulate them without this information. I
> suspect that your output is something like a time series object, and
> once that is known, it should not be too hard to display its contents
> in the way you want.
>
> Jim
>
>
> On Sat, Mar 18, 2017 at 7:12 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> Dear Jim,
>>
>> Hope you are doing great. I tried to do what you suggested but R send an
>> error message saying that $ operator is invalid for atomic vectors.
>>
>> The format of the forecasts are as follows: forecasted years are as rows,
>> and forecasted months are in columns what I want to do is to have two
>> colums, one with the forecasted dates in (MMM-YYYY format) and the second
>> column with the actual forecast results.
>>
>> The output that is giving me hard time is the forecast output from nnetar
>> model.
>>
>> Thanks for your valuable support,
>>
>> Best of regards,
>>
>> Paul
>>
>>
>> 2017-03-16 18:23 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>>>
>>> Hi Paul,
>>> It looks like the information that is printed is in:
>>>
>>> TSModelForecast$mean
>>>
>>> If str(TSModelForecast$mean) returns something like a list with two
>>> components, you can probably use something like this:
>>>
>>> paste(format(TSModelForecast$mean$Date,"%b-%Y"),
>>>   TSModelForecast$mean$Forecast,sep="-",collapse="\n")
>>>
>>> It also might be in TSModelForecast$fitted
>>>
>>> Jim
>>>
>>>
>>> On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>> Dear friends,
>>>>
>>>> I am currently using R version 3.3.3 (64-bit) and used the following
>>>> code
>>>> to generate forecasts:
>>>>
>>>>> library(forecast)
>>>>>
>>>>> library(tseries)
>>>>
>>>>      ?tseries? version: 0.10-35
>>>>
>>>>      ?tseries? is a package for time series analysis and computational
>>>> finance.
>>>>
>>>>      See ?library(help="tseries")? for details.
>>>>
>>>>
>>>>> DAT<-read.csv("TrainingData.csv")
>>>>>
>>>>> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>>>>>
>>>>> TSmodel<-nnetar(TSdata)
>>>>>
>>>>> TSmodelForecast<-forecast(TSmodel, h=24)
>>>>>
>>>>> TSmodelForecast
>>>>
>>>> The problem is that the output comes in this fashion:
>>>>
>>>>                  Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
>>>> Sep   Oct
>>>>   2017        10      20      15      40     9         8         21
>>>> 21
>>>>      19     18
>>>>   2018        34      15       7        6      10      11
>>>>
>>>> The format I would like to have is the following:
>>>>
>>>> Date                 Forecast
>>>> Jan-2017               10
>>>> Feb-2017               20
>>>> Mar-2017               15
>>>> Apr-2017                40
>>>> May-2017               9
>>>> Jun-2017                8
>>>> Jul-2017                 21
>>>> Aug-2017               21
>>>> Sep-2017               19
>>>> etc                          etc
>>>>
>>>> Is there a way to make the results look like this?
>>>>
>>>> Attached is a dataset as a reference.
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Sat Mar 18 11:12:13 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 18 Mar 2017 21:12:13 +1100
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <CAMOcQfNjLHt6aYpgQeBwKiO3HH8CB2hxj8h5mWDo=JvU-Sy=9Q@mail.gmail.com>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>
	<CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>
	<CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>
	<CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
	<CAMOcQfNjLHt6aYpgQeBwKiO3HH8CB2hxj8h5mWDo=JvU-Sy=9Q@mail.gmail.com>
Message-ID: <CA+8X3fU63vA1NPSj5G37Kj5iko00e3jmxToAaQ9uzYm7WQ4moQ@mail.gmail.com>

Hi Paul,
A more educated guess is:

print(data.frame(Date=paste(rep(month.abb,32),
 rep(1986:2017,each=12), sep="-")[-(378:384)],
 Forecast=mf5$x))

Someone else may be able to tell you how to extract the dates from the
time series object mf5$x

Jim


On Sat, Mar 18, 2017 at 8:23 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear Jim,
>
> Thank you for your valuable replies. So variable mf5 has the forecasts for a
> fitted nnetar model.
>
> Below is the class and the str(mf5) output. Maybe with this information I am
> sharing with you, hopefully you can give me some more guidance.
>
> Again, thank you so much!
>
>> class(mf5)
> [1] "forecast"
>>
>> str(mf5)
> List of 16
>  $ x        : Time-Series [1:377] from 1986 to 2017: 48 40 44 35 44 42 39 37
> 41 36 ...
>  $ m        : num 12
>  $ p        : num 25
>  $ P        : num 1
>  $ scalex   :List of 2
>   ..$ center: num 38.1
>   ..$ scale : num 10.9
>  $ size     : num 13
>  $ subset   : int [1:377] 1 2 3 4 5 6 7 8 9 10 ...
>  $ model    :List of 20
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 5.83
>   .. ..$ wts          : num [1:352] -1.081 2.199 0.734 1.358 1.115 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.246 0.439 -0.357 1.325 -0.195 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.0754 0.00853 -0.0242 -0.05026
> 0.0898 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.54
>   .. ..$ wts          : num [1:352] -7.113 4.668 -0.801 -5.487 2.751 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.145 0.443 -0.401 1.286 -0.158 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.0258 0.0037 0.02 -0.0107 0.0528 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 1.1
>   .. ..$ wts          : num [1:352] -2.24 -0.698 -0.243 -2.575 4.073 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.2466 0.2986 -0.4369 1.3053 -0.0965
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.07551 0.14845 0.056 -0.03027
> -0.00844 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 1.8
>   .. ..$ wts          : num [1:352] 0.427 1.89 -0.705 -3.121 -1.134 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.11 0.37 -0.38 1.25 -0.15 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.06113 0.07689 -0.00135 0.02279
> 0.04491 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.67
>   .. ..$ wts          : num [1:352] -0.632 2.121 6.144 1.697 0.953 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.2228 0.4483 -0.3944 1.236 -0.0856
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.05171 -0.00123 0.01351 0.03908
> -0.01928 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 1.8
>   .. ..$ wts          : num [1:352] -0.919 -0.769 1.105 -0.444 4.516 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.0833 0.4158 -0.3748 1.3173 -0.082
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.08773 0.03123 -0.00616 -0.04231
> -0.02296 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.65
>   .. ..$ wts          : num [1:352] 2.03 -1.6 -1.91 -4.65 -3.03 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.199 0.447 -0.443 1.263 -0.138 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.02808 0.000236 0.061884 0.012432
> 0.033544 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 7.79
>   .. ..$ wts          : num [1:352] -3.314 3.89 -6.355 0.842 4.491 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.171 0.462 -0.337 1.24 -0.128 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.000172 -0.014804 -0.044404 0.03475
> 0.023508 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.3
>   .. ..$ wts          : num [1:352] 5.12 -2.27 2.25 4.02 -6.78 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.1137 0.4326 -0.4635 1.2762 -0.0999
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.05741 0.01451 0.08259 -0.00115
> -0.00503 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.42
>   .. ..$ wts          : num [1:352] 4.12 -1.78 2.89 4.28 2.57 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.0986 0.4599 -0.4425 1.2061 -0.1931
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.0724 -0.0128 0.0615 0.069 0.0882
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.81
>   .. ..$ wts          : num [1:352] -1.207 -1.817 -3.409 -4.643 0.775 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.0905 0.5451 -0.4395 1.1706 -0.0989
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.08053 -0.09806 0.05853 0.10442
> -0.00604 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 6.06
>   .. ..$ wts          : num [1:352] 1.092 4.676 -0.514 1.13 1.276 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.1781 0.4221 -0.4852 1.2227 -0.0774
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.007 0.025 0.1043 0.0523 -0.0275
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 4.1
>   .. ..$ wts          : num [1:352] -4.1 1.95 -5.39 6.06 -3.65 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.1674 0.4017 -0.3968 1.2474 -0.0835
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.00363 0.0454 0.01586 0.02764
> -0.02148 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 1.22
>   .. ..$ wts          : num [1:352] -2.5 1.43 2.96 -2.31 -1.18 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.1436 0.446 -0.4246 1.2081 -0.0853
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.02742 0.00101 0.04371 0.06697
> -0.01964 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 0.858
>   .. ..$ wts          : num [1:352] 2.6535 4.398 0.0444 4.9804 -0.6771 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.089 0.4388 -0.283 1.1308 -0.0592
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.0821 0.0083 -0.0979 0.1443 -0.0457
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.19
>   .. ..$ wts          : num [1:352] 1.216 -4.28 -2.531 0.987 1.311 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.1548 0.4733 -0.3074 1.2065 -0.0909
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.0163 -0.0263 -0.0735 0.0685 -0.014
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.51
>   .. ..$ wts          : num [1:352] -0.862 1.953 1.304 -0.273 1.033 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.141 0.492 -0.376 1.244 -0.101 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.02978 -0.04529 -0.00509 0.03066
> -0.00362 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.02
>   .. ..$ wts          : num [1:352] 6.78 -0.31 -1.04 -7.21 2.37 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.0302 0.4157 -0.3828 1.134 -0.1247
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.14087 0.03136 0.00183 0.14107
> 0.01977 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 1.81
>   .. ..$ wts          : num [1:352] 0.385 1.215 -2.217 -1.288 -1.172 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] 0.26023 0.47306 -0.31769 1.29285
> -0.00974 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] -0.0892 -0.026 -0.0632 -0.0178
> -0.0952 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..$ :List of 15
>   .. ..$ n            : num [1:3] 25 13 1
>   .. ..$ nunits       : int 40
>   .. ..$ nconn        : num [1:41] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ conn         : num [1:352] 0 1 2 3 4 5 6 7 8 9 ...
>   .. ..$ nsunits      : num 39
>   .. ..$ decay        : num 0
>   .. ..$ entropy      : logi FALSE
>   .. ..$ softmax      : logi FALSE
>   .. ..$ censored     : logi FALSE
>   .. ..$ value        : num 2.11
>   .. ..$ wts          : num [1:352] 3.38 -2.75 -3.5 -1.13 -8.48 ...
>   .. ..$ convergence  : int 1
>   .. ..$ fitted.values: num [1:352, 1] -0.0863 0.4472 -0.3007 1.2226 -0.1176
> ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ residuals    : num [1:352, 1] 0.257314 -0.000178 -0.080274 0.052434
> 0.012663 ...
>   .. .. ..- attr(*, "dimnames")=List of 2
>   .. .. .. ..$ : NULL
>   .. .. .. ..$ : NULL
>   .. ..$ call         : language nnet.default(x = x, y = y, size = ..1,
> linout = linout, trace = trace)
>   .. ..- attr(*, "class")= chr "nnet"
>   ..- attr(*, "class")= chr "nnetarmodels"
>  $ nnetargs : list()
>  $ fitted   : Time-Series [1:377] from 1986 to 2017: NA NA NA NA NA NA NA NA
> NA NA ...
>  $ residuals: Time-Series [1:377] from 1986 to 2017: NA NA NA NA NA NA NA NA
> NA NA ...
>  $ lags     : num [1:25] 1 2 3 4 5 6 7 8 9 10 ...
>  $ series   : chr "TSDat"
>  $ method   : chr "NNAR(25,1,13)[12]"
>  $ call     : language nnetar(y = TSDat)
>  $ mean     : Time-Series [1:24] from 2017 to 2019: 54.7 50.3 55.4 62.6 59.7
> ...
>  - attr(*, "class")= chr "forecast"
>>
>
>
> 2017-03-17 15:48 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Paul,
>> When manipulating any R object, the first thing to ascertain is what it
>> is:
>>
>> class(TSmodelForecast)
>>
>> should give you useful information.
>>
>> str(TSmodelForecast)
>>
>> should give you more. Because of the wealth of defined data structures
>> in R, it is difficult to manipulate them without this information. I
>> suspect that your output is something like a time series object, and
>> once that is known, it should not be too hard to display its contents
>> in the way you want.
>>
>> Jim
>>
>>
>> On Sat, Mar 18, 2017 at 7:12 AM, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> > Dear Jim,
>> >
>> > Hope you are doing great. I tried to do what you suggested but R send an
>> > error message saying that $ operator is invalid for atomic vectors.
>> >
>> > The format of the forecasts are as follows: forecasted years are as
>> > rows,
>> > and forecasted months are in columns what I want to do is to have two
>> > colums, one with the forecasted dates in (MMM-YYYY format) and the
>> > second
>> > column with the actual forecast results.
>> >
>> > The output that is giving me hard time is the forecast output from
>> > nnetar
>> > model.
>> >
>> > Thanks for your valuable support,
>> >
>> > Best of regards,
>> >
>> > Paul
>> >
>> >
>> > 2017-03-16 18:23 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>> >>
>> >> Hi Paul,
>> >> It looks like the information that is printed is in:
>> >>
>> >> TSModelForecast$mean
>> >>
>> >> If str(TSModelForecast$mean) returns something like a list with two
>> >> components, you can probably use something like this:
>> >>
>> >> paste(format(TSModelForecast$mean$Date,"%b-%Y"),
>> >>  TSModelForecast$mean$Forecast,sep="-",collapse="\n")
>> >>
>> >> It also might be in TSModelForecast$fitted
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com>
>> >> wrote:
>> >> > Dear friends,
>> >> >
>> >> > I am currently using R version 3.3.3 (64-bit) and used the following
>> >> > code
>> >> > to generate forecasts:
>> >> >
>> >> >> library(forecast)
>> >> >>
>> >> >> library(tseries)
>> >> >
>> >> >     ?tseries? version: 0.10-35
>> >> >
>> >> >     ?tseries? is a package for time series analysis and computational
>> >> > finance.
>> >> >
>> >> >     See ?library(help="tseries")? for details.
>> >> >
>> >> >
>> >> >> DAT<-read.csv("TrainingData.csv")
>> >> >>
>> >> >> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>> >> >>
>> >> >> TSmodel<-nnetar(TSdata)
>> >> >>
>> >> >> TSmodelForecast<-forecast(TSmodel, h=24)
>> >> >>
>> >> >> TSmodelForecast
>> >> >
>> >> > The problem is that the output comes in this fashion:
>> >> >
>> >> >                 Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
>> >> > Sep   Oct
>> >> >  2017        10      20      15      40     9         8         21
>> >> > 21
>> >> >     19     18
>> >> >  2018        34      15       7        6      10      11
>> >> >
>> >> > The format I would like to have is the following:
>> >> >
>> >> > Date                 Forecast
>> >> > Jan-2017               10
>> >> > Feb-2017               20
>> >> > Mar-2017               15
>> >> > Apr-2017                40
>> >> > May-2017               9
>> >> > Jun-2017                8
>> >> > Jul-2017                 21
>> >> > Aug-2017               21
>> >> > Sep-2017               19
>> >> > etc                          etc
>> >> >
>> >> > Is there a way to make the results look like this?
>> >> >
>> >> > Attached is a dataset as a reference.
>> >> >
>> >> > Best regards,
>> >> >
>> >> > Paul
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From ruipbarradas at sapo.pt  Sat Mar 18 14:37:17 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 18 Mar 2017 13:37:17 +0000
Subject: [R] Transposing forecasts results from nnetar function and turn
 them into a data frame
In-Reply-To: <58CC58F3.4090703@sapo.pt>
References: <CAMOcQfNSJi+EWc80UyA8cGWGd-WdV9+d0JR=zvsxm_n8hwvHGg@mail.gmail.com>	<CA+8X3fWaLuwUoXpz24sYG=bFmZGKx9wJn2mEeK1_=48tSCKKFw@mail.gmail.com>	<CAMOcQfNL4OD7a60khtirvYf301tND+NCH+Qh5qWbP=aqp4vDow@mail.gmail.com>	<CA+8X3fXYddP=BW7NFPk7pmP-Q2w4Z5VsTWCjg7_XWFTpLa3zxQ@mail.gmail.com>
	<58CC58F3.4090703@sapo.pt>
Message-ID: <58CD380D.5030101@sapo.pt>

Hello,

Is this what you want?


fun <- function(x, a){
	y <- as.numeric(as.character(x))
	z <- paste(a, names(x))
	data.frame(z, y)
}

dat2 <- as.data.frame(TSmodelForecast)

tmp <- lapply(seq_along(dat2), function(i) fun(dat2[[i]], names(dat2)[i]))
result <- do.call(rbind, tmp)

Hope this helps,

Rui Barradas

Em 17-03-2017 21:45, Rui Barradas escreveu:
> Hello,
>
> By running the code of the OP, I've come to the conclusion that
> print.forecast calls print.data.frame:
>
> forecast:::print.forecast
> function (x, ...)
> {
>      print(as.data.frame(x))
> }
> <bytecode: 0x0000000007ac9cd0>
> <environment: namespace:forecast>
>
> But I'm unable to get what the OP wants by call as.data.frame(...).
> Here is the code with some made up data.
>
> library(forecast)
> library(tseries)
>
> DAT <- data.frame(x = sample(100, 100, TRUE))
>
> TSdata <- ts(DAT[,1], start=c(1994,10), frequency=12)
> TSmodel <- nnetar(TSdata)
> TSmodelForecast <- forecast(TSmodel, h=24)
> TSmodelForecast
>
> str(as.data.frame(TSmodelForecast))
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-03-2017 20:48, Jim Lemon escreveu:
>> Hi Paul,
>> When manipulating any R object, the first thing to ascertain is what
>> it is:
>>
>> class(TSmodelForecast)
>>
>> should give you useful information.
>>
>> str(TSmodelForecast)
>>
>> should give you more. Because of the wealth of defined data structures
>> in R, it is difficult to manipulate them without this information. I
>> suspect that your output is something like a time series object, and
>> once that is known, it should not be too hard to display its contents
>> in the way you want.
>>
>> Jim
>>
>>
>> On Sat, Mar 18, 2017 at 7:12 AM, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>> Dear Jim,
>>>
>>> Hope you are doing great. I tried to do what you suggested but R send an
>>> error message saying that $ operator is invalid for atomic vectors.
>>>
>>> The format of the forecasts are as follows: forecasted years are as
>>> rows,
>>> and forecasted months are in columns what I want to do is to have two
>>> colums, one with the forecasted dates in (MMM-YYYY format) and the
>>> second
>>> column with the actual forecast results.
>>>
>>> The output that is giving me hard time is the forecast output from
>>> nnetar
>>> model.
>>>
>>> Thanks for your valuable support,
>>>
>>> Best of regards,
>>>
>>> Paul
>>>
>>>
>>> 2017-03-16 18:23 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>>>>
>>>> Hi Paul,
>>>> It looks like the information that is printed is in:
>>>>
>>>> TSModelForecast$mean
>>>>
>>>> If str(TSModelForecast$mean) returns something like a list with two
>>>> components, you can probably use something like this:
>>>>
>>>> paste(format(TSModelForecast$mean$Date,"%b-%Y"),
>>>>   TSModelForecast$mean$Forecast,sep="-",collapse="\n")
>>>>
>>>> It also might be in TSModelForecast$fitted
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Fri, Mar 17, 2017 at 5:34 AM, Paul Bernal <paulbernal07 at gmail.com>
>>>> wrote:
>>>>> Dear friends,
>>>>>
>>>>> I am currently using R version 3.3.3 (64-bit) and used the following
>>>>> code
>>>>> to generate forecasts:
>>>>>
>>>>>> library(forecast)
>>>>>>
>>>>>> library(tseries)
>>>>>
>>>>>      ?tseries? version: 0.10-35
>>>>>
>>>>>      ?tseries? is a package for time series analysis and computational
>>>>> finance.
>>>>>
>>>>>      See ?library(help="tseries")? for details.
>>>>>
>>>>>
>>>>>> DAT<-read.csv("TrainingData.csv")
>>>>>>
>>>>>> TSdata<-ts(DAT[,1], start=c(1994,10), frequency=12)
>>>>>>
>>>>>> TSmodel<-nnetar(TSdata)
>>>>>>
>>>>>> TSmodelForecast<-forecast(TSmodel, h=24)
>>>>>>
>>>>>> TSmodelForecast
>>>>>
>>>>> The problem is that the output comes in this fashion:
>>>>>
>>>>>                  Jan    Feb    Mar    Apr    May    Jun     Jul    Aug
>>>>> Sep   Oct
>>>>>   2017        10      20      15      40     9         8         21
>>>>> 21
>>>>>      19     18
>>>>>   2018        34      15       7        6      10      11
>>>>>
>>>>> The format I would like to have is the following:
>>>>>
>>>>> Date                 Forecast
>>>>> Jan-2017               10
>>>>> Feb-2017               20
>>>>> Mar-2017               15
>>>>> Apr-2017                40
>>>>> May-2017               9
>>>>> Jun-2017                8
>>>>> Jul-2017                 21
>>>>> Aug-2017               21
>>>>> Sep-2017               19
>>>>> etc                          etc
>>>>>
>>>>> Is there a way to make the results look like this?
>>>>>
>>>>> Attached is a dataset as a reference.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Paul
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Mar 18 14:51:35 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 18 Mar 2017 08:51:35 -0500
Subject: [R] find and
Message-ID: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>

Hi all,

I am trying to find a city that do not have the same "var" value.
Within city the var should be the same otherwise exclude the city from
the final data set.
Here is my sample data and my attempt. City1 and city4 should be excluded.

DF4 <- read.table(header=TRUE, text=' city  wk var
city1  1  x
city1  2  -
city1  3  x
city2  1  x
city2  2  x
city2  3  x
city2  4  x
city3  1  x
city3  2  x
city3  3  x
city3  4  x
city4  1  x
city4  2  x
city4  3  y
city4  4  y
city5  3  -
city5  4  -')

my attempt
     test2  <-   data.table(DF4, key="city,var")
     ID1    <-   test2[ !duplicated(test2),]
    dps     <-   ID1$city[duplicated(ID1$city)]
   Ddup  <-   which(test2$city %in% dps)

    if(length(Ddup) !=0)  {
          test2   <-  test2[- Ddup,]  }

want     <-  data.frame(test2)


I want get the following result but I am not getting it.

   city wk var
  city2  1   x
  city2  2   x
  city2  3   x
  city2  4   x
  city3  1   x
  city3  2   x
 city3  3   x
 city3  4   x
 city5  3   -
 city5  4   -

Can some help me out the problem is?

Thank you.


From ruipbarradas at sapo.pt  Sat Mar 18 15:15:04 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 18 Mar 2017 14:15:04 +0000
Subject: [R] find and
In-Reply-To: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>
References: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>
Message-ID: <58CD40E8.40704@sapo.pt>

Hello,

I believe this does it.


sp <- split(DF4, DF4$city)
want <- do.call(rbind, lapply(sp, function(x)
		if(length(unique(x$var)) == 1) x else NULL))
rownames(want) <- NULL
want


Hope this helps,

Rui Barradas

Em 18-03-2017 13:51, Ashta escreveu:
> Hi all,
>
> I am trying to find a city that do not have the same "var" value.
> Within city the var should be the same otherwise exclude the city from
> the final data set.
> Here is my sample data and my attempt. City1 and city4 should be excluded.
>
> DF4 <- read.table(header=TRUE, text=' city  wk var
> city1  1  x
> city1  2  -
> city1  3  x
> city2  1  x
> city2  2  x
> city2  3  x
> city2  4  x
> city3  1  x
> city3  2  x
> city3  3  x
> city3  4  x
> city4  1  x
> city4  2  x
> city4  3  y
> city4  4  y
> city5  3  -
> city5  4  -')
>
> my attempt
>       test2  <-   data.table(DF4, key="city,var")
>       ID1    <-   test2[ !duplicated(test2),]
>      dps     <-   ID1$city[duplicated(ID1$city)]
>     Ddup  <-   which(test2$city %in% dps)
>
>      if(length(Ddup) !=0)  {
>            test2   <-  test2[- Ddup,]  }
>
> want     <-  data.frame(test2)
>
>
> I want get the following result but I am not getting it.
>
>     city wk var
>    city2  1   x
>    city2  2   x
>    city2  3   x
>    city2  4   x
>    city3  1   x
>    city3  2   x
>   city3  3   x
>   city3  4   x
>   city5  3   -
>   city5  4   -
>
> Can some help me out the problem is?
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From evan.cooch at gmail.com  Fri Mar 17 18:14:24 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 17 Mar 2017 13:14:24 -0400
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
	<CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
Message-ID: <fbaaed80-eab5-134b-7245-b100b8e80262@gmail.com>



On 3/17/2017 12:58 PM, Ulrik Stervbo wrote:
> Hi Evan
>
> you can easily do this by applying diff() to each exp group.
>
> Either using dplyr:
> library(dplyr)
> mydata %>%
>   group_by(exp) %>%
>   summarise(difference = diff(rslt))
>
> Or with base R
> aggregate(mydata, by = list(group = mydata$exp), FUN = diff)
>
>


Indeed -- thanks very much!

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Fri Mar 17 18:25:08 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 17 Mar 2017 13:25:08 -0400
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <CAGxFJbTFx0iP9FbV_=j4J1smZnZEPkzXhSb0_=zsYui02KuHRg@mail.gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
	<CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
	<CAGxFJbTFx0iP9FbV_=j4J1smZnZEPkzXhSb0_=zsYui02KuHRg@mail.gmail.com>
Message-ID: <eefc0427-5e4d-f1cf-05e4-6742b7d95e11@gmail.com>



On 3/17/2017 1:19 PM, Bert Gunter wrote:
> Evan:
>
> You misunderstand the concept of a lagged variable.

Well, lag in R, perhaps (and by my own admission). In SAS, thats exactly 
how it works.:

data test;
input exp rslt;
cards;
<data in the data frame in OP>
     *;


     data test2; set test; by exp;
     diff=rslt-lag(rslt);
       if last.exp;

>
> Ulrik:
>
> Well, yes, that is certainly a general solution that works. However,
> given the *specific* structure described by the OP, an even more
> direct (maybe more efficient?) way to do it just uses (logical)
> subscripting:
>
> odds <-  (seq_len(nrow(mydata)) %% 2) == 1
> newdat <-data.frame(mydata[odds,1 ],mydata[!odds,2] - mydata[odds,2])
> names(newdat) <- names(mydata)
>

Interesting - thanks!

>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 17, 2017 at 9:58 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> Hi Evan
>>
>> you can easily do this by applying diff() to each exp group.
>>
>> Either using dplyr:
>> library(dplyr)
>> mydata %>%
>>    group_by(exp) %>%
>>    summarise(difference = diff(rslt))
>>
>> Or with base R
>> aggregate(mydata, by = list(group = mydata$exp), FUN = diff)
>>
>> HTH
>> Ulrik
>>
>>
>> On Fri, 17 Mar 2017 at 17:34 Evan Cooch <evan.cooch at gmail.com> wrote:
>>
>>> Suppose I have a dataframe that looks like the following:
>>>
>>> n=2
>>> mydata <- data.frame(exp = rep(1:5,each=n), rslt =
>>> c(12,15,7,8,24,28,33,15,22,11))
>>> mydata
>>>      exp rslt
>>> 1    1   12
>>> 2    1   15
>>> 3    2    7
>>> 4    2    8
>>> 5    3   24
>>> 6    3   28
>>> 7    4   33
>>> 8    4   15
>>> 9    5   22
>>> 10   5   11
>>>
>>> The variable 'exp' (for experiment') occurs in pairs over consecutive
>>> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is
>>> the 'control', and the second is a 'treatment'. The rslt column is the
>>> result.
>>>
>>> What I'm trying to do is create a subset of this dataframe that consists
>>> of the exp number, and the lagged difference between the 'control' and
>>> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For
>>> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is
>>> take mydata (above), and turn it into
>>>
>>>        exp  diff
>>> 1   1      3
>>> 2   2      1
>>> 3   3      4
>>> 4   4      -18
>>> 5   5      -11
>>>
>>> The basic 'trick' I can't figure out is how to create a lagged variable
>>> between the second row (record) for a given level of exp, and the first
>>> row for that exp.  This is easy to do in SAS (which I'm more familiar
>>> with), but I'm struggling with the equivalent in R. The brute force
>>> approach  I thought of is to simply split the dataframe into to (one
>>> even rows, one odd rows), merge by exp, and then calculate a difference.
>>> But this seems to require renaming the rslt column in the two new
>>> dataframes so they are different in the merge (say, rslt_cont n the odd
>>> dataframe, and rslt_trt in the even dataframe), allowing me to calculate
>>> a difference between the two.
>>>
>>> While I suppose this would work, I'm wondering if I'm missing a more
>>> elegant 'in place' approach that doesn't require me to split the data
>>> frame and do every via a merge.
>>>
>>> Suggestions/pointers to the obvious welcome. I've tried playing with
>>> lag, and some approaches using lag in the zoo package,  but haven't
>>> found the magic trick. The problem (meaning, what I can't figure out)
>>> seems to be conditioning the lag on the level of exp.
>>>
>>> Many thanks...
>>>
>>>
>>> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y =
>>> c(6,17,26,37,44))
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Fri Mar 17 18:57:48 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 17 Mar 2017 13:57:48 -0400
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <CAGxFJbR3ciRTF4ZcgCKYEe0Av+qFWTQtEUp4OfmBjSEX0v7zZA@mail.gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
	<CAKVAULOVoZWRZp_XUa6oAS11swnGt5dRz506QLEayf77zjNs+A@mail.gmail.com>
	<CAGxFJbTFx0iP9FbV_=j4J1smZnZEPkzXhSb0_=zsYui02KuHRg@mail.gmail.com>
	<eefc0427-5e4d-f1cf-05e4-6742b7d95e11@gmail.com>
	<CAGxFJbR3ciRTF4ZcgCKYEe0Av+qFWTQtEUp4OfmBjSEX0v7zZA@mail.gmail.com>
Message-ID: <46f40d98-8500-9405-8d83-01eb8ddfbfd3@gmail.com>

Thanks very much. I suspect 50% of my time in R is spent translating 
from what I know how to do in SAS (25+ years of heavy use), to what is 
equivalent in SAS. So far, I haven't found anything I can do in SAS that 
I can't do in R, with some help. ;-)

Cheers...

On 3/17/2017 1:51 PM, Bert Gunter wrote:
> Evan:
>
> Yes, I stand partially corrected. You have the concept correct, but R
> implements it differently than SAS.
>
> I think what you want for your approach is diff():
>
> evens <-  (seq_len(nrow(mydata)) %% 2) == 0
> newdat <-data.frame(exp=mydata[evens,1 ],reslt= diff(mydata[,2])[evens[-1]])
>
> ... which seems neater to me than what I offered previously.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 17, 2017 at 10:25 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>>
>> On 3/17/2017 1:19 PM, Bert Gunter wrote:
>>> Evan:
>>>
>>> You misunderstand the concept of a lagged variable.
>>
>> Well, lag in R, perhaps (and by my own admission). In SAS, thats exactly how
>> it works.:
>>
>> data test;
>> input exp rslt;
>> cards;
>> <data in the data frame in OP>
>>      *;
>>
>>
>>      data test2; set test; by exp;
>>      diff=rslt-lag(rslt);
>>        if last.exp;
>>
>>> Ulrik:
>>>
>>> Well, yes, that is certainly a general solution that works. However,
>>> given the *specific* structure described by the OP, an even more
>>> direct (maybe more efficient?) way to do it just uses (logical)
>>> subscripting:
>>>
>>> odds <-  (seq_len(nrow(mydata)) %% 2) == 1
>>> newdat <-data.frame(mydata[odds,1 ],mydata[!odds,2] - mydata[odds,2])
>>> names(newdat) <- names(mydata)
>>>
>> Interesting - thanks!
>>
>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Mar 17, 2017 at 9:58 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>> wrote:
>>>> Hi Evan
>>>>
>>>> you can easily do this by applying diff() to each exp group.
>>>>
>>>> Either using dplyr:
>>>> library(dplyr)
>>>> mydata %>%
>>>>     group_by(exp) %>%
>>>>     summarise(difference = diff(rslt))
>>>>
>>>> Or with base R
>>>> aggregate(mydata, by = list(group = mydata$exp), FUN = diff)
>>>>
>>>> HTH
>>>> Ulrik
>>>>
>>>>
>>>> On Fri, 17 Mar 2017 at 17:34 Evan Cooch <evan.cooch at gmail.com> wrote:
>>>>
>>>>> Suppose I have a dataframe that looks like the following:
>>>>>
>>>>> n=2
>>>>> mydata <- data.frame(exp = rep(1:5,each=n), rslt =
>>>>> c(12,15,7,8,24,28,33,15,22,11))
>>>>> mydata
>>>>>       exp rslt
>>>>> 1    1   12
>>>>> 2    1   15
>>>>> 3    2    7
>>>>> 4    2    8
>>>>> 5    3   24
>>>>> 6    3   28
>>>>> 7    4   33
>>>>> 8    4   15
>>>>> 9    5   22
>>>>> 10   5   11
>>>>>
>>>>> The variable 'exp' (for experiment') occurs in pairs over consecutive
>>>>> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is
>>>>> the 'control', and the second is a 'treatment'. The rslt column is the
>>>>> result.
>>>>>
>>>>> What I'm trying to do is create a subset of this dataframe that consists
>>>>> of the exp number, and the lagged difference between the 'control' and
>>>>> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For
>>>>> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is
>>>>> take mydata (above), and turn it into
>>>>>
>>>>>         exp  diff
>>>>> 1   1      3
>>>>> 2   2      1
>>>>> 3   3      4
>>>>> 4   4      -18
>>>>> 5   5      -11
>>>>>
>>>>> The basic 'trick' I can't figure out is how to create a lagged variable
>>>>> between the second row (record) for a given level of exp, and the first
>>>>> row for that exp.  This is easy to do in SAS (which I'm more familiar
>>>>> with), but I'm struggling with the equivalent in R. The brute force
>>>>> approach  I thought of is to simply split the dataframe into to (one
>>>>> even rows, one odd rows), merge by exp, and then calculate a difference.
>>>>> But this seems to require renaming the rslt column in the two new
>>>>> dataframes so they are different in the merge (say, rslt_cont n the odd
>>>>> dataframe, and rslt_trt in the even dataframe), allowing me to calculate
>>>>> a difference between the two.
>>>>>
>>>>> While I suppose this would work, I'm wondering if I'm missing a more
>>>>> elegant 'in place' approach that doesn't require me to split the data
>>>>> frame and do every via a merge.
>>>>>
>>>>> Suggestions/pointers to the obvious welcome. I've tried playing with
>>>>> lag, and some approaches using lag in the zoo package,  but haven't
>>>>> found the magic trick. The problem (meaning, what I can't figure out)
>>>>> seems to be conditioning the lag on the level of exp.
>>>>>
>>>>> Many thanks...
>>>>>
>>>>>
>>>>> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y =
>>>>> c(6,17,26,37,44))
>>>>>
>>>>>
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From alicia.m.ellis at gmail.com  Fri Mar 17 19:33:03 2017
From: alicia.m.ellis at gmail.com (Alicia Ellis)
Date: Fri, 17 Mar 2017 14:33:03 -0400
Subject: [R] Changing cell value for MANY unique pairings of values in 2
	columns
Message-ID: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>

 am cleaning some very messy health record lab data.  Several of the rows
in the VALUE column have text entries and they need to be converted to
numeric in the NUMERIC_VALUE column based on the values in VALUE and
DESCRIPTION.  For example:

df <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than 0.30",
"12%", "<0.2", "Unknown"),
                 DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
                 NUMERIC_VALUE=c(9, 9,9,9,9,9,9))
df

df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION == "A"]=999999999


However, I need to do this for ~500 unique pairings of VALUE and
DESCRIPTION entries.  I'm trying to find an easy way to do this without
having to have 500 lines of code for each unique pairing.  Some of the
pairings will be changed to the same value (e.g., 99999999, or -999999999)
but many will be unique numeric values.


I've started by creating a new object called rules where a SUBSET of df
rows are included with the new value they should be changed to.


rules <- data.frame(VALUE = c("<60",  "Negative", "Less than 0.30", "<0.2",
"Unknown"),
                    DESCRIPTION = c("A", "B", "C", "E", "E"),
                    NEW_VALUE=c(60, -999999,0.29,0.1,777777))
rules


I tried doing a loop to change the values in df based on the suggested
value in rules:

for (i in (1 : nrow(rules))) {
  df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
[i,2]]=rules[i,3]
}
df

This gives the error:

Error in Ops.factor(df$VALUE, rules[i, 1]) :
  level sets of factors are differentwork and I think because when I write

If I create rules using the exact same levels as df it works:

rules <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
0.30", "12%", "<0.2", "Unknown"),
                    DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
                    NEW_VALUE=c(60, 999999,-999999,0.29,12,0.1,777777))
rules

for (i in (1 : nrow(rules))) {
  df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
[i,2]]=rules[i,3]
}
df


Can anyone suggest a way to modify my for loop so that it works for a
subset of rows in df and accomplish what I want?  Or suggest a completely
different method that works?


Thanks!

	[[alternative HTML version deleted]]


From sreejitk87 at gmail.com  Sat Mar 18 05:28:43 2017
From: sreejitk87 at gmail.com (Sreejit K)
Date: Sat, 18 Mar 2017 09:58:43 +0530
Subject: [R] Optimum number of PC and observations in Elasticnet R package
Message-ID: <CAHncmU_-Pktq1SnMG4-qWaoRyzABVJhvTYoDuwwaoQpfbESQrQ@mail.gmail.com>

Respected Sirs/Madam,

Good Morning

As part of a project I'm using elasticnet package in R for sparse pca. I
would be great help for me if you can advice me on how to select Optimum
number of principal components and number of observation in elasticnet
package (k, para ) in R.


-- 


*Thanks & Regards*

*Sreejit K.*

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sat Mar 18 16:40:47 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 18 Mar 2017 15:40:47 +0000
Subject: [R] find and
In-Reply-To: <58CD40E8.40704@sapo.pt>
References: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>
	<58CD40E8.40704@sapo.pt>
Message-ID: <CAKVAULN2vcRkTWnWOBWuurkBG=qS+ss63O+ny+UX+_FTu=JDiw@mail.gmail.com>

Using dplyr:

library(dplyr)

# Counting unique
DF4 %>%
  group_by(city) %>%
  filter(length(unique(var)) == 1)

# Counting not duplicated
DF4 %>%
  group_by(city) %>%
  filter(sum(!duplicated(var)) == 1)

HTH
Ulrik


On Sat, 18 Mar 2017 at 15:17 Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I believe this does it.
>
>
> sp <- split(DF4, DF4$city)
> want <- do.call(rbind, lapply(sp, function(x)
>                 if(length(unique(x$var)) == 1) x else NULL))
> rownames(want) <- NULL
> want
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 18-03-2017 13:51, Ashta escreveu:
> > Hi all,
> >
> > I am trying to find a city that do not have the same "var" value.
> > Within city the var should be the same otherwise exclude the city from
> > the final data set.
> > Here is my sample data and my attempt. City1 and city4 should be
> excluded.
> >
> > DF4 <- read.table(header=TRUE, text=' city  wk var
> > city1  1  x
> > city1  2  -
> > city1  3  x
> > city2  1  x
> > city2  2  x
> > city2  3  x
> > city2  4  x
> > city3  1  x
> > city3  2  x
> > city3  3  x
> > city3  4  x
> > city4  1  x
> > city4  2  x
> > city4  3  y
> > city4  4  y
> > city5  3  -
> > city5  4  -')
> >
> > my attempt
> >       test2  <-   data.table(DF4, key="city,var")
> >       ID1    <-   test2[ !duplicated(test2),]
> >      dps     <-   ID1$city[duplicated(ID1$city)]
> >     Ddup  <-   which(test2$city %in% dps)
> >
> >      if(length(Ddup) !=0)  {
> >            test2   <-  test2[- Ddup,]  }
> >
> > want     <-  data.frame(test2)
> >
> >
> > I want get the following result but I am not getting it.
> >
> >     city wk var
> >    city2  1   x
> >    city2  2   x
> >    city2  3   x
> >    city2  4   x
> >    city3  1   x
> >    city3  2   x
> >   city3  3   x
> >   city3  4   x
> >   city5  3   -
> >   city5  4   -
> >
> > Can some help me out the problem is?
> >
> > Thank you.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mrguilfoyle at gmail.com  Sat Mar 18 17:18:07 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Sat, 18 Mar 2017 16:18:07 +0000
Subject: [R] lagging over consecutive pairs of rows in dataframe
In-Reply-To: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
References: <6cacac4b-18ce-b157-9bd0-e914cb2ae2a1@gmail.com>
Message-ID: <98FD6DF6-50EA-42DB-B1A7-DFA3C19826F7@gmail.com>

If you are strict about your data formatting then the following is a fast way of calculating the differences, based on reshaping the data column:

A = matrix(mydata$rslt, nrow=2)
data.frame(exp=1:ncol(A), diff=A[2,]-A[1,])

alternatively, if the 'exp' values are not guaranteed to be sequential you can reshape an index:

A = matrix(1:nrow(mydata), nrow=2)
data.frame(exp=mydata$exp[A[1,]], diff=mydata$rslt[A[2,]]-mydata$rslt[A[1,]])

However, I would suggest that you have a further variable to label 'control' and 'treatment' groups and explicitly use this for the calculation.  Otherwise, if at any time you sort or reorder the data you will run into problems or produce erroneous results (but more than likely won't generate any actual R errors to alert you):

data.frame(exp = unique(mydata$exp), diff = as.vector(by(mydata, mydata$exp, function(x) x$rslt[x$type=='treatment']-x$rslt[x$type=='control'])))

The efficiency of the various options that have been suggested in this thread piqued my interest so a quick benchmark seemed in order (see below, including a 'safer' method).  Of course, this is probably only relevant if you have huge datasets that you are repeatedly performing this calculation on.


library('microbenchmark')

#create some example data similar to the OP
ndata = 1000
mydata = data.frame(exp = cumsum(rep(c(1,0),ndata)),rslt=sample(1:50, size = ndata*2, replace = TRUE), type=rep(c('control','treatment'),ndata))

#various suggested options
diff.BG = function(mydata) {
  evens <-  (seq_len(nrow(mydata)) %% 2) == 0
  data.frame(exp = mydata[evens,1 ], diff = diff(mydata[,2])[evens[-1]])
}

diff.US = function(mydata) {
  aggregate(mydata$rslt, by = list(group = mydata$exp), FUN = diff)
}

diff.MG1 = function(mydata) {
  A = matrix(mydata$rslt, nrow=2)
  data.frame(exp=1:ncol(A), diff=A[2,]-A[1,])
}

diff.MG2 = function(mydata) {
  A = matrix(1:nrow(mydata), nrow=2)
  data.frame(exp=mydata$exp[A[1,]], diff=mydata$rslt[A[2,]]-mydata$rslt[A[1,]])
}

diff.safe = function(mydata) {
  data.frame(exp = unique(mydata$exp), diff = as.vector(by(mydata, mydata$exp, function(x) x$rslt[x$type=='treatment']-x$rslt[x$type=='control'])))
}

#benchmark
microbenchmark(BG=diff.BG(mydata), US=diff.US(mydata), MG1=diff.MG1(mydata), MG2=diff.MG2(mydata), safe=diff.safe(my data))

Unit: microseconds
 expr       min          lq        mean      median          uq        max neval
   BG   273.837    299.0015    351.0377    316.7400    350.5220   2385.289   100
   US  9872.457  10511.1065  11555.6048  11108.0790  12471.8060  17609.518   100
  MG1   168.783    196.8635    229.9329    210.9370    249.4895    471.381   100
  MG2   221.303    237.0480    265.5097    254.3895    280.7815    418.728   100
 safe 97869.540 104164.5130 109579.9834 107199.7715 110315.8590 170028.377   100



> On 17 Mar 2017, at 14:54, Evan Cooch <evan.cooch at gmail.com> wrote:
> 
> Suppose I have a dataframe that looks like the following:
> 
> n=2
> mydata <- data.frame(exp = rep(1:5,each=n), rslt = 
> c(12,15,7,8,24,28,33,15,22,11))
> mydata
>    exp rslt
> 1    1   12
> 2    1   15
> 3    2    7
> 4    2    8
> 5    3   24
> 6    3   28
> 7    4   33
> 8    4   15
> 9    5   22
> 10   5   11
> 
> The variable 'exp' (for experiment') occurs in pairs over consecutive 
> rows -- 1,1, then 2,2, then 3,3, and so on. The first row in a pair is 
> the 'control', and the second is a 'treatment'. The rslt column is the 
> result.
> 
> What I'm trying to do is create a subset of this dataframe that consists 
> of the exp number, and the lagged difference between the 'control' and 
> 'treatment' result.  So, for exp=1, the difference is (15-12)=3. For 
> exp=2,  the difference is (8-7)=1, and so on. What I'm hoping to do is 
> take mydata (above), and turn it into
> 
>      exp  diff
> 1   1      3
> 2   2      1
> 3   3      4
> 4   4      -18
> 5   5      -11
> 
> The basic 'trick' I can't figure out is how to create a lagged variable 
> between the second row (record) for a given level of exp, and the first 
> row for that exp.  This is easy to do in SAS (which I'm more familiar 
> with), but I'm struggling with the equivalent in R. The brute force 
> approach  I thought of is to simply split the dataframe into to (one 
> even rows, one odd rows), merge by exp, and then calculate a difference. 
> But this seems to require renaming the rslt column in the two new 
> dataframes so they are different in the merge (say, rslt_cont n the odd 
> dataframe, and rslt_trt in the even dataframe), allowing me to calculate 
> a difference between the two.
> 
> While I suppose this would work, I'm wondering if I'm missing a more 
> elegant 'in place' approach that doesn't require me to split the data 
> frame and do every via a merge.
> 
> Suggestions/pointers to the obvious welcome. I've tried playing with 
> lag, and some approaches using lag in the zoo package,  but haven't 
> found the magic trick. The problem (meaning, what I can't figure out) 
> seems to be conditioning the lag on the level of exp.
> 
> Many thanks...
> 
> 
> mydata <-*data.frame*(x = c(20,35,45,55,70), n = rep(50,5), y = c(6,17,26,37,44))
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Mar 18 17:52:26 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Mar 2017 09:52:26 -0700
Subject: [R] Changing cell value for MANY unique pairings of values in 2
	columns
In-Reply-To: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>
References: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>
Message-ID: <8737BB93-F854-4423-9438-A75A8F53D5D4@comcast.net>


> On Mar 17, 2017, at 11:33 AM, Alicia Ellis <alicia.m.ellis at gmail.com> wrote:
> 
> am cleaning some very messy health record lab data.  Several of the rows
> in the VALUE column have text entries and they need to be converted to
> numeric in the NUMERIC_VALUE column based on the values in VALUE and
> DESCRIPTION.  For example:
> 
> df <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than 0.30",
> "12%", "<0.2", "Unknown"),
>                 DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>                 NUMERIC_VALUE=c(9, 9,9,9,9,9,9))
> df
> 
> df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION == "A"]=999999999
> 
> 
> However, I need to do this for ~500 unique pairings of VALUE and
> DESCRIPTION entries.  I'm trying to find an easy way to do this without
> having to have 500 lines of code for each unique pairing.  Some of the
> pairings will be changed to the same value (e.g., 99999999, or -999999999)
> but many will be unique numeric values.

I'm not convinced that you have the necessary scientific background to do this job properly. There are different sorts of lab tests: enzymatic activity, solute concentrations, and viral titers come to mind immediately for which the handling would be materially different. If you have a serum sodium level of less than 100 mEq/ml, then that is a value inconsistent with human life and the value should be set to NA. If you have a value of alkaline phosphatase that is 0 it is most suggestive of specimen mishandling. If you have a hepatitis B antigen level of "Positive", then it seems a perfectly informative value that should not be changed.

Furthermore the attempt to change vlaues that you think are missing to 99999999, or -999999999 is simply wrongheaded. Learn to use the missing value indicator NA rather thna setting these to a numeric value.

You should seek advice within your organization before you charge ahead with this strategy.

-- 
David.
> 
> 
> I've started by creating a new object called rules where a SUBSET of df
> rows are included with the new value they should be changed to.
> 
> 
> rules <- data.frame(VALUE = c("<60",  "Negative", "Less than 0.30", "<0.2",
> "Unknown"),
>                    DESCRIPTION = c("A", "B", "C", "E", "E"),
>                    NEW_VALUE=c(60, -999999,0.29,0.1,777777))
> rules
> 
> 
> I tried doing a loop to change the values in df based on the suggested
> value in rules:
> 
> for (i in (1 : nrow(rules))) {
>  df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
> [i,2]]=rules[i,3]
> }
> df
> 
> This gives the error:
> 
> Error in Ops.factor(df$VALUE, rules[i, 1]) :
>  level sets of factors are differentwork and I think because when I write
> 
> If I create rules using the exact same levels as df it works:
> 
> rules <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
> 0.30", "12%", "<0.2", "Unknown"),
>                    DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>                    NEW_VALUE=c(60, 999999,-999999,0.29,12,0.1,777777))
> rules
> 
> for (i in (1 : nrow(rules))) {
>  df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
> [i,2]]=rules[i,3]
> }
> df
> 
> 
> Can anyone suggest a way to modify my for loop so that it works for a
> subset of rows in df and accomplish what I want?  Or suggest a completely
> different method that works?
> 
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Mar 18 18:33:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Mar 2017 10:33:32 -0700
Subject: [R] Changing cell value for MANY unique pairings of values in 2
	columns
In-Reply-To: <8737BB93-F854-4423-9438-A75A8F53D5D4@comcast.net>
References: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>
	<8737BB93-F854-4423-9438-A75A8F53D5D4@comcast.net>
Message-ID: <E0AEDE89-4DB7-47A8-AEF8-92B20BF8FEF3@comcast.net>


> On Mar 18, 2017, at 9:52 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Mar 17, 2017, at 11:33 AM, Alicia Ellis <alicia.m.ellis at gmail.com> wrote:
>> 
>> am cleaning some very messy health record lab data.  Several of the rows
>> in the VALUE column have text entries and they need to be converted to
>> numeric in the NUMERIC_VALUE column based on the values in VALUE and
>> DESCRIPTION.  For example:
>> 
>> df <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than 0.30",
>> "12%", "<0.2", "Unknown"),
>>                DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>>                NUMERIC_VALUE=c(9, 9,9,9,9,9,9))
>> df
>> 
>> df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION == "A"]=999999999
>> 
>> 
>> However, I need to do this for ~500 unique pairings of VALUE and
>> DESCRIPTION entries.  I'm trying to find an easy way to do this without
>> having to have 500 lines of code for each unique pairing.  Some of the
>> pairings will be changed to the same value (e.g., 99999999, or -999999999)
>> but many will be unique numeric values.
> 
> I'm not convinced that you have the necessary scientific background to do this job properly. There are different sorts of lab tests: enzymatic activity, solute concentrations, and viral titers come to mind immediately for which the handling would be materially different. If you have a serum sodium level of less than 100 mEq/ml, then that is a value inconsistent with human life and the value should be set to NA. If you have a value of alkaline phosphatase that is 0 it is most suggestive of specimen mishandling. If you have a hepatitis B antigen level of "Positive", then it seems a perfectly informative value that should not be changed.
> 
> Furthermore the attempt to change vlaues that you think are missing to 99999999, or -999999999 is simply wrongheaded. Learn to use the missing value indicator NA rather thna setting these to a numeric value.
> 
> You should seek advice within your organization before you charge ahead with this strategy.

I've been informed that my concerns are misplaced and that the scientific concerns I raised were inflated. The "answer" then might be:

merge( df, rules, by=1:2, all.x=TRUE)  # Or

merge( df, rules, by=c("VALUE", "DESCRIPTION") , all.x=TRUE)


Which returns in this example:


           VALUE DESCRIPTION NUMERIC_VALUE  NEW_VALUE
1           <0.2           E         9e+00       0.10
2            <60           A         9e+00      60.00
3            12%           D         9e+00         NA
4 Less than 0.30           C         9e+00       0.29
5       Negative           B         9e+00 -999999.00
6       Positive           A         1e+09         NA
7        Unknown           E         9e+00  777777.00

I'm leaving it in this form because I remain worried. I have no particular concerns about setting a value of "<0.2" to 0.1 but worry about setting values of  "<60" to 60.00 or "Less than 0.30" to 0.29 don't really accord with practice that I have seen in analysis of laboratory values. And I remain concerned that using flagrantly false numeric values as indicators will create serious errors down the line if this data is ever used by someone who has not been involved with its manipulation or has even forgotten months later how it was massaged. 

-- 
David.
> -- 
> David.
>> 
>> 
>> I've started by creating a new object called rules where a SUBSET of df
>> rows are included with the new value they should be changed to.
>> 
>> 
>> rules <- data.frame(VALUE = c("<60",  "Negative", "Less than 0.30", "<0.2",
>> "Unknown"),
>>                   DESCRIPTION = c("A", "B", "C", "E", "E"),
>>                   NEW_VALUE=c(60, -999999,0.29,0.1,777777))
>> rules
>> 
>> 
>> I tried doing a loop to change the values in df based on the suggested
>> value in rules:
>> 
>> for (i in (1 : nrow(rules))) {
>> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
>> [i,2]]=rules[i,3]
>> }
>> df
>> 
>> This gives the error:
>> 
>> Error in Ops.factor(df$VALUE, rules[i, 1]) :
>> level sets of factors are differentwork and I think because when I write
>> 
>> If I create rules using the exact same levels as df it works:
>> 
>> rules <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
>> 0.30", "12%", "<0.2", "Unknown"),
>>                   DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>>                   NEW_VALUE=c(60, 999999,-999999,0.29,12,0.1,777777))
>> rules
>> 
>> for (i in (1 : nrow(rules))) {
>> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
>> [i,2]]=rules[i,3]
>> }
>> df
>> 
>> 
>> Can anyone suggest a way to modify my for loop so that it works for a
>> subset of rows in df and accomplish what I want?  Or suggest a completely
>> different method that works?
>> 
>> 
>> Thanks!
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Mar 18 20:32:18 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Mar 2017 12:32:18 -0700
Subject: [R] Reversing table()
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1CA12@SRVEXCHCM301.precheza.cz>
References: <4390131.CCuTsum1AT@sigma>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1CA12@SRVEXCHCM301.precheza.cz>
Message-ID: <F8BECFAA-7DCD-48D1-B3BC-E9A2356E1E05@comcast.net>


> On Mar 17, 2017, at 6:30 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Is this what you want?
> 
> http://opensourceconnections.com/blog/2016/09/17/expanding-data-frequency-table-r-stata/

Or perhaps (assuming the table's name is "tbl":


dtbl <- as.data.frame(tbl)
xpd <- dtbl[ rep(row.names(dtbl), dtbl$Freq), ]
str(xpd)

-- 
Best.
David.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin E.
>> Thorpe
>> Sent: Friday, March 17, 2017 1:23 PM
>> To: r-help <r-help at stat.math.ethz.ch>
>> Subject: [R] Reversing table()
>> 
>> I am wondering if there is a way to undo the results of table().
>> 
>> For example if you had a table that looked like the result of table(x, y) or
>> table(x, y, z) is there a simple/elegant way to reverse the process to get the
>> "original" x, y and z vectors?
>> 
>> Thanks,
>> 
>> Kevin
>> 
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka Shing
>> Knowledge Institute of St. Michael's Hospital Assistant Professor, Dalla Lana
>> School of Public Health University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From erinm.hodgess at gmail.com  Sat Mar 18 22:08:52 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 18 Mar 2017 16:08:52 -0500
Subject: [R] Setting up workers with Rmpi
Message-ID: <CACxE24nwS5MOqcycTMtv7tMBtY+AyWddEPAA6nr+48O_Nr6PRg@mail.gmail.com>

Hello!


I'm trying to run a very simple test with Rmpi via the mpirun function
outside of R.  Here is the script file:


Es-MacBook-Pro:~ emhodgess$ cat bb.in

library(Rmpi)

x <- 5

mpi.remote.exec(rnorm(x))

mpi.finalize()



And here is the output:

Es-MacBook-Pro:~ emhodgess$ mpirun -np 4 Rscript bb.in

Error in mpi.remote.exec(rnorm(x)) : It seems no slaves running.

Execution halted

Error in mpi.remote.exec(rnorm(x)) : It seems no slaves running.

Execution halted

Error in mpi.remote.exec(rnorm(x)) : It seems no slaves running.

Execution halted

-------------------------------------------------------

Primary job  terminated normally, but 1 process returned

a non-zero exit code.. Per user-direction, the job has been aborted.

-------------------------------------------------------

--------------------------------------------------------------------------

mpirun detected that one or more processes exited with non-zero status,
thus causing

the job to be terminated. The first process to do so was:


  Process name: [[39079,1],2]

  Exit code:    1

--------------------------------------------------------------------------

I had always thought that the numbers of workers was obtained from the np
value and passed through to R.  Apparently not.

Here is the session info:
> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.6           lattice_0.20-34       codetools_0.2-15
 [4] mvtnorm_1.0-5         zoo_1.7-13            MASS_7.3-45
 [7] grid_3.3.3            plyr_1.8.4            fBasics_3011.87
[10] xtable_1.8-2          nlme_3.1-131          fGarch_3010.82.1
[13] coda_0.18-1           estimability_1.2      lsmeans_2.25
[16] multcomp_1.4-6        timeDate_3012.100     rpart_4.1-10
[19] Matrix_1.2-8          sandwich_2.3-4        splines_3.3.3
[22] TH.data_1.0-7         tools_3.3.3           rsm_2.8
[25] survival_2.40-1       timeSeries_3022.101.2
>

I also did the same thing on my Ubuntu laptop; same results.

Any suggestions much appreciated.

Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sat Mar 18 23:22:20 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 18 Mar 2017 17:22:20 -0500
Subject: [R] find and
In-Reply-To: <CAKVAULN2vcRkTWnWOBWuurkBG=qS+ss63O+ny+UX+_FTu=JDiw@mail.gmail.com>
References: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>
	<58CD40E8.40704@sapo.pt>
	<CAKVAULN2vcRkTWnWOBWuurkBG=qS+ss63O+ny+UX+_FTu=JDiw@mail.gmail.com>
Message-ID: <CADDFq33hh=19ANGZAVjK6wcQnc6gojocM2b_TfgqSjgDZh9UFg@mail.gmail.com>

Thank you Rudi and  Ulrik.

Rudi, your option worked for the small data set but when I applied to
the big data set it taking long and never finished and have to kill
it. I dont know why.


Ulrik's option worked fine for the big data set  (> 1.5M  records)
and took less than 2 minutes.

These two are giving me the same  results.
# Counting unique
DF4 %>%    group_by(city) %>%     filter(length(unique(var)) == 1)
# Counting not duplicated
DF4 %>%    group_by(city) %>%    filter(sum(!duplicated(var)) == 1)

 Thank yo again.


On Sat, Mar 18, 2017 at 10:40 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Using dplyr:
>
> library(dplyr)
>
> # Counting unique
> DF4 %>%
>   group_by(city) %>%
>   filter(length(unique(var)) == 1)
>
> # Counting not duplicated
> DF4 %>%
>   group_by(city) %>%
>   filter(sum(!duplicated(var)) == 1)
>
> HTH
> Ulrik
>
>
> On Sat, 18 Mar 2017 at 15:17 Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> I believe this does it.
>>
>>
>> sp <- split(DF4, DF4$city)
>> want <- do.call(rbind, lapply(sp, function(x)
>>                 if(length(unique(x$var)) == 1) x else NULL))
>> rownames(want) <- NULL
>> want
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 18-03-2017 13:51, Ashta escreveu:
>> > Hi all,
>> >
>> > I am trying to find a city that do not have the same "var" value.
>> > Within city the var should be the same otherwise exclude the city from
>> > the final data set.
>> > Here is my sample data and my attempt. City1 and city4 should be
>> > excluded.
>> >
>> > DF4 <- read.table(header=TRUE, text=' city  wk var
>> > city1  1  x
>> > city1  2  -
>> > city1  3  x
>> > city2  1  x
>> > city2  2  x
>> > city2  3  x
>> > city2  4  x
>> > city3  1  x
>> > city3  2  x
>> > city3  3  x
>> > city3  4  x
>> > city4  1  x
>> > city4  2  x
>> > city4  3  y
>> > city4  4  y
>> > city5  3  -
>> > city5  4  -')
>> >
>> > my attempt
>> >       test2  <-   data.table(DF4, key="city,var")
>> >       ID1    <-   test2[ !duplicated(test2),]
>> >      dps     <-   ID1$city[duplicated(ID1$city)]
>> >     Ddup  <-   which(test2$city %in% dps)
>> >
>> >      if(length(Ddup) !=0)  {
>> >            test2   <-  test2[- Ddup,]  }
>> >
>> > want     <-  data.frame(test2)
>> >
>> >
>> > I want get the following result but I am not getting it.
>> >
>> >     city wk var
>> >    city2  1   x
>> >    city2  2   x
>> >    city2  3   x
>> >    city2  4   x
>> >    city3  1   x
>> >    city3  2   x
>> >   city3  3   x
>> >   city3  4   x
>> >   city5  3   -
>> >   city5  4   -
>> >
>> > Can some help me out the problem is?
>> >
>> > Thank you.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Sun Mar 19 02:06:59 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 18 Mar 2017 20:06:59 -0500
Subject: [R] Setting up workers with Rmpi: SOLVED for Ubuntu
Message-ID: <CACxE24=odAJF3U5=x1zSr=GVxpqKxuLf6gq+xgh=n2LMBD3B1g@mail.gmail.com>

Hello!

I found the answer in a very fine book by Prof. Norm Matloff.  There is a
section on Rmpi on this exact topic for Linux on pages 192-193.  So I
followed those instructions, and I'm set.

Thanks though!


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Sun Mar 19 06:06:30 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 19 Mar 2017 16:06:30 +1100
Subject: [R] add median value and standard deviation bar to lattice plot
References: <CAMk+s2TN5C5QpKhHwYAOroDsGvQECz6u6QuMr+wDEqDQT-t9EQ@mail.gmail.com>
Message-ID: <000201d2a06e$926e8910$b74b9b30$@bigpond.com>

Hi Luigi

Try this

library(lattice)
library(latticeExtra)
with( dflu,
useOuterStrips(
  strip = strip.custom(par.strip.text = list(cex = 0.75)),
  strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
  dotplot(
    average ~ type|target+cluster,
    my.data,
    horizontal = FALSE,
    groups = type,
   # pch=1,
    jitter.data = TRUE,
    main = "Group-wise",
    xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
    col = c("grey", "green", "red"),
    par.settings = list(strip.background =
list(col=c("paleturquoise","grey")),
                        superpose.symbol = list(col=c("grey", "green",
"red"),
                                                pch = 1),
                        dot.line = list(col = "white")),
    scales = list(alternating = FALSE, x=list(draw=FALSE)),
    key = list(
      space = "top",
      columns = 3,
      text = list(c("Blank", "Negative", "Positive"), col="black"),
      rectangles = list(col=c("grey", "green", "red"))
    ),
    lx = lower, ux = upper,
  panel = panel.superpose,
  panel.groups = function(x,y,horizontal, ..., group.number){
                    pnl = panel.number()
                    st <- boxplot.stats(y)
                    ly = st$conf[1]
                    uy = st$conf[2]
                    cat(pnl, ly, uy, "\n")

                    if (uy != ly){
                    panel.arrows(x-0.2, ly, x-0.2, uy, col =  c("grey",
"green", "red")[group.number],
                                 length = 0.1, unit = "in",
                                 lwd = 2,
                                 angle = 90, code = 3)

                    }
                    panel.xyplot(x, y,  ...)

  }
)
) )

or

with( dflu,
useOuterStrips(
  strip = strip.custom(par.strip.text = list(cex = 0.75)),
  strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
  dotplot(
    average ~ type|target+cluster,
    my.data,
    horizontal = FALSE,
    groups = type,
   # pch=1,
    jitter.data = TRUE,
    main = "Group-wise",
    xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
    col = c("grey", "green", "red"),
    par.settings = list(strip.background =
list(col=c("paleturquoise","grey")),
                        superpose.symbol = list(col=c("grey", "green",
"red"),
                                                pch = 1),
                        dot.line = list(col = "white")),
    scales = list(alternating = FALSE, x=list(draw=FALSE)),
    key = list(
      space = "top",
      columns = 3,
      text = list(c("Blank", "Negative", "Positive"), col="black"),
      rectangles = list(col=c("grey", "green", "red"))
    ),
    lx = lower, ux = upper,
  panel = panel.superpose,
  panel.groups = function(x,y,horizontal, col, ... ){
                    pnl = panel.number()
                    st <- boxplot.stats(y)
                    ly = st$conf[1]
                    uy = st$conf[2]
                    cat(pnl, ly, uy, "\n")

                    if (uy != ly){
                    panel.arrows(x-0.2, ly, x-0.2, uy, col = col,
                                 length = 0.1, unit = "in",
                                 lwd = 2,
                                 angle = 90, code = 3)

                    }
                    panel.xyplot(x, y,  ...)

  }
)
) )

panel.superpose avoids the needs for subscripts
Used dotplot as I could not get into panel.stripplot easily

made dot.lie white to avoid having lines all over. -- change to transparent

The transparency of the arrows can be added using alpha - need to check
device if can be used
Formula can be changed just used that in demos for lattice

Not sure what you mean by 2

Anyway you have all the right tools here to do it

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Wednesday, 15 March 2017 20:23
To: r-help
Subject: [R] add median value and standard deviation bar to lattice plot

Dear all,
I am analyzing some multivariate data that is organized like this:
1st variable = cluster (A or B)
2nd variable = target (a, b, c, d, e)
3rd variable = type (blank, negative, positive)
4th variable = sample (the actual name of the sample)
5th variable = average (the actual reading -- please not that this is the
mean of different measures with an assumed normal distribution, but the
assumption might not always be true)
6th variable = stdev (the standard deviation associated with each reading)
7th variable = ll (lower limit that is average stdev)
8th variable = ul (upper limit that is average + stdev)

I am plotting the data using lattice's stripplot and I would need to add:
1. an error bar for each measurement. the bar should be possibly coloured
in light grey and semitransparent to reduce the noise of the plot.
2. a type-based median bar to show differences in measurements between
blanks, negative and positive samples within each panel.

How would I do that?
Many thanks,
Luigi

>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71, 128,
39,
42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129, 94, 49,
33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43, 32.5, 59,
58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125, 90,
73,
84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176, 45,
76,
33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5, 212,
40,
68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140, 186,
297,
32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5,
54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92, 87, 59,
33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55, 26.72,
1.83,
9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55, 11.42,
64.12,
0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75, 4.25,
9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92, 72.62,
70.26,
59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05, 38.56,
3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3, 7.41,
9.86,
63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69,
6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71,
87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06, 38.47,
88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01, 34.88,
28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13, 8.15,
1.08,
9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86, 38.83,
8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61, 3.65,
-27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88, 44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03, 53.95,
109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2, 39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79, 7.88,
47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32, 40.46,
38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4, 45.78,
42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87, 38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78, 46.55,
90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79, 176.14,
85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06, 37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14, 47.17,
21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05, 189.37,
72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43, 174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21, 172.12,
85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98, 59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32, 146.39,
98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15, 127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91, 132.82,
78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27, 67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38, 33.4,
114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75, 176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev, ll,
ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)
useOuterStrips(
  strip = strip.custom(par.strip.text = list(cex = 0.75)),
  strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
  stripplot(
    average ~ type|target+cluster,
    my.data,
    groups = type,
    pch=1,
    jitter.data = TRUE,
    main = "Group-wise",
    xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
    col = c("grey", "green", "red"),
    par.settings = list(strip.background = list(col=c("paleturquoise",
"grey"))),
    scales = list(alternating = FALSE, x=list(draw=FALSE)),
    key = list(
      space = "top",
      columns = 3,
      text = list(c("Blank", "Negative", "Positive"), col="black"),
      rectangles = list(col=c("grey", "green", "red"))
    )
  )
)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From david.tn.jones at gmail.com  Sun Mar 19 05:08:36 2017
From: david.tn.jones at gmail.com (David Jones)
Date: Sat, 18 Mar 2017 23:08:36 -0500
Subject: [R] Options for bootstrapped CIs for indirect effect: Nested data
 structure, missing data, and fully continuous X variable
Message-ID: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>

I am looking for a package or other solution in R that can evaluate
indirect effects and meets all of the following criteria:

* Can create bootstrapped CIs around an indirect effect (or can
implement any other method of creating asymmetric CIs)
* Can address nested data (e.g., through multilevel/mixed effects)
* Can allow for fully continuous X variables
* Can address missing data (e.g., using multiple imputation via a
package such as mice; I have a non-normally distributed mediator so
cannot use ML for all estimation)

Any input on what would address these criteria would be greatly appreciated.

Here are the packages I have tried so far:

* lavaan.survey - can do all of the above except for bootstrap
estimation of the indirect effect (lavaan is great but cannot do
multilevel, lavaan.survey is also great but cannot do the bootstrap
estimate)
* mediation - Has many strong features, but limits the X (treatment)
variable to take 2 values at a time, whereas I have dozens of X values
(from an observational study)
* piecewiseSEM - Is very flexible and allows for multilevel data
structure and multiple distributions, but does not have
bootstrap/asymmetric CIs for indirect effects


From bgunter.4567 at gmail.com  Sun Mar 19 17:34:09 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 19 Mar 2017 09:34:09 -0700
Subject: [R] Options for bootstrapped CIs for indirect effect: Nested
 data structure, missing data, and fully continuous X variable
In-Reply-To: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>
References: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>
Message-ID: <CAGxFJbR_e7D4k7b5kym19B_vbQbKQo7E07id7WkPWYSV-f3_tw@mail.gmail.com>

Obviously question: Did you check the boot package ??

Also, try searching rseek.org.

I suspect that in any case, you may have to do some
customizing/programming, as you seem to have quite a few criteria.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 18, 2017 at 9:08 PM, David Jones <david.tn.jones at gmail.com> wrote:
> I am looking for a package or other solution in R that can evaluate
> indirect effects and meets all of the following criteria:
>
> * Can create bootstrapped CIs around an indirect effect (or can
> implement any other method of creating asymmetric CIs)
> * Can address nested data (e.g., through multilevel/mixed effects)
> * Can allow for fully continuous X variables
> * Can address missing data (e.g., using multiple imputation via a
> package such as mice; I have a non-normally distributed mediator so
> cannot use ML for all estimation)
>
> Any input on what would address these criteria would be greatly appreciated.
>
> Here are the packages I have tried so far:
>
> * lavaan.survey - can do all of the above except for bootstrap
> estimation of the indirect effect (lavaan is great but cannot do
> multilevel, lavaan.survey is also great but cannot do the bootstrap
> estimate)
> * mediation - Has many strong features, but limits the X (treatment)
> variable to take 2 values at a time, whereas I have dozens of X values
> (from an observational study)
> * piecewiseSEM - Is very flexible and allows for multilevel data
> structure and multiple distributions, but does not have
> bootstrap/asymmetric CIs for indirect effects
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Sun Mar 19 19:43:55 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Sun, 19 Mar 2017 18:43:55 +0000 (UTC)
Subject: [R] Prophet package
References: <2075312749.3263727.1489949035378.ref@mail.yahoo.com>
Message-ID: <2075312749.3263727.1489949035378@mail.yahoo.com>

Dear All


wonder if you could assist with the following

we have:

library(prophet) 

library(dplyr) 


abc<-c(0.3684693,0.4938679, 0.4429201,0.452598,0.4301452,0.4315169, 
0.447026,0.496179,0.4045693,0.398533, 0.3551111,0.431079,0.4063136,0.4120126,0.5210375,0.402897,0.4466131,0.5005669,0.5014164,0.5042271,0.5498575,0.6014215,0.4415863,0.4377443,0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143,0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978 
,0.383012,0.3763665,0.3550609,0.2958678,0.3726571,0.3442298 
#,0.3403275,0.2973978 
#, 0.4,0.4,0.4, 0.4,0.4,0.4, 0.4,0.4,0.4 

) 

df<-data.frame(ds = seq(as.Date('2013-08-01'), as.Date('2017-01-01'), by = 'm'),abc) 
names(df)<-c("ds","y") 


m<-prophet(df,yearly.seasonality = TRUE) 
future <- make_future_dataframe(m, periods = 730) 
forecast <- predict(m, future) 
plot(m, forecast)
points(x=as.Date('2017-02-01'),y=0.5)

results in error message :


Error in plot.xy(xy.coords(x, y), type = type, ...) : 
plot.new has not been called yet

would you have a solution to plot the point on the plot?

appreiate the help,

Andras Farkas,


From drjimlemon at gmail.com  Sun Mar 19 21:38:33 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 20 Mar 2017 07:38:33 +1100
Subject: [R] Prophet package
In-Reply-To: <2075312749.3263727.1489949035378@mail.yahoo.com>
References: <2075312749.3263727.1489949035378.ref@mail.yahoo.com>
	<2075312749.3263727.1489949035378@mail.yahoo.com>
Message-ID: <CA+8X3fXoH1fW01+PScPvWarESWZzm5g4Z3wQvmHDTuNZRc4fbA@mail.gmail.com>

Hi Andras,
Did you get a plot from your plot command? It looks to me as thought
there was an error, perhaps because the plot command tried to treat
"forecast" as a vector.

Jim

On Mon, Mar 20, 2017 at 5:43 AM, Andras Farkas via R-help
<r-help at r-project.org> wrote:
> Dear All
>
>
> wonder if you could assist with the following
>
> we have:
>
> library(prophet)
>
> library(dplyr)
>
>
> abc<-c(0.3684693,0.4938679, 0.4429201,0.452598,0.4301452,0.4315169,
> 0.447026,0.496179,0.4045693,0.398533, 0.3551111,0.431079,0.4063136,0.4120126,0.5210375,0.402897,0.4466131,0.5005669,0.5014164,0.5042271,0.5498575,0.6014215,0.4415863,0.4377443,0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143,0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978
> ,0.383012,0.3763665,0.3550609,0.2958678,0.3726571,0.3442298
> #,0.3403275,0.2973978
> #, 0.4,0.4,0.4, 0.4,0.4,0.4, 0.4,0.4,0.4
>
> )
>
> df<-data.frame(ds = seq(as.Date('2013-08-01'), as.Date('2017-01-01'), by = 'm'),abc)
> names(df)<-c("ds","y")
>
>
> m<-prophet(df,yearly.seasonality = TRUE)
> future <- make_future_dataframe(m, periods = 730)
> forecast <- predict(m, future)
> plot(m, forecast)
> points(x=as.Date('2017-02-01'),y=0.5)
>
> results in error message :
>
>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
> plot.new has not been called yet
>
> would you have a solution to plot the point on the plot?
>
> appreiate the help,
>
> Andras Farkas,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Mon Mar 20 00:45:05 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Sun, 19 Mar 2017 23:45:05 +0000 (UTC)
Subject: [R] Prophet package
In-Reply-To: <CA+8X3fXoH1fW01+PScPvWarESWZzm5g4Z3wQvmHDTuNZRc4fbA@mail.gmail.com>
References: <2075312749.3263727.1489949035378.ref@mail.yahoo.com>
	<2075312749.3263727.1489949035378@mail.yahoo.com>
	<CA+8X3fXoH1fW01+PScPvWarESWZzm5g4Z3wQvmHDTuNZRc4fbA@mail.gmail.com>
Message-ID: <1223484866.3433550.1489967105711@mail.yahoo.com>

Hi Jim,
Yes, the plot function works well and produces a plot, it is only the points function I am unable to get to display the points...
Thanks
Andras

Sent from Yahoo Mail on Android 
 
  On Sun, Mar 19, 2017 at 4:38 PM, Jim Lemon<drjimlemon at gmail.com> wrote:   Hi Andras,
Did you get a plot from your plot command? It looks to me as thought
there was an error, perhaps because the plot command tried to treat
"forecast" as a vector.

Jim

On Mon, Mar 20, 2017 at 5:43 AM, Andras Farkas via R-help
<r-help at r-project.org> wrote:
> Dear All
>
>
> wonder if you could assist with the following
>
> we have:
>
> library(prophet)
>
> library(dplyr)
>
>
> abc<-c(0.3684693,0.4938679, 0.4429201,0.452598,0.4301452,0.4315169,
> 0.447026,0.496179,0.4045693,0.398533, 0.3551111,0.431079,0.4063136,0.4120126,0.5210375,0.402897,0.4466131,0.5005669,0.5014164,0.5042271,0.5498575,0.6014215,0.4415863,0.4377443,0.4316092,0.4156757,0.3517915,0.3669508,0.3899471,0.3964143,0.4001074,0.3851003,0.4222451,0.375324,0.3652045,0.3376978
> ,0.383012,0.3763665,0.3550609,0.2958678,0.3726571,0.3442298
> #,0.3403275,0.2973978
> #, 0.4,0.4,0.4, 0.4,0.4,0.4, 0.4,0.4,0.4
>
> )
>
> df<-data.frame(ds = seq(as.Date('2013-08-01'), as.Date('2017-01-01'), by = 'm'),abc)
> names(df)<-c("ds","y")
>
>
> m<-prophet(df,yearly.seasonality = TRUE)
> future <- make_future_dataframe(m, periods = 730)
> forecast <- predict(m, future)
> plot(m, forecast)
> points(x=as.Date('2017-02-01'),y=0.5)
>
> results in error message :
>
>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
> plot.new has not been called yet
>
> would you have a solution to plot the point on the plot?
>
> appreiate the help,
>
> Andras Farkas,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.  

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar 20 08:55:46 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 20 Mar 2017 08:55:46 +0100
Subject: [R] Options for bootstrapped CIs for indirect effect: Nested
 data structure, missing data, and fully continuous X variable
In-Reply-To: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>
References: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>
Message-ID: <CAJuCY5zSF5MXwYvJAyziEp6UZjGZTWD+iQzRdAR2d+abKVmCGg@mail.gmail.com>

Dear David,

Please have a look at our multimput package
(https://github.com/inbo/multimput). It handles multiple imputation
based on generalised linear mixed models. Currently based on either
glmer (lme4) and inla (INLA) . After imputation you can apply any
model or function you like. So you could use the boot package as Bert
suggested.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-19 5:08 GMT+01:00 David Jones <david.tn.jones at gmail.com>:
> I am looking for a package or other solution in R that can evaluate
> indirect effects and meets all of the following criteria:
>
> * Can create bootstrapped CIs around an indirect effect (or can
> implement any other method of creating asymmetric CIs)
> * Can address nested data (e.g., through multilevel/mixed effects)
> * Can allow for fully continuous X variables
> * Can address missing data (e.g., using multiple imputation via a
> package such as mice; I have a non-normally distributed mediator so
> cannot use ML for all estimation)
>
> Any input on what would address these criteria would be greatly appreciated.
>
> Here are the packages I have tried so far:
>
> * lavaan.survey - can do all of the above except for bootstrap
> estimation of the indirect effect (lavaan is great but cannot do
> multilevel, lavaan.survey is also great but cannot do the bootstrap
> estimate)
> * mediation - Has many strong features, but limits the X (treatment)
> variable to take 2 values at a time, whereas I have dozens of X values
> (from an observational study)
> * piecewiseSEM - Is very flexible and allows for multilevel data
> structure and multiple distributions, but does not have
> bootstrap/asymmetric CIs for indirect effects
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From helios.derosario at ibv.upv.es  Mon Mar 20 10:39:58 2017
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Mon, 20 Mar 2017 10:39:58 +0100
Subject: [R] [FORGED] Re:  Crete stats course
Message-ID: <58CFB17E0200000C000316E4@mailhost.biomec.upv.es>

The fact related to Rolf's vague recollection is here:
https://stat.ethz.ch/pipermail/r-help/2015-March/426799.html 

And the relevant post (Martin Maechler's answer):
https://stat.ethz.ch/pipermail/r-help/2015-March/426834.html 

Should that be a FAQ?

Helios

> On 16/03/17 03:57, Bert Gunter wrote:
>> Perhaps this has been asked and settled before, but while such
courses
>> certainly might be of interest to those who read this list, they
are
>> for profit, and therefore advertising them here does seem somewhat
>> inappropriate.
>>
[...]
>
>>> On 15/03/2017 20:13, Rolf Turner <r.turner at auckland.ac.nz>
answered:
>
> I have a *vague* recollection that it *has* been asked before and
that 
> there was a consensus, or a pronouncement from R core (or a
combination 
> of the two; or something like that) that such announcements were OK
as 
> long as they were reasonably brief and not overly frequent.  Or 
> something like that.



DESCARGATE el ANUARIO del IBV 2015 desde 
http://www.ibv.org/anuario/Anuario2015/

INSTITUTO DE BIOMEC?NICA 
Universitat Polit?cnica de Val?ncia - Edificio 9C 
Camino de Vera s/n - 46022 VALENCIA (ESPA?A) 
Tel. +34 961111170 +34 610567200 - Fax +34 96 387 91 69 
www.ibv.org 

Antes de imprimir este e-mail piense bien si es necesario hacerlo. En
cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n de
Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From tring at gvdnet.dk  Mon Mar 20 12:42:11 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 20 Mar 2017 12:42:11 +0100
Subject: [R] ggplot expressions
Message-ID: <c2945c59-52d7-f25e-85ba-0f4e5805e28b@gvdnet.dk>

Dear friends - here is an example of something that I find annoying

library(ggplot2)
DDF <- data.frame(x=x<-seq(1,10),y=x^2)
G <- ggplot(data=DDF,aes(x=x,y=y)) + geom_point()
GG<-G+ylab(expression(paste("Total ",CO[2]," halved")))
GG
GG+annotate("text",x=5,y=50,label=expression(paste("Total ",CO[2]," 
halved")))

On my system, R version 3.3.2 (2016-10-31) Windows - the third line 
produces the wanted formatting of CO2  with "2" lowered - while the last 
line produces an error  "invalid 'type' (expression) of argument" - with 
exactly the same string - how comes?

Beautiful ggplot is not exactly low in documentation but finding the 
right stuff is not always easy (for me:-))

Best wishes
Troels Ring, MD
Aalborg, Denmark


From dwinsemius at comcast.net  Mon Mar 20 15:19:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Mar 2017 07:19:32 -0700
Subject: [R] ggplot expressions
In-Reply-To: <c2945c59-52d7-f25e-85ba-0f4e5805e28b@gvdnet.dk>
References: <c2945c59-52d7-f25e-85ba-0f4e5805e28b@gvdnet.dk>
Message-ID: <8C5A6989-D54E-45C0-89F8-D7C944943D82@comcast.net>


> On Mar 20, 2017, at 4:42 AM, Troels Ring <tring at gvdnet.dk> wrote:
> 
> Dear friends - here is an example of something that I find annoying
> 
> library(ggplot2)
> DDF <- data.frame(x=x<-seq(1,10),y=x^2)
> G <- ggplot(data=DDF,aes(x=x,y=y)) + geom_point()
> GG<-G+ylab(expression(paste("Total ",CO[2]," halved")))
> GG
> GG+annotate("text",x=5,y=50,label=expression(paste("Total ",CO[2]," halved")))
> 
> On my system, R version 3.3.2 (2016-10-31) Windows - the third line produces the wanted formatting of CO2  with "2" lowered - while the last line produces an error  "invalid 'type' (expression) of argument" - with exactly the same string - how comes?
> 
> Beautiful ggplot is not exactly low in documentation but finding the right stuff is not always easy (for me:-))

As the Posting Guide recommends, the question should include the complete text of the error message:

"Error in stats::complete.cases(df[, vars, drop = FALSE]) : 
  invalid 'type' (expression) of argument"

In this case, however I find that message completely opaque and the results of traceback() likewise uninformative, so going back to the help pages, always a good place to start, notice that the last example on `?annotate` is isomorphic to you problem, so try using the curiously unlisted `parse`-parameter to annotate. The parse parameter according to the documentation is being passed to `layer`, but `?layer` doesn't describe a parse parameter so I think it's a defect (somewhere) in the ggplot2 help pages.

GG + annotate("text", x=5, y=50, label = "Total~CO[2]~halved", parse=TRUE)

I have removed the call to `paste` since I find that it's use inhibits learning to use expressions most economically. I think it's better to use the tilde rather than assembling a mishmash of quoted and unquoted sub-expressions.

-- 
David.



> 
> Best wishes
> Troels Ring, MD
> Aalborg, Denmark
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Mar 20 15:47:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Mar 2017 07:47:40 -0700
Subject: [R] Options for bootstrapped CIs for indirect effect: Nested
 data structure, missing data, and fully continuous X variable
In-Reply-To: <CAJuCY5zSF5MXwYvJAyziEp6UZjGZTWD+iQzRdAR2d+abKVmCGg@mail.gmail.com>
References: <CAJgUsw+MNRyQV0yiSpM4HaCfNCUTFoM_eg5oNyX8mzknMwtjpA@mail.gmail.com>
	<CAJuCY5zSF5MXwYvJAyziEp6UZjGZTWD+iQzRdAR2d+abKVmCGg@mail.gmail.com>
Message-ID: <CAGxFJbT5c6D4+qU4DU3DY=GF8CqDeeSZGAYGy=SUiw4iJehKdA@mail.gmail.com>

Private, because off topic.

Thierry:

I believe your advice is incorrect. The imputation and model fitting
*must* be included as part of the bootstrap sampling -- that is, you
must fit and multiple impute for each bootstrap sample as that mimics
what you did with the original sample.  Your procedure underestimates
variability and so is likely to lead to irreproducible results.

Of course, if I'm wrong, I would appreciate expanation and correction,
but I would certainly understand if you have bigger fish to fry.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 20, 2017 at 12:55 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear David,
>
> Please have a look at our multimput package
> (https://github.com/inbo/multimput). It handles multiple imputation
> based on generalised linear mixed models. Currently based on either
> glmer (lme4) and inla (INLA) . After imputation you can apply any
> model or function you like. So you could use the boot package as Bert
> suggested.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2017-03-19 5:08 GMT+01:00 David Jones <david.tn.jones at gmail.com>:
>> I am looking for a package or other solution in R that can evaluate
>> indirect effects and meets all of the following criteria:
>>
>> * Can create bootstrapped CIs around an indirect effect (or can
>> implement any other method of creating asymmetric CIs)
>> * Can address nested data (e.g., through multilevel/mixed effects)
>> * Can allow for fully continuous X variables
>> * Can address missing data (e.g., using multiple imputation via a
>> package such as mice; I have a non-normally distributed mediator so
>> cannot use ML for all estimation)
>>
>> Any input on what would address these criteria would be greatly appreciated.
>>
>> Here are the packages I have tried so far:
>>
>> * lavaan.survey - can do all of the above except for bootstrap
>> estimation of the indirect effect (lavaan is great but cannot do
>> multilevel, lavaan.survey is also great but cannot do the bootstrap
>> estimate)
>> * mediation - Has many strong features, but limits the X (treatment)
>> variable to take 2 values at a time, whereas I have dozens of X values
>> (from an observational study)
>> * piecewiseSEM - Is very flexible and allows for multilevel data
>> structure and multiple distributions, but does not have
>> bootstrap/asymmetric CIs for indirect effects
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rahul2014 at vit.ac.in  Mon Mar 20 12:23:55 2017
From: rahul2014 at vit.ac.in (RAHUL 14BCE0064)
Date: Mon, 20 Mar 2017 16:53:55 +0530
Subject: [R] A request
Message-ID: <CAMpybKNaPbesMnnypRo_O4D9tok2_Q3khsMGtkSjzFK=N9t50g@mail.gmail.com>

Hello there!!

Could somebody please go through the question (
http://stats.stackexchange.com/questions/268323/string-kernels-in-r)?

In short I need the reference to the algorithms used for string kernels in
Kernlab package in R.


Thank you.

Regards:
Rahul

	[[alternative HTML version deleted]]


From abhishek.fpm2014 at iimraipur.ac.in  Mon Mar 20 12:50:42 2017
From: abhishek.fpm2014 at iimraipur.ac.in (Abhishek Kumar Rohit)
Date: Mon, 20 Mar 2017 17:20:42 +0530
Subject: [R] ESTIMATION OF PANEL VAR
Message-ID: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>

Is there any package available for estimating Panel VAR. Can the packages
vars and palm be combined in some way to do that?

Regards,
*Abhishek Rohit*
Research Fellow
IIM Raipur

	[[alternative HTML version deleted]]


From julia.silge at gmail.com  Mon Mar 20 14:19:40 2017
From: julia.silge at gmail.com (Julia Silge)
Date: Mon, 20 Mar 2017 13:19:40 +0000
Subject: [R] How do you discover and learn about R packages?
Message-ID: <CA+mbi1cgSqkctDYPkvnMQjg==vc6zOM0gQZnac4MmKf+fc_CTg@mail.gmail.com>

I am contributing to a session at userR 2017 this coming July that will
focus on discovering and learning about R packages. This is an increasingly
important issue for R users as we all decide which of the 10,000+ packages
to invest time in understanding and then use in our work.

To prepare for this session and gain some understanding, I am running an
online survey about how R users currently discover and learn about R
packages:
http://doo.vote/a87ff60

The question has one multiple select question about how you currently
discover and learn about R packages. If you have other ways that you don?t
feel were fairly covered in the survey options, feel free to reply to me or
leave a comment here on my blog:
http://juliasilge.com/blog/Package-Search/

Thanks,
Julia

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 20 17:44:17 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Mar 2017 09:44:17 -0700
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
Message-ID: <CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>

Excuse my denseness, but huh??

If you receive no satisfactory responses, please read the posting
guide to learn how to post an intelligible question.

Otherwise, just ignore me.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
<abhishek.fpm2014 at iimraipur.ac.in> wrote:
> Is there any package available for estimating Panel VAR. Can the packages
> vars and palm be combined in some way to do that?
>
> Regards,
> *Abhishek Rohit*
> Research Fellow
> IIM Raipur
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Mar 20 17:52:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Mar 2017 09:52:46 -0700
Subject: [R] find and
In-Reply-To: <58CD40E8.40704@sapo.pt>
References: <CADDFq323c9GEk_rp0rPpZP1w3JsQ1BeSOSs5jc2KsDHPYQH3VQ@mail.gmail.com>
	<58CD40E8.40704@sapo.pt>
Message-ID: <CAGxFJbTu+tcpVYcTiH_-Sn3BVcFu+ZUov75ihEsixeJ_4Y+oeQ@mail.gmail.com>

Here is a version similar to Rui's, but using ave() and logical
indexing to simplify a bit:


> DF4[with(DF4, ave(as.numeric(var), city, FUN = function(x)length(unique(x))) ==1), ]

    city wk var
4  city2  1   x
5  city2  2   x
6  city2  3   x
7  city2  4   x
8  city3  1   x
9  city3  2   x
10 city3  3   x
11 city3  4   x
16 city5  3   -
17 city5  4   -


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 18, 2017 at 7:15 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> I believe this does it.
>
>
> sp <- split(DF4, DF4$city)
> want <- do.call(rbind, lapply(sp, function(x)
>                 if(length(unique(x$var)) == 1) x else NULL))
> rownames(want) <- NULL
> want
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 18-03-2017 13:51, Ashta escreveu:
>>
>> Hi all,
>>
>> I am trying to find a city that do not have the same "var" value.
>> Within city the var should be the same otherwise exclude the city from
>> the final data set.
>> Here is my sample data and my attempt. City1 and city4 should be excluded.
>>
>> DF4 <- read.table(header=TRUE, text=' city  wk var
>> city1  1  x
>> city1  2  -
>> city1  3  x
>> city2  1  x
>> city2  2  x
>> city2  3  x
>> city2  4  x
>> city3  1  x
>> city3  2  x
>> city3  3  x
>> city3  4  x
>> city4  1  x
>> city4  2  x
>> city4  3  y
>> city4  4  y
>> city5  3  -
>> city5  4  -')
>>
>> my attempt
>>       test2  <-   data.table(DF4, key="city,var")
>>       ID1    <-   test2[ !duplicated(test2),]
>>      dps     <-   ID1$city[duplicated(ID1$city)]
>>     Ddup  <-   which(test2$city %in% dps)
>>
>>      if(length(Ddup) !=0)  {
>>            test2   <-  test2[- Ddup,]  }
>>
>> want     <-  data.frame(test2)
>>
>>
>> I want get the following result but I am not getting it.
>>
>>     city wk var
>>    city2  1   x
>>    city2  2   x
>>    city2  3   x
>>    city2  4   x
>>    city3  1   x
>>    city3  2   x
>>   city3  3   x
>>   city3  4   x
>>   city5  3   -
>>   city5  4   -
>>
>> Can some help me out the problem is?
>>
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar 20 18:18:08 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Mar 2017 17:18:08 +0000
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
	<CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
Message-ID: <91764a836bd04fa791f21b1c1fbac4fa@exch-2p-mbx-w2.ads.tamu.edu>

I had no clue either, but consulting the oracle known as "google" with the query: "panel var in r" produced links to a recent paper by Sigmund et al called "Panel Vector Autoregression in R: The panelvar Package."

However the package does not seem to be available on CRAN so you'll have to contact the author(s) of the paper.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Monday, March 20, 2017 11:44 AM
To: Abhishek Kumar Rohit <abhishek.fpm2014 at iimraipur.ac.in>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] ESTIMATION OF PANEL VAR

Excuse my denseness, but huh??

If you receive no satisfactory responses, please read the posting
guide to learn how to post an intelligible question.

Otherwise, just ignore me.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
<abhishek.fpm2014 at iimraipur.ac.in> wrote:
> Is there any package available for estimating Panel VAR. Can the packages
> vars and palm be combined in some way to do that?
>
> Regards,
> *Abhishek Rohit*
> Research Fellow
> IIM Raipur
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nospam at lisse.NA  Mon Mar 20 17:53:20 2017
From: nospam at lisse.NA (Dr Eberhard Lisse)
Date: Mon, 20 Mar 2017 17:53:20 +0100
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
Message-ID: <28bc3413-5f44-3a71-9511-1148d213fa89@lisse.NA>

What did

https://www.google.de/search?q=Panel+VAR+R

show?

el

On 2017-03-20 12:50 , Abhishek Kumar Rohit wrote:
> Is there any package available for estimating Panel VAR. Can the packages
> vars and palm be combined in some way to do that?
> 
> Regards,
> *Abhishek Rohit*
> Research Fellow
> IIM Raipur
> 
> 	[[alternative HTML version deleted]]
>


From glacour at adding.fr  Mon Mar 20 18:39:31 2017
From: glacour at adding.fr (Guillaume LACOUR)
Date: Mon, 20 Mar 2017 17:39:31 +0000
Subject: [R] Elaborate OrgChart
Message-ID: <b6cf2db737554adc8d44b37705af6e1c@ex-ext-01.addinggroup.lan>

Hi,
I'm trying to draw a chart such as the one provided by gvisOrgChart in the GoogleVis demo, that would provide more options such as boxes with varying size or the ability to add basic statistics on each subgroup represented by a box.
Any idea ?
Thanks


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Mar 20 20:21:18 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Mar 2017 12:21:18 -0700
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <91764a836bd04fa791f21b1c1fbac4fa@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
	<CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
	<91764a836bd04fa791f21b1c1fbac4fa@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <421555F6-9AB4-42D4-BF86-0B1E4677E5B1@comcast.net>


> On Mar 20, 2017, at 10:18 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> I had no clue either, but consulting the oracle known as "google" with the query: "panel var in r" produced links to a recent paper by Sigmund et al called "Panel Vector Autoregression in R: The panelvar Package."
> 
> However the package does not seem to be available on CRAN so you'll have to contact the author(s) of the paper.

It's not on CRAN because it's a STATA package.

-- 
David
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Monday, March 20, 2017 11:44 AM
> To: Abhishek Kumar Rohit <abhishek.fpm2014 at iimraipur.ac.in>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] ESTIMATION OF PANEL VAR
> 
> Excuse my denseness, but huh??
> 
> If you receive no satisfactory responses, please read the posting
> guide to learn how to post an intelligible question.
> 
> Otherwise, just ignore me.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
> <abhishek.fpm2014 at iimraipur.ac.in> wrote:
>> Is there any package available for estimating Panel VAR. Can the packages
>> vars and palm be combined in some way to do that?
>> 
>> Regards,
>> *Abhishek Rohit*
>> Research Fellow
>> IIM Raipur
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Mar 20 20:27:44 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Mar 2017 12:27:44 -0700
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <421555F6-9AB4-42D4-BF86-0B1E4677E5B1@comcast.net>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
	<CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
	<91764a836bd04fa791f21b1c1fbac4fa@exch-2p-mbx-w2.ads.tamu.edu>
	<421555F6-9AB4-42D4-BF86-0B1E4677E5B1@comcast.net>
Message-ID: <E1F8B907-FDC9-4C77-869B-D26215C35E90@comcast.net>


> On Mar 20, 2017, at 12:21 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Mar 20, 2017, at 10:18 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>> I had no clue either, but consulting the oracle known as "google" with the query: "panel var in r" produced links to a recent paper by Sigmund et al called "Panel Vector Autoregression in R: The panelvar Package."
>> 
>> However the package does not seem to be available on CRAN so you'll have to contact the author(s) of the paper.
> 
> It's not on CRAN because it's a STATA package.

Ooops, I didn't read that abstract carefully enough and have now read the paper. It's an extension to the plm R package.

> The January 2017 posting to CrossValidated.com: http://stats.stackexchange.com/questions/237332/panel-vector-autoregression-models-in-r/237333

... says code is "available soon".

> -- 
> David
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
>> Sent: Monday, March 20, 2017 11:44 AM
>> To: Abhishek Kumar Rohit <abhishek.fpm2014 at iimraipur.ac.in>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] ESTIMATION OF PANEL VAR
>> 
>> Excuse my denseness, but huh??
>> 
>> If you receive no satisfactory responses, please read the posting
>> guide to learn how to post an intelligible question.
>> 
>> Otherwise, just ignore me.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
>> <abhishek.fpm2014 at iimraipur.ac.in> wrote:
>>> Is there any package available for estimating Panel VAR. Can the packages
>>> vars and palm be combined in some way to do that?
>>> 
>>> Regards,
>>> *Abhishek Rohit*
>>> Research Fellow
>>> IIM Raipur
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Mon Mar 20 22:12:34 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Mar 2017 21:12:34 +0000
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <421555F6-9AB4-42D4-BF86-0B1E4677E5B1@comcast.net>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
	<CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
	<91764a836bd04fa791f21b1c1fbac4fa@exch-2p-mbx-w2.ads.tamu.edu>
	<421555F6-9AB4-42D4-BF86-0B1E4677E5B1@comcast.net>
Message-ID: <9853215969c94dcaaa21e8b1d384977e@exch-2p-mbx-w2.ads.tamu.edu>

It is confusing, but he is comparing STATA package xtabond2 with R packages plm and panelvar. For example:

"The same example with out [sic] code reads as follows:
R> library(panelvar)
R> library(plm)
R> data("abdata")"

Suggests that panelvar is an R package, but apparently one that is not published on CRAN.

David C

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, March 20, 2017 2:21 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Bert Gunter <bgunter.4567 at gmail.com>; Abhishek Kumar Rohit <abhishek.fpm2014 at iimraipur.ac.in>; R-help <r-help at r-project.org>
Subject: Re: [R] ESTIMATION OF PANEL VAR


> On Mar 20, 2017, at 10:18 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> I had no clue either, but consulting the oracle known as "google" with the query: "panel var in r" produced links to a recent paper by Sigmund et al called "Panel Vector Autoregression in R: The panelvar Package."
> 
> However the package does not seem to be available on CRAN so you'll have to contact the author(s) of the paper.

It's not on CRAN because it's a STATA package.

-- 
David
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Monday, March 20, 2017 11:44 AM
> To: Abhishek Kumar Rohit <abhishek.fpm2014 at iimraipur.ac.in>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] ESTIMATION OF PANEL VAR
> 
> Excuse my denseness, but huh??
> 
> If you receive no satisfactory responses, please read the posting
> guide to learn how to post an intelligible question.
> 
> Otherwise, just ignore me.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
> <abhishek.fpm2014 at iimraipur.ac.in> wrote:
>> Is there any package available for estimating Panel VAR. Can the packages
>> vars and palm be combined in some way to do that?
>> 
>> Regards,
>> *Abhishek Rohit*
>> Research Fellow
>> IIM Raipur
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon Mar 20 22:19:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Mar 2017 08:19:53 +1100
Subject: [R] Elaborate OrgChart
In-Reply-To: <b6cf2db737554adc8d44b37705af6e1c@ex-ext-01.addinggroup.lan>
References: <b6cf2db737554adc8d44b37705af6e1c@ex-ext-01.addinggroup.lan>
Message-ID: <CA+8X3fVAYtXxc2aSXYwuAECeu6rZb+_e9pnETUFrqXZzz4E_YA@mail.gmail.com>

Hi Guillaume,
If you are talking about the "Bubble Chart", you might be able to use
the boxed.labels function in plotrix. Here is a slight modification of
the first example for the size_n_color function that may help.

library(plotrix)

 meantemp<-c(19,22,25,29,21,20,16,27,23,26)
 totalrain<-c(174,152,196,120,177,183,92,153,161,85)
 numpumpkin<-c(53,47,61,63,38,42,48,71,66,29)
 meanwt<-c(1.5,2.3,2.8,1.9,2.4,1.8,2.6,2.2,1.7)
 size_n_color(meantemp,totalrain,meanwt/5,NA,xlim=c(15,30),
  color.scale(numpumpkin,c(0.8,0),c(0.8,1),0),
  xlab="Temperature (degrees C)",ylab="Rainfall (mm)",
  main="Number and weight of pumpkins by temperature and rainfall",
  xat=seq(15,30,by=5),yat=seq(80,200,by=20))
 color.legend(15,55,18.5,60,seq(40,70,by=10),
  rect.col=color.scale(seq(40,70,by=10),c(0.8,0),c(0.8,1),0))
 points(15:18,rep(126,4),cex=seq(1.5,3.0,by=0.5))
 text(15:19,rep(134,5),c("1.5","2.0","2.5","3.0","kg"))
 par(xpd=TRUE)
 text(13.5,60,"Number of\npumpkins")
 par(xpd=FALSE)
boxed.labels(meantemp,totalrain,numpumpkin,cex=0.7)

Jim


On Tue, Mar 21, 2017 at 4:39 AM, Guillaume LACOUR <glacour at adding.fr> wrote:
> Hi,
> I'm trying to draw a chart such as the one provided by gvisOrgChart in the GoogleVis demo, that would provide more options such as boxes with varying size or the ability to add basic statistics on each subgroup represented by a box.
> Any idea ?
> Thanks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From La.Moeller at gmx.de  Mon Mar 20 18:25:33 2017
From: La.Moeller at gmx.de (=?UTF-8?Q?=22Lars_M=C3=B6ller=22?=)
Date: Mon, 20 Mar 2017 18:25:33 +0100
Subject: [R] Problems with installing RWeka on MacBook
Message-ID: <trinity-6f677a9a-981d-4d89-83ae-873253a3eaae-1490030733408@3capp-gmx-bs16>

A non-text attachment was scrubbed...
Name: Problem_RWeka.png
Type: image/png
Size: 312275 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170320/6813414f/attachment.png>

From strunky at gmail.com  Mon Mar 20 22:30:18 2017
From: strunky at gmail.com (Jacob Strunk)
Date: Mon, 20 Mar 2017 14:30:18 -0700
Subject: [R] problem with extract raster with polygon
Message-ID: <CAKo8+ciLTW2w8hWaQCTre_+bHYDzDvdh+4B9Ng70-AhUCm_4ow@mail.gmail.com>

Hello, I am having some troubles extracting pixels from a raster using
polygons. When I attempt to do so, pixels which are only partially
intersected by polygons are not included.

In the example below the number of pixels returned is less than the number
of pixels which can be seen intersecting polygons.

As an aside I also encountered strange behavior in my example below after
buffering polygons by 10 units. After buffering polygons by 10 units, the
number of pixels return by extract was actually reduced.


Example
r <- raster(ncol=5, nrow=5)
r[] <- 1:ncell(r)

cds1 <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-70), c(-180,-20))
cds2 <- rbind(c(80,0), c(100,60), c(120,0), c(120,-55), c(80,0))
polys <- spPolygons(cds1, cds2)


plot(r)
plot(polys, add=TRUE)
plot(buffer(polys,10,dissolve=F), add=TRUE)
plot(buffer(polys,30,dissolve=F), add=TRUE)
plot(buffer(polys,100,dissolve=F), add=TRUE)

extract(r, polys)
extract(r, buffer(polys,10,dissolve=F))
extract(r, buffer(polys,30,dissolve=F))
extract(r, buffer(polys,100,dissolve=F))

my R output:
> extract(r, polys)
[[1]]
[1] 11 12 16

[[2]]
[1] 14  4 15 25

> extract(r, buffer(polys,10,dissolve=F))
[[1]]
[1] 11 12 16

[[2]]

14

> extract(r, buffer(polys,30,dissolve=F))
[[1]]
[1] 11 12 16 17 21

[[2]]
[1]  9 14 15 19 20 25

> extract(r, buffer(polys,100,dissolve=F))
[[1]]
 [1]  1  2  3  6  7  8 11 12 13 16 17 18 21 22 23

[[2]]
 [1]  3  4  5  8  9 10 13 14 15 18 19 20 24 25

> R.Version()
$platform
[1] "x86_64-w64-mingw32"

$arch
[1] "x86_64"

$os
[1] "mingw32"

$system
[1] "x86_64, mingw32"

$status
[1] ""

$major
[1] "3"

$minor
[1] "3.2"

$year
[1] "2016"

$month
[1] "10"

$day
[1] "31"

$`svn rev`
[1] "71607"

$language
[1] "R"

$version.string
[1] "R version 3.3.2 (2016-10-31)"

$nickname
[1] "Sincere Pumpkin Patch"



"Documentation for package ?raster? version 2.5-8" from Raster help pages


Thanks for any help

-- 
Jacob

	[[alternative HTML version deleted]]


From alicia.m.ellis at gmail.com  Mon Mar 20 23:51:25 2017
From: alicia.m.ellis at gmail.com (Alicia Ellis)
Date: Mon, 20 Mar 2017 18:51:25 -0400
Subject: [R] Changing cell value for MANY unique pairings of values in 2
	columns
In-Reply-To: <E0AEDE89-4DB7-47A8-AEF8-92B20BF8FEF3@comcast.net>
References: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>
	<8737BB93-F854-4423-9438-A75A8F53D5D4@comcast.net>
	<E0AEDE89-4DB7-47A8-AEF8-92B20BF8FEF3@comcast.net>
Message-ID: <CAPUn7Bc_qJW8CnmzotYhscGV0ZAGH08LCUn2DV3APc=Uw=p2=A@mail.gmail.com>

The solution proposed below does not accomplish my goal.  In the column
labeled NEW_VALUE, there are two NAs where the value in NUMERIC_VALUE for
that row should be.

Can anyone else suggest a solution to my problem?

Thanks!

On Sat, Mar 18, 2017 at 1:33 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 18, 2017, at 9:52 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Mar 17, 2017, at 11:33 AM, Alicia Ellis <alicia.m.ellis at gmail.com>
> wrote:
> >>
> >> am cleaning some very messy health record lab data.  Several of the rows
> >> in the VALUE column have text entries and they need to be converted to
> >> numeric in the NUMERIC_VALUE column based on the values in VALUE and
> >> DESCRIPTION.  For example:
> >>
> >> df <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
> 0.30",
> >> "12%", "<0.2", "Unknown"),
> >>                DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
> >>                NUMERIC_VALUE=c(9, 9,9,9,9,9,9))
> >> df
> >>
> >> df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION ==
> "A"]=999999999
> >>
> >>
> >> However, I need to do this for ~500 unique pairings of VALUE and
> >> DESCRIPTION entries.  I'm trying to find an easy way to do this without
> >> having to have 500 lines of code for each unique pairing.  Some of the
> >> pairings will be changed to the same value (e.g., 99999999, or
> -999999999)
> >> but many will be unique numeric values.
> >
> > I'm not convinced that you have the necessary scientific background to
> do this job properly. There are different sorts of lab tests: enzymatic
> activity, solute concentrations, and viral titers come to mind immediately
> for which the handling would be materially different. If you have a serum
> sodium level of less than 100 mEq/ml, then that is a value inconsistent
> with human life and the value should be set to NA. If you have a value of
> alkaline phosphatase that is 0 it is most suggestive of specimen
> mishandling. If you have a hepatitis B antigen level of "Positive", then it
> seems a perfectly informative value that should not be changed.
> >
> > Furthermore the attempt to change vlaues that you think are missing to
> 99999999, or -999999999 is simply wrongheaded. Learn to use the missing
> value indicator NA rather thna setting these to a numeric value.
> >
> > You should seek advice within your organization before you charge ahead
> with this strategy.
>
> I've been informed that my concerns are misplaced and that the scientific
> concerns I raised were inflated. The "answer" then might be:
>
> merge( df, rules, by=1:2, all.x=TRUE)  # Or
>
> merge( df, rules, by=c("VALUE", "DESCRIPTION") , all.x=TRUE)
>
>
> Which returns in this example:
>
>
>            VALUE DESCRIPTION NUMERIC_VALUE  NEW_VALUE
> 1           <0.2           E         9e+00       0.10
> 2            <60           A         9e+00      60.00
> 3            12%           D         9e+00         NA
> 4 Less than 0.30           C         9e+00       0.29
> 5       Negative           B         9e+00 -999999.00
> 6       Positive           A         1e+09         NA
> 7        Unknown           E         9e+00  777777.00
>
> I'm leaving it in this form because I remain worried. I have no particular
> concerns about setting a value of "<0.2" to 0.1 but worry about setting
> values of  "<60" to 60.00 or "Less than 0.30" to 0.29 don't really accord
> with practice that I have seen in analysis of laboratory values. And I
> remain concerned that using flagrantly false numeric values as indicators
> will create serious errors down the line if this data is ever used by
> someone who has not been involved with its manipulation or has even
> forgotten months later how it was massaged.
>
> --
> David.
> > --
> > David.
> >>
> >>
> >> I've started by creating a new object called rules where a SUBSET of df
> >> rows are included with the new value they should be changed to.
> >>
> >>
> >> rules <- data.frame(VALUE = c("<60",  "Negative", "Less than 0.30",
> "<0.2",
> >> "Unknown"),
> >>                   DESCRIPTION = c("A", "B", "C", "E", "E"),
> >>                   NEW_VALUE=c(60, -999999,0.29,0.1,777777))
> >> rules
> >>
> >>
> >> I tried doing a loop to change the values in df based on the suggested
> >> value in rules:
> >>
> >> for (i in (1 : nrow(rules))) {
> >> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
> >> [i,2]]=rules[i,3]
> >> }
> >> df
> >>
> >> This gives the error:
> >>
> >> Error in Ops.factor(df$VALUE, rules[i, 1]) :
> >> level sets of factors are differentwork and I think because when I write
> >>
> >> If I create rules using the exact same levels as df it works:
> >>
> >> rules <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
> >> 0.30", "12%", "<0.2", "Unknown"),
> >>                   DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
> >>                   NEW_VALUE=c(60, 999999,-999999,0.29,12,0.1,777777))
> >> rules
> >>
> >> for (i in (1 : nrow(rules))) {
> >> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
> >> [i,2]]=rules[i,3]
> >> }
> >> df
> >>
> >>
> >> Can anyone suggest a way to modify my for loop so that it works for a
> >> subset of rows in df and accomplish what I want?  Or suggest a
> completely
> >> different method that works?
> >>
> >>
> >> Thanks!
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dmorrison01 at ucla.edu  Tue Mar 21 00:46:44 2017
From: dmorrison01 at ucla.edu (Douglas Ezra Morrison)
Date: Mon, 20 Mar 2017 23:46:44 +0000
Subject: [R] assigning dimnames to arrays
Message-ID: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>

Dear R-Help readers,

I am writing to ask about some behavior of base::dimnames() that surprised
me. If I create an array with one of its dimensions = 1, and then try to
assign names to that dimension, I get an error unless I name one of the
other dimensions first. For example:

> temp1 = array(NA, c(3,2,1))
> dimnames(temp1)[[3]] = "test"

results in the error: "Error in dimnames(temp1)[[3]] = "test" : 'dimnames'
must be a list"

However, the following works:

> temp1 = array(NA, c(3,2,1))
> dimnames(temp1)[[2]] = c("a","b")
> dimnames(temp1)[[3]] = "test"

I found an explanation of what is happening on stackoverflow (
http://stackoverflow.com/questions/12578461/r-dimnames-of-matrix-strange-behaviour/42915723),
however, I didn't see any explanation of why this behavior is
intended/desirable. Moreover, it recently caused a problem in a place where
I couldn't easily work around it, without submitting edits to or forking
someone else's R package. Is there any possibility that this behavior is a
bug that could be fixed, or is it something I should learn to live with?

Thanks,
Doug

-- 

Typed from a mobile device - apologies for typos and brevity.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Mar 21 10:21:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Mar 2017 20:21:24 +1100
Subject: [R] Changing cell value for MANY unique pairings of values in 2
	columns
In-Reply-To: <CAPUn7Bc_qJW8CnmzotYhscGV0ZAGH08LCUn2DV3APc=Uw=p2=A@mail.gmail.com>
References: <CAPUn7Be9eE9+VqM_Txxvot+mP9GH_qB9f3t6Gk8evzgOdcON+A@mail.gmail.com>
	<8737BB93-F854-4423-9438-A75A8F53D5D4@comcast.net>
	<E0AEDE89-4DB7-47A8-AEF8-92B20BF8FEF3@comcast.net>
	<CAPUn7Bc_qJW8CnmzotYhscGV0ZAGH08LCUn2DV3APc=Uw=p2=A@mail.gmail.com>
Message-ID: <CA+8X3fX86ugPq1-aPnk4pHBwaR=y1whdez3DeOjRiwDy9_qbuw@mail.gmail.com>

Hi Alicia,
If I understand this, perhaps:

df<-data.frame(VALUE=c("<60","Positive","Negative","Less than 0.30",
 "12%","<0.2","Unknown"),
 DESCRIPTION = c("A","A", "B","C","D","E","E"),
 NUMERIC_VALUE=c(9,9,9,9,9,9,9))

df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION == "A"]<-
 999999999

rules<-data.frame(VALUE = c("<60","Negative","Less than 0.30",
 "<0.2","Unknown"),
 DESCRIPTION = c("A", "B", "C", "E", "E"),
 NEW_VALUE=c(60, -999999,0.29,0.1,777777))

for(row in 1:dim(df)[1]) {
 if(df$VALUE %in% rules$VALUE && df$DESCRIPTION %in% rules$DESCRIPTION) {
  which_value<-which(as.character(df$VALUE[row]) ==
   as.character(rules$VALUE))
  which_desc<-which(as.character(df$DESCRIPTION[row]) ==
   as.character(rules$DESCRIPTION))
  cat(which_value,which_desc,"\n")
  if(length(which_value) && length(which_desc) &&
   which_value == which_desc)
   df$NUMERIC_VALUE[row]<-rules$NEW_VALUE[which_value]
 }
}

Jim

On Tue, Mar 21, 2017 at 9:51 AM, Alicia Ellis <alicia.m.ellis at gmail.com> wrote:
> The solution proposed below does not accomplish my goal.  In the column
> labeled NEW_VALUE, there are two NAs where the value in NUMERIC_VALUE for
> that row should be.
>
> Can anyone else suggest a solution to my problem?
>
> Thanks!
>
> On Sat, Mar 18, 2017 at 1:33 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Mar 18, 2017, at 9:52 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> >
>> >
>> >> On Mar 17, 2017, at 11:33 AM, Alicia Ellis <alicia.m.ellis at gmail.com>
>> wrote:
>> >>
>> >> am cleaning some very messy health record lab data.  Several of the rows
>> >> in the VALUE column have text entries and they need to be converted to
>> >> numeric in the NUMERIC_VALUE column based on the values in VALUE and
>> >> DESCRIPTION.  For example:
>> >>
>> >> df <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
>> 0.30",
>> >> "12%", "<0.2", "Unknown"),
>> >>                DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>> >>                NUMERIC_VALUE=c(9, 9,9,9,9,9,9))
>> >> df
>> >>
>> >> df$NUMERIC_VALUE[df$VALUE == "Positive" & df$DESCRIPTION ==
>> "A"]=999999999
>> >>
>> >>
>> >> However, I need to do this for ~500 unique pairings of VALUE and
>> >> DESCRIPTION entries.  I'm trying to find an easy way to do this without
>> >> having to have 500 lines of code for each unique pairing.  Some of the
>> >> pairings will be changed to the same value (e.g., 99999999, or
>> -999999999)
>> >> but many will be unique numeric values.
>> >
>> > I'm not convinced that you have the necessary scientific background to
>> do this job properly. There are different sorts of lab tests: enzymatic
>> activity, solute concentrations, and viral titers come to mind immediately
>> for which the handling would be materially different. If you have a serum
>> sodium level of less than 100 mEq/ml, then that is a value inconsistent
>> with human life and the value should be set to NA. If you have a value of
>> alkaline phosphatase that is 0 it is most suggestive of specimen
>> mishandling. If you have a hepatitis B antigen level of "Positive", then it
>> seems a perfectly informative value that should not be changed.
>> >
>> > Furthermore the attempt to change vlaues that you think are missing to
>> 99999999, or -999999999 is simply wrongheaded. Learn to use the missing
>> value indicator NA rather thna setting these to a numeric value.
>> >
>> > You should seek advice within your organization before you charge ahead
>> with this strategy.
>>
>> I've been informed that my concerns are misplaced and that the scientific
>> concerns I raised were inflated. The "answer" then might be:
>>
>> merge( df, rules, by=1:2, all.x=TRUE)  # Or
>>
>> merge( df, rules, by=c("VALUE", "DESCRIPTION") , all.x=TRUE)
>>
>>
>> Which returns in this example:
>>
>>
>>            VALUE DESCRIPTION NUMERIC_VALUE  NEW_VALUE
>> 1           <0.2           E         9e+00       0.10
>> 2            <60           A         9e+00      60.00
>> 3            12%           D         9e+00         NA
>> 4 Less than 0.30           C         9e+00       0.29
>> 5       Negative           B         9e+00 -999999.00
>> 6       Positive           A         1e+09         NA
>> 7        Unknown           E         9e+00  777777.00
>>
>> I'm leaving it in this form because I remain worried. I have no particular
>> concerns about setting a value of "<0.2" to 0.1 but worry about setting
>> values of  "<60" to 60.00 or "Less than 0.30" to 0.29 don't really accord
>> with practice that I have seen in analysis of laboratory values. And I
>> remain concerned that using flagrantly false numeric values as indicators
>> will create serious errors down the line if this data is ever used by
>> someone who has not been involved with its manipulation or has even
>> forgotten months later how it was massaged.
>>
>> --
>> David.
>> > --
>> > David.
>> >>
>> >>
>> >> I've started by creating a new object called rules where a SUBSET of df
>> >> rows are included with the new value they should be changed to.
>> >>
>> >>
>> >> rules <- data.frame(VALUE = c("<60",  "Negative", "Less than 0.30",
>> "<0.2",
>> >> "Unknown"),
>> >>                   DESCRIPTION = c("A", "B", "C", "E", "E"),
>> >>                   NEW_VALUE=c(60, -999999,0.29,0.1,777777))
>> >> rules
>> >>
>> >>
>> >> I tried doing a loop to change the values in df based on the suggested
>> >> value in rules:
>> >>
>> >> for (i in (1 : nrow(rules))) {
>> >> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
>> >> [i,2]]=rules[i,3]
>> >> }
>> >> df
>> >>
>> >> This gives the error:
>> >>
>> >> Error in Ops.factor(df$VALUE, rules[i, 1]) :
>> >> level sets of factors are differentwork and I think because when I write
>> >>
>> >> If I create rules using the exact same levels as df it works:
>> >>
>> >> rules <- data.frame(VALUE = c("<60", "Positive", "Negative", "Less than
>> >> 0.30", "12%", "<0.2", "Unknown"),
>> >>                   DESCRIPTION = c("A","A", "B", "C", "D", "E", "E"),
>> >>                   NEW_VALUE=c(60, 999999,-999999,0.29,12,0.1,777777))
>> >> rules
>> >>
>> >> for (i in (1 : nrow(rules))) {
>> >> df$NUMERIC_VALUE[df$VALUE == rules[i,1] & df$DESCRIPTION == rules
>> >> [i,2]]=rules[i,3]
>> >> }
>> >> df
>> >>
>> >>
>> >> Can anyone suggest a way to modify my for loop so that it works for a
>> >> subset of rows in df and accomplish what I want?  Or suggest a
>> completely
>> >> different method that works?
>> >>
>> >>
>> >> Thanks!
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tal.galili at gmail.com  Tue Mar 21 10:30:33 2017
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 21 Mar 2017 11:30:33 +0200
Subject: [R] Why is options(digits = 1) displays two digits?
Message-ID: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>

This may have been asked before, but I don't understand the behavior
of options(digits = 1) for vectors containing values such as 0.01

For example, why is this happening:
options(digits = 1)
> 0.01
[1] 0.01


More examples:
> options(digits = 7)
> 0.1
[1] 0.1
> 0.01
[1] 0.01
> 0.11
[1] 0.11
> c(0.1,0.01)
[1] 0.10 0.01
> options(digits = 1)
> 0.1
[1] 0.1
> 0.01
[1] 0.01
> 0.11
[1] 0.1
> c(0.1,0.01)
[1] 0.10 0.01
>

The help file in ?options says:
digits:
controls the number of digits to print when printing numeric values. It is
a suggestion only.


Is this what is mean by "It is a suggestion only." ?

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Tue Mar 21 10:45:13 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 21 Mar 2017 10:45:13 +0100
Subject: [R] Why is options(digits = 1) displays two digits?
In-Reply-To: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>
References: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>
Message-ID: <a103cd77-0a42-9eaf-360a-aa6b58c76031@math.uni-giessen.de>

Hi, Tal,

in print.default it says:

digits:

a non-null value for digits specifies the __minimum__
number of __significant__ digits to be printed in values.

Maybe this clarifies your observation.

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 21.03.2017 um 10:30 schrieb Tal Galili:
> This may have been asked before, but I don't understand the behavior
> of options(digits = 1) for vectors containing values such as 0.01
>
> For example, why is this happening:
> options(digits = 1)
>> 0.01
> [1] 0.01
>
>
> More examples:
>> options(digits = 7)
>> 0.1
> [1] 0.1
>> 0.01
> [1] 0.01
>> 0.11
> [1] 0.11
>> c(0.1,0.01)
> [1] 0.10 0.01
>> options(digits = 1)
>> 0.1
> [1] 0.1
>> 0.01
> [1] 0.01
>> 0.11
> [1] 0.1
>> c(0.1,0.01)
> [1] 0.10 0.01
>>
>
> The help file in ?options says:
> digits:
> controls the number of digits to print when printing numeric values. It is
> a suggestion only.
>
>
> Is this what is mean by "It is a suggestion only." ?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Tue Mar 21 10:53:29 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Mar 2017 20:53:29 +1100
Subject: [R] Why is options(digits = 1) displays two digits?
In-Reply-To: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>
References: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>
Message-ID: <CA+8X3fXHckBom8DPLD9Nmtu32sLMfHzVu2=7QXSE=HN2ruY9ug@mail.gmail.com>

I'd say it's about equivalent to suggesting to Vladimir Putin that he
stop trying to take over territories bordering Russia.

Jim


On Tue, Mar 21, 2017 at 8:30 PM, Tal Galili <tal.galili at gmail.com> wrote:
> This may have been asked before, but I don't understand the behavior
> of options(digits = 1) for vectors containing values such as 0.01
>
> For example, why is this happening:
> options(digits = 1)
>> 0.01
> [1] 0.01
>
>
> More examples:
>> options(digits = 7)
>> 0.1
> [1] 0.1
>> 0.01
> [1] 0.01
>> 0.11
> [1] 0.11
>> c(0.1,0.01)
> [1] 0.10 0.01
>> options(digits = 1)
>> 0.1
> [1] 0.1
>> 0.01
> [1] 0.01
>> 0.11
> [1] 0.1
>> c(0.1,0.01)
> [1] 0.10 0.01
>>
>
> The help file in ?options says:
> digits:
> controls the number of digits to print when printing numeric values. It is
> a suggestion only.
>
>
> Is this what is mean by "It is a suggestion only." ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Tue Mar 21 11:10:51 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Mar 2017 11:10:51 +0100
Subject: [R] Why is options(digits = 1) displays two digits?
In-Reply-To: <a103cd77-0a42-9eaf-360a-aa6b58c76031@math.uni-giessen.de>
References: <CANdJ3dWt6Mr1on+DLZvJGywKDm86wxVxWeUnBhSBdcOLGbuxUA@mail.gmail.com>
	<a103cd77-0a42-9eaf-360a-aa6b58c76031@math.uni-giessen.de>
Message-ID: <22736.64555.350530.678125@stat.math.ethz.ch>

>>>>> Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de>
>>>>>     on Tue, 21 Mar 2017 10:45:13 +0100 writes:

    > Hi, Tal,
    > in print.default it says:

    > digits:

    > a non-null value for digits specifies the __minimum__
    > number of __significant__ digits to be printed in values.

    > Maybe this clarifies your observation.

    > Hth  --  Gerrit

I hope too, thank you Gerrit.

It seems that many people do not understand the term
"number of significant digits".

I think you can learn about it by studying (the help page and
examples of)
   signif(x, digits)

and maybe compare with  round (x, digits).

    > Am 21.03.2017 um 10:30 schrieb Tal Galili:
    >> This may have been asked before, but I don't understand the behavior
    >> of options(digits = 1) for vectors containing values such as 0.01
    >> 
    >> For example, why is this happening:
    >> options(digits = 1)
    >>> 0.01
    >> [1] 0.01
    >> 
    >> 
    >> More examples:
    >>> options(digits = 7)
    >>> 0.1
    >> [1] 0.1
    >>> 0.01
    >> [1] 0.01
    >>> 0.11
    >> [1] 0.11
    >>> c(0.1,0.01)
    >> [1] 0.10 0.01
    >>> options(digits = 1)
    >>> 0.1
    >> [1] 0.1
    >>> 0.01
    >> [1] 0.01
    >>> 0.11
    >> [1] 0.1
    >>> c(0.1,0.01)
    >> [1] 0.10 0.01
    >>> 
    >> 
    >> The help file in ?options says:
    >> digits:
    >> controls the number of digits to print when printing numeric values. It is
    >> a suggestion only.
    >> 
    >> 
    >> Is this what is mean by "It is a suggestion only." ?


From justinthong93 at gmail.com  Tue Mar 21 11:21:40 2017
From: justinthong93 at gmail.com (Justin Thong)
Date: Tue, 21 Mar 2017 10:21:40 +0000
Subject: [R] Kernel Density Estimation: Generate a sample from Epanechnikov
	Kernel
Message-ID: <CAEtAGeruHXyuyHdJ4wah1Lwk2XMtHbAb15DQR8GHisyj2ps2Ng@mail.gmail.com>

Below are samples from a kernel density estimated "data" with gaussian
kernel.
I really like this solution of estimation of a kernel because it is nice
and elegant.

fit<-density(data)
rnorm(N, sample(data, size = N, replace = TRUE), fit$bw)  #samples from
kernel density estimation

I am however interested in generating a kernel density estimate with
an Epanechnikov kernel

fit<-density(data,kernel = "epanechnikov")
#is there a quick way to compute the samples and INCORPORATING THE
BANDWIDTH of the #kernel density estimate


Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From danprec at hotmail.com  Tue Mar 21 11:57:17 2017
From: danprec at hotmail.com (DANIEL PRECIADO)
Date: Tue, 21 Mar 2017 10:57:17 +0000
Subject: [R] nlmrt problems - No confInt,  NA StdErr, t-, or p-values
Message-ID: <MWHPR08MB260833ED6F4D67A0014B929CA03D0@MWHPR08MB2608.namprd08.prod.outlook.com>

Dear list,

I want to use nlxb (package nlmrt) to fit different datasets to a gaussian, obtain parameters (including standard error, t-and p-value) and confidence intervals.

nlxb generates the parameters, but very often results in NA standard error,t-and p-values. Furthermore, using confint() to obtain the confidence intervals generates a : Error in vcov.default(object) :   object does not have variance-covariance matrix" erro.

Can someone indicate why is nlxb generating NAs (when nls has no problem with them) and how to obtain confidence intervals from an nlmrt object?

Thanks


	[[alternative HTML version deleted]]


From mdayan.research at gmail.com  Tue Mar 21 13:04:31 2017
From: mdayan.research at gmail.com (Michael Dayan)
Date: Tue, 21 Mar 2017 13:04:31 +0100
Subject: [R] Using betareg package to fit beta mixture with given initial
	parameters
Message-ID: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>

Hi,

I would like to fit a mixture of two beta distributions with parameters
(alpha1, beta1) for the first component, (alpha2, beta2) for the second
component, and lambda for the mixing parameter. I also would like to set a
maximum of 200 iterations and a tolerance of 1e-08.

My question is: how to use the betareg package to run the fit with initial
values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw in
the documentation that I would need to use the 'start' option of the
betareg function, with start described as "an optional vector with starting
values for all parameters (including phi)". However I could not find how to
define this list given my alpha1, beta1, alpha2, beta2 and lambda.

The current code I have is:
mydata$y <- <my_data>
bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
200, fsmaxit = 200)


And I suspect I would need to do something along the lines:

initial.vals <- c(?, ?, ?, ?, ?)
bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
200, fsmaxit = 200, control=betareg.control(start=initial.vals)))

But I do not know what to use for initial.vals.

Best wishes,

Michael

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Tue Mar 21 14:12:17 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 21 Mar 2017 09:12:17 -0400
Subject: [R] nlmrt problems - No confInt, NA StdErr, t-, or p-values
In-Reply-To: <MWHPR08MB260833ED6F4D67A0014B929CA03D0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB260833ED6F4D67A0014B929CA03D0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <CAP01uRmxv1Rb2s1ftJP8NUD70OkE88fTzFEJTmX_jcfUWd=U7g@mail.gmail.com>

You can use wrapnls from the nlmrt package to get an nls object.  Run
it instead of nlxb. It runs nlxb followed by nls so that the output is
an nls object..  Then you can use all of nls' methods.

On occiasion that fails even if nlxb succeeds since the nls
optimization can fail independently of nlxb.  Also, it does not show
the output from nlxb, only from the final nls, so you could
alternately run nlxb and then run nls2 from the nls2 package after
that.  nls2 can compute the nls object at a particular set of
coefficients so no second optimization that could fail is done. Here
is an example that uses nls2 to generate starting values for nlxb,
then runs nlxb and then uses nls2 again to get an nls object so that
it canthen  use nls methods (in this case fitted) on it.

http://stackoverflow.com/questions/42511278/nls-curve-fit-singular-matrix-error/42513058#42513058




On Tue, Mar 21, 2017 at 6:57 AM, DANIEL PRECIADO <danprec at hotmail.com> wrote:
> Dear list,
>
> I want to use nlxb (package nlmrt) to fit different datasets to a gaussian, obtain parameters (including standard error, t-and p-value) and confidence intervals.
>
> nlxb generates the parameters, but very often results in NA standard error,t-and p-values. Furthermore, using confint() to obtain the confidence intervals generates a : Error in vcov.default(object) :   object does not have variance-covariance matrix" erro.
>
> Can someone indicate why is nlxb generating NAs (when nls has no problem with them) and how to obtain confidence intervals from an nlmrt object?
>
> Thanks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dwinsemius at comcast.net  Tue Mar 21 16:21:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Mar 2017 08:21:32 -0700
Subject: [R] assigning dimnames to arrays
In-Reply-To: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>
References: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>
Message-ID: <2A0DC5F3-1B9D-4879-9170-9B1D53AFE9DE@comcast.net>


> On Mar 20, 2017, at 4:46 PM, Douglas Ezra Morrison <dmorrison01 at ucla.edu> wrote:
> 
> Dear R-Help readers,
> 
> I am writing to ask about some behavior of base::dimnames() that surprised
> me. If I create an array with one of its dimensions = 1, and then try to
> assign names to that dimension, I get an error unless I name one of the
> other dimensions first. For example:
> 
>> temp1 = array(NA, c(3,2,1))
>> dimnames(temp1)[[3]] = "test"
> 
> results in the error: "Error in dimnames(temp1)[[3]] = "test" : 'dimnames'
> must be a list"
> 
> However, the following works:
> 
>> temp1 = array(NA, c(3,2,1))

Why not:

temp1 = array(NA, c(3,2,1))
dimnames(temp1) <- list(NULL,NULL,"test")


>> dimnames(temp1)[[2]] = c("a","b")
>> dimnames(temp1)[[3]] = "test"
> 
> I found an explanation of what is happening on stackoverflow (
> http://stackoverflow.com/questions/12578461/r-dimnames-of-matrix-strange-behaviour/42915723),
> however, I didn't see any explanation of why this behavior is
> intended/desirable. Moreover, it recently caused a problem in a place where
> I couldn't easily work around it, without submitting edits to or forking
> someone else's R package. Is there any possibility that this behavior is a
> bug that could be fixed, or is it something I should learn to live with?

I doubt that a request for changing the behavior of the `dimnames.<-` function will get very far. Learn to use the language as it's designed.

David.

> 
> Thanks,
> Doug
> 
> -- 
> 
> Typed from a mobile device - apologies for typos and brevity.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kontakt at benjaminschlegel.ch  Tue Mar 21 10:01:32 2017
From: kontakt at benjaminschlegel.ch (kontakt at benjaminschlegel.ch)
Date: Tue, 21 Mar 2017 10:01:32 +0100
Subject: [R] [R-pkgs] New package: brant
Message-ID: <007301d2a221$bc45b0b0$34d11210$@benjaminschlegel.ch>

Dear R users,

I am pleased to announce the release on CRAN of brant 0.1-1:
https://cran.r-project.org/package=brant. I implemented the brant test
(Brant, Rollin 1990) in R together with Prof. Marco Steenbergen at our
Institute.

The function brant() tests the parallel regression assumption for ordinal
logistic regressions.

Any comments, suggestions or queries are gratefully received.

Best
Benjamin




Benjamin Schlegel
Assistent Lehrstuhl f?r Methoden
Institut f?r Politikwissenschaft
Universit?t Z?rich
Affolternstrasse 56
CH-8050 Z?rich
Tel. +41 44 634 62 08
E-Mail: kontakt at benjaminschlegel.ch <mailto:kontakt at benjaminschlegel.ch> 
Webseite: https://benjaminschlegel.ch



 

 


	[[alternative HTML version deleted]]

-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From Swarna.Gupta at ihsmarkit.com  Tue Mar 21 12:25:55 2017
From: Swarna.Gupta at ihsmarkit.com (Gupta, Swarna)
Date: Tue, 21 Mar 2017 11:25:55 +0000
Subject: [R] Issues in Cubist package (predict function) in R
Message-ID: <66d564987a5a4ba6b46d4c4e13223cce@vwc-2pmaiap06.ihs.internal.corp>

Hi,

This mail is in regards with a query we have in usage of Cubist package in R.
We are using the CRAN package - "Cubist" for predicting sales. We have a large training dataset which in turn gives a huge specification result file.
(Note: Independent variables consists of both character and numerical variables)
We use this specification file to predict for our testing data which has similar structure like training data used.

The problem is when we provide large testing dataset at one go in the predict function of the Cubist package we get "0" as predicted value.
But when we provide the testing dataset in small chunks into the predict function of the Cubist package we get appropriate values as the predictions.
In order to do further research in this, we tried different combinations of data to identify the exact issue but we couldn't really identify the cause of the issue.

In our opinion this problem is likely because of some memory/stack overflow exception in the Cubist package.
A combination of number of rows and the complexity of operation for these rows (number of if conditions they satisfy in the specifications) might be causing this issue.

Could you please clarify the issue ? Any help would be great.

Thanks,
Swarna Gupta


	[[alternative HTML version deleted]]


From carlganz at ucla.edu  Tue Mar 21 16:50:12 2017
From: carlganz at ucla.edu (Ganz, Carl)
Date: Tue, 21 Mar 2017 15:50:12 +0000
Subject: [R] Issue with subset in glm
Message-ID: <A5A30F1D451F924B902DDE8063410E67136F61@EM1A.ad.ucla.edu>

Hello,

I am experiencing odd behavior with the subset parameter for glm. It appears that the parameter uses non-standard evaluation, but only in some cases. Below is a reproducible example.

library(survey) # for example dataset

data(api)
stype <- "E"
(a <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = apistrat$stype == stype))
(b <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = apistrat$stype == "E"))
# should be equal since stype = "E" but they aren't
coef(a)==coef(b)

# for some reason works as expected here
i = 4
(c <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==i))
(d <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==4))
coef(c)==coef(d)

I can't really explain what is happening so I would appreciate help.

Kind Regards,
Carl Ganz


From pdalgd at gmail.com  Tue Mar 21 17:14:11 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Mar 2017 17:14:11 +0100
Subject: [R] ESTIMATION OF PANEL VAR
In-Reply-To: <CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
References: <CAH6n2Nkv2oLqitRew3Ceck=ZN0Y=oL2c4d9Ftq7_8jn95BUzOw@mail.gmail.com>
	<CAGxFJbSYwu43SCaaO1UkZFBHYiUHdaWTQ4HEqRv38Us2S+xMow@mail.gmail.com>
Message-ID: <E033E65A-A3BA-46EE-BACA-DC98F73DB1EF@gmail.com>

This one was actually clear enough to those exposed to the econometric lingo: Panel = "repeated measurements", VAR = Vector AutoRegression (not to be confused with var() or VaR).

-pd

> On 20 Mar 2017, at 17:44 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Excuse my denseness, but huh??
> 
> If you receive no satisfactory responses, please read the posting
> guide to learn how to post an intelligible question.
> 
> Otherwise, just ignore me.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Mar 20, 2017 at 4:50 AM, Abhishek Kumar Rohit
> <abhishek.fpm2014 at iimraipur.ac.in> wrote:
>> Is there any package available for estimating Panel VAR. Can the packages
>> vars and palm be combined in some way to do that?
>> 
>> Regards,
>> *Abhishek Rohit*
>> Research Fellow
>> IIM Raipur
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Tue Mar 21 17:15:50 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 21 Mar 2017 16:15:50 +0000
Subject: [R] Issue with subset in glm
In-Reply-To: <A5A30F1D451F924B902DDE8063410E67136F61@EM1A.ad.ucla.edu>
References: <A5A30F1D451F924B902DDE8063410E67136F61@EM1A.ad.ucla.edu>
Message-ID: <c7fcc3233cc24157a7f0fc86773f410f@exch-2p-mbx-w2.ads.tamu.edu>

When you use the data= argument in glm(), the function looks in the data.frame for a variable first. You have created two versions of stype, one in the data.frame and one outside it. So your first glm() selects all the cases apistrat since apistrat$stype always equals apistrat$stype. You can see this with

(b <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = stype == "E"))

gives the same results as

(a <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = apistrat$stype == "E"))

If you want to use a variable outside the data frame, give it another name, e.g.:

styp <- "E"
(a <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = stype == styp))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ganz, Carl
Sent: Tuesday, March 21, 2017 10:50 AM
To: r-help at r-project.org
Subject: [R] Issue with subset in glm

Hello,

I am experiencing odd behavior with the subset parameter for glm. It appears that the parameter uses non-standard evaluation, but only in some cases. Below is a reproducible example.

library(survey) # for example dataset

data(api)
stype <- "E"
(a <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = apistrat$stype == stype))
(b <- glm(api00~ell+meals+mobility, data = apistrat, 
    subset = apistrat$stype == "E"))
# should be equal since stype = "E" but they aren't
coef(a)==coef(b)

# for some reason works as expected here
i = 4
(c <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==i))
(d <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==4))
coef(c)==coef(d)

I can't really explain what is happening so I would appreciate help.

Kind Regards,
Carl Ganz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Mar 21 17:29:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Mar 2017 09:29:21 -0700
Subject: [R] assigning dimnames to arrays
In-Reply-To: <2A0DC5F3-1B9D-4879-9170-9B1D53AFE9DE@comcast.net>
References: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>
	<2A0DC5F3-1B9D-4879-9170-9B1D53AFE9DE@comcast.net>
Message-ID: <A7CBA650-C59A-4BD2-A1C4-4AEE40F8B9AA@dcn.davis.ca.us>

While I generally agree that it is better to design code that sets all of the dimension names simultaneously, the discrepancy between behavior when the dimensions are longer than 1 and when they are equal to 1 seems irregular. Someone went to some lengths to make it possible to set dimnames individually "most" of the time and it is not clear to me why they stopped short of all the time. 
-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2017 8:21:32 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Mar 20, 2017, at 4:46 PM, Douglas Ezra Morrison
><dmorrison01 at ucla.edu> wrote:
>> 
>> Dear R-Help readers,
>> 
>> I am writing to ask about some behavior of base::dimnames() that
>surprised
>> me. If I create an array with one of its dimensions = 1, and then try
>to
>> assign names to that dimension, I get an error unless I name one of
>the
>> other dimensions first. For example:
>> 
>>> temp1 = array(NA, c(3,2,1))
>>> dimnames(temp1)[[3]] = "test"
>> 
>> results in the error: "Error in dimnames(temp1)[[3]] = "test" :
>'dimnames'
>> must be a list"
>> 
>> However, the following works:
>> 
>>> temp1 = array(NA, c(3,2,1))
>
>Why not:
>
>temp1 = array(NA, c(3,2,1))
>dimnames(temp1) <- list(NULL,NULL,"test")
>
>
>>> dimnames(temp1)[[2]] = c("a","b")
>>> dimnames(temp1)[[3]] = "test"
>> 
>> I found an explanation of what is happening on stackoverflow (
>>
>http://stackoverflow.com/questions/12578461/r-dimnames-of-matrix-strange-behaviour/42915723),
>> however, I didn't see any explanation of why this behavior is
>> intended/desirable. Moreover, it recently caused a problem in a place
>where
>> I couldn't easily work around it, without submitting edits to or
>forking
>> someone else's R package. Is there any possibility that this behavior
>is a
>> bug that could be fixed, or is it something I should learn to live
>with?
>
>I doubt that a request for changing the behavior of the `dimnames.<-`
>function will get very far. Learn to use the language as it's designed.
>
>David.
>
>> 
>> Thanks,
>> Doug
>> 
>> -- 
>> 
>> Typed from a mobile device - apologies for typos and brevity.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Mar 21 17:40:55 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Mar 2017 09:40:55 -0700
Subject: [R] assigning dimnames to arrays
In-Reply-To: <A7CBA650-C59A-4BD2-A1C4-4AEE40F8B9AA@dcn.davis.ca.us>
References: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>
	<2A0DC5F3-1B9D-4879-9170-9B1D53AFE9DE@comcast.net>
	<A7CBA650-C59A-4BD2-A1C4-4AEE40F8B9AA@dcn.davis.ca.us>
Message-ID: <CAF8bMcbymgYiR1S+_exA2MWaAhTJfFTZ+gN_4UGcxam50g8DeA@mail.gmail.com>

It happens because dimnames(originalArray) is NULL and when [[<- extends
NULL it turns it into a list if the size of the new element is not one
but into a vector with the type of new element if the new element's
size is one.
  > str( `[[<-`(NULL, 3, value="One") )
   chr [1:3] NA NA "One"
  > str( `[[<-`(NULL, 3, value=c("One","Two") ))
  List of 3
   $ : NULL
   $ : NULL
   $ : chr [1:2] "One" "Two"
  > str( `[[<-`(NULL, 3, value=character(0) ))
  List of 3
   $ : NULL
   $ : NULL
   $ : chr(0)
dimnames(x) <- characterVector could be changed to call as.list() on
its right hand side.  That would help in this case but would cover up
usage errors in other cases.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Mar 21, 2017 at 9:29 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> While I generally agree that it is better to design code that sets all of the dimension names simultaneously, the discrepancy between behavior when the dimensions are longer than 1 and when they are equal to 1 seems irregular. Someone went to some lengths to make it possible to set dimnames individually "most" of the time and it is not clear to me why they stopped short of all the time.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 21, 2017 8:21:32 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Mar 20, 2017, at 4:46 PM, Douglas Ezra Morrison
>><dmorrison01 at ucla.edu> wrote:
>>>
>>> Dear R-Help readers,
>>>
>>> I am writing to ask about some behavior of base::dimnames() that
>>surprised
>>> me. If I create an array with one of its dimensions = 1, and then try
>>to
>>> assign names to that dimension, I get an error unless I name one of
>>the
>>> other dimensions first. For example:
>>>
>>>> temp1 = array(NA, c(3,2,1))
>>>> dimnames(temp1)[[3]] = "test"
>>>
>>> results in the error: "Error in dimnames(temp1)[[3]] = "test" :
>>'dimnames'
>>> must be a list"
>>>
>>> However, the following works:
>>>
>>>> temp1 = array(NA, c(3,2,1))
>>
>>Why not:
>>
>>temp1 = array(NA, c(3,2,1))
>>dimnames(temp1) <- list(NULL,NULL,"test")
>>
>>
>>>> dimnames(temp1)[[2]] = c("a","b")
>>>> dimnames(temp1)[[3]] = "test"
>>>
>>> I found an explanation of what is happening on stackoverflow (
>>>
>>http://stackoverflow.com/questions/12578461/r-dimnames-of-matrix-strange-behaviour/42915723),
>>> however, I didn't see any explanation of why this behavior is
>>> intended/desirable. Moreover, it recently caused a problem in a place
>>where
>>> I couldn't easily work around it, without submitting edits to or
>>forking
>>> someone else's R package. Is there any possibility that this behavior
>>is a
>>> bug that could be fixed, or is it something I should learn to live
>>with?
>>
>>I doubt that a request for changing the behavior of the `dimnames.<-`
>>function will get very far. Learn to use the language as it's designed.
>>
>>David.
>>
>>>
>>> Thanks,
>>> Doug
>>>
>>> --
>>>
>>> Typed from a mobile device - apologies for typos and brevity.
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>David Winsemius
>>Alameda, CA, USA
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Mar 21 18:02:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Mar 2017 10:02:40 -0700
Subject: [R] assigning dimnames to arrays
In-Reply-To: <CAF8bMcbymgYiR1S+_exA2MWaAhTJfFTZ+gN_4UGcxam50g8DeA@mail.gmail.com>
References: <CAKuzz_Wjk61Z3DMZtcZJtgmAGB1rTY2HxnOJcFVanNQxFPuYGw@mail.gmail.com>
	<2A0DC5F3-1B9D-4879-9170-9B1D53AFE9DE@comcast.net>
	<A7CBA650-C59A-4BD2-A1C4-4AEE40F8B9AA@dcn.davis.ca.us>
	<CAF8bMcbymgYiR1S+_exA2MWaAhTJfFTZ+gN_4UGcxam50g8DeA@mail.gmail.com>
Message-ID: <6AC6DE98-6D91-4340-AE28-50F5E1F7281D@dcn.davis.ca.us>

Thanks,  Bill.

Sooo... taking the error literally, 

temp1 = array(NA, c(3,2,1))
dimnames(temp1)[[3]] = list( "test" )

works, even though

mode( dimnames(temp1)[[3]] )

yields

"character".

Setting all the dimension names simultaneously still feels way better.
-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2017 9:40:55 AM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>It happens because dimnames(originalArray) is NULL and when [[<-
>extends
>NULL it turns it into a list if the size of the new element is not one
>but into a vector with the type of new element if the new element's
>size is one.
>  > str( `[[<-`(NULL, 3, value="One") )
>   chr [1:3] NA NA "One"
>  > str( `[[<-`(NULL, 3, value=c("One","Two") ))
>  List of 3
>   $ : NULL
>   $ : NULL
>   $ : chr [1:2] "One" "Two"
>  > str( `[[<-`(NULL, 3, value=character(0) ))
>  List of 3
>   $ : NULL
>   $ : NULL
>   $ : chr(0)
>dimnames(x) <- characterVector could be changed to call as.list() on
>its right hand side.  That would help in this case but would cover up
>usage errors in other cases.
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Tue, Mar 21, 2017 at 9:29 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> While I generally agree that it is better to design code that sets
>all of the dimension names simultaneously, the discrepancy between
>behavior when the dimensions are longer than 1 and when they are equal
>to 1 seems irregular. Someone went to some lengths to make it possible
>to set dimnames individually "most" of the time and it is not clear to
>me why they stopped short of all the time.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 21, 2017 8:21:32 AM PDT, David Winsemius
><dwinsemius at comcast.net> wrote:
>>>
>>>> On Mar 20, 2017, at 4:46 PM, Douglas Ezra Morrison
>>><dmorrison01 at ucla.edu> wrote:
>>>>
>>>> Dear R-Help readers,
>>>>
>>>> I am writing to ask about some behavior of base::dimnames() that
>>>surprised
>>>> me. If I create an array with one of its dimensions = 1, and then
>try
>>>to
>>>> assign names to that dimension, I get an error unless I name one of
>>>the
>>>> other dimensions first. For example:
>>>>
>>>>> temp1 = array(NA, c(3,2,1))
>>>>> dimnames(temp1)[[3]] = "test"
>>>>
>>>> results in the error: "Error in dimnames(temp1)[[3]] = "test" :
>>>'dimnames'
>>>> must be a list"
>>>>
>>>> However, the following works:
>>>>
>>>>> temp1 = array(NA, c(3,2,1))
>>>
>>>Why not:
>>>
>>>temp1 = array(NA, c(3,2,1))
>>>dimnames(temp1) <- list(NULL,NULL,"test")
>>>
>>>
>>>>> dimnames(temp1)[[2]] = c("a","b")
>>>>> dimnames(temp1)[[3]] = "test"
>>>>
>>>> I found an explanation of what is happening on stackoverflow (
>>>>
>>>http://stackoverflow.com/questions/12578461/r-dimnames-of-matrix-strange-behaviour/42915723),
>>>> however, I didn't see any explanation of why this behavior is
>>>> intended/desirable. Moreover, it recently caused a problem in a
>place
>>>where
>>>> I couldn't easily work around it, without submitting edits to or
>>>forking
>>>> someone else's R package. Is there any possibility that this
>behavior
>>>is a
>>>> bug that could be fixed, or is it something I should learn to live
>>>with?
>>>
>>>I doubt that a request for changing the behavior of the `dimnames.<-`
>>>function will get very far. Learn to use the language as it's
>designed.
>>>
>>>David.
>>>
>>>>
>>>> Thanks,
>>>> Doug
>>>>
>>>> --
>>>>
>>>> Typed from a mobile device - apologies for typos and brevity.
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>David Winsemius
>>>Alameda, CA, USA
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From SWay at meco.com  Tue Mar 21 21:32:27 2017
From: SWay at meco.com (Shawn Way)
Date: Tue, 21 Mar 2017 20:32:27 +0000
Subject: [R] Data and Variables from Tables
Message-ID: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>

I have an org-mode table with the following structure that I am pulling into an R data.frame, using the sfsmisc package and using xtable to print in org-mode

| Symbol | Value | Units               |
|----------+-------+-------------------|
| A             |         1 | kg/hr                    |
| \beta    |         2 | \frac{m^3}{hr} |
| G            |     .25 | in                           |

This all works well and looks great.

What I am trying to do is use this to generate variables for programming as well.  For example, when processed I would have the following variables:

A <- 1
beta <- 2
G <- .25

Has anyone done something like this or can someone point me in the right direction to do this?



Shawn Way

???


From profjcnash at gmail.com  Tue Mar 21 22:18:48 2017
From: profjcnash at gmail.com (J C Nash)
Date: Tue, 21 Mar 2017 17:18:48 -0400
Subject: [R] nlmrt problems - No confInt, NA StdErr, t-, or p-values
In-Reply-To: <MWHPR08MB260833ED6F4D67A0014B929CA03D0@MWHPR08MB2608.namprd08.prod.outlook.com>
References: <MWHPR08MB260833ED6F4D67A0014B929CA03D0@MWHPR08MB2608.namprd08.prod.outlook.com>
Message-ID: <998aab8c-ad7d-5ccf-39f5-58bb07c503c7@gmail.com>

Note that the recently released package nlsr by Duncan Murdoch and I has a slight update in the functions nlxb() and 
nlfb() as well as a lot of features for symbolic derivative calculation.

JN

On 2017-03-21 06:57 AM, DANIEL PRECIADO wrote:
> Dear list,
>
> I want to use nlxb (package nlmrt) to fit different datasets to a gaussian, obtain parameters (including standard error, t-and p-value) and confidence intervals.
>
> nlxb generates the parameters, but very often results in NA standard error,t-and p-values. Furthermore, using confint() to obtain the confidence intervals generates a : Error in vcov.default(object) :   object does not have variance-covariance matrix" erro.
>
> Can someone indicate why is nlxb generating NAs (when nls has no problem with them) and how to obtain confidence intervals from an nlmrt object?
>
> Thanks
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From es at enricoschumann.net  Tue Mar 21 22:39:38 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 21 Mar 2017 22:39:38 +0100
Subject: [R] Data and Variables from Tables
In-Reply-To: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>
	(Shawn Way's message of "Tue, 21 Mar 2017 20:32:27 +0000")
References: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <87inn2l36t.fsf@enricoschumann.net>

On Tue, 21 Mar 2017, Shawn Way writes:

> I have an org-mode table with the following structure
> that I am pulling into an R data.frame, using the
> sfsmisc package and using xtable to print in org-mode
>
> | Symbol | Value | Units               |
> |----------+-------+-------------------|
> | A             |         1 | kg/hr                    |
> | \beta    |         2 | \frac{m^3}{hr} |
> | G            |     .25 | in                           |
>
> This all works well and looks great.
>
> What I am trying to do is use this to generate
> variables for programming as well.  For example, when
> processed I would have the following variables:
>
> A <- 1
> beta <- 2
> G <- .25
>
> Has anyone done something like this or can someone
> point me in the right direction to do this?
>
> Shawn Way
>

You may be looking for ?assign.

  df <- data.frame(Symbol = c("A", "\\beta",  "G"),
                   Value  = c(  1,        2, 0.25))
  
  ## remove backslashes
  df[["Symbol"]] <- gsub("\\", "", df[["Symbol"]], fixed = TRUE)
  
  for (i in seq_len(nrow(df)))
      assign(df[i, "Symbol"], df[i, "Value"])
  
But depending on what you want to do, it may be
cleaner/safer to keep the variables from the table
together in a list.

    tbl <- as.list(df[["Value"]])
    names(tbl) <- df[["Symbol"]]

    ## $A
    ## [1] 1
    ## 
    ## $beta
    ## [1] 2
    ## 
    ## $G
    ## [1] 0.25


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From SWay at meco.com  Tue Mar 21 23:18:38 2017
From: SWay at meco.com (Shawn Way)
Date: Tue, 21 Mar 2017 22:18:38 +0000
Subject: [R] Data and Variables from Tables
In-Reply-To: <87inn2l36t.fsf@enricoschumann.net>
References: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>
	<87inn2l36t.fsf@enricoschumann.net>
Message-ID: <3eef58c38d0647a8a675af47db10e94a@CTC-HOU-EXMB-02.ctcloud.local>

That worked perfectly!

This makes using a large number of values for programming and their documentation significantly easier.

Thank you

Shawn Way, PE

-----Original Message-----
From: Enrico Schumann [mailto:es at enricoschumann.net] 
Sent: Tuesday, March 21, 2017 4:40 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] Data and Variables from Tables

On Tue, 21 Mar 2017, Shawn Way writes:

> I have an org-mode table with the following structure that I am 
> pulling into an R data.frame, using the sfsmisc package and using 
> xtable to print in org-mode
>
> | Symbol | Value | Units               |
> |----------+-------+-------------------|
> | A             |         1 | kg/hr                    |
> | \beta    |         2 | \frac{m^3}{hr} |
> | G            |     .25 | in                           |
>
> This all works well and looks great.
>
> What I am trying to do is use this to generate variables for 
> programming as well.  For example, when processed I would have the 
> following variables:
>
> A <- 1
> beta <- 2
> G <- .25
>
> Has anyone done something like this or can someone point me in the 
> right direction to do this?
>
> Shawn Way
>

You may be looking for ?assign.

  df <- data.frame(Symbol = c("A", "\\beta",  "G"),
                   Value  = c(  1,        2, 0.25))
  
  ## remove backslashes
  df[["Symbol"]] <- gsub("\\", "", df[["Symbol"]], fixed = TRUE)
  
  for (i in seq_len(nrow(df)))
      assign(df[i, "Symbol"], df[i, "Value"])
  
But depending on what you want to do, it may be cleaner/safer to keep the variables from the table together in a list.

    tbl <- as.list(df[["Value"]])
    names(tbl) <- df[["Symbol"]]

    ## $A
    ## [1] 1
    ## 
    ## $beta
    ## [1] 2
    ## 
    ## $G
    ## [1] 0.25


--
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jdnewmil at dcn.davis.ca.us  Tue Mar 21 23:39:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Mar 2017 15:39:44 -0700
Subject: [R] Data and Variables from Tables
In-Reply-To: <3eef58c38d0647a8a675af47db10e94a@CTC-HOU-EXMB-02.ctcloud.local>
References: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>
	<87inn2l36t.fsf@enricoschumann.net>
	<3eef58c38d0647a8a675af47db10e94a@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <8DEDE7EA-D5B4-41FF-8B01-28660A729CDB@dcn.davis.ca.us>

He offered two solutions, and I want to second the vote against the first one. 

I often put large numbers of configuration variables in a few CSV files organized by topic area and read them in. The resulting data frames are capable of holding multiple cases if desired and I just specify which case (row) I am interested in using and pass around 1-row data frames to the computation functions.
-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2017 3:18:38 PM PDT, Shawn Way <SWay at meco.com> wrote:
>That worked perfectly!
>
>This makes using a large number of values for programming and their
>documentation significantly easier.
>
>Thank you
>
>Shawn Way, PE
>
>-----Original Message-----
>From: Enrico Schumann [mailto:es at enricoschumann.net] 
>Sent: Tuesday, March 21, 2017 4:40 PM
>To: Shawn Way <SWay at meco.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Data and Variables from Tables
>
>On Tue, 21 Mar 2017, Shawn Way writes:
>
>> I have an org-mode table with the following structure that I am 
>> pulling into an R data.frame, using the sfsmisc package and using 
>> xtable to print in org-mode
>>
>> | Symbol | Value | Units               |
>> |----------+-------+-------------------|
>> | A             |         1 | kg/hr                    |
>> | \beta    |         2 | \frac{m^3}{hr} |
>> | G            |     .25 | in                           |
>>
>> This all works well and looks great.
>>
>> What I am trying to do is use this to generate variables for 
>> programming as well.  For example, when processed I would have the 
>> following variables:
>>
>> A <- 1
>> beta <- 2
>> G <- .25
>>
>> Has anyone done something like this or can someone point me in the 
>> right direction to do this?
>>
>> Shawn Way
>>
>
>You may be looking for ?assign.
>
>  df <- data.frame(Symbol = c("A", "\\beta",  "G"),
>                   Value  = c(  1,        2, 0.25))
>  
>  ## remove backslashes
>  df[["Symbol"]] <- gsub("\\", "", df[["Symbol"]], fixed = TRUE)
>  
>  for (i in seq_len(nrow(df)))
>      assign(df[i, "Symbol"], df[i, "Value"])
>  
>But depending on what you want to do, it may be cleaner/safer to keep
>the variables from the table together in a list.
>
>    tbl <- as.list(df[["Value"]])
>    names(tbl) <- df[["Symbol"]]
>
>    ## $A
>    ## [1] 1
>    ## 
>    ## $beta
>    ## [1] 2
>    ## 
>    ## $G
>    ## [1] 0.25
>
>
>--
>Enrico Schumann
>Lucerne, Switzerland
>http://enricoschumann.net
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joeceradini at gmail.com  Wed Mar 22 00:50:15 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Tue, 21 Mar 2017 17:50:15 -0600
Subject: [R] string pattern matching
Message-ID: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>

Hi Folks,

Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
Or is that a ridiculous question, since I'm trying to find something
based on a pattern that doesn't exist?

test <- c("x1", "x2", "x3", "x1 + x2 + x3")
test
[1] "x1"           "x2"           "x3"           "x1 + x2 + x3"

grep("x1 + x2", test, fixed=TRUE, value = TRUE)
[1] "x1 + x2 + x3"


But what if only have "x1 + x3" as the pattern and still want to
return "x1 + x2 + x3"?

grep("x1 + x3", test, fixed=TRUE, value = TRUE)
character(0)

I'm sure this looks like an odd question. I'm trying to build a
function and stuck on this. Rather than dropping the whole function on
the list, I thought I'd try one piece I needed help with...although I
suspect that this question itself probably does bode well for my
function :)

Thanks!
Joe


From drjimlemon at gmail.com  Wed Mar 22 01:43:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 22 Mar 2017 11:43:10 +1100
Subject: [R] string pattern matching
In-Reply-To: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
Message-ID: <CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>

Hi Joe,
This may help you:

test <- c("x1", "x2", "x3", "x1 + x2 + x3")
multigrep<-function(x1,x2) {
 xbits<-unlist(strsplit(x1," "))
 nbits<-length(xbits)
 xans<-rep(FALSE,nbits)
 for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
 return(all(xans))
}
multigrep("x1 + x3","x1 + x2 + x3")
[1] TRUE
multigrep("x1 + x4","x1 + x2 + x3")
[1] FALSE

Jim

On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Hi Folks,
>
> Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
> Or is that a ridiculous question, since I'm trying to find something
> based on a pattern that doesn't exist?
>
> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> test
> [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>
> grep("x1 + x2", test, fixed=TRUE, value = TRUE)
> [1] "x1 + x2 + x3"
>
>
> But what if only have "x1 + x3" as the pattern and still want to
> return "x1 + x2 + x3"?
>
> grep("x1 + x3", test, fixed=TRUE, value = TRUE)
> character(0)
>
> I'm sure this looks like an odd question. I'm trying to build a
> function and stuck on this. Rather than dropping the whole function on
> the list, I thought I'd try one piece I needed help with...although I
> suspect that this question itself probably does bode well for my
> function :)
>
> Thanks!
> Joe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Mar 22 02:31:59 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 21 Mar 2017 18:31:59 -0700
Subject: [R] string pattern matching
In-Reply-To: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
Message-ID: <CAGxFJbQBmek4zaub1BQ49T0+gQAn1SvyHD8bVsfM9RczEvO6KA@mail.gmail.com>

It is not clear to me what you mean, but:

> grep ("x1 \\+.* \\+ x3",test, value = TRUE)
[1] "x1 + x2 + x3"

## This will miss "x1 + x3" though.

seems to do what you want, maybe. Perhaps you need to read up about
regular expressions and/or clarify what you want to do.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 21, 2017 at 4:50 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Hi Folks,
>
> Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
> Or is that a ridiculous question, since I'm trying to find something
> based on a pattern that doesn't exist?
>
> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> test
> [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>
> grep("x1 + x2", test, fixed=TRUE, value = TRUE)
> [1] "x1 + x2 + x3"
>
>
> But what if only have "x1 + x3" as the pattern and still want to
> return "x1 + x2 + x3"?
>
> grep("x1 + x3", test, fixed=TRUE, value = TRUE)
> character(0)
>
> I'm sure this looks like an odd question. I'm trying to build a
> function and stuck on this. Rather than dropping the whole function on
> the list, I thought I'd try one piece I needed help with...although I
> suspect that this question itself probably does bode well for my
> function :)
>
> Thanks!
> Joe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Mar 22 04:29:01 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Mar 2017 20:29:01 -0700
Subject: [R] string pattern matching
In-Reply-To: <CAGxFJbQBmek4zaub1BQ49T0+gQAn1SvyHD8bVsfM9RczEvO6KA@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CAGxFJbQBmek4zaub1BQ49T0+gQAn1SvyHD8bVsfM9RczEvO6KA@mail.gmail.com>
Message-ID: <95A25FB7-B9CC-4F58-BD33-DC30144B8471@comcast.net>


> On Mar 21, 2017, at 6:31 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> It is not clear to me what you mean, but:
> 
>> grep ("x1 \\+.* \\+ x3",test, value = TRUE)
> [1] "x1 + x2 + x3"
> 
> ## This will miss "x1 + x3" though.

So then this might be acceptable:

grep ("x1\\ \\+.* x3", test, value = TRUE)


> 
> seems to do what you want, maybe. Perhaps you need to read up about
> regular expressions and/or clarify what you want to do.
> 
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Mar 21, 2017 at 4:50 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>> Hi Folks,
>> 
>> Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
>> Or is that a ridiculous question, since I'm trying to find something
>> based on a pattern that doesn't exist?
>> 
>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>> test
>> [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>> 
>> grep("x1 + x2", test, fixed=TRUE, value = TRUE)
>> [1] "x1 + x2 + x3"
>> 
>> 
>> But what if only have "x1 + x3" as the pattern and still want to
>> return "x1 + x2 + x3"?
>> 
>> grep("x1 + x3", test, fixed=TRUE, value = TRUE)
>> character(0)
>> 
>> I'm sure this looks like an odd question. I'm trying to build a
>> function and stuck on this. Rather than dropping the whole function on
>> the list, I thought I'd try one piece I needed help with...although I
>> suspect that this question itself probably does bode well for my
>> function :)
>> 
>> Thanks!
>> Joe
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Mar 22 04:30:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Mar 2017 20:30:48 -0700
Subject: [R] Using betareg package to fit beta mixture with given
	initial parameters
In-Reply-To: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
References: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
Message-ID: <6F5A6F09-470D-4D9B-ACC3-90E121F891DA@comcast.net>


> On Mar 21, 2017, at 5:04 AM, Michael Dayan <mdayan.research at gmail.com> wrote:
> 
> Hi,
> 
> I would like to fit a mixture of two beta distributions with parameters
> (alpha1, beta1) for the first component, (alpha2, beta2) for the second
> component, and lambda for the mixing parameter. I also would like to set a
> maximum of 200 iterations and a tolerance of 1e-08.
> 
> My question is: how to use the betareg package to run the fit with initial
> values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw in
> the documentation that I would need to use the 'start' option of the
> betareg function, with start described as "an optional vector with starting
> values for all parameters (including phi)". However I could not find how to
> define this list given my alpha1, beta1, alpha2, beta2 and lambda.
> 
> The current code I have is:
> mydata$y <- <my_data>
> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> 200, fsmaxit = 200)
> 
> 
> And I suspect I would need to do something along the lines:
> 
> initial.vals <- c(?, ?, ?, ?, ?)
> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> 200, fsmaxit = 200, control=betareg.control(start=initial.vals)))
> 
> But I do not know what to use for initial.vals.

If there were sensitivity to data, then wouldn't  that depend on your (unprovided) data?


> 
> Best wishes,
> 
> Michael
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ulrik.stervbo at gmail.com  Wed Mar 22 07:22:36 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 22 Mar 2017 06:22:36 +0000
Subject: [R] string pattern matching
In-Reply-To: <CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
Message-ID: <CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>

Hi Joe,

you could also rethink your pattern:

grep("x1 \\+ x2", test, value = TRUE)

grep("x1 \\+ x", test, value = TRUE)

grep("x1 \\+ x[0-9]", test, value = TRUE)

HTH
Ulrik

On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Joe,
> This may help you:
>
> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> multigrep<-function(x1,x2) {
>  xbits<-unlist(strsplit(x1," "))
>  nbits<-length(xbits)
>  xans<-rep(FALSE,nbits)
>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
>  return(all(xans))
> }
> multigrep("x1 + x3","x1 + x2 + x3")
> [1] TRUE
> multigrep("x1 + x4","x1 + x2 + x3")
> [1] FALSE
>
> Jim
>
> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> > Hi Folks,
> >
> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
> > Or is that a ridiculous question, since I'm trying to find something
> > based on a pattern that doesn't exist?
> >
> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> > test
> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
> >
> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
> > [1] "x1 + x2 + x3"
> >
> >
> > But what if only have "x1 + x3" as the pattern and still want to
> > return "x1 + x2 + x3"?
> >
> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
> > character(0)
> >
> > I'm sure this looks like an odd question. I'm trying to build a
> > function and stuck on this. Rather than dropping the whole function on
> > the list, I thought I'd try one piece I needed help with...although I
> > suspect that this question itself probably does bode well for my
> > function :)
> >
> > Thanks!
> > Joe
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mdayan.research at gmail.com  Wed Mar 22 07:26:40 2017
From: mdayan.research at gmail.com (Michael Dayan)
Date: Wed, 22 Mar 2017 07:26:40 +0100
Subject: [R] Using betareg package to fit beta mixture with given
	initial parameters
In-Reply-To: <CAK8FaMM=foAEbtzuf6Tj9Gzj9akuVdi87UDOiA1WTeNBtQxHZg@mail.gmail.com>
References: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
	<6F5A6F09-470D-4D9B-ACC3-90E121F891DA@comcast.net>
	<CAK8FaMM=foAEbtzuf6Tj9Gzj9akuVdi87UDOiA1WTeNBtQxHZg@mail.gmail.com>
Message-ID: <CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>

The method of setting the initial values given lambda, alpha1, etc. should
not depend on the exact values of lambda, alpha1, etc. in my situation,
i.e. it does not depend on my data.

On Mar 22, 2017 04:30, "David Winsemius" <dwinsemius at comcast.net> wrote:


> On Mar 21, 2017, at 5:04 AM, Michael Dayan <mdayan.research at gmail.com>
wrote:
>
> Hi,
>
> I would like to fit a mixture of two beta distributions with parameters
> (alpha1, beta1) for the first component, (alpha2, beta2) for the second
> component, and lambda for the mixing parameter. I also would like to set a
> maximum of 200 iterations and a tolerance of 1e-08.
>
> My question is: how to use the betareg package to run the fit with initial
> values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw
in
> the documentation that I would need to use the 'start' option of the
> betareg function, with start described as "an optional vector with
starting
> values for all parameters (including phi)". However I could not find how
to
> define this list given my alpha1, beta1, alpha2, beta2 and lambda.
>
> The current code I have is:
> mydata$y <- <my_data>
> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> 200, fsmaxit = 200)
>
>
> And I suspect I would need to do something along the lines:
>
> initial.vals <- c(?, ?, ?, ?, ?)
> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> 200, fsmaxit = 200, control=betareg.control(start=initial.vals)))
>
> But I do not know what to use for initial.vals.

If there were sensitivity to data, then wouldn't  that depend on your
(unprovided) data?


>
> Best wishes,
>
> Michael
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Mar 22 11:31:50 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 22 Mar 2017 10:31:50 +0000
Subject: [R] A request
In-Reply-To: <CAMpybKNaPbesMnnypRo_O4D9tok2_Q3khsMGtkSjzFK=N9t50g@mail.gmail.com>
References: <CAMpybKNaPbesMnnypRo_O4D9tok2_Q3khsMGtkSjzFK=N9t50g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1DA93@SRVEXCHCM301.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of RAHUL
> 14BCE0064
> Sent: Monday, March 20, 2017 12:24 PM
> To: r-help at r-project.org
> Subject: [R] A request
>
> Hello there!!
>
> Could somebody please go through the question (
> http://stats.stackexchange.com/questions/268323/string-kernels-in-r)?
>

Page not found so no question to go through.


> In short I need the reference to the algorithms used for string kernels in
> Kernlab package in R.

There are plenty references in docs and if it is still not enough you can go through actual code.

Cheers
Petr


>
>
> Thank you.
>
> Regards:
> Rahul
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Achim.Zeileis at uibk.ac.at  Wed Mar 22 11:34:01 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 22 Mar 2017 11:34:01 +0100 (CET)
Subject: [R] Using betareg package to fit beta mixture with given
 initial parameters
In-Reply-To: <CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>
References: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
	<6F5A6F09-470D-4D9B-ACC3-90E121F891DA@comcast.net>
	<CAK8FaMM=foAEbtzuf6Tj9Gzj9akuVdi87UDOiA1WTeNBtQxHZg@mail.gmail.com>
	<CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1703221122410.13640@paninaro>

On Wed, 22 Mar 2017, Michael Dayan wrote:

> The method of setting the initial values given lambda, alpha1, etc. should
> not depend on the exact values of lambda, alpha1, etc. in my situation,
> i.e. it does not depend on my data.

Presently, flexmix() that betamix() is built on cannot take the parameters 
directly for initialization. However, it is possible to pass a matrix with 
initial 'cluster' probabilities. This can be easily generated using 
dbeta().

For a concrete example consider the data generated in this discussion on 
SO:

http://stats.stackexchange.com/questions/114959/mixture-of-beta-distributions-full-example

Using that data with random starting values requires 42 iterations until 
convergence:

set.seed(0)
m1 <- betamix(y ~ 1 | 1, data = d, k = 2)
m1

## Call:
## betamix(formula = y ~ 1 | 1, data = d, k = 2)
## 
## Cluster sizes:
##   1   2
##  50 100
## 
## convergence after 42 iterations

Instead we could initialize with the posterior probabilities obtained at 
the observed data (d$y), the true alpha/beta parameters (10; 30 vs. 30; 
10) and the true cluster proportions (2/3 vs. 1/3):

p <- cbind(2/3 * dbeta(d$y, 10, 30), 1/3 * dbeta(d$y, 30, 10))
p <- p/rowSums(p)

This converges after only 2 iterations:

set.seed(0)
m2 <- betamix(y ~ 1 | 1, data = d, k = 2, cluster = p)
m2

## Call:
## betamix(formula = y ~ 1 | 1, data = d, k = 2, cluster = p)
## 
## Cluster sizes:
##   1   2
## 100  50
## 
## convergence after 2 iterations

Up to label switching and small numerical differences, the parameter 
estimates agree. (Of course, these are on the mu/phi scale and not 
alpha/beta as explained in the SO post linked above.)

coef(m1)
##        (Intercept) (phi)_(Intercept)
## Comp.1    1.196286          3.867808
## Comp.2   -1.096487          3.898976
coef(m2)
##        (Intercept) (phi)_(Intercept)
## Comp.1   -1.096487          3.898976
## Comp.2    1.196286          3.867808


> On Mar 22, 2017 04:30, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>
>> On Mar 21, 2017, at 5:04 AM, Michael Dayan <mdayan.research at gmail.com>
> wrote:
>>
>> Hi,
>>
>> I would like to fit a mixture of two beta distributions with parameters
>> (alpha1, beta1) for the first component, (alpha2, beta2) for the second
>> component, and lambda for the mixing parameter. I also would like to set a
>> maximum of 200 iterations and a tolerance of 1e-08.
>>
>> My question is: how to use the betareg package to run the fit with initial
>> values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw
> in
>> the documentation that I would need to use the 'start' option of the
>> betareg function, with start described as "an optional vector with
> starting
>> values for all parameters (including phi)". However I could not find how
> to
>> define this list given my alpha1, beta1, alpha2, beta2 and lambda.
>>
>> The current code I have is:
>> mydata$y <- <my_data>
>> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
>> 200, fsmaxit = 200)
>>
>>
>> And I suspect I would need to do something along the lines:
>>
>> initial.vals <- c(?, ?, ?, ?, ?)
>> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
>> 200, fsmaxit = 200, control=betareg.control(start=initial.vals)))
>>
>> But I do not know what to use for initial.vals.
>
> If there were sensitivity to data, then wouldn't  that depend on your
> (unprovided) data?
>
>
>>
>> Best wishes,
>>
>> Michael
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dileepkunjaai at gmail.com  Wed Mar 22 11:56:48 2017
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Wed, 22 Mar 2017 16:26:48 +0530
Subject: [R] Extracting Monthly timeseries data for a defined period using
	ncdf4 package
Message-ID: <CALTF6skK3cj3z-Ez-qtN9q1LuL9D74wY1=E4JQjRcYzxr5aisA@mail.gmail.com>

Dear All,

I am trying to extract a time series dataset from a netCDF file.

I want to extract data for the time period  1971-1  to 1990-12-31 only.

time axis units is  'days since 1850-1-1'

For one or two files I can use "count" argument,  but I have more than 100
such files and its time units are different.

Is there any easy way to extract the particular time period using ncdf4
package?

Thank you in advance.


-- 
DILEEPKUMAR. R
J R F, IIT DELHI

	[[alternative HTML version deleted]]


From swbueno at gmail.com  Wed Mar 22 13:43:57 2017
From: swbueno at gmail.com (Santiago Bueno)
Date: Wed, 22 Mar 2017 08:43:57 -0400
Subject: [R] Using betareg package to fit beta mixture with given
	initial parameters
In-Reply-To: <CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>
References: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
	<6F5A6F09-470D-4D9B-ACC3-90E121F891DA@comcast.net>
	<CAK8FaMM=foAEbtzuf6Tj9Gzj9akuVdi87UDOiA1WTeNBtQxHZg@mail.gmail.com>
	<CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>
Message-ID: <CAGfmZu69XdyTcr3YoCcgUC7hQCr9qjekMo62u6xORhZgSZu2Mg@mail.gmail.com>

Tree dbh haut Btot
1 35.00 18.90 0.357
2 25.00 16.60 0.214
3 23.00 19.50 0.173
4 13.50 15.60 0.060
5 20.00 18.80 0.134
6 23.00 17.40 0.137
7 29.00 19.90 0.428
8 17.60 18.20 0.100
9 31.00 25.30 0.514
10 26.00 23.50 0.273
11 13.00 13.00 0.031
12 32.00 20.70 0.356
13 28.00 28.50 0.349
14 15.00 18.20 0.068
15 19.00 14.90 0.110
16 33.00 14.90 0.260
17 24.00 19.10 0.160
18 22.00 19.20 0.204
19 39.00 25.20 0.724
20 30.00 26.60 0.386
Hello dear all:

I am using above data to run the following code;

library(nlme)

start <- coef(lm(Btot~I(dbh**2*haut),data=dat))

names(start) <- c("a","b")

model1 <-(nlme (Btot~a+b*dbh**2*haut, data=cbind(dat, g="a"), fixed=a+b~1,
start=start,

groups=~g, weights=varPower(form=~dbh)))


I get regression parameters with the intercept being non-significant.
Therefore, I run the following code to obtain an equation without
intercept..


summary(nlme(Btot~b*dbh**2*haut, data=cbind(dat,g="a"), fixed=b~1,
start=start["b"], groups=~g, weights=varPower(form=~dbh)))


When I do run the last code, I get the following error:


Error in nlme.formula(Btot ~ b * dbh**2 * haut, data = cbind(dat, g = "a"),
 :

  step halving factor reduced below minimum in PNLS step

Can someone help??


Best regards,

Santiago

On Wed, Mar 22, 2017 at 2:26 AM, Michael Dayan <mdayan.research at gmail.com>
wrote:

> The method of setting the initial values given lambda, alpha1, etc. should
> not depend on the exact values of lambda, alpha1, etc. in my situation,
> i.e. it does not depend on my data.
>
> On Mar 22, 2017 04:30, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>
> > On Mar 21, 2017, at 5:04 AM, Michael Dayan <mdayan.research at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I would like to fit a mixture of two beta distributions with parameters
> > (alpha1, beta1) for the first component, (alpha2, beta2) for the second
> > component, and lambda for the mixing parameter. I also would like to set
> a
> > maximum of 200 iterations and a tolerance of 1e-08.
> >
> > My question is: how to use the betareg package to run the fit with
> initial
> > values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw
> in
> > the documentation that I would need to use the 'start' option of the
> > betareg function, with start described as "an optional vector with
> starting
> > values for all parameters (including phi)". However I could not find how
> to
> > define this list given my alpha1, beta1, alpha2, beta2 and lambda.
> >
> > The current code I have is:
> > mydata$y <- <my_data>
> > bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> > 200, fsmaxit = 200)
> >
> >
> > And I suspect I would need to do something along the lines:
> >
> > initial.vals <- c(?, ?, ?, ?, ?)
> > bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
> > 200, fsmaxit = 200, control=betareg.control(start=initial.vals)))
> >
> > But I do not know what to use for initial.vals.
>
> If there were sensitivity to data, then wouldn't  that depend on your
> (unprovided) data?
>
>
> >
> > Best wishes,
> >
> > Michael
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From SWay at meco.com  Wed Mar 22 14:06:43 2017
From: SWay at meco.com (Shawn Way)
Date: Wed, 22 Mar 2017 13:06:43 +0000
Subject: [R] Data and Variables from Tables
In-Reply-To: <8DEDE7EA-D5B4-41FF-8B01-28660A729CDB@dcn.davis.ca.us>
References: <445313496e4e4261bfe20bc7b422635f@CTC-HOU-EXMB-02.ctcloud.local>
	<87inn2l36t.fsf@enricoschumann.net>
	<3eef58c38d0647a8a675af47db10e94a@CTC-HOU-EXMB-02.ctcloud.local>
	<8DEDE7EA-D5B4-41FF-8B01-28660A729CDB@dcn.davis.ca.us>
Message-ID: <0f273e9a242f4ac2a0f1e73d7977aac8@CTC-HOU-EXMB-02.ctcloud.local>

I implemented the second as well.  It was much easier to create a function to automate this as well as assign  the results to a single data.frame

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, March 21, 2017 5:40 PM
To: r-help at r-project.org; Shawn Way <SWay at meco.com>; Enrico Schumann <es at enricoschumann.net>
Cc: r-help at r-project.org
Subject: Re: [R] Data and Variables from Tables

He offered two solutions, and I want to second the vote against the first one. 

I often put large numbers of configuration variables in a few CSV files organized by topic area and read them in. The resulting data frames are capable of holding multiple cases if desired and I just specify which case (row) I am interested in using and pass around 1-row data frames to the computation functions.
--
Sent from my phone. Please excuse my brevity.

On March 21, 2017 3:18:38 PM PDT, Shawn Way <SWay at meco.com> wrote:
>That worked perfectly!
>
>This makes using a large number of values for programming and their 
>documentation significantly easier.
>
>Thank you
>
>Shawn Way, PE
>
>-----Original Message-----
>From: Enrico Schumann [mailto:es at enricoschumann.net]
>Sent: Tuesday, March 21, 2017 4:40 PM
>To: Shawn Way <SWay at meco.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Data and Variables from Tables
>
>On Tue, 21 Mar 2017, Shawn Way writes:
>
>> I have an org-mode table with the following structure that I am 
>> pulling into an R data.frame, using the sfsmisc package and using 
>> xtable to print in org-mode
>>
>> | Symbol | Value | Units               |
>> |----------+-------+-------------------|
>> | A             |         1 | kg/hr                    |
>> | \beta    |         2 | \frac{m^3}{hr} |
>> | G            |     .25 | in                           |
>>
>> This all works well and looks great.
>>
>> What I am trying to do is use this to generate variables for 
>> programming as well.  For example, when processed I would have the 
>> following variables:
>>
>> A <- 1
>> beta <- 2
>> G <- .25
>>
>> Has anyone done something like this or can someone point me in the 
>> right direction to do this?
>>
>> Shawn Way
>>
>
>You may be looking for ?assign.
>
>  df <- data.frame(Symbol = c("A", "\\beta",  "G"),
>                   Value  = c(  1,        2, 0.25))
>  
>  ## remove backslashes
>  df[["Symbol"]] <- gsub("\\", "", df[["Symbol"]], fixed = TRUE)
>  
>  for (i in seq_len(nrow(df)))
>      assign(df[i, "Symbol"], df[i, "Value"])
>  
>But depending on what you want to do, it may be cleaner/safer to keep 
>the variables from the table together in a list.
>
>    tbl <- as.list(df[["Value"]])
>    names(tbl) <- df[["Symbol"]]
>
>    ## $A
>    ## [1] 1
>    ## 
>    ## $beta
>    ## [1] 2
>    ## 
>    ## $G
>    ## [1] 0.25
>
>
>--
>Enrico Schumann
>Lucerne, Switzerland
>http://enricoschumann.net
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From joeceradini at gmail.com  Wed Mar 22 14:39:51 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 22 Mar 2017 07:39:51 -0600
Subject: [R] string pattern matching
In-Reply-To: <CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
	<CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
Message-ID: <CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>

Wow. Thanks to everyone (Jim, Ng Bo Lin, Bert, David, and Ulrik) for
all the quick and helpful responses. They have given me a better
understanding of regular expressions, and certainly answered my
question.

Joe

On Wed, Mar 22, 2017 at 12:22 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Joe,
>
> you could also rethink your pattern:
>
> grep("x1 \\+ x2", test, value = TRUE)
>
> grep("x1 \\+ x", test, value = TRUE)
>
> grep("x1 \\+ x[0-9]", test, value = TRUE)
>
> HTH
> Ulrik
>
> On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Joe,
>> This may help you:
>>
>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>> multigrep<-function(x1,x2) {
>>  xbits<-unlist(strsplit(x1," "))
>>  nbits<-length(xbits)
>>  xans<-rep(FALSE,nbits)
>>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
>>  return(all(xans))
>> }
>> multigrep("x1 + x3","x1 + x2 + x3")
>> [1] TRUE
>> multigrep("x1 + x4","x1 + x2 + x3")
>> [1] FALSE
>>
>> Jim
>>
>> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com>
>> wrote:
>> > Hi Folks,
>> >
>> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
>> > Or is that a ridiculous question, since I'm trying to find something
>> > based on a pattern that doesn't exist?
>> >
>> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>> > test
>> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>> >
>> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
>> > [1] "x1 + x2 + x3"
>> >
>> >
>> > But what if only have "x1 + x3" as the pattern and still want to
>> > return "x1 + x2 + x3"?
>> >
>> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
>> > character(0)
>> >
>> > I'm sure this looks like an odd question. I'm trying to build a
>> > function and stuck on this. Rather than dropping the whole function on
>> > the list, I thought I'd try one piece I needed help with...although I
>> > suspect that this question itself probably does bode well for my
>> > function :)
>> >
>> > Thanks!
>> > Joe
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org


From momo820526 at gmail.com  Wed Mar 22 09:11:32 2017
From: momo820526 at gmail.com (=?UTF-8?B?6Kyd5a2f54+C?=)
Date: Wed, 22 Mar 2017 16:11:32 +0800
Subject: [R] r question
Message-ID: <CA+mU4QETQODjx5zir0EUEBs4arhYoWSxYM9DWz3d3heE2uXU0g@mail.gmail.com>

Hi ,I have some question about simulate, I don't know how to paste question
to this website,so I paste below.
I use genoud to find the maximum likelihood value, but when I use numcut=3
,it will get error message,like this " coxph.wtest(fit$var[nabeta, nabeta],
temp, control$toler.chol) : NA/NaN/Inf"
and this is my code
library(rgenoud)
library(survival)
N=500
ei=rexp(N)
censor=rep(1,N)
x1=runif(N)
x2=runif(N)
x3=runif(N)
truecut=c(0.3,0.6)
dum1=1*(x1>truecut[1] & x1<truecut[2])
dum2=1*(x1>truecut[2])
x_true=cbind(dum1,dum2,x2,x3)
relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
beta_true<-relativerisk
Ti=exp(x_true%*%beta_true)*ei
confound=cbind(x2,x3)
initial2<-c(0.09,0.299,0.597,-0.17,-1.3,-3.1,-1.4,-1.12)
numcut=2
 domain2<<-matrix(c(rep(c(0.05,0.95),numcut),rep(c(0,5),numcut+dim(confound)[2])),ncol=2,byrow
= TRUE)

loglikfun <- function(beta, formula) {
  beta1 <- coxph(formula, init = beta,
control=list('iter.max'=0))#iteration is zero
  return(beta1$loglik[2])
}
obj <- function(xx){
  cutoff <- xx[1:numcut_global] #cutpoint
  cut_design <-
cut(target_global,breaks=c(0,sort(cutoff)+seq(0,gap_global*(length(cutoff)-1),by=gap_global),target_max),quantile=FALSE,labels=c(0:numcut_global))
  beta <- -xx[(numcut+1):nvars]  #coefficients of parameters
  logliks <-
loglikfun(beta,Surv(time_global,censor_global)~cut_design+confound_global)
  return(logliks)
}
maxloglik<-function(target,numcut,time,censor,confound,domain2,initial2,gap){
  time_global<<-time
  censor_global<<-censor
  target_global<<-target
  nvars<<-2*numcut+dim(confound)[2]
  confound_global<<-confound
  numcut_global<<-numcut
  target_max<<-max(target)
  gap_global<<-gap
  ccc<-genoud(obj, nvars, max=TRUE, pop.size=100, max.generations=6,
wait.generations=10,
              hard.generation.limit=TRUE, starting.values=initial2,
MemoryMatrix=TRUE,
              Domains=domain2, solution.tolerance=0.001,
              gr=NULL, boundary.enforcement=2, lexical=FALSE,
gradient.check=TRUE)
  ccc$par_corr<-ccc$par #the coefficients of genoud

ccc$par_corr[1:numcut]<-sort(ccc$par[1:numcut])+seq(0,gap_global*(numcut-1),by=gap_global)
#sort cutpoint
  return(ccc)
}


maxloglik(x1,3,Ti,censor,confound,domain2,initial2,0.02)$par_corr

I have no idea about the error ,maybe is my initial is wrong.
thank you
 From Meng-Ke

	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Wed Mar 22 13:15:04 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Wed, 22 Mar 2017 12:15:04 +0000 (UTC)
Subject: [R]  argument to 'which' is not logical
References: <586684963.372211.1490184904525.ref@mail.yahoo.com>
Message-ID: <586684963.372211.1490184904525@mail.yahoo.com>

I'm trying to run the code:?inds<-which(c != 0 ), but it gave me error:?Error in base::which(x, arr.ind, useNames, ...) :?? argument to 'which' is not logical
Here is code:
alphas <- seq(0, 1, by=.002)mses <- numeric(501)mins <- numeric(501)maxes <- numeric(501)for(i in 1:501){? cvfits <- cv.glmnet(Train2, Train$Item_Outlet_Sales, alpha=alphas[i], nfolds=32)? loc <- which(cvfits$lambda==cvfits$lambda.min)? maxes[i] <- cvfits$lambda %>% max? mins[i] <- cvfits$lambda %>% min? mses[i] <- cvfits$cvm[loc]}`%ni%`<-Negate(`%in%`)c<-coef(cvfits,s='lambda.1se',exact=TRUE)inds<-which(c != 0 )
Here is the c content looks like:?> c33 x 1 sparse Matrix of class "dgCMatrix"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1(Intercept) ? ? ? ? ? ? ? ? ? ? ?7.476895931Item_Fat_Content.Low.Fat ? ? ? ? . ? ? ? ? ?Item_Fat_Content.Regular ? ? ? ? . ? ? ? ? ?Item_Type.Breads ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Breakfast ? ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Canned ? ? ? ? ? ? ? ? 0.003430669Item_Type.Dairy ? ? ? ? ? ? ? ? -0.022579673Item_Type.Frozen.Foods ? ? ? ? ?-0.008216547Item_Type.Fruits.and.Vegetables ?. ? ? ? ? ?Item_Type.Hard.Drinks ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Health.and.Hygiene ? ? . ? ? ? ? ?Item_Type.Household ? ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Meat ? ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Others ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Seafood ? ? ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Snack.Foods ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Soft.Drinks ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Starchy.Foods ? ? ? ? ?. ? ? ? ? ?Outlet_Establishment_Year.1987 ?-0.345927916Outlet_Establishment_Year.1997 ? 1.692678186Outlet_Establishment_Year.1998 ?-2.259508290Outlet_Establishment_Year.1999 ? . ? ? ? ? ?Outlet_Establishment_Year.2002 ?-0.032971913Outlet_Establishment_Year.2004 ? 1.756230495Outlet_Establishment_Year.2007 ? . ? ? ? ? ?Outlet_Establishment_Year.2009 ?-0.549210057Outlet_Size.Medium ? ? ? ? ? ? ? 0.056897825Outlet_Size.Small ? ? ? ? ? ? ? -1.706006538Outlet_Location_Type.Tier.3 ? ? ?0.373456218Item_Identifier_CombinedFD ? ? ? . ? ? ? ? ?Item_MRP ? ? ? ? ? ? ? ? ? ? ? ? 0.505435352Item_Weight ? ? ? ? ? ? ? ? ? ? ?. ? ? ? ? ?Item_Visibility_MeanRatio ? ? ? -0.007274202
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 22 15:19:34 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 22 Mar 2017 07:19:34 -0700
Subject: [R] argument to 'which' is not logical
In-Reply-To: <586684963.372211.1490184904525@mail.yahoo.com>
References: <586684963.372211.1490184904525.ref@mail.yahoo.com>
	<586684963.372211.1490184904525@mail.yahoo.com>
Message-ID: <81B8D898-8C72-4510-9BBA-ED323B33E1D6@dcn.davis.ca.us>

The `c` function is extremely common. You CAN redefine this object as a numeric variable if you want but I strongly recommend against it. 

I don't recognize the function you are using to create cvfits, but it looks like the coef method for that object is not returning a numeric vector, so your comparison is with some other kind of object. 

Notice how ugly your code looks below... only you can fix this by setting your email program to send plain text to the mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On March 22, 2017 5:15:04 AM PDT, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
>I'm trying to run the code:?inds<-which(c != 0 ), but it gave me
>error:?Error in base::which(x, arr.ind, useNames, ...) :?? argument to
>'which' is not logical
>Here is code:
>alphas <- seq(0, 1, by=.002)mses <- numeric(501)mins <-
>numeric(501)maxes <- numeric(501)for(i in 1:501){? cvfits <-
>cv.glmnet(Train2, Train$Item_Outlet_Sales, alpha=alphas[i], nfolds=32)?
>loc <- which(cvfits$lambda==cvfits$lambda.min)? maxes[i] <-
>cvfits$lambda %>% max? mins[i] <- cvfits$lambda %>% min? mses[i] <-
>cvfits$cvm[loc]}`%ni%`<-Negate(`%in%`)c<-coef(cvfits,s='lambda.1se',exact=TRUE)inds<-which(c
>!= 0 )
>Here is the c content looks like:?> c33 x 1 sparse Matrix of class
>"dgCMatrix"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1(Intercept) ? ?
>? ? ? ? ? ? ? ? ?7.476895931Item_Fat_Content.Low.Fat ? ? ? ? . ? ? ? ?
>?Item_Fat_Content.Regular ? ? ? ? . ? ? ? ? ?Item_Type.Breads ? ? ? ? ?
>? ? ? . ? ? ? ? ?Item_Type.Breakfast ? ? ? ? ? ? ?. ? ? ? ?
>?Item_Type.Canned ? ? ? ? ? ? ? ? 0.003430669Item_Type.Dairy ? ? ? ? ?
>? ? ? -0.022579673Item_Type.Frozen.Foods ? ? ? ?
>?-0.008216547Item_Type.Fruits.and.Vegetables ?. ? ? ? ?
>?Item_Type.Hard.Drinks ? ? ? ? ? ?. ? ? ? ?
>?Item_Type.Health.and.Hygiene ? ? . ? ? ? ? ?Item_Type.Household ? ? ?
>? ? ? ?. ? ? ? ? ?Item_Type.Meat ? ? ? ? ? ? ? ? ? . ? ? ? ?
>?Item_Type.Others ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Seafood ? ? ? ?
>? ? ? ?. ? ? ? ? ?Item_Type.Snack.Foods ? ? ? ? ? ?. ? ? ? ?
>?Item_Type.Soft.Drinks ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Starchy.Foods ?
>? ? ? ?. ? ? ? ? ?Outlet_Establishment_Year.1987
>?-0.345927916Outlet_Establishment_Year.1997 ?
>1.692678186Outlet_Establishment_Year.1998
>?-2.259508290Outlet_Establishment_Year.1999 ? . ? ? ? ?
>?Outlet_Establishment_Year.2002
>?-0.032971913Outlet_Establishment_Year.2004 ?
>1.756230495Outlet_Establishment_Year.2007 ? . ? ? ? ?
>?Outlet_Establishment_Year.2009 ?-0.549210057Outlet_Size.Medium ? ? ? ?
>? ? ? 0.056897825Outlet_Size.Small ? ? ? ? ? ? ?
>-1.706006538Outlet_Location_Type.Tier.3 ? ?
>?0.373456218Item_Identifier_CombinedFD ? ? ? . ? ? ? ? ?Item_MRP ? ? ?
>? ? ? ? ? ? ? ? ? 0.505435352Item_Weight ? ? ? ? ? ? ? ? ? ? ?. ? ? ? ?
>?Item_Visibility_MeanRatio ? ? ? -0.007274202
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Mar 22 15:38:47 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 22 Mar 2017 07:38:47 -0700
Subject: [R] Issue with subset in glm
In-Reply-To: <A5A30F1D451F924B902DDE8063410E67136F61@EM1A.ad.ucla.edu>
References: <A5A30F1D451F924B902DDE8063410E67136F61@EM1A.ad.ucla.edu>
Message-ID: <CAGxFJbT9kCYPCzk9mxEehs87YLy7FYqzEgV888fDZ9ffWhgMyg@mail.gmail.com>

The subset argument is evaluated in "data" first, then in the caller's
environment, etc.
So:

1) In your first example, stype is a *vector*, and the subset
expression is identically TRUE, hence is equivalent to making the call
without the subset argument.

2) The second call fits the subset with stype = "E", hence is different.

3) "i" is not found in mtcars, hence is looked for in the caller,
where it has the value 4, giving the same subset and result as in the
next call.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 21, 2017 at 8:50 AM, Ganz, Carl <carlganz at ucla.edu> wrote:
> Hello,
>
> I am experiencing odd behavior with the subset parameter for glm. It appears that the parameter uses non-standard evaluation, but only in some cases. Below is a reproducible example.
>
> library(survey) # for example dataset
>
> data(api)
> stype <- "E"
> (a <- glm(api00~ell+meals+mobility, data = apistrat,
>     subset = apistrat$stype == stype))
> (b <- glm(api00~ell+meals+mobility, data = apistrat,
>     subset = apistrat$stype == "E"))
> # should be equal since stype = "E" but they aren't
> coef(a)==coef(b)
>
> # for some reason works as expected here
> i = 4
> (c <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==i))
> (d <- glm(mpg ~ wt, data = mtcars, subset = mtcars$cyl==4))
> coef(c)==coef(d)
>
> I can't really explain what is happening so I would appreciate help.
>
> Kind Regards,
> Carl Ganz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Mar 22 16:11:14 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 Mar 2017 08:11:14 -0700
Subject: [R] string pattern matching
In-Reply-To: <CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
	<CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
	<CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>
Message-ID: <CAF8bMca9-GG946ACE9r_-G=Ee4i5cSYWnGaNLMUrCgVHYG_gSQ@mail.gmail.com>

You did not describe the goal of your pattern matching.  Were you trying
to match any string that could be interpreted as an R expression containing
X1 and X3 as additive terms?   If so, you could turn the string into a one-sided
formula and use the terms() function.  E.g.,

f <- function(string) {
    fmla <- as.formula(paste("~", string))
    term.labels <- attr(terms(fmla), "term.labels")
    all(c("X1","X3") %in% term.labels)
}

> f("X3 + X2 + X1")
[1] TRUE
> f("- X3 + X2 + X1")
[1] FALSE
> f("X3 + X2 + log(X1)")
[1] FALSE
> f("X3 + X2 + log(X1) + X1")
[1] TRUE
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 22, 2017 at 6:39 AM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Wow. Thanks to everyone (Jim, Ng Bo Lin, Bert, David, and Ulrik) for
> all the quick and helpful responses. They have given me a better
> understanding of regular expressions, and certainly answered my
> question.
>
> Joe
>
> On Wed, Mar 22, 2017 at 12:22 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> Hi Joe,
>>
>> you could also rethink your pattern:
>>
>> grep("x1 \\+ x2", test, value = TRUE)
>>
>> grep("x1 \\+ x", test, value = TRUE)
>>
>> grep("x1 \\+ x[0-9]", test, value = TRUE)
>>
>> HTH
>> Ulrik
>>
>> On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Joe,
>>> This may help you:
>>>
>>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>> multigrep<-function(x1,x2) {
>>>  xbits<-unlist(strsplit(x1," "))
>>>  nbits<-length(xbits)
>>>  xans<-rep(FALSE,nbits)
>>>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
>>>  return(all(xans))
>>> }
>>> multigrep("x1 + x3","x1 + x2 + x3")
>>> [1] TRUE
>>> multigrep("x1 + x4","x1 + x2 + x3")
>>> [1] FALSE
>>>
>>> Jim
>>>
>>> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com>
>>> wrote:
>>> > Hi Folks,
>>> >
>>> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
>>> > Or is that a ridiculous question, since I'm trying to find something
>>> > based on a pattern that doesn't exist?
>>> >
>>> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>> > test
>>> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>>> >
>>> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
>>> > [1] "x1 + x2 + x3"
>>> >
>>> >
>>> > But what if only have "x1 + x3" as the pattern and still want to
>>> > return "x1 + x2 + x3"?
>>> >
>>> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
>>> > character(0)
>>> >
>>> > I'm sure this looks like an odd question. I'm trying to build a
>>> > function and stuck on this. Rather than dropping the whole function on
>>> > the list, I thought I'd try one piece I needed help with...although I
>>> > suspect that this question itself probably does bode well for my
>>> > function :)
>>> >
>>> > Thanks!
>>> > Joe
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From santosh2005 at gmail.com  Wed Mar 22 16:52:55 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 22 Mar 2017 08:52:55 -0700
Subject: [R] fread transforms numbers
Message-ID: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>

Hi

I have been using "fread" utility of "data.table" packge .. on a dataset of
about 20 million rows. It's a fantastic package to read datasets. Thank
you, Matt D.

However, I am faced with a peculiar instance of  certain numbers in a
column being transformed.

In the dataset, a column has values ranging from 1 to 9##########
(nchar(x)=11, e.g. 98765432109). After using "fread" to read the dataset,
values in all the columns are displayed correctly upto the first 1000 rows.
If "fread" is applied for reading >1000 rows of  the total of 20Million
rows, the values in only this (column (having wide range of values) are
displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)

I tried reading all the columns as "character" and didn't help.

Would highly appreciate your assistance!

Thanks so much in advance.

Best regards,
Santosh

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 22 17:58:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 22 Mar 2017 09:58:36 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
Message-ID: <44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>

You failed to provide a reproducible example, and you posted HTML so the quality of any answer will be limited by the quality of your question.

My stab at your problem is that you should read ?fread, and in particular should try using the colClasses argument.
-- 
Sent from my phone. Please excuse my brevity.

On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
>Hi
>
>I have been using "fread" utility of "data.table" packge .. on a
>dataset of
>about 20 million rows. It's a fantastic package to read datasets. Thank
>you, Matt D.
>
>However, I am faced with a peculiar instance of  certain numbers in a
>column being transformed.
>
>In the dataset, a column has values ranging from 1 to 9##########
>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
>dataset,
>values in all the columns are displayed correctly upto the first 1000
>rows.
>If "fread" is applied for reading >1000 rows of  the total of 20Million
>rows, the values in only this (column (having wide range of values) are
>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
>
>I tried reading all the columns as "character" and didn't help.
>
>Would highly appreciate your assistance!
>
>Thanks so much in advance.
>
>Best regards,
>Santosh
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Mar 22 18:22:22 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 Mar 2017 10:22:22 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
	<44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
Message-ID: <CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>

Here is a way to reproduce the problem:
  > data.table::fread("9876543210\n") # number bigger than 2^31-1
                V1
  1: 4.879661e-314
and your work-around does fix things up
  > data.table::fread("9876543210\n", colClasses="numeric")
             V1
  1: 9876543210

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 22, 2017 at 9:58 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You failed to provide a reproducible example, and you posted HTML so the quality of any answer will be limited by the quality of your question.
>
> My stab at your problem is that you should read ?fread, and in particular should try using the colClasses argument.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
>>Hi
>>
>>I have been using "fread" utility of "data.table" packge .. on a
>>dataset of
>>about 20 million rows. It's a fantastic package to read datasets. Thank
>>you, Matt D.
>>
>>However, I am faced with a peculiar instance of  certain numbers in a
>>column being transformed.
>>
>>In the dataset, a column has values ranging from 1 to 9##########
>>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
>>dataset,
>>values in all the columns are displayed correctly upto the first 1000
>>rows.
>>If "fread" is applied for reading >1000 rows of  the total of 20Million
>>rows, the values in only this (column (having wide range of values) are
>>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
>>
>>I tried reading all the columns as "character" and didn't help.
>>
>>Would highly appreciate your assistance!
>>
>>Thanks so much in advance.
>>
>>Best regards,
>>Santosh
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashley.patton at aol.co.uk  Wed Mar 22 15:05:20 2017
From: ashley.patton at aol.co.uk (Ashley Patton)
Date: Wed, 22 Mar 2017 10:05:20 -0400
Subject: [R] Correlation code not working but not sure why
Message-ID: <15af65610be-896-1d326@webstg-a03.mail.aol.com>

Good afternoon,

I was wondering if someone could help me with what I am sure is likely to be a really simple problem but I cannot work out what I have done wrong. I have tried searching the forums/Google etc but can't find anything quite like the code I am using other than things that do not differ from what I have done. I suspect then that the problem is in my naming of things but I don't know what is causing the issue.

I have data that comprises 53 columns containing temperature data for 53 sites recording continuously for a year, 48 times a day (half hourly). I also have one column that contains average air temperature for a city during the same time period. I would like to see if my collective site temperature data shows any correlation with the city air temperature data and so I have attempted to combined the data from the 53 site columns using the code below and then repeat the air temperature 53 times to correlate it against and then perform a Pearson's correlation. My data looks something like this:

Site   BHCS306   BH9OB1U   BHCS276   BHCS207...      AirTempC
         12.2          12.4            12.2           12.7                 15.3
         12.2          12.5            12.3           12.7                 16.2
         12.3          12.5            12.5           12.8                 16.1... 
repeating for 53 sites recording every half hour for a year

The code I used was this:


#String together data from all 53 sites into one column
AllTemps <- c(data[,"BHCS306"],data[,"BH9OB1U"],data[,"BHCS276"],data[,"BHCS207AL"],data[,"BHCS178AL"],data[,"BHCS159AL"],data[,"BHCS318"],data[,"BHCS211"],data[,"BH7OB1L"],data[,"BHCS274B"],data[,"BHCS337"],data[,"BH2PB1"],data[,"BHCS038"],data[,"BHCS074AL"],data[,"BH9OB1L"],data[,"Site 5"],data[,"BH6PB4"],data[,"BH6PB1"],data[,"BHCS329"],data[,"BH5PB1T"],data[,"BH4PB1T"],data[,"BHCS233T"],data[,"BHCS229"],data[,"BHCS272T"],data[,"BHCS217T"],data[,"BHCS283"],data[,"BHCS248"],data[,"BHCS002A"],data[,"BHCS245B"],data[,"BH4PB2T"],data[,"BH6PB2"],data[,"BH5PB1B"],data[,"BH4PB1B"],data[,"BHCS233B"],data[,"BHCS313L"],data[,"BHCS272B"],data[,"BHCS266"],data[,"BHCS217B"],data[,"BHCS241"],data[,"BH4PB2B"],data[,"BHCS116AL"],data[,"BHCS067A"],data[,"BHCS304L"],data[,"BH1OB1L"],data[,"BHCS307L"],data[,"BHCS037C"],data[,"BHCS301L"],data[,"BHCS238A"],data[,"BH3OB1"],data[,"BHCS308L"],data[,"BHCS278"],data[,"BHCS285"],data[,"BHCS133CL"],data[,"BHCS332L"])

#Copy air temp data 53 times
airTemps53 <- c(rep(AirTempC, times = 53))

#Run correlation between site temps and air temps
cor.test(AllTemps, airTemps53, alternative = "two.sided", method = "pearson")

The error it returned was this:

> #Copy air temp data 53 times
> airTemps53 <- c(rep(AirTempC, times = 53))
> 
> #Run correlation between site temps and air temps
> cor.test(AllTemps, airTemps53, alternative = "two.sided", method = "pearson")
Error in cor.test(AllTemps, airTemps53, alternative = "two.sided", method = "pearson") : 
  object 'AllTemps' not found

Can anyone spot my mistake? I am very new to this so I am sure I have done something obvious and silly so please forgive me.

Additionally I was wondering if there was a an easy way to offset the data to see if, for example, I can see if there is a lag time between changes in air temperature correlating with changes in temperature at my sites or do I need to do this by manually offsetting the data in Excel first?

Many thanks,
Ashley


From mattjdowle at gmail.com  Wed Mar 22 20:17:51 2017
From: mattjdowle at gmail.com (Matt Dowle)
Date: Wed, 22 Mar 2017 12:17:51 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
	<44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
	<CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>
Message-ID: <CAOuOy3etyVB3LABWuAXXNawzngKnxgOvjQHAhHtp8SMqc8aupg@mail.gmail.com>

Thanks Bill for cc.

Santosh,

I'm almost certain you don't have package bit64 installed.  When you do it
works fine :

> remove.packages("bit64")
> data.table::fread("9876543210\n")
              V1
1: 4.879661e-314
> install.packages("bit64")
> data.table::fread("9876543210\n")
           V1
1: 9876543210

News for data.table v1.10.2 on CRAN 31 Jan 2017 contained :

* When fread() or print() see integer64 columns are present, bit64's
namespace is now automatically loaded for convenience.

However, when data.table loads the namespace there is a bug in this
function :

> data.table:::require_bit64
function ()
{
    tt = try(requireNamespace("bit64", quietly = TRUE))
    if (inherits(tt, "try-error"))
        warning("Some columns are type 'integer64' but package bit64 is not
installed. Those columns will print as strange looking floating point data.
There is no need to reload the data. Simply install.packages('bit64') to
obtain the integer64 print method and print the data again.")
}

The intent was to display that nice helpful message to you.   Due to this
report, I can see now that I shouldn't have wrapped requireNamespace() with
try() because  requireNamespace() returns TRUE or FALSE anyway. Even though
requireNamespace() prints 'Failed with error' it doesn't actually throw an
error.  I'll change data.table's function to the following :

if (!requireNamespace("bit64", quietly = TRUE))
    warning("Some columns ...")

bit64 is correctly Suggests not Depends.   It's just unfortunate the
intended message wasn't displayed.

Santosh, in future please follow the data.table support guide here:
https://github.com/Rdatatable/data.table/wiki/Support.  r-help is not
supposed to be used for package support.  The main thing though is thanks
for helping me find this bug.

Thanks,
Matt


On Wed, Mar 22, 2017 at 10:22 AM, William Dunlap <wdunlap at tibco.com> wrote:

> Here is a way to reproduce the problem:
>   > data.table::fread("9876543210\n") # number bigger than 2^31-1
>                 V1
>   1: 4.879661e-314
> and your work-around does fix things up
>   > data.table::fread("9876543210\n", colClasses="numeric")
>              V1
>   1: 9876543210
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Mar 22, 2017 at 9:58 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> > You failed to provide a reproducible example, and you posted HTML so the
> quality of any answer will be limited by the quality of your question.
> >
> > My stab at your problem is that you should read ?fread, and in
> particular should try using the colClasses argument.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
> >>Hi
> >>
> >>I have been using "fread" utility of "data.table" packge .. on a
> >>dataset of
> >>about 20 million rows. It's a fantastic package to read datasets. Thank
> >>you, Matt D.
> >>
> >>However, I am faced with a peculiar instance of  certain numbers in a
> >>column being transformed.
> >>
> >>In the dataset, a column has values ranging from 1 to 9##########
> >>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
> >>dataset,
> >>values in all the columns are displayed correctly upto the first 1000
> >>rows.
> >>If "fread" is applied for reading >1000 rows of  the total of 20Million
> >>rows, the values in only this (column (having wide range of values) are
> >>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
> >>
> >>I tried reading all the columns as "character" and didn't help.
> >>
> >>Would highly appreciate your assistance!
> >>
> >>Thanks so much in advance.
> >>
> >>Best regards,
> >>Santosh
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Mar 22 22:53:52 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 22 Mar 2017 21:53:52 +0000
Subject: [R] r question
In-Reply-To: <CA+mU4QETQODjx5zir0EUEBs4arhYoWSxYM9DWz3d3heE2uXU0g@mail.gmail.com>
References: <CA+mU4QETQODjx5zir0EUEBs4arhYoWSxYM9DWz3d3heE2uXU0g@mail.gmail.com>
Message-ID: <58D2F270.2@sapo.pt>

Hello,

There's a paenthesis missing in

 > relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
+ beta_true<-relativerisk
Error: unexpected symbol in:
"relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
beta_true"

The correct instruction would be

relativerisk<- matrix(log(c(1,1,2,2)),ncol=4,byrow = TRUE)

And there's an error in your matrix multiply.

 > Ti=exp(x_true%*%beta_true)*ei
Error in x_true %*% beta_true : non-conformable arguments

It can be corrected if you transpose beta_true.

Ti=exp(x_true %*% t(beta_true))*ei

At this point I've stoped running your code, I believe you must revise 
it and try to see what's wrong instruction by instruction. Do that and 
post again.
ALso, get rid of the <<-, use <-
If you do this, I'll explain the difference in the next answer to your 
doubts.

Hope this helps,

Rui Barradas


Em 22-03-2017 08:11, ??? escreveu:
> Hi ,I have some question about simulate, I don't know how to paste question
> to this website,so I paste below.
> I use genoud to find the maximum likelihood value, but when I use numcut=3
> ,it will get error message,like this " coxph.wtest(fit$var[nabeta, nabeta],
> temp, control$toler.chol) : NA/NaN/Inf"
> and this is my code
> library(rgenoud)
> library(survival)
> N=500
> ei=rexp(N)
> censor=rep(1,N)
> x1=runif(N)
> x2=runif(N)
> x3=runif(N)
> truecut=c(0.3,0.6)
> dum1=1*(x1>truecut[1] & x1<truecut[2])
> dum2=1*(x1>truecut[2])
> x_true=cbind(dum1,dum2,x2,x3)
> relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
> beta_true<-relativerisk
> Ti=exp(x_true%*%beta_true)*ei
> confound=cbind(x2,x3)
> initial2<-c(0.09,0.299,0.597,-0.17,-1.3,-3.1,-1.4,-1.12)
> numcut=2
>   domain2<<-matrix(c(rep(c(0.05,0.95),numcut),rep(c(0,5),numcut+dim(confound)[2])),ncol=2,byrow
> = TRUE)
>
> loglikfun <- function(beta, formula) {
>    beta1 <- coxph(formula, init = beta,
> control=list('iter.max'=0))#iteration is zero
>    return(beta1$loglik[2])
> }
> obj <- function(xx){
>    cutoff <- xx[1:numcut_global] #cutpoint
>    cut_design <-
> cut(target_global,breaks=c(0,sort(cutoff)+seq(0,gap_global*(length(cutoff)-1),by=gap_global),target_max),quantile=FALSE,labels=c(0:numcut_global))
>    beta <- -xx[(numcut+1):nvars]  #coefficients of parameters
>    logliks <-
> loglikfun(beta,Surv(time_global,censor_global)~cut_design+confound_global)
>    return(logliks)
> }
> maxloglik<-function(target,numcut,time,censor,confound,domain2,initial2,gap){
>    time_global<<-time
>    censor_global<<-censor
>    target_global<<-target
>    nvars<<-2*numcut+dim(confound)[2]
>    confound_global<<-confound
>    numcut_global<<-numcut
>    target_max<<-max(target)
>    gap_global<<-gap
>    ccc<-genoud(obj, nvars, max=TRUE, pop.size=100, max.generations=6,
> wait.generations=10,
>                hard.generation.limit=TRUE, starting.values=initial2,
> MemoryMatrix=TRUE,
>                Domains=domain2, solution.tolerance=0.001,
>                gr=NULL, boundary.enforcement=2, lexical=FALSE,
> gradient.check=TRUE)
>    ccc$par_corr<-ccc$par #the coefficients of genoud
>
> ccc$par_corr[1:numcut]<-sort(ccc$par[1:numcut])+seq(0,gap_global*(numcut-1),by=gap_global)
> #sort cutpoint
>    return(ccc)
> }
>
>
> maxloglik(x1,3,Ti,censor,confound,domain2,initial2,0.02)$par_corr
>
> I have no idea about the error ,maybe is my initial is wrong.
> thank you
>   From Meng-Ke
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From frainj at gmail.com  Thu Mar 23 00:03:47 2017
From: frainj at gmail.com (John C Frain)
Date: Wed, 22 Mar 2017 23:03:47 +0000
Subject: [R] Correlation code not working but not sure why
In-Reply-To: <15af65610be-896-1d326@webstg-a03.mail.aol.com>
References: <15af65610be-896-1d326@webstg-a03.mail.aol.com>
Message-ID: <CAHrK51624qRECd9sxPjJb+5JviLJGGtSnzpNfvu50b4Dcp1xhg@mail.gmail.com>

I can't see anything wrong with your code. You should read the posting
guide and produce a minimal example showing the problem and any other
details requested there.

If I take just the small sample of data that you have provided and run a
slightly adapted version of your code

data = read.table("query.txt",header = TRUE )
data
AllTemps <-
c(data[,"BHCS306"],data[,"BH9OB1U"],data[,"BHCS276"],data[,"BHCS207"])
AirTempC <- data[,"AirTempC"]
airTemps53 <- c(rep(AirTempC, times = 4))
cor.test(AllTemps, airTemps53, alternative = "two.sided", method =
"pearson")

I get the following output - which gives what I require. (I would not
endorse the idea of looking at this correlation. Perhaps some kind of
stacked regression with dummy variables for the sites might be more
appropriate)


> data = read.table("query.txt",header = TRUE )
> data
  BHCS306 BH9OB1U BHCS276 BHCS207 AirTempC
1    12.2    12.4    12.2    12.7     15.3
2    12.2    12.5    12.3    12.7     16.2
3    12.3    12.5    12.5    12.8     16.1
> AllTemps <-
c(data[,"BHCS306"],data[,"BH9OB1U"],data[,"BHCS276"],data[,"BHCS207"])
> AirTempC <- data[,"AirTempC"]
> airTemps53 <- c(rep(AirTempC, times = 4))
> cor.test(AllTemps, airTemps53, alternative = "two.sided", method =
"pearson")

Pearson's product-moment correlation

data:  AllTemps and airTemps53
t = 0.68527, df = 10, p-value = 0.5087
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.4122189  0.7005406
sample estimates:
      cor
0.2117855


John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 22 March 2017 at 14:05, Ashley Patton via R-help <r-help at r-project.org>
wrote:

> Good afternoon,
>
> I was wondering if someone could help me with what I am sure is likely to
> be a really simple problem but I cannot work out what I have done wrong. I
> have tried searching the forums/Google etc but can't find anything quite
> like the code I am using other than things that do not differ from what I
> have done. I suspect then that the problem is in my naming of things but I
> don't know what is causing the issue.
>
> I have data that comprises 53 columns containing temperature data for 53
> sites recording continuously for a year, 48 times a day (half hourly). I
> also have one column that contains average air temperature for a city
> during the same time period. I would like to see if my collective site
> temperature data shows any correlation with the city air temperature data
> and so I have attempted to combined the data from the 53 site columns using
> the code below and then repeat the air temperature 53 times to correlate it
> against and then perform a Pearson's correlation. My data looks something
> like this:
>
> Site   BHCS306   BH9OB1U   BHCS276   BHCS207...      AirTempC
>          12.2          12.4            12.2           12.7
>  15.3
>          12.2          12.5            12.3           12.7
>  16.2
>          12.3          12.5            12.5           12.8
>  16.1...
> repeating for 53 sites recording every half hour for a year
>
> The code I used was this:
>
>
> #String together data from all 53 sites into one column
> AllTemps <- c(data[,"BHCS306"],data[,"BH9OB1U"],data[,"BHCS276"],
> data[,"BHCS207AL"],data[,"BHCS178AL"],data[,"BHCS159AL"]
> ,data[,"BHCS318"],data[,"BHCS211"],data[,"BH7OB1L"],
> data[,"BHCS274B"],data[,"BHCS337"],data[,"BH2PB1"],
> data[,"BHCS038"],data[,"BHCS074AL"],data[,"BH9OB1L"],data[,"Site
> 5"],data[,"BH6PB4"],data[,"BH6PB1"],data[,"BHCS329"],
> data[,"BH5PB1T"],data[,"BH4PB1T"],data[,"BHCS233T"],
> data[,"BHCS229"],data[,"BHCS272T"],data[,"BHCS217T"],
> data[,"BHCS283"],data[,"BHCS248"],data[,"BHCS002A"],
> data[,"BHCS245B"],data[,"BH4PB2T"],data[,"BH6PB2"],
> data[,"BH5PB1B"],data[,"BH4PB1B"],data[,"BHCS233B"],
> data[,"BHCS313L"],data[,"BHCS272B"],data[,"BHCS266"],
> data[,"BHCS217B"],data[,"BHCS241"],data[,"BH4PB2B"],
> data[,"BHCS116AL"],data[,"BHCS067A"],data[,"BHCS304L"],
> data[,"BH1OB1L"],data[,"BHCS307L"],data[,"BHCS037C"],
> data[,"BHCS301L"],data[,"BHCS238A"],data[,"BH3OB1"],
> data[,"BHCS308L"],data[,"BHCS278"],data[,"BHCS285"],
> data[,"BHCS133CL"],data[,"BHCS332L"])
>
> #Copy air temp data 53 times
> airTemps53 <- c(rep(AirTempC, times = 53))
>
> #Run correlation between site temps and air temps
> cor.test(AllTemps, airTemps53, alternative = "two.sided", method =
> "pearson")
>
> The error it returned was this:
>
> > #Copy air temp data 53 times
> > airTemps53 <- c(rep(AirTempC, times = 53))
> >
> > #Run correlation between site temps and air temps
> > cor.test(AllTemps, airTemps53, alternative = "two.sided", method =
> "pearson")
> Error in cor.test(AllTemps, airTemps53, alternative = "two.sided", method
> = "pearson") :
>   object 'AllTemps' not found
>
> Can anyone spot my mistake? I am very new to this so I am sure I have done
> something obvious and silly so please forgive me.
>
> Additionally I was wondering if there was a an easy way to offset the data
> to see if, for example, I can see if there is a lag time between changes in
> air temperature correlating with changes in temperature at my sites or do I
> need to do this by manually offsetting the data in Excel first?
>
> Many thanks,
> Ashley
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Thu Mar 23 03:50:40 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 22 Mar 2017 19:50:40 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <CAOuOy3etyVB3LABWuAXXNawzngKnxgOvjQHAhHtp8SMqc8aupg@mail.gmail.com>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
	<44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
	<CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>
	<CAOuOy3etyVB3LABWuAXXNawzngKnxgOvjQHAhHtp8SMqc8aupg@mail.gmail.com>
Message-ID: <CAN_e6XsXj_kX0GoU5XeL5ncMzz13SkXw01TQ8kcDCXHSKDGyew@mail.gmail.com>

Thanks so much for your suggestions! Will try them out!

Santosh

On Wed, Mar 22, 2017 at 12:17 PM, Matt Dowle <mattjdowle at gmail.com> wrote:

> Thanks Bill for cc.
>
> Santosh,
>
> I'm almost certain you don't have package bit64 installed.  When you do it
> works fine :
>
> > remove.packages("bit64")
> > data.table::fread("9876543210\n")
>               V1
> 1: 4.879661e-314
> > install.packages("bit64")
> > data.table::fread("9876543210\n")
>            V1
> 1: 9876543210
>
> News for data.table v1.10.2 on CRAN 31 Jan 2017 contained :
>
> * When fread() or print() see integer64 columns are present, bit64's
> namespace is now automatically loaded for convenience.
>
> However, when data.table loads the namespace there is a bug in this
> function :
>
> > data.table:::require_bit64
> function ()
> {
>     tt = try(requireNamespace("bit64", quietly = TRUE))
>     if (inherits(tt, "try-error"))
>         warning("Some columns are type 'integer64' but package bit64 is
> not installed. Those columns will print as strange looking floating point
> data. There is no need to reload the data. Simply install.packages('bit64')
> to obtain the integer64 print method and print the data again.")
> }
>
> The intent was to display that nice helpful message to you.   Due to this
> report, I can see now that I shouldn't have wrapped requireNamespace() with
> try() because  requireNamespace() returns TRUE or FALSE anyway. Even though
> requireNamespace() prints 'Failed with error' it doesn't actually throw an
> error.  I'll change data.table's function to the following :
>
> if (!requireNamespace("bit64", quietly = TRUE))
>     warning("Some columns ...")
>
> bit64 is correctly Suggests not Depends.   It's just unfortunate the
> intended message wasn't displayed.
>
> Santosh, in future please follow the data.table support guide here:
> https://github.com/Rdatatable/data.table/wiki/Support.  r-help is not
> supposed to be used for package support.  The main thing though is thanks
> for helping me find this bug.
>
> Thanks,
> Matt
>
>
> On Wed, Mar 22, 2017 at 10:22 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> Here is a way to reproduce the problem:
>>   > data.table::fread("9876543210\n") # number bigger than 2^31-1
>>                 V1
>>   1: 4.879661e-314
>> and your work-around does fix things up
>>   > data.table::fread("9876543210\n", colClasses="numeric")
>>              V1
>>   1: 9876543210
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Mar 22, 2017 at 9:58 AM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>> > You failed to provide a reproducible example, and you posted HTML so
>> the quality of any answer will be limited by the quality of your question.
>> >
>> > My stab at your problem is that you should read ?fread, and in
>> particular should try using the colClasses argument.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com>
>> wrote:
>> >>Hi
>> >>
>> >>I have been using "fread" utility of "data.table" packge .. on a
>> >>dataset of
>> >>about 20 million rows. It's a fantastic package to read datasets. Thank
>> >>you, Matt D.
>> >>
>> >>However, I am faced with a peculiar instance of  certain numbers in a
>> >>column being transformed.
>> >>
>> >>In the dataset, a column has values ranging from 1 to 9##########
>> >>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
>> >>dataset,
>> >>values in all the columns are displayed correctly upto the first 1000
>> >>rows.
>> >>If "fread" is applied for reading >1000 rows of  the total of 20Million
>> >>rows, the values in only this (column (having wide range of values) are
>> >>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
>> >>
>> >>I tried reading all the columns as "character" and didn't help.
>> >>
>> >>Would highly appreciate your assistance!
>> >>
>> >>Thanks so much in advance.
>> >>
>> >>Best regards,
>> >>Santosh
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Thu Mar 23 03:54:25 2017
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 22 Mar 2017 19:54:25 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <CAN_e6XsXj_kX0GoU5XeL5ncMzz13SkXw01TQ8kcDCXHSKDGyew@mail.gmail.com>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
	<44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
	<CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>
	<CAOuOy3etyVB3LABWuAXXNawzngKnxgOvjQHAhHtp8SMqc8aupg@mail.gmail.com>
	<CAN_e6XsXj_kX0GoU5XeL5ncMzz13SkXw01TQ8kcDCXHSKDGyew@mail.gmail.com>
Message-ID: <CAN_e6XuMB7eOKrp1B5B4CBtwPzG5NmdqN4SK0b7=5VDTdDyaWQ@mail.gmail.com>

Dear Rxperts..
I am using R version 3.2.3 on Linux.. it says bit64 is not available for R
version 3.2.3..

Thanks and your assistance much appreciated!
Best regards,
Santosh


On Wed, Mar 22, 2017 at 7:50 PM, Santosh <santosh2005 at gmail.com> wrote:

> Thanks so much for your suggestions! Will try them out!
>
> Santosh
>
> On Wed, Mar 22, 2017 at 12:17 PM, Matt Dowle <mattjdowle at gmail.com> wrote:
>
>> Thanks Bill for cc.
>>
>> Santosh,
>>
>> I'm almost certain you don't have package bit64 installed.  When you do
>> it works fine :
>>
>> > remove.packages("bit64")
>> > data.table::fread("9876543210\n")
>>               V1
>> 1: 4.879661e-314
>> > install.packages("bit64")
>> > data.table::fread("9876543210\n")
>>            V1
>> 1: 9876543210
>>
>> News for data.table v1.10.2 on CRAN 31 Jan 2017 contained :
>>
>> * When fread() or print() see integer64 columns are present, bit64's
>> namespace is now automatically loaded for convenience.
>>
>> However, when data.table loads the namespace there is a bug in this
>> function :
>>
>> > data.table:::require_bit64
>> function ()
>> {
>>     tt = try(requireNamespace("bit64", quietly = TRUE))
>>     if (inherits(tt, "try-error"))
>>         warning("Some columns are type 'integer64' but package bit64 is
>> not installed. Those columns will print as strange looking floating point
>> data. There is no need to reload the data. Simply install.packages('bit64')
>> to obtain the integer64 print method and print the data again.")
>> }
>>
>> The intent was to display that nice helpful message to you.   Due to this
>> report, I can see now that I shouldn't have wrapped requireNamespace() with
>> try() because  requireNamespace() returns TRUE or FALSE anyway. Even though
>> requireNamespace() prints 'Failed with error' it doesn't actually throw an
>> error.  I'll change data.table's function to the following :
>>
>> if (!requireNamespace("bit64", quietly = TRUE))
>>     warning("Some columns ...")
>>
>> bit64 is correctly Suggests not Depends.   It's just unfortunate the
>> intended message wasn't displayed.
>>
>> Santosh, in future please follow the data.table support guide here:
>> https://github.com/Rdatatable/data.table/wiki/Support.  r-help is not
>> supposed to be used for package support.  The main thing though is thanks
>> for helping me find this bug.
>>
>> Thanks,
>> Matt
>>
>>
>> On Wed, Mar 22, 2017 at 10:22 AM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>> Here is a way to reproduce the problem:
>>>   > data.table::fread("9876543210\n") # number bigger than 2^31-1
>>>                 V1
>>>   1: 4.879661e-314
>>> and your work-around does fix things up
>>>   > data.table::fread("9876543210\n", colClasses="numeric")
>>>              V1
>>>   1: 9876543210
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Wed, Mar 22, 2017 at 9:58 AM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> > You failed to provide a reproducible example, and you posted HTML so
>>> the quality of any answer will be limited by the quality of your question.
>>> >
>>> > My stab at your problem is that you should read ?fread, and in
>>> particular should try using the colClasses argument.
>>> > --
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>> > On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com>
>>> wrote:
>>> >>Hi
>>> >>
>>> >>I have been using "fread" utility of "data.table" packge .. on a
>>> >>dataset of
>>> >>about 20 million rows. It's a fantastic package to read datasets. Thank
>>> >>you, Matt D.
>>> >>
>>> >>However, I am faced with a peculiar instance of  certain numbers in a
>>> >>column being transformed.
>>> >>
>>> >>In the dataset, a column has values ranging from 1 to 9##########
>>> >>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
>>> >>dataset,
>>> >>values in all the columns are displayed correctly upto the first 1000
>>> >>rows.
>>> >>If "fread" is applied for reading >1000 rows of  the total of 20Million
>>> >>rows, the values in only this (column (having wide range of values) are
>>> >>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
>>> >>
>>> >>I tried reading all the columns as "character" and didn't help.
>>> >>
>>> >>Would highly appreciate your assistance!
>>> >>
>>> >>Thanks so much in advance.
>>> >>
>>> >>Best regards,
>>> >>Santosh
>>> >>
>>> >>       [[alternative HTML version deleted]]
>>> >>
>>> >>______________________________________________
>>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>PLEASE do read the posting guide
>>> >>http://www.R-project.org/posting-guide.html
>>> >>and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 23 05:48:17 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 22 Mar 2017 21:48:17 -0700
Subject: [R] fread transforms numbers
In-Reply-To: <CAN_e6XuMB7eOKrp1B5B4CBtwPzG5NmdqN4SK0b7=5VDTdDyaWQ@mail.gmail.com>
References: <CAN_e6XvvkUv0O15quoBbKPRVHbn89R5Y16N1gh0oQ_k4MinkGA@mail.gmail.com>
	<44D0FF52-CB88-4872-B63F-0638F8F6C69C@dcn.davis.ca.us>
	<CAF8bMcaPzv8sCyv7aV9FxcsAZt45ss7E7OfXTr=1Nznm1LN_=A@mail.gmail.com>
	<CAOuOy3etyVB3LABWuAXXNawzngKnxgOvjQHAhHtp8SMqc8aupg@mail.gmail.com>
	<CAN_e6XsXj_kX0GoU5XeL5ncMzz13SkXw01TQ8kcDCXHSKDGyew@mail.gmail.com>
	<CAN_e6XuMB7eOKrp1B5B4CBtwPzG5NmdqN4SK0b7=5VDTdDyaWQ@mail.gmail.com>
Message-ID: <AA90C2FE-3F97-412A-8F5D-4DECDECA21A9@dcn.davis.ca.us>

A) You have been given a workaround (colClasses).

B) 3.2.3 is not the current version of R. Support for older versions may vary from CRAN mirror to mirror. You could try another mirror. 

C) Technically, "Linux" is not an operating system, it is a kernel. Debian and Fedora are examples of operating systems, and instructions for installing and upgrading R on them are different. They also have dedicated R mailing lists, and separate instructions for installing and upgrading on them are available on CRAN.

D) Typically OS's based on Linux install from source, and the bit64 package only depends on R >= 3.0.1, so this seems like your R is just not configured to look in an appropriate place for the package. You would have to provide more details on your setup to get help from any R mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On March 22, 2017 7:54:25 PM PDT, Santosh <santosh2005 at gmail.com> wrote:
>Dear Rxperts..
>I am using R version 3.2.3 on Linux.. it says bit64 is not available
>for R
>version 3.2.3..
>
>Thanks and your assistance much appreciated!
>Best regards,
>Santosh
>
>
>On Wed, Mar 22, 2017 at 7:50 PM, Santosh <santosh2005 at gmail.com> wrote:
>
>> Thanks so much for your suggestions! Will try them out!
>>
>> Santosh
>>
>> On Wed, Mar 22, 2017 at 12:17 PM, Matt Dowle <mattjdowle at gmail.com>
>wrote:
>>
>>> Thanks Bill for cc.
>>>
>>> Santosh,
>>>
>>> I'm almost certain you don't have package bit64 installed.  When you
>do
>>> it works fine :
>>>
>>> > remove.packages("bit64")
>>> > data.table::fread("9876543210\n")
>>>               V1
>>> 1: 4.879661e-314
>>> > install.packages("bit64")
>>> > data.table::fread("9876543210\n")
>>>            V1
>>> 1: 9876543210
>>>
>>> News for data.table v1.10.2 on CRAN 31 Jan 2017 contained :
>>>
>>> * When fread() or print() see integer64 columns are present, bit64's
>>> namespace is now automatically loaded for convenience.
>>>
>>> However, when data.table loads the namespace there is a bug in this
>>> function :
>>>
>>> > data.table:::require_bit64
>>> function ()
>>> {
>>>     tt = try(requireNamespace("bit64", quietly = TRUE))
>>>     if (inherits(tt, "try-error"))
>>>         warning("Some columns are type 'integer64' but package bit64
>is
>>> not installed. Those columns will print as strange looking floating
>point
>>> data. There is no need to reload the data. Simply
>install.packages('bit64')
>>> to obtain the integer64 print method and print the data again.")
>>> }
>>>
>>> The intent was to display that nice helpful message to you.   Due to
>this
>>> report, I can see now that I shouldn't have wrapped
>requireNamespace() with
>>> try() because  requireNamespace() returns TRUE or FALSE anyway. Even
>though
>>> requireNamespace() prints 'Failed with error' it doesn't actually
>throw an
>>> error.  I'll change data.table's function to the following :
>>>
>>> if (!requireNamespace("bit64", quietly = TRUE))
>>>     warning("Some columns ...")
>>>
>>> bit64 is correctly Suggests not Depends.   It's just unfortunate the
>>> intended message wasn't displayed.
>>>
>>> Santosh, in future please follow the data.table support guide here:
>>> https://github.com/Rdatatable/data.table/wiki/Support.  r-help is
>not
>>> supposed to be used for package support.  The main thing though is
>thanks
>>> for helping me find this bug.
>>>
>>> Thanks,
>>> Matt
>>>
>>>
>>> On Wed, Mar 22, 2017 at 10:22 AM, William Dunlap <wdunlap at tibco.com>
>>> wrote:
>>>
>>>> Here is a way to reproduce the problem:
>>>>   > data.table::fread("9876543210\n") # number bigger than 2^31-1
>>>>                 V1
>>>>   1: 4.879661e-314
>>>> and your work-around does fix things up
>>>>   > data.table::fread("9876543210\n", colClasses="numeric")
>>>>              V1
>>>>   1: 9876543210
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Wed, Mar 22, 2017 at 9:58 AM, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>> > You failed to provide a reproducible example, and you posted HTML
>so
>>>> the quality of any answer will be limited by the quality of your
>question.
>>>> >
>>>> > My stab at your problem is that you should read ?fread, and in
>>>> particular should try using the colClasses argument.
>>>> > --
>>>> > Sent from my phone. Please excuse my brevity.
>>>> >
>>>> > On March 22, 2017 8:52:55 AM PDT, Santosh <santosh2005 at gmail.com>
>>>> wrote:
>>>> >>Hi
>>>> >>
>>>> >>I have been using "fread" utility of "data.table" packge .. on a
>>>> >>dataset of
>>>> >>about 20 million rows. It's a fantastic package to read datasets.
>Thank
>>>> >>you, Matt D.
>>>> >>
>>>> >>However, I am faced with a peculiar instance of  certain numbers
>in a
>>>> >>column being transformed.
>>>> >>
>>>> >>In the dataset, a column has values ranging from 1 to 9##########
>>>> >>(nchar(x)=11, e.g. 98765432109). After using "fread" to read the
>>>> >>dataset,
>>>> >>values in all the columns are displayed correctly upto the first
>1000
>>>> >>rows.
>>>> >>If "fread" is applied for reading >1000 rows of  the total of
>20Million
>>>> >>rows, the values in only this (column (having wide range of
>values) are
>>>> >>displayed as x.xxxxxxxe-3yy. (e.g. 3.5639877e-324)
>>>> >>
>>>> >>I tried reading all the columns as "character" and didn't help.
>>>> >>
>>>> >>Would highly appreciate your assistance!
>>>> >>
>>>> >>Thanks so much in advance.
>>>> >>
>>>> >>Best regards,
>>>> >>Santosh
>>>> >>
>>>> >>       [[alternative HTML version deleted]]
>>>> >>
>>>> >>______________________________________________
>>>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>PLEASE do read the posting guide
>>>> >>http://www.R-project.org/posting-guide.html
>>>> >>and provide commented, minimal, self-contained, reproducible
>code.
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible
>code.
>>>>
>>>
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dileepkunjaai at gmail.com  Thu Mar 23 11:07:01 2017
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Thu, 23 Mar 2017 15:37:01 +0530
Subject: [R] Extracting time-series data from netCDF file for a defined
 period using ncdf4 package
Message-ID: <CALTF6sm+r6VxwPdkE6d+XATqmNUqBKhxPe370X9KO=PCQFdr6Q@mail.gmail.com>

Dear All,

I am trying to extract a time series  from a netCDF file.

I want to extract data for the time period  1971-1  to 1990-12-31 only.

time axis units is  'days since 1850-1-1'

For one or two files I can use "count" argument,  but I have more than 100
such files and its time units are different.

Is there any easy way to extract the particular time period using ncdf4
package?

Thank you in advance.

-- 
DILEEPKUMAR. R
J R F, IIT DELHI

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Thu Mar 23 11:32:33 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Thu, 23 Mar 2017 10:32:33 +0000 (UTC)
Subject: [R] R package
References: <1997562274.3233497.1490265153123.ref@mail.yahoo.com>
Message-ID: <1997562274.3233497.1490265153123@mail.yahoo.com>

Hi all,

I have a data frame containing serial numbers for US. I also have a column showing the city in US, now my question is is there a package in R able to get the city in US as input and then return the name of State for that city?!

Thanks for any help!
Elahe


From cindylywang92 at gmail.com  Thu Mar 23 09:40:08 2017
From: cindylywang92 at gmail.com (Cindy Wang)
Date: Thu, 23 Mar 2017 16:40:08 +0800
Subject: [R] Error in leaps.
Message-ID: <CAAJ0LogPC0qZBFgX22RExGZT8YaGUK+7Z4nw-tn5DhczBr7Pcw@mail.gmail.com>

Dear All,

I am trying to use the model, Program Evaluation in order to determine the
economic impact of a policy change. While trying to run my own data on
RStudio, using the codes from the paper "An R Package for the Panel
Approach Method for Program Evaluation: Pampe" by Ainhoa Vega-Bayo, I keep
encountering an error that reads:

Error in leaps.setup(x, y, wt = weights, nbest = nbest, nvmax = nvmax,  :
  y and x different lengths

To be honest, I am very new to R so I am not familiar with how it works and
what every thing means, so its been quite a challenge for me to overcome
this error. The packages that I have installed are "Formula", "plm",
"leaps" and "pampe".

If anyone could provide some help and advice on how I could overcome this
error, it would be greatly appreciated.

I am happy to provide more information if needed.

Regards,
Cindy

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Mar 23 12:25:52 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 23 Mar 2017 11:25:52 +0000
Subject: [R] R package
In-Reply-To: <1997562274.3233497.1490265153123@mail.yahoo.com>
References: <1997562274.3233497.1490265153123.ref@mail.yahoo.com>
	<1997562274.3233497.1490265153123@mail.yahoo.com>
Message-ID: <CAKVAULP55BiSJTem3JT4L69VXSee9uZoMVWvSo18_bsYjd8-2g@mail.gmail.com>

Hi Elahe,

maybe the us.cities() in the maps package is what you look for.

HTH
Ulrik

On Thu, 23 Mar 2017 at 11:34 Elahe chalabi via R-help <r-help at r-project.org>
wrote:

> Hi all,
>
> I have a data frame containing serial numbers for US. I also have a column
> showing the city in US, now my question is is there a package in R able to
> get the city in US as input and then return the name of State for that
> city?!
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Thu Mar 23 12:59:35 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 23 Mar 2017 11:59:35 +0000 (UTC)
Subject: [R] Error in leaps.
In-Reply-To: <CAAJ0LogPC0qZBFgX22RExGZT8YaGUK+7Z4nw-tn5DhczBr7Pcw@mail.gmail.com>
References: <CAAJ0LogPC0qZBFgX22RExGZT8YaGUK+7Z4nw-tn5DhczBr7Pcw@mail.gmail.com>
Message-ID: <1598653307.1860508.1490270375933@mail.yahoo.com>

Hi Cindy,Welcome to R-help.
Have? a look at the posting guidelines and their suggestion about a minimal example. What we? need to help you is some sample data and a "minimal" amount of code that illustrates your problem. Someone may be able to guess the problem from your errror message but I'd not bet on it.

Have a look at http://adv-r.had.co.nz/Reproducibility.html for some excellent suggestions on how to do this. And please supply the data using the dput() command. It provides an exact copy of the data on your computer so we know we are working with exactly the same data you are.




 

    On Thursday, March 23, 2017 6:35 AM, Cindy Wang <cindylywang92 at gmail.com> wrote:
 

 Dear All,

I am trying to use the model, Program Evaluation in order to determine the
economic impact of a policy change. While trying to run my own data on
RStudio, using the codes from the paper "An R Package for the Panel
Approach Method for Program Evaluation: Pampe" by Ainhoa Vega-Bayo, I keep
encountering an error that reads:

Error in leaps.setup(x, y, wt = weights, nbest = nbest, nvmax = nvmax,? :
? y and x different lengths

To be honest, I am very new to R so I am not familiar with how it works and
what every thing means, so its been quite a challenge for me to overcome
this error. The packages that I have installed are "Formula", "plm",
"leaps" and "pampe".

If anyone could provide some help and advice on how I could overcome this
error, it would be greatly appreciated.

I am happy to provide more information if needed.

Regards,
Cindy

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From joeceradini at gmail.com  Thu Mar 23 14:37:24 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Thu, 23 Mar 2017 07:37:24 -0600
Subject: [R] string pattern matching
In-Reply-To: <CAF8bMca9-GG946ACE9r_-G=Ee4i5cSYWnGaNLMUrCgVHYG_gSQ@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
	<CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
	<CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>
	<CAF8bMca9-GG946ACE9r_-G=Ee4i5cSYWnGaNLMUrCgVHYG_gSQ@mail.gmail.com>
Message-ID: <CAKq2vL5fsifziYmuAGJSrt=n0aVhsVvifo89Y2f_ix83qB1rng@mail.gmail.com>

Thanks for the additional response, Bill. I did not want to bog down
the question with the full context of the function. Briefly, given a
set of nested and non-nested regression models, I want to compare AIC
(bigger model - smaller model) and do an LRT for all the nested models
that differ by a single predictor. All models, nested or not, would
also have an AIC value (I am aware of the critiques of mixing p-value
hypothesis testing and information criteria). So, not quite
MuMIn::dredge. The tricky part, for me, has been doing the comparisons
for only the nested models in a set that contains nested and
non-nested. I made some progress with the function, so I'll refrain
from bugging the list with the whole thing unless (when) I'm stuck
again.

For those interested in the motivation, I'm running with the idea of
trying to flag uninformative parameters which "steal" AIC model
weight, and potentially result in a misleading model set, depending
how the reader interprets the set.
Arnold, T. W. 2010. Uninformative parameters and model selection using
Akaike?s information criterion. Journal of Wildlife Management
74:1175?1178.
Murtaugh, P. 2014. In defense of P values. Ecology 95:611?617.

Joe

On Wed, Mar 22, 2017 at 9:11 AM, William Dunlap <wdunlap at tibco.com> wrote:
> You did not describe the goal of your pattern matching.  Were you trying
> to match any string that could be interpreted as an R expression containing
> X1 and X3 as additive terms?   If so, you could turn the string into a one-sided
> formula and use the terms() function.  E.g.,
>
> f <- function(string) {
>     fmla <- as.formula(paste("~", string))
>     term.labels <- attr(terms(fmla), "term.labels")
>     all(c("X1","X3") %in% term.labels)
> }
>
>> f("X3 + X2 + X1")
> [1] TRUE
>> f("- X3 + X2 + X1")
> [1] FALSE
>> f("X3 + X2 + log(X1)")
> [1] FALSE
>> f("X3 + X2 + log(X1) + X1")
> [1] TRUE
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Mar 22, 2017 at 6:39 AM, Joe Ceradini <joeceradini at gmail.com> wrote:
>> Wow. Thanks to everyone (Jim, Ng Bo Lin, Bert, David, and Ulrik) for
>> all the quick and helpful responses. They have given me a better
>> understanding of regular expressions, and certainly answered my
>> question.
>>
>> Joe
>>
>> On Wed, Mar 22, 2017 at 12:22 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>>> Hi Joe,
>>>
>>> you could also rethink your pattern:
>>>
>>> grep("x1 \\+ x2", test, value = TRUE)
>>>
>>> grep("x1 \\+ x", test, value = TRUE)
>>>
>>> grep("x1 \\+ x[0-9]", test, value = TRUE)
>>>
>>> HTH
>>> Ulrik
>>>
>>> On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>> Hi Joe,
>>>> This may help you:
>>>>
>>>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>>> multigrep<-function(x1,x2) {
>>>>  xbits<-unlist(strsplit(x1," "))
>>>>  nbits<-length(xbits)
>>>>  xans<-rep(FALSE,nbits)
>>>>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
>>>>  return(all(xans))
>>>> }
>>>> multigrep("x1 + x3","x1 + x2 + x3")
>>>> [1] TRUE
>>>> multigrep("x1 + x4","x1 + x2 + x3")
>>>> [1] FALSE
>>>>
>>>> Jim
>>>>
>>>> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com>
>>>> wrote:
>>>> > Hi Folks,
>>>> >
>>>> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
>>>> > Or is that a ridiculous question, since I'm trying to find something
>>>> > based on a pattern that doesn't exist?
>>>> >
>>>> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>>> > test
>>>> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>>>> >
>>>> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
>>>> > [1] "x1 + x2 + x3"
>>>> >
>>>> >
>>>> > But what if only have "x1 + x3" as the pattern and still want to
>>>> > return "x1 + x2 + x3"?
>>>> >
>>>> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
>>>> > character(0)
>>>> >
>>>> > I'm sure this looks like an odd question. I'm trying to build a
>>>> > function and stuck on this. Rather than dropping the whole function on
>>>> > the list, I thought I'd try one piece I needed help with...although I
>>>> > suspect that this question itself probably does bode well for my
>>>> > function :)
>>>> >
>>>> > Thanks!
>>>> > Joe
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide
>>>> > http://www.R-project.org/posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Cooperative Fish and Wildlife Research Unit
>> Zoology and Physiology Dept.
>> University of Wyoming
>> JoeCeradini at gmail.com / 914.707.8506
>> wyocoopunit.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org


From btupper at bigelow.org  Thu Mar 23 15:12:26 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 23 Mar 2017 10:12:26 -0400
Subject: [R] Extracting time-series data from netCDF file for a defined
	period using ncdf4 package
In-Reply-To: <CALTF6sm+r6VxwPdkE6d+XATqmNUqBKhxPe370X9KO=PCQFdr6Q@mail.gmail.com>
References: <CALTF6sm+r6VxwPdkE6d+XATqmNUqBKhxPe370X9KO=PCQFdr6Q@mail.gmail.com>
Message-ID: <163DE333-CA42-42CE-B7CA-CEFB2CA56976@bigelow.org>

Hi,

You problem as stated certainly is puzzling since you have one NCDF file but 'time units are different'.  I don't know what to make of that.

If you had a simpler case where data are dimensioned as [x,y,t] then you can convert dates to index use in ncdf4::ncvar_get()

I would start with a look-up-table of the dates in the file.

lut <- seq(from = as.Date("1850-01-01"), to = as.Date(Sys.Date()), by = 'day')

The use base::findInterval() to convert your start/stop dates to indices. 

mine <- as.Date(c("1971-01-01", "1990-03-01"))

startstop <- findInterval(mine, lut)


Is that at all close to what you seek?
Ben





> On Mar 23, 2017, at 6:07 AM, ???????? kunjaai <dileepkunjaai at gmail.com> wrote:
> 
> Dear All,
> 
> I am trying to extract a time series  from a netCDF file.
> 
> I want to extract data for the time period  1971-1  to 1990-12-31 only.
> 
> time axis units is  'days since 1850-1-1'
> 
> For one or two files I can use "count" argument,  but I have more than 100
> such files and its time units are different.
> 
> Is there any easy way to extract the particular time period using ncdf4
> package?
> 
> Thank you in advance.
> 
> -- 
> DILEEPKUMAR. R
> J R F, IIT DELHI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From emil.larsson at lansstyrelsen.se  Thu Mar 23 13:43:33 2017
From: emil.larsson at lansstyrelsen.se (Larsson Emil)
Date: Thu, 23 Mar 2017 12:43:33 +0000
Subject: [R] "Ordiellipse" in vegan package plot;
 how to plot sd for individual species
Message-ID: <1490273003294.23873@lansstyrelsen.se>

Hi R-Help,



I have been looking for an answer to this question for some time without success, so now my hope is that you will distribute it to your email subscribers, or direct me to another forum where this question is not off-topic.


I have a dataset with 224 rows (=sites), ca 20 environmental variables, and presence/absence data for ca 40 species. TI have done an RDA ordination using the vegan package and plotted all species. Now, I want to add standard deviation for each species as circles or ellipses.


How can I do this? I tried using "ordiellipse", guided by this similar request from 2010 answered by Jari Oksanen:


http://r-sig-ecology.471788.n2.nabble.com/Fwd-R-cca-standard-error-species-td4997341.html


I am close but I cannot make it work. I have attached the dataset (V=variables, S= species) and an example sketch of how the final plot should look.


Here is my script so far:


# add environmental and species data separately:

env<-read.delim("clipboard")
attach(env)
str(env)
species<-read.delim("clipboard")
attach(species)?
str(species)

# run RDA command and plot:
mod<-rda(species,env,scale=TRUE)
plot(mod, display = "species")
ordiellipse(mod, groups = rep(1, 224), display="lc", kind ="sd", draw = "polygon",
alpha = 127, label = FALSE, show.groups=TRUE, w = NULL, border = NULL, lty = NULL, lwd=NULL)





Very grateful for any help.



Best regards,


Emil Larsson

From jszhao at yeah.net  Thu Mar 23 15:24:25 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Thu, 23 Mar 2017 22:24:25 +0800
Subject: [R] Can fallback font be specified?
Message-ID: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>

Hi there,

I am a Chinese R user. I hope to plot the following code with Chinese in 
one font family, such as SimHei, but English in another font family, 
such as Times New Roman.

plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "serif")

In my case, the system default font is "SimSun", so the above code 
fallback "\u4F60\u597D", which is not in the font Times, to SimSun.

If I use:

plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "SimHei")

Then The "Hello" will in "SimHei" family, it's not as beautiful as Times.

Is it possible to specify the fallback font family in R? Any hints or 
suggestions?

Thanks in advance.

Best,
Jinsong

 > version
                _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          3.3
year           2017
month          03
day            06
svn rev        72310
language       R
version.string R version 3.3.3 (2017-03-06)
nickname       Another Canoe

 > Sys.getlocale()
[1] "LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese 
(Simplified)_China.936;LC_MONETARY=Chinese 
(Simplified)_China.936;LC_NUMERIC=C;LC_TIME=Chinese (Simplified)_China.936"


From paulbernal07 at gmail.com  Thu Mar 23 16:22:47 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 23 Mar 2017 10:22:47 -0500
Subject: [R] Modeling Time Series with Missing Observations
Message-ID: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>

Dear all,

Hope you are doing well. I am trying to model the historical number of
transits of a particular market segment, but the problem is that I have
missing data.

I am working with monthly data, so I have 12 observations per year (in
general). The problem is that, when I bring the data from the database, the
following happens, for example:

January-2000, Feb-2000, Apr-2000, Jun 2000 (I have missing observations)

when I am supposed to have the sequence January-2000, Feb-2000, Mar-2000,
Apr-2000, May-2000, Jun-2000, etc.

How can I model a time series when there are missing months? I was planning
making up fictional or fake observations with a value of 1 to fill in the
gaps but not sure if this is a reasonable approach.

Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 23 16:42:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 23 Mar 2017 08:42:52 -0700
Subject: [R] Modeling Time Series with Missing Observations
In-Reply-To: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>
References: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>
Message-ID: <21B26FE4-6E71-406E-9F56-7024D9A3D61B@dcn.davis.ca.us>

Even the most basic introduction to R discusses the use of NA for missing data. Injecting values that could be mistaken for actual readings is a dangerous approach. You can use the merge function to introduce missing rows into zoo objects or data frames. 
-- 
Sent from my phone. Please excuse my brevity.

On March 23, 2017 8:22:47 AM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear all,
>
>Hope you are doing well. I am trying to model the historical number of
>transits of a particular market segment, but the problem is that I have
>missing data.
>
>I am working with monthly data, so I have 12 observations per year (in
>general). The problem is that, when I bring the data from the database,
>the
>following happens, for example:
>
>January-2000, Feb-2000, Apr-2000, Jun 2000 (I have missing
>observations)
>
>when I am supposed to have the sequence January-2000, Feb-2000,
>Mar-2000,
>Apr-2000, May-2000, Jun-2000, etc.
>
>How can I model a time series when there are missing months? I was
>planning
>making up fictional or fake observations with a value of 1 to fill in
>the
>gaps but not sure if this is a reasonable approach.
>
>Any help and/or guidance will be greatly appreciated,
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Mar 23 16:48:29 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Mar 2017 08:48:29 -0700
Subject: [R] string pattern matching
In-Reply-To: <CAKq2vL5fsifziYmuAGJSrt=n0aVhsVvifo89Y2f_ix83qB1rng@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
	<CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
	<CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>
	<CAF8bMca9-GG946ACE9r_-G=Ee4i5cSYWnGaNLMUrCgVHYG_gSQ@mail.gmail.com>
	<CAKq2vL5fsifziYmuAGJSrt=n0aVhsVvifo89Y2f_ix83qB1rng@mail.gmail.com>
Message-ID: <CAF8bMcYKHXaepm24t9eXv8hu45bmwGGJ5VJopQ8CXokn6n9SWQ@mail.gmail.com>

If you are trying to see if one model nested in another then I think
looking at the 'term.labels' attribute of terms(formula) is the way to
go.  Most formula-based modelling functions store the output of
terms(formula) in their output and many supply a method for the terms
function that extracts that from their output.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Mar 23, 2017 at 6:37 AM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Thanks for the additional response, Bill. I did not want to bog down
> the question with the full context of the function. Briefly, given a
> set of nested and non-nested regression models, I want to compare AIC
> (bigger model - smaller model) and do an LRT for all the nested models
> that differ by a single predictor. All models, nested or not, would
> also have an AIC value (I am aware of the critiques of mixing p-value
> hypothesis testing and information criteria). So, not quite
> MuMIn::dredge. The tricky part, for me, has been doing the comparisons
> for only the nested models in a set that contains nested and
> non-nested. I made some progress with the function, so I'll refrain
> from bugging the list with the whole thing unless (when) I'm stuck
> again.
>
> For those interested in the motivation, I'm running with the idea of
> trying to flag uninformative parameters which "steal" AIC model
> weight, and potentially result in a misleading model set, depending
> how the reader interprets the set.
> Arnold, T. W. 2010. Uninformative parameters and model selection using
> Akaike?s information criterion. Journal of Wildlife Management
> 74:1175?1178.
> Murtaugh, P. 2014. In defense of P values. Ecology 95:611?617.
>
> Joe
>
> On Wed, Mar 22, 2017 at 9:11 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> You did not describe the goal of your pattern matching.  Were you trying
>> to match any string that could be interpreted as an R expression containing
>> X1 and X3 as additive terms?   If so, you could turn the string into a one-sided
>> formula and use the terms() function.  E.g.,
>>
>> f <- function(string) {
>>     fmla <- as.formula(paste("~", string))
>>     term.labels <- attr(terms(fmla), "term.labels")
>>     all(c("X1","X3") %in% term.labels)
>> }
>>
>>> f("X3 + X2 + X1")
>> [1] TRUE
>>> f("- X3 + X2 + X1")
>> [1] FALSE
>>> f("X3 + X2 + log(X1)")
>> [1] FALSE
>>> f("X3 + X2 + log(X1) + X1")
>> [1] TRUE
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Mar 22, 2017 at 6:39 AM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>> Wow. Thanks to everyone (Jim, Ng Bo Lin, Bert, David, and Ulrik) for
>>> all the quick and helpful responses. They have given me a better
>>> understanding of regular expressions, and certainly answered my
>>> question.
>>>
>>> Joe
>>>
>>> On Wed, Mar 22, 2017 at 12:22 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>>>> Hi Joe,
>>>>
>>>> you could also rethink your pattern:
>>>>
>>>> grep("x1 \\+ x2", test, value = TRUE)
>>>>
>>>> grep("x1 \\+ x", test, value = TRUE)
>>>>
>>>> grep("x1 \\+ x[0-9]", test, value = TRUE)
>>>>
>>>> HTH
>>>> Ulrik
>>>>
>>>> On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>>
>>>>> Hi Joe,
>>>>> This may help you:
>>>>>
>>>>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>>>> multigrep<-function(x1,x2) {
>>>>>  xbits<-unlist(strsplit(x1," "))
>>>>>  nbits<-length(xbits)
>>>>>  xans<-rep(FALSE,nbits)
>>>>>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
>>>>>  return(all(xans))
>>>>> }
>>>>> multigrep("x1 + x3","x1 + x2 + x3")
>>>>> [1] TRUE
>>>>> multigrep("x1 + x4","x1 + x2 + x3")
>>>>> [1] FALSE
>>>>>
>>>>> Jim
>>>>>
>>>>> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <joeceradini at gmail.com>
>>>>> wrote:
>>>>> > Hi Folks,
>>>>> >
>>>>> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the pattern?
>>>>> > Or is that a ridiculous question, since I'm trying to find something
>>>>> > based on a pattern that doesn't exist?
>>>>> >
>>>>> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
>>>>> > test
>>>>> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
>>>>> >
>>>>> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
>>>>> > [1] "x1 + x2 + x3"
>>>>> >
>>>>> >
>>>>> > But what if only have "x1 + x3" as the pattern and still want to
>>>>> > return "x1 + x2 + x3"?
>>>>> >
>>>>> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
>>>>> > character(0)
>>>>> >
>>>>> > I'm sure this looks like an odd question. I'm trying to build a
>>>>> > function and stuck on this. Rather than dropping the whole function on
>>>>> > the list, I thought I'd try one piece I needed help with...although I
>>>>> > suspect that this question itself probably does bode well for my
>>>>> > function :)
>>>>> >
>>>>> > Thanks!
>>>>> > Joe
>>>>> >
>>>>> > ______________________________________________
>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > PLEASE do read the posting guide
>>>>> > http://www.R-project.org/posting-guide.html
>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Cooperative Fish and Wildlife Research Unit
>>> Zoology and Physiology Dept.
>>> University of Wyoming
>>> JoeCeradini at gmail.com / 914.707.8506
>>> wyocoopunit.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org


From joeceradini at gmail.com  Thu Mar 23 16:56:11 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Thu, 23 Mar 2017 09:56:11 -0600
Subject: [R] string pattern matching
In-Reply-To: <CAF8bMcYKHXaepm24t9eXv8hu45bmwGGJ5VJopQ8CXokn6n9SWQ@mail.gmail.com>
References: <CAKq2vL51rEzr5w7cB-kL9GQW-avv8S6H3tX9UrfmuMSBqvJ8OA@mail.gmail.com>
	<CA+8X3fWSpiJCuQrjiYXrqFhvcDMFy_wKdWYrdah6L7WksmGAxg@mail.gmail.com>
	<CAKVAULN7_UkaK7Z22yH5vO-vzPksqMp+jqXrnnqe4yqMoYYYAA@mail.gmail.com>
	<CAKq2vL6Hk5emy4y7rq7TiNh9mkT75wocMccMcxLLo2UVuFhqLA@mail.gmail.com>
	<CAF8bMca9-GG946ACE9r_-G=Ee4i5cSYWnGaNLMUrCgVHYG_gSQ@mail.gmail.com>
	<CAKq2vL5fsifziYmuAGJSrt=n0aVhsVvifo89Y2f_ix83qB1rng@mail.gmail.com>
	<CAF8bMcYKHXaepm24t9eXv8hu45bmwGGJ5VJopQ8CXokn6n9SWQ@mail.gmail.com>
Message-ID: <CAKq2vL6Kcma-jdq3xTmTefbYQV-+QS2e+XFT-ksHYmW8VpqW_Q@mail.gmail.com>

Oh, I see the utility of that now. Definitely will be using "term.labels"
(which I was not aware of). Thanks!

On Thu, Mar 23, 2017 at 9:48 AM, William Dunlap <wdunlap at tibco.com> wrote:

> If you are trying to see if one model nested in another then I think
> looking at the 'term.labels' attribute of terms(formula) is the way to
> go.  Most formula-based modelling functions store the output of
> terms(formula) in their output and many supply a method for the terms
> function that extracts that from their output.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Mar 23, 2017 at 6:37 AM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> > Thanks for the additional response, Bill. I did not want to bog down
> > the question with the full context of the function. Briefly, given a
> > set of nested and non-nested regression models, I want to compare AIC
> > (bigger model - smaller model) and do an LRT for all the nested models
> > that differ by a single predictor. All models, nested or not, would
> > also have an AIC value (I am aware of the critiques of mixing p-value
> > hypothesis testing and information criteria). So, not quite
> > MuMIn::dredge. The tricky part, for me, has been doing the comparisons
> > for only the nested models in a set that contains nested and
> > non-nested. I made some progress with the function, so I'll refrain
> > from bugging the list with the whole thing unless (when) I'm stuck
> > again.
> >
> > For those interested in the motivation, I'm running with the idea of
> > trying to flag uninformative parameters which "steal" AIC model
> > weight, and potentially result in a misleading model set, depending
> > how the reader interprets the set.
> > Arnold, T. W. 2010. Uninformative parameters and model selection using
> > Akaike?s information criterion. Journal of Wildlife Management
> > 74:1175?1178.
> > Murtaugh, P. 2014. In defense of P values. Ecology 95:611?617.
> >
> > Joe
> >
> > On Wed, Mar 22, 2017 at 9:11 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >> You did not describe the goal of your pattern matching.  Were you trying
> >> to match any string that could be interpreted as an R expression
> containing
> >> X1 and X3 as additive terms?   If so, you could turn the string into a
> one-sided
> >> formula and use the terms() function.  E.g.,
> >>
> >> f <- function(string) {
> >>     fmla <- as.formula(paste("~", string))
> >>     term.labels <- attr(terms(fmla), "term.labels")
> >>     all(c("X1","X3") %in% term.labels)
> >> }
> >>
> >>> f("X3 + X2 + X1")
> >> [1] TRUE
> >>> f("- X3 + X2 + X1")
> >> [1] FALSE
> >>> f("X3 + X2 + log(X1)")
> >> [1] FALSE
> >>> f("X3 + X2 + log(X1) + X1")
> >> [1] TRUE
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Wed, Mar 22, 2017 at 6:39 AM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> >>> Wow. Thanks to everyone (Jim, Ng Bo Lin, Bert, David, and Ulrik) for
> >>> all the quick and helpful responses. They have given me a better
> >>> understanding of regular expressions, and certainly answered my
> >>> question.
> >>>
> >>> Joe
> >>>
> >>> On Wed, Mar 22, 2017 at 12:22 AM, Ulrik Stervbo <
> ulrik.stervbo at gmail.com> wrote:
> >>>> Hi Joe,
> >>>>
> >>>> you could also rethink your pattern:
> >>>>
> >>>> grep("x1 \\+ x2", test, value = TRUE)
> >>>>
> >>>> grep("x1 \\+ x", test, value = TRUE)
> >>>>
> >>>> grep("x1 \\+ x[0-9]", test, value = TRUE)
> >>>>
> >>>> HTH
> >>>> Ulrik
> >>>>
> >>>> On Wed, 22 Mar 2017 at 02:10 Jim Lemon <drjimlemon at gmail.com> wrote:
> >>>>>
> >>>>> Hi Joe,
> >>>>> This may help you:
> >>>>>
> >>>>> test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> >>>>> multigrep<-function(x1,x2) {
> >>>>>  xbits<-unlist(strsplit(x1," "))
> >>>>>  nbits<-length(xbits)
> >>>>>  xans<-rep(FALSE,nbits)
> >>>>>  for(i in 1:nbits) if(length(grep(xbits[i],x2))) xans[i]<-TRUE
> >>>>>  return(all(xans))
> >>>>> }
> >>>>> multigrep("x1 + x3","x1 + x2 + x3")
> >>>>> [1] TRUE
> >>>>> multigrep("x1 + x4","x1 + x2 + x3")
> >>>>> [1] FALSE
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>> On Wed, Mar 22, 2017 at 10:50 AM, Joe Ceradini <
> joeceradini at gmail.com>
> >>>>> wrote:
> >>>>> > Hi Folks,
> >>>>> >
> >>>>> > Is there a way to find "x1 + x2 + x3" given "x1 + x3" as the
> pattern?
> >>>>> > Or is that a ridiculous question, since I'm trying to find
> something
> >>>>> > based on a pattern that doesn't exist?
> >>>>> >
> >>>>> > test <- c("x1", "x2", "x3", "x1 + x2 + x3")
> >>>>> > test
> >>>>> > [1] "x1"           "x2"           "x3"           "x1 + x2 + x3"
> >>>>> >
> >>>>> > grep("x1 + x2", test, fixed=TRUE, value = TRUE)
> >>>>> > [1] "x1 + x2 + x3"
> >>>>> >
> >>>>> >
> >>>>> > But what if only have "x1 + x3" as the pattern and still want to
> >>>>> > return "x1 + x2 + x3"?
> >>>>> >
> >>>>> > grep("x1 + x3", test, fixed=TRUE, value = TRUE)
> >>>>> > character(0)
> >>>>> >
> >>>>> > I'm sure this looks like an odd question. I'm trying to build a
> >>>>> > function and stuck on this. Rather than dropping the whole
> function on
> >>>>> > the list, I thought I'd try one piece I needed help
> with...although I
> >>>>> > suspect that this question itself probably does bode well for my
> >>>>> > function :)
> >>>>> >
> >>>>> > Thanks!
> >>>>> > Joe
> >>>>> >
> >>>>> > ______________________________________________
> >>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> > PLEASE do read the posting guide
> >>>>> > http://www.R-project.org/posting-guide.html
> >>>>> > and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>
> >>> --
> >>> Cooperative Fish and Wildlife Research Unit
> >>> Zoology and Physiology Dept.
> >>> University of Wyoming
> >>> JoeCeradini at gmail.com / 914.707.8506
> >>> wyocoopunit.org
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Cooperative Fish and Wildlife Research Unit
> > Zoology and Physiology Dept.
> > University of Wyoming
> > JoeCeradini at gmail.com / 914.707.8506
> > wyocoopunit.org
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Mar 23 17:06:28 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 23 Mar 2017 16:06:28 +0000
Subject: [R] argument to 'which' is not logical
In-Reply-To: <586684963.372211.1490184904525@mail.yahoo.com>
References: <586684963.372211.1490184904525.ref@mail.yahoo.com>
	<586684963.372211.1490184904525@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E26724056F0B2595@GBTEDVPEXCMB04.corp.lgc-group.com>

> I'm trying to run the code:?inds<-which(c != 0 ), but it gave me error:?Error in
> base::which(x, arr.ind, useNames, ...) :?? argument to 'which' is not logical

Your coefficients are not a numeric vector. You'll have to sort that out by extracting or testing the individual values. A look at your output _tells you_ that the object is a sparse matrix of class dgCMatrix . Looking that up would tell you that the nonzero elements are in slot x of the object. So it may be unnecessary to ask which are zero; maybe you just need c at x (though I also would recommend you avoid using common function names as variable names)

If you do need to test elements for zeroes, though, note that '==' and '!=' are not usually recommended for comparisons with zero owing to finite numerical representation. So that may well be unwise. See the Note in ?'=='.

S Ellison



> Here is code:
> alphas <- seq(0, 1, by=.002)mses <- numeric(501)mins <- numeric(501)maxes
> <- numeric(501)for(i in 1:501){? cvfits <- cv.glmnet(Train2,
> Train$Item_Outlet_Sales, alpha=alphas[i], nfolds=32)? loc <-
> which(cvfits$lambda==cvfits$lambda.min)? maxes[i] <- cvfits$lambda %>%
> max? mins[i] <- cvfits$lambda %>% min? mses[i] <- cvfits$cvm[loc]}`%ni%`<-
> Negate(`%in%`)c<-coef(cvfits,s='lambda.1se',exact=TRUE)inds<-which(c != 0
> ) Here is the c content looks like:?> c33 x 1 sparse Matrix of class
> "dgCMatrix"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1(Intercept) ? ? ? ? ? ? ? ? ? ? ?7.476895931Item_Fa
> t_Content.Low.Fat ? ? ? ? . ? ? ? ? ?Item_Fat_Content.Regular ? ? ? ? . ? ? ? ? ?Item_Type
> .Breads ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Breakfast ? ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Canned
> ? ? ? ? ? ? 0.003430669Item_Type.Dairy ? ? ? ? ? ? ? ? -
> 0.022579673Item_Type.Frozen.Foods ? ? ? ? ?-
> 0.008216547Item_Type.Fruits.and.Vegetables ?. ? ? ? ? ?Item_Type.Hard.Drinks
> ? ? ? ? ?. ? ? ? ? ?Item_Type.Health.and.Hygiene ? ? . ? ? ? ? ?Item_Type.Household
>  ? ?. ? ? ? ? ?Item_Type.Meat ? ? ? ? ? ? ? ? ? . ? ? ? ? ?Item_Type.Others ? ? ? ? ? ? ? ? . ? ? ? ? ?Item
> _Type.Seafood ? ? ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Snack.Foods ? ? ? ? ? ?. ? ? ? ? ?Item_Type.S
> oft.Drinks ? ? ? ? ? ?. ? ? ? ? ?Item_Type.Starchy.Foods ? ? ? ? ?. ? ? ? ? ?Outlet_Establishm
> ent_Year.1987 ?-
> 0.345927916Outlet_Establishment_Year.1997 ? 1.692678186Outlet_Establishm
> ent_Year.1998 ?-
> 2.259508290Outlet_Establishment_Year.1999 ? . ? ? ? ? ?Outlet_Establishment_Y
> ear.2002 ?-
> 0.032971913Outlet_Establishment_Year.2004 ? 1.756230495Outlet_Establishm
> ent_Year.2007 ? . ? ? ? ? ?Outlet_Establishment_Year.2009 ?-
> 0.549210057Outlet_Size.Medium ? ? ? ? ? ? ? 0.056897825Outlet_Size.Small
>  -
> 1.706006538Outlet_Location_Type.Tier.3 ? ? ?0.373456218Item_Identifier_Com
> binedFD ? ? ? . ? ? ? ? ?Item_MRP ? ? ? ? ? ? ? ? ? ? ? ? 0.505435352Item_Weight
> . ? ? ? ? ?Item_Visibility_MeanRatio ? ? ? -0.007274202
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From dcarlson at tamu.edu  Thu Mar 23 17:47:50 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 23 Mar 2017 16:47:50 +0000
Subject: [R] "Ordiellipse" in vegan package plot;
 how to plot sd for individual species
In-Reply-To: <1490273003294.23873@lansstyrelsen.se>
References: <1490273003294.23873@lansstyrelsen.se>
Message-ID: <d3cd24cfedbc4263a04822d0f34e32b1@exch-2p-mbx-w2.ads.tamu.edu>

Most attachments (including your data and graph) get stripped from mail sent to the list. If the data are a plain text file, giving the file an extension of .txt will usually let it survive the trip (even if it is a .csv file). Graphics will survive if they are .png files. 

If the datasets are not large, use dput(env) and dput(species), and then paste the output of those commands into your email message. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Larsson Emil
Sent: Thursday, March 23, 2017 7:44 AM
To: r-help at r-project.org
Subject: [R] "Ordiellipse" in vegan package plot; how to plot sd for individual species

Hi R-Help,



I have been looking for an answer to this question for some time without success, so now my hope is that you will distribute it to your email subscribers, or direct me to another forum where this question is not off-topic.


I have a dataset with 224 rows (=sites), ca 20 environmental variables, and presence/absence data for ca 40 species. TI have done an RDA ordination using the vegan package and plotted all species. Now, I want to add standard deviation for each species as circles or ellipses.


How can I do this? I tried using "ordiellipse", guided by this similar request from 2010 answered by Jari Oksanen:


http://r-sig-ecology.471788.n2.nabble.com/Fwd-R-cca-standard-error-species-td4997341.html


I am close but I cannot make it work. I have attached the dataset (V=variables, S= species) and an example sketch of how the final plot should look.


Here is my script so far:


# add environmental and species data separately:

env<-read.delim("clipboard")
attach(env)
str(env)
species<-read.delim("clipboard")
attach(species)?
str(species)

# run RDA command and plot:
mod<-rda(species,env,scale=TRUE)
plot(mod, display = "species")
ordiellipse(mod, groups = rep(1, 224), display="lc", kind ="sd", draw = "polygon",
alpha = 127, label = FALSE, show.groups=TRUE, w = NULL, border = NULL, lty = NULL, lwd=NULL)





Very grateful for any help.



Best regards,


Emil Larsson
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From munevver.rock at gmail.com  Thu Mar 23 17:55:58 2017
From: munevver.rock at gmail.com (munevver kaya)
Date: Thu, 23 Mar 2017 19:55:58 +0300
Subject: [R] (no subject)
Message-ID: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>

Dear Sir/Madam,
I do not want to receive any email by r-help. Can you delete me in your
mail list? Thank you.

Sincerely,
Munevver Basman

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 23 18:57:08 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 23 Mar 2017 18:57:08 +0100
Subject: [R] (no subject)
In-Reply-To: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
References: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
Message-ID: <9929CE3C-AB9D-4CBE-8931-96C3C852E2A5@gmail.com>

The recipe for unsubscribing is in the footer of every r-help message. General readers of the list can not do it for you.

-pd

> On 23 Mar 2017, at 17:55 , munevver kaya <munevver.rock at gmail.com> wrote:
> 
> Dear Sir/Madam,
> I do not want to receive any email by r-help. Can you delete me in your
> mail list? Thank you.
> 
> Sincerely,
> Munevver Basman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chalabi.elahe at yahoo.de  Thu Mar 23 19:19:31 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Thu, 23 Mar 2017 18:19:31 +0000 (UTC)
Subject: [R] correct subset in R
References: <1403504767.2556008.1490293171879.ref@mail.yahoo.com>
Message-ID: <1403504767.2556008.1490293171879@mail.yahoo.com>

Hi all,
I found an answer to the last question I asked in this group and now I want to have a correct subset of my data:

I have a following df1 which is list of all cities in US and their states:

$ name         : Factor w/ 1008 levels "Ackley","Ackworth",..: 1 2 3 
$ state        : Factor w/ 1 level "Iowa": 1 1 1 1 1 1 1 1 1 1 .

the other data frame I have is df2 which is the list of cities I have and I want to get their state from df1:

$ cities : Factor w/ 547 levels "Afton","Boone","Calmar",...: 1 2 3 


now how should I subset in a way to get related states of $cities from df1?

Thanks for any help!
Elahe


From ruipbarradas at sapo.pt  Thu Mar 23 19:28:39 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 23 Mar 2017 18:28:39 +0000
Subject: [R] correct subset in R
In-Reply-To: <1403504767.2556008.1490293171879@mail.yahoo.com>
References: <1403504767.2556008.1490293171879.ref@mail.yahoo.com>
	<1403504767.2556008.1490293171879@mail.yahoo.com>
Message-ID: <58D413D7.7020105@sapo.pt>

Hello,

I would try ?merge, in particular see the arguments by.x and by.y

Hope this helps,

Rui Barradas

Em 23-03-2017 18:19, Elahe chalabi via R-help escreveu:
> Hi all,
> I found an answer to the last question I asked in this group and now I want to have a correct subset of my data:
>
> I have a following df1 which is list of all cities in US and their states:
>
> $ name         : Factor w/ 1008 levels "Ackley","Ackworth",..: 1 2 3
> $ state        : Factor w/ 1 level "Iowa": 1 1 1 1 1 1 1 1 1 1 .
>
> the other data frame I have is df2 which is the list of cities I have and I want to get their state from df1:
>
> $ cities : Factor w/ 547 levels "Afton","Boone","Calmar",...: 1 2 3
>
>
> now how should I subset in a way to get related states of $cities from df1?
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Mar 23 20:58:43 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Mar 2017 12:58:43 -0700
Subject: [R] correct subset in R
In-Reply-To: <58D413D7.7020105@sapo.pt>
References: <1403504767.2556008.1490293171879.ref@mail.yahoo.com>
	<1403504767.2556008.1490293171879@mail.yahoo.com>
	<58D413D7.7020105@sapo.pt>
Message-ID: <38A4892C-471B-49ED-AFCF-0523CD6BFFC9@comcast.net>


> On Mar 23, 2017, at 11:28 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I would try ?merge, in particular see the arguments by.x and by.y
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 23-03-2017 18:19, Elahe chalabi via R-help escreveu:
>> Hi all,
>> I found an answer to the last question I asked in this group and now I want to have a correct subset of my data:
>> 
>> I have a following df1 which is list of all cities in US and their states:
>> 
>> $ name         : Factor w/ 1008 levels "Ackley","Ackworth",..: 1 2 3
>> $ state        : Factor w/ 1 level "Iowa": 1 1 1 1 1 1 1 1 1 1 .
>> 
>> the other data frame I have is df2 which is the list of cities I have and I want to get their state from df1:
>> 
>> $ cities : Factor w/ 547 levels "Afton","Boone","Calmar",...: 1 2 3
>> 
>> 
>> now how should I subset in a way to get related states of $cities from df1?

I think this is the proper use of the `match` function or its derivative `%in%`:

df1[ match(df2$cities, df1$name, no.match=0) , "state"]  # numeric indexing

df1[ df1$name %in% df2$cities , "state"] # logical indexing


Untested since the example is incomplete.

-- 
David

>> 
>> Thanks for any help!
>> Elahe
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Thu Mar 23 22:30:02 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 23 Mar 2017 21:30:02 +0000
Subject: [R] r question
In-Reply-To: <CA+mU4QHPWF5ZRi_xsU73A8_fsezxyTnU7=YuvLZ3kK_a6SunQg@mail.gmail.com>
References: <CA+mU4QETQODjx5zir0EUEBs4arhYoWSxYM9DWz3d3heE2uXU0g@mail.gmail.com>
	<58D2F270.2@sapo.pt>
	<CA+mU4QHPWF5ZRi_xsU73A8_fsezxyTnU7=YuvLZ3kK_a6SunQg@mail.gmail.com>
Message-ID: <58D43E5A.4070701@sapo.pt>

Hello,

Please keep this on the list. I'm cc-ing r-help and so should you always.

I got no error, just warning messages. After a long output I got the 
following.

NOTE: HARD MAXIMUM GENERATION LIMIT HIT

Solution Fitness Value: -2.592094e+03

Parameters at the Solution (parameter, gradient):

  X[ 1] :        7.390657e-02    G[ 1] : 0.000000e+00
  X[ 2] :        3.193020e-01    G[ 2] : 0.000000e+00
  X[ 3] :        6.826336e-01    G[ 3] : 0.000000e+00
  X[ 4] :        4.481256e-01    G[ 4] : 0.000000e+00
  X[ 5] :        5.325378e-01    G[ 5] : 0.000000e+00
  X[ 6] :        1.512199e-01    G[ 6] : 0.000000e+00
  X[ 7] :        -3.160607e-01   G[ 7] : 0.000000e+00
  X[ 8] :        -1.762058e-01   G[ 8] : 0.000000e+00

Solution Found Generation 6
Number of Generations Run 6

Thu Mar 23 21:26:47 2017
Total run time : 0 hours 0 minutes and 36 seconds
[1]  0.07390657  0.33930201  0.72263362  0.44812561  0.53253780  0.15121993
[7] -0.31606071 -0.17620576
Warning messages:
1: In genoud(obj, nvars, max = TRUE, pop.size = 100, max.generations = 6,  :
   'starting.values' which are outside of the bounds have been provided.
            Continuing, but unexpected behavior can occur with 
'boundary.enforcement!=0'
2: In genoud(obj, nvars, max = TRUE, pop.size = 100, max.generations = 6,  :
   Stopped because hard maximum generation limit was hit.

I cannot reproduce your error message.

Rui Barradas

Em 23-03-2017 02:45, ??? escreveu:
> Hi, thanks for your help.I run again my code
> this is my cold.
> run"maxloglik(x1,numcut,Ti,censor,confound,domain2,initial2,0.02)$par_corr"
> library(rgenoud)
> library(survival)
> N=500
> ei=rexp(N)
> censor=rep(1,N)
> x1=runif(N)
> x2=runif(N)
> x3=runif(N)
> truecut=c(0.3,0.6)
> dum1=1*(x1>truecut[1] & x1<truecut[2])
> dum2=1*(x1>truecut[2])
> x_true=cbind(dum1,dum2,x2,x3)
> relativerisk<- matrix(log(c(1,1,2,2,
>                              1.25,1.5,2,2,
>                              1.5,2.5,2,2,
>                              1.75,2.5,2,2,
>                              2,3,2,2,
>                              3,5,2,2,
>                              4,7,2,2,
>                              5,9,2,2,
>                              6,11,2,2)),ncol=4,byrow = TRUE)
> beta_true<-relativerisk[1,]  #I wanna see the effect of different
> relativerisk,this way I choose relativerisk[1,]
> Ti=exp(x_true%*%beta_true)*ei
> confound=cbind(x2,x3)
> numcut=3
> initial2<-c(0.1303100 ,0.3259150 ,0.6264413,0.47507966 ,-0.03886098
> ,-0.21062905 ,-0.31606071 ,-0.17620576)
> domain2<-matrix(c(rep(c(0.05,0.95),numcut),rep(c(0,5),numcut+dim(confound)[2])),ncol=2,byrow
> = TRUE)
> loglikfun <- function(beta, formula) {
>    beta1 <- coxph(formula, init = beta,
> control=list('iter.max'=0))#iteration is zero
>    return(beta1$loglik[2])
> }
> obj <- function(xx){
>    cutoff <- xx[1:numcut_global] #cutpoint
>    cut_design <-
> cut(target_global,breaks=c(0,sort(cutoff)+seq(0,gap_global*(length(cutoff)-1),by=gap_global),target_max),quantile=FALSE,labels=c(0:numcut_global))
>    beta <- xx[(numcut+1):nvars]  #coefficients of parameters
>    logliks <-
> loglikfun(beta,Surv(time_global,censor_global)~cut_design+confound_global)
>    return(logliks)
> }
> maxloglik<-function(target,numcut,time,censor,confound,domain2,initial2,gap){
>    time_global<<-time
>    censor_global<<-censor
>    target_global<<-target
>    nvars<<-2*numcut+dim(confound)[2]
>    confound_global<<-confound
>    numcut_global<<-numcut
>    target_max<<-max(target)
>    gap_global<<-gap
>    ccc<-genoud(obj, nvars, max=TRUE, pop.size=100, max.generations=6,
> wait.generations=10,
>                hard.generation.limit=TRUE, starting.values=initial2,
> MemoryMatrix=TRUE,
>                Domains=domain2, solution.tolerance=0.001,
>                gr=NULL, boundary.enforcement=2, lexical=FALSE,
> gradient.check=TRUE)
>    ccc$par_corr<-ccc$par #the coefficients of genoud
>
> ccc$par_corr[1:numcut]<-sort(ccc$par[1:numcut])+seq(0,gap_global*(numcut-1),by=gap_global)
> #sort cutpoint
>    return(ccc)
> }
>
>
> but I get error message like this
>  > maxloglik(x1,numcut,Ti,censor,confound,domain2,initial2,0.02)$par_corr
>
>
> Thu Mar 23 10:38:27 2017
> Domains:
>   5.000000e-02   <=  X1   <=    9.500000e-01
>   5.000000e-02   <=  X2   <=    9.500000e-01
>   5.000000e-02   <=  X3   <=    9.500000e-01
>   0.000000e+00   <=  X4   <=    5.000000e+00
>   0.000000e+00   <=  X5   <=    5.000000e+00
>   0.000000e+00   <=  X6   <=    5.000000e+00
>   0.000000e+00   <=  X7   <=    5.000000e+00
>   0.000000e+00   <=  X8   <=    5.000000e+00
>
> Data Type: Floating Point
> Operators (code number, name, population)
> (1) Cloning........................... 15
> (2) Uniform Mutation.................. 12
> (3) Boundary Mutation................. 12
> (4) Non-Uniform Mutation.............. 12
> (5) Polytope Crossover................ 12
> (6) Simple Crossover.................. 12
> (7) Whole Non-Uniform Mutation........ 12
> (8) Heuristic Crossover............... 12
> (9) Local-Minimum Crossover........... 0
>
> HARD Maximum Number of Generations: 6
> Maximum Nonchanging Generations: 10
> Population size       : 100
> Convergence Tolerance: 1.000000e-03
>
> Using the BFGS Derivative Based Optimizer on the Best Individual Each
> Generation.
> Checking Gradients before Stopping.
> Not Using Out of Bounds Individuals and Not Allowing Trespassing.
>
> Maximization Problem.
> GENERATION: 0 (initializing the population)
> Fitness value... -2.579176e+03
> mean............ -3.480611e+03
> variance........ 1.187916e+05
> #unique......... 100, #Total UniqueCount: 100
> var 1:
> best............ 1.303100e-01
> mean............ 5.286724e-01
> variance........ 7.963177e-02
> var 2:
> best............ 3.259150e-01
> mean............ 4.996113e-01
> variance........ 5.772924e-02
> var 3:
> best............ 6.264413e-01
> mean............ 5.465332e-01
> variance........ 6.837739e-02
> var 4:
> best............ 4.750797e-01
> mean............ 2.524373e+00
> variance........ 2.104958e+00
> var 5:
> best............ -3.886098e-02
> mean............ 2.500733e+00
> variance........ 1.892662e+00
> var 6:
> best............ -2.106291e-01
> mean............ 2.578064e+00
> variance........ 2.202828e+00
> var 7:
> best............ -3.160607e-01
> mean............ 2.470152e+00
> variance........ 2.159971e+00
> var 8:
> best............ -1.762058e-01
> mean............ 2.550891e+00
> variance........ 1.880531e+00
>   Show Traceback
>   Rerun with Debug
>   Error in coxph.wtest(fit$var[nabeta, nabeta], temp, control$toler.chol) :
>    NA/NaN/Inf in foreign function call (arg 3)
>
> I don't know what happened.Thanks for your help.
>
> Meng-Ke
>
> 2017-03-23 5:53 GMT+08:00 Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>>:
>
>     Hello,
>
>     There's a paenthesis missing in
>
>     > relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
>     + beta_true<-relativerisk
>     Error: unexpected symbol in:
>     "relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
>     beta_true"
>
>     The correct instruction would be
>
>     relativerisk<- matrix(log(c(1,1,2,2)),ncol=4,byrow = TRUE)
>
>     And there's an error in your matrix multiply.
>
>      > Ti=exp(x_true%*%beta_true)*ei
>     Error in x_true %*% beta_true : non-conformable arguments
>
>     It can be corrected if you transpose beta_true.
>
>     Ti=exp(x_true %*% t(beta_true))*ei
>
>     At this point I've stoped running your code, I believe you must
>     revise it and try to see what's wrong instruction by instruction. Do
>     that and post again.
>     ALso, get rid of the <<-, use <-
>     If you do this, I'll explain the difference in the next answer to
>     your doubts.
>
>     Hope this helps,
>
>     Rui Barradas
>
>
>
>     Em 22-03-2017 08 <tel:22-03-2017%2008>:11, ??? escreveu:
>
>         Hi ,I have some question about simulate, I don't know how to
>         paste question
>         to this website,so I paste below.
>         I use genoud to find the maximum likelihood value, but when I
>         use numcut=3
>         ,it will get error message,like this "
>         coxph.wtest(fit$var[nabeta, nabeta],
>         temp, control$toler.chol) : NA/NaN/Inf"
>         and this is my code
>         library(rgenoud)
>         library(survival)
>         N=500
>         ei=rexp(N)
>         censor=rep(1,N)
>         x1=runif(N)
>         x2=runif(N)
>         x3=runif(N)
>         truecut=c(0.3,0.6)
>         dum1=1*(x1>truecut[1] & x1<truecut[2])
>         dum2=1*(x1>truecut[2])
>         x_true=cbind(dum1,dum2,x2,x3)
>         relativerisk<- matrix(log(c(1,1,2,2),ncol=4,byrow = TRUE)
>         beta_true<-relativerisk
>         Ti=exp(x_true%*%beta_true)*ei
>         confound=cbind(x2,x3)
>         initial2<-c(0.09,0.299,0.597,-0.17,-1.3,-3.1,-1.4,-1.12)
>         numcut=2
>
>         domain2<<-matrix(c(rep(c(0.05,0.95),numcut),rep(c(0,5),numcut+dim(confound)[2])),ncol=2,byrow
>         = TRUE)
>
>         loglikfun <- function(beta, formula) {
>             beta1 <- coxph(formula, init = beta,
>         control=list('iter.max'=0))#iteration is zero
>             return(beta1$loglik[2])
>         }
>         obj <- function(xx){
>             cutoff <- xx[1:numcut_global] #cutpoint
>             cut_design <-
>         cut(target_global,breaks=c(0,sort(cutoff)+seq(0,gap_global*(length(cutoff)-1),by=gap_global),target_max),quantile=FALSE,labels=c(0:numcut_global))
>             beta <- -xx[(numcut+1):nvars]  #coefficients of parameters
>             logliks <-
>         loglikfun(beta,Surv(time_global,censor_global)~cut_design+confound_global)
>             return(logliks)
>         }
>         maxloglik<-function(target,numcut,time,censor,confound,domain2,initial2,gap){
>             time_global<<-time
>             censor_global<<-censor
>             target_global<<-target
>             nvars<<-2*numcut+dim(confound)[2]
>             confound_global<<-confound
>             numcut_global<<-numcut
>             target_max<<-max(target)
>             gap_global<<-gap
>             ccc<-genoud(obj, nvars, max=TRUE, pop.size=100,
>         max.generations=6,
>         wait.generations=10,
>                         hard.generation.limit=TRUE,
>         starting.values=initial2,
>         MemoryMatrix=TRUE,
>                         Domains=domain2, solution.tolerance=0.001,
>                         gr=NULL, boundary.enforcement=2, lexical=FALSE,
>         gradient.check=TRUE)
>             ccc$par_corr<-ccc$par #the coefficients of genoud
>
>         ccc$par_corr[1:numcut]<-sort(ccc$par[1:numcut])+seq(0,gap_global*(numcut-1),by=gap_global)
>         #sort cutpoint
>             return(ccc)
>         }
>
>
>         maxloglik(x1,3,Ti,censor,confound,domain2,initial2,0.02)$par_corr
>
>         I have no idea about the error ,maybe is my initial is wrong.
>         thank you
>            From Meng-Ke
>
>                  [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Thu Mar 23 22:38:06 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Mar 2017 08:38:06 +1100
Subject: [R] (no subject)
In-Reply-To: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
References: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
Message-ID: <CA+8X3fWqvYtS4ozZLwFS4hZff7Gs6R=oUgriVB+2Bn9bCyQO7Q@mail.gmail.com>

Hi Munevver,

Go here:

https://stat.ethz.ch/mailman/listinfo/r-help

which is probably where you subscribed, and

UNSUBSCRIBE

Jim

On Fri, Mar 24, 2017 at 3:55 AM, munevver kaya <munevver.rock at gmail.com> wrote:
> Dear Sir/Madam,
> I do not want to receive any email by r-help. Can you delete me in your
> mail list? Thank you.
>
> Sincerely,
> Munevver Basman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marine.regis at hotmail.fr  Thu Mar 23 22:59:21 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 23 Mar 2017 21:59:21 +0000
Subject: [R] How to change parameter values as a function to time with the
 package "deSolve"
Message-ID: <AM5PR0701MB23389BB9261BDE8FC26479E2E23F0@AM5PR0701MB2338.eurprd07.prod.outlook.com>

Hello,

I am trying to solve an ODE in R using deSolve. With the following code, I expected the parameter ?gamma0? takes the values 5 at time step 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 and 10, and 0 otherwise. However, the print(gamma0) shows that ?gamma0? stays at 0.

Here is my ODE:

param <- c(a = 0.1, b = 1)
yini <- c(alpha0 = 0, beta0 = 0)

mod <- function(times, yini, param) {

  with(as.list(c(yini, parameters)), {

  gamma0 <- ifelse(times %in% seq(0,10,1), 5, 0)

  # print(gamma0)

  dalpha0 <- - a*alpha0 + gamma0
  dbeta0 <- a*alpha0 - b*beta0
  return(list(c(dalpha0, dbeta0)))

  })}

times <- seq(from = 0, to = 10, by = 1/24)
out <- ode(func = mod, times = times, y = yini, parms = param)
plot(out, lwd = 2, xlab = "day")


What am I doing wrong? Thanks in advance for your help!
Marine


	[[alternative HTML version deleted]]


From frainj at gmail.com  Thu Mar 23 23:42:08 2017
From: frainj at gmail.com (John C Frain)
Date: Thu, 23 Mar 2017 22:42:08 +0000
Subject: [R] Modeling Time Series with Missing Observations
In-Reply-To: <21B26FE4-6E71-406E-9F56-7024D9A3D61B@dcn.davis.ca.us>
References: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>
	<21B26FE4-6E71-406E-9F56-7024D9A3D61B@dcn.davis.ca.us>
Message-ID: <CAHrK514+wAB06_OJxKG9KMd6m+wqAcp52bFp==0gSCXaWEzFsg@mail.gmail.com>

Google "arima missing data r"  will bring up several references including
http://stats.stackexchange.com/questions/104565/how-to-use-auto-arima-to-impute-missing-values.
There are several other useful results in that search.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 23 March 2017 at 15:42, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Even the most basic introduction to R discusses the use of NA for missing
> data. Injecting values that could be mistaken for actual readings is a
> dangerous approach. You can use the merge function to introduce missing
> rows into zoo objects or data frames.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 23, 2017 8:22:47 AM PDT, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >Dear all,
> >
> >Hope you are doing well. I am trying to model the historical number of
> >transits of a particular market segment, but the problem is that I have
> >missing data.
> >
> >I am working with monthly data, so I have 12 observations per year (in
> >general). The problem is that, when I bring the data from the database,
> >the
> >following happens, for example:
> >
> >January-2000, Feb-2000, Apr-2000, Jun 2000 (I have missing
> >observations)
> >
> >when I am supposed to have the sequence January-2000, Feb-2000,
> >Mar-2000,
> >Apr-2000, May-2000, Jun-2000, etc.
> >
> >How can I model a time series when there are missing months? I was
> >planning
> >making up fictional or fake observations with a value of 1 to fill in
> >the
> >gaps but not sure if this is a reasonable approach.
> >
> >Any help and/or guidance will be greatly appreciated,
> >
> >Best regards,
> >
> >Paul
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Mar 24 02:11:41 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Mar 2017 18:11:41 -0700
Subject: [R] Modeling Time Series with Missing Observations
In-Reply-To: <CAHrK514+wAB06_OJxKG9KMd6m+wqAcp52bFp==0gSCXaWEzFsg@mail.gmail.com>
References: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>
	<21B26FE4-6E71-406E-9F56-7024D9A3D61B@dcn.davis.ca.us>
	<CAHrK514+wAB06_OJxKG9KMd6m+wqAcp52bFp==0gSCXaWEzFsg@mail.gmail.com>
Message-ID: <44E934E6-7A61-483B-BF2C-15981115DE34@comcast.net>

There's also an irts-package "irregular time series"

Sent from my iPhone

> On Mar 23, 2017, at 3:42 PM, John C Frain <frainj at gmail.com> wrote:
> 
> Google "arima missing data r"  will bring up several references including
> http://stats.stackexchange.com/questions/104565/how-to-use-auto-arima-to-impute-missing-values.
> There are several other useful results in that search.
> 
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
> 
>> On 23 March 2017 at 15:42, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> Even the most basic introduction to R discusses the use of NA for missing
>> data. Injecting values that could be mistaken for actual readings is a
>> dangerous approach. You can use the merge function to introduce missing
>> rows into zoo objects or data frames.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On March 23, 2017 8:22:47 AM PDT, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>> Dear all,
>>> 
>>> Hope you are doing well. I am trying to model the historical number of
>>> transits of a particular market segment, but the problem is that I have
>>> missing data.
>>> 
>>> I am working with monthly data, so I have 12 observations per year (in
>>> general). The problem is that, when I bring the data from the database,
>>> the
>>> following happens, for example:
>>> 
>>> January-2000, Feb-2000, Apr-2000, Jun 2000 (I have missing
>>> observations)
>>> 
>>> when I am supposed to have the sequence January-2000, Feb-2000,
>>> Mar-2000,
>>> Apr-2000, May-2000, Jun-2000, etc.
>>> 
>>> How can I model a time series when there are missing months? I was
>>> planning
>>> making up fictional or fake observations with a value of 1 to fill in
>>> the
>>> gaps but not sure if this is a reasonable approach.
>>> 
>>> Any help and/or guidance will be greatly appreciated,
>>> 
>>> Best regards,
>>> 
>>> Paul
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Mar 24 06:01:49 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Mar 2017 22:01:49 -0700
Subject: [R] How to change parameter values as a function to time with
	the package "deSolve"
In-Reply-To: <AM5PR0701MB23389BB9261BDE8FC26479E2E23F0@AM5PR0701MB2338.eurprd07.prod.outlook.com>
References: <AM5PR0701MB23389BB9261BDE8FC26479E2E23F0@AM5PR0701MB2338.eurprd07.prod.outlook.com>
Message-ID: <3C69FCE6-4963-4D40-9ADB-45197F75F0D9@comcast.net>


> On Mar 23, 2017, at 2:59 PM, Marine Regis <marine.regis at hotmail.fr> wrote:
> 
> Hello,
> 
> I am trying to solve an ODE in R using deSolve. With the following code, I expected the parameter ?gamma0? takes the values 5 at time step 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 and 10, and 0 otherwise. However, the print(gamma0) shows that ?gamma0? stays at 0.
> 
> Here is my ODE:
> 
> param <- c(a = 0.1, b = 1)
> yini <- c(alpha0 = 0, beta0 = 0)
> 
> mod <- function(times, yini, param) {
> 
>  with(as.list(c(yini, parameters)), {
> 
>  gamma0 <- ifelse(times %in% seq(0,10,1), 5, 0)
> 
>  # print(gamma0)
> 
>  dalpha0 <- - a*alpha0 + gamma0
>  dbeta0 <- a*alpha0 - b*beta0
>  return(list(c(dalpha0, dbeta0)))
> 
>  })}
> 
> times <- seq(from = 0, to = 10, by = 1/24)
> out <- ode(func = mod, times = times, y = yini, parms = param)
> plot(out, lwd = 2, xlab = "day")
> 
> 
> What am I doing wrong? Thanks in advance for your help!

When I execute that code I get:

Error in as.list(c(yini, parameters)) : object 'parameters' not found

(The mistake seems fairly obvious when you look are the parameter list for your `mod` function.)

Additionally: It's not generally good practice to use `with` inside functions, but that's not the problem here.

-- 
David.

> Marine
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ashimkapoor at gmail.com  Fri Mar 24 06:41:14 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Fri, 24 Mar 2017 11:11:14 +0530
Subject: [R] switch parameter in MSwM package
Message-ID: <CAC8=1erYVWFveTf4N-ZdoH1vHC0QQ5H4pRwhYFe_G=G=46RLQA@mail.gmail.com>

Dear All,

I am currently trying to use the Markov Switching Models(MSwM) package in
R.I am not sure as to how to use the switch parameter.  From what I
understand, switch is a boolean vector which says what parameters are
regime dependent.

My confusion is that what is the order of the parameters when I say switch
= rep(TRUE,6) ? For instance what are parameters 1/2/3 ?

The first parameter is probably the regime dependent intercept. The last
parameter I think will be regime dependent variance.

Can someone please show me how I can code the following equation?

y_t =mu_{S_t} + Phi_{S_t, 1 } * ( y_{t-1} - mu_{S_{t-1} } )  + sigma_{S_t}
* epsilon_t

where epsilon_t is N(0,1).

Is parameter 2 corresponding to Phi_{S_t,1}  or mu_{S_{t-1}} ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 23 18:28:35 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Mar 2017 10:28:35 -0700
Subject: [R] (no subject)
In-Reply-To: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
References: <CAKM1wmV_dCH7NcsPunh=hYJ_ndUu+-SpwK19j4Pmzd0MYkp8Gg@mail.gmail.com>
Message-ID: <CAGxFJbTh-air6uwepMkZ_Qibngv+3GWJ2R8NhqCRWp5hs=d-gQ@mail.gmail.com>

Please read and follow the directions at the bottom of your email.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 23, 2017 at 9:55 AM, munevver kaya <munevver.rock at gmail.com> wrote:
> Dear Sir/Madam,
> I do not want to receive any email by r-help. Can you delete me in your
> mail list? Thank you.
>
> Sincerely,
> Munevver Basman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Mar 23 18:17:40 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 23 Mar 2017 13:17:40 -0400
Subject: [R] Setting up a .Rprofile file
Message-ID: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>

Hi R'ers:
I would like to setting up a .Rprofile file with
setwd("C:/R_WorkDir")
set.seed(12345)
options (prompt "> R ")

---
Can you help providing the code or instructive link, I've find many links, but I can't figure it out?

Thanks.
Bruce 

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net


From es at enricoschumann.net  Fri Mar 24 08:48:11 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 24 Mar 2017 08:48:11 +0100
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com> (Bruce Ratner
	PhD's message of "Thu, 23 Mar 2017 13:17:40 -0400")
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
Message-ID: <87wpbfjetg.fsf@enricoschumann.net>

On Thu, 23 Mar 2017, Bruce Ratner PhD writes:

> Hi R'ers:
> I would like to setting up a .Rprofile file with
> setwd("C:/R_WorkDir")
> set.seed(12345)
> options (prompt "> R ")
>
> ---
> Can you help providing the code or instructive link,
> I've find many links, but I can't figure it out?
>
> Thanks.
> Bruce 
>

Quoting from ?Startup:

,----
| [...] unless ?--no-init-file? was given, R searches
| for a user profile, a file of R code.  The path of
| this file can be specified by the ?R_PROFILE_USER?
| environment variable (and tilde expansion will be
| performed).  If this is unset, a file called
| ?.Rprofile? is searched for in the current directory
| or in the user's home directory (in that order).  The
| user profile file is sourced into the workspace.
`----

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From bhh at xs4all.nl  Fri Mar 24 09:49:17 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 24 Mar 2017 09:49:17 +0100
Subject: [R] Modeling Time Series with Missing Observations
In-Reply-To: <44E934E6-7A61-483B-BF2C-15981115DE34@comcast.net>
References: <CAMOcQfPjaCDUCn+ouRMzx=7bJskf0Me+8w6d1WnpihMNNGR5fQ@mail.gmail.com>
	<21B26FE4-6E71-406E-9F56-7024D9A3D61B@dcn.davis.ca.us>
	<CAHrK514+wAB06_OJxKG9KMd6m+wqAcp52bFp==0gSCXaWEzFsg@mail.gmail.com>
	<44E934E6-7A61-483B-BF2C-15981115DE34@comcast.net>
Message-ID: <29DAE30A-0460-4389-A382-F4A4657572B7@xs4all.nl>


There is also a package imputeTS, which may be able to do what you want.
It has a nice Introduction vignette  and also appears to have nice plot functions

Berend Hasselman


> On 24 Mar 2017, at 02:11, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> There's also an irts-package "irregular time series"
> 
> Sent from my iPhone
> 
>> On Mar 23, 2017, at 3:42 PM, John C Frain <frainj at gmail.com> wrote:
>> 
>> Google "arima missing data r"  will bring up several references including
>> http://stats.stackexchange.com/questions/104565/how-to-use-auto-arima-to-impute-missing-values.
>> There are several other useful results in that search.
>> 
>> John C Frain
>> 3 Aranleigh Park
>> Rathfarnham
>> Dublin 14
>> Ireland
>> www.tcd.ie/Economics/staff/frainj/home.html
>> mailto:frainj at tcd.ie
>> mailto:frainj at gmail.com
>> 
>>> On 23 March 2017 at 15:42, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> Even the most basic introduction to R discusses the use of NA for missing
>>> data. Injecting values that could be mistaken for actual readings is a
>>> dangerous approach. You can use the merge function to introduce missing
>>> rows into zoo objects or data frames.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On March 23, 2017 8:22:47 AM PDT, Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>> Dear all,
>>>> 
>>>> Hope you are doing well. I am trying to model the historical number of
>>>> transits of a particular market segment, but the problem is that I have
>>>> missing data.
>>>> 
>>>> I am working with monthly data, so I have 12 observations per year (in
>>>> general). The problem is that, when I bring the data from the database,
>>>> the
>>>> following happens, for example:
>>>> 
>>>> January-2000, Feb-2000, Apr-2000, Jun 2000 (I have missing
>>>> observations)
>>>> 
>>>> when I am supposed to have the sequence January-2000, Feb-2000,
>>>> Mar-2000,
>>>> Apr-2000, May-2000, Jun-2000, etc.
>>>> 
>>>> How can I model a time series when there are missing months? I was
>>>> planning
>>>> making up fictional or fake observations with a value of 1 to fill in
>>>> the
>>>> gaps but not sure if this is a reasonable approach.
>>>> 
>>>> Any help and/or guidance will be greatly appreciated,
>>>> 
>>>> Best regards,
>>>> 
>>>> Paul
>>>> 
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From es at enricoschumann.net  Fri Mar 24 11:03:34 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 24 Mar 2017 11:03:34 +0100
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com> (Bruce Ratner
	PhD's message of "Fri, 24 Mar 2017 05:36:49 -0400")
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
	<87wpbfjetg.fsf@enricoschumann.net>
	<77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
Message-ID: <87poh7j8jt.fsf@enricoschumann.net>

On Fri, 24 Mar 2017, Bruce Ratner PhD writes:

> Henrico:
> Thanks for quick reply.
> However, one last question:
> If I want to change working directory, and put setwd() in the Rprofile
> file, logically R will not know where the be work directory is,
> correct?
>
> So, should I install R in my preferred working directory?
>
> Thanks again, in advance. 
> Bruce
>

Hm, I think I don't understand what you mean here. Where R
is installed and where it is run are (usually) not the same
places.

Let $ be a shell prompt, and let > be the R
prompt. Then:

  $ cd /tmp/
  $ R -q
  > getwd()
  [1] "/tmp"
  > q("no")
  $ cd ~/Documents/
  $ R -q
  > getwd()
  [1] "~/Documents"

Now I write into my "~./Rprofile" file:

  setwd("~/Downloads")

$ cd /tmp/
$ R -q
> getwd()
[1] "~/Downloads"


But maybe I am completely misunderstanding what you
mean....

Kind regards
     Enrico


>
>
>> On Mar 24, 2017, at 3:48 AM, Enrico Schumann <es at enricoschumann.net> wrote:
>> 
>> On Thu, 23 Mar 2017, Bruce Ratner PhD writes:
>> 
>>> Hi R'ers:
>>> I would like to setting up a .Rprofile file with
>>> setwd("C:/R_WorkDir")
>>> set.seed(12345)
>>> options (prompt "> R ")
>>> 
>>> ---
>>> Can you help providing the code or instructive link,
>>> I've find many links, but I can't figure it out?
>>> 
>>> Thanks.
>>> Bruce 
>>> 
>> 
>> Quoting from ?Startup:
>> 
>> ,----
>> | [...] unless ?--no-init-file? was given, R searches
>> | for a user profile, a file of R code.  The path of
>> | this file can be specified by the ?R_PROFILE_USER?
>> | environment variable (and tilde expansion will be
>> | performed).  If this is unset, a file called
>> | ?.Rprofile? is searched for in the current directory
>> | or in the user's home directory (in that order).  The
>> | user profile file is sourced into the workspace.
>> `----
>> 

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ntfredo at gmail.com  Fri Mar 24 13:18:09 2017
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 24 Mar 2017 14:18:09 +0200
Subject: [R] Error: could not find function "ap"
Message-ID: <CAGh51gSsYSqfKwbk1vjRc-G+hsoTeHgXKsY8sqn6dC+jjByP=Q@mail.gmail.com>

Dear All,

I hope you are doing well.

I am new in using evapotranspiration packages and got the following error:

Error: could not find function "ap"

The code I am using and data are:

dat1<-read.csv("/home/fredo/Documents/Meteo Data/Meteo Rwa
data.csv",header=T,na.string="9999")
dat1$u.daily<-dat1$Wind.Speed*0.514444
dat1$Date<-as.Date(paste(dat1$Year,dat1$Month,dat1$Day,sep="-"))
#dat1$DOY<-dayOfYear(dat1$Date)
dat1$Longitude<-30.11
dat1$Latitude<--1.95
dat1$Elevation<-1490
dat1$RHmax.daily<-dat1$RHmax.daily
dat1$RHmin.daily<-dat1$RHmin.daily
dat1$Tmax.daily<-dat1$Tmax.daily
dat1$Tmin.daily<-dat1$Tmin.daily
#dat1<-subset(select=-Wind.direction.measured.in.Degrees)
Sunshine<-dat1$n.daily
lat<-as.numeric(dat1$Latitude)
lon<-as.numeric(dat1$Longitude)
days<-dat1$Date
require(zoo)
A <- 0.21
B <- 0.57
dat1$RS.daily<-ap(days,lat,lon,A,B,Sunshine,extraT=NULL)
View(dat1)



dput(head(dat1))
structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L
), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Wind.Speed = c(5L,
4L, 4L, 3L, 5L, 6L), n.daily = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
), Tmax.daily = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin.daily = c(14.5,
16, 14.4, 14.8, 16.6, 15.4), RHmax.daily = c(100L, 95L, 97L,
100L, 97L, 99L), RHmin.daily = c(45L, 62L, 72L, 55L, 54L, 63L
), Station.Name = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI
AERO", class = "factor"),
    Elevation = c(1490, 1490, 1490, 1490, 1490, 1490), Longitude = c(30.11,
    30.11, 30.11, 30.11, 30.11, 30.11), Latitude = c(-1.95, -1.95,
    -1.95, -1.95, -1.95, -1.95), u.daily = c(2.57222, 2.057776,
    2.057776, 1.543332, 2.57222, 3.086664), Date = structure(c(5113,
    5114, 5115, 5116, 5117, 5118), class = "Date")), .Names = c("Year",
"Month", "Day", "Wind.Speed", "n.daily", "Tmax.daily", "Tmin.daily",
"RHmax.daily", "RHmin.daily", "Station.Name", "Elevation", "Longitude",
"Latitude", "u.daily", "Date"), row.names = c(NA, 6L), class = "data.frame")


I appreciate your help in advance!

Best regards,
Fredo.






Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Mar 24 14:28:08 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Mar 2017 13:28:08 +0000
Subject: [R] Error: could not find function "ap"
In-Reply-To: <CAGh51gSsYSqfKwbk1vjRc-G+hsoTeHgXKsY8sqn6dC+jjByP=Q@mail.gmail.com>
References: <CAGh51gSsYSqfKwbk1vjRc-G+hsoTeHgXKsY8sqn6dC+jjByP=Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1E27A@SRVEXCHCM301.precheza.cz>

Hi

Did you define function ap?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Frederic
> Ntirenganya
> Sent: Friday, March 24, 2017 1:18 PM
> To: r-help at r-project.org
> Subject: [R] Error: could not find function "ap"
>
> Dear All,
>
> I hope you are doing well.
>
> I am new in using evapotranspiration packages and got the following error:
>
> Error: could not find function "ap"
>
> The code I am using and data are:
>
> dat1<-read.csv("/home/fredo/Documents/Meteo Data/Meteo Rwa
> data.csv",header=T,na.string="9999")
> dat1$u.daily<-dat1$Wind.Speed*0.514444
> dat1$Date<-as.Date(paste(dat1$Year,dat1$Month,dat1$Day,sep="-"))
> #dat1$DOY<-dayOfYear(dat1$Date)
> dat1$Longitude<-30.11
> dat1$Latitude<--1.95
> dat1$Elevation<-1490
> dat1$RHmax.daily<-dat1$RHmax.daily
> dat1$RHmin.daily<-dat1$RHmin.daily
> dat1$Tmax.daily<-dat1$Tmax.daily
> dat1$Tmin.daily<-dat1$Tmin.daily
> #dat1<-subset(select=-Wind.direction.measured.in.Degrees)
> Sunshine<-dat1$n.daily
> lat<-as.numeric(dat1$Latitude)
> lon<-as.numeric(dat1$Longitude)
> days<-dat1$Date
> require(zoo)
> A <- 0.21
> B <- 0.57
> dat1$RS.daily<-ap(days,lat,lon,A,B,Sunshine,extraT=NULL)
> View(dat1)
>
>
>
> dput(head(dat1))
> structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L ), Month =
> c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Wind.Speed = c(5L, 4L, 4L, 3L, 5L, 6L), n.daily
> = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7 ), Tmax.daily = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5),
> Tmin.daily = c(14.5, 16, 14.4, 14.8, 16.6, 15.4), RHmax.daily = c(100L, 95L, 97L,
> 100L, 97L, 99L), RHmin.daily = c(45L, 62L, 72L, 55L, 54L, 63L ), Station.Name =
> structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class = "factor"),
>     Elevation = c(1490, 1490, 1490, 1490, 1490, 1490), Longitude = c(30.11,
>     30.11, 30.11, 30.11, 30.11, 30.11), Latitude = c(-1.95, -1.95,
>     -1.95, -1.95, -1.95, -1.95), u.daily = c(2.57222, 2.057776,
>     2.057776, 1.543332, 2.57222, 3.086664), Date = structure(c(5113,
>     5114, 5115, 5116, 5117, 5118), class = "Date")), .Names = c("Year", "Month",
> "Day", "Wind.Speed", "n.daily", "Tmax.daily", "Tmin.daily", "RHmax.daily",
> "RHmin.daily", "Station.Name", "Elevation", "Longitude", "Latitude",
> "u.daily", "Date"), row.names = c(NA, 6L), class = "data.frame")
>
>
> I appreciate your help in advance!
>
> Best regards,
> Fredo.
>
>
>
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Fri Mar 24 15:11:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Mar 2017 07:11:58 -0700
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <87poh7j8jt.fsf@enricoschumann.net>
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
	<87wpbfjetg.fsf@enricoschumann.net>
	<77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
	<87poh7j8jt.fsf@enricoschumann.net>
Message-ID: <3CFF9A88-C67B-48F3-B4B8-44577A6C384E@dcn.davis.ca.us>

OP is on some variant of MSWindows, which doesn't use a Bash shell, so the syntax of that example is a bit foreign, Enrico. 

I would say that the concept of using .Rprofile to change directories is ill-advised, since having ALL of your R work in one place is not sustainable. However you can make one or more clickable icons (shortcuts) on your desktop or start menu with the Startup Directory property set to the directory you want to work in. You can modify a shortcut made by the installer, or  hold the Alt key down while dragging the RGui.exe icon to some convenient place, and use the right-click popup menu to change Properties.

I used to create a .RData file in the directory I wanted to work in and double click that to get R started in that directory, but the side effects of loading objects into the R global environment can really confuse things and create puzzling behaviour if that file gets changed. These days I use RStudio and double click on a .Rproj (project) file to get RStudio going with the directory set to where that file is without mucking with the global environment. 
-- 
Sent from my phone. Please excuse my brevity.

On March 24, 2017 3:03:34 AM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>On Fri, 24 Mar 2017, Bruce Ratner PhD writes:
>
>> Henrico:
>> Thanks for quick reply.
>> However, one last question:
>> If I want to change working directory, and put setwd() in the
>Rprofile
>> file, logically R will not know where the be work directory is,
>> correct?
>>
>> So, should I install R in my preferred working directory?
>>
>> Thanks again, in advance. 
>> Bruce
>>
>
>Hm, I think I don't understand what you mean here. Where R
>is installed and where it is run are (usually) not the same
>places.
>
>Let $ be a shell prompt, and let > be the R
>prompt. Then:
>
>  $ cd /tmp/
>  $ R -q
>  > getwd()
>  [1] "/tmp"
>  > q("no")
>  $ cd ~/Documents/
>  $ R -q
>  > getwd()
>  [1] "~/Documents"
>
>Now I write into my "~./Rprofile" file:
>
>  setwd("~/Downloads")
>
>$ cd /tmp/
>$ R -q
>> getwd()
>[1] "~/Downloads"
>
>
>But maybe I am completely misunderstanding what you
>mean....
>
>Kind regards
>     Enrico
>
>
>>
>>
>>> On Mar 24, 2017, at 3:48 AM, Enrico Schumann <es at enricoschumann.net>
>wrote:
>>> 
>>> On Thu, 23 Mar 2017, Bruce Ratner PhD writes:
>>> 
>>>> Hi R'ers:
>>>> I would like to setting up a .Rprofile file with
>>>> setwd("C:/R_WorkDir")
>>>> set.seed(12345)
>>>> options (prompt "> R ")
>>>> 
>>>> ---
>>>> Can you help providing the code or instructive link,
>>>> I've find many links, but I can't figure it out?
>>>> 
>>>> Thanks.
>>>> Bruce 
>>>> 
>>> 
>>> Quoting from ?Startup:
>>> 
>>> ,----
>>> | [...] unless ?--no-init-file? was given, R searches
>>> | for a user profile, a file of R code.  The path of
>>> | this file can be specified by the ?R_PROFILE_USER?
>>> | environment variable (and tilde expansion will be
>>> | performed).  If this is unset, a file called
>>> | ?.Rprofile? is searched for in the current directory
>>> | or in the user's home directory (in that order).  The
>>> | user profile file is sourced into the workspace.
>>> `----
>>> 
>
>-- 
>Enrico Schumann
>Lucerne, Switzerland
>http://enricoschumann.net
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marine.regis at hotmail.fr  Fri Mar 24 15:28:48 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Fri, 24 Mar 2017 14:28:48 +0000
Subject: [R] How to change parameter values as a function to time with
 the package "deSolve"
In-Reply-To: <3C69FCE6-4963-4D40-9ADB-45197F75F0D9@comcast.net>
References: <AM5PR0701MB23389BB9261BDE8FC26479E2E23F0@AM5PR0701MB2338.eurprd07.prod.outlook.com>,
	<3C69FCE6-4963-4D40-9ADB-45197F75F0D9@comcast.net>
Message-ID: <AM5PR0701MB2338832CBC17C85449423E2CE23E0@AM5PR0701MB2338.eurprd07.prod.outlook.com>

Thanks very much David for your answer. Sorry ! here is the code without the error:


library(deSolve)
param <- c(a = 0.1, b = 1)
yini <- c(alpha0 = 6, beta0 = 2)

mod <- function(times, yini, param) {

  with(as.list(c(yini, param)), {

    gamma0 <- ifelse(times %in% seq(0,10,1), 5, 0)

    ## print(gamma0)

    dalpha0 <- - a*alpha0 + gamma0
    dbeta0 <- a*alpha0 - b*beta0
    return(list(c(dalpha0, dbeta0)))

  })}

times <- seq(from = 0, to = 10, by = 1/24)
out <- ode(func = mod, times = times, y = yini, parms = param)
plot(out, lwd = 2, xlab = "day")

Thanks in advance for your help!
Marine



________________________________
De : David Winsemius <dwinsemius at comcast.net>
Envoy? : vendredi 24 mars 2017 06:01
? : Marine Regis
Cc : r-help at r-project.org
Objet : Re: [R] How to change parameter values as a function to time with the package "deSolve"


> On Mar 23, 2017, at 2:59 PM, Marine Regis <marine.regis at hotmail.fr> wrote:
>
> Hello,
>
> I am trying to solve an ODE in R using deSolve. With the following code, I expected the parameter ?gamma0? takes the values 5 at time step 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 and 10, and 0 otherwise. However, the print(gamma0) shows that ?gamma0? stays at 0.
>
> Here is my ODE:
>
> param <- c(a = 0.1, b = 1)
> yini <- c(alpha0 = 0, beta0 = 0)
>
> mod <- function(times, yini, param) {
>
>  with(as.list(c(yini, parameters)), {
>
>  gamma0 <- ifelse(times %in% seq(0,10,1), 5, 0)
>
>  # print(gamma0)
>
>  dalpha0 <- - a*alpha0 + gamma0
>  dbeta0 <- a*alpha0 - b*beta0
>  return(list(c(dalpha0, dbeta0)))
>
>  })}
>
> times <- seq(from = 0, to = 10, by = 1/24)
> out <- ode(func = mod, times = times, y = yini, parms = param)
> plot(out, lwd = 2, xlab = "day")
>
>
> What am I doing wrong? Thanks in advance for your help!

When I execute that code I get:

Error in as.list(c(yini, parameters)) : object 'parameters' not found

(The mistake seems fairly obvious when you look are the parameter list for your `mod` function.)

Additionally: It's not generally good practice to use `with` inside functions, but that's not the problem here.

--
David.

> Marine
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
R-help Info Page - Homepage - SfS ? Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From br at dmstat1.com  Fri Mar 24 10:36:49 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 24 Mar 2017 05:36:49 -0400
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <87wpbfjetg.fsf@enricoschumann.net>
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
	<87wpbfjetg.fsf@enricoschumann.net>
Message-ID: <77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>

Henrico:
Thanks for quick reply.
However, one last question:
If I want to change working directory, and put setwd() in the Rprofile file, logically R will not know where the be work directory is, correct?

So, should I install R in my preferred working directory?

Thanks again, in advance. 
Bruce


______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Mar 24, 2017, at 3:48 AM, Enrico Schumann <es at enricoschumann.net> wrote:
> 
> On Thu, 23 Mar 2017, Bruce Ratner PhD writes:
> 
>> Hi R'ers:
>> I would like to setting up a .Rprofile file with
>> setwd("C:/R_WorkDir")
>> set.seed(12345)
>> options (prompt "> R ")
>> 
>> ---
>> Can you help providing the code or instructive link,
>> I've find many links, but I can't figure it out?
>> 
>> Thanks.
>> Bruce 
>> 
> 
> Quoting from ?Startup:
> 
> ,----
> | [...] unless ?--no-init-file? was given, R searches
> | for a user profile, a file of R code.  The path of
> | this file can be specified by the ?R_PROFILE_USER?
> | environment variable (and tilde expansion will be
> | performed).  If this is unset, a file called
> | ?.Rprofile? is searched for in the current directory
> | or in the user's home directory (in that order).  The
> | user profile file is sourced into the workspace.
> `----
> 
> -- 
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
> 


From mdayan.research at gmail.com  Fri Mar 24 16:58:45 2017
From: mdayan.research at gmail.com (Michael Dayan)
Date: Fri, 24 Mar 2017 16:58:45 +0100
Subject: [R] Using betareg package to fit beta mixture with given
	initial parameters
In-Reply-To: <alpine.DEB.2.20.1703221122410.13640@paninaro>
References: <CAK8FaMN+_WZpezvT8kxm6zUi3Lq1-hZsGH4sp9e6PfSi4HvFXA@mail.gmail.com>
	<6F5A6F09-470D-4D9B-ACC3-90E121F891DA@comcast.net>
	<CAK8FaMM=foAEbtzuf6Tj9Gzj9akuVdi87UDOiA1WTeNBtQxHZg@mail.gmail.com>
	<CAK8FaMMFPawx+meUEab217Hi9OL=hZM7YNEazPN8t_wT-09iLQ@mail.gmail.com>
	<alpine.DEB.2.20.1703221122410.13640@paninaro>
Message-ID: <CAK8FaMPfFi37sKGDQ_XzTy1v6gnPUhrJDg_MdOm2fHV+YSKwUA@mail.gmail.com>

Dear Achim,

Thank you for your help, this is exactly what I needed. Your help and
didactic example is very much appreciated.

Best wishes,

Michael

On Wed, Mar 22, 2017 at 11:34 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Wed, 22 Mar 2017, Michael Dayan wrote:
>
> The method of setting the initial values given lambda, alpha1, etc. should
>> not depend on the exact values of lambda, alpha1, etc. in my situation,
>> i.e. it does not depend on my data.
>>
>
> Presently, flexmix() that betamix() is built on cannot take the parameters
> directly for initialization. However, it is possible to pass a matrix with
> initial 'cluster' probabilities. This can be easily generated using dbeta().
>
> For a concrete example consider the data generated in this discussion on
> SO:
>
> http://stats.stackexchange.com/questions/114959/mixture-of-b
> eta-distributions-full-example
>
> Using that data with random starting values requires 42 iterations until
> convergence:
>
> set.seed(0)
> m1 <- betamix(y ~ 1 | 1, data = d, k = 2)
> m1
>
> ## Call:
> ## betamix(formula = y ~ 1 | 1, data = d, k = 2)
> ## ## Cluster sizes:
> ##   1   2
> ##  50 100
> ## ## convergence after 42 iterations
>
> Instead we could initialize with the posterior probabilities obtained at
> the observed data (d$y), the true alpha/beta parameters (10; 30 vs. 30; 10)
> and the true cluster proportions (2/3 vs. 1/3):
>
> p <- cbind(2/3 * dbeta(d$y, 10, 30), 1/3 * dbeta(d$y, 30, 10))
> p <- p/rowSums(p)
>
> This converges after only 2 iterations:
>
> set.seed(0)
> m2 <- betamix(y ~ 1 | 1, data = d, k = 2, cluster = p)
> m2
>
> ## Call:
> ## betamix(formula = y ~ 1 | 1, data = d, k = 2, cluster = p)
> ## ## Cluster sizes:
> ##   1   2
> ## 100  50
> ## ## convergence after 2 iterations
>
> Up to label switching and small numerical differences, the parameter
> estimates agree. (Of course, these are on the mu/phi scale and not
> alpha/beta as explained in the SO post linked above.)
>
> coef(m1)
> ##        (Intercept) (phi)_(Intercept)
> ## Comp.1    1.196286          3.867808
> ## Comp.2   -1.096487          3.898976
> coef(m2)
> ##        (Intercept) (phi)_(Intercept)
> ## Comp.1   -1.096487          3.898976
> ## Comp.2    1.196286          3.867808
>
>
>
> On Mar 22, 2017 04:30, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>
>>
>> On Mar 21, 2017, at 5:04 AM, Michael Dayan <mdayan.research at gmail.com>
>>>
>> wrote:
>>
>>>
>>> Hi,
>>>
>>> I would like to fit a mixture of two beta distributions with parameters
>>> (alpha1, beta1) for the first component, (alpha2, beta2) for the second
>>> component, and lambda for the mixing parameter. I also would like to set
>>> a
>>> maximum of 200 iterations and a tolerance of 1e-08.
>>>
>>> My question is: how to use the betareg package to run the fit with
>>> initial
>>> values for the parameters alpha1, beta1, alpha2, beta2 and lambda? I saw
>>>
>> in
>>
>>> the documentation that I would need to use the 'start' option of the
>>> betareg function, with start described as "an optional vector with
>>>
>> starting
>>
>>> values for all parameters (including phi)". However I could not find how
>>>
>> to
>>
>>> define this list given my alpha1, beta1, alpha2, beta2 and lambda.
>>>
>>> The current code I have is:
>>> mydata$y <- <my_data>
>>> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
>>> 200, fsmaxit = 200)
>>>
>>>
>>> And I suspect I would need to do something along the lines:
>>>
>>> initial.vals <- c(?, ?, ?, ?, ?)
>>> bmix <- betamix(y ~ 1 | 1, data = mydata, k = 2, fstol = 1e-08, maxit =
>>> 200, fsmaxit = 200, control=betareg.control(start=initial.vals)))
>>>
>>> But I do not know what to use for initial.vals.
>>>
>>
>> If there were sensitivity to data, then wouldn't  that depend on your
>> (unprovided) data?
>>
>>
>>
>>> Best wishes,
>>>
>>> Michael
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>>
>> posting-guide.html
>>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar 24 18:00:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Mar 2017 10:00:50 -0700
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
	<87wpbfjetg.fsf@enricoschumann.net>
	<77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
Message-ID: <CAGxFJbSWtvDL=WNVKmEBqV+jgvjNb5fs7Y65c8vmMO3ixpZ6Hw@mail.gmail.com>

Inline.

Cheers,

Bert

On Fri, Mar 24, 2017 at 2:36 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> Henrico:
> Thanks for quick reply.
> However, one last question:
> If I want to change working directory, and put setwd() in the Rprofile file, logically R will not know where the be work directory is, correct?

No. See ?setwd . It requires a dir argument and will therefore give an
error if one is not supplied. Nothing to do with "knowing" what the
current working directory is.
>
> So, should I install R in my preferred working directory?

No (imho, anyway). Your working directory may change over time,
depending on how you organize things of course.

Please re-read the advice you have been given as well as ?startup.

Cheers,
Bert


>
> Thanks again, in advance.
> Bruce
>
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Mar 24, 2017, at 3:48 AM, Enrico Schumann <es at enricoschumann.net> wrote:
>>
>> On Thu, 23 Mar 2017, Bruce Ratner PhD writes:
>>
>>> Hi R'ers:
>>> I would like to setting up a .Rprofile file with
>>> setwd("C:/R_WorkDir")
>>> set.seed(12345)
>>> options (prompt "> R ")
>>>
>>> ---
>>> Can you help providing the code or instructive link,
>>> I've find many links, but I can't figure it out?
>>>
>>> Thanks.
>>> Bruce
>>>
>>
>> Quoting from ?Startup:
>>
>> ,----
>> | [...] unless ?--no-init-file? was given, R searches
>> | for a user profile, a file of R code.  The path of
>> | this file can be specified by the ?R_PROFILE_USER?
>> | environment variable (and tilde expansion will be
>> | performed).  If this is unset, a file called
>> | ?.Rprofile? is searched for in the current directory
>> | or in the user's home directory (in that order).  The
>> | user profile file is sourced into the workspace.
>> `----
>>
>> --
>> Enrico Schumann
>> Lucerne, Switzerland
>> http://enricoschumann.net
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Fri Mar 24 18:25:28 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 24 Mar 2017 10:25:28 -0700
Subject: [R] Setting up a .Rprofile file
In-Reply-To: <77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
References: <1DA83730-E797-45C2-B001-854E3693E2AA@dmstat1.com>
	<87wpbfjetg.fsf@enricoschumann.net>
	<77EFA35C-D62D-4CF7-A844-CFB920BC1323@dmstat1.com>
Message-ID: <CAFDcVCTbMQXoDWL+8kWm+By0f9YZTvLAx7w2cq0GZmWk-BuyYQ@mail.gmail.com>

R for Windows is a bit peculiar where it locates your .Rprofile file,
or rather what it consider to be your home directory.  If you look
from within R, the file you do want to create / edit is:

> f <- normalizePath("~/.Rprofile", mustWork = FALSE)
> f
[1] "C:\\Users\\joe\\Documents\\.Rprofile"

For instance, to change what your R prompt looks you can add this from
within R as:

> cat('options(prompt = "> R ")\n', file = f, append = TRUE)

Hope this helps

Henrik

On Fri, Mar 24, 2017 at 2:36 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> Henrico:
> Thanks for quick reply.
> However, one last question:
> If I want to change working directory, and put setwd() in the Rprofile file, logically R will not know where the be work directory is, correct?
>
> So, should I install R in my preferred working directory?
>
> Thanks again, in advance.
> Bruce
>
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analytics -- www.DMSTAT1.com
> Machine-Learning Data Mining -- www.GenIQ.net
>
>
>
>> On Mar 24, 2017, at 3:48 AM, Enrico Schumann <es at enricoschumann.net> wrote:
>>
>> On Thu, 23 Mar 2017, Bruce Ratner PhD writes:
>>
>>> Hi R'ers:
>>> I would like to setting up a .Rprofile file with
>>> setwd("C:/R_WorkDir")
>>> set.seed(12345)
>>> options (prompt "> R ")
>>>
>>> ---
>>> Can you help providing the code or instructive link,
>>> I've find many links, but I can't figure it out?
>>>
>>> Thanks.
>>> Bruce
>>>
>>
>> Quoting from ?Startup:
>>
>> ,----
>> | [...] unless ?--no-init-file? was given, R searches
>> | for a user profile, a file of R code.  The path of
>> | this file can be specified by the ?R_PROFILE_USER?
>> | environment variable (and tilde expansion will be
>> | performed).  If this is unset, a file called
>> | ?.Rprofile? is searched for in the current directory
>> | or in the user's home directory (in that order).  The
>> | user profile file is sourced into the workspace.
>> `----
>>
>> --
>> Enrico Schumann
>> Lucerne, Switzerland
>> http://enricoschumann.net
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Fri Mar 24 19:55:41 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sat, 25 Mar 2017 00:25:41 +0530
Subject: [R] Default value of Numerals argument in read.table function R
	3.3.2 on Mac
Message-ID: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>

Hi,

The help file for function read.table mentions the default value for the
argument numerals  as
c("allow.loss", "warn.loss", "no.loss")

How are the three values used as default values ?

Thanks
Ramnik

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Mar 24 20:19:13 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 24 Mar 2017 15:19:13 -0400
Subject: [R] Default value of Numerals argument in read.table function R
 3.3.2 on Mac
In-Reply-To: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>
References: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>
Message-ID: <CAM_vju=kg1z+vRtENevRaO_wnshG6KgE0F9PwEmPwscj=Gp0pw@mail.gmail.com>

Those are the available options, not the defaults. If you follow the
chain to ?type.convert as the help for read.table suggests, you will
learn that "allow.loss" is the default value. The help for
type.convert also explains what each option means.

Sarah

On Fri, Mar 24, 2017 at 2:55 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> Hi,
>
> The help file for function read.table mentions the default value for the
> argument numerals  as
> c("allow.loss", "warn.loss", "no.loss")
>
> How are the three values used as default values ?
>
> Thanks
> Ramnik
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From bgunter.4567 at gmail.com  Fri Mar 24 21:17:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Mar 2017 13:17:33 -0700
Subject: [R] Default value of Numerals argument in read.table function R
 3.3.2 on Mac
In-Reply-To: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>
References: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>
Message-ID: <CAGxFJbSnOArwpFAGprawyyqfL39LyQPtcDq32NRVmdqF1FB68w@mail.gmail.com>

Follow the "type.convert" link in the numerals section of ?read.table.
That's what it's there for.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 24, 2017 at 11:55 AM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> Hi,
>
> The help file for function read.table mentions the default value for the
> argument numerals  as
> c("allow.loss", "warn.loss", "no.loss")
>
> How are the three values used as default values ?
>
> Thanks
> Ramnik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Mar 24 21:27:28 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Mar 2017 13:27:28 -0700
Subject: [R] Default value of Numerals argument in read.table function R
 3.3.2 on Mac
In-Reply-To: <CAGxFJbSnOArwpFAGprawyyqfL39LyQPtcDq32NRVmdqF1FB68w@mail.gmail.com>
References: <CAMLd9E6TRp9Y1u0cQ8HYs8Lia5AK=PQZsDU+7_7rz1vA3kxe=g@mail.gmail.com>
	<CAGxFJbSnOArwpFAGprawyyqfL39LyQPtcDq32NRVmdqF1FB68w@mail.gmail.com>
Message-ID: <CAGxFJbStkHu8-YAETzzMaxWk5SzWaUB9fULOCT8Gcmt5+QVFGQ@mail.gmail.com>

... and I should have added:

It is a specific instance of how ?match.arg works .

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 24, 2017 at 1:17 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Follow the "type.convert" link in the numerals section of ?read.table.
> That's what it's there for.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 24, 2017 at 11:55 AM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>> Hi,
>>
>> The help file for function read.table mentions the default value for the
>> argument numerals  as
>> c("allow.loss", "warn.loss", "no.loss")
>>
>> How are the three values used as default values ?
>>
>> Thanks
>> Ramnik
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Mar 24 17:37:17 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 24 Mar 2017 16:37:17 +0000
Subject: [R] FW:  "Ordiellipse" in vegan package plot;
 how to plot sd for individual species
In-Reply-To: <1490366396026.43922@lansstyrelsen.se>
References: <1490273003294.23873@lansstyrelsen.se>,
	<d3cd24cfedbc4263a04822d0f34e32b1@exch-2p-mbx-w2.ads.tamu.edu>
	<1490366396026.43922@lansstyrelsen.se>
Message-ID: <0c0903a1a5a44024b0137a69596cc133@exch-2p-mbx-w2.ads.tamu.edu>

I'm forwarding your response with attachments to the list. They all made it through this time. After reading the earlier query and Jari Oksanen's responses it seem that you want to insert a species in the w= argument, not NULL. Following his example with your data:

attach(species)
plot(mod, display = "species")
ordiellipse(mod, rep(1, nrow(species)), show= TRUE,
     display="lc", kind="sd", scaling=2, w=S1, col=2)

produces a large ellipse. But changing the species often fails with a warning message. For example S2 and S3 fail, but S4 works. 

It may be best to communicate directly with the package author:

> maintainer("vegan")
[1] "Jari Oksanen <jari.oksanen at oulu.fi>"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: Larsson Emil [mailto:emil.larsson at lansstyrelsen.se] 
Sent: Friday, March 24, 2017 9:40 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: SV: [R] "Ordiellipse" in vegan package plot; how to plot sd for individual species

Thanks David,

I have converted the data to .txt (tab-delimited - hope that works) and graph to .png. Thanks.


/Emil
________________________________________
Fr?n: David L Carlson <dcarlson at tamu.edu>
Skickat: den 23 mars 2017 17:47
Till: Larsson Emil; r-help at r-project.org
?mne: RE: [R] "Ordiellipse" in vegan package plot; how to plot sd for individual species

Most attachments (including your data and graph) get stripped from mail sent to the list. If the data are a plain text file, giving the file an extension of .txt will usually let it survive the trip (even if it is a .csv file). Graphics will survive if they are .png files.

If the datasets are not large, use dput(env) and dput(species), and then paste the output of those commands into your email message.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Larsson Emil
Sent: Thursday, March 23, 2017 7:44 AM
To: r-help at r-project.org
Subject: [R] "Ordiellipse" in vegan package plot; how to plot sd for individual species

Hi R-Help,



I have been looking for an answer to this question for some time without success, so now my hope is that you will distribute it to your email subscribers, or direct me to another forum where this question is not off-topic.


I have a dataset with 224 rows (=sites), ca 20 environmental variables, and presence/absence data for ca 40 species. TI have done an RDA ordination using the vegan package and plotted all species. Now, I want to add standard deviation for each species as circles or ellipses.


How can I do this? I tried using "ordiellipse", guided by this similar request from 2010 answered by Jari Oksanen:


http://r-sig-ecology.471788.n2.nabble.com/Fwd-R-cca-standard-error-species-td4997341.html


I am close but I cannot make it work. I have attached the dataset (V=variables, S= species) and an example sketch of how the final plot should look.


Here is my script so far:


# add environmental and species data separately:

env<-read.delim("clipboard")
attach(env)
str(env)
species<-read.delim("clipboard")
attach(species)
str(species)

# run RDA command and plot:
mod<-rda(species,env,scale=TRUE)
plot(mod, display = "species")
ordiellipse(mod, groups = rep(1, 224), display="lc", kind ="sd", draw = "polygon",
alpha = 127, label = FALSE, show.groups=TRUE, w = NULL, border = NULL, lty = NULL, lwd=NULL)





Very grateful for any help.



Best regards,


Emil Larsson
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: env_data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170324/3f52702b/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: species_data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170324/3f52702b/attachment-0001.txt>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ordination plot species.png
Type: image/png
Size: 40732 bytes
Desc: ordination plot species.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170324/3f52702b/attachment.png>

From qillbel at gmail.com  Fri Mar 24 18:12:08 2017
From: qillbel at gmail.com (Qill Bel)
Date: Fri, 24 Mar 2017 17:12:08 +0000
Subject: [R] change the value of vector based on the string of its name
Message-ID: <CAFGNhN=q7jZqU6+hTCO6EzQtktvnZYfKaDW118xZNkFd41vVDg@mail.gmail.com>

Dear R-users,

Imagine I have 3 vectors:
*proc1<-0*
*proc2<-0*
*cpd<-c("proc1","proc2")*

How can I change the value of proc1 to 1, based on vector cpd only?
I tried with *as.factor(cpd[1])<-1*, but it produces an error.

Any idea how could I achieve that?

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Fri Mar 24 23:26:45 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Fri, 24 Mar 2017 22:26:45 +0000 (UTC)
Subject: [R] Unzip multiple layer of compressed (zip/tar) file
References: <1805563078.3321689.1490394405566.ref@mail.yahoo.com>
Message-ID: <1805563078.3321689.1490394405566@mail.yahoo.com>

Hi, 

In a folder , there are multiple compressed (zip+tar) files. Each of compressed file can have multiple layer of  compression (compressed file inside the compressed file and so on).

Can anyone suggest, is there any way to decompress all the files in a single directory ?   
 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 


From dwinsemius at comcast.net  Fri Mar 24 23:45:14 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 24 Mar 2017 15:45:14 -0700
Subject: [R] change the value of vector based on the string of its name
In-Reply-To: <CAFGNhN=q7jZqU6+hTCO6EzQtktvnZYfKaDW118xZNkFd41vVDg@mail.gmail.com>
References: <CAFGNhN=q7jZqU6+hTCO6EzQtktvnZYfKaDW118xZNkFd41vVDg@mail.gmail.com>
Message-ID: <DC0FA78C-F889-4A28-8C21-5243BF22FCA1@comcast.net>


> On Mar 24, 2017, at 10:12 AM, Qill Bel <qillbel at gmail.com> wrote:
> 
> Dear R-users,
> 
> Imagine I have 3 vectors:
> *proc1<-0*
> *proc2<-0*
> *cpd<-c("proc1","proc2")*

The `cpd` vector has only character values in it, and has no relation to either the `proc1` or `proc2` vectors. If you want it refer to  them (or contain their values),  then omit the quotes. The values will not retain their names in this instance. The R names `proc`` and `proc2` will be looked up and their values places in an unnamed numeric vector. You could however make it so with:

cpd<-c("proc1"=proc1,"proc2"=proc2)

#The quotes are not needed and so this would be equivalent"

cpd<-c( proc1=proc1, proc2=proc2)

There is a `get`-function, but teaching you how to use it to solve the problem is likely to be a disservice since it would allow you to continue using R as a macro-processor.

> 

> How can I change the value of proc1 to 1, based on vector cpd only?
> I tried with *as.factor(cpd[1])<-1*, but it produces an error.

Doesn't make much sense to me to use assignment to a factor in this instance, but that's probably because we come from different programming backgrounds. Neither your code nor mine would have produced a factor vector. You should say in natural language what it is that you want to happen.

(Perhaps) Try this:

cpd[1] <- 1

Or:

cpd['proc1'] <- 1


> 
> Any idea how could I achieve that?
> 
> 	[[alternative HTML version deleted]]

And learn to post in plain text. Reading the Posting Guide will also be a good idea. As would be studying a bit longer the "Introduction to R" that is shipped with every installation.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From valkremk at gmail.com  Sat Mar 25 04:56:53 2017
From: valkremk at gmail.com (Val)
Date: Fri, 24 Mar 2017 22:56:53 -0500
Subject: [R] create new
Message-ID: <CAJOiR6a7c2k0o8aP_N6erHyKusV0f4WJjvT4ULWmnp=+xLc8oQ@mail.gmail.com>

Hi all,


I have several variables in a group and one group  contains three
variables. Sample of data ( Year, x1, x3 and x2)

mydat <- read.table(header=TRUE, text=' Year  x1  x3  x2
Year1  10  12    0
Year2   0  15    0
Year3   0   0    20
Year4  25   0   12
Year5  15  25   12
Year6   0  16   14
Year7   0  10    0')

I want create another variable( x4) based on the following condition.

if x1  > 0  then x4 = x1; regardless of  x2 and x3 values.
if x1  = 0  and x2  > 0 then x4 = x2;
if x1  = 0 and  x2  = 0 then x4 = x3

The desired output looks like as follows
Year    x1  x3  x2   x4
Year1  10  12    0  10
Year2    0  15    0  15
Year3    0    0   20  20
Year4  25    0   12  25
Year5  15  25   12  15
Year6    0  16   14  14
Year7    0  10     0  10

Thank you in advance


From bgunter.4567 at gmail.com  Sat Mar 25 06:02:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Mar 2017 22:02:27 -0700
Subject: [R] create new
In-Reply-To: <CAJOiR6a7c2k0o8aP_N6erHyKusV0f4WJjvT4ULWmnp=+xLc8oQ@mail.gmail.com>
References: <CAJOiR6a7c2k0o8aP_N6erHyKusV0f4WJjvT4ULWmnp=+xLc8oQ@mail.gmail.com>
Message-ID: <CAGxFJbTkO0ZPaEwZoV7gS-2NCziq+XRnJ4r9_W_pHm_1-62HTw@mail.gmail.com>

?ifelse

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 24, 2017 at 8:56 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
>
>
> I have several variables in a group and one group  contains three
> variables. Sample of data ( Year, x1, x3 and x2)
>
> mydat <- read.table(header=TRUE, text=' Year  x1  x3  x2
> Year1  10  12    0
> Year2   0  15    0
> Year3   0   0    20
> Year4  25   0   12
> Year5  15  25   12
> Year6   0  16   14
> Year7   0  10    0')
>
> I want create another variable( x4) based on the following condition.
>
> if x1  > 0  then x4 = x1; regardless of  x2 and x3 values.
> if x1  = 0  and x2  > 0 then x4 = x2;
> if x1  = 0 and  x2  = 0 then x4 = x3
>
> The desired output looks like as follows
> Year    x1  x3  x2   x4
> Year1  10  12    0  10
> Year2    0  15    0  15
> Year3    0    0   20  20
> Year4  25    0   12  25
> Year5  15  25   12  15
> Year6    0  16   14  14
> Year7    0  10     0  10
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katharina.voigt1 at gmail.com  Sat Mar 25 02:24:43 2017
From: katharina.voigt1 at gmail.com (Katharina Voigt)
Date: Sat, 25 Mar 2017 12:24:43 +1100
Subject: [R] Post hoc comparisons for interaction effects linear mixed
	effects models (lm4)
Message-ID: <8E4935E9-2136-4835-8A5D-6DAE4066E2F0@gmail.com>

Hi,
I want to obtain post hoc comparisons for a model with a three-way interaction (FullModel5 <- lmer(CIVADmc ~ 1 + Factor1 * Factor2 * Factor3 + (1|ID) + (1 | Item), data=Exp3_WTP_diffi).
I tried: "summary(glht(FullModel4, linfct = mcp(Factor1*Factor2*Factor3 = "Tukey")), test = adjusted("holm?))? , but this does not work.
any suggestions?








	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sat Mar 25 09:38:23 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 25 Mar 2017 09:38:23 +0100
Subject: [R] Post hoc comparisons for interaction effects linear mixed
 effects models (lm4)
In-Reply-To: <8E4935E9-2136-4835-8A5D-6DAE4066E2F0@gmail.com>
References: <8E4935E9-2136-4835-8A5D-6DAE4066E2F0@gmail.com>
Message-ID: <CAJuCY5y0rCopUYrLbjAiNkFhYegU1M=dB+W8Q0p3Nw_0g8og4g@mail.gmail.com>

Dear Katherina,

Multcomp can't handle interactions automatically. You need to create the
contrasts manually.

Best regards,

Thierry

Op 25-mrt.-2017 08:13 schreef "Katharina Voigt" <katharina.voigt1 at gmail.com
>:

> Hi,
> I want to obtain post hoc comparisons for a model with a three-way
> interaction (FullModel5 <- lmer(CIVADmc ~ 1 + Factor1 * Factor2 * Factor3 +
> (1|ID) + (1 | Item), data=Exp3_WTP_diffi).
> I tried: "summary(glht(FullModel4, linfct = mcp(Factor1*Factor2*Factor3 =
> "Tukey")), test = adjusted("holm?))? , but this does not work.
> any suggestions?
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Mar 25 10:04:04 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 25 Mar 2017 20:04:04 +1100
Subject: [R] change the value of vector based on the string of its name
In-Reply-To: <CAFGNhN=q7jZqU6+hTCO6EzQtktvnZYfKaDW118xZNkFd41vVDg@mail.gmail.com>
References: <CAFGNhN=q7jZqU6+hTCO6EzQtktvnZYfKaDW118xZNkFd41vVDg@mail.gmail.com>
Message-ID: <CA+8X3fUmDrK2mH3ve3h393hjZdTdbAKoeQ+S=sVPVddOfOVjXQ@mail.gmail.com>

Hi Qill,
If I have interpreted your example correctly:

proc1<-0
proc2<-0
cpd<-c("proc1","proc2")
assign("proc1",which(cpd=="proc1"))

Jim


On Sat, Mar 25, 2017 at 4:12 AM, Qill Bel <qillbel at gmail.com> wrote:
> Dear R-users,
>
> Imagine I have 3 vectors:
> *proc1<-0*
> *proc2<-0*
> *cpd<-c("proc1","proc2")*
>
> How can I change the value of proc1 to 1, based on vector cpd only?
> I tried with *as.factor(cpd[1])<-1*, but it produces an error.
>
> Any idea how could I achieve that?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Mar 25 11:34:25 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 25 Mar 2017 21:34:25 +1100
Subject: [R] create new
In-Reply-To: <CAJOiR6a7c2k0o8aP_N6erHyKusV0f4WJjvT4ULWmnp=+xLc8oQ@mail.gmail.com>
References: <CAJOiR6a7c2k0o8aP_N6erHyKusV0f4WJjvT4ULWmnp=+xLc8oQ@mail.gmail.com>
Message-ID: <CA+8X3fUUpbuJVPeNTEH_VcVgKKJotSm6vyPwPL58TWBF0p9Umw@mail.gmail.com>

Hi Val,
How about this:

cinmat<-
 matrix(c(mydat$x1>0,mydat$x1==0&mydat$x2==0,mydat$x1==0&mydat$x2>0),
 ncol=3)

mydat$x4<-rowSums(mydat[,c("x1","x3","x2")]*cinmat)

Jim


On Sat, Mar 25, 2017 at 2:56 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
>
>
> I have several variables in a group and one group  contains three
> variables. Sample of data ( Year, x1, x3 and x2)
>
> mydat <- read.table(header=TRUE, text=' Year  x1  x3  x2
> Year1  10  12    0
> Year2   0  15    0
> Year3   0   0    20
> Year4  25   0   12
> Year5  15  25   12
> Year6   0  16   14
> Year7   0  10    0')
>
> I want create another variable( x4) based on the following condition.
>
> if x1  > 0  then x4 = x1; regardless of  x2 and x3 values.
> if x1  = 0  and x2  > 0 then x4 = x2;
> if x1  = 0 and  x2  = 0 then x4 = x3
>
> The desired output looks like as follows
> Year    x1  x3  x2   x4
> Year1  10  12    0  10
> Year2    0  15    0  15
> Year3    0    0   20  20
> Year4  25    0   12  25
> Year5  15  25   12  15
> Year6    0  16   14  14
> Year7    0  10     0  10
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Sat Mar 25 11:44:37 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 25 Mar 2017 11:44:37 +0100
Subject: [R] passing API key in leaflet
Message-ID: <CAJuCY5zzh=7y4QsHVGvcPX5aMr4X59sT+Fuxgq7p7SQWy_SEhw@mail.gmail.com>

Dear all,

I'd like to use the OpenCycleMap as background image in a leaflet map.
This requires an API key. I've stored the key in an environment
variable. Below is a minimal example of the leaflet map. I still get
the "API Key Required" message on the tiles. Any suggestions?

library(leaflet)
leaflet() %>%
  addProviderTiles(
    "Thunderforest.OpenCycleMap",
    options = providerTileOptions(apikey = Sys.getenv("OCM_API"))
  )

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


From sezenismail at gmail.com  Sat Mar 25 18:42:35 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Sat, 25 Mar 2017 20:42:35 +0300
Subject: [R] Need class/object type advice to store a particular data
	structure
Message-ID: <A9821879-6308-4C0E-9778-AC829C1653DD@gmail.com>

Hello Everyone,

I have a particular data structure and need your advice what would be the best class/object type to store this kind of a data.

In summary, data is consist of a time series of vertical observations of more than one variables. Observations are made at a particular latitude/longitude location.  Hence, I may have observation locations more than one. 

In detail, imagine a list of data.frames and each data.frame contains 7 columns and variable number of rows. Rows represent the vertical coordinate meaning height from surface. Columns are observed variables. Each list of data.frame is belong to a single measurement location that has a latitude and longitude.

So, this is a time series of data.frames but number of rows might change. Is there a class to store this kind of data, for instance, such as SpatialPoints, SPatialPointsDataFrame or RasterStack or Raster object?

I?m asking this question, because I want to take advantage of a ready class for statistical calculations.

Thanks in advance;

Ismail SEZEN

From ntfredo at gmail.com  Sat Mar 25 19:48:52 2017
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sat, 25 Mar 2017 21:48:52 +0300
Subject: [R] Error: could not find function "ap"
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1E27A@SRVEXCHCM301.precheza.cz>
References: <CAGh51gSsYSqfKwbk1vjRc-G+hsoTeHgXKsY8sqn6dC+jjByP=Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A1E27A@SRVEXCHCM301.precheza.cz>
Message-ID: <CAGh51gSLXPgQ6BUbxbDjTc1Pus+FXCB8e7VeQUAfkkht2NqQSQ@mail.gmail.com>

It seems like it is from sirad packages.

Thanks for the help.

Cheers

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Fri, Mar 24, 2017 at 4:28 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Did you define function ap?
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Frederic
> > Ntirenganya
> > Sent: Friday, March 24, 2017 1:18 PM
> > To: r-help at r-project.org
> > Subject: [R] Error: could not find function "ap"
> >
> > Dear All,
> >
> > I hope you are doing well.
> >
> > I am new in using evapotranspiration packages and got the following
> error:
> >
> > Error: could not find function "ap"
> >
> > The code I am using and data are:
> >
> > dat1<-read.csv("/home/fredo/Documents/Meteo Data/Meteo Rwa
> > data.csv",header=T,na.string="9999")
> > dat1$u.daily<-dat1$Wind.Speed*0.514444
> > dat1$Date<-as.Date(paste(dat1$Year,dat1$Month,dat1$Day,sep="-"))
> > #dat1$DOY<-dayOfYear(dat1$Date)
> > dat1$Longitude<-30.11
> > dat1$Latitude<--1.95
> > dat1$Elevation<-1490
> > dat1$RHmax.daily<-dat1$RHmax.daily
> > dat1$RHmin.daily<-dat1$RHmin.daily
> > dat1$Tmax.daily<-dat1$Tmax.daily
> > dat1$Tmin.daily<-dat1$Tmin.daily
> > #dat1<-subset(select=-Wind.direction.measured.in.Degrees)
> > Sunshine<-dat1$n.daily
> > lat<-as.numeric(dat1$Latitude)
> > lon<-as.numeric(dat1$Longitude)
> > days<-dat1$Date
> > require(zoo)
> > A <- 0.21
> > B <- 0.57
> > dat1$RS.daily<-ap(days,lat,lon,A,B,Sunshine,extraT=NULL)
> > View(dat1)
> >
> >
> >
> > dput(head(dat1))
> > structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L ),
> Month =
> > c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Wind.Speed = c(5L, 4L, 4L, 3L, 5L,
> 6L), n.daily
> > = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7 ), Tmax.daily = c(27.4, 26.3, 22.9,
> 27.7, 28.5, 25.5),
> > Tmin.daily = c(14.5, 16, 14.4, 14.8, 16.6, 15.4), RHmax.daily = c(100L,
> 95L, 97L,
> > 100L, 97L, 99L), RHmin.daily = c(45L, 62L, 72L, 55L, 54L, 63L ),
> Station.Name =
> > structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class =
> "factor"),
> >     Elevation = c(1490, 1490, 1490, 1490, 1490, 1490), Longitude =
> c(30.11,
> >     30.11, 30.11, 30.11, 30.11, 30.11), Latitude = c(-1.95, -1.95,
> >     -1.95, -1.95, -1.95, -1.95), u.daily = c(2.57222, 2.057776,
> >     2.057776, 1.543332, 2.57222, 3.086664), Date = structure(c(5113,
> >     5114, 5115, 5116, 5117, 5118), class = "Date")), .Names = c("Year",
> "Month",
> > "Day", "Wind.Speed", "n.daily", "Tmax.daily", "Tmin.daily",
> "RHmax.daily",
> > "RHmin.daily", "Station.Name", "Elevation", "Longitude", "Latitude",
> > "u.daily", "Date"), row.names = c(NA, 6L), class = "data.frame")
> >
> >
> > I appreciate your help in advance!
> >
> > Best regards,
> > Fredo.
> >
> >
> >
> >
> >
> >
> > Frederic Ntirenganya
> > Maseno University,
> > African Maths Initiative,
> > Kenya.
> > Mobile:(+254)718492836
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 25 21:10:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 25 Mar 2017 13:10:45 -0700
Subject: [R] Need class/object type advice to store a particular data
	structure
In-Reply-To: <A9821879-6308-4C0E-9778-AC829C1653DD@gmail.com>
References: <A9821879-6308-4C0E-9778-AC829C1653DD@gmail.com>
Message-ID: <CAGxFJbRnCRVeUKdrKhWSTUzqQfopLj+13zAvckX4O+_+1rwUTw@mail.gmail.com>

Can't personally help, but I assume you've checked out the CRAN
"Spatial" task view, right?

https://cran.r-project.org/web/views/Spatial.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 25, 2017 at 10:42 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
> Hello Everyone,
>
> I have a particular data structure and need your advice what would be the best class/object type to store this kind of a data.
>
> In summary, data is consist of a time series of vertical observations of more than one variables. Observations are made at a particular latitude/longitude location.  Hence, I may have observation locations more than one.
>
> In detail, imagine a list of data.frames and each data.frame contains 7 columns and variable number of rows. Rows represent the vertical coordinate meaning height from surface. Columns are observed variables. Each list of data.frame is belong to a single measurement location that has a latitude and longitude.
>
> So, this is a time series of data.frames but number of rows might change. Is there a class to store this kind of data, for instance, such as SpatialPoints, SPatialPointsDataFrame or RasterStack or Raster object?
>
> I?m asking this question, because I want to take advantage of a ready class for statistical calculations.
>
> Thanks in advance;
>
> Ismail SEZEN
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Mar 25 21:12:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 25 Mar 2017 13:12:33 -0700
Subject: [R] Need class/object type advice to store a particular data
	structure
In-Reply-To: <CAGxFJbRnCRVeUKdrKhWSTUzqQfopLj+13zAvckX4O+_+1rwUTw@mail.gmail.com>
References: <A9821879-6308-4C0E-9778-AC829C1653DD@gmail.com>
	<CAGxFJbRnCRVeUKdrKhWSTUzqQfopLj+13zAvckX4O+_+1rwUTw@mail.gmail.com>
Message-ID: <CAGxFJbRugC=w44f6VYo8RR49-Jezar+Z9=SLG4eFvUNMaUaopg@mail.gmail.com>

... or, better yet, the SpatioTemperal task view ...

https://cran.r-project.org/web/views/SpatioTemporal.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 25, 2017 at 1:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Can't personally help, but I assume you've checked out the CRAN
> "Spatial" task view, right?
>
> https://cran.r-project.org/web/views/Spatial.html
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Mar 25, 2017 at 10:42 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
>> Hello Everyone,
>>
>> I have a particular data structure and need your advice what would be the best class/object type to store this kind of a data.
>>
>> In summary, data is consist of a time series of vertical observations of more than one variables. Observations are made at a particular latitude/longitude location.  Hence, I may have observation locations more than one.
>>
>> In detail, imagine a list of data.frames and each data.frame contains 7 columns and variable number of rows. Rows represent the vertical coordinate meaning height from surface. Columns are observed variables. Each list of data.frame is belong to a single measurement location that has a latitude and longitude.
>>
>> So, this is a time series of data.frames but number of rows might change. Is there a class to store this kind of data, for instance, such as SpatialPoints, SPatialPointsDataFrame or RasterStack or Raster object?
>>
>> I?m asking this question, because I want to take advantage of a ready class for statistical calculations.
>>
>> Thanks in advance;
>>
>> Ismail SEZEN
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sun Mar 26 06:37:58 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 25 Mar 2017 23:37:58 -0500
Subject: [R] combine
Message-ID: <CADDFq314=wMyTXVK4RUBeOeCS6uD_nS_JF2woU_KQKnrOKfvLA@mail.gmail.com>

Hi all,

I have more than two files  and merge by a single column and preserve the
other columns.
Here is an example of two files

dat1 <- read.table(header=TRUE, text=' ID  T1 T2
ID1    125    245
ID2    141    264
ID3    133    281')

dat2 <- read.table(header=TRUE, text=' ID  G1 G2
ID2    25 46
ID4     41    64
ID5    33    81')

 How do I get the following output?

ID     T1       T2   G1    G2
ID1    125    245    0      0
ID2    141    264  25    46
ID3    133    281   0      0
ID4       0       0     41   64
ID5       0      0      33   81

Thank you.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Mar 26 07:04:24 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 26 Mar 2017 01:04:24 -0400
Subject: [R] combine
In-Reply-To: <CADDFq314=wMyTXVK4RUBeOeCS6uD_nS_JF2woU_KQKnrOKfvLA@mail.gmail.com>
References: <CADDFq314=wMyTXVK4RUBeOeCS6uD_nS_JF2woU_KQKnrOKfvLA@mail.gmail.com>
Message-ID: <CC754DF7-BC33-47A0-9CBE-59C5510E1966@utoronto.ca>

Initially:

dat3 <- merge(dat1, dat2, all.x = TRUE, all.y = TRUE)

... and then you had asked for 0, not NA in your results.
I think that's not a good idea - since you can't distinguish
a legitimate value 0 from a missing value that way, but if you
must:

dat3[is.na(dat3)] <- 0

B.
(and don't post in HTML)





> On Mar 26, 2017, at 12:37 AM, Ashta <sewashm at gmail.com> wrote:
> 
> Hi all,
> 
> I have more than two files  and merge by a single column and preserve the
> other columns.
> Here is an example of two files
> 
> dat1 <- read.table(header=TRUE, text=' ID  T1 T2
> ID1    125    245
> ID2    141    264
> ID3    133    281')
> 
> dat2 <- read.table(header=TRUE, text=' ID  G1 G2
> ID2    25 46
> ID4     41    64
> ID5    33    81')
> 
> How do I get the following output?
> 
> ID     T1       T2   G1    G2
> ID1    125    245    0      0
> ID2    141    264  25    46
> ID3    133    281   0      0
> ID4       0       0     41   64
> ID5       0      0      33   81
> 
> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Mar 26 11:37:30 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Mar 2017 02:37:30 -0700
Subject: [R] combine
In-Reply-To: <CADDFq314=wMyTXVK4RUBeOeCS6uD_nS_JF2woU_KQKnrOKfvLA@mail.gmail.com>
References: <CADDFq314=wMyTXVK4RUBeOeCS6uD_nS_JF2woU_KQKnrOKfvLA@mail.gmail.com>
Message-ID: <CAGxFJbQZVmCJv8cZ+88s690Szpe8ZfC-UNyr1tgAY469=bV--A@mail.gmail.com>

?merge
with all.x and all.y both set to TRUE.
Use the NA's **NOT** 0's for nonmatching values that merge() gives.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 25, 2017 at 9:37 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I have more than two files  and merge by a single column and preserve the
> other columns.
> Here is an example of two files
>
> dat1 <- read.table(header=TRUE, text=' ID  T1 T2
> ID1    125    245
> ID2    141    264
> ID3    133    281')
>
> dat2 <- read.table(header=TRUE, text=' ID  G1 G2
> ID2    25 46
> ID4     41    64
> ID5    33    81')
>
>  How do I get the following output?
>
> ID     T1       T2   G1    G2
> ID1    125    245    0      0
> ID2    141    264  25    46
> ID3    133    281   0      0
> ID4       0       0     41   64
> ID5       0      0      33   81
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Sun Mar 26 16:05:42 2017
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 26 Mar 2017 16:05:42 +0200
Subject: [R] Script Taking Long to run
Message-ID: <CAGh51gRV98hqPPB7mTtvB_tNmkHAUEgsG4ZcQfy3um1yY4sL0Q@mail.gmail.com>

Dear R users,

I do have a challenge in a srcipt of computing Sora Radiation. One line is
taking long time without giving the results. The line in which I have
problem is :
dat1$RS.daily<-ap(days=days,lat=lat,lon=lon,A=A,B=B,SSD=Sunshine,extraT=NULL)

Could you please assist me? Thanks

Here is the code:

library("sirad", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
library("Evapotranspiration", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
library("agridat", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
require(zoo)

dat1<-read.csv("/home/fredo/Documents/Meteo Data/Meteo Rwa
data.csv",header=T,na.string="9999")
dat1$u.daily<-dat1$Wind.Speed*0.514444
dat1$Date<-as.Date(paste(dat1$Year,dat1$Month,dat1$Day,sep="-"))
dat1$DOY<-dayOfYear(dat1$Date)
dat1$Longitude<-30.11
dat1$Latitude<--1.95
dat1$Elevation<-1490
A <- 0.21
B <- 0.57
dat1$RHmax.daily<-dat1$RHmax.daily
dat1$RHmin.daily<-dat1$RHmin.daily
dat1$Tmax.daily<-dat1$Tmax.daily
dat1$Tmin.daily<-dat1$Tmin.daily
dat1<-subset(select=-Wind.direction.measured.in.Degrees)
Sunshine<-dat1$n.daily
lat<-as.numeric(dat1$Latitude)
lon<-as.numeric(dat1$Longitude)
days<-dat1$Date

dat1$RS.daily<-ap(days=days,lat=lat,lon=lon,A=A,B=B,SSD=Sunshine,extraT=NULL)

#View(dat1)

DATA:

dput(head(dat1))
structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L
), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Wind.Speed = c(5L,
4L, 4L, 3L, 5L, 6L), n.daily = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
), Tmax.daily = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin.daily = c(14.5,
16, 14.4, 14.8, 16.6, 15.4), RHmax.daily = c(100L, 95L, 97L,
100L, 97L, 99L), RHmin.daily = c(45L, 62L, 72L, 55L, 54L, 63L
), Station.Name = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI
AERO", class = "factor"),
    Elevation = c(1490, 1490, 1490, 1490, 1490, 1490), Longitude = c(30.11,
    30.11, 30.11, 30.11, 30.11, 30.11), Latitude = c(-1.95, -1.95,
    -1.95, -1.95, -1.95, -1.95), u.daily = c(2.57222, 2.057776,
    2.057776, 1.543332, 2.57222, 3.086664), Date = structure(c(5113,
    5114, 5115, 5116, 5117, 5118), class = "Date"), DOY = c(1,
    2, 3, 4, 5, 6)), .Names = c("Year", "Month", "Day", "Wind.Speed",
"n.daily", "Tmax.daily", "Tmin.daily", "RHmax.daily", "RHmin.daily",
"Station.Name", "Elevation", "Longitude", "Latitude", "u.daily",
"Date", "DOY"), row.names = c(NA, 6L), class = "data.frame")

Any help is appreciated!

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Mar 26 16:36:22 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 26 Mar 2017 07:36:22 -0700
Subject: [R] Script Taking Long to run
In-Reply-To: <CAGh51gRV98hqPPB7mTtvB_tNmkHAUEgsG4ZcQfy3um1yY4sL0Q@mail.gmail.com>
References: <CAGh51gRV98hqPPB7mTtvB_tNmkHAUEgsG4ZcQfy3um1yY4sL0Q@mail.gmail.com>
Message-ID: <3C3EDBA9-8840-4EA3-A358-4E665B9364DB@dcn.davis.ca.us>

This is not a question about R... it is either a bug in the sirad package or normal behaviour for that function. Either way you should be corresponding with the package maintainer. 
-- 
Sent from my phone. Please excuse my brevity.

On March 26, 2017 7:05:42 AM PDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Dear R users,
>
>I do have a challenge in a srcipt of computing Sora Radiation. One line
>is
>taking long time without giving the results. The line in which I have
>problem is :
>dat1$RS.daily<-ap(days=days,lat=lat,lon=lon,A=A,B=B,SSD=Sunshine,extraT=NULL)
>
>Could you please assist me? Thanks
>
>Here is the code:
>
>library("sirad", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
>library("Evapotranspiration",
>lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
>library("agridat", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.0")
>require(zoo)
>
>dat1<-read.csv("/home/fredo/Documents/Meteo Data/Meteo Rwa
>data.csv",header=T,na.string="9999")
>dat1$u.daily<-dat1$Wind.Speed*0.514444
>dat1$Date<-as.Date(paste(dat1$Year,dat1$Month,dat1$Day,sep="-"))
>dat1$DOY<-dayOfYear(dat1$Date)
>dat1$Longitude<-30.11
>dat1$Latitude<--1.95
>dat1$Elevation<-1490
>A <- 0.21
>B <- 0.57
>dat1$RHmax.daily<-dat1$RHmax.daily
>dat1$RHmin.daily<-dat1$RHmin.daily
>dat1$Tmax.daily<-dat1$Tmax.daily
>dat1$Tmin.daily<-dat1$Tmin.daily
>dat1<-subset(select=-Wind.direction.measured.in.Degrees)
>Sunshine<-dat1$n.daily
>lat<-as.numeric(dat1$Latitude)
>lon<-as.numeric(dat1$Longitude)
>days<-dat1$Date
>
>dat1$RS.daily<-ap(days=days,lat=lat,lon=lon,A=A,B=B,SSD=Sunshine,extraT=NULL)
>
>#View(dat1)
>
>DATA:
>
>dput(head(dat1))
>structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L
>), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Wind.Speed = c(5L,
>4L, 4L, 3L, 5L, 6L), n.daily = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
>), Tmax.daily = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin.daily =
>c(14.5,
>16, 14.4, 14.8, 16.6, 15.4), RHmax.daily = c(100L, 95L, 97L,
>100L, 97L, 99L), RHmin.daily = c(45L, 62L, 72L, 55L, 54L, 63L
>), Station.Name = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI
>AERO", class = "factor"),
>Elevation = c(1490, 1490, 1490, 1490, 1490, 1490), Longitude = c(30.11,
>    30.11, 30.11, 30.11, 30.11, 30.11), Latitude = c(-1.95, -1.95,
>    -1.95, -1.95, -1.95, -1.95), u.daily = c(2.57222, 2.057776,
>    2.057776, 1.543332, 2.57222, 3.086664), Date = structure(c(5113,
>    5114, 5115, 5116, 5117, 5118), class = "Date"), DOY = c(1,
>    2, 3, 4, 5, 6)), .Names = c("Year", "Month", "Day", "Wind.Speed",
>"n.daily", "Tmax.daily", "Tmin.daily", "RHmax.daily", "RHmin.daily",
>"Station.Name", "Elevation", "Longitude", "Latitude", "u.daily",
>"Date", "DOY"), row.names = c(NA, 6L), class = "data.frame")
>
>Any help is appreciated!
>
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Mar 26 17:58:20 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Mar 2017 08:58:20 -0700
Subject: [R] passing API key in leaflet
In-Reply-To: <CAJuCY5zzh=7y4QsHVGvcPX5aMr4X59sT+Fuxgq7p7SQWy_SEhw@mail.gmail.com>
References: <CAJuCY5zzh=7y4QsHVGvcPX5aMr4X59sT+Fuxgq7p7SQWy_SEhw@mail.gmail.com>
Message-ID: <1CBC96D4-32A8-4B77-A09B-C9B06AE1C5FC@comcast.net>


> On Mar 25, 2017, at 3:44 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear all,
> 
> I'd like to use the OpenCycleMap as background image in a leaflet map.
> This requires an API key. I've stored the key in an environment
> variable. Below is a minimal example of the leaflet map. I still get
> the "API Key Required" message on the tiles. Any suggestions?
> 
> library(leaflet)
> leaflet() %>%
>  addProviderTiles(
>    "Thunderforest.OpenCycleMap",
>    options = providerTileOptions(apikey = Sys.getenv("OCM_API"))
>  )

I don't have any experience with this package but I found myself wondering whether the environment being used was shared by the enviroionment in which the key had been stored. And whether you could do a debugging `print` of hte item returned by Sys.getenv("OCM_API") inside that calling chain?

Best;
David
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jszhao at yeah.net  Sun Mar 26 16:09:50 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sun, 26 Mar 2017 22:09:50 +0800
Subject: [R] Can fallback font be specified?
In-Reply-To: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>
References: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>
Message-ID: <047e79ec-6b20-c46f-d8de-901bce1046d4@yeah.net>

Hi there,

I have searched the google, however, I don't find anything that related 
with fallback font in R.

I also try to read the source code of R, however, I am not familiar with 
C and the algorithm about font specific in text/plot.

Thus, I try to specify different fonts for Latin and non-latin 
characters. I try to use expression():

plot(1:10, xlab = "")
mtext(expression(phantom(Hello)*\u4F60\u597D), side = 1, family = "SimSun")
mtext(expression(Hello*phantom(\u4F60\u597D), side = 1, family = "serif")

However, "Hello" in Simsun has a different strwidth with that in serif. 
Thus, there are more space between Hello and \u4F60\u597D than it should be.

The other way is to merge a Latin font, such as Times New Roman with a 
non Latin font, such as SimSun. There are several fontforge scripts for 
the purpose. However, there will cause fontforge core dump. I don't have 
chance to test it.

Will the R core team or someone response to it, if I filed a wishlist in 
R bugzilla?

Best,
Jinsong

On 2017/3/23 22:24, Jinsong Zhao wrote:
> Hi there,
>
> I am a Chinese R user. I hope to plot the following code with Chinese in
> one font family, such as SimHei, but English in another font family,
> such as Times New Roman.
>
> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "serif")
>
> In my case, the system default font is "SimSun", so the above code
> fallback "\u4F60\u597D", which is not in the font Times, to SimSun.
>
> If I use:
>
> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "SimHei")
>
> Then The "Hello" will in "SimHei" family, it's not as beautiful as Times.
>
> Is it possible to specify the fallback font family in R? Any hints or
> suggestions?
>
> Thanks in advance.
>
> Best,
> Jinsong
>
>> version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          3.3
> year           2017
> month          03
> day            06
> svn rev        72310
> language       R
> version.string R version 3.3.3 (2017-03-06)
> nickname       Another Canoe
>
>> Sys.getlocale()
> [1] "LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese
> (Simplified)_China.936;LC_MONETARY=Chinese
> (Simplified)_China.936;LC_NUMERIC=C;LC_TIME=Chinese (Simplified)_China.936


From rentar18 at gmail.com  Sun Mar 26 19:16:01 2017
From: rentar18 at gmail.com (MyCalendar)
Date: Sun, 26 Mar 2017 13:16:01 -0400
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
	with nice headers
Message-ID: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>

Hi R'ers:
After browsing for a good package for quality table construction, I found nothing.
Any advice?
Thanks 
Bruce 

-------

From istazahn at gmail.com  Sun Mar 26 20:29:01 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 26 Mar 2017 14:29:01 -0400
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <CA+vqiLH=fqtwfSYxN-V=+TGntFgxKd4d1p4MG01g-uOr4G6EHw@mail.gmail.com>

You're going to have to be more specific. What output format? What packages
did you find and in what ways are they unsatisfactory?

Best,
Ista

On Mar 26, 2017 2:22 PM, "MyCalendar" <rentar18 at gmail.com> wrote:

Hi R'ers:
After browsing for a good package for quality table construction, I found
nothing.
Any advice?
Thanks
Bruce

-------
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Mar 26 20:44:05 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 26 Mar 2017 14:44:05 -0400
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <86c6d20a-7ee0-fe4d-2cd3-24151d01eabb@gmail.com>

On 26/03/2017 1:16 PM, MyCalendar wrote:
> Hi R'ers:
> After browsing for a good package for quality table construction, I found nothing.
> Any advice?

Try the task view on Reproducible research: 
<https://cran.r-project.org/web/views/ReproducibleResearch.html>.

Duncan Murdoch


From rmh at temple.edu  Sun Mar 26 20:45:09 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 26 Mar 2017 11:45:09 -0700
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <CAGx1TMCGWkURudQc4HOoKs5Ky_UZHXBa1KegJ1c4wvH6gj27rw@mail.gmail.com>

I will assume that a "quality table" is a LaTeX tabular environment,
possibly with some
nested row or column structures.  For that I recommend the latex
function in the Hmisc
package.  The examples in ?latex are simple.  Quite complex
structures, for example, with
nested sets of labled rows and columns, can be built by using some of
the many optional
arguments.  The resulting .tex file can be input into your larger .tex file.

The default settings use the system latex command to build and immediately
display a dvi file of the table (or other R object).
For Mac or WIndows I use pdflatex to build and display a pdf file.  This needs
options(latexcmd='pdflatex');options(dviExtension='pdf');options(xdvicmd='open')
Some linux versions will need a different value for the xdvicmd
option.  See ?latex
for discussion of options.

You can embed R graphics into your table using the microplot package.
See the examples,
vignette, and demos for details.  Microplots can be use to place
graphics in html files and
other file types.

Rich

On Sun, Mar 26, 2017 at 10:16 AM, MyCalendar <rentar18 at gmail.com> wrote:
> Hi R'ers:
> After browsing for a good package for quality table construction, I found nothing.
> Any advice?
> Thanks
> Bruce
>
> -------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Mar 26 21:27:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Mar 2017 12:27:45 -0700
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <CAGxFJbRF5=gMchk7byGmD+8t17-N=Qh-EqCHfJx3+nog4m84rA@mail.gmail.com>

Look again!

(e.g. google "make tables in R")

(Note that "quality table construction" is subjective and undefined,
so it's up to you to either define them sufficiently for others or do
your own research to see if what's out there meets your undefined
criteria).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 26, 2017 at 10:16 AM, MyCalendar <rentar18 at gmail.com> wrote:
> Hi R'ers:
> After browsing for a good package for quality table construction, I found nothing.
> Any advice?
> Thanks
> Bruce
>
> -------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Mar 26 23:28:30 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Mar 2017 08:28:30 +1100
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <CA+8X3fXHM_-s2R+pkvWcB2oPen846E9RaoEh_3mCK3j0c8hQvw@mail.gmail.com>

Hi Bruce,
Well, a start might be:

bdf<-data.frame(Pre=sample(10:20,10),
 During=sample(8:18,10),
 EOT=sample(5:15,10),fu3mo=sample(7:17,10),
 fu6mo=sample(10:20,10))
rownames(bdf)<-paste("S",1:10,sep="")
plot.new()
library(plotrix)
addtable2plot(0.15,0.2,bdf,display.rownames=TRUE,
 bty="o",vlines=TRUE,hlines=TRUE,title="My table")

Jim


On Mon, Mar 27, 2017 at 4:16 AM, MyCalendar <rentar18 at gmail.com> wrote:
> Hi R'ers:
> After browsing for a good package for quality table construction, I found nothing.
> Any advice?
> Thanks
> Bruce
>
> -------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul at stat.auckland.ac.nz  Mon Mar 27 00:46:49 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 27 Mar 2017 11:46:49 +1300
Subject: [R] [FORGED]  Can fallback font be specified?
In-Reply-To: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>
References: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>
Message-ID: <c0c6796c-abe9-49bd-d3e2-86ab10c3a89f@stat.auckland.ac.nz>

Hi

The following code uses 'gridSVG' to export the plot to SVG (after using 
'gridGraphics' to convert the plot to using 'grid'), which allows you to 
specify a "font stack" for the exported SVG.  In this example, I am 
adding "SimHei" to the "serif" font stack.  I attach a screen shot of 
what the result looks like for me in Firefox on Windows (because I am 
not sure what it should look like).  The idea here is really just to 
pass the effort of deciding which font to use on to a web browser.

library(gridSVG)
library(gridGraphics)

fonts <- getSVGFonts()
fonts$serif <- c(fonts$serif, "SimHei")
setSVGFonts(fonts)

plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family="serif")

grid.echo()
grid.export("test-1.svg", xmldecl='')

Does that help at all?

Paul

On 24/03/2017 3:24 a.m., Jinsong Zhao wrote:
> Hi there,
>
> I am a Chinese R user. I hope to plot the following code with Chinese in
> one font family, such as SimHei, but English in another font family,
> such as Times New Roman.
>
> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "serif")
>
> In my case, the system default font is "SimSun", so the above code
> fallback "\u4F60\u597D", which is not in the font Times, to SimSun.
>
> If I use:
>
> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "SimHei")
>
> Then The "Hello" will in "SimHei" family, it's not as beautiful as Times.
>
> Is it possible to specify the fallback font family in R? Any hints or
> suggestions?
>
> Thanks in advance.
>
> Best,
> Jinsong
>
>> version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          3.3
> year           2017
> month          03
> day            06
> svn rev        72310
> language       R
> version.string R version 3.3.3 (2017-03-06)
> nickname       Another Canoe
>
>> Sys.getlocale()
> [1] "LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese
> (Simplified)_China.936;LC_MONETARY=Chinese
> (Simplified)_China.936;LC_NUMERIC=C;LC_TIME=Chinese (Simplified)_China.936"
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: screen.png
Type: image/png
Size: 14565 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170327/dddfc2f4/attachment.png>

From rbaer at atsu.edu  Mon Mar 27 00:54:36 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 26 Mar 2017 17:54:36 -0500
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
 with nice headers
In-Reply-To: <CA+8X3fXHM_-s2R+pkvWcB2oPen846E9RaoEh_3mCK3j0c8hQvw@mail.gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
	<CA+8X3fXHM_-s2R+pkvWcB2oPen846E9RaoEh_3mCK3j0c8hQvw@mail.gmail.com>
Message-ID: <c40514d7-63d0-b1b9-fbb1-08c0d0c5589f@atsu.edu>

Quite nice Jim.  A little par() magic, some well thought plot window 
dimensions, and good to go.

I wasn't looking, but now that I've seen it, I can imagine uses.

Bruce - see also 
https://cran.r-project.org/web/packages/xtable/vignettes/xtableGallery.pdf

On 3/26/2017 4:28 PM, Jim Lemon wrote:
> Hi Bruce,
> Well, a start might be:
>
> bdf<-data.frame(Pre=sample(10:20,10),
>   During=sample(8:18,10),
>   EOT=sample(5:15,10),fu3mo=sample(7:17,10),
>   fu6mo=sample(10:20,10))
> rownames(bdf)<-paste("S",1:10,sep="")
> plot.new()
> library(plotrix)
> addtable2plot(0.15,0.2,bdf,display.rownames=TRUE,
>   bty="o",vlines=TRUE,hlines=TRUE,title="My table")
>
> Jim
>
>
> On Mon, Mar 27, 2017 at 4:16 AM, MyCalendar <rentar18 at gmail.com> wrote:
>> Hi R'ers:
>> After browsing for a good package for quality table construction, I found nothing.
>> Any advice?
>> Thanks
>> Bruce
>>
>> -------
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Mon Mar 27 02:55:20 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 27 Mar 2017 08:55:20 +0800
Subject: [R] [FORGED]  Can fallback font be specified?
In-Reply-To: <c0c6796c-abe9-49bd-d3e2-86ab10c3a89f@stat.auckland.ac.nz>
References: <49b552b8-c384-7839-84f2-9f7443b320ff@yeah.net>
	<c0c6796c-abe9-49bd-d3e2-86ab10c3a89f@stat.auckland.ac.nz>
Message-ID: <77387edc-1163-217f-0755-a07f9d69760c@yeah.net>

On 2017/3/27 6:46, Paul Murrell wrote:
> Hi
>
> The following code uses 'gridSVG' to export the plot to SVG (after using
> 'gridGraphics' to convert the plot to using 'grid'), which allows you to
> specify a "font stack" for the exported SVG.  In this example, I am
> adding "SimHei" to the "serif" font stack.  I attach a screen shot of
> what the result looks like for me in Firefox on Windows (because I am
> not sure what it should look like).  The idea here is really just to
> pass the effort of deciding which font to use on to a web browser.
>
> library(gridSVG)
> library(gridGraphics)
>
> fonts <- getSVGFonts()
> fonts$serif <- c(fonts$serif, "SimHei")
> setSVGFonts(fonts)
>
> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family="serif")
>
> grid.echo()
> grid.export("test-1.svg", xmldecl='')
>
> Does that help at all?
>
> Paul

Thank you very much.

The code solve my concerns about fonts. gridGraphics make me to draw my 
plot in base graphics that I used to. I can convert SVG to any other 
format using Inkscape.

Best,
Jinsong

>
> On 24/03/2017 3:24 a.m., Jinsong Zhao wrote:
>> Hi there,
>>
>> I am a Chinese R user. I hope to plot the following code with Chinese in
>> one font family, such as SimHei, but English in another font family,
>> such as Times New Roman.
>>
>> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "serif")
>>
>> In my case, the system default font is "SimSun", so the above code
>> fallback "\u4F60\u597D", which is not in the font Times, to SimSun.
>>
>> If I use:
>>
>> plot(1:10, type = "n", xlab = "Hello \u4F60\u597D", family = "SimHei")
>>
>> Then The "Hello" will in "SimHei" family, it's not as beautiful as Times.
>>
>> Is it possible to specify the fallback font family in R? Any hints or
>> suggestions?
>>
>> Thanks in advance.
>>
>> Best,
>> Jinsong
>>


From rentar18 at gmail.com  Mon Mar 27 01:13:00 2017
From: rentar18 at gmail.com (MyCalendar)
Date: Sun, 26 Mar 2017 19:13:00 -0400
Subject: [R] Assistance would be appreciated
Message-ID: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>

Hi R'ers:
Newbie to R, but I guarantee that I don't ask for help until, in this case, I spent
Over ten hours today ( Sunday, wife loves it!! )
I can't find the bug, trying to remove column cum_wt.
Assistance would be appreciated. 
Bruce 
--- Code ---

yhat     <- seq(1, 0.05, length.out = 20)
Response <-c(1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0)
cum_R    <- cumsum(Response)
sam_size <- length(Response)
cum_wt   <- seq(1:1,length=20)
wt       <- seq(1:1,by=0, length=20)
dec      <- (cum_wt/sam_size)
decc     <- floor((cum_wt*10)/(sam_size+1))
dec_mean <- aggregate(Response, by=list(decc), mean)
d        <- data.frame(yhat, Response, cum_R, sam_size, cum_wt,wt, decc, dec_mean)
d

#decc=0
decc_0           <- subset(d, decc ==0)
mean_decc_0      <- colMeans(decc_0, 2)
mean_decc_0[1,5] <- NULL
mean_decc_0
______________





-------
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Mar 27 11:30:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Mar 2017 20:30:24 +1100
Subject: [R] Assistance would be appreciated
In-Reply-To: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>
References: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>
Message-ID: <CA+8X3fWqukGoFrzxetjCwJYJRRwpBZn=9gjyehCxpa_RjwWAaA@mail.gmail.com>

Hi is it still Bruce?,

mean_decc_0<-mean_decc_0[c(1:4,6:8)]

Jim

On Mon, Mar 27, 2017 at 10:13 AM, MyCalendar <rentar18 at gmail.com> wrote:
> Hi R'ers:
> Newbie to R, but I guarantee that I don't ask for help until, in this case, I spent
> Over ten hours today ( Sunday, wife loves it!! )
> I can't find the bug, trying to remove column cum_wt.
> Assistance would be appreciated.
> Bruce
> --- Code ---
>
> yhat     <- seq(1, 0.05, length.out = 20)
> Response <-c(1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0)
> cum_R    <- cumsum(Response)
> sam_size <- length(Response)
> cum_wt   <- seq(1:1,length=20)
> wt       <- seq(1:1,by=0, length=20)
> dec      <- (cum_wt/sam_size)
> decc     <- floor((cum_wt*10)/(sam_size+1))
> dec_mean <- aggregate(Response, by=list(decc), mean)
> d        <- data.frame(yhat, Response, cum_R, sam_size, cum_wt,wt, decc, dec_mean)
> d
>
> #decc=0
> decc_0           <- subset(d, decc ==0)
> mean_decc_0      <- colMeans(decc_0, 2)
> mean_decc_0[1,5] <- NULL
> mean_decc_0
> ______________
>
>
>
>
>
> -------
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Mon Mar 27 11:30:29 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 27 Mar 2017 11:30:29 +0200
Subject: [R] Assistance would be appreciated
In-Reply-To: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>
References: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>
Message-ID: <C0BD33D6-BCC5-457E-A2B5-7287D28A7045@xs4all.nl>


> On 27 Mar 2017, at 01:13, MyCalendar <rentar18 at gmail.com> wrote:
> 
> Hi R'ers:
> Newbie to R, but I guarantee that I don't ask for help until, in this case, I spent
> Over ten hours today ( Sunday, wife loves it!! )
> I can't find the bug, trying to remove column cum_wt.
> Assistance would be appreciated. 

mean_decc_0 is a matrix? No it isn't.
Use str(mean_decc_0) to see what it actually is.
Then try setting the required element to NULL. And ponder your goal.

Berend Hasselman

> Bruce 
> --- Code ---
> 
> yhat     <- seq(1, 0.05, length.out = 20)
> Response <-c(1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0)
> cum_R    <- cumsum(Response)
> sam_size <- length(Response)
> cum_wt   <- seq(1:1,length=20)
> wt       <- seq(1:1,by=0, length=20)
> dec      <- (cum_wt/sam_size)
> decc     <- floor((cum_wt*10)/(sam_size+1))
> dec_mean <- aggregate(Response, by=list(decc), mean)
> d        <- data.frame(yhat, Response, cum_R, sam_size, cum_wt,wt, decc, dec_mean)
> d
> 
> #decc=0
> decc_0           <- subset(d, decc ==0)
> mean_decc_0      <- colMeans(decc_0, 2)
> mean_decc_0[1,5] <- NULL
> mean_decc_0
> ______________
> 
> 
> 
> 
> 
> -------
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Mon Mar 27 13:04:56 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 27 Mar 2017 11:04:56 +0000 (UTC)
Subject: [R] Presentation Quality Tables, e.g., Ten rows, Five columns,
	with nice headers
In-Reply-To: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
References: <34F94040-D8D1-4E33-A999-155B60D8F026@gmail.com>
Message-ID: <615433967.3667622.1490612696914@mail.yahoo.com>

If you are working in LaTeX I'd suggest having a look at the R package? xtable with the? LaTeX package booktabs.? 


 

    On Sunday, March 26, 2017 2:23 PM, MyCalendar <rentar18 at gmail.com> wrote:
 

 Hi R'ers:
After browsing for a good package for quality table construction, I found nothing.
Any advice?
Thanks 
Bruce 

-------
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From paladini at trustindata.de  Mon Mar 27 11:08:12 2017
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Mon, 27 Mar 2017 11:08:12 +0200
Subject: [R] pvclust: highly varying results for the exactly same analysis,
 unknown warning message
Message-ID: <20170327110812.Horde.14YMX-Pr2C-o2bqDxfi4Kg1@webmail.df.eu>

Hello,
I have got problems using pvclust() and it would be really nice if  
somebody could help me.

I have got a dataframe called "owner2006" looking like this:


                       company  year share0 share1 share2  share5  
share6  share7 share11 share12
1                   aareal bank 2006  57.800   0.00 42.200   0.000   
0.000   0.000       0       0
3                        adidas 2006  94.730   0.00  5.270   0.000   
0.000   0.000       0       0
5           airbus group (eads) 2006  33.470   0.00  5.020  22.490  
35.530   0.000       0       0
.
.
.
.
(The data frame dimension is 124 rows, 10 colums.)


I use the following code


ownerscale2006=owner2006
ownerscale2006[,c(3:10)]=scale( owner2006[,c(3:10)])

fit=pvclust(t(ownerscale2006[,c(3:10)]), method.hclust="ward",  
method.dist="euclidean")
plot(fit, main="owner,2006,scaled")
pvrect(fit, alpha=.95)


What concerns me is that the outcome varies so much. One time only two  
clusters are proposed next time there are six clusters highlighted.
Shouldn`t the outcome be always nearly the same? Is there something  
wrong with my analysis or can a certain data-structure cause such  
highly varing outcomes?


Moreover I get always  warning messages :
1: In a$p[] <- c(0, bp[r == 1]) :
   number of items to replace is not a multiple of replacement length
2: In a$p[] <- c(0, bp[r == 1]) :
   number of items to replace is not a multiple of replacement length
3: In a$p[] <- c(0, bp[r == 1]) :
   number of items to replace is not a multiple of replacement length
4: In a$p[] <- c(0, bp[r == 1]) :
   number of items to replace is not a multiple of replacement length
5: In a$p[] <- c(1, bp[r == 1]) :
   number of items to replace is not a multiple of replacement length


And I haven't the faintest idea what they mean in this context.


I would be very grateful if somebody could help me.

Best regards

Claudia Paladini


From rentar18 at gmail.com  Mon Mar 27 12:09:44 2017
From: rentar18 at gmail.com (MyCalendar)
Date: Mon, 27 Mar 2017 06:09:44 -0400
Subject: [R] Assistance would be appreciated
In-Reply-To: <C0BD33D6-BCC5-457E-A2B5-7287D28A7045@xs4all.nl>
References: <1B833440-1B87-4698-943C-2269172F1DF1@gmail.com>
	<C0BD33D6-BCC5-457E-A2B5-7287D28A7045@xs4all.nl>
Message-ID: <8A6A3606-FA81-4C37-BAD7-27D5D26A4D04@gmail.com>

Hey Berend and Jim:
Yes, it's me, Bruce. 
I will try your inputs, and let you know. 
Thanks.
Bruce

PS: I goal is to create:  mean_decc_0, mean_decc_1, ..., mean_decc_9
And then stack them. Also, Aren't these dataframe?
-------

> On Mar 27, 2017, at 5:30 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
>> On 27 Mar 2017, at 01:13, MyCalendar <rentar18 at gmail.com> wrote:
>> 
>> Hi R'ers:
>> Newbie to R, but I guarantee that I don't ask for help until, in this case, I spent
>> Over ten hours today ( Sunday, wife loves it!! )
>> I can't find the bug, trying to remove column cum_wt.
>> Assistance would be appreciated. 
> 
> mean_decc_0 is a matrix? No it isn't.
> Use str(mean_decc_0) to see what it actually is.
> Then try setting the required element to NULL. And ponder your goal.
> 
> Berend Hasselman
> 
>> Bruce 
>> --- Code ---
>> 
>> yhat     <- seq(1, 0.05, length.out = 20)
>> Response <-c(1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0)
>> cum_R    <- cumsum(Response)
>> sam_size <- length(Response)
>> cum_wt   <- seq(1:1,length=20)
>> wt       <- seq(1:1,by=0, length=20)
>> dec      <- (cum_wt/sam_size)
>> decc     <- floor((cum_wt*10)/(sam_size+1))
>> dec_mean <- aggregate(Response, by=list(decc), mean)
>> d        <- data.frame(yhat, Response, cum_R, sam_size, cum_wt,wt, decc, dec_mean)
>> d
>> 
>> #decc=0
>> decc_0           <- subset(d, decc ==0)
>> mean_decc_0      <- colMeans(decc_0, 2)
>> mean_decc_0[1,5] <- NULL
>> mean_decc_0
>> ______________
>> 
>> 
>> 
>> 
>> 
>> -------
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From saubhagya at gatech.edu  Mon Mar 27 16:07:30 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Mon, 27 Mar 2017 14:07:30 +0000
Subject: [R] R version 3.3.2,
 Windows 10: How to identify the common coordinates in two different
 SpatialPixelDataFrame
Message-ID: <DM5PR07MB3179E214DD8BE5FC050AB904CF330@DM5PR07MB3179.namprd07.prod.outlook.com>

Hello Everyone,

I am resending this message as due to some reason, the message was not posted on the list before.

I have two SpatialPixelDataFrames (a and b) which have few common coordinates/locations. I need to identify these common coordinates and remove them from both the dataframes.

Though I have been able to identify and separate common coordinate points (an2 and bn2), but I feel my code is very inefficient. Is there is better way to do it. I have shared my code here.

Secondly, I am also not sure about how can I remove these locations from the original dataframes "a" and "b".

Thank You
#-----code starts---------------------

# separating the points with same coordinates

a<-data.frame(x=c(1,4,6,3,2),y=c(1,3,5,2,9),z=c(5,6,7,8,3))
b<-data.frame(x=c(2,4,2,3,4),y=c(9,3,6,7,4),z=c(3,6,3,4,9))
gridded(a) = ~x+y
gridded(b) = ~x+y

# comparing x coordinates
res <- outer(a at coords[,1], b at coords[,1], `==`)

# an and bn have common x coordinates
index.temp<-which(res,arr.ind = T)
an<-a[unique(index.temp[,1]),]
bn<-b[unique(index.temp[,2]),]

#comparing y coordinates
res <- outer(an at coords[,2], bn at coords[,2], `==`)
index.temp<-which(res,arr.ind = T)

#an2 and bn2 have comon x and y coordinates
an2<-an[unique(index.temp[,1]),]
bn2<-bn[unique(index.temp[,2]),]

#--code ends-----------------------------------

Thank You
Saubhagya

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Mon Mar 27 16:15:12 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 27 Mar 2017 09:15:12 -0500
Subject: [R] Handling nonexistent observations in R for time series analysis
	and forecasting
Message-ID: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>

Dear friends,

Hope you are all doing great. I am trying to model historical data on
transits, and the dates are in the following format: 1985-10-01
00:00:00.000 (this would be october, 1985).
The data comes from an SQL Server Database and there are several missing
observations. The problem is that, for example, there are dates for which
no transit was recorded (because no transit took place) and instead of
having that date recorded with an NA value, that date does not appear,
resulting in a sequence like this:
1985-01-01 00:00:00.000, 1985-02-01 00:00:00.000, 1985-05-01 00:00:00.00
in this example you start in january 1985, the february 1985, then the next
available observation is on may 1985.
I know R?s tsclean(data) function takes care of missing values, but that
only works if you at least have the non available dates recorded with a
value of NA, but what if I do not have those missing observations?

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 27 16:33:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Mar 2017 07:33:29 -0700
Subject: [R] Handling nonexistent observations in R for time series
 analysis and forecasting
In-Reply-To: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
References: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
Message-ID: <CAGxFJbTg83hQRjBqaRKr08JF+S7XQaq5jxatTb1FGN7kizqMqg@mail.gmail.com>

A statistics, not really an R programming question, so I believe OT here.
But:

1. See the CRAN Time series task view for what's available:
https://cran.r-project.org/web/views/TimeSeries.html

2. stats.stackexchange.com is a good site for statistical questions.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 27, 2017 at 7:15 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear friends,
>
> Hope you are all doing great. I am trying to model historical data on
> transits, and the dates are in the following format: 1985-10-01
> 00:00:00.000 (this would be october, 1985).
> The data comes from an SQL Server Database and there are several missing
> observations. The problem is that, for example, there are dates for which
> no transit was recorded (because no transit took place) and instead of
> having that date recorded with an NA value, that date does not appear,
> resulting in a sequence like this:
> 1985-01-01 00:00:00.000, 1985-02-01 00:00:00.000, 1985-05-01 00:00:00.00
> in this example you start in january 1985, the february 1985, then the next
> available observation is on may 1985.
> I know R?s tsclean(data) function takes care of missing values, but that
> only works if you at least have the non available dates recorded with a
> value of NA, but what if I do not have those missing observations?
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Mon Mar 27 18:50:20 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 27 Mar 2017 12:50:20 -0400
Subject: [R] assistance is greatly needed
Message-ID: <4551ac94-713f-3586-ef7d-1b2621bf9ebe@dmstat1.com>

Hi R'ers:
I am seeking the attachment.
Any help is greatly appreciated.
Thanks.
Bruce
----
**** Code ***
yhat     <- seq(1, 0.05, length.out = 20)
Response <-c(1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0)
cum_R    <- cumsum(Response)
sam_size <- length(Response)
cum_n    <- seq(1:1,length=20)
cum_wt       <- seq(1:1,by=0,length=20)

dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))
dec_mean <- aggregate(Response, by=list(decc), mean)
d        <- data.frame(yhat, Response, cum_R, sam_size, cum_wt, cum_n, 
decc, dec_mean)
d
# decc=0
decc_0      <- subset(d, decc ==0)
mean_decc_0 <- colMeans(decc_0, 2)
mean_decc_0 <- mean_decc_0[c(2:4,7)]
mean_decc_0

decc_0      <- subset(d, decc ==0)
sum_decc_0  <- colSums(d, 2)
sum_decc_0
sum_decc_0  <- sum_decc_0[c(5)]
sum_decc_0
add_decc_0  <- cbind(mean_decc_0, sum_decc_0)
add_decc_0

-- 
Bruce
  


From jdnewmil at dcn.davis.ca.us  Mon Mar 27 18:55:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Mar 2017 09:55:59 -0700
Subject: [R] Handling nonexistent observations in R for time series
	analysis and forecasting
In-Reply-To: <CAGxFJbTg83hQRjBqaRKr08JF+S7XQaq5jxatTb1FGN7kizqMqg@mail.gmail.com>
References: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
	<CAGxFJbTg83hQRjBqaRKr08JF+S7XQaq5jxatTb1FGN7kizqMqg@mail.gmail.com>
Message-ID: <4A578D2A-FEE3-46DF-BB80-7AAEB04344EE@dcn.davis.ca.us>

Actually, I think his question is about R because one answer that has been mentioned is to use the merge function, but I haven't felt the urge to create a reprex for him (see Posting Guide) and he keeps posting in HTML so it would have been corrupted even if he had. Someone else also pointed out that there is an option to use irregular time series analysis.
-- 
Sent from my phone. Please excuse my brevity.

On March 27, 2017 7:33:29 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>A statistics, not really an R programming question, so I believe OT
>here.
>But:
>
>1. See the CRAN Time series task view for what's available:
>https://cran.r-project.org/web/views/TimeSeries.html
>
>2. stats.stackexchange.com is a good site for statistical questions.
>
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Mon, Mar 27, 2017 at 7:15 AM, Paul Bernal <paulbernal07 at gmail.com>
>wrote:
>> Dear friends,
>>
>> Hope you are all doing great. I am trying to model historical data on
>> transits, and the dates are in the following format: 1985-10-01
>> 00:00:00.000 (this would be october, 1985).
>> The data comes from an SQL Server Database and there are several
>missing
>> observations. The problem is that, for example, there are dates for
>which
>> no transit was recorded (because no transit took place) and instead
>of
>> having that date recorded with an NA value, that date does not
>appear,
>> resulting in a sequence like this:
>> 1985-01-01 00:00:00.000, 1985-02-01 00:00:00.000, 1985-05-01
>00:00:00.00
>> in this example you start in january 1985, the february 1985, then
>the next
>> available observation is on may 1985.
>> I know R?s tsclean(data) function takes care of missing values, but
>that
>> only works if you at least have the non available dates recorded with
>a
>> value of NA, but what if I do not have those missing observations?
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From o.o.wolf at qmul.ac.uk  Mon Mar 27 19:09:23 2017
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Mon, 27 Mar 2017 18:09:23 +0100
Subject: [R] How to load fonts in text3d?
Message-ID: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>

I'm trying to run the example given in ?text3d as follows:

library(rgl)
open3d()
famnum <- rep(1:4, 8)
family <- c("serif", "sans", "mono", "symbol")[famnum]
font <- rep(rep(1:4, each = 4), 2)
cex <- rep(1:2, each = 16)
text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
       color = "blue", family = family, font = font, cex = cex)

This results in a couple of warning messages of the following kind:

In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
  font family "serif" not found, using "bitmap"

I would like to use another font instead of bitmap but it seems to
switchback to bitmap whatever argument I give as family e.g. 'family =
"FreeSans"'.
Wonder if this is a bug or I'm doing something wrong.

This is on
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)
with the following rgl version loaded:
[1] rgl_0.96.0


Thanks in advance for any indications


From bgunter.4567 at gmail.com  Mon Mar 27 20:08:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Mar 2017 11:08:03 -0700
Subject: [R] Handling nonexistent observations in R for time series
 analysis and forecasting
In-Reply-To: <4A578D2A-FEE3-46DF-BB80-7AAEB04344EE@dcn.davis.ca.us>
References: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
	<CAGxFJbTg83hQRjBqaRKr08JF+S7XQaq5jxatTb1FGN7kizqMqg@mail.gmail.com>
	<4A578D2A-FEE3-46DF-BB80-7AAEB04344EE@dcn.davis.ca.us>
Message-ID: <CAGxFJbSLToZmvheR--GYU79FfWs=qayYkxH_LJSjZgX-CvpCzw@mail.gmail.com>

Ok Jeff. Thanks.

Bert



On Mar 27, 2017 9:56 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

> Actually, I think his question is about R because one answer that has been
> mentioned is to use the merge function, but I haven't felt the urge to
> create a reprex for him (see Posting Guide) and he keeps posting in HTML so
> it would have been corrupted even if he had. Someone else also pointed out
> that there is an option to use irregular time series analysis.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 27, 2017 7:33:29 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >A statistics, not really an R programming question, so I believe OT
> >here.
> >But:
> >
> >1. See the CRAN Time series task view for what's available:
> >https://cran.r-project.org/web/views/TimeSeries.html
> >
> >2. stats.stackexchange.com is a good site for statistical questions.
> >
> >
> >Cheers,
> >Bert
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Mon, Mar 27, 2017 at 7:15 AM, Paul Bernal <paulbernal07 at gmail.com>
> >wrote:
> >> Dear friends,
> >>
> >> Hope you are all doing great. I am trying to model historical data on
> >> transits, and the dates are in the following format: 1985-10-01
> >> 00:00:00.000 (this would be october, 1985).
> >> The data comes from an SQL Server Database and there are several
> >missing
> >> observations. The problem is that, for example, there are dates for
> >which
> >> no transit was recorded (because no transit took place) and instead
> >of
> >> having that date recorded with an NA value, that date does not
> >appear,
> >> resulting in a sequence like this:
> >> 1985-01-01 00:00:00.000, 1985-02-01 00:00:00.000, 1985-05-01
> >00:00:00.00
> >> in this example you start in january 1985, the february 1985, then
> >the next
> >> available observation is on may 1985.
> >> I know R?s tsclean(data) function takes care of missing values, but
> >that
> >> only works if you at least have the non available dates recorded with
> >a
> >> value of NA, but what if I do not have those missing observations?
> >>
> >> Any help will be greatly appreciated,
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar 27 21:21:14 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Mar 2017 15:21:14 -0400
Subject: [R] How to load fonts in text3d?
In-Reply-To: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
References: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
Message-ID: <2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>

On 27/03/2017 1:09 PM, olsen wrote:
> I'm trying to run the example given in ?text3d as follows:
>
> library(rgl)
> open3d()
> famnum <- rep(1:4, 8)
> family <- c("serif", "sans", "mono", "symbol")[famnum]
> font <- rep(rep(1:4, each = 4), 2)
> cex <- rep(1:2, each = 16)
> text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
>        color = "blue", family = family, font = font, cex = cex)
>
> This results in a couple of warning messages of the following kind:
>
> In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
>   font family "serif" not found, using "bitmap"
>
> I would like to use another font instead of bitmap but it seems to
> switchback to bitmap whatever argument I give as family e.g. 'family =
> "FreeSans"'.
> Wonder if this is a bug or I'm doing something wrong.
>
> This is on
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
> with the following rgl version loaded:
> [1] rgl_0.96.0

What do you see if you run rglFonts()?  It should list the fonts you 
have installed.  On MacOS, I see

 > rglFonts()
$serif
[1] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[2] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[3] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[4] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"

$sans
[1] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
[2] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
[3] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
[4] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"

$mono
[1] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
[2] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
[3] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
[4] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"

$symbol
[1] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[2] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[3] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
[4] 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"

If you don't have Freetype installed on your system, you won't be able 
to use any of those.

Duncan Murdoch


From paulbernal07 at gmail.com  Mon Mar 27 22:09:59 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 27 Mar 2017 15:09:59 -0500
Subject: [R] Looping Through DataFrames with Differing Lenghts
Message-ID: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>

Dear friends,

I have one dataframe which contains 378 observations, and another one,
containing 362 observations.

Both dataframes have two columns, one date column and another one with the
number of transits.

I wanted to come up with a code so that I could fill in the dates that are
missing in one of the dataframes and replace the column of transits with
the value NA.

I have tried several things but R obviously complains that the length of
the dataframes are different.

How can I solve this?

Any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Mon Mar 27 22:15:39 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 27 Mar 2017 20:15:39 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
Message-ID: <979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>

Make some small dataframes of just a few rows that illustrate the problem structure. Make a third that has the result you want. You will get an answer very quickly. Without a self-contained reproducible problem, results vary.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I have one dataframe which contains 378 observations, and another one,
> containing 362 observations.
>
> Both dataframes have two columns, one date column and another one with the
> number of transits.
>
> I wanted to come up with a code so that I could fill in the dates that are
> missing in one of the dataframes and replace the column of transits with
> the value NA.
>
> I have tried several things but R obviously complains that the length of
> the dataframes are different.
>
> How can I solve this?
>
> Any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From dwinsemius at comcast.net  Tue Mar 28 00:51:26 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 27 Mar 2017 15:51:26 -0700
Subject: [R] Handling nonexistent observations in R for time series
	analysis and forecasting
In-Reply-To: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
References: <CAMOcQfPRcJFCFzZ5CYHguwLYC990CtYuaMpBPtbTE_-fcokwMw@mail.gmail.com>
Message-ID: <3A9BBDD7-AA26-48BF-81BA-A0BBE402D94A@comcast.net>


> On Mar 27, 2017, at 7:15 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> Hope you are all doing great. I am trying to model historical data on
> transits, and the dates are in the following format: 1985-10-01
> 00:00:00.000 (this would be october, 1985).
> The data comes from an SQL Server Database and there are several missing
> observations. The problem is that, for example, there are dates for which
> no transit was recorded (because no transit took place) and instead of
> having that date recorded with an NA value, that date does not appear,
> resulting in a sequence like this:
> 1985-01-01 00:00:00.000, 1985-02-01 00:00:00.000, 1985-05-01 00:00:00.00
> in this example you start in january 1985, the february 1985, then the next
> available observation is on may 1985.
> I know R?s tsclean(data) function takes care of missing values, but that
> only works if you at least have the non available dates recorded with a
> value of NA, but what if I do not have those missing observations?
> 
> Any help will be greatly appreciated,

And the other readers of this ist will greatly appreciate a working example and plain text postings. Assuming you have these date-times in a dataframe named dat within a column named `time`:

> merge(x=data.frame(time=seq(min(dat$time), max(dat$time), by="month")), y=dat,all.x=TRUE, by.y='time')
        time X.placeholder.
1 1985-01-01    placeholder
2 1985-02-01    placeholder
3 1985-03-01           <NA>
4 1985-04-01           <NA>
5 1985-05-01    placeholder
> 
> Best regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ulrik.stervbo at gmail.com  Tue Mar 28 05:15:57 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 28 Mar 2017 03:15:57 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
Message-ID: <CAKVAULNPJfxo+-Q-66oG_dQ3mH89g3r+haNEF0nrK2DYA2sPpw@mail.gmail.com>

You could use merge() or %in%.

Best,
Ulrik

Mark Sharp <msharp at txbiomed.org> schrieb am Mo., 27. M?rz 2017, 22:20:

> Make some small dataframes of just a few rows that illustrate the problem
> structure. Make a third that has the result you want. You will get an
> answer very quickly. Without a self-contained reproducible problem, results
> vary.
>
> Mark
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
>
>
>
>
>
> > On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friends,
> >
> > I have one dataframe which contains 378 observations, and another one,
> > containing 362 observations.
> >
> > Both dataframes have two columns, one date column and another one with
> the
> > number of transits.
> >
> > I wanted to come up with a code so that I could fill in the dates that
> are
> > missing in one of the dataframes and replace the column of transits with
> > the value NA.
> >
> > I have tried several things but R obviously complains that the length of
> > the dataframes are different.
> >
> > How can I solve this?
> >
> > Any guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jeremiejuste at gmail.com  Tue Mar 28 07:28:54 2017
From: jeremiejuste at gmail.com (Jeremie Juste)
Date: Tue, 28 Mar 2017 07:28:54 +0200
Subject: [R] How to source a local R file to a remote session.
Message-ID: <87k27a9dgp.fsf@gmail.com>


Hello,

I don't know exactly where to turn to.
I'm using Emacs speak statistics and I can execute a codes on my local
computer to a remote session seemlessly.

But I've always wondered how to source a file on local computer to the
remote session? Till now I have copied the files to the remote host and
source from there but it complicates the version control process.


Any suggestions on this?



Best regards,

Jeremie


From peter.anthoni at kit.edu  Tue Mar 28 07:42:41 2017
From: peter.anthoni at kit.edu (Anthoni, Peter (IMK))
Date: Tue, 28 Mar 2017 05:42:41 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
Message-ID: <F71A1BBB-DE5C-4984-9A7F-D9168310389B@kit.edu>

Hi Paul,

match might help, but without a real data sample, it is hard to check if the following might work.

mm=match(df.col378[,"Date"],df.col362[,"Date"])
#mm will have NAs, where there is no matching date in df.col362
#and have the index of the match, where the two dates match
new.df=cbind(df.col378,"transits.col362"=df.col362[mm,"transits"])

cheers
Peter



> On 27 Mar 2017, at 22:09, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> I have one dataframe which contains 378 observations, and another one,
> containing 362 observations.
> 
> Both dataframes have two columns, one date column and another one with the
> number of transits.
> 
> I wanted to come up with a code so that I could fill in the dates that are
> missing in one of the dataframes and replace the column of transits with
> the value NA.
> 
> I have tried several things but R obviously complains that the length of
> the dataframes are different.
> 
> How can I solve this?
> 
> Any guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Mar 28 07:59:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Mar 2017 22:59:40 -0700
Subject: [R] How to source a local R file to a remote session.
In-Reply-To: <87k27a9dgp.fsf@gmail.com>
References: <87k27a9dgp.fsf@gmail.com>
Message-ID: <BAD52EF7-4D3C-4A7F-B527-E454B54BBCF9@dcn.davis.ca.us>

Use the "parallel" package? 
-- 
Sent from my phone. Please excuse my brevity.

On March 27, 2017 10:28:54 PM PDT, Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>Hello,
>
>I don't know exactly where to turn to.
>I'm using Emacs speak statistics and I can execute a codes on my local
>computer to a remote session seemlessly.
>
>But I've always wondered how to source a file on local computer to the
>remote session? Till now I have copied the files to the remote host and
>source from there but it complicates the version control process.
>
>
>Any suggestions on this?
>
>
>
>Best regards,
>
>Jeremie
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From soni.archit1989 at gmail.com  Tue Mar 28 09:50:47 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Tue, 28 Mar 2017 13:20:47 +0530
Subject: [R] Remove dependency of Image's physical location while sending
	email.
Message-ID: <CAJ7HxBwLD6G0ewB7N-7B6zU4spEOZ0XFaLLApSWCsRSDO1-mUA@mail.gmail.com>

Hello All,

I am using below code to send alerts from R. However, while testing the
emails to other users The image which is used as inline in email
configuration is not showing up as it is referencing to my temp folder.

Any ideas to resolve this ? I need to have embedded image irrespective of
the fact if the image gets deleted etc.

My Code:

(require(mailR))
y <- TriggerEmailR #my variable to trigger the script
#ImgSaveLocation - Local temp folder where image is saved.
bdy <- paste("<html><body> Hello, </br> </br> Avg. DIP has gone above 30
days <img src =" ,ImgSaveLocation, "> </br></br> Check the analysis:
</br></br> Note: This is a system generated email, please do not reply to
this email.</br></body></html>")
send.mail(from = "abc at abc.com",
          to = c("Recipient 1 <>" ),
          subject = "Alert",
          body = bdy,
          html = TRUE,
          inline = TRUE,
          smtp = list(host.name = "<<>>"),
          authenticate = FALSE,
          send = TRUE)

-- 
?Thanks in advance,
Archit

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Tue Mar 28 10:19:10 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 28 Mar 2017 09:19:10 +0100
Subject: [R] plot empty when drawing from custom function
Message-ID: <CAMk+s2SaMemtMtL7rqYWQo=eRrfSQizAReT=kD4SYaEPfpZ_Qg@mail.gmail.com>

Dear all,
I have set a function to draw some data using lattice; the drawing
works when I use lattice on its own, but if I put it into my custom
function, the final plot is empty, yet the terminal reports RStudioGD
        1
as normal.
What am I missing?
regards,
Luigi

>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
128, 39, 42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
94, 49, 33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
32.5, 59, 58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
90, 73, 84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
45, 76, 33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
212, 40, 68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
186, 297, 32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5, 54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
87, 59, 33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
26.72, 1.83, 9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev,
ll, ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)
  jpeg(filename = "DATA.jpg", width = 30, height = 20, units = "cm", res=300)
 useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )
  dev.off()



# inside a function
printer <- function(DATA) {
  jpeg(filename = "DATA_2.jpg", width = 30, height = 20, units = "cm", res=300)

  useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      DATA,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )
  dev.off()

}

printer(my.data)


From gabrielle.perron at mail.mcgill.ca  Mon Mar 27 17:23:07 2017
From: gabrielle.perron at mail.mcgill.ca (Gabrielle Perron)
Date: Mon, 27 Mar 2017 15:23:07 +0000
Subject: [R] R glm function ignores some predictor variables
Message-ID: <DM2PR0301MB12485BF88BC14A893C187E8FB4330@DM2PR0301MB1248.namprd03.prod.outlook.com>

Hi,


This is my first time using this mailing list. I have looked at the posting guide, but please do let me know if I should be doing something differently.


Here is my question, I apologize in advance for not being able to provide example data, I am using very large tables, and what I am trying to do works fine with simpler examples, so providing example data cannot help. It has always worked for me until now. So I am just trying to get your ideas on what might be the issue. But if there is any way I could provide more information, do let me know.


So, I have a vector corresponding to a response variable and a table of predictor variables. The response vector is numeric, the predictor variables (columns of the table) are in the binary format (0s and 1s).


I am running the glm function (multivariate linear regression) using the response vector and the table of predictors:


    fit <- glm(response ~ as.matrix(predictors), na.action=na.exclude)

    coeff <- as.vector(coef(summary(fit))[,4])[-1]


When I have been doing that in the past, I would extract the vector of regression coefficient to use it for further analysis.


The problem is that now the regression returns a vector of coefficients which is missing some values. Essentially some predictor variables are not attributed a coefficient at all by glm. But there are no error messages.


The summary of the model looks normal, but some predictor variables are missing like I mentioned. Most other predictors have assigned data (coefficient, pvalue, etc.).

About 30 predictors are missing from the model, over 200.


I have tried using different response variables (vectors), but I am getting the same issue, although the missing predictors vary depending on the response vector...


Any ideas on what might be going on? I think this can happen if some variables have 0 variance, but I have checked that. There are also no NA values and no missing values in the tables.


What could cause glm to ignore/remove some predictor variables?


Any suggestion is welcome!


Thank you,


Gabrielle







	[[alternative HTML version deleted]]


From jamilnaser79 at gmail.com  Mon Mar 27 20:26:16 2017
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Tue, 28 Mar 2017 00:26:16 +0600
Subject: [R] Managing axis labels
Message-ID: <CAJK=5Y=LyMwBe82kgV8OeOR66iouSshmUed8RbH5odNLKN8SJQ@mail.gmail.com>

Dear R-users,
I would like to ask probably a silly thing. For some reason, I need x-axis
and y-axis labels to be of different size. Here is a little example where I
want "?" to appear bigger than "Concentration". I have tried in the
following way, but it is not working.

?
x<-seq(1,10,1)
y<-seq(2,20,2)
plot(x, y, xlab=expression(vartheta), ylab="Concentration", cex.axis=1.5)

axis(1, cex.lab=3.0)
axis(2, cex.lab=2.0)

Any suggestion will be much appreciated.

Kind Regards,
Jamil.

	[[alternative HTML version deleted]]


From john9427 at gmail.com  Mon Mar 27 20:47:20 2017
From: john9427 at gmail.com (John Murtagh)
Date: Mon, 27 Mar 2017 19:47:20 +0100
Subject: [R] Arguments imply differing number of rows: 1, 0
Message-ID: <CA+abw2Wdvm7jSSgGX=6qJni_wdKSYRDu_yur8XxwdxEW5tCBJg@mail.gmail.com>

Hi All,

I am trying to generate a cdf plot by using ggplot and have looked at some
examples online. However when I try to replicate it I get the following
error:

"arguments imply differing number of rows: 1, 0"

I made a search and it seems from what I gather the nrows!=ncol and that
doesn't work for a data.frame. I am confused a bit as my MCtab dataframe is
similar.

If someone can explain what is going wrong or what i am
misunderstanding/doing wrong would be great? Code is below to replicate.
Thanks

library (triangle)
library(ggplot2)

n = 1000
W1 = rtriangle(n,330,400)
W2 = rtriangle(n,300,420)
SO = rtriangle(n,0.2,0.3)

MCtab <- data.frame(W1,W2,SO)

set.seed(1)
for (n in 1:n) {
  N0 <- (W1 + W2 + SO )}

set.seed(1)
for (n in 1:n) {
  N1 <- ((0.99*W1 + 0.99*W2 + 0.99*SO ))}

set.seed(1)
for (n in 1:n) {
  N2 <- ((0.98*W1 + 0.98*W2 + 0.98*SO))}

ggdata <- data.frame(N0,N1,N2)


ggdata <- ddply(ggdata, .(N0,N1,N2), transform, ecd=ecdf)


cdf <- ggplot(ggdata, aes(x=value)) +
stat_ecdf(aes(colour="blue","red","green"))
cdf

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Mon Mar 27 16:21:10 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 27 Mar 2017 22:21:10 +0800
Subject: [R] ! in expression(!abc) that produces !(abc).
Message-ID: <82e9f4af-a095-e0fa-3418-74fbd4f50f52@yeah.net>

Hi there,

I happened to find the expression(!abc) produces !(abc) when I used 
plotmath in a text annotation. Here is the mini-example.

 > plot(1, type = "n")
 > text(1,1, expression(!abc))

I don't find "!" in plotmath document.

By the way, how to reduce the space between two adjacent strings, 
something opposite to "~~". I mean, to get a space that is narrower than 
"~" but wider than "*".

Best,
Jinsong


From paulbernal07 at gmail.com  Mon Mar 27 22:49:16 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 27 Mar 2017 15:49:16 -0500
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
Message-ID: <CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>

Dear friend Mark,

Great suggestion! Thank you for replying.

I have two dataframes, dataframe1 and dataframe2.

dataframe1 has two columns, one with the dates in YYYY-MM-DD format and the
other colum with number of transits (all of which were set to NA values).
dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
(march 1 2017).

dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
format, and the other column with number of transits. dataframe2 starts
have the same start and end dates, however, dataframe2 has missing dates
between the start and end dates, so it has fewer observations.

dataframe1 has a total of 378 observations and dataframe2 has a  total of
362 observations.

I would like to come up with a code that could do the following:

Get the dates of dataframe1 that are missing in dataframe2 and add them as
records to dataframe 2 but with NA values.

<dataframe1                              <dataframe2

Date              Transits                  Date
Transits
1985-10-01    NA                         1985-10-01                15
1985-11-01    NA                         1986-01-01                 20
1985-12-01    NA                         1986-02-01                 5
1986-01-01    NA
1986-02-01    NA
2017-03-01    NA

I would like to fill in the missing dates in dataframe2, with NA as value
for the missing transits, so that I  could end up with a dataframe3 looking
as follows:

<dataframe3
Date                                Transits
1985-10-01                      15
1985-11-01                       NA
1985-12-01                       NA
1986-01-01                       20
1986-02-01                       5
2017-03-01                       NA

This is what I want to accomplish.

Thanks, beforehand for your help,

Best regards,

Paul


2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:

> Make some small dataframes of just a few rows that illustrate the problem
> structure. Make a third that has the result you want. You will get an
> answer very quickly. Without a self-contained reproducible problem, results
> vary.
>
> Mark
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
>
>
>
>
>
> > On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friends,
> >
> > I have one dataframe which contains 378 observations, and another one,
> > containing 362 observations.
> >
> > Both dataframes have two columns, one date column and another one with
> the
> > number of transits.
> >
> > I wanted to come up with a code so that I could fill in the dates that
> are
> > missing in one of the dataframes and replace the column of transits with
> > the value NA.
> >
> > I have tried several things but R obviously complains that the length of
> > the dataframes are different.
> >
> > How can I solve this?
> >
> > Any guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

	[[alternative HTML version deleted]]


From wjhaynes at wisc.edu  Mon Mar 27 22:44:42 2017
From: wjhaynes at wisc.edu (WILLIAM J HAYNES)
Date: Mon, 27 Mar 2017 15:44:42 -0500
Subject: [R] My installed R cannot run the X11 server
Message-ID: <791AFA1C-324E-47FB-A8A1-AEE8B28D87A9@wisc.edu>

HI,

I installed R on a Mac Book Pro running 10.10.5 and for some reason my X11.app is in a place that the R installation cannot find.  How can I set the environmental variables so the X11 server will run. I also have Xquartx.app but R does not seem to find that either.

Best Regards,
William ?John" Haynes





	[[alternative HTML version deleted]]


From calandra at rgzm.de  Tue Mar 28 11:14:45 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Tue, 28 Mar 2017 11:14:45 +0200
Subject: [R] Managing axis labels
In-Reply-To: <CAJK=5Y=LyMwBe82kgV8OeOR66iouSshmUed8RbH5odNLKN8SJQ@mail.gmail.com>
References: <CAJK=5Y=LyMwBe82kgV8OeOR66iouSshmUed8RbH5odNLKN8SJQ@mail.gmail.com>
Message-ID: <40b0dd50-9923-ffec-5d70-c35fa8374a06@rgzm.de>

Hi Jamil,

You first need to specify 'xaxt' and 'yaxt' in your plot() call, and 
then you can set the size of the labels with cex.axis:

plot(x, y, xlab=expression(vartheta), ylab="Concentration", xaxt="n", 
yaxt="n")axis(1, cex.axis=3) axis(2, cex.axis=2)

HTH,
Ivan

--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 27/03/2017 20:26, Naser Jamil wrote:
> Dear R-users,
> I would like to ask probably a silly thing. For some reason, I need x-axis
> and y-axis labels to be of different size. Here is a little example where I
> want "?" to appear bigger than "Concentration". I have tried in the
> following way, but it is not working.
>
> ?
> x<-seq(1,10,1)
> y<-seq(2,20,2)
> plot(x, y, xlab=expression(vartheta), ylab="Concentration", cex.axis=1.5)
>
> axis(1, cex.lab=3.0)
> axis(2, cex.lab=2.0)
>
> Any suggestion will be much appreciated.
>
> Kind Regards,
> Jamil.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Tue Mar 28 11:32:42 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 28 Mar 2017 11:32:42 +0200
Subject: [R] Arguments imply differing number of rows: 1, 0
In-Reply-To: <CA+abw2Wdvm7jSSgGX=6qJni_wdKSYRDu_yur8XxwdxEW5tCBJg@mail.gmail.com>
References: <CA+abw2Wdvm7jSSgGX=6qJni_wdKSYRDu_yur8XxwdxEW5tCBJg@mail.gmail.com>
Message-ID: <5e554f8a-951b-e9f0-5b05-5938a1f0d7f0@math.uni-giessen.de>

Hi, John,

see inline.

Am 27.03.2017 um 20:47 schrieb John Murtagh:
> Hi All,
>
> I am trying to generate a cdf plot by using ggplot and have looked at some
> examples online. However when I try to replicate it I get the following
> error:
>
> "arguments imply differing number of rows: 1, 0"
>
> I made a search and it seems from what I gather the nrows!=ncol and that
> doesn't work for a data.frame. I am confused a bit as my MCtab dataframe is
> similar.
>
> If someone can explain what is going wrong or what i am
> misunderstanding/doing wrong would be great? Code is below to replicate.
> Thanks
>
> library (triangle)
> library(ggplot2)
>
> n = 1000
> W1 = rtriangle(n,330,400)
> W2 = rtriangle(n,300,420)
> SO = rtriangle(n,0.2,0.3)
>
> MCtab <- data.frame(W1,W2,SO)
>
> set.seed(1)
> for (n in 1:n) {
>   N0 <- (W1 + W2 + SO )}
>
> set.seed(1)
> for (n in 1:n) {
>   N1 <- ((0.99*W1 + 0.99*W2 + 0.99*SO ))}
>
> set.seed(1)
> for (n in 1:n) {
>   N2 <- ((0.98*W1 + 0.98*W2 + 0.98*SO))}
>
> ggdata <- data.frame(N0,N1,N2)
>
>
> ggdata <- ddply(ggdata, .(N0,N1,N2), transform, ecd=ecdf)

I'm not familiar with ggplot, but I do not think that splitting your
ggdata by your numerical variables N1, N2 and N3 makes any sense ...

PS: I also think that your loops to create N1, N2 and N3 are pretty
nonsensical.

>
> cdf <- ggplot(ggdata, aes(x=value)) +
> stat_ecdf(aes(colour="blue","red","green"))
> cdf
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner


From Gerrit.Eichner at math.uni-giessen.de  Tue Mar 28 11:37:50 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 28 Mar 2017 11:37:50 +0200
Subject: [R] plot empty when drawing from custom function
In-Reply-To: <CAMk+s2SaMemtMtL7rqYWQo=eRrfSQizAReT=kD4SYaEPfpZ_Qg@mail.gmail.com>
References: <CAMk+s2SaMemtMtL7rqYWQo=eRrfSQizAReT=kD4SYaEPfpZ_Qg@mail.gmail.com>
Message-ID: <85bf453d-f7d7-e35c-4f6d-597d33bcb493@math.uni-giessen.de>

Hi, Luigi,

you are probably missing a call to print() around the call to
the latticeExtra plotting function useOuterStrips() you use
inside your function printer().

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 28.03.2017 um 10:19 schrieb Luigi Marongiu:
> Dear all,
> I have set a function to draw some data using lattice; the drawing
> works when I use lattice on its own, but if I put it into my custom
> function, the final plot is empty, yet the terminal reports RStudioGD
>         1
> as normal.
> What am I missing?
> regards,
> Luigi
>
>>>>
> cluster <- c(rep("A", 90), rep("B", 100))
> sample <- c(
>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
> "blank"), 5),
>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
> "cow-59", "blank"), 5)
> )
> type <- c(
>   rep(c("negative", "negative", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "blank"), 5),
>   rep(c("negative", "positive", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "positive", "positive", "blank"), 5)
> )
> target <- c(
> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
> )
> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
> 128, 39, 42, 47, 86, 100,
>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
> 94, 49, 33, 28, 31, 26, 23,
>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
> 32.5, 59, 58.5, 61, 62.5, 58,
>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
> 90, 73, 84, 95.5, 62, 82, 138,
>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
> 45, 76, 33, 37, 51, 44, 50, 54,
>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
> 212, 40, 68, 121, 80, 57,
>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
> 186, 297, 32, 184, 36, 45, 45, 44,
>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
> 79, 34, 74.5, 54, 49, 55, 56,
>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
> 87, 59, 33, 58, 51, 54,
>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
> 26.72, 1.83, 9.92, 4.59, 19, 7.96,
>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
> 11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
> 4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
> 72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
> 38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
> 7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
> 9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
> 64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
> 38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
> 34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
> 8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>                0.15, 1.28, 7.42, 71.15, 9.39)
> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
> 38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
> 3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
> 44.09,
>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
> 53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
> 39.57,
>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
> 7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
> 40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
> 45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
> 38.85,
>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
> 34.72, 42.58, -18.15, 39.61)
> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
> 46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
> 176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
> 37.97,
>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
> 47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
> 169.69,
>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
> 189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
> 174.3,
>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
> 172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
> 59.92,
>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
> 143.71,
>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
> 146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
> 127.25,
>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
> 132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
> 67.67,
>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
> 33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
> 176.6,
>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
> my.data <- data.frame(cluster, type, target, sample, average, stdev,
> ll, ul, stringsAsFactors = FALSE)
>
> library(lattice)
> library(latticeExtra)
>   jpeg(filename = "DATA.jpg", width = 30, height = 20, units = "cm", res=300)
>  useOuterStrips(
>     strip = strip.custom(par.strip.text = list(cex = 0.75)),
>     strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>     stripplot(
>       average ~ type|target+cluster,
>       panel = function(x,y,col,...)
>         panel.superpose(x,y,col=col,...),
>       panel.groups = function(x,y,col,...){
>         panel.stripplot(x,y,col=col,...)
>         m <- median(y)
>         panel.segments(x0 = x[1] -.5, y0 = m,
>                        x1 = x[1] +.5, y1 = m,
>                        col=col, lwd=2
>         )
>       },
>       my.data,
>       groups = type,
>       pch=1,
>       jitter.data = TRUE,
>       main = "Group-wise",
>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>       col = c("grey", "green", "red"),
>       par.settings = list(strip.background =
> list(col=c("paleturquoise", "grey"))),
>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>       key = list(
>         space = "top",
>         columns = 3,
>         text = list(c("Blank", "Negative", "Positive"), col="black"),
>         rectangles = list(col=c("grey", "green", "red"))
>       )
>     )
>   )
>   dev.off()
>
>
>
> # inside a function
> printer <- function(DATA) {
>   jpeg(filename = "DATA_2.jpg", width = 30, height = 20, units = "cm", res=300)
>
>   useOuterStrips(
>     strip = strip.custom(par.strip.text = list(cex = 0.75)),
>     strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>     stripplot(
>       average ~ type|target+cluster,
>       panel = function(x,y,col,...)
>         panel.superpose(x,y,col=col,...),
>       panel.groups = function(x,y,col,...){
>         panel.stripplot(x,y,col=col,...)
>         m <- median(y)
>         panel.segments(x0 = x[1] -.5, y0 = m,
>                        x1 = x[1] +.5, y1 = m,
>                        col=col, lwd=2
>         )
>       },
>       DATA,
>       groups = type,
>       pch=1,
>       jitter.data = TRUE,
>       main = "Group-wise",
>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>       col = c("grey", "green", "red"),
>       par.settings = list(strip.background =
> list(col=c("paleturquoise", "grey"))),
>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>       key = list(
>         space = "top",
>         columns = 3,
>         text = list(c("Blank", "Negative", "Positive"), col="black"),
>         rectangles = list(col=c("grey", "green", "red"))
>       )
>     )
>   )
>   dev.off()
>
> }
>
> printer(my.data)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Tue Mar 28 11:38:51 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Mar 2017 02:38:51 -0700
Subject: [R] plot empty when drawing from custom function
In-Reply-To: <CAMk+s2SaMemtMtL7rqYWQo=eRrfSQizAReT=kD4SYaEPfpZ_Qg@mail.gmail.com>
References: <CAMk+s2SaMemtMtL7rqYWQo=eRrfSQizAReT=kD4SYaEPfpZ_Qg@mail.gmail.com>
Message-ID: <CAGxFJbROetjtwi0QgubTzSGE48hhmYZ_KsgnKxcUdLaJmAL=fQ@mail.gmail.com>

FAQ 7.16

Bert



On Mar 28, 2017 1:20 AM, "Luigi Marongiu" <marongiu.luigi at gmail.com> wrote:

Dear all,
I have set a function to draw some data using lattice; the drawing
works when I use lattice on its own, but if I put it into my custom
function, the final plot is empty, yet the terminal reports RStudioGD
        1
as normal.
What am I missing?
regards,
Luigi

>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
128, 39, 42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
94, 49, 33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
32.5, 59, 58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
90, 73, 84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
45, 76, 33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
212, 40, 68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
186, 297, 32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5, 54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
87, 59, 33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
26.72, 1.83, 9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev,
ll, ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)
  jpeg(filename = "DATA.jpg", width = 30, height = 20, units = "cm",
res=300)
 useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )
  dev.off()



# inside a function
printer <- function(DATA) {
  jpeg(filename = "DATA_2.jpg", width = 30, height = 20, units = "cm",
res=300)

  useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      DATA,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )
  dev.off()

}

printer(my.data)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Mar 28 11:55:15 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 28 Mar 2017 20:55:15 +1100
Subject: [R] R glm function ignores some predictor variables
In-Reply-To: <DM2PR0301MB12485BF88BC14A893C187E8FB4330@DM2PR0301MB1248.namprd03.prod.outlook.com>
References: <DM2PR0301MB12485BF88BC14A893C187E8FB4330@DM2PR0301MB1248.namprd03.prod.outlook.com>
Message-ID: <CA+8X3fVZM3ceqFGxhb6QSaN-PafrDWXpDXv7=Mtk5tqcO+4j3g@mail.gmail.com>

Hi Gabrielle,
With that number of binary predictors it would be no surprise if some
were linear combinations of others.

Jim


On Tue, Mar 28, 2017 at 2:23 AM, Gabrielle Perron
<gabrielle.perron at mail.mcgill.ca> wrote:
> Hi,
>
>
> This is my first time using this mailing list. I have looked at the posting guide, but please do let me know if I should be doing something differently.
>
>
> Here is my question, I apologize in advance for not being able to provide example data, I am using very large tables, and what I am trying to do works fine with simpler examples, so providing example data cannot help. It has always worked for me until now. So I am just trying to get your ideas on what might be the issue. But if there is any way I could provide more information, do let me know.
>
>
> So, I have a vector corresponding to a response variable and a table of predictor variables. The response vector is numeric, the predictor variables (columns of the table) are in the binary format (0s and 1s).
>
>
> I am running the glm function (multivariate linear regression) using the response vector and the table of predictors:
>
>
>     fit <- glm(response ~ as.matrix(predictors), na.action=na.exclude)
>
>     coeff <- as.vector(coef(summary(fit))[,4])[-1]
>
>
> When I have been doing that in the past, I would extract the vector of regression coefficient to use it for further analysis.
>
>
> The problem is that now the regression returns a vector of coefficients which is missing some values. Essentially some predictor variables are not attributed a coefficient at all by glm. But there are no error messages.
>
>
> The summary of the model looks normal, but some predictor variables are missing like I mentioned. Most other predictors have assigned data (coefficient, pvalue, etc.).
>
> About 30 predictors are missing from the model, over 200.
>
>
> I have tried using different response variables (vectors), but I am getting the same issue, although the missing predictors vary depending on the response vector...
>
>
> Any ideas on what might be going on? I think this can happen if some variables have 0 variance, but I have checked that. There are also no NA values and no missing values in the tables.
>
>
> What could cause glm to ignore/remove some predictor variables?
>
>
> Any suggestion is welcome!
>
>
> Thank you,
>
>
> Gabrielle
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Mar 28 12:00:20 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 28 Mar 2017 12:00:20 +0200
Subject: [R] R glm function ignores some predictor variables
In-Reply-To: <DM2PR0301MB12485BF88BC14A893C187E8FB4330@DM2PR0301MB1248.namprd03.prod.outlook.com>
References: <DM2PR0301MB12485BF88BC14A893C187E8FB4330@DM2PR0301MB1248.namprd03.prod.outlook.com>
Message-ID: <A84575CD-9E0C-41DA-BE32-E748A011F9E5@gmail.com>


> On 27 Mar 2017, at 17:23 , Gabrielle Perron <gabrielle.perron at mail.mcgill.ca> wrote:
> 
> Hi,
> 
> 
> This is my first time using this mailing list. I have looked at the posting guide, but please do let me know if I should be doing something differently.


Avoid sending in HTML. It's not really bad here except for excessive inter-paragraph spacing, but the autoconversion to plain text can make posts almost unreadable.

---
It looks like some of your predictors are equal to linear combinations of other predictors. E.g., if you have dummies for mutually exclusive groups, they will sum to a vector of ones, which is already in the model for the intercept term, so one must be removed. (R has a better interface to this sort of thing, using factor variables, but that is another story.) With many predictors, this can happen in less obvious ways as well.

For plain multiple regression, I think most would use lm() and not glm(). It shouldn't make much of a difference, but some details may differ.

-pd

> Here is my question, I apologize in advance for not being able to provide example data, I am using very large tables, and what I am trying to do works fine with simpler examples, so providing example data cannot help. It has always worked for me until now. So I am just trying to get your ideas on what might be the issue. But if there is any way I could provide more information, do let me know.
> 
> 
> So, I have a vector corresponding to a response variable and a table of predictor variables. The response vector is numeric, the predictor variables (columns of the table) are in the binary format (0s and 1s).
> 
> 
> I am running the glm function (multivariate linear regression) using the response vector and the table of predictors:
> 
> 
>    fit <- glm(response ~ as.matrix(predictors), na.action=na.exclude)
> 
>    coeff <- as.vector(coef(summary(fit))[,4])[-1]
> 
> 
> When I have been doing that in the past, I would extract the vector of regression coefficient to use it for further analysis.
> 
> 
> The problem is that now the regression returns a vector of coefficients which is missing some values. Essentially some predictor variables are not attributed a coefficient at all by glm. But there are no error messages.
> 
> 
> The summary of the model looks normal, but some predictor variables are missing like I mentioned. Most other predictors have assigned data (coefficient, pvalue, etc.).
> 
> About 30 predictors are missing from the model, over 200.
> 
> 
> I have tried using different response variables (vectors), but I am getting the same issue, although the missing predictors vary depending on the response vector...
> 
> 
> Any ideas on what might be going on? I think this can happen if some variables have 0 variance, but I have checked that. There are also no NA values and no missing values in the tables.
> 
> 
> What could cause glm to ignore/remove some predictor variables?
> 
> 
> Any suggestion is welcome!
> 
> 
> Thank you,
> 
> 
> Gabrielle
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Mar 28 12:02:55 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 28 Mar 2017 12:02:55 +0200
Subject: [R] My installed R cannot run the X11 server
In-Reply-To: <791AFA1C-324E-47FB-A8A1-AEE8B28D87A9@wisc.edu>
References: <791AFA1C-324E-47FB-A8A1-AEE8B28D87A9@wisc.edu>
Message-ID: <DE4272EB-A07D-4F64-80BB-375EC26FAB57@gmail.com>

Did you follow XQuartz's advice of logging out and back in after the install?

-pd

> On 27 Mar 2017, at 22:44 , WILLIAM J HAYNES <wjhaynes at wisc.edu> wrote:
> 
> HI,
> 
> I installed R on a Mac Book Pro running 10.10.5 and for some reason my X11.app is in a place that the R installation cannot find.  How can I set the environmental variables so the X11 server will run. I also have Xquartx.app but R does not seem to find that either.
> 
> Best Regards,
> William ?John" Haynes
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From o.o.wolf at qmul.ac.uk  Tue Mar 28 12:05:39 2017
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Tue, 28 Mar 2017 11:05:39 +0100
Subject: [R] How to load fonts in text3d?
In-Reply-To: <2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>
References: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
	<2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>
Message-ID: <f427ca5f-3f21-90f4-2c53-9da413f0423c@qmul.ac.uk>

thanks, the fonts seem to be on:
> rglFonts()
$serif
[1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"

$sans
[1] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
[2] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
[3] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
[4] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"

$mono
[1] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
[2] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
[3] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
[4] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"

$symbol
[1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
[4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"

On 27/03/17 20:21, Duncan Murdoch wrote:
> On 27/03/2017 1:09 PM, olsen wrote:
>> I'm trying to run the example given in ?text3d as follows:
>>
>> library(rgl)
>> open3d()
>> famnum <- rep(1:4, 8)
>> family <- c("serif", "sans", "mono", "symbol")[famnum]
>> font <- rep(rep(1:4, each = 4), 2)
>> cex <- rep(1:2, each = 16)
>> text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
>>        color = "blue", family = family, font = font, cex = cex)
>>
>> This results in a couple of warning messages of the following kind:
>>
>> In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
>>   font family "serif" not found, using "bitmap"
>>
>> I would like to use another font instead of bitmap but it seems to
>> switchback to bitmap whatever argument I give as family e.g. 'family =
>> "FreeSans"'.
>> Wonder if this is a bug or I'm doing something wrong.
>>
>> This is on
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux 9 (stretch)
>> with the following rgl version loaded:
>> [1] rgl_0.96.0
> 
> What do you see if you run rglFonts()?  It should list the fonts you
> have installed.  On MacOS, I see
> 
>> rglFonts()
> $serif
> [1]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [2]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [3]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [4]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> 
> $sans
> [1]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
> 
> [2]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
> 
> [3]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
> 
> [4]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
> 
> 
> $mono
> [1]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
> 
> [2]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
> 
> [3]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
> 
> [4]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
> 
> 
> $symbol
> [1]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [2]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [3]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> [4]
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
> 
> 
> If you don't have Freetype installed on your system, you won't be able
> to use any of those.
> 
> Duncan Murdoch
> 

-- 
Our solar system is the cream of the crop
http://hasa-labs.org


From o.o.wolf at qmul.ac.uk  Tue Mar 28 12:39:45 2017
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Tue, 28 Mar 2017 11:39:45 +0100
Subject: [R] How to load fonts in text3d?
In-Reply-To: <f427ca5f-3f21-90f4-2c53-9da413f0423c@qmul.ac.uk>
References: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
	<2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>
	<f427ca5f-3f21-90f4-2c53-9da413f0423c@qmul.ac.uk>
Message-ID: <5cd310d5-e2d4-f237-9e65-b65a6d0e2f25@qmul.ac.uk>

I think I found the fly in the ointment, running the same text3d() lines
with 'useFreeType=TRUE' returns:
"FreeType not supported in this build"


On 28/03/17 11:05, olsen wrote:
> thanks, the fonts seem to be on:
>> rglFonts()
> $serif
> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> 
> $sans
> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
> 
> $mono
> [1] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
> [2] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
> [3] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
> [4] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
> 
> $symbol
> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
> 
> On 27/03/17 20:21, Duncan Murdoch wrote:
>> On 27/03/2017 1:09 PM, olsen wrote:
>>> I'm trying to run the example given in ?text3d as follows:
>>>
>>> library(rgl)
>>> open3d()
>>> famnum <- rep(1:4, 8)
>>> family <- c("serif", "sans", "mono", "symbol")[famnum]
>>> font <- rep(rep(1:4, each = 4), 2)
>>> cex <- rep(1:2, each = 16)
>>> text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
>>>        color = "blue", family = family, font = font, cex = cex)
>>>
>>> This results in a couple of warning messages of the following kind:
>>>
>>> In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
>>>   font family "serif" not found, using "bitmap"
>>>
>>> I would like to use another font instead of bitmap but it seems to
>>> switchback to bitmap whatever argument I give as family e.g. 'family =
>>> "FreeSans"'.
>>> Wonder if this is a bug or I'm doing something wrong.
>>>
>>> This is on
>>> R version 3.3.2 (2016-10-31)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Debian GNU/Linux 9 (stretch)
>>> with the following rgl version loaded:
>>> [1] rgl_0.96.0
>>
>> What do you see if you run rglFonts()?  It should list the fonts you
>> have installed.  On MacOS, I see
>>
>>> rglFonts()
>> $serif
>> [1]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [2]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [3]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [4]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>>
>> $sans
>> [1]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>
>> [2]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>
>> [3]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>
>> [4]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>
>>
>> $mono
>> [1]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>
>> [2]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>
>> [3]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>
>> [4]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>
>>
>> $symbol
>> [1]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [2]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [3]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>> [4]
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>
>>
>> If you don't have Freetype installed on your system, you won't be able
>> to use any of those.
>>
>> Duncan Murdoch
>>
>


From ulrik.stervbo at gmail.com  Tue Mar 28 11:22:09 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 28 Mar 2017 09:22:09 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
Message-ID: <CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>

Hi Paul,

does this do what you want?

exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
"1986-01-01"), Transits = c(NA, NA, NA, NA))
exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits = c(15,
20))

tmpdf <- subset(exdf1, !Date %in% exdf2$Date)

rbind(exdf2, tmpdf)

HTH,
Ulrik

On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com> wrote:

Dear friend Mark,

Great suggestion! Thank you for replying.

I have two dataframes, dataframe1 and dataframe2.

dataframe1 has two columns, one with the dates in YYYY-MM-DD format and the
other colum with number of transits (all of which were set to NA values).
dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
(march 1 2017).

dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
format, and the other column with number of transits. dataframe2 starts
have the same start and end dates, however, dataframe2 has missing dates
between the start and end dates, so it has fewer observations.

dataframe1 has a total of 378 observations and dataframe2 has a  total of
362 observations.

I would like to come up with a code that could do the following:

Get the dates of dataframe1 that are missing in dataframe2 and add them as
records to dataframe 2 but with NA values.

<dataframe1                              <dataframe2

Date              Transits                  Date
Transits
1985-10-01    NA                         1985-10-01                15
1985-11-01    NA                         1986-01-01                 20
1985-12-01    NA                         1986-02-01                 5
1986-01-01    NA
1986-02-01    NA
2017-03-01    NA

I would like to fill in the missing dates in dataframe2, with NA as value
for the missing transits, so that I  could end up with a dataframe3 looking
as follows:

<dataframe3
Date                                Transits
1985-10-01                      15
1985-11-01                       NA
1985-12-01                       NA
1986-01-01                       20
1986-02-01                       5
2017-03-01                       NA

This is what I want to accomplish.

Thanks, beforehand for your help,

Best regards,

Paul


2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:

> Make some small dataframes of just a few rows that illustrate the problem
> structure. Make a third that has the result you want. You will get an
> answer very quickly. Without a self-contained reproducible problem,
results
> vary.
>
> Mark
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
>
>
>
>
>
> > On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friends,
> >
> > I have one dataframe which contains 378 observations, and another one,
> > containing 362 observations.
> >
> > Both dataframes have two columns, one date column and another one with
> the
> > number of transits.
> >
> > I wanted to come up with a code so that I could fill in the dates that
> are
> > missing in one of the dataframes and replace the column of transits with
> > the value NA.
> >
> > I have tried several things but R obviously complains that the length of
> > the dataframes are different.
> >
> > How can I solve this?
> >
> > Any guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received
this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Mar 28 14:49:53 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Mar 2017 08:49:53 -0400
Subject: [R] How to load fonts in text3d?
In-Reply-To: <5cd310d5-e2d4-f237-9e65-b65a6d0e2f25@qmul.ac.uk>
References: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
	<2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>
	<f427ca5f-3f21-90f4-2c53-9da413f0423c@qmul.ac.uk>
	<5cd310d5-e2d4-f237-9e65-b65a6d0e2f25@qmul.ac.uk>
Message-ID: <41ddcf96-ccef-1005-29fe-4b8ea7723418@gmail.com>

On 28/03/2017 6:39 AM, olsen wrote:
> I think I found the fly in the ointment, running the same text3d() lines
> with 'useFreeType=TRUE' returns:
> "FreeType not supported in this build"

You need to install FreeType and FTGL.  I think this is how to do it on 
Trusty.  Don't know if it will work on your Ubuntu version.

sudo apt-get install libfreetype6-dev
sudo apt-get install libftgl-dev

and then reinstall rgl from within R using

install.packages("rgl", type="source")

Duncan Murdoch

>
>
> On 28/03/17 11:05, olsen wrote:
>> thanks, the fonts seem to be on:
>>> rglFonts()
>> $serif
>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>
>> $sans
>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>>
>> $mono
>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>>
>> $symbol
>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>
>> On 27/03/17 20:21, Duncan Murdoch wrote:
>>> On 27/03/2017 1:09 PM, olsen wrote:
>>>> I'm trying to run the example given in ?text3d as follows:
>>>>
>>>> library(rgl)
>>>> open3d()
>>>> famnum <- rep(1:4, 8)
>>>> family <- c("serif", "sans", "mono", "symbol")[famnum]
>>>> font <- rep(rep(1:4, each = 4), 2)
>>>> cex <- rep(1:2, each = 16)
>>>> text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
>>>>        color = "blue", family = family, font = font, cex = cex)
>>>>
>>>> This results in a couple of warning messages of the following kind:
>>>>
>>>> In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
>>>>   font family "serif" not found, using "bitmap"
>>>>
>>>> I would like to use another font instead of bitmap but it seems to
>>>> switchback to bitmap whatever argument I give as family e.g. 'family =
>>>> "FreeSans"'.
>>>> Wonder if this is a bug or I'm doing something wrong.
>>>>
>>>> This is on
>>>> R version 3.3.2 (2016-10-31)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Debian GNU/Linux 9 (stretch)
>>>> with the following rgl version loaded:
>>>> [1] rgl_0.96.0
>>>
>>> What do you see if you run rglFonts()?  It should list the fonts you
>>> have installed.  On MacOS, I see
>>>
>>>> rglFonts()
>>> $serif
>>> [1]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [2]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [3]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [4]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>>
>>> $sans
>>> [1]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>
>>> [2]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>
>>> [3]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>
>>> [4]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>
>>>
>>> $mono
>>> [1]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>
>>> [2]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>
>>> [3]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>
>>> [4]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>
>>>
>>> $symbol
>>> [1]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [2]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [3]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>> [4]
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>
>>>
>>> If you don't have Freetype installed on your system, you won't be able
>>> to use any of those.
>>>
>>> Duncan Murdoch
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From therneau at mayo.edu  Tue Mar 28 14:53:22 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 28 Mar 2017 07:53:22 -0500
Subject: [R] finding out if a method exists
Message-ID: <f40b15$641duq@ironport10.mayo.edu>

I'm thinking of adding a new "cmatrix" function/method to the survival package but before 
I do I'd like to find out if any other packages already use this function name.   The 
obvious method is to look at the NAMESPACE file for each package in CRAN and read the 
export list.

This is the kind of task for which someone, somewhere will have written routines.  I just 
don't know who or where.

Any hints?

Terry T.


From G.Maubach at weinwolf.de  Tue Mar 28 15:05:12 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 28 Mar 2017 15:05:12 +0200
Subject: [R] Way to Plot Multiple Variables and Change Color
Message-ID: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>

Hi All,

in my current project I have to plot a whole bunch of related variables 
(item batteries, e.g. How do you rate ... a) Accelaration, b) Horse Power, 
c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.

I need to present the results as stacked bar charts where the variables 
are columns and the percentages of the scales values (1 .. 4) are the 
chunks of the stacked bar for each variable. To do this I have transformed 
my data from wide to long and calculated the percentage for each variable 
and value. The code for this is as follows:

-- cut --

dfr <- structure(
  list(
    v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
               4, 4, 4, 1, 1, 3, 3, 4),
    v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
               4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
    v07_03 = c(3, 2, 2, 1, 4, 1,
               2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
    v07_04 = c(3, 1, 1,
               4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
    v07_05 = c(1,
               2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
    v07_06 = c(1,
               2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
    v07_07 = c(3,
               2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
    v07_08 = c(3,
               2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
    cased_id = structure(
      1:20,
      .Label = c(
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
        "13",
        "14",
        "15",
        "16",
        "17",
        "18",
        "19",
        "20"
      ),
      class = "factor"
    )
  ),
  .Names = c(
    "v07_01",
    "v07_02",
    "v07_03",
    "v07_04",
    "v07_05",
    "v07_06",
    "v07_07",
    "v07_08",
    "cased_id"
  ),
  row.names = c(NA, -20L),
  class = c("tbl_df", "tbl",
            "data.frame")
)

mdf <- melt(df)
d_result <- mdf  %>%
  dplyr::group_by(variable) %>%
  count(value)

ggplot(
  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(0,100))

-- cut --

Is there an easier way of doing this, i. e. a way without need to 
transform the data?

How can I change the colors for the data points 1 .. 4?

I tried

-- cut --

  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(0,100)) +
  scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))

-- cut -

but this does not work cause I am mixing continuous and descrete values.

How can I change the colors for the bars?

Kind regards

Georg


From murdoch.duncan at gmail.com  Tue Mar 28 15:11:46 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Mar 2017 09:11:46 -0400
Subject: [R] finding out if a method exists
In-Reply-To: <f40b15$641duq@ironport10.mayo.edu>
References: <f40b15$641duq@ironport10.mayo.edu>
Message-ID: <11f28ea7-4fc2-66c7-9804-6a2819eae558@gmail.com>

On 28/03/2017 8:53 AM, Therneau, Terry M., Ph.D. wrote:
> I'm thinking of adding a new "cmatrix" function/method to the survival package but before
> I do I'd like to find out if any other packages already use this function name.   The
> obvious method is to look at the NAMESPACE file for each package in CRAN and read the
> export list.
>
> This is the kind of task for which someone, somewhere will have written routines.  I just
> don't know who or where.
>
> Any hints?


Google is pretty good at finding documentation.  Since CRAN won't let 
you publish a package that exports a function without documenting it, 
that's probably good enough (though it will lead to a few false 
positives, e.g. multcomp::simtest has an argument named cmatrix).

I don't see a cmatrix function in a Google search.

I happen to have a copy of all CRAN packages on my system, and searching 
the NAMESPACE files finds no cmatrix, but it does find ibd::Cmatrix.  So 
I think you're safe.

Duncan Murdoch


From o.o.wolf at qmul.ac.uk  Tue Mar 28 15:19:47 2017
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Tue, 28 Mar 2017 14:19:47 +0100
Subject: [R] How to load fonts in text3d?
In-Reply-To: <41ddcf96-ccef-1005-29fe-4b8ea7723418@gmail.com>
References: <b2786156-624c-2d81-6793-678c5b4956a6@qmul.ac.uk>
	<2b258b02-5423-bbac-7b4f-3cc5349351a9@gmail.com>
	<f427ca5f-3f21-90f4-2c53-9da413f0423c@qmul.ac.uk>
	<5cd310d5-e2d4-f237-9e65-b65a6d0e2f25@qmul.ac.uk>
	<41ddcf96-ccef-1005-29fe-4b8ea7723418@gmail.com>
Message-ID: <f7554517-6a61-1ee0-5462-0f3e42833943@qmul.ac.uk>

Following these pointers given by Duncan Murdoch is the key to success,
at least on my system.

Many thanks!
olsen



On 28/03/17 13:49, Duncan Murdoch wrote:
> On 28/03/2017 6:39 AM, olsen wrote:
>> I think I found the fly in the ointment, running the same text3d() lines
>> with 'useFreeType=TRUE' returns:
>> "FreeType not supported in this build"
> 
> You need to install FreeType and FTGL.  I think this is how to do it on
> Trusty.  Don't know if it will work on your Ubuntu version.
> 
> sudo apt-get install libfreetype6-dev
> sudo apt-get install libftgl-dev
> 
> and then reinstall rgl from within R using
> 
> install.packages("rgl", type="source")
> 
> Duncan Murdoch
> 
>>
>>
>> On 28/03/17 11:05, olsen wrote:
>>> thanks, the fonts seem to be on:
>>>> rglFonts()
>>> $serif
>>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>>
>>> $sans
>>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSans.ttf"
>>>
>>> $mono
>>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeMono.ttf"
>>>
>>> $symbol
>>> [1] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [2] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [3] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>> [4] "/usr/lib/R/site-library/rgl/fonts/FreeSerif.ttf"
>>>
>>> On 27/03/17 20:21, Duncan Murdoch wrote:
>>>> On 27/03/2017 1:09 PM, olsen wrote:
>>>>> I'm trying to run the example given in ?text3d as follows:
>>>>>
>>>>> library(rgl)
>>>>> open3d()
>>>>> famnum <- rep(1:4, 8)
>>>>> family <- c("serif", "sans", "mono", "symbol")[famnum]
>>>>> font <- rep(rep(1:4, each = 4), 2)
>>>>> cex <- rep(1:2, each = 16)
>>>>> text3d(font, cex, famnum, text = paste(family, font), adj = 0.5,
>>>>>        color = "blue", family = family, font = font, cex = cex)
>>>>>
>>>>> This results in a couple of warning messages of the following kind:
>>>>>
>>>>> In rgl.texts(x = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,  ... :
>>>>>   font family "serif" not found, using "bitmap"
>>>>>
>>>>> I would like to use another font instead of bitmap but it seems to
>>>>> switchback to bitmap whatever argument I give as family e.g. 'family =
>>>>> "FreeSans"'.
>>>>> Wonder if this is a bug or I'm doing something wrong.
>>>>>
>>>>> This is on
>>>>> R version 3.3.2 (2016-10-31)
>>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>> Running under: Debian GNU/Linux 9 (stretch)
>>>>> with the following rgl version loaded:
>>>>> [1] rgl_0.96.0
>>>>
>>>> What do you see if you run rglFonts()?  It should list the fonts you
>>>> have installed.  On MacOS, I see
>>>>
>>>>> rglFonts()
>>>> $serif
>>>> [1]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [2]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [3]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [4]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>>
>>>> $sans
>>>> [1]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>>
>>>>
>>>> [2]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>>
>>>>
>>>> [3]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>>
>>>>
>>>> [4]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSans.ttf"
>>>>
>>>>
>>>>
>>>> $mono
>>>> [1]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>>
>>>>
>>>> [2]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>>
>>>>
>>>> [3]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>>
>>>>
>>>> [4]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeMono.ttf"
>>>>
>>>>
>>>>
>>>> $symbol
>>>> [1]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [2]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [3]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>> [4]
>>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgl/fonts/FreeSerif.ttf"
>>>>
>>>>
>>>>
>>>> If you don't have Freetype installed on your system, you won't be able
>>>> to use any of those.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From therneau at mayo.edu  Tue Mar 28 15:40:04 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 28 Mar 2017 08:40:04 -0500
Subject: [R] finding out if a method exists
In-Reply-To: <11f28ea7-4fc2-66c7-9804-6a2819eae558@gmail.com>
References: <f40b15$641duq@ironport10.mayo.edu>
	<11f28ea7-4fc2-66c7-9804-6a2819eae558@gmail.com>
Message-ID: <f40b15$641v93@ironport10.mayo.edu>

Thanks much Duncan.  Having someone do the work for me is even better than a function!
The cmatrix function will be to make contrast matrices BTW.

On 03/28/2017 08:11 AM, Duncan Murdoch wrote:
> On 28/03/2017 8:53 AM, Therneau, Terry M., Ph.D. wrote:
>> I'm thinking of adding a new "cmatrix" function/method to the survival package but before
>> I do I'd like to find out if any other packages already use this function name.   The
>> obvious method is to look at the NAMESPACE file for each package in CRAN and read the
>> export list.
>>
>> This is the kind of task for which someone, somewhere will have written routines.  I just
>> don't know who or where.
>>
>> Any hints?
>
>
> Google is pretty good at finding documentation.  Since CRAN won't let you publish a
> package that exports a function without documenting it, that's probably good enough
> (though it will lead to a few false positives, e.g. multcomp::simtest has an argument
> named cmatrix).
>
> I don't see a cmatrix function in a Google search.
>
> I happen to have a copy of all CRAN packages on my system, and searching the NAMESPACE
> files finds no cmatrix, but it does find ibd::Cmatrix.  So I think you're safe.
>
> Duncan Murdoch
>


From paulbernal07 at gmail.com  Tue Mar 28 16:12:10 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 28 Mar 2017 09:12:10 -0500
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
Message-ID: <CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>

Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and
valuable replies,

I am trying to reformat a date as follows:

Data<-read.csv("Container.csv")

DataFrame<-data.frame(Data)

DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")

#trying to put it in YYYY-MM-DD format

However, when I do this, I get a bunch of NAs for the dates.

I am providing a sample dataset as a reference.

Any help will be greatly appreciated,

Best regards,

Paul

2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:

> Hi Paul,
>
> Using the example provided by Ulrik, where
>
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?,
> "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,20)),
>
> You could also try the following function:
>
> for (i in 1:dim(exdf1)[1]){
>         if (!exdf1[i, 1] %in% exdf2[, 1]){
>                 exdf2 <- rbind(exdf2, exdf1[i,])
>         }
> }
>
> Basically, what the function does is that it runs through the number of
> rows in exdf1, and checks if the Date of the exdf1 row already exists in
> Date column of exdf2. If so, it skips it. Otherwise, it binds the row to
> df2.
>
> Hope this helps!
>
>
> Side note.: Computational efficiency wise, think Ulrik?s answer is
> probably better. Presentation wise, his is also much better.
>
> Regards,
> Bo Lin
>
> > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> >
> > Hi Paul,
> >
> > does this do what you want?
> >
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,
> > 20))
> >
> > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> >
> > rbind(exdf2, tmpdf)
> >
> > HTH,
> > Ulrik
> >
> > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friend Mark,
> >
> > Great suggestion! Thank you for replying.
> >
> > I have two dataframes, dataframe1 and dataframe2.
> >
> > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and
> the
> > other colum with number of transits (all of which were set to NA values).
> > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
> > (march 1 2017).
> >
> > dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
> > format, and the other column with number of transits. dataframe2 starts
> > have the same start and end dates, however, dataframe2 has missing dates
> > between the start and end dates, so it has fewer observations.
> >
> > dataframe1 has a total of 378 observations and dataframe2 has a  total of
> > 362 observations.
> >
> > I would like to come up with a code that could do the following:
> >
> > Get the dates of dataframe1 that are missing in dataframe2 and add them
> as
> > records to dataframe 2 but with NA values.
> >
> > <dataframe1                              <dataframe2
> >
> > Date              Transits                  Date
> > Transits
> > 1985-10-01    NA                         1985-10-01                15
> > 1985-11-01    NA                         1986-01-01                 20
> > 1985-12-01    NA                         1986-02-01                 5
> > 1986-01-01    NA
> > 1986-02-01    NA
> > 2017-03-01    NA
> >
> > I would like to fill in the missing dates in dataframe2, with NA as value
> > for the missing transits, so that I  could end up with a dataframe3
> looking
> > as follows:
> >
> > <dataframe3
> > Date                                Transits
> > 1985-10-01                      15
> > 1985-11-01                       NA
> > 1985-12-01                       NA
> > 1986-01-01                       20
> > 1986-02-01                       5
> > 2017-03-01                       NA
> >
> > This is what I want to accomplish.
> >
> > Thanks, beforehand for your help,
> >
> > Best regards,
> >
> > Paul
> >
> >
> > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
> >
> >> Make some small dataframes of just a few rows that illustrate the
> problem
> >> structure. Make a third that has the result you want. You will get an
> >> answer very quickly. Without a self-contained reproducible problem,
> > results
> >> vary.
> >>
> >> Mark
> >> R. Mark Sharp, Ph.D.
> >> msharp at TxBiomed.org
> >>
> >>
> >>
> >>
> >>
> >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I have one dataframe which contains 378 observations, and another one,
> >>> containing 362 observations.
> >>>
> >>> Both dataframes have two columns, one date column and another one with
> >> the
> >>> number of transits.
> >>>
> >>> I wanted to come up with a code so that I could fill in the dates that
> >> are
> >>> missing in one of the dataframes and replace the column of transits
> with
> >>> the value NA.
> >>>
> >>> I have tried several things but R obviously complains that the length
> of
> >>> the dataframes are different.
> >>>
> >>> How can I solve this?
> >>>
> >>> Any guidance will be greatly appreciated,
> >>>
> >>> Best regards,
> >>>
> >>> Paul
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> >> transmitted, may contain privileged and confidential information and is
> >> intended solely for the exclusive use of the individual or entity to
> whom
> >> it is addressed. If you are not the intended recipient, you are hereby
> >> notified that any review, dissemination, distribution or copying of this
> >> e-mail and/or attachments is strictly prohibited. If you have received
> > this
> >> e-mail in error, please immediately notify the sender stating that this
> >> transmission was misdirected; return the e-mail to sender; destroy all
> >> paper copies and delete all electronic copies from your system without
> >> disclosing its contents.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

From soeren.vogel at posteo.ch  Tue Mar 28 16:14:26 2017
From: soeren.vogel at posteo.ch (=?UTF-8?Q?S=c3=b6ren_Vogel?=)
Date: Tue, 28 Mar 2017 16:14:26 +0200
Subject: [R] How to apply calculations in "formula" to "data frame"
Message-ID: <62b0f0b6-99a4-6686-d552-bbb2b31a85a6@posteo.ch>

Hello

Ho can I apply a formula to a data frame?

library("formula.tools")
Data <- data.frame("v1" = rnorm(31), "v2" = runif(31), "v3" = sample(1:7, 31, repl=T), "v4" = rlnorm(31))
For1 <- as.formula(v1 ~ .^3)
Lhs <- Data[, formula.tools::lhs.vars(formula)]
Rhs <- apply_formula_to_data_frame_and_return_result(data, formula) # ???

Thank you,
S?ren


From paulbernal07 at gmail.com  Tue Mar 28 16:32:15 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 28 Mar 2017 09:32:15 -0500
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <2B9B3001-35DE-4AE0-B327-9A56964CF5C2@gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
	<CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
	<2B9B3001-35DE-4AE0-B327-9A56964CF5C2@gmail.com>
Message-ID: <CAMOcQfNO1WPvMrEUj5Syc43dd5-KyA8-hQfTogwR2vp_7HFKzw@mail.gmail.com>

Dear Bo Lin,

I tried doing
Containerdata$TransitDate<-as.Date(Containerdata$TransitDate, "%e-%B-%y")
but I keep getting NAs.

I also tried a solution that I saw in stackoverflow doing:

> lct<-Sys.getlocale("LC_TIME"); Sys.setlocale("LC_TIME", "C")
[1] "C"
>
> Sys.setlocale("LC_TIME", lct)
[1] "English_United States.1252"

but didn?t work.

Any other suggestion?

Thank you for your valuable help,

Regards,

Paul

2017-03-28 9:19 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:

> Hi Paul,
>
> The date format that you have supplied to R isn?t exactly right.
>
> Instead of supplying the format ?%Y-%m-%d?, it appears that the format of
> your data adheres to the ?%e-%B-%y? format. In this case, %e refers to Day,
> and takes an integer between (0 - 31), %B refers to the 3 letter
> abbreviated version of the Month, and %y refers to the Year provided in a
> ?2-integer? format.
>
> Hope this helps!
>
> Thank you.
>
> Regards,
> Bo Lin
>
> On 28 Mar 2017, at 10:12 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and
> valuable replies,
>
> I am trying to reformat a date as follows:
>
> Data<-read.csv("Container.csv")
>
> DataFrame<-data.frame(Data)
>
> DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")
>
> #trying to put it in YYYY-MM-DD format
>
> However, when I do this, I get a bunch of NAs for the dates.
>
> I am providing a sample dataset as a reference.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> 2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:
>
>> Hi Paul,
>>
>> Using the example provided by Ulrik, where
>>
>> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?,
>> "1986-01-01"), Transits = c(NA, NA, NA, NA))
>> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
>> c(15,20)),
>>
>> You could also try the following function:
>>
>> for (i in 1:dim(exdf1)[1]){
>>         if (!exdf1[i, 1] %in% exdf2[, 1]){
>>                 exdf2 <- rbind(exdf2, exdf1[i,])
>>         }
>> }
>>
>> Basically, what the function does is that it runs through the number of
>> rows in exdf1, and checks if the Date of the exdf1 row already exists in
>> Date column of exdf2. If so, it skips it. Otherwise, it binds the row to
>> df2.
>>
>> Hope this helps!
>>
>>
>> Side note.: Computational efficiency wise, think Ulrik?s answer is
>> probably better. Presentation wise, his is also much better.
>>
>> Regards,
>> Bo Lin
>>
>> > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>> wrote:
>> >
>> > Hi Paul,
>> >
>> > does this do what you want?
>> >
>> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
>> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
>> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
>> c(15,
>> > 20))
>> >
>> > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
>> >
>> > rbind(exdf2, tmpdf)
>> >
>> > HTH,
>> > Ulrik
>> >
>> > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> >
>> > Dear friend Mark,
>> >
>> > Great suggestion! Thank you for replying.
>> >
>> > I have two dataframes, dataframe1 and dataframe2.
>> >
>> > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and
>> the
>> > other colum with number of transits (all of which were set to NA
>> values).
>> > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in
>> 2017-03-01
>> > (march 1 2017).
>> >
>> > dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
>> > format, and the other column with number of transits. dataframe2 starts
>> > have the same start and end dates, however, dataframe2 has missing dates
>> > between the start and end dates, so it has fewer observations.
>> >
>> > dataframe1 has a total of 378 observations and dataframe2 has a  total
>> of
>> > 362 observations.
>> >
>> > I would like to come up with a code that could do the following:
>> >
>> > Get the dates of dataframe1 that are missing in dataframe2 and add them
>> as
>> > records to dataframe 2 but with NA values.
>> >
>> > <dataframe1                              <dataframe2
>> >
>> > Date              Transits                  Date
>> > Transits
>> > 1985-10-01    NA                         1985-10-01                15
>> > 1985-11-01    NA                         1986-01-01                 20
>> > 1985-12-01    NA                         1986-02-01                 5
>> > 1986-01-01    NA
>> > 1986-02-01    NA
>> > 2017-03-01    NA
>> >
>> > I would like to fill in the missing dates in dataframe2, with NA as
>> value
>> > for the missing transits, so that I  could end up with a dataframe3
>> looking
>> > as follows:
>> >
>> > <dataframe3
>> > Date                                Transits
>> > 1985-10-01                      15
>> > 1985-11-01                       NA
>> > 1985-12-01                       NA
>> > 1986-01-01                       20
>> > 1986-02-01                       5
>> > 2017-03-01                       NA
>> >
>> > This is what I want to accomplish.
>> >
>> > Thanks, beforehand for your help,
>> >
>> > Best regards,
>> >
>> > Paul
>> >
>> >
>> > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
>> >
>> >> Make some small dataframes of just a few rows that illustrate the
>> problem
>> >> structure. Make a third that has the result you want. You will get an
>> >> answer very quickly. Without a self-contained reproducible problem,
>> > results
>> >> vary.
>> >>
>> >> Mark
>> >> R. Mark Sharp, Ph.D.
>> >> msharp at TxBiomed.org
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> >>>
>> >>> Dear friends,
>> >>>
>> >>> I have one dataframe which contains 378 observations, and another one,
>> >>> containing 362 observations.
>> >>>
>> >>> Both dataframes have two columns, one date column and another one with
>> >> the
>> >>> number of transits.
>> >>>
>> >>> I wanted to come up with a code so that I could fill in the dates that
>> >> are
>> >>> missing in one of the dataframes and replace the column of transits
>> with
>> >>> the value NA.
>> >>>
>> >>> I have tried several things but R obviously complains that the length
>> of
>> >>> the dataframes are different.
>> >>>
>> >>> How can I solve this?
>> >>>
>> >>> Any guidance will be greatly appreciated,
>> >>>
>> >>> Best regards,
>> >>>
>> >>> Paul
>> >>>
>> >>> [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> <http://www.r-project.org/>
>> >> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>> >> transmitted, may contain privileged and confidential information and is
>> >> intended solely for the exclusive use of the individual or entity to
>> whom
>> >> it is addressed. If you are not the intended recipient, you are hereby
>> >> notified that any review, dissemination, distribution or copying of
>> this
>> >> e-mail and/or attachments is strictly prohibited. If you have received
>> > this
>> >> e-mail in error, please immediately notify the sender stating that this
>> >> transmission was misdirected; return the e-mail to sender; destroy all
>> >> paper copies and delete all electronic copies from your system without
>> >> disclosing its contents.
>> >>
>> >
>> >        [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
> <Container.csv>
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Mar 28 16:35:49 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 28 Mar 2017 14:35:49 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
	<CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
Message-ID: <8d1216826c684718860c45f81dc7d9f7@exch-2p-mbx-w2.ads.tamu.edu>

We did not get the file on the list. You need to rename your file to "Container.txt" or the mailing list will strip it from your message. The read.csv() function returns a data frame so Data is already a data frame. The command DataFrame<-data.frame(Data) just makes a copy of Data. 

Without the file, it is difficult to be certain, but your dates are probably stored as character strings and read.csv() will turn those to factors unless you tell it not to do that. Try

Data<-read.csv("Container.csv", stringsAsFactors=FALSE)
str(Data) # To see how the dates are stored

and see if things work better. If not, rename the file or use dput(Data) and copy the result into your email message. If the data is very long, use dput(head(Data, 15)).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: Tuesday, March 28, 2017 9:12 AM
To: Ng Bo Lin <ngbolin91 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Looping Through DataFrames with Differing Lenghts

Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and
valuable replies,

I am trying to reformat a date as follows:

Data<-read.csv("Container.csv")

DataFrame<-data.frame(Data)

DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")

#trying to put it in YYYY-MM-DD format

However, when I do this, I get a bunch of NAs for the dates.

I am providing a sample dataset as a reference.

Any help will be greatly appreciated,

Best regards,

Paul

2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:

> Hi Paul,
>
> Using the example provided by Ulrik, where
>
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?,
> "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,20)),
>
> You could also try the following function:
>
> for (i in 1:dim(exdf1)[1]){
>         if (!exdf1[i, 1] %in% exdf2[, 1]){
>                 exdf2 <- rbind(exdf2, exdf1[i,])
>         }
> }
>
> Basically, what the function does is that it runs through the number of
> rows in exdf1, and checks if the Date of the exdf1 row already exists in
> Date column of exdf2. If so, it skips it. Otherwise, it binds the row to
> df2.
>
> Hope this helps!
>
>
> Side note.: Computational efficiency wise, think Ulrik?s answer is
> probably better. Presentation wise, his is also much better.
>
> Regards,
> Bo Lin
>
> > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> >
> > Hi Paul,
> >
> > does this do what you want?
> >
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,
> > 20))
> >
> > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> >
> > rbind(exdf2, tmpdf)
> >
> > HTH,
> > Ulrik
> >
> > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friend Mark,
> >
> > Great suggestion! Thank you for replying.
> >
> > I have two dataframes, dataframe1 and dataframe2.
> >
> > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and
> the
> > other colum with number of transits (all of which were set to NA values).
> > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
> > (march 1 2017).
> >
> > dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
> > format, and the other column with number of transits. dataframe2 starts
> > have the same start and end dates, however, dataframe2 has missing dates
> > between the start and end dates, so it has fewer observations.
> >
> > dataframe1 has a total of 378 observations and dataframe2 has a  total of
> > 362 observations.
> >
> > I would like to come up with a code that could do the following:
> >
> > Get the dates of dataframe1 that are missing in dataframe2 and add them
> as
> > records to dataframe 2 but with NA values.
> >
> > <dataframe1                              <dataframe2
> >
> > Date              Transits                  Date
> > Transits
> > 1985-10-01    NA                         1985-10-01                15
> > 1985-11-01    NA                         1986-01-01                 20
> > 1985-12-01    NA                         1986-02-01                 5
> > 1986-01-01    NA
> > 1986-02-01    NA
> > 2017-03-01    NA
> >
> > I would like to fill in the missing dates in dataframe2, with NA as value
> > for the missing transits, so that I  could end up with a dataframe3
> looking
> > as follows:
> >
> > <dataframe3
> > Date                                Transits
> > 1985-10-01                      15
> > 1985-11-01                       NA
> > 1985-12-01                       NA
> > 1986-01-01                       20
> > 1986-02-01                       5
> > 2017-03-01                       NA
> >
> > This is what I want to accomplish.
> >
> > Thanks, beforehand for your help,
> >
> > Best regards,
> >
> > Paul
> >
> >
> > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
> >
> >> Make some small dataframes of just a few rows that illustrate the
> problem
> >> structure. Make a third that has the result you want. You will get an
> >> answer very quickly. Without a self-contained reproducible problem,
> > results
> >> vary.
> >>
> >> Mark
> >> R. Mark Sharp, Ph.D.
> >> msharp at TxBiomed.org
> >>
> >>
> >>
> >>
> >>
> >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I have one dataframe which contains 378 observations, and another one,
> >>> containing 362 observations.
> >>>
> >>> Both dataframes have two columns, one date column and another one with
> >> the
> >>> number of transits.
> >>>
> >>> I wanted to come up with a code so that I could fill in the dates that
> >> are
> >>> missing in one of the dataframes and replace the column of transits
> with
> >>> the value NA.
> >>>
> >>> I have tried several things but R obviously complains that the length
> of
> >>> the dataframes are different.
> >>>
> >>> How can I solve this?
> >>>
> >>> Any guidance will be greatly appreciated,
> >>>
> >>> Best regards,
> >>>
> >>> Paul
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> >> transmitted, may contain privileged and confidential information and is
> >> intended solely for the exclusive use of the individual or entity to
> whom
> >> it is addressed. If you are not the intended recipient, you are hereby
> >> notified that any review, dissemination, distribution or copying of this
> >> e-mail and/or attachments is strictly prohibited. If you have received
> > this
> >> e-mail in error, please immediately notify the sender stating that this
> >> transmission was misdirected; return the e-mail to sender; destroy all
> >> paper copies and delete all electronic copies from your system without
> >> disclosing its contents.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ulrik.stervbo at gmail.com  Tue Mar 28 16:35:29 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 28 Mar 2017 14:35:29 +0000
Subject: [R] Way to Plot Multiple Variables and Change Color
In-Reply-To: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
Message-ID: <CAKVAULP=CgUcSyxtXjJPwcvjC9n3rkinBuGer4UoW7FUuJuq5g@mail.gmail.com>

Hi Georg,

I am a little unsure of what you want to do, but maybe this:

mdf <- melt(dfr)
d_result <- mdf  %>%
  dplyr::group_by(variable, value) %>%
  summarise(n = n())

ggplot(
  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity")

HTH
Ulrik

On Tue, 28 Mar 2017 at 15:11 <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> in my current project I have to plot a whole bunch of related variables
> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse Power,
> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>
> I need to present the results as stacked bar charts where the variables
> are columns and the percentages of the scales values (1 .. 4) are the
> chunks of the stacked bar for each variable. To do this I have transformed
> my data from wide to long and calculated the percentage for each variable
> and value. The code for this is as follows:
>
> -- cut --
>
> dfr <- structure(
>   list(
>     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>                4, 4, 4, 1, 1, 3, 3, 4),
>     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>     v07_03 = c(3, 2, 2, 1, 4, 1,
>                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>     v07_04 = c(3, 1, 1,
>                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>     v07_05 = c(1,
>                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>     v07_06 = c(1,
>                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>     v07_07 = c(3,
>                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>     v07_08 = c(3,
>                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>     cased_id = structure(
>       1:20,
>       .Label = c(
>         "1",
>         "2",
>         "3",
>         "4",
>         "5",
>         "6",
>         "7",
>         "8",
>         "9",
>         "10",
>         "11",
>         "12",
>         "13",
>         "14",
>         "15",
>         "16",
>         "17",
>         "18",
>         "19",
>         "20"
>       ),
>       class = "factor"
>     )
>   ),
>   .Names = c(
>     "v07_01",
>     "v07_02",
>     "v07_03",
>     "v07_04",
>     "v07_05",
>     "v07_06",
>     "v07_07",
>     "v07_08",
>     "cased_id"
>   ),
>   row.names = c(NA, -20L),
>   class = c("tbl_df", "tbl",
>             "data.frame")
> )
>
> mdf <- melt(df)
> d_result <- mdf  %>%
>   dplyr::group_by(variable) %>%
>   count(value)
>
> ggplot(
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100))
>
> -- cut --
>
> Is there an easier way of doing this, i. e. a way without need to
> transform the data?
>
> How can I change the colors for the data points 1 .. 4?
>
> I tried
>
> -- cut --
>
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100)) +
>   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>
> -- cut -
>
> but this does not work cause I am mixing continuous and descrete values.
>
> How can I change the colors for the bars?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Mar 28 16:57:38 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 28 Mar 2017 16:57:38 +0200
Subject: [R] How to apply calculations in "formula" to "data frame"
In-Reply-To: <62b0f0b6-99a4-6686-d552-bbb2b31a85a6@posteo.ch>
References: <62b0f0b6-99a4-6686-d552-bbb2b31a85a6@posteo.ch>
Message-ID: <C4DC59F1-F6A0-4A4C-8FEB-29F22E0667B3@gmail.com>


> On 28 Mar 2017, at 16:14 , S?ren Vogel <soeren.vogel at posteo.ch> wrote:
> 
> Hello
> 
> Ho can I apply a formula to a data frame?


That would depend on whether the formula has any special interpretation.

If if is just an elementary expression, then it would be like 

eval(For1[[3]], Data, environment(For1))

but you are using "." to represent... what exactly?

One possibility is model.matrix(For1, Data)

but I'm not at all sure that that is what you want.

-pd

> 
> library("formula.tools")
> Data <- data.frame("v1" = rnorm(31), "v2" = runif(31), "v3" = sample(1:7, 31, repl=T), "v4" = rlnorm(31))
> For1 <- as.formula(v1 ~ .^3)
> Lhs <- Data[, formula.tools::lhs.vars(formula)]
> Rhs <- apply_formula_to_data_frame_and_return_result(data, formula) # ???
> 
> Thank you,
> S?ren
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tring at gvdnet.dk  Tue Mar 28 17:28:30 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Tue, 28 Mar 2017 17:28:30 +0200
Subject: [R] lubridate inserting unwelcome 9:21
Message-ID: <78b54b8c-b41e-4180-4248-7685467287a7@gvdnet.dk>

Dear friends - I have a series of times on successive days and would 
like to convert them into a successive common time for each person (ID) 
. Using lubridate and adding days(1) does as expected apart from 
changing time zone to LMT from UTC and suddenly adding 9:21 (H:M) to all 
times. Individual parts of the instructions seem OK. I'm sorry for the 
clumsy demonstration - but the error comes through.

R version 3.3.2 (2016-10-31) - Windows.

All best wishes
Troels

library(lubridate)

SSS <- structure(list(ID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L,
3L, 3L, 3L, 3L, 3L, 3L), Time = c(-1L, 0L, 1L, 2L, 3L, 4L, 5L,
6L, 7L, 8L, 9L, 10L, 11L, -1L, 0L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
8L, 9L, 10L, -1L, 0L, 1L, 2L, 3L, 4L, 5L), VT = structure(c(3L,
5L, 11L, 11L, 8L, 10L, 8L, 10L, 8L, 7L, 11L, 5L, 5L, 12L, 5L,
7L, 7L, 5L, 5L, 8L, 10L, 8L, 7L, 7L, 7L, 2L, 8L, 7L, 8L, 7L,
10L, 8L), .Label = c("02:00", "03:00", "04:00", "05:00", "06:00",
"09:00", "10:00", "11:00", "11:30", "12:00", "13:00", "14:00",
"15:00", "17:00", "18:00", "21:30", "23:00"), class = "factor")), .Names 
= c("ID",
"Time", "VT"), row.names = c(NA, 32L), class = "data.frame")

SSS$VT  <- parse_date_time(SSS$VT,"HM")
str(SSS$VT)

TT <- list()
for(i in 1:3) {
#i <- 1
BS <- subset(SSS,ID==i)
TT[[i]] <- c(BS$VT + (1:length(BS[,1])-1)*days(1))
}
BS$VT
(1:length(BS[,1])-1)*days(1)

#these appear as expected but

TT

#appears disturbed 9:21 inserted - LMT time zone - how comes?


From rmh at temple.edu  Tue Mar 28 17:41:24 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 28 Mar 2017 08:41:24 -0700
Subject: [R] Way to Plot Multiple Variables and Change Color
In-Reply-To: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
Message-ID: <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>

I think you are looking for the likert function in the HH package.
>From ?likert


Diverging stacked barcharts for Likert, semantic differential, rating
scale data, and population pyramids.


This will get you started.  Much more fine control is available.  See
the examples and demo.

## install.packages("HH") ## if not yet on your system.

library(HH)

AA <- dfr[,-9]

labels <- sort(unique(as.vector(data.matrix(AA))))
result.template <- integer(length(labels))
names(result.template) <- labels

BB <- apply(AA, 2, function(x, result=result.template) {
  tx <- table(x)
  result[names(tx)] <- tx
  result
}
)

BB

likert(t(BB), ReferenceZero=0, horizontal=FALSE)


On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I have to plot a whole bunch of related variables
> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse Power,
> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>
> I need to present the results as stacked bar charts where the variables
> are columns and the percentages of the scales values (1 .. 4) are the
> chunks of the stacked bar for each variable. To do this I have transformed
> my data from wide to long and calculated the percentage for each variable
> and value. The code for this is as follows:
>
> -- cut --
>
> dfr <- structure(
>   list(
>     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>                4, 4, 4, 1, 1, 3, 3, 4),
>     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>     v07_03 = c(3, 2, 2, 1, 4, 1,
>                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>     v07_04 = c(3, 1, 1,
>                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>     v07_05 = c(1,
>                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>     v07_06 = c(1,
>                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>     v07_07 = c(3,
>                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>     v07_08 = c(3,
>                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>     cased_id = structure(
>       1:20,
>       .Label = c(
>         "1",
>         "2",
>         "3",
>         "4",
>         "5",
>         "6",
>         "7",
>         "8",
>         "9",
>         "10",
>         "11",
>         "12",
>         "13",
>         "14",
>         "15",
>         "16",
>         "17",
>         "18",
>         "19",
>         "20"
>       ),
>       class = "factor"
>     )
>   ),
>   .Names = c(
>     "v07_01",
>     "v07_02",
>     "v07_03",
>     "v07_04",
>     "v07_05",
>     "v07_06",
>     "v07_07",
>     "v07_08",
>     "cased_id"
>   ),
>   row.names = c(NA, -20L),
>   class = c("tbl_df", "tbl",
>             "data.frame")
> )
>
> mdf <- melt(df)
> d_result <- mdf  %>%
>   dplyr::group_by(variable) %>%
>   count(value)
>
> ggplot(
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100))
>
> -- cut --
>
> Is there an easier way of doing this, i. e. a way without need to
> transform the data?
>
> How can I change the colors for the data points 1 .. 4?
>
> I tried
>
> -- cut --
>
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100)) +
>   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>
> -- cut -
>
> but this does not work cause I am mixing continuous and descrete values.
>
> How can I change the colors for the bars?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue Mar 28 17:56:41 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 28 Mar 2017 17:56:41 +0200
Subject: [R] Antwort: Re:  Way to Plot Multiple Variables and Change Color
In-Reply-To: <CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
	<CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
Message-ID: <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>

Hi Richard,

many thanks for your reply.

Your solution is not exactly what I was looking for. I would like to know 
how I can change the colors of the stacked bars in my plot and not use the 
default values. How can this be done?

Kind regards

Georg




Von:    "Richard M. Heiberger" <rmh at temple.edu>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  28.03.2017 17:40
Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color



I think you are looking for the likert function in the HH package.
>From ?likert


Diverging stacked barcharts for Likert, semantic differential, rating
scale data, and population pyramids.


This will get you started.  Much more fine control is available.  See
the examples and demo.

## install.packages("HH") ## if not yet on your system.

library(HH)

AA <- dfr[,-9]

labels <- sort(unique(as.vector(data.matrix(AA))))
result.template <- integer(length(labels))
names(result.template) <- labels

BB <- apply(AA, 2, function(x, result=result.template) {
  tx <- table(x)
  result[names(tx)] <- tx
  result
}
)

BB

likert(t(BB), ReferenceZero=0, horizontal=FALSE)


On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> in my current project I have to plot a whole bunch of related variables
> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse 
Power,
> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>
> I need to present the results as stacked bar charts where the variables
> are columns and the percentages of the scales values (1 .. 4) are the
> chunks of the stacked bar for each variable. To do this I have 
transformed
> my data from wide to long and calculated the percentage for each 
variable
> and value. The code for this is as follows:
>
> -- cut --
>
> dfr <- structure(
>   list(
>     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>                4, 4, 4, 1, 1, 3, 3, 4),
>     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>     v07_03 = c(3, 2, 2, 1, 4, 1,
>                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>     v07_04 = c(3, 1, 1,
>                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>     v07_05 = c(1,
>                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>     v07_06 = c(1,
>                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>     v07_07 = c(3,
>                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>     v07_08 = c(3,
>                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>     cased_id = structure(
>       1:20,
>       .Label = c(
>         "1",
>         "2",
>         "3",
>         "4",
>         "5",
>         "6",
>         "7",
>         "8",
>         "9",
>         "10",
>         "11",
>         "12",
>         "13",
>         "14",
>         "15",
>         "16",
>         "17",
>         "18",
>         "19",
>         "20"
>       ),
>       class = "factor"
>     )
>   ),
>   .Names = c(
>     "v07_01",
>     "v07_02",
>     "v07_03",
>     "v07_04",
>     "v07_05",
>     "v07_06",
>     "v07_07",
>     "v07_08",
>     "cased_id"
>   ),
>   row.names = c(NA, -20L),
>   class = c("tbl_df", "tbl",
>             "data.frame")
> )
>
> mdf <- melt(df)
> d_result <- mdf  %>%
>   dplyr::group_by(variable) %>%
>   count(value)
>
> ggplot(
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100))
>
> -- cut --
>
> Is there an easier way of doing this, i. e. a way without need to
> transform the data?
>
> How can I change the colors for the data points 1 .. 4?
>
> I tried
>
> -- cut --
>
>   d_result,
>   aes(variable, y = n, fill = value)) +
>   geom_bar(stat = "identity") +
>   coord_cartesian(ylim = c(0,100)) +
>   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>
> -- cut -
>
> but this does not work cause I am mixing continuous and descrete values.
>
> How can I change the colors for the bars?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Mar 28 18:04:47 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 28 Mar 2017 09:04:47 -0700
Subject: [R] Way to Plot Multiple Variables and Change Color
In-Reply-To: <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
	<CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
	<OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
Message-ID: <CAGx1TMC740VDZJpYR4RxDNVkO=T+FBMaw0kBKnN8Bg=aJB8Ang@mail.gmail.com>

The colors can be specified with the standard lattice "col=" argument.

likert(t(BB), ReferenceZero=0, horizontal=FALSE,
       col=RColorBrewer::brewer.pal(4, "Blues"))

Most other customizations you might need are also possible.  Many examples
are in the examples section of ?likert and in the demo.

Rich


On Tue, Mar 28, 2017 at 8:56 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Richard,
>
> many thanks for your reply.
>
> Your solution is not exactly what I was looking for. I would like to know
> how I can change the colors of the stacked bars in my plot and not use the
> default values. How can this be done?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    "Richard M. Heiberger" <rmh at temple.edu>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  28.03.2017 17:40
> Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color
>
>
>
> I think you are looking for the likert function in the HH package.
> From ?likert
>
>
> Diverging stacked barcharts for Likert, semantic differential, rating
> scale data, and population pyramids.
>
>
> This will get you started.  Much more fine control is available.  See
> the examples and demo.
>
> ## install.packages("HH") ## if not yet on your system.
>
> library(HH)
>
> AA <- dfr[,-9]
>
> labels <- sort(unique(as.vector(data.matrix(AA))))
> result.template <- integer(length(labels))
> names(result.template) <- labels
>
> BB <- apply(AA, 2, function(x, result=result.template) {
>   tx <- table(x)
>   result[names(tx)] <- tx
>   result
> }
> )
>
> BB
>
> likert(t(BB), ReferenceZero=0, horizontal=FALSE)
>
>
> On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> in my current project I have to plot a whole bunch of related variables
>> (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
> Power,
>> c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
>>
>> I need to present the results as stacked bar charts where the variables
>> are columns and the percentages of the scales values (1 .. 4) are the
>> chunks of the stacked bar for each variable. To do this I have
> transformed
>> my data from wide to long and calculated the percentage for each
> variable
>> and value. The code for this is as follows:
>>
>> -- cut --
>>
>> dfr <- structure(
>>   list(
>>     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
>>                4, 4, 4, 1, 1, 3, 3, 4),
>>     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
>>                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
>>     v07_03 = c(3, 2, 2, 1, 4, 1,
>>                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
>>     v07_04 = c(3, 1, 1,
>>                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
>>     v07_05 = c(1,
>>                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
>>     v07_06 = c(1,
>>                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
>>     v07_07 = c(3,
>>                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
>>     v07_08 = c(3,
>>                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
>>     cased_id = structure(
>>       1:20,
>>       .Label = c(
>>         "1",
>>         "2",
>>         "3",
>>         "4",
>>         "5",
>>         "6",
>>         "7",
>>         "8",
>>         "9",
>>         "10",
>>         "11",
>>         "12",
>>         "13",
>>         "14",
>>         "15",
>>         "16",
>>         "17",
>>         "18",
>>         "19",
>>         "20"
>>       ),
>>       class = "factor"
>>     )
>>   ),
>>   .Names = c(
>>     "v07_01",
>>     "v07_02",
>>     "v07_03",
>>     "v07_04",
>>     "v07_05",
>>     "v07_06",
>>     "v07_07",
>>     "v07_08",
>>     "cased_id"
>>   ),
>>   row.names = c(NA, -20L),
>>   class = c("tbl_df", "tbl",
>>             "data.frame")
>> )
>>
>> mdf <- melt(df)
>> d_result <- mdf  %>%
>>   dplyr::group_by(variable) %>%
>>   count(value)
>>
>> ggplot(
>>   d_result,
>>   aes(variable, y = n, fill = value)) +
>>   geom_bar(stat = "identity") +
>>   coord_cartesian(ylim = c(0,100))
>>
>> -- cut --
>>
>> Is there an easier way of doing this, i. e. a way without need to
>> transform the data?
>>
>> How can I change the colors for the data points 1 .. 4?
>>
>> I tried
>>
>> -- cut --
>>
>>   d_result,
>>   aes(variable, y = n, fill = value)) +
>>   geom_bar(stat = "identity") +
>>   coord_cartesian(ylim = c(0,100)) +
>>   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
>>
>> -- cut -
>>
>> but this does not work cause I am mixing continuous and descrete values.
>>
>> How can I change the colors for the bars?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From G.Maubach at weinwolf.de  Tue Mar 28 18:07:24 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 28 Mar 2017 18:07:24 +0200
Subject: [R] Antwort: Re:  Way to Plot Multiple Variables and Change Color
In-Reply-To: <CAKVAULP=CgUcSyxtXjJPwcvjC9n3rkinBuGer4UoW7FUuJuq5g@mail.gmail.com>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
	<CAKVAULP=CgUcSyxtXjJPwcvjC9n3rkinBuGer4UoW7FUuJuq5g@mail.gmail.com>
Message-ID: <OF5D16DF67.0D7EC9A5-ONC12580F1.00584B3B-C12580F1.00589197@lotus.hawesko.de>

Hi Ulrik,

your answer is very valuable to me. If you do not know what I do, others 
don't either. So I should definitely adapt my code.

The result of your code and my code is the same. Thus, I use your code 
cause it is better readable.

My other question was how I can change the color palette for the stacked 
bars. Could you give me a hint where I need to look in ggplot2 
documentation?

Kind regards

Georg




Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  28.03.2017 16:35
Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color



Hi Georg,

I am a little unsure of what you want to do, but maybe this:

mdf <- melt(dfr)
d_result <- mdf  %>%
  dplyr::group_by(variable, value) %>%
  summarise(n = n())

ggplot(
  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity") 

HTH
Ulrik

On Tue, 28 Mar 2017 at 15:11 <G.Maubach at weinwolf.de> wrote:
Hi All,

in my current project I have to plot a whole bunch of related variables
(item batteries, e.g. How do you rate ... a) Accelaration, b) Horse Power,
c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.

I need to present the results as stacked bar charts where the variables
are columns and the percentages of the scales values (1 .. 4) are the
chunks of the stacked bar for each variable. To do this I have transformed
my data from wide to long and calculated the percentage for each variable
and value. The code for this is as follows:

-- cut --

dfr <- structure(
  list(
    v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
               4, 4, 4, 1, 1, 3, 3, 4),
    v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
               4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
    v07_03 = c(3, 2, 2, 1, 4, 1,
               2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
    v07_04 = c(3, 1, 1,
               4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
    v07_05 = c(1,
               2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
    v07_06 = c(1,
               2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
    v07_07 = c(3,
               2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
    v07_08 = c(3,
               2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
    cased_id = structure(
      1:20,
      .Label = c(
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
        "13",
        "14",
        "15",
        "16",
        "17",
        "18",
        "19",
        "20"
      ),
      class = "factor"
    )
  ),
  .Names = c(
    "v07_01",
    "v07_02",
    "v07_03",
    "v07_04",
    "v07_05",
    "v07_06",
    "v07_07",
    "v07_08",
    "cased_id"
  ),
  row.names = c(NA, -20L),
  class = c("tbl_df", "tbl",
            "data.frame")
)

mdf <- melt(df)
d_result <- mdf  %>%
  dplyr::group_by(variable) %>%
  count(value)

ggplot(
  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(0,100))

-- cut --

Is there an easier way of doing this, i. e. a way without need to
transform the data?

How can I change the colors for the data points 1 .. 4?

I tried

-- cut --

  d_result,
  aes(variable, y = n, fill = value)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(0,100)) +
  scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))

-- cut -

but this does not work cause I am mixing continuous and descrete values.

How can I change the colors for the bars?

Kind regards

Georg

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ngbolin91 at gmail.com  Tue Mar 28 15:15:32 2017
From: ngbolin91 at gmail.com (Ng Bo Lin)
Date: Tue, 28 Mar 2017 21:15:32 +0800
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
Message-ID: <4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>

Hi Paul,

Using the example provided by Ulrik, where

> exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?, "1986-01-01"), Transits = c(NA, NA, NA, NA))
> exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits = c(15,20)),

You could also try the following function:

for (i in 1:dim(exdf1)[1]){
        if (!exdf1[i, 1] %in% exdf2[, 1]){
                exdf2 <- rbind(exdf2, exdf1[i,])
        }
}

Basically, what the function does is that it runs through the number of rows in exdf1, and checks if the Date of the exdf1 row already exists in Date column of exdf2. If so, it skips it. Otherwise, it binds the row to df2.

Hope this helps!


Side note.: Computational efficiency wise, think Ulrik?s answer is probably better. Presentation wise, his is also much better.

Regards,
Bo Lin

> On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Paul,
> 
> does this do what you want?
> 
> exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> "1986-01-01"), Transits = c(NA, NA, NA, NA))
> exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits = c(15,
> 20))
> 
> tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> 
> rbind(exdf2, tmpdf)
> 
> HTH,
> Ulrik
> 
> On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friend Mark,
> 
> Great suggestion! Thank you for replying.
> 
> I have two dataframes, dataframe1 and dataframe2.
> 
> dataframe1 has two columns, one with the dates in YYYY-MM-DD format and the
> other colum with number of transits (all of which were set to NA values).
> dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
> (march 1 2017).
> 
> dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
> format, and the other column with number of transits. dataframe2 starts
> have the same start and end dates, however, dataframe2 has missing dates
> between the start and end dates, so it has fewer observations.
> 
> dataframe1 has a total of 378 observations and dataframe2 has a  total of
> 362 observations.
> 
> I would like to come up with a code that could do the following:
> 
> Get the dates of dataframe1 that are missing in dataframe2 and add them as
> records to dataframe 2 but with NA values.
> 
> <dataframe1                              <dataframe2
> 
> Date              Transits                  Date
> Transits
> 1985-10-01    NA                         1985-10-01                15
> 1985-11-01    NA                         1986-01-01                 20
> 1985-12-01    NA                         1986-02-01                 5
> 1986-01-01    NA
> 1986-02-01    NA
> 2017-03-01    NA
> 
> I would like to fill in the missing dates in dataframe2, with NA as value
> for the missing transits, so that I  could end up with a dataframe3 looking
> as follows:
> 
> <dataframe3
> Date                                Transits
> 1985-10-01                      15
> 1985-11-01                       NA
> 1985-12-01                       NA
> 1986-01-01                       20
> 1986-02-01                       5
> 2017-03-01                       NA
> 
> This is what I want to accomplish.
> 
> Thanks, beforehand for your help,
> 
> Best regards,
> 
> Paul
> 
> 
> 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
> 
>> Make some small dataframes of just a few rows that illustrate the problem
>> structure. Make a third that has the result you want. You will get an
>> answer very quickly. Without a self-contained reproducible problem,
> results
>> vary.
>> 
>> Mark
>> R. Mark Sharp, Ph.D.
>> msharp at TxBiomed.org
>> 
>> 
>> 
>> 
>> 
>>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>>> 
>>> Dear friends,
>>> 
>>> I have one dataframe which contains 378 observations, and another one,
>>> containing 362 observations.
>>> 
>>> Both dataframes have two columns, one date column and another one with
>> the
>>> number of transits.
>>> 
>>> I wanted to come up with a code so that I could fill in the dates that
>> are
>>> missing in one of the dataframes and replace the column of transits with
>>> the value NA.
>>> 
>>> I have tried several things but R obviously complains that the length of
>>> the dataframes are different.
>>> 
>>> How can I solve this?
>>> 
>>> Any guidance will be greatly appreciated,
>>> 
>>> Best regards,
>>> 
>>> Paul
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>> transmitted, may contain privileged and confidential information and is
>> intended solely for the exclusive use of the individual or entity to whom
>> it is addressed. If you are not the intended recipient, you are hereby
>> notified that any review, dissemination, distribution or copying of this
>> e-mail and/or attachments is strictly prohibited. If you have received
> this
>> e-mail in error, please immediately notify the sender stating that this
>> transmission was misdirected; return the e-mail to sender; destroy all
>> paper copies and delete all electronic copies from your system without
>> disclosing its contents.
>> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ngbolin91 at gmail.com  Tue Mar 28 16:19:15 2017
From: ngbolin91 at gmail.com (Ng Bo Lin)
Date: Tue, 28 Mar 2017 22:19:15 +0800
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
	<CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
Message-ID: <2B9B3001-35DE-4AE0-B327-9A56964CF5C2@gmail.com>

Hi Paul,

The date format that you have supplied to R isn?t exactly right.

Instead of supplying the format ?%Y-%m-%d?, it appears that the format of your data adheres to the ?%e-%B-%y? format. In this case, %e refers to Day, and takes an integer between (0 - 31), %B refers to the 3 letter abbreviated version of the Month, and %y refers to the Year provided in a ?2-integer? format.

Hope this helps!

Thank you.

Regards,
Bo Lin
> On 28 Mar 2017, at 10:12 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and valuable replies,
> 
> I am trying to reformat a date as follows:
> 
> Data<-read.csv("Container.csv")
> 
> DataFrame<-data.frame(Data)
> 
> DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")
> 
> #trying to put it in YYYY-MM-DD format
> 
> However, when I do this, I get a bunch of NAs for the dates.
> 
> I am providing a sample dataset as a reference.
> 
> Any help will be greatly appreciated,
> 
> Best regards,
> 
> Paul
> 
> 2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com <mailto:ngbolin91 at gmail.com>>:
> Hi Paul,
> 
> Using the example provided by Ulrik, where
> 
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?, "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits = c(15,20)),
> 
> You could also try the following function:
> 
> for (i in 1:dim(exdf1)[1]){
>         if (!exdf1[i, 1] %in% exdf2[, 1]){
>                 exdf2 <- rbind(exdf2, exdf1[i,])
>         }
> }
> 
> Basically, what the function does is that it runs through the number of rows in exdf1, and checks if the Date of the exdf1 row already exists in Date column of exdf2. If so, it skips it. Otherwise, it binds the row to df2.
> 
> Hope this helps!
> 
> 
> Side note.: Computational efficiency wise, think Ulrik?s answer is probably better. Presentation wise, his is also much better.
> 
> Regards,
> Bo Lin
> 
> > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com <mailto:ulrik.stervbo at gmail.com>> wrote:
> >
> > Hi Paul,
> >
> > does this do what you want?
> >
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits = c(15,
> > 20))
> >
> > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> >
> > rbind(exdf2, tmpdf)
> >
> > HTH,
> > Ulrik
> >
> > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com <mailto:paulbernal07 at gmail.com>> wrote:
> >
> > Dear friend Mark,
> >
> > Great suggestion! Thank you for replying.
> >
> > I have two dataframes, dataframe1 and dataframe2.
> >
> > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and the
> > other colum with number of transits (all of which were set to NA values).
> > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
> > (march 1 2017).
> >
> > dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
> > format, and the other column with number of transits. dataframe2 starts
> > have the same start and end dates, however, dataframe2 has missing dates
> > between the start and end dates, so it has fewer observations.
> >
> > dataframe1 has a total of 378 observations and dataframe2 has a  total of
> > 362 observations.
> >
> > I would like to come up with a code that could do the following:
> >
> > Get the dates of dataframe1 that are missing in dataframe2 and add them as
> > records to dataframe 2 but with NA values.
> >
> > <dataframe1                              <dataframe2
> >
> > Date              Transits                  Date
> > Transits
> > 1985-10-01    NA                         1985-10-01                15
> > 1985-11-01    NA                         1986-01-01                 20
> > 1985-12-01    NA                         1986-02-01                 5
> > 1986-01-01    NA
> > 1986-02-01    NA
> > 2017-03-01    NA
> >
> > I would like to fill in the missing dates in dataframe2, with NA as value
> > for the missing transits, so that I  could end up with a dataframe3 looking
> > as follows:
> >
> > <dataframe3
> > Date                                Transits
> > 1985-10-01                      15
> > 1985-11-01                       NA
> > 1985-12-01                       NA
> > 1986-01-01                       20
> > 1986-02-01                       5
> > 2017-03-01                       NA
> >
> > This is what I want to accomplish.
> >
> > Thanks, beforehand for your help,
> >
> > Best regards,
> >
> > Paul
> >
> >
> > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org <mailto:msharp at txbiomed.org>>:
> >
> >> Make some small dataframes of just a few rows that illustrate the problem
> >> structure. Make a third that has the result you want. You will get an
> >> answer very quickly. Without a self-contained reproducible problem,
> > results
> >> vary.
> >>
> >> Mark
> >> R. Mark Sharp, Ph.D.
> >> msharp at TxBiomed.org
> >>
> >>
> >>
> >>
> >>
> >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com <mailto:paulbernal07 at gmail.com>> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I have one dataframe which contains 378 observations, and another one,
> >>> containing 362 observations.
> >>>
> >>> Both dataframes have two columns, one date column and another one with
> >> the
> >>> number of transits.
> >>>
> >>> I wanted to come up with a code so that I could fill in the dates that
> >> are
> >>> missing in one of the dataframes and replace the column of transits with
> >>> the value NA.
> >>>
> >>> I have tried several things but R obviously complains that the length of
> >>> the dataframes are different.
> >>>
> >>> How can I solve this?
> >>>
> >>> Any guidance will be greatly appreciated,
> >>>
> >>> Best regards,
> >>>
> >>> Paul
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>> PLEASE do read the posting guide http://www.R-project.org/ <http://www.r-project.org/>
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> >> transmitted, may contain privileged and confidential information and is
> >> intended solely for the exclusive use of the individual or entity to whom
> >> it is addressed. If you are not the intended recipient, you are hereby
> >> notified that any review, dissemination, distribution or copying of this
> >> e-mail and/or attachments is strictly prohibited. If you have received
> > this
> >> e-mail in error, please immediately notify the sender stating that this
> >> transmission was misdirected; return the e-mail to sender; destroy all
> >> paper copies and delete all electronic copies from your system without
> >> disclosing its contents.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> <Container.csv>


	[[alternative HTML version deleted]]


From urieduardo at gmail.com  Tue Mar 28 15:53:33 2017
From: urieduardo at gmail.com (=?UTF-8?Q?Uri_Eduardo_Ram=C3=ADrez_Pasos?=)
Date: Tue, 28 Mar 2017 15:53:33 +0200
Subject: [R] ANOVA for one subject
Message-ID: <CADO6phhC4hR336BRKReyfRMjg1pjn8JEfvAW6TKd9RJHPXw2Ow@mail.gmail.com>

Dear everyone,

I have a 2x3  design (medication x stimulus type) but very few subjects (6)
and I would like to perform intra-subject stats using r's aov (I've already
run the group analysis). Is there a conceptual problem with this, as long
as I don't interpret the results as representative of the population with
the disease I'm studying? Could anyone point me to any discussion of this
practice, as to its merits for example?

Many thanks,
U. Pasos

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Tue Mar 28 16:40:43 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 28 Mar 2017 09:40:43 -0500
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <8d1216826c684718860c45f81dc7d9f7@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
	<CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
	<8d1216826c684718860c45f81dc7d9f7@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAMOcQfNzLrWdUR4-LonGOW1-+ObicJPRXLGstxB6GrBNnSSp0Q@mail.gmail.com>

Dear friend David,

Thank you for your valuable suggestion. So here is the file in .txt format.

Best of regards,

Paul

2017-03-28 9:35 GMT-05:00 David L Carlson <dcarlson at tamu.edu>:

> We did not get the file on the list. You need to rename your file to
> "Container.txt" or the mailing list will strip it from your message. The
> read.csv() function returns a data frame so Data is already a data frame.
> The command DataFrame<-data.frame(Data) just makes a copy of Data.
>
> Without the file, it is difficult to be certain, but your dates are
> probably stored as character strings and read.csv() will turn those to
> factors unless you tell it not to do that. Try
>
> Data<-read.csv("Container.csv", stringsAsFactors=FALSE)
> str(Data) # To see how the dates are stored
>
> and see if things work better. If not, rename the file or use dput(Data)
> and copy the result into your email message. If the data is very long, use
> dput(head(Data, 15)).
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Bernal
> Sent: Tuesday, March 28, 2017 9:12 AM
> To: Ng Bo Lin <ngbolin91 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Looping Through DataFrames with Differing Lenghts
>
> Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and
> valuable replies,
>
> I am trying to reformat a date as follows:
>
> Data<-read.csv("Container.csv")
>
> DataFrame<-data.frame(Data)
>
> DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")
>
> #trying to put it in YYYY-MM-DD format
>
> However, when I do this, I get a bunch of NAs for the dates.
>
> I am providing a sample dataset as a reference.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> 2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:
>
> > Hi Paul,
> >
> > Using the example provided by Ulrik, where
> >
> > > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?,
> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> > c(15,20)),
> >
> > You could also try the following function:
> >
> > for (i in 1:dim(exdf1)[1]){
> >         if (!exdf1[i, 1] %in% exdf2[, 1]){
> >                 exdf2 <- rbind(exdf2, exdf1[i,])
> >         }
> > }
> >
> > Basically, what the function does is that it runs through the number of
> > rows in exdf1, and checks if the Date of the exdf1 row already exists in
> > Date column of exdf2. If so, it skips it. Otherwise, it binds the row to
> > df2.
> >
> > Hope this helps!
> >
> >
> > Side note.: Computational efficiency wise, think Ulrik?s answer is
> > probably better. Presentation wise, his is also much better.
> >
> > Regards,
> > Bo Lin
> >
> > > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> > wrote:
> > >
> > > Hi Paul,
> > >
> > > does this do what you want?
> > >
> > > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> > > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> > c(15,
> > > 20))
> > >
> > > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> > >
> > > rbind(exdf2, tmpdf)
> > >
> > > HTH,
> > > Ulrik
> > >
> > > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> > >
> > > Dear friend Mark,
> > >
> > > Great suggestion! Thank you for replying.
> > >
> > > I have two dataframes, dataframe1 and dataframe2.
> > >
> > > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and
> > the
> > > other colum with number of transits (all of which were set to NA
> values).
> > > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in
> 2017-03-01
> > > (march 1 2017).
> > >
> > > dataframe2 has the same  two columns, one with the dates in YYYY-MM-DD
> > > format, and the other column with number of transits. dataframe2 starts
> > > have the same start and end dates, however, dataframe2 has missing
> dates
> > > between the start and end dates, so it has fewer observations.
> > >
> > > dataframe1 has a total of 378 observations and dataframe2 has a  total
> of
> > > 362 observations.
> > >
> > > I would like to come up with a code that could do the following:
> > >
> > > Get the dates of dataframe1 that are missing in dataframe2 and add them
> > as
> > > records to dataframe 2 but with NA values.
> > >
> > > <dataframe1                              <dataframe2
> > >
> > > Date              Transits                  Date
> > > Transits
> > > 1985-10-01    NA                         1985-10-01                15
> > > 1985-11-01    NA                         1986-01-01                 20
> > > 1985-12-01    NA                         1986-02-01                 5
> > > 1986-01-01    NA
> > > 1986-02-01    NA
> > > 2017-03-01    NA
> > >
> > > I would like to fill in the missing dates in dataframe2, with NA as
> value
> > > for the missing transits, so that I  could end up with a dataframe3
> > looking
> > > as follows:
> > >
> > > <dataframe3
> > > Date                                Transits
> > > 1985-10-01                      15
> > > 1985-11-01                       NA
> > > 1985-12-01                       NA
> > > 1986-01-01                       20
> > > 1986-02-01                       5
> > > 2017-03-01                       NA
> > >
> > > This is what I want to accomplish.
> > >
> > > Thanks, beforehand for your help,
> > >
> > > Best regards,
> > >
> > > Paul
> > >
> > >
> > > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
> > >
> > >> Make some small dataframes of just a few rows that illustrate the
> > problem
> > >> structure. Make a third that has the result you want. You will get an
> > >> answer very quickly. Without a self-contained reproducible problem,
> > > results
> > >> vary.
> > >>
> > >> Mark
> > >> R. Mark Sharp, Ph.D.
> > >> msharp at TxBiomed.org
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> > >>>
> > >>> Dear friends,
> > >>>
> > >>> I have one dataframe which contains 378 observations, and another
> one,
> > >>> containing 362 observations.
> > >>>
> > >>> Both dataframes have two columns, one date column and another one
> with
> > >> the
> > >>> number of transits.
> > >>>
> > >>> I wanted to come up with a code so that I could fill in the dates
> that
> > >> are
> > >>> missing in one of the dataframes and replace the column of transits
> > with
> > >>> the value NA.
> > >>>
> > >>> I have tried several things but R obviously complains that the length
> > of
> > >>> the dataframes are different.
> > >>>
> > >>> How can I solve this?
> > >>>
> > >>> Any guidance will be greatly appreciated,
> > >>>
> > >>> Best regards,
> > >>>
> > >>> Paul
> > >>>
> > >>> [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/
> > >> posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> > >> transmitted, may contain privileged and confidential information and
> is
> > >> intended solely for the exclusive use of the individual or entity to
> > whom
> > >> it is addressed. If you are not the intended recipient, you are hereby
> > >> notified that any review, dissemination, distribution or copying of
> this
> > >> e-mail and/or attachments is strictly prohibited. If you have received
> > > this
> > >> e-mail in error, please immediately notify the sender stating that
> this
> > >> transmission was misdirected; return the e-mail to sender; destroy all
> > >> paper copies and delete all electronic copies from your system without
> > >> disclosing its contents.
> > >>
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-------------- next part --------------
TransitDate	Transits
1-Oct-85	4
1-Nov-85	4
1-Dec-85	5
1-Jan-86	4
1-Feb-86	3
1-Mar-86	6
1-Apr-86	4
1-May-86	3
1-Jun-86	4
1-Jul-86	5
1-Aug-86	5
1-Sep-86	4
1-Oct-86	4
1-Nov-86	5
1-Dec-86	2
1-Feb-88	1
1-Mar-88	1
1-Apr-88	2
1-May-88	2
1-Jul-88	1
1-Aug-88	1
1-Sep-88	1
1-Oct-88	2
1-Dec-88	2
1-Jan-89	3
1-Mar-89	2
1-Apr-89	3
1-May-89	4
1-Jun-89	3
1-Jul-89	3
1-Aug-89	2
1-Sep-89	5
1-Oct-89	3
1-Nov-89	3
1-Dec-89	4
1-Jan-90	6
1-Feb-90	4
1-Mar-90	6
1-Apr-90	3
1-May-90	7
1-Jun-90	7
1-Jul-90	3
1-Aug-90	6
1-Sep-90	5
1-Oct-90	6
1-Nov-90	7
1-Dec-90	6
1-Jan-91	5
1-Feb-91	7
1-Mar-91	7
1-Apr-91	7
1-May-91	8
1-Jun-91	7
1-Jul-91	7
1-Aug-91	8
1-Sep-91	9
1-Oct-91	8
1-Nov-91	8
1-Dec-91	9
1-Jan-92	10
1-Feb-92	8
1-Mar-92	8
1-Apr-92	7
1-May-92	9
1-Jun-92	8
1-Jul-92	12
1-Aug-92	12
1-Sep-92	11
1-Oct-92	12
1-Nov-92	12
1-Dec-92	11
1-Jan-93	13
1-Feb-93	10
1-Mar-93	11
1-Apr-93	12
1-May-93	15
1-Jun-93	14
1-Jul-93	12
1-Aug-93	14
1-Sep-93	11
1-Oct-93	16
1-Nov-93	10
1-Dec-93	14
1-Jan-94	12
1-Feb-94	14
1-Mar-94	14
1-Apr-94	16
1-May-94	15
1-Jun-94	14
1-Jul-94	16
1-Aug-94	16
1-Sep-94	14
1-Oct-94	17
1-Nov-94	14
1-Dec-94	14
1-Jan-95	16
1-Feb-95	18
1-Mar-95	15
1-Apr-95	17
1-May-95	19
1-Jun-95	21
1-Jul-95	23
1-Aug-95	24
1-Sep-95	21
1-Oct-95	24
1-Nov-95	20
1-Dec-95	26
1-Jan-96	22
1-Feb-96	21
1-Mar-96	25
1-Apr-96	23
1-May-96	24
1-Jun-96	24
1-Jul-96	22
1-Aug-96	25
1-Sep-96	24
1-Oct-96	24
1-Nov-96	25
1-Dec-96	25
1-Jan-97	25
1-Feb-97	20
1-Mar-97	26
1-Apr-97	22
1-May-97	26
1-Jun-97	24
1-Jul-97	21
1-Aug-97	27
1-Sep-97	23
1-Oct-97	25
1-Nov-97	25
1-Dec-97	26
1-Jan-98	25
1-Feb-98	20
1-Mar-98	25
1-Apr-98	19
1-May-98	28
1-Jun-98	24
1-Jul-98	25
1-Aug-98	25
1-Sep-98	26
1-Oct-98	28
1-Nov-98	25
1-Dec-98	26
1-Jan-99	28
1-Feb-99	24
1-Mar-99	26
1-Apr-99	26
1-May-99	30
1-Jun-99	24
1-Jul-99	28
1-Aug-99	26
1-Sep-99	24
1-Oct-99	29
1-Nov-99	27
1-Dec-99	25
1-Jan-00	29
1-Feb-00	25
1-Mar-00	29
1-Apr-00	25
1-May-00	31
1-Jun-00	24
1-Jul-00	36
1-Aug-00	29
1-Sep-00	30
1-Oct-00	37
1-Nov-00	34
1-Dec-00	42
1-Jan-01	41
1-Feb-01	37
1-Mar-01	42
1-Apr-01	43
1-May-01	46
1-Jun-01	49
1-Jul-01	41
1-Aug-01	50
1-Sep-01	46
1-Oct-01	47
1-Nov-01	49
1-Dec-01	56
1-Jan-02	55
1-Feb-02	54
1-Mar-02	55
1-Apr-02	59
1-May-02	60
1-Jun-02	58
1-Jul-02	66
1-Aug-02	68
1-Sep-02	66
1-Oct-02	68
1-Nov-02	67
1-Dec-02	79
1-Jan-03	73
1-Feb-03	71
1-Mar-03	85
1-Apr-03	79
1-May-03	80
1-Jun-03	82
1-Jul-03	86
1-Aug-03	78
1-Sep-03	86
1-Oct-03	81
1-Nov-03	90
1-Dec-03	93
1-Jan-04	95
1-Feb-04	84
1-Mar-04	93
1-Apr-04	88
1-May-04	92
1-Jun-04	99
1-Jul-04	90
1-Aug-04	105
1-Sep-04	99
1-Oct-04	103
1-Nov-04	97
1-Dec-04	97
1-Jan-05	106
1-Feb-05	95
1-Mar-05	102
1-Apr-05	98
1-May-05	117
1-Jun-05	100
1-Jul-05	111
1-Aug-05	115
1-Sep-05	111
1-Oct-05	116
1-Nov-05	120
1-Dec-05	118
1-Jan-06	126
1-Feb-06	107
1-Mar-06	128
1-Apr-06	123
1-May-06	140
1-Jun-06	135
1-Jul-06	142
1-Aug-06	138
1-Sep-06	147
1-Oct-06	149
1-Nov-06	146
1-Dec-06	153
1-Jan-07	143
1-Feb-07	131
1-Mar-07	134
1-Apr-07	132
1-May-07	143
1-Jun-07	137
1-Jul-07	152
1-Aug-07	146
1-Sep-07	152
1-Oct-07	153
1-Nov-07	141
1-Dec-07	142
1-Jan-08	130
1-Feb-08	122
1-Mar-08	124
1-Apr-08	127
1-May-08	138
1-Jun-08	126
1-Jul-08	138
1-Aug-08	142
1-Sep-08	137
1-Oct-08	137
1-Nov-08	139
1-Dec-08	130
1-Jan-09	134
1-Feb-09	115
1-Mar-09	122
1-Apr-09	129
1-May-09	130
1-Jun-09	122
1-Jul-09	117
1-Aug-09	114
1-Sep-09	119
1-Oct-09	112
1-Nov-09	102
1-Dec-09	98
1-Jan-10	92
1-Feb-10	86
1-Mar-10	108
1-Apr-10	95
1-May-10	109
1-Jun-10	110
1-Jul-10	109
1-Aug-10	118
1-Sep-10	115
1-Oct-10	123
1-Nov-10	110
1-Dec-10	117
1-Jan-11	114
1-Feb-11	110
1-Mar-11	114
1-Apr-11	120
1-May-11	131
1-Jun-11	122
1-Jul-11	124
1-Aug-11	133
1-Sep-11	129
1-Oct-11	133
1-Nov-11	133
1-Dec-11	126
1-Jan-12	137
1-Feb-12	110
1-Mar-12	128
1-Apr-12	127
1-May-12	132
1-Jun-12	127
1-Jul-12	150
1-Aug-12	136
1-Sep-12	135
1-Oct-12	140
1-Nov-12	124
1-Dec-12	136
1-Jan-13	136
1-Feb-13	127
1-Mar-13	128
1-Apr-13	130
1-May-13	132
1-Jun-13	128
1-Jul-13	122
1-Aug-13	130
1-Sep-13	124
1-Oct-13	129
1-Nov-13	117
1-Dec-13	108
1-Jan-14	115
1-Feb-14	104
1-Mar-14	120
1-Apr-14	117
1-May-14	122
1-Jun-14	109
1-Jul-14	111
1-Aug-14	116
1-Sep-14	117
1-Oct-14	115
1-Nov-14	110
1-Dec-14	106
1-Jan-15	109
1-Feb-15	93
1-Mar-15	111
1-Apr-15	107
1-May-15	120
1-Jun-15	113
1-Jul-15	131
1-Aug-15	127
1-Sep-15	120
1-Oct-15	124
1-Nov-15	123
1-Dec-15	117
1-Jan-16	132
1-Feb-16	117
1-Mar-16	124
1-Apr-16	121
1-May-16	122
1-Jun-16	114
1-Jul-16	99
1-Aug-16	76
1-Sep-16	60
1-Oct-16	64
1-Nov-16	47
1-Dec-16	54
1-Jan-17	48
1-Feb-17	41
1-Mar-17	30

From ulrik.stervbo at gmail.com  Tue Mar 28 18:33:22 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 28 Mar 2017 16:33:22 +0000
Subject: [R] Antwort: Re: Way to Plot Multiple Variables and Change Color
In-Reply-To: <OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
References: <OFCB21F74E.9EFC42EC-ONC12580F1.0046F207-C12580F1.0047E36C@lotus.hawesko.de>
	<CAGx1TMASXjBhm=27_-qZ-4xDwdBpWt=PJE9GDk1m8GXL5zphDg@mail.gmail.com>
	<OF785096C4.90D32BA3-ONC12580F1.00575513-C12580F1.0057964A@lotus.hawesko.de>
Message-ID: <CAKVAULN0N__NWzb=MVQp-DPMVABGrL4D7NX_njqD3UjFo4mysg@mail.gmail.com>

Hi Georg,

you were on the right path - it is all about scale_fill*

The 'problem' as you've discovered is that value is continuous, but
applying scale_fill_manual or others (except scale_fill_gradient) expects
discrete values.

The solution is simply to set the fill with that by using factor():

ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
or:
 ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("red","blue", "green", "purple"))

When using colorBrewer (which I highly recommend), I use scale_*_brewer
rather than setting the colour manually:

ggplot(
  d_result,
  aes(variable, y = n, fill = factor(value))) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Blues ")

Best,
Ulrik


On Tue, 28 Mar 2017 at 18:21 <G.Maubach at weinwolf.de> wrote:

> Hi Richard,
>
> many thanks for your reply.
>
> Your solution is not exactly what I was looking for. I would like to know
> how I can change the colors of the stacked bars in my plot and not use the
> default values. How can this be done?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    "Richard M. Heiberger" <rmh at temple.edu>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  28.03.2017 17:40
> Betreff:        Re: [R] Way to Plot Multiple Variables and Change Color
>
>
>
> I think you are looking for the likert function in the HH package.
> >From ?likert
>
>
> Diverging stacked barcharts for Likert, semantic differential, rating
> scale data, and population pyramids.
>
>
> This will get you started.  Much more fine control is available.  See
> the examples and demo.
>
> ## install.packages("HH") ## if not yet on your system.
>
> library(HH)
>
> AA <- dfr[,-9]
>
> labels <- sort(unique(as.vector(data.matrix(AA))))
> result.template <- integer(length(labels))
> names(result.template) <- labels
>
> BB <- apply(AA, 2, function(x, result=result.template) {
>   tx <- table(x)
>   result[names(tx)] <- tx
>   result
> }
> )
>
> BB
>
> likert(t(BB), ReferenceZero=0, horizontal=FALSE)
>
>
> On Tue, Mar 28, 2017 at 6:05 AM,  <G.Maubach at weinwolf.de> wrote:
> > Hi All,
> >
> > in my current project I have to plot a whole bunch of related variables
> > (item batteries, e.g. How do you rate ... a) Accelaration, b) Horse
> Power,
> > c) Color Palette, etc.) which are all rated on a scale from 1 .. 4.
> >
> > I need to present the results as stacked bar charts where the variables
> > are columns and the percentages of the scales values (1 .. 4) are the
> > chunks of the stacked bar for each variable. To do this I have
> transformed
> > my data from wide to long and calculated the percentage for each
> variable
> > and value. The code for this is as follows:
> >
> > -- cut --
> >
> > dfr <- structure(
> >   list(
> >     v07_01 = c(3, 1, 1, 4, 3, 4, 4, 1, 3, 2, 2, 3,
> >                4, 4, 4, 1, 1, 3, 3, 4),
> >     v07_02 = c(1, 2, 1, 1, 2, 1, 4, 1, 1,
> >                4, 4, 1, 4, 4, 1, 3, 2, 3, 3, 1),
> >     v07_03 = c(3, 2, 2, 1, 4, 1,
> >                2, 3, 3, 1, 4, 2, 3, 1, 4, 1, 4, 2, 2, 3),
> >     v07_04 = c(3, 1, 1,
> >                4, 2, 4, 4, 2, 2, 2, 4, 1, 2, 1, 3, 1, 2, 4, 1, 4),
> >     v07_05 = c(1,
> >                2, 2, 2, 4, 4, 1, 1, 4, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 4),
> >     v07_06 = c(1,
> >                2, 1, 2, 1, 1, 3, 4, 3, 2, 2, 3, 3, 2, 4, 2, 3, 1, 4, 3),
> >     v07_07 = c(3,
> >                2, 3, 3, 1, 1, 3, 3, 4, 4, 1, 3, 1, 3, 2, 4, 1, 2, 3, 4),
> >     v07_08 = c(3,
> >                2, 1, 2, 2, 2, 3, 3, 4, 4, 1, 1, 1, 2, 3, 1, 4, 2, 2, 4),
> >     cased_id = structure(
> >       1:20,
> >       .Label = c(
> >         "1",
> >         "2",
> >         "3",
> >         "4",
> >         "5",
> >         "6",
> >         "7",
> >         "8",
> >         "9",
> >         "10",
> >         "11",
> >         "12",
> >         "13",
> >         "14",
> >         "15",
> >         "16",
> >         "17",
> >         "18",
> >         "19",
> >         "20"
> >       ),
> >       class = "factor"
> >     )
> >   ),
> >   .Names = c(
> >     "v07_01",
> >     "v07_02",
> >     "v07_03",
> >     "v07_04",
> >     "v07_05",
> >     "v07_06",
> >     "v07_07",
> >     "v07_08",
> >     "cased_id"
> >   ),
> >   row.names = c(NA, -20L),
> >   class = c("tbl_df", "tbl",
> >             "data.frame")
> > )
> >
> > mdf <- melt(df)
> > d_result <- mdf  %>%
> >   dplyr::group_by(variable) %>%
> >   count(value)
> >
> > ggplot(
> >   d_result,
> >   aes(variable, y = n, fill = value)) +
> >   geom_bar(stat = "identity") +
> >   coord_cartesian(ylim = c(0,100))
> >
> > -- cut --
> >
> > Is there an easier way of doing this, i. e. a way without need to
> > transform the data?
> >
> > How can I change the colors for the data points 1 .. 4?
> >
> > I tried
> >
> > -- cut --
> >
> >   d_result,
> >   aes(variable, y = n, fill = value)) +
> >   geom_bar(stat = "identity") +
> >   coord_cartesian(ylim = c(0,100)) +
> >   scale_fill_manual(values = RColorBrewer::brewer.pal(4, "Blues"))
> >
> > -- cut -
> >
> > but this does not work cause I am mixing continuous and descrete values.
> >
> > How can I change the colors for the bars?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Mar 28 19:33:14 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 28 Mar 2017 17:33:14 +0000
Subject: [R] Looping Through DataFrames with Differing Lenghts
In-Reply-To: <CAMOcQfNzLrWdUR4-LonGOW1-+ObicJPRXLGstxB6GrBNnSSp0Q@mail.gmail.com>
References: <CAMOcQfNdcGOwjtKBoCL329Yu=+dskR12MeAim7bc6rdY3FrgwA@mail.gmail.com>
	<979DAB3D-6DCF-4C47-9AA3-4F4B28880064@TxBiomed.org>
	<CAMOcQfPknNp-2d-T9Oof=WGif7oOL4_Pu5W7aecO76_kt8RbWw@mail.gmail.com>
	<CAKVAULO7z1NR4v+JvWYRq8KwCJwT_h7y6jnCByN0PL5+eh1Kbw@mail.gmail.com>
	<4042B8C2-1120-41E5-A645-732F99C55016@gmail.com>
	<CAMOcQfPFnemYVyVz62SV62GdKUfZqry=-GdvRVysGfEuzAicaw@mail.gmail.com>
	<8d1216826c684718860c45f81dc7d9f7@exch-2p-mbx-w2.ads.tamu.edu>
	<CAMOcQfNzLrWdUR4-LonGOW1-+ObicJPRXLGstxB6GrBNnSSp0Q@mail.gmail.com>
Message-ID: <bd55b7aa327647b0b13e8ef7ca09f537@exch-2p-mbx-w2.ads.tamu.edu>

You have multiple problems. You do not seem to understand read.csv() or as.Date() so you really need to read the manual pages:

?read.csv
?as.Date

> Data <- read.csv("Container.csv")
> str(Data)
'data.frame':   362 obs. of  1 variable:
 $ TransitDate.Transits: Factor w/ 362 levels "1-Apr-00\t25",..: 319 289 78 140 110 229 18 259 199 169 ...

Notice you have a single factor that combines the TransitDate and Transits because the file you sent was NOT a .csv file, but a tab-delimited file:

> Data <- read.delim("Container.csv")
> str(Data)
'data.frame':   362 obs. of  2 variables:
 $ TransitDate: Factor w/ 362 levels "1-Apr-00","1-Apr-01",..: 319 289 78 140 110 229 18 259 199 169 ...
 $ Transits   : int  4 4 5 4 3 6 4 3 4 5 ...

Now we get two variables, but the date is still a factor.

> Data <- read.delim("Container.csv", stringsAsFactors=FALSE)
> str(Data)
'data.frame':   362 obs. of  2 variables:
 $ TransitDate: chr  "1-Oct-85" "1-Nov-85" "1-Dec-85" "1-Jan-86" ...
 $ Transits   : int  4 4 5 4 3 6 4 3 4 5 ...

Now we get the date as characters, but as Ng Bo Lin pointed out, it is not in the format you indicated: "%Y-%m-%d", %Y means a year with the century (e.g. 1985), but you have 2-digit years (85), %m means month as a decimal number (e.g. 10 for October), but you have a 3-digit abbreviation for the month. And the order is backwards. What you need is

> TDate <- as.Date(Data$TransitDate, "%e-%B-%y")
> head(TDate)
[1] "1985-10-01" "1985-11-01" "1985-12-01" "1986-01-01" "1986-02-01" "1986-03-01"

You probably should preserve the original date and not overwrite it so something like

> Data$Transit <- TDate
> str(Data)
'data.frame':   362 obs. of  3 variables:
 $ TransitDate: chr  "1-Oct-85" "1-Nov-85" "1-Dec-85" "1-Jan-86" ...
 $ Transits   : int  4 4 5 4 3 6 4 3 4 5 ...
 $ Transit    : Date, format: "1985-10-01" "1985-11-01" ...

Would be preferable. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


From: Paul Bernal [mailto:paulbernal07 at gmail.com] 
Sent: Tuesday, March 28, 2017 9:41 AM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Ng Bo Lin <ngbolin91 at gmail.com>; r-help at r-project.org
Subject: Re: [R] Looping Through DataFrames with Differing Lenghts

Dear friend David,

Thank you for your valuable suggestion. So here is the file in .txt format.

Best of regards,

Paul

2017-03-28 9:35 GMT-05:00 David L Carlson <dcarlson at tamu.edu>:
We did not get the file on the list. You need to rename your file to "Container.txt" or the mailing list will strip it from your message. The read.csv() function returns a data frame so Data is already a data frame. The command DataFrame<-data.frame(Data) just makes a copy of Data.

Without the file, it is difficult to be certain, but your dates are probably stored as character strings and read.csv() will turn those to factors unless you tell it not to do that. Try

Data<-read.csv("Container.csv", stringsAsFactors=FALSE)
str(Data) # To see how the dates are stored

and see if things work better. If not, rename the file or use dput(Data) and copy the result into your email message. If the data is very long, use dput(head(Data, 15)).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: Tuesday, March 28, 2017 9:12 AM
To: Ng Bo Lin <ngbolin91 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Looping Through DataFrames with Differing Lenghts

Dear friends Ng Bo Lin, Mark and Ulrik, thank you all for your kind and
valuable replies,

I am trying to reformat a date as follows:

Data<-read.csv("Container.csv")

DataFrame<-data.frame(Data)

DataFrame$TransitDate<-as.Date(DataFrame$TransitDate, "%Y-%m-%d")

#trying to put it in YYYY-MM-DD format

However, when I do this, I get a bunch of NAs for the dates.

I am providing a sample dataset as a reference.

Any help will be greatly appreciated,

Best regards,

Paul

2017-03-28 8:15 GMT-05:00 Ng Bo Lin <ngbolin91 at gmail.com>:

> Hi Paul,
>
> Using the example provided by Ulrik, where
>
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01?,
> "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,20)),
>
> You could also try the following function:
>
> for (i in 1:dim(exdf1)[1]){
>? ? ? ? ?if (!exdf1[i, 1] %in% exdf2[, 1]){
>? ? ? ? ? ? ? ? ?exdf2 <- rbind(exdf2, exdf1[i,])
>? ? ? ? ?}
> }
>
> Basically, what the function does is that it runs through the number of
> rows in exdf1, and checks if the Date of the exdf1 row already exists in
> Date column of exdf2. If so, it skips it. Otherwise, it binds the row to
> df2.
>
> Hope this helps!
>
>
> Side note.: Computational efficiency wise, think Ulrik?s answer is
> probably better. Presentation wise, his is also much better.
>
> Regards,
> Bo Lin
>
> > On 28 Mar 2017, at 5:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> >
> > Hi Paul,
> >
> > does this do what you want?
> >
> > exdf1 <- data.frame(Date = c("1985-10-01", "1985-11-01", "1985-12-01",
> > "1986-01-01"), Transits = c(NA, NA, NA, NA))
> > exdf2 <- data.frame(Date = c("1985-10-01", "1986-01-01"), Transits =
> c(15,
> > 20))
> >
> > tmpdf <- subset(exdf1, !Date %in% exdf2$Date)
> >
> > rbind(exdf2, tmpdf)
> >
> > HTH,
> > Ulrik
> >
> > On Tue, 28 Mar 2017 at 10:50 Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Dear friend Mark,
> >
> > Great suggestion! Thank you for replying.
> >
> > I have two dataframes, dataframe1 and dataframe2.
> >
> > dataframe1 has two columns, one with the dates in YYYY-MM-DD format and
> the
> > other colum with number of transits (all of which were set to NA values).
> > dataframe1 starts in 1985-10-01 (october 1st 1985) and ends in 2017-03-01
> > (march 1 2017).
> >
> > dataframe2 has the same? two columns, one with the dates in YYYY-MM-DD
> > format, and the other column with number of transits. dataframe2 starts
> > have the same start and end dates, however, dataframe2 has missing dates
> > between the start and end dates, so it has fewer observations.
> >
> > dataframe1 has a total of 378 observations and dataframe2 has a? total of
> > 362 observations.
> >
> > I would like to come up with a code that could do the following:
> >
> > Get the dates of dataframe1 that are missing in dataframe2 and add them
> as
> > records to dataframe 2 but with NA values.
> >
> > <dataframe1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? <dataframe2
> >
> > Date? ? ? ? ? ? ? Transits? ? ? ? ? ? ? ? ? Date
> > Transits
> > 1985-10-01? ? NA? ? ? ? ? ? ? ? ? ? ? ? ?1985-10-01? ? ? ? ? ? ? ? 15
> > 1985-11-01? ? NA? ? ? ? ? ? ? ? ? ? ? ? ?1986-01-01? ? ? ? ? ? ? ? ?20
> > 1985-12-01? ? NA? ? ? ? ? ? ? ? ? ? ? ? ?1986-02-01? ? ? ? ? ? ? ? ?5
> > 1986-01-01? ? NA
> > 1986-02-01? ? NA
> > 2017-03-01? ? NA
> >
> > I would like to fill in the missing dates in dataframe2, with NA as value
> > for the missing transits, so that I? could end up with a dataframe3
> looking
> > as follows:
> >
> > <dataframe3
> > Date? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Transits
> > 1985-10-01? ? ? ? ? ? ? ? ? ? ? 15
> > 1985-11-01? ? ? ? ? ? ? ? ? ? ? ?NA
> > 1985-12-01? ? ? ? ? ? ? ? ? ? ? ?NA
> > 1986-01-01? ? ? ? ? ? ? ? ? ? ? ?20
> > 1986-02-01? ? ? ? ? ? ? ? ? ? ? ?5
> > 2017-03-01? ? ? ? ? ? ? ? ? ? ? ?NA
> >
> > This is what I want to accomplish.
> >
> > Thanks, beforehand for your help,
> >
> > Best regards,
> >
> > Paul
> >
> >
> > 2017-03-27 15:15 GMT-05:00 Mark Sharp <msharp at txbiomed.org>:
> >
> >> Make some small dataframes of just a few rows that illustrate the
> problem
> >> structure. Make a third that has the result you want. You will get an
> >> answer very quickly. Without a self-contained reproducible problem,
> > results
> >> vary.
> >>
> >> Mark
> >> R. Mark Sharp, Ph.D.
> >> msharp at TxBiomed.org
> >>
> >>
> >>
> >>
> >>
> >>> On Mar 27, 2017, at 3:09 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I have one dataframe which contains 378 observations, and another one,
> >>> containing 362 observations.
> >>>
> >>> Both dataframes have two columns, one date column and another one with
> >> the
> >>> number of transits.
> >>>
> >>> I wanted to come up with a code so that I could fill in the dates that
> >> are
> >>> missing in one of the dataframes and replace the column of transits
> with
> >>> the value NA.
> >>>
> >>> I have tried several things but R obviously complains that the length
> of
> >>> the dataframes are different.
> >>>
> >>> How can I solve this?
> >>>
> >>> Any guidance will be greatly appreciated,
> >>>
> >>> Best regards,
> >>>
> >>> Paul
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> >> transmitted, may contain privileged and confidential information and is
> >> intended solely for the exclusive use of the individual or entity to
> whom
> >> it is addressed. If you are not the intended recipient, you are hereby
> >> notified that any review, dissemination, distribution or copying of this
> >> e-mail and/or attachments is strictly prohibited. If you have received
> > this
> >> e-mail in error, please immediately notify the sender stating that this
> >> transmission was misdirected; return the e-mail to sender; destroy all
> >> paper copies and delete all electronic copies from your system without
> >> disclosing its contents.
> >>
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >? ? ? ?[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bhamlion78 at gmail.com  Tue Mar 28 18:32:25 2017
From: bhamlion78 at gmail.com (Leon Lee)
Date: Tue, 28 Mar 2017 12:32:25 -0400
Subject: [R] A question on modeling brain growth using GAM
Message-ID: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>

Hi, R experts

I am new to R & GAM toolbox and would like to get inputs from you all on my
models. The question I have is as follows:
I have 30 subjects with each subject being scanned from one to three times
in the first year of life. The brain volume from each scan was measured.
The scan time was randomly distributed from birth to 1 year.
Each subject has different gestational age ranging from 38 to 41 weeks
Each subject has chronological age from birth to 1 year old
Each subject has gender category.
Now, I want to look at how predictors, such as subject's chronological age,
gestational age and gender will explain the changes in brain volume. I also
want to include interactions between gender and age, gestational and
chronological age. Random effects are also included in the model to account
for subject variability. My model looks like the follows:

gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge +
sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML", data=mydata)

Are there any obvious mistakes in the model? Any suggestions will be
greatly appreciated!

L

	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Tue Mar 28 18:50:21 2017
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Tue, 28 Mar 2017 12:50:21 -0400
Subject: [R] Splitting on metacharacters
Message-ID: <CAB9UfhQxdx_Xt9O3P2kwyH4oYHC-Y5GQW--TysNRLim_ZzqCsQ@mail.gmail.com>

Hi R-help,

I would like to:

Extract the "26" and "f" from the following string (i.e. age and gender).
I've tried a bunch of strsplit, grep, etc. Please help!

*"{\"Q0\":\"37\",\"Q1\":\"f\"}"*


Thanks,

Edward

-- 
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University
*Computational Cognitive Neuroscience Laboratory
<http://gershmanlab.webfactional.com/>*

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue Mar 28 19:48:27 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 28 Mar 2017 13:48:27 -0400
Subject: [R] Splitting on metacharacters
In-Reply-To: <CAB9UfhQxdx_Xt9O3P2kwyH4oYHC-Y5GQW--TysNRLim_ZzqCsQ@mail.gmail.com>
References: <CAB9UfhQxdx_Xt9O3P2kwyH4oYHC-Y5GQW--TysNRLim_ZzqCsQ@mail.gmail.com>
Message-ID: <3D2A0A64-AA7C-44D0-9DB3-AA0FF797BA50@utoronto.ca>

You haven't actually _defined_ what the expected range of variations of your string are, but if I speculate wildly, I can come up with the following two solutions that may get you started.

s <- '*"{\"Q0\":\"37\",\"Q1\":\"f\"}"*'
regmatches(s, gregexpr("([0-9]{2,}|[a-z]+)", s))[[1]]
strsplit(s, "\\\"")[[1]][c(5, 9)]


Obviously, there are many more possibilities.
B.


> On Mar 28, 2017, at 12:50 PM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> 
> Hi R-help,
> 
> I would like to:
> 
> Extract the "26" and "f" from the following string (i.e. age and gender).
> I've tried a bunch of strsplit, grep, etc. Please help!
> 
> *"{\"Q0\":\"37\",\"Q1\":\"f\"}"*
> 
> 
> Thanks,
> 
> Edward
> 
> -- 
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
> *Computational Cognitive Neuroscience Laboratory
> <http://gershmanlab.webfactional.com/>*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From soeren.vogel at posteo.ch  Tue Mar 28 20:00:30 2017
From: soeren.vogel at posteo.ch (=?utf-8?Q?S=C3=B6ren_Vogel?=)
Date: Tue, 28 Mar 2017 20:00:30 +0200
Subject: [R] How to apply calculations in "formula" to "data frame"
In-Reply-To: <C4DC59F1-F6A0-4A4C-8FEB-29F22E0667B3@gmail.com>
References: <62b0f0b6-99a4-6686-d552-bbb2b31a85a6@posteo.ch>
	<C4DC59F1-F6A0-4A4C-8FEB-29F22E0667B3@gmail.com>
Message-ID: <319D8955-706B-411A-BC0B-E8BB762DDF4A@posteo.ch>

`model.matrix` was what I was looking for.

Thanks,
S?ren

> On 28.03.2017, at 16:57, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 28 Mar 2017, at 16:14 , S?ren Vogel <soeren.vogel at posteo.ch> wrote:
>> 
>> Hello
>> 
>> Ho can I apply a formula to a data frame?
> 
> 
> That would depend on whether the formula has any special interpretation.
> 
> If if is just an elementary expression, then it would be like 
> 
> eval(For1[[3]], Data, environment(For1))
> 
> but you are using "." to represent... what exactly?
> 
> One possibility is model.matrix(For1, Data)
> 
> but I'm not at all sure that that is what you want.
> 
> -pd
> 
>> 
>> library("formula.tools")
>> Data <- data.frame("v1" = rnorm(31), "v2" = runif(31), "v3" = sample(1:7, 31, repl=T), "v4" = rlnorm(31))
>> For1 <- as.formula(v1 ~ .^3)
>> Lhs <- Data[, formula.tools::lhs.vars(formula)]
>> Rhs <- apply_formula_to_data_frame_and_return_result(data, formula) # ???
>> 
>> Thank you,
>> S?ren
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From NordlDJ at dshs.wa.gov  Tue Mar 28 20:08:30 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 28 Mar 2017 18:08:30 +0000
Subject: [R] Splitting on metacharacters
In-Reply-To: <CAB9UfhQxdx_Xt9O3P2kwyH4oYHC-Y5GQW--TysNRLim_ZzqCsQ@mail.gmail.com>
References: <CAB9UfhQxdx_Xt9O3P2kwyH4oYHC-Y5GQW--TysNRLim_ZzqCsQ@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E993F4@WAXMXOLYMB025.WAX.wa.lcl>

What you are seeing when printing depends on how you do it (and it can be confusing).  Try this, type the following lines exactly (or copy and paste)  and carefully study the results.  In particular, compare the results of cat(s,'\n') with the results of strsplit(s, '"') .

s <- "{\"Q0\":\"37\",\"Q1\":\"f\"}"
s
cat(s,'\n')
'"'    # single quote, double quote, single quote

strsplit(s, '"')


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Patzelt,
> Edward
> Sent: Tuesday, March 28, 2017 9:50 AM
> To: R-help at r-project.org
> Subject: [R] Splitting on metacharacters
> 
> Hi R-help,
> 
> I would like to:
> 
> Extract the "26" and "f" from the following string (i.e. age and gender).
> I've tried a bunch of strsplit, grep, etc. Please help!
> 
> *"{\"Q0\":\"37\",\"Q1\":\"f\"}"*
> 
> 
> Thanks,
> 
> Edward
> 
> --
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
> *Computational Cognitive Neuroscience Laboratory
> <http://gershmanlab.webfactional.com/>*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Mar 28 20:38:26 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 28 Mar 2017 11:38:26 -0700
Subject: [R] lubridate inserting unwelcome 9:21
In-Reply-To: <78b54b8c-b41e-4180-4248-7685467287a7@gvdnet.dk>
References: <78b54b8c-b41e-4180-4248-7685467287a7@gvdnet.dk>
Message-ID: <DD1F028D-A184-409D-888A-1CC80F71EA0C@dcn.davis.ca.us>

Analyzing time data as POSIXct without dates is IMO unwise (likely to give you trouble). My approach is to always keep the date and time together or to use numeric hours-after-midnight. Others have invented packages like chron to deal with such data.
-- 
Sent from my phone. Please excuse my brevity.

On March 28, 2017 8:28:30 AM PDT, Troels Ring <tring at gvdnet.dk> wrote:
>Dear friends - I have a series of times on successive days and would 
>like to convert them into a successive common time for each person (ID)
>
>. Using lubridate and adding days(1) does as expected apart from 
>changing time zone to LMT from UTC and suddenly adding 9:21 (H:M) to
>all 
>times. Individual parts of the instructions seem OK. I'm sorry for the 
>clumsy demonstration - but the error comes through.
>
>R version 3.3.2 (2016-10-31) - Windows.
>
>All best wishes
>Troels
>
>library(lubridate)
>
>SSS <- structure(list(ID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L,
>3L, 3L, 3L, 3L, 3L, 3L), Time = c(-1L, 0L, 1L, 2L, 3L, 4L, 5L,
>6L, 7L, 8L, 9L, 10L, 11L, -1L, 0L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
>8L, 9L, 10L, -1L, 0L, 1L, 2L, 3L, 4L, 5L), VT = structure(c(3L,
>5L, 11L, 11L, 8L, 10L, 8L, 10L, 8L, 7L, 11L, 5L, 5L, 12L, 5L,
>7L, 7L, 5L, 5L, 8L, 10L, 8L, 7L, 7L, 7L, 2L, 8L, 7L, 8L, 7L,
>10L, 8L), .Label = c("02:00", "03:00", "04:00", "05:00", "06:00",
>"09:00", "10:00", "11:00", "11:30", "12:00", "13:00", "14:00",
>"15:00", "17:00", "18:00", "21:30", "23:00"), class = "factor")),
>.Names 
>= c("ID",
>"Time", "VT"), row.names = c(NA, 32L), class = "data.frame")
>
>SSS$VT  <- parse_date_time(SSS$VT,"HM")
>str(SSS$VT)
>
>TT <- list()
>for(i in 1:3) {
>#i <- 1
>BS <- subset(SSS,ID==i)
>TT[[i]] <- c(BS$VT + (1:length(BS[,1])-1)*days(1))
>}
>BS$VT
>(1:length(BS[,1])-1)*days(1)
>
>#these appear as expected but
>
>TT
>
>#appears disturbed 9:21 inserted - LMT time zone - how comes?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Mar 28 22:28:55 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Mar 2017 13:28:55 -0700
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
Message-ID: <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>


> On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
> 
> Hi, R experts
> 
> I am new to R & GAM toolbox and would like to get inputs from you all on my
> models. The question I have is as follows:
> I have 30 subjects with each subject being scanned from one to three times
> in the first year of life. The brain volume from each scan was measured.
> The scan time was randomly distributed from birth to 1 year.
> Each subject has different gestational age ranging from 38 to 41 weeks
> Each subject has chronological age from birth to 1 year old
> Each subject has gender category.
> Now, I want to look at how predictors, such as subject's chronological age,
> gestational age and gender will explain the changes in brain volume. I also
> want to include interactions between gender and age, gestational and
> chronological age. Random effects are also included in the model to account
> for subject variability. My model looks like the follows:
> 
> gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge +
> sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML", data=mydata)
> 
> Are there any obvious mistakes in the model? Any suggestions will be
> greatly appreciated!

I'm not seeing mistakes in the syntax but I would question whether 30 subjects is sufficient to adequately support estimates in a a model of this complexity. I would also think that the 's(age)' and 'sex' terms would get aliased out in a model with "+ s(age, by=sex)". Most R regression functions handle removal of over-parametrization automatically.

You also have a variable number of measurements per subject. I am unable to comment on the effort to account for the implicit and variably measured correlation and auto-correlation of values within subjects using a "smooth" on subjIndexF, since that is not an approach I was familiar with.  But I am getting concerned whether you are also new to statistical modeling in addition to your use of R and GAM being "new to you"?

(Perhaps Simon or one of the mixed-effects experts can correct the gaps in my understanding of how to model repeated measures in the context of small numbers of subjects and irregular emasurements.)

Please read the Posting Guide and the pages of candidate mailing lists. Rhelp is not really the place to go when you need statistical advice. I'm not sure if this is really in the center of concerns that get discussed on the Mixed Models list, but to my eyes it would be a better fit there.

-- 
David.
> 
> L
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tring at gvdnet.dk  Tue Mar 28 20:58:07 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Tue, 28 Mar 2017 20:58:07 +0200
Subject: [R] lubridate inserting unwelcome 9:21
In-Reply-To: <78b54b8c-b41e-4180-4248-7685467287a7@gvdnet.dk>
References: <78b54b8c-b41e-4180-4248-7685467287a7@gvdnet.dk>
Message-ID: <0fe4be86-fe3c-2a55-2c53-dc0db0ae6dae@gvdnet.dk>

Thanks a lot - I got interested to make it work since just formatting  
in lubricate as a time  automatically puts the same complete date, which 
was OK for me - and also provided a utility for adding days - which 
apparently then needs tweaking -

Best wishes

Troels


Den 28-03-2017 kl. 20:38 skrev Jeff Newmiller:
> Analyzing time data as POSIXct without dates is IMO unwise (likely to give you trouble). My approach is to always keep the date and time together or to use numeric hours-after-midnight. Others have invented packages like chron to deal with such data.


From oliveirajc at ufv.br  Wed Mar 29 15:44:25 2017
From: oliveirajc at ufv.br (julio cesar oliveira)
Date: Wed, 29 Mar 2017 10:44:25 -0300
Subject: [R] Plot Arrows with Angle and length
Message-ID: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>

Dears,

The arrows command uses the start and end coordinates of each vector, but I
have the starting coordinates, azimuth, and length.

So, There are package that plot this arrows?

Example:

> x<- c(1,2,4)
> y<- c(2,3,5)
> Azimuth<- c(45,90,180)
> Length<- c(1,0.5,1)


Thanks,

Julio

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Mar 29 16:09:54 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 29 Mar 2017 15:09:54 +0100
Subject: [R] Plot Arrows with Angle and length
In-Reply-To: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
References: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E26724056F16D272@GBTEDVPEXCMB04.corp.lgc-group.com>

> The arrows command uses the start and end coordinates of each vector, but
> I have the starting coordinates, azimuth, and length.
> 
> So, There are package that plot this arrows?
> 
> Example:
> 
> > x<- c(1,2,4)
> > y<- c(2,3,5)
> > Azimuth<- c(45,90,180)
> > Length<- c(1,0.5,1)

May be packages out there but if it's a quick fix you want, roll your own.

arrows.az <- function(x, y, azimuth, length, ..., units=c("degrees", "radians")) {
	units <- match.arg(units)
	az.rad <- switch(units,
		degrees=azimuth*pi/180,
		radians=azimuth
	)
	arrows(x, y, x+cos(az.rad)*length, y+sin(az.rad)*length, ...)
}

plot(0:6, 0:6, type="n")
arrows.az(x, y, Azimuth, Length)

"..." means you can pass all the other options to arrows()

S Ellison


> 
> 
> Thanks,
> 
> Julio
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Wed Mar 29 16:13:10 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 29 Mar 2017 15:13:10 +0100
Subject: [R] Plot Arrows with Angle and length - correction
Message-ID: <1A8C1289955EF649A09086A153E26724056F16D276@GBTEDVPEXCMB04.corp.lgc-group.com>

Apologies; 'length' is an arrows() argument. Use something else - see below.

> > x<- c(1,2,4)
> > y<- c(2,3,5)
> > Azimuth<- c(45,90,180)
> > Length<- c(1,0.5,1)

May be packages out there but if it's a quick fix you want, roll your own.

arrows.az <- function(x, y, azimuth, size, ..., units=c("degrees", "radians")) {
	#Using 'size' to avoid clash with arrows(..., length=...)
	units <- match.arg(units)
	az.rad <- switch(units,
		degrees=azimuth*pi/180,
		radians=azimuth
	)
	arrows(x, y, x+cos(az.rad)*size, y+sin(az.rad)*size, ...)
}

plot(0:6, 0:6, type="n")
arrows.az(x, y, Azimuth, Length)

"..." means you can pass all the other options to arrows()

S Ellison


> 
> 
> Thanks,
> 
> Julio
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bgunter.4567 at gmail.com  Wed Mar 29 16:16:22 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Mar 2017 07:16:22 -0700
Subject: [R] Plot Arrows with Angle and length
In-Reply-To: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
References: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
Message-ID: <CAGxFJbTKtbxEeQVLb_umf6VO2Q3HO28jnCs14kQjiSL25iTmjw@mail.gmail.com>

It's just basic trig to convert.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 29, 2017 at 6:44 AM, julio cesar oliveira <oliveirajc at ufv.br> wrote:
> Dears,
>
> The arrows command uses the start and end coordinates of each vector, but I
> have the starting coordinates, azimuth, and length.
>
> So, There are package that plot this arrows?
>
> Example:
>
>> x<- c(1,2,4)
>> y<- c(2,3,5)
>> Azimuth<- c(45,90,180)
>> Length<- c(1,0.5,1)
>
>
> Thanks,
>
> Julio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From osismail100 at gmail.com  Wed Mar 29 09:49:47 2017
From: osismail100 at gmail.com (Omayma Said)
Date: Wed, 29 Mar 2017 09:49:47 +0200
Subject: [R] RMySQL system error: 10060
Message-ID: <CANFFi3j1+p=D5SErUkQsnpxeW6Fu=UQoBEWQpH8f-JfMVGAaHA@mail.gmail.com>

I have a project with a connection that was working properly on the same
device. I usually work on two devices and pull my updates from a remote
repo.
I suddenly got the error below. However, I could connect from the same
device through MySQL workbench.

I posted the on [Stackoverflow](
http://stackoverflow.com/questions/43073782/rmysql-system-error-10060)


library(RMySQL)

con <- dbConnect(RMySQL::MySQL(),
                 host = "xxx",
                 dbname="yyy",
                 user = "zzz",
                 password = "############")
Error in .local(drv, ...) :
  Failed to connect to database: Error: Lost connection to MySQL
server at 'reading authorization packet', system error: 10060

> sessionInfo()
R version 3.3.1 (2016-06-21)Platform: x86_64-w64-mingw32/x64
(64-bit)Running under: Windows >= 8 x64 (build 9200)

locale:[1] LC_COLLATE=English_United States.1252
LC_CTYPE=English_United States.1252   [3] LC_MONETARY=English_United
States.1252 LC_NUMERIC=C                          [5]
LC_TIME=English_United States.1252

attached base packages:[1] stats     graphics  grDevices utils
datasets  methods   base

other attached packages:[1] RMySQL_0.10.10 DBI_0.4-1

loaded via a namespace (and not attached):[1] tools_3.3.1

	[[alternative HTML version deleted]]


From eha at posteo.de  Sun Mar 26 12:18:58 2017
From: eha at posteo.de (Eugene Ha)
Date: Sun, 26 Mar 2017 12:18:58 +0200
Subject: [R] [R-pkgs] valaddin (0.1.0): Make your functions more robust
Message-ID: <9CBE69FA-C589-4AF7-BFF1-C98BF9AEE7A8@posteo.de>

Dear fellow R users,

valaddin (0.1.0) has been published on CRAN:
https://cran.r-project.org/package=valaddin

Using valaddin, you can transform an existing function into a function with
input validation, without having to rewrite it with stop() or stopifnot()
statements. It therefore provides a convenient and consistent way to make
your functions more robust and more predictable, either interactively at
the console, or in your programs.

To learn more, see:

- The landing page of the source repository:
  https://github.com/egnha/valaddin

- The package vignette, which gives an overview of use cases:
  https://cran.r-project.org/package=valaddin/vignettes/valaddin.html

Bug reports and other feedback are welcome at the issues page on GitHub:
https://github.com/egnha/valaddin/issues

- Eugene Ha

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From joe.gain at uni-konstanz.de  Wed Mar 29 10:44:21 2017
From: joe.gain at uni-konstanz.de (Joe Gain)
Date: Wed, 29 Mar 2017 10:44:21 +0200
Subject: [R] Archive format
Message-ID: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>

Hello,

we are collecting information on the subject of research data management 
in German on the webplatform:

www.forschungsdaten.info

One of the topics, which we are writing about, is how to *archive* data. 
Unfortunately, none of us in the project is an expert with respect to R 
and so I would like to ask the list, what they recommend? A related 
question is to do with the sharing of data. We have already asked some 
academics, who have basically replied that they don't really know other 
than to strongly recommend a plain text format.

We would also like to know, if members of the list recommend converting 
formats from commercial software such as S-Plus, Terr, SPSS etc. to an 
R-compatible format for long term archivation? Are there any general 
rules and best practices, when it comes to archiving (and sharing) 
statistical data and statistical programs?

Any comments would be much appreciated!
Joe

-- 
B 1003
Kommunikations-, Informations-, Medienzentrum (KIM)
Universitaet Konstanz

t: ++49-7531-883234
e: joe.gain at uni-konstanz.de


From bgunter.4567 at gmail.com  Wed Mar 29 16:48:01 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Mar 2017 07:48:01 -0700
Subject: [R] Archive format
In-Reply-To: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
Message-ID: <CAGxFJbR67dZbH3-dGRcY9_qodZH74Bdnme6sJqTWYCExoU72hg@mail.gmail.com>

Joe:

1. This may be the wrong forum for this question, as this list is
about R programming issues. However, I don't know what the right forum
should be. You might consider stats.stackexchange.com. Some IT forum
might be better (but which???)

2. A google search on "data formats for archiving" (or similar) seemed
to produce many useful hits. I think you'd learn more from that than
you would here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 29, 2017 at 1:44 AM, Joe Gain <joe.gain at uni-konstanz.de> wrote:
> Hello,
>
> we are collecting information on the subject of research data management in
> German on the webplatform:
>
> www.forschungsdaten.info
>
> One of the topics, which we are writing about, is how to *archive* data.
> Unfortunately, none of us in the project is an expert with respect to R and
> so I would like to ask the list, what they recommend? A related question is
> to do with the sharing of data. We have already asked some academics, who
> have basically replied that they don't really know other than to strongly
> recommend a plain text format.
>
> We would also like to know, if members of the list recommend converting
> formats from commercial software such as S-Plus, Terr, SPSS etc. to an
> R-compatible format for long term archivation? Are there any general rules
> and best practices, when it comes to archiving (and sharing) statistical
> data and statistical programs?
>
> Any comments would be much appreciated!
> Joe
>
> --
> B 1003
> Kommunikations-, Informations-, Medienzentrum (KIM)
> Universitaet Konstanz
>
> t: ++49-7531-883234
> e: joe.gain at uni-konstanz.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Mar 29 17:00:44 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 29 Mar 2017 17:00:44 +0200
Subject: [R] Archive format
In-Reply-To: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
Message-ID: <CAJuCY5x0UXSAG+9Wp6Jh_0AVa7eH44jmzk8BpJGRHME9Fajf0Q@mail.gmail.com>

Dear Joe,

I'd choose a plain text format. They can be read and parsed with a
very wide range of software. That is IMHO a much more important factor
for long term archivation that file size or the ease to read it with
specific software.

The choice between tab-delimited, comma separated values, XML, JSON,
... will depend upon the data (and the metadata).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-29 10:44 GMT+02:00 Joe Gain <joe.gain at uni-konstanz.de>:
> Hello,
>
> we are collecting information on the subject of research data management in
> German on the webplatform:
>
> www.forschungsdaten.info
>
> One of the topics, which we are writing about, is how to *archive* data.
> Unfortunately, none of us in the project is an expert with respect to R and
> so I would like to ask the list, what they recommend? A related question is
> to do with the sharing of data. We have already asked some academics, who
> have basically replied that they don't really know other than to strongly
> recommend a plain text format.
>
> We would also like to know, if members of the list recommend converting
> formats from commercial software such as S-Plus, Terr, SPSS etc. to an
> R-compatible format for long term archivation? Are there any general rules
> and best practices, when it comes to archiving (and sharing) statistical
> data and statistical programs?
>
> Any comments would be much appreciated!
> Joe
>
> --
> B 1003
> Kommunikations-, Informations-, Medienzentrum (KIM)
> Universitaet Konstanz
>
> t: ++49-7531-883234
> e: joe.gain at uni-konstanz.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Wed Mar 29 17:02:27 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 29 Mar 2017 10:02:27 -0500
Subject: [R] Getting an unexpected extra row when merging two dataframes
Message-ID: <CAMOcQfPsEvRcch-neMxQhM=bHKFn7RE4Ee1Kp1eUzYNfz5jZgQ@mail.gmail.com>

Hello everyone,

Hope you are all doing great. So I have two datasets:

-dataset1Frame: which contains the historical number of transits from
october 1st, 1985 up to march 1, 2017. It has two columns, one called
TransitDate and the other called Transits. dataset1Frame is a table comming
from an SQL Server Database.

-TransitDateFrame: a made up dataframe that goes from october 1st, 1985 up
to the last date available in dataset1Frame.

Note: The reason why I made up TransitDataFrame is because, since sometimes
dataset1Frame has missing observations (some dates do not exist), and I
just want to make sure I have all the dates available from october 1, 1985
up to the last available observation.
The idea is to leave the transits that do exist as they come, and add the
dates missing as aditional rows (observations) with a value of NA for the
transits.

That being said, here is the code:

>install.packages("src/lubridate_1.6.0.zip", lib=".", repos=NULL,
verbose=TRUE)
>library(lubridate, lib.loc=".", verbose=TRUE)
>library(forecast)
>library(tseries)
>library(stats)
>library(stats4)

>dataset1 <-read.table("CONTAINERTESTDATA.txt")


>dataset1Frame<-data.frame(dataset1)

>dataset1Frame$TransitDate<-as.Date(dataset1Frame$TransitDate, "%Y-%m-%d")

>TransitDate<-seq(as.Date("1985-10-01"),
as.Date(dataset1Frame[nrow(dataset1Frame),1]), "months")

>TransitDate["Transits"]<-NA

>TransitDateFrame<-data.frame(TransitDate)

>NewTransitsFrame<-merge(dataset1Frame,TransitDateFrame, all.y=TRUE)

#Output from resulting dataframes

>TransitDateFrame

>NewTransitsFrame

Why is there an additional row(observation) with a value of NA if I
specified that the dataframe should only go to the last observation? There
should be 378 observations at the end and I get 379 observations instead.

The reason I am doing it this way is because this is how I got to fill in
the gaps in dates (whenever there are nonexistent observations/missing
data).

Any guidance will be greatly appreciated.

I am attaching a .txt file as a reference,

Best regards,

Paul
-------------- next part --------------
TransitDate	Transits
1-Oct-85	55
1-Nov-85	66
1-Dec-85	14
1-Jan-86	48
1-Feb-86	57
1-Mar-86	49
1-Apr-86	70
1-May-86	19
1-Jun-86	27
1-Jul-86	28
1-Aug-86	27
1-Sep-86	66
1-Oct-86	26
1-Nov-86	52
1-Dec-86	29
1-Jan-87	59
1-Feb-87	47
1-Mar-87	59
1-Apr-87	46
1-May-87	39
1-Jun-87	11
1-Jul-87	42
1-Aug-87	14
1-Sep-87	38
1-Oct-87	34
1-Nov-87	21
1-Dec-87	39
1-Jan-88	18
1-Feb-88	67
1-Mar-88	35
1-Apr-88	49
1-May-88	36
1-Jun-88	22
1-Jul-88	69
1-Aug-88	69
1-Sep-88	33
1-Oct-88	26
1-Nov-88	43
1-Dec-88	11
1-Jan-89	46
1-Feb-89	22
1-Mar-89	53
1-Apr-89	46
1-May-89	49
1-Jun-89	64
1-Jul-89	16
1-Aug-89	31
1-Sep-89	22
1-Oct-89	37
1-Nov-89	32
1-Dec-89	60
1-Jan-90	65
1-Feb-90	72
1-Mar-90	14
1-Apr-90	35
1-May-90	25
1-Jun-90	9
1-Jul-90	56
1-Aug-90	47
1-Sep-90	62
1-Oct-90	39
1-Nov-90	36
1-Dec-90	60
1-Jan-91	48
1-Feb-91	56
1-Mar-91	42
1-Apr-91	32
1-May-91	28
1-Jun-91	64
1-Jul-91	30
1-Aug-91	12
1-Sep-91	29
1-Oct-91	63
1-Nov-91	38
1-Dec-91	64
1-Jan-92	16
1-Feb-92	70
1-Mar-92	49
1-Apr-92	34
1-May-92	34
1-Jun-92	69
1-Jul-92	11
1-Aug-92	20
1-Sep-92	17
1-Oct-92	51
1-Nov-92	41
1-Dec-92	18
1-Jan-93	16
1-Feb-93	15
1-Mar-93	43
1-Apr-93	58
1-May-93	43
1-Jun-93	49
1-Jul-93	69
1-Aug-93	45
1-Sep-93	68
1-Oct-93	19
1-Nov-93	18
1-Dec-93	30
1-Jan-94	43
1-Feb-94	28
1-Mar-94	13
1-Apr-94	47
1-May-94	71
1-Jun-94	67
1-Jul-94	28
1-Aug-94	44
1-Sep-94	61
1-Oct-94	73
1-Nov-94	68
1-Dec-94	61
1-Jan-95	34
1-Feb-95	70
1-Mar-95	16
1-Apr-95	68
1-May-95	40
1-Jun-95	60
1-Jul-95	69
1-Aug-95	53
1-Sep-95	20
1-Oct-95	28
1-Nov-95	61
1-Dec-95	41
1-Jan-96	25
1-Feb-96	40
1-Mar-96	31
1-Apr-96	24
1-May-96	57
1-Jun-96	22
1-Jul-96	44
1-Aug-96	19
1-Sep-96	24
1-Oct-96	50
1-Nov-96	46
1-Dec-96	50
1-Jan-97	22
1-Feb-97	31
1-Mar-97	32
1-Apr-97	45
1-May-97	19
1-Jun-97	40
1-Jul-97	22
1-Aug-97	60
1-Sep-97	48
1-Oct-97	68
1-Nov-97	45
1-Dec-97	42
1-Jan-98	33
1-Feb-98	70
1-Mar-98	41
1-Apr-98	67
1-May-98	24
1-Jun-98	29
1-Jul-98	73
1-Aug-98	50
1-Sep-98	13
1-Oct-98	11
1-Nov-98	28
1-Dec-98	31
1-Jan-99	35
1-Feb-99	22
1-Mar-99	22
1-Apr-99	52
1-May-99	38
1-Jun-99	41
1-Jul-99	64
1-Aug-99	57
1-Sep-99	66
1-Oct-99	13
1-Nov-99	10
1-Dec-99	16
1-Jan-00	31
1-Feb-00	16
1-Mar-00	38
1-Apr-00	50
1-May-00	44
1-Jun-00	19
1-Jul-00	61
1-Aug-00	63
1-Sep-00	12
1-Oct-00	68
1-Nov-00	65
1-Dec-00	20
1-Jan-01	58
1-Feb-01	73
1-Mar-01	57
1-Apr-01	23
1-May-01	50
1-Jun-01	71
1-Jul-01	48
1-Aug-01	35
1-Sep-01	42
1-Oct-01	9
1-Nov-01	42
1-Dec-01	29
1-Jan-02	57
1-Feb-02	63
1-Mar-02	49
1-Apr-02	44
1-May-02	39
1-Jun-02	63
1-Jul-02	35
1-Aug-02	11
1-Sep-02	26
1-Oct-02	43
1-Nov-02	62
1-Dec-02	27
1-Jan-03	69
1-Feb-03	22
1-Mar-03	56
1-Apr-03	21
1-May-03	43
1-Jun-03	58
1-Jul-03	52
1-Aug-03	18
1-Sep-03	12
1-Oct-03	32
1-Nov-03	12
1-Dec-03	58
1-Jan-04	27
1-Feb-04	27
1-Mar-04	51
1-Apr-04	33
1-May-04	66
1-Jun-04	61
1-Jul-04	53
1-Aug-04	68
1-Sep-04	29
1-Oct-04	22
1-Nov-04	10
1-Dec-04	60
1-Jan-05	59
1-Feb-05	68
1-Mar-05	24
1-Apr-05	69
1-May-05	43
1-Jun-05	32
1-Jul-05	37
1-Aug-05	13
1-Sep-05	34
1-Oct-05	13
1-Nov-05	42
1-Dec-05	69
1-Jan-06	67
1-Feb-06	34
1-Mar-06	56
1-Apr-06	40
1-May-06	58
1-Jun-06	57
1-Jul-06	36
1-Aug-06	44
1-Sep-06	47
1-Oct-06	45
1-Nov-06	41
1-Dec-06	12
1-Jan-07	56
1-Feb-07	24
1-Mar-07	29
1-Apr-07	22
1-May-07	19
1-Jun-07	69
1-Jul-07	47
1-Aug-07	51
1-Sep-07	30
1-Oct-07	25
1-Nov-07	55
1-Dec-07	73
1-Jan-08	10
1-Feb-08	20
1-Mar-08	16
1-Apr-08	30
1-May-08	48
1-Jun-08	48
1-Jul-08	58
1-Aug-08	59
1-Sep-08	26
1-Oct-08	70
1-Nov-08	51
1-Dec-08	33
1-Jan-09	52
1-Feb-09	15
1-Mar-09	54
1-Apr-09	63
1-May-09	50
1-Jun-09	33
1-Jul-09	43
1-Aug-09	25
1-Sep-09	39
1-Oct-09	9
1-Nov-09	71
1-Dec-09	64
1-Jan-10	62
1-Feb-10	61
1-Mar-10	54
1-Apr-10	38
1-May-10	45
1-Jun-10	55
1-Jul-10	52
1-Aug-10	49
1-Sep-10	43
1-Oct-10	19
1-Nov-10	22
1-Dec-10	53
1-Jan-11	70
1-Feb-11	36
1-Mar-11	49
1-Apr-11	42
1-May-11	39
1-Jun-11	29
1-Jul-11	73
1-Aug-11	19
1-Sep-11	24
1-Oct-11	28
1-Nov-11	66
1-Dec-11	67
1-Jan-12	67
1-Feb-12	21
1-Mar-12	59
1-Apr-12	45
1-May-12	24
1-Jun-12	9
1-Jul-12	61
1-Aug-12	38
1-Sep-12	42
1-Oct-12	66
1-Nov-12	22
1-Dec-12	73
1-Jan-13	48
1-Feb-13	63
1-Mar-13	47
1-Apr-13	38
1-May-13	54
1-Jun-13	30
1-Jul-13	30
1-Aug-13	52
1-Sep-13	21
1-Oct-13	52
1-Nov-13	73
1-Dec-13	24
1-Jan-14	67
1-Feb-14	13
1-Mar-14	51
1-Apr-14	49
1-May-14	22
1-Jun-14	33
1-Jul-14	15
1-Aug-14	24
1-Sep-14	23
1-Oct-14	40
1-Nov-14	51
1-Dec-14	46
1-Jan-15	13
1-Feb-15	73
1-Mar-15	63
1-Apr-15	67
1-May-15	59
1-Jun-15	29
1-Jul-15	56
1-Aug-15	73
1-Sep-15	51
1-Oct-15	40
1-Nov-15	17
1-Dec-15	51
1-Jan-16	41
1-Feb-16	64
1-Mar-16	31
1-Apr-16	15
1-May-16	13
1-Jun-16	53
1-Jul-16	20
1-Aug-16	11
1-Sep-16	43
1-Oct-16	68
1-Nov-16	70
1-Dec-16	14
1-Jan-17	45
1-Feb-17	27
1-Mar-17	40

From wdunlap at tibco.com  Wed Mar 29 17:24:31 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Mar 2017 08:24:31 -0700
Subject: [R] Plot Arrows with Angle and length
In-Reply-To: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
References: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
Message-ID: <CAF8bMcboc8FS5WLAvm=1Xg3+CL4wbX8tZCr=8_w09vpTfGaO_w@mail.gmail.com>

II find using complex numbers makes for less typing with
this sort of thing.  Note the use of plot(asp=1,...) to force
equal scales on both axes so the angles are right.
(I think asp=1 should have been the default when plotting complex
numbers, but too late now.)

> azimuthToNative <- function(degreesClockwise) {
+     # convert degrees clockwise from north to
+     # radians counter-clockwise from east.
+     (90-degreesClockwise)/180*base::pi
+ }
> start <- complex(real=x, imaginary=y)
> end <- start + complex(modulus = Length, argument = azimuthToNative(Azimuth))
> plot(c(start, end), type="n", asp=1) # asp=1 => equal scaling on both axes
> arrows(Re(start),Im(start),Re(end),Im(end)) # no complex method for arrows
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 29, 2017 at 6:44 AM, julio cesar oliveira <oliveirajc at ufv.br> wrote:
> Dears,
>
> The arrows command uses the start and end coordinates of each vector, but I
> have the starting coordinates, azimuth, and length.
>
> So, There are package that plot this arrows?
>
> Example:
>
>> x<- c(1,2,4)
>> y<- c(2,3,5)
>> Azimuth<- c(45,90,180)
>> Length<- c(1,0.5,1)
>
>
> Thanks,
>
> Julio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 29 17:36:38 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 29 Mar 2017 08:36:38 -0700
Subject: [R] Archive format
In-Reply-To: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
Message-ID: <44AD98FD-8DA9-4F7E-9EB4-B17F30799BE9@dcn.davis.ca.us>

The relevance to R (and therefore R-help) of this question is marginal at best. R might not be the language of choice when you go retrieve the data. 

Also, this question seems dangerously close to a troll, because the obvious answer is that the data should be in an open format but if you are not currently working with data in an open format then you increase the cost of archiving and risk losing information up front by extracting it from a proprietary format, and balancing those concerns is more political than technical. 

Note that there exist open binary formats, and the goals of your archiving task and nature of the data would have to be considered in deciding which of the many to use. My own experience has been that plain text survives time best, but YMMV.
-- 
Sent from my phone. Please excuse my brevity.

On March 29, 2017 1:44:21 AM PDT, Joe Gain <joe.gain at uni-konstanz.de> wrote:
>Hello,
>
>we are collecting information on the subject of research data
>management 
>in German on the webplatform:
>
>www.forschungsdaten.info
>
>One of the topics, which we are writing about, is how to *archive*
>data. 
>Unfortunately, none of us in the project is an expert with respect to R
>
>and so I would like to ask the list, what they recommend? A related 
>question is to do with the sharing of data. We have already asked some 
>academics, who have basically replied that they don't really know other
>
>than to strongly recommend a plain text format.
>
>We would also like to know, if members of the list recommend converting
>
>formats from commercial software such as S-Plus, Terr, SPSS etc. to an 
>R-compatible format for long term archivation? Are there any general 
>rules and best practices, when it comes to archiving (and sharing) 
>statistical data and statistical programs?
>
>Any comments would be much appreciated!
>Joe


From drjimlemon at gmail.com  Wed Mar 29 22:54:46 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Mar 2017 07:54:46 +1100
Subject: [R] Plot Arrows with Angle and length
In-Reply-To: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
References: <CAG+u5gqCzshLNhP1U1wA0no=PzzFM8gfXotWkw7y5m+OxFc3FA@mail.gmail.com>
Message-ID: <CA+8X3fVLDV-zGmDHHBWQtgXLv7m-iaBqDxu+Eos0OBEcv1N-fg@mail.gmail.com>

Hi Julio,
Perhaps "vectorField" (plotrix) is what you are looking for.

Jim


On Thu, Mar 30, 2017 at 12:44 AM, julio cesar oliveira
<oliveirajc at ufv.br> wrote:
> Dears,
>
> The arrows command uses the start and end coordinates of each vector, but I
> have the starting coordinates, azimuth, and length.
>
> So, There are package that plot this arrows?
>
> Example:
>
>> x<- c(1,2,4)
>> y<- c(2,3,5)
>> Azimuth<- c(45,90,180)
>> Length<- c(1,0.5,1)
>
>
> Thanks,
>
> Julio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Mar 30 00:14:48 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 29 Mar 2017 18:14:48 -0400
Subject: [R] I want to delete "yhat" and transpose "Response" into a vector
Message-ID: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>

Hi R'ers:
I need a little help.
Thanks in advance.
Bruce

dd    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
dd    <- data.frame(yhat,Response)
attach(dd)

dd <- dd[order(-yhat),]
dd
# delete yhat and transpose Response into a vector
Attached is dataset.

-- 
Bruce


From murdoch.duncan at gmail.com  Thu Mar 30 00:29:00 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Mar 2017 18:29:00 -0400
Subject: [R] I want to delete "yhat" and transpose "Response" into a
 vector
In-Reply-To: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
References: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
Message-ID: <d30a9d13-405d-22bd-ef77-aeab8f227484@gmail.com>

On 29/03/2017 6:14 PM, BR_email wrote:
> Hi R'ers:
> I need a little help.
> Thanks in advance.
> Bruce
>
> dd    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
> dd    <- data.frame(yhat,Response)
> attach(dd)
>
> dd <- dd[order(-yhat),]
> dd
> # delete yhat and transpose Response into a vector

Sounds like a homework assignment.  We don't do those.

Duncan Murdoch


From drjimlemon at gmail.com  Thu Mar 30 00:33:12 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Mar 2017 09:33:12 +1100
Subject: [R] I want to delete "yhat" and transpose "Response" into a
	vector
In-Reply-To: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
References: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
Message-ID: <CA+8X3fV+s5QhdnDcwZ_mtQ20L7b=n-FfkM25cnqo3CcXHZzV-g@mail.gmail.com>

Hi Bruce,
Before we get into the whole business of why your CSV file is lying by
the side of the road to the R help list, let's deal with a few more
important things.

1) You have created a data frame "dd" by reading your CSV file (we hope).

2) You have then overwritten this with two vectors (?) of data. I
looks very much like you have tried to do this with two columns of the
first "dd". As you haven't specified that these belong to "dd', it is
likely that the two vectors were already defined in the environment in
which you did this.

3) OR you have already attached "dd" previously and that prevented the
error that would have been generated in 2.

4) You have then reordered 'dd' with the _negative_ values of yhat.

5) You then asked us how to delete the "yhat" column:

dd<-dd[,-which(names(dd)=="yhat")]

and transpose (! - I think you mean "transform") Response into a vector:

transform:
dd$Response

Jim

On Thu, Mar 30, 2017 at 9:14 AM, BR_email <br at dmstat1.com> wrote:
> Hi R'ers:
> I need a little help.
> Thanks in advance.
> Bruce
>
> dd    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
> dd    <- data.frame(yhat,Response)
> attach(dd)
>
> dd <- dd[order(-yhat),]
> dd
> # delete yhat and transpose Response into a vector
> Attached is dataset.
>
> --
> Bruce
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Thu Mar 30 00:39:18 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Wed, 29 Mar 2017 18:39:18 -0400
Subject: [R] I want to delete "yhat" and transpose "Response" into a
	vector
In-Reply-To: <d30a9d13-405d-22bd-ef77-aeab8f227484@gmail.com>
References: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
	<d30a9d13-405d-22bd-ef77-aeab8f227484@gmail.com>
Message-ID: <DE225890-E7D8-4D09-8ECF-D50D37D9C341@dmstat1.com>

Duncan, it's not a homework assignment. 
Jim, thank you. 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On Mar 29, 2017, at 6:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> Duncan


From br at dmstat1.com  Thu Mar 30 00:43:04 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Wed, 29 Mar 2017 18:43:04 -0400
Subject: [R] I want to delete "yhat" and transpose "Response" into a
	vector
In-Reply-To: <d30a9d13-405d-22bd-ef77-aeab8f227484@gmail.com>
References: <7563671d-e1a2-2d99-aab3-377a106d5957@dmstat1.com>
	<d30a9d13-405d-22bd-ef77-aeab8f227484@gmail.com>
Message-ID: <31FA9604-7315-4AA9-986D-B34F2413DA6A@dmstat1.com>

Duncan, it's not a homework assignment. 
Thanks. 
Bruce 

______________




> On Mar 29, 2017, at 6:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 29/03/2017 6:14 PM, BR_email wrote:
>> Hi R'ers:
>> I need a little help.
>> Thanks in advance.
>> Bruce
>> 
>> dd    <- read.csv("C:/R_Data/firstRdata.csv", sep=",", header=TRUE)
>> dd    <- data.frame(yhat,Response)
>> attach(dd)
>> 
>> dd <- dd[order(-yhat),]
>> dd
>> # delete yhat and transpose Response into a vector
> 
> Sounds like a homework assignment.  We don't do those.
> 
> Duncan Murdoch
> 
> 


From jholtman at gmail.com  Thu Mar 30 02:18:40 2017
From: jholtman at gmail.com (jim holtman)
Date: Wed, 29 Mar 2017 20:18:40 -0400
Subject: [R] Getting an unexpected extra row when merging two dataframes
In-Reply-To: <CAMOcQfPsEvRcch-neMxQhM=bHKFn7RE4Ee1Kp1eUzYNfz5jZgQ@mail.gmail.com>
References: <CAMOcQfPsEvRcch-neMxQhM=bHKFn7RE4Ee1Kp1eUzYNfz5jZgQ@mail.gmail.com>
Message-ID: <CAAxdm-70Bv-393eGDJcSW1G-F=5AyLuTwFx0_W7CJ7O7qUgp1g@mail.gmail.com>

first of all when you read the data in you get 379 rows of data since
you did not say 'header = TRUE' in the read.table.  Here is what the
first 6 lines of you data are:

> dataset1 <- read.table('/users/jh52822/downloads/containertestdata.txt')
>
> str(dataset1)
'data.frame':   379 obs. of  2 variables:
 $ V1: Factor w/ 379 levels "1-Apr-00","1-Apr-01",..: 379 333 301 80
145 113 239 18 270 207 ...
 $ V2: Factor w/ 66 levels "10","11","12",..: 66 46 57 5 39 48 40 61 10 18 ...
> View(dataset1)
> head(dataset1)
           V1       V2
1 TransitDate Transits
2    1-Oct-85       55
3    1-Nov-85       66
4    1-Dec-85       14
5    1-Jan-86       48
6    1-Feb-86       57
>

You need to learn to use 'str' to look at the structure.  So when you
are converting the dates, you will get an NA because the first row has
"TransitDate".  Now if you had used 'header = TRUE', you data would
look like this:

> dataset1 <- read.table('/users/jh52822/downloads/containertestdata.txt',
+                     header = TRUE,
+                     as.is = TRUE  # prevent conversion to factors
+                     )
>
> str(dataset1)
'data.frame':   378 obs. of  2 variables:
 $ TransitDate: chr  "1-Oct-85" "1-Nov-85" "1-Dec-85" "1-Jan-86" ...
 $ Transits   : int  55 66 14 48 57 49 70 19 27 28 ...
> head(dataset1)
  TransitDate Transits
1    1-Oct-85       55
2    1-Nov-85       66
3    1-Dec-85       14
4    1-Jan-86       48
5    1-Feb-86       57
6    1-Mar-86       49
>

So try again.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Mar 29, 2017 at 11:02 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Hello everyone,
>
> Hope you are all doing great. So I have two datasets:
>
> -dataset1Frame: which contains the historical number of transits from
> october 1st, 1985 up to march 1, 2017. It has two columns, one called
> TransitDate and the other called Transits. dataset1Frame is a table comming
> from an SQL Server Database.
>
> -TransitDateFrame: a made up dataframe that goes from october 1st, 1985 up
> to the last date available in dataset1Frame.
>
> Note: The reason why I made up TransitDataFrame is because, since sometimes
> dataset1Frame has missing observations (some dates do not exist), and I
> just want to make sure I have all the dates available from october 1, 1985
> up to the last available observation.
> The idea is to leave the transits that do exist as they come, and add the
> dates missing as aditional rows (observations) with a value of NA for the
> transits.
>
> That being said, here is the code:
>
>>install.packages("src/lubridate_1.6.0.zip", lib=".", repos=NULL,
> verbose=TRUE)
>>library(lubridate, lib.loc=".", verbose=TRUE)
>>library(forecast)
>>library(tseries)
>>library(stats)
>>library(stats4)
>
>>dataset1 <-read.table("CONTAINERTESTDATA.txt")
>
>
>>dataset1Frame<-data.frame(dataset1)
>
>>dataset1Frame$TransitDate<-as.Date(dataset1Frame$TransitDate, "%Y-%m-%d")
>
>>TransitDate<-seq(as.Date("1985-10-01"),
> as.Date(dataset1Frame[nrow(dataset1Frame),1]), "months")
>
>>TransitDate["Transits"]<-NA
>
>>TransitDateFrame<-data.frame(TransitDate)
>
>>NewTransitsFrame<-merge(dataset1Frame,TransitDateFrame, all.y=TRUE)
>
> #Output from resulting dataframes
>
>>TransitDateFrame
>
>>NewTransitsFrame
>
> Why is there an additional row(observation) with a value of NA if I
> specified that the dataframe should only go to the last observation? There
> should be 378 observations at the end and I get 379 observations instead.
>
> The reason I am doing it this way is because this is how I got to fill in
> the gaps in dates (whenever there are nonexistent observations/missing
> data).
>
> Any guidance will be greatly appreciated.
>
> I am attaching a .txt file as a reference,
>
> Best regards,
>
> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alicia.m.ellis at gmail.com  Wed Mar 29 21:31:36 2017
From: alicia.m.ellis at gmail.com (Alicia Ellis)
Date: Wed, 29 Mar 2017 15:31:36 -0400
Subject: [R] Calculating between and within subject coefficient of variation
Message-ID: <CAPUn7BeUSav+98rUanpB2FfrYRV69Bk6LqsKx6K4y9Bb7Wx4pw@mail.gmail.com>

Let's say I have repeated measures of some outcome on some subjects.  I
want to be able to calculate the within and between subject coefficient of
variation for this measure.

An example data frame is:

df<-data.frame(ID = c(1,1,1,2,2,2,3,3,3),
               DAY = c(0,3,6, 0,3,6, 0,3,6),
               VALUE = c(1,2,3,4,5,5,2,3,4)
)

Where ID is the identifier of the subject, DAY is the day the measurement
was taken, and VALUE is the measurement taken on that day.


Can someone suggest an efficient way to do this?  I assume I need to start
with repeated measures ANOVA or mixed model but I'm having trouble figuring
out how to use the outputs from those to get the numbers I want.

Thanks!

	[[alternative HTML version deleted]]


From art.tem.us at gmail.com  Thu Mar 30 00:57:22 2017
From: art.tem.us at gmail.com (Art U)
Date: Wed, 29 Mar 2017 18:57:22 -0400
Subject: [R] Parallel programming.
Message-ID: <CAKY_brGQFDagKen_05xA6_XPk=rk1JkBjFXCGe_pQ+oKU0ngYw@mail.gmail.com>

Hello everyone,

I have general question about parallel programming. I'm doing simulations
that involves bootstrap. For now I'm using parLapply only for bootstrap
part and then function "replicate" for simulations. It is very long
function, so here is a short version:


simfun=function(data,n,alpha){

 #code{}
  cl <- makeCluster(detectCores())
  clusterExport(cl,c("data"), envir=environment())
  clusterExport(cl,c("n"), envir=environment())
  q=1000;

#Bootstrap - zero-corrected stepwise selection
  repl=*parLapply*(cl=cl,1:q,function(i,dataB=data,smpl=n,...){
    dataB <- dataB[sample(nrow(dataB),size=n,replace=TRUE),]
    m1=glm(y~x1+x2+x3+t,family=binomial,data=dataB)
    S=step(m1,direction="backward",trace=F);
    Sstep=summary(S);Sstep

    if (any(rownames(Sstep$coefficients)=="t")==TRUE){
      beta.Step.zero=Sstep$coefficients[paste0("t"), ][1]
    }else{
      beta.Step.zero=0;
    }
    return(beta.Step.zero)
  })
  stopCluster(cl)

  beta.Step.zero.v=(do.call("rbind", repl));
  beta.Step.zero=mean(beta.Step.zero.v);beta.Step.zero
  lower.step.zero=quantile(beta.Step.zero.v, c(.025,
.975))[1];lower.step.zero
  upper.step.zero=quantile(beta.Step.zero.v, c(.025,
.975))[2];upper.step.zero
  Ind.Step.zero=as.integer(bt > lower.step.zero & bt < upper.step.zero);
  Len.Step.zero=upper.step.zero-lower.step.zero;

#more code{}


 return(list(Ind.Step.zero=Ind.Step.zero,Len.Step.zero=Len.Step.zero,lower.step.zero=lower.step.zero,beta.Step.zero=beta.Step.zero,upper.step.zero=upper.step.zero))
}
simN=1000;
repl=*replicate*(simN,simfun(data=data,n=n,alpha=0.025))


For now this code works in waves, each step in replicate it starts to use
all CPU and then stops. Is there the way to convert such function to 100%
parallel programming function? Or any way to make it faster?

Thank you in advance.
Ariel

-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Thu Mar 30 09:51:05 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 30 Mar 2017 08:51:05 +0100
Subject: [R] customize labels useOuterStrips lattice
Message-ID: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>

Dear all,
I am plotting some data using lattice and the function useOuterStrips
to make use of more labels. It is possible to customize the labels of
useOuterStrips so I can decide what to write in it? instead of having,
let's say, A and B I could put something more descriptive.
best regards
luigi


>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
128, 39, 42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
94, 49, 33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
32.5, 59, 58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
90, 73, 84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
45, 76, 33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
212, 40, 68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
186, 297, 32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5, 54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
87, 59, 33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
26.72, 1.83, 9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev,
ll, ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)

  useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )


From thierry.onkelinx at inbo.be  Thu Mar 30 10:09:45 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 30 Mar 2017 10:09:45 +0200
Subject: [R] passing API key in leaflet
In-Reply-To: <1CBC96D4-32A8-4B77-A09B-C9B06AE1C5FC@comcast.net>
References: <CAJuCY5zzh=7y4QsHVGvcPX5aMr4X59sT+Fuxgq7p7SQWy_SEhw@mail.gmail.com>
	<1CBC96D4-32A8-4B77-A09B-C9B06AE1C5FC@comcast.net>
Message-ID: <CAJuCY5zBsKAvxtiNA168gxn9cOYVCzkWvUNLrxmDb172Bm=bfA@mail.gmail.com>

Hi David,

The key was stored correctly in the environment. I solved the problem
by using addTiles() instead of addProviderTiles()

leaflet() %>%
  addTiles(
    paste0(
      "https://{s}.tile.thunderforest.com/cycle/{z}/{x}/{y}.png?apikey=",
      Sys.getenv("OCM_API")
    )
  )

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-26 17:58 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>
>> On Mar 25, 2017, at 3:44 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>
>> Dear all,
>>
>> I'd like to use the OpenCycleMap as background image in a leaflet map.
>> This requires an API key. I've stored the key in an environment
>> variable. Below is a minimal example of the leaflet map. I still get
>> the "API Key Required" message on the tiles. Any suggestions?
>>
>> library(leaflet)
>> leaflet() %>%
>>  addProviderTiles(
>>    "Thunderforest.OpenCycleMap",
>>    options = providerTileOptions(apikey = Sys.getenv("OCM_API"))
>>  )
>
> I don't have any experience with this package but I found myself wondering whether the environment being used was shared by the enviroionment in which the key had been stored. And whether you could do a debugging `print` of hte item returned by Sys.getenv("OCM_API") inside that calling chain?
>
> Best;
> David
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From jholtman at gmail.com  Thu Mar 30 13:07:14 2017
From: jholtman at gmail.com (jim holtman)
Date: Thu, 30 Mar 2017 07:07:14 -0400
Subject: [R] Getting an unexpected extra row when merging two dataframes
In-Reply-To: <58dc84c6.16031f0a.50808.260e@mx.google.com>
References: <CAMOcQfPsEvRcch-neMxQhM=bHKFn7RE4Ee1Kp1eUzYNfz5jZgQ@mail.gmail.com>
	<58dc84c6.16031f0a.50808.260e@mx.google.com>
Message-ID: <CAAxdm-7YVRbLYjTmXs3dQLYssExh6D5mFwbU=PsE0fB7FNac_A@mail.gmail.com>

you need to show what 'str' shows for the data structure

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Mar 30, 2017 at 12:08 AM, paulbernal07 at gmail.com
<paulbernal07 at gmail.com> wrote:
> Dear Jim,
>
> Thank you for your kind reply. However I forgot to tell you that the data
> was actually read from a Microsoft SQL Server database, so I used a select
> statement to read (import) it.
>
> I am working with the R script module of Microsoft Azure Machine Learning
> Studio, adn I used an sql connection to read in the table.
>
> That being said, how can I do to fix tve issue?
>
> Best regards,
>
> Paul
>
>
>
> -------- Mensaje original --------
> Asunto: Re: [R] Getting an unexpected extra row when merging two dataframes
> De: jim holtman
> Para: Paul Bernal
> CC: r-help at r-project.org
>
>
> first of all when you read the data in you get 379 rows of data since
> you did not say 'header = TRUE' in the read.table. Here is what the
> first 6 lines of you data are:
>
>> dataset1 <- read.table('/users/jh52822/downloads/containertestdata.txt')
>>
>> str(dataset1)
> 'data.frame': 379 obs. of 2 variables:
> $ V1: Factor w/ 379 levels "1-Apr-00","1-Apr-01",..: 379 333 301 80
> 145 113 239 18 270 207 ...
> $ V2: Factor w/ 66 levels "10","11","12",..: 66 46 57 5 39 48 40 61 10 18
> ...
>> View(dataset1)
>> head(dataset1)
> V1 V2
> 1 TransitDate Transits
> 2 1-Oct-85 55
> 3 1-Nov-85 66
> 4 1-Dec-85 14
> 5 1-Jan-86 48
> 6 1-Feb-86 57
>>
>
> You need to learn to use 'str' to look at the structure. So when you
> are converting the dates, you will get an NA because the first row has
> "TransitDate". Now if you had used 'header = TRUE', you data would
> look like this:
>
>> dataset1 <- read.table('/users/jh52822/downloads/containertestdata.txt',
> + header = TRUE,
> + as.is = TRUE # prevent conversion to factors
> + )
>>
>> str(dataset1)
> 'data.frame': 378 obs. of 2 variables:
> $ TransitDate: chr "1-Oct-85" "1-Nov-85" "1-Dec-85" "1-Jan-86" ...
> $ Transits : int 55 66 14 48 57 49 70 19 27 28 ...
>> head(dataset1)
> TransitDate Transits
> 1 1-Oct-85 55
> 2 1-Nov-85 66
> 3 1-Dec-85 14
> 4 1-Jan-86 48
> 5 1-Feb-86 57
> 6 1-Mar-86 49
>>
>
> So try again.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Wed, Mar 29, 2017 at 11:02 AM, Paul Bernal wrote:
>> Hello everyone,
>>
>> Hope you are all doing great. So I have two datasets:
>>
>> -dataset1Frame: which contains the historical number of transits from
>> october 1st, 1985 up to march 1, 2017. It has two columns, one called
>> TransitDate and the other called Transits. dataset1Frame is a table
>> comming
>> from an SQL Server Database.
>>
>> -TransitDateFrame: a made up dataframe that goes from october 1st, 1985 up
>> to the last date available in dataset1Frame.
>>
>> Note: The reason why I made up TransitDataFrame is because, since
>> sometimes
>> dataset1Frame has missing observations (some dates do not exist), and I
>> just want to make sure I have all the dates available from october 1, 1985
>> up to the last available observation.
>> The idea is to leave the transits that do exist as they come, and add the
>> dates missing as aditional rows (observations) with a value of NA for the
>> transits.
>>
>> That being said, here is the code:
>>
>>>install.packages("src/lubridate_1.6.0.zip", lib=".", repos=NULL,
>> verbose=TRUE)
>>>library(lubridate, lib.loc=".", verbose=TRUE)
>>>library(forecast)
>>>library(tseries)
>>>library(stats)
>>>library(stats4)
>>
>>>dataset1 <-read.table("CONTAINERTESTDATA.txt")
>>
>>
>>>dataset1Frame<-data.frame(dataset1)
>>
>>>dataset1Frame$TransitDate<-as.Date(dataset1Frame$TransitDate, "%Y-%m-%d")
>>
>>>TransitDate<-seq(as.Date("1985-10-01"),
>> as.Date(dataset1Frame[nrow(dataset1Frame),1]), "months")
>>
>>>TransitDate["Transits"]<-NA
>>
>>>TransitDateFrame<-data.frame(TransitDate)
>>
>>>NewTransitsFrame<-merge(dataset1Frame,TransitDateFrame, all.y=TRUE)
>>
>> #Output from resulting dataframes
>>
>>>TransitDateFrame
>>
>>>NewTransitsFrame
>>
>> Why is there an additional row(observation) with a value of NA if I
>> specified that the dataframe should only go to the last observation? There
>> should be 378 observations at the end and I get 379 observations instead.
>>
>> The reason I am doing it this way is because this is how I got to fill in
>> the gaps in dates (whenever there are nonexistent observations/missing
>> data).
>>
>> Any guidance will be greatly appreciated.
>>
>> I am attaching a .txt file as a reference,
>>
>> Best regards,
>>
>> Paul
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Mar 30 15:11:45 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 31 Mar 2017 00:11:45 +1100
Subject: [R] customize labels useOuterStrips lattice
In-Reply-To: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>
References: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>
Message-ID: <001701d2a957$2efff160$8cffd420$@bigpond.com>

Hi Luigi

see
?strip.custom

too late to do any more

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Thursday, 30 March 2017 18:51
To: r-help
Subject: [R] customize labels useOuterStrips lattice

Dear all,
I am plotting some data using lattice and the function useOuterStrips
to make use of more labels. It is possible to customize the labels of
useOuterStrips so I can decide what to write in it? instead of having,
let's say, A and B I could put something more descriptive.
best regards
luigi


>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
128, 39, 42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
94, 49, 33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
32.5, 59, 58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
90, 73, 84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
45, 76, 33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
212, 40, 68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
186, 297, 32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5, 54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
87, 59, 33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
26.72, 1.83, 9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev,
ll, ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)

  useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From joe.gain at uni-konstanz.de  Thu Mar 30 10:14:51 2017
From: joe.gain at uni-konstanz.de (Joe Gain)
Date: Thu, 30 Mar 2017 10:14:51 +0200
Subject: [R] Archive format
In-Reply-To: <44AD98FD-8DA9-4F7E-9EB4-B17F30799BE9@dcn.davis.ca.us>
References: <d1a6c316-3346-906d-0028-43ea3a480326@uni-konstanz.de>
	<44AD98FD-8DA9-4F7E-9EB4-B17F30799BE9@dcn.davis.ca.us>
Message-ID: <a211e8d5-5261-80f9-c04b-2d278dee5ebf@uni-konstanz.de>

On 29.03.2017 17:36, Jeff Newmiller wrote:
> The relevance to R (and therefore R-help) of this question is marginal at best. R might not be the language of choice when you go retrieve the data.
>
> Also, this question seems dangerously close to a troll, because the obvious answer is that the data should be in an open format but if you are not currently working with data in an open format then you increase the cost of archiving and risk losing information up front by extracting it from a proprietary format, and balancing those concerns is more political than technical.
>
> Note that there exist open binary formats, and the goals of your archiving task and nature of the data would have to be considered in deciding which of the many to use. My own experience has been that plain text survives time best, but YMMV.
>

Well, I didn't mean to troll the list. We have a small section on R, and 
in response to a question that we got from a user, we thought it would 
be a good idea to check with some actual R-users.

I think the responses are pretty much in line with what we expected. 
There's unsurprisingly no simple solution. A text format is advantageous 
due to the many options that a user has to work with text data. Your 
point is valid, with regards to the format of the source-data, which can 
be a clear constraint (other constraints are, for example, of a legal 
nature). I'm not trying to advocate for open formats per se, just trying 
to gather information so as to be able to make a recommendation.

I think we need to restructure the information on our web platform to 
clearly differentiate between data and the source code, scripts etc. 
which are used to process the data ("algorithms").

There is a big problem with data that has been archived but nobody knows 
what it is/ was for. Archivation, sharing, reproducibility are important 
subjects and we are interested in the experience of statisticians in 
dealing with these problems.

Thanks for the replies!
Joe

-- 
B 1003
Kommunikations-, Informations-, Medienzentrum (KIM)
Universitaet Konstanz

t: ++49-7531-883234
e: joe.gain at uni-konstanz.de


From eshithasunithi2 at gmail.com  Thu Mar 30 11:51:50 2017
From: eshithasunithi2 at gmail.com (Eshi Vaz)
Date: Thu, 30 Mar 2017 10:51:50 +0100
Subject: [R] fisher.test function error
Message-ID: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>

Dear All,

When trying to computer a fisher?s exact test using the fisher.test function from the gmodels() package, R-Studio gave me an error:

 Bug in FEXACT: gave negative key.

I used a workspace of 2e+07. I would really appreciate your help as I do not know how to resolve the issue, especially because I am a novice at R-Programming.

Thank you so much,

Eshi.
	[[alternative HTML version deleted]]


From bhamlion78 at gmail.com  Thu Mar 30 15:56:55 2017
From: bhamlion78 at gmail.com (Leon Lee)
Date: Thu, 30 Mar 2017 09:56:55 -0400
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
	<A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
Message-ID: <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>

David

Thank you for your reply. I apologize if I posted in the wrong forum, as I
really couldn't decide which forum is the best place for my question and I
saw similar questions asked before in this forum.

I agree that a sample of ~30 subjects (70 scans in total), the model can be
too complicated. Based on that, I did the following:
(1) ignored the gender effect, as we have less females than males.
(2) corrected chronological age based on their gestational age, that is, we
subtracted an infant's chronological age by 2 weeks, if the infant's
gestational age is 38 weeks instead of 40weeks.

When I ran the model with corrected age, gestational age and their
interactions modeled, I found the main effect of gestational age and the
interaction between the two are gone.

So, my final model will look something like this:
gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re"),
method="REML", data=mydata)

Does this look more reasonable? Yes, I am relatively new to the mixed
model. We originally applied functional data analysis (PACE) on the data,
but want to see the results using a different approach. Also, I couldn't
find the Mixed Models list, do you mind sending me a link?

Thank you!
Longchuan


On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
> >
> > Hi, R experts
> >
> > I am new to R & GAM toolbox and would like to get inputs from you all on
> my
> > models. The question I have is as follows:
> > I have 30 subjects with each subject being scanned from one to three
> times
> > in the first year of life. The brain volume from each scan was measured.
> > The scan time was randomly distributed from birth to 1 year.
> > Each subject has different gestational age ranging from 38 to 41 weeks
> > Each subject has chronological age from birth to 1 year old
> > Each subject has gender category.
> > Now, I want to look at how predictors, such as subject's chronological
> age,
> > gestational age and gender will explain the changes in brain volume. I
> also
> > want to include interactions between gender and age, gestational and
> > chronological age. Random effects are also included in the model to
> account
> > for subject variability. My model looks like the follows:
> >
> > gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge +
> > sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML",
> data=mydata)
> >
> > Are there any obvious mistakes in the model? Any suggestions will be
> > greatly appreciated!
>
> I'm not seeing mistakes in the syntax but I would question whether 30
> subjects is sufficient to adequately support estimates in a a model of this
> complexity. I would also think that the 's(age)' and 'sex' terms would get
> aliased out in a model with "+ s(age, by=sex)". Most R regression functions
> handle removal of over-parametrization automatically.
>
> You also have a variable number of measurements per subject. I am unable
> to comment on the effort to account for the implicit and variably measured
> correlation and auto-correlation of values within subjects using a "smooth"
> on subjIndexF, since that is not an approach I was familiar with.  But I am
> getting concerned whether you are also new to statistical modeling in
> addition to your use of R and GAM being "new to you"?
>
> (Perhaps Simon or one of the mixed-effects experts can correct the gaps in
> my understanding of how to model repeated measures in the context of small
> numbers of subjects and irregular emasurements.)
>
> Please read the Posting Guide and the pages of candidate mailing lists.
> Rhelp is not really the place to go when you need statistical advice. I'm
> not sure if this is really in the center of concerns that get discussed on
> the Mixed Models list, but to my eyes it would be a better fit there.
>
> --
> David.
> >
> > L
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From Ludwig.Kreuzpointner at psychologie.uni-regensburg.de  Thu Mar 30 16:09:17 2017
From: Ludwig.Kreuzpointner at psychologie.uni-regensburg.de (Ludwig Kreuzpointner)
Date: Thu, 30 Mar 2017 16:09:17 +0200
Subject: [R] sem-Package BIC calculation wrong!?
References: <58DD118D020000AA00040363@gwsmtp1.uni-regensburg.de>
Message-ID: <58DD118D020000AA00040363@gwsmtp1.uni-regensburg.de>

To whom it may concern,
when I was calculating BIC with sem
e.g. as follows:

cfa.mod <- cfa(reference.indicators=FALSE, covs=NULL)    
F1: Sentences, Vocabulary, Sent.Completion, First.Letters, Four.Letter.Words 

cfa.sem <- sem(cfa.mod, S=Thurstone, N=355) 
summary(cfa.sem)


the BIC value is wrong!

For the example it results 

BIC =  104.5072

Correct with a formula I found in text books:

BIC= ?2 + ln(N)[k(k + 1)/2 - df]

BIC should be 192.588977895

104.5072 I got, when set k=0

I think there must be a mistake when getting the numbers of parameters.

Kind regard
Ludwig Kreuzpointner


From akumar at stat.tamu.edu  Thu Mar 30 17:21:47 2017
From: akumar at stat.tamu.edu (Maity, Arnab K)
Date: Thu, 30 Mar 2017 15:21:47 +0000
Subject: [R] rtmvt function in tmvtnorm package
Message-ID: <1490887307467.38281@stat.tamu.edu>

Dear R users.


I am trying to generate random numbers from truncated multivariate t distribution. I use the following:


as.vector(rtmvt(n = 1, sigma = Qc.inv, df = 3, lower = logtime[censored.id],
+                 algorithm = "gibbs"))
Error in while (!acceptedW) { : missing value where TRUE/FALSE needed

I try to provide the following informations. Please do not hesitate to let me know this needs additional information to figure out the issue.

head(logtime[censored.id])
[1] 6.429719 6.444131 6.472346 5.560682 6.426488 6.442540

str(logtime[censored.id])
 num [1:188] 6.43 6.44 6.47 5.56 6.43 ...

str(Qc.inv)
 num [1:188, 1:188] 103.19 4.08 37.41 6.3 -14.77 ...?


head(Qc.inv)
           [,1]       [,2]       [,3]        [,4]       [,5]        [,6]       [,7]      [,8]      [,9]       [,10]
[1,] 103.191668   4.084550  37.410771   6.3025844 -14.770439  -3.8583584   5.747125 -14.36141 -22.17369  -0.8416707
[2,]   4.084550  87.162964  50.557940  63.4295196   5.436691 -27.6904379  38.266155 -46.98055  60.98667 -44.3544933
[3,]  37.410771  50.557940  90.820251  46.7400501 -13.133446  -8.0695965  17.170853 -63.98366  54.33788 -19.4413197
[4,]   6.302584  63.429520  46.740050 119.5991486  -2.559422   0.6971248 -18.273204 -12.02721  62.34241 -47.9675229
[5,] -14.770439   5.436691 -13.133446  -2.5594223 112.370413 -14.7914540 -28.387638  12.90690   1.95228  15.3878938
         [,11]      [,12]      [,13]     [,14]      [,15]      [,16]      [,17]      [,18]      [,19]      [,20]     [,21]
[1,] -17.48124  -7.273790   8.758612 -13.05318  21.177517 -29.007640 -16.768586  -7.818816   1.208103   8.582474 21.626926
[2,] -23.13822  21.086132   1.463960 -26.01017   9.572186  -3.852163   8.672799  62.533319 -31.195415  29.340774  4.598501
[3,]  -5.85877   3.857264  -8.385349 -35.61114   1.462074 -12.510675 -13.025487  43.858855 -26.933323  13.406022  5.546703
[4,] -16.96809 -49.094863 -22.028717 -17.48911   7.386639  10.312270  -7.241734  -5.993691 -32.500451 -14.981188 -4.367750
[5,]  38.65007   1.955743  -8.558712  20.58457   2.885866  26.334345  17.182626 -28.025123  30.137036  -5.740590 53.073941
         [,22]     [,23]     [,24]     [,25]      [,26]     [,27]      [,28]      [,29]     [,30]       [,31]      [,32]
[1,] -12.15187  10.21008 -11.61987 -19.63323  -1.721833  17.99243  13.109449 -31.143517 -40.12807  -0.1653785  -4.822136
[2,]   2.41622   5.58190  56.21415 -54.34755 -77.215336 -44.56425 -12.002085 -20.969070 -40.53237   2.4771632  70.096085
[3,] -11.29728  12.47286  44.66689 -44.39676 -41.685117 -36.36607  -2.217315 -25.926949 -51.33097 -10.2219419  76.837953
[4,] -38.49505  20.89032  51.08699 -35.80768 -81.644230 -34.66880 -14.792076 -57.208095 -26.46859  26.9316783  39.304252
[5,]  -4.77228 -15.25001 -87.11353  17.42737  27.454779  25.76826  22.083931  15.958689  32.37850  18.8141986 -70.850367
           [,33]      [,34]      [,35]     [,36]      [,37]      [,38]      [,39]     [,40]     [,41]      [,42]
[1,] -2.56292765 -33.118852 -18.307195  36.89452  -1.885574  15.925918  17.691148 18.782399 -41.10868 -29.037948
[2,] -2.02761046   2.672841 -17.359895  14.83541   8.339768 -15.386750  30.548170 -4.970033  77.36239   4.131188
[3,] -4.36046815 -18.094746 -21.765883  53.43321  24.070214  -1.101232  26.965988  6.375775  46.91174  -1.913579
[4,] -3.76249568 -25.524182   2.602313  18.28056  20.136158  -6.153071 -17.007229 -3.769837  78.79886  26.536849
[5,] 25.37333844  49.122800  11.949395 -59.69279 -12.625364  -3.006932  -3.339474  4.432715 -47.78852   7.994049
          [,43]     [,44]       [,45]      [,46]     [,47]       [,48]    [,49]      [,50]       [,51]     [,52]
[1,] -16.267829 -45.68288  -0.9729662  35.912833  17.81573 -17.0232904 12.63011   3.555426  24.8776107 -25.48942
[2,]  82.933423 -36.37741  51.7247691  61.127603  19.89547 -18.3325435 20.60206 -15.699770  -0.6351787  70.94141
[3,]  78.898704 -32.66581  49.4823361  90.760972  27.78720 -25.8065567 20.21728 -38.261012   3.6325671  37.57488
[4,]  35.226743 -14.69262 110.5254558  63.774194  47.31054  -0.9152841 46.89370  12.069090  12.5332734 114.91011
[5,]  -6.376021  47.47343 -20.5772250 -52.031861 -13.94213  21.3513364 19.16880  20.127523 -32.2555406 -18.92199
          [,53]      [,54]      [,55]     [,56]      [,57]      [,58]     [,59]      [,60]      [,61]      [,62]
[1,]  12.469217   6.605384  -4.494773 19.587522  15.141511  -2.255163 -14.52668 -23.508476 -19.964215  16.356070
[2,]   2.430749 -53.520707  15.240484  7.383617  37.162205   4.596894 -15.61655  41.328329  26.597582 -20.284451
[3,]   8.044619 -63.331045  15.273209  8.023244  32.557750 -10.413627 -34.16039   7.432020  -2.407745 -12.517345
[4,]   6.711366   1.887722  -8.265214 37.653400   3.035649  -3.024647 -32.66960 -28.599953 -42.168595  -8.492222
[5,]   4.511080  13.903864 -23.154220  3.062098 -29.587412  -1.163289  55.84688  -3.639603 -21.439437  38.018817
          [,63]     [,64]      [,65]     [,66]      [,67]      [,68]      [,69]      [,70]      [,71]      [,72]
[1,]  13.982151 -22.02268  25.866270 -12.08414  23.053014  21.556927   2.819743 19.1345911 -17.210878  -3.184506
[2,]   7.788247  63.47815  17.791832 -21.16284  -4.209961 -42.637213  -4.099067 -0.9309052  -6.720104 -29.233959
[3,]  19.690538  52.88822  21.955619 -42.82107   9.414819 -22.909848 -13.214196  7.5379555 -12.694570  -9.288349
[4,]  -6.014174  61.90719  10.600601 -17.65842 -13.480349 -33.061214 -21.210248 -4.2349719 -36.595840 -35.717801
[5,] -11.423140 -33.43289  -9.146526  34.56827 -33.603768  -4.916534 -16.399510 16.8362281 -26.050498  17.289870
          [,73]       [,74]      [,75]      [,76]     [,77]       [,78]      [,79]      [,80]      [,81]     [,82]
[1,]   6.964887 -19.0131849 -10.962387 -22.728584 19.731447 -14.4056740 -17.679696 29.6706552 -22.053506 -17.48776
[2,] -17.662100 -12.5177737  24.514905 -22.924204 10.412900  23.8088390   4.505117  0.2874799 -13.577099 -29.54475
[3,] -32.940665 -16.7930969  11.186390 -24.569641 28.516972  -3.2546103  -7.214680 21.3045453 -25.773707 -29.81783
[4,] -11.286910 -39.1702779  -5.449232 -29.545835 -6.294758 -28.5684830 -45.273614  5.0762319  13.113599 -15.79635
[5,]  31.333027  11.4067957 -16.613807  13.564670  9.303830   0.3982714 -14.078076 11.4432835   3.080034  46.16064
         [,83]     [,84]     [,85]      [,86]      [,87]      [,88]     [,89]     [,90]       [,91]      [,92]      [,93]
[1,] -3.906635 -2.036687 36.231318   1.978159  18.619529  -5.943974 -15.81537  13.53967  -0.4787321 81.8858093   9.413964
[2,]  9.895242 20.683990  5.394997 -55.667260 -21.186389 -11.300155 -58.29189  99.98059 -16.8738084 -7.3087708  41.740481
[3,] 23.970624  3.885754 24.283760 -55.392558  -9.477462 -15.805712 -56.66153  84.92105  -6.0043295 50.1668868  30.358107
[4,] 14.864745 53.962209  6.203406 -23.362368   5.517740  18.233364 -40.12964  95.98350  -6.9243722  0.9468412  40.706512
[5,] 29.943262 11.676235 11.573591 -20.293979 -52.197347   5.904125  25.25067 -58.43703 -11.6620474 -3.9049881 -18.875764
          [,94]      [,95]     [,96]       [,97]      [,98]      [,99]     [,100]     [,101]     [,102]    [,103]
[1,] -32.337495 -23.340426 -24.40618 -19.4082269  -1.005875  -4.883524 -14.197968  -5.057439  54.608183  7.263058
[2,] -16.566362 -37.763768 -49.21907   9.0779860 -18.507662 -49.554422  -5.151398 -42.875991  -6.163987 16.396033
[3,]   7.361798 -24.443326 -67.04417  -0.5159425   9.182521 -28.393355  -7.082648 -24.799091  25.170788  8.985544
[4,]  -1.470292  -9.184299 -17.00770  20.2941387  -3.724142 -19.939988  18.563237 -30.592172  13.180990  3.332729
[5,]  13.518459  19.125688  27.93643  10.6967343  -1.075586 -46.329372  13.515783  -3.248747 -58.384232  1.226128
         [,104]     [,105]    [,106]     [,107]    [,108]     [,109]     [,110]     [,111]     [,112]    [,113]     [,114]
[1,]  -2.783984  -3.295524  11.29617  -6.879183  -8.77472  36.177076 -29.587546 -40.080265 -25.430473 -37.17276 -11.128502
[2,] -11.232139  43.029711  23.60616 -40.193228 -50.56181 -13.012208  -2.889829 -19.197624 -24.090489 -30.80387 -57.987228
[3,]  -9.494581  40.367104  22.19689 -50.332619 -38.60635  18.252724  -8.371556 -50.459492 -32.892205 -32.71281 -52.578621
[4,] -14.763432  57.171749  39.39698 -14.194628 -48.54200 -11.480950  29.842519   8.461525 -29.581543 -14.45019 -61.539376
[5,]  35.999386 -55.199291 -27.29228  13.679432  46.43779  15.443550  16.762766  47.363841   6.601030  34.60518   6.425318
          [,115]     [,116]     [,117]     [,118]     [,119]    [,120]     [,121]     [,122]      [,123]     [,124]
[1,] -28.0788201   2.795296 -11.912358   2.008978   5.954441 10.150284   76.87015 -12.112914  26.2381588  21.353587
[2,]  13.0434948 -86.770100 -32.289060  30.192063  26.058932 23.175750  156.57766  33.764106 -10.6066801 -26.536997
[3,]   4.0653563 -72.282057 -29.496555  14.812384  25.376773 36.308814  163.04189   5.887244  -8.9368539 -16.602686
[4,]  31.5764056 -94.742572 -12.460407 -20.891842  45.973622 22.262936  126.89295 -19.561184 -32.9636552 -21.243088
[5,]  -0.5232302   7.492366   9.945984  -8.220790 -56.306737 -2.519593 -157.57534  -3.650186  -0.4155292  -2.840519
        [,125]     [,126]    [,127]    [,128]     [,129]    [,130]    [,131]     [,132]    [,133]     [,134]     [,135]
[1,] -4.585794 -36.901027 -15.59164 -5.499519   6.320217  6.019933  8.041211   84.02361 -22.26605  15.292450 28.5002527
[2,] 25.156326 -35.497406  25.25636 46.764479  -4.009387 -3.715176 34.891294   71.15530 -59.16251  64.457691 -7.7945660
[3,] 14.475696 -39.375082  32.88338 46.149627 -15.372631 -6.276070 40.264960  103.50387 -47.33394  57.736449  0.8483884
[4,] 50.980979 -24.473197  34.02081 76.904984  16.369162 -5.151141 36.530545   57.74893 -41.08018  46.239025 19.0796365
[5,] -7.335968 -27.829077 -23.66170  7.324798 -17.248833  3.707905 -6.798728 -109.16067  19.54411  -3.039534 -3.7824092
         [,136]     [,137]    [,138]    [,139]      [,140]     [,141]     [,142]    [,143]      [,144]    [,145]
[1,]  36.234463 20.0556223 -1.341857 -19.96725  18.0023242   1.665664   5.371864  11.60666  39.3974082  4.584100
[2,] -41.410580 15.4481192 -6.127424 -24.62600   7.4695956  22.849235 -22.581623  37.26669  -2.2523877  3.774307
[3,]  -7.658759 40.7641851 -5.643633 -22.20056  -0.1027485  -3.635687 -26.151056  38.00414   0.1316689 13.971692
[4,] -43.071731 -0.6670018 26.180700  20.86533  32.0538761  -2.455869  -3.237107  15.66135  15.8291925  7.563325
[5,]   6.385692 24.7458970 17.968295  33.62893 -20.9196039 -20.913955  17.824869 -20.55771  10.8353349  7.344602
         [,146]     [,147]      [,148]     [,149]     [,150]     [,151]     [,152]     [,153]     [,154]     [,155]
[1,]  -8.466086  25.364601 -13.1476576 -18.523840 -20.504276 -21.129528  44.445610 -17.699666  -2.076396 -10.208587
[2,]  -3.171823 -26.739525  23.5873941  28.953444   8.715197  25.259473   6.125369  35.971721  -8.536349   1.553710
[3,] -22.052442   2.722391   3.6739037   5.594339  -3.743816  32.997087  19.478487   6.711170 -13.349878 -25.554481
[4,] -27.630730 -14.732013 -43.9759145 -71.284352 -79.358262  17.084033   9.974541 -27.593717 -13.316136  14.554874
[5,]  40.393284 -50.831849   0.9654449   3.038550  13.628554  -9.762681 -10.644181   6.950414  19.482954   7.661743
         [,156]     [,157]      [,158]    [,159]    [,160]     [,161]     [,162]    [,163]    [,164]     [,165]    [,166]
[1,]  -9.112719  -6.719075 -24.0711028 -17.92269  11.23068   9.413791 -19.887453 -14.21604 14.361151 -25.664229  45.50516
[2,]  40.598364  35.294214  -0.8229091 -55.90226  29.32080 -29.263128 -67.991295 -49.02238  7.651142   1.483744  33.91063
[3,]  27.560787  14.768593  -5.8015368 -61.59669  22.90750 -23.354103 -47.536524 -46.06624  8.847841  -2.706972  37.69478
[4,]  51.150407  52.696012 -38.7055320 -32.92318  54.73381 -25.953583 -47.267089 -37.44935  3.253286  17.468427  14.48600
[5,]   9.453210 -24.866868   4.7077020  21.45067 -14.09162 -16.242264   7.338362  28.33953 36.344855 -59.245388 -36.39018
         [,167]    [,168]     [,169]     [,170]     [,171]     [,172]     [,173]     [,174]     [,175]     [,176]
[1,]  -4.544885  28.38020  -9.372145   9.069206  -7.334183  54.079158  14.571735  -7.217508   8.903421 -49.861188
[2,] -48.735364  41.15537  -8.257373 -54.573811 -58.287592  31.172724 -11.509056 -33.037815 -32.704394  49.739077
[3,] -43.699640  25.65660 -12.765806 -39.802160 -67.101921  31.340425  -1.715203 -35.724065 -40.198980  14.113654
[4,] -48.981659 -11.08451 -14.208159 -30.535879 -34.068724  18.976165  -8.110733 -10.423814 -14.832156  80.339284
[5,]  12.362941 -26.47636  14.835659 -19.872435  28.620478 -47.771748  21.539988  18.354632  14.042340   3.418625
         [,177]     [,178]    [,179]    [,180]    [,181]     [,182]     [,183]     [,184]     [,185]     [,186]
[1,] -30.061208 -26.107934 38.131471  16.44638 -13.16901  -3.077926 -16.106648  34.713017 -23.500839 -14.173299
[2,]  17.301250   2.592833  6.800865  30.23491 -33.33400  36.484838 -19.618483 -29.548019   1.566512  -5.933797
[3,]  -1.892444 -23.573705 31.698060  39.24516 -32.73860  28.346661 -11.194460  18.044047   9.627726 -16.775216
[4,]  21.688662 -52.169082 14.064823  29.39702 -14.96946  52.200631 -16.705632 -29.799225  20.396586 -12.273845
[5,]  13.689477  -7.804491 -7.646703  23.52350  16.55569 -35.096878  -3.024644  -5.026317   2.780635  53.187411
          [,187]     [,188]
[1,] -22.2201269  -7.659217
[2,] -25.1642470  50.317881
[3,] -40.3367680  35.464506
[4,]   1.2765687 -11.863266
[5,]  49.6019190 -17.990819
 [ reached getOption("max.print") -- omitted 1 row ]





Arnab Kumar Maity
Department of Statistics
Texas A&M University
3143 TAMU, Room 401A
College Station, TX 77843
akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
arnabkrmaity at tamu.edu
+1 779 777 3428<tel:%2B1%20779%20777%203428>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar 30 17:29:07 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 30 Mar 2017 08:29:07 -0700
Subject: [R] fisher.test function error
In-Reply-To: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
References: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
Message-ID: <A3D559DB-2DDD-4B7A-AE12-D26BD9214A88@comcast.net>


> On Mar 30, 2017, at 2:51 AM, Eshi Vaz <eshithasunithi2 at gmail.com> wrote:
> 
> Dear All,
> 
> When trying to computer a fisher?s exact test using the fisher.test function from the gmodels() package, R-Studio gave me an error:

Seems unlikely that Rstudio would generate an error message about R code. It's just  a shell around the R interpreter.

> Bug in FEXACT: gave negative key.

I do not see the word "key" in any of the error messages from stats::fisher.test. Error message do not generally use the word "bug" either. You should post the exact error message copied from the console display,

> 
> I used a workspace of 2e+07. I would really appreciate your help as I do not know how to resolve the issue, especially because I am a novice at R-Programming.

What is needed is the exact code used and some sort of effort at delivering a reproducible example. The function fisher.test is most likely not from the gmodels package but rather from the stats-package. You should be able to see this by typing this at the console:

fisher.test   
# when I do this  I see `<environment: namespace:stats>` as the last line
# ... and there is no fisher.test in the gmodels Index page


Please read the Posting Guide and see if you can respond with a reproducible example. Postings to Rhelp should be in plain text, since postings in HTML are likely to be corrupted.

Best;
David.
> 
> Thank you so much,
> 
> Eshi.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Mar 30 18:06:13 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 30 Mar 2017 09:06:13 -0700
Subject: [R] A question on modeling brain growth using GAM
In-Reply-To: <CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
References: <CAJDdXga744D+JFzKC5omseH_D2TVzX0Ud-MHYyF2PkGcr+EMsA@mail.gmail.com>
	<A35FF4C1-5EE7-4A9F-AD57-F66742DF2C76@comcast.net>
	<CAJDdXgaTcy-fT5hGwcepuZ0pswDJKBzh3ny8XEVJWe9=xrQXZA@mail.gmail.com>
Message-ID: <6E2EFFC0-6BD6-4C44-9890-48700D0AEF3B@comcast.net>


> On Mar 30, 2017, at 6:56 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
> 
> David
> 
> Thank you for your reply. I apologize if I posted in the wrong forum, as I really couldn't decide which forum is the best place for my question and I saw similar questions asked before in this forum. 
> 
> I agree that a sample of ~30 subjects (70 scans in total), the model can be too complicated. Based on that, I did the following:
> (1) ignored the gender effect, as we have less females than males. 
> (2) corrected chronological age based on their gestational age, that is, we subtracted an infant's chronological age by 2 weeks, if the infant's gestational age is 38 weeks instead of 40weeks. 
> 
> When I ran the model with corrected age, gestational age and their interactions modeled, I found the main effect of gestational age and the interaction between the two are gone. 
> 
> So, my final model will look something like this:
> gamObj=gam(brainVolume~ s(correctedAge) +  s(subjIndexF, bs="re"), method="REML", data=mydata)
> 
> Does this look more reasonable?

I'm still having difficulty understand how a "smoothing" function would be used to handle repeated measures without some sort of "group-within" indicator. 

I would have imagined (and this is because I have no experience with using this package for repeated measures) something along the lines of:

 ...+s(correctedAg|subjIndexF)

I see this statement in the docs:


smooth.construct.re.smooth.spec {mgcv}	

"gam can deal with simple independent random effects, by exploiting the link between smooths and random effects to treat random effects as smooths. s(x,bs="re") implements this."

But I don't see that as applying to the dependency between individuals measured repeatedly. I find no examples of repeated measures problems being solve by gam(). There is also a note on the same page:

"Note that smooth ids are not supported for random effect terms. Unlike most smooth terms, side conditions are never applied to random effect terms in the event of nesting (since they are identifiable without side conditions)."

When I do a search on "using gam mgcv formula mixed effects" I am referred to packages 'gamm' and 'gamm4' produced by the same author (Simon Wood) as pkg 'mgcv', or to package `nlme`.


> Yes, I am relatively new to the mixed model. We originally applied functional data analysis (PACE) on the data, but want to see the results using a different approach. Also, I couldn't find the Mixed Models list, do you mind sending me a link?   

This is a link to the main mailing lists page:

https://www.r-project.org/mail.html

Found with a search on Google with "R mailing lists"


> 
> Thank you!
> Longchuan
> 
> 
> On Tue, Mar 28, 2017 at 4:28 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 28, 2017, at 9:32 AM, Leon Lee <bhamlion78 at gmail.com> wrote:
> >
> > Hi, R experts
> >
> > I am new to R & GAM toolbox and would like to get inputs from you all on my
> > models. The question I have is as follows:
> > I have 30 subjects with each subject being scanned from one to three times
> > in the first year of life. The brain volume from each scan was measured.
> > The scan time was randomly distributed from birth to 1 year.
> > Each subject has different gestational age ranging from 38 to 41 weeks
> > Each subject has chronological age from birth to 1 year old
> > Each subject has gender category.
> > Now, I want to look at how predictors, such as subject's chronological age,
> > gestational age and gender will explain the changes in brain volume. I also
> > want to include interactions between gender and age, gestational and
> > chronological age. Random effects are also included in the model to account
> > for subject variability. My model looks like the follows:
> >
> > gam=gam(brainVolume~ s(age) + ti(age, gestationalAge) + gestationalAge +
> > sex + s(age, by=sex) +  s(subjIndexF, bs="re"), method="REML", data=mydata)
> >
> > Are there any obvious mistakes in the model? Any suggestions will be
> > greatly appreciated!
> 
> I'm not seeing mistakes in the syntax but I would question whether 30 subjects is sufficient to adequately support estimates in a a model of this complexity. I would also think that the 's(age)' and 'sex' terms would get aliased out in a model with "+ s(age, by=sex)". Most R regression functions handle removal of over-parametrization automatically.
> 
> You also have a variable number of measurements per subject. I am unable to comment on the effort to account for the implicit and variably measured correlation and auto-correlation of values within subjects using a "smooth" on subjIndexF, since that is not an approach I was familiar with.  But I am getting concerned whether you are also new to statistical modeling in addition to your use of R and GAM being "new to you"?
> 
> (Perhaps Simon or one of the mixed-effects experts can correct the gaps in my understanding of how to model repeated measures in the context of small numbers of subjects and irregular emasurements.)
> 
> Please read the Posting Guide and the pages of candidate mailing lists. Rhelp is not really the place to go when you need statistical advice. I'm not sure if this is really in the center of concerns that get discussed on the Mixed Models list, but to my eyes it would be a better fit there.
> 
> --
> David.
> >
> > L
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Thu Mar 30 18:32:52 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 30 Mar 2017 12:32:52 -0400
Subject: [R] customize labels useOuterStrips lattice
In-Reply-To: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>
References: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>
Message-ID: <CAGx1TMCCvKb4TSJfuP+EjYdAKFqOc7-7VUZiP8sr=pt47fDNMQ@mail.gmail.com>

## I find it easiest to change the "trellis" object.

## assign the result of your useOuterStrips() call to an object name,
for example

myplot <- useOuterStrips(   ...   )

## then

names(myplot)
myplot$condlevels
myplot$condlevels$target <- c("much","more","interesting","names","here")
myplot$condlevels$cluster <- c("also","better")
myplot

On Thu, Mar 30, 2017 at 3:51 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I am plotting some data using lattice and the function useOuterStrips
> to make use of more labels. It is possible to customize the labels of
> useOuterStrips so I can decide what to write in it? instead of having,
> let's say, A and B I could put something more descriptive.
> best regards
> luigi
>
>
>>>>
> cluster <- c(rep("A", 90), rep("B", 100))
> sample <- c(
>   rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
> "cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
>         "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
> "blank"), 5),
>   rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
> "cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
>         "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
> "cow-59", "blank"), 5)
> )
> type <- c(
>   rep(c("negative", "negative", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "blank"), 5),
>   rep(c("negative", "positive", "negative", "negative", "negative",
> "negative", "negative", "negative", "positive", "positive",
>         "positive", "positive", "positive", "positive", "positive",
> "positive", "positive", "positive", "positive", "blank"), 5)
> )
> target <- c(
> c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
> c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
> )
> average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
> 128, 39, 42, 47, 86, 100,
>              69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
> 94, 49, 33, 28, 31, 26, 23,
>              30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
> 32.5, 59, 58.5, 61, 62.5, 58,
>              59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
> 90, 73, 84, 95.5, 62, 82, 138,
>              103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
> 45, 76, 33, 37, 51, 44, 50, 54,
>              66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
> 212, 40, 68, 121, 80, 57,
>              81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
> 186, 297, 32, 184, 36, 45, 45, 44,
>              86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
> 79, 34, 74.5, 54, 49, 55, 56,
>              59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
> 87, 59, 33, 58, 51, 54,
>              52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
> stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
> 26.72, 1.83, 9.92, 4.59, 19, 7.96,
>                7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
> 11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
>                42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
> 4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
>                97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
> 72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
>                95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
> 38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
>                27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
> 7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
>                19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
> 9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
>                73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
> 64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
>                3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
> 38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
>                28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
> 34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
>                59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
> 8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
>                0.15, 1.28, 7.42, 71.15, 9.39)
> ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
> 37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
>         10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
> 52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
>         26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
> 38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
>         -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
> 3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
> 44.09,
>         -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
> 53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
> 39.57,
>         -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
> 7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
>         40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
> -2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
>         12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
> 40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
>         41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
> 6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
>         19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
> 45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
> 38.85,
>         43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
> 34.72, 42.58, -18.15, 39.61)
> ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
> 46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
>         161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
> 176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
> 37.97,
>         29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
> 47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
>         156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
> 159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
> 169.69,
>         93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
> 189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
> 174.3,
>         40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
> 172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
> 59.92,
>         92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
> 201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
> 143.71,
>         273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
> 146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
> 127.25,
>         120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
> 132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
> 67.67,
>         154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
> 33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
> 176.6,
>         49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
> my.data <- data.frame(cluster, type, target, sample, average, stdev,
> ll, ul, stringsAsFactors = FALSE)
>
> library(lattice)
> library(latticeExtra)
>
>   useOuterStrips(
>     strip = strip.custom(par.strip.text = list(cex = 0.75)),
>     strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
>     stripplot(
>       average ~ type|target+cluster,
>       panel = function(x,y,col,...)
>         panel.superpose(x,y,col=col,...),
>       panel.groups = function(x,y,col,...){
>         panel.stripplot(x,y,col=col,...)
>         m <- median(y)
>         panel.segments(x0 = x[1] -.5, y0 = m,
>                        x1 = x[1] +.5, y1 = m,
>                        col=col, lwd=2
>         )
>       },
>       my.data,
>       groups = type,
>       pch=1,
>       jitter.data = TRUE,
>       main = "Group-wise",
>       xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
>       col = c("grey", "green", "red"),
>       par.settings = list(strip.background =
> list(col=c("paleturquoise", "grey"))),
>       scales = list(alternating = FALSE, x=list(draw=FALSE)),
>       key = list(
>         space = "top",
>         columns = 3,
>         text = list(c("Blank", "Negative", "Positive"), col="black"),
>         rectangles = list(col=c("grey", "green", "red"))
>       )
>     )
>   )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Mar 30 19:17:14 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 30 Mar 2017 19:17:14 +0200
Subject: [R] sem-Package BIC calculation wrong!?
In-Reply-To: <58DD118D020000AA00040363@gwsmtp1.uni-regensburg.de>
References: <58DD118D020000AA00040363@gwsmtp1.uni-regensburg.de>
	<58DD118D020000AA00040363@gwsmtp1.uni-regensburg.de>
Message-ID: <F86E052C-8679-4AA4-B37B-ADEA400A12AB@gmail.com>


> On 30 Mar 2017, at 16:09 , Ludwig Kreuzpointner <Ludwig.Kreuzpointner at psychologie.uni-regensburg.de> wrote:
> 
> To whom it may concern,
> when I was calculating BIC with sem
> e.g. as follows:
> 
> cfa.mod <- cfa(reference.indicators=FALSE, covs=NULL)    
> F1: Sentences, Vocabulary, Sent.Completion, First.Letters, Four.Letter.Words 
> 
> cfa.sem <- sem(cfa.mod, S=Thurstone, N=355) 
> summary(cfa.sem)
> 
> 
> the BIC value is wrong!
> 
> For the example it results 
> 
> BIC =  104.5072
> 
> Correct with a formula I found in text books:
> 
> BIC= ?2 + ln(N)[k(k + 1)/2 - df]
> 
> BIC should be 192.588977895
> 
> 104.5072 I got, when set k=0
> 
> I think there must be a mistake when getting the numbers of parameters.

The generic definition of BIC is -2 log L + p log N, where p is the number of parameters. However, like the log-likelihood itself, it is only determined up to an additive constant, so it is not obvious that one number is more correct than the other.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sshelburne at jrad.us  Thu Mar 30 20:15:28 2017
From: sshelburne at jrad.us (Shannon Shelburne)
Date: Thu, 30 Mar 2017 18:15:28 +0000
Subject: [R] Generating Covering Arrays
Message-ID: <bfae4882b41e4c86ab4c55ae0538c942@JRADS9.jrad.local>

Hello,

I am trying to determine if R has a package for generating covering arrays. I have done a general Google search as well as searched several R forums and help sites but have not been able to find anything definitive one way or the other. I know there are packages that have the ability to generate Orthogonal Arrays (e.g., DoE.base) but I am looking for the capability to generate Covering Arrays for some software testing (the main difference being in an orthogonal array, each combination occurs exactly x times, but in a covering array each combination occurs at least x times; a relaxing of the requirement that can make a difference in the ability to find a solution as well as in the size of the array). If anyone knows of a package for Covering Arrays, I would greatly appreciate the information.

Thank you in advance,
Shannon




________________________________

This e-mail and any attachments are proprietary and are intended for the sole use of the individual or entity to whom it is addressed, and may constitute Federal Government records and property. If you are not the intended recipient or the employee or agent responsible for delivering the transmission to the intended recipient, be aware that any disclosure, copying, distribution or use of this e-mail or any attachment is prohibited. If you have received this e-mail in error, please notify the sender immediately and delete this e-mail and any attachments from your system. Thank you for your cooperation.


From paulbernal07 at gmail.com  Thu Mar 30 23:31:22 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 30 Mar 2017 16:31:22 -0500
Subject: [R] Getting unexpected extra rows (continued)
Message-ID: <CAMOcQfMP46kaw9X0pYap5pGyv9ffgqi_2H76n+Hz5786R2kuJw@mail.gmail.com>

Hello everyone,

So I have  created a date sequence with the following code:

>x<-seq(as.Date("1985-10-01"), as.Date(Sys.Date()), "months")

>x["Transits"]<-NA

>xFrame<-data.frame(x)


> str(xFrame)

'data.frame':   379 obs. of  1 variable:
 $ x: Date, format: "1985-10-01" "1985-11-01" "1985-12-01" "1986-01-01" ...

How can I make this a dataframe with two columns (date and transits) and
378 observations with value NA?

Any help will be greatly appreciated,

Regards,

Paul

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Thu Mar 30 23:34:29 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 30 Mar 2017 16:34:29 -0500
Subject: [R] Date operation Question in R
Message-ID: <CAMOcQfO94JDOC2n=3YSAii4CmQZzUshp9R4vkSRtDGZA5cqA5g@mail.gmail.com>

Hello everyone,

Is there a way to use the function seq to generate a date sequence in this
kind of format: jan-2007?

Also, is there a way to change the Sys.Date() format to the one mentioned
above (jan-2007)?

Thanks in advance for your valuable help,

Best regards,

Paul

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Fri Mar 31 00:09:14 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 30 Mar 2017 22:09:14 +0000
Subject: [R] Getting unexpected extra rows (continued)
In-Reply-To: <CAMOcQfMP46kaw9X0pYap5pGyv9ffgqi_2H76n+Hz5786R2kuJw@mail.gmail.com>
References: <CAMOcQfMP46kaw9X0pYap5pGyv9ffgqi_2H76n+Hz5786R2kuJw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E99B01@WAXMXOLYMB025.WAX.wa.lcl>

This is pretty basic stuff which suggests you need to (re)read the intro to R that comes with your R installation.  One approach would be :

xFrame <- data.frame(x=x, Transits=NA)


hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Bernal
> Sent: Thursday, March 30, 2017 2:31 PM
> To: r-help at r-project.org
> Subject: [R] Getting unexpected extra rows (continued)
> 
> Hello everyone,
> 
> So I have  created a date sequence with the following code:
> 
> >x<-seq(as.Date("1985-10-01"), as.Date(Sys.Date()), "months")
> 
> >x["Transits"]<-NA
> 
> >xFrame<-data.frame(x)
> 
> 
> > str(xFrame)
> 
> 'data.frame':   379 obs. of  1 variable:
>  $ x: Date, format: "1985-10-01" "1985-11-01" "1985-12-01" "1986-01-01" ...
> 
> How can I make this a dataframe with two columns (date and transits) and
> 378 observations with value NA?
> 
> Any help will be greatly appreciated,
> 
> Regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thpe at simecol.de  Fri Mar 31 00:16:21 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Fri, 31 Mar 2017 00:16:21 +0200
Subject: [R] Date operation Question in R
In-Reply-To: <CAMOcQfO94JDOC2n=3YSAii4CmQZzUshp9R4vkSRtDGZA5cqA5g@mail.gmail.com>
References: <CAMOcQfO94JDOC2n=3YSAii4CmQZzUshp9R4vkSRtDGZA5cqA5g@mail.gmail.com>
Message-ID: <3a4dce28-2813-ad41-1528-d7c012f0e3c8@simecol.de>

On 30.03.2017 23:34, Paul Bernal wrote:
> Hello everyone,
>
> Is there a way to use the function seq to generate a date sequence in
> this kind of format: jan-2007?

format(seq(ISOdate(2017,1,1), ISOdate(2017,12,31), "months"), "%b-%Y")

>
> Also, is there a way to change the Sys.Date() format to the one
> mentioned above (jan-2007)?

format(Sys.Date(), "%b-%Y")

see ?strptime for details.

Thomas

>
> Thanks in advance for your valuable help,
>
> Best regards,
>
> Paul


From dulcalma at bigpond.com  Fri Mar 31 02:52:04 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 31 Mar 2017 11:52:04 +1100
Subject: [R] customize labels useOuterStrips lattice
In-Reply-To: <001701d2a957$2efff160$8cffd420$@bigpond.com>
References: <CAMk+s2ReuOXJ1FQLVo0ahJYMnAur+xBd+_yycLQokcQV63L1Vw@mail.gmail.com>
	<001701d2a957$2efff160$8cffd420$@bigpond.com>
Message-ID: <000301d2a9b9$03aba470$0b02ed50$@bigpond.com>

Hi  Luigi

You were nearly there!

Using Rich's factors

  useOuterStrips(strip = strip.custom(factor.levels =
c("much","more","interesting","names","here"),
                                      par.strip.text = list(cex = 0.75)),
                 strip.left = strip.custom(factor.levels =
c("also","better"),
                                           par.strip.text = list(cex =
0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )

Regards

Duncan


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
Mackay
Sent: Friday, 31 March 2017 00:12
To: R; 'Luigi Marongiu'
Subject: Re: [R] customize labels useOuterStrips lattice

Hi Luigi

see
?strip.custom

too late to do any more

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Thursday, 30 March 2017 18:51
To: r-help
Subject: [R] customize labels useOuterStrips lattice

Dear all,
I am plotting some data using lattice and the function useOuterStrips
to make use of more labels. It is possible to customize the labels of
useOuterStrips so I can decide what to write in it? instead of having,
let's say, A and B I could put something more descriptive.
best regards
luigi


>>>
cluster <- c(rep("A", 90), rep("B", 100))
sample <- c(
  rep(c("cow-01", "cow-02", "cow-03", "cow-04", "cow-05", "cow-06",
"cow-07", "cow-08", "cow-09", "cow-10", "cow-11",
        "cow-12", "cow-13", "cow-14", "cow-15", "cow-16", "cow-17",
"blank"), 5),
  rep(c("cow-26", "cow-35", "cow-36", "cow-37", "cow-38", "cow-39",
"cow-40", "cow-41", "cow-42", "cow-43", "cow-44", "cow-45",
        "cow-46", "cow-47", "cow-48", "cow-49", "cow-50", "cow-51",
"cow-59", "blank"), 5)
)
type <- c(
  rep(c("negative", "negative", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "blank"), 5),
  rep(c("negative", "positive", "negative", "negative", "negative",
"negative", "negative", "negative", "positive", "positive",
        "positive", "positive", "positive", "positive", "positive",
"positive", "positive", "positive", "positive", "blank"), 5)
)
target <- c(
c(rep("a", 18), rep("b", 18), rep("c", 18), rep("d", 18), rep("e", 18)),
c(rep("a", 20), rep("b", 20), rep("c", 20), rep("d", 20), rep("e", 20))
)
average <- c(88.5, 49, 41, 33, 35, 45, 95, 30, 41, 64, 22, 29, 59, 71,
128, 39, 42, 47, 86, 100,
             69, 44, 53, 66, 66, 71, 161, 69, 22.5, 30, 67, 99, 129,
94, 49, 33, 28, 31, 26, 23,
             30, 41, 35, 23, 38, 43, 15, 21, 45, 51.5, 34, 26, 43,
32.5, 59, 58.5, 61, 62.5, 58,
             59.5, 60.5, 60, 64, 110, 55, 66, 197, 83.5, 155, 76, 125,
90, 73, 84, 95.5, 62, 82, 138,
             103.5, 57, 138, 149.5, 57, 54, 245.5, 191, 131, 96, 176,
45, 76, 33, 37, 51, 44, 50, 54,
             66, 49, 90, 66.5, 42.5, 67, 56, 54, 50, 45, 99, 50, 51.5,
212, 40, 68, 121, 80, 57,
             81.5, 128, 77, 119.5, 126, 184, 101, 103, 88, 100, 140,
186, 297, 32, 184, 36, 45, 45, 44,
             86, 65, 61, 76, 62, 136, 84, 80, 56, 109, 116, 54, 59,
79, 34, 74.5, 54, 49, 55, 56,
             59, 56, 56, 57, 67, 65, 63, 52, 58, 59, 56, 54, 66, 92,
87, 59, 33, 58, 51, 54,
             52, 47, 45, 42, 52, 57, 79, 42, 45.5, 47, 47, 36, 50, 53, 49 )
stdev <- c(17.85, 6.31, 3.42, 1.04, 0.51, 6.04, 38.43, 2.78, 5.55,
26.72, 1.83, 9.92, 4.59, 19, 7.96,
               7.5, 1.06, 9.66, 75.94, 36.79, 50.45, 9.79, 1.55,
11.42, 64.12, 0.79, 15.14, 16.15, 8.12, 4.04, 92.57, 35.35,
               42.28, 52.96, 7.06, 4.97, 1.15, 4.77, 6.59, 7.27, 0.75,
4.25, 9, 0.1, 1.14, 4.17, 6.73, 3.81, 3.27,
               97.44, 9.74, 0.45, 8.14, 5.91, 13.1, 98.22, 8.92,
72.62, 70.26, 59.46, 29.89, 56.35, 91.25, 49.94, 20.65, 62.04,
               95.13, 35.89, 99.64, 29.44, 33.12, 45.91, 96.69, 9.05,
38.56, 3.09, 0.6, 8.69, 16.95, 74.03, 84.05, 39.87, 15.52,
               27.92, 35.72, 80.26, 71.93, 66.73, 87.8, 5.43, 98.3,
7.41, 9.86, 63.64, 0.36, 5.84, 1.58, 20.1, 4.21, 82.12,
               19.29, 9.02, 22.12, 54.08, 74.95, 3.24, 9.67, 67.98,
9.92, 40.69, 6.24, 8.76, 74.25, 46.34, 25.69, 90.63, 83.71,
               73.53, 57.88, 15.84, 82.07, 67.45, 47.39, 98.77, 75.1,
64.9, 3.71, 87.44, 61.06, 4.77, 57.54, 7.68, 4.54, 6.15,
               3.32, 60.39, 33.78, 66.22, 18.67, 76.53, 63.54, 47.06,
38.47, 88.15, 18.25, 4.26, 67.19, 88.87, 29.65, 7.33, 68.18,
               28.03, 6.91, 77.82, 22.23, 73.23, 95.21, 27.11, 37.01,
34.88, 28.15, 11.27, 15.67, 96.08, 89.52, 28.6, 8.22, 23.55,
               59.2, 36.38, 41.38, 0.4, 56.82, 32.35, 20.6, 18.13,
8.15, 1.08, 9.85, 1.07, 37.75, 97.6, 7.16, 8.51, 4.42,
               0.15, 1.28, 7.42, 71.15, 9.39)
ll <- c(70.65, 42.69, 37.58, 31.96, 34.49, 38.96, 56.57, 27.22, 35.45,
37.28, 20.17, 19.08, 54.41, 52, 120.04, 31.5, 40.94, 37.34,
        10.06, 63.21, 18.55, 34.21, 51.45, 54.58, 1.88, 70.21, 145.86,
52.85, 14.38, 25.96, -25.57, 63.65, 86.72, 41.04, 41.94, 28.03,
        26.85, 26.23, 19.41, 15.73, 29.25, 36.75, 26, 22.9, 36.86,
38.83, 8.27, 17.19, 41.73, -45.94, 24.26, 25.55, 34.86, 26.59, 45.9,
        -39.72, 52.08, -10.12, -12.26, 0.0399999999999991, 30.61,
3.65, -27.25, 60.06, 34.35, 3.96, 101.87, 47.61, 55.36, 46.56, 91.88,
44.09,
        -23.69, 74.95, 56.94, 58.91, 81.4, 129.31, 86.55, -17.03,
53.95, 109.63, 41.48, 26.08, 209.78, 110.74, 59.07, 29.27, 88.2,
39.57,
        -22.3, 25.59, 27.14, -12.64, 43.64, 44.16, 52.42, 45.9, 44.79,
7.88, 47.21, 33.48, 44.88, 1.92, -20.95, 46.76, 35.33, 31.02,
        40.08, 10.81, 205.76, 31.24, -6.25, 74.66, 54.31, -33.63,
-2.20999999999999, 54.47, 19.12, 103.66, 43.93, 116.55, 53.61, 4.23,
        12.9, 35.1, 136.29, 98.56, 235.94, 27.23, 126.46, 28.32,
40.46, 38.85, 40.68, 25.61, 31.22, -5.22, 57.33, -14.53, 72.46, 36.94,
        41.53, -32.15, 90.75, 111.74, -13.19, -29.87, 49.35, 26.67,
6.31999999999999, 25.97, 42.09, -22.82, 33.77, -14.23, -39.21, 28.89,
        19.99, 32.12, 36.85, 51.73, 36.33, -38.08, -30.52, 27.4,
45.78, 42.45, 32.8, 50.62, 17.62, 32.6, 1.18, 18.65, 33.4, 33.87,
38.85,
        43.92, 32.15, 50.93, 19.25, -18.6, 34.84, 36.99, 42.58, 46.85,
34.72, 42.58, -18.15, 39.61)
ul <- c(106.35, 55.31, 44.42, 34.04, 35.51, 51.04, 133.43, 32.78,
46.55, 90.72, 23.83, 38.92, 63.59, 90, 135.96, 46.5, 43.06, 56.66,
        161.94, 136.79, 119.45, 53.79, 54.55, 77.42, 130.12, 71.79,
176.14, 85.15, 30.62, 34.04, 159.57, 134.35, 171.28, 146.96, 56.06,
37.97,
        29.15, 35.77, 32.59, 30.27, 30.75, 45.25, 44, 23.1, 39.14,
47.17, 21.73, 24.81, 48.27, 148.94, 43.74, 26.45, 51.14, 38.41, 72.1,
        156.72, 69.92, 135.12, 128.26, 118.96, 90.39, 116.35, 155.25,
159.94, 75.65, 128.04, 292.13, 119.39, 254.64, 105.44, 158.12, 135.91,
169.69,
        93.05, 134.06, 65.09, 82.6, 146.69, 120.45, 131.03, 222.05,
189.37, 72.52, 81.92, 281.22, 271.26, 202.93, 162.73, 263.8, 50.43,
174.3,
        40.41, 46.86, 114.64, 44.36, 55.84, 55.58, 86.1, 53.21,
172.12, 85.79, 51.52, 89.12, 110.08, 128.95, 53.24, 54.67, 166.98,
59.92,
        92.19, 218.24, 48.76, 142.25, 167.34, 105.69, 147.63, 165.21,
201.53, 134.88, 135.34, 208.07, 251.45, 148.39, 201.77, 163.1, 164.9,
143.71,
        273.44, 358.06, 36.77, 241.54, 43.68, 49.54, 51.15, 47.32,
146.39, 98.78, 127.22, 94.67, 138.53, 199.54, 131.06, 118.47, 144.15,
127.25,
        120.26, 121.19, 147.87, 108.65, 41.33, 142.68, 82.03, 55.91,
132.82, 78.23, 132.23, 151.21, 83.11, 94.01, 101.88, 93.15, 74.27,
67.67,
        154.08, 148.52, 84.6, 62.22, 89.55, 151.2, 123.38, 100.38,
33.4, 114.82, 83.35, 74.6, 70.13, 55.15, 46.08, 51.85, 53.07, 94.75,
176.6,
        49.16, 54.01, 51.42, 47.15, 37.28, 57.42, 124.15, 58.39)
my.data <- data.frame(cluster, type, target, sample, average, stdev,
ll, ul, stringsAsFactors = FALSE)

library(lattice)
library(latticeExtra)

  useOuterStrips(
    strip = strip.custom(par.strip.text = list(cex = 0.75)),
    strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
    stripplot(
      average ~ type|target+cluster,
      panel = function(x,y,col,...)
        panel.superpose(x,y,col=col,...),
      panel.groups = function(x,y,col,...){
        panel.stripplot(x,y,col=col,...)
        m <- median(y)
        panel.segments(x0 = x[1] -.5, y0 = m,
                       x1 = x[1] +.5, y1 = m,
                       col=col, lwd=2
        )
      },
      my.data,
      groups = type,
      pch=1,
      jitter.data = TRUE,
      main = "Group-wise",
      xlab = expression(bold("Target")), ylab = expression(bold("Reading")),
      col = c("grey", "green", "red"),
      par.settings = list(strip.background =
list(col=c("paleturquoise", "grey"))),
      scales = list(alternating = FALSE, x=list(draw=FALSE)),
      key = list(
        space = "top",
        columns = 3,
        text = list(c("Blank", "Negative", "Positive"), col="black"),
        rectangles = list(col=c("grey", "green", "red"))
      )
    )
  )

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From shukla.kank at gmail.com  Thu Mar 30 23:37:43 2017
From: shukla.kank at gmail.com (Kankana Shukla)
Date: Thu, 30 Mar 2017 16:37:43 -0500
Subject: [R] Using R and Python together
Message-ID: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>

Hello,

I am running a deep neural network in Python.  The input to the NN is the
output from my R code. I am currently running the python script and calling
the R code using a subprocess call, but this does not allow me to
recursively change (increment) parameters used in the R code that would be
the inputs to the python code.  So in short, I would like to follow this
automated process:

   1. Parameters used in R code generate output
   2. This output is input to Python code
   3. If output of Python code > x,  stop
   4. Else, increment parameters used as input in R code (step 1) and
   repeat all steps

I have searched for examples using R and Python together, and rpy2 seems
like the way to go, but is there another (easier) way to do it?  I would
highly appreciate the help.

Thanks in advance,

Kankana

	[[alternative HTML version deleted]]


From neiljsalkind at gmail.com  Fri Mar 31 03:21:18 2017
From: neiljsalkind at gmail.com (Neil Salkind)
Date: Thu, 30 Mar 2017 20:21:18 -0500
Subject: [R] Difference between R for the Mac and for Windows
Message-ID: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>

Can someone please direct me to an answer to the question as to how R differs for these two operating systems, if at all? Thanks - Neil 

From boris.steipe at utoronto.ca  Fri Mar 31 05:40:29 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 30 Mar 2017 23:40:29 -0400
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
Message-ID: <101C74D7-D1B6-44CA-AEB5-7B026414D9DF@utoronto.ca>

I can't remember having seen my students write code that runs correctly on one platform but not the other. Obviously under the hood there are significant differences, but as far as code goes, R seems quite foolproof. There are GUI differences in base R - but AFAIK no such differences in the RStudio IDE.

B. 




> On Mar 30, 2017, at 9:21 PM, Neil Salkind <neiljsalkind at gmail.com> wrote:
> 
> Can someone please direct me to an answer to the question as to how R differs for these two operating systems, if at all? Thanks - Neil 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From liuwensui at gmail.com  Fri Mar 31 05:58:55 2017
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 31 Mar 2017 03:58:55 +0000
Subject: [R] Using R and Python together
In-Reply-To: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
Message-ID: <CAKyN3iCdpTXKTVC3DTcXkYpKrr5TrmNopas5cse=3-0=trnMCw@mail.gmail.com>

How about pyper?

On Thu, Mar 30, 2017 at 10:42 PM Kankana Shukla <shukla.kank at gmail.com>
wrote:

> Hello,
>
> I am running a deep neural network in Python.  The input to the NN is the
> output from my R code. I am currently running the python script and calling
> the R code using a subprocess call, but this does not allow me to
> recursively change (increment) parameters used in the R code that would be
> the inputs to the python code.  So in short, I would like to follow this
> automated process:
>
>    1. Parameters used in R code generate output
>    2. This output is input to Python code
>    3. If output of Python code > x,  stop
>    4. Else, increment parameters used as input in R code (step 1) and
>    repeat all steps
>
> I have searched for examples using R and Python together, and rpy2 seems
> like the way to go, but is there another (easier) way to do it?  I would
> highly appreciate the help.
>
> Thanks in advance,
>
> Kankana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Mar 31 07:36:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 30 Mar 2017 22:36:33 -0700
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <101C74D7-D1B6-44CA-AEB5-7B026414D9DF@utoronto.ca>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<101C74D7-D1B6-44CA-AEB5-7B026414D9DF@utoronto.ca>
Message-ID: <157F60E3-FDD3-4A02-BFCA-1E34898D984D@comcast.net>


> On Mar 30, 2017, at 8:40 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> I can't remember having seen my students write code that runs correctly on one platform but not the other. Obviously under the hood there are significant differences, but as far as code goes, R seems quite foolproof. There are GUI differences in base R - but AFAIK no such differences in the RStudio IDE.
> 
> B. 
> 
> 

The Mac version of R is more like the Linux version when run from the UNIX command line. RStudio and the R.app GUI's are both nice IDE's. A few packages are not available because of the need to link to programs that are only available on a particular OS. You can see which ones with a visit to the Cran package checks pages.

-- 
David


> 
> 
>> On Mar 30, 2017, at 9:21 PM, Neil Salkind <neiljsalkind at gmail.com> wrote:
>> 
>> Can someone please direct me to an answer to the question as to how R differs for these two operating systems, if at all? Thanks - Neil 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ulrik.stervbo at gmail.com  Fri Mar 31 08:23:50 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 31 Mar 2017 06:23:50 +0000
Subject: [R] Using R and Python together
In-Reply-To: <CAKyN3iCdpTXKTVC3DTcXkYpKrr5TrmNopas5cse=3-0=trnMCw@mail.gmail.com>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
	<CAKyN3iCdpTXKTVC3DTcXkYpKrr5TrmNopas5cse=3-0=trnMCw@mail.gmail.com>
Message-ID: <CAKVAULOTWYYm+d5Epeui9suZc9uC-Rub+WCDr0HHbCd7V=wKQQ@mail.gmail.com>

'Snakemake' (https://snakemake.readthedocs.io/en/stable/) was created to
ease pipelines through different tools so it might be useful.

In all honesty I only know of Snakemake, so it might be the completely
wrong horse.

HTH
Ulrik

On Fri, 31 Mar 2017 at 06:01 Wensui Liu <liuwensui at gmail.com> wrote:

> How about pyper?
>
> On Thu, Mar 30, 2017 at 10:42 PM Kankana Shukla <shukla.kank at gmail.com>
> wrote:
>
> > Hello,
> >
> > I am running a deep neural network in Python.  The input to the NN is the
> > output from my R code. I am currently running the python script and
> calling
> > the R code using a subprocess call, but this does not allow me to
> > recursively change (increment) parameters used in the R code that would
> be
> > the inputs to the python code.  So in short, I would like to follow this
> > automated process:
> >
> >    1. Parameters used in R code generate output
> >    2. This output is input to Python code
> >    3. If output of Python code > x,  stop
> >    4. Else, increment parameters used as input in R code (step 1) and
> >    repeat all steps
> >
> > I have searched for examples using R and Python together, and rpy2 seems
> > like the way to go, but is there another (easier) way to do it?  I would
> > highly appreciate the help.
> >
> > Thanks in advance,
> >
> > Kankana
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Mar 31 10:50:06 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 31 Mar 2017 10:50:06 +0200
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <101C74D7-D1B6-44CA-AEB5-7B026414D9DF@utoronto.ca>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<101C74D7-D1B6-44CA-AEB5-7B026414D9DF@utoronto.ca>
Message-ID: <1ADBD70D-EF0B-4DEF-9E0B-6C6A1A84C19A@gmail.com>

File encodings differ when you move outside of standard ASCII code. Not really R's problem, but it is a fly in the ointment when teaching classes with mixed laptop armoury and there are also differences between classroom and desktop computers. RStudio does have features to switch encodings, but I usually sidestep the issue by commenting scripts in English.

-pd 

> On 31 Mar 2017, at 05:40 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> I can't remember having seen my students write code that runs correctly on one platform but not the other. Obviously under the hood there are significant differences, but as far as code goes, R seems quite foolproof. There are GUI differences in base R - but AFAIK no such differences in the RStudio IDE.
> 
> B. 
> 
> 
> 
> 
>> On Mar 30, 2017, at 9:21 PM, Neil Salkind <neiljsalkind at gmail.com> wrote:
>> 
>> Can someone please direct me to an answer to the question as to how R differs for these two operating systems, if at all? Thanks - Neil 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From stefanML at collocations.de  Fri Mar 31 14:04:05 2017
From: stefanML at collocations.de (Stefan Evert)
Date: Fri, 31 Mar 2017 14:04:05 +0200
Subject: [R] fisher.test function error
In-Reply-To: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
References: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
Message-ID: <B8C3E00E-6D78-4F35-9FD2-E5D0B760CBF5@collocations.de>


> On 30 Mar 2017, at 11:51, Eshi Vaz <eshithasunithi2 at gmail.com> wrote:
> 
> When trying to computer a fisher?s exact test using the fisher.test function from the gmodels() package,  <----

The problem seems to be with a different fisher.test() function from the gmodels package, not with stats::fisher.test.

The usual recommendation is to contact the package authors for help.

Best regards,
Stefan

From stefanML at collocations.de  Fri Mar 31 14:08:03 2017
From: stefanML at collocations.de (Stefan Evert)
Date: Fri, 31 Mar 2017 14:08:03 +0200
Subject: [R] Using R and Python together
In-Reply-To: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
Message-ID: <986012A3-CA97-47CF-B7CB-D83DE73A2285@collocations.de>


> On 30 Mar 2017, at 23:37, Kankana Shukla <shukla.kank at gmail.com> wrote:
> 
> I have searched for examples using R and Python together, and rpy2 seems
> like the way to go, but is there another (easier) way to do it? 

Rpy2 would seem to be a very easy and convenient solution.  What do you need that can't easily be down with rpy2?

Best regards,
Stefan

From pdalgd at gmail.com  Fri Mar 31 14:21:42 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 31 Mar 2017 14:21:42 +0200
Subject: [R] fisher.test function error
In-Reply-To: <B8C3E00E-6D78-4F35-9FD2-E5D0B760CBF5@collocations.de>
References: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
	<B8C3E00E-6D78-4F35-9FD2-E5D0B760CBF5@collocations.de>
Message-ID: <ABB6DF6C-CA65-4D9B-A0D9-62B08D6D5A1A@gmail.com>


> On 31 Mar 2017, at 14:04 , Stefan Evert <stefanML at collocations.de> wrote:
> 
> 
>> On 30 Mar 2017, at 11:51, Eshi Vaz <eshithasunithi2 at gmail.com> wrote:
>> 
>> When trying to computer a fisher?s exact test using the fisher.test function from the gmodels() package,  <----
> 
> The problem seems to be with a different fisher.test() function from the gmodels package, not with stats::fisher.test.

That's what I thought, but there is no fisher.test variant in gmodels. There is CrossTable, which calls fisher.test in its print method, but as far as I can tell, that is the usual one from stats.

At any rate, it would be useful to know what the table looks like. If has a huge number of rows or columns then

(a) it could be the result of a coding blunder
(b) be quite meaninglesss to attack with a fisher exact test


-pd

> 
> The usual recommendation is to contact the package authors for help.
> 
> Best regards,
> Stefan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_schwartz at me.com  Fri Mar 31 14:45:18 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 31 Mar 2017 07:45:18 -0500
Subject: [R] fisher.test function error
In-Reply-To: <B8C3E00E-6D78-4F35-9FD2-E5D0B760CBF5@collocations.de>
References: <966725BC-E5CE-498B-9DD3-4009459A28F3@gmail.com>
	<B8C3E00E-6D78-4F35-9FD2-E5D0B760CBF5@collocations.de>
Message-ID: <1C452AAB-C054-4D27-9ECB-6D0BADBDF944@me.com>


> On Mar 31, 2017, at 7:04 AM, Stefan Evert <stefanML at collocations.de> wrote:
> 
> 
>> On 30 Mar 2017, at 11:51, Eshi Vaz <eshithasunithi2 at gmail.com> wrote:
>> 
>> When trying to computer a fisher?s exact test using the fisher.test function from the gmodels() package,  <----
> 
> The problem seems to be with a different fisher.test() function from the gmodels package, not with stats::fisher.test.
> 
> The usual recommendation is to contact the package authors for help.
> 
> Best regards,
> Stefan


There is no fisher.test() function in the gmodels package. 

The error message is being generated from compiled code in stats::fisher.test().

A Google search for the error message indicates that there are reports going back at least as far as 2002, suggesting that the underlying issue is an integer overflow:

  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=1662

with at least one example resolved back in 2005:

  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=6986

The former report has recent reports from 2014/2015 suggesting that the original 2002 issue is still present, at least in specific situations:

d4 <- matrix(c(0, 0, 0, 0, 0,  0, 3, 0, 1, 0,  0, 0, 0, 0, 0,
               1, 0, 0, 0, 0,  1, 0, 0, 2, 0,  0, 0, 1, 0, 0,
               0, 1, 0, 1, 0,  4, 0, 2, 0, 0,  0, 1, 0, 0, 0,  0, 0, 0, 0, 0,
               0, 1, 0, 0, 2,  0, 0, 0, 2, 2,  0, 1, 0, 0, 0,
               0, 0, 1, 1, 0,  0, 0, 0, 0, 0,  0, 1, 0, 0, 0,
               1, 0, 0, 0, 2,  0, 0, 0, 3, 0,  0, 0, 0, 0, 1,  0, 0, 0, 0, 0,
               2, 0, 0, 0, 0,  0, 0, 0, 0, 0,  0, 0, 1, 0, 1,
               0, 0, 0, 0, 2,  0, 0, 0, 0, 8,  0, 0, 0, 3, 0,
               0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  0, 0, 0, 0, 1,
               0, 0, 1, 0, 0,  0, 0, 0, 0, 0,  2, 0, 0, 1, 0,
               0, 2, 0, 0, 0,  0, 2, 0, 0, 1,  3, 0, 0, 0, 0,
               0, 0, 0, 0, 0,  0, 0, 0, 0, 1,  0, 0, 1, 0, 0,  4, 0, 0, 0, 0),
             nr=50)

> fisher.test(d4)
Error in fisher.test(d4) : FEXACT error 30.
Stack length exceeded in f3xact.
This problem should not occur.


tab <- structure(list(V1 = c(1, 0, 0, 0, 0, 0), 
                      V2 = c(323, 4, 1, 0, 0, 22), 
                      V3 = c(3, 0, 0, 0, 0, 1), 
                      V4 = c(2, 0, 1, 0, 1, 3), 
                      V5 = c(1, 0, 0, 0, 0, 4), 
                      V6 = c(1, 0, 0, 0, 0, 0), 
                      V7 = c(0, 0, 0, 1, 0, 1), 
                      V8 = c(96, 0, 0, 0, 0, 2)), 
                      .Names = c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8"), 
                      class = "data.frame", row.names = c(NA, -6L))

> fisher.test(tab)
Error in fisher.test(tab) : Bug in FEXACT: gave negative key


Note that in the second example, the data frame is coerced to a matrix inside fisher.test().

The above two examples were run using R version 3.3.3 on macOS 10.12.4 in a CLI console.

Regards,

Marc Schwartz


From istazahn at gmail.com  Fri Mar 31 14:47:45 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 31 Mar 2017 08:47:45 -0400
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
Message-ID: <CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>

The only place I've noticed differences is in encoding and string sorting,
both of which are locale and library dependent.

Best,
Ista

On Mar 31, 2017 8:14 AM, "Neil Salkind" <neiljsalkind at gmail.com> wrote:

> Can someone please direct me to an answer to the question as to how R
> differs for these two operating systems, if at all? Thanks - Neil
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deanforce14 at gmail.com  Fri Mar 31 17:58:10 2017
From: deanforce14 at gmail.com (Dean Force)
Date: Fri, 31 Mar 2017 11:58:10 -0400
Subject: [R] conditional regression with mgcv
Message-ID: <CAEd09GSbJ1D6j6exLuR3X66=aOAvgXvjLwtvwVaZ8TY3yezg3A@mail.gmail.com>

Hello,


As a part of a larger project, I am trying to run a conditional logistic
regression to look at whether maternal age is implicated in the risk of
developing gestational diabetes. I am using a matched case-control design,
where mothers with GDM were individually matched with up to 6 controls
based on several parameters.


I run the following model:


model <- gam(gdm ~ s(maternal_age, bs="cr") + strata(risk_set) +
as.factor(district) + as.factor(riskfactor1)+as.factor(riskfactor2), data =
dt, family=cox.ph(), weights = wt)



weights are defined as 0 for censoring, 1 for event, and each subject has
one event/censoring time and one row of covariate values. In total there
are 1000 cases, matched to 5500 controls, so there are 1000 risk_set that I
define as strata.

When running the model, I keep getting the following error: ?Error in
xat[[i]] : subscript out of bounds?. Am I doing something wrong?

Using mgcv_1.8.



Thank you!

	[[alternative HTML version deleted]]


From br at dmstat1.com  Fri Mar 31 18:20:13 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 31 Mar 2017 12:20:13 -0400
Subject: [R] Taking the sum of only some columns of a data frame
Message-ID: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>

Hi R'ers:
Given a data.frame of five columns and ten rows. 
I would like to take the sum of, say, the first and third columns only.
For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows. 

Thanks, in advance. 
Bruce 


______________
Bruce Ratner PhD
The Significant Statistician?




	[[alternative HTML version deleted]]


From HDoran at air.org  Fri Mar 31 18:33:57 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 31 Mar 2017 16:33:57 +0000
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D39E50@DC1VEX10MB01.air.org>

I do not believe this can be done in one step

dat <- data.frame(matrix(rnorm(50), 5))

 pos <- c(1,3)
res <-  apply(dat[, pos], 2, sum)

 x <- numeric(5)
 x[pos] <- res

rbind(dat,x)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bruce Ratner PhD
Sent: Friday, March 31, 2017 12:20 PM
To: r-help at r-project.org
Subject: [R] Taking the sum of only some columns of a data frame

Hi R'ers:
Given a data.frame of five columns and ten rows. 
I would like to take the sum of, say, the first and third columns only.
For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows. 

Thanks, in advance. 
Bruce 


______________
Bruce Ratner PhD
The Significant Statistician?




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From HDoran at air.org  Fri Mar 31 18:35:52 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 31 Mar 2017 16:35:52 +0000
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D39E50@DC1VEX10MB01.air.org>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD6860141D39E50@DC1VEX10MB01.air.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D39E83@DC1VEX10MB01.air.org>

Apologies, my code below has an error that recycles the vector x. Hopefully, the concept is clear.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Friday, March 31, 2017 12:34 PM
To: 'Bruce Ratner PhD' <br at dmstat1.com>; r-help at r-project.org
Subject: Re: [R] Taking the sum of only some columns of a data frame

I do not believe this can be done in one step

dat <- data.frame(matrix(rnorm(50), 5))

 pos <- c(1,3)
res <-  apply(dat[, pos], 2, sum)

 x <- numeric(5)
 x[pos] <- res

rbind(dat,x)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bruce Ratner PhD
Sent: Friday, March 31, 2017 12:20 PM
To: r-help at r-project.org
Subject: [R] Taking the sum of only some columns of a data frame

Hi R'ers:
Given a data.frame of five columns and ten rows. 
I would like to take the sum of, say, the first and third columns only.
For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows. 

Thanks, in advance. 
Bruce 


______________
Bruce Ratner PhD
The Significant Statistician?




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Fri Mar 31 18:40:40 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 31 Mar 2017 09:40:40 -0700
Subject: [R] Date operation Question in R
In-Reply-To: <3a4dce28-2813-ad41-1528-d7c012f0e3c8@simecol.de>
References: <CAMOcQfO94JDOC2n=3YSAii4CmQZzUshp9R4vkSRtDGZA5cqA5g@mail.gmail.com>
	<3a4dce28-2813-ad41-1528-d7c012f0e3c8@simecol.de>
Message-ID: <63393726-C1F7-47FC-9820-64F3FF394184@comcast.net>


> On Mar 30, 2017, at 3:16 PM, Thomas Petzoldt <thpe at simecol.de> wrote:
> 
> On 30.03.2017 23:34, Paul Bernal wrote:
>> Hello everyone,
>> 
>> Is there a way to use the function seq to generate a date sequence in
>> this kind of format: jan-2007?
> 
> format(seq(ISOdate(2017,1,1), ISOdate(2017,12,31), "months"), "%b-%Y")

But since the original one asked for a starting point of Sys.Date, on this 31st day of March, it might be useful to demonstrate that there are pifalls for the uninitiated useR. Note the many duplicate "months":

> format(seq(ISOdate(2017,1,31), ISOdate(2018,12,31), "months"), "%b-%Y")
 [1] "Jan-2017" "Mar-2017" "Mar-2017" "May-2017" "May-2017" "Jul-2017" "Jul-2017"
 [8] "Aug-2017" "Oct-2017" "Oct-2017" "Dec-2017" "Dec-2017" "Jan-2018" "Mar-2018"
[15] "Mar-2018" "May-2018" "May-2018" "Jul-2018" "Jul-2018" "Aug-2018" "Oct-2018"
[22] "Oct-2018" "Dec-2018" "Dec-2018"

-- 
David.
> 
>> 
>> Also, is there a way to change the Sys.Date() format to the one
>> mentioned above (jan-2007)?
> 
> format(Sys.Date(), "%b-%Y")
> 
> see ?strptime for details.
> 
> Thomas
> 
>> 
>> Thanks in advance for your valuable help,
>> 
>> Best regards,
>> 
>> Paul
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shukla.kank at gmail.com  Fri Mar 31 18:38:16 2017
From: shukla.kank at gmail.com (Kankana Shukla)
Date: Fri, 31 Mar 2017 11:38:16 -0500
Subject: [R] Using R and Python together
In-Reply-To: <986012A3-CA97-47CF-B7CB-D83DE73A2285@collocations.de>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
	<986012A3-CA97-47CF-B7CB-D83DE73A2285@collocations.de>
Message-ID: <CAN8Bj0nOO-FCPucGXC_x0AtdYzFAsECv7ifKsXQnO4M1aHY=GQ@mail.gmail.com>

I'm not great at rpy2.  Are there any good examples I could see to learn
how to do that?  My R code is very long and complicated.

On Fri, Mar 31, 2017 at 7:08 AM, Stefan Evert <stefanML at collocations.de>
wrote:

>
> > On 30 Mar 2017, at 23:37, Kankana Shukla <shukla.kank at gmail.com> wrote:
> >
> > I have searched for examples using R and Python together, and rpy2 seems
> > like the way to go, but is there another (easier) way to do it?
>
> Rpy2 would seem to be a very easy and convenient solution.  What do you
> need that can't easily be down with rpy2?
>
> Best regards,
> Stefan

	[[alternative HTML version deleted]]


From HDoran at air.org  Fri Mar 31 19:06:46 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 31 Mar 2017 17:06:46 +0000
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <62A6D137-4E4D-40E8-8C0F-0CC287583495@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD6860141D39E50@DC1VEX10MB01.air.org>
	<62A6D137-4E4D-40E8-8C0F-0CC287583495@dmstat1.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D39EFB@DC1VEX10MB01.air.org>

Let's keep r-list on the email per typical protocol. Apply is a function in base R, so you don't need to install it

-----Original Message-----
From: Bruce Ratner PhD [mailto:br at dmstat1.com] 
Sent: Friday, March 31, 2017 1:06 PM
To: Doran, Harold <HDoran at air.org>
Subject: Re: [R] Taking the sum of only some columns of a data frame

Hey Harold:
Thanks for quick reply. 
But, I can't install "apply."

Is there anything you can suggest to get my install of apply on R 3.3.3, or a work around of your original answer?

Thanks, so much. 
Bruce 

______________
Bruce Ratner PhD
The Significant Statistician?




> On Mar 31, 2017, at 12:33 PM, Doran, Harold <HDoran at air.org> wrote:
> 
> apply


From bhh at xs4all.nl  Fri Mar 31 19:15:55 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 31 Mar 2017 19:15:55 +0200
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
Message-ID: <5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>


I have noted a difference between R on macOS en on Kubuntu Trusty (64bits) with complex division.
I don't know what would happen R on Windows.

R.3.3.3:

macOS (10.11.6)
-----------------
> (1+2i)/0
[1] NaN+NaNi
> (-1+2i)/0
[1] NaN+NaNi
> 
> 1i/0
[1] NaN+NaNi
> 1i/(0+0i)
[1] NaN+NaNi


KubuntuTrusty
-----------------
> (1+2i)/0
[1] Inf+Infi
> (-1+2i)/0
[1] -Inf+Infi
> 
> 1i/0
[1] NaN+Infi
> 1i/(0+0i)
[1] NaN+Infi

Interesting to see what R on Windows delivers.

Berend Hasselman


From wdunlap at tibco.com  Fri Mar 31 19:19:39 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 31 Mar 2017 10:19:39 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
Message-ID: <CAF8bMcYP88+CiwLR_XRBnFZht+r107Leua3sKFEJHuqApn+QiQ@mail.gmail.com>

> dat <- data.frame(Group=LETTERS[1:5], X=1:5, Y=11:15)
> pos <- c(2,3)
> rbind(dat, Sum=lapply(seq_len(ncol(dat)), function(i) if (i %in% pos) sum(dat[,i]) else NA_real_))
    Group  X  Y
1       A  1 11
2       B  2 12
3       C  3 13
4       D  4 14
5       E  5 15
Sum  <NA> 15 65
> str(.Last.value)
'data.frame':   6 obs. of  3 variables:
 $ Group: Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5 NA
 $ X    : int  1 2 3 4 5 15
 $ Y    : int  11 12 13 14 15 65
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> Hi R'ers:
> Given a data.frame of five columns and ten rows.
> I would like to take the sum of, say, the first and third columns only.
> For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows.
>
> Thanks, in advance.
> Bruce
>
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Fri Mar 31 19:22:25 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 31 Mar 2017 19:22:25 +0200
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
	<5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
Message-ID: <4c83eae3-c3e5-3a2a-6384-e7cdc9636474@statistik.tu-dortmund.de>



On 31.03.2017 19:15, Berend Hasselman wrote:
>
> I have noted a difference between R on macOS en on Kubuntu Trusty (64bits) with complex division.
> I don't know what would happen R on Windows.
>
> R.3.3.3:
>
> macOS (10.11.6)
> -----------------
>> (1+2i)/0
> [1] NaN+NaNi
>> (-1+2i)/0
> [1] NaN+NaNi
>>
>> 1i/0
> [1] NaN+NaNi
>> 1i/(0+0i)
> [1] NaN+NaNi
>
>
> KubuntuTrusty
> -----------------
>> (1+2i)/0
> [1] Inf+Infi
>> (-1+2i)/0
> [1] -Inf+Infi
>>
>> 1i/0
> [1] NaN+Infi
>> 1i/(0+0i)
> [1] NaN+Infi
>
> Interesting to see what R on Windows delivers.

Same as KubuntuTrusty and what I would expect.

Best,
Uwe Ligges



>
> Berend Hasselman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Fri Mar 31 19:28:25 2017
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 31 Mar 2017 12:28:25 -0500
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
	<5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
Message-ID: <CAAJSdjhmE-Q5aP5_aAdn0v+KqE+X46rD_UXjhNGgJLt=BPn=-A@mail.gmail.com>

On Fri, Mar 31, 2017 at 12:15 PM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> I have noted a difference between R on macOS en on Kubuntu Trusty (64bits)
> with complex division.
> I don't know what would happen R on Windows.
>
> R.3.3.3:
>
> macOS (10.11.6)
> -----------------
> > (1+2i)/0
> [1] NaN+NaNi
> > (-1+2i)/0
> [1] NaN+NaNi
> >
> > 1i/0
> [1] NaN+NaNi
> > 1i/(0+0i)
> [1] NaN+NaNi
>
>
> KubuntuTrusty
> -----------------
> > (1+2i)/0
> [1] Inf+Infi
> > (-1+2i)/0
> [1] -Inf+Infi
> >
> > 1i/0
> [1] NaN+Infi
> > 1i/(0+0i)
> [1] NaN+Infi
>
> Interesting to see what R on Windows delivers.
>

?> (1+2i)/0
[1] Inf+Infi
> (-1+2i)/0
[1] -Inf+Infi
> 1i/0
[1] NaN+Infi
> 1i/(0+0i)
[1] NaN+Infi
> Sys.info()
                     sysname                      release
                   "Windows"                      "7 x64"
                     version                     nodename
"build 7601, Service Pack 1"                 "IT-JMCKOWN"
                     machine                        login
                    "x86-64"                "John.Mckown"
                        user               effective_user
               "John.Mckown"                "John.Mckown"
>

Same as Kubuntu. I am _guessing_ that the MacOS somehow sets up the
floating point processing to work differently, since they are all on Intel
machines nowadays. Or the R was customized to detect division by zero in
software and not really do any floating point processing at all.
?

>
> Berend Hasselman
>
>

-- 
"Irrigation of the land with seawater desalinated by fusion power is
ancient. It's called 'rain'." -- Michael McClary, in alt.fusion

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Fri Mar 31 19:37:24 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 31 Mar 2017 19:37:24 +0200
Subject: [R] Difference between R for the Mac and for Windows
In-Reply-To: <CAAJSdjhmE-Q5aP5_aAdn0v+KqE+X46rD_UXjhNGgJLt=BPn=-A@mail.gmail.com>
References: <DFE7AFAB-E49B-4317-A44B-4EC1A2622D1C@gmail.com>
	<CA+vqiLE63fFOFwk88+DbEF7MgkEhV_dJSB4W7ZxeGwVGK0TW+g@mail.gmail.com>
	<5F8D42CD-8C83-4945-BBA0-83A43B29E48E@xs4all.nl>
	<CAAJSdjhmE-Q5aP5_aAdn0v+KqE+X46rD_UXjhNGgJLt=BPn=-A@mail.gmail.com>
Message-ID: <1859410A-8249-4A64-BC01-7D2E4D7C513A@xs4all.nl>


> On 31 Mar 2017, at 19:28, John McKown <john.archie.mckown at gmail.com> wrote:
> 
> On Fri, Mar 31, 2017 at 12:15 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> I have noted a difference between R on macOS en on Kubuntu Trusty (64bits) with complex division.
> I don't know what would happen R on Windows.
> 
> R.3.3.3:
> 
> macOS (10.11.6)
> -----------------
> > (1+2i)/0
> [1] NaN+NaNi
> > (-1+2i)/0
> [1] NaN+NaNi
> >
> > 1i/0
> [1] NaN+NaNi
> > 1i/(0+0i)
> [1] NaN+NaNi
> 
> 
> KubuntuTrusty
> -----------------
> > (1+2i)/0
> [1] Inf+Infi
> > (-1+2i)/0
> [1] -Inf+Infi
> >
> > 1i/0
> [1] NaN+Infi
> > 1i/(0+0i)
> [1] NaN+Infi
> 
> Interesting to see what R on Windows delivers.
> 
> ?> (1+2i)/0
> [1] Inf+Infi
> > (-1+2i)/0
> [1] -Inf+Infi
> > 1i/0
> [1] NaN+Infi
> > 1i/(0+0i)
> [1] NaN+Infi
> > Sys.info()
>                      sysname                      release 
>                    "Windows"                      "7 x64" 
>                      version                     nodename 
> "build 7601, Service Pack 1"                 "IT-JMCKOWN" 
>                      machine                        login 
>                     "x86-64"                "John.Mckown" 
>                         user               effective_user 
>                "John.Mckown"                "John.Mckown" 
> > 
> 
> Same as Kubuntu. I am _guessing_ that the MacOS somehow sets up the floating point processing to work differently, since they are all on Intel machines nowadays. Or the R was customized to detect division by zero in software and not really do any floating point processing at all.
> ?
> 

I think it's the system math library that does this.

I have assumed that the Kubuntu Trusty (and Windows) give the correct result.
In my package geigen I have taken that into account and made a specialized complexdivision function that tries to detect a possibly wrong outcome (which appears to happen only on macOS).

Berend Hasselman

> Berend Hasselman
> 
> 
> 
> -- 
> "Irrigation of the land with seawater desalinated by fusion power is ancient. It's called 'rain'." -- Michael McClary, in alt.fusion
> 
> Maranatha! <><
> John McKown


From wjm1 at caa.columbia.edu  Fri Mar 31 19:46:26 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Fri, 31 Mar 2017 10:46:26 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
Message-ID: <CAA99HCwj-qV9rbBG8xaAiUzFrw84a0jsmbQWONQdfYZNSv2vPA@mail.gmail.com>

I'm sure there are more efficient ways, but this works:

> test1 <- matrix(runif(50), nrow=10, ncol=5)
> ## test1 <- as.data.frame(test1)
> test1 <- rbind(test1, NA)
> test1[11, c(1,3)] <- colSums(test1[1:10,c(1,3)])
> test1


HTH,

Bill.

William Michels, Ph.D.



On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>
> Hi R'ers:
> Given a data.frame of five columns and ten rows.
> I would like to take the sum of, say, the first and third columns only.
> For the remaining columns, I do not want any calculations, thus rending their "values" on the "total" row blank. The sum/total row is to be combined to the original data.frame, yielding a data.frame with five columns and eleven rows.
>
> Thanks, in advance.
> Bruce
>
>
> ______________
> Bruce Ratner PhD
> The Significant Statistician?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From liuwensui at gmail.com  Fri Mar 31 20:35:44 2017
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 31 Mar 2017 13:35:44 -0500
Subject: [R] Using R and Python together
In-Reply-To: <CAN8Bj0nOO-FCPucGXC_x0AtdYzFAsECv7ifKsXQnO4M1aHY=GQ@mail.gmail.com>
References: <CAN8Bj0kPOxR+X5O+iUDPPPB2qMUiEPWE7XGPdMoZQNd_DjGOAw@mail.gmail.com>
	<986012A3-CA97-47CF-B7CB-D83DE73A2285@collocations.de>
	<CAN8Bj0nOO-FCPucGXC_x0AtdYzFAsECv7ifKsXQnO4M1aHY=GQ@mail.gmail.com>
Message-ID: <CAKyN3iB-Xr7xwUfU0tsb5RjDDSOG3voWvLOfHPUEevxOSCEeNw@mail.gmail.com>

In https://statcompute.wordpress.com/?s=rpy2, you can find examples of rpy2.

In https://statcompute.wordpress.com/?s=pyper, you can find examples of pyper.

On Fri, Mar 31, 2017 at 11:38 AM, Kankana Shukla <shukla.kank at gmail.com> wrote:
> I'm not great at rpy2.  Are there any good examples I could see to learn
> how to do that?  My R code is very long and complicated.
>
> On Fri, Mar 31, 2017 at 7:08 AM, Stefan Evert <stefanML at collocations.de>
> wrote:
>
>>
>> > On 30 Mar 2017, at 23:37, Kankana Shukla <shukla.kank at gmail.com> wrote:
>> >
>> > I have searched for examples using R and Python together, and rpy2 seems
>> > like the way to go, but is there another (easier) way to do it?
>>
>> Rpy2 would seem to be a very easy and convenient solution.  What do you
>> need that can't easily be down with rpy2?
>>
>> Best regards,
>> Stefan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Fri Mar 31 22:05:09 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Fri, 31 Mar 2017 13:05:09 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <11fcc6a3-39ef-6d93-f1cc-3fbca3b22698@dmstat1.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<CAA99HCwj-qV9rbBG8xaAiUzFrw84a0jsmbQWONQdfYZNSv2vPA@mail.gmail.com>
	<11fcc6a3-39ef-6d93-f1cc-3fbca3b22698@dmstat1.com>
Message-ID: <CAA99HCwD0oEwi5rOrGK_-rri+=mmU0wvv_wWzSVTQ9fkdtVc_A@mail.gmail.com>

Again, you should always copy the R-help list on replies to your OP.

The short answer is you **shouldn't** replace NAs with blanks in your
matrix or dataframe.  NA is the proper designation for those cell
positions. Replacing NA with a "blank" in a dataframe will convert
that column to a "character" mode, precluding further numeric
manipulation of those columns.

Consider your workflow:  are you tying to export a table? If so, take
a look at installing pander (see 'missing' argument on webpage below):

https://cran.r-project.org/web/packages/pander/README.html

Finally, please review the Introductory PDF, available here:

https://cran.r-project.org/doc/manuals/R-intro.pdf

HTH, Bill.

William Michels, Ph.D.



On Fri, Mar 31, 2017 at 11:21 AM, BR_email <br at dmstat1.com> wrote:
> William:
> How can I replace the "NAs" with blanks?
> Bruce
>
> Bruce Ratner, Ph.D.
> The Significant Statistician?
>
>
> William Michels wrote:
>>
>> I'm sure there are more efficient ways, but this works:
>>
>>> test1 <- matrix(runif(50), nrow=10, ncol=5)
>>> ## test1 <- as.data.frame(test1)
>>> test1 <- rbind(test1, NA)
>>> test1[11, c(1,3)] <- colSums(test1[1:10,c(1,3)])
>>> test1
>>
>>
>> HTH,
>>
>> Bill.
>>
>> William Michels, Ph.D.
>>
>>
>>
>> On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>>>
>>> Hi R'ers:
>>> Given a data.frame of five columns and ten rows.
>>> I would like to take the sum of, say, the first and third columns only.
>>> For the remaining columns, I do not want any calculations, thus rending
>>> their "values" on the "total" row blank. The sum/total row is to be combined
>>> to the original data.frame, yielding a data.frame with five columns and
>>> eleven rows.
>>>
>>> Thanks, in advance.
>>> Bruce
>>>
>>>
>>> ______________
>>> Bruce Ratner PhD
>>> The Significant Statistician?
>>>
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>


From axel.urbiz at gmail.com  Fri Mar 31 23:43:07 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 31 Mar 2017 17:43:07 -0400
Subject: [R] Deploying R on the cloud - Help Please
Message-ID: <CAAyVsX+zVVJ-r3GCE=jHvF=wN4LvTPz+sMfd0YH2Ack=ADA6Zg@mail.gmail.com>

Hello,

I work for a large organization who is looking to productionize (deploy)
models built in R on the cloud. Currently, we were looking into IBM
Bluemix, but I?ve been told only Python is supported for model deployment.

I?d appreciate if anyone can point me to the right direction here in terms
of best practices / companies that support deploying R models on the cloud.



Thank you for your help.

Regards,

Axel.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar 31 23:49:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 31 Mar 2017 14:49:16 -0700
Subject: [R] Taking the sum of only some columns of a data frame
In-Reply-To: <CAA99HCwD0oEwi5rOrGK_-rri+=mmU0wvv_wWzSVTQ9fkdtVc_A@mail.gmail.com>
References: <CDC5E133-8B03-4126-ACFA-237B3E1F33F2@dmstat1.com>
	<CAA99HCwj-qV9rbBG8xaAiUzFrw84a0jsmbQWONQdfYZNSv2vPA@mail.gmail.com>
	<11fcc6a3-39ef-6d93-f1cc-3fbca3b22698@dmstat1.com>
	<CAA99HCwD0oEwi5rOrGK_-rri+=mmU0wvv_wWzSVTQ9fkdtVc_A@mail.gmail.com>
Message-ID: <B3EDDFBE-C1E4-4A5B-9DB7-C2E78E680923@dcn.davis.ca.us>

You can also look at the knitr-RMarkdown work flow, or the knitr-latex work flow. In both of these it is reasonable to convert your data frame to a temporary character-only form purely for output purposes. However, one can usually use an existing function to push your results out without damaging your working data. 

It is important to separate your data from your output because mixing results (totals) with data makes using the data further extremely difficult. Mixing them is one of the major flaws of the spreadsheet model of computation, and it causes problems there as well as in R.
-- 
Sent from my phone. Please excuse my brevity.

On March 31, 2017 1:05:09 PM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>Again, you should always copy the R-help list on replies to your OP.
>
>The short answer is you **shouldn't** replace NAs with blanks in your
>matrix or dataframe.  NA is the proper designation for those cell
>positions. Replacing NA with a "blank" in a dataframe will convert
>that column to a "character" mode, precluding further numeric
>manipulation of those columns.
>
>Consider your workflow:  are you tying to export a table? If so, take
>a look at installing pander (see 'missing' argument on webpage below):
>
>https://cran.r-project.org/web/packages/pander/README.html
>
>Finally, please review the Introductory PDF, available here:
>
>https://cran.r-project.org/doc/manuals/R-intro.pdf
>
>HTH, Bill.
>
>William Michels, Ph.D.
>
>
>
>On Fri, Mar 31, 2017 at 11:21 AM, BR_email <br at dmstat1.com> wrote:
>> William:
>> How can I replace the "NAs" with blanks?
>> Bruce
>>
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>>
>>
>> William Michels wrote:
>>>
>>> I'm sure there are more efficient ways, but this works:
>>>
>>>> test1 <- matrix(runif(50), nrow=10, ncol=5)
>>>> ## test1 <- as.data.frame(test1)
>>>> test1 <- rbind(test1, NA)
>>>> test1[11, c(1,3)] <- colSums(test1[1:10,c(1,3)])
>>>> test1
>>>
>>>
>>> HTH,
>>>
>>> Bill.
>>>
>>> William Michels, Ph.D.
>>>
>>>
>>>
>>> On Fri, Mar 31, 2017 at 9:20 AM, Bruce Ratner PhD <br at dmstat1.com>
>wrote:
>>>>
>>>> Hi R'ers:
>>>> Given a data.frame of five columns and ten rows.
>>>> I would like to take the sum of, say, the first and third columns
>only.
>>>> For the remaining columns, I do not want any calculations, thus
>rending
>>>> their "values" on the "total" row blank. The sum/total row is to be
>combined
>>>> to the original data.frame, yielding a data.frame with five columns
>and
>>>> eleven rows.
>>>>
>>>> Thanks, in advance.
>>>> Bruce
>>>>
>>>>
>>>> ______________
>>>> Bruce Ratner PhD
>>>> The Significant Statistician?
>>>>
>>>>
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pittbox33 at gmail.com  Fri Mar 31 20:16:02 2017
From: pittbox33 at gmail.com (Piotr Koller)
Date: Fri, 31 Mar 2017 20:16:02 +0200
Subject: [R] Variation of bubble sort (based on divisors)
Message-ID: <CA+0Zh7z2fOUTb4eh=7HiVx4=YOoq=Zx=30ysZcka4Vpkr1V2-w@mail.gmail.com>

Hi, I'd like to create a function that will sort values of a vector on a
given basis:

-zeros

-ones

-numbers divisible by 2

-numbers divisible by 3 (but not by 2)

-numbers divisible by 5 (but not by 2 and 3)

etc.

I also want to omit zeros in those turns. So when I have a given vector of
c(0:10), I want to receive 0 1 2 4 6 8 10 3 9 5 7 I think it'd be the best
to use some variation of bubble sort, so it'd look like that

sort <- function(x) {
 for (j in (length(x)-1):1) {
   for (i in j:(length(x)-1)) {
     if (x[i+1]%%divisor==0 && x[i]%%divisor!=0) {
      temp <- x[i]
      x[i] <- x[i+1]
      x[i+1] <- temp
      }
    }
  }
 return(x)}

This function works out well on a given divisor and incresing sequences.

sort <- function(x) {
  for (j in (length(x)-1):1) {
     for (i in j:(length(x)-1)) {
       if (x[i+1]%%5==0 && x[i]%%5!=0) {
        temp <- x[i]
        x[i] <- x[i+1]
        x[i+1] <- temp
       }
      }
     }
  return(x)
 }

x <- c(1:10)
print(x)
print(bubblesort(x))

This function does its job. It moves values divisible by 5 on the
beginning. The question is how to increase divisor every "round" ?

Thanks for any kind of help

	[[alternative HTML version deleted]]


