From sven.templer at gmail.com  Wed Apr  1 00:18:23 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 1 Apr 2015 00:18:23 +0200
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
Message-ID: <CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>

If you don't mind an extra column, you could use something similar to:

data.frame(r=seq(8),foo=NA,bar=NA)

If you do, here is another approach (see function body):

empty.frame <- function (r = 1, n = 1, fill = NA_real_) {
  data.frame(setNames(lapply(rep(fill, length(n)), rep, times=r), n))
}
empty.frame()
empty.frame(, seq(3))
empty.frame(8, c("foo", "bar"))

I could not put it in one line either, without retyping at least one
argument (n in this case).
So I suggest a function is the way to go for a simplified syntax ...

Thanks to all for the ideas!
Sven

On 31 March 2015 at 20:55, William Dunlap <wdunlap at tibco.com> wrote:

> You can use structure() to attach the names to a list that is input to
> data.frame.
> E.g.,
>
> dfNames <- c("First", "Second Name")
> data.frame(lapply(structure(dfNames, names=dfNames),
> function(name)rep(NA_real_, 5)))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
> > Hi,
> >
> > Duncan Murdoch suggested:
> >
> > > The matrix() function has a dimnames argument, so you could do this:
> > >
> > > names <- c("strat", "id", "pid")
> > > data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
> >
> > That's a definite improvement, thanks. But no way to skip matrix()? It
> > just seems unRlike, although since it's only full of NA values there
> > are no coercion issues with column types or anything, so it doesn't
> > hurt. It's just inelegant. :)
> >
> > Sarah
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Wed Apr  1 00:35:40 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 31 Mar 2015 18:35:40 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>
Message-ID: <CAGx1TMAM_4T34Qeh3Jp-n--92ap67-U4PPSNNoURbR5_Dwda_A@mail.gmail.com>

I got rid of the extra column.

data.frame(r=seq(8), foo=NA, bar=NA, row.names="r")

Rich

On Tue, Mar 31, 2015 at 6:18 PM, Sven E. Templer <sven.templer at gmail.com> wrote:
> If you don't mind an extra column, you could use something similar to:
>
> data.frame(r=seq(8),foo=NA,bar=NA)
>
> If you do, here is another approach (see function body):
>
> empty.frame <- function (r = 1, n = 1, fill = NA_real_) {
>   data.frame(setNames(lapply(rep(fill, length(n)), rep, times=r), n))
> }
> empty.frame()
> empty.frame(, seq(3))
> empty.frame(8, c("foo", "bar"))
>
> I could not put it in one line either, without retyping at least one
> argument (n in this case).
> So I suggest a function is the way to go for a simplified syntax ...
>
> Thanks to all for the ideas!
> Sven
>
> On 31 March 2015 at 20:55, William Dunlap <wdunlap at tibco.com> wrote:
>
>> You can use structure() to attach the names to a list that is input to
>> data.frame.
>> E.g.,
>>
>> dfNames <- c("First", "Second Name")
>> data.frame(lapply(structure(dfNames, names=dfNames),
>> function(name)rep(NA_real_, 5)))
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>> > Hi,
>> >
>> > Duncan Murdoch suggested:
>> >
>> > > The matrix() function has a dimnames argument, so you could do this:
>> > >
>> > > names <- c("strat", "id", "pid")
>> > > data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>> >
>> > That's a definite improvement, thanks. But no way to skip matrix()? It
>> > just seems unRlike, although since it's only full of NA values there
>> > are no coercion issues with column types or anything, so it doesn't
>> > hurt. It's just inelegant. :)
>> >
>> > Sarah
>> > --
>> > Sarah Goslee
>> > http://www.functionaldiversity.org
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Apr  1 01:31:50 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 31 Mar 2015 16:31:50 -0700
Subject: [R] Using matlab code in R
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536C01C@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536C01C@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <C7D7F7E4-E9C8-419C-9231-04FD4D8450D1@dcn.davis.CA.us>

The Posting Guide recommends searching the archives before posting. Consider [1] and learn.

[1] https://stat.ethz.ch/pipermail/r-help/2007-March/127981.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 31, 2015 1:47:49 PM PDT, "T.Riedle" <tr206 at kent.ac.uk> wrote:
>Hi everybody,
>I have a matlab code which I would like to use for my empirical
>analysis. Unfortunately, I am not familiar with matlab and it would be
>great if there was a tool to "translate" the matlab code into R so that
>I can work with the code in R.
>Is there such a tool or package in R?
>
>Kind regards,
>T.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Wed Apr  1 01:42:52 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 19:42:52 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAGx1TMAM_4T34Qeh3Jp-n--92ap67-U4PPSNNoURbR5_Dwda_A@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>
	<CAGx1TMAM_4T34Qeh3Jp-n--92ap67-U4PPSNNoURbR5_Dwda_A@mail.gmail.com>
Message-ID: <CAM_vjumj2oh3UevoLnNmTir+iD_42NyPF-tpMovFQeT=kU2N+g@mail.gmail.com>

On Tue, Mar 31, 2015 at 6:35 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> I got rid of the extra column.
>
> data.frame(r=seq(8), foo=NA, bar=NA, row.names="r")

Brilliant!

After much fussing, including a disturbing detour into nested lapply
statements from which I barely emerged with my sanity (arguable, I
suppose), here is a one-liner that creates a data frame of arbitrary
number of rows given an existing data frame as template for column
number and name:


n <- 8
df1 <- data.frame(A=runif(9), B=runif(9))

do.call(data.frame, setNames(c(list(seq(n), "r"), as.list(rep(NA,
ncol(df1)))), c("r", "row.names", colnames(df1))))

It's not elegant, but it is fairly R-ish. I should probably stop
hunting for an elegant solution now.

Thanks, everyone!

Sarah


> Rich
>
> On Tue, Mar 31, 2015 at 6:18 PM, Sven E. Templer <sven.templer at gmail.com> wrote:
>> If you don't mind an extra column, you could use something similar to:
>>
>> data.frame(r=seq(8),foo=NA,bar=NA)
>>
>> If you do, here is another approach (see function body):
>>
>> empty.frame <- function (r = 1, n = 1, fill = NA_real_) {
>>   data.frame(setNames(lapply(rep(fill, length(n)), rep, times=r), n))
>> }
>> empty.frame()
>> empty.frame(, seq(3))
>> empty.frame(8, c("foo", "bar"))
>>
>> I could not put it in one line either, without retyping at least one
>> argument (n in this case).
>> So I suggest a function is the way to go for a simplified syntax ...
>>
>> Thanks to all for the ideas!
>> Sven
>>
>> On 31 March 2015 at 20:55, William Dunlap <wdunlap at tibco.com> wrote:
>>
>>> You can use structure() to attach the names to a list that is input to
>>> data.frame.
>>> E.g.,
>>>
>>> dfNames <- c("First", "Second Name")
>>> data.frame(lapply(structure(dfNames, names=dfNames),
>>> function(name)rep(NA_real_, 5)))
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
>>> wrote:
>>>
>>> > Hi,
>>> >
>>> > Duncan Murdoch suggested:
>>> >
>>> > > The matrix() function has a dimnames argument, so you could do this:
>>> > >
>>> > > names <- c("strat", "id", "pid")
>>> > > data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>>> >
>>> > That's a definite improvement, thanks. But no way to skip matrix()? It
>>> > just seems unRlike, although since it's only full of NA values there
>>> > are no coercion issues with column types or anything, so it doesn't
>>> > hurt. It's just inelegant. :)
>>> >
>>> > Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From henrik.bengtsson at ucsf.edu  Wed Apr  1 02:06:50 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 31 Mar 2015 17:06:50 -0700
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjumj2oh3UevoLnNmTir+iD_42NyPF-tpMovFQeT=kU2N+g@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>
	<CAGx1TMAM_4T34Qeh3Jp-n--92ap67-U4PPSNNoURbR5_Dwda_A@mail.gmail.com>
	<CAM_vjumj2oh3UevoLnNmTir+iD_42NyPF-tpMovFQeT=kU2N+g@mail.gmail.com>
Message-ID: <CAFDcVCRvHmVO=mFVPQkRN934trssXFDnAmiH1=xttCAXRK5qMw@mail.gmail.com>

I've got dataFrame() in R.utils for this purpose, e.g.

> df <- dataFrame(colClasses=c(a="integer", b="double", c="character"), nrow=10L)
> str(df)
'data.frame':   10 obs. of  3 variables:
 $ a: int  0 0 0 0 0 0 0 0 0 0
 $ b: num  0 0 0 0 0 0 0 0 0 0
 $ c: chr  "" "" "" "" ...

Related: You can use the colClasses() function to generate the
'colClasses' argument "dynamically", e.g.

> cols <- colClasses("idc")
> names(cols) <- c("a", "b", "c")
> str(cols)
 Named chr [1:3] "integer" "double" "character"
 - attr(*, "names")= chr [1:3] "a" "b" "c"

> cols <- colClasses(sprintf("c2d%di", 4))
> df <- dataFrame(colClasses=cols, nrow=10L)
str(df)
'data.frame':   10 obs. of  7 variables:
 $ : chr  "" "" "" "" ...
 $ : num  0 0 0 0 0 0 0 0 0 0
 $ : num  0 0 0 0 0 0 0 0 0 0
 $ : int  0 0 0 0 0 0 0 0 0 0
 $ : int  0 0 0 0 0 0 0 0 0 0
 $ : int  0 0 0 0 0 0 0 0 0 0
 $ : int  0 0 0 0 0 0 0 0 0 0


dataFrame() is basically implemented as:

dataFrame <- function(colClasses, nrow=1L, ...) {
  df <- vector("list", length=length(colClasses))
  names(df) <- names(colClasses)
  for (kk in seq(along=df)) {
    df[[kk]] <- vector(colClasses[kk], length=nrow)
  }
  attr(df, "row.names") <- seq(length=nrow)
  class(df) <- "data.frame"
  df
} # dataFrame()

/Henrik

On Tue, Mar 31, 2015 at 4:42 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> On Tue, Mar 31, 2015 at 6:35 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> I got rid of the extra column.
>>
>> data.frame(r=seq(8), foo=NA, bar=NA, row.names="r")
>
> Brilliant!
>
> After much fussing, including a disturbing detour into nested lapply
> statements from which I barely emerged with my sanity (arguable, I
> suppose), here is a one-liner that creates a data frame of arbitrary
> number of rows given an existing data frame as template for column
> number and name:
>
>
> n <- 8
> df1 <- data.frame(A=runif(9), B=runif(9))
>
> do.call(data.frame, setNames(c(list(seq(n), "r"), as.list(rep(NA,
> ncol(df1)))), c("r", "row.names", colnames(df1))))
>
> It's not elegant, but it is fairly R-ish. I should probably stop
> hunting for an elegant solution now.
>
> Thanks, everyone!
>
> Sarah
>
>
>> Rich
>>
>> On Tue, Mar 31, 2015 at 6:18 PM, Sven E. Templer <sven.templer at gmail.com> wrote:
>>> If you don't mind an extra column, you could use something similar to:
>>>
>>> data.frame(r=seq(8),foo=NA,bar=NA)
>>>
>>> If you do, here is another approach (see function body):
>>>
>>> empty.frame <- function (r = 1, n = 1, fill = NA_real_) {
>>>   data.frame(setNames(lapply(rep(fill, length(n)), rep, times=r), n))
>>> }
>>> empty.frame()
>>> empty.frame(, seq(3))
>>> empty.frame(8, c("foo", "bar"))
>>>
>>> I could not put it in one line either, without retyping at least one
>>> argument (n in this case).
>>> So I suggest a function is the way to go for a simplified syntax ...
>>>
>>> Thanks to all for the ideas!
>>> Sven
>>>
>>> On 31 March 2015 at 20:55, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>>> You can use structure() to attach the names to a list that is input to
>>>> data.frame.
>>>> E.g.,
>>>>
>>>> dfNames <- c("First", "Second Name")
>>>> data.frame(lapply(structure(dfNames, names=dfNames),
>>>> function(name)rep(NA_real_, 5)))
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
>>>> wrote:
>>>>
>>>> > Hi,
>>>> >
>>>> > Duncan Murdoch suggested:
>>>> >
>>>> > > The matrix() function has a dimnames argument, so you could do this:
>>>> > >
>>>> > > names <- c("strat", "id", "pid")
>>>> > > data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>>>> >
>>>> > That's a definite improvement, thanks. But no way to skip matrix()? It
>>>> > just seems unRlike, although since it's only full of NA values there
>>>> > are no coercion issues with column types or anything, so it doesn't
>>>> > hurt. It's just inelegant. :)
>>>> >
>>>> > Sarah
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luysgarcia at gmail.com  Wed Apr  1 05:41:51 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Wed, 1 Apr 2015 00:41:51 -0300
Subject: [R] Edit plot adehabitatHS
Message-ID: <CANxP2S7a8E=ZAcgA8JrEv4zy5buOg0F7AdKMMM-LweTW_LQznA@mail.gmail.com>

Dear R experts,

I am making a selectivity analysis using the  package. Nevertheless, I am
having some troubles, and I would like to know if somebody know how to help
me:

1) When changing the x-axis labels. The programm uses the name habitat
instead of the names specified in the file.

2) Is it possible to edit this plot, #3 (bottom-left), for example is it
possible to change the symbols style, the legend position or size? I do not
know how to edit this kind of data, if somebody has an example using this
package, I would really appreaciate it.

Thanks!!

Please find attached the plot, the script and the respective plot


library(adehabitatHS)
pse<-read.table("pseudos.txt", header=T)

attach(pse)
names(pse)
head(pse)
(wiRatio <- widesI(Diet, Dis))
png(filename = "plotpseudos3.png", width = 500, height = 500)
opar <- par(mfrow=c(2,2))
plot(wiRatio)

par(opar)
dev.off()
-------------- next part --------------
MSp	Orden	Dis	Diet
MSp52	Hemiptera	31	2
MSp84	Hemiptera	2	1
MSp92	Hymenoptera	47	2
MSp100	Hymenoptera	19	1
MSp101	Hymenoptera	31	28
MSp102	Hymenoptera	83	15
MSp104	Hymenoptera	77	40
MSp105	Hymenoptera	110	9
MSp106	Hymenoptera	41	3
MSp107	Hymenoptera	1	3
MSp108	Hymenoptera	1	2
MSp109	Hymenoptera	1	1
MSp110	Hymenoptera	1	1
MSp143	Mantodea	1	1
MSp164	Neuroptera	5	1
MSp176	Araneae	6	1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plotpseudos3.png
Type: image/png
Size: 7300 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150401/077d11ba/attachment.png>

From acefix at rocketmail.com  Wed Apr  1 07:28:27 2015
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 1 Apr 2015 05:28:27 +0000 (UTC)
Subject: [R] about model.matrix
Message-ID: <1849201368.2662055.1427866107312.JavaMail.yahoo@mail.yahoo.com>

I tried to run the sample code from R:
dd <- data.frame(a = gl(3,4), b = gl(4,1,12))?  a b
1  1 1
2  1 2
3  1 3
4  1 4
5  2 1
6  2 2
7  2 3
8  2 4
9  3 1
10 3 2
11 3 3
12 3 4
options("contrasts")
model.matrix(~ a + b, dd)(Intercept) a2 a3 b2 b3 b4
1            1  0  0  0  0  0
2            1  0  0  1  0  0
3            1  0  0  0  1  0
4            1  0  0  0  0  1
5            1  1  0  0  0  0
6            1  1  0  1  0  0
7            1  1  0  0  1  0
8            1  1  0  0  0  1
9            1  0  1  0  0  0
10           1  0  1  1  0  0
11           1  0  1  0  1  0
12           1  0  1  0  0  1
when I tried to remove the intercept from the matrix, I used the following codemodel.matrix(~ 0+a + b, dd)
 a1 a2 a3 b2 b3 b41 1 0 0 0 0 02 1 0 0 1 0 03 1 0 0 0 1 04 1 0 0 0 0 15 0 1 0 0 0 06 0 1 0 1 0 07 0 1 0 0 1 08 0 1 0  0 0 19 0 0 1 0 0 010 0 0 1 1 0 011 0 0 1 0 1 012 0 0 1 0 0 1?when I tried to remove the intercept

Here I noticed that, all levels of a, a1, a2, and a3, were included. I wonder how  I can include the "b1" in the matrix as well?   a1 a2 a3 b1 b2 b3 b4
1   1  0  0  1  0  0  0
2   1  0  0  0  1  0  0
3   1  0  0  0  0  1  0
4   1  0  0  0  0  0  1
5   0  1  0  1  0  0  0
6   0  1  0  0  1  0  0
7   0  1  0  0  0  1  0
8   0  1  0  0  0  0  1
9   0  0  1  1  0  0  0
10  0  0  1  0  1  0  0
11  0  0  1  0  0  1  0
12  0  0  1  0  0  0  1?

	[[alternative HTML version deleted]]


From firespot71 at gmail.com  Wed Apr  1 10:52:03 2015
From: firespot71 at gmail.com (Thomas)
Date: Wed, 1 Apr 2015 10:52:03 +0200
Subject: [R] read.table with a "memory connection"
Message-ID: <mfgbjl$vg9$1@ger.gmane.org>

Hi,

Is there a way to create "memory connections" in R which are valid 
connections to read.table (and associated function)? By saying "memory 
connection" I refer to something like a connection created from a simple 
character object (of length 1) - instead of having the content in a 
physical file just have it in an ordinary R object. More or less the 
equivalent to the std::istringstream class in C++.

thanks,
Thomas


From ripley at stats.ox.ac.uk  Wed Apr  1 11:06:07 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 01 Apr 2015 10:06:07 +0100
Subject: [R] read.table with a "memory connection"
In-Reply-To: <mfgbjl$vg9$1@ger.gmane.org>
References: <mfgbjl$vg9$1@ger.gmane.org>
Message-ID: <551BB4FF.6030700@stats.ox.ac.uk>

On 01/04/2015 09:52, Thomas wrote:
> Hi,
>
> Is there a way to create "memory connections" in R which are valid
> connections to read.table (and associated function)? By saying "memory
> connection" I refer to something like a connection created from a simple
> character object (of length 1) - instead of having the content in a
> physical file just have it in an ordinary R object. More or less the
> equivalent to the std::istringstream class in C++.

I believe you are looking for 'text connections':  see the 'text' 
argument to read.table() and ?textConnection.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From alaios at yahoo.com  Wed Apr  1 12:34:30 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 1 Apr 2015 10:34:30 +0000 (UTC)
Subject: [R] From replicate to accesing sublists
Message-ID: <1131154192.2740130.1427884470942.JavaMail.yahoo@mail.yahoo.com>

Dear all,I have a R structure that was created with replicate.The data sets looks to be a matrix with each cell being a list.
str(error_suburban_0[,1],max.level=1)
List of 4
 $ vaR      :List of 20
  ..- attr(*, "class")= chr "variogram"
 $ Shadowing:List of 2
  ..- attr(*, "class")= chr "geodata"
 $ FIT      :List of 1
 $ propmodel:List of 12
  ..- attr(*, "class")= chr "lm"


The error_suburban is a matrix that each field so 
error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4],... and so on,  contains the four sublists
$ vaR      :List of 20
  ..- attr(*, "class")= chr "variogram"
 $ Shadowing:List of 2
  ..- attr(*, "class")= chr "geodata"
 $ FIT      :List of 1
 $ propmodel:List of 12
  ..- attr(*, "class")= chr "lm"


I would like to pick for each of these matrix elements to collect only the $Shadowing sublist
error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4]... and so on

Right now I am implementing this by a for loop that access each matrix element sequentially.

Can you please advice me if there is a better approach to do that in R?
Regards
Alex
?

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Apr  1 15:06:32 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 1 Apr 2015 08:06:32 -0500
Subject: [R] Calculating different PCAs in R
In-Reply-To: <1688822560.2389058.1427837184259.JavaMail.yahoo@mail.yahoo.com>
References: <1688822560.2389058.1427837184259.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCFKWSd_uDLXOair7V0kXf4Wug9kFzzntZGKoo5nM4Mzjg@mail.gmail.com>

PCA 1, 2, and 3 refer to the scores not the loadings.
Check out the help for princomp.

?princomp

pc.cr <- princomp(USArrests, cor = TRUE)
pc.cr$scores[1:3, ]

Jean


On Tue, Mar 31, 2015 at 4:26 PM, im db <imdb.subscribe at gmail.com> wrote:

> Dear All, I want to use princomp() function in R in order to calculate
> Principle Component Analysis.In different papers, I have seen "PCA 1", "PCA
> 2", "PCA 11" , etc. Would you please tell me how can i calculate different
> PCAs in R?At the moment i just use this line "eigenVectors <-
> pca$loadings"But I don?t know if it is correct to use loadings.Thank you in
> advance.  Best regards,
> Iman Dabbaghi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Apr  1 15:40:23 2015
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Apr 2015 09:40:23 -0400
Subject: [R] Can not load Rcmdr
In-Reply-To: <1427833189081-4705370.post@n4.nabble.com>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>	<1358324274.2051.20.camel@milan>
	<516C6865.6000406@gmx.de>	<web-453502593@cgpsrv2.cis.mcmaster.ca>	<1418399588968-4700714.post@n4.nabble.com>
	<1427833189081-4705370.post@n4.nabble.com>
Message-ID: <000601d06c81$6827e390$3877aab0$@mcmaster.ca>

Dear Angela,

There's very little to go on here. The messages to which you refer concern
primarily Mac OS X, where the most common problem is failure to install
XQuartz or to reinstall it after an OS upgrade. Help for this and other Mac
OS X problems is available in the Rcmdr installation notes, at
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>.

In my limited experience, Linux systems typically include both X Windows and
a suitable Tcl/Tk. In your case, there's probably little you can do without
administrator privileges to install or update software (including, BTW, R,
for which you're using an old version). You can, however, confirm that the
problem concerns Tcl/Tk. Load the tcltk package independently of the Rcmdr
via library(tcltk). If tcltk loads without error, then try to do something
with it, such as example("tkProgressBar"). 

Finally, I don't think that it's reasonable to think of the Rcmdr as a
substitute for RStudio or Emacs.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of a b
> Sent: March-31-15 4:20 PM
> To: r-help at r-project.org
> Subject: Re: [R] Can not load Rcmdr
> 
> I have a similar issue with tcl.
> 
> I am using R on a Linux server.  Rcmdr installed OK, but it won't run:
> 
> > R.Version()
> $platform
> [1] "x86_64-unknown-linux-gnu"
> 
> $arch
> [1] "x86_64"
> 
> $os
> [1] "linux-gnu"
> 
> $system
> [1] "x86_64, linux-gnu"
> 
> $status
> [1] ""
> 
> $major
> [1] "3"
> 
> $minor
> [1] "1.0"
> 
> $year
> [1] "2014"
> 
> $month
> [1] "04"
> 
> $day
> [1] "10"
> 
> $`svn rev`
> [1] "65387"
> 
> $language
> [1] "R"
> 
> $version.string
> [1] "R version 3.1.0 (2014-04-10)"
> 
> $nickname
> [1] "Spring Dance"
> 
> > library(Rcmdr)
> Error : .onAttach failed in attachNamespace() for 'Rcmdr', details:
>   call: structure(.External(.C_dotTcl, ...), class = "tclObj")
>   error: [tcl] Invalid state name hover.
> 
> Error: package or namespace load failed for 'Rcmdr'
> >
> 
> 
> This is kind of frustrating because I don't have admin privileges to
install
> Rstudio on this server, either.
> 
> I guess it's time to use Emacs.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Can-not-load-
> Rcmdr-tp4655656p4705370.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From alaios at yahoo.com  Wed Apr  1 16:14:29 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 1 Apr 2015 14:14:29 +0000 (UTC)
Subject: [R] change language  at console
Message-ID: <1538493775.2899949.1427897669877.JavaMail.yahoo@mail.yahoo.com>

Hi all,I am a linux R user and my default R environemnt (after writing R in linux console) returns the error messages in German (I am not the system adminitstrator and I can not change system settings). I know that the English package is also installed so I guess I need to set some environmental variable for this.Any idea how I am doing that?
RegardsAlex


	[[alternative HTML version deleted]]


From firespot71 at gmail.com  Wed Apr  1 16:26:30 2015
From: firespot71 at gmail.com (Thomas)
Date: Wed, 1 Apr 2015 16:26:30 +0200
Subject: [R] read.table with a "memory connection"
In-Reply-To: <551BB4FF.6030700@stats.ox.ac.uk>
References: <mfgbjl$vg9$1@ger.gmane.org> <551BB4FF.6030700@stats.ox.ac.uk>
Message-ID: <mfgv6o$3uf$1@ger.gmane.org>

On 01/04/2015 11:06, Prof Brian Ripley wrote:
> On 01/04/2015 09:52, Thomas wrote:
>> Hi,
>
> I believe you are looking for 'text connections':  see the 'text'
> argument to read.table() and ?textConnection.
>

Thanks, that's it !


From ripley at stats.ox.ac.uk  Wed Apr  1 16:42:29 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 01 Apr 2015 15:42:29 +0100
Subject: [R] change language  at console
In-Reply-To: <1538493775.2899949.1427897669877.JavaMail.yahoo@mail.yahoo.com>
References: <1538493775.2899949.1427897669877.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <551C03D5.9030502@stats.ox.ac.uk>

On 01/04/2015 15:14, Alaios via R-help wrote:
> Hi all,I am a linux R user and my default R environemnt (after writing R in linux console) returns the error messages in German (I am not the system adminitstrator and I can not change system settings). I know that the English package is also installed so I guess I need to set some environmental variable for this.Any idea how I am doing that?
> RegardsAlex
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do (and not send HTML).  It is in the manual, 
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Internationalization 
and specifically
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Localization-of-messages

I would start by trying LANGUAGE=en , e.g.

LANGUAGE=en R

or

env LANGUAGE=en R

depending on your shell.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From angela.baldo at ARS.USDA.GOV  Wed Apr  1 16:14:38 2015
From: angela.baldo at ARS.USDA.GOV (a b)
Date: Wed, 1 Apr 2015 07:14:38 -0700 (PDT)
Subject: [R] Can not load Rcmdr
In-Reply-To: <000601d06c81$6827e390$3877aab0$@mcmaster.ca>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>
	<1358324274.2051.20.camel@milan> <516C6865.6000406@gmx.de>
	<web-453502593@cgpsrv2.cis.mcmaster.ca>
	<1418399588968-4700714.post@n4.nabble.com>
	<1427833189081-4705370.post@n4.nabble.com>
	<000601d06c81$6827e390$3877aab0$@mcmaster.ca>
Message-ID: <1427897678888-4705394.post@n4.nabble.com>

Thanks for the quick response!

While I agree Rcommander is not the same thing as either ESS or RStudio, it
can also be useful as a wrapper when testing out functions and scripts.  I
learned R on it and it's a more comfortable environment for me than ESS. 
(Thank you for writing it!)

Strangely tcltk seems to be functioning just fine on my system. 
tkProgressBar() shows a little horizontal thermometer window with no
complaints.

The problem comes when I try to load Rcommander.
splines, RcmdrMisc, car, and sandwich all load, but then a dialog box pops
up saying that XLConnect is missing and asking permission to install it.

XLConnect won't install because rJava is apparently unavailable for
XLConnectJars because I need to be root in order to install rJava

So I guess I've just answered my own question - without admin access I won't
have either Rstudio or RCommander.  That's the cost of paying someone else
to maintain our Big Machine as part of a server array.

Thanks again,

anja







--
View this message in context: http://r.789695.n4.nabble.com/Can-not-load-Rcmdr-tp4655656p4705394.html
Sent from the R help mailing list archive at Nabble.com.


From angela.baldo at ARS.USDA.GOV  Wed Apr  1 16:34:13 2015
From: angela.baldo at ARS.USDA.GOV (a b)
Date: Wed, 1 Apr 2015 07:34:13 -0700 (PDT)
Subject: [R] Can not load Rcmdr
In-Reply-To: <1427897678888-4705394.post@n4.nabble.com>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>
	<1358324274.2051.20.camel@milan> <516C6865.6000406@gmx.de>
	<web-453502593@cgpsrv2.cis.mcmaster.ca>
	<1418399588968-4700714.post@n4.nabble.com>
	<1427833189081-4705370.post@n4.nabble.com>
	<000601d06c81$6827e390$3877aab0$@mcmaster.ca>
	<1427897678888-4705394.post@n4.nabble.com>
Message-ID: <1427898853706-4705399.post@n4.nabble.com>

BTW I've also tried this as non-root:

R CMD javareconf -e

and there's still a problem with rJava not being able to access the library
that was supposedly compiled and installed in my home R directory.

I think it may have to do with the fact we're using an older version of R. 
We're using Java 1.8.0_31-b13 which may be an issue too.



--
View this message in context: http://r.789695.n4.nabble.com/Can-not-load-Rcmdr-tp4655656p4705399.html
Sent from the R help mailing list archive at Nabble.com.


From rshepard at appl-ecosys.com  Wed Apr  1 16:55:08 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 1 Apr 2015 07:55:08 -0700 (PDT)
Subject: [R] change language  at console
In-Reply-To: <551C03D5.9030502@stats.ox.ac.uk>
References: <1538493775.2899949.1427897669877.JavaMail.yahoo@mail.yahoo.com>
	<551C03D5.9030502@stats.ox.ac.uk>
Message-ID: <alpine.LNX.2.11.1504010754190.26540@localhost>

On Wed, 1 Apr 2015, Prof Brian Ripley wrote:

> I would start by trying LANGUAGE=en , e.g.

   More specifically, you can use en_US or en_GB.

Rich


From istazahn at gmail.com  Wed Apr  1 17:47:18 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 1 Apr 2015 11:47:18 -0400
Subject: [R] Can not load Rcmdr
In-Reply-To: <1427897678888-4705394.post@n4.nabble.com>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>
	<1358324274.2051.20.camel@milan> <516C6865.6000406@gmx.de>
	<web-453502593@cgpsrv2.cis.mcmaster.ca>
	<1418399588968-4700714.post@n4.nabble.com>
	<1427833189081-4705370.post@n4.nabble.com>
	<000601d06c81$6827e390$3877aab0$@mcmaster.ca>
	<1427897678888-4705394.post@n4.nabble.com>
Message-ID: <CA+vqiLEKad4xbKwdUD5eZOJSv8UDsNkXosUZcXvCoMnjK7_d+Q@mail.gmail.com>

On Wed, Apr 1, 2015 at 10:14 AM, a b <angela.baldo at ars.usda.gov> wrote:
> Thanks for the quick response!
>
> While I agree Rcommander is not the same thing as either ESS or RStudio, it
> can also be useful as a wrapper when testing out functions and scripts.  I
> learned R on it and it's a more comfortable environment for me than ESS.
> (Thank you for writing it!)
>
> Strangely tcltk seems to be functioning just fine on my system.
> tkProgressBar() shows a little horizontal thermometer window with no
> complaints.
>
> The problem comes when I try to load Rcommander.
> splines, RcmdrMisc, car, and sandwich all load, but then a dialog box pops
> up saying that XLConnect is missing and asking permission to install it.
>
> XLConnect won't install because rJava is apparently unavailable for
> XLConnectJars because I need to be root in order to install rJava

Why don't you just say "No" when it asks if you want XLConnect?

--Ista

>
> So I guess I've just answered my own question - without admin access I won't
> have either Rstudio or RCommander.  That's the cost of paying someone else
> to maintain our Big Machine as part of a server array.
>
> Thanks again,
>
> anja
>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Can-not-load-Rcmdr-tp4655656p4705394.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Apr  1 17:54:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Apr 2015 08:54:09 -0700
Subject: [R] From replicate to accesing sublists
In-Reply-To: <1131154192.2740130.1427884470942.JavaMail.yahoo@mail.yahoo.com>
References: <1131154192.2740130.1427884470942.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <FD08E6E6-A318-4ED4-9C36-DB8A164283DE@comcast.net>


On Apr 1, 2015, at 3:34 AM, Alaios via R-help wrote:

> Dear all,I have a R structure that was created with replicate.The data sets looks to be a matrix with each cell being a list.
> str(error_suburban_0[,1],max.level=1)
> List of 4
> $ vaR      :List of 20
>  ..- attr(*, "class")= chr "variogram"
> $ Shadowing:List of 2
>  ..- attr(*, "class")= chr "geodata"
> $ FIT      :List of 1
> $ propmodel:List of 12
>  ..- attr(*, "class")= chr "lm"
> 
> 
> The error_suburban is a matrix that each field so 
> error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4],... and so on,  contains the four sublists
> $ vaR      :List of 20
>  ..- attr(*, "class")= chr "variogram"
> $ Shadowing:List of 2
>  ..- attr(*, "class")= chr "geodata"
> $ FIT      :List of 1
> $ propmodel:List of 12
>  ..- attr(*, "class")= chr "lm"
> 
> 
> I would like to pick for each of these matrix elements to collect only the $Shadowing sublist
> error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4]... and so on
> 
> Right now I am implementing this by a for loop that access each matrix element sequentially.

It would have been better to show the results of dim() or dput(). Matrix objects (which are capable of holding lists) should be accessible with either a single or double argument to "[". This should deliver contents:

for (i in 1:4)  print(  error_suburban_0[i]$Shadowing )

If the matrix has 4 or more rows, then that would be accessing only from the first column. If fewer than 4 rows, you would be wrapping around to later columns.

-- 
David.

> 
> Can you please advice me if there is a better approach to do that in R?
> Regards
> Alex
>  
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list. Please reconfigure your email client to sent in plain text.

-- 

David Winsemius
Alameda, CA, USA


From lists at dewey.myzen.co.uk  Wed Apr  1 17:58:38 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 01 Apr 2015 16:58:38 +0100
Subject: [R] about model.matrix
In-Reply-To: <1849201368.2662055.1427866107312.JavaMail.yahoo@mail.yahoo.com>
References: <1849201368.2662055.1427866107312.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <551C15AE.8050208@dewey.myzen.co.uk>

This is really a question about statistics rather than R but see below

On 01/04/2015 06:28, Fix Ace wrote:
> I tried to run the sample code from R:
> dd <- data.frame(a = gl(3,4), b = gl(4,1,12))   a b
> 1  1 1
> 2  1 2
> 3  1 3
> 4  1 4
> 5  2 1
> 6  2 2
> 7  2 3
> 8  2 4
> 9  3 1
> 10 3 2
> 11 3 3
> 12 3 4
> options("contrasts")
> model.matrix(~ a + b, dd)(Intercept) a2 a3 b2 b3 b4
> 1            1  0  0  0  0  0
> 2            1  0  0  1  0  0
> 3            1  0  0  0  1  0
> 4            1  0  0  0  0  1
> 5            1  1  0  0  0  0
> 6            1  1  0  1  0  0
> 7            1  1  0  0  1  0
> 8            1  1  0  0  0  1
> 9            1  0  1  0  0  0
> 10           1  0  1  1  0  0
> 11           1  0  1  0  1  0
> 12           1  0  1  0  0  1
> when I tried to remove the intercept from the matrix, I used the following codemodel.matrix(~ 0+a + b, dd)
>   a1 a2 a3 b2 b3 b41 1 0 0 0 0 02 1 0 0 1 0 03 1 0 0 0 1 04 1 0 0 0 0 15 0 1 0 0 0 06 0 1 0 1 0 07 0 1 0 0 1 08 0 1 0  0 0 19 0 0 1 0 0 010 0 0 1 1 0 011 0 0 1 0 1 012 0 0 1 0 0 1 when I tried to remove the intercept
>

That got mangled but

In your matrix below try forming the sum of a1+a2+a3 and the sum of 
b1+b2+b3+b4. I think you will find they are linearly related.

> Here I noticed that, all levels of a, a1, a2, and a3, were included. I wonder how  I can include the "b1" in the matrix as well?   a1 a2 a3 b1 b2 b3 b4
> 1   1  0  0  1  0  0  0
> 2   1  0  0  0  1  0  0
> 3   1  0  0  0  0  1  0
> 4   1  0  0  0  0  0  1
> 5   0  1  0  1  0  0  0
> 6   0  1  0  0  1  0  0
> 7   0  1  0  0  0  1  0
> 8   0  1  0  0  0  0  1
> 9   0  0  1  1  0  0  0
> 10  0  0  1  0  1  0  0
> 11  0  0  1  0  0  1  0
> 12  0  0  1  0  0  0  1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jfox at mcmaster.ca  Wed Apr  1 17:09:35 2015
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Apr 2015 11:09:35 -0400
Subject: [R] Can not load Rcmdr
In-Reply-To: <1427897678888-4705394.post@n4.nabble.com>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>	<1358324274.2051.20.camel@milan>
	<516C6865.6000406@gmx.de>	<web-453502593@cgpsrv2.cis.mcmaster.ca>	<1418399588968-4700714.post@n4.nabble.com>	<1427833189081-4705370.post@n4.nabble.com>	<000601d06c81$6827e390$3877aab0$@mcmaster.ca>
	<1427897678888-4705394.post@n4.nabble.com>
Message-ID: <001d01d06c8d$de72abf0$9b5803d0$@mcmaster.ca>

Dear anja,

You shouldn't really need XLConnect -- if it's absent, the only consequence
is that you  won't be able to import Excel files directly in the Rcmdr. Just
say "no" when the Rcmdr asks to install XLConnect, and the Rcmdr GUI should
start up normally (unless there's some other problem). If that's the case,
you can set options(Rcmdr=list(check.packages=FALSE)) before you load the
Rcmdr package, and the package check will be skipped; more conveniently you
can put this command in your R profile.

I hope this helps,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of a b
> Sent: April-01-15 10:15 AM
> To: r-help at r-project.org
> Subject: Re: [R] Can not load Rcmdr
> 
> Thanks for the quick response!
> 
> While I agree Rcommander is not the same thing as either ESS or RStudio,
it
> can also be useful as a wrapper when testing out functions and scripts.  I
> learned R on it and it's a more comfortable environment for me than ESS.
> (Thank you for writing it!)
> 
> Strangely tcltk seems to be functioning just fine on my system.
> tkProgressBar() shows a little horizontal thermometer window with no
> complaints.
> 
> The problem comes when I try to load Rcommander.
> splines, RcmdrMisc, car, and sandwich all load, but then a dialog box pops
up
> saying that XLConnect is missing and asking permission to install it.
> 
> XLConnect won't install because rJava is apparently unavailable for
> XLConnectJars because I need to be root in order to install rJava
> 
> So I guess I've just answered my own question - without admin access I
> won't have either Rstudio or RCommander.  That's the cost of paying
> someone else to maintain our Big Machine as part of a server array.
> 
> Thanks again,
> 
> anja
> 
> 
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Can-not-load-
> Rcmdr-tp4655656p4705394.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.


From aragorn168b at gmail.com  Wed Apr  1 21:55:36 2015
From: aragorn168b at gmail.com (Arunkumar Srinivasan)
Date: Wed, 1 Apr 2015 21:55:36 +0200
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <1427826919.3658.13.camel@maladmin.com>
References: <20150330135059.GL1250@albert.catwhisker.org>
	<9990A6ED67E.000007F3jrkrideau@inbox.com>
	<20150331172209.GW1250@albert.catwhisker.org>
	<CA+vqiLEp7D2rvEWEDSVENgijKWnoBRBaNYkHmuv_R9u+Uo9hHw@mail.gmail.com>
	<1427826919.3658.13.camel@maladmin.com>
Message-ID: <CAAf756NcGwk+x5r_nVVWk6gFTpba1H=my_qfTj4i87u9Vu5d2A@mail.gmail.com>

David,

In data.table v1.9.5 (current development version, which you can get
from here: https://github.com/Rdatatable/data.table/wiki/Installation),
new features were added to both `melt` and `cast` for data.tables.
They both can handle multiple columns simultaneously. I think this
would be of interest for you..

Using 1.9.5, here's how I'd do it.

require(data.table) ## v1.9.5+
cols <- grep("^da2.*$", names(bw), value=TRUE)      ## (1)
splt <- split(cols, seq_len(length(cols)/2L))       ## (2)
vars <- unique(gsub("(.*?)_(.*$)", "\\1", cols))    ## (3)
vals <- unique(gsub("(.*?)_(.*$)", "\\2", cols))    ## (4)

ans1 = melt(setDT(bw), measure=splt, variable.name="disc",
value.name=vals) ## (5)
setattr(ans1$disc, 'levels', vars) ## (6)

Explanation:
-------------------

1. Get all cols you've to melt
2. Split them into column pairs that should be combined together
3. Get levels for 'variable' column
4. Get column names for molten result
5. Melt by providing list of columns with each element containing the
columns you'd want to combine together in the molten result directly.
6. Set levels for variable column appropriately.

Advantages:
------------------

1. melting by combining corresponding columns together, directly, is
straightforward and easy to understand, since that's the task you want
to perform. Having to combine all columns together and then split them
back seems roundabout.

2. "casting" (tidyr::spread internally uses reshape2::dcast) is a
relatively complicated operation, and in this case it can be
completely avoided which will save both time and memory (see benchmark
at the bottom of post). It also reorders the result which may not be
desirable.

3. In 'bw', columns `da20_dev_type` and `da2_dev_type` are type
'factor' while others are type 'numeric'. reshape2::melt (or)
tidyr::gather, since it combines all columns will have to coerce these
different types to a common type, here 'character'. So, you'll have to
convert the columns back to the right type after casting. I think
you'll agree that's unnecessary. `melt.data.table` preserves the type
as it combines only relevant columns together.

4. Since the operation is performed in a straightforward manner (and
in C for speed), it's incredibly fast *and* memory efficient.

Benchmark (on ~180,000 rows)
---------------------------------------------

library(tidyr)
library(dplyr)
require(data.table) ## v1.9.5+

# replacing timestamp so that rows for unique (for spread to work correctly)
bw.large = rbindlist(replicate(1e4, bw, simplify=FALSE))[, timestamp := .I][]
object.size(bw.large)/1024^2 # ~38MB

The data is 38MB, which is not at all large... but enough to illustrate.

# data.table
system.time({
cols <- grep("^da2.*$", names(bw), value=TRUE)      ## (1)
splt <- split(cols, seq_len(length(cols)/2L))       ## (2)
vars <- unique(gsub("(.*?)_(.*$)", "\\1", cols))    ## (3)
vals <- unique(gsub("(.*?)_(.*$)", "\\2", cols))    ## (4)

ans1 = melt(setDT(bw.large), measure=splt, variable.name="disc",
value.name=vals) ## (5)
setattr(ans1$disc, 'levels', vars) ## (6)
})
#    user  system elapsed
#   0.260   0.013   0.275

Memory used: 56MB

# tidyr
system.time({
ans2 <- gather(setDF(bw.large), key = "tmp", value = "value",
matches("^d[a-z]+[0-9]+"))
ans2 <- separate(ans2, tmp, c("disc", "var"), "_", extra = "merge")
ans2 <- spread(ans2, var, value)
})
#    user  system elapsed
#  15.818   1.128  17.063

Memory used : 750MB

And that's ~62x speedup.

HTH
Arun Srinivasan
Co-developer, data.table.


On Tue, Mar 31, 2015 at 8:35 PM, Tom Wright <tom at maladmin.com> wrote:
> Nice clean-up!!!
>
> On Tue, 2015-03-31 at 14:19 -0400, Ista Zahn wrote:
>> library(tidyr)
>> library(dplyr)
>> bw <- gather(bw, key = "tmp", value = "value",
>> matches("^d[a-z]+[0-9]+"))
>> bw <- separate(bw, tmp, c("disc", "var"), "_", extra = "merge")
>> bw <- spread(bw, var, value)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cflynch at ncsu.edu  Wed Apr  1 22:54:04 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Wed, 1 Apr 2015 16:54:04 -0400
Subject: [R] Kruskal-Wallace power tests.
Message-ID: <CAE=6FXbA81NGUcWEgBcTJaM4oGT=hEvWjHZP6-Ys=O5+Mro7LA@mail.gmail.com>

Greetings, I am working on a project where we are applying the
Kruskal-Wallace test to some factor data to evaluate their correlation with
existing grade data.  I know that the grade data is nonnormal therefore we
cannot rely on ANOVA or a similar parametric test.  What I would like to
find is a mechanism for making power calculations for the KW test given the
nonparametric assumptions.  My perusal of the literature has suggested that
a simulation would be the best method.

Can anyone point me to good examples of such simulations for KW in R?  And
does anyone have a favourite package for generating simulated data or
conducting such tests?

    Thank you,
    Collin.

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Apr  1 23:46:36 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 01 Apr 2015 22:46:36 +0100
Subject: [R] 2 statistics courses in Perth
Message-ID: <551C673C.7090902@highstat.com>

Apologies for cross-posting


We would like to announce the following 2 statistics courses in Perth, 
Australia.

Course1:  Data exploration, regression, GLM & GAM with introduction to R
Location: UWA, Perth, Australia
Date:       20-24 July 2015
Price:       500 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_07Perth_regression_GLM_GAM.pdf


Course2:  Introduction to Linear mixed effects models,  GLMM and MCMC with R
Location: UWA, Perth, Australia
Date:       27-31 July 2015
Price:       500 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_07Perth_GLMM.pdf

Kind regards,

Alain Zuur




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From marion.howard at hotmail.com  Wed Apr  1 23:04:50 2015
From: marion.howard at hotmail.com (marion howard)
Date: Thu, 2 Apr 2015 07:04:50 +1000
Subject: [R] Error in dis[sppInSample,sppInSample]:subscript out of bounds
Message-ID: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>

Hello,
I am new to R and am encountering an error message that I cannot find a solution for.
I am attempting to calculate MPD (mean pairwise distance), without weighting for abundance, with a community species list and a phylogenetic tree in newick format with branch lengths.
I have read in both list and tree .txt files and calculated PD without any problem.
To calculate MPD I have entered:>MPD1=mpd(list,cophenetic(tree))
Error:Error in dis[sppInSample, sppInSample] : subscript out of bounds
Thank you for you helpCheersMarion. 		 	   		  
	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Apr  2 01:43:28 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 1 Apr 2015 23:43:28 +0000
Subject: [R] Error in dis[sppInSample,
 sppInSample]:subscript out of bounds
In-Reply-To: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>
References: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>
Message-ID: <D141CEFD.1245E9%macqueen1@llnl.gov>

Before (I hope!) someone else answers in an unkind tone (and someone
probably will), I have a few suggestions:

1) please use plain text email (an option somewhere in your email
software). Using HTML email usually makes the email harder to read on
r-help.

2) if at all possible, please try to construct an example that other
people can easily run for themselves and provide the data. It makes it
much easier to provide help. This may be hard for someone new to R, but it
is worth it. The usual suggestion is to use the dput() function to include
example data in your email (or the real data if there's not too much of
it, and you are able to share).

3) please identify which packages your functions come from, since they are
not (I believe) part of base R. Sometimes it is essential to also include
the output of sessionInfo()

4) and check the posting guide mentioned at the bottom of the email for
suggestions on how to ask a question so as to have the best chance of
getting good answers.

Expectation are pretty high on r-help.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/1/15, 2:04 PM, "marion howard" <marion.howard at hotmail.com> wrote:

>Hello,
>I am new to R and am encountering an error message that I cannot find a
>solution for.
>I am attempting to calculate MPD (mean pairwise distance), without
>weighting for abundance, with a community species list and a phylogenetic
>tree in newick format with branch lengths.
>I have read in both list and tree .txt files and calculated PD without
>any problem.
>To calculate MPD I have entered:>MPD1=mpd(list,cophenetic(tree))
>Error:Error in dis[sppInSample, sppInSample] : subscript out of bounds
>Thank you for you helpCheersMarion. 		 	   		
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From arountre at umich.edu  Thu Apr  2 04:03:29 2015
From: arountre at umich.edu (Adam Rountrey)
Date: Wed, 1 Apr 2015 22:03:29 -0400
Subject: [R] Windows serial connection
Message-ID: <CAN8WEg2W8-mqoscnF=Qe1g5auQVgDTHoJnmmP=WpiyFO+yXTiw@mail.gmail.com>

Using Windows 8.1

I have an Arduino connected and I am trying to read from and write to a
serial connection using R.  The problem involves the reading.  I am able to
establish the connection using the following:

> system("mode COM4 baud=9600 parity=n data=8", show.output.on.console=T)
> a = file("COM4", open="r+",encoding="UTF8", blocking=F)

I am able to write to the connection using:

> writeOne = function(x){
>    cat(paste(x, "\n", sep=""), file = a)
> }
> writeOne("test")

I am able to read from the connection using:

b = readLines(a,n=1)

However, if I read the last line in the COM4 buffer, and the Arduino later
writes more to the buffer, I am unable to read it.  I only get
"character(0)".  The Arduino seems to be behaving okay, as I can read an
write using the Arduino Serial Monitor.  If after reaching this point, I
close the connection and open it again, I am able to read from COM4 again
(until I read a final value again).  Any ideas as to what might be going
one here?

Many thanks for any ideas.

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Thu Apr  2 06:59:06 2015
From: alaios at yahoo.com (Alaios)
Date: Thu, 2 Apr 2015 04:59:06 +0000 (UTC)
Subject: [R] From replicate to accesing sublists
In-Reply-To: <FD08E6E6-A318-4ED4-9C36-DB8A164283DE@comcast.net>
References: <FD08E6E6-A318-4ED4-9C36-DB8A164283DE@comcast.net>
Message-ID: <1149840251.3444077.1427950746802.JavaMail.yahoo@mail.yahoo.com>

Thanks.The code you gave me at the end works correctly.. I was wondering if there is more efficient way to access each element withouth this classic for loop.
RegardsAlex
 


     On Wednesday, April 1, 2015 5:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
   

 
On Apr 1, 2015, at 3:34 AM, Alaios via R-help wrote:

> Dear all,I have a R structure that was created with replicate.The data sets looks to be a matrix with each cell being a list.
> str(error_suburban_0[,1],max.level=1)
> List of 4
> $ vaR? ? ? :List of 20
>? ..- attr(*, "class")= chr "variogram"
> $ Shadowing:List of 2
>? ..- attr(*, "class")= chr "geodata"
> $ FIT? ? ? :List of 1
> $ propmodel:List of 12
>? ..- attr(*, "class")= chr "lm"
> 
> 
> The error_suburban is a matrix that each field so 
> error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4],... and so on,? contains the four sublists
> $ vaR? ? ? :List of 20
>? ..- attr(*, "class")= chr "variogram"
> $ Shadowing:List of 2
>? ..- attr(*, "class")= chr "geodata"
> $ FIT? ? ? :List of 1
> $ propmodel:List of 12
>? ..- attr(*, "class")= chr "lm"
> 
> 
> I would like to pick for each of these matrix elements to collect only the $Shadowing sublist
> error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4]... and so on
> 
> Right now I am implementing this by a for loop that access each matrix element sequentially.

It would have been better to show the results of dim() or dput(). Matrix objects (which are capable of holding lists) should be accessible with either a single or double argument to "[". This should deliver contents:

for (i in 1:4)? print(? error_suburban_0[i]$Shadowing )

If the matrix has 4 or more rows, then that would be accessing only from the first column. If fewer than 4 rows, you would be wrapping around to later columns.

-- 
David.

> 
> Can you please advice me if there is a better approach to do that in R?
> Regards
> Alex
>? 
> 
> ??? [[alternative HTML version deleted]]

This is a plain text mailing list. Please reconfigure your email client to sent in plain text.

-- 

David Winsemius
Alameda, CA, USA


  
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Apr  2 09:26:47 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Apr 2015 09:26:47 +0200
Subject: [R] error MANOVA in R
In-Reply-To: <CAPxEaESWK9qKUO68DF1Z9SuUkWdsKrb5ZSHf7dF_hD2VGPe9fg@mail.gmail.com>
References: <CAPxEaESWK9qKUO68DF1Z9SuUkWdsKrb5ZSHf7dF_hD2VGPe9fg@mail.gmail.com>
Message-ID: <89803908-11D5-4311-974B-4DBE7B482D71@gmail.com>


> On 30 Mar 2015, at 17:11 , Gian Maria Niccol? Benucci <gian.benucci at gmail.com> wrote:
> 
> Dear R-usrs,
> 
> I am trying to perform a MANOVA on a data frame with 31 columns about soil
> parameters and 1 column containing the explanatory variable (Fraction) that
> have three levels.
> my code is the following:
> 
> datam <- read.table("data_manova2.csv", header=T, sep=",")
> names(datam)
> 
> manova_fraction2 <- manova(cbind(pH, AWC, WEOC, WEN, C.mic, CO2.C, Ca, Mg,
> K, Na, sol.exch.Fe, easily.reducible.Fe, amourphou.Fe.oxide...Fe.OM,
> crystalline.Fe.oxides, TN, TOC, NH4.N, NO3.N, N.org, organic.P, avaiable.P,
> Total.PLFA, Tot.Bat, Gram., Gram..1, Funghi, AMF, protozoa, actinomiceti,
> non.specifici) ~ as.factor(Fraction), data= datam)
> 
> summary(manova_fraction2)
> 
> when I did the summary I got this error
> 
>> summary(manova_fraction2)
> Error in summary.manova(manova_fraction2) : residuals have rank 18 < 30
> 
> ?Is this error possibly due to high correlation between my variables?
> 

Nope. Too few observations. For classical MANOVA, you need  > p degrees of freedom to determine the covariance matrix with full rank. As far as I can tell, you have only 21 observations (21-3=18 degrees of freedom) for your p=30 response variables. 

> Many thanks in advance,

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m at feng.li  Thu Apr  2 15:31:56 2015
From: m at feng.li (Feng Li)
Date: Thu, 2 Apr 2015 21:31:56 +0800
Subject: [R] Inverse of many small matrices
Message-ID: <551D44CC.5010005@feng.li>

Dear all,

I am working with a likelihood function that requires the inverse of 
many small covariance matrices for multivariate normal densities. When 
the sample size is large, this calculation is really heavy. Those 
matrices are independent but unfortunately I can hardly find a way to 
vectorize them.

Can anyone give me a hint to speed this up? Thanks in advance!



Feng

-- 
Feng Li, Ph.D.
School of Statistics and Mathematics
Central University of Finance and Economics
100081 Beijing, China
http://feng.li/


From S.Ellison at LGCGroup.com  Thu Apr  2 16:06:01 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 2 Apr 2015 15:06:01 +0100
Subject: [R] Calculating Kendall's tau
In-Reply-To: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
References: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED676699B0A0@GOLD.corp.lgc-group.com>

> I am analyzing trend ?using Mann-kendall ?test for 31 independent sample, each
> sample ?have 34 years dataset. ?I supposed to find Kendall ?tau? for each
> sample. The data is arranged in column wise (I attached ?the data).To find
> Kendall tau, I wrote R script as:
> ...
> Anyone can tell me how can I get orderly displayed ??tau? value? 

Usually, in R, a hypothesis test returns an object, and you can extract an individual element of that object.

MannKendall seems to be no exception. Looking at the help page, a MannKendall test returns...
" A list with class Kendall.
tau 	Kendall?s tau statistic
sl 	two-sided p-value
S	Kendall Score
D	denominator, tau=S/D
varS	variance of S"

To get just tau, say something like MannKendalltau[i]<-MannKendall(y[,i])$tau

But your code is a bit of a mess....
MannKendalltau<- numeric(nc) simply makes MannKendalltau a single integer equal to nc; that doesn't look sensible when the next thing you do is treat MannKendalltau as a vector. R's been kind to you and extended MannKendalltau when you tried to add things to later, non-existent, elements, but it clearly wasn't the right thing to do. Look up ?numeric, and then look up ?vector for next time you want to set up an empty vector.

Second, since MannKendall(y[,i]) ) returns a list object of class Kendall, MannKendalltau[i]<-MannKendall(y[,i]) assigns a whole  object containing 5 values to each new element of your MannKendalltau. So your result is a list of lists.

Finally, you don?t need a loop at all. On a data frame, sapply would work nicely, so (although I've not tested it) something like

sapply(desta[,2:nc], 2, function(x) ManKendall(x)$tau)

ought to do the whole thing in one shot and package it nicely into a named vector while it's about it.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From cflynch at ncsu.edu  Thu Apr  2 16:25:20 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Thu, 2 Apr 2015 10:25:20 -0400
Subject: [R] Kruskal-Wallace power calculations.
Message-ID: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>

Greetings, I am working on a project where we are applying the
Kruskal-Wallace test to some factor data to evaluate their correlation with
existing grade data.  I know that the grade data is nonnormal therefore we
cannot rely on ANOVA or a similar parametric test.  What I would like to
find is a mechanism for making power calculations for the KW test given the
nonparametric assumptions.  My perusal of the literature has suggested that
a simulation would be the best method.

Can anyone point me to good examples of such simulations for KW in R?  And
does anyone have a favourite package for generating simulated data or
conducting such tests?

    Thank you,
    Collin.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Apr  2 16:40:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 02 Apr 2015 10:40:45 -0400
Subject: [R] Inverse of many small matrices
In-Reply-To: <551D44CC.5010005@feng.li>
References: <551D44CC.5010005@feng.li>
Message-ID: <551D54ED.7060902@gmail.com>

On 02/04/2015 9:31 AM, Feng Li wrote:
> Dear all,
>
> I am working with a likelihood function that requires the inverse of
> many small covariance matrices for multivariate normal densities. When
> the sample size is large, this calculation is really heavy. Those
> matrices are independent but unfortunately I can hardly find a way to
> vectorize them.
>
> Can anyone give me a hint to speed this up? Thanks in advance!
>

Are you sure you need the inverses of those matrices?  For example, if 
you are trying to compute x^t Ainv x,
where Ainv is A inverse, the naive calculation is t(x) %*% solve(A) %*% 
x, but that's likely slower and less accurate than other equivalent 
ones, such as x %*% solve(A, x), and I wouldn't be surprised if there 
are better ones.

Duncan Murdoch


From acefix at rocketmail.com  Thu Apr  2 16:20:54 2015
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 2 Apr 2015 14:20:54 +0000 (UTC)
Subject: [R] about model.matrix
In-Reply-To: <551C15AE.8050208@dewey.myzen.co.uk>
References: <551C15AE.8050208@dewey.myzen.co.uk>
Message-ID: <590951224.3724632.1427984454648.JavaMail.yahoo@mail.yahoo.com>

Thank you very much for the response. Then what does it mean? I am not a stat person, but have to use it for my project. :(
Could you please recommend some readings about it? Thanks a lot! 


     On Wednesday, April 1, 2015 10:58 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
   

 This is really a question about statistics rather than R but see below

On 01/04/2015 06:28, Fix Ace wrote:
> I tried to run the sample code from R:
> dd <- data.frame(a = gl(3,4), b = gl(4,1,12))? a b
> 1? 1 1
> 2? 1 2
> 3? 1 3
> 4? 1 4
> 5? 2 1
> 6? 2 2
> 7? 2 3
> 8? 2 4
> 9? 3 1
> 10 3 2
> 11 3 3
> 12 3 4
> options("contrasts")
> model.matrix(~ a + b, dd)(Intercept) a2 a3 b2 b3 b4
> 1? ? ? ? ? ? 1? 0? 0? 0? 0? 0
> 2? ? ? ? ? ? 1? 0? 0? 1? 0? 0
> 3? ? ? ? ? ? 1? 0? 0? 0? 1? 0
> 4? ? ? ? ? ? 1? 0? 0? 0? 0? 1
> 5? ? ? ? ? ? 1? 1? 0? 0? 0? 0
> 6? ? ? ? ? ? 1? 1? 0? 1? 0? 0
> 7? ? ? ? ? ? 1? 1? 0? 0? 1? 0
> 8? ? ? ? ? ? 1? 1? 0? 0? 0? 1
> 9? ? ? ? ? ? 1? 0? 1? 0? 0? 0
> 10? ? ? ? ? 1? 0? 1? 1? 0? 0
> 11? ? ? ? ? 1? 0? 1? 0? 1? 0
> 12? ? ? ? ? 1? 0? 1? 0? 0? 1
> when I tried to remove the intercept from the matrix, I used the following codemodel.matrix(~ 0+a + b, dd)
>? a1 a2 a3 b2 b3 b41 1 0 0 0 0 02 1 0 0 1 0 03 1 0 0 0 1 04 1 0 0 0 0 15 0 1 0 0 0 06 0 1 0 1 0 07 0 1 0 0 1 08 0 1 0? 0 0 19 0 0 1 0 0 010 0 0 1 1 0 011 0 0 1 0 1 012 0 0 1 0 0 1 when I tried to remove the intercept
>

That got mangled but

In your matrix below try forming the sum of a1+a2+a3 and the sum of 
b1+b2+b3+b4. I think you will find they are linearly related.

> Here I noticed that, all levels of a, a1, a2, and a3, were included. I wonder how? I can include the "b1" in the matrix as well?? a1 a2 a3 b1 b2 b3 b4
> 1? 1? 0? 0? 1? 0? 0? 0
> 2? 1? 0? 0? 0? 1? 0? 0
> 3? 1? 0? 0? 0? 0? 1? 0
> 4? 1? 0? 0? 0? 0? 0? 1
> 5? 0? 1? 0? 1? 0? 0? 0
> 6? 0? 1? 0? 0? 1? 0? 0
> 7? 0? 1? 0? 0? 0? 1? 0
> 8? 0? 1? 0? 0? 0? 0? 1
> 9? 0? 0? 1? 1? 0? 0? 0
> 10? 0? 0? 1? 0? 1? 0? 0
> 11? 0? 0? 1? 0? 0? 1? 0
> 12? 0? 0? 1? 0? 0? 0? 1
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


  
	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Apr  2 17:08:02 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 2 Apr 2015 07:08:02 -0800
Subject: [R] Error in dis[sppInSample,
 sppInSample]:subscript out of  bounds
In-Reply-To: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>
Message-ID: <B2AE4C994DF.00000276jrkrideau@inbox.com>

As a follow-up to Don's reply have a look at https://github.com/hadley/devtools/wiki/Reproducibility and/or  ttp://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for some useful suggestions on how to frame a question.

If you need to include sample data with your reply please read carefully about the dput function and supply your data in dput() format.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marion.howard at hotmail.com
> Sent: Thu, 2 Apr 2015 07:04:50 +1000
> To: r-help at r-project.org
> Subject: [R] Error in dis[sppInSample,sppInSample]:subscript out of
> bounds
> 
> Hello,
> I am new to R and am encountering an error message that I cannot find a
> solution for.
> I am attempting to calculate MPD (mean pairwise distance), without
> weighting for abundance, with a community species list and a phylogenetic
> tree in newick format with branch lengths.
> I have read in both list and tree .txt files and calculated PD without
> any problem.
> To calculate MPD I have entered:>MPD1=mpd(list,cophenetic(tree))
> Error:Error in dis[sppInSample, sppInSample] : subscript out of bounds
> Thank you for you helpCheersMarion.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From gunter.berton at gene.com  Thu Apr  2 17:16:17 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 2 Apr 2015 08:16:17 -0700
Subject: [R] about model.matrix
In-Reply-To: <590951224.3724632.1427984454648.JavaMail.yahoo@mail.yahoo.com>
References: <551C15AE.8050208@dewey.myzen.co.uk>
	<590951224.3724632.1427984454648.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te1+uxEce19+Mj-LkthOZ759qFfE-07WT9LTYUiTvMoOZQ@mail.gmail.com>

This is a big topic. You might try looking for tutorials on "linear
models", with "rank" or "rank deficiency" as subtopics. One possible
book is:

http://www.amazon.com/Linear-Models-Chapman-Statistical-Science/dp/1439887330/ref=sr_1_5?s=books&ie=UTF8&qid=1427987551&sr=1-5&keywords=linear+models+in+statistics

... but there are dozens.

Better yet, consult a local statistical expert for help. Trying to
educate yourself is laudable, but may be unrealistic.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Apr 2, 2015 at 7:20 AM, Fix Ace <acefix at rocketmail.com> wrote:
> Thank you very much for the response. Then what does it mean? I am not a stat person, but have to use it for my project. :(
> Could you please recommend some readings about it? Thanks a lot!
>
>
>      On Wednesday, April 1, 2015 10:58 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
>
>  This is really a question about statistics rather than R but see below
>
> On 01/04/2015 06:28, Fix Ace wrote:
>> I tried to run the sample code from R:
>> dd <- data.frame(a = gl(3,4), b = gl(4,1,12))  a b
>> 1  1 1
>> 2  1 2
>> 3  1 3
>> 4  1 4
>> 5  2 1
>> 6  2 2
>> 7  2 3
>> 8  2 4
>> 9  3 1
>> 10 3 2
>> 11 3 3
>> 12 3 4
>> options("contrasts")
>> model.matrix(~ a + b, dd)(Intercept) a2 a3 b2 b3 b4
>> 1            1  0  0  0  0  0
>> 2            1  0  0  1  0  0
>> 3            1  0  0  0  1  0
>> 4            1  0  0  0  0  1
>> 5            1  1  0  0  0  0
>> 6            1  1  0  1  0  0
>> 7            1  1  0  0  1  0
>> 8            1  1  0  0  0  1
>> 9            1  0  1  0  0  0
>> 10          1  0  1  1  0  0
>> 11          1  0  1  0  1  0
>> 12          1  0  1  0  0  1
>> when I tried to remove the intercept from the matrix, I used the following codemodel.matrix(~ 0+a + b, dd)
>>  a1 a2 a3 b2 b3 b41 1 0 0 0 0 02 1 0 0 1 0 03 1 0 0 0 1 04 1 0 0 0 0 15 0 1 0 0 0 06 0 1 0 1 0 07 0 1 0 0 1 08 0 1 0  0 0 19 0 0 1 0 0 010 0 0 1 1 0 011 0 0 1 0 1 012 0 0 1 0 0 1 when I tried to remove the intercept
>>
>
> That got mangled but
>
> In your matrix below try forming the sum of a1+a2+a3 and the sum of
> b1+b2+b3+b4. I think you will find they are linearly related.
>
>> Here I noticed that, all levels of a, a1, a2, and a3, were included. I wonder how  I can include the "b1" in the matrix as well?  a1 a2 a3 b1 b2 b3 b4
>> 1  1  0  0  1  0  0  0
>> 2  1  0  0  0  1  0  0
>> 3  1  0  0  0  0  1  0
>> 4  1  0  0  0  0  0  1
>> 5  0  1  0  1  0  0  0
>> 6  0  1  0  0  1  0  0
>> 7  0  1  0  0  0  1  0
>> 8  0  1  0  0  0  0  1
>> 9  0  0  1  1  0  0  0
>> 10  0  0  1  0  1  0  0
>> 11  0  0  1  0  0  1  0
>> 12  0  0  1  0  0  0  1
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Apr  2 17:21:02 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 2 Apr 2015 08:21:02 -0700
Subject: [R] Calculating Kendall's tau
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED676699B0A0@GOLD.corp.lgc-group.com>
References: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
	<A4E5A0B016B8CB41A485FC629B633CED676699B0A0@GOLD.corp.lgc-group.com>
Message-ID: <CAF8bMcbnC6E_HLcZyA+_wm56QBGcntq5q2e1uRuRkcMAQ_xFbA@mail.gmail.com>

> MannKendalltau<- numeric(nc) simply makes MannKendalltau a single
> integer equal to nc; that doesn't look sensible when the next thing you
> do is treat MannKendalltau as a vector.

No, numeric(nc) makes a "numeric" (double precision) vector of length nc
filled with zeros.

Perhaps you were thinking of as.numeric(nc), which makes a numeric vector
of length one containing the value nc.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 2, 2015 at 7:06 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > I am analyzing trend  using Mann-kendall  test for 31 independent
> sample, each
> > sample  have 34 years dataset.  I supposed to find Kendall ?tau? for each
> > sample. The data is arranged in column wise (I attached  the data).To
> find
> > Kendall tau, I wrote R script as:
> > ...
> > Anyone can tell me how can I get orderly displayed  ?tau? value?
>
> Usually, in R, a hypothesis test returns an object, and you can extract an
> individual element of that object.
>
> MannKendall seems to be no exception. Looking at the help page, a
> MannKendall test returns...
> " A list with class Kendall.
> tau     Kendall?s tau statistic
> sl      two-sided p-value
> S       Kendall Score
> D       denominator, tau=S/D
> varS    variance of S"
>
> To get just tau, say something like
> MannKendalltau[i]<-MannKendall(y[,i])$tau
>
> But your code is a bit of a mess....
> MannKendalltau<- numeric(nc) simply makes MannKendalltau a single integer
> equal to nc; that doesn't look sensible when the next thing you do is treat
> MannKendalltau as a vector. R's been kind to you and extended
> MannKendalltau when you tried to add things to later, non-existent,
> elements, but it clearly wasn't the right thing to do. Look up ?numeric,
> and then look up ?vector for next time you want to set up an empty vector.
>
> Second, since MannKendall(y[,i]) ) returns a list object of class Kendall,
> MannKendalltau[i]<-MannKendall(y[,i]) assigns a whole  object containing 5
> values to each new element of your MannKendalltau. So your result is a list
> of lists.
>
> Finally, you don?t need a loop at all. On a data frame, sapply would work
> nicely, so (although I've not tested it) something like
>
> sapply(desta[,2:nc], 2, function(x) ManKendall(x)$tau)
>
> ought to do the whole thing in one shot and package it nicely into a named
> vector while it's about it.
>
> S Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:17}}


From jdnewmil at dcn.davis.CA.us  Thu Apr  2 17:23:06 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 02 Apr 2015 08:23:06 -0700
Subject: [R] Kruskal-Wallace power calculations.
In-Reply-To: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
References: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
Message-ID: <19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>

Please stop... you are acting like a broken record, and are also posting in HTML format. Please read the Posting Guide and demonstrate that you have used a search engine on this topic before posting again.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 2, 2015 7:25:20 AM PDT, Collin Lynch <cflynch at ncsu.edu> wrote:
>Greetings, I am working on a project where we are applying the
>Kruskal-Wallace test to some factor data to evaluate their correlation
>with
>existing grade data.  I know that the grade data is nonnormal therefore
>we
>cannot rely on ANOVA or a similar parametric test.  What I would like
>to
>find is a mechanism for making power calculations for the KW test given
>the
>nonparametric assumptions.  My perusal of the literature has suggested
>that
>a simulation would be the best method.
>
>Can anyone point me to good examples of such simulations for KW in R? 
>And
>does anyone have a favourite package for generating simulated data or
>conducting such tests?
>
>    Thank you,
>    Collin.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Thu Apr  2 18:02:39 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 02 Apr 2015 17:02:39 +0100
Subject: [R] about model.matrix
In-Reply-To: <590951224.3724632.1427984454648.JavaMail.yahoo@mail.yahoo.com>
References: <551C15AE.8050208@dewey.myzen.co.uk>
	<590951224.3724632.1427984454648.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <551D681F.8080509@dewey.myzen.co.uk>

You cannot have columns which are linearly dependent.

Starting a project which uses statistics without having some sort of 
local statistical backup seems unprofitable.

install.packages("fortunes") # if not already done
library(fortunes)
fortune(122)

On 02/04/2015 15:20, Fix Ace wrote:
> Thank you very much for the response. Then what does it mean? I am not a
> stat person, but have to use it for my project. :(
>
> Could you please recommend some readings about it? Thanks a lot!
>
>
>
> On Wednesday, April 1, 2015 10:58 AM, Michael Dewey
> <lists at dewey.myzen.co.uk> wrote:
>
>
> This is really a question about statistics rather than R but see below
>
> On 01/04/2015 06:28, Fix Ace wrote:
>  > I tried to run the sample code from R:
>  > dd <- data.frame(a = gl(3,4), b = gl(4,1,12))  a b
>  > 1  1 1
>  > 2  1 2
>  > 3  1 3
>  > 4  1 4
>  > 5  2 1
>  > 6  2 2
>  > 7  2 3
>  > 8  2 4
>  > 9  3 1
>  > 10 3 2
>  > 11 3 3
>  > 12 3 4
>  > options("contrasts")
>  > model.matrix(~ a + b, dd)(Intercept) a2 a3 b2 b3 b4
>  > 1            1  0  0  0  0  0
>  > 2            1  0  0  1  0  0
>  > 3            1  0  0  0  1  0
>  > 4            1  0  0  0  0  1
>  > 5            1  1  0  0  0  0
>  > 6            1  1  0  1  0  0
>  > 7            1  1  0  0  1  0
>  > 8            1  1  0  0  0  1
>  > 9            1  0  1  0  0  0
>  > 10          1  0  1  1  0  0
>  > 11          1  0  1  0  1  0
>  > 12          1  0  1  0  0  1
>  > when I tried to remove the intercept from the matrix, I used the
> following codemodel.matrix(~ 0+a + b, dd)
>  >  a1 a2 a3 b2 b3 b41 1 0 0 0 0 02 1 0 0 1 0 03 1 0 0 0 1 04 1 0 0 0 0
> 15 0 1 0 0 0 06 0 1 0 1 0 07 0 1 0 0 1 08 0 1 0  0 0 19 0 0 1 0 0 010 0
> 0 1 1 0 011 0 0 1 0 1 012 0 0 1 0 0 1 when I tried to remove the intercept
>  >
>
> That got mangled but
>
> In your matrix below try forming the sum of a1+a2+a3 and the sum of
> b1+b2+b3+b4. I think you will find they are linearly related.
>
>
>  > Here I noticed that, all levels of a, a1, a2, and a3, were included.
> I wonder how  I can include the "b1" in the matrix as well?  a1 a2 a3 b1
> b2 b3 b4
>  > 1  1  0  0  1  0  0  0
>  > 2  1  0  0  0  1  0  0
>  > 3  1  0  0  0  0  1  0
>  > 4  1  0  0  0  0  0  1
>  > 5  0  1  0  1  0  0  0
>  > 6  0  1  0  0  1  0  0
>  > 7  0  1  0  0  0  1  0
>  > 8  0  1  0  0  0  0  1
>  > 9  0  0  1  1  0  0  0
>  > 10  0  0  1  0  1  0  0
>  > 11  0  0  1  0  0  1  0
>  > 12  0  0  1  0  0  0  1
>
>  >
>  >     [[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dimitri.liakhovitski at gmail.com  Thu Apr  2 19:03:06 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 2 Apr 2015 13:03:06 -0400
Subject: [R] Color US counties on US map using a numeric variable for color
	intensity
Message-ID: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>

I have a data frame 'mydata.final' (see below) that contains US
counties and a continuous numeric variable 'Mean.Wait' that ranges
from zero to 10 or so. I also created variable 'wait' that is based on
the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
'Mean.Wait') to 5 (highest values on 'Mean.Wait').

I can create a map of the US with the counties colored based on the
values of 'wait' using R package 'maps':

#################################################################
### Generating an artificial data file:
#################################################################
library(maps)
mydata.final <- data.frame(county = (map('county', plot = FALSE)$names),
                 stringsAsFactors = F)

### My numeric variable:
set.seed(123)
mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10

### Introducing NAs to mimic my real data set:
set.seed(1234)
mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA

### Cutting the original numeric variable into categories
### because I don't know how to color based on 'Mean.Wait':
mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
levels(mydata.final$wait) <- 1:5
mydata.final$wait <- as.numeric(as.character(mydata.final$wait))

####################################################################
Building a US map based on 'wait' (5 categories)
#################################################################

### Creating my 5 colors:
pal <- colorRampPalette(c("yellow", "red"))
allcolors <- pal(5)

### Looking at my 5 colors:
barplot(1:5, rep(1,5), col = allcolors, horiz = T)

### Builiding the US map using 5 categories in 'wait':
map('county', fill = TRUE, col = allcolors[mydata.final$wait],
            resolution = 0, lty = 0, bg = "transparent")
map('state', lwd=1, add=TRUE)

My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
('wait'), I'd like to color the counties on the map based on the
intensity of my (continuous) 'Mean.Wait'. What would be the way to do
it and maybe even to add a legend?
Thanks a lot!

-- 
Dimitri Liakhovitski


From dwinsemius at comcast.net  Thu Apr  2 19:13:59 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Apr 2015 10:13:59 -0700
Subject: [R] From replicate to accesing sublists
In-Reply-To: <1149840251.3444077.1427950746802.JavaMail.yahoo@mail.yahoo.com>
References: <FD08E6E6-A318-4ED4-9C36-DB8A164283DE@comcast.net>
	<1149840251.3444077.1427950746802.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4F32DA39-16A7-48B5-980F-79AC7D0E7669@comcast.net>


On Apr 1, 2015, at 9:59 PM, Alaios wrote:

You are still replying with formatted email. This mailing list attempts to be an HTML-free zone.

> Thanks.The code you gave me at the end works correctly.. I was wondering if there is more efficient way to access each element withouth this classic for loop.

I don't think we can answer that unless we have a better understanding of the goals of this effort and the uses to which the data will be put.

If you used apply() you could work on an entire row or column at a time.

You could disguise the loop with no gain in time efficiency with sapply().

Shadows <- sapply(error_suburban_0, "[[", 'Shadowing') # saves you the typing effort of not calculating the length of the object; cleaner syntax.

There is a misconception that refuses to die, despite being smacked down many,many times on Rhelp, that loops in R are inefficient. It is usually the algorithm inside the loop that is inefficient.

-- 
David.

> 
> Regards
> Alex
> 
> 
> 
> On Wednesday, April 1, 2015 5:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> On Apr 1, 2015, at 3:34 AM, Alaios via R-help wrote:
> 
> > Dear all,I have a R structure that was created with replicate.The data sets looks to be a matrix with each cell being a list.
> > str(error_suburban_0[,1],max.level=1)
> > List of 4
> > $ vaR      :List of 20
> >  ..- attr(*, "class")= chr "variogram"
> > $ Shadowing:List of 2
> >  ..- attr(*, "class")= chr "geodata"
> > $ FIT      :List of 1
> > $ propmodel:List of 12
> >  ..- attr(*, "class")= chr "lm"
> > 
> > 
> > The error_suburban is a matrix that each field so 
> > error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4],... and so on,  contains the four sublists
> > $ vaR      :List of 20
> >  ..- attr(*, "class")= chr "variogram"
> > $ Shadowing:List of 2
> >  ..- attr(*, "class")= chr "geodata"
> > $ FIT      :List of 1
> > $ propmodel:List of 12
> >  ..- attr(*, "class")= chr "lm"
> > 
> > 
> > I would like to pick for each of these matrix elements to collect only the $Shadowing sublist
> > error_suburban_0[,1], error_suburban_0[,2], error_suburban_0[,3], error_suburban_0[,4]... and so on
> > 
> > Right now I am implementing this by a for loop that access each matrix element sequentially.
> 
> It would have been better to show the results of dim() or dput(). Matrix objects (which are capable of holding lists) should be accessible with either a single or double argument to "[". This should deliver contents:
> 
> for (i in 1:4)  print(  error_suburban_0[i]$Shadowing )
> 
> If the matrix has 4 or more rows, then that would be accessing only from the first column. If fewer than 4 rows, you would be wrapping around to later columns.
> 
> -- 
> David.
> 
> 
> > 
> > Can you please advice me if there is a better approach to do that in R?
> > Regards
> > Alex
> >  
> > 
> >     [[alternative HTML version deleted]]
> 
> 
> This is a plain text mailing list. Please reconfigure your email client to sent in plain text.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Apr  2 19:16:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Apr 2015 10:16:46 -0700
Subject: [R] Calculating Kendall's tau
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED676699B0A0@GOLD.corp.lgc-group.com>
References: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
	<A4E5A0B016B8CB41A485FC629B633CED676699B0A0@GOLD.corp.lgc-group.com>
Message-ID: <80A5132A-D606-4C81-8112-E12673012539@comcast.net>


On Apr 2, 2015, at 7:06 AM, S Ellison wrote:

>> I am analyzing trend  using Mann-kendall  test for 31 independent sample, each
>> sample  have 34 years dataset.  I supposed to find Kendall ?tau? for each
>> sample. The data is arranged in column wise (I attached  the data).To find
>> Kendall tau, I wrote R script as:
>> ...
>> Anyone can tell me how can I get orderly displayed  ?tau? value? 
> 
> Usually, in R, a hypothesis test returns an object, and you can extract an individual element of that object.
> 
> MannKendall seems to be no exception. Looking at the help page, a MannKendall test returns...
> " A list with class Kendall.
> tau 	Kendall?s tau statistic
> sl 	two-sided p-value
> S	Kendall Score
> D	denominator, tau=S/D
> varS	variance of S"
> 
> To get just tau, say something like MannKendalltau[i]<-MannKendall(y[,i])$tau
> 
> But your code is a bit of a mess....
> MannKendalltau<- numeric(nc) simply makes MannKendalltau a single integer equal to nc; that doesn't look sensible when the next thing you do is treat MannKendalltau as a vector. R's been kind to you and extended MannKendalltau when you tried to add things to later, non-existent, elements, but it clearly wasn't the right thing to do. Look up ?numeric, and then look up ?vector for next time you want to set up an empty vector.
> 
> Second, since MannKendall(y[,i]) ) returns a list object of class Kendall, MannKendalltau[i]<-MannKendall(y[,i]) assigns a whole  object containing 5 values to each new element of your MannKendalltau. So your result is a list of lists.
> 
> Finally, you don?t need a loop at all. On a data frame, sapply would work nicely, so (although I've not tested it) something like
> 
> sapply(desta[,2:nc], 2, function(x) ManKendall(x)$tau)

That looks more line an apply call. The second argument to sapply needs to be a function or function name.


-- 
David.
> 
> ought to do the whole thing in one shot and package it nicely into a named vector while it's about it.
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:19}}


From sjkiss at gmail.com  Thu Apr  2 21:30:46 2015
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 2 Apr 2015 15:30:46 -0400
Subject: [R] recode the same subset of variables in several list elements
Message-ID: <F43FA97C-4A07-463B-9EDC-7A6C1B2F305A@gmail.com>

Hi there: I have a list of data frames with identical variable  names.  I?d like to reverse scale the same variables in each data.frame.  
I?d appreciate any one?s suggestions as to how to accomplish this. Right now, I?m working with the code at the very bottom of my sample data. 
Thanks, Simon Kiss

#Create data.frame1
df<-data.frame(
  ivar1=sample(c(1,2,3), replace=TRUE, size=100),
  ivar2=sample(c(1,2,3), replace=TRUE, size=100),
  hvar1=sample(c(1,2,3), replace=TRUE, size=100),
  hvar2=sample(c(1,2,3), replace=TRUE, size=100),
  evar1=sample(c(1,2,3), replace=TRUE, size=100),
  evar2=sample(c(1,2,3), replace=TRUE, size=100)
  )
  
#data.frame2
  df1<-data.frame(
    ivar1=sample(c(1,2,3), replace=TRUE, size=100),
    ivar2=sample(c(1,2,3), replace=TRUE, size=100),
    hvar1=sample(c(1,2,3), replace=TRUE, size=100),
    hvar2=sample(c(1,2,3), replace=TRUE, size=100),
    evar1=sample(c(1,2,3), replace=TRUE, size=100),
    evar2=sample(c(1,2,3), replace=TRUE, size=100)
  )

#List
list1<-list(df, df1)
#vector of first variables I?d like to recode
i.recodes<-grep('^i.', names(df), value=TRUE)
#Vector of second variables to recode
e.recodes<-grep('^e.', names(df), value=TRUE)

#Set up RESCALE function from RPMG package
RESCALE <- function (x, nx1, nx2, minx, maxx) 
{ nx = nx1 + (nx2 - nx1) * (x - minx)/(maxx - minx)
  return(nx)
}

#This is what I?m playing around with
test<-lapply(list1, function(y) {
  out<-y[,i.recodes]
  out<-lapply(out, function(x) RESCALE(x, 0,1,1,6))
  y[,names(x)]<-out
})
	[[alternative HTML version deleted]]


From desta_yo at yahoo.com  Thu Apr  2 21:44:02 2015
From: desta_yo at yahoo.com (Desta Yoseph)
Date: Thu, 2 Apr 2015 19:44:02 +0000 (UTC)
Subject: [R] Calculating Kendall's tau
In-Reply-To: <80A5132A-D606-4C81-8112-E12673012539@comcast.net>
References: <80A5132A-D606-4C81-8112-E12673012539@comcast.net>
Message-ID: <740876354.4627804.1428003842321.JavaMail.yahoo@mail.yahoo.com>

Thank you for ?the explanation and comments. I managed to solve and your comments are helpfully!?thanks once again,Desta 


     On Thursday, April 2, 2015 7:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
   

 
On Apr 2, 2015, at 7:06 AM, S Ellison wrote:

>> I am analyzing trend? using Mann-kendall? test for 31 independent sample, each
>> sample? have 34 years dataset.? I supposed to find Kendall ?tau? for each
>> sample. The data is arranged in column wise (I attached? the data).To find
>> Kendall tau, I wrote R script as:
>> ...
>> Anyone can tell me how can I get orderly displayed? ?tau? value? 
> 
> Usually, in R, a hypothesis test returns an object, and you can extract an individual element of that object.
> 
> MannKendall seems to be no exception. Looking at the help page, a MannKendall test returns...
> " A list with class Kendall.
> tau ??? Kendall?s tau statistic
> sl ??? two-sided p-value
> S??? Kendall Score
> D??? denominator, tau=S/D
> varS??? variance of S"
> 
> To get just tau, say something like MannKendalltau[i]<-MannKendall(y[,i])$tau
> 
> But your code is a bit of a mess....
> MannKendalltau<- numeric(nc) simply makes MannKendalltau a single integer equal to nc; that doesn't look sensible when the next thing you do is treat MannKendalltau as a vector. R's been kind to you and extended MannKendalltau when you tried to add things to later, non-existent, elements, but it clearly wasn't the right thing to do. Look up ?numeric, and then look up ?vector for next time you want to set up an empty vector.
> 
> Second, since MannKendall(y[,i]) ) returns a list object of class Kendall, MannKendalltau[i]<-MannKendall(y[,i]) assigns a whole? object containing 5 values to each new element of your MannKendalltau. So your result is a list of lists.
> 
> Finally, you don?t need a loop at all. On a data frame, sapply would work nicely, so (although I've not tested it) something like
> 
> sapply(desta[,2:nc], 2, function(x) ManKendall(x)$tau)

That looks more line an apply call. The second argument to sapply needs to be a function or function name.


-- 
David.
> 
> ought to do the whole thing in one shot and package it nicely into a named vector while it's about it.
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:12}}


From jvadams at usgs.gov  Thu Apr  2 22:26:08 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 2 Apr 2015 15:26:08 -0500
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
Message-ID: <CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>

Dimitri,

You could use colorRamp() and rgb() to get more continuous colors.
For example

newpal <- colorRamp(c("yellow", "red"))
missing <- is.na(mydata.final$Mean.Wait)
newcol <- ifelse(missing, "white",
  rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)), maxColorValue=255))
map('county', fill=TRUE, col=newcol,
            resolution=0, lty=0, bg="transparent")
map('state', lwd=1, add=TRUE)

Jean


On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> I have a data frame 'mydata.final' (see below) that contains US
> counties and a continuous numeric variable 'Mean.Wait' that ranges
> from zero to 10 or so. I also created variable 'wait' that is based on
> the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
>
> I can create a map of the US with the counties colored based on the
> values of 'wait' using R package 'maps':
>
> #################################################################
> ### Generating an artificial data file:
> #################################################################
> library(maps)
> mydata.final <- data.frame(county = (map('county', plot = FALSE)$names),
>                  stringsAsFactors = F)
>
> ### My numeric variable:
> set.seed(123)
> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
>
> ### Introducing NAs to mimic my real data set:
> set.seed(1234)
> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
>
> ### Cutting the original numeric variable into categories
> ### because I don't know how to color based on 'Mean.Wait':
> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
> levels(mydata.final$wait) <- 1:5
> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
>
> ####################################################################
> Building a US map based on 'wait' (5 categories)
> #################################################################
>
> ### Creating my 5 colors:
> pal <- colorRampPalette(c("yellow", "red"))
> allcolors <- pal(5)
>
> ### Looking at my 5 colors:
> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
>
> ### Builiding the US map using 5 categories in 'wait':
> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
>             resolution = 0, lty = 0, bg = "transparent")
> map('state', lwd=1, add=TRUE)
>
> My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
> ('wait'), I'd like to color the counties on the map based on the
> intensity of my (continuous) 'Mean.Wait'. What would be the way to do
> it and maybe even to add a legend?
> Thanks a lot!
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Apr  2 23:02:44 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 2 Apr 2015 17:02:44 -0400
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
	<CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
Message-ID: <CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>

Thank you, Jean, but I think this newcol line is not working. I am running:

newcol <- ifelse(missing, "white",

rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
na.rm=T)),
                     maxColorValue=255))

# And I am getting:
Error in rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,  :
  color intensity NA, not in 0:255

I think it's not liking the NAs - despite the ifelse...

On Thu, Apr 2, 2015 at 4:26 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> Dimitri,
>
> You could use colorRamp() and rgb() to get more continuous colors.
> For example
>
> newpal <- colorRamp(c("yellow", "red"))
> missing <- is.na(mydata.final$Mean.Wait)
> newcol <- ifelse(missing, "white",
>   rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)), maxColorValue=255))
> map('county', fill=TRUE, col=newcol,
>             resolution=0, lty=0, bg="transparent")
> map('state', lwd=1, add=TRUE)
>
> Jean
>
>
> On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>>
>> I have a data frame 'mydata.final' (see below) that contains US
>> counties and a continuous numeric variable 'Mean.Wait' that ranges
>> from zero to 10 or so. I also created variable 'wait' that is based on
>> the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
>> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
>>
>> I can create a map of the US with the counties colored based on the
>> values of 'wait' using R package 'maps':
>>
>> #################################################################
>> ### Generating an artificial data file:
>> #################################################################
>> library(maps)
>> mydata.final <- data.frame(county = (map('county', plot = FALSE)$names),
>>                  stringsAsFactors = F)
>>
>> ### My numeric variable:
>> set.seed(123)
>> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
>>
>> ### Introducing NAs to mimic my real data set:
>> set.seed(1234)
>> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
>>
>> ### Cutting the original numeric variable into categories
>> ### because I don't know how to color based on 'Mean.Wait':
>> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
>> levels(mydata.final$wait) <- 1:5
>> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
>>
>> ####################################################################
>> Building a US map based on 'wait' (5 categories)
>> #################################################################
>>
>> ### Creating my 5 colors:
>> pal <- colorRampPalette(c("yellow", "red"))
>> allcolors <- pal(5)
>>
>> ### Looking at my 5 colors:
>> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
>>
>> ### Builiding the US map using 5 categories in 'wait':
>> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
>>             resolution = 0, lty = 0, bg = "transparent")
>> map('state', lwd=1, add=TRUE)
>>
>> My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
>> ('wait'), I'd like to color the counties on the map based on the
>> intensity of my (continuous) 'Mean.Wait'. What would be the way to do
>> it and maybe even to add a legend?
>> Thanks a lot!
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Thu Apr  2 23:08:57 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 2 Apr 2015 17:08:57 -0400
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
	<CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
	<CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>
Message-ID: <CAN2xGJb6vLPdmxx49tAUO5tbw6VfvVoScO=Gi0nB3s+St9hTcw@mail.gmail.com>

Jean, I think I fixed it:

newpal <- colorRamp(c("yellow", "red"))
missing <- is.na(mydata.final$Mean.Wait)
newcol <- ifelse(missing, "white",

rgb(newpal(mydata.final$Mean.Wait[!is.na(mydata.final$Mean.Wait)]/
                                  max(mydata.final$Mean.Wait,
na.rm=T)), maxColorValue=255))
map('county', fill=TRUE, col=newcol,
    resolution=0, lty=0, bg="transparent")
map('state', lwd=1, add=TRUE)

One understanding question: what exactly does this rgb line do and why
do we have to say "maxColorValue=255"?
Thank you!

On Thu, Apr 2, 2015 at 5:02 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Thank you, Jean, but I think this newcol line is not working. I am running:
>
> newcol <- ifelse(missing, "white",
>
> rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
> na.rm=T)),
>                      maxColorValue=255))
>
> # And I am getting:
> Error in rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,  :
>   color intensity NA, not in 0:255
>
> I think it's not liking the NAs - despite the ifelse...
>
> On Thu, Apr 2, 2015 at 4:26 PM, Adams, Jean <jvadams at usgs.gov> wrote:
>> Dimitri,
>>
>> You could use colorRamp() and rgb() to get more continuous colors.
>> For example
>>
>> newpal <- colorRamp(c("yellow", "red"))
>> missing <- is.na(mydata.final$Mean.Wait)
>> newcol <- ifelse(missing, "white",
>>   rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)), maxColorValue=255))
>> map('county', fill=TRUE, col=newcol,
>>             resolution=0, lty=0, bg="transparent")
>> map('state', lwd=1, add=TRUE)
>>
>> Jean
>>
>>
>> On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>>
>>> I have a data frame 'mydata.final' (see below) that contains US
>>> counties and a continuous numeric variable 'Mean.Wait' that ranges
>>> from zero to 10 or so. I also created variable 'wait' that is based on
>>> the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
>>> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
>>>
>>> I can create a map of the US with the counties colored based on the
>>> values of 'wait' using R package 'maps':
>>>
>>> #################################################################
>>> ### Generating an artificial data file:
>>> #################################################################
>>> library(maps)
>>> mydata.final <- data.frame(county = (map('county', plot = FALSE)$names),
>>>                  stringsAsFactors = F)
>>>
>>> ### My numeric variable:
>>> set.seed(123)
>>> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
>>>
>>> ### Introducing NAs to mimic my real data set:
>>> set.seed(1234)
>>> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
>>>
>>> ### Cutting the original numeric variable into categories
>>> ### because I don't know how to color based on 'Mean.Wait':
>>> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
>>> levels(mydata.final$wait) <- 1:5
>>> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
>>>
>>> ####################################################################
>>> Building a US map based on 'wait' (5 categories)
>>> #################################################################
>>>
>>> ### Creating my 5 colors:
>>> pal <- colorRampPalette(c("yellow", "red"))
>>> allcolors <- pal(5)
>>>
>>> ### Looking at my 5 colors:
>>> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
>>>
>>> ### Builiding the US map using 5 categories in 'wait':
>>> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
>>>             resolution = 0, lty = 0, bg = "transparent")
>>> map('state', lwd=1, add=TRUE)
>>>
>>> My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
>>> ('wait'), I'd like to color the counties on the map based on the
>>> intensity of my (continuous) 'Mean.Wait'. What would be the way to do
>>> it and maybe even to add a legend?
>>> Thanks a lot!
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From drjimlemon at gmail.com  Fri Apr  3 00:18:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Apr 2015 09:18:04 +1100
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CAN2xGJb6vLPdmxx49tAUO5tbw6VfvVoScO=Gi0nB3s+St9hTcw@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
	<CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
	<CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>
	<CAN2xGJb6vLPdmxx49tAUO5tbw6VfvVoScO=Gi0nB3s+St9hTcw@mail.gmail.com>
Message-ID: <CA+8X3fW=AC-ROOg0C5Swv8OT4ezomi1P8g9eOjqLagqtqyNYjA@mail.gmail.com>

Hi Dimitri,
You can also try the color.scale function in plotrix, which allows you to
specify the NA color in the call.

newcol<-color.scale(mydata.final$Mean.Wait,extremes=c("yellow","red"),na.color="white")

Jim


On Fri, Apr 3, 2015 at 8:08 AM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Jean, I think I fixed it:
>
> newpal <- colorRamp(c("yellow", "red"))
> missing <- is.na(mydata.final$Mean.Wait)
> newcol <- ifelse(missing, "white",
>
> rgb(newpal(mydata.final$Mean.Wait[!is.na(mydata.final$Mean.Wait)]/
>                                   max(mydata.final$Mean.Wait,
> na.rm=T)), maxColorValue=255))
> map('county', fill=TRUE, col=newcol,
>     resolution=0, lty=0, bg="transparent")
> map('state', lwd=1, add=TRUE)
>
> One understanding question: what exactly does this rgb line do and why
> do we have to say "maxColorValue=255"?
> Thank you!
>
> On Thu, Apr 2, 2015 at 5:02 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
> > Thank you, Jean, but I think this newcol line is not working. I am
> running:
> >
> > newcol <- ifelse(missing, "white",
> >
> > rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
> > na.rm=T)),
> >                      maxColorValue=255))
> >
> > # And I am getting:
> > Error in rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,  :
> >   color intensity NA, not in 0:255
> >
> > I think it's not liking the NAs - despite the ifelse...
> >
> > On Thu, Apr 2, 2015 at 4:26 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> >> Dimitri,
> >>
> >> You could use colorRamp() and rgb() to get more continuous colors.
> >> For example
> >>
> >> newpal <- colorRamp(c("yellow", "red"))
> >> missing <- is.na(mydata.final$Mean.Wait)
> >> newcol <- ifelse(missing, "white",
> >>   rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)), maxColorValue=255))
> >> map('county', fill=TRUE, col=newcol,
> >>             resolution=0, lty=0, bg="transparent")
> >> map('state', lwd=1, add=TRUE)
> >>
> >> Jean
> >>
> >>
> >> On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski
> >> <dimitri.liakhovitski at gmail.com> wrote:
> >>>
> >>> I have a data frame 'mydata.final' (see below) that contains US
> >>> counties and a continuous numeric variable 'Mean.Wait' that ranges
> >>> from zero to 10 or so. I also created variable 'wait' that is based on
> >>> the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
> >>> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
> >>>
> >>> I can create a map of the US with the counties colored based on the
> >>> values of 'wait' using R package 'maps':
> >>>
> >>> #################################################################
> >>> ### Generating an artificial data file:
> >>> #################################################################
> >>> library(maps)
> >>> mydata.final <- data.frame(county = (map('county', plot =
> FALSE)$names),
> >>>                  stringsAsFactors = F)
> >>>
> >>> ### My numeric variable:
> >>> set.seed(123)
> >>> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
> >>>
> >>> ### Introducing NAs to mimic my real data set:
> >>> set.seed(1234)
> >>> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
> >>>
> >>> ### Cutting the original numeric variable into categories
> >>> ### because I don't know how to color based on 'Mean.Wait':
> >>> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
> >>> levels(mydata.final$wait) <- 1:5
> >>> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
> >>>
> >>> ####################################################################
> >>> Building a US map based on 'wait' (5 categories)
> >>> #################################################################
> >>>
> >>> ### Creating my 5 colors:
> >>> pal <- colorRampPalette(c("yellow", "red"))
> >>> allcolors <- pal(5)
> >>>
> >>> ### Looking at my 5 colors:
> >>> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
> >>>
> >>> ### Builiding the US map using 5 categories in 'wait':
> >>> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
> >>>             resolution = 0, lty = 0, bg = "transparent")
> >>> map('state', lwd=1, add=TRUE)
> >>>
> >>> My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
> >>> ('wait'), I'd like to color the counties on the map based on the
> >>> intensity of my (continuous) 'Mean.Wait'. What would be the way to do
> >>> it and maybe even to add a legend?
> >>> Thanks a lot!
> >>>
> >>> --
> >>> Dimitri Liakhovitski
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >
> >
> > --
> > Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr  3 00:30:18 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Apr 2015 09:30:18 +1100
Subject: [R] recode the same subset of variables in several list elements
In-Reply-To: <F43FA97C-4A07-463B-9EDC-7A6C1B2F305A@gmail.com>
References: <F43FA97C-4A07-463B-9EDC-7A6C1B2F305A@gmail.com>
Message-ID: <CA+8X3fURYSwJi7ZuiXusro-f8uM9RYBjod5unhmP1oY7wo3RXg@mail.gmail.com>

Hi Simon,
How about this?

library(plotrix)
revlist<-grep("i",names(df),fixed=TRUE)
df[,revlist]<-sapply(df[,revlist],rescale,c(3,1))

Jim


On Fri, Apr 3, 2015 at 6:30 AM, Simon Kiss <sjkiss at gmail.com> wrote:

> Hi there: I have a list of data frames with identical variable  names.
> I?d like to reverse scale the same variables in each data.frame.
> I?d appreciate any one?s suggestions as to how to accomplish this. Right
> now, I?m working with the code at the very bottom of my sample data.
> Thanks, Simon Kiss
>
> #Create data.frame1
> df<-data.frame(
>   ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>   ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>   hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>   hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>   evar1=sample(c(1,2,3), replace=TRUE, size=100),
>   evar2=sample(c(1,2,3), replace=TRUE, size=100)
>   )
>
> #data.frame2
>   df1<-data.frame(
>     ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>     ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>     hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>     hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>     evar1=sample(c(1,2,3), replace=TRUE, size=100),
>     evar2=sample(c(1,2,3), replace=TRUE, size=100)
>   )
>
> #List
> list1<-list(df, df1)
> #vector of first variables I?d like to recode
> i.recodes<-grep('^i.', names(df), value=TRUE)
> #Vector of second variables to recode
> e.recodes<-grep('^e.', names(df), value=TRUE)
>
> #Set up RESCALE function from RPMG package
> RESCALE <- function (x, nx1, nx2, minx, maxx)
> { nx = nx1 + (nx2 - nx1) * (x - minx)/(maxx - minx)
>   return(nx)
> }
>
> #This is what I?m playing around with
> test<-lapply(list1, function(y) {
>   out<-y[,i.recodes]
>   out<-lapply(out, function(x) RESCALE(x, 0,1,1,6))
>   y[,names(x)]<-out
> })
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr  3 00:35:30 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Apr 2015 09:35:30 +1100
Subject: [R] Kruskal-Wallace power calculations.
In-Reply-To: <19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>
References: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
	<19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>
Message-ID: <CA+8X3fV4HvfD92EZGCOukPejmAuG_iUtG-SdBzXTtd4tuoP_mQ@mail.gmail.com>

Hi Collin,
Have a look at this:

http://stats.stackexchange.com/questions/70643/power-analysis-for-kruskal-wallis-or-mann-whitney-u-test-using-r

Although, thinking about it, this might have constituted your "perusal of
the literature".

Plus it always looks better when you spell the names properly

Jim


On Fri, Apr 3, 2015 at 2:23 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please stop... you are acting like a broken record, and are also posting
> in HTML format. Please read the Posting Guide and demonstrate that you have
> used a search engine on this topic before posting again.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 2, 2015 7:25:20 AM PDT, Collin Lynch <cflynch at ncsu.edu> wrote:
> >Greetings, I am working on a project where we are applying the
> >Kruskal-Wallace test to some factor data to evaluate their correlation
> >with
> >existing grade data.  I know that the grade data is nonnormal therefore
> >we
> >cannot rely on ANOVA or a similar parametric test.  What I would like
> >to
> >find is a mechanism for making power calculations for the KW test given
> >the
> >nonparametric assumptions.  My perusal of the literature has suggested
> >that
> >a simulation would be the best method.
> >
> >Can anyone point me to good examples of such simulations for KW in R?
> >And
> >does anyone have a favourite package for generating simulated data or
> >conducting such tests?
> >
> >    Thank you,
> >    Collin.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Fri Apr  3 01:05:15 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 2 Apr 2015 19:05:15 -0400
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CA+8X3fW=AC-ROOg0C5Swv8OT4ezomi1P8g9eOjqLagqtqyNYjA@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
	<CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
	<CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>
	<CAN2xGJb6vLPdmxx49tAUO5tbw6VfvVoScO=Gi0nB3s+St9hTcw@mail.gmail.com>
	<CA+8X3fW=AC-ROOg0C5Swv8OT4ezomi1P8g9eOjqLagqtqyNYjA@mail.gmail.com>
Message-ID: <CAN2xGJbM1Ap+OTOHzCPB0ubA4gNyEWs_gXAFC2H_rsW22c7JeQ@mail.gmail.com>

This is really cool, Jim - thanks a lot!

On Thu, Apr 2, 2015 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Dimitri,
> You can also try the color.scale function in plotrix, which allows you to
> specify the NA color in the call.
>
> newcol<-color.scale(mydata.final$Mean.Wait,extremes=c("yellow","red"),na.color="white")
>
> Jim
>
>
> On Fri, Apr 3, 2015 at 8:08 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Jean, I think I fixed it:
>>
>> newpal <- colorRamp(c("yellow", "red"))
>> missing <- is.na(mydata.final$Mean.Wait)
>> newcol <- ifelse(missing, "white",
>>
>> rgb(newpal(mydata.final$Mean.Wait[!is.na(mydata.final$Mean.Wait)]/
>>                                   max(mydata.final$Mean.Wait,
>> na.rm=T)), maxColorValue=255))
>> map('county', fill=TRUE, col=newcol,
>>     resolution=0, lty=0, bg="transparent")
>> map('state', lwd=1, add=TRUE)
>>
>> One understanding question: what exactly does this rgb line do and why
>> do we have to say "maxColorValue=255"?
>> Thank you!
>>
>> On Thu, Apr 2, 2015 at 5:02 PM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>> > Thank you, Jean, but I think this newcol line is not working. I am
>> > running:
>> >
>> > newcol <- ifelse(missing, "white",
>> >
>> > rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
>> > na.rm=T)),
>> >                      maxColorValue=255))
>> >
>> > # And I am getting:
>> > Error in rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
>> > :
>> >   color intensity NA, not in 0:255
>> >
>> > I think it's not liking the NAs - despite the ifelse...
>> >
>> > On Thu, Apr 2, 2015 at 4:26 PM, Adams, Jean <jvadams at usgs.gov> wrote:
>> >> Dimitri,
>> >>
>> >> You could use colorRamp() and rgb() to get more continuous colors.
>> >> For example
>> >>
>> >> newpal <- colorRamp(c("yellow", "red"))
>> >> missing <- is.na(mydata.final$Mean.Wait)
>> >> newcol <- ifelse(missing, "white",
>> >>   rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)), maxColorValue=255))
>> >> map('county', fill=TRUE, col=newcol,
>> >>             resolution=0, lty=0, bg="transparent")
>> >> map('state', lwd=1, add=TRUE)
>> >>
>> >> Jean
>> >>
>> >>
>> >> On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski
>> >> <dimitri.liakhovitski at gmail.com> wrote:
>> >>>
>> >>> I have a data frame 'mydata.final' (see below) that contains US
>> >>> counties and a continuous numeric variable 'Mean.Wait' that ranges
>> >>> from zero to 10 or so. I also created variable 'wait' that is based on
>> >>> the 'Mean.Wait' and takes on discrete values from 1 (lowest values on
>> >>> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
>> >>>
>> >>> I can create a map of the US with the counties colored based on the
>> >>> values of 'wait' using R package 'maps':
>> >>>
>> >>> #################################################################
>> >>> ### Generating an artificial data file:
>> >>> #################################################################
>> >>> library(maps)
>> >>> mydata.final <- data.frame(county = (map('county', plot =
>> >>> FALSE)$names),
>> >>>                  stringsAsFactors = F)
>> >>>
>> >>> ### My numeric variable:
>> >>> set.seed(123)
>> >>> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
>> >>>
>> >>> ### Introducing NAs to mimic my real data set:
>> >>> set.seed(1234)
>> >>> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
>> >>>
>> >>> ### Cutting the original numeric variable into categories
>> >>> ### because I don't know how to color based on 'Mean.Wait':
>> >>> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
>> >>> levels(mydata.final$wait) <- 1:5
>> >>> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
>> >>>
>> >>> ####################################################################
>> >>> Building a US map based on 'wait' (5 categories)
>> >>> #################################################################
>> >>>
>> >>> ### Creating my 5 colors:
>> >>> pal <- colorRampPalette(c("yellow", "red"))
>> >>> allcolors <- pal(5)
>> >>>
>> >>> ### Looking at my 5 colors:
>> >>> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
>> >>>
>> >>> ### Builiding the US map using 5 categories in 'wait':
>> >>> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
>> >>>             resolution = 0, lty = 0, bg = "transparent")
>> >>> map('state', lwd=1, add=TRUE)
>> >>>
>> >>> My goal is: instead of splitting 'Mean.Wait' into 5 ordered categories
>> >>> ('wait'), I'd like to color the counties on the map based on the
>> >>> intensity of my (continuous) 'Mean.Wait'. What would be the way to do
>> >>> it and maybe even to add a legend?
>> >>> Thanks a lot!
>> >>>
>> >>> --
>> >>> Dimitri Liakhovitski
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >
>> >
>> >
>> > --
>> > Dimitri Liakhovitski
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dimitri Liakhovitski


From hill0093 at umn.edu  Fri Apr  3 02:16:30 2015
From: hill0093 at umn.edu (Hurr)
Date: Thu, 2 Apr 2015 17:16:30 -0700 (PDT)
Subject: [R] double-axis labels function of each other
Message-ID: <1428020190501-4705457.post@n4.nabble.com>

I have been doing other things, but want again to learn R.
First some code:

#try 2 axes at bottom
x1 <- c(1,2,3,4,5,6,7,8,9)
x2 <- c(5,1,9,6,3,7,8,2,4)
plot(x1,x2,type="l") #scatter plot x1 on horizontal, x2 on vertical axis
axis(1,labels=TRUE,tick=TRUE,col="red",col.axis="red",lwd=4,line=2.5)

Some simple questions:
1)How do I make it put the value 1/HorizScaleValue at the lower axis ticks?
2)How do I give more space at the bottom for the lower axis?
3)How do I make the two X axes the same length?




--
View this message in context: http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457.html
Sent from the R help mailing list archive at Nabble.com.


From cflynch at ncsu.edu  Fri Apr  3 04:19:17 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Thu, 2 Apr 2015 22:19:17 -0400
Subject: [R] Kruskal-Wallace power calculations.
In-Reply-To: <CA+8X3fV4HvfD92EZGCOukPejmAuG_iUtG-SdBzXTtd4tuoP_mQ@mail.gmail.com>
References: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
	<19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>
	<CA+8X3fV4HvfD92EZGCOukPejmAuG_iUtG-SdBzXTtd4tuoP_mQ@mail.gmail.com>
Message-ID: <CAE=6FXb7BJBDW6FbYD=8m932-Y1ZmP0C-pnhjboks7Kzeo=X1Q@mail.gmail.com>

Thank you Jim, I did see those (though not my typo :) and am still
pondering the warning about post-hoc analyses.

The situation that I am in is that I have a set of individuals who
have been assigned a course grade.  We have then clustered these
individuals into about 50 communities using standard community
detection algorithms with the goal of determining whether community
membership affects one of their grades.  We are using the KW test as
the grade data is strongly non-normal and my coauthors preferred KW as
an alternative.

The two issues that I am struggling with are: 1) whether the post-hoc
power analysis would be useful; and 2) how to code the simulation
studies that are described in:
http://onlinelibrary.wiley.com/doi/10.1002/bimj.4710380510/abstract


Problem #1 is of course beyond the scope of this e-mail list though I
would welcome anyone's suggestions on that point.  I am not sure that
I buy the arguments against it offered here:

http://graphpad.com/support/faq/why-it-is-not-helpful-to-compute-the-power-of-an-experiment-to-detect-the-difference-actually-observed-why-is-post-hoc-power-analysis-futile/

It seems that the rationale boils down to "you didn't find it so you
couldn't find it" but that does not tell me how far off I was from the
goal.  I am still perusing the articles the author cites however.


With respect to question #2 I am trying to lay my hands on the article
and did find this old r-help discussion:
http://r.789695.n4.nabble.com/Power-of-Kruskal-Wallis-Test-td4671188.html
however I am not sure how to adapt the simulation studies that it
links to to my current problem.  The links it leads to focus on
mixed-effects models.  This may be more of a pure stats question and
not suited for this list but I thought I'd ask in the hopes that
anyone had any more specific KW code or knew of a good tutorial for
the right kinds of simulation studies.

    Thank you,
    Collin.




On Thu, Apr 2, 2015 at 6:35 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Collin,
> Have a look at this:
>
> http://stats.stackexchange.com/questions/70643/power-analysis-for-kruskal-wallis-or-mann-whitney-u-test-using-r
>
> Although, thinking about it, this might have constituted your "perusal of
> the literature".
>
> Plus it always looks better when you spell the names properly
>
> Jim
>
>
> On Fri, Apr 3, 2015 at 2:23 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>>
>> Please stop... you are acting like a broken record, and are also posting
>> in HTML format. Please read the Posting Guide and demonstrate that you have
>> used a search engine on this topic before posting again.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 2, 2015 7:25:20 AM PDT, Collin Lynch <cflynch at ncsu.edu> wrote:
>> >Greetings, I am working on a project where we are applying the
>> >Kruskal-Wallace test to some factor data to evaluate their correlation
>> >with
>> >existing grade data.  I know that the grade data is nonnormal therefore
>> >we
>> >cannot rely on ANOVA or a similar parametric test.  What I would like
>> >to
>> >find is a mechanism for making power calculations for the KW test given
>> >the
>> >nonparametric assumptions.  My perusal of the literature has suggested
>> >that
>> >a simulation would be the best method.
>> >
>> >Can anyone point me to good examples of such simulations for KW in R?
>> >And
>> >does anyone have a favourite package for generating simulated data or
>> >conducting such tests?
>> >
>> >    Thank you,
>> >    Collin.
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From m at feng.li  Fri Apr  3 05:00:28 2015
From: m at feng.li (Feng Li)
Date: Fri, 3 Apr 2015 11:00:28 +0800
Subject: [R] Inverse of many small matrices
In-Reply-To: <551D54ED.7060902@gmail.com>
References: <551D44CC.5010005@feng.li> <551D54ED.7060902@gmail.com>
Message-ID: <551E024C.3090309@feng.li>

On 04/02/2015 10:40 PM, Duncan Murdoch wrote:
> On 02/04/2015 9:31 AM, Feng Li wrote:
>> Dear all,
>>
>> I am working with a likelihood function that requires the inverse of
>> many small covariance matrices for multivariate normal densities. When
>> the sample size is large, this calculation is really heavy. Those
>> matrices are independent but unfortunately I can hardly find a way to
>> vectorize them.
>>
>> Can anyone give me a hint to speed this up? Thanks in advance!
>>
>
> Are you sure you need the inverses of those matrices?  For example, if
> you are trying to compute x^t Ainv x,
> where Ainv is A inverse, the naive calculation is t(x) %*% solve(A) %*%
> x, but that's likely slower and less accurate than other equivalent
> ones, such as x %*% solve(A, x), and I wouldn't be surprised if there
> are better ones.
>
> Duncan Murdoch

I agree what you suggested is good practice. But my likelihood function 
needs to calculate "x %*% solve(A_i, x)" for i=1,...,n, which is the 
bottom neck.


Feng


From drjimlemon at gmail.com  Fri Apr  3 05:58:39 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Apr 2015 14:58:39 +1100
Subject: [R] double-axis labels function of each other
In-Reply-To: <1428020190501-4705457.post@n4.nabble.com>
References: <1428020190501-4705457.post@n4.nabble.com>
Message-ID: <CA+8X3fVBug-0V7W1F6aUeP-teAXvRsndeuDEkTcDP1T8vQdnFQ@mail.gmail.com>

Hi Hurr,
Try this:

par(mar=c(7,4,4,2))
plot(x1,x2,type="l",xlab="")
require(plotrix)
fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),2),tick=TRUE,
 col="red",col.axis="red",lwd=4,pos=-0.2)
mtext("x1",side=1,line=4.5)

Jim

On Fri, Apr 3, 2015 at 11:16 AM, Hurr <hill0093 at umn.edu> wrote:

> I have been doing other things, but want again to learn R.
> First some code:
>
> #try 2 axes at bottom
> x1 <- c(1,2,3,4,5,6,7,8,9)
> x2 <- c(5,1,9,6,3,7,8,2,4)
> plot(x1,x2,type="l") #scatter plot x1 on horizontal, x2 on vertical axis
> axis(1,labels=TRUE,tick=TRUE,col="red",col.axis="red",lwd=4,line=2.5)
>
> Some simple questions:
> 1)How do I make it put the value 1/HorizScaleValue at the lower axis ticks?
> 2)How do I give more space at the bottom for the lower axis?
> 3)How do I make the two X axes the same length?
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hill0093 at umn.edu  Fri Apr  3 06:44:03 2015
From: hill0093 at umn.edu (Hurr)
Date: Thu, 2 Apr 2015 21:44:03 -0700 (PDT)
Subject: [R] double-axis labels function of each other
In-Reply-To: <CA+8X3fVBug-0V7W1F6aUeP-teAXvRsndeuDEkTcDP1T8vQdnFQ@mail.gmail.com>
References: <1428020190501-4705457.post@n4.nabble.com>
	<CA+8X3fVBug-0V7W1F6aUeP-teAXvRsndeuDEkTcDP1T8vQdnFQ@mail.gmail.com>
Message-ID: <1428036243314-4705460.post@n4.nabble.com>

Thanks, That was good help; I tried this; I hope I didn't copy it wrong:

#try 2 axes at bottom
x1 <- c(1,2,3,4,5,6,7,8,9)
x2 <- c(5,1,9,6,3,7,8,2,4)
par(mar=c(7,4,4,2))
plot(x1,x2,type="l",xlab=??) #scatter plot x1 on horiz, x2 on vert axis
require(plotrix)
fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
 col=?red?,col.axis=?red?,lwd=4,pos=-0.2)
mtext(?x1?,side=1,line=4.5)

This is the response I got. 

> #try 2 axes at bottom
> x1 <- c(1,2,3,4,5,6,7,8,9)
> x2 <- c(5,1,9,6,3,7,8,2,4)
> par(mar=c(7,4,4,2))
> plot(x1,x2,type="l",xlab=??) #scatter plot x1 on horiz, x2 on vert axis
Error: unexpected input in "plot(x1,x2,type="l",xlab=?"
> require(plotrix)
> fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
+  col=?red?,col.axis=?red?,lwd=4,pos=-0.2)
Error: unexpected input in:
"fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
 col=?"
> mtext(?x1?,side=1,line=4.5)
Error: unexpected input in "mtext(?"
>

This works but the X-axis name is not in right place:

#try 2 axes at bottom
x1 <- c(1,2,3,4,5,6,7,8,9)
x2 <- c(5,1,9,6,3,7,8,2,4)
par(mar=c(7,4,4,2))
plot(x1,x2,type="l") #scatter plot x1 on horiz, x2 on vert axis
require(plotrix)
fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),2),tick=TRUE,
 lwd=4,pos=-0.2)




--
View this message in context: http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457p4705460.html
Sent from the R help mailing list archive at Nabble.com.


From mmoragues at fulbrightmail.org  Fri Apr  3 02:30:32 2015
From: mmoragues at fulbrightmail.org (Marc Moragues)
Date: Thu, 02 Apr 2015 17:30:32 -0700
Subject: [R] Multistratum blocking in AlgDesign
Message-ID: <1428021032.5342.9.camel@fulbrightmail.org>

Hi all,

I need to design an experiment very similar to the design described in
the AlgDesign vignette on page 44.  When I run the code on the vignette,
I get the following error:

> library(AlgDesign)
> Rep<-gen.factorial(3,1,factor=1,varName="Rep")
> Block<-gen.factorial(3,1,factor=1,varName="Block")
> firstDesign<-optBlock(~.,within=Block,whole=Rep,blocks=rep(3,3))
Error in optBlock(~., within = Block, whole = Rep, blocks = rep(3,
3)) : 
  All variables seem to be block variables

This is my sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
base     

other attached packages:
[1] AlgDesign_1.1-7.3

loaded via a namespace (and not attached):
[1] compiler_3.1.1 tools_3.1.1  

I searched this error on rseek.org and the archives and found nothing
that was helpful.

Any help would be appreciated.
Marc.


From drjimlemon at gmail.com  Fri Apr  3 07:38:08 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Apr 2015 16:38:08 +1100
Subject: [R] double-axis labels function of each other
In-Reply-To: <1428036243314-4705460.post@n4.nabble.com>
References: <1428020190501-4705457.post@n4.nabble.com>
	<CA+8X3fVBug-0V7W1F6aUeP-teAXvRsndeuDEkTcDP1T8vQdnFQ@mail.gmail.com>
	<1428036243314-4705460.post@n4.nabble.com>
Message-ID: <CA+8X3fUJTttYq=HNLMp15a6iitVVb2g+4O_xZx3OXZmUrj_rpg@mail.gmail.com>

Hi Hurr,
The problem is with the quotes in xlab="". In your version the quotes are
not ASCII double quotes but some sort of "smart" quotes. Either your email
client has substituted them or more likely, you are editing your code in
something like MS Word and cutting and pasting the result into R. Try just
typing this in R:

plot(x1,x2,type="l",xlab="")

and the first error should not appear. The error with "mtext" is the same
problem. The reason that the x axis label is in the wrong place is that it
is not suppressed in the initial plot.

Jim


On Fri, Apr 3, 2015 at 3:44 PM, Hurr <hill0093 at umn.edu> wrote:

> Thanks, That was good help; I tried this; I hope I didn't copy it wrong:
>
> #try 2 axes at bottom
> x1 <- c(1,2,3,4,5,6,7,8,9)
> x2 <- c(5,1,9,6,3,7,8,2,4)
> par(mar=c(7,4,4,2))
> plot(x1,x2,type="l",xlab=??) #scatter plot x1 on horiz, x2 on vert axis
> require(plotrix)
> fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
>  col=?red?,col.axis=?red?,lwd=4,pos=-0.2)
> mtext(?x1?,side=1,line=4.5)
>
> This is the response I got.
>
> > #try 2 axes at bottom
> > x1 <- c(1,2,3,4,5,6,7,8,9)
> > x2 <- c(5,1,9,6,3,7,8,2,4)
> > par(mar=c(7,4,4,2))
> > plot(x1,x2,type="l",xlab=??) #scatter plot x1 on horiz, x2 on vert axis
> Error: unexpected input in "plot(x1,x2,type="l",xlab=?"
> > require(plotrix)
> > fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
> +  col=?red?,col.axis=?red?,lwd=4,pos=-0.2)
> Error: unexpected input in:
> "fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),3),tick=TRUE,
>  col=?"
> > mtext(?x1?,side=1,line=4.5)
> Error: unexpected input in "mtext(?"
> >
>
> This works but the X-axis name is not in right place:
>
> #try 2 axes at bottom
> x1 <- c(1,2,3,4,5,6,7,8,9)
> x2 <- c(5,1,9,6,3,7,8,2,4)
> par(mar=c(7,4,4,2))
> plot(x1,x2,type="l") #scatter plot x1 on horiz, x2 on vert axis
> require(plotrix)
> fullaxis(1,at=pretty(x1),labels=round(1/pretty(x1),2),tick=TRUE,
>  lwd=4,pos=-0.2)
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457p4705460.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hill0093 at umn.edu  Fri Apr  3 08:59:17 2015
From: hill0093 at umn.edu (Hurr)
Date: Thu, 2 Apr 2015 23:59:17 -0700 (PDT)
Subject: [R] double-axis labels function of each other
In-Reply-To: <CA+8X3fUJTttYq=HNLMp15a6iitVVb2g+4O_xZx3OXZmUrj_rpg@mail.gmail.com>
References: <1428020190501-4705457.post@n4.nabble.com>
	<CA+8X3fVBug-0V7W1F6aUeP-teAXvRsndeuDEkTcDP1T8vQdnFQ@mail.gmail.com>
	<1428036243314-4705460.post@n4.nabble.com>
	<CA+8X3fUJTttYq=HNLMp15a6iitVVb2g+4O_xZx3OXZmUrj_rpg@mail.gmail.com>
Message-ID: <1428044357220-4705463.post@n4.nabble.com>

Yes, I keep a copy in MS Word. 
Would Notepad be OK?
I need sleep now, will work tomorrow.




--
View this message in context: http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457p4705463.html
Sent from the R help mailing list archive at Nabble.com.


From daniel at nextpagesoft.net  Fri Apr  3 12:06:52 2015
From: daniel at nextpagesoft.net (Daniel Lewandowski)
Date: Fri, 3 Apr 2015 12:06:52 +0200
Subject: [R] Package build system adds line break in DESCRIPTION URL
Message-ID: <551E663C.2000202@nextpagesoft.net>

Has anybody noticed that if field URL in DESCRIPTION contains a uri with 
66 or more characters, then file DESCRIPTION in the resulting package 
includes a line break at the beginning?

So this (source DESCRIPTION):

URL: 
http://ecdc.europa.eu/en/data-tools/seroincidence-calculator-tool/Pages/default.aspx

becomes (again file DESCRIPTION, but inside the package)

URL:
http://ecdc.europa.eu/en/data-tools/seroincidence-calculator-tool/Pages/default.aspx

This has been tested with R on Windows 8.1 (devel 01/04/2015 and 3.1.3) 
and Linux Mint (3.1.3). It has many sad implications including not 
acceptance of such packages to CRAN.


From michelgomez at free.fr  Fri Apr  3 14:01:31 2015
From: michelgomez at free.fr (Michel)
Date: Fri, 3 Apr 2015 14:01:31 +0200
Subject: [R] RInside
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAJVMB2j7GuRLk8yWzCjoIWYBAAAAAA==@free.fr>

help

Hello
I'm newbee with R and RInside
My question is about stderr in R. Is there a way to collect R stderr in C++
program embedding R Thanks in advance

Michel


---
L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.


From emorway at usgs.gov  Fri Apr  3 14:17:46 2015
From: emorway at usgs.gov (Morway, Eric)
Date: Fri, 3 Apr 2015 05:17:46 -0700
Subject: [R] applying cumsum within groups
Message-ID: <CAPoqHzpovwPrJ9f6e89jBk1wCsfVUYJzhZAsDLuPvUgpJ_9S0Q@mail.gmail.com>

This small example will be applied to a problem with 1.4e6 lines of data.
First, here is the dataset and a few lines of R script, followed by an
explanation of what I'd like to get:

dat <- read.table(textConnection("ISEG  IRCH  val
 1    1   265
 1    2   260
 1    3   234
54   39   467
54   40   468
54   41   460
54   42   489
 1    1   265
 1    2   276
 1    3   217
54   39   456
54   40   507
54   41   483
54   42   457
 1    1   265
 1    2   287
 1    3   224
54   39   473
54   40   502
54   41   497
54   42   447
 1    1   230
 1    2   251
 1    3   199
54   39   439
54   40   474
54   41   477
54   42   413
 1    1   230
 1    2   262
 1    3   217
54   39   455
54   40   493
54   41   489
54   42   431
 1    1   1002
 1    2   1222
 1    3   1198
54   39   1876
54   40   1565
54   41   1455
54   42   1427
 1    1   1002
 1    2   1246
 1    3   1153
54   39   1813
54   40   1490
54   41   1518
54   42   1486
 1    1   1002
 1    2   1229
 1    3   1142
54   39   1797
54   40   1517
54   41   1527
54   42   1514"),header=TRUE)

dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
tmp <- diff(dat[dat$seq==1,]$val)!=0
dat$idx <- 0
dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
dat$ts <- cumsum(dat$idx)

At this point, I'd like to add one more column called "iter" that counts up
by 1 based on "seq", but within each "ts".  So, the result would look like
this (undoubtedly this is a simple problem with something like ddply, but
I've been unable to construct the R for it):

dat
 ISEG IRCH  val seq idx ts iter
    1    1  265   1   1  1    1
    1    2  260   0   0  1    1
    1    3  234   0   0  1    1
   54   39  467   0   0  1    1
   54   40  468   0   0  1    1
   54   41  460   0   0  1    1
   54   42  489   0   0  1    1
    1    1  265   1   0  1    2
    1    2  276   0   0  1    2
    1    3  217   0   0  1    2
   54   39  456   0   0  1    2
   54   40  507   0   0  1    2
   54   41  483   0   0  1    2
   54   42  457   0   0  1    2
    1    1  265   1   0  1    3
    1    2  287   0   0  1    3
    1    3  224   0   0  1    3
   54   39  473   0   0  1    3
   54   40  502   0   0  1    3
   54   41  497   0   0  1    3
   54   42  447   0   0  1    3
    1    1  230   1   1  2    1
    1    2  251   0   0  2    1
    1    3  199   0   0  2    1
   54   39  439   0   0  2    1
   54   40  474   0   0  2    1
   54   41  477   0   0  2    1
   54   42  413   0   0  2    1
    1    1  230   1   0  2    2
    1    2  262   0   0  2    2
    1    3  217   0   0  2    2
   54   39  455   0   0  2    2
   54   40  493   0   0  2    2
   54   41  489   0   0  2    2
   54   42  431   0   0  2    2
    1    1 1002   1   1  3    1
    1    2 1222   0   0  3    1
    1    3 1198   0   0  3    1
   54   39 1876   0   0  3    1
   54   40 1565   0   0  3    1
   54   41 1455   0   0  3    1
   54   42 1427   0   0  3    1
    1    1 1002   1   0  3    2
    1    2 1246   0   0  3    2
    1    3 1153   0   0  3    2
   54   39 1813   0   0  3    2
   54   40 1490   0   0  3    2
   54   41 1518   0   0  3    2
   54   42 1486   0   0  3    2
    1    1 1002   1   0  3    3
    1    2 1229   0   0  3    3
    1    3 1142   0   0  3    3
   54   39 1797   0   0  3    3
   54   40 1517   0   0  3    3
   54   41 1527   0   0  3    3
   54   42 1514   0   0  3    3

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr  3 14:51:58 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Apr 2015 14:51:58 +0200
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
Message-ID: <D3397225-7EC3-4F7C-A600-33F547A80F00@gmail.com>


> On 31 Mar 2015, at 20:55 , William Dunlap <wdunlap at tibco.com> wrote:
> 
> You can use structure() to attach the names to a list that is input to
> data.frame.
> E.g.,
> 
> dfNames <- c("First", "Second Name")
> data.frame(lapply(structure(dfNames, names=dfNames),
> function(name)rep(NA_real_, 5)))
> 

Yes, I cooked up something similar:

names <- c("foo","bar","baz")
names(names) <- names # confuse 'em....
as.data.frame(lapply(names, function(x) rep(NA_real_,10)))

but wouldn't it be more to the point to do

df <- as.data.frame(rep(list(rep(NA_real_, 10)),3))
names(df) <- names

?

The lapply() approach could be generalized to a vector of column classes, though. 

A general solution looks impracticable; once you start considering how to specify factor columns with each their own level set, things get a bit out of hand. 

-pd

> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> 
>> Hi,
>> 
>> Duncan Murdoch suggested:
>> 
>>> The matrix() function has a dimnames argument, so you could do this:
>>> 
>>> names <- c("strat", "id", "pid")
>>> data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>> 
>> That's a definite improvement, thanks. But no way to skip matrix()? It
>> just seems unRlike, although since it's only full of NA values there
>> are no coercion issues with column types or anything, so it doesn't
>> hurt. It's just inelegant. :)
>> 
>> Sarah
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Fri Apr  3 16:01:38 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 3 Apr 2015 09:01:38 -0500
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjumj2oh3UevoLnNmTir+iD_42NyPF-tpMovFQeT=kU2N+g@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<CAHuTOvrOcVUZ41-cB_fMVE4Ja75afsuo30RyEznRpVkgh3htZQ@mail.gmail.com>
	<CAGx1TMAM_4T34Qeh3Jp-n--92ap67-U4PPSNNoURbR5_Dwda_A@mail.gmail.com>
	<CAM_vjumj2oh3UevoLnNmTir+iD_42NyPF-tpMovFQeT=kU2N+g@mail.gmail.com>
Message-ID: <CABdHhvEBCVgWE=nze1dQXWgQpZd_-8Rv+gnrcQhQVEw-gNTg1g@mail.gmail.com>

On Tue, Mar 31, 2015 at 6:42 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> On Tue, Mar 31, 2015 at 6:35 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> I got rid of the extra column.
>>
>> data.frame(r=seq(8), foo=NA, bar=NA, row.names="r")
>
> Brilliant!
>
> After much fussing, including a disturbing detour into nested lapply
> statements from which I barely emerged with my sanity (arguable, I
> suppose), here is a one-liner that creates a data frame of arbitrary
> number of rows given an existing data frame as template for column
> number and name:
>
>
> n <- 8
> df1 <- data.frame(A=runif(9), B=runif(9))
>
> do.call(data.frame, setNames(c(list(seq(n), "r"), as.list(rep(NA,
> ncol(df1)))), c("r", "row.names", colnames(df1))))
>
> It's not elegant, but it is fairly R-ish. I should probably stop
> hunting for an elegant solution now.

Given a template df, you can create a new df with subsetting:

df2 <- df1[rep(NA_real_, 8), ]
rownames(df2) <- NULL
df2

This has the added benefit of preserving the types.

Hadley

-- 
http://had.co.nz/


From bbolker at gmail.com  Fri Apr  3 16:25:24 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 3 Apr 2015 14:25:24 +0000
Subject: [R] Package build system adds line break in DESCRIPTION URL
References: <551E663C.2000202@nextpagesoft.net>
Message-ID: <loom.20150403T162229-170@post.gmane.org>

Daniel Lewandowski <daniel <at> nextpagesoft.net> writes:

> 
> Has anybody noticed that if field URL in DESCRIPTION contains a uri with 
> 66 or more characters, then file DESCRIPTION in the resulting package 
> includes a line break at the beginning?
> 
> So this (source DESCRIPTION):
> 
> URL: 
> http://ecdc.europa.eu/en/data-tools/
   seroincidence-calculator-tool/Pages/default.aspx

> 
> becomes (again file DESCRIPTION, but inside the package)
> 
> URL:
> http://ecdc.europa.eu/en/data-tools/seroincidence-calculator-tool/
   Pages/default.aspx
> 
> This has been tested with R on Windows 8.1 (devel 01/04/2015 and 3.1.3) 
> and Linux Mint (3.1.3). It has many sad implications including not 
> acceptance of such packages to CRAN.
> 

  (links line-broken above to make gmane happy).

  Haven't tested, but seems it would not be *too* hard to trace
through the code to see what's happening in the package-building
process.  Two thoughts:

 (1) as a workaround, could you use a URL-shortener such as tinyurl?
tinyurl allows you to specify a somewhat meaningful name for the
shortened URL, e.g. http://tinyurl.com/reproducible-000

 (2) this feels like it is more suitable for r-devel at r-project.org

  Ben Bolker


From xavier.chiriboga at unine.ch  Fri Apr  3 16:33:33 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 3 Apr 2015 14:33:33 +0000
Subject: [R] WEIBULL or EXPONENTIAL?
Message-ID: <7B64C8E017B948419F014C915AA6D7342A051E84@mail-mbx-03.UNINE.CH>

Dear members,



I am doing a survival analysis wiith the function coxph...however I am wondering how can I know if my data follows a EXPONENTIAL or WEIBULL distribution?

I have 3 censored datum. Using R studio.



Thanks for the suggestions,



Xavier


From wdunlap at tibco.com  Fri Apr  3 16:46:34 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 3 Apr 2015 07:46:34 -0700
Subject: [R] idiom for constructing data frame
In-Reply-To: <D3397225-7EC3-4F7C-A600-33F547A80F00@gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<D3397225-7EC3-4F7C-A600-33F547A80F00@gmail.com>
Message-ID: <CAF8bMcYXTqA85F53xeiSxPoA2L9VUfuzsgiyvknbBYhCJCVtAw@mail.gmail.com>

> but wouldn't it be more to the point to do
>
> df <- as.data.frame(rep(list(rep(NA_real_, 10)),3))
> names(df) <- names

As a matter of personal style (and functional programming
sensibility), I prefer not to make named objects and then modify them.
Also, the names coming out of that as.data.frame call are exceedingly
ugly and I'd rather not generate them at all.

Also adding the names after calling data.frame means can give
different results than passing them into data.frame(), which can
mangle nonsyntactic names like "Second Name" into "Second.Name".
It is often preferable, but it is different.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 3, 2015 at 5:51 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 31 Mar 2015, at 20:55 , William Dunlap <wdunlap at tibco.com> wrote:
> >
> > You can use structure() to attach the names to a list that is input to
> > data.frame.
> > E.g.,
> >
> > dfNames <- c("First", "Second Name")
> > data.frame(lapply(structure(dfNames, names=dfNames),
> > function(name)rep(NA_real_, 5)))
> >
>
> Yes, I cooked up something similar:
>
> names <- c("foo","bar","baz")
> names(names) <- names # confuse 'em....
> as.data.frame(lapply(names, function(x) rep(NA_real_,10)))
>
> but wouldn't it be more to the point to do
>
> df <- as.data.frame(rep(list(rep(NA_real_, 10)),3))
> names(df) <- names
>
> ?
>
> The lapply() approach could be generalized to a vector of column classes,
> though.
>
> A general solution looks impracticable; once you start considering how to
> specify factor columns with each their own level set, things get a bit out
> of hand.
>
> -pd
>
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >
> >> Hi,
> >>
> >> Duncan Murdoch suggested:
> >>
> >>> The matrix() function has a dimnames argument, so you could do this:
> >>>
> >>> names <- c("strat", "id", "pid")
> >>> data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
> >>
> >> That's a definite improvement, thanks. But no way to skip matrix()? It
> >> just seems unRlike, although since it's only full of NA values there
> >> are no coercion issues with column types or anything, so it doesn't
> >> hurt. It's just inelegant. :)
> >>
> >> Sarah
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From JLucke at ria.buffalo.edu  Fri Apr  3 17:35:50 2015
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Fri, 3 Apr 2015 11:35:50 -0400
Subject: [R] WEIBULL or EXPONENTIAL?
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A051E84@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A051E84@mail-mbx-03.UNINE.CH>
Message-ID: <OFB484048D.DB166DB6-ON85257E1C.005564C1-85257E1C.0055AD61@ria.buffalo.edu>

As a start you can use an exploratory approach.  Standard survival 
analysis texts show you how to use a log-log plot to assess whether a 
distribution is Weibull.   Of course, the exponential is a special case of 
the Weibull. 



CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> 
Sent by: "R-help" <r-help-bounces at r-project.org>
04/03/2015 10:33 AM

To
"r-help at r-project.org" <r-help at r-project.org>, 
cc

Subject
[R] WEIBULL or EXPONENTIAL?






Dear members,



I am doing a survival analysis wiith the function coxph...however I am 
wondering how can I know if my data follows a EXPONENTIAL or WEIBULL 
distribution?

I have 3 censored datum. Using R studio.



Thanks for the suggestions,



Xavier

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr  3 17:38:41 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Apr 2015 17:38:41 +0200
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAF8bMcYXTqA85F53xeiSxPoA2L9VUfuzsgiyvknbBYhCJCVtAw@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
	<CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>
	<D3397225-7EC3-4F7C-A600-33F547A80F00@gmail.com>
	<CAF8bMcYXTqA85F53xeiSxPoA2L9VUfuzsgiyvknbBYhCJCVtAw@mail.gmail.com>
Message-ID: <DB313B5D-80BD-4569-8547-CB4C4098F232@gmail.com>


> On 03 Apr 2015, at 16:46 , William Dunlap <wdunlap at tibco.com> wrote:
> 
> > 
> > df <- as.data.frame(rep(list(rep(NA_real_, 10)),3))
> > names(df) <- names
> 
> As a matter of personal style (and functional programming
> sensibility), I prefer not to make named objects and then modify them.
> Also, the names coming out of that as.data.frame call are exceedingly
> ugly and I'd rather not generate them at all.
> 

Ah, yes, I missed the generation of intermediate names. You can name the list before as.data.frame, though:

l <- rep(list(rep(NA_real_, 10)),3)
names(l) <- names
as.data.frame(l)

or as a one-liner:

as.data.frame(structure(rep(list(rep(NA_real_, 10)), 3) , .Names=names))

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Fri Apr  3 17:47:53 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 3 Apr 2015 07:47:53 -0800
Subject: [R] double-axis labels function of each other
In-Reply-To: <1428044357220-4705463.post@n4.nabble.com>
References: <1428020190501-4705457.post@n4.nabble.com>
	<ca+8x3fvbug-0v7w1f6auep-teaxvrsndeudektcdp1t8vqdnfq@mail.gmail.com>
	<1428036243314-4705460.post@n4.nabble.com>
	<ca+8x3fujtttyq=hnlmp15a6iitvvb2g+4o_xzx3oxzmurj_rpg@mail.gmail.com>
Message-ID: <BF9A01DEB36.0000029Ejrkrideau@inbox.com>

Notepad should be fine but you will, I think, still have to correct the apostrophes if you are copying from Word.  

Any code written in Notepad should be fine.  

There are several dedicated editors or IDE's for use with R that you might want to look into.  RStudio, Tinn-R and EMACs with ESS are some that come to mind.  Among other things, they usually offer code highlighting which can be very useful for finding where there are typos, missing commas, and so on.

I run Linux (Ubuntu) and find gedit with an R plug-in to be very good also.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: hill0093 at umn.edu
> Sent: Thu, 2 Apr 2015 23:59:17 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] double-axis labels function of each other
> 
> Yes, I keep a copy in MS Word.
> Would Notepad be OK?
> I need sleep now, will work tomorrow.
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/double-axis-labels-function-of-each-other-tp4705457p4705463.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From wingkeong at outlook.com  Fri Apr  3 14:09:41 2015
From: wingkeong at outlook.com (Wing Keong Lew)
Date: Fri, 3 Apr 2015 20:09:41 +0800
Subject: [R] Cut breaks in descending order
Message-ID: <COL128-W18BB9C8BA8DC8C64FB4741A3F10@phx.gbl>

Hi,

Is it a requirement to provide the break intervals of the cut function in ascending order? The help documentation for cut didn't specify this but the labels returned are reversed if I indicate the break intervals in a descending order. Here is an example

tbl<-data.frame(x=c(0:10))
tbl$ascending<-cut(tbl$x, breaks=c(0,3,5,9,99), labels=c('<3','4-5','6-9','>9'), include.lowest=T)
tbl$descending<-cut(tbl$x, breaks=c(99,9,5,3,0), labels=c('>9','6-8','4-5','<3'), include.lowest=T)
tbl
? ? x ascending descending
1 ? 0 ? ? ? ?<3 ? ? ? ?>9
2 ? 1 ? ? ? ?<3 ? ? ? ?>9
3 ? 2 ? ? ? ?<3 ? ? ? ?>9
4 ? 3 ? ? ? ?<3 ? ? ? ?>9
5 ? 4 ? ? ? 4-5 ? ? ? 6-8
6 ? 5 ? ? ? 4-5 ? ? ? 6-8
7 ? 6 ? ? ? 6-9 ? ? ? 4-5
8 ? 7 ? ? ? 6-9 ? ? ? 4-5
9 ? 8 ? ? ? 6-9 ? ? ? 4-5
10 ?9 ? ? ? 6-9 ? ? ? 4-5
11 10 ? ? ? ?>9 ? ? ? ?<3

Appreciate any guidance on this.
Regards
Wing Keong

 		 	   		  

From sjo.india at gmail.com  Fri Apr  3 16:18:24 2015
From: sjo.india at gmail.com (Sudheer Joseph)
Date: Fri, 3 Apr 2015 19:48:24 +0530
Subject: [R] question on waveletcomp plot image
Message-ID: <CAFP9GyZHQn5TTKVRChfXJ1evDEzQpgVd9-XjVz+LRvUUasf4ZA@mail.gmail.com>

Dear R experts,
                         I have used waveletcomp package of R  and was
trying to get the dates formatted as month & year but get below error while
trying it with the example provided  in
http://www.hs-stat.com/projects/WaveletComp/WaveletComp_guided_tour.pdf
Kindly help me with the dateformat so that I can get %Y-%m as xaxis label
data(FXtrade.transactions)
my.data.a = FXtrade.transactions[FXtrade.transactions$active == T, ]
my.w.a = analyze.wavelet(
+     my.data.a, "transactions",
+     loess.span = 0.0, # no detrending required
+     dt = 1/(12*24),
+     # one day has 12*24 5-minute time slots
+     dj = 1/250,
+     # resolution along period axis
+     lowerPeriod = 1/8, # lowest period of interest: 3 hours
+     make.pval = T,
+     # draws white lines indicating significance
+     n.sim = 10)


wt.image(my.w.a, n.levels = 250, periodlab = "periods (days)",
+          legend.params = list(lab = "wavelet power levels"),
+          show.date = T, date.format = "%Y %m", timelab = "")
Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -In
with best regards

Sudheer

**********************************************************************************
Dr. Sudheer Joseph

Scientist,

INCOIS, MoES, Govt. of India.
"OCEAN VALLEY" , Pragathi Nagar (BO), Nizampet SO,  Telangana, India. PIN-
500 090.
Tel:+91-9440832534(Mobile) Tel:+91-40-23886047(O),Fax:+91-40-23892910(O)
E-mail: sjo.India at gmail.com;  sjo at incois.gov.in.
-------------------* --------------------
"The ultimate measure of a man is not where he stands in moments of
comfort and convenience, but where he stands at times of challenge and
controversy."
                        Martin Luther King, Jr.
***********************************************************************************

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Apr  3 18:34:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Apr 2015 09:34:46 -0700
Subject: [R] Cut breaks in descending order
In-Reply-To: <COL128-W18BB9C8BA8DC8C64FB4741A3F10@phx.gbl>
References: <COL128-W18BB9C8BA8DC8C64FB4741A3F10@phx.gbl>
Message-ID: <9F3E3F4D-EB0F-402C-9CF8-0DF42CE95083@comcast.net>


On Apr 3, 2015, at 5:09 AM, Wing Keong Lew wrote:

> Hi,
> 
> Is it a requirement to provide the break intervals of the cut function in ascending order?

Apparently not. I get teh sam splits even with random permutations. It is apparently a "requirement" to make sure you labels match the sorted order of the breaks.

The findInterval function does require that its `vec` argument be non-decreasing, but I do not see a discussion of break order in the help page. Looking at cut.default the first think it does to the breaks is sort them.

  #... snipped code that deals with length(breaks)==1
   else nb <- length(breaks <- sort.int(as.double(breaks)))

-- 
David.

> The help documentation for cut didn't specify this but the labels returned are reversed if I indicate the break intervals in a descending order. Here is an example
> 
> tbl<-data.frame(x=c(0:10))
> tbl$ascending<-cut(tbl$x, breaks=c(0,3,5,9,99), labels=c('<3','4-5','6-9','>9'), include.lowest=T)
> tbl$descending<-cut(tbl$x, breaks=c(99,9,5,3,0), labels=c('>9','6-8','4-5','<3'), include.lowest=T)
> tbl
>     x ascending descending
> 1   0        <3        >9
> 2   1        <3        >9
> 3   2        <3        >9
> 4   3        <3        >9
> 5   4       4-5       6-8
> 6   5       4-5       6-8
> 7   6       6-9       4-5
> 8   7       6-9       4-5
> 9   8       6-9       4-5
> 10  9       6-9       4-5
> 11 10        >9        <3
> 
> Appreciate any guidance on this.
> Regards
> Wing Keong
> 
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Apr  3 18:17:20 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Apr 2015 09:17:20 -0700
Subject: [R] applying cumsum within groups
In-Reply-To: <CAPoqHzpovwPrJ9f6e89jBk1wCsfVUYJzhZAsDLuPvUgpJ_9S0Q@mail.gmail.com>
References: <CAPoqHzpovwPrJ9f6e89jBk1wCsfVUYJzhZAsDLuPvUgpJ_9S0Q@mail.gmail.com>
Message-ID: <9EF4E26A-1404-4D74-B436-FE5877E84049@comcast.net>


On Apr 3, 2015, at 5:17 AM, Morway, Eric wrote:

> This small example will be applied to a problem with 1.4e6 lines of data.
> First, here is the dataset and a few lines of R script, followed by an
> explanation of what I'd like to get:
> 
> dat <- read.table(textConnection("ISEG  IRCH  val
> 1    1   265
> 1    2   260
> 1    3   234
> 54   39   467
> 54   40   468
> 54   41   460
> 54   42   489
> 1    1   265
> 1    2   276
> 1    3   217
> 54   39   456
> 54   40   507
> 54   41   483
> 54   42   457
> 1    1   265
> 1    2   287
> 1    3   224
> 54   39   473
> 54   40   502
> 54   41   497
> 54   42   447
> 1    1   230
> 1    2   251
> 1    3   199
> 54   39   439
> 54   40   474
> 54   41   477
> 54   42   413
> 1    1   230
> 1    2   262
> 1    3   217
> 54   39   455
> 54   40   493
> 54   41   489
> 54   42   431
> 1    1   1002
> 1    2   1222
> 1    3   1198
> 54   39   1876
> 54   40   1565
> 54   41   1455
> 54   42   1427
> 1    1   1002
> 1    2   1246
> 1    3   1153
> 54   39   1813
> 54   40   1490
> 54   41   1518
> 54   42   1486
> 1    1   1002
> 1    2   1229
> 1    3   1142
> 54   39   1797
> 54   40   1517
> 54   41   1527
> 54   42   1514"),header=TRUE)
> 
> dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
> tmp <- diff(dat[dat$seq==1,]$val)!=0
> dat$idx <- 0
> dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
> dat$ts <- cumsum(dat$idx)
> 
> At this point, I'd like to add one more column called "iter" that counts up
> by 1 based on "seq", but within each "ts".  So, the result would look like
> this (undoubtedly this is a simple problem with something like ddply, but
> I've been unable to construct the R for it):

> dat$iter2 <- ave(dat$seq, dat$ts,FUN=cumsum)
> dat
   ISEG IRCH  val seq idx ts iter iter2
1     1    1  265   1   1  1  1_1     1
2     1    2  260   0   0  1  1_1     1
3     1    3  234   0   0  1  1_1     1
4    54   39  467   0   0  1  1_1     1
5    54   40  468   0   0  1  1_1     1
6    54   41  460   0   0  1  1_1     1
7    54   42  489   0   0  1  1_1     1
8     1    1  265   1   0  1  1_2     2
9     1    2  276   0   0  1  1_2     2
10    1    3  217   0   0  1  1_2     2
11   54   39  456   0   0  1  1_2     2
12   54   40  507   0   0  1  1_2     2
13   54   41  483   0   0  1  1_2     2
14   54   42  457   0   0  1  1_2     2
15    1    1  265   1   0  1  1_3     3
16    1    2  287   0   0  1  1_3     3
17    1    3  224   0   0  1  1_3     3
18   54   39  473   0   0  1  1_3     3
19   54   40  502   0   0  1  1_3     3
20   54   41  497   0   0  1  1_3     3
21   54   42  447   0   0  1  1_3     3
22    1    1  230   1   1  2  2_4     1
23    1    2  251   0   0  2  2_4     1
snipped----->

-- 
David
> 
> dat
> ISEG IRCH  val seq idx ts iter
>    1    1  265   1   1  1    1
>    1    2  260   0   0  1    1
>    1    3  234   0   0  1    1
>   54   39  467   0   0  1    1
>   54   40  468   0   0  1    1
>   54   41  460   0   0  1    1
>   54   42  489   0   0  1    1
>    1    1  265   1   0  1    2
>    1    2  276   0   0  1    2
>    1    3  217   0   0  1    2
>   54   39  456   0   0  1    2
>   54   40  507   0   0  1    2
>   54   41  483   0   0  1    2
>   54   42  457   0   0  1    2
>    1    1  265   1   0  1    3
>    1    2  287   0   0  1    3
>    1    3  224   0   0  1    3
>   54   39  473   0   0  1    3
>   54   40  502   0   0  1    3
>   54   41  497   0   0  1    3
>   54   42  447   0   0  1    3
>    1    1  230   1   1  2    1
>    1    2  251   0   0  2    1
>    1    3  199   0   0  2    1
>   54   39  439   0   0  2    1
>   54   40  474   0   0  2    1
>   54   41  477   0   0  2    1
>   54   42  413   0   0  2    1
>    1    1  230   1   0  2    2
>    1    2  262   0   0  2    2
>    1    3  217   0   0  2    2
>   54   39  455   0   0  2    2
>   54   40  493   0   0  2    2
>   54   41  489   0   0  2    2
>   54   42  431   0   0  2    2
>    1    1 1002   1   1  3    1
>    1    2 1222   0   0  3    1
>    1    3 1198   0   0  3    1
>   54   39 1876   0   0  3    1
>   54   40 1565   0   0  3    1
>   54   41 1455   0   0  3    1
>   54   42 1427   0   0  3    1
>    1    1 1002   1   0  3    2
>    1    2 1246   0   0  3    2
>    1    3 1153   0   0  3    2
>   54   39 1813   0   0  3    2
>   54   40 1490   0   0  3    2
>   54   41 1518   0   0  3    2
>   54   42 1486   0   0  3    2
>    1    1 1002   1   0  3    3
>    1    2 1229   0   0  3    3
>    1    3 1142   0   0  3    3
>   54   39 1797   0   0  3    3
>   54   40 1517   0   0  3    3
>   54   41 1527   0   0  3    3
>   54   42 1514   0   0  3    3
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Fri Apr  3 19:12:39 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Apr 2015 19:12:39 +0200
Subject: [R] applying cumsum within groups
In-Reply-To: <CAPoqHzpovwPrJ9f6e89jBk1wCsfVUYJzhZAsDLuPvUgpJ_9S0Q@mail.gmail.com>
References: <CAPoqHzpovwPrJ9f6e89jBk1wCsfVUYJzhZAsDLuPvUgpJ_9S0Q@mail.gmail.com>
Message-ID: <8F28955E-66FA-47A5-AF43-E8209C3C68CC@gmail.com>

ave() is your friend (unfortunately named as it may be):

> ave(dat$seq, dat$ts, FUN=cumsum)
 [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1
[39] 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3


> On 03 Apr 2015, at 14:17 , Morway, Eric <emorway at usgs.gov> wrote:
> 
> This small example will be applied to a problem with 1.4e6 lines of data.
> First, here is the dataset and a few lines of R script, followed by an
> explanation of what I'd like to get:
> 
> dat <- read.table(textConnection("ISEG  IRCH  val
> 1    1   265
> 1    2   260
> 1    3   234
> 54   39   467
> 54   40   468
> 54   41   460
> 54   42   489
> 1    1   265
> 1    2   276
> 1    3   217
> 54   39   456
> 54   40   507
> 54   41   483
> 54   42   457
> 1    1   265
> 1    2   287
> 1    3   224
> 54   39   473
> 54   40   502
> 54   41   497
> 54   42   447
> 1    1   230
> 1    2   251
> 1    3   199
> 54   39   439
> 54   40   474
> 54   41   477
> 54   42   413
> 1    1   230
> 1    2   262
> 1    3   217
> 54   39   455
> 54   40   493
> 54   41   489
> 54   42   431
> 1    1   1002
> 1    2   1222
> 1    3   1198
> 54   39   1876
> 54   40   1565
> 54   41   1455
> 54   42   1427
> 1    1   1002
> 1    2   1246
> 1    3   1153
> 54   39   1813
> 54   40   1490
> 54   41   1518
> 54   42   1486
> 1    1   1002
> 1    2   1229
> 1    3   1142
> 54   39   1797
> 54   40   1517
> 54   41   1527
> 54   42   1514"),header=TRUE)
> 
> dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
> tmp <- diff(dat[dat$seq==1,]$val)!=0
> dat$idx <- 0
> dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
> dat$ts <- cumsum(dat$idx)
> 
> At this point, I'd like to add one more column called "iter" that counts up
> by 1 based on "seq", but within each "ts".  So, the result would look like
> this (undoubtedly this is a simple problem with something like ddply, but
> I've been unable to construct the R for it):
> 
> dat
> ISEG IRCH  val seq idx ts iter
>    1    1  265   1   1  1    1
>    1    2  260   0   0  1    1
>    1    3  234   0   0  1    1
>   54   39  467   0   0  1    1
>   54   40  468   0   0  1    1
>   54   41  460   0   0  1    1
>   54   42  489   0   0  1    1
>    1    1  265   1   0  1    2
>    1    2  276   0   0  1    2
>    1    3  217   0   0  1    2
>   54   39  456   0   0  1    2
>   54   40  507   0   0  1    2
>   54   41  483   0   0  1    2
>   54   42  457   0   0  1    2
>    1    1  265   1   0  1    3
>    1    2  287   0   0  1    3
>    1    3  224   0   0  1    3
>   54   39  473   0   0  1    3
>   54   40  502   0   0  1    3
>   54   41  497   0   0  1    3
>   54   42  447   0   0  1    3
>    1    1  230   1   1  2    1
>    1    2  251   0   0  2    1
>    1    3  199   0   0  2    1
>   54   39  439   0   0  2    1
>   54   40  474   0   0  2    1
>   54   41  477   0   0  2    1
>   54   42  413   0   0  2    1
>    1    1  230   1   0  2    2
>    1    2  262   0   0  2    2
>    1    3  217   0   0  2    2
>   54   39  455   0   0  2    2
>   54   40  493   0   0  2    2
>   54   41  489   0   0  2    2
>   54   42  431   0   0  2    2
>    1    1 1002   1   1  3    1
>    1    2 1222   0   0  3    1
>    1    3 1198   0   0  3    1
>   54   39 1876   0   0  3    1
>   54   40 1565   0   0  3    1
>   54   41 1455   0   0  3    1
>   54   42 1427   0   0  3    1
>    1    1 1002   1   0  3    2
>    1    2 1246   0   0  3    2
>    1    3 1153   0   0  3    2
>   54   39 1813   0   0  3    2
>   54   40 1490   0   0  3    2
>   54   41 1518   0   0  3    2
>   54   42 1486   0   0  3    2
>    1    1 1002   1   0  3    3
>    1    2 1229   0   0  3    3
>    1    3 1142   0   0  3    3
>   54   39 1797   0   0  3    3
>   54   40 1517   0   0  3    3
>   54   41 1527   0   0  3    3
>   54   42 1514   0   0  3    3
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jvadams at usgs.gov  Fri Apr  3 19:41:17 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 3 Apr 2015 12:41:17 -0500
Subject: [R] Color US counties on US map using a numeric variable for
 color intensity
In-Reply-To: <CAN2xGJbM1Ap+OTOHzCPB0ubA4gNyEWs_gXAFC2H_rsW22c7JeQ@mail.gmail.com>
References: <CAN2xGJZP9T=HpEw0oQgtPrypgZZQhw5E70P2Y5Er5SMMv5wBUg@mail.gmail.com>
	<CAN5YmCHYCnLwueThjfhn8=6upCNc8Abn=msixXH1jKO6okhyTw@mail.gmail.com>
	<CAN2xGJbRRC8HWfe16g7Ktrp6a+ZaB+_06J283dwyRShPYaVBSw@mail.gmail.com>
	<CAN2xGJb6vLPdmxx49tAUO5tbw6VfvVoScO=Gi0nB3s+St9hTcw@mail.gmail.com>
	<CA+8X3fW=AC-ROOg0C5Swv8OT4ezomi1P8g9eOjqLagqtqyNYjA@mail.gmail.com>
	<CAN2xGJbM1Ap+OTOHzCPB0ubA4gNyEWs_gXAFC2H_rsW22c7JeQ@mail.gmail.com>
Message-ID: <CAN5YmCEsEWNKaxQC3_mj8akxpTCD63uZy=dF-E61qS4Z5ZC29w@mail.gmail.com>

Dimitri,

To answer your questions:
The colorRamp() function creates a new function, newpal().
The value returned by newpal() is a numeric matrix of RGB color values.
The rgb() function is then used to convert this numeric matrix to colors,
with the argument maxColorValue
giving the maximum of the color values range.  Typically either 255 or 1.
See the help files for more information

?colorRamp
?rgb


I think Jim Lemon's suggestion to use color.scale() function is a handier
solution.

Jean

On Thu, Apr 2, 2015 at 6:05 PM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> This is really cool, Jim - thanks a lot!
>
> On Thu, Apr 2, 2015 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Dimitri,
> > You can also try the color.scale function in plotrix, which allows you to
> > specify the NA color in the call.
> >
> >
> newcol<-color.scale(mydata.final$Mean.Wait,extremes=c("yellow","red"),na.color="white")
> >
> > Jim
> >
> >
> > On Fri, Apr 3, 2015 at 8:08 AM, Dimitri Liakhovitski
> > <dimitri.liakhovitski at gmail.com> wrote:
> >>
> >> Jean, I think I fixed it:
> >>
> >> newpal <- colorRamp(c("yellow", "red"))
> >> missing <- is.na(mydata.final$Mean.Wait)
> >> newcol <- ifelse(missing, "white",
> >>
> >> rgb(newpal(mydata.final$Mean.Wait[!is.na(mydata.final$Mean.Wait)]/
> >>                                   max(mydata.final$Mean.Wait,
> >> na.rm=T)), maxColorValue=255))
> >> map('county', fill=TRUE, col=newcol,
> >>     resolution=0, lty=0, bg="transparent")
> >> map('state', lwd=1, add=TRUE)
> >>
> >> One understanding question: what exactly does this rgb line do and why
> >> do we have to say "maxColorValue=255"?
> >> Thank you!
> >>
> >> On Thu, Apr 2, 2015 at 5:02 PM, Dimitri Liakhovitski
> >> <dimitri.liakhovitski at gmail.com> wrote:
> >> > Thank you, Jean, but I think this newcol line is not working. I am
> >> > running:
> >> >
> >> > newcol <- ifelse(missing, "white",
> >> >
> >> > rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
> >> > na.rm=T)),
> >> >                      maxColorValue=255))
> >> >
> >> > # And I am getting:
> >> > Error in rgb(newpal(mydata.final$Mean.Wait/max(mydata.final$Mean.Wait,
> >> > :
> >> >   color intensity NA, not in 0:255
> >> >
> >> > I think it's not liking the NAs - despite the ifelse...
> >> >
> >> > On Thu, Apr 2, 2015 at 4:26 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> >> >> Dimitri,
> >> >>
> >> >> You could use colorRamp() and rgb() to get more continuous colors.
> >> >> For example
> >> >>
> >> >> newpal <- colorRamp(c("yellow", "red"))
> >> >> missing <- is.na(mydata.final$Mean.Wait)
> >> >> newcol <- ifelse(missing, "white",
> >> >>   rgb(newpal(mydat$Mean.Wait/max(mydat$Mean.Wait)),
> maxColorValue=255))
> >> >> map('county', fill=TRUE, col=newcol,
> >> >>             resolution=0, lty=0, bg="transparent")
> >> >> map('state', lwd=1, add=TRUE)
> >> >>
> >> >> Jean
> >> >>
> >> >>
> >> >> On Thu, Apr 2, 2015 at 12:03 PM, Dimitri Liakhovitski
> >> >> <dimitri.liakhovitski at gmail.com> wrote:
> >> >>>
> >> >>> I have a data frame 'mydata.final' (see below) that contains US
> >> >>> counties and a continuous numeric variable 'Mean.Wait' that ranges
> >> >>> from zero to 10 or so. I also created variable 'wait' that is based
> on
> >> >>> the 'Mean.Wait' and takes on discrete values from 1 (lowest values
> on
> >> >>> 'Mean.Wait') to 5 (highest values on 'Mean.Wait').
> >> >>>
> >> >>> I can create a map of the US with the counties colored based on the
> >> >>> values of 'wait' using R package 'maps':
> >> >>>
> >> >>> #################################################################
> >> >>> ### Generating an artificial data file:
> >> >>> #################################################################
> >> >>> library(maps)
> >> >>> mydata.final <- data.frame(county = (map('county', plot =
> >> >>> FALSE)$names),
> >> >>>                  stringsAsFactors = F)
> >> >>>
> >> >>> ### My numeric variable:
> >> >>> set.seed(123)
> >> >>> mydata.final$Mean.Wait <- runif(nrow(mydata.final)) * 10
> >> >>>
> >> >>> ### Introducing NAs to mimic my real data set:
> >> >>> set.seed(1234)
> >> >>> mydata.final$Mean.Wait[sample(1:nrow(mydata.final), 1500)] <- NA
> >> >>>
> >> >>> ### Cutting the original numeric variable into categories
> >> >>> ### because I don't know how to color based on 'Mean.Wait':
> >> >>> mydata.final$wait <- cut(mydata.final$Mean.Wait, breaks = 5)
> >> >>> levels(mydata.final$wait) <- 1:5
> >> >>> mydata.final$wait <- as.numeric(as.character(mydata.final$wait))
> >> >>>
> >> >>> ####################################################################
> >> >>> Building a US map based on 'wait' (5 categories)
> >> >>> #################################################################
> >> >>>
> >> >>> ### Creating my 5 colors:
> >> >>> pal <- colorRampPalette(c("yellow", "red"))
> >> >>> allcolors <- pal(5)
> >> >>>
> >> >>> ### Looking at my 5 colors:
> >> >>> barplot(1:5, rep(1,5), col = allcolors, horiz = T)
> >> >>>
> >> >>> ### Builiding the US map using 5 categories in 'wait':
> >> >>> map('county', fill = TRUE, col = allcolors[mydata.final$wait],
> >> >>>             resolution = 0, lty = 0, bg = "transparent")
> >> >>> map('state', lwd=1, add=TRUE)
> >> >>>
> >> >>> My goal is: instead of splitting 'Mean.Wait' into 5 ordered
> categories
> >> >>> ('wait'), I'd like to color the counties on the map based on the
> >> >>> intensity of my (continuous) 'Mean.Wait'. What would be the way to
> do
> >> >>> it and maybe even to add a legend?
> >> >>> Thanks a lot!
> >> >>>
> >> >>> --
> >> >>> Dimitri Liakhovitski
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide
> >> >>> http://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >> >
> >> >
> >> >
> >> > --
> >> > Dimitri Liakhovitski
> >>
> >>
> >>
> >> --
> >> Dimitri Liakhovitski
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Fri Apr  3 20:24:29 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 3 Apr 2015 19:24:29 +0100
Subject: [R] open xlsx file using read.xls function of gdata package
Message-ID: <CAMk+s2SjuLgqWiMMzgvDFfgv_WSeEY7_uMys7PT1uAWVmNCPUQ@mail.gmail.com>

Dear all,
I am trying to open excel files using the gdata package. I can do that
using a .xls file, but the same file, containing the same data,
formatted in .xlsx gives error (R does not recognize the pattern from
where to start reading the data).
Doen anybody knows whether it is possible to read .xlslx with this package?
Am I missing another package to implement the reading of the .xlsx?
Thank you
Luigi

PS: this is the error I get:
> my.file <- "array.xlsx"
> my.data<-read.xls(
+       my.file,
+       sheet="sheet x",
+       verbose=FALSE,
+       pattern="row name",
+       na.strings=c("NA","#DIV/0!"),
+       method="tab",
+       perl="perl"
+     )
> Warning message:
In read.xls(my.file, sheet = "sheet x", verbose = FALSE,  :
  pattern not found


The verbose version runs like this:
    ?array.xlsx?
to tab  file
    ?/tmp/Rtmp2tAjzz/filef06102dd018.tab?
...

Executing ' '/usr/bin/perl'
'/home/gigiux/R/x86_64-pc-linux-gnu-library/3.0/gdata/perl/xls2tab.pl'
 'array.xlsx' '/tmp/Rtmp2tAjzz/filef06102dd018.tab' 'sheet x' '...

Loading 'array.xlsx'...
Done.

Orignal Filename: array.xlsx
Number of Sheets: 2

Writing sheet 'sheet x' to file '/tmp/Rtmp2tAjzz/filef06102dd018.tab'
Minrow=31 Maxrow=17310 Mincol=0 Maxcol=4
  (Ignored 0 blank lines.)

0

Done.

Searching for lines tfntaining pattern  row name ...
Warning message:
In read.xls(my.file, sheet = "sheet x", verbose = TRUE,  :
  pattern not found
>


From jdnewmil at dcn.davis.CA.us  Fri Apr  3 21:07:01 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 03 Apr 2015 12:07:01 -0700
Subject: [R] open xlsx file using read.xls function of gdata package
In-Reply-To: <CAMk+s2SjuLgqWiMMzgvDFfgv_WSeEY7_uMys7PT1uAWVmNCPUQ@mail.gmail.com>
References: <CAMk+s2SjuLgqWiMMzgvDFfgv_WSeEY7_uMys7PT1uAWVmNCPUQ@mail.gmail.com>
Message-ID: <B45C0B14-1D95-4417-880F-F028E5F7D08C@dcn.davis.CA.us>

I had poor luck with gdata. I have had better luck with XLConnect. There is no single best package for this, since each seems to leverage efforts made in other languages (so there are non-R configuration requirements to keep working) and Excel is a proprietary moving target. In general YMMV when it comes to Excel data. In most cases I just export the data to CSV and avoid the issue.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 3, 2015 11:24:29 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Dear all,
>I am trying to open excel files using the gdata package. I can do that
>using a .xls file, but the same file, containing the same data,
>formatted in .xlsx gives error (R does not recognize the pattern from
>where to start reading the data).
>Doen anybody knows whether it is possible to read .xlslx with this
>package?
>Am I missing another package to implement the reading of the .xlsx?
>Thank you
>Luigi
>
>PS: this is the error I get:
>> my.file <- "array.xlsx"
>> my.data<-read.xls(
>+       my.file,
>+       sheet="sheet x",
>+       verbose=FALSE,
>+       pattern="row name",
>+       na.strings=c("NA","#DIV/0!"),
>+       method="tab",
>+       perl="perl"
>+     )
>> Warning message:
>In read.xls(my.file, sheet = "sheet x", verbose = FALSE,  :
>  pattern not found
>
>
>The verbose version runs like this:
>    ?array.xlsx?
>to tab  file
>    ?/tmp/Rtmp2tAjzz/filef06102dd018.tab?
>...
>
>Executing ' '/usr/bin/perl'
>'/home/gigiux/R/x86_64-pc-linux-gnu-library/3.0/gdata/perl/xls2tab.pl'
> 'array.xlsx' '/tmp/Rtmp2tAjzz/filef06102dd018.tab' 'sheet x' '...
>
>Loading 'array.xlsx'...
>Done.
>
>Orignal Filename: array.xlsx
>Number of Sheets: 2
>
>Writing sheet 'sheet x' to file '/tmp/Rtmp2tAjzz/filef06102dd018.tab'
>Minrow=31 Maxrow=17310 Mincol=0 Maxcol=4
>  (Ignored 0 blank lines.)
>
>0
>
>Done.
>
>Searching for lines tfntaining pattern  row name ...
>Warning message:
>In read.xls(my.file, sheet = "sheet x", verbose = TRUE,  :
>  pattern not found
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Fri Apr  3 21:42:43 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Fri, 3 Apr 2015 19:42:43 +0000 (UTC)
Subject: [R] WEIBULL or EXPONENTIAL?
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A051E84@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A051E84@mail-mbx-03.UNINE.CH>
Message-ID: <394662645.6333120.1428090163127.JavaMail.yahoo@mail.yahoo.com>

Hi Xavier,

I use the fitdistrplus and logspline packages to know which distribution fits better my data.


Here is an example :

install.packages("fitdistrplus")
library(fitdistrplus)
instal.packages("logspline")
library(logspline)
x=c(44986,18288,56147,44488,41018,40631,27301,39025,45688,47172,12300,21558,16103,48874,67245,36119,10398,42630,12879,34058,84443,30639)
descdist(x,discrete=FALSE) 

Cheers,
S.



________________________________
De : CHIRIBOGA Xavier <xavier.chiriboga at unine.ch>
? : "r-help at r-project.org" <r-help at r-project.org> 
Envoy? le : Vendredi 3 avril 2015 16h33
Objet : [R] WEIBULL or EXPONENTIAL?


Dear members,



I am doing a survival analysis wiith the function coxph...however I am wondering how can I know if my data follows a EXPONENTIAL or WEIBULL distribution?

I have 3 censored datum. Using R studio.



Thanks for the suggestions,



Xavier

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wyllys at ischool.utexas.edu  Fri Apr  3 23:07:57 2015
From: wyllys at ischool.utexas.edu (Ronald Wyllys)
Date: Fri, 03 Apr 2015 16:07:57 -0500
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
Message-ID: <551F012D.3020304@ischool.utexas.edu>

For an edx course, MIT's "The Analtics Edge", I need to install the 
"caret" package that was originated and is maintained by Dr. Max Kuhn of 
Pfizer. So far, every effort I've made to try to 
install.packages("caret") has failed.  (I'm using R v. 3.1.3 and RStudio 
v. 0.98.1103 in LinuxMint 17.1)

Here are some of the things I've tried unsuccessfully:
install.packages("caret", repos=c("http://rstudio.org/_packages", 
"http://cran.rstudio.com"))
install.packages("caret", dependencies=TRUE)
install.packages("caret", repos=c("http://rstudio.org/_packages", 
"http://cran.rstudio.com"), dependencies=TRUE)
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("caret", repos="http://cran.rstudio.com/")

I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas, 
and tried the above installs again, unsuccessfully.

I've succeeded in individually installing a number of packages on which 
"caret" appears to be dependent.  Specifically, I've been able to 
install  "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and 
"scales".  But I've had no success with trying to do individual installs 
of "BradleyTerry2", "car", "lme4", "quantreg", and "RcppEigen".

Any suggestions will be very gratefully received (and tried out quickly).

Thanks in advance.

Ron Wyllys


From sarah.goslee at gmail.com  Fri Apr  3 23:14:19 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 3 Apr 2015 17:14:19 -0400
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
In-Reply-To: <551F012D.3020304@ischool.utexas.edu>
References: <551F012D.3020304@ischool.utexas.edu>
Message-ID: <CAM_vjukTxUmx0=xZq8TQUSn2njz1ypK7P+3qBGiCCL_mro-MPw@mail.gmail.com>

Hi Ron,

Without knowing more it's really hard to help. What error messages are
you getting?
"failed" and "no success" are utterly uninformative - there are many
things that could be wrong.

The first thing, though, is always to check whether you have the
necessary dependencies installed, eg devel libraries.

Sarah

On Fri, Apr 3, 2015 at 5:07 PM, Ronald Wyllys <wyllys at ischool.utexas.edu> wrote:
> For an edx course, MIT's "The Analtics Edge", I need to install the "caret"
> package that was originated and is maintained by Dr. Max Kuhn of Pfizer. So
> far, every effort I've made to try to install.packages("caret") has failed.
> (I'm using R v. 3.1.3 and RStudio v. 0.98.1103 in LinuxMint 17.1)
>
> Here are some of the things I've tried unsuccessfully:
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"))
> install.packages("caret", dependencies=TRUE)
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"), dependencies=TRUE)
> install.packages("caret", dependencies = c("Depends", "Suggests"))
> install.packages("caret", repos="http://cran.rstudio.com/")
>
> I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas, and
> tried the above installs again, unsuccessfully.
>
> I've succeeded in individually installing a number of packages on which
> "caret" appears to be dependent.  Specifically, I've been able to install
> "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and "scales".  But I've
> had no success with trying to do individual installs of "BradleyTerry2",
> "car", "lme4", "quantreg", and "RcppEigen".
>
> Any suggestions will be very gratefully received (and tried out quickly).
>
> Thanks in advance.
>
> Ron Wyllys
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ligges at statistik.tu-dortmund.de  Fri Apr  3 23:15:53 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 03 Apr 2015 23:15:53 +0200
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
In-Reply-To: <551F012D.3020304@ischool.utexas.edu>
References: <551F012D.3020304@ischool.utexas.edu>
Message-ID: <551F0309.4020401@statistik.tu-dortmund.de>

What is the error message?

Best,
Uwe Ligges

On 03.04.2015 23:07, Ronald Wyllys wrote:
> For an edx course, MIT's "The Analtics Edge", I need to install the
> "caret" package that was originated and is maintained by Dr. Max Kuhn of
> Pfizer. So far, every effort I've made to try to
> install.packages("caret") has failed.  (I'm using R v. 3.1.3 and RStudio
> v. 0.98.1103 in LinuxMint 17.1)
>
> Here are some of the things I've tried unsuccessfully:
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"))
> install.packages("caret", dependencies=TRUE)
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"), dependencies=TRUE)
> install.packages("caret", dependencies = c("Depends", "Suggests"))
> install.packages("caret", repos="http://cran.rstudio.com/")
>
> I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas,
> and tried the above installs again, unsuccessfully.
>
> I've succeeded in individually installing a number of packages on which
> "caret" appears to be dependent.  Specifically, I've been able to
> install  "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and
> "scales".  But I've had no success with trying to do individual installs
> of "BradleyTerry2", "car", "lme4", "quantreg", and "RcppEigen".
>
> Any suggestions will be very gratefully received (and tried out quickly).
>
> Thanks in advance.
>
> Ron Wyllys
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cflynch at ncsu.edu  Fri Apr  3 23:17:40 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Fri, 3 Apr 2015 17:17:40 -0400
Subject: [R] Kruskal-Wallace power calculations.
In-Reply-To: <CAFEqCdyUf2mfJCHKiQ5_QeXWc1yn2DBKwBjz88K8dFs5v3puPw@mail.gmail.com>
References: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
	<19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>
	<CA+8X3fV4HvfD92EZGCOukPejmAuG_iUtG-SdBzXTtd4tuoP_mQ@mail.gmail.com>
	<CAE=6FXb7BJBDW6FbYD=8m932-Y1ZmP0C-pnhjboks7Kzeo=X1Q@mail.gmail.com>
	<CAFEqCdyUf2mfJCHKiQ5_QeXWc1yn2DBKwBjz88K8dFs5v3puPw@mail.gmail.com>
Message-ID: <CAE=6FXagtXBtJjKNyGFHi9ACYLFnxZxjrY0ik3hz3XGWA1y1ww@mail.gmail.com>

Thank you very much Greg, I will give that a try.

    Best,
    Collin.

On Fri, Apr 3, 2015 at 1:43 PM, Greg Snow <538280 at gmail.com> wrote:
> Here is some sample code:
>
> ## Simulation function to create data, analyze it using
> ## kruskal.test, and return the p-value
> ## change rexp to change the simulation distribution
>
> simfun <- function(means, k=length(means), n=rep(50,k)) {
>   mydata <- lapply( seq_len(k), function(i) {
>     rexp(n[i], 1) - 1 + means[i]
>   })
>   kruskal.test(mydata)$p.value
> }
>
> # simulate under the null to check proper sizing
> B <- 10000
> out1 <- replicate(B, simfun(rep(3,4)))
> hist(out1)
> mean( out1 <= 0.05 )
> binom.test( sum(out1 <= 0.05), B, p=0.05)
>
> ### Now simulate for power
>
> B <- 10000
> out2 <- replicate(B, simfun( c(3,3,3.2,3.3)))
> hist(out2)
> mean( out2 <= 0.05 )
> binom.test( sum(out2 <= 0.05), B, p=0.05 )
>
> This simulates from a continuous exponential (skewed) and shifts to
> get the means (shifted location is a common assumption, though not
> required for the actual test).
>
> On Thu, Apr 2, 2015 at 8:19 PM, Collin Lynch <cflynch at ncsu.edu> wrote:
>> Thank you Jim, I did see those (though not my typo :) and am still
>> pondering the warning about post-hoc analyses.
>>
>> The situation that I am in is that I have a set of individuals who
>> have been assigned a course grade.  We have then clustered these
>> individuals into about 50 communities using standard community
>> detection algorithms with the goal of determining whether community
>> membership affects one of their grades.  We are using the KW test as
>> the grade data is strongly non-normal and my coauthors preferred KW as
>> an alternative.
>>
>> The two issues that I am struggling with are: 1) whether the post-hoc
>> power analysis would be useful; and 2) how to code the simulation
>> studies that are described in:
>> http://onlinelibrary.wiley.com/doi/10.1002/bimj.4710380510/abstract
>>
>>
>> Problem #1 is of course beyond the scope of this e-mail list though I
>> would welcome anyone's suggestions on that point.  I am not sure that
>> I buy the arguments against it offered here:
>>
>> http://graphpad.com/support/faq/why-it-is-not-helpful-to-compute-the-power-of-an-experiment-to-detect-the-difference-actually-observed-why-is-post-hoc-power-analysis-futile/
>>
>> It seems that the rationale boils down to "you didn't find it so you
>> couldn't find it" but that does not tell me how far off I was from the
>> goal.  I am still perusing the articles the author cites however.
>>
>>
>> With respect to question #2 I am trying to lay my hands on the article
>> and did find this old r-help discussion:
>> http://r.789695.n4.nabble.com/Power-of-Kruskal-Wallis-Test-td4671188.html
>> however I am not sure how to adapt the simulation studies that it
>> links to to my current problem.  The links it leads to focus on
>> mixed-effects models.  This may be more of a pure stats question and
>> not suited for this list but I thought I'd ask in the hopes that
>> anyone had any more specific KW code or knew of a good tutorial for
>> the right kinds of simulation studies.
>>
>>     Thank you,
>>     Collin.
>>
>>
>>
>>
>> On Thu, Apr 2, 2015 at 6:35 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Collin,
>>> Have a look at this:
>>>
>>> http://stats.stackexchange.com/questions/70643/power-analysis-for-kruskal-wallis-or-mann-whitney-u-test-using-r
>>>
>>> Although, thinking about it, this might have constituted your "perusal of
>>> the literature".
>>>
>>> Plus it always looks better when you spell the names properly
>>>
>>> Jim
>>>
>>>
>>> On Fri, Apr 3, 2015 at 2:23 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>>
>>>> Please stop... you are acting like a broken record, and are also posting
>>>> in HTML format. Please read the Posting Guide and demonstrate that you have
>>>> used a search engine on this topic before posting again.
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On April 2, 2015 7:25:20 AM PDT, Collin Lynch <cflynch at ncsu.edu> wrote:
>>>> >Greetings, I am working on a project where we are applying the
>>>> >Kruskal-Wallace test to some factor data to evaluate their correlation
>>>> >with
>>>> >existing grade data.  I know that the grade data is nonnormal therefore
>>>> >we
>>>> >cannot rely on ANOVA or a similar parametric test.  What I would like
>>>> >to
>>>> >find is a mechanism for making power calculations for the KW test given
>>>> >the
>>>> >nonparametric assumptions.  My perusal of the literature has suggested
>>>> >that
>>>> >a simulation would be the best method.
>>>> >
>>>> >Can anyone point me to good examples of such simulations for KW in R?
>>>> >And
>>>> >does anyone have a favourite package for generating simulated data or
>>>> >conducting such tests?
>>>> >
>>>> >    Thank you,
>>>> >    Collin.
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> >______________________________________________
>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >PLEASE do read the posting guide
>>>> >http://www.R-project.org/posting-guide.html
>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From aolinto.lst at gmail.com  Sat Apr  4 01:08:11 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Fri, 3 Apr 2015 20:08:11 -0300
Subject: [R] species names on a RDA plot
Message-ID: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>

Dear R users

I'm trying to do a RDA analysis based on Borcard et al. 2011 Numerical
Ecology with R examples.

What I cannot understand is why when I run the script (RDA.R) using the
dataset from book (dataset1.rar) RDA triplot shows species names and when I
use my dataset (dataset2.rar) species names are not shown.

Data and script can be downloaded at
https://app.box.com/s/oayq7tglbmdsu72fj05h83dlzclsiglg

Does anyone know why this happens? Thanks for any clue.

Best regards

Ant?nio Olinto ?vila da Silva
Fisheries Institute
S?o Paulo, Brasil

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Sat Apr  4 02:12:27 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 3 Apr 2015 19:12:27 -0500
Subject: [R] open xlsx file using read.xls function of gdata package
In-Reply-To: <CAMk+s2SjuLgqWiMMzgvDFfgv_WSeEY7_uMys7PT1uAWVmNCPUQ@mail.gmail.com>
References: <CAMk+s2SjuLgqWiMMzgvDFfgv_WSeEY7_uMys7PT1uAWVmNCPUQ@mail.gmail.com>
Message-ID: <CABdHhvG8E7SjEWJWcW2L34=82jhiEgpuV0Zoz2CDr5QUS18aWA@mail.gmail.com>

You might try the readxl package - it's only available on github but it
reads both xlsx and xls. All going well, it should be on its way to CRAN
next week.

Hadley

On Friday, April 3, 2015, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Dear all,
> I am trying to open excel files using the gdata package. I can do that
> using a .xls file, but the same file, containing the same data,
> formatted in .xlsx gives error (R does not recognize the pattern from
> where to start reading the data).
> Doen anybody knows whether it is possible to read .xlslx with this package?
> Am I missing another package to implement the reading of the .xlsx?
> Thank you
> Luigi
>
> PS: this is the error I get:
> > my.file <- "array.xlsx"
> > my.data<-read.xls(
> +       my.file,
> +       sheet="sheet x",
> +       verbose=FALSE,
> +       pattern="row name",
> +       na.strings=c("NA","#DIV/0!"),
> +       method="tab",
> +       perl="perl"
> +     )
> > Warning message:
> In read.xls(my.file, sheet = "sheet x", verbose = FALSE,  :
>   pattern not found
>
>
> The verbose version runs like this:
>     ?array.xlsx?
> to tab  file
>     ?/tmp/Rtmp2tAjzz/filef06102dd018.tab?
> ...
>
> Executing ' '/usr/bin/perl'
> '/home/gigiux/R/x86_64-pc-linux-gnu-library/3.0/gdata/perl/xls2tab.pl'
>  'array.xlsx' '/tmp/Rtmp2tAjzz/filef06102dd018.tab' 'sheet x' '...
>
> Loading 'array.xlsx'...
> Done.
>
> Orignal Filename: array.xlsx
> Number of Sheets: 2
>
> Writing sheet 'sheet x' to file '/tmp/Rtmp2tAjzz/filef06102dd018.tab'
> Minrow=31 Maxrow=17310 Mincol=0 Maxcol=4
>   (Ignored 0 blank lines.)
>
> 0
>
> Done.
>
> Searching for lines tfntaining pattern  row name ...
> Warning message:
> In read.xls(my.file, sheet = "sheet x", verbose = TRUE,  :
>   pattern not found
> >
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/

	[[alternative HTML version deleted]]


From ali.alrubaiee1984 at gmail.com  Fri Apr  3 20:16:11 2015
From: ali.alrubaiee1984 at gmail.com (ali alRubaiee)
Date: Fri, 3 Apr 2015 14:16:11 -0400
Subject: [R] command help
Message-ID: <CAO9gewWej-pEN1kZ+8+fpoDA2mtayFywzprntEG7A_d9MNQvHw@mail.gmail.com>

Dear colleagues,
I wanted to run a command to do iteration for the following equation:
Pj+1=TT11+FtransposeTT22F-FtransposeTT21-TT12
F+y[(Atranspose-FtransposeBtranspose)P(A-BF)]

where TT11, TT22,TT12, TT21, F transpose, A, B and F are matrices and y is
a scalar
we want to find the iteration for P using loop. Can you send me the right
command for the loop for the above equation?


Thank you in advance,
Ali

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Fri Apr  3 19:43:47 2015
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 3 Apr 2015 11:43:47 -0600
Subject: [R] Kruskal-Wallace power calculations.
In-Reply-To: <CAE=6FXb7BJBDW6FbYD=8m932-Y1ZmP0C-pnhjboks7Kzeo=X1Q@mail.gmail.com>
References: <CAE=6FXaSzJ+xKfqd37ciwge3BPu8BtA9QKAwyQgbKWVyzzAh5Q@mail.gmail.com>
	<19C30859-55AB-4D68-9429-0A6F95BDD56B@dcn.davis.CA.us>
	<CA+8X3fV4HvfD92EZGCOukPejmAuG_iUtG-SdBzXTtd4tuoP_mQ@mail.gmail.com>
	<CAE=6FXb7BJBDW6FbYD=8m932-Y1ZmP0C-pnhjboks7Kzeo=X1Q@mail.gmail.com>
Message-ID: <CAFEqCdyUf2mfJCHKiQ5_QeXWc1yn2DBKwBjz88K8dFs5v3puPw@mail.gmail.com>

Here is some sample code:

## Simulation function to create data, analyze it using
## kruskal.test, and return the p-value
## change rexp to change the simulation distribution

simfun <- function(means, k=length(means), n=rep(50,k)) {
  mydata <- lapply( seq_len(k), function(i) {
    rexp(n[i], 1) - 1 + means[i]
  })
  kruskal.test(mydata)$p.value
}

# simulate under the null to check proper sizing
B <- 10000
out1 <- replicate(B, simfun(rep(3,4)))
hist(out1)
mean( out1 <= 0.05 )
binom.test( sum(out1 <= 0.05), B, p=0.05)

### Now simulate for power

B <- 10000
out2 <- replicate(B, simfun( c(3,3,3.2,3.3)))
hist(out2)
mean( out2 <= 0.05 )
binom.test( sum(out2 <= 0.05), B, p=0.05 )

This simulates from a continuous exponential (skewed) and shifts to
get the means (shifted location is a common assumption, though not
required for the actual test).

On Thu, Apr 2, 2015 at 8:19 PM, Collin Lynch <cflynch at ncsu.edu> wrote:
> Thank you Jim, I did see those (though not my typo :) and am still
> pondering the warning about post-hoc analyses.
>
> The situation that I am in is that I have a set of individuals who
> have been assigned a course grade.  We have then clustered these
> individuals into about 50 communities using standard community
> detection algorithms with the goal of determining whether community
> membership affects one of their grades.  We are using the KW test as
> the grade data is strongly non-normal and my coauthors preferred KW as
> an alternative.
>
> The two issues that I am struggling with are: 1) whether the post-hoc
> power analysis would be useful; and 2) how to code the simulation
> studies that are described in:
> http://onlinelibrary.wiley.com/doi/10.1002/bimj.4710380510/abstract
>
>
> Problem #1 is of course beyond the scope of this e-mail list though I
> would welcome anyone's suggestions on that point.  I am not sure that
> I buy the arguments against it offered here:
>
> http://graphpad.com/support/faq/why-it-is-not-helpful-to-compute-the-power-of-an-experiment-to-detect-the-difference-actually-observed-why-is-post-hoc-power-analysis-futile/
>
> It seems that the rationale boils down to "you didn't find it so you
> couldn't find it" but that does not tell me how far off I was from the
> goal.  I am still perusing the articles the author cites however.
>
>
> With respect to question #2 I am trying to lay my hands on the article
> and did find this old r-help discussion:
> http://r.789695.n4.nabble.com/Power-of-Kruskal-Wallis-Test-td4671188.html
> however I am not sure how to adapt the simulation studies that it
> links to to my current problem.  The links it leads to focus on
> mixed-effects models.  This may be more of a pure stats question and
> not suited for this list but I thought I'd ask in the hopes that
> anyone had any more specific KW code or knew of a good tutorial for
> the right kinds of simulation studies.
>
>     Thank you,
>     Collin.
>
>
>
>
> On Thu, Apr 2, 2015 at 6:35 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Collin,
>> Have a look at this:
>>
>> http://stats.stackexchange.com/questions/70643/power-analysis-for-kruskal-wallis-or-mann-whitney-u-test-using-r
>>
>> Although, thinking about it, this might have constituted your "perusal of
>> the literature".
>>
>> Plus it always looks better when you spell the names properly
>>
>> Jim
>>
>>
>> On Fri, Apr 3, 2015 at 2:23 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>>
>>> Please stop... you are acting like a broken record, and are also posting
>>> in HTML format. Please read the Posting Guide and demonstrate that you have
>>> used a search engine on this topic before posting again.
>>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 2, 2015 7:25:20 AM PDT, Collin Lynch <cflynch at ncsu.edu> wrote:
>>> >Greetings, I am working on a project where we are applying the
>>> >Kruskal-Wallace test to some factor data to evaluate their correlation
>>> >with
>>> >existing grade data.  I know that the grade data is nonnormal therefore
>>> >we
>>> >cannot rely on ANOVA or a similar parametric test.  What I would like
>>> >to
>>> >find is a mechanism for making power calculations for the KW test given
>>> >the
>>> >nonparametric assumptions.  My perusal of the literature has suggested
>>> >that
>>> >a simulation would be the best method.
>>> >
>>> >Can anyone point me to good examples of such simulations for KW in R?
>>> >And
>>> >does anyone have a favourite package for generating simulated data or
>>> >conducting such tests?
>>> >
>>> >    Thank you,
>>> >    Collin.
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From mehmet.suzen at physics.org  Fri Apr  3 21:03:59 2015
From: mehmet.suzen at physics.org (Suzen, Mehmet)
Date: Fri, 3 Apr 2015 20:03:59 +0100
Subject: [R] glmnet: converting coefficients back to original scale
In-Reply-To: <CAK2mLtNNEC6b+5OhszfLpC9SRvZvf-v1KBwPRYMLFQWYzDikzw@mail.gmail.com>
References: <CAK2mLtNNEC6b+5OhszfLpC9SRvZvf-v1KBwPRYMLFQWYzDikzw@mail.gmail.com>
Message-ID: <CAPtbhHxV5Qz+7A2tSxEhFTFiYjjueq-tVE1gpwWkwpkfEXboQg@mail.gmail.com>

This is interesting, can you post your lm.ridge solution as well?  I
suspect in glmnet, you need to use model.matrix with intercept, that
could be the reason.

-m


From jdnewmil at dcn.davis.CA.us  Sat Apr  4 05:19:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 03 Apr 2015 20:19:14 -0700
Subject: [R] command help
In-Reply-To: <CAO9gewWej-pEN1kZ+8+fpoDA2mtayFywzprntEG7A_d9MNQvHw@mail.gmail.com>
References: <CAO9gewWej-pEN1kZ+8+fpoDA2mtayFywzprntEG7A_d9MNQvHw@mail.gmail.com>
Message-ID: <8E81FA86-AFD5-411A-9915-862FA769E606@dcn.davis.CA.us>

I cannot make sense of your email. This is partly due to your use of HTML, which the Posting Guidelines warn you not to do. 

The symbolic language used on this mailing list is R. The linear algebra operations available in R are rather straightforward. Please read the documentation and convey your request using R do we can understand you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 3, 2015 11:16:11 AM PDT, ali alRubaiee <ali.alrubaiee1984 at gmail.com> wrote:
>Dear colleagues,
>I wanted to run a command to do iteration for the following equation:
>Pj+1=TT11+FtransposeTT22F-FtransposeTT21-TT12
>F+y[(Atranspose-FtransposeBtranspose)P(A-BF)]
>
>where TT11, TT22,TT12, TT21, F transpose, A, B and F are matrices and y
>is
>a scalar
>we want to find the iteration for P using loop. Can you send me the
>right
>command for the loop for the above equation?
>
>
>Thank you in advance,
>Ali
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Apr  4 11:24:04 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 4 Apr 2015 11:24:04 +0200
Subject: [R] Does fitCopula work for amhCopula and joeCopula?
In-Reply-To: <DUB407-EAS95CE8BE31F5717A220EBE8BF40@phx.gbl>
References: <DUB407-EAS95CE8BE31F5717A220EBE8BF40@phx.gbl>
Message-ID: <7B73D13A-8761-48B5-8C38-7A9194DE36D3@gmail.com>

You might be better off on a list specifically for financial data analysis. In particular, few people here will instantly know that you are talking about functions the copula package. And even many of us who have dabbled in copulas will have difficulty knowing all of the details of them. Also, "doesn't work" is too unspecific to allow people to pinpoint the problem, and you might be expected to narrow down and debug the issue rather than just handing us a lot of R code.

Offhand, you certainly have a problem with reuse of the variable name `j`.

-pd

> On 31 Mar 2015, at 18:39 , Laura Gianfagna <laura.gianfagna at outlook.it> wrote:
> 
> Good evening, this is a part of my Routine  which calculates the copula parameter and loglikelihood for each pair of rows of a data matrix, choosing, for each pair, the copula which gives the maximum likelihood. If I do my computation with this routine with only:
> 
> 
> f <- frankCopula(2,2)
>  g <- gumbelCopula(2,2)
>  c <- claytonCopula(2,2)
> 
> 
> the program works correctly and gives the expected results.
> 
> If  I insert also:
> 
> 
>  a <- amhCopula(1,2)
>  j <- joeCopula(2,2)
> 
> 
> then the program doesn?t work anymore. 
> 
> I tried on samples such as:
> 
> 
> n <- 1000
> f <- frankCopula(20,2)
> x_1 <- rCopula(n,f)
> f <- gumbelCopula(50,2)
> x_2 <- rCopula(n,f)
> f <- joeCopula(70,2)
> x_3<- rCopula(n,f)
> x <- cbind(x_1, x_2, x_3)
> data <- t(x)
> dim <- dim(data)[1]
> 
> 
> 
> 
> 
> Here is the part of code of Routine_Copula:
> 
> Routine_Copula <- function(data,dim){
> 
>  library(copula)
>  library(gtools)
> 
>  n <- dim(data)[1];  # number of rows of the input matrix
>  m <- dim(data)[2];  # number of columns of the input matrix
> 
>  # Probability integral transform of the data
>  ecdf <- matrix(0,n,m);
>  for (i in 1:n){
>    e <- matrix(data[i,],m,1);
>    #ecdf[i,] <- pobs(e);
>    ecdf[i,] <- pobs(e, na.last=TRUE);
>    #na.last for controlling the treatment of NAs. If TRUE, missing values in the data are put last; if FALSE, they are put first; if NA, they are removed; if "keep" they are kept with rank NA.
> 
>  }
> 
> 
> 
> f <- frankCopula(2,2)
>  g <- gumbelCopula(2,2)
>  c <- claytonCopula(2,2)
>  a <- amhCopula(1,2)
>  j <- joeCopula(2,2)
> 
> 
> 
> 
> 
> [?.]
> 
> 
> for (j in 1:n_comb){
>    input <- t(ecdf[comb[,j],])
> 
>    try(summary <- fitCopula(f,input,method='mpl',start=2),silent=TRUE);
>    resmatpar[j,1] <- summary at estimate;
>    resmatllk[j,1] <- summary at loglik;
> 
>    try(summary <- fitCopula(g,input,method='mpl',start=2),silent=TRUE);
>    resmatpar[j,2] <- summary at estimate;
>    resmatllk[j,2] <- summary at loglik;
> 
>    try(summary <- fitCopula(c,input,method='mpl',start=2),silent=TRUE);
>    resmatpar[j,3] <- summary at estimate;
>    resmatllk[j,3] <- summary at loglik;
> 
> 
> try(summary <- fitCopula(a,input,method='mpl',start=1),silent=TRUE);
>    resmatpar[j,4] <- summary at estimate;
>     resmatllk[j,4] <- summary at loglik;
> 
> try(summary <- fitCopula(j,input,method='mpl',start=2),silent=TRUE);     
> 
> resmatpar[j,5] <- summary at estimate;
> resmatllk[j,5] <- summary at loglik;
> 
> d <- c(resmatllk[j,1],resmatllk[j,2],resmatllk[j,3],resmatllk[j,4],resmatllk[j,5]);
> 
> 
> 
>    copchoice[j] <- which(d==max(d));
>    param[j] <- resmatpar[j,copchoice[j]];
>    loglik[j] <- resmatllk[j,copchoice[j]];
> 
>  }
> 
> 
> Thank you
> 
> Laura Gianfagna
> 
> 
> ?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From markseeto at gmail.com  Sat Apr  4 12:09:49 2015
From: markseeto at gmail.com (Mark Seeto)
Date: Sat, 4 Apr 2015 21:09:49 +1100
Subject: [R] glmnet: converting coefficients back to original scale
In-Reply-To: <CAPtbhHxV5Qz+7A2tSxEhFTFiYjjueq-tVE1gpwWkwpkfEXboQg@mail.gmail.com>
References: <CAK2mLtNNEC6b+5OhszfLpC9SRvZvf-v1KBwPRYMLFQWYzDikzw@mail.gmail.com>
	<CAPtbhHxV5Qz+7A2tSxEhFTFiYjjueq-tVE1gpwWkwpkfEXboQg@mail.gmail.com>
Message-ID: <CAK2mLtNWWRQsbeMEGWsYEquQY34AZA-DECAS4TT0M82Yq77Y1w@mail.gmail.com>

Thanks for your reply Mehmet. I've found that the problem was that I
didn't scale the lambda value. My original example did not follow the
instruction not to give a single lambda value, but that in itself
wasn't the problem. Example shown below.

library(glmnet)
library(MASS)

set.seed(1)
n <- 20

d <- data.frame(x1 = rnorm(n, 1, 1),
                x2 = rnorm(n, 10, 2),
                y = rnorm(n, 1, 2))

# Sample means
mx1 <- mean(d$x1)
mx2 <- mean(d$x2)
my <- mean(d$y)

# Scaling factors
sx1 <- sd(d$x1)*sqrt((n-1)/n)
sx2 <- sd(d$x2)*sqrt((n-1)/n)
sy <- sd(d$y)*sqrt((n-1)/n)

# Scaled variables
d$x1s <- (d$x1 - mx1)/sx1
d$x2s <- (d$x2 - mx2)/sx2
d$ys <- (d$y - my)/sy

# Centred y
d$yc <- d$y - my

lam <- 1  # lambda value for lm.ridge

lmr1 <- lm.ridge(y ~ x1 + x2, data=d, lambda=lam)
lmr2 <- lm.ridge(yc ~ x1s + x2s, data=d, lambda=lam)

coef(lmr1)

my - coef(lmr2)["x1s"]*mx1/sx1 - coef(lmr2)["x2s"]*mx2/sx2
# same as coef(lmr1)[1]

coef(lmr2)["x1s"]/sx1  # same as coef(lmr1)["x1"]
coef(lmr2)["x2s"]/sx2  # same as coef(lmr1)["x2"]

glmnet1 <- glmnet(as.matrix(d[, c("x1", "x2")]), d[, "y"], alpha=0)
glmnet2 <- glmnet(as.matrix(d[, c("x1s", "x2s")]), d[, "ys"], alpha=0)

# Note: glmnet1$lambda is glmnet2$lambda*sy

ind <- 80  # index of lambda values to look at

coef(glmnet1)[, ind]

my - coef(glmnet2)["x1s", ind]*mx1*sy/sx1 -
  coef(glmnet2)["x2s", ind]*mx2*sy/sx2
# same as coef(glmnet1)["(Intercept)", ind]

coef(glmnet2)["x1s", ind]*sy/sx1
# same as coef(glmnet1)["x1", ind]

coef(glmnet2)["x2s", ind]*sy/sx2
# same as coef(glmnet1)["x2", ind]


On Sat, Apr 4, 2015 at 6:03 AM, Suzen, Mehmet <mehmet.suzen at physics.org> wrote:
> This is interesting, can you post your lm.ridge solution as well?  I
> suspect in glmnet, you need to use model.matrix with intercept, that
> could be the reason.
>
> -m


From aolinto.lst at gmail.com  Sat Apr  4 14:44:53 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sat, 4 Apr 2015 09:44:53 -0300
Subject: [R] species names on a RDA plot
In-Reply-To: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>
References: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>
Message-ID: <CAE8g1gPjfGvF42b5j38uE_AWU270NGBFyEV7iPpAd_NGawmVVQ@mail.gmail.com>

Hello everybody

The problem is that species names are shown in the ordination diagram when
the data set has a maximum of 80 rows, and mine has 81 (!!!).

So now the question is: it is possible to go through this limitation?

Thanks again,

Ant?nio Olinto


2015-04-03 20:08 GMT-03:00 Antonio Silva <aolinto.lst at gmail.com>:

> Dear R users
>
> I'm trying to do a RDA analysis based on Borcard et al. 2011 Numerical
> Ecology with R examples.
>
> What I cannot understand is why when I run the script (RDA.R) using the
> dataset from book (dataset1.rar) RDA triplot shows species names and when I
> use my dataset (dataset2.rar) species names are not shown.
>
> Data and script can be downloaded at
> https://app.box.com/s/oayq7tglbmdsu72fj05h83dlzclsiglg
>
> Does anyone know why this happens? Thanks for any clue.
>
> Best regards
>
> Ant?nio Olinto ?vila da Silva
> Fisheries Institute
> S?o Paulo, Brasil
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Apr  4 16:59:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 4 Apr 2015 06:59:30 -0800
Subject: [R] command help
In-Reply-To: <CAO9gewWej-pEN1kZ+8+fpoDA2mtayFywzprntEG7A_d9MNQvHw@mail.gmail.com>
Message-ID: <CBC08AC01F2.00000CDCjrkrideau@inbox.com>

Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ali.alrubaiee1984 at gmail.com
> Sent: Fri, 3 Apr 2015 14:16:11 -0400
> To: r-help at r-project.org
> Subject: [R] command help
> 
> Dear colleagues,
> I wanted to run a command to do iteration for the following equation:
> Pj+1=TT11+FtransposeTT22F-FtransposeTT21-TT12
> F+y[(Atranspose-FtransposeBtranspose)P(A-BF)]
> 
> where TT11, TT22,TT12, TT21, F transpose, A, B and F are matrices and y
> is
> a scalar
> we want to find the iteration for P using loop. Can you send me the right
> command for the loop for the above equation?
> 
> 
> Thank you in advance,
> Ali
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Sat Apr  4 17:11:08 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 4 Apr 2015 07:11:08 -0800
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
In-Reply-To: <551F012D.3020304@ischool.utexas.edu>
Message-ID: <CBDA85CC73A.00000CF5jrkrideau@inbox.com>

Try installing from somewhere outside of RStudio or reboot and retry in RStudio.  I find that if RStudio is open for a long time I occasionally get some weird (buggy?) results but I cannot reproduce to send in an bug report.

Load R  and from the command line or Windows RGui try installing.  As a test I just installed it successully with the command "install.packages("caret")" executed in R (using gedit with its 
R-plug-in) and running Ubuntu 14.04


For future reference:
Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example





John Kane
Kingston ON Canada


> -----Original Message-----
> From: wyllys at ischool.utexas.edu
> Sent: Fri, 03 Apr 2015 16:07:57 -0500
> To: r-help at r-project.org
> Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
> 
> For an edx course, MIT's "The Analtics Edge", I need to install the
> "caret" package that was originated and is maintained by Dr. Max Kuhn of
> Pfizer. So far, every effort I've made to try to
> install.packages("caret") has failed.  (I'm using R v. 3.1.3 and RStudio
> v. 0.98.1103 in LinuxMint 17.1)
> 
> Here are some of the things I've tried unsuccessfully:
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"))
> install.packages("caret", dependencies=TRUE)
> install.packages("caret", repos=c("http://rstudio.org/_packages",
> "http://cran.rstudio.com"), dependencies=TRUE)
> install.packages("caret", dependencies = c("Depends", "Suggests"))
> install.packages("caret", repos="http://cran.rstudio.com/")
> 
> I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas,
> and tried the above installs again, unsuccessfully.
> 
> I've succeeded in individually installing a number of packages on which
> "caret" appears to be dependent.  Specifically, I've been able to
> install  "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and
> "scales".  But I've had no success with trying to do individual installs
> of "BradleyTerry2", "car", "lme4", "quantreg", and "RcppEigen".
> 
> Any suggestions will be very gratefully received (and tried out quickly).
> 
> Thanks in advance.
> 
> Ron Wyllys
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From glennmschultz at me.com  Sat Apr  4 17:48:28 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 04 Apr 2015 15:48:28 +0000 (GMT)
Subject: [R] Building Package Help Files
Message-ID: <9a5fe818-735f-43f1-9629-8750d68471a3@me.com>

Hello All,

I am working on the documentation for my R package and I have a question regarding the help files. ?I have noticed in some packages the developer created an alphabetical list with hyper links. ?My package is for the analysis of mortgage backed securities. ? So I would like to organize the help files under titles as follows:


Passthrough Analysis
-

REMIC Analysis and Structuring
-

Prepayment Model
-

Is a scheme like this possible? ?If so, how would I go about accomplishing this?

Best Regards,
Glenn

From mxkuhn at gmail.com  Sat Apr  4 19:56:34 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sat, 4 Apr 2015 13:56:34 -0400
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
In-Reply-To: <CBDA85CC73A.00000CF5jrkrideau@inbox.com>
References: <551F012D.3020304@ischool.utexas.edu>
	<CBDA85CC73A.00000CF5jrkrideau@inbox.com>
Message-ID: <CAJ9CoWkAWBNFOKss4Fj9mRd6Wk_WWL+O1-4r2P5-RJBiNC46+w@mail.gmail.com>

I thought that this might be relevant:

https://stackoverflow.com/questions/28985759/cant-install-the-caret-package-in-r-in-my-linux-machine

but it seems that you installed nloptr.

I would also suggest doing the install in base R and trying a different
mirror. I would avoid installing via RStudio unless you have just started a
new R session.



On Sat, Apr 4, 2015 at 11:11 AM, John Kane <jrkrideau at inbox.com> wrote:

> Try installing from somewhere outside of RStudio or reboot and retry in
> RStudio.  I find that if RStudio is open for a long time I occasionally get
> some weird (buggy?) results but I cannot reproduce to send in an bug report.
>
> Load R  and from the command line or Windows RGui try installing.  As a
> test I just installed it successully with the command
> "install.packages("caret")" executed in R (using gedit with its
> R-plug-in) and running Ubuntu 14.04
>
>
> For future reference:
> Reproducibility
> https://github.com/hadley/devtools/wiki/Reproducibility
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: wyllys at ischool.utexas.edu
> > Sent: Fri, 03 Apr 2015 16:07:57 -0500
> > To: r-help at r-project.org
> > Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
> >
> > For an edx course, MIT's "The Analtics Edge", I need to install the
> > "caret" package that was originated and is maintained by Dr. Max Kuhn of
> > Pfizer. So far, every effort I've made to try to
> > install.packages("caret") has failed.  (I'm using R v. 3.1.3 and RStudio
> > v. 0.98.1103 in LinuxMint 17.1)
> >
> > Here are some of the things I've tried unsuccessfully:
> > install.packages("caret", repos=c("http://rstudio.org/_packages",
> > "http://cran.rstudio.com"))
> > install.packages("caret", dependencies=TRUE)
> > install.packages("caret", repos=c("http://rstudio.org/_packages",
> > "http://cran.rstudio.com"), dependencies=TRUE)
> > install.packages("caret", dependencies = c("Depends", "Suggests"))
> > install.packages("caret", repos="http://cran.rstudio.com/")
> >
> > I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas,
> > and tried the above installs again, unsuccessfully.
> >
> > I've succeeded in individually installing a number of packages on which
> > "caret" appears to be dependent.  Specifically, I've been able to
> > install  "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and
> > "scales".  But I've had no success with trying to do individual installs
> > of "BradleyTerry2", "car", "lme4", "quantreg", and "RcppEigen".
> >
> > Any suggestions will be very gratefully received (and tried out quickly).
> >
> > Thanks in advance.
> >
> > Ron Wyllys
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wyllys at ischool.utexas.edu  Sat Apr  4 20:00:56 2015
From: wyllys at ischool.utexas.edu (Ronald Wyllys)
Date: Sat, 04 Apr 2015 13:00:56 -0500
Subject: [R] SOLVED: Repeated failures to install "caret" package (of Max
	Kuhn)
Message-ID: <552026D8.20301@ischool.utexas.edu>

These are notes on what I did to be able to install package "caret".

0.    The initial action was to re-install R v. 3.1.3 from this source 
file: r-base-core_3.1.3-1trusty_amd64.deb (available on CRAN Mirrors). 
This is the source file for Ubuntu 14.04, known as "trusty", upon which 
LinuxMint 17.1 is based.  (LinuxMint 17.1 is the operating system that I 
use in my desktop and laptop.)

1.    got llapack and lbas
      (This starting point was suggested in a stackoverflow query: 
"cannot find -llapack", as answered by janneb.  I got to stackoverflow 
after Uwe Liggis raised [in his response to my post on the 
R-helper at r-project.org mailing list] the question of whether my R 
installation was complete.  I am also grateful for Sarah Goslee's and 
John Kane's thought-provoking comments in their responses to my post.)
     This step required my using the Synaptic Package Manager to install
     liblapack-dev
     liblapack3
     libopenblas-base
     libopenblas-dev
     These four packages together supplied llapack and lbas

2.    used the SPM to install
     r-cran-rcppeigen
     r-cran-lme4

Note:  Steps 1 and 2 together enabled me to use install.packages to 
install BradleyTerry2.

3.    used SPM to install
     r-cran-car

4.    used R's install.packages to install quantreg, nloptr

5.    found via the SPM that minqa was already installed as r-cran-minqa

6.    used SPM to install
     r-cran-scales
     r-cran-reshape2

7.     found via the SPM that stringr was already installed as 
r-cran-stringr

8.    Succeeded in using install.packages to install caret

I wish to express my sincere gratitude to the people named above who 
responded to my initial post concerning my failures to install "caret".

This experience has taught me some useful things about working with R in 
Linux: in particular, I learned that one needs to work patiently and 
perseveringly through the process of figuring out what dependencies are 
impeding the desired installation and how these dependencies can be 
found and installed in R or in Linux.

Ronald Wyllys


From ligges at statistik.tu-dortmund.de  Sun Apr  5 00:17:46 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 05 Apr 2015 00:17:46 +0200
Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
In-Reply-To: <CAJ9CoWkAWBNFOKss4Fj9mRd6Wk_WWL+O1-4r2P5-RJBiNC46+w@mail.gmail.com>
References: <551F012D.3020304@ischool.utexas.edu>	<CBDA85CC73A.00000CF5jrkrideau@inbox.com>
	<CAJ9CoWkAWBNFOKss4Fj9mRd6Wk_WWL+O1-4r2P5-RJBiNC46+w@mail.gmail.com>
Message-ID: <5520630A.6090408@statistik.tu-dortmund.de>



On 04.04.2015 19:56, Max Kuhn wrote:
> I thought that this might be relevant:
>
> https://stackoverflow.com/questions/28985759/cant-install-the-caret-package-in-r-in-my-linux-machine
>
> but it seems that you installed nloptr.
>
> I would also suggest doing the install in base R and trying a different
> mirror. I would avoid installing via RStudio unless you have just started a
> new R session.

Private communication showed that the OP did not have liblapack nor 
libblas in the standard locations.

Best,
Uwe Ligges


>
>
> On Sat, Apr 4, 2015 at 11:11 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>> Try installing from somewhere outside of RStudio or reboot and retry in
>> RStudio.  I find that if RStudio is open for a long time I occasionally get
>> some weird (buggy?) results but I cannot reproduce to send in an bug report.
>>
>> Load R  and from the command line or Windows RGui try installing.  As a
>> test I just installed it successully with the command
>> "install.packages("caret")" executed in R (using gedit with its
>> R-plug-in) and running Ubuntu 14.04
>>
>>
>> For future reference:
>> Reproducibility
>> https://github.com/hadley/devtools/wiki/Reproducibility
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>>
>>
>>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: wyllys at ischool.utexas.edu
>>> Sent: Fri, 03 Apr 2015 16:07:57 -0500
>>> To: r-help at r-project.org
>>> Subject: [R] Repeated failures to install "caret" package (of Max Kuhn)
>>>
>>> For an edx course, MIT's "The Analtics Edge", I need to install the
>>> "caret" package that was originated and is maintained by Dr. Max Kuhn of
>>> Pfizer. So far, every effort I've made to try to
>>> install.packages("caret") has failed.  (I'm using R v. 3.1.3 and RStudio
>>> v. 0.98.1103 in LinuxMint 17.1)
>>>
>>> Here are some of the things I've tried unsuccessfully:
>>> install.packages("caret", repos=c("http://rstudio.org/_packages",
>>> "http://cran.rstudio.com"))
>>> install.packages("caret", dependencies=TRUE)
>>> install.packages("caret", repos=c("http://rstudio.org/_packages",
>>> "http://cran.rstudio.com"), dependencies=TRUE)
>>> install.packages("caret", dependencies = c("Depends", "Suggests"))
>>> install.packages("caret", repos="http://cran.rstudio.com/")
>>>
>>> I've changed my CRAN mirror from UCLA to Revolution Analytics in Dallas,
>>> and tried the above installs again, unsuccessfully.
>>>
>>> I've succeeded in individually installing a number of packages on which
>>> "caret" appears to be dependent.  Specifically, I've been able to
>>> install  "nloptr", "minqa", "Rcpp", "reshape2", "stringr", and
>>> "scales".  But I've had no success with trying to do individual installs
>>> of "BradleyTerry2", "car", "lme4", "quantreg", and "RcppEigen".
>>>
>>> Any suggestions will be very gratefully received (and tried out quickly).
>>>
>>> Thanks in advance.
>>>
>>> Ron Wyllys
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Sun Apr  5 03:22:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 5 Apr 2015 11:22:16 +1000
Subject: [R] species names on a RDA plot
In-Reply-To: <CAE8g1gPjfGvF42b5j38uE_AWU270NGBFyEV7iPpAd_NGawmVVQ@mail.gmail.com>
References: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>
	<CAE8g1gPjfGvF42b5j38uE_AWU270NGBFyEV7iPpAd_NGawmVVQ@mail.gmail.com>
Message-ID: <CA+8X3fUCzdfBZk_-1i5n8GP-YX372hbGG1z5_4bFJ-TK_o98cw@mail.gmail.com>

Hi Antonio,
Is it possible to use "add=TRUE" and display the plot in two passes?

Jim


On Sat, Apr 4, 2015 at 11:44 PM, Antonio Silva <aolinto.lst at gmail.com>
wrote:

> Hello everybody
>
> The problem is that species names are shown in the ordination diagram when
> the data set has a maximum of 80 rows, and mine has 81 (!!!).
>
> So now the question is: it is possible to go through this limitation?
>
> Thanks again,
>
> Ant?nio Olinto
>
>
> 2015-04-03 20:08 GMT-03:00 Antonio Silva <aolinto.lst at gmail.com>:
>
> > Dear R users
> >
> > I'm trying to do a RDA analysis based on Borcard et al. 2011 Numerical
> > Ecology with R examples.
> >
> > What I cannot understand is why when I run the script (RDA.R) using the
> > dataset from book (dataset1.rar) RDA triplot shows species names and
> when I
> > use my dataset (dataset2.rar) species names are not shown.
> >
> > Data and script can be downloaded at
> > https://app.box.com/s/oayq7tglbmdsu72fj05h83dlzclsiglg
> >
> > Does anyone know why this happens? Thanks for any clue.
> >
> > Best regards
> >
> > Ant?nio Olinto ?vila da Silva
> > Fisheries Institute
> > S?o Paulo, Brasil
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From gian.benucci at gmail.com  Sun Apr  5 09:24:28 2015
From: gian.benucci at gmail.com (=?UTF-8?Q?Gian_Maria_Niccol=C3=B2_Benucci?=)
Date: Sun, 5 Apr 2015 09:24:28 +0200
Subject: [R] error MANOVA in R
In-Reply-To: <89803908-11D5-4311-974B-4DBE7B482D71@gmail.com>
References: <CAPxEaESWK9qKUO68DF1Z9SuUkWdsKrb5ZSHf7dF_hD2VGPe9fg@mail.gmail.com>
	<89803908-11D5-4311-974B-4DBE7B482D71@gmail.com>
Message-ID: <CAPxEaETxYr=yfi=DgkYXBsnz8KvzQ6R_o7gPHZC4ojmMuK_LpQ@mail.gmail.com>

Hi Peter,
Thank you so much for your tips. Have a nice Easter.
Gian

Il gioved? 2 aprile 2015, peter dalgaard <pdalgd at gmail.com> ha scritto:

>
> > On 30 Mar 2015, at 17:11 , Gian Maria Niccol? Benucci <
> gian.benucci at gmail.com <javascript:;>> wrote:
> >
> > Dear R-usrs,
> >
> > I am trying to perform a MANOVA on a data frame with 31 columns about
> soil
> > parameters and 1 column containing the explanatory variable (Fraction)
> that
> > have three levels.
> > my code is the following:
> >
> > datam <- read.table("data_manova2.csv", header=T, sep=",")
> > names(datam)
> >
> > manova_fraction2 <- manova(cbind(pH, AWC, WEOC, WEN, C.mic, CO2.C, Ca,
> Mg,
> > K, Na, sol.exch.Fe, easily.reducible.Fe, amourphou.Fe.oxide...Fe.OM,
> > crystalline.Fe.oxides, TN, TOC, NH4.N, NO3.N, N.org, organic.P,
> avaiable.P,
> > Total.PLFA, Tot.Bat, Gram., Gram..1, Funghi, AMF, protozoa, actinomiceti,
> > non.specifici) ~ as.factor(Fraction), data= datam)
> >
> > summary(manova_fraction2)
> >
> > when I did the summary I got this error
> >
> >> summary(manova_fraction2)
> > Error in summary.manova(manova_fraction2) : residuals have rank 18 < 30
> >
> > ?Is this error possibly due to high correlation between my variables?
> >
>
> Nope. Too few observations. For classical MANOVA, you need  > p degrees of
> freedom to determine the covariance matrix with full rank. As far as I can
> tell, you have only 21 observations (21-3=18 degrees of freedom) for your
> p=30 response variables.
>
> > Many thanks in advance,
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk <javascript:;>  Priv: PDalgd at gmail.com <javascript:;>
>
>
>
>
>
>
>
>
>

-- 
Gian Maria Niccol? Benucci, PhD
University of Perugia
Dept. of Agricultural, Food and Environmental Sciences
Borgo XX Giugno, 74
06121 - Perugia, ITALY
Tel: +390755856417
Email: gian.benucci at gmail.com


*----- Do not print this email unless you really need to. Save paper and
protect the environment! -----*

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sun Apr  5 11:34:30 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 5 Apr 2015 11:34:30 +0200
Subject: [R] Aggregating daily rainfall raster data to bimontly data
Message-ID: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>

Dear community,

I have daily rainfall raster data for 30 years (1982_2011). I would like to
aggregate daily to bimonthly raster data. Could somebody kindly help on how
to go about it!

Thanks for your help

-- 
John

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Sun Apr  5 15:03:20 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sun, 5 Apr 2015 09:03:20 -0400
Subject: [R] ggplot: connect points with line (not in order)
Message-ID: <CAEQKoCE2KOGty+JEtNYJ7H9O6meUA0s_07kQnLJcf7gv13rTJA@mail.gmail.com>

Hi,

I am trying to connect points, but not in a different order than the
default value in ggplot. For example:

 xx <- sample(1:100,5)
  yy <- sample(1:100,5)

  mydat <- data.frame(xx,yy)
  print(mydat)

  ggplot(mydat,aes(xx,yy)) + geom_point() + geom_line()


I want to connect the points as they appear in mydat, and not necessarily
from the smallest value on the 'x' axis to the largest.

How can I do this?

thanks!

	[[alternative HTML version deleted]]


From wickedpuppy at gmail.com  Sun Apr  5 15:15:37 2015
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 5 Apr 2015 21:15:37 +0800
Subject: [R] ggplot: connect points with line (not in order)
In-Reply-To: <CAEQKoCE2KOGty+JEtNYJ7H9O6meUA0s_07kQnLJcf7gv13rTJA@mail.gmail.com>
References: <CAEQKoCE2KOGty+JEtNYJ7H9O6meUA0s_07kQnLJcf7gv13rTJA@mail.gmail.com>
Message-ID: <CAJ_FNV7O54KP7EirOX0ireQEfBZkq=WZWvgKGcdaRUmvnKCn-w@mail.gmail.com>

Will this do?

ggplot(mydat,aes(xx,yy)) + geom_path()

>From : http://stackoverflow.com/questions/15706281/controlling-order-of-points-in-ggplot2-in-r


----------------------------------------------------------------------------------
|

http://billyam.com  || http://use-r.com  || http://shinyserver.com (BETA)

SAS Certified Base Programmer for SAS 9
Oracle SQL Expert(11g)



On Sun, Apr 5, 2015 at 9:03 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
> Hi,
>
> I am trying to connect points, but not in a different order than the
> default value in ggplot. For example:
>
>  xx <- sample(1:100,5)
>   yy <- sample(1:100,5)
>
>   mydat <- data.frame(xx,yy)
>   print(mydat)
>
>   ggplot(mydat,aes(xx,yy)) + geom_point() + geom_line()
>
>
> I want to connect the points as they appear in mydat, and not necessarily
> from the smallest value on the 'x' axis to the largest.
>
> How can I do this?
>
> thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Sun Apr  5 17:04:06 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sun, 5 Apr 2015 11:04:06 -0400
Subject: [R] ggplot: connect points with line (not in order)
In-Reply-To: <CAJ_FNV7O54KP7EirOX0ireQEfBZkq=WZWvgKGcdaRUmvnKCn-w@mail.gmail.com>
References: <CAEQKoCE2KOGty+JEtNYJ7H9O6meUA0s_07kQnLJcf7gv13rTJA@mail.gmail.com>
	<CAJ_FNV7O54KP7EirOX0ireQEfBZkq=WZWvgKGcdaRUmvnKCn-w@mail.gmail.com>
Message-ID: <CAEQKoCEptfMXRRD=K+BWccgYfQgwfbBoXrGqxFd=kKA-fO8y-w@mail.gmail.com>

thanks!

On Sun, Apr 5, 2015 at 9:15 AM, billy am <wickedpuppy at gmail.com> wrote:

> Will this do?
>
> ggplot(mydat,aes(xx,yy)) + geom_path()
>
> From :
> http://stackoverflow.com/questions/15706281/controlling-order-of-points-in-ggplot2-in-r
>
>
>
> ----------------------------------------------------------------------------------
> |
>
> http://billyam.com  || http://use-r.com  || http://shinyserver.com (BETA)
>
> SAS Certified Base Programmer for SAS 9
> Oracle SQL Expert(11g)
>
>
>
> On Sun, Apr 5, 2015 at 9:03 PM, Brian Smith <bsmith030465 at gmail.com>
> wrote:
> > Hi,
> >
> > I am trying to connect points, but not in a different order than the
> > default value in ggplot. For example:
> >
> >  xx <- sample(1:100,5)
> >   yy <- sample(1:100,5)
> >
> >   mydat <- data.frame(xx,yy)
> >   print(mydat)
> >
> >   ggplot(mydat,aes(xx,yy)) + geom_point() + geom_line()
> >
> >
> > I want to connect the points as they appear in mydat, and not necessarily
> > from the smallest value on the 'x' axis to the largest.
> >
> > How can I do this?
> >
> > thanks!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun Apr  5 18:13:01 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 5 Apr 2015 08:13:01 -0800
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
Message-ID: <D8F78324C00.00000856jrkrideau@inbox.com>

Someone might if they had any idea of what the data actually looked like and what you are trying to do. The 'bimonthly' for example, is ambiguous in English; do you mean every two months or twice a month?

Have a look at https://github.com/hadley/devtools/wiki/Reproducibility and   http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example with special attention to dput() as a method of supplying sample data to the help list.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: johnwasige at gmail.com
> Sent: Sun, 5 Apr 2015 11:34:30 +0200
> To: r-help at r-project.org
> Subject: [R] Aggregating daily rainfall raster data to bimontly data
> 
> Dear community,
> 
> I have daily rainfall raster data for 30 years (1982_2011). I would like
> to
> aggregate daily to bimonthly raster data. Could somebody kindly help on
> how
> to go about it!
> 
> Thanks for your help
> 
> --
> John
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From gunter.berton at gene.com  Sun Apr  5 18:39:54 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 5 Apr 2015 09:39:54 -0700
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <D8F78324C00.00000856jrkrideau@inbox.com>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
Message-ID: <CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>

See ?tapply

However, as John said, without knowing the structure of your data, it
is impossible to provide a guaranteed recipe. For example, does the
data structure contain date information? -- it would be difficult (but
not impossible depending on data structure) to aggregate by calendar
(bi-monthly, depending on your meaning of "bi") without knowing the
months. Aggregating by every n days would be easy, but that's probably
not what you want.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com> wrote:
> Someone might if they had any idea of what the data actually looked like and what you are trying to do. The 'bimonthly' for example, is ambiguous in English; do you mean every two months or twice a month?
>
> Have a look at https://github.com/hadley/devtools/wiki/Reproducibility and   http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example with special attention to dput() as a method of supplying sample data to the help list.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: johnwasige at gmail.com
>> Sent: Sun, 5 Apr 2015 11:34:30 +0200
>> To: r-help at r-project.org
>> Subject: [R] Aggregating daily rainfall raster data to bimontly data
>>
>> Dear community,
>>
>> I have daily rainfall raster data for 30 years (1982_2011). I would like
>> to
>> aggregate daily to bimonthly raster data. Could somebody kindly help on
>> how
>> to go about it!
>>
>> Thanks for your help
>>
>> --
>> John
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johnwasige at gmail.com  Sun Apr  5 18:45:00 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 5 Apr 2015 18:45:00 +0200
Subject: [R] Aggregating daily rainfall raster data to bimontly ( twice a
	month) data
Message-ID: <CAJgdCD5t+pgeuefW_MiB4KUPww+ijbhT7QDpS51XeJaCCyQtsQ@mail.gmail.com>

Dear community,

I have daily rainfall raster data for 30 years (1982_2011). I would like to
aggregate daily to bimonthly (twice a month) raster data. Could somebody
kindly help on how to go about it!

Thanks for your help

JOHN


Thanks Kane, bimonthly here means twice a month.

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sun Apr  5 18:52:18 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 5 Apr 2015 18:52:18 +0200
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
Message-ID: <CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>

Thanks Bert,

The structure of the data is a raster stack with nraw=867, Ncol=995

Rgds John


On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com> wrote:

> See ?tapply
>
> However, as John said, without knowing the structure of your data, it
> is impossible to provide a guaranteed recipe. For example, does the
> data structure contain date information? -- it would be difficult (but
> not impossible depending on data structure) to aggregate by calendar
> (bi-monthly, depending on your meaning of "bi") without knowing the
> months. Aggregating by every n days would be easy, but that's probably
> not what you want.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com> wrote:
> > Someone might if they had any idea of what the data actually looked like
> and what you are trying to do. The 'bimonthly' for example, is ambiguous in
> English; do you mean every two months or twice a month?
> >
> > Have a look at https://github.com/hadley/devtools/wiki/Reproducibility
> and
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> with special attention to dput() as a method of supplying sample data to
> the help list.
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: johnwasige at gmail.com
> >> Sent: Sun, 5 Apr 2015 11:34:30 +0200
> >> To: r-help at r-project.org
> >> Subject: [R] Aggregating daily rainfall raster data to bimontly data
> >>
> >> Dear community,
> >>
> >> I have daily rainfall raster data for 30 years (1982_2011). I would like
> >> to
> >> aggregate daily to bimonthly raster data. Could somebody kindly help on
> >> how
> >> to go about it!
> >>
> >> Thanks for your help
> >>
> >> --
> >> John
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ____________________________________________________________
> > FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> and family!
> > Visit http://www.inbox.com/photosharing to find out more!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Apr  5 19:08:05 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 05 Apr 2015 10:08:05 -0700
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
	<CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
Message-ID: <78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>

Please stop posting using HTML (as the Posting Guide warns you), and follow John Kane's advice. Your reply below is not helping us understand as well as you seem to think it should.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 5, 2015 9:52:18 AM PDT, John Wasige <johnwasige at gmail.com> wrote:
>Thanks Bert,
>
>The structure of the data is a raster stack with nraw=867, Ncol=995
>
>Rgds John
>
>
>On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com>
>wrote:
>
>> See ?tapply
>>
>> However, as John said, without knowing the structure of your data, it
>> is impossible to provide a guaranteed recipe. For example, does the
>> data structure contain date information? -- it would be difficult
>(but
>> not impossible depending on data structure) to aggregate by calendar
>> (bi-monthly, depending on your meaning of "bi") without knowing the
>> months. Aggregating by every n days would be easy, but that's
>probably
>> not what you want.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com>
>wrote:
>> > Someone might if they had any idea of what the data actually looked
>like
>> and what you are trying to do. The 'bimonthly' for example, is
>ambiguous in
>> English; do you mean every two months or twice a month?
>> >
>> > Have a look at
>https://github.com/hadley/devtools/wiki/Reproducibility
>> and
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> with special attention to dput() as a method of supplying sample data
>to
>> the help list.
>> >
>> > John Kane
>> > Kingston ON Canada
>> >
>> >
>> >> -----Original Message-----
>> >> From: johnwasige at gmail.com
>> >> Sent: Sun, 5 Apr 2015 11:34:30 +0200
>> >> To: r-help at r-project.org
>> >> Subject: [R] Aggregating daily rainfall raster data to bimontly
>data
>> >>
>> >> Dear community,
>> >>
>> >> I have daily rainfall raster data for 30 years (1982_2011). I
>would like
>> >> to
>> >> aggregate daily to bimonthly raster data. Could somebody kindly
>help on
>> >> how
>> >> to go about it!
>> >>
>> >> Thanks for your help
>> >>
>> >> --
>> >> John
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ____________________________________________________________
>> > FREE ONLINE PHOTOSHARING - Share your photos online with your
>friends
>> and family!
>> > Visit http://www.inbox.com/photosharing to find out more!
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wibbeltjec at hotmail.com  Sat Apr  4 22:27:23 2015
From: wibbeltjec at hotmail.com (Carlijn Wibbelink)
Date: Sat, 4 Apr 2015 22:27:23 +0200
Subject: [R] Trim and fill procedure
Message-ID: <DUB122-W32E7B4112E469625EC90C1C0F00@phx.gbl>

Hi all,

I have a question concerning the trim and fill procedure in metafor. In STATA it is possible to obtain the values of the added estimated effect sizes. I was wondering if this is also possible in R and if so, how I can obtain the new data with the added values. 
I would really appreciate your response. 


 		 	   		  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Apr  5 23:25:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Apr 2015 07:25:43 +1000
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
	<CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
	<78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>
Message-ID: <CA+8X3fXkdbJa-spGRUQcqWfkmECWb7TC6w63TU3bshHwHPV_qA@mail.gmail.com>

Hi John,
One way is to create an index variable that will divide your data into the
appropriate intervals. There are a number of ways to do this. Say you want
the "two month" version of bimonthly and you have a date variable
("raindate") for each observation like "1982-01-01".

date_order<-paste(rep(month.abb,30),rep(1982:2011,each=12),sep="")
month_index<-factor(format(as.Date(raindate,"%Y-%m-%d"),"%b%Y"),levels=date_order)

You can then subset the raster matrices by "month_index" and average them
for each group

Jim

On Mon, Apr 6, 2015 at 3:08 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please stop posting using HTML (as the Posting Guide warns you), and
> follow John Kane's advice. Your reply below is not helping us understand as
> well as you seem to think it should.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 5, 2015 9:52:18 AM PDT, John Wasige <johnwasige at gmail.com> wrote:
> >Thanks Bert,
> >
> >The structure of the data is a raster stack with nraw=867, Ncol=995
> >
> >Rgds John
> >
> >
> >On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com>
> >wrote:
> >
> >> See ?tapply
> >>
> >> However, as John said, without knowing the structure of your data, it
> >> is impossible to provide a guaranteed recipe. For example, does the
> >> data structure contain date information? -- it would be difficult
> >(but
> >> not impossible depending on data structure) to aggregate by calendar
> >> (bi-monthly, depending on your meaning of "bi") without knowing the
> >> months. Aggregating by every n days would be easy, but that's
> >probably
> >> not what you want.
> >>
> >> Cheers,
> >> Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com>
> >wrote:
> >> > Someone might if they had any idea of what the data actually looked
> >like
> >> and what you are trying to do. The 'bimonthly' for example, is
> >ambiguous in
> >> English; do you mean every two months or twice a month?
> >> >
> >> > Have a look at
> >https://github.com/hadley/devtools/wiki/Reproducibility
> >> and
> >>
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> with special attention to dput() as a method of supplying sample data
> >to
> >> the help list.
> >> >
> >> > John Kane
> >> > Kingston ON Canada
> >> >
> >> >
> >> >> -----Original Message-----
> >> >> From: johnwasige at gmail.com
> >> >> Sent: Sun, 5 Apr 2015 11:34:30 +0200
> >> >> To: r-help at r-project.org
> >> >> Subject: [R] Aggregating daily rainfall raster data to bimontly
> >data
> >> >>
> >> >> Dear community,
> >> >>
> >> >> I have daily rainfall raster data for 30 years (1982_2011). I
> >would like
> >> >> to
> >> >> aggregate daily to bimonthly raster data. Could somebody kindly
> >help on
> >> >> how
> >> >> to go about it!
> >> >>
> >> >> Thanks for your help
> >> >>
> >> >> --
> >> >> John
> >> >>
> >> >>       [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ____________________________________________________________
> >> > FREE ONLINE PHOTOSHARING - Share your photos online with your
> >friends
> >> and family!
> >> > Visit http://www.inbox.com/photosharing to find out more!
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sun Apr  5 23:40:58 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 5 Apr 2015 23:40:58 +0200
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CA+8X3fXkdbJa-spGRUQcqWfkmECWb7TC6w63TU3bshHwHPV_qA@mail.gmail.com>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
	<CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
	<78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>
	<CA+8X3fXkdbJa-spGRUQcqWfkmECWb7TC6w63TU3bshHwHPV_qA@mail.gmail.com>
Message-ID: <CAJgdCD5Sby-nZdieL8M8aB-9VMSmm08jg8FgRrhyKk2ZMGPcBA@mail.gmail.com>

Thanks Jim!

Do you have an idea on how I can go about getting bi-monthly (twice a
month) results for the month with 28, 29, 30 and 31 daily observations?

Thanks for your help

John.

On Sun, Apr 5, 2015 at 11:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi John,
> One way is to create an index variable that will divide your data into the
> appropriate intervals. There are a number of ways to do this. Say you want
> the "two month" version of bimonthly and you have a date variable
> ("raindate") for each observation like "1982-01-01".
>
> date_order<-paste(rep(month.abb,30),rep(1982:2011,each=12),sep="")
>
> month_index<-factor(format(as.Date(raindate,"%Y-%m-%d"),"%b%Y"),levels=date_order)
>
> You can then subset the raster matrices by "month_index" and average them
> for each group
>
> Jim
>
> On Mon, Apr 6, 2015 at 3:08 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> Please stop posting using HTML (as the Posting Guide warns you), and
>> follow John Kane's advice. Your reply below is not helping us understand as
>> well as you seem to think it should.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 5, 2015 9:52:18 AM PDT, John Wasige <johnwasige at gmail.com>
>> wrote:
>> >Thanks Bert,
>> >
>> >The structure of the data is a raster stack with nraw=867, Ncol=995
>> >
>> >Rgds John
>> >
>> >
>> >On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com>
>> >wrote:
>> >
>> >> See ?tapply
>> >>
>> >> However, as John said, without knowing the structure of your data, it
>> >> is impossible to provide a guaranteed recipe. For example, does the
>> >> data structure contain date information? -- it would be difficult
>> >(but
>> >> not impossible depending on data structure) to aggregate by calendar
>> >> (bi-monthly, depending on your meaning of "bi") without knowing the
>> >> months. Aggregating by every n days would be easy, but that's
>> >probably
>> >> not what you want.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >> Bert Gunter
>> >> Genentech Nonclinical Biostatistics
>> >> (650) 467-7374
>> >>
>> >> "Data is not information. Information is not knowledge. And knowledge
>> >> is certainly not wisdom."
>> >> Clifford Stoll
>> >>
>> >>
>> >>
>> >>
>> >> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com>
>> >wrote:
>> >> > Someone might if they had any idea of what the data actually looked
>> >like
>> >> and what you are trying to do. The 'bimonthly' for example, is
>> >ambiguous in
>> >> English; do you mean every two months or twice a month?
>> >> >
>> >> > Have a look at
>> >https://github.com/hadley/devtools/wiki/Reproducibility
>> >> and
>> >>
>> >
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >> with special attention to dput() as a method of supplying sample data
>> >to
>> >> the help list.
>> >> >
>> >> > John Kane
>> >> > Kingston ON Canada
>> >> >
>> >> >
>> >> >> -----Original Message-----
>> >> >> From: johnwasige at gmail.com
>> >> >> Sent: Sun, 5 Apr 2015 11:34:30 +0200
>> >> >> To: r-help at r-project.org
>> >> >> Subject: [R] Aggregating daily rainfall raster data to bimontly
>> >data
>> >> >>
>> >> >> Dear community,
>> >> >>
>> >> >> I have daily rainfall raster data for 30 years (1982_2011). I
>> >would like
>> >> >> to
>> >> >> aggregate daily to bimonthly raster data. Could somebody kindly
>> >help on
>> >> >> how
>> >> >> to go about it!
>> >> >>
>> >> >> Thanks for your help
>> >> >>
>> >> >> --
>> >> >> John
>> >> >>
>> >> >>       [[alternative HTML version deleted]]
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> > ____________________________________________________________
>> >> > FREE ONLINE PHOTOSHARING - Share your photos online with your
>> >friends
>> >> and family!
>> >> > Visit http://www.inbox.com/photosharing to find out more!
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Sun Apr  5 23:43:37 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Sun, 5 Apr 2015 17:43:37 -0400
Subject: [R] open xlsx file using read.xls function of gdata 	package
Message-ID: <49F0F9C9-80F8-4D88-AD1A-695565805577@gmail.com>

Will it work with .xlsm files?

Best,
KW

> You might try the readxl package - it's only available on github but it
> reads both xlsx and xls. All going well, it should be on its way to CRAN
> next week.
> 
> Hadley
> 
> On Friday, April 3, 2015, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
>> Dear all,
>> I am trying to open excel files using the gdata package. I can do that
>> using a .xls file, but the same file, containing the same data,
>> formatted in .xlsx gives error (R does not recognize the pattern from
>> where to start reading the data).
>> Doen anybody knows whether it is possible to read .xlslx with this package?
>> Am I missing another package to implement the reading of the .xlsx?
>> Thank you
>> Luigi
>> 
>> PS: this is the error I get:
>>> my.file <- "array.xlsx"
>>> my.data<-read.xls(
>> +       my.file,
>> +       sheet="sheet x",
>> +       verbose=FALSE,
>> +       pattern="row name",
>> +       na.strings=c("NA","#DIV/0!"),
>> +       method="tab",
>> +       perl="perl"
>> +     )
>>> Warning message:
>> In read.xls(my.file, sheet = "sheet x", verbose = FALSE,  :
>>  pattern not found
>> 
>> 
>> The verbose version runs like this:
>>    ?array.xlsx?
>> to tab  file
>>    ?/tmp/Rtmp2tAjzz/filef06102dd018.tab?
>> ...
>> 
>> Executing ' '/usr/bin/perl'
>> '/home/gigiux/R/x86_64-pc-linux-gnu-library/3.0/gdata/perl/xls2tab.pl'
>> 'array.xlsx' '/tmp/Rtmp2tAjzz/filef06102dd018.tab' 'sheet x' '...
>> 
>> Loading 'array.xlsx'...
>> Done.
>> 
>> Orignal Filename: array.xlsx
>> Number of Sheets: 2
>> 
>> Writing sheet 'sheet x' to file '/tmp/Rtmp2tAjzz/filef06102dd018.tab'
>> Minrow=31 Maxrow=17310 Mincol=0 Maxcol=4
>>  (Ignored 0 blank lines.)
>> 
>> 0
>> 
>> Done.
>> 
>> Searching for lines tfntaining pattern  row name ...
>> Warning message:
>> In read.xls(my.file, sheet = "sheet x", verbose = TRUE,  :
>>  pattern not found
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
>> more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> http://had.co.nz/
> 
> 	[[alternative HTML version deleted]]
> 
> 


---
KW


From dwinsemius at comcast.net  Mon Apr  6 00:11:05 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 5 Apr 2015 15:11:05 -0700
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CAJgdCD5Sby-nZdieL8M8aB-9VMSmm08jg8FgRrhyKk2ZMGPcBA@mail.gmail.com>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
	<CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
	<78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>
	<CA+8X3fXkdbJa-spGRUQcqWfkmECWb7TC6w63TU3bshHwHPV_qA@mail.gmail.com>
	<CAJgdCD5Sby-nZdieL8M8aB-9VMSmm08jg8FgRrhyKk2ZMGPcBA@mail.gmail.com>
Message-ID: <CC2E7114-406D-49FE-A29D-45BD0BA1DBB3@comcast.net>


On Apr 5, 2015, at 2:40 PM, John Wasige wrote:

> Thanks Jim!
> 
> Do you have an idea on how I can go about getting bi-monthly (twice a
> month) results for the month with 28, 29, 30 and 31 daily observations?
> 
> Thanks for your help

raindate <- seq.Date(as.Date("1982-01-01"), as.Date("1983-01-01"),by=1)

 paste( format( head(raindate,30), "%Y"),
        cut(as.numeric(format( head(raindate,30),"%d")), c(0,16,32) ),
       sep="_")

 [1] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]" 
 [5] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]" 
 [9] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]" 
[13] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]" 
[17] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
[21] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
[25] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
[29] "1982_(16,32]" "1982_(16,32]"

Another method would be to use `cut` on  as.POSIXlt(raindate)$mday

-- 
David.
> 
> John.
> 
> On Sun, Apr 5, 2015 at 11:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi John,
>> One way is to create an index variable that will divide your data into the
>> appropriate intervals. There are a number of ways to do this. Say you want
>> the "two month" version of bimonthly and you have a date variable
>> ("raindate") for each observation like "1982-01-01".
>> 
>> date_order<-paste(rep(month.abb,30),rep(1982:2011,each=12),sep="")
>> 
>> month_index<-factor(format(as.Date(raindate,"%Y-%m-%d"),"%b%Y"),levels=date_order)
>> 
>> You can then subset the raster matrices by "month_index" and average them
>> for each group
>> 
>> Jim
>> 
>> On Mon, Apr 6, 2015 at 3:08 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> Please stop posting using HTML (as the Posting Guide warns you), and
>>> follow John Kane's advice. Your reply below is not helping us understand as
>>> well as you seem to think it should.
>>> 
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> 
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On April 5, 2015 9:52:18 AM PDT, John Wasige <johnwasige at gmail.com>
>>> wrote:
>>>> Thanks Bert,
>>>> 
>>>> The structure of the data is a raster stack with nraw=867, Ncol=995
>>>> 
>>>> Rgds John
>>>> 
>>>> 
>>>> On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com>
>>>> wrote:
>>>> 
>>>>> See ?tapply
>>>>> 
>>>>> However, as John said, without knowing the structure of your data, it
>>>>> is impossible to provide a guaranteed recipe. For example, does the
>>>>> data structure contain date information? -- it would be difficult
>>>> (but
>>>>> not impossible depending on data structure) to aggregate by calendar
>>>>> (bi-monthly, depending on your meaning of "bi") without knowing the
>>>>> months. Aggregating by every n days would be easy, but that's
>>>> probably
>>>>> not what you want.
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> Bert Gunter
>>>>> Genentech Nonclinical Biostatistics
>>>>> (650) 467-7374
>>>>> 
>>>>> "Data is not information. Information is not knowledge. And knowledge
>>>>> is certainly not wisdom."
>>>>> Clifford Stoll
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com>
>>>> wrote:
>>>>>> Someone might if they had any idea of what the data actually looked
>>>> like
>>>>> and what you are trying to do. The 'bimonthly' for example, is
>>>> ambiguous in
>>>>> English; do you mean every two months or twice a month?
>>>>>> 
>>>>>> Have a look at
>>>> https://github.com/hadley/devtools/wiki/Reproducibility
>>>>> and
>>>>> 
>>>> 
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>> with special attention to dput() as a method of supplying sample data
>>>> to
>>>>> the help list.
>>>>>> 
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>> 
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: johnwasige at gmail.com
>>>>>>> Sent: Sun, 5 Apr 2015 11:34:30 +0200
>>>>>>> To: r-help at r-project.org
>>>>>>> Subject: [R] Aggregating daily rainfall raster data to bimontly
>>>> data
>>>>>>> 
>>>>>>> Dear community,
>>>>>>> 
>>>>>>> I have daily rainfall raster data for 30 years (1982_2011). I
>>>> would like
>>>>>>> to
>>>>>>> aggregate daily to bimonthly raster data. Could somebody kindly
>>>> help on
>>>>>>> how
>>>>>>> to go about it!
>>>>>>> 
>>>>>>> Thanks for your help
>>>>>>> 
>>>>>>> --
>>>>>>> John
>>>>>>> 
>>>>>>>      [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ____________________________________________________________
>>>>>> FREE ONLINE PHOTOSHARING - Share your photos online with your
>>>> friends
>>>>> and family!
>>>>>> Visit http://www.inbox.com/photosharing to find out more!
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From aolinto.lst at gmail.com  Mon Apr  6 03:17:08 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sun, 5 Apr 2015 22:17:08 -0300
Subject: [R] species names on a RDA plot
In-Reply-To: <CA+8X3fUCzdfBZk_-1i5n8GP-YX372hbGG1z5_4bFJ-TK_o98cw@mail.gmail.com>
References: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>
	<CAE8g1gPjfGvF42b5j38uE_AWU270NGBFyEV7iPpAd_NGawmVVQ@mail.gmail.com>
	<CA+8X3fUCzdfBZk_-1i5n8GP-YX372hbGG1z5_4bFJ-TK_o98cw@mail.gmail.com>
Message-ID: <CAE8g1gP0Zy+eowrMWdVik4JCEo1umh4yz80bX_Y7QRhHE-RL4w@mail.gmail.com>

Thanks for your attention Jim

Following your idea of adding one more step to construct the diagram, I used

text(spe2.rdaspe, row.names(spe2.rdaspe), pos=3, col="red",cex=0.8)

and I could add species names.

It seems that there's nothing we can do in the plot line.

Have a nice week, best regards

Antonio Olinto


2015-04-04 22:22 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Antonio,
> Is it possible to use "add=TRUE" and display the plot in two passes?
>
> Jim
>
>
> On Sat, Apr 4, 2015 at 11:44 PM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
>
>> Hello everybody
>>
>> The problem is that species names are shown in the ordination diagram when
>> the data set has a maximum of 80 rows, and mine has 81 (!!!).
>>
>> So now the question is: it is possible to go through this limitation?
>>
>> Thanks again,
>>
>> Ant?nio Olinto
>>
>>
>> 2015-04-03 20:08 GMT-03:00 Antonio Silva <aolinto.lst at gmail.com>:
>>
>> > Dear R users
>> >
>> > I'm trying to do a RDA analysis based on Borcard et al. 2011 Numerical
>> > Ecology with R examples.
>> >
>> > What I cannot understand is why when I run the script (RDA.R) using the
>> > dataset from book (dataset1.rar) RDA triplot shows species names and
>> when I
>> > use my dataset (dataset2.rar) species names are not shown.
>> >
>> > Data and script can be downloaded at
>> > https://app.box.com/s/oayq7tglbmdsu72fj05h83dlzclsiglg
>> >
>> > Does anyone know why this happens? Thanks for any clue.
>> >
>> > Best regards
>> >
>> > Ant?nio Olinto ?vila da Silva
>> > Fisheries Institute
>> > S?o Paulo, Brasil
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Mon Apr  6 07:46:12 2015
From: johnwasige at gmail.com (John Wasige)
Date: Mon, 6 Apr 2015 07:46:12 +0200
Subject: [R] Aggregating daily rainfall raster data to bimontly data
In-Reply-To: <CC2E7114-406D-49FE-A29D-45BD0BA1DBB3@comcast.net>
References: <CAJgdCD7KaeLLnCzGHfe_0upXk97aEOE7MMFqAPGqXosuXD2_0Q@mail.gmail.com>
	<D8F78324C00.00000856jrkrideau@inbox.com>
	<CACk-te3VeUken+u0PO0x3OTbLF7M1bM6TQWV=97ObGzz_tcK3w@mail.gmail.com>
	<CAJgdCD7jnwVKZL+AUVWPYh2v77AOARYq2cFZMatT3EVRqabvfA@mail.gmail.com>
	<78C05B51-EBB8-4F73-A1AC-3E0C71E0CAC8@dcn.davis.CA.us>
	<CA+8X3fXkdbJa-spGRUQcqWfkmECWb7TC6w63TU3bshHwHPV_qA@mail.gmail.com>
	<CAJgdCD5Sby-nZdieL8M8aB-9VMSmm08jg8FgRrhyKk2ZMGPcBA@mail.gmail.com>
	<CC2E7114-406D-49FE-A29D-45BD0BA1DBB3@comcast.net>
Message-ID: <CAJgdCD4_OGis2gtBB-cvvTFWhi7zbURKaOaVH07uUzQkZOi4wg@mail.gmail.com>

Many thanks everybody for your kind help.

John?

On Mon, Apr 6, 2015 at 12:11 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Apr 5, 2015, at 2:40 PM, John Wasige wrote:
>
> > Thanks Jim!
> >
> > Do you have an idea on how I can go about getting bi-monthly (twice a
> > month) results for the month with 28, 29, 30 and 31 daily observations?
> >
> > Thanks for your help
>
> raindate <- seq.Date(as.Date("1982-01-01"), as.Date("1983-01-01"),by=1)
>
>  paste( format( head(raindate,30), "%Y"),
>         cut(as.numeric(format( head(raindate,30),"%d")), c(0,16,32) ),
>        sep="_")
>
>  [1] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"
>  [5] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"
>  [9] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"
> [13] "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"  "1982_(0,16]"
> [17] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
> [21] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
> [25] "1982_(16,32]" "1982_(16,32]" "1982_(16,32]" "1982_(16,32]"
> [29] "1982_(16,32]" "1982_(16,32]"
>
> Another method would be to use `cut` on  as.POSIXlt(raindate)$mday
>
> --
> David.
> >
> > John.
> >
> > On Sun, Apr 5, 2015 at 11:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi John,
> >> One way is to create an index variable that will divide your data into
> the
> >> appropriate intervals. There are a number of ways to do this. Say you
> want
> >> the "two month" version of bimonthly and you have a date variable
> >> ("raindate") for each observation like "1982-01-01".
> >>
> >> date_order<-paste(rep(month.abb,30),rep(1982:2011,each=12),sep="")
> >>
> >>
> month_index<-factor(format(as.Date(raindate,"%Y-%m-%d"),"%b%Y"),levels=date_order)
> >>
> >> You can then subset the raster matrices by "month_index" and average
> them
> >> for each group
> >>
> >> Jim
> >>
> >> On Mon, Apr 6, 2015 at 3:08 AM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> Please stop posting using HTML (as the Posting Guide warns you), and
> >>> follow John Kane's advice. Your reply below is not helping us
> understand as
> >>> well as you seem to think it should.
> >>>
> >>>
> ---------------------------------------------------------------------------
> >>> Jeff Newmiller                        The     .....       .....  Go
> >>> Live...
> >>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>> Go...
> >>>                                      Live:   OO#.. Dead: OO#..  Playing
> >>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> rocks...1k
> >>>
> >>>
> ---------------------------------------------------------------------------
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> On April 5, 2015 9:52:18 AM PDT, John Wasige <johnwasige at gmail.com>
> >>> wrote:
> >>>> Thanks Bert,
> >>>>
> >>>> The structure of the data is a raster stack with nraw=867, Ncol=995
> >>>>
> >>>> Rgds John
> >>>>
> >>>>
> >>>> On Sun, Apr 5, 2015 at 6:39 PM, Bert Gunter <gunter.berton at gene.com>
> >>>> wrote:
> >>>>
> >>>>> See ?tapply
> >>>>>
> >>>>> However, as John said, without knowing the structure of your data, it
> >>>>> is impossible to provide a guaranteed recipe. For example, does the
> >>>>> data structure contain date information? -- it would be difficult
> >>>> (but
> >>>>> not impossible depending on data structure) to aggregate by calendar
> >>>>> (bi-monthly, depending on your meaning of "bi") without knowing the
> >>>>> months. Aggregating by every n days would be easy, but that's
> >>>> probably
> >>>>> not what you want.
> >>>>>
> >>>>> Cheers,
> >>>>> Bert
> >>>>>
> >>>>> Bert Gunter
> >>>>> Genentech Nonclinical Biostatistics
> >>>>> (650) 467-7374
> >>>>>
> >>>>> "Data is not information. Information is not knowledge. And knowledge
> >>>>> is certainly not wisdom."
> >>>>> Clifford Stoll
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Sun, Apr 5, 2015 at 9:13 AM, John Kane <jrkrideau at inbox.com>
> >>>> wrote:
> >>>>>> Someone might if they had any idea of what the data actually looked
> >>>> like
> >>>>> and what you are trying to do. The 'bimonthly' for example, is
> >>>> ambiguous in
> >>>>> English; do you mean every two months or twice a month?
> >>>>>>
> >>>>>> Have a look at
> >>>> https://github.com/hadley/devtools/wiki/Reproducibility
> >>>>> and
> >>>>>
> >>>>
> >>>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>>>> with special attention to dput() as a method of supplying sample data
> >>>> to
> >>>>> the help list.
> >>>>>>
> >>>>>> John Kane
> >>>>>> Kingston ON Canada
> >>>>>>
> >>>>>>
> >>>>>>> -----Original Message-----
> >>>>>>> From: johnwasige at gmail.com
> >>>>>>> Sent: Sun, 5 Apr 2015 11:34:30 +0200
> >>>>>>> To: r-help at r-project.org
> >>>>>>> Subject: [R] Aggregating daily rainfall raster data to bimontly
> >>>> data
> >>>>>>>
> >>>>>>> Dear community,
> >>>>>>>
> >>>>>>> I have daily rainfall raster data for 30 years (1982_2011). I
> >>>> would like
> >>>>>>> to
> >>>>>>> aggregate daily to bimonthly raster data. Could somebody kindly
> >>>> help on
> >>>>>>> how
> >>>>>>> to go about it!
> >>>>>>>
> >>>>>>> Thanks for your help
> >>>>>>>
> >>>>>>> --
> >>>>>>> John
> >>>>>>>
> >>>>>>>      [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>> ____________________________________________________________
> >>>>>> FREE ONLINE PHOTOSHARING - Share your photos online with your
> >>>> friends
> >>>>> and family!
> >>>>>> Visit http://www.inbox.com/photosharing to find out more!
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>      [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Mon Apr  6 08:05:55 2015
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sun, 5 Apr 2015 23:05:55 -0700
Subject: [R] Combine list element by column name to make a dataframe
In-Reply-To: <339423473.194948.1428265952510.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>

Hi ,?

I have a example list like follow?


############################################

lst<-list(setNames(c(1,10,50,60,70,80),c("id","id1","math","phy","che","bio")),setNames(c(2,20,45),c("id","id1","phy")),setNames(c(3,30,75),c("id","id1","bio")))


My expected outcome :?

---------------------------------------------------------------------

df<-rbind(c(1,10,50,60,70,80),c(2,20,NA,45,NA,NA),c(3,30,NA,NA,NA,75))

colnames(df)<-c("id","id1","math","phy","che","bio")

row.names(df) <- NULL

df

############################################


Any suggestion will be appreciated .?

Thanks in advance.

?

Best regards


...........................?

Tanvir Ahamed

G?teborg, Sweden




	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Apr  6 10:41:02 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Apr 2015 10:41:02 +0200
Subject: [R] Combine list element by column name to make a dataframe
In-Reply-To: <1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
References: <1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
Message-ID: <FFE434F1-16A3-473D-8C01-418B13C4E55E@gmail.com>


> On 06 Apr 2015, at 08:05 , Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
> 
> Hi ,?
> 
> I have a example list like follow?
> 
> 
> ############################################
> 
> lst<-list(setNames(c(1,10,50,60,70,80),c("id","id1","math","phy","che","bio")),setNames(c(2,20,45),c("id","id1","phy")),setNames(c(3,30,75),c("id","id1","bio")))
> 
> 
> My expected outcome :?
> 
> ---------------------------------------------------------------------
> 
> df<-rbind(c(1,10,50,60,70,80),c(2,20,NA,45,NA,NA),c(3,30,NA,NA,NA,75))
> 
> colnames(df)<-c("id","id1","math","phy","che","bio")
> 
> row.names(df) <- NULL
> 
> df
> 
> ############################################
> 
> 
> Any suggestion will be appreciated .?

Hmm, in principle this looks like a merge() problem, if you first convert each list element to a data frame. That could be painful to get right though.

You could try something like this:

> nm <- Reduce(union, lapply(lst, names)) # or just type it in
> nm
[1] "id"   "id1"  "math" "phy"  "che"  "bio" 
> blank <- setNames(rep(NA_real_, length(nm)), nm)
> fill1 <- function(x, blank) {blank[names(x)] <- x; blank}
> lapply(lst, fill1, blank)
[[1]]
  id  id1 math  phy  che  bio 
   1   10   50   60   70   80 

[[2]]
  id  id1 math  phy  che  bio 
   2   20   NA   45   NA   NA 

[[3]]
  id  id1 math  phy  che  bio 
   3   30   NA   NA   NA   75 

> do.call(rbind,lapply(lst, fill1, blank))
     id id1 math phy che bio
[1,]  1  10   50  60  70  80
[2,]  2  20   NA  45  NA  NA
[3,]  3  30   NA  NA  NA  75

(NB, this is a matrix, not a data frame, but so is your "df"!)

Notice that this does not do a proper merge on the id fields, i.e. if you have two different records with different grades (say one with "che" and another with "phy") on the same id, you get two records, not one. However, that might well be what you wanted.

(It is tempting to use 

> fill1 <- function(x) `[<-`(blank, names(x), x)
> lapply(lst, fill1)

which does seem to work, but should probably be avoided because of the risk of destructive modification.) 


> 
> Thanks in advance.
> 
> ?
> 
> Best regards
> 
> 
> ...........................?
> 
> Tanvir Ahamed
> 
> G?teborg, Sweden
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jmhannon.ucdavis at gmail.com  Mon Apr  6 10:43:59 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 6 Apr 2015 01:43:59 -0700
Subject: [R] Combine list element by column name to make a dataframe
In-Reply-To: <1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
References: <339423473.194948.1428265952510.JavaMail.yahoo@mail.yahoo.com>
	<1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
Message-ID: <CACdH2ZbqRFisH_VFMad3AXzqJpexHXB0PoFiPSQLwwsyqWZMoQ@mail.gmail.com>

Maybe something like the appended?

-- Mike

lst <- list(setNames(c(1,10,50,60,70,80),
                     c("id","id1","math","phy","che","bio")),
            setNames(c(2,20,45),
                     c("id","id1","phy")),
            setNames(c(3,30,75),
                     c("id","id1","bio")))

lst


df <- rbind(c(1,10,50,60,70,80),
            c(2,20,NA,45,NA,NA),
            c(3,30,NA,NA,NA,75))

colnames(df)<-c("id","id1","math","phy","che","bio")
row.names(df) <- NULL

df

allNames <- unique(unlist(lapply(lst, names)))
allNames

newLst <- lapply(lst, function(element) {
    element[allNames]
})
newLst

df2 <- do.call(rbind, newLst)
df2

all.equal(df, df2)

On Sun, Apr 5, 2015 at 11:05 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hi ,
>
> I have a example list like follow
>
>
> ############################################
>
> lst<-list(setNames(c(1,10,50,60,70,80),c("id","id1","math","phy","che","bio")),setNames(c(2,20,45),c("id","id1","phy")),setNames(c(3,30,75),c("id","id1","bio")))
>
>
> My expected outcome :
>
> ---------------------------------------------------------------------
>
> df<-rbind(c(1,10,50,60,70,80),c(2,20,NA,45,NA,NA),c(3,30,NA,NA,NA,75))
>
> colnames(df)<-c("id","id1","math","phy","che","bio")
>
> row.names(df) <- NULL
>
> df
>
> ############################################
>
>
> Any suggestion will be appreciated .
>
> Thanks in advance.
>
>
>
> Best regards
>
>
> ...........................
>
> Tanvir Ahamed
>
> G?teborg, Sweden
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Apr  6 14:55:06 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 06 Apr 2015 13:55:06 +0100
Subject: [R] Trim and fill procedure
In-Reply-To: <DUB122-W32E7B4112E469625EC90C1C0F00@phx.gbl>
References: <DUB122-W32E7B4112E469625EC90C1C0F00@phx.gbl>
Message-ID: <5522822A.6040502@dewey.myzen.co.uk>

Hello Carlijn

Well the documentation for trimfill says they are added.

library(metafor)
example(trimfill)

This now leaves you with
res
res.tf

By looking at these and seeing which vectors have grown you should be 
able to extract the yi and vi which you want.

Wolfgang will doubtless be on the list soon to tell us there is a neater 
way of doing this.

On 04/04/2015 21:27, Carlijn Wibbelink wrote:
> Hi all,
>
> I have a question concerning the trim and fill procedure in metafor. In STATA it is possible to obtain the values of the added estimated effect sizes. I was wondering if this is also possible in R and if so, how I can obtain the new data with the added values.
> I would really appreciate your response.
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From marcgg.lamblin at gmail.com  Mon Apr  6 13:50:24 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Mon, 6 Apr 2015 13:50:24 +0200
Subject: [R] Verify that a grid is uniform
Message-ID: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>

I need to control of a given grid is uniform. This control using signif
until now works:

if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
abscissa[1:(length(abscissa) - 1)]) == signif(rep((range(abscissa)[2] -
         range(abscissa)[1])/(length(abscissa) - 1), length(abscissa) -
1)))) {
# other stuff
}

Does someone have some suggestions to improve this control? Thanks in
advance!! :)

Marc

	[[alternative HTML version deleted]]


From leptostracan at yahoo.com  Mon Apr  6 13:44:13 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Mon, 6 Apr 2015 04:44:13 -0700
Subject: [R] strip levels
Message-ID: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>

To whom it may help,

I am new to R.

I have been tring to have a lattice plot in two strip levels: 4 stations in 2 years.  

I type in:

histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)

The second level, i.e. Year, showed as "Raw.no10$Year" in the each of the lattice plot, instead of its respective year, such as "2002" and "2014".

I changed to the following programme language, therefore:

histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE) 

in order to specify the variable names of the strip.

Instead of showing "Raw.no10$Year", each of the lattice plot states "2014"!  They should have 4 plots showing "2002" and another 4 showing "2014".

Could any one help indicating what has gone wrong?

I am really helpless and frustrated now.  T_T

Regards,
Christine


From samadder.debojyoti at gmail.com  Mon Apr  6 14:50:11 2015
From: samadder.debojyoti at gmail.com (Debojyoti Samadder)
Date: Mon, 6 Apr 2015 18:20:11 +0530
Subject: [R] problem in search function
Message-ID: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>

Dear sir,
I tried   "help.search("rnorm")" in R version 3.1.2 .
It gave a error
"Error in `[<-`(`*tmp*`, , "name", value = sub("\\.[^.]*$", "",
basename(vDB$File))) :
  subscript out of bounds".
  Can you tell me the reason.It may be silly.
                                                              Regards
                                                              Debojyoti
Samadder

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Apr  6 16:32:53 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 6 Apr 2015 10:32:53 -0400
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
Message-ID: <CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>

Without a reproducible example that includes some sample data (fake is
fine), the code you used (NOT in HTML format), and some clear idea of
what output you expect, it's impossible to figure out how to help you.
Here are some suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Without knowing what you want, it looks like abscissa is a vector, and
so I'm not sure how this defines a grid, but
length(unique(diff(vec)))
might help. Note that this DOES NOT account for machine precision in any way.

Sarah

On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin <marcgg.lamblin at gmail.com> wrote:
> I need to control of a given grid is uniform. This control using signif
> until now works:
>
> if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
> abscissa[1:(length(abscissa) - 1)]) == signif(rep((range(abscissa)[2] -
>          range(abscissa)[1])/(length(abscissa) - 1), length(abscissa) -
> 1)))) {
> # other stuff
> }
>
> Does someone have some suggestions to improve this control? Thanks in
> advance!! :)
>
> Marc
>
>         [[alternative HTML version deleted]]
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sjkiss at gmail.com  Mon Apr  6 16:33:13 2015
From: sjkiss at gmail.com (Simon Kiss)
Date: Mon, 6 Apr 2015 10:33:13 -0400
Subject: [R] recode the same subset of variables in several list elements
In-Reply-To: <CA+8X3fURYSwJi7ZuiXusro-f8uM9RYBjod5unhmP1oY7wo3RXg@mail.gmail.com>
References: <F43FA97C-4A07-463B-9EDC-7A6C1B2F305A@gmail.com>
	<CA+8X3fURYSwJi7ZuiXusro-f8uM9RYBjod5unhmP1oY7wo3RXg@mail.gmail.com>
Message-ID: <934A132E-B774-427A-AA93-751D6DD6BD4D@gmail.com>

Hi Jim, So that does the rescale part very efficiently. But I?d like to know how to do that on each list element using lapply or llply.  I have about 4 data frames and a few other recodes to do so automating would be nice, rather than applying your code to each individual list element.
simon
> On Apr 2, 2015, at 6:30 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Simon,
> How about this?
> 
> library(plotrix)
> revlist<-grep("i",names(df),fixed=TRUE)
> df[,revlist]<-sapply(df[,revlist],rescale,c(3,1))
> 
> Jim
> 
> 
> On Fri, Apr 3, 2015 at 6:30 AM, Simon Kiss <sjkiss at gmail.com <mailto:sjkiss at gmail.com>> wrote:
> Hi there: I have a list of data frames with identical variable  names.  I?d like to reverse scale the same variables in each data.frame.
> I?d appreciate any one?s suggestions as to how to accomplish this. Right now, I?m working with the code at the very bottom of my sample data.
> Thanks, Simon Kiss
> 
> #Create data.frame1
> df<-data.frame(
>   ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>   ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>   hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>   hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>   evar1=sample(c(1,2,3), replace=TRUE, size=100),
>   evar2=sample(c(1,2,3), replace=TRUE, size=100)
>   )
> 
> #data.frame2
>   df1<-data.frame(
>     ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>     ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>     hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>     hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>     evar1=sample(c(1,2,3), replace=TRUE, size=100),
>     evar2=sample(c(1,2,3), replace=TRUE, size=100)
>   )
> 
> #List
> list1<-list(df, df1)
> #vector of first variables I?d like to recode
> i.recodes<-grep('^i.', names(df), value=TRUE)
> #Vector of second variables to recode
> e.recodes<-grep('^e.', names(df), value=TRUE)
> 
> #Set up RESCALE function from RPMG package
> RESCALE <- function (x, nx1, nx2, minx, maxx)
> { nx = nx1 + (nx2 - nx1) * (x - minx)/(maxx - minx)
>   return(nx)
> }
> 
> #This is what I?m playing around with
> test<-lapply(list1, function(y) {
>   out<-y[,i.recodes]
>   out<-lapply(out, function(x) RESCALE(x, 0,1,1,6))
>   y[,names(x)]<-out
> })
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Apr  6 16:37:11 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 6 Apr 2015 10:37:11 -0400
Subject: [R] problem in search function
In-Reply-To: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
References: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
Message-ID: <CAM_vju=AXpTdBWmvXp-O4ganfK0cXwzJzpVLrTicSCWkpcP3sg@mail.gmail.com>

On Mon, Apr 6, 2015 at 8:50 AM, Debojyoti Samadder
<samadder.debojyoti at gmail.com> wrote:
> Dear sir,

The masculine is no longer the default form of address. "Dear list" is
fine, as are many other options.

> I tried   "help.search("rnorm")" in R version 3.1.2 .
> It gave a error
> "Error in `[<-`(`*tmp*`, , "name", value = sub("\\.[^.]*$", "",
> basename(vDB$File))) :
>   subscript out of bounds".
>   Can you tell me the reason.It may be silly.

What OS?
What happens in a clean R session with no saved data nor packages loaded?
What happens if you upgrade to the current version of R (3.1.3)?

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Mon Apr  6 16:39:49 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 6 Apr 2015 10:39:49 -0400
Subject: [R] strip levels
In-Reply-To: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>
References: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>
Message-ID: <CAM_vjuk4s_5s4R48Nx7pFxBn8SHt1KAz9Cf8_EN=x+Seac4wTQ@mail.gmail.com>

Hi,

On Mon, Apr 6, 2015 at 7:44 AM, Christine Lee via R-help
<r-help at r-project.org> wrote:
> To whom it may help,
>
> I am new to R.
>
> I have been tring to have a lattice plot in two strip levels: 4 stations in 2 years.
>
> I type in:
>
> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)

In both examples, you're mis-stating the data. Given the data
argument, you do not need to restate the data source.

histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,
layout=c(4,2),nin=30,xlab="Prosomal Width (mm)",
strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)

If that doesn't solve your problem, then please use
dput(head(Raw.no10), 20) to provide some example data, or create fake
data of the same structure.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


> The second level, i.e. Year, showed as "Raw.no10$Year" in the each of the lattice plot, instead of its respective year, such as "2002" and "2014".
>
> I changed to the following programme language, therefore:
>
> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>
> in order to specify the variable names of the strip.
>
> Instead of showing "Raw.no10$Year", each of the lattice plot states "2014"!  They should have 4 plots showing "2002" and another 4 showing "2014".
>
> Could any one help indicating what has gone wrong?
>
> I am really helpless and frustrated now.  T_T
>
> Regards,
> Christine


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Mon Apr  6 16:46:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 06 Apr 2015 07:46:10 -0700
Subject: [R] problem in search function
In-Reply-To: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
References: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
Message-ID: <88456EFB-C419-4121-9404-01CF02FBE6E2@dcn.davis.CA.us>

In this case I think it means your installation of the R software is broken, though if you are messing around with environment variables that could probably also do this. You should read the Posting Guide and follow the guidance there if you want more specific feedback.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 6, 2015 5:50:11 AM PDT, Debojyoti Samadder <samadder.debojyoti at gmail.com> wrote:
>Dear sir,
>I tried   "help.search("rnorm")" in R version 3.1.2 .
>It gave a error
>"Error in `[<-`(`*tmp*`, , "name", value = sub("\\.[^.]*$", "",
>basename(vDB$File))) :
>  subscript out of bounds".
>  Can you tell me the reason.It may be silly.
>                                                              Regards
>                                                              Debojyoti
>Samadder
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Apr  6 17:15:35 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 06 Apr 2015 16:15:35 +0100
Subject: [R] strip levels
In-Reply-To: <CAM_vjuk4s_5s4R48Nx7pFxBn8SHt1KAz9Cf8_EN=x+Seac4wTQ@mail.gmail.com>
References: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>
	<CAM_vjuk4s_5s4R48Nx7pFxBn8SHt1KAz9Cf8_EN=x+Seac4wTQ@mail.gmail.com>
Message-ID: <5522A317.7010001@dewey.myzen.co.uk>

See inline

On 06/04/2015 15:39, Sarah Goslee wrote:
> Hi,
>
> On Mon, Apr 6, 2015 at 7:44 AM, Christine Lee via R-help
> <r-help at r-project.org> wrote:
>> To whom it may help,
>>
>> I am new to R.
>>
>> I have been tring to have a lattice plot in two strip levels: 4 stations in 2 years.
>>
>> I type in:
>>
>> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>
> In both examples, you're mis-stating the data. Given the data
> argument, you do not need to restate the data source.
>
> histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,

I think Sarah meant to type Station * Year and not as above

> layout=c(4,2),nin=30,xlab="Prosomal Width (mm)",
> strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>
> If that doesn't solve your problem, then please use
> dput(head(Raw.no10), 20) to provide some example data, or create fake
> data of the same structure.
>
> Without a reproducible example that includes some sample data (fake is
> fine), the code you used, and some clear idea of what output you
> expect, it's impossible to figure out how to help you. Here are some
> suggestions for creating a good reproducible example:
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
>> The second level, i.e. Year, showed as "Raw.no10$Year" in the each of the lattice plot, instead of its respective year, such as "2002" and "2014".
>>
>> I changed to the following programme language, therefore:
>>
>> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>>
>> in order to specify the variable names of the strip.
>>
>> Instead of showing "Raw.no10$Year", each of the lattice plot states "2014"!  They should have 4 plots showing "2002" and another 4 showing "2014".
>>
>> Could any one help indicating what has gone wrong?
>>
>> I am really helpless and frustrated now.  T_T
>>
>> Regards,
>> Christine
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From sarah.goslee at gmail.com  Mon Apr  6 18:16:08 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 6 Apr 2015 12:16:08 -0400
Subject: [R] problem in search function
In-Reply-To: <CADktfGWJOV+LKNxqgtvu7ZZt1Wy+_pNFTrGRPW9mWGFOeimr=g@mail.gmail.com>
References: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
	<CAM_vju=AXpTdBWmvXp-O4ganfK0cXwzJzpVLrTicSCWkpcP3sg@mail.gmail.com>
	<CADktfGWJOV+LKNxqgtvu7ZZt1Wy+_pNFTrGRPW9mWGFOeimr=g@mail.gmail.com>
Message-ID: <CAM_vjunoJDV3ERM_oM_2waxyJVbvUjtmN6UzXzqUz_84H0AtXw@mail.gmail.com>

It still sounds like a broken installation. I'd uninstall and
reinstall, I think.

But I've copied this back to the list (rather than just to me), and
someone else might have a better solution.

Sarah

On Mon, Apr 6, 2015 at 12:02 PM, Debojyoti Samadder
<samadder.debojyoti at gmail.com> wrote:
> Dear list memeber,
>               At first sorry.I am using windows 7 home basic.In R (3.1.3)
> with no saved data nor packages loaded the problem is still there.
>
>
> Regards
>
> Debojyoti Samadder
>
> On Mon, Apr 6, 2015 at 8:07 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> On Mon, Apr 6, 2015 at 8:50 AM, Debojyoti Samadder
>> <samadder.debojyoti at gmail.com> wrote:
>> > Dear sir,
>>
>> The masculine is no longer the default form of address. "Dear list" is
>> fine, as are many other options.
>>
>> > I tried   "help.search("rnorm")" in R version 3.1.2 .
>> > It gave a error
>> > "Error in `[<-`(`*tmp*`, , "name", value = sub("\\.[^.]*$", "",
>> > basename(vDB$File))) :
>> >   subscript out of bounds".
>> >   Can you tell me the reason.It may be silly.
>>
>> What OS?
>> What happens in a clean R session with no saved data nor packages loaded?
>> What happens if you upgrade to the current version of R (3.1.3)?
>>
>> Sarah
>>
>> --


From leptostracan at yahoo.com  Mon Apr  6 18:40:37 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Mon, 6 Apr 2015 09:40:37 -0700
Subject: [R] strip levels
Message-ID: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>

Thank you very much to Both Sarah and Michael,

Your responses are deeply appreciated.  TxT

I have omitted the reinstatement of the data source as follows:

library(lattice)
histogram(~Width|Station*Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE) 

Instead of showing respective year of 2002 and 2014 in each of the lattice plot, it just shows "Year" in all lattice plot as attached.  TxT

Do you know what has gone wrong?

Many thanks.

Regards,
Christine




--------------------------------------------
2015?4?6? ????Michael Dewey <lists at dewey.myzen.co.uk> ???

 ??: Re: [R] strip levels
 ???: "Sarah Goslee" <sarah.goslee at gmail.com>, "Chr
 ??(CC): "r-help" <r-help at r-project.org>
 ??: 2015?4?6?,???,??11:15

 See inline

 On 06/04/2015 15:39, Sarah
 Goslee wrote:
 > Hi,
 >
 > On Mon, Apr 6, 2015
 at 7:44 AM, Christine Lee via R-help
 >
 <r-help at r-project.org>
 wrote:
 >> To whom it may help,
 >>
 >> I am new to
 R.
 >>
 >> I have
 been tring to have a lattice plot in two strip levels: 4
 stations in 2 years.
 >>
 >> I type in:
 >>
 >>
 histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
 data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
 Width (mm)",
 strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
 >
 > In both examples,
 you're mis-stating the data. Given the data
 > argument, you do not need to restate the
 data source.
 >
 >
 histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,

 I think Sarah meant to type
 Station * Year and not as above

 >
 layout=c(4,2),nin=30,xlab="Prosomal Width
 (mm)",
 >
 strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
 >
 > If that doesn't
 solve your problem, then please use
 >
 dput(head(Raw.no10), 20) to provide some example data, or
 create fake
 > data of the same
 structure.
 >
 > Without
 a reproducible example that includes some sample data (fake
 is
 > fine), the code you used, and some
 clear idea of what output you
 > expect,
 it's impossible to figure out how to help you. Here are
 some
 > suggestions for creating a good
 reproducible example:
 > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
 >
 >
 >> The second level, i.e. Year, showed as
 "Raw.no10$Year" in the each of the lattice plot,
 instead of its respective year, such as "2002" and
 "2014".
 >>
 >> I changed to the following programme
 language, therefore:
 >>
 >>
 histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
 data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
 Width (mm)",
 strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
 >>
 >> in order to
 specify the variable names of the strip.
 >>
 >> Instead of
 showing "Raw.no10$Year", each of the lattice plot
 states "2014"!? They should have 4 plots showing
 "2002" and another 4 showing "2014".
 >>
 >> Could any one
 help indicating what has gone wrong?
 >>
 >> I am really
 helpless and frustrated now.? T_T
 >>
 >> Regards,
 >> Christine
 >
 >

 -- 
 Michael
 http://www.dewey.myzen.co.uk/home.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Histogram-no10-1.pdf
Type: application/pdf
Size: 6924 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150406/15ddc7d2/attachment.pdf>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: testing.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150406/15ddc7d2/attachment.txt>

From sarah.goslee at gmail.com  Mon Apr  6 18:50:47 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 6 Apr 2015 12:50:47 -0400
Subject: [R] strip levels
In-Reply-To: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>
References: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>
Message-ID: <CAM_vjun7-Je=d2j-NC_vWPRu+KJQB9vT0eGUTD_-wBho_O542Q@mail.gmail.com>

Please use dput() to provide your data, as already requested. Just
providing the text file doesn't tell us enough about the structure:
are some columns factors? etc.

Or, if you must provide an attachment (really not preferred, as many
attachments won't make it to the list, and many people do not want to
open unsolicited attachments), also include the code to import it
*exactly the way you did*.


Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example



Sarah

On Mon, Apr 6, 2015 at 12:40 PM, Christine Lee <leptostracan at yahoo.com> wrote:
> Thank you very much to Both Sarah and Michael,
>
> Your responses are deeply appreciated.  TxT
>
> I have omitted the reinstatement of the data source as follows:
>
> library(lattice)
> histogram(~Width|Station*Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>
> Instead of showing respective year of 2002 and 2014 in each of the lattice plot, it just shows "Year" in all lattice plot as attached.  TxT
>
> Do you know what has gone wrong?
>
> Many thanks.
>
> Regards,
> Christine
>
>
>
>
> --------------------------------------------
> 2015?4?6? ????Michael Dewey <lists at dewey.myzen.co.uk> ???
>
>  ??: Re: [R] strip levels
>  ???: "Sarah Goslee" <sarah.goslee at gmail.com>, "Christine Lee" <leptostracan at yahoo.com>
>  ??(CC): "r-help" <r-help at r-project.org>
>  ??: 2015?4?6?,???,??11:15
>
>  See inline
>
>  On 06/04/2015 15:39, Sarah
>  Goslee wrote:
>  > Hi,
>  >
>  > On Mon, Apr 6, 2015
>  at 7:44 AM, Christine Lee via R-help
>  >
>  <r-help at r-project.org>
>  wrote:
>  >> To whom it may help,
>  >>
>  >> I am new to
>  R.
>  >>
>  >> I have
>  been tring to have a lattice plot in two strip levels: 4
>  stations in 2 years.
>  >>
>  >> I type in:
>  >>
>  >>
>  histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
>  data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
>  Width (mm)",
>  strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>  >
>  > In both examples,
>  you're mis-stating the data. Given the data
>  > argument, you do not need to restate the
>  data source.
>  >
>  >
>  histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,
>
>  I think Sarah meant to type
>  Station * Year and not as above
>
>  >
>  layout=c(4,2),nin=30,xlab="Prosomal Width
>  (mm)",
>  >
>  strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>  >
>  > If that doesn't
>  solve your problem, then please use
>  >
>  dput(head(Raw.no10), 20) to provide some example data, or
>  create fake
>  > data of the same
>  structure.
>  >
>  > Without
>  a reproducible example that includes some sample data (fake
>  is
>  > fine), the code you used, and some
>  clear idea of what output you
>  > expect,
>  it's impossible to figure out how to help you. Here are
>  some
>  > suggestions for creating a good
>  reproducible example:
>  > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>  >
>  >
>  >> The second level, i.e. Year, showed as
>  "Raw.no10$Year" in the each of the lattice plot,
>  instead of its respective year, such as "2002" and
>  "2014".
>  >>
>  >> I changed to the following programme
>  language, therefore:
>  >>
>  >>
>  histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
>  data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
>  Width (mm)",
>  strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>  >>
>  >> in order to
>  specify the variable names of the strip.
>  >>
>  >> Instead of
>  showing "Raw.no10$Year", each of the lattice plot
>  states "2014"!  They should have 4 plots showing
>  "2002" and another 4 showing "2014".
>  >>
>  >> Could any one
>  help indicating what has gone wrong?
>  >>
>  >> I am really
>  helpless and frustrated now.  T_T
>  >>
>  >> Regards,
>  >> Christine
>  >
>  >
>


From marcgg.lamblin at gmail.com  Mon Apr  6 19:11:53 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Mon, 6 Apr 2015 19:11:53 +0200
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
Message-ID: <CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>

The aim is to control if a given abscissa/grid is uniform or not. Abscissa
in generic vector of real ordered numbers.

Here a reproducibile code:

# uniform abscissa/grid
abscissa1 <- seq(0, 1, length=100)
# non-uniform abscissa/grid
abscissa2 <- sort(runif(100))

control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
abscissa1[1:(length(abscissa1) - 1)]) == signif(rep((range(abscissa1)[2] -
range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) - 1)))
control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
abscissa2[1:(length(abscissa2) - 1)]) == signif(rep((range(abscissa2)[2] -
range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) - 1)))

control1
control2

As expected control1 is TRUE and control2 is FALSE. Actually in this code
it is possible also to use
diff inside signif.
Do you mean that the control to perform can be done in this manner

if (length(unique(diff(vec))) == 1) {
  control <- TRUE
} else {
  control <- FALSE
}

I have tried to apply this control on abscissa1 which is uniform but
length(unique(diff(abscissa1))) was greater than one; probably, as you
said, this is due to the fact that in this way I don't take into account
the machine precision.
What I want to understand is if there is a SAFE solution, even if until now
this control is working correctly. I have seen in the documentation of
signif that by default the number of digits considered are 6. The number of
digits to consider depends on the scale used. It doesn't make sense to
increase the number of digits with respect to default because, in this
case, you are not using an handy scale.
Maybe it could be better directly to ask user if the abscissa passed as
argument is uniform or not.
Thanks a lot for the link!!!

Marc




2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:

> Without a reproducible example that includes some sample data (fake is
> fine), the code you used (NOT in HTML format), and some clear idea of
> what output you expect, it's impossible to figure out how to help you.
> Here are some suggestions for creating a good reproducible example:
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Without knowing what you want, it looks like abscissa is a vector, and
> so I'm not sure how this defines a grid, but
> length(unique(diff(vec)))
> might help. Note that this DOES NOT account for machine precision in any
> way.
>
> Sarah
>
> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin <marcgg.lamblin at gmail.com>
> wrote:
> > I need to control of a given grid is uniform. This control using signif
> > until now works:
> >
> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
> > abscissa[1:(length(abscissa) - 1)]) == signif(rep((range(abscissa)[2] -
> >          range(abscissa)[1])/(length(abscissa) - 1), length(abscissa) -
> > 1)))) {
> > # other stuff
> > }
> >
> > Does someone have some suggestions to improve this control? Thanks in
> > advance!! :)
> >
> > Marc
> >
> >         [[alternative HTML version deleted]]
> >
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From catalinroibu at gmail.com  Mon Apr  6 19:16:39 2015
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 6 Apr 2015 20:16:39 +0300
Subject: [R] stripchart
Message-ID: <CAEW+BD+LEP_8CBVvCVHkEyOp0hfhGzJriTYi217jGN-jhm80Qw@mail.gmail.com>

Dear all!

I have a problem! I want to plot temperature anomalies per months until
1901-2014. For this I want to make a stripchart. I used the specified
command, but I want to plot the extreme values with full dots  above 90th
and bellow 10th percentile, and the normal values with hallow dots.

Please help me how to succeed with that!

Thank you!

?Best regards!

Catalin?

-- 
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Mon Apr  6 19:18:02 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 6 Apr 2015 19:18:02 +0200
Subject: [R] sort adjacency  matrix
In-Reply-To: <DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
Message-ID: <DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>

Dear group 
i have the following matrix

1  . . 1 . . 1 . . . .
2  . . . . . . 1 . . .
3  1 . . . 1 . . 1 . 1
4  . . . . . 1 . . . .
5  . . 1 . . . . . . 1
6  1 . . 1 . . . . 1 .
7  . 1 . . . . . 1 . .
8  . . 1 . . . 1 . . 1
9  . . . . . 1 . . . 1
10 . . 1 . 1 . . 1 1 .

I want to sort it according to ones in each row ascending (where max number of ones first)

to be as follow

3  1 . . . 1 . . 1 . 1
10 . . 1 . 1 . . 1 1 .
6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .

how can I do this in R
thanks in advance
 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Apr  6 19:47:14 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 6 Apr 2015 10:47:14 -0700
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
	<CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
Message-ID: <CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>

Perhaps ?diff might be useful here:

z <- runif(20)
all(diff(z) == z[2] - z[1] )
## FALSE

z <- seq_len(10)
all(diff(z) == z[2] - z[1] )
##TRUE

You can use signif or round as before to allow for "near uniformity"
or use ?zapsmall or an explicit comparison with a tolerancec instead
of ==, e.g. all(diff(z) - z[2] + z[1] < tol)

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Apr 6, 2015 at 10:11 AM, Marc Lamblin <marcgg.lamblin at gmail.com> wrote:
> The aim is to control if a given abscissa/grid is uniform or not. Abscissa
> in generic vector of real ordered numbers.
>
> Here a reproducibile code:
>
> # uniform abscissa/grid
> abscissa1 <- seq(0, 1, length=100)
> # non-uniform abscissa/grid
> abscissa2 <- sort(runif(100))
>
> control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
> abscissa1[1:(length(abscissa1) - 1)]) == signif(rep((range(abscissa1)[2] -
> range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) - 1)))
> control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
> abscissa2[1:(length(abscissa2) - 1)]) == signif(rep((range(abscissa2)[2] -
> range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) - 1)))
>
> control1
> control2
>
> As expected control1 is TRUE and control2 is FALSE. Actually in this code
> it is possible also to use
> diff inside signif.
> Do you mean that the control to perform can be done in this manner
>
> if (length(unique(diff(vec))) == 1) {
>   control <- TRUE
> } else {
>   control <- FALSE
> }
>
> I have tried to apply this control on abscissa1 which is uniform but
> length(unique(diff(abscissa1))) was greater than one; probably, as you
> said, this is due to the fact that in this way I don't take into account
> the machine precision.
> What I want to understand is if there is a SAFE solution, even if until now
> this control is working correctly. I have seen in the documentation of
> signif that by default the number of digits considered are 6. The number of
> digits to consider depends on the scale used. It doesn't make sense to
> increase the number of digits with respect to default because, in this
> case, you are not using an handy scale.
> Maybe it could be better directly to ask user if the abscissa passed as
> argument is uniform or not.
> Thanks a lot for the link!!!
>
> Marc
>
>
>
>
> 2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
>
>> Without a reproducible example that includes some sample data (fake is
>> fine), the code you used (NOT in HTML format), and some clear idea of
>> what output you expect, it's impossible to figure out how to help you.
>> Here are some suggestions for creating a good reproducible example:
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>> Without knowing what you want, it looks like abscissa is a vector, and
>> so I'm not sure how this defines a grid, but
>> length(unique(diff(vec)))
>> might help. Note that this DOES NOT account for machine precision in any
>> way.
>>
>> Sarah
>>
>> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin <marcgg.lamblin at gmail.com>
>> wrote:
>> > I need to control of a given grid is uniform. This control using signif
>> > until now works:
>> >
>> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
>> > abscissa[1:(length(abscissa) - 1)]) == signif(rep((range(abscissa)[2] -
>> >          range(abscissa)[1])/(length(abscissa) - 1), length(abscissa) -
>> > 1)))) {
>> > # other stuff
>> > }
>> >
>> > Does someone have some suggestions to improve this control? Thanks in
>> > advance!! :)
>> >
>> > Marc
>> >
>> >         [[alternative HTML version deleted]]
>> >
>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Apr  6 19:51:48 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 6 Apr 2015 10:51:48 -0700
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
	<CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
	<CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>
Message-ID: <CACk-te0tW0fL-fkDDfRY0-nAvC_me4+75=U8aD8gD+Xnd_ssNQ@mail.gmail.com>

... correction: you need to use absolute value for the comparison, of course.

all(abs(diff(z) - z[2] + z[1]) < tol)

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Apr 6, 2015 at 10:47 AM, Bert Gunter <bgunter at gene.com> wrote:
> Perhaps ?diff might be useful here:
>
> z <- runif(20)
> all(diff(z) == z[2] - z[1] )
> ## FALSE
>
> z <- seq_len(10)
> all(diff(z) == z[2] - z[1] )
> ##TRUE
>
> You can use signif or round as before to allow for "near uniformity"
> or use ?zapsmall or an explicit comparison with a tolerancec instead
> of ==, e.g. all(diff(z) - z[2] + z[1] < tol)
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Mon, Apr 6, 2015 at 10:11 AM, Marc Lamblin <marcgg.lamblin at gmail.com> wrote:
>> The aim is to control if a given abscissa/grid is uniform or not. Abscissa
>> in generic vector of real ordered numbers.
>>
>> Here a reproducibile code:
>>
>> # uniform abscissa/grid
>> abscissa1 <- seq(0, 1, length=100)
>> # non-uniform abscissa/grid
>> abscissa2 <- sort(runif(100))
>>
>> control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
>> abscissa1[1:(length(abscissa1) - 1)]) == signif(rep((range(abscissa1)[2] -
>> range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) - 1)))
>> control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
>> abscissa2[1:(length(abscissa2) - 1)]) == signif(rep((range(abscissa2)[2] -
>> range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) - 1)))
>>
>> control1
>> control2
>>
>> As expected control1 is TRUE and control2 is FALSE. Actually in this code
>> it is possible also to use
>> diff inside signif.
>> Do you mean that the control to perform can be done in this manner
>>
>> if (length(unique(diff(vec))) == 1) {
>>   control <- TRUE
>> } else {
>>   control <- FALSE
>> }
>>
>> I have tried to apply this control on abscissa1 which is uniform but
>> length(unique(diff(abscissa1))) was greater than one; probably, as you
>> said, this is due to the fact that in this way I don't take into account
>> the machine precision.
>> What I want to understand is if there is a SAFE solution, even if until now
>> this control is working correctly. I have seen in the documentation of
>> signif that by default the number of digits considered are 6. The number of
>> digits to consider depends on the scale used. It doesn't make sense to
>> increase the number of digits with respect to default because, in this
>> case, you are not using an handy scale.
>> Maybe it could be better directly to ask user if the abscissa passed as
>> argument is uniform or not.
>> Thanks a lot for the link!!!
>>
>> Marc
>>
>>
>>
>>
>> 2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
>>
>>> Without a reproducible example that includes some sample data (fake is
>>> fine), the code you used (NOT in HTML format), and some clear idea of
>>> what output you expect, it's impossible to figure out how to help you.
>>> Here are some suggestions for creating a good reproducible example:
>>>
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>
>>> Without knowing what you want, it looks like abscissa is a vector, and
>>> so I'm not sure how this defines a grid, but
>>> length(unique(diff(vec)))
>>> might help. Note that this DOES NOT account for machine precision in any
>>> way.
>>>
>>> Sarah
>>>
>>> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin <marcgg.lamblin at gmail.com>
>>> wrote:
>>> > I need to control of a given grid is uniform. This control using signif
>>> > until now works:
>>> >
>>> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
>>> > abscissa[1:(length(abscissa) - 1)]) == signif(rep((range(abscissa)[2] -
>>> >          range(abscissa)[1])/(length(abscissa) - 1), length(abscissa) -
>>> > 1)))) {
>>> > # other stuff
>>> > }
>>> >
>>> > Does someone have some suggestions to improve this control? Thanks in
>>> > advance!! :)
>>> >
>>> > Marc
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Apr  6 20:09:48 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 6 Apr 2015 18:09:48 +0000
Subject: [R] sort adjacency  matrix
In-Reply-To: <DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67C2BF@mb02.ads.tamu.edu>

The answer depends on what kind of matrix/data frame you have. That is why we encourage people to use dput() to create a copy of the sample data in their email. Some combination of order() function the rowSums() function will probably get you what you want. For example,

dat[order(rowSums(dat=="1"), decreasing=TRUE),]

or

dat[order(rowSums(dat), decreasing=TRUE),]

or

dat[order(rowSums(dat, na.rm=TRUE), decreasing=TRUE),]

Note that the order is not unique since there are ties in the number of 1s.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia Ibrahim
Sent: Monday, April 6, 2015 12:18 PM
To: r-help at r-project.org
Subject: [R] sort adjacency matrix

Dear group 
i have the following matrix

1  . . 1 . . 1 . . . .
2  . . . . . . 1 . . .
3  1 . . . 1 . . 1 . 1
4  . . . . . 1 . . . .
5  . . 1 . . . . . . 1
6  1 . . 1 . . . . 1 .
7  . 1 . . . . . 1 . .
8  . . 1 . . . 1 . . 1
9  . . . . . 1 . . . 1
10 . . 1 . 1 . . 1 1 .

I want to sort it according to ones in each row ascending (where max number of ones first)

to be as follow

3  1 . . . 1 . . 1 . 1
10 . . 1 . 1 . . 1 1 .
6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .

how can I do this in R
thanks in advance
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nicole.ford at me.com  Mon Apr  6 20:14:11 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Mon, 06 Apr 2015 14:14:11 -0400
Subject: [R] R crashes upon changing directories, loading files, etc.
Message-ID: <60360FC9-8F7E-4EC7-B007-00700F85D6D2@me.com>

Hello,

I am experiencing an issue, repeatedly, which began today.  

Example code:

load(file.choose())  ##sometimes it crashes here/ endless spinner/ other times I can get through.

or: i go up to options at the top to set wd, or select ?file? -> ?open? and it will do the same thing.

I found a page where people were indicating they had this issue, but there was no one responding with a fix.  see below:

bugs.r-project.org/bugzilla/show_bug.cgi?id=14240


I am running :

R version 3.1.3 (2015-03-09) -- "Smooth Sidewalk"
Platform: x86_64-apple-darwin13.4.0 (64-bit)
On OS X 10.10

Any help/ direction is appreciated.

~Nicole
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Apr  6 20:15:23 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 6 Apr 2015 11:15:23 -0700
Subject: [R] sort adjacency matrix
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67C2BF@mb02.ads.tamu.edu>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67C2BF@mb02.ads.tamu.edu>
Message-ID: <CACk-te2kOz9a7nnPfd9ai8L-HuZnx-RWnqJbaiN1hETLUHt7yw@mail.gmail.com>

Not quite, David.

If I understand the OP's query, he wants the ties to be broken by the
"lexicographic" order (with apologies if I have misused this term) of
the 1's within the rows. Makes things a bit more interesting.

Have at it!

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Apr 6, 2015 at 11:09 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> The answer depends on what kind of matrix/data frame you have. That is why we encourage people to use dput() to create a copy of the sample data in their email. Some combination of order() function the rowSums() function will probably get you what you want. For example,
>
> dat[order(rowSums(dat=="1"), decreasing=TRUE),]
>
> or
>
> dat[order(rowSums(dat), decreasing=TRUE),]
>
> or
>
> dat[order(rowSums(dat, na.rm=TRUE), decreasing=TRUE),]
>
> Note that the order is not unique since there are ties in the number of 1s.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia Ibrahim
> Sent: Monday, April 6, 2015 12:18 PM
> To: r-help at r-project.org
> Subject: [R] sort adjacency matrix
>
> Dear group
> i have the following matrix
>
> 1  . . 1 . . 1 . . . .
> 2  . . . . . . 1 . . .
> 3  1 . . . 1 . . 1 . 1
> 4  . . . . . 1 . . . .
> 5  . . 1 . . . . . . 1
> 6  1 . . 1 . . . . 1 .
> 7  . 1 . . . . . 1 . .
> 8  . . 1 . . . 1 . . 1
> 9  . . . . . 1 . . . 1
> 10 . . 1 . 1 . . 1 1 .
>
> I want to sort it according to ones in each row ascending (where max number of ones first)
>
> to be as follow
>
> 3  1 . . . 1 . . 1 . 1
> 10 . . 1 . 1 . . 1 1 .
> 6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .
>
> how can I do this in R
> thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Apr  6 20:20:02 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 06 Apr 2015 19:20:02 +0100
Subject: [R] sort adjacency  matrix
In-Reply-To: <DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
Message-ID: <5522CE52.3080407@sapo.pt>

Hello,

You should have used ?dput to post your data example.
Since you haven't, I've made up one.

set.seed(4795)
mat <- matrix(sample(0:1, 24, replace = TRUE), nrow = 6)
mat

inx <- order(rowSums(mat), decreasing = TRUE)
mat[inx, ]


Hope this helps,

Rui Barradas

Em 06-04-2015 18:18, Ragia Ibrahim escreveu:
> Dear group
> i have the following matrix
>
> 1  . . 1 . . 1 . . . .
> 2  . . . . . . 1 . . .
> 3  1 . . . 1 . . 1 . 1
> 4  . . . . . 1 . . . .
> 5  . . 1 . . . . . . 1
> 6  1 . . 1 . . . . 1 .
> 7  . 1 . . . . . 1 . .
> 8  . . 1 . . . 1 . . 1
> 9  . . . . . 1 . . . 1
> 10 . . 1 . 1 . . 1 1 .
>
> I want to sort it according to ones in each row ascending (where max number of ones first)
>
> to be as follow
>
> 3  1 . . . 1 . . 1 . 1
> 10 . . 1 . 1 . . 1 1 .
> 6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .
>
> how can I do this in R
> thanks in advance
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ragia11 at hotmail.com  Mon Apr  6 20:36:04 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 6 Apr 2015 20:36:04 +0200
Subject: [R] sort adjacency  matrix_with data
In-Reply-To: <5522CE52.3080407@sapo.pt>
References: <mailman.0.1418986801.25142.r-help@r-project.org>,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>
Message-ID: <DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>

Hi again
the data represents a  directed graph  represented in a matrix

e.g 
library(igraph)
g <- forest.fire.game(10, fw.prob=0.3 , bw.factor=0.32/0.3, directed = TRUE)

m=get.adjacency(g , attr=NULL)
print(m)

----------
many thanks and pardon me for multiple posts
Ragia

> Date: Mon, 6 Apr 2015 19:20:02 +0100
> From: ruipbarradas at sapo.pt
> To: ragia11 at hotmail.com; r-help at r-project.org
> Subject: Re: [R] sort adjacency  matrix
> 
> Hello,
> 
> You should have used ?dput to post your data example.
> Since you haven't, I've made up one.
> 
> set.seed(4795)
> mat <- matrix(sample(0:1, 24, replace = TRUE), nrow = 6)
> mat
> 
> inx <- order(rowSums(mat), decreasing = TRUE)
> mat[inx, ]
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 06-04-2015 18:18, Ragia Ibrahim escreveu:
> > Dear group
> > i have the following matrix
> >
> > 1  . . 1 . . 1 . . . .
> > 2  . . . . . . 1 . . .
> > 3  1 . . . 1 . . 1 . 1
> > 4  . . . . . 1 . . . .
> > 5  . . 1 . . . . . . 1
> > 6  1 . . 1 . . . . 1 .
> > 7  . 1 . . . . . 1 . .
> > 8  . . 1 . . . 1 . . 1
> > 9  . . . . . 1 . . . 1
> > 10 . . 1 . 1 . . 1 1 .
> >
> > I want to sort it according to ones in each row ascending (where max number of ones first)
> >
> > to be as follow
> >
> > 3  1 . . . 1 . . 1 . 1
> > 10 . . 1 . 1 . . 1 1 .
> > 6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .
> >
> > how can I do this in R
> > thanks in advance
> >   		 	   		
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
 		 	   		  
	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Mon Apr  6 21:22:57 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 6 Apr 2015 11:22:57 -0800
Subject: [R] stripchart
In-Reply-To: <CAEW+BD+LEP_8CBVvCVHkEyOp0hfhGzJriTYi217jGN-jhm80Qw@mail.gmail.com>
Message-ID: <E732B2D5F1E.000008A7jrkrideau@inbox.com>

Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


John Kane
Kingston ON Canada


> -----Original Message-----
> From: catalinroibu at gmail.com
> Sent: Mon, 6 Apr 2015 20:16:39 +0300
> To: r-help at r-project.org
> Subject: [R] stripchart
> 
> Dear all!
> 
> I have a problem! I want to plot temperature anomalies per months until
> 1901-2014. For this I want to make a stripchart. I used the specified
> command, but I want to plot the extreme values with full dots  above 90th
> and bellow 10th percentile, and the normal values with hallow dots.
> 
> Please help me how to succeed with that!
> 
> Thank you!
> 
> ?Best regards!
> 
> Catalin
> 
> --
> ---
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                        +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From catalinroibu at gmail.com  Mon Apr  6 21:58:50 2015
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 6 Apr 2015 22:58:50 +0300
Subject: [R] stripchart
In-Reply-To: <E732B2D5F1E.000008A7jrkrideau@inbox.com>
References: <CAEW+BD+LEP_8CBVvCVHkEyOp0hfhGzJriTYi217jGN-jhm80Qw@mail.gmail.com>
	<E732B2D5F1E.000008A7jrkrideau@inbox.com>
Message-ID: <CAEW+BDKZDwsr1cQ6s3paPXgaWXj8LOzN0O8FzVSpn-__zgQHGQ@mail.gmail.com>

original data are something like that:

structure(list(year = 1901:2013, J = c(1.547878, -1.100605, -0.4222952,
-1.221505, -0.2250523, -0.1260924, -0.6251569, -0.7348371, 0.9646313,
1.21345, 0.9746932, 0.5155271, -0.3323591, -0.6689715, 0.8461724,
1.772659, 1.436295, -1.108881, -1.196227, 1.445744, -0.0565,
0.7037539, 1.119812, -0.6622664, -0.5224946, 1.041975, 0.824515,
-0.8732078, 1.436339, -1.733533, -0.5700181, 0.1557751, 1.168567,
0.0399, 0.4697068, -1.099068, 0.985188, -0.5109026, -1.066961,
1.542147, 1.586152, 1.397714, 1.277232, -1.071034, 1.539472,
-1.380059, 1.644268, 1.464481, -1.238555, -0.4090864, -1.280815,
0.2857544, 1.24601, -0.5919045, -0.2339949, 0.2059847, 0.3540879,
-0.1751796, 0.8592942, 0.9626673, 0.400106, -0.4759586, 2.004117,
-1.320636, 0.9035271, 1.80419, -0.2640611, 1.058896, -0.6948445,
0.913681, -0.149598, -0.5239062, -1.011054, -1.345659, -1.216435,
0.85655, -0.3159549, -1.610421, 0.6497665, -0.1180871, 0.6042945,
-0.6747061, -1.086684, 0.4286363, 0.2062943, -0.9906784, 0.111785,
0.8267142, -1.784543, -1.561615, -1.007119, -0.6332595, -1.107667,
-0.6721798, 0.0634, 0.1228354, -1.41257, -0.00162, 0.1837752,
-0.3076835, -0.5630923, -1.247347, -0.2751805, 0.9607666, 0.5469976,
-0.3865913, -0.2693521, -1.347567, 0.9775242, 0.9699011, -1.084863,
-0.9071805, 0.649987), F = c(0.4591538, -0.4417025, -1.359395,
-0.2941213, 0.9557736, 0.0489, 0.8010427, 0.8289859, 1.525705,
0.8249512, -0.7795842, -0.2815648, -1.607204, -2.063595, -0.5948904,
1.318963, -0.422867, -1.242612, -0.5462019, 1.265098, 1.308775,
0.2138544, 0.1100373, 0.0955, 0.1504445, -0.654495, -0.9949232,
-0.3433218, 0.2200913, -0.5812335, -1.16412, 1.725803, 1.462846,
-0.2685312, -0.7131541, 0.8674642, 0.1434308, 0.6649086, -0.2836231,
1.011171, 1.227065, -0.4076338, -0.2451349, 1.500328, -0.3398285,
-0.2637176, 0.2768139, -0.7930014, -1.186443, -1.589864, -0.268713,
1.716344, 1.655646, -0.0696, 0.3210001, 1.54118, -0.5956404,
1.192839, -1.143002, -0.1229445, -1.007617, 0.5116903, -0.1294708,
0.4975231, 0.6975465, -0.9618053, 1.400303, 0.8693725, 1.935434,
1.490129, -0.1925304, -1.584169, 1.633565, -0.9840832, -0.4863658,
-1.879413, -0.6335605, 1.776826, -0.6738441, -1.158889, -0.6118617,
-0.1720929, -1.136563, 1.761316, 0.0408, 0.9216075, -0.7774346,
-0.3991293, -1.565672, -0.4566557, -0.1506024, -0.7665204, 0.1048304,
-1.066744, -0.6170129, 0.5299917, -1.061891, -1.259606, 1.569042,
-0.0407, -0.4636387, -1.112958, -0.1084111, 0.7898362, 1.212461,
-1.02738, 0.7161179, -1.503321, 1.081438, 0.8915679, -0.4056812,
1.241801, -0.0242), M = c(1.871017, 0.9996752, -0.7870979, 1.064545,
-1.689601, -0.3018643, 1.88244, -0.8268481, 0.9663578, -1.42123,
-1.180585, 0.2628357, -0.171538, 1.955883, 1.621714, -0.2572742,
1.086263, -0.8372855, 0.7002838, 1.661519, -1.298887, 0.6245486,
1.899476, -0.2381713, -0.9496545, 0.0396, 0.2139787, -1.119811,
-0.2978846, 0.3680027, 0.191265, 0.4833405, 1.477369, -1.241489,
-0.6909285, 0.0746, -1.185222, -0.3605966, 1.038924, -0.1580821,
0.8105857, -1.105557, -1.39728, 1.396135, -0.9131418, -1.089108,
-0.2248994, 0.1220693, -0.00738, 1.054322, -0.0652, 0.6394631,
-1.354327, -1.364385, 0.0776, -0.2159752, -1.345767, -0.3184824,
-0.9450837, -1.524513, -0.8446239, 1.717726, 0.6830018, 0.8245416,
-0.258855, 1.284419, 0.4350424, -0.0874, 1.127433, 0.1933339,
1.163728, -0.3325101, 0.6792468, -1.73808, -1.603025, -0.7328446,
-0.3346718, 0.154218, -0.0799, 1.193308, 0.7970957, -0.0666,
-0.1044125, 0.5359862, -1.74367, -1.086822, -0.8943136, 1.813055,
-0.4922638, -1.402903, -1.368604, 0.6998838, 1.603749, -0.3893991,
0.4724727, -0.2015617, -1.302567, 1.192791, -0.2543702, 0.3820274,
0.5904814, 0.39335, -0.7998094, -0.4258821, -0.2402134, 1.887602,
0.2859741, 0.6394421, 0.3296217, -0.4768481, -0.9271579, -0.4178298,
0.9319752), A = c(1.392185, -0.3900369, 1.261199, -1.34034, 1.179663,
0.1689164, -0.3248958, -0.145077, -1.052619, 0.5047106, 0.4222224,
0.5631918, -0.2590194, 1.29997, 0.2538769, 0.0119, -0.3699814,
-1.322974, 0.1010328, -1.525166, -0.9178712, 1.061223, -0.0769,
1.561162, -0.383757, -0.6107053, -0.6424132, -0.1334207, -0.7172619,
1.357379, -0.1621245, -0.9258102, 1.190403, -1.567006, 0.0555,
0.7781268, 1.510963, 0.6724311, -1.471632, 0.8010631, 2.013016,
1.295346, -1.65198, -0.3035999, 1.117184, -1.383585, -1.779259,
-1.972591, -1.084347, -0.042, 1.091324, -1.427761, -0.4119558,
-0.7783867, 0.3951252, -0.364529, 0.092, 1.141092, -1.289819,
-1.350992, 0.8888445, -0.1811455, -0.6622333, -0.7942793, 0.5927276,
-0.6182556, 0.3626767, -1.479712, 0.1824882, 1.288104, -1.031188,
0.8364891, -0.2128168, -0.7637377, 0.9009821, -0.1863963, 1.193561,
1.952563, 1.789684, 0.9170451, -0.4016054, 0.657072, -0.54377,
1.172889, 0.2413363, -0.6554105, -0.3052756, 0.7067626, 0.6384293,
1.114955, -0.1679992, -0.2559434, 1.259343, -0.9420805, -0.8246916,
-0.0622, 0.7463045, -0.3551283, 0.9530525, -0.8550238, 0.5273587,
-1.195716, -1.309607, -1.010941, 1.273224, 0.3587953, -1.008615,
1.867905, -1.915486, -0.7199854, 0.6902546, 0.7576268, -0.2066464
), M.1 = c(-0.459597, 0.3073703, 0.6373122, 0.0323, -0.2990144,
1.348451, -1.058786, -0.9588742, -1.054953, 0.088, -0.1543588,
0.8382852, 0.381209, 1.455177, 0.2044187, 1.933988, -1.491534,
-1.131024, 0.8778787, 1.131279, -0.2765887, 0.7649798, 0.1513148,
-1.505724, -0.9782518, 1.056937, 0.2421261, -0.1931907, 0.3331755,
1.636935, 0.8483486, 1.150103, 0.3569795, -0.9200462, -1.248399,
-2.131074, -1.837349, 0.7884224, 0.1044271, 1.618109, -0.0884,
-0.3093464, 0.1750515, 0.3157889, -0.4007615, -0.3602178, -1.577297,
0.3156092, -0.6090513, 0.0777, -0.0739, -0.6141033, 0.2053224,
0.7730377, 0.0937, -0.9651945, 0.5940142, -1.869726, -0.9225557,
1.613315, 0.9881144, -0.5748347, -0.4094839, -1.146461, -0.1883968,
0.0229, 0.0222, -0.839798, -1.156032, 1.79293, 1.093842, 0.0501,
0.9138928, 0.7618006, 1.250165, -0.5041265, -0.3824979, 1.1509,
-1.064404, 0.1799515, 1.721967, -1.418593, 0.9714718, 1.813877,
-0.2158474, -1.854743, 0.1794739, 0.9863014, -0.00756, -0.1975708,
2.630607, -0.2897428, -0.1823791, -0.2188942, 0.1931569, -0.4849184,
-0.910131, 0.330787, -1.41867, -1.686491, -0.4433936, -1.031551,
-1.176649, -0.5566295, 1.134091, 0.7463202, -0.6417032, 0.4953422,
-0.6160501, 0.8935812, -1.324298, 0.9829205, 1.150733), J.1 = c(1.825126,
-0.5984555, 0.5062206, 0.2729266, -0.0121, 0.3048763, 0.1185485,
-1.452631, 0.8458623, -0.6238015, 1.501945, -0.9960235, 0.3034413,
1.115355, -1.548629, -0.7492623, -0.3663574, -0.3106384, 0.4708462,
1.154669, 0.1342134, 1.176006, -0.179569, -0.2387322, 0.2095732,
0.263253, -0.9764008, -0.2424318, -1.509435, -0.8619977, -0.6949487,
1.13643, 0.3285941, -0.4237518, -0.6995585, 1.141431, -0.8279015,
-0.2238075, -0.5552112, 1.712743, 0.9339596, 0.7134116, -1.569646,
-1.354327, -2.151799, 0.3125413, 1.392763, 2.343378, 1.500511,
-1.07474, -0.3640471, -1.174823, -0.8083484, -0.8629019, 0.1802151,
-0.8400947, -0.6961728, 0.6121192, -0.158193, -0.6731861, -1.164061,
0.4841825, -1.099666, -1.828531, 1.224967, -0.1096543, 0.315272,
-0.7347631, 1.474177, 0.189875, 0.9930706, 1.00275, -0.3786205,
0.9757372, 0.7885385, 0.3145336, -0.1258672, 0.710925, 1.03332,
0.7255082, 0.1398514, 0.1243291, 0.5082635, 0.2700605, 2.298389,
-0.3160264, -1.028077, 0.8622152, 1.412863, -0.5811861, -0.0531,
0.9467085, 0.0786, -0.6774637, 0.5012567, 0.0711, -0.3342393,
-0.5698247, -0.2223169, -1.402855, 0.958059, -0.4716635, -2.096799,
-1.816265, -0.1956688, 0.5804866, -1.539355, -0.0941, -0.4405876,
1.56924, 0.2990377, -1.507233, 1.800162), J.2 = c(0.7125305,
-0.2484601, -0.1309015, -1.607252, -1.249372, 0.0415, 0.3784786,
0.4004564, -1.373159, 1.473249, 1.253015, 0.5879295, 0.2819284,
0.1612775, -0.0827, 0.0441, -0.7687836, 0.4403304, 1.202746,
-0.9197539, -0.1688939, -1.780381, 0.4153456, -0.5441434, -0.0481,
0.7404298, -0.4266277, -0.9788033, 1.081349, -1.615727, -0.390704,
-0.6905217, 1.253196, 0.2652828, 0.646424, -1.066357, -0.00207,
-1.155523, -0.6725245, -0.2743259, -0.3313848, 0.5575091, 1.044034,
0.3188159, -1.475527, -0.4916094, 1.162765, 0.9864765, 1.109815,
0.0177, -0.6357729, -1.168194, -1.492512, 0.1192912, 1.425088,
-1.508932, -1.239281, -1.210208, -1.149243, -1.427692, 0.0798,
-0.5581351, -0.1625799, 0.2180536, -0.3759806, 0.2217173, -0.2400341,
1.483425, 1.441966, 1.171917, 1.379586, -0.1496088, -0.6433921,
2.09978, 0.8546344, 0.2083152, 0.631144, 0.3003181, -0.8270686,
1.175304, 1.417394, 1.004064, 0.2477521, 0.6266472, -0.7291934,
0.5905515, -0.9555936, 0.5712249, -1.173295, -0.00711, 1.255848,
-1.226201, 0.2382776, -1.697067, -1.16022, -0.4587435, 1.856619,
1.517898, 0.0553, 0.7973539, -0.0488, 1.606414, 1.556608, 0.9845491,
-0.0782, 0.0774, -0.5242269, 1.876367, -1.416478, -1.027787,
-0.421659, -1.592346, -1.424157), A.1 = c(0.7710939, 0.0543,
-0.5300472, 0.6592121, -1.153847, -0.1456997, -1.832444, 0.3726975,
-1.555021, -0.1779477, 0.853007, 0.0148, 1.405779, 0.0653, 0.7474295,
-0.9215167, 0.5334297, 0.8162999, -0.3440735, -0.2200963, -1.429803,
-0.0353, -1.46344, 0.2656482, 0.6850917, 0.3424074, 2.003194,
1.554138, -0.8998712, 0.9580757, 0.2230041, 0.2162019, 1.065416,
-0.0352, -0.6884875, 0.7631074, 2.31387, 0.8385554, -1.21593,
1.103421, -0.2796364, -1.717311, -1.118207, 0.3429681, 0.6491678,
-1.641407, 1.391316, -0.7211239, -0.3269602, 0.3379903, 0.8097239,
-1.095252, -0.8706113, 0.9977409, 1.415604, 0.3823287, -0.53202,
1.815458, 0.5080889, -0.619583, -0.5816615, -1.347994, -0.2950751,
0.00293, -1.013928, 0.6205906, -0.229311, -0.0918, 0.3008375,
0.3231607, 0.0565, 1.937777, -0.7516724, 0.4014818, -1.14229,
0.0812, 1.433859, -0.9256708, 0.9253611, -0.7319795, -1.178572,
-0.6748386, 1.244621, -0.5254955, -0.5324911, -0.3484317, 0.6396209,
-0.8255401, 1.461768, -0.9260288, 1.208898, -2.027193, -1.250234,
1.360385, 1.20246, 1.352473, 0.747547, -0.7985137, -0.2918135,
-1.429048, -1.08267, -0.226564, -1.423707, 1.778427, 0.5396544,
0.9709455, 0.9165762, -0.2737122, -0.6247987, -0.4211569, -1.091536,
-0.9024249, -0.4648108), S = c(-0.8618388, -0.0332, -2.145797,
1.858552, -0.2969203, 0.14438, 0.4080206, 1.465032, 0.9768468,
-1.4789, 0.2597017, 2.307055, 0.2776116, 0.506233, -0.0605, -1.754613,
-1.510066, -0.4301712, -1.690894, -0.5364874, -0.2276098, 0.8183981,
0.9121475, -0.2545718, 0.276076, -0.6841297, 0.1504795, 0.4432018,
0.365016, -0.1197473, 0.2825312, -0.35693, 0.1777097, 1.29534,
-0.1185746, 0.2778297, 0.000208, 0.5252196, 0.4327488, -0.2277896,
1.49888, -1.133052, 0.7170076, -0.5383621, -1.494164, -0.2049331,
-0.5630803, -0.6943023, -0.0121, -0.2480845, -0.5522097, -0.4257083,
-0.5035902, -0.2110623, 1.901829, 0.5416803, 0.2940297, -0.2385825,
-0.1606006, -0.6408279, -1.996327, -0.0744, -1.030415, 1.219432,
-0.5174201, -0.5638925, -0.2753139, 1.393646, -1.120592, -0.0916,
0.881043, 1.116105, -1.002848, 1.251612, -1.37734, 1.755553,
0.8505045, 1.61046, -1.215773, -0.2731214, 0.8397942, -1.808574,
-1.323098, -0.1434434, -0.2961432, -1.331223, -1.040429, 0.5865396,
1.883039, -0.8122656, 0.1586151, 0.6313211, 0.7063697, -0.9452625,
1.77178, 2.067997, -0.1469796, 0.543735, -0.5135865, 0.1696817,
1.98517, 0.2124236, -0.3413171, 0.5659797, -1.424213, -1.178379,
0.8146986, 0.6695309, -1.679428, 0.7691776, -0.9977649, 0.3209742,
1.221028), O = c(1.41081, 0.2794146, 0.7500096, 0.2865539, 1.756024,
-0.9420308, -1.534693, 0.8799208, -0.8840324, 0.657547, -0.1988259,
0.8938275, -1.497176, 1.160732, 0.7338172, 1.519444, 1.143451,
2.062596, 1.041898, -0.8042107, -1.311448, 1.492421, -0.8708527,
-1.280516, -0.977245, -0.4174474, 0.5002149, -0.0074, -1.076548,
0.2027731, -0.5576773, 0.9159288, 0.628099, -0.0279, -1.177137,
0.8651672, 0.1002702, 1.668067, 2.096398, 1.163112, 0.5318853,
-0.4009511, -1.126641, 1.524528, -0.3486073, 1.72486, 0.3027355,
-0.9869668, -1.523738, 1.478759, -0.5618216, 0.8416752, -1.394072,
-0.6274928, -0.4747858, -1.009026, -0.7476265, 0.0703, -0.7152165,
0.545657, -1.342295, -1.503654, -0.7281811, 0.5582658, -1.318162,
-0.2957245, -0.993159, 0.5168112, -1.310361, 0.2813013, -0.7797307,
1.548533, -1.0072, 0.5857817, 1.606338, 0.6956402, -1.187455,
-1.363752, 0.2583569, 0.5203429, 0.2434425, -0.8046308, -1.114945,
-0.6434187, -0.9872744, -0.5792918, 0.4110919, -1.258956, -0.616523,
-0.3439566, 0.8936544, 0.2170967, -1.169243, 0.892866, -1.06335,
0.2329752, 0.6772005, 1.275011, 0.5593982, -1.444531, -0.2763905,
0.9387801, 1.232073, -0.6661146, 0.1706444, -0.2514986, 0.9861698,
0.3247585, 1.582411, 0.2701326, -0.0097, 0.2282059, -1.418496
), N = c(-1.509117, -1.865568, -0.9207457, 1.589874, 0.382475,
0.2372435, 0.1056492, -0.2351283, 0.0642, 1.678718, -0.5379919,
0.4989375, 1.576607, -0.684436, 0.6053467, -0.4453632, 0.3452958,
1.707276, 0.6281493, 0.8101255, 1.759663, 0.1725115, -1.197022,
0.7000259, 0.7414397, -1.926519, -0.5840425, -0.0826, 0.7428133,
-0.5476953, 0.7237629, -1.129797, 0.9455895, -0.6096208, -0.6842518,
0.00181, 0.9162412, -1.274803, -1.203836, -0.847842, 0.8018484,
1.195398, 0.9078937, 0.2084386, -1.377868, 1.344439, 1.657746,
-0.9019613, 1.267303, 0.0347, -0.9681922, 0.8730431, -0.7356324,
0.4806201, 0.4684249, -0.3170492, 1.126324, 0.7814922, 1.304149,
1.999495, -0.2693311, 1.716548, -1.467723, 0.00245, 0.4545638,
1.448339, -1.192959, -0.0747, -0.6172311, -0.4099933, -0.4685052,
0.556715, -1.523987, 0.4994395, -0.9713943, 0.3854924, 0.246838,
0.0763, -0.1699395, 0.5965068, 1.380759, -1.121356, -0.7884063,
0.1874816, 0.5991878, -1.553753, 1.40589, -1.189748, -0.9560809,
-1.059296, -1.190311, -0.6166247, -0.00346, -0.597102, 0.4561315,
0.9741255, -0.8903497, 0.8815181, -0.3522395, -1.083957, 1.553848,
0.8013645, -1.448561, 1.096503, 0.3007325, -1.080419, 0.627004,
-1.01452, -1.32398, -0.1690037, -1.808708, -0.8492975, -0.420956
), D = c(0.2536002, 0.9746647, 0.0391, -0.5228497, 0.1569641,
1.047966, 0.0229, -0.0995, 0.2635663, -0.6151057, 0.9903812,
-0.3476267, -0.9942705, -1.006192, -1.525466, -0.7323552, 0.2951043,
1.434593, 1.776893, -0.472288, -0.7126557, -0.7370189, 1.95417,
-1.370966, 0.7726845, 0.7082534, -0.6715661, 1.17026, -1.16282,
1.173137, -0.4252348, -0.9583436, -0.4809905, -1.418637, 0.2530024,
-1.122147, -0.0234, 0.99437, 0.4095966, 0.729747, -0.2727098,
-0.6143018, 1.646983, -0.8654616, 0.0658, 0.8169893, 1.01281,
-1.794421, 0.788344, -0.1552048, -1.113021, 0.5335623, -0.4326706,
0.2005343, -0.2204396, 1.86017, 0.1751825, -1.363381, 0.6559588,
0.1089933, -0.6156067, -0.1475329, 1.435637, -0.051, -0.9724815,
-0.2217541, 0.2237121, -0.2329498, 2.171139, 0.5472844, 1.38426,
-1.755075, -0.5630907, 0.31985, -1.853139, 0.8960767, -0.8075317,
0.2993207, -0.641555, 1.363514, 0.3422053, 0.4911866, -1.111221,
-0.0137, -0.6198144, -1.292335, 1.118542, -0.000946, -1.619747,
1.677535, -0.8993699, -0.3782237, 0.4151115, -0.2513984, 0.7183175,
1.229746, 1.615256, -1.024167, 0.9041114, -0.6676438, -0.2487,
-1.408996, -0.265974, -1.116754, -0.1568737, -1.831107, 1.065047,
0.9980727, 0.935714, 1.137962, -1.070733, 1.876622, -1.579149
)), .Names = c("year", "J", "F", "M", "A", "M.1", "J.1", "J.2",
"A.1", "S", "O", "N", "D"), class = "data.frame", row.names = c(NA,
-113L))



On 6 April 2015 at 22:22, John Kane <jrkrideau at inbox.com> wrote:

> Reproducibility
> https://github.com/hadley/devtools/wiki/Reproducibility
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: catalinroibu at gmail.com
> > Sent: Mon, 6 Apr 2015 20:16:39 +0300
> > To: r-help at r-project.org
> > Subject: [R] stripchart
> >
> > Dear all!
> >
> > I have a problem! I want to plot temperature anomalies per months until
> > 1901-2014. For this I want to make a stripchart. I used the specified
> > command, but I want to plot the extreme values with full dots  above 90th
> > and bellow 10th percentile, and the normal values with hallow dots.
> >
> > Please help me how to succeed with that!
> >
> > Thank you!
> >
> > ?Best regards!
> >
> > Catalin
> >
> > --
> > ---
> > Catalin-Constantin ROIBU
> > Lecturer PhD, Forestry engineer
> > Forestry Faculty of Suceava
> > Str. Universitatii no. 13, Suceava, 720229, Romania
> > office phone     +4 0230 52 29 78, ext. 531
> > mobile phone   +4 0745 53 18 01
> >                        +4 0766 71 76 58
> > FAX:                +4 0230 52 16 64
> > silvic.usv.ro
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>


-- 
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

	[[alternative HTML version deleted]]


From catalinroibu at gmail.com  Mon Apr  6 22:01:54 2015
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 6 Apr 2015 23:01:54 +0300
Subject: [R] stripchart
In-Reply-To: <CAEW+BDKZDwsr1cQ6s3paPXgaWXj8LOzN0O8FzVSpn-__zgQHGQ@mail.gmail.com>
References: <CAEW+BD+LEP_8CBVvCVHkEyOp0hfhGzJriTYi217jGN-jhm80Qw@mail.gmail.com>
	<E732B2D5F1E.000008A7jrkrideau@inbox.com>
	<CAEW+BDKZDwsr1cQ6s3paPXgaWXj8LOzN0O8FzVSpn-__zgQHGQ@mail.gmail.com>
Message-ID: <CAEW+BDL7FzKi6rmwYf5MZc6L51uO3wkvrf7qXJrC0bC1vjHGOw@mail.gmail.com>

?Mi data is like that:
i tried:

stripchart(spei[, 1:3], method="jitter", xlim=c(1,2.5),at=c(1.25, 1.75,
2.25),offset=1/2,vertical=TRUE, pch=19, las=1, subset(spei,
speia,1]==quantile(spei[,1],c(.10,.90))))


structure(list(year = 1901:2013, J = c(1.547878, -1.100605, -0.4222952,
-1.221505, -0.2250523, -0.1260924, -0.6251569, -0.7348371, 0.9646313,
1.21345, 0.9746932, 0.5155271, -0.3323591, -0.6689715, 0.8461724,
1.772659, 1.436295, -1.108881, -1.196227, 1.445744, -0.0565,
0.7037539, 1.119812, -0.6622664, -0.5224946, 1.041975, 0.824515,
-0.8732078, 1.436339, -1.733533, -0.5700181, 0.1557751, 1.168567,
0.0399, 0.4697068, -1.099068, 0.985188, -0.5109026, -1.066961,
1.542147, 1.586152, 1.397714, 1.277232, -1.071034, 1.539472,
-1.380059, 1.644268, 1.464481, -1.238555, -0.4090864, -1.280815,
0.2857544, 1.24601, -0.5919045, -0.2339949, 0.2059847, 0.3540879,
-0.1751796, 0.8592942, 0.9626673, 0.400106, -0.4759586, 2.004117,
-1.320636, 0.9035271, 1.80419, -0.2640611, 1.058896, -0.6948445,
0.913681, -0.149598, -0.5239062, -1.011054, -1.345659, -1.216435,
0.85655, -0.3159549, -1.610421, 0.6497665, -0.1180871, 0.6042945,
-0.6747061, -1.086684, 0.4286363, 0.2062943, -0.9906784, 0.111785,
0.8267142, -1.784543, -1.561615, -1.007119, -0.6332595, -1.107667,
-0.6721798, 0.0634, 0.1228354, -1.41257, -0.00162, 0.1837752,
-0.3076835, -0.5630923, -1.247347, -0.2751805, 0.9607666, 0.5469976,
-0.3865913, -0.2693521, -1.347567, 0.9775242, 0.9699011, -1.084863,
-0.9071805, 0.649987), F = c(0.4591538, -0.4417025, -1.359395,
-0.2941213, 0.9557736, 0.0489, 0.8010427, 0.8289859, 1.525705,
0.8249512, -0.7795842, -0.2815648, -1.607204, -2.063595, -0.5948904,
1.318963, -0.422867, -1.242612, -0.5462019, 1.265098, 1.308775,
0.2138544, 0.1100373, 0.0955, 0.1504445, -0.654495, -0.9949232,
-0.3433218, 0.2200913, -0.5812335, -1.16412, 1.725803, 1.462846,
-0.2685312, -0.7131541, 0.8674642, 0.1434308, 0.6649086, -0.2836231,
1.011171, 1.227065, -0.4076338, -0.2451349, 1.500328, -0.3398285,
-0.2637176, 0.2768139, -0.7930014, -1.186443, -1.589864, -0.268713,
1.716344, 1.655646, -0.0696, 0.3210001, 1.54118, -0.5956404,
1.192839, -1.143002, -0.1229445, -1.007617, 0.5116903, -0.1294708,
0.4975231, 0.6975465, -0.9618053, 1.400303, 0.8693725, 1.935434,
1.490129, -0.1925304, -1.584169, 1.633565, -0.9840832, -0.4863658,
-1.879413, -0.6335605, 1.776826, -0.6738441, -1.158889, -0.6118617,
-0.1720929, -1.136563, 1.761316, 0.0408, 0.9216075, -0.7774346,
-0.3991293, -1.565672, -0.4566557, -0.1506024, -0.7665204, 0.1048304,
-1.066744, -0.6170129, 0.5299917, -1.061891, -1.259606, 1.569042,
-0.0407, -0.4636387, -1.112958, -0.1084111, 0.7898362, 1.212461,
-1.02738, 0.7161179, -1.503321, 1.081438, 0.8915679, -0.4056812,
1.241801, -0.0242), M = c(1.871017, 0.9996752, -0.7870979, 1.064545,
-1.689601, -0.3018643, 1.88244, -0.8268481, 0.9663578, -1.42123,
-1.180585, 0.2628357, -0.171538, 1.955883, 1.621714, -0.2572742,
1.086263, -0.8372855, 0.7002838, 1.661519, -1.298887, 0.6245486,
1.899476, -0.2381713, -0.9496545, 0.0396, 0.2139787, -1.119811,
-0.2978846, 0.3680027, 0.191265, 0.4833405, 1.477369, -1.241489,
-0.6909285, 0.0746, -1.185222, -0.3605966, 1.038924, -0.1580821,
0.8105857, -1.105557, -1.39728, 1.396135, -0.9131418, -1.089108,
-0.2248994, 0.1220693, -0.00738, 1.054322, -0.0652, 0.6394631,
-1.354327, -1.364385, 0.0776, -0.2159752, -1.345767, -0.3184824,
-0.9450837, -1.524513, -0.8446239, 1.717726, 0.6830018, 0.8245416,
-0.258855, 1.284419, 0.4350424, -0.0874, 1.127433, 0.1933339,
1.163728, -0.3325101, 0.6792468, -1.73808, -1.603025, -0.7328446,
-0.3346718, 0.154218, -0.0799, 1.193308, 0.7970957, -0.0666,
-0.1044125, 0.5359862, -1.74367, -1.086822, -0.8943136, 1.813055,
-0.4922638, -1.402903, -1.368604, 0.6998838, 1.603749, -0.3893991,
0.4724727, -0.2015617, -1.302567, 1.192791, -0.2543702, 0.3820274,
0.5904814, 0.39335, -0.7998094, -0.4258821, -0.2402134, 1.887602,
0.2859741, 0.6394421, 0.3296217, -0.4768481, -0.9271579, -0.4178298,
0.9319752), A = c(1.392185, -0.3900369, 1.261199, -1.34034, 1.179663,
0.1689164, -0.3248958, -0.145077, -1.052619, 0.5047106, 0.4222224,
0.5631918, -0.2590194, 1.29997, 0.2538769, 0.0119, -0.3699814,
-1.322974, 0.1010328, -1.525166, -0.9178712, 1.061223, -0.0769,
1.561162, -0.383757, -0.6107053, -0.6424132, -0.1334207, -0.7172619,
1.357379, -0.1621245, -0.9258102, 1.190403, -1.567006, 0.0555,
0.7781268, 1.510963, 0.6724311, -1.471632, 0.8010631, 2.013016,
1.295346, -1.65198, -0.3035999, 1.117184, -1.383585, -1.779259,
-1.972591, -1.084347, -0.042, 1.091324, -1.427761, -0.4119558,
-0.7783867, 0.3951252, -0.364529, 0.092, 1.141092, -1.289819,
-1.350992, 0.8888445, -0.1811455, -0.6622333, -0.7942793, 0.5927276,
-0.6182556, 0.3626767, -1.479712, 0.1824882, 1.288104, -1.031188,
0.8364891, -0.2128168, -0.7637377, 0.9009821, -0.1863963, 1.193561,
1.952563, 1.789684, 0.9170451, -0.4016054, 0.657072, -0.54377,
1.172889, 0.2413363, -0.6554105, -0.3052756, 0.7067626, 0.6384293,
1.114955, -0.1679992, -0.2559434, 1.259343, -0.9420805, -0.8246916,
-0.0622, 0.7463045, -0.3551283, 0.9530525, -0.8550238, 0.5273587,
-1.195716, -1.309607, -1.010941, 1.273224, 0.3587953, -1.008615,
1.867905, -1.915486, -0.7199854, 0.6902546, 0.7576268, -0.2066464
), M.1 = c(-0.459597, 0.3073703, 0.6373122, 0.0323, -0.2990144,
1.348451, -1.058786, -0.9588742, -1.054953, 0.088, -0.1543588,
0.8382852, 0.381209, 1.455177, 0.2044187, 1.933988, -1.491534,
-1.131024, 0.8778787, 1.131279, -0.2765887, 0.7649798, 0.1513148,
-1.505724, -0.9782518, 1.056937, 0.2421261, -0.1931907, 0.3331755,
1.636935, 0.8483486, 1.150103, 0.3569795, -0.9200462, -1.248399,
-2.131074, -1.837349, 0.7884224, 0.1044271, 1.618109, -0.0884,
-0.3093464, 0.1750515, 0.3157889, -0.4007615, -0.3602178, -1.577297,
0.3156092, -0.6090513, 0.0777, -0.0739, -0.6141033, 0.2053224,
0.7730377, 0.0937, -0.9651945, 0.5940142, -1.869726, -0.9225557,
1.613315, 0.9881144, -0.5748347, -0.4094839, -1.146461, -0.1883968,
0.0229, 0.0222, -0.839798, -1.156032, 1.79293, 1.093842, 0.0501,
0.9138928, 0.7618006, 1.250165, -0.5041265, -0.3824979, 1.1509,
-1.064404, 0.1799515, 1.721967, -1.418593, 0.9714718, 1.813877,
-0.2158474, -1.854743, 0.1794739, 0.9863014, -0.00756, -0.1975708,
2.630607, -0.2897428, -0.1823791, -0.2188942, 0.1931569, -0.4849184,
-0.910131, 0.330787, -1.41867, -1.686491, -0.4433936, -1.031551,
-1.176649, -0.5566295, 1.134091, 0.7463202, -0.6417032, 0.4953422,
-0.6160501, 0.8935812, -1.324298, 0.9829205, 1.150733), J.1 = c(1.825126,
-0.5984555, 0.5062206, 0.2729266, -0.0121, 0.3048763, 0.1185485,
-1.452631, 0.8458623, -0.6238015, 1.501945, -0.9960235, 0.3034413,
1.115355, -1.548629, -0.7492623, -0.3663574, -0.3106384, 0.4708462,
1.154669, 0.1342134, 1.176006, -0.179569, -0.2387322, 0.2095732,
0.263253, -0.9764008, -0.2424318, -1.509435, -0.8619977, -0.6949487,
1.13643, 0.3285941, -0.4237518, -0.6995585, 1.141431, -0.8279015,
-0.2238075, -0.5552112, 1.712743, 0.9339596, 0.7134116, -1.569646,
-1.354327, -2.151799, 0.3125413, 1.392763, 2.343378, 1.500511,
-1.07474, -0.3640471, -1.174823, -0.8083484, -0.8629019, 0.1802151,
-0.8400947, -0.6961728, 0.6121192, -0.158193, -0.6731861, -1.164061,
0.4841825, -1.099666, -1.828531, 1.224967, -0.1096543, 0.315272,
-0.7347631, 1.474177, 0.189875, 0.9930706, 1.00275, -0.3786205,
0.9757372, 0.7885385, 0.3145336, -0.1258672, 0.710925, 1.03332,
0.7255082, 0.1398514, 0.1243291, 0.5082635, 0.2700605, 2.298389,
-0.3160264, -1.028077, 0.8622152, 1.412863, -0.5811861, -0.0531,
0.9467085, 0.0786, -0.6774637, 0.5012567, 0.0711, -0.3342393,
-0.5698247, -0.2223169, -1.402855, 0.958059, -0.4716635, -2.096799,
-1.816265, -0.1956688, 0.5804866, -1.539355, -0.0941, -0.4405876,
1.56924, 0.2990377, -1.507233, 1.800162), J.2 = c(0.7125305,
-0.2484601, -0.1309015, -1.607252, -1.249372, 0.0415, 0.3784786,
0.4004564, -1.373159, 1.473249, 1.253015, 0.5879295, 0.2819284,
0.1612775, -0.0827, 0.0441, -0.7687836, 0.4403304, 1.202746,
-0.9197539, -0.1688939, -1.780381, 0.4153456, -0.5441434, -0.0481,
0.7404298, -0.4266277, -0.9788033, 1.081349, -1.615727, -0.390704,
-0.6905217, 1.253196, 0.2652828, 0.646424, -1.066357, -0.00207,
-1.155523, -0.6725245, -0.2743259, -0.3313848, 0.5575091, 1.044034,
0.3188159, -1.475527, -0.4916094, 1.162765, 0.9864765, 1.109815,
0.0177, -0.6357729, -1.168194, -1.492512, 0.1192912, 1.425088,
-1.508932, -1.239281, -1.210208, -1.149243, -1.427692, 0.0798,
-0.5581351, -0.1625799, 0.2180536, -0.3759806, 0.2217173, -0.2400341,
1.483425, 1.441966, 1.171917, 1.379586, -0.1496088, -0.6433921,
2.09978, 0.8546344, 0.2083152, 0.631144, 0.3003181, -0.8270686,
1.175304, 1.417394, 1.004064, 0.2477521, 0.6266472, -0.7291934,
0.5905515, -0.9555936, 0.5712249, -1.173295, -0.00711, 1.255848,
-1.226201, 0.2382776, -1.697067, -1.16022, -0.4587435, 1.856619,
1.517898, 0.0553, 0.7973539, -0.0488, 1.606414, 1.556608, 0.9845491,
-0.0782, 0.0774, -0.5242269, 1.876367, -1.416478, -1.027787,
-0.421659, -1.592346, -1.424157), A.1 = c(0.7710939, 0.0543,
-0.5300472, 0.6592121, -1.153847, -0.1456997, -1.832444, 0.3726975,
-1.555021, -0.1779477, 0.853007, 0.0148, 1.405779, 0.0653, 0.7474295,
-0.9215167, 0.5334297, 0.8162999, -0.3440735, -0.2200963, -1.429803,
-0.0353, -1.46344, 0.2656482, 0.6850917, 0.3424074, 2.003194,
1.554138, -0.8998712, 0.9580757, 0.2230041, 0.2162019, 1.065416,
-0.0352, -0.6884875, 0.7631074, 2.31387, 0.8385554, -1.21593,
1.103421, -0.2796364, -1.717311, -1.118207, 0.3429681, 0.6491678,
-1.641407, 1.391316, -0.7211239, -0.3269602, 0.3379903, 0.8097239,
-1.095252, -0.8706113, 0.9977409, 1.415604, 0.3823287, -0.53202,
1.815458, 0.5080889, -0.619583, -0.5816615, -1.347994, -0.2950751,
0.00293, -1.013928, 0.6205906, -0.229311, -0.0918, 0.3008375,
0.3231607, 0.0565, 1.937777, -0.7516724, 0.4014818, -1.14229,
0.0812, 1.433859, -0.9256708, 0.9253611, -0.7319795, -1.178572,
-0.6748386, 1.244621, -0.5254955, -0.5324911, -0.3484317, 0.6396209,
-0.8255401, 1.461768, -0.9260288, 1.208898, -2.027193, -1.250234,
1.360385, 1.20246, 1.352473, 0.747547, -0.7985137, -0.2918135,
-1.429048, -1.08267, -0.226564, -1.423707, 1.778427, 0.5396544,
0.9709455, 0.9165762, -0.2737122, -0.6247987, -0.4211569, -1.091536,
-0.9024249, -0.4648108), S = c(-0.8618388, -0.0332, -2.145797,
1.858552, -0.2969203, 0.14438, 0.4080206, 1.465032, 0.9768468,
-1.4789, 0.2597017, 2.307055, 0.2776116, 0.506233, -0.0605, -1.754613,
-1.510066, -0.4301712, -1.690894, -0.5364874, -0.2276098, 0.8183981,
0.9121475, -0.2545718, 0.276076, -0.6841297, 0.1504795, 0.4432018,
0.365016, -0.1197473, 0.2825312, -0.35693, 0.1777097, 1.29534,
-0.1185746, 0.2778297, 0.000208, 0.5252196, 0.4327488, -0.2277896,
1.49888, -1.133052, 0.7170076, -0.5383621, -1.494164, -0.2049331,
-0.5630803, -0.6943023, -0.0121, -0.2480845, -0.5522097, -0.4257083,
-0.5035902, -0.2110623, 1.901829, 0.5416803, 0.2940297, -0.2385825,
-0.1606006, -0.6408279, -1.996327, -0.0744, -1.030415, 1.219432,
-0.5174201, -0.5638925, -0.2753139, 1.393646, -1.120592, -0.0916,
0.881043, 1.116105, -1.002848, 1.251612, -1.37734, 1.755553,
0.8505045, 1.61046, -1.215773, -0.2731214, 0.8397942, -1.808574,
-1.323098, -0.1434434, -0.2961432, -1.331223, -1.040429, 0.5865396,
1.883039, -0.8122656, 0.1586151, 0.6313211, 0.7063697, -0.9452625,
1.77178, 2.067997, -0.1469796, 0.543735, -0.5135865, 0.1696817,
1.98517, 0.2124236, -0.3413171, 0.5659797, -1.424213, -1.178379,
0.8146986, 0.6695309, -1.679428, 0.7691776, -0.9977649, 0.3209742,
1.221028), O = c(1.41081, 0.2794146, 0.7500096, 0.2865539, 1.756024,
-0.9420308, -1.534693, 0.8799208, -0.8840324, 0.657547, -0.1988259,
0.8938275, -1.497176, 1.160732, 0.7338172, 1.519444, 1.143451,
2.062596, 1.041898, -0.8042107, -1.311448, 1.492421, -0.8708527,
-1.280516, -0.977245, -0.4174474, 0.5002149, -0.0074, -1.076548,
0.2027731, -0.5576773, 0.9159288, 0.628099, -0.0279, -1.177137,
0.8651672, 0.1002702, 1.668067, 2.096398, 1.163112, 0.5318853,
-0.4009511, -1.126641, 1.524528, -0.3486073, 1.72486, 0.3027355,
-0.9869668, -1.523738, 1.478759, -0.5618216, 0.8416752, -1.394072,
-0.6274928, -0.4747858, -1.009026, -0.7476265, 0.0703, -0.7152165,
0.545657, -1.342295, -1.503654, -0.7281811, 0.5582658, -1.318162,
-0.2957245, -0.993159, 0.5168112, -1.310361, 0.2813013, -0.7797307,
1.548533, -1.0072, 0.5857817, 1.606338, 0.6956402, -1.187455,
-1.363752, 0.2583569, 0.5203429, 0.2434425, -0.8046308, -1.114945,
-0.6434187, -0.9872744, -0.5792918, 0.4110919, -1.258956, -0.616523,
-0.3439566, 0.8936544, 0.2170967, -1.169243, 0.892866, -1.06335,
0.2329752, 0.6772005, 1.275011, 0.5593982, -1.444531, -0.2763905,
0.9387801, 1.232073, -0.6661146, 0.1706444, -0.2514986, 0.9861698,
0.3247585, 1.582411, 0.2701326, -0.0097, 0.2282059, -1.418496
), N = c(-1.509117, -1.865568, -0.9207457, 1.589874, 0.382475,
0.2372435, 0.1056492, -0.2351283, 0.0642, 1.678718, -0.5379919,
0.4989375, 1.576607, -0.684436, 0.6053467, -0.4453632, 0.3452958,
1.707276, 0.6281493, 0.8101255, 1.759663, 0.1725115, -1.197022,
0.7000259, 0.7414397, -1.926519, -0.5840425, -0.0826, 0.7428133,
-0.5476953, 0.7237629, -1.129797, 0.9455895, -0.6096208, -0.6842518,
0.00181, 0.9162412, -1.274803, -1.203836, -0.847842, 0.8018484,
1.195398, 0.9078937, 0.2084386, -1.377868, 1.344439, 1.657746,
-0.9019613, 1.267303, 0.0347, -0.9681922, 0.8730431, -0.7356324,
0.4806201, 0.4684249, -0.3170492, 1.126324, 0.7814922, 1.304149,
1.999495, -0.2693311, 1.716548, -1.467723, 0.00245, 0.4545638,
1.448339, -1.192959, -0.0747, -0.6172311, -0.4099933, -0.4685052,
0.556715, -1.523987, 0.4994395, -0.9713943, 0.3854924, 0.246838,
0.0763, -0.1699395, 0.5965068, 1.380759, -1.121356, -0.7884063,
0.1874816, 0.5991878, -1.553753, 1.40589, -1.189748, -0.9560809,
-1.059296, -1.190311, -0.6166247, -0.00346, -0.597102, 0.4561315,
0.9741255, -0.8903497, 0.8815181, -0.3522395, -1.083957, 1.553848,
0.8013645, -1.448561, 1.096503, 0.3007325, -1.080419, 0.627004,
-1.01452, -1.32398, -0.1690037, -1.808708, -0.8492975, -0.420956
), D = c(0.2536002, 0.9746647, 0.0391, -0.5228497, 0.1569641,
1.047966, 0.0229, -0.0995, 0.2635663, -0.6151057, 0.9903812,
-0.3476267, -0.9942705, -1.006192, -1.525466, -0.7323552, 0.2951043,
1.434593, 1.776893, -0.472288, -0.7126557, -0.7370189, 1.95417,
-1.370966, 0.7726845, 0.7082534, -0.6715661, 1.17026, -1.16282,
1.173137, -0.4252348, -0.9583436, -0.4809905, -1.418637, 0.2530024,
-1.122147, -0.0234, 0.99437, 0.4095966, 0.729747, -0.2727098,
-0.6143018, 1.646983, -0.8654616, 0.0658, 0.8169893, 1.01281,
-1.794421, 0.788344, -0.1552048, -1.113021, 0.5335623, -0.4326706,
0.2005343, -0.2204396, 1.86017, 0.1751825, -1.363381, 0.6559588,
0.1089933, -0.6156067, -0.1475329, 1.435637, -0.051, -0.9724815,
-0.2217541, 0.2237121, -0.2329498, 2.171139, 0.5472844, 1.38426,
-1.755075, -0.5630907, 0.31985, -1.853139, 0.8960767, -0.8075317,
0.2993207, -0.641555, 1.363514, 0.3422053, 0.4911866, -1.111221,
-0.0137, -0.6198144, -1.292335, 1.118542, -0.000946, -1.619747,
1.677535, -0.8993699, -0.3782237, 0.4151115, -0.2513984, 0.7183175,
1.229746, 1.615256, -1.024167, 0.9041114, -0.6676438, -0.2487,
-1.408996, -0.265974, -1.116754, -0.1568737, -1.831107, 1.065047,
0.9980727, 0.935714, 1.137962, -1.070733, 1.876622, -1.579149
)), .Names = c("year", "J", "F", "M", "A", "M.1", "J.1", "J.2",
"A.1", "S", "O", "N", "D"), class = "data.frame", row.names = c(NA,
-113L))

On 6 April 2015 at 22:58, catalin roibu <catalinroibu at gmail.com> wrote:

> original data are something like that:
>
> structure(list(year = 1901:2013, J = c(1.547878, -1.100605, -0.4222952,
> -1.221505, -0.2250523, -0.1260924, -0.6251569, -0.7348371, 0.9646313,
> 1.21345, 0.9746932, 0.5155271, -0.3323591, -0.6689715, 0.8461724,
> 1.772659, 1.436295, -1.108881, -1.196227, 1.445744, -0.0565,
> 0.7037539, 1.119812, -0.6622664, -0.5224946, 1.041975, 0.824515,
> -0.8732078, 1.436339, -1.733533, -0.5700181, 0.1557751, 1.168567,
> 0.0399, 0.4697068, -1.099068, 0.985188, -0.5109026, -1.066961,
> 1.542147, 1.586152, 1.397714, 1.277232, -1.071034, 1.539472,
> -1.380059, 1.644268, 1.464481, -1.238555, -0.4090864, -1.280815,
> 0.2857544, 1.24601, -0.5919045, -0.2339949, 0.2059847, 0.3540879,
> -0.1751796, 0.8592942, 0.9626673, 0.400106, -0.4759586, 2.004117,
> -1.320636, 0.9035271, 1.80419, -0.2640611, 1.058896, -0.6948445,
> 0.913681, -0.149598, -0.5239062, -1.011054, -1.345659, -1.216435,
> 0.85655, -0.3159549, -1.610421, 0.6497665, -0.1180871, 0.6042945,
> -0.6747061, -1.086684, 0.4286363, 0.2062943, -0.9906784, 0.111785,
> 0.8267142, -1.784543, -1.561615, -1.007119, -0.6332595, -1.107667,
> -0.6721798, 0.0634, 0.1228354, -1.41257, -0.00162, 0.1837752,
> -0.3076835, -0.5630923, -1.247347, -0.2751805, 0.9607666, 0.5469976,
> -0.3865913, -0.2693521, -1.347567, 0.9775242, 0.9699011, -1.084863,
> -0.9071805, 0.649987), F = c(0.4591538, -0.4417025, -1.359395,
> -0.2941213, 0.9557736, 0.0489, 0.8010427, 0.8289859, 1.525705,
> 0.8249512, -0.7795842, -0.2815648, -1.607204, -2.063595, -0.5948904,
> 1.318963, -0.422867, -1.242612, -0.5462019, 1.265098, 1.308775,
> 0.2138544, 0.1100373, 0.0955, 0.1504445, -0.654495, -0.9949232,
> -0.3433218, 0.2200913, -0.5812335, -1.16412, 1.725803, 1.462846,
> -0.2685312, -0.7131541, 0.8674642, 0.1434308, 0.6649086, -0.2836231,
> 1.011171, 1.227065, -0.4076338, -0.2451349, 1.500328, -0.3398285,
> -0.2637176, 0.2768139, -0.7930014, -1.186443, -1.589864, -0.268713,
> 1.716344, 1.655646, -0.0696, 0.3210001, 1.54118, -0.5956404,
> 1.192839, -1.143002, -0.1229445, -1.007617, 0.5116903, -0.1294708,
> 0.4975231, 0.6975465, -0.9618053, 1.400303, 0.8693725, 1.935434,
> 1.490129, -0.1925304, -1.584169, 1.633565, -0.9840832, -0.4863658,
> -1.879413, -0.6335605, 1.776826, -0.6738441, -1.158889, -0.6118617,
> -0.1720929, -1.136563, 1.761316, 0.0408, 0.9216075, -0.7774346,
> -0.3991293, -1.565672, -0.4566557, -0.1506024, -0.7665204, 0.1048304,
> -1.066744, -0.6170129, 0.5299917, -1.061891, -1.259606, 1.569042,
> -0.0407, -0.4636387, -1.112958, -0.1084111, 0.7898362, 1.212461,
> -1.02738, 0.7161179, -1.503321, 1.081438, 0.8915679, -0.4056812,
> 1.241801, -0.0242), M = c(1.871017, 0.9996752, -0.7870979, 1.064545,
> -1.689601, -0.3018643, 1.88244, -0.8268481, 0.9663578, -1.42123,
> -1.180585, 0.2628357, -0.171538, 1.955883, 1.621714, -0.2572742,
> 1.086263, -0.8372855, 0.7002838, 1.661519, -1.298887, 0.6245486,
> 1.899476, -0.2381713, -0.9496545, 0.0396, 0.2139787, -1.119811,
> -0.2978846, 0.3680027, 0.191265, 0.4833405, 1.477369, -1.241489,
> -0.6909285, 0.0746, -1.185222, -0.3605966, 1.038924, -0.1580821,
> 0.8105857, -1.105557, -1.39728, 1.396135, -0.9131418, -1.089108,
> -0.2248994, 0.1220693, -0.00738, 1.054322, -0.0652, 0.6394631,
> -1.354327, -1.364385, 0.0776, -0.2159752, -1.345767, -0.3184824,
> -0.9450837, -1.524513, -0.8446239, 1.717726, 0.6830018, 0.8245416,
> -0.258855, 1.284419, 0.4350424, -0.0874, 1.127433, 0.1933339,
> 1.163728, -0.3325101, 0.6792468, -1.73808, -1.603025, -0.7328446,
> -0.3346718, 0.154218, -0.0799, 1.193308, 0.7970957, -0.0666,
> -0.1044125, 0.5359862, -1.74367, -1.086822, -0.8943136, 1.813055,
> -0.4922638, -1.402903, -1.368604, 0.6998838, 1.603749, -0.3893991,
> 0.4724727, -0.2015617, -1.302567, 1.192791, -0.2543702, 0.3820274,
> 0.5904814, 0.39335, -0.7998094, -0.4258821, -0.2402134, 1.887602,
> 0.2859741, 0.6394421, 0.3296217, -0.4768481, -0.9271579, -0.4178298,
> 0.9319752), A = c(1.392185, -0.3900369, 1.261199, -1.34034, 1.179663,
> 0.1689164, -0.3248958, -0.145077, -1.052619, 0.5047106, 0.4222224,
> 0.5631918, -0.2590194, 1.29997, 0.2538769, 0.0119, -0.3699814,
> -1.322974, 0.1010328, -1.525166, -0.9178712, 1.061223, -0.0769,
> 1.561162, -0.383757, -0.6107053, -0.6424132, -0.1334207, -0.7172619,
> 1.357379, -0.1621245, -0.9258102, 1.190403, -1.567006, 0.0555,
> 0.7781268, 1.510963, 0.6724311, -1.471632, 0.8010631, 2.013016,
> 1.295346, -1.65198, -0.3035999, 1.117184, -1.383585, -1.779259,
> -1.972591, -1.084347, -0.042, 1.091324, -1.427761, -0.4119558,
> -0.7783867, 0.3951252, -0.364529, 0.092, 1.141092, -1.289819,
> -1.350992, 0.8888445, -0.1811455, -0.6622333, -0.7942793, 0.5927276,
> -0.6182556, 0.3626767, -1.479712, 0.1824882, 1.288104, -1.031188,
> 0.8364891, -0.2128168, -0.7637377, 0.9009821, -0.1863963, 1.193561,
> 1.952563, 1.789684, 0.9170451, -0.4016054, 0.657072, -0.54377,
> 1.172889, 0.2413363, -0.6554105, -0.3052756, 0.7067626, 0.6384293,
> 1.114955, -0.1679992, -0.2559434, 1.259343, -0.9420805, -0.8246916,
> -0.0622, 0.7463045, -0.3551283, 0.9530525, -0.8550238, 0.5273587,
> -1.195716, -1.309607, -1.010941, 1.273224, 0.3587953, -1.008615,
> 1.867905, -1.915486, -0.7199854, 0.6902546, 0.7576268, -0.2066464
> ), M.1 = c(-0.459597, 0.3073703, 0.6373122, 0.0323, -0.2990144,
> 1.348451, -1.058786, -0.9588742, -1.054953, 0.088, -0.1543588,
> 0.8382852, 0.381209, 1.455177, 0.2044187, 1.933988, -1.491534,
> -1.131024, 0.8778787, 1.131279, -0.2765887, 0.7649798, 0.1513148,
> -1.505724, -0.9782518, 1.056937, 0.2421261, -0.1931907, 0.3331755,
> 1.636935, 0.8483486, 1.150103, 0.3569795, -0.9200462, -1.248399,
> -2.131074, -1.837349, 0.7884224, 0.1044271, 1.618109, -0.0884,
> -0.3093464, 0.1750515, 0.3157889, -0.4007615, -0.3602178, -1.577297,
> 0.3156092, -0.6090513, 0.0777, -0.0739, -0.6141033, 0.2053224,
> 0.7730377, 0.0937, -0.9651945, 0.5940142, -1.869726, -0.9225557,
> 1.613315, 0.9881144, -0.5748347, -0.4094839, -1.146461, -0.1883968,
> 0.0229, 0.0222, -0.839798, -1.156032, 1.79293, 1.093842, 0.0501,
> 0.9138928, 0.7618006, 1.250165, -0.5041265, -0.3824979, 1.1509,
> -1.064404, 0.1799515, 1.721967, -1.418593, 0.9714718, 1.813877,
> -0.2158474, -1.854743, 0.1794739, 0.9863014, -0.00756, -0.1975708,
> 2.630607, -0.2897428, -0.1823791, -0.2188942, 0.1931569, -0.4849184,
> -0.910131, 0.330787, -1.41867, -1.686491, -0.4433936, -1.031551,
> -1.176649, -0.5566295, 1.134091, 0.7463202, -0.6417032, 0.4953422,
> -0.6160501, 0.8935812, -1.324298, 0.9829205, 1.150733), J.1 = c(1.825126,
> -0.5984555, 0.5062206, 0.2729266, -0.0121, 0.3048763, 0.1185485,
> -1.452631, 0.8458623, -0.6238015, 1.501945, -0.9960235, 0.3034413,
> 1.115355, -1.548629, -0.7492623, -0.3663574, -0.3106384, 0.4708462,
> 1.154669, 0.1342134, 1.176006, -0.179569, -0.2387322, 0.2095732,
> 0.263253, -0.9764008, -0.2424318, -1.509435, -0.8619977, -0.6949487,
> 1.13643, 0.3285941, -0.4237518, -0.6995585, 1.141431, -0.8279015,
> -0.2238075, -0.5552112, 1.712743, 0.9339596, 0.7134116, -1.569646,
> -1.354327, -2.151799, 0.3125413, 1.392763, 2.343378, 1.500511,
> -1.07474, -0.3640471, -1.174823, -0.8083484, -0.8629019, 0.1802151,
> -0.8400947, -0.6961728, 0.6121192, -0.158193, -0.6731861, -1.164061,
> 0.4841825, -1.099666, -1.828531, 1.224967, -0.1096543, 0.315272,
> -0.7347631, 1.474177, 0.189875, 0.9930706, 1.00275, -0.3786205,
> 0.9757372, 0.7885385, 0.3145336, -0.1258672, 0.710925, 1.03332,
> 0.7255082, 0.1398514, 0.1243291, 0.5082635, 0.2700605, 2.298389,
> -0.3160264, -1.028077, 0.8622152, 1.412863, -0.5811861, -0.0531,
> 0.9467085, 0.0786, -0.6774637, 0.5012567, 0.0711, -0.3342393,
> -0.5698247, -0.2223169, -1.402855, 0.958059, -0.4716635, -2.096799,
> -1.816265, -0.1956688, 0.5804866, -1.539355, -0.0941, -0.4405876,
> 1.56924, 0.2990377, -1.507233, 1.800162), J.2 = c(0.7125305,
> -0.2484601, -0.1309015, -1.607252, -1.249372, 0.0415, 0.3784786,
> 0.4004564, -1.373159, 1.473249, 1.253015, 0.5879295, 0.2819284,
> 0.1612775, -0.0827, 0.0441, -0.7687836, 0.4403304, 1.202746,
> -0.9197539, -0.1688939, -1.780381, 0.4153456, -0.5441434, -0.0481,
> 0.7404298, -0.4266277, -0.9788033, 1.081349, -1.615727, -0.390704,
> -0.6905217, 1.253196, 0.2652828, 0.646424, -1.066357, -0.00207,
> -1.155523, -0.6725245, -0.2743259, -0.3313848, 0.5575091, 1.044034,
> 0.3188159, -1.475527, -0.4916094, 1.162765, 0.9864765, 1.109815,
> 0.0177, -0.6357729, -1.168194, -1.492512, 0.1192912, 1.425088,
> -1.508932, -1.239281, -1.210208, -1.149243, -1.427692, 0.0798,
> -0.5581351, -0.1625799, 0.2180536, -0.3759806, 0.2217173, -0.2400341,
> 1.483425, 1.441966, 1.171917, 1.379586, -0.1496088, -0.6433921,
> 2.09978, 0.8546344, 0.2083152, 0.631144, 0.3003181, -0.8270686,
> 1.175304, 1.417394, 1.004064, 0.2477521, 0.6266472, -0.7291934,
> 0.5905515, -0.9555936, 0.5712249, -1.173295, -0.00711, 1.255848,
> -1.226201, 0.2382776, -1.697067, -1.16022, -0.4587435, 1.856619,
> 1.517898, 0.0553, 0.7973539, -0.0488, 1.606414, 1.556608, 0.9845491,
> -0.0782, 0.0774, -0.5242269, 1.876367, -1.416478, -1.027787,
> -0.421659, -1.592346, -1.424157), A.1 = c(0.7710939, 0.0543,
> -0.5300472, 0.6592121, -1.153847, -0.1456997, -1.832444, 0.3726975,
> -1.555021, -0.1779477, 0.853007, 0.0148, 1.405779, 0.0653, 0.7474295,
> -0.9215167, 0.5334297, 0.8162999, -0.3440735, -0.2200963, -1.429803,
> -0.0353, -1.46344, 0.2656482, 0.6850917, 0.3424074, 2.003194,
> 1.554138, -0.8998712, 0.9580757, 0.2230041, 0.2162019, 1.065416,
> -0.0352, -0.6884875, 0.7631074, 2.31387, 0.8385554, -1.21593,
> 1.103421, -0.2796364, -1.717311, -1.118207, 0.3429681, 0.6491678,
> -1.641407, 1.391316, -0.7211239, -0.3269602, 0.3379903, 0.8097239,
> -1.095252, -0.8706113, 0.9977409, 1.415604, 0.3823287, -0.53202,
> 1.815458, 0.5080889, -0.619583, -0.5816615, -1.347994, -0.2950751,
> 0.00293, -1.013928, 0.6205906, -0.229311, -0.0918, 0.3008375,
> 0.3231607, 0.0565, 1.937777, -0.7516724, 0.4014818, -1.14229,
> 0.0812, 1.433859, -0.9256708, 0.9253611, -0.7319795, -1.178572,
> -0.6748386, 1.244621, -0.5254955, -0.5324911, -0.3484317, 0.6396209,
> -0.8255401, 1.461768, -0.9260288, 1.208898, -2.027193, -1.250234,
> 1.360385, 1.20246, 1.352473, 0.747547, -0.7985137, -0.2918135,
> -1.429048, -1.08267, -0.226564, -1.423707, 1.778427, 0.5396544,
> 0.9709455, 0.9165762, -0.2737122, -0.6247987, -0.4211569, -1.091536,
> -0.9024249, -0.4648108), S = c(-0.8618388, -0.0332, -2.145797,
> 1.858552, -0.2969203, 0.14438, 0.4080206, 1.465032, 0.9768468,
> -1.4789, 0.2597017, 2.307055, 0.2776116, 0.506233, -0.0605, -1.754613,
> -1.510066, -0.4301712, -1.690894, -0.5364874, -0.2276098, 0.8183981,
> 0.9121475, -0.2545718, 0.276076, -0.6841297, 0.1504795, 0.4432018,
> 0.365016, -0.1197473, 0.2825312, -0.35693, 0.1777097, 1.29534,
> -0.1185746, 0.2778297, 0.000208, 0.5252196, 0.4327488, -0.2277896,
> 1.49888, -1.133052, 0.7170076, -0.5383621, -1.494164, -0.2049331,
> -0.5630803, -0.6943023, -0.0121, -0.2480845, -0.5522097, -0.4257083,
> -0.5035902, -0.2110623, 1.901829, 0.5416803, 0.2940297, -0.2385825,
> -0.1606006, -0.6408279, -1.996327, -0.0744, -1.030415, 1.219432,
> -0.5174201, -0.5638925, -0.2753139, 1.393646, -1.120592, -0.0916,
> 0.881043, 1.116105, -1.002848, 1.251612, -1.37734, 1.755553,
> 0.8505045, 1.61046, -1.215773, -0.2731214, 0.8397942, -1.808574,
> -1.323098, -0.1434434, -0.2961432, -1.331223, -1.040429, 0.5865396,
> 1.883039, -0.8122656, 0.1586151, 0.6313211, 0.7063697, -0.9452625,
> 1.77178, 2.067997, -0.1469796, 0.543735, -0.5135865, 0.1696817,
> 1.98517, 0.2124236, -0.3413171, 0.5659797, -1.424213, -1.178379,
> 0.8146986, 0.6695309, -1.679428, 0.7691776, -0.9977649, 0.3209742,
> 1.221028), O = c(1.41081, 0.2794146, 0.7500096, 0.2865539, 1.756024,
> -0.9420308, -1.534693, 0.8799208, -0.8840324, 0.657547, -0.1988259,
> 0.8938275, -1.497176, 1.160732, 0.7338172, 1.519444, 1.143451,
> 2.062596, 1.041898, -0.8042107, -1.311448, 1.492421, -0.8708527,
> -1.280516, -0.977245, -0.4174474, 0.5002149, -0.0074, -1.076548,
> 0.2027731, -0.5576773, 0.9159288, 0.628099, -0.0279, -1.177137,
> 0.8651672, 0.1002702, 1.668067, 2.096398, 1.163112, 0.5318853,
> -0.4009511, -1.126641, 1.524528, -0.3486073, 1.72486, 0.3027355,
> -0.9869668, -1.523738, 1.478759, -0.5618216, 0.8416752, -1.394072,
> -0.6274928, -0.4747858, -1.009026, -0.7476265, 0.0703, -0.7152165,
> 0.545657, -1.342295, -1.503654, -0.7281811, 0.5582658, -1.318162,
> -0.2957245, -0.993159, 0.5168112, -1.310361, 0.2813013, -0.7797307,
> 1.548533, -1.0072, 0.5857817, 1.606338, 0.6956402, -1.187455,
> -1.363752, 0.2583569, 0.5203429, 0.2434425, -0.8046308, -1.114945,
> -0.6434187, -0.9872744, -0.5792918, 0.4110919, -1.258956, -0.616523,
> -0.3439566, 0.8936544, 0.2170967, -1.169243, 0.892866, -1.06335,
> 0.2329752, 0.6772005, 1.275011, 0.5593982, -1.444531, -0.2763905,
> 0.9387801, 1.232073, -0.6661146, 0.1706444, -0.2514986, 0.9861698,
> 0.3247585, 1.582411, 0.2701326, -0.0097, 0.2282059, -1.418496
> ), N = c(-1.509117, -1.865568, -0.9207457, 1.589874, 0.382475,
> 0.2372435, 0.1056492, -0.2351283, 0.0642, 1.678718, -0.5379919,
> 0.4989375, 1.576607, -0.684436, 0.6053467, -0.4453632, 0.3452958,
> 1.707276, 0.6281493, 0.8101255, 1.759663, 0.1725115, -1.197022,
> 0.7000259, 0.7414397, -1.926519, -0.5840425, -0.0826, 0.7428133,
> -0.5476953, 0.7237629, -1.129797, 0.9455895, -0.6096208, -0.6842518,
> 0.00181, 0.9162412, -1.274803, -1.203836, -0.847842, 0.8018484,
> 1.195398, 0.9078937, 0.2084386, -1.377868, 1.344439, 1.657746,
> -0.9019613, 1.267303, 0.0347, -0.9681922, 0.8730431, -0.7356324,
> 0.4806201, 0.4684249, -0.3170492, 1.126324, 0.7814922, 1.304149,
> 1.999495, -0.2693311, 1.716548, -1.467723, 0.00245, 0.4545638,
> 1.448339, -1.192959, -0.0747, -0.6172311, -0.4099933, -0.4685052,
> 0.556715, -1.523987, 0.4994395, -0.9713943, 0.3854924, 0.246838,
> 0.0763, -0.1699395, 0.5965068, 1.380759, -1.121356, -0.7884063,
> 0.1874816, 0.5991878, -1.553753, 1.40589, -1.189748, -0.9560809,
> -1.059296, -1.190311, -0.6166247, -0.00346, -0.597102, 0.4561315,
> 0.9741255, -0.8903497, 0.8815181, -0.3522395, -1.083957, 1.553848,
> 0.8013645, -1.448561, 1.096503, 0.3007325, -1.080419, 0.627004,
> -1.01452, -1.32398, -0.1690037, -1.808708, -0.8492975, -0.420956
> ), D = c(0.2536002, 0.9746647, 0.0391, -0.5228497, 0.1569641,
> 1.047966, 0.0229, -0.0995, 0.2635663, -0.6151057, 0.9903812,
> -0.3476267, -0.9942705, -1.006192, -1.525466, -0.7323552, 0.2951043,
> 1.434593, 1.776893, -0.472288, -0.7126557, -0.7370189, 1.95417,
> -1.370966, 0.7726845, 0.7082534, -0.6715661, 1.17026, -1.16282,
> 1.173137, -0.4252348, -0.9583436, -0.4809905, -1.418637, 0.2530024,
> -1.122147, -0.0234, 0.99437, 0.4095966, 0.729747, -0.2727098,
> -0.6143018, 1.646983, -0.8654616, 0.0658, 0.8169893, 1.01281,
> -1.794421, 0.788344, -0.1552048, -1.113021, 0.5335623, -0.4326706,
> 0.2005343, -0.2204396, 1.86017, 0.1751825, -1.363381, 0.6559588,
> 0.1089933, -0.6156067, -0.1475329, 1.435637, -0.051, -0.9724815,
> -0.2217541, 0.2237121, -0.2329498, 2.171139, 0.5472844, 1.38426,
> -1.755075, -0.5630907, 0.31985, -1.853139, 0.8960767, -0.8075317,
> 0.2993207, -0.641555, 1.363514, 0.3422053, 0.4911866, -1.111221,
> -0.0137, -0.6198144, -1.292335, 1.118542, -0.000946, -1.619747,
> 1.677535, -0.8993699, -0.3782237, 0.4151115, -0.2513984, 0.7183175,
> 1.229746, 1.615256, -1.024167, 0.9041114, -0.6676438, -0.2487,
> -1.408996, -0.265974, -1.116754, -0.1568737, -1.831107, 1.065047,
> 0.9980727, 0.935714, 1.137962, -1.070733, 1.876622, -1.579149
> )), .Names = c("year", "J", "F", "M", "A", "M.1", "J.1", "J.2",
> "A.1", "S", "O", "N", "D"), class = "data.frame", row.names = c(NA,
> -113L))
>
>
>
> On 6 April 2015 at 22:22, John Kane <jrkrideau at inbox.com> wrote:
>
>> Reproducibility
>> https://github.com/hadley/devtools/wiki/Reproducibility
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>> > -----Original Message-----
>> > From: catalinroibu at gmail.com
>> > Sent: Mon, 6 Apr 2015 20:16:39 +0300
>> > To: r-help at r-project.org
>> > Subject: [R] stripchart
>> >
>> > Dear all!
>> >
>> > I have a problem! I want to plot temperature anomalies per months until
>> > 1901-2014. For this I want to make a stripchart. I used the specified
>> > command, but I want to plot the extreme values with full dots  above
>> 90th
>> > and bellow 10th percentile, and the normal values with hallow dots.
>> >
>> > Please help me how to succeed with that!
>> >
>> > Thank you!
>> >
>> > ?Best regards!
>> >
>> > Catalin
>> >
>> > --
>> > ---
>> > Catalin-Constantin ROIBU
>> > Lecturer PhD, Forestry engineer
>> > Forestry Faculty of Suceava
>> > Str. Universitatii no. 13, Suceava, 720229, Romania
>> > office phone     +4 0230 52 29 78, ext. 531
>> > mobile phone   +4 0745 53 18 01
>> >                        +4 0766 71 76 58
>> > FAX:                +4 0230 52 16 64
>> > silvic.usv.ro
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> Check it out at http://mysecurelogon.com/password-manager
>>
>>
>>
>
>
> --
> ---
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                        +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro
>



-- 
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Apr  6 22:17:32 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 06 Apr 2015 21:17:32 +0100
Subject: [R] R crashes upon changing directories, loading files, etc.
In-Reply-To: <60360FC9-8F7E-4EC7-B007-00700F85D6D2@me.com>
References: <60360FC9-8F7E-4EC7-B007-00700F85D6D2@me.com>
Message-ID: <5522E9DC.1040304@stats.ox.ac.uk>

It seems this is not R but R.app (the separate project providing an OS X 
console: see the 'R Installation and Administration' manual).  If so, 
the only appropriate list is R-sig-Mac (see the posting guide).

On 06/04/2015 19:14, Nicole Ford wrote:
> Hello,
>
> I am experiencing an issue, repeatedly, which began today.
>
> Example code:
>
> load(file.choose())  ##sometimes it crashes here/ endless spinner/ other times I can get through.
>
> or: i go up to options at the top to set wd, or select ?file? -> ?open? and it will do the same thing.
>
> I found a page where people were indicating they had this issue, but there was no one responding with a fix.  see below:
>
> bugs.r-project.org/bugzilla/show_bug.cgi?id=14240

Which is about Windows in 2010, and does have a response.

>
>
> I am running :
>
> R version 3.1.3 (2015-03-09) -- "Smooth Sidewalk"
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> On OS X 10.10
>
> Any help/ direction is appreciated.
>
> ~Nicole
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From pdalgd at gmail.com  Mon Apr  6 23:26:53 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Apr 2015 23:26:53 +0200
Subject: [R] R crashes upon changing directories, loading files, etc.
In-Reply-To: <5522E9DC.1040304@stats.ox.ac.uk>
References: <60360FC9-8F7E-4EC7-B007-00700F85D6D2@me.com>
	<5522E9DC.1040304@stats.ox.ac.uk>
Message-ID: <A2FAFA39-35B2-4D48-8C9B-724864A0806D@gmail.com>


> On 06 Apr 2015, at 22:17 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> Nicole Ford wrote:

[snip]
>> 
>> I found a page where people were indicating they had this issue, but there was no one responding with a fix.  see below:
>> 
>> bugs.r-project.org/bugzilla/show_bug.cgi?id=14240
> 
> Which is about Windows in 2010, and does have a response.

It might be noted, though, that this is not the first report from someone having this sort of issue on Yosemite. See e.g. Christopher Swan's note from April 4 on R-sig-Mac.

(This sort of issue tends to be slow to fix. We need to have a developer who can reproduce the issue _and_ is capable of debugging Mac GUI code.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Mon Apr  6 23:55:28 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Apr 2015 14:55:28 -0700
Subject: [R] sort adjacency matrix
In-Reply-To: <CACk-te2kOz9a7nnPfd9ai8L-HuZnx-RWnqJbaiN1hETLUHt7yw@mail.gmail.com>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67C2BF@mb02.ads.tamu.edu>
	<CACk-te2kOz9a7nnPfd9ai8L-HuZnx-RWnqJbaiN1hETLUHt7yw@mail.gmail.com>
Message-ID: <87A751ED-796E-4163-8B8D-5503BCF0B788@comcast.net>


On Apr 6, 2015, at 11:15 AM, Bert Gunter wrote:

> Not quite, David.
> 
> If I understand the OP's query, he wants the ties to be broken by the
> "lexicographic" order (with apologies if I have misused this term) of
> the 1's within the rows. Makes things a bit more interesting.

This should correct the problem:

> M <- as.matrix(m)
> M[ order(rowSums(M=="1"), 
+           apply(M, 1, paste0, collapse=".") ,
+           decreasing=TRUE), ]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    1    1    1    0    0    0    0    0     0
 [2,]    0    0    0    1    1    0    1    0    0     0
 [3,]    1    0    0    0    0    0    0    0    0     0
 [4,]    1    0    0    0    0    0    0    0    0     0
 [5,]    1    0    0    0    0    0    0    0    0     0
 [6,]    0    1    0    0    0    0    0    0    0     0
 [7,]    0    1    0    0    0    0    0    0    0     0
 [8,]    0    0    0    0    1    0    0    0    0     0
 [9,]    0    0    0    0    1    0    0    0    0     0
[10,]    0    0    0    0    0    0    0    0    0     0

The original matrix was sparse and I get this error message when attempting to use 'order' in the i-argument to the `[` method for dgCMatrix: 

Error in m[order(rowSums(m == "1"), apply(m, 1, paste0, collapse = "."),  : 
  error in evaluating the argument 'i' in selecting a method for function '[': Error: not-yet-implemented method for ==(<dgCMatrix>, <character>).
 ->>  Ask the package authors to implement the missing feature.


HTH;
-- 
David.


> Have at it!
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Mon, Apr 6, 2015 at 11:09 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> The answer depends on what kind of matrix/data frame you have. That is why we encourage people to use dput() to create a copy of the sample data in their email. Some combination of order() function the rowSums() function will probably get you what you want. For example,
>> 
>> dat[order(rowSums(dat=="1"), decreasing=TRUE),]
>> 
>> or
>> 
>> dat[order(rowSums(dat), decreasing=TRUE),]
>> 
>> or
>> 
>> dat[order(rowSums(dat, na.rm=TRUE), decreasing=TRUE),]
>> 
>> Note that the order is not unique since there are ties in the number of 1s.
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia Ibrahim
>> Sent: Monday, April 6, 2015 12:18 PM
>> To: r-help at r-project.org
>> Subject: [R] sort adjacency matrix
>> 
>> Dear group
>> i have the following matrix
>> 
>> 1  . . 1 . . 1 . . . .
>> 2  . . . . . . 1 . . .
>> 3  1 . . . 1 . . 1 . 1
>> 4  . . . . . 1 . . . .
>> 5  . . 1 . . . . . . 1
>> 6  1 . . 1 . . . . 1 .
>> 7  . 1 . . . . . 1 . .
>> 8  . . 1 . . . 1 . . 1
>> 9  . . . . . 1 . . . 1
>> 10 . . 1 . 1 . . 1 1 .
>> 
>> I want to sort it according to ones in each row ascending (where max number of ones first)
>> 
>> to be as follow
>> 
>> 3  1 . . . 1 . . 1 . 1
>> 10 . . 1 . 1 . . 1 1 .
>> 6  1 . . 1 . . . . 1 .8  . . 1 . . . 1 . . 11  . . 1 . . 1 . . . .5  . . 1 . . . . . . 17  . 1 . . . . . 1 . .9  . . . . . 1 . . . 12  . . . . . . 1 . . .4  . . . . . 1 . . . .
>> 
>> how can I do this in R
>> thanks in advance
>> 
> 


David Winsemius
Alameda, CA, USA


From marcgg.lamblin at gmail.com  Mon Apr  6 23:55:53 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Mon, 6 Apr 2015 23:55:53 +0200
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CACk-te0tW0fL-fkDDfRY0-nAvC_me4+75=U8aD8gD+Xnd_ssNQ@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
	<CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
	<CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>
	<CACk-te0tW0fL-fkDDfRY0-nAvC_me4+75=U8aD8gD+Xnd_ssNQ@mail.gmail.com>
Message-ID: <CABYYu7vRu7BfoySakgQ5nTNF0zoRMBSPxpLZyCP8otwF6UcApA@mail.gmail.com>

The first solution with diff works for uniform abscissa only with integer
values.

z <- seq(0, 10, length=100)
all(diff(z) == z[2] - z[1] )
## FALSE

In this case, as you recommended, I could use signif or round or a
tolerance for real numbers. In my particular case, in order to set a
tolerance, I need the scale used and I don't have this information. I
prefer to test the "near uniformity".
I didn't know the function zapsmall. It could be useful!
Thanks Sarah and Bert!!!

Marc





2015-04-06 19:51 GMT+02:00 Bert Gunter <gunter.berton at gene.com>:

> ... correction: you need to use absolute value for the comparison, of
> course.
>
> all(abs(diff(z) - z[2] + z[1]) < tol)
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Mon, Apr 6, 2015 at 10:47 AM, Bert Gunter <bgunter at gene.com> wrote:
> > Perhaps ?diff might be useful here:
> >
> > z <- runif(20)
> > all(diff(z) == z[2] - z[1] )
> > ## FALSE
> >
> > z <- seq_len(10)
> > all(diff(z) == z[2] - z[1] )
> > ##TRUE
> >
> > You can use signif or round as before to allow for "near uniformity"
> > or use ?zapsmall or an explicit comparison with a tolerancec instead
> > of ==, e.g. all(diff(z) - z[2] + z[1] < tol)
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Mon, Apr 6, 2015 at 10:11 AM, Marc Lamblin <marcgg.lamblin at gmail.com>
> wrote:
> >> The aim is to control if a given abscissa/grid is uniform or not.
> Abscissa
> >> in generic vector of real ordered numbers.
> >>
> >> Here a reproducibile code:
> >>
> >> # uniform abscissa/grid
> >> abscissa1 <- seq(0, 1, length=100)
> >> # non-uniform abscissa/grid
> >> abscissa2 <- sort(runif(100))
> >>
> >> control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
> >> abscissa1[1:(length(abscissa1) - 1)]) ==
> signif(rep((range(abscissa1)[2] -
> >> range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) - 1)))
> >> control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
> >> abscissa2[1:(length(abscissa2) - 1)]) ==
> signif(rep((range(abscissa2)[2] -
> >> range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) - 1)))
> >>
> >> control1
> >> control2
> >>
> >> As expected control1 is TRUE and control2 is FALSE. Actually in this
> code
> >> it is possible also to use
> >> diff inside signif.
> >> Do you mean that the control to perform can be done in this manner
> >>
> >> if (length(unique(diff(vec))) == 1) {
> >>   control <- TRUE
> >> } else {
> >>   control <- FALSE
> >> }
> >>
> >> I have tried to apply this control on abscissa1 which is uniform but
> >> length(unique(diff(abscissa1))) was greater than one; probably, as you
> >> said, this is due to the fact that in this way I don't take into account
> >> the machine precision.
> >> What I want to understand is if there is a SAFE solution, even if until
> now
> >> this control is working correctly. I have seen in the documentation of
> >> signif that by default the number of digits considered are 6. The
> number of
> >> digits to consider depends on the scale used. It doesn't make sense to
> >> increase the number of digits with respect to default because, in this
> >> case, you are not using an handy scale.
> >> Maybe it could be better directly to ask user if the abscissa passed as
> >> argument is uniform or not.
> >> Thanks a lot for the link!!!
> >>
> >> Marc
> >>
> >>
> >>
> >>
> >> 2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
> >>
> >>> Without a reproducible example that includes some sample data (fake is
> >>> fine), the code you used (NOT in HTML format), and some clear idea of
> >>> what output you expect, it's impossible to figure out how to help you.
> >>> Here are some suggestions for creating a good reproducible example:
> >>>
> >>>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>>
> >>> Without knowing what you want, it looks like abscissa is a vector, and
> >>> so I'm not sure how this defines a grid, but
> >>> length(unique(diff(vec)))
> >>> might help. Note that this DOES NOT account for machine precision in
> any
> >>> way.
> >>>
> >>> Sarah
> >>>
> >>> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin <marcgg.lamblin at gmail.com
> >
> >>> wrote:
> >>> > I need to control of a given grid is uniform. This control using
> signif
> >>> > until now works:
> >>> >
> >>> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
> >>> > abscissa[1:(length(abscissa) - 1)]) ==
> signif(rep((range(abscissa)[2] -
> >>> >          range(abscissa)[1])/(length(abscissa) - 1),
> length(abscissa) -
> >>> > 1)))) {
> >>> > # other stuff
> >>> > }
> >>> >
> >>> > Does someone have some suggestions to improve this control? Thanks in
> >>> > advance!! :)
> >>> >
> >>> > Marc
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>>
> >>>
> >>> --
> >>> Sarah Goslee
> >>> http://www.functionaldiversity.org
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kshav.91 at gmail.com  Mon Apr  6 22:56:30 2015
From: kshav.91 at gmail.com (Keshav Dhandhania)
Date: Mon, 6 Apr 2015 20:56:30 +0000
Subject: [R]  Fast multiple match function
Message-ID: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>

Hi,

I know that one can find all occurrences of x in a vector v by doing
> which(x == v).

However, if I need to do this again and again, where v is remaining the
same, then this is quite inefficient. In my particular case, I need to do
this millions of times, and length(v) = 100 million.

Does anyone have suggestion on how to go about it?
I know of a package called fmatch that does the above for the match
function. But they don't handle multiple matches.

Thanks

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Apr  7 00:30:41 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Apr 2015 15:30:41 -0700
Subject: [R] Fast multiple match function
In-Reply-To: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
Message-ID: <DC0DAC2B-C88B-4C95-837A-61534F540855@comcast.net>


On Apr 6, 2015, at 1:56 PM, Keshav Dhandhania wrote:

> Hi,
> 
> I know that one can find all occurrences of x in a vector v by doing
>> which(x == v).
> 
> However, if I need to do this again and again, where v is remaining the
> same, then this is quite inefficient. In my particular case, I need to do
> this millions of times, and length(v) = 100 million.
> 
> Does anyone have suggestion on how to go about it?
> I know of a package called fmatch that does the above for the match
> function. But they don't handle multiple matches.
> 

You should explain why you need to do it millions of times and you should pose a small sample problem that presents the level of complexity needed in a minimal size.

> Thanks
> 
> 	[[alternative HTML version deleted]]

And you should read the Posting Guide where it is strongly advised that you not post in HTML format. I have used gmail and I do know that it is fairly easy to post in plain text.

-- 
David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Tue Apr  7 00:49:28 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 6 Apr 2015 15:49:28 -0700
Subject: [R] Fast multiple match function
In-Reply-To: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
Message-ID: <CAF8bMcamYVNLMw9YWtcHY3+E37KiUCsWGVs4iBsua34ox=ERwA@mail.gmail.com>

split() might help, but you should give a more complete
explanation of your problem.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Apr 6, 2015 at 1:56 PM, Keshav Dhandhania <kshav.91 at gmail.com>
wrote:

> Hi,
>
> I know that one can find all occurrences of x in a vector v by doing
> > which(x == v).
>
> However, if I need to do this again and again, where v is remaining the
> same, then this is quite inefficient. In my particular case, I need to do
> this millions of times, and length(v) = 100 million.
>
> Does anyone have suggestion on how to go about it?
> I know of a package called fmatch that does the above for the match
> function. But they don't handle multiple matches.
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Apr  7 00:55:37 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 6 Apr 2015 15:55:37 -0700
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CABYYu7vRu7BfoySakgQ5nTNF0zoRMBSPxpLZyCP8otwF6UcApA@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
	<CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
	<CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>
	<CACk-te0tW0fL-fkDDfRY0-nAvC_me4+75=U8aD8gD+Xnd_ssNQ@mail.gmail.com>
	<CABYYu7vRu7BfoySakgQ5nTNF0zoRMBSPxpLZyCP8otwF6UcApA@mail.gmail.com>
Message-ID: <CACk-te1=twvWdSYDFj=7GoBVHuN2xx_z1nwokT4EDqH-BtrfUA@mail.gmail.com>

Does not min(abs(diff(z))) give you the scaling you need to set a tolerance?

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Apr 6, 2015 at 2:55 PM, Marc Lamblin <marcgg.lamblin at gmail.com> wrote:
> The first solution with diff works for uniform abscissa only with integer
> values.
>
> z <- seq(0, 10, length=100)
> all(diff(z) == z[2] - z[1] )
> ## FALSE
>
> In this case, as you recommended, I could use signif or round or a tolerance
> for real numbers. In my particular case, in order to set a tolerance, I need
> the scale used and I don't have this information. I prefer to test the "near
> uniformity".
> I didn't know the function zapsmall. It could be useful!
> Thanks Sarah and Bert!!!
>
> Marc
>
>
>
>
>
> 2015-04-06 19:51 GMT+02:00 Bert Gunter <gunter.berton at gene.com>:
>>
>> ... correction: you need to use absolute value for the comparison, of
>> course.
>>
>> all(abs(diff(z) - z[2] + z[1]) < tol)
>>
>> -- Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Mon, Apr 6, 2015 at 10:47 AM, Bert Gunter <bgunter at gene.com> wrote:
>> > Perhaps ?diff might be useful here:
>> >
>> > z <- runif(20)
>> > all(diff(z) == z[2] - z[1] )
>> > ## FALSE
>> >
>> > z <- seq_len(10)
>> > all(diff(z) == z[2] - z[1] )
>> > ##TRUE
>> >
>> > You can use signif or round as before to allow for "near uniformity"
>> > or use ?zapsmall or an explicit comparison with a tolerancec instead
>> > of ==, e.g. all(diff(z) - z[2] + z[1] < tol)
>> >
>> > Cheers,
>> > Bert
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> > (650) 467-7374
>> >
>> > "Data is not information. Information is not knowledge. And knowledge
>> > is certainly not wisdom."
>> > Clifford Stoll
>> >
>> >
>> >
>> >
>> > On Mon, Apr 6, 2015 at 10:11 AM, Marc Lamblin <marcgg.lamblin at gmail.com>
>> > wrote:
>> >> The aim is to control if a given abscissa/grid is uniform or not.
>> >> Abscissa
>> >> in generic vector of real ordered numbers.
>> >>
>> >> Here a reproducibile code:
>> >>
>> >> # uniform abscissa/grid
>> >> abscissa1 <- seq(0, 1, length=100)
>> >> # non-uniform abscissa/grid
>> >> abscissa2 <- sort(runif(100))
>> >>
>> >> control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
>> >> abscissa1[1:(length(abscissa1) - 1)]) ==
>> >> signif(rep((range(abscissa1)[2] -
>> >> range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) - 1)))
>> >> control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
>> >> abscissa2[1:(length(abscissa2) - 1)]) ==
>> >> signif(rep((range(abscissa2)[2] -
>> >> range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) - 1)))
>> >>
>> >> control1
>> >> control2
>> >>
>> >> As expected control1 is TRUE and control2 is FALSE. Actually in this
>> >> code
>> >> it is possible also to use
>> >> diff inside signif.
>> >> Do you mean that the control to perform can be done in this manner
>> >>
>> >> if (length(unique(diff(vec))) == 1) {
>> >>   control <- TRUE
>> >> } else {
>> >>   control <- FALSE
>> >> }
>> >>
>> >> I have tried to apply this control on abscissa1 which is uniform but
>> >> length(unique(diff(abscissa1))) was greater than one; probably, as you
>> >> said, this is due to the fact that in this way I don't take into
>> >> account
>> >> the machine precision.
>> >> What I want to understand is if there is a SAFE solution, even if until
>> >> now
>> >> this control is working correctly. I have seen in the documentation of
>> >> signif that by default the number of digits considered are 6. The
>> >> number of
>> >> digits to consider depends on the scale used. It doesn't make sense to
>> >> increase the number of digits with respect to default because, in this
>> >> case, you are not using an handy scale.
>> >> Maybe it could be better directly to ask user if the abscissa passed as
>> >> argument is uniform or not.
>> >> Thanks a lot for the link!!!
>> >>
>> >> Marc
>> >>
>> >>
>> >>
>> >>
>> >> 2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
>> >>
>> >>> Without a reproducible example that includes some sample data (fake is
>> >>> fine), the code you used (NOT in HTML format), and some clear idea of
>> >>> what output you expect, it's impossible to figure out how to help you.
>> >>> Here are some suggestions for creating a good reproducible example:
>> >>>
>> >>>
>> >>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >>>
>> >>> Without knowing what you want, it looks like abscissa is a vector, and
>> >>> so I'm not sure how this defines a grid, but
>> >>> length(unique(diff(vec)))
>> >>> might help. Note that this DOES NOT account for machine precision in
>> >>> any
>> >>> way.
>> >>>
>> >>> Sarah
>> >>>
>> >>> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin
>> >>> <marcgg.lamblin at gmail.com>
>> >>> wrote:
>> >>> > I need to control of a given grid is uniform. This control using
>> >>> > signif
>> >>> > until now works:
>> >>> >
>> >>> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
>> >>> > abscissa[1:(length(abscissa) - 1)]) ==
>> >>> > signif(rep((range(abscissa)[2] -
>> >>> >          range(abscissa)[1])/(length(abscissa) - 1),
>> >>> > length(abscissa) -
>> >>> > 1)))) {
>> >>> > # other stuff
>> >>> > }
>> >>> >
>> >>> > Does someone have some suggestions to improve this control? Thanks
>> >>> > in
>> >>> > advance!! :)
>> >>> >
>> >>> > Marc
>> >>> >
>> >>> >         [[alternative HTML version deleted]]
>> >>> >
>> >>>
>> >>>
>> >>> --
>> >>> Sarah Goslee
>> >>> http://www.functionaldiversity.org
>> >>>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>
>


From dulcalma at bigpond.com  Tue Apr  7 02:57:22 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 7 Apr 2015 10:57:22 +1000
Subject: [R] strip levels
In-Reply-To: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>
References: <1428320653.27517.YahooMailBasic@web120801.mail.ne1.yahoo.com>
Message-ID: <000c01d070cd$ce9d3440$6bd79cc0$@bigpond.com>

Hi

also have a look at useOuterStrips in the latticeExtra package if you want
station x time conditioning

useOuterStrips(strip      = strip.custom(par.strip.text = list(cex = 0.75)),
               strip.left = strip.custom(horizontal = FALSE,
                            par.strip.text = list(cex = 0.75)),
useOuterStrips(strip      = strip.custom(factor.levels = ... ,
                                         par.strip.text = list(cex = 0.75)),
               strip.left = strip.custom(factor.levels =  ...,
                                         horizontal = FALSE,
                                         par.strip.text = par.strip.text =
list(cex = 0.75)),
histogram(...)
) ## useOuterStrips

... = your code

Regards

Duncan Mackay

Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christine
Lee via R-help
Sent: Monday, 6 April 2015 21:44
To: r-help at r-project.org
Subject: [R] strip levels

To whom it may help,

I am new to R.

I have been tring to have a lattice plot in two strip levels: 4 stations in
2 years.  

I type in:

histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10,
layout=c(4,2),nin=30,xlab="Prosomal Width (mm)",
strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.tabl
e=TRUE)

The second level, i.e. Year, showed as "Raw.no10$Year" in the each of the
lattice plot, instead of its respective year, such as "2002" and "2014".

I changed to the following programme language, therefore:

histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year, data=Raw.no10,
layout=c(4,2),nin=30,xlab="Prosomal Width (mm)",
strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",
tick=-1,col='grey',as.table=TRUE) 

in order to specify the variable names of the strip.

Instead of showing "Raw.no10$Year", each of the lattice plot states "2014"!
They should have 4 plots showing "2002" and another 4 showing "2014".

Could any one help indicating what has gone wrong?

I am really helpless and frustrated now.  T_T

Regards,
Christine

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Apr  7 05:33:51 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 7 Apr 2015 13:33:51 +1000
Subject: [R] Combine list element by column name to make a dataframe
In-Reply-To: <1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
References: <339423473.194948.1428265952510.JavaMail.yahoo@mail.yahoo.com>
	<1428300355.24552.YahooMailAndroidMobile@web162103.mail.bf1.yahoo.com>
Message-ID: <000e01d070e3$ab2d8a80$01889f80$@bigpond.com>

forgot to cc to list

have a look at https://stat.ethz.ch/pipermail/r-help/2012-January/300275.html

and other messages in the sequence

if you use Marc Schwartz's list2df you with have to transpose  it with t()

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohammad Tanvir Ahamed via R-help
Sent: Monday, 6 April 2015 16:06
To: r-help at r-project.org
Subject: [R] Combine list element by column name to make a dataframe

Hi ,?

I have a example list like follow?


############################################

lst<-list(setNames(c(1,10,50,60,70,80),c("id","id1","math","phy","che","bio")),setNames(c(2,20,45),c("id","id1","phy")),setNames(c(3,30,75),c("id","id1","bio")))


My expected outcome :?

---------------------------------------------------------------------

df<-rbind(c(1,10,50,60,70,80),c(2,20,NA,45,NA,NA),c(3,30,NA,NA,NA,75))

colnames(df)<-c("id","id1","math","phy","che","bio")

row.names(df) <- NULL

df

############################################


Any suggestion will be appreciated .?

Thanks in advance.

?

Best regards


...........................?

Tanvir Ahamed

G?teborg, Sweden




	[[alternative HTML version deleted]]


From arnab_stat at yahoo.com  Tue Apr  7 01:03:50 2015
From: arnab_stat at yahoo.com (ARNAB KR MAITY)
Date: Mon, 6 Apr 2015 23:03:50 +0000 (UTC)
Subject: [R] problem in search function
In-Reply-To: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
References: <CADktfGVKyUQg9rKgXk-7SXFS+Y6yyoJg2Jcu7VAdhjReYbGDzg@mail.gmail.com>
Message-ID: <726334787.768141.1428361430815.JavaMail.yahoo@mail.yahoo.com>

Please try help(rnorm)
Thanks & Regards,Arnab?Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb,
Illinois 60115
U.S.A
      From: Debojyoti Samadder <samadder.debojyoti at gmail.com>
 To: r-help at r-project.org 
 Sent: Monday, April 6, 2015 7:50 AM
 Subject: [R] problem in search function
   
Dear sir,
I tried? "help.search("rnorm")" in R version 3.1.2 .
It gave a error
"Error in `[<-`(`*tmp*`, , "name", value = sub("\\.[^.]*$", "",
basename(vDB$File))) :
? subscript out of bounds".
? Can you tell me the reason.It may be silly.
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Regards
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Debojyoti
Samadder

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From osiris94 at gmx.ch  Tue Apr  7 00:52:04 2015
From: osiris94 at gmx.ch (Osiris10101)
Date: Mon, 6 Apr 2015 15:52:04 -0700 (PDT)
Subject: [R] Simulate values
Message-ID: <1428360724353-4705574.post@n4.nabble.com>

Hello,

I'm facing the following task:
Simulate 500 values of the statistic (n-1)s^2/sigma^2 based on taking 500
samples of size n=40
from the N(mu=10; sigma^2 = 25) distribution.

I think with the following command:
rep(rnorm(40,10,25),times=500)
I was able to simulate the samples but how I now can simulate the values of
the chi-square-distribution is a mystery to me...

I hope anyone can help me, shouldn't be a big problem...

Thanks in advance!

Reason for posting:
I started a course at the University of Manchester and had to catch up with
R, which I never used back in Switzerland. Now I'm solving some exercises to
get more practice and this is one of them.



--
View this message in context: http://r.789695.n4.nabble.com/Simulate-values-tp4705574.html
Sent from the R help mailing list archive at Nabble.com.


From leptostracan at yahoo.com  Tue Apr  7 06:38:37 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Mon, 6 Apr 2015 21:38:37 -0700
Subject: [R] strip levels
In-Reply-To: <000c01d070cd$ce9d3440$6bd79cc0$@bigpond.com>
Message-ID: <1428381517.61754.YahooMailBasic@web120805.mail.ne1.yahoo.com>

Thank you Duncan,

I am new to R.  Could you please tell me how to download the latticeExtra package to get stationx time conditioning?  I am terribly sorry that I have read 3-4 R books for dummies but I am still quite helpless with using R.  >_<

Regards,
Christine


--------------------------------------------
2015?4?7? ????Duncan Mackay <dulcalma at bigpond.com> ???

 ??: RE: [R] strip levels
 ???: "R" <r-help at r-project.org>, "'Christine Lee'"
 ??: 2015?4?7?,???,??8:57

 Hi

 also have a look at useOuterStrips in the
 latticeExtra package if you want
 station x
 time conditioning

 useOuterStrips(strip? ? ? =
 strip.custom(par.strip.text = list(cex = 0.75)),
 ? ? ? ? ? ? ???strip.left =
 strip.custom(horizontal = FALSE,
 ? ? ? ?
 ? ? ? ? ? ? ? ? ? ? par.strip.text = list(cex =
 0.75)),
 useOuterStrips(strip? ? ? =
 strip.custom(factor.levels = ... ,
 ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???par.strip.text = list(cex = 0.75)),
 ? ? ? ? ? ? ???strip.left =
 strip.custom(factor.levels =? ...,
 ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???horizontal = FALSE,
 ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???par.strip.text = par.strip.text =
 list(cex = 0.75)),
 histogram(...)
 ) ##
 useOuterStrips

 ... = your
 code

 Regards

 Duncan Mackay

 Department of Agronomy and
 Soil Science
 University of New England
 Armidale NSW 2351
 Email: home:
 mackay at northnet.com.au

 -----Original Message-----
 From: R-help [mailto:r-help-bounces at r-project.org]
 On Behalf Of Christine
 Lee via R-help
 Sent: Monday, 6 April 2015 21:44
 To: r-help at r-project.org
 Subject: [R] strip levels

 To whom it may help,

 I am new to R.

 I have been tring to have a lattice plot in two
 strip levels: 4 stations in
 2 years.? 

 I type in:

 histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
 data=Raw.no10,
 layout=c(4,2),nin=30,xlab="Prosomal Width
 (mm)",
 strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.tabl
 e=TRUE)

 The
 second level, i.e. Year, showed as "Raw.no10$Year"
 in the each of the
 lattice plot, instead of
 its respective year, such as "2002" and
 "2014".

 I changed
 to the following programme language, therefore:

 histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
 data=Raw.no10,
 layout=c(4,2),nin=30,xlab="Prosomal Width
 (mm)",
 strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",
 tick=-1,col='grey',as.table=TRUE) 

 in order to specify the
 variable names of the strip.

 Instead of showing "Raw.no10$Year",
[[elided Yahoo spam]]
 They should have 4 plots showing
 "2002" and another 4 showing "2014".

 Could any one help indicating
 what has gone wrong?

 I am
 really helpless and frustrated now.? T_T

 Regards,
 Christine

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.


From kehld at ktk.pte.hu  Tue Apr  7 06:39:32 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Tue, 7 Apr 2015 04:39:32 +0000
Subject: [R] Simulate values
In-Reply-To: <1428360724353-4705574.post@n4.nabble.com>
References: <1428360724353-4705574.post@n4.nabble.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14403CE5@EMAIL.ktkdom.pte.hu>

People do not usually do homework stuff here but I do not see the point in repeating the same sample 500 times. You might want to simulate 40x500 independent samples and put those in a matrix (see ?matrix) with lets say 40 rows and 500 columns. Once done, you can apply calculate the 500 sample standard deviations (or the chi-square values) where the ?apply function might help you.

Lets start with that and lets see where you get.

kd
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Osiris10101 [osiris94 at gmx.ch]
K?ldve: 2015. ?prilis 7. 0:52
To: r-help at r-project.org
T?rgy: [R] Simulate values

Hello,

I'm facing the following task:
Simulate 500 values of the statistic (n-1)s^2/sigma^2 based on taking 500
samples of size n=40
from the N(mu=10; sigma^2 = 25) distribution.

I think with the following command:
rep(rnorm(40,10,25),times=500)
I was able to simulate the samples but how I now can simulate the values of
the chi-square-distribution is a mystery to me...

I hope anyone can help me, shouldn't be a big problem...

Thanks in advance!

Reason for posting:
I started a course at the University of Manchester and had to catch up with
R, which I never used back in Switzerland. Now I'm solving some exercises to
get more practice and this is one of them.



--
View this message in context: http://r.789695.n4.nabble.com/Simulate-values-tp4705574.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nicole.ford at me.com  Tue Apr  7 07:17:03 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Tue, 07 Apr 2015 01:17:03 -0400
Subject: [R] R crashes upon changing directories, loading files, etc.
In-Reply-To: <A2FAFA39-35B2-4D48-8C9B-724864A0806D@gmail.com>
References: <60360FC9-8F7E-4EC7-B007-00700F85D6D2@me.com>
	<5522E9DC.1040304@stats.ox.ac.uk>
	<A2FAFA39-35B2-4D48-8C9B-724864A0806D@gmail.com>
Message-ID: <2D059DF5-4E13-4DD7-9097-2770D9845A7D@me.com>

Yes, it definitely is the GUI as it works just fine when I load data using a file path.  I can work around it, thankfully, but it would be great if this issue could be fixed.  I suspected Yosemite as it's given me multiple problems since install.

Thanks for the input.  Hopefully someone with that skill set might see this and the other thread you mentioned. 

~Nicole



Sent from my iPhone

> On Apr 6, 2015, at 5:26 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 06 Apr 2015, at 22:17 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> 
>> Nicole Ford wrote:
> 
> [snip]
>>> 
>>> I found a page where people were indicating they had this issue, but there was no one responding with a fix.  see below:
>>> 
>>> bugs.r-project.org/bugzilla/show_bug.cgi?id=14240
>> 
>> Which is about Windows in 2010, and does have a response.
> 
> It might be noted, though, that this is not the first report from someone having this sort of issue on Yosemite. See e.g. Christopher Swan's note from April 4 on R-sig-Mac.
> 
> (This sort of issue tends to be slow to fix. We need to have a developer who can reproduce the issue _and_ is capable of debugging Mac GUI code.)
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


From dwinsemius at comcast.net  Tue Apr  7 08:28:29 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Apr 2015 23:28:29 -0700
Subject: [R] strip levels
In-Reply-To: <1428381517.61754.YahooMailBasic@web120805.mail.ne1.yahoo.com>
References: <1428381517.61754.YahooMailBasic@web120805.mail.ne1.yahoo.com>
Message-ID: <0325E3E2-17DC-4734-8CE7-97106B14AFA1@comcast.net>


On Apr 6, 2015, at 9:38 PM, Christine Lee via R-help wrote:

> Thank you Duncan,
> 
> I am new to R.  Could you please tell me how to download the latticeExtra package to get stationx time conditioning?  I am terribly sorry that I have read 3-4 R books for dummies but I am still quite helpless with using R.  >_<
> 

These books didn't illustrate acquiring packages?

Read:

?install.packages

Also read the posting guide where it is suggested that you describe your setup: R version, operating system, etc.

-- 
David.
> Regards,
> Christine
> 
> 
> --------------------------------------------
> 2015?4?7? ????Duncan Mackay <dulcalma at bigpond.com> ???
> 
> ??: RE: [R] strip levels
> ???: "R" <r-help at r-project.org>, "'Christine Lee'"
> ??: 2015?4?7?,???,??8:57
> 
> Hi
> 
> also have a look at useOuterStrips in the
> latticeExtra package if you want
> station x
> time conditioning
> 
> useOuterStrips(strip      =
> strip.custom(par.strip.text = list(cex = 0.75)),
>                strip.left =
> strip.custom(horizontal = FALSE,
>        
>                     par.strip.text = list(cex =
> 0.75)),
> useOuterStrips(strip      =
> strip.custom(factor.levels = ... ,
>      
>                                
>    par.strip.text = list(cex = 0.75)),
>                strip.left =
> strip.custom(factor.levels =  ...,
>      
>                                
>    horizontal = FALSE,
>      
>                                
>    par.strip.text = par.strip.text =
> list(cex = 0.75)),
> histogram(...)
> ) ##
> useOuterStrips
> 
> ... = your
> code
> 
> Regards
> 
> Duncan Mackay
> 
> Department of Agronomy and
> Soil Science
> University of New England
> Armidale NSW 2351
> Email: home:
> mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org]
> On Behalf Of Christine
> Lee via R-help
> Sent: Monday, 6 April 2015 21:44
> To: r-help at r-project.org
> Subject: [R] strip levels
> 
> To whom it may help,
> 
> I am new to R.
> 
> I have been tring to have a lattice plot in two
> strip levels: 4 stations in
> 2 years.  
> 
> I type in:
> 
> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> data=Raw.no10,
> layout=c(4,2),nin=30,xlab="Prosomal Width
> (mm)",
> strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.tabl
> e=TRUE)
> 
> The
> second level, i.e. Year, showed as "Raw.no10$Year"
> in the each of the
> lattice plot, instead of
> its respective year, such as "2002" and
> "2014".
> 
> I changed
> to the following programme language, therefore:
> 
> histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> data=Raw.no10,
> layout=c(4,2),nin=30,xlab="Prosomal Width
> (mm)",
> strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",
> tick=-1,col='grey',as.table=TRUE) 
> 
> in order to specify the
> variable names of the strip.
> 
> Instead of showing "Raw.no10$Year",
> [[elided Yahoo spam]]
> They should have 4 plots showing
> "2002" and another 4 showing "2014".
> 
> Could any one help indicating
> what has gone wrong?
> 
> I am
> really helpless and frustrated now.  T_T
> 
> Regards,
> Christine
> 
> ______________________________________________
> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Tue Apr  7 09:09:19 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Apr 2015 17:09:19 +1000
Subject: [R] stripchart
In-Reply-To: <CAEW+BDL7FzKi6rmwYf5MZc6L51uO3wkvrf7qXJrC0bC1vjHGOw@mail.gmail.com>
References: <CAEW+BD+LEP_8CBVvCVHkEyOp0hfhGzJriTYi217jGN-jhm80Qw@mail.gmail.com>
	<E732B2D5F1E.000008A7jrkrideau@inbox.com>
	<CAEW+BDKZDwsr1cQ6s3paPXgaWXj8LOzN0O8FzVSpn-__zgQHGQ@mail.gmail.com>
	<CAEW+BDL7FzKi6rmwYf5MZc6L51uO3wkvrf7qXJrC0bC1vjHGOw@mail.gmail.com>
Message-ID: <CA+8X3fVKy4y=uDWdCj1krncjRL_CKJ7zNeKuUyWAjzFDbMLDbQ@mail.gmail.com>

Hi Catalin,
I'm not quite sure which values you want to use, but does this start to do
what you want?

Jq90<-quantile(spei$J,0.9)
Jq10<-quantile(spei$J,0.1)
require(plotrix)
plot(spei$year,spei$J,xlab="Year",ylab="Temerature anomaly",
 main="Temperature anomalies by year (1901 to 2013)",
 pch=ifelse(spei$J>=Jq90|spei$J<=Jq10,19,1),
 col=color.scale(spei$J,extremes=c("blue","red")))
abline(h=c(Jq10,Jq90),lty=2)
mtext(c("q10","q90"),side=4,line=0.5,at=c(Jq10,Jq90),las=1)

The stripchart that I got was just three wodges of points.

Jim


On Tue, Apr 7, 2015 at 6:01 AM, catalin roibu <catalinroibu at gmail.com>
wrote:

> ?Mi data is like that:
> i tried:
>
> stripchart(spei[, 1:3], method="jitter", xlim=c(1,2.5),at=c(1.25, 1.75,
> 2.25),offset=1/2,vertical=TRUE, pch=19, las=1, subset(spei,
> speia,1]==quantile(spei[,1],c(.10,.90))))
>
>
> structure(list(year = 1901:2013, J = c(1.547878, -1.100605, -0.4222952,
> -1.221505, -0.2250523, -0.1260924, -0.6251569, -0.7348371, 0.9646313,
> 1.21345, 0.9746932, 0.5155271, -0.3323591, -0.6689715, 0.8461724,
> 1.772659, 1.436295, -1.108881, -1.196227, 1.445744, -0.0565,
> 0.7037539, 1.119812, -0.6622664, -0.5224946, 1.041975, 0.824515,
> -0.8732078, 1.436339, -1.733533, -0.5700181, 0.1557751, 1.168567,
> 0.0399, 0.4697068, -1.099068, 0.985188, -0.5109026, -1.066961,
> 1.542147, 1.586152, 1.397714, 1.277232, -1.071034, 1.539472,
> -1.380059, 1.644268, 1.464481, -1.238555, -0.4090864, -1.280815,
> 0.2857544, 1.24601, -0.5919045, -0.2339949, 0.2059847, 0.3540879,
> -0.1751796, 0.8592942, 0.9626673, 0.400106, -0.4759586, 2.004117,
> -1.320636, 0.9035271, 1.80419, -0.2640611, 1.058896, -0.6948445,
> 0.913681, -0.149598, -0.5239062, -1.011054, -1.345659, -1.216435,
> 0.85655, -0.3159549, -1.610421, 0.6497665, -0.1180871, 0.6042945,
> -0.6747061, -1.086684, 0.4286363, 0.2062943, -0.9906784, 0.111785,
> 0.8267142, -1.784543, -1.561615, -1.007119, -0.6332595, -1.107667,
> -0.6721798, 0.0634, 0.1228354, -1.41257, -0.00162, 0.1837752,
> -0.3076835, -0.5630923, -1.247347, -0.2751805, 0.9607666, 0.5469976,
> -0.3865913, -0.2693521, -1.347567, 0.9775242, 0.9699011, -1.084863,
> -0.9071805, 0.649987), F = c(0.4591538, -0.4417025, -1.359395,
> -0.2941213, 0.9557736, 0.0489, 0.8010427, 0.8289859, 1.525705,
> 0.8249512, -0.7795842, -0.2815648, -1.607204, -2.063595, -0.5948904,
> 1.318963, -0.422867, -1.242612, -0.5462019, 1.265098, 1.308775,
> 0.2138544, 0.1100373, 0.0955, 0.1504445, -0.654495, -0.9949232,
> -0.3433218, 0.2200913, -0.5812335, -1.16412, 1.725803, 1.462846,
> -0.2685312, -0.7131541, 0.8674642, 0.1434308, 0.6649086, -0.2836231,
> 1.011171, 1.227065, -0.4076338, -0.2451349, 1.500328, -0.3398285,
> -0.2637176, 0.2768139, -0.7930014, -1.186443, -1.589864, -0.268713,
> 1.716344, 1.655646, -0.0696, 0.3210001, 1.54118, -0.5956404,
> 1.192839, -1.143002, -0.1229445, -1.007617, 0.5116903, -0.1294708,
> 0.4975231, 0.6975465, -0.9618053, 1.400303, 0.8693725, 1.935434,
> 1.490129, -0.1925304, -1.584169, 1.633565, -0.9840832, -0.4863658,
> -1.879413, -0.6335605, 1.776826, -0.6738441, -1.158889, -0.6118617,
> -0.1720929, -1.136563, 1.761316, 0.0408, 0.9216075, -0.7774346,
> -0.3991293, -1.565672, -0.4566557, -0.1506024, -0.7665204, 0.1048304,
> -1.066744, -0.6170129, 0.5299917, -1.061891, -1.259606, 1.569042,
> -0.0407, -0.4636387, -1.112958, -0.1084111, 0.7898362, 1.212461,
> -1.02738, 0.7161179, -1.503321, 1.081438, 0.8915679, -0.4056812,
> 1.241801, -0.0242), M = c(1.871017, 0.9996752, -0.7870979, 1.064545,
> -1.689601, -0.3018643, 1.88244, -0.8268481, 0.9663578, -1.42123,
> -1.180585, 0.2628357, -0.171538, 1.955883, 1.621714, -0.2572742,
> 1.086263, -0.8372855, 0.7002838, 1.661519, -1.298887, 0.6245486,
> 1.899476, -0.2381713, -0.9496545, 0.0396, 0.2139787, -1.119811,
> -0.2978846, 0.3680027, 0.191265, 0.4833405, 1.477369, -1.241489,
> -0.6909285, 0.0746, -1.185222, -0.3605966, 1.038924, -0.1580821,
> 0.8105857, -1.105557, -1.39728, 1.396135, -0.9131418, -1.089108,
> -0.2248994, 0.1220693, -0.00738, 1.054322, -0.0652, 0.6394631,
> -1.354327, -1.364385, 0.0776, -0.2159752, -1.345767, -0.3184824,
> -0.9450837, -1.524513, -0.8446239, 1.717726, 0.6830018, 0.8245416,
> -0.258855, 1.284419, 0.4350424, -0.0874, 1.127433, 0.1933339,
> 1.163728, -0.3325101, 0.6792468, -1.73808, -1.603025, -0.7328446,
> -0.3346718, 0.154218, -0.0799, 1.193308, 0.7970957, -0.0666,
> -0.1044125, 0.5359862, -1.74367, -1.086822, -0.8943136, 1.813055,
> -0.4922638, -1.402903, -1.368604, 0.6998838, 1.603749, -0.3893991,
> 0.4724727, -0.2015617, -1.302567, 1.192791, -0.2543702, 0.3820274,
> 0.5904814, 0.39335, -0.7998094, -0.4258821, -0.2402134, 1.887602,
> 0.2859741, 0.6394421, 0.3296217, -0.4768481, -0.9271579, -0.4178298,
> 0.9319752), A = c(1.392185, -0.3900369, 1.261199, -1.34034, 1.179663,
> 0.1689164, -0.3248958, -0.145077, -1.052619, 0.5047106, 0.4222224,
> 0.5631918, -0.2590194, 1.29997, 0.2538769, 0.0119, -0.3699814,
> -1.322974, 0.1010328, -1.525166, -0.9178712, 1.061223, -0.0769,
> 1.561162, -0.383757, -0.6107053, -0.6424132, -0.1334207, -0.7172619,
> 1.357379, -0.1621245, -0.9258102, 1.190403, -1.567006, 0.0555,
> 0.7781268, 1.510963, 0.6724311, -1.471632, 0.8010631, 2.013016,
> 1.295346, -1.65198, -0.3035999, 1.117184, -1.383585, -1.779259,
> -1.972591, -1.084347, -0.042, 1.091324, -1.427761, -0.4119558,
> -0.7783867, 0.3951252, -0.364529, 0.092, 1.141092, -1.289819,
> -1.350992, 0.8888445, -0.1811455, -0.6622333, -0.7942793, 0.5927276,
> -0.6182556, 0.3626767, -1.479712, 0.1824882, 1.288104, -1.031188,
> 0.8364891, -0.2128168, -0.7637377, 0.9009821, -0.1863963, 1.193561,
> 1.952563, 1.789684, 0.9170451, -0.4016054, 0.657072, -0.54377,
> 1.172889, 0.2413363, -0.6554105, -0.3052756, 0.7067626, 0.6384293,
> 1.114955, -0.1679992, -0.2559434, 1.259343, -0.9420805, -0.8246916,
> -0.0622, 0.7463045, -0.3551283, 0.9530525, -0.8550238, 0.5273587,
> -1.195716, -1.309607, -1.010941, 1.273224, 0.3587953, -1.008615,
> 1.867905, -1.915486, -0.7199854, 0.6902546, 0.7576268, -0.2066464
> ), M.1 = c(-0.459597, 0.3073703, 0.6373122, 0.0323, -0.2990144,
> 1.348451, -1.058786, -0.9588742, -1.054953, 0.088, -0.1543588,
> 0.8382852, 0.381209, 1.455177, 0.2044187, 1.933988, -1.491534,
> -1.131024, 0.8778787, 1.131279, -0.2765887, 0.7649798, 0.1513148,
> -1.505724, -0.9782518, 1.056937, 0.2421261, -0.1931907, 0.3331755,
> 1.636935, 0.8483486, 1.150103, 0.3569795, -0.9200462, -1.248399,
> -2.131074, -1.837349, 0.7884224, 0.1044271, 1.618109, -0.0884,
> -0.3093464, 0.1750515, 0.3157889, -0.4007615, -0.3602178, -1.577297,
> 0.3156092, -0.6090513, 0.0777, -0.0739, -0.6141033, 0.2053224,
> 0.7730377, 0.0937, -0.9651945, 0.5940142, -1.869726, -0.9225557,
> 1.613315, 0.9881144, -0.5748347, -0.4094839, -1.146461, -0.1883968,
> 0.0229, 0.0222, -0.839798, -1.156032, 1.79293, 1.093842, 0.0501,
> 0.9138928, 0.7618006, 1.250165, -0.5041265, -0.3824979, 1.1509,
> -1.064404, 0.1799515, 1.721967, -1.418593, 0.9714718, 1.813877,
> -0.2158474, -1.854743, 0.1794739, 0.9863014, -0.00756, -0.1975708,
> 2.630607, -0.2897428, -0.1823791, -0.2188942, 0.1931569, -0.4849184,
> -0.910131, 0.330787, -1.41867, -1.686491, -0.4433936, -1.031551,
> -1.176649, -0.5566295, 1.134091, 0.7463202, -0.6417032, 0.4953422,
> -0.6160501, 0.8935812, -1.324298, 0.9829205, 1.150733), J.1 = c(1.825126,
> -0.5984555, 0.5062206, 0.2729266, -0.0121, 0.3048763, 0.1185485,
> -1.452631, 0.8458623, -0.6238015, 1.501945, -0.9960235, 0.3034413,
> 1.115355, -1.548629, -0.7492623, -0.3663574, -0.3106384, 0.4708462,
> 1.154669, 0.1342134, 1.176006, -0.179569, -0.2387322, 0.2095732,
> 0.263253, -0.9764008, -0.2424318, -1.509435, -0.8619977, -0.6949487,
> 1.13643, 0.3285941, -0.4237518, -0.6995585, 1.141431, -0.8279015,
> -0.2238075, -0.5552112, 1.712743, 0.9339596, 0.7134116, -1.569646,
> -1.354327, -2.151799, 0.3125413, 1.392763, 2.343378, 1.500511,
> -1.07474, -0.3640471, -1.174823, -0.8083484, -0.8629019, 0.1802151,
> -0.8400947, -0.6961728, 0.6121192, -0.158193, -0.6731861, -1.164061,
> 0.4841825, -1.099666, -1.828531, 1.224967, -0.1096543, 0.315272,
> -0.7347631, 1.474177, 0.189875, 0.9930706, 1.00275, -0.3786205,
> 0.9757372, 0.7885385, 0.3145336, -0.1258672, 0.710925, 1.03332,
> 0.7255082, 0.1398514, 0.1243291, 0.5082635, 0.2700605, 2.298389,
> -0.3160264, -1.028077, 0.8622152, 1.412863, -0.5811861, -0.0531,
> 0.9467085, 0.0786, -0.6774637, 0.5012567, 0.0711, -0.3342393,
> -0.5698247, -0.2223169, -1.402855, 0.958059, -0.4716635, -2.096799,
> -1.816265, -0.1956688, 0.5804866, -1.539355, -0.0941, -0.4405876,
> 1.56924, 0.2990377, -1.507233, 1.800162), J.2 = c(0.7125305,
> -0.2484601, -0.1309015, -1.607252, -1.249372, 0.0415, 0.3784786,
> 0.4004564, -1.373159, 1.473249, 1.253015, 0.5879295, 0.2819284,
> 0.1612775, -0.0827, 0.0441, -0.7687836, 0.4403304, 1.202746,
> -0.9197539, -0.1688939, -1.780381, 0.4153456, -0.5441434, -0.0481,
> 0.7404298, -0.4266277, -0.9788033, 1.081349, -1.615727, -0.390704,
> -0.6905217, 1.253196, 0.2652828, 0.646424, -1.066357, -0.00207,
> -1.155523, -0.6725245, -0.2743259, -0.3313848, 0.5575091, 1.044034,
> 0.3188159, -1.475527, -0.4916094, 1.162765, 0.9864765, 1.109815,
> 0.0177, -0.6357729, -1.168194, -1.492512, 0.1192912, 1.425088,
> -1.508932, -1.239281, -1.210208, -1.149243, -1.427692, 0.0798,
> -0.5581351, -0.1625799, 0.2180536, -0.3759806, 0.2217173, -0.2400341,
> 1.483425, 1.441966, 1.171917, 1.379586, -0.1496088, -0.6433921,
> 2.09978, 0.8546344, 0.2083152, 0.631144, 0.3003181, -0.8270686,
> 1.175304, 1.417394, 1.004064, 0.2477521, 0.6266472, -0.7291934,
> 0.5905515, -0.9555936, 0.5712249, -1.173295, -0.00711, 1.255848,
> -1.226201, 0.2382776, -1.697067, -1.16022, -0.4587435, 1.856619,
> 1.517898, 0.0553, 0.7973539, -0.0488, 1.606414, 1.556608, 0.9845491,
> -0.0782, 0.0774, -0.5242269, 1.876367, -1.416478, -1.027787,
> -0.421659, -1.592346, -1.424157), A.1 = c(0.7710939, 0.0543,
> -0.5300472, 0.6592121, -1.153847, -0.1456997, -1.832444, 0.3726975,
> -1.555021, -0.1779477, 0.853007, 0.0148, 1.405779, 0.0653, 0.7474295,
> -0.9215167, 0.5334297, 0.8162999, -0.3440735, -0.2200963, -1.429803,
> -0.0353, -1.46344, 0.2656482, 0.6850917, 0.3424074, 2.003194,
> 1.554138, -0.8998712, 0.9580757, 0.2230041, 0.2162019, 1.065416,
> -0.0352, -0.6884875, 0.7631074, 2.31387, 0.8385554, -1.21593,
> 1.103421, -0.2796364, -1.717311, -1.118207, 0.3429681, 0.6491678,
> -1.641407, 1.391316, -0.7211239, -0.3269602, 0.3379903, 0.8097239,
> -1.095252, -0.8706113, 0.9977409, 1.415604, 0.3823287, -0.53202,
> 1.815458, 0.5080889, -0.619583, -0.5816615, -1.347994, -0.2950751,
> 0.00293, -1.013928, 0.6205906, -0.229311, -0.0918, 0.3008375,
> 0.3231607, 0.0565, 1.937777, -0.7516724, 0.4014818, -1.14229,
> 0.0812, 1.433859, -0.9256708, 0.9253611, -0.7319795, -1.178572,
> -0.6748386, 1.244621, -0.5254955, -0.5324911, -0.3484317, 0.6396209,
> -0.8255401, 1.461768, -0.9260288, 1.208898, -2.027193, -1.250234,
> 1.360385, 1.20246, 1.352473, 0.747547, -0.7985137, -0.2918135,
> -1.429048, -1.08267, -0.226564, -1.423707, 1.778427, 0.5396544,
> 0.9709455, 0.9165762, -0.2737122, -0.6247987, -0.4211569, -1.091536,
> -0.9024249, -0.4648108), S = c(-0.8618388, -0.0332, -2.145797,
> 1.858552, -0.2969203, 0.14438, 0.4080206, 1.465032, 0.9768468,
> -1.4789, 0.2597017, 2.307055, 0.2776116, 0.506233, -0.0605, -1.754613,
> -1.510066, -0.4301712, -1.690894, -0.5364874, -0.2276098, 0.8183981,
> 0.9121475, -0.2545718, 0.276076, -0.6841297, 0.1504795, 0.4432018,
> 0.365016, -0.1197473, 0.2825312, -0.35693, 0.1777097, 1.29534,
> -0.1185746, 0.2778297, 0.000208, 0.5252196, 0.4327488, -0.2277896,
> 1.49888, -1.133052, 0.7170076, -0.5383621, -1.494164, -0.2049331,
> -0.5630803, -0.6943023, -0.0121, -0.2480845, -0.5522097, -0.4257083,
> -0.5035902, -0.2110623, 1.901829, 0.5416803, 0.2940297, -0.2385825,
> -0.1606006, -0.6408279, -1.996327, -0.0744, -1.030415, 1.219432,
> -0.5174201, -0.5638925, -0.2753139, 1.393646, -1.120592, -0.0916,
> 0.881043, 1.116105, -1.002848, 1.251612, -1.37734, 1.755553,
> 0.8505045, 1.61046, -1.215773, -0.2731214, 0.8397942, -1.808574,
> -1.323098, -0.1434434, -0.2961432, -1.331223, -1.040429, 0.5865396,
> 1.883039, -0.8122656, 0.1586151, 0.6313211, 0.7063697, -0.9452625,
> 1.77178, 2.067997, -0.1469796, 0.543735, -0.5135865, 0.1696817,
> 1.98517, 0.2124236, -0.3413171, 0.5659797, -1.424213, -1.178379,
> 0.8146986, 0.6695309, -1.679428, 0.7691776, -0.9977649, 0.3209742,
> 1.221028), O = c(1.41081, 0.2794146, 0.7500096, 0.2865539, 1.756024,
> -0.9420308, -1.534693, 0.8799208, -0.8840324, 0.657547, -0.1988259,
> 0.8938275, -1.497176, 1.160732, 0.7338172, 1.519444, 1.143451,
> 2.062596, 1.041898, -0.8042107, -1.311448, 1.492421, -0.8708527,
> -1.280516, -0.977245, -0.4174474, 0.5002149, -0.0074, -1.076548,
> 0.2027731, -0.5576773, 0.9159288, 0.628099, -0.0279, -1.177137,
> 0.8651672, 0.1002702, 1.668067, 2.096398, 1.163112, 0.5318853,
> -0.4009511, -1.126641, 1.524528, -0.3486073, 1.72486, 0.3027355,
> -0.9869668, -1.523738, 1.478759, -0.5618216, 0.8416752, -1.394072,
> -0.6274928, -0.4747858, -1.009026, -0.7476265, 0.0703, -0.7152165,
> 0.545657, -1.342295, -1.503654, -0.7281811, 0.5582658, -1.318162,
> -0.2957245, -0.993159, 0.5168112, -1.310361, 0.2813013, -0.7797307,
> 1.548533, -1.0072, 0.5857817, 1.606338, 0.6956402, -1.187455,
> -1.363752, 0.2583569, 0.5203429, 0.2434425, -0.8046308, -1.114945,
> -0.6434187, -0.9872744, -0.5792918, 0.4110919, -1.258956, -0.616523,
> -0.3439566, 0.8936544, 0.2170967, -1.169243, 0.892866, -1.06335,
> 0.2329752, 0.6772005, 1.275011, 0.5593982, -1.444531, -0.2763905,
> 0.9387801, 1.232073, -0.6661146, 0.1706444, -0.2514986, 0.9861698,
> 0.3247585, 1.582411, 0.2701326, -0.0097, 0.2282059, -1.418496
> ), N = c(-1.509117, -1.865568, -0.9207457, 1.589874, 0.382475,
> 0.2372435, 0.1056492, -0.2351283, 0.0642, 1.678718, -0.5379919,
> 0.4989375, 1.576607, -0.684436, 0.6053467, -0.4453632, 0.3452958,
> 1.707276, 0.6281493, 0.8101255, 1.759663, 0.1725115, -1.197022,
> 0.7000259, 0.7414397, -1.926519, -0.5840425, -0.0826, 0.7428133,
> -0.5476953, 0.7237629, -1.129797, 0.9455895, -0.6096208, -0.6842518,
> 0.00181, 0.9162412, -1.274803, -1.203836, -0.847842, 0.8018484,
> 1.195398, 0.9078937, 0.2084386, -1.377868, 1.344439, 1.657746,
> -0.9019613, 1.267303, 0.0347, -0.9681922, 0.8730431, -0.7356324,
> 0.4806201, 0.4684249, -0.3170492, 1.126324, 0.7814922, 1.304149,
> 1.999495, -0.2693311, 1.716548, -1.467723, 0.00245, 0.4545638,
> 1.448339, -1.192959, -0.0747, -0.6172311, -0.4099933, -0.4685052,
> 0.556715, -1.523987, 0.4994395, -0.9713943, 0.3854924, 0.246838,
> 0.0763, -0.1699395, 0.5965068, 1.380759, -1.121356, -0.7884063,
> 0.1874816, 0.5991878, -1.553753, 1.40589, -1.189748, -0.9560809,
> -1.059296, -1.190311, -0.6166247, -0.00346, -0.597102, 0.4561315,
> 0.9741255, -0.8903497, 0.8815181, -0.3522395, -1.083957, 1.553848,
> 0.8013645, -1.448561, 1.096503, 0.3007325, -1.080419, 0.627004,
> -1.01452, -1.32398, -0.1690037, -1.808708, -0.8492975, -0.420956
> ), D = c(0.2536002, 0.9746647, 0.0391, -0.5228497, 0.1569641,
> 1.047966, 0.0229, -0.0995, 0.2635663, -0.6151057, 0.9903812,
> -0.3476267, -0.9942705, -1.006192, -1.525466, -0.7323552, 0.2951043,
> 1.434593, 1.776893, -0.472288, -0.7126557, -0.7370189, 1.95417,
> -1.370966, 0.7726845, 0.7082534, -0.6715661, 1.17026, -1.16282,
> 1.173137, -0.4252348, -0.9583436, -0.4809905, -1.418637, 0.2530024,
> -1.122147, -0.0234, 0.99437, 0.4095966, 0.729747, -0.2727098,
> -0.6143018, 1.646983, -0.8654616, 0.0658, 0.8169893, 1.01281,
> -1.794421, 0.788344, -0.1552048, -1.113021, 0.5335623, -0.4326706,
> 0.2005343, -0.2204396, 1.86017, 0.1751825, -1.363381, 0.6559588,
> 0.1089933, -0.6156067, -0.1475329, 1.435637, -0.051, -0.9724815,
> -0.2217541, 0.2237121, -0.2329498, 2.171139, 0.5472844, 1.38426,
> -1.755075, -0.5630907, 0.31985, -1.853139, 0.8960767, -0.8075317,
> 0.2993207, -0.641555, 1.363514, 0.3422053, 0.4911866, -1.111221,
> -0.0137, -0.6198144, -1.292335, 1.118542, -0.000946, -1.619747,
> 1.677535, -0.8993699, -0.3782237, 0.4151115, -0.2513984, 0.7183175,
> 1.229746, 1.615256, -1.024167, 0.9041114, -0.6676438, -0.2487,
> -1.408996, -0.265974, -1.116754, -0.1568737, -1.831107, 1.065047,
> 0.9980727, 0.935714, 1.137962, -1.070733, 1.876622, -1.579149
> )), .Names = c("year", "J", "F", "M", "A", "M.1", "J.1", "J.2",
> "A.1", "S", "O", "N", "D"), class = "data.frame", row.names = c(NA,
> -113L))
>
> On 6 April 2015 at 22:58, catalin roibu <catalinroibu at gmail.com> wrote:
>
> > original data are something like that:
> >
> > structure(list(year = 1901:2013, J = c(1.547878, -1.100605, -0.4222952,
> > -1.221505, -0.2250523, -0.1260924, -0.6251569, -0.7348371, 0.9646313,
> > 1.21345, 0.9746932, 0.5155271, -0.3323591, -0.6689715, 0.8461724,
> > 1.772659, 1.436295, -1.108881, -1.196227, 1.445744, -0.0565,
> > 0.7037539, 1.119812, -0.6622664, -0.5224946, 1.041975, 0.824515,
> > -0.8732078, 1.436339, -1.733533, -0.5700181, 0.1557751, 1.168567,
> > 0.0399, 0.4697068, -1.099068, 0.985188, -0.5109026, -1.066961,
> > 1.542147, 1.586152, 1.397714, 1.277232, -1.071034, 1.539472,
> > -1.380059, 1.644268, 1.464481, -1.238555, -0.4090864, -1.280815,
> > 0.2857544, 1.24601, -0.5919045, -0.2339949, 0.2059847, 0.3540879,
> > -0.1751796, 0.8592942, 0.9626673, 0.400106, -0.4759586, 2.004117,
> > -1.320636, 0.9035271, 1.80419, -0.2640611, 1.058896, -0.6948445,
> > 0.913681, -0.149598, -0.5239062, -1.011054, -1.345659, -1.216435,
> > 0.85655, -0.3159549, -1.610421, 0.6497665, -0.1180871, 0.6042945,
> > -0.6747061, -1.086684, 0.4286363, 0.2062943, -0.9906784, 0.111785,
> > 0.8267142, -1.784543, -1.561615, -1.007119, -0.6332595, -1.107667,
> > -0.6721798, 0.0634, 0.1228354, -1.41257, -0.00162, 0.1837752,
> > -0.3076835, -0.5630923, -1.247347, -0.2751805, 0.9607666, 0.5469976,
> > -0.3865913, -0.2693521, -1.347567, 0.9775242, 0.9699011, -1.084863,
> > -0.9071805, 0.649987), F = c(0.4591538, -0.4417025, -1.359395,
> > -0.2941213, 0.9557736, 0.0489, 0.8010427, 0.8289859, 1.525705,
> > 0.8249512, -0.7795842, -0.2815648, -1.607204, -2.063595, -0.5948904,
> > 1.318963, -0.422867, -1.242612, -0.5462019, 1.265098, 1.308775,
> > 0.2138544, 0.1100373, 0.0955, 0.1504445, -0.654495, -0.9949232,
> > -0.3433218, 0.2200913, -0.5812335, -1.16412, 1.725803, 1.462846,
> > -0.2685312, -0.7131541, 0.8674642, 0.1434308, 0.6649086, -0.2836231,
> > 1.011171, 1.227065, -0.4076338, -0.2451349, 1.500328, -0.3398285,
> > -0.2637176, 0.2768139, -0.7930014, -1.186443, -1.589864, -0.268713,
> > 1.716344, 1.655646, -0.0696, 0.3210001, 1.54118, -0.5956404,
> > 1.192839, -1.143002, -0.1229445, -1.007617, 0.5116903, -0.1294708,
> > 0.4975231, 0.6975465, -0.9618053, 1.400303, 0.8693725, 1.935434,
> > 1.490129, -0.1925304, -1.584169, 1.633565, -0.9840832, -0.4863658,
> > -1.879413, -0.6335605, 1.776826, -0.6738441, -1.158889, -0.6118617,
> > -0.1720929, -1.136563, 1.761316, 0.0408, 0.9216075, -0.7774346,
> > -0.3991293, -1.565672, -0.4566557, -0.1506024, -0.7665204, 0.1048304,
> > -1.066744, -0.6170129, 0.5299917, -1.061891, -1.259606, 1.569042,
> > -0.0407, -0.4636387, -1.112958, -0.1084111, 0.7898362, 1.212461,
> > -1.02738, 0.7161179, -1.503321, 1.081438, 0.8915679, -0.4056812,
> > 1.241801, -0.0242), M = c(1.871017, 0.9996752, -0.7870979, 1.064545,
> > -1.689601, -0.3018643, 1.88244, -0.8268481, 0.9663578, -1.42123,
> > -1.180585, 0.2628357, -0.171538, 1.955883, 1.621714, -0.2572742,
> > 1.086263, -0.8372855, 0.7002838, 1.661519, -1.298887, 0.6245486,
> > 1.899476, -0.2381713, -0.9496545, 0.0396, 0.2139787, -1.119811,
> > -0.2978846, 0.3680027, 0.191265, 0.4833405, 1.477369, -1.241489,
> > -0.6909285, 0.0746, -1.185222, -0.3605966, 1.038924, -0.1580821,
> > 0.8105857, -1.105557, -1.39728, 1.396135, -0.9131418, -1.089108,
> > -0.2248994, 0.1220693, -0.00738, 1.054322, -0.0652, 0.6394631,
> > -1.354327, -1.364385, 0.0776, -0.2159752, -1.345767, -0.3184824,
> > -0.9450837, -1.524513, -0.8446239, 1.717726, 0.6830018, 0.8245416,
> > -0.258855, 1.284419, 0.4350424, -0.0874, 1.127433, 0.1933339,
> > 1.163728, -0.3325101, 0.6792468, -1.73808, -1.603025, -0.7328446,
> > -0.3346718, 0.154218, -0.0799, 1.193308, 0.7970957, -0.0666,
> > -0.1044125, 0.5359862, -1.74367, -1.086822, -0.8943136, 1.813055,
> > -0.4922638, -1.402903, -1.368604, 0.6998838, 1.603749, -0.3893991,
> > 0.4724727, -0.2015617, -1.302567, 1.192791, -0.2543702, 0.3820274,
> > 0.5904814, 0.39335, -0.7998094, -0.4258821, -0.2402134, 1.887602,
> > 0.2859741, 0.6394421, 0.3296217, -0.4768481, -0.9271579, -0.4178298,
> > 0.9319752), A = c(1.392185, -0.3900369, 1.261199, -1.34034, 1.179663,
> > 0.1689164, -0.3248958, -0.145077, -1.052619, 0.5047106, 0.4222224,
> > 0.5631918, -0.2590194, 1.29997, 0.2538769, 0.0119, -0.3699814,
> > -1.322974, 0.1010328, -1.525166, -0.9178712, 1.061223, -0.0769,
> > 1.561162, -0.383757, -0.6107053, -0.6424132, -0.1334207, -0.7172619,
> > 1.357379, -0.1621245, -0.9258102, 1.190403, -1.567006, 0.0555,
> > 0.7781268, 1.510963, 0.6724311, -1.471632, 0.8010631, 2.013016,
> > 1.295346, -1.65198, -0.3035999, 1.117184, -1.383585, -1.779259,
> > -1.972591, -1.084347, -0.042, 1.091324, -1.427761, -0.4119558,
> > -0.7783867, 0.3951252, -0.364529, 0.092, 1.141092, -1.289819,
> > -1.350992, 0.8888445, -0.1811455, -0.6622333, -0.7942793, 0.5927276,
> > -0.6182556, 0.3626767, -1.479712, 0.1824882, 1.288104, -1.031188,
> > 0.8364891, -0.2128168, -0.7637377, 0.9009821, -0.1863963, 1.193561,
> > 1.952563, 1.789684, 0.9170451, -0.4016054, 0.657072, -0.54377,
> > 1.172889, 0.2413363, -0.6554105, -0.3052756, 0.7067626, 0.6384293,
> > 1.114955, -0.1679992, -0.2559434, 1.259343, -0.9420805, -0.8246916,
> > -0.0622, 0.7463045, -0.3551283, 0.9530525, -0.8550238, 0.5273587,
> > -1.195716, -1.309607, -1.010941, 1.273224, 0.3587953, -1.008615,
> > 1.867905, -1.915486, -0.7199854, 0.6902546, 0.7576268, -0.2066464
> > ), M.1 = c(-0.459597, 0.3073703, 0.6373122, 0.0323, -0.2990144,
> > 1.348451, -1.058786, -0.9588742, -1.054953, 0.088, -0.1543588,
> > 0.8382852, 0.381209, 1.455177, 0.2044187, 1.933988, -1.491534,
> > -1.131024, 0.8778787, 1.131279, -0.2765887, 0.7649798, 0.1513148,
> > -1.505724, -0.9782518, 1.056937, 0.2421261, -0.1931907, 0.3331755,
> > 1.636935, 0.8483486, 1.150103, 0.3569795, -0.9200462, -1.248399,
> > -2.131074, -1.837349, 0.7884224, 0.1044271, 1.618109, -0.0884,
> > -0.3093464, 0.1750515, 0.3157889, -0.4007615, -0.3602178, -1.577297,
> > 0.3156092, -0.6090513, 0.0777, -0.0739, -0.6141033, 0.2053224,
> > 0.7730377, 0.0937, -0.9651945, 0.5940142, -1.869726, -0.9225557,
> > 1.613315, 0.9881144, -0.5748347, -0.4094839, -1.146461, -0.1883968,
> > 0.0229, 0.0222, -0.839798, -1.156032, 1.79293, 1.093842, 0.0501,
> > 0.9138928, 0.7618006, 1.250165, -0.5041265, -0.3824979, 1.1509,
> > -1.064404, 0.1799515, 1.721967, -1.418593, 0.9714718, 1.813877,
> > -0.2158474, -1.854743, 0.1794739, 0.9863014, -0.00756, -0.1975708,
> > 2.630607, -0.2897428, -0.1823791, -0.2188942, 0.1931569, -0.4849184,
> > -0.910131, 0.330787, -1.41867, -1.686491, -0.4433936, -1.031551,
> > -1.176649, -0.5566295, 1.134091, 0.7463202, -0.6417032, 0.4953422,
> > -0.6160501, 0.8935812, -1.324298, 0.9829205, 1.150733), J.1 = c(1.825126,
> > -0.5984555, 0.5062206, 0.2729266, -0.0121, 0.3048763, 0.1185485,
> > -1.452631, 0.8458623, -0.6238015, 1.501945, -0.9960235, 0.3034413,
> > 1.115355, -1.548629, -0.7492623, -0.3663574, -0.3106384, 0.4708462,
> > 1.154669, 0.1342134, 1.176006, -0.179569, -0.2387322, 0.2095732,
> > 0.263253, -0.9764008, -0.2424318, -1.509435, -0.8619977, -0.6949487,
> > 1.13643, 0.3285941, -0.4237518, -0.6995585, 1.141431, -0.8279015,
> > -0.2238075, -0.5552112, 1.712743, 0.9339596, 0.7134116, -1.569646,
> > -1.354327, -2.151799, 0.3125413, 1.392763, 2.343378, 1.500511,
> > -1.07474, -0.3640471, -1.174823, -0.8083484, -0.8629019, 0.1802151,
> > -0.8400947, -0.6961728, 0.6121192, -0.158193, -0.6731861, -1.164061,
> > 0.4841825, -1.099666, -1.828531, 1.224967, -0.1096543, 0.315272,
> > -0.7347631, 1.474177, 0.189875, 0.9930706, 1.00275, -0.3786205,
> > 0.9757372, 0.7885385, 0.3145336, -0.1258672, 0.710925, 1.03332,
> > 0.7255082, 0.1398514, 0.1243291, 0.5082635, 0.2700605, 2.298389,
> > -0.3160264, -1.028077, 0.8622152, 1.412863, -0.5811861, -0.0531,
> > 0.9467085, 0.0786, -0.6774637, 0.5012567, 0.0711, -0.3342393,
> > -0.5698247, -0.2223169, -1.402855, 0.958059, -0.4716635, -2.096799,
> > -1.816265, -0.1956688, 0.5804866, -1.539355, -0.0941, -0.4405876,
> > 1.56924, 0.2990377, -1.507233, 1.800162), J.2 = c(0.7125305,
> > -0.2484601, -0.1309015, -1.607252, -1.249372, 0.0415, 0.3784786,
> > 0.4004564, -1.373159, 1.473249, 1.253015, 0.5879295, 0.2819284,
> > 0.1612775, -0.0827, 0.0441, -0.7687836, 0.4403304, 1.202746,
> > -0.9197539, -0.1688939, -1.780381, 0.4153456, -0.5441434, -0.0481,
> > 0.7404298, -0.4266277, -0.9788033, 1.081349, -1.615727, -0.390704,
> > -0.6905217, 1.253196, 0.2652828, 0.646424, -1.066357, -0.00207,
> > -1.155523, -0.6725245, -0.2743259, -0.3313848, 0.5575091, 1.044034,
> > 0.3188159, -1.475527, -0.4916094, 1.162765, 0.9864765, 1.109815,
> > 0.0177, -0.6357729, -1.168194, -1.492512, 0.1192912, 1.425088,
> > -1.508932, -1.239281, -1.210208, -1.149243, -1.427692, 0.0798,
> > -0.5581351, -0.1625799, 0.2180536, -0.3759806, 0.2217173, -0.2400341,
> > 1.483425, 1.441966, 1.171917, 1.379586, -0.1496088, -0.6433921,
> > 2.09978, 0.8546344, 0.2083152, 0.631144, 0.3003181, -0.8270686,
> > 1.175304, 1.417394, 1.004064, 0.2477521, 0.6266472, -0.7291934,
> > 0.5905515, -0.9555936, 0.5712249, -1.173295, -0.00711, 1.255848,
> > -1.226201, 0.2382776, -1.697067, -1.16022, -0.4587435, 1.856619,
> > 1.517898, 0.0553, 0.7973539, -0.0488, 1.606414, 1.556608, 0.9845491,
> > -0.0782, 0.0774, -0.5242269, 1.876367, -1.416478, -1.027787,
> > -0.421659, -1.592346, -1.424157), A.1 = c(0.7710939, 0.0543,
> > -0.5300472, 0.6592121, -1.153847, -0.1456997, -1.832444, 0.3726975,
> > -1.555021, -0.1779477, 0.853007, 0.0148, 1.405779, 0.0653, 0.7474295,
> > -0.9215167, 0.5334297, 0.8162999, -0.3440735, -0.2200963, -1.429803,
> > -0.0353, -1.46344, 0.2656482, 0.6850917, 0.3424074, 2.003194,
> > 1.554138, -0.8998712, 0.9580757, 0.2230041, 0.2162019, 1.065416,
> > -0.0352, -0.6884875, 0.7631074, 2.31387, 0.8385554, -1.21593,
> > 1.103421, -0.2796364, -1.717311, -1.118207, 0.3429681, 0.6491678,
> > -1.641407, 1.391316, -0.7211239, -0.3269602, 0.3379903, 0.8097239,
> > -1.095252, -0.8706113, 0.9977409, 1.415604, 0.3823287, -0.53202,
> > 1.815458, 0.5080889, -0.619583, -0.5816615, -1.347994, -0.2950751,
> > 0.00293, -1.013928, 0.6205906, -0.229311, -0.0918, 0.3008375,
> > 0.3231607, 0.0565, 1.937777, -0.7516724, 0.4014818, -1.14229,
> > 0.0812, 1.433859, -0.9256708, 0.9253611, -0.7319795, -1.178572,
> > -0.6748386, 1.244621, -0.5254955, -0.5324911, -0.3484317, 0.6396209,
> > -0.8255401, 1.461768, -0.9260288, 1.208898, -2.027193, -1.250234,
> > 1.360385, 1.20246, 1.352473, 0.747547, -0.7985137, -0.2918135,
> > -1.429048, -1.08267, -0.226564, -1.423707, 1.778427, 0.5396544,
> > 0.9709455, 0.9165762, -0.2737122, -0.6247987, -0.4211569, -1.091536,
> > -0.9024249, -0.4648108), S = c(-0.8618388, -0.0332, -2.145797,
> > 1.858552, -0.2969203, 0.14438, 0.4080206, 1.465032, 0.9768468,
> > -1.4789, 0.2597017, 2.307055, 0.2776116, 0.506233, -0.0605, -1.754613,
> > -1.510066, -0.4301712, -1.690894, -0.5364874, -0.2276098, 0.8183981,
> > 0.9121475, -0.2545718, 0.276076, -0.6841297, 0.1504795, 0.4432018,
> > 0.365016, -0.1197473, 0.2825312, -0.35693, 0.1777097, 1.29534,
> > -0.1185746, 0.2778297, 0.000208, 0.5252196, 0.4327488, -0.2277896,
> > 1.49888, -1.133052, 0.7170076, -0.5383621, -1.494164, -0.2049331,
> > -0.5630803, -0.6943023, -0.0121, -0.2480845, -0.5522097, -0.4257083,
> > -0.5035902, -0.2110623, 1.901829, 0.5416803, 0.2940297, -0.2385825,
> > -0.1606006, -0.6408279, -1.996327, -0.0744, -1.030415, 1.219432,
> > -0.5174201, -0.5638925, -0.2753139, 1.393646, -1.120592, -0.0916,
> > 0.881043, 1.116105, -1.002848, 1.251612, -1.37734, 1.755553,
> > 0.8505045, 1.61046, -1.215773, -0.2731214, 0.8397942, -1.808574,
> > -1.323098, -0.1434434, -0.2961432, -1.331223, -1.040429, 0.5865396,
> > 1.883039, -0.8122656, 0.1586151, 0.6313211, 0.7063697, -0.9452625,
> > 1.77178, 2.067997, -0.1469796, 0.543735, -0.5135865, 0.1696817,
> > 1.98517, 0.2124236, -0.3413171, 0.5659797, -1.424213, -1.178379,
> > 0.8146986, 0.6695309, -1.679428, 0.7691776, -0.9977649, 0.3209742,
> > 1.221028), O = c(1.41081, 0.2794146, 0.7500096, 0.2865539, 1.756024,
> > -0.9420308, -1.534693, 0.8799208, -0.8840324, 0.657547, -0.1988259,
> > 0.8938275, -1.497176, 1.160732, 0.7338172, 1.519444, 1.143451,
> > 2.062596, 1.041898, -0.8042107, -1.311448, 1.492421, -0.8708527,
> > -1.280516, -0.977245, -0.4174474, 0.5002149, -0.0074, -1.076548,
> > 0.2027731, -0.5576773, 0.9159288, 0.628099, -0.0279, -1.177137,
> > 0.8651672, 0.1002702, 1.668067, 2.096398, 1.163112, 0.5318853,
> > -0.4009511, -1.126641, 1.524528, -0.3486073, 1.72486, 0.3027355,
> > -0.9869668, -1.523738, 1.478759, -0.5618216, 0.8416752, -1.394072,
> > -0.6274928, -0.4747858, -1.009026, -0.7476265, 0.0703, -0.7152165,
> > 0.545657, -1.342295, -1.503654, -0.7281811, 0.5582658, -1.318162,
> > -0.2957245, -0.993159, 0.5168112, -1.310361, 0.2813013, -0.7797307,
> > 1.548533, -1.0072, 0.5857817, 1.606338, 0.6956402, -1.187455,
> > -1.363752, 0.2583569, 0.5203429, 0.2434425, -0.8046308, -1.114945,
> > -0.6434187, -0.9872744, -0.5792918, 0.4110919, -1.258956, -0.616523,
> > -0.3439566, 0.8936544, 0.2170967, -1.169243, 0.892866, -1.06335,
> > 0.2329752, 0.6772005, 1.275011, 0.5593982, -1.444531, -0.2763905,
> > 0.9387801, 1.232073, -0.6661146, 0.1706444, -0.2514986, 0.9861698,
> > 0.3247585, 1.582411, 0.2701326, -0.0097, 0.2282059, -1.418496
> > ), N = c(-1.509117, -1.865568, -0.9207457, 1.589874, 0.382475,
> > 0.2372435, 0.1056492, -0.2351283, 0.0642, 1.678718, -0.5379919,
> > 0.4989375, 1.576607, -0.684436, 0.6053467, -0.4453632, 0.3452958,
> > 1.707276, 0.6281493, 0.8101255, 1.759663, 0.1725115, -1.197022,
> > 0.7000259, 0.7414397, -1.926519, -0.5840425, -0.0826, 0.7428133,
> > -0.5476953, 0.7237629, -1.129797, 0.9455895, -0.6096208, -0.6842518,
> > 0.00181, 0.9162412, -1.274803, -1.203836, -0.847842, 0.8018484,
> > 1.195398, 0.9078937, 0.2084386, -1.377868, 1.344439, 1.657746,
> > -0.9019613, 1.267303, 0.0347, -0.9681922, 0.8730431, -0.7356324,
> > 0.4806201, 0.4684249, -0.3170492, 1.126324, 0.7814922, 1.304149,
> > 1.999495, -0.2693311, 1.716548, -1.467723, 0.00245, 0.4545638,
> > 1.448339, -1.192959, -0.0747, -0.6172311, -0.4099933, -0.4685052,
> > 0.556715, -1.523987, 0.4994395, -0.9713943, 0.3854924, 0.246838,
> > 0.0763, -0.1699395, 0.5965068, 1.380759, -1.121356, -0.7884063,
> > 0.1874816, 0.5991878, -1.553753, 1.40589, -1.189748, -0.9560809,
> > -1.059296, -1.190311, -0.6166247, -0.00346, -0.597102, 0.4561315,
> > 0.9741255, -0.8903497, 0.8815181, -0.3522395, -1.083957, 1.553848,
> > 0.8013645, -1.448561, 1.096503, 0.3007325, -1.080419, 0.627004,
> > -1.01452, -1.32398, -0.1690037, -1.808708, -0.8492975, -0.420956
> > ), D = c(0.2536002, 0.9746647, 0.0391, -0.5228497, 0.1569641,
> > 1.047966, 0.0229, -0.0995, 0.2635663, -0.6151057, 0.9903812,
> > -0.3476267, -0.9942705, -1.006192, -1.525466, -0.7323552, 0.2951043,
> > 1.434593, 1.776893, -0.472288, -0.7126557, -0.7370189, 1.95417,
> > -1.370966, 0.7726845, 0.7082534, -0.6715661, 1.17026, -1.16282,
> > 1.173137, -0.4252348, -0.9583436, -0.4809905, -1.418637, 0.2530024,
> > -1.122147, -0.0234, 0.99437, 0.4095966, 0.729747, -0.2727098,
> > -0.6143018, 1.646983, -0.8654616, 0.0658, 0.8169893, 1.01281,
> > -1.794421, 0.788344, -0.1552048, -1.113021, 0.5335623, -0.4326706,
> > 0.2005343, -0.2204396, 1.86017, 0.1751825, -1.363381, 0.6559588,
> > 0.1089933, -0.6156067, -0.1475329, 1.435637, -0.051, -0.9724815,
> > -0.2217541, 0.2237121, -0.2329498, 2.171139, 0.5472844, 1.38426,
> > -1.755075, -0.5630907, 0.31985, -1.853139, 0.8960767, -0.8075317,
> > 0.2993207, -0.641555, 1.363514, 0.3422053, 0.4911866, -1.111221,
> > -0.0137, -0.6198144, -1.292335, 1.118542, -0.000946, -1.619747,
> > 1.677535, -0.8993699, -0.3782237, 0.4151115, -0.2513984, 0.7183175,
> > 1.229746, 1.615256, -1.024167, 0.9041114, -0.6676438, -0.2487,
> > -1.408996, -0.265974, -1.116754, -0.1568737, -1.831107, 1.065047,
> > 0.9980727, 0.935714, 1.137962, -1.070733, 1.876622, -1.579149
> > )), .Names = c("year", "J", "F", "M", "A", "M.1", "J.1", "J.2",
> > "A.1", "S", "O", "N", "D"), class = "data.frame", row.names = c(NA,
> > -113L))
> >
> >
> >
> > On 6 April 2015 at 22:22, John Kane <jrkrideau at inbox.com> wrote:
> >
> >> Reproducibility
> >> https://github.com/hadley/devtools/wiki/Reproducibility
> >>
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >>
> >> > -----Original Message-----
> >> > From: catalinroibu at gmail.com
> >> > Sent: Mon, 6 Apr 2015 20:16:39 +0300
> >> > To: r-help at r-project.org
> >> > Subject: [R] stripchart
> >> >
> >> > Dear all!
> >> >
> >> > I have a problem! I want to plot temperature anomalies per months
> until
> >> > 1901-2014. For this I want to make a stripchart. I used the specified
> >> > command, but I want to plot the extreme values with full dots  above
> >> 90th
> >> > and bellow 10th percentile, and the normal values with hallow dots.
> >> >
> >> > Please help me how to succeed with that!
> >> >
> >> > Thank you!
> >> >
> >> > ?Best regards!
> >> >
> >> > Catalin
> >> >
> >> > --
> >> > ---
> >> > Catalin-Constantin ROIBU
> >> > Lecturer PhD, Forestry engineer
> >> > Forestry Faculty of Suceava
> >> > Str. Universitatii no. 13, Suceava, 720229, Romania
> >> > office phone     +4 0230 52 29 78, ext. 531
> >> > mobile phone   +4 0745 53 18 01
> >> >                        +4 0766 71 76 58
> >> > FAX:                +4 0230 52 16 64
> >> > silvic.usv.ro
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ____________________________________________________________
> >> Can't remember your password? Do you need a strong and secure password?
> >> Use Password manager! It stores your passwords & protects your account.
> >> Check it out at http://mysecurelogon.com/password-manager
> >>
> >>
> >>
> >
> >
> > --
> > ---
> > Catalin-Constantin ROIBU
> > Lecturer PhD, Forestry engineer
> > Forestry Faculty of Suceava
> > Str. Universitatii no. 13, Suceava, 720229, Romania
> > office phone     +4 0230 52 29 78, ext. 531
> > mobile phone   +4 0745 53 18 01
> >                        +4 0766 71 76 58
> > FAX:                +4 0230 52 16 64
> > silvic.usv.ro
> >
>
>
>
> --
> ---
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                        +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr  7 09:18:54 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Apr 2015 17:18:54 +1000
Subject: [R] recode the same subset of variables in several list elements
In-Reply-To: <934A132E-B774-427A-AA93-751D6DD6BD4D@gmail.com>
References: <F43FA97C-4A07-463B-9EDC-7A6C1B2F305A@gmail.com>
	<CA+8X3fURYSwJi7ZuiXusro-f8uM9RYBjod5unhmP1oY7wo3RXg@mail.gmail.com>
	<934A132E-B774-427A-AA93-751D6DD6BD4D@gmail.com>
Message-ID: <CA+8X3fWcQYS4b4+xr5m1n=ogexsnabdQdBqotN2jQ5UfGrtaBg@mail.gmail.com>

Hi Simon,
Let's see. If I wrap the code into a function:

reverse.df.elements<-function(df,pattern="i",newrange=c(3,1)) {
 revlist<-grep(pattern,names(df),fixed=TRUE)
 df[,revlist]<-sapply(df[,revlist],rescale,newrange)
 return(df)
}

Then this might do the trick:

lapply(list1,reverse.df.elements,pattern="i",newrange=c(3,1))

Allowing you to select which elements to reverse and specify the new range.

Jim


On Tue, Apr 7, 2015 at 12:33 AM, Simon Kiss <sjkiss at gmail.com> wrote:

> Hi Jim, So that does the rescale part very efficiently. But I?d like to
> know how to do that on each list element using lapply or llply.  I have
> about 4 data frames and a few other recodes to do so automating would be
> nice, rather than applying your code to each individual list element.
> simon
>
> On Apr 2, 2015, at 6:30 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Simon,
> How about this?
>
> library(plotrix)
> revlist<-grep("i",names(df),fixed=TRUE)
> df[,revlist]<-sapply(df[,revlist],rescale,c(3,1))
>
> Jim
>
>
> On Fri, Apr 3, 2015 at 6:30 AM, Simon Kiss <sjkiss at gmail.com> wrote:
>
>> Hi there: I have a list of data frames with identical variable  names.
>> I?d like to reverse scale the same variables in each data.frame.
>> I?d appreciate any one?s suggestions as to how to accomplish this. Right
>> now, I?m working with the code at the very bottom of my sample data.
>> Thanks, Simon Kiss
>>
>> #Create data.frame1
>> df<-data.frame(
>>   ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>>   ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>>   hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>>   hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>>   evar1=sample(c(1,2,3), replace=TRUE, size=100),
>>   evar2=sample(c(1,2,3), replace=TRUE, size=100)
>>   )
>>
>> #data.frame2
>>   df1<-data.frame(
>>     ivar1=sample(c(1,2,3), replace=TRUE, size=100),
>>     ivar2=sample(c(1,2,3), replace=TRUE, size=100),
>>     hvar1=sample(c(1,2,3), replace=TRUE, size=100),
>>     hvar2=sample(c(1,2,3), replace=TRUE, size=100),
>>     evar1=sample(c(1,2,3), replace=TRUE, size=100),
>>     evar2=sample(c(1,2,3), replace=TRUE, size=100)
>>   )
>>
>> #List
>> list1<-list(df, df1)
>> #vector of first variables I?d like to recode
>> i.recodes<-grep('^i.', names(df), value=TRUE)
>> #Vector of second variables to recode
>> e.recodes<-grep('^e.', names(df), value=TRUE)
>>
>> #Set up RESCALE function from RPMG package
>> RESCALE <- function (x, nx1, nx2, minx, maxx)
>> { nx = nx1 + (nx2 - nx1) * (x - minx)/(maxx - minx)
>>   return(nx)
>> }
>>
>> #This is what I?m playing around with
>> test<-lapply(list1, function(y) {
>>   out<-y[,i.recodes]
>>   out<-lapply(out, function(x) RESCALE(x, 0,1,1,6))
>>   y[,names(x)]<-out
>> })
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr  7 09:22:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Apr 2015 17:22:47 +1000
Subject: [R] strip levels
In-Reply-To: <0325E3E2-17DC-4734-8CE7-97106B14AFA1@comcast.net>
References: <1428381517.61754.YahooMailBasic@web120805.mail.ne1.yahoo.com>
	<0325E3E2-17DC-4734-8CE7-97106B14AFA1@comcast.net>
Message-ID: <CA+8X3fUB-vmW=H4UQkLpC4Cu3mXZT4FWsq+7iy66gTvKoatf2Q@mail.gmail.com>

Hi Chistine,
The latticeExtra package should be included with your installation of R.
Enter:

library(latticeExtra)

in your R session to make it available.

Jim


On Tue, Apr 7, 2015 at 4:28 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Apr 6, 2015, at 9:38 PM, Christine Lee via R-help wrote:
>
> > Thank you Duncan,
> >
> > I am new to R.  Could you please tell me how to download the
> latticeExtra package to get stationx time conditioning?  I am terribly
> sorry that I have read 3-4 R books for dummies but I am still quite
> helpless with using R.  >_<
> >
>
> These books didn't illustrate acquiring packages?
>
> Read:
>
> ?install.packages
>
> Also read the posting guide where it is suggested that you describe your
> setup: R version, operating system, etc.
>
> --
> David.
> > Regards,
> > Christine
> >
> >
> > --------------------------------------------
> > 2015?4?7? ????Duncan Mackay <dulcalma at bigpond.com> ???
> >
> > ??: RE: [R] strip levels
> > ???: "R" <r-help at r-project.org>, "'Christine Lee'"
> > ??: 2015?4?7?,???,??8:57
> >
> > Hi
> >
> > also have a look at useOuterStrips in the
> > latticeExtra package if you want
> > station x
> > time conditioning
> >
> > useOuterStrips(strip      =
> > strip.custom(par.strip.text = list(cex = 0.75)),
> >                strip.left =
> > strip.custom(horizontal = FALSE,
> >
> >                     par.strip.text = list(cex =
> > 0.75)),
> > useOuterStrips(strip      =
> > strip.custom(factor.levels = ... ,
> >
> >
> >    par.strip.text = list(cex = 0.75)),
> >                strip.left =
> > strip.custom(factor.levels =  ...,
> >
> >
> >    horizontal = FALSE,
> >
> >
> >    par.strip.text = par.strip.text =
> > list(cex = 0.75)),
> > histogram(...)
> > ) ##
> > useOuterStrips
> >
> > ... = your
> > code
> >
> > Regards
> >
> > Duncan Mackay
> >
> > Department of Agronomy and
> > Soil Science
> > University of New England
> > Armidale NSW 2351
> > Email: home:
> > mackay at northnet.com.au
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org]
> > On Behalf Of Christine
> > Lee via R-help
> > Sent: Monday, 6 April 2015 21:44
> > To: r-help at r-project.org
> > Subject: [R] strip levels
> >
> > To whom it may help,
> >
> > I am new to R.
> >
> > I have been tring to have a lattice plot in two
> > strip levels: 4 stations in
> > 2 years.
> >
> > I type in:
> >
> > histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> > data=Raw.no10,
> > layout=c(4,2),nin=30,xlab="Prosomal Width
> > (mm)",
> >
> strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.tabl
> > e=TRUE)
> >
> > The
> > second level, i.e. Year, showed as "Raw.no10$Year"
> > in the each of the
> > lattice plot, instead of
> > its respective year, such as "2002" and
> > "2014".
> >
> > I changed
> > to the following programme language, therefore:
> >
> > histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> > data=Raw.no10,
> > layout=c(4,2),nin=30,xlab="Prosomal Width
> > (mm)",
> > strip=strip.custom(bg='white',var.name
> =c("2002","2014")),ylab="Frequencies",
> > tick=-1,col='grey',as.table=TRUE)
> >
> > in order to specify the
> > variable names of the strip.
> >
> > Instead of showing "Raw.no10$Year",
> > [[elided Yahoo spam]]
> > They should have 4 plots showing
> > "2002" and another 4 showing "2014".
> >
> > Could any one help indicating
> > what has gone wrong?
> >
> > I am
> > really helpless and frustrated now.  T_T
> >
> > Regards,
> > Christine
> >
> > ______________________________________________
> > R-help at r-project.org
> > mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Apr  7 09:57:33 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 07 Apr 2015 08:57:33 +0100
Subject: [R] strip levels
In-Reply-To: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>
References: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>
Message-ID: <55238DED.4050106@dewey.myzen.co.uk>

Dear Christine
Are you sure that your variable Year is not numeric? You example plot 
looks to me as though it is treating it as a shingle.

What does str(Raw.no10) tell you about Year?

On 06/04/2015 17:40, Christine Lee wrote:
> Thank you very much to Both Sarah and Michael,
>
> Your responses are deeply appreciated.  TxT
>
> I have omitted the reinstatement of the data source as follows:
>
> library(lattice)
> histogram(~Width|Station*Year, data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>
> Instead of showing respective year of 2002 and 2014 in each of the lattice plot, it just shows "Year" in all lattice plot as attached.  TxT
>
> Do you know what has gone wrong?
>
> Many thanks.
>
> Regards,
> Christine
>
>
>
>
> --------------------------------------------
> 2015?4?6? ????Michael Dewey <lists at dewey.myzen.co.uk> ???
>
>   ??: Re: [R] strip levels
>   ???: "Sarah Goslee" <sarah.goslee at gmail.com>, "Christine Lee" <leptostracan at yahoo.com>
>   ??(CC): "r-help" <r-help at r-project.org>
>   ??: 2015?4?6?,???,??11:15
>
>   See inline
>
>   On 06/04/2015 15:39, Sarah
>   Goslee wrote:
>   > Hi,
>   >
>   > On Mon, Apr 6, 2015
>   at 7:44 AM, Christine Lee via R-help
>   >
>   <r-help at r-project.org>
>   wrote:
>   >> To whom it may help,
>   >>
>   >> I am new to
>   R.
>   >>
>   >> I have
>   been tring to have a lattice plot in two strip levels: 4
>   stations in 2 years.
>   >>
>   >> I type in:
>   >>
>   >>
>   histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
>   data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
>   Width (mm)",
>   strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>   >
>   > In both examples,
>   you're mis-stating the data. Given the data
>   > argument, you do not need to restate the
>   data source.
>   >
>   >
>   histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,
>
>   I think Sarah meant to type
>   Station * Year and not as above
>
>   >
>   layout=c(4,2),nin=30,xlab="Prosomal Width
>   (mm)",
>   >
>   strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>   >
>   > If that doesn't
>   solve your problem, then please use
>   >
>   dput(head(Raw.no10), 20) to provide some example data, or
>   create fake
>   > data of the same
>   structure.
>   >
>   > Without
>   a reproducible example that includes some sample data (fake
>   is
>   > fine), the code you used, and some
>   clear idea of what output you
>   > expect,
>   it's impossible to figure out how to help you. Here are
>   some
>   > suggestions for creating a good
>   reproducible example:
>   > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>   >
>   >
>   >> The second level, i.e. Year, showed as
>   "Raw.no10$Year" in the each of the lattice plot,
>   instead of its respective year, such as "2002" and
>   "2014".
>   >>
>   >> I changed to the following programme
>   language, therefore:
>   >>
>   >>
>   histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
>   data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
>   Width (mm)",
>   strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)
>   >>
>   >> in order to
>   specify the variable names of the strip.
>   >>
>   >> Instead of
>   showing "Raw.no10$Year", each of the lattice plot
>   states "2014"!  They should have 4 plots showing
>   "2002" and another 4 showing "2014".
>   >>
>   >> Could any one
>   help indicating what has gone wrong?
>   >>
>   >> I am really
>   helpless and frustrated now.  T_T
>   >>
>   >> Regards,
>   >> Christine
>   >
>   >
>
>   --
>   Michael
>   http://www.dewey.myzen.co.uk/home.html
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From marcgg.lamblin at gmail.com  Tue Apr  7 10:24:38 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Tue, 7 Apr 2015 10:24:38 +0200
Subject: [R] Verify that a grid is uniform
In-Reply-To: <CACk-te1=twvWdSYDFj=7GoBVHuN2xx_z1nwokT4EDqH-BtrfUA@mail.gmail.com>
References: <CABYYu7uBPK_Skm-tasS2-QHDnbQOw3HUo+VwrfybK3uJoCJ8=g@mail.gmail.com>
	<CAM_vjumA0UZ3A4-x3ek3htNnPmYs5zWXwrng+61zzFLkL=Jo_A@mail.gmail.com>
	<CABYYu7vkvcLu44DsKTMXG6=9UWrU+-Q5GaEugfpT9ydvrUXifQ@mail.gmail.com>
	<CACk-te31BOYRvnRRPy=V_VOtfMDQimtCareXRpbRNyep7w50Qw@mail.gmail.com>
	<CACk-te0tW0fL-fkDDfRY0-nAvC_me4+75=U8aD8gD+Xnd_ssNQ@mail.gmail.com>
	<CABYYu7vRu7BfoySakgQ5nTNF0zoRMBSPxpLZyCP8otwF6UcApA@mail.gmail.com>
	<CACk-te1=twvWdSYDFj=7GoBVHuN2xx_z1nwokT4EDqH-BtrfUA@mail.gmail.com>
Message-ID: <CABYYu7tBt6oZmfeHoUbFPN8Xz+66qqih8-jcEL1rVuzJRUL8hA@mail.gmail.com>

Yes, it could be a reasonable choice but I am not sure in general. If
min(abs(diff(z))) is significant (global minimum or accentuated local
minimum) my abscissa is not uniform a priori without performing the control.

2015-04-07 0:55 GMT+02:00 Bert Gunter <gunter.berton at gene.com>:

> Does not min(abs(diff(z))) give you the scaling you need to set a
> tolerance?
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Mon, Apr 6, 2015 at 2:55 PM, Marc Lamblin <marcgg.lamblin at gmail.com>
> wrote:
> > The first solution with diff works for uniform abscissa only with integer
> > values.
> >
> > z <- seq(0, 10, length=100)
> > all(diff(z) == z[2] - z[1] )
> > ## FALSE
> >
> > In this case, as you recommended, I could use signif or round or a
> tolerance
> > for real numbers. In my particular case, in order to set a tolerance, I
> need
> > the scale used and I don't have this information. I prefer to test the
> "near
> > uniformity".
> > I didn't know the function zapsmall. It could be useful!
> > Thanks Sarah and Bert!!!
> >
> > Marc
> >
> >
> >
> >
> >
> > 2015-04-06 19:51 GMT+02:00 Bert Gunter <gunter.berton at gene.com>:
> >>
> >> ... correction: you need to use absolute value for the comparison, of
> >> course.
> >>
> >> all(abs(diff(z) - z[2] + z[1]) < tol)
> >>
> >> -- Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Mon, Apr 6, 2015 at 10:47 AM, Bert Gunter <bgunter at gene.com> wrote:
> >> > Perhaps ?diff might be useful here:
> >> >
> >> > z <- runif(20)
> >> > all(diff(z) == z[2] - z[1] )
> >> > ## FALSE
> >> >
> >> > z <- seq_len(10)
> >> > all(diff(z) == z[2] - z[1] )
> >> > ##TRUE
> >> >
> >> > You can use signif or round as before to allow for "near uniformity"
> >> > or use ?zapsmall or an explicit comparison with a tolerancec instead
> >> > of ==, e.g. all(diff(z) - z[2] + z[1] < tol)
> >> >
> >> > Cheers,
> >> > Bert
> >> >
> >> > Bert Gunter
> >> > Genentech Nonclinical Biostatistics
> >> > (650) 467-7374
> >> >
> >> > "Data is not information. Information is not knowledge. And knowledge
> >> > is certainly not wisdom."
> >> > Clifford Stoll
> >> >
> >> >
> >> >
> >> >
> >> > On Mon, Apr 6, 2015 at 10:11 AM, Marc Lamblin <
> marcgg.lamblin at gmail.com>
> >> > wrote:
> >> >> The aim is to control if a given abscissa/grid is uniform or not.
> >> >> Abscissa
> >> >> in generic vector of real ordered numbers.
> >> >>
> >> >> Here a reproducibile code:
> >> >>
> >> >> # uniform abscissa/grid
> >> >> abscissa1 <- seq(0, 1, length=100)
> >> >> # non-uniform abscissa/grid
> >> >> abscissa2 <- sort(runif(100))
> >> >>
> >> >> control1 <- all(signif(abscissa1[1:(length(abscissa1) - 1) + 1] -
> >> >> abscissa1[1:(length(abscissa1) - 1)]) ==
> >> >> signif(rep((range(abscissa1)[2] -
> >> >> range(abscissa1)[1])/(length(abscissa1) - 1), length(abscissa1) -
> 1)))
> >> >> control2 <- all(signif(abscissa2[1:(length(abscissa2) - 1) + 1] -
> >> >> abscissa2[1:(length(abscissa2) - 1)]) ==
> >> >> signif(rep((range(abscissa2)[2] -
> >> >> range(abscissa2)[1])/(length(abscissa2) - 1), length(abscissa2) -
> 1)))
> >> >>
> >> >> control1
> >> >> control2
> >> >>
> >> >> As expected control1 is TRUE and control2 is FALSE. Actually in this
> >> >> code
> >> >> it is possible also to use
> >> >> diff inside signif.
> >> >> Do you mean that the control to perform can be done in this manner
> >> >>
> >> >> if (length(unique(diff(vec))) == 1) {
> >> >>   control <- TRUE
> >> >> } else {
> >> >>   control <- FALSE
> >> >> }
> >> >>
> >> >> I have tried to apply this control on abscissa1 which is uniform but
> >> >> length(unique(diff(abscissa1))) was greater than one; probably, as
> you
> >> >> said, this is due to the fact that in this way I don't take into
> >> >> account
> >> >> the machine precision.
> >> >> What I want to understand is if there is a SAFE solution, even if
> until
> >> >> now
> >> >> this control is working correctly. I have seen in the documentation
> of
> >> >> signif that by default the number of digits considered are 6. The
> >> >> number of
> >> >> digits to consider depends on the scale used. It doesn't make sense
> to
> >> >> increase the number of digits with respect to default because, in
> this
> >> >> case, you are not using an handy scale.
> >> >> Maybe it could be better directly to ask user if the abscissa passed
> as
> >> >> argument is uniform or not.
> >> >> Thanks a lot for the link!!!
> >> >>
> >> >> Marc
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> 2015-04-06 16:32 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
> >> >>
> >> >>> Without a reproducible example that includes some sample data (fake
> is
> >> >>> fine), the code you used (NOT in HTML format), and some clear idea
> of
> >> >>> what output you expect, it's impossible to figure out how to help
> you.
> >> >>> Here are some suggestions for creating a good reproducible example:
> >> >>>
> >> >>>
> >> >>>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> >>>
> >> >>> Without knowing what you want, it looks like abscissa is a vector,
> and
> >> >>> so I'm not sure how this defines a grid, but
> >> >>> length(unique(diff(vec)))
> >> >>> might help. Note that this DOES NOT account for machine precision in
> >> >>> any
> >> >>> way.
> >> >>>
> >> >>> Sarah
> >> >>>
> >> >>> On Mon, Apr 6, 2015 at 7:50 AM, Marc Lamblin
> >> >>> <marcgg.lamblin at gmail.com>
> >> >>> wrote:
> >> >>> > I need to control of a given grid is uniform. This control using
> >> >>> > signif
> >> >>> > until now works:
> >> >>> >
> >> >>> > if (all(signif(abscissa[1:(length(abscissa) - 1) + 1] -
> >> >>> > abscissa[1:(length(abscissa) - 1)]) ==
> >> >>> > signif(rep((range(abscissa)[2] -
> >> >>> >          range(abscissa)[1])/(length(abscissa) - 1),
> >> >>> > length(abscissa) -
> >> >>> > 1)))) {
> >> >>> > # other stuff
> >> >>> > }
> >> >>> >
> >> >>> > Does someone have some suggestions to improve this control? Thanks
> >> >>> > in
> >> >>> > advance!! :)
> >> >>> >
> >> >>> > Marc
> >> >>> >
> >> >>> >         [[alternative HTML version deleted]]
> >> >>> >
> >> >>>
> >> >>>
> >> >>> --
> >> >>> Sarah Goslee
> >> >>> http://www.functionaldiversity.org
> >> >>>
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Apr  7 11:33:47 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 7 Apr 2015 09:33:47 +0000
Subject: [R] strip levels
In-Reply-To: <55238DED.4050106@dewey.myzen.co.uk>
References: <1428338437.94232.YahooMailBasic@web120804.mail.ne1.yahoo.com>
	<55238DED.4050106@dewey.myzen.co.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C26381@SRVEXCHMBX.precheza.cz>

Hi

As Michael suggested your Year variable is probably numeric. Quick fix could be.

histogram(~Width|Station*as.factor(Year), data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal Width (mm)", strip=strip.custom(bg='white'),ylab="Frequencies",tick=-1,col='grey',as.table=TRUE)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Tuesday, April 07, 2015 9:58 AM
> To: Christine Lee; Sarah Goslee
> Cc: r-help
> Subject: Re: [R] strip levels
>
> Dear Christine
> Are you sure that your variable Year is not numeric? You example plot
> looks to me as though it is treating it as a shingle.
>
> What does str(Raw.no10) tell you about Year?
>
> On 06/04/2015 17:40, Christine Lee wrote:
> > Thank you very much to Both Sarah and Michael,
> >
> > Your responses are deeply appreciated.  TxT
> >
> > I have omitted the reinstatement of the data source as follows:
> >
> > library(lattice)
> > histogram(~Width|Station*Year, data=Raw.no10,
> > layout=c(4,2),nin=30,xlab="Prosomal Width (mm)",
> > strip=strip.custom(bg='white'),ylab="Frequencies",tick=-
> 1,col='grey',a
> > s.table=TRUE)
> >
> > Instead of showing respective year of 2002 and 2014 in each of the
> > lattice plot, it just shows "Year" in all lattice plot as attached.
> > TxT
> >
> > Do you know what has gone wrong?
> >
> > Many thanks.
> >
> > Regards,
> > Christine
> >
> >
> >
> >
> > --------------------------------------------
> > 2015?4?6? ????Michael Dewey <lists at dewey.myzen.co.uk> ???
> >
> >   ??: Re: [R] strip levels
> >   ???: "Sarah Goslee" <sarah.goslee at gmail.com>, "Christine Lee"
> <leptostracan at yahoo.com>
> >   ??(CC): "r-help" <r-help at r-project.org>
> >   ??: 2015?4?6?,???,??11:15
> >
> >   See inline
> >
> >   On 06/04/2015 15:39, Sarah
> >   Goslee wrote:
> >   > Hi,
> >   >
> >   > On Mon, Apr 6, 2015
> >   at 7:44 AM, Christine Lee via R-help
> >   >
> >   <r-help at r-project.org>
> >   wrote:
> >   >> To whom it may help,
> >   >>
> >   >> I am new to
> >   R.
> >   >>
> >   >> I have
> >   been tring to have a lattice plot in two strip levels: 4
> >   stations in 2 years.
> >   >>
> >   >> I type in:
> >   >>
> >   >>
> >   histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> >   data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
> >   Width (mm)",
> >   strip=strip.custom(bg='white'),ylab="Frequencies",tick=-
> 1,col='grey',as.table=TRUE)
> >   >
> >   > In both examples,
> >   you're mis-stating the data. Given the data
> >   > argument, you do not need to restate the
> >   data source.
> >   >
> >   >
> >   histogram(~Width | Station*Raw.no10$Year, data=Raw.no10,
> >
> >   I think Sarah meant to type
> >   Station * Year and not as above
> >
> >   >
> >   layout=c(4,2),nin=30,xlab="Prosomal Width
> >   (mm)",
> >   >
> >   strip=strip.custom(bg='white'),ylab="Frequencies",tick=-
> 1,col='grey',as.table=TRUE)
> >   >
> >   > If that doesn't
> >   solve your problem, then please use
> >   >
> >   dput(head(Raw.no10), 20) to provide some example data, or
> >   create fake
> >   > data of the same
> >   structure.
> >   >
> >   > Without
> >   a reproducible example that includes some sample data (fake
> >   is
> >   > fine), the code you used, and some
> >   clear idea of what output you
> >   > expect,
> >   it's impossible to figure out how to help you. Here are
> >   some
> >   > suggestions for creating a good
> >   reproducible example:
> >   > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example
> >   >
> >   >
> >   >> The second level, i.e. Year, showed as
> >   "Raw.no10$Year" in the each of the lattice plot,
> >   instead of its respective year, such as "2002" and
> >   "2014".
> >   >>
> >   >> I changed to the following programme
> >   language, therefore:
> >   >>
> >   >>
> >   histogram(~Raw.no10$Width|Raw.no10$Station*Raw.no10$Year,
> >   data=Raw.no10, layout=c(4,2),nin=30,xlab="Prosomal
> >   Width (mm)",
> >
> strip=strip.custom(bg='white',var.name=c("2002","2014")),ylab="Frequenc
> ies",tick=-1,col='grey',as.table=TRUE)
> >   >>
> >   >> in order to
> >   specify the variable names of the strip.
> >   >>
> >   >> Instead of
> >   showing "Raw.no10$Year", each of the lattice plot
> >   states "2014"!  They should have 4 plots showing
> >   "2002" and another 4 showing "2014".
> >   >>
> >   >> Could any one
> >   help indicating what has gone wrong?
> >   >>
> >   >> I am really
> >   helpless and frustrated now.  T_T
> >   >>
> >   >> Regards,
> >   >> Christine
> >   >
> >   >
> >
> >   --
> >   Michael
> >   http://www.dewey.myzen.co.uk/home.html
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr  7 13:07:25 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 7 Apr 2015 13:07:25 +0200
Subject: [R] Trim and fill procedure
In-Reply-To: <5522822A.6040502@dewey.myzen.co.uk>
References: <DUB122-W32E7B4112E469625EC90C1C0F00@phx.gbl>
	<5522822A.6040502@dewey.myzen.co.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F09A1F85F@UM-MAIL4112.unimaas.nl>

Yes, a comparison of the two objects would tell you what's been added.

An object returned by the trimfill() function also has a vector added to it, named 'fill', which indicates whether the data (which are stored in the vector 'yi') are observed or augmented values. So, for example:

library(metafor)

### load BCG vaccine data
data(dat.bcg)

### meta-analysis of the log relative risks using a fixed-effects model
res <- rma(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, method="FE")

### trim and fill analysis
tmp <- trimfill(res)

### show log relative risks and dummy variable to indicate augmented values
data.frame(tmp$yi, tmp$fill)

### that's in fact how the funnel() function knows how to draw the points when you do:
funnel(tmp)

Best,
Wolfgang

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Monday, April 06, 2015 14:55
> To: Carlijn Wibbelink; r-help at r-project.org
> Subject: Re: [R] Trim and fill procedure
> 
> Hello Carlijn
> 
> Well the documentation for trimfill says they are added.
> 
> library(metafor)
> example(trimfill)
> 
> This now leaves you with
> res
> res.tf
> 
> By looking at these and seeing which vectors have grown you should be
> able to extract the yi and vi which you want.
> 
> Wolfgang will doubtless be on the list soon to tell us there is a neater
> way of doing this.
> 
> On 04/04/2015 21:27, Carlijn Wibbelink wrote:
> > Hi all,
> >
> > I have a question concerning the trim and fill procedure in metafor. In
> STATA it is possible to obtain the values of the added estimated effect
> sizes. I was wondering if this is also possible in R and if so, how I can
> obtain the new data with the added values.
> > I would really appreciate your response.
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From s-dhar at northwestern.edu  Tue Apr  7 16:47:31 2015
From: s-dhar at northwestern.edu (Sumitrajit Dhar)
Date: Tue, 7 Apr 2015 14:47:31 +0000
Subject: [R] Assembling output of table()
Message-ID: <F9B9A821-F688-4CAF-94FB-4162F1CC3A31@northwestern.edu>

Hi folks,

I am struggling with something that should be simple.

Here is my data frame:
head(jData[,1:8])
  x study_id qx_1_v4j qx_1a_v4j qx_1b_v4j qx_2_v4j qx_2a_v4j qx_3_v4j
1 1  MCJ1001        1         1         1        1         1        1
2 2  MCJ1002        1         1         2        1         2        0
3 3  MCJ1003        1         1         1        0        NA        1
4 4  MCJ1004        1         1         2        1         3        0
5 5  MCJ1005        1         1         1        1         1        1
6 6  MCJ1006        1         1         0        1         3        0


I want to run table() on each of the columns and compile the results into a single list/table/whatever works with the first column being the column name. The resulting output will have different numbers of columns per row.

Is this possible?

Regards, 
Sumit


From ruipbarradas at sapo.pt  Tue Apr  7 17:34:49 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 07 Apr 2015 16:34:49 +0100
Subject: [R] Assembling output of table()
In-Reply-To: <F9B9A821-F688-4CAF-94FB-4162F1CC3A31@northwestern.edu>
References: <F9B9A821-F688-4CAF-94FB-4162F1CC3A31@northwestern.edu>
Message-ID: <5523F919.1050709@sapo.pt>

Hello,

Maybe something like th following.

lapply(jData, table)

Hope this helps,

Rui Barradas

Em 07-04-2015 15:47, Sumitrajit Dhar escreveu:
> Hi folks,
>
> I am struggling with something that should be simple.
>
> Here is my data frame:
> head(jData[,1:8])
>    x study_id qx_1_v4j qx_1a_v4j qx_1b_v4j qx_2_v4j qx_2a_v4j qx_3_v4j
> 1 1  MCJ1001        1         1         1        1         1        1
> 2 2  MCJ1002        1         1         2        1         2        0
> 3 3  MCJ1003        1         1         1        0        NA        1
> 4 4  MCJ1004        1         1         2        1         3        0
> 5 5  MCJ1005        1         1         1        1         1        1
> 6 6  MCJ1006        1         1         0        1         3        0
>
>
> I want to run table() on each of the columns and compile the results into a single list/table/whatever works with the first column being the column name. The resulting output will have different numbers of columns per row.
>
> Is this possible?
>
> Regards,
> Sumit
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 at gmail.com  Tue Apr  7 17:57:59 2015
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 7 Apr 2015 09:57:59 -0600
Subject: [R] Simulate values
In-Reply-To: <1428360724353-4705574.post@n4.nabble.com>
References: <1428360724353-4705574.post@n4.nabble.com>
Message-ID: <CAFEqCdwdVyrihEC+t7_3F6tvdqP7bXwVdYrcW_3CaWCOotXSoA@mail.gmail.com>

Thanks for your final paragraph, we sometimes see people who want us
to do their homework for them and that does not go over well, but I
think you situation is one where many would be happy to help.  So here
are some hints to help:

The rnorm command expects the standard deviation, not the variance, so
to generate normals with variance equal to 25 you need to specify the
square root (5) as the 3rd argument.

The rep command will just repeat the 40 random number 500 times, not
generate new ones, so you will have the exact same sample (and all in
one long vector).  There are a few different ways to do this, but for
easiest understanding I would suggest using the replicate function,
this function will run a set of code the requested number of times, so
think about how you would generate your data and compute the test
statistic from the generated data, then pass that code to the
replicate function (if it is more than 1 line then use curly brackets
({}) to group the lines of code) to generate your 500 test statistics.

On Mon, Apr 6, 2015 at 4:52 PM, Osiris10101 <osiris94 at gmx.ch> wrote:
> Hello,
>
> I'm facing the following task:
> Simulate 500 values of the statistic (n-1)s^2/sigma^2 based on taking 500
> samples of size n=40
> from the N(mu=10; sigma^2 = 25) distribution.
>
> I think with the following command:
> rep(rnorm(40,10,25),times=500)
> I was able to simulate the samples but how I now can simulate the values of
> the chi-square-distribution is a mystery to me...
>
> I hope anyone can help me, shouldn't be a big problem...
>
> Thanks in advance!
>
> Reason for posting:
> I started a course at the University of Manchester and had to catch up with
> R, which I never used back in Switzerland. Now I'm solving some exercises to
> get more practice and this is one of them.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Simulate-values-tp4705574.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From optionsraghu at gmail.com  Tue Apr  7 18:30:53 2015
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Tue, 7 Apr 2015 17:30:53 +0100
Subject: [R] Unable to Scale/Display properly in plotting a xts/timeseries
 graph in a single plot
Message-ID: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>

Dear guRus

I have xts data as:
str(volsA)
An ?xts? object on 2014-05-13/2015-04-07 containing:
  Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:2] "vol1" "vol2"
  Indexed by objects of class: [Date] TZ: UTC
  xts Attributes:
List of 1
 $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
1.4e+09 ...
>
I am trying t0 plot them in a single frame but the scaling does not
happen properly.

plot(vols,plot.type="s",format="auto")
lines(vols[,2],col="red")

The lower graph in red gets displayed as a truncated graph and does
not fully exhibit the relationship. Can someone kindly help in
scaling/display please?

Thanks
Raghu


From josh.m.ulrich at gmail.com  Tue Apr  7 18:47:52 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 7 Apr 2015 11:47:52 -0500
Subject: [R] Unable to Scale/Display properly in plotting a
 xts/timeseries graph in a single plot
In-Reply-To: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
References: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
Message-ID: <CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>

On Tue, Apr 7, 2015 at 11:30 AM, Raghuraman Ramachandran
<optionsraghu at gmail.com> wrote:
> Dear guRus
>
> I have xts data as:
> str(volsA)
> An ?xts? object on 2014-05-13/2015-04-07 containing:
>   Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : NULL
>   ..$ : chr [1:2] "vol1" "vol2"
>   Indexed by objects of class: [Date] TZ: UTC
>   xts Attributes:
> List of 1
>  $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
>   .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
> 1.4e+09 ...
>>
> I am trying t0 plot them in a single frame but the scaling does not
> happen properly.
>
> plot(vols,plot.type="s",format="auto")
> lines(vols[,2],col="red")
>
> The lower graph in red gets displayed as a truncated graph and does
> not fully exhibit the relationship. Can someone kindly help in
> scaling/display please?
>
What's the output of sessionInfo() from your R session?

> Thanks
> Raghu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From optionsraghu at gmail.com  Tue Apr  7 19:10:15 2015
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Tue, 7 Apr 2015 18:10:15 +0100
Subject: [R] Unable to Scale/Display properly in plotting a
 xts/timeseries graph in a single plot
In-Reply-To: <CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
References: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
	<CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
Message-ID: <CADgEnDnxnCgX-BJEPKtBc3aRFW3FtUGP5xpfEpzeEz1PB2FPHg@mail.gmail.com>

Thanks Josh. I am not sure if I can attach a Jpeg. Please find attached.

On Tue, Apr 7, 2015 at 5:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Tue, Apr 7, 2015 at 11:30 AM, Raghuraman Ramachandran
> <optionsraghu at gmail.com> wrote:
>> Dear guRus
>>
>> I have xts data as:
>> str(volsA)
>> An ?xts? object on 2014-05-13/2015-04-07 containing:
>>   Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
>>  - attr(*, "dimnames")=List of 2
>>   ..$ : NULL
>>   ..$ : chr [1:2] "vol1" "vol2"
>>   Indexed by objects of class: [Date] TZ: UTC
>>   xts Attributes:
>> List of 1
>>  $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
>>   .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
>> 1.4e+09 ...
>>>
>> I am trying t0 plot them in a single frame but the scaling does not
>> happen properly.
>>
>> plot(vols,plot.type="s",format="auto")
>> lines(vols[,2],col="red")
>>
>> The lower graph in red gets displayed as a truncated graph and does
>> not fully exhibit the relationship. Can someone kindly help in
>> scaling/display please?
>>
> What's the output of sessionInfo() from your R session?
>
>> Thanks
>> Raghu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com

From josh.m.ulrich at gmail.com  Tue Apr  7 19:16:24 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 7 Apr 2015 12:16:24 -0500
Subject: [R] Unable to Scale/Display properly in plotting a
 xts/timeseries graph in a single plot
In-Reply-To: <CADgEnDnxnCgX-BJEPKtBc3aRFW3FtUGP5xpfEpzeEz1PB2FPHg@mail.gmail.com>
References: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
	<CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
	<CADgEnDnxnCgX-BJEPKtBc3aRFW3FtUGP5xpfEpzeEz1PB2FPHg@mail.gmail.com>
Message-ID: <CAPPM_gT_XFrvjAOyBMDbAL-a1TwQzWkxqXbmks6kDELCaWN57w@mail.gmail.com>

The sessionInfo() function does not create a plot...

On Tue, Apr 7, 2015 at 12:10 PM, Raghuraman Ramachandran
<optionsraghu at gmail.com> wrote:
> Thanks Josh. I am not sure if I can attach a Jpeg. Please find attached.
>
> On Tue, Apr 7, 2015 at 5:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> On Tue, Apr 7, 2015 at 11:30 AM, Raghuraman Ramachandran
>> <optionsraghu at gmail.com> wrote:
>>> Dear guRus
>>>
>>> I have xts data as:
>>> str(volsA)
>>> An ?xts? object on 2014-05-13/2015-04-07 containing:
>>>   Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
>>>  - attr(*, "dimnames")=List of 2
>>>   ..$ : NULL
>>>   ..$ : chr [1:2] "vol1" "vol2"
>>>   Indexed by objects of class: [Date] TZ: UTC
>>>   xts Attributes:
>>> List of 1
>>>  $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
>>>   .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
>>> 1.4e+09 ...
>>>>
>>> I am trying t0 plot them in a single frame but the scaling does not
>>> happen properly.
>>>
>>> plot(vols,plot.type="s",format="auto")
>>> lines(vols[,2],col="red")
>>>
>>> The lower graph in red gets displayed as a truncated graph and does
>>> not fully exhibit the relationship. Can someone kindly help in
>>> scaling/display please?
>>>
>> What's the output of sessionInfo() from your R session?
>>
>>> Thanks
>>> Raghu
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From wdunlap at tibco.com  Tue Apr  7 19:29:35 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 7 Apr 2015 10:29:35 -0700
Subject: [R] Unable to Scale/Display properly in plotting a
 xts/timeseries graph in a single plot
In-Reply-To: <CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
References: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
	<CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
Message-ID: <CAF8bMcbXDGHR0mzCDJMCyQNTBC6fEZ2e7uDOL-DXO2E9Hcs9XQ@mail.gmail.com>

> plot(vols,plot.type="s",format="auto")
> lines(vols[,2],col="red")

Did you get any warning messages when you did that?  I get
  > library(xts)
  > z <- xts(cbind(One=sin(1:20), Two=cos(1:20)+1.5), order.by
=as.Date("2015-04-06")+(0:19))
  > plot(z)
  Warning message:
  In plot.xts(z) : only the univariate series will be plotted
and the y limits on the plot are at about c(-1,1).  Thus the
added points in z[,2] will not all be within the limits.

You need to supply ylim=range(z) in the plot call if you want
the limits to include the range of the second column of z.
  > plot(z[,1], ylim=range(z))
  > lines(z[,2], col="red")


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 7, 2015 at 9:47 AM, Joshua Ulrich <josh.m.ulrich at gmail.com>
wrote:

> On Tue, Apr 7, 2015 at 11:30 AM, Raghuraman Ramachandran
> <optionsraghu at gmail.com> wrote:
> > Dear guRus
> >
> > I have xts data as:
> > str(volsA)
> > An ?xts? object on 2014-05-13/2015-04-07 containing:
> >   Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
> >  - attr(*, "dimnames")=List of 2
> >   ..$ : NULL
> >   ..$ : chr [1:2] "vol1" "vol2"
> >   Indexed by objects of class: [Date] TZ: UTC
> >   xts Attributes:
> > List of 1
> >  $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
> >   .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
> > 1.4e+09 ...
> >>
> > I am trying t0 plot them in a single frame but the scaling does not
> > happen properly.
> >
> > plot(vols,plot.type="s",format="auto")
> > lines(vols[,2],col="red")
> >
> > The lower graph in red gets displayed as a truncated graph and does
> > not fully exhibit the relationship. Can someone kindly help in
> > scaling/display please?
> >
> What's the output of sessionInfo() from your R session?
>
> > Thanks
> > Raghu
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Tue Apr  7 21:31:49 2015
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 7 Apr 2015 21:31:49 +0200
Subject: [R] Fast multiple match function
In-Reply-To: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
	(Keshav Dhandhania's message of "Mon, 6 Apr 2015 20:56:30 +0000")
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
Message-ID: <87k2xng2fu.fsf@enricoschumann.net>

On Mon, 06 Apr 2015, Keshav Dhandhania <kshav.91 at gmail.com> writes:

> Hi,
>
> I know that one can find all occurrences of x in a vector v by doing
>> which(x == v).
>
> However, if I need to do this again and again, where v is remaining the
> same, then this is quite inefficient. In my particular case, I need to do
> this millions of times, and length(v) = 100 million.
>
> Does anyone have suggestion on how to go about it?
> I know of a package called fmatch that does the above for the match
> function. But they don't handle multiple matches.
>

Perhaps 'match(x, v)' is what you want? In which 'x' may be a vector of
length > 1.

In any case, have you actually tried package 'fastmatch'? The function
'fmatch', which that package provides, is very fast for repeated
lookups in a table 'v'.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From hpages at fredhutch.org  Tue Apr  7 22:21:51 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 7 Apr 2015 13:21:51 -0700
Subject: [R] Fast multiple match function
In-Reply-To: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
Message-ID: <55243C5F.7060000@fredhutch.org>

Hi Keshav,

findMatches() in the S4Vectors/IRanges packages (Bioconductor) I think
does what you want:

   library(IRanges)
   y <- c(16L, -3L, -2L, 15L, 15L, 0L, 8L, 15L, -2L)
   x <- c(unique(y), 999L)
   hits <- findMatches(x, y)

Then:

   > hits
   Hits object with 9 hits and 0 metadata columns:
         queryHits subjectHits
         <integer>   <integer>
     [1]         1           1
     [2]         2           2
     [3]         3           3
     [4]         3           9
     [5]         4           4
     [6]         4           5
     [7]         4           8
     [8]         5           6
     [9]         6           7
     -------
     queryLength: 7
     subjectLength: 9

The Hits object can be turned into a list with:

   > as.list(hits)
   [[1]]
   [1] 1

   [[2]]
   [1] 2

   [[3]]
   [1] 3 9

   [[4]]
   [1] 4 5 8

   [[5]]
   [1] 6

   [[6]]
   [1] 7

   [[7]]
   integer(0)

H.

 > sessionInfo()
R version 3.2.0 beta (2015-04-05 r68151)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
[1] IRanges_2.1.43       S4Vectors_0.5.22     BiocGenerics_0.13.11

loaded via a namespace (and not attached):
[1] tools_3.2.0

On 04/06/2015 01:56 PM, Keshav Dhandhania wrote:
> Hi,
>
> I know that one can find all occurrences of x in a vector v by doing
>> which(x == v).
>
> However, if I need to do this again and again, where v is remaining the
> same, then this is quite inefficient. In my particular case, I need to do
> this millions of times, and length(v) = 100 million.
>
> Does anyone have suggestion on how to go about it?
> I know of a package called fmatch that does the above for the match
> function. But they don't handle multiple matches.
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kshav.91 at gmail.com  Tue Apr  7 22:50:39 2015
From: kshav.91 at gmail.com (Keshav Dhandhania)
Date: Tue, 7 Apr 2015 13:50:39 -0700
Subject: [R] Fast multiple match function
In-Reply-To: <55243C5F.7060000@fredhutch.org>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
	<55243C5F.7060000@fredhutch.org>
Message-ID: <CAO3abBrSASVERgRScjW=Ujp1J_U0x9K9AyPiXGQHmsZJ-tLR+Q@mail.gmail.com>

Hi all,

Thanks for the responses.
Herve's example is a good small size example of what I wanted.

> y <- c(16, -3, -2, 15, 15, 0, 8, 15, -2)
> someCoolFunc(-2, y)
[1] 3 9
> someCoolFunc(15, y)
[1] 4 5 8

The requirement is that I want someCoolFunc() to run in O(number of
matches) time, instead of O(size of y).
This is because y is big. And I don't know all the queries I want to
do up-front. And the results of some queries might change the queries
I want to do in the future.

@David: I hope the above description is more clear.
@Enrico, Herve: I want both the functionality provided by one function.
- On repeated calls, fmatch() does give O(1) performance, but it does
not give all matches.
- findMatches() gives all matches, but I need to know the entire
vector x beforehand. I don't have that luxury.


I do have something that works now, using split and fmatch (package
fastmatch). So just posting that in case anyone in the future has the
same problem.
> y.unique <- unique(y)
>
> # create a map from the unique elements of y to the locations of all occurrences of the element
> y.map <- split(1:length(y), match(y, y.unique))
>
> # write a wrapper function that does a look-up on the unique list. and then returns all matches using the map.
> someCoolFunc <- function(x) { y.map[[ fmatch(x, y.unique) ]] }



On Tue, 7 Apr 2015 at 13:21 Herv? Pag?s <hpages at fredhutch.org> wrote:
>
> Hi Keshav,
>
> findMatches() in the S4Vectors/IRanges packages (Bioconductor) I think
> does what you want:
>
>    library(IRanges)
>    y <- c(16L, -3L, -2L, 15L, 15L, 0L, 8L, 15L, -2L)
>    x <- c(unique(y), 999L)
>    hits <- findMatches(x, y)
>
> Then:
>
>    > hits
>    Hits object with 9 hits and 0 metadata columns:
>          queryHits subjectHits
>          <integer>   <integer>
>      [1]         1           1
>      [2]         2           2
>      [3]         3           3
>      [4]         3           9
>      [5]         4           4
>      [6]         4           5
>      [7]         4           8
>      [8]         5           6
>      [9]         6           7
>      -------
>      queryLength: 7
>      subjectLength: 9
>
> The Hits object can be turned into a list with:
>
>    > as.list(hits)
>    [[1]]
>    [1] 1
>
>    [[2]]
>    [1] 2
>
>    [[3]]
>    [1] 3 9
>
>    [[4]]
>    [1] 4 5 8
>
>    [[5]]
>    [1] 6
>
>    [[6]]
>    [1] 7
>
>    [[7]]
>    integer(0)
>
> H.
>
>  > sessionInfo()
> R version 3.2.0 beta (2015-04-05 r68151)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.2 LTS
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] parallel  stats4    stats     graphics  grDevices utils     datasets
> [8] methods   base
>
> other attached packages:
> [1] IRanges_2.1.43       S4Vectors_0.5.22     BiocGenerics_0.13.11
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.0
>
> On 04/06/2015 01:56 PM, Keshav Dhandhania wrote:
> > Hi,
> >
> > I know that one can find all occurrences of x in a vector v by doing
> >> which(x == v).
> >
> > However, if I need to do this again and again, where v is remaining the
> > same, then this is quite inefficient. In my particular case, I need to do
> > this millions of times, and length(v) = 100 million.
> >
> > Does anyone have suggestion on how to go about it?
> > I know of a package called fmatch that does the above for the match
> > function. But they don't handle multiple matches.
> >
> > Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From optionsraghu at gmail.com  Tue Apr  7 23:52:41 2015
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Tue, 7 Apr 2015 22:52:41 +0100
Subject: [R] Unable to Scale/Display properly in plotting a
 xts/timeseries graph in a single plot
In-Reply-To: <CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
References: <CADgEnDk=GdzZd1ySOAUKL1Hfs15jpo7+-SR9V=iAwy6JpXTQ5g@mail.gmail.com>
	<CAPPM_gR+9S1+ub_ud7YR8mzu6X5Y98=rH9i=3rAjR32K_2fppw@mail.gmail.com>
Message-ID: <CADgEnD=1NZ1ozt8z_wYT7D1AWWt1fqoWv-7-aykaMxx6gZkJSA@mail.gmail.com>

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RCurl_1.95-4.5 bitops_1.0-6   XML_3.98-1.1   xts_0.9-7      zoo_1.7-11

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-29 tools_3.0.2     TTR_0.22-0

Thanks
Raghu

On Tue, Apr 7, 2015 at 5:47 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Tue, Apr 7, 2015 at 11:30 AM, Raghuraman Ramachandran
> <optionsraghu at gmail.com> wrote:
>> Dear guRus
>>
>> I have xts data as:
>> str(volsA)
>> An ?xts? object on 2014-05-13/2015-04-07 containing:
>>   Data: num [1:221, 1:2] 18.8 18.5 18.4 22.2 22 ...
>>  - attr(*, "dimnames")=List of 2
>>   ..$ : NULL
>>   ..$ : chr [1:2] "vol1" "vol2"
>>   Indexed by objects of class: [Date] TZ: UTC
>>   xts Attributes:
>> List of 1
>>  $ na.action:Class 'omit'  atomic [1:20] 1 2 3 4 5 6 7 8 9 10 ...
>>   .. ..- attr(*, "index")= num [1:20] 1.4e+09 1.4e+09 1.4e+09 1.4e+09
>> 1.4e+09 ...
>>>
>> I am trying t0 plot them in a single frame but the scaling does not
>> happen properly.
>>
>> plot(vols,plot.type="s",format="auto")
>> lines(vols[,2],col="red")
>>
>> The lower graph in red gets displayed as a truncated graph and does
>> not fully exhibit the relationship. Can someone kindly help in
>> scaling/display please?
>>
> What's the output of sessionInfo() from your R session?
>
>> Thanks
>> Raghu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From jdnewmil at dcn.davis.CA.us  Wed Apr  8 00:41:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 7 Apr 2015 15:41:11 -0700
Subject: [R] Fast multiple match function
In-Reply-To: <CAO3abBrSASVERgRScjW=Ujp1J_U0x9K9AyPiXGQHmsZJ-tLR+Q@mail.gmail.com>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
	<55243C5F.7060000@fredhutch.org>
	<CAO3abBrSASVERgRScjW=Ujp1J_U0x9K9AyPiXGQHmsZJ-tLR+Q@mail.gmail.com>
Message-ID: <1DABB053-C0EE-4EC8-916F-F5ED2ACB95FB@dcn.davis.CA.us>

You might find the data.table package helpful. It uses an index sorted with a radix sort and minimizes moving the data around in memory.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 7, 2015 1:50:39 PM PDT, Keshav Dhandhania <kshav.91 at gmail.com> wrote:
>Hi all,
>
>Thanks for the responses.
>Herve's example is a good small size example of what I wanted.
>
>> y <- c(16, -3, -2, 15, 15, 0, 8, 15, -2)
>> someCoolFunc(-2, y)
>[1] 3 9
>> someCoolFunc(15, y)
>[1] 4 5 8
>
>The requirement is that I want someCoolFunc() to run in O(number of
>matches) time, instead of O(size of y).
>This is because y is big. And I don't know all the queries I want to
>do up-front. And the results of some queries might change the queries
>I want to do in the future.
>
>@David: I hope the above description is more clear.
>@Enrico, Herve: I want both the functionality provided by one function.
>- On repeated calls, fmatch() does give O(1) performance, but it does
>not give all matches.
>- findMatches() gives all matches, but I need to know the entire
>vector x beforehand. I don't have that luxury.
>
>
>I do have something that works now, using split and fmatch (package
>fastmatch). So just posting that in case anyone in the future has the
>same problem.
>> y.unique <- unique(y)
>>
>> # create a map from the unique elements of y to the locations of all
>occurrences of the element
>> y.map <- split(1:length(y), match(y, y.unique))
>>
>> # write a wrapper function that does a look-up on the unique list.
>and then returns all matches using the map.
>> someCoolFunc <- function(x) { y.map[[ fmatch(x, y.unique) ]] }
>
>
>
>On Tue, 7 Apr 2015 at 13:21 Herv? Pag?s <hpages at fredhutch.org> wrote:
>>
>> Hi Keshav,
>>
>> findMatches() in the S4Vectors/IRanges packages (Bioconductor) I
>think
>> does what you want:
>>
>>    library(IRanges)
>>    y <- c(16L, -3L, -2L, 15L, 15L, 0L, 8L, 15L, -2L)
>>    x <- c(unique(y), 999L)
>>    hits <- findMatches(x, y)
>>
>> Then:
>>
>>    > hits
>>    Hits object with 9 hits and 0 metadata columns:
>>          queryHits subjectHits
>>          <integer>   <integer>
>>      [1]         1           1
>>      [2]         2           2
>>      [3]         3           3
>>      [4]         3           9
>>      [5]         4           4
>>      [6]         4           5
>>      [7]         4           8
>>      [8]         5           6
>>      [9]         6           7
>>      -------
>>      queryLength: 7
>>      subjectLength: 9
>>
>> The Hits object can be turned into a list with:
>>
>>    > as.list(hits)
>>    [[1]]
>>    [1] 1
>>
>>    [[2]]
>>    [1] 2
>>
>>    [[3]]
>>    [1] 3 9
>>
>>    [[4]]
>>    [1] 4 5 8
>>
>>    [[5]]
>>    [1] 6
>>
>>    [[6]]
>>    [1] 7
>>
>>    [[7]]
>>    integer(0)
>>
>> H.
>>
>>  > sessionInfo()
>> R version 3.2.0 beta (2015-04-05 r68151)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.2 LTS
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] parallel  stats4    stats     graphics  grDevices utils    
>datasets
>> [8] methods   base
>>
>> other attached packages:
>> [1] IRanges_2.1.43       S4Vectors_0.5.22     BiocGenerics_0.13.11
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.0
>>
>> On 04/06/2015 01:56 PM, Keshav Dhandhania wrote:
>> > Hi,
>> >
>> > I know that one can find all occurrences of x in a vector v by
>doing
>> >> which(x == v).
>> >
>> > However, if I need to do this again and again, where v is remaining
>the
>> > same, then this is quite inefficient. In my particular case, I need
>to do
>> > this millions of times, and length(v) = 100 million.
>> >
>> > Does anyone have suggestion on how to go about it?
>> > I know of a package called fmatch that does the above for the match
>> > function. But they don't handle multiple matches.
>> >
>> > Thanks
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kehld at ktk.pte.hu  Wed Apr  8 04:34:32 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Wed, 8 Apr 2015 02:34:32 +0000
Subject: [R] Simulate values
In-Reply-To: <trinity-27714541-5fd3-4460-9017-d900fefc1ec4-1428445714514@3capp-gmx-bs56>
References: <1428360724353-4705574.post@n4.nabble.com>,
	<33D76D77E9AC4B438DA38B348ED6890D14403CE5@EMAIL.ktkdom.pte.hu>,
	<trinity-27714541-5fd3-4460-9017-d900fefc1ec4-1428445714514@3capp-gmx-bs56>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14403F5C@EMAIL.ktkdom.pte.hu>

Hi Mike,

please keep conversation on the list. Your code looks waaaay better now.
I would not name the variable variances2 but that is just a matter of taste.
What you could also do as a one-liner is something like

n <- 40
REPS <- 50000
mu <- 10
sigma <- 5

chisq <- replicate(REPS,(n-1)*var(rnorm(n,mu,sigma))/sigma^2)

Try to draw a histogram of the variances2 or chisq values and superimpose the theoratical distribution.
?hist and ?curve might help.

Best,
kd
________________________________
Felad?: "Mike Brechb?hler" [osiris94 at gmx.ch]
K?ldve: 2015. ?prilis 8. 0:28
To: Kehl D?niel
T?rgy: Aw: RE: [R] Simulate values

Hey Daniel,

Thanks for your answer.

I changed my commands and ended up with:
matrix <- matrix(rnorm(500 * 40, 10, 5), ncol = 40, nrow = 500)
variances1 <- apply(matrix, 1, var)
variances2 <-(40 - 1) * variances1 / 25
What do you think about it? Does that work and was more or less what you expected to see?

Best wishes,
Mike

Gesendet: Dienstag, 07. April 2015 um 05:39 Uhr
Von: "Kehl D?niel" <kehld at ktk.pte.hu>
An: Osiris10101 <osiris94 at gmx.ch>, "r-help at r-project.org" <r-help at r-project.org>
Betreff: RE: [R] Simulate values
People do not usually do homework stuff here but I do not see the point in repeating the same sample 500 times. You might want to simulate 40x500 independent samples and put those in a matrix (see ?matrix) with lets say 40 rows and 500 columns. Once done, you can apply calculate the 500 sample standard deviations (or the chi-square values) where the ?apply function might help you.

Lets start with that and lets see where you get.

kd
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Osiris10101 [osiris94 at gmx.ch]
K?ldve: 2015. ?prilis 7. 0:52
To: r-help at r-project.org
T?rgy: [R] Simulate values

Hello,

I'm facing the following task:
Simulate 500 values of the statistic (n-1)s^2/sigma^2 based on taking 500
samples of size n=40
from the N(mu=10; sigma^2 = 25) distribution.

I think with the following command:
rep(rnorm(40,10,25),times=500)
I was able to simulate the samples but how I now can simulate the values of
the chi-square-distribution is a mystery to me...

I hope anyone can help me, shouldn't be a big problem...

Thanks in advance!

Reason for posting:
I started a course at the University of Manchester and had to catch up with
R, which I never used back in Switzerland. Now I'm solving some exercises to
get more practice and this is one of them.



--
View this message in context: http://r.789695.n4.nabble.com/Simulate-values-tp4705574.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Wed Apr  8 10:14:26 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Wed, 8 Apr 2015 08:14:26 +0000
Subject: [R] survreg FUNCTION
Message-ID: <7B64C8E017B948419F014C915AA6D7342A051FC6@mail-mbx-03.UNINE.CH>

Dear members,



I am trying a survival analysis , I got:



Error: could not find function "survreg"



I already load

the packages: survival

the function: splines



What can I do?



Thanks for you help,



Xavier


From pdalgd at gmail.com  Wed Apr  8 13:13:47 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 8 Apr 2015 13:13:47 +0200
Subject: [R] survreg FUNCTION
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A051FC6@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A051FC6@mail-mbx-03.UNINE.CH>
Message-ID: <8B2B28C5-7031-4F67-B5BF-6608B97EA22B@gmail.com>


On 08 Apr 2015, at 10:14 , CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:

> Dear members,
> 
> 
> 
> I am trying a survival analysis , I got:
> 
> 
> 
> Error: could not find function "survreg"
> 
> 
> 
> I already load
> 
> the packages: survival
> 
> the function: splines
> 

Load or install? I suspect you actually did the latter.

> 
> 
> What can I do?
> 

If installed and not loaded, load it with library(survival).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pushpa.methekar at ge.com  Wed Apr  8 10:23:51 2015
From: pushpa.methekar at ge.com (Methekar, Pushpa (GE Transportation, Non-GE))
Date: Wed, 8 Apr 2015 08:23:51 +0000
Subject: [R] How to calculate vif of each term of model in R?
Message-ID: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>




I am beginner in R doing modelling in R, I loaded excel sheet in R, i have chosen x elements and y elements then fitted model for linear and second order regression. Now I have both models. I am bit confused how to calculate vif for each term in model like

e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package then it's giving me like

    vif(model1)

       x1         x2         x3         x4         x5         x6         x7

 6.679692   1.520271   1.667125   3.618439   4.931810   2.073879  13.870630

        x8         x9

   220.969628 214.034135

now i want to compare each term with std vif as vif>=10 and which will satisfy this condition i want to delete that term and update model1. i have done something like this

fun = function(model1) {

 for(i in 1:length(model1))    {

      v=vif(model1)

         ss=any(v[i]>=10)

                if(ss==1){update(model1,.~.,-v[i])}

                else{print("no update")}

                 i<-i+1

    }



        return(model1)

      }

fun(model1)

but giving error as

Error in if (ss == 1) { : missing value where TRUE/FALSE needed.

please tell me how do i solve this problem.



	[[alternative HTML version deleted]]


From a_lafontaine at hotmail.com  Wed Apr  8 16:07:42 2015
From: a_lafontaine at hotmail.com (Alexandre Lafontaine)
Date: Wed, 8 Apr 2015 10:07:42 -0400
Subject: [R] Coxme penalized log-likelihood mismatch
Message-ID: <SNT153-W81AD1ADC7BA9BC6BC97ADDECFC0@phx.gbl>

Hi,?

I need to extract the penalized log-likehood term from coxme objects but I find the values stored whitin the object different than the penalized term given in the summary output of coxme function. Both the Null and the Integrated values are identical but the penalized is always off.?

Any thoughts on why and how i can extract the right value to compute the AIC myself? (I know an AIC value is given in the output but I need to compute it myself inside a loop)?

Many thanks,?

Alexandre Lafontaine


 		 	   		  

From mepstein at illinois.edu  Wed Apr  8 16:41:12 2015
From: mepstein at illinois.edu (Milt Epstein)
Date: Wed, 8 Apr 2015 09:41:12 -0500 (CDT)
Subject: [R] script works in Rstudio but not with Rscript
Message-ID: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>

Greetings.  I am new to R, but have quite a bit of experience
programming with other languages (e.g., Perl, Java, Python, shell
scripting).  I'm now working on a project where I need to use R.  A
colleague wrote a number of small scripts that work fine in Rstudio,
but a couple of them don't work when run using Rscript (which we're
planning on doing).  The behavior is basically the same on a few
different machines (two of them are Linux, one I think is a Mac).  To
run the scripts using Rscript, we put one of the following lines at
the top of the script:

#!/usr/bin/Rscript
#!/usr/bin/env Rscript

or called the script using Rscript:

Rscript scriptname

In all cases, the behavior is the same.

Here's one of the scripts:

#!/usr/bin/env Rscript

library(apcluster)
options(stringsAsFactors = FALSE)

args <- commandArgs(TRUE)
num <- args[1]

numClusters <- num
mydata <- read.csv("input_data.csv")
xData <- mydata[, 1]
yData <- mydata[, 2]

fit <- apclusterK(negDistMat(r=2), mydata, K = numClusters)
#Leave the rest commented for now
#output <- data.frame(xData, yData, c(as.data.frame(fit[1]), as.data.frame(fit[2]), as.data.frame(fit[3])))
#write.csv <- write.table(output, file = "output_AP.csv", sep = ",", row.names = FALSE, col.names = FALSE)

Here's a call to the script:

$ ./affinity_propagation.R 3

Attaching 

The following object is masked package::

    heatmap

Trying p = -15.41969 
   Number of clusters: 17 
Error in tmpk - K : non-numeric argument to binary operator
Calls: apclusterK ... apclusterK -> .local -> apclusterK -> apclusterK -> .local
Execution halted

The line with the expression "tmpk - K" is from the code for the
apclusterK() function (from the apcluster library).  The
definition/value of tmpk is set using a call to the function length().
I mention this because the failure we're getting with the other script
also seems to involve an expression with call to length().  Here's the
error from calling that script:

$ ./spectral_clustering.R 3
Loading required package: methods
Error in length(tmpsig) * nc : non-numeric argument to binary operator
Calls: specc -> specc -> .local -> matrix
Execution halted

The script is calling the specc() function in the kernlab library.

Any ideas what's going on here, why it's not working and what we can
do to get it to work?  Is there something that needs to be set or run
in .Renviron or .Rprofile, say?

Thanks.

Milt Epstein
Programmer in Computational Genomics
Institute for Genomic Biology (IGB)
University of Illinois at Urbana-Champaign (UIUC)
mepstein at illinois.edu


From sl-research at outlook.com  Wed Apr  8 17:00:02 2015
From: sl-research at outlook.com (Sebastian L)
Date: Wed, 8 Apr 2015 17:00:02 +0200
Subject: [R] C compilation error (unknown type R_xlen_t) when installing
 Rmpi package
Message-ID: <COL125-W410C7425FBD9C8C7C4B504F7FC0@phx.gbl>

Hi,

I am trying to use the parallel computing cluster of our university. To that end, I would like to install the Rmpi package on the cluster. The R version currently installed on the cluster is 

R version 2.15.2 (2012-10-26) -- "Trick or Treat"
Platform: x86_64-redhat-linux-gnu (64-bit)

I am trying to install the Rmpi package from the tar.gz source file, but encounter the following problem during the compilation process:

What I run within R is
install.packages("/home/myusername/Rpackages/Rmpi_0.6-5.tar.gz", repos = NULL, type = "source", lib = "/home/myusername/Rpackages/", 
configure.args=c("--with-Rmpi-libpath=/usr/mpi/gcc/openmpi-1.6.3/lib64/","--with??-Rmpi-type=OPENMPI", "--with-Rmpi-include=/usr/mpi/gcc/openmpi-1.6.3/include/"))

and I get the following output with an error message:

* installing *source* package ?Rmpi? ...
** Paket ?Rmpi? erfolgreich entpackt und MD5 Summen ?berpr?ft
checking for openpty in -lutil... no
checking for main in -lpthread... no
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -DPACKAGE_NAME=\"\" -DPACKAGE_TARNAME=\"\" -DPACKAGE_VERSION=\"\" -DPACKAGE_STRING=\"\" -DPACKAGE_BUGREPORT=\"\" -DPACKAGE_URL=\"\" -I/usr/mpi/gcc/openmpi-1.6.3/include/  -DMPI2 -DOPENMPI -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c Rmpi.c -o Rmpi.o
Rmpi.c: In Funktion ?mpi_bcast?:
Rmpi.c:605:2: Fehler: unbekannter Typname: ?R_xlen_t?
make: *** [Rmpi.o] Fehler 1
ERROR: compilation failed for package ?Rmpi?

I can not quite figure out what happens here, and what "unknown type name "R_xlen_t"" possibly refers to. 

Thanks in advance

 		 	   		  

From henrik.bengtsson at ucsf.edu  Wed Apr  8 18:22:46 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 8 Apr 2015 09:22:46 -0700
Subject: [R] C compilation error (unknown type R_xlen_t) when installing
 Rmpi package
In-Reply-To: <COL125-W410C7425FBD9C8C7C4B504F7FC0@phx.gbl>
References: <COL125-W410C7425FBD9C8C7C4B504F7FC0@phx.gbl>
Message-ID: <CAFDcVCTZBZ9CKu43=FQRR9dx9worJCVf=zXryqiA73aoZCBZ5g@mail.gmail.com>

Support for long vectors (and hence R_xlen_t) was introduced in R 3.0.0.

Your version is far outdated. If you wait a teeny but longer (after April
16) to update, you'll get R 3.2.0.

Henrik
On Apr 8, 2015 08:00, "Sebastian L" <sl-research at outlook.com> wrote:

> Hi,
>
> I am trying to use the parallel computing cluster of our university. To
> that end, I would like to install the Rmpi package on the cluster. The R
> version currently installed on the cluster is
>
> R version 2.15.2 (2012-10-26) -- "Trick or Treat"
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> I am trying to install the Rmpi package from the tar.gz source file, but
> encounter the following problem during the compilation process:
>
> What I run within R is
> install.packages("/home/myusername/Rpackages/Rmpi_0.6-5.tar.gz", repos =
> NULL, type = "source", lib = "/home/myusername/Rpackages/",
> configure.args=c("--with-Rmpi-libpath=/usr/mpi/gcc/openmpi-1.6.3/lib64/","--with??-Rmpi-type=OPENMPI",
> "--with-Rmpi-include=/usr/mpi/gcc/openmpi-1.6.3/include/"))
>
> and I get the following output with an error message:
>
> * installing *source* package ?Rmpi? ...
> ** Paket ?Rmpi? erfolgreich entpackt und MD5 Summen ?berpr?ft
> checking for openpty in -lutil... no
> checking for main in -lpthread... no
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -DPACKAGE_NAME=\"\"
> -DPACKAGE_TARNAME=\"\" -DPACKAGE_VERSION=\"\" -DPACKAGE_STRING=\"\"
> -DPACKAGE_BUGREPORT=\"\" -DPACKAGE_URL=\"\"
> -I/usr/mpi/gcc/openmpi-1.6.3/include/  -DMPI2 -DOPENMPI
> -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2
> -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64
> -mtune=generic  -c Rmpi.c -o Rmpi.o
> Rmpi.c: In Funktion ?mpi_bcast?:
> Rmpi.c:605:2: Fehler: unbekannter Typname: ?R_xlen_t?
> make: *** [Rmpi.o] Fehler 1
> ERROR: compilation failed for package ?Rmpi?
>
> I can not quite figure out what happens here, and what "unknown type name
> "R_xlen_t"" possibly refers to.
>
> Thanks in advance
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Wed Apr  8 18:30:11 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 08 Apr 2015 17:30:11 +0100
Subject: [R] C compilation error (unknown type R_xlen_t) when installing
 Rmpi package
In-Reply-To: <COL125-W410C7425FBD9C8C7C4B504F7FC0@phx.gbl>
References: <COL125-W410C7425FBD9C8C7C4B504F7FC0@phx.gbl>
Message-ID: <55255793.7010204@stats.ox.ac.uk>

On 08/04/2015 16:00, Sebastian L wrote:
> Hi,
>
> I am trying to use the parallel computing cluster of our university. To that end, I would like to install the Rmpi package on the cluster. The R version currently installed on the cluster is

This was a matter for the R-devel list as it involves compiled code: see 
the posting guide.

> R version 2.15.2 (2012-10-26) -- "Trick or Treat"
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> I am trying to install the Rmpi package from the tar.gz source file, but encounter the following problem during the compilation process:
>
> What I run within R is
> install.packages("/home/myusername/Rpackages/Rmpi_0.6-5.tar.gz", repos = NULL, type = "source", lib = "/home/myusername/Rpackages/",
> configure.args=c("--with-Rmpi-libpath=/usr/mpi/gcc/openmpi-1.6.3/lib64/","--with??-Rmpi-type=OPENMPI", "--with-Rmpi-include=/usr/mpi/gcc/openmpi-1.6.3/include/"))
>
> and I get the following output with an error message:
>
> * installing *source* package ?Rmpi? ...
> ** Paket ?Rmpi? erfolgreich entpackt und MD5 Summen ?berpr?ft
> checking for openpty in -lutil... no
> checking for main in -lpthread... no
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -DPACKAGE_NAME=\"\" -DPACKAGE_TARNAME=\"\" -DPACKAGE_VERSION=\"\" -DPACKAGE_STRING=\"\" -DPACKAGE_BUGREPORT=\"\" -DPACKAGE_URL=\"\" -I/usr/mpi/gcc/openmpi-1.6.3/include/  -DMPI2 -DOPENMPI -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c Rmpi.c -o Rmpi.o
> Rmpi.c: In Funktion ?mpi_bcast?:
> Rmpi.c:605:2: Fehler: unbekannter Typname: ?R_xlen_t?
> make: *** [Rmpi.o] Fehler 1
> ERROR: compilation failed for package ?Rmpi?
>
> I can not quite figure out what happens here, and what "unknown type name "R_xlen_t"" possibly refers to.

It is a C type introduced in R 3.0.0.  Find in the CRAN archives a 
version of Rmpi as old as your version of R (or at least earlier than 
3.0.0) and install that.

Note to the maintainer (Cc:ed) -- you need to correct the R version 
dependence.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From henrik.bengtsson at ucsf.edu  Wed Apr  8 18:39:30 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 8 Apr 2015 09:39:30 -0700
Subject: [R] script works in Rstudio but not with Rscript
In-Reply-To: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>
References: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>
Message-ID: <CAFDcVCThPD3keMOC-hit=L8-dLv+9sNT7Mg=rT=Jp3EqLc1LxQ@mail.gmail.com>

Does it work with R -f script?  If so, then it's because Rscript does not
attaching methods package by default, but R does. Try loading methods at
the top of your script.

My $.02

Henrik
On Apr 8, 2015 07:41, "Milt Epstein" <mepstein at illinois.edu> wrote:

> Greetings.  I am new to R, but have quite a bit of experience
> programming with other languages (e.g., Perl, Java, Python, shell
> scripting).  I'm now working on a project where I need to use R.  A
> colleague wrote a number of small scripts that work fine in Rstudio,
> but a couple of them don't work when run using Rscript (which we're
> planning on doing).  The behavior is basically the same on a few
> different machines (two of them are Linux, one I think is a Mac).  To
> run the scripts using Rscript, we put one of the following lines at
> the top of the script:
>
> #!/usr/bin/Rscript
> #!/usr/bin/env Rscript
>
> or called the script using Rscript:
>
> Rscript scriptname
>
> In all cases, the behavior is the same.
>
> Here's one of the scripts:
>
> #!/usr/bin/env Rscript
>
> library(apcluster)
> options(stringsAsFactors = FALSE)
>
> args <- commandArgs(TRUE)
> num <- args[1]
>
> numClusters <- num
> mydata <- read.csv("input_data.csv")
> xData <- mydata[, 1]
> yData <- mydata[, 2]
>
> fit <- apclusterK(negDistMat(r=2), mydata, K = numClusters)
> #Leave the rest commented for now
> #output <- data.frame(xData, yData, c(as.data.frame(fit[1]),
> as.data.frame(fit[2]), as.data.frame(fit[3])))
> #write.csv <- write.table(output, file = "output_AP.csv", sep = ",",
> row.names = FALSE, col.names = FALSE)
>
> Here's a call to the script:
>
> $ ./affinity_propagation.R 3
>
> Attaching
>
> The following object is masked package::
>
>     heatmap
>
> Trying p = -15.41969
>    Number of clusters: 17
> Error in tmpk - K : non-numeric argument to binary operator
> Calls: apclusterK ... apclusterK -> .local -> apclusterK -> apclusterK ->
> .local
> Execution halted
>
> The line with the expression "tmpk - K" is from the code for the
> apclusterK() function (from the apcluster library).  The
> definition/value of tmpk is set using a call to the function length().
> I mention this because the failure we're getting with the other script
> also seems to involve an expression with call to length().  Here's the
> error from calling that script:
>
> $ ./spectral_clustering.R 3
> Loading required package: methods
> Error in length(tmpsig) * nc : non-numeric argument to binary operator
> Calls: specc -> specc -> .local -> matrix
> Execution halted
>
> The script is calling the specc() function in the kernlab library.
>
> Any ideas what's going on here, why it's not working and what we can
> do to get it to work?  Is there something that needs to be set or run
> in .Renviron or .Rprofile, say?
>
> Thanks.
>
> Milt Epstein
> Programmer in Computational Genomics
> Institute for Genomic Biology (IGB)
> University of Illinois at Urbana-Champaign (UIUC)
> mepstein at illinois.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t.jombart at imperial.ac.uk  Wed Apr  8 19:02:20 2015
From: t.jombart at imperial.ac.uk (Jombart, Thibaut)
Date: Wed, 8 Apr 2015 17:02:20 +0000
Subject: [R] FW: r-sig-genetics is alive!
In-Reply-To: <2CB2DA8E426F3541AB1907F98ABA6570ABF11DDF@icexch-m1.ic.ac.uk>
References: <2CB2DA8E426F3541AB1907F98ABA6570ABF11DDF@icexch-m1.ic.ac.uk>
Message-ID: <2CB2DA8E426F3541AB1907F98ABA6570ABF11E4C@icexch-m1.ic.ac.uk>


Dear all, 

a small "heads up" for R-sig-genetics, a mailing list devoted to population genetics in R. See below, and sorry about the double-posting.

All the best

Thibaut


------------------------------------------
From: Jombart, Thibaut
Sent: 08 April 2015 17:21
To: r-sig-genetics at r-project.org
Subject: r-sig-genetics is alive!

Dear all, 

after a rather quiet existence for the last few years, it may be good to send this reminder: r-sig-genetics is alive!

Many awesome people have subscribed lately, and I am looking forward to seeing exciting discussions here. Posting guidelines have been freshly updated:
https://stat.ethz.ch/mailman/listinfo/r-sig-genetics

Coming soon: exciting news regarding future releases of a bunch of population genetics packages.

All the best

Thibaut
               

==============================
Dr Thibaut Jombart
MRC Centre for Outbreak Analysis and Modelling
Department of Infectious Disease Epidemiology
Imperial College - School of Public Health
Norfolk Place, London W2 1PG, UK
Tel. : 0044 (0)20 7594 3658
http://sites.google.com/site/thibautjombart/
http://sites.google.com/site/therepiproject/
http://adegenet.r-forge.r-project.org/
Twitter: @thibautjombart


From kristi.glover at hotmail.com  Wed Apr  8 19:49:47 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 8 Apr 2015 11:49:47 -0600
Subject: [R] your suggestions in MRMs
Message-ID: <COL130-W9039018173D365E531C5FAFAFC0@phx.gbl>

Hi R Users,
I was trying to  perfom multiple regression on resemblance matrices (MRMs). This technique in avaiable  in "ecodist" package  and looked at the example data to know how I need to organize my data set. I think the data is distance matrix but I was wondering the rows name. For example, there are (these are the subset of the data of "graze") 
         sitelocation forestpct
1.1.2001    12.187743     63.88
1.2.2001    12.186077     71.33
2.1.2001    12.406362     72.45
2.2.2001    12.416265     77.13
3.1.1998     8.409213     18.35

if we look at the first row, 1.1.2001: sitelocation (column) is 12.187.. which is the euclidean distance between two points (XY cordinates). But I was confused at the row name where 1.1.2001 which is to me is site1 and site1 of 2001. Isn't it supposed to be "0" if both are the same site.  I think I misunderstood it. Any one can help me about what it is? 

I put the example for your reference

install.packages("ecodist")
library(ecodist)
data(graze)
graze[1:5,1:2]

Thanks for your help

KG



 		 	   		  
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Apr  8 20:23:27 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 8 Apr 2015 14:23:27 -0400
Subject: [R] your suggestions in MRMs
In-Reply-To: <COL130-W9039018173D365E531C5FAFAFC0@phx.gbl>
References: <COL130-W9039018173D365E531C5FAFAFC0@phx.gbl>
Message-ID: <CAM_vjum4VheJnvZt1A7O_0zvp707h+qCuMQx=ShvKz4Yt+s70Q@mail.gmail.com>

Kristi,

The row names are utterly arbitrary. Each row is a separate site, and
sitelocation is a location variable (both intended to conceal the
absolute location, which is confidential since it's on private
property). It is NOT the Euclidean distance, nor is a row representing
a pair of sites.

If you look at the full example, dist() is used to calculate the
Euclidean distance as part of the MRM code.

Sarah

On Wed, Apr 8, 2015 at 1:49 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Hi R Users,
> I was trying to  perfom multiple regression on resemblance matrices (MRMs). This technique in avaiable  in "ecodist" package  and looked at the example data to know how I need to organize my data set. I think the data is distance matrix but I was wondering the rows name. For example, there are (these are the subset of the data of "graze")
>          sitelocation forestpct
> 1.1.2001    12.187743     63.88
> 1.2.2001    12.186077     71.33
> 2.1.2001    12.406362     72.45
> 2.2.2001    12.416265     77.13
> 3.1.1998     8.409213     18.35
>
> if we look at the first row, 1.1.2001: sitelocation (column) is 12.187.. which is the euclidean distance between two points (XY cordinates). But I was confused at the row name where 1.1.2001 which is to me is site1 and site1 of 2001. Isn't it supposed to be "0" if both are the same site.  I think I misunderstood it. Any one can help me about what it is?
>
> I put the example for your reference
>
> install.packages("ecodist")
> library(ecodist)
> data(graze)
> graze[1:5,1:2]
>
> Thanks for your help
>
> KG
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From emorway at usgs.gov  Wed Apr  8 20:47:32 2015
From: emorway at usgs.gov (Morway, Eric)
Date: Wed, 8 Apr 2015 11:47:32 -0700
Subject: [R] data-mining with multiple filters applied to multiple columns
Message-ID: <CAPoqHzpq0Pbwn15b2NQs4N9FOheiZedLkiiJNyMZTz9nMrMwOA@mail.gmail.com>

Using this representative dataset of a much larger dataset:

dat <- read.table(textConnection("ISEG  IRCH  div  gw
 1   1   265  229
 1   2   260  298
 1   3   234  196
54   1   432  485
54  39   467  485
54  40   468  468
54  41   460  381
54  42   489  502
 1   1   265  317
 1   2   276  225
 1   3   217  164
54   1   430  489
54  39   456  495
54  40   507  607
54  41   483  424
54  42   457  404
 1   1   265  278
 1   2   287  370
 1   3   224  274
54   1   412  585
54  39   473  532
54  40   502  595
54  41   497  441
54  42   447  467
 1   1   230  258
 1   2   251  152
 1   3   199  179
54   1   412  415
54  39   439  538
54  40   474  486
54  41   477  484
54  42   413  346
 1   1   230  171
 1   2   262  171
 1   3   217  263
54   1   432  485
54  39   455  482
54  40   493  419
54  41   489  536
54  42   431  504
 1   1  1002  1090
 1   2  1222  1178
 1   3  1198  1177
54   1  1432  1485
54  39  1876  1975
54  40  1565  1646
54  41  1455  1451
54  42  1427  1524
 1   1  1002  968
 1   2  1246  1306
 1   3  1153  1158
54   1  1532  1585
54  39  1790  1889
54  40  1490  1461
54  41  1518  1536
54  42  1486  1585
 1   1  1002  1081
 1   2  1229  1262
 1   3  1142  1241
54   1  1632  1659
54  39  1797  1730
54  40  1517  1466
54  41  1527  1589
54  42  1514  1612"),header=TRUE)

dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
tmp <- diff(dat[dat$seq==1,]$div)!=0
dat$idx <- 0
dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
dat$ts <- cumsum(dat$idx)
dat$iter <- ave(dat$seq, dat$ts,FUN=cumsum)
dat$ct <- seq(1:length(dat[,1]))

dat[1,]
#  ISEG IRCH div  gw seq idx ts iter ct
#     1    1 265 229   1   1  1    1  1

I'm attempting to carry out 2 data mining tasks:

1)  for each time step ('ts') and each ISEG within those time steps, I want
to difference the max and min 'div' values and store the result.  I got
close with this command, but the results were repeated:

with(subset(dat,ts==1 & IRCH==1),
ave(div,ISEG,FUN=function(x){max(x)-min(x)}))
#  0 20  0 20  0 20

There are a few shortcomings with this line of script that I'm hoping could
be improved upon: (1) I hard-coded ts==1, ideally, the R script would
iterate over all 'ts', (2) I really only need the results printed once ("0
 20"), and (3) it would be nice to store the results in something like this
(the results shown next are from a brute-force hand-calculation on the dat
data.frame):

ISEG IRCH ts div_diff
   1    1  1        0
  54    1  1       20
   1    1  2        0
  54    1  2       20
   1    1  3        0
  54    1  3      200

2) The second data-mining attempt is a bit more convoluted and to
demonstrate what I'd like to get, here it is in parts.  First:

aggregate(gw ~ ISEG + iter, subset(dat,ts==1), sum)
  ISEG iter   gw
1    1    1  723
2   54    1 2321
3    1    2  706
4   54    2 2419
5    1    3  922
6   54    3 2620

Once again, ts==1 is hard-coded, but this would ideally loop through all
unique 'ts' in the dataset.  Next, with this result, I'd like to difference
the maximum and minimum 'gw' values associated with each ISEG.  I tried:

with(aggregate(gw ~ ISEG + iter, subset(dat,ts==1), sum), ave(gw, ISEG,
function(x){max(x)-min(x)}))
#Error in unique.default(x, nmax = nmax) :
#  unique() applies only to vectors

but didn't know what to do with the error.  for the result above, the
answer I'm seeking is:

ISEG diff
   1  216
  54  289

For ts==1, the value of 216 results from 922 - 706 [max(gw) - min(gw) for
ISEG==1] and the value of 289 results from 2620 - 2321 [max(gw) - min(gw)
for ISEG==54].  So, the culmination of what I'm after would be the result
from data-mining effort 1 + data-mining effort 2:

ISEG IRCH ts div_diff gw_diff
   1    1  1        0     216
  54    1  1       20     289
   1    1  2        0      16
  54    1  2       20     157
   1    1  3        0     152
  54    1  3      200      25

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Apr  8 21:01:37 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 8 Apr 2015 13:01:37 -0600
Subject: [R] your suggestions in MRMs
In-Reply-To: <CAM_vjum4VheJnvZt1A7O_0zvp707h+qCuMQx=ShvKz4Yt+s70Q@mail.gmail.com>
References: <COL130-W9039018173D365E531C5FAFAFC0@phx.gbl>,
	<CAM_vjum4VheJnvZt1A7O_0zvp707h+qCuMQx=ShvKz4Yt+s70Q@mail.gmail.com>
Message-ID: <COL130-W13F5591BCA513DF30E92A7FAFC0@phx.gbl>






Hi Sarah,

Thanks for the reply. I again looked at the example, but I did not find the way to
calculate the location variable. All example in the document
("ecodist") has the Euclidean distance. did not find the example to
conceal the absolute location. There are some example:

page 21 and 22 : iris.md <- distance(iris[,1:4], "mahal"): it is
calculated distance matrix using four variables (I understood this one)

page 26: space.d <- distance(space, "eucl"), here space is XY coordinate,
so on



I am just wondering how I can conceal my absolute location (XY) and make my
data compatible to your data set so that I can use your functions. I am sorry for bothering you, Sarah. 

example of my data set: column names (site,
XY coordinates, temp, years)

site1, 25.01;34.78 (XY cordicnate),
35degree celcius; year2001

site1, 25.01;34.78 (XY cordicnate), 33degree celcius;
year2002

site2, 25.05; 35.56 (XY coordinate); 37degree
celcius; year2001

site2, 25.05; 35.56 (XY coordinate);
32degree celcius; year2002





Thanks

 

=======


> Date: Wed, 8 Apr 2015 14:23:27 -0400
> Subject: Re: [R] your suggestions in MRMs
> From: sarah.goslee at gmail.com
> To: kristi.glover at hotmail.com
> CC: r-help at r-project.org
> 
> Kristi,
> 
> The row names are utterly arbitrary. Each row is a separate site, and
> sitelocation is a location variable (both intended to conceal the
> absolute location, which is confidential since it's on private
> property). It is NOT the Euclidean distance, nor is a row representing
> a pair of sites.
> 
> If you look at the full example, dist() is used to calculate the
> Euclidean distance as part of the MRM code.
> 
> Sarah
> 
> On Wed, Apr 8, 2015 at 1:49 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> > Hi R Users,
> > I was trying to  perfom multiple regression on resemblance matrices (MRMs). This technique in avaiable  in "ecodist" package  and looked at the example data to know how I need to organize my data set. I think the data is distance matrix but I was wondering the rows name. For example, there are (these are the subset of the data of "graze")
> >          sitelocation forestpct
> > 1.1.2001    12.187743     63.88
> > 1.2.2001    12.186077     71.33
> > 2.1.2001    12.406362     72.45
> > 2.2.2001    12.416265     77.13
> > 3.1.1998     8.409213     18.35
> >
> > if we look at the first row, 1.1.2001: sitelocation (column) is 12.187.. which is the euclidean distance between two points (XY cordinates). But I was confused at the row name where 1.1.2001 which is to me is site1 and site1 of 2001. Isn't it supposed to be "0" if both are the same site.  I think I misunderstood it. Any one can help me about what it is?
> >
> > I put the example for your reference
> >
> > install.packages("ecodist")
> > library(ecodist)
> > data(graze)
> > graze[1:5,1:2]
> >
> > Thanks for your help
> >
> > KG
> >
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org

 		 	   		  
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Apr  8 21:14:09 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 8 Apr 2015 15:14:09 -0400
Subject: [R] your suggestions in MRMs
In-Reply-To: <COL130-W13F5591BCA513DF30E92A7FAFC0@phx.gbl>
References: <COL130-W9039018173D365E531C5FAFAFC0@phx.gbl>
	<CAM_vjum4VheJnvZt1A7O_0zvp707h+qCuMQx=ShvKz4Yt+s70Q@mail.gmail.com>
	<COL130-W13F5591BCA513DF30E92A7FAFC0@phx.gbl>
Message-ID: <CAM_vju=Gt4=umXBKv4yyw5LqR6fD8WR4cx0aUuzgMrMP-sgXDw@mail.gmail.com>

Kristi,

You're completely missing the point, I think.

Instead of providing X,Y coordinates in the sample dataset graze
within the ecodist package, I provided one location, X if you'd like,
called sitelocation.

If you look at the example in ?MRM,

data(graze)
LOAR10.mrm <- MRM(dist(LOAR10) ~ dist(sitelocation) + dist(forestpct),
data=graze, nperm=100)

This is a toy example,with only one species, geographic distance, and
another potential explanatory variable.

dist(LOAR10) - species distance; you'd use whatever set of species
you're studying

dist(sitelocation) - geographic distance, you'd use your x and y
coordinates as in dist(xy.matrix)

dist(forestpct) - you'd use whatever variable or variables are
appropriate for your study


I concealed the location of these sites BEFORE I made the data public,
which is why there's one location variable instead of x,y coordinates.

Each row of graze is a single site, with some information associated.

You don't need to conceal your location for your own analysis. You
just need to use the appropriate data within the dist() command to
calculate the distances, and with the appropriate distance metrics if
Euclidean isn't appropriate for your data.

Reading the papers cited in ?MRM might help you understand the logic a
bit better.

Sarah


On Wed, Apr 8, 2015 at 3:01 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Hi Sarah,
> Thanks for the reply. I again looked at the example, but I did not find the
> way to calculate the location variable. All example in the document
> ("ecodist") has the Euclidean distance. did not find the example to conceal
> the absolute location. There are some example:
> page 21 and 22 : iris.md <- distance(iris[,1:4], "mahal"): it is calculated
> distance matrix using four variables (I understood this one)
> page 26: space.d <- distance(space, "eucl"), here space is XY coordinate, so
> on
>
> I am just wondering how I can conceal my absolute location (XY) and make my
> data compatible to your data set so that I can use your functions. I am
> sorry for bothering you, Sarah.
>
> example of my data set: column names (site, XY coordinates, temp, years)
>
> site1, 25.01;34.78 (XY cordicnate), 35degree celcius; year2001
>
> site1, 25.01;34.78 (XY cordicnate), 33degree celcius; year2002
>
> site2, 25.05; 35.56 (XY coordinate); 37degree celcius; year2001
>
> site2, 25.05; 35.56 (XY coordinate); 32degree celcius; year2002
>
>
>
> Thanks
>
>
>
> =======
>
>
>> Date: Wed, 8 Apr 2015 14:23:27 -0400
>> Subject: Re: [R] your suggestions in MRMs
>> From: sarah.goslee at gmail.com
>> To: kristi.glover at hotmail.com
>> CC: r-help at r-project.org
>>
>> Kristi,
>>
>> The row names are utterly arbitrary. Each row is a separate site, and
>> sitelocation is a location variable (both intended to conceal the
>> absolute location, which is confidential since it's on private
>> property). It is NOT the Euclidean distance, nor is a row representing
>> a pair of sites.
>>
>> If you look at the full example, dist() is used to calculate the
>> Euclidean distance as part of the MRM code.
>>
>> Sarah
>>
>> On Wed, Apr 8, 2015 at 1:49 PM, Kristi Glover <kristi.glover at hotmail.com>
>> wrote:
>> > Hi R Users,
>> > I was trying to perfom multiple regression on resemblance matrices
>> > (MRMs). This technique in avaiable in "ecodist" package and looked at the
>> > example data to know how I need to organize my data set. I think the data is
>> > distance matrix but I was wondering the rows name. For example, there are
>> > (these are the subset of the data of "graze")
>> > sitelocation forestpct
>> > 1.1.2001 12.187743 63.88
>> > 1.2.2001 12.186077 71.33
>> > 2.1.2001 12.406362 72.45
>> > 2.2.2001 12.416265 77.13
>> > 3.1.1998 8.409213 18.35
>> >
>> > if we look at the first row, 1.1.2001: sitelocation (column) is 12.187..
>> > which is the euclidean distance between two points (XY cordinates). But I
>> > was confused at the row name where 1.1.2001 which is to me is site1 and
>> > site1 of 2001. Isn't it supposed to be "0" if both are the same site. I
>> > think I misunderstood it. Any one can help me about what it is?
>> >
>> > I put the example for your reference
>> >
>> > install.packages("ecodist")
>> > library(ecodist)
>> > data(graze)
>> > graze[1:5,1:2]
>> >
>> > Thanks for your help
>> >
>> > KG
>> >
>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From mepstein at illinois.edu  Wed Apr  8 20:20:37 2015
From: mepstein at illinois.edu (Milt Epstein)
Date: Wed, 8 Apr 2015 13:20:37 -0500 (CDT)
Subject: [R] script works in Rstudio but not with Rscript
In-Reply-To: <CAFDcVCThPD3keMOC-hit=L8-dLv+9sNT7Mg=rT=Jp3EqLc1LxQ@mail.gmail.com>
References: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>
	<CAFDcVCThPD3keMOC-hit=L8-dLv+9sNT7Mg=rT=Jp3EqLc1LxQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1504081242410.4839@mepstein0.ncsa.illinois.edu>

OK, this suggestion brings up some interesting results.  No solution,
however.  But it's interesting ... and maybe some helpful leads.

The basic/short answer to your question is no, it doesn't work with "R
-f script".

The longer answer: Note that the script is currently set up to be
called with a command line argument, "./affinity_propagation.R 3".  So
first I tried "R -f affinity_propagation.R 3".  That failed, but
because it wasn't using the "3" as an argument.  So I modified the
code to hard-code the value 3 in there and not read the command line
argument using commandArgs(TRUE).  Then I ran the script using
"./affinity_propagation.R" -- and it worked!  "R -f
affinity_propagation.R" also worked.

Then I noticed the --args command line option for R, and I ran "R -f
affinity_propagation.R --args 3" on the original script, and it
failed, the same error as I described below.

Also, when you say "Try loading methods", do you mean just a line like
the following?:

library(methods)

I tried that as well, and it didn't help, same error.

So, given all that, any new ideas?  Is the call to commandArgs()
screwing something up?  Can that be fixed somehow?  Is there another
library/function I could/should use to read command line arguments?

Hmmm, playing around with things some more, it looks like if I do:

num <- as.integer(args[1])

rather than:

num <- args[1]

things work.  So maybe this is an issue with types, scalar vs. array,
number vs. string?

Milt Epstein
Programmer in Computational Genomics
Institute for Genomic Biology (IGB)
University of Illinois at Urbana-Champaign (UIUC)
mepstein at illinois.edu


On Wed, 8 Apr 2015, Henrik Bengtsson wrote:

> Does it work with R -f script?  If so, then it's because Rscript does not
> attaching methods package by default, but R does. Try loading methods at
> the top of your script.
> 
> My $.02
> 
> Henrik
> On Apr 8, 2015 07:41, "Milt Epstein" <mepstein at illinois.edu> wrote:
> 
> > Greetings.  I am new to R, but have quite a bit of experience
> > programming with other languages (e.g., Perl, Java, Python, shell
> > scripting).  I'm now working on a project where I need to use R.  A
> > colleague wrote a number of small scripts that work fine in Rstudio,
> > but a couple of them don't work when run using Rscript (which we're
> > planning on doing).  The behavior is basically the same on a few
> > different machines (two of them are Linux, one I think is a Mac).  To
> > run the scripts using Rscript, we put one of the following lines at
> > the top of the script:
> >
> > #!/usr/bin/Rscript
> > #!/usr/bin/env Rscript
> >
> > or called the script using Rscript:
> >
> > Rscript scriptname
> >
> > In all cases, the behavior is the same.
> >
> > Here's one of the scripts:
> >
> > #!/usr/bin/env Rscript
> >
> > library(apcluster)
> > options(stringsAsFactors = FALSE)
> >
> > args <- commandArgs(TRUE)
> > num <- args[1]
> >
> > numClusters <- num
> > mydata <- read.csv("input_data.csv")
> > xData <- mydata[, 1]
> > yData <- mydata[, 2]
> >
> > fit <- apclusterK(negDistMat(r=2), mydata, K = numClusters)
> > #Leave the rest commented for now
> > #output <- data.frame(xData, yData, c(as.data.frame(fit[1]),
> > as.data.frame(fit[2]), as.data.frame(fit[3])))
> > #write.csv <- write.table(output, file = "output_AP.csv", sep = ",",
> > row.names = FALSE, col.names = FALSE)
> >
> > Here's a call to the script:
> >
> > $ ./affinity_propagation.R 3
> >
> > Attaching
> >
> > The following object is masked package::
> >
> >     heatmap
> >
> > Trying p = -15.41969
> >    Number of clusters: 17
> > Error in tmpk - K : non-numeric argument to binary operator
> > Calls: apclusterK ... apclusterK -> .local -> apclusterK -> apclusterK ->
> > .local
> > Execution halted
> >
> > The line with the expression "tmpk - K" is from the code for the
> > apclusterK() function (from the apcluster library).  The
> > definition/value of tmpk is set using a call to the function length().
> > I mention this because the failure we're getting with the other script
> > also seems to involve an expression with call to length().  Here's the
> > error from calling that script:
> >
> > $ ./spectral_clustering.R 3
> > Loading required package: methods
> > Error in length(tmpsig) * nc : non-numeric argument to binary operator
> > Calls: specc -> specc -> .local -> matrix
> > Execution halted
> >
> > The script is calling the specc() function in the kernlab library.
> >
> > Any ideas what's going on here, why it's not working and what we can
> > do to get it to work?  Is there something that needs to be set or run
> > in .Renviron or .Rprofile, say?
> >
> > Thanks.
> >
> > Milt Epstein
> > Programmer in Computational Genomics
> > Institute for Genomic Biology (IGB)
> > University of Illinois at Urbana-Champaign (UIUC)
> > mepstein at illinois.edu
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From wdunlap at tibco.com  Wed Apr  8 22:40:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Apr 2015 13:40:16 -0700
Subject: [R] script works in Rstudio but not with Rscript
In-Reply-To: <Pine.LNX.4.64.1504081242410.4839@mepstein0.ncsa.illinois.edu>
References: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>
	<CAFDcVCThPD3keMOC-hit=L8-dLv+9sNT7Mg=rT=Jp3EqLc1LxQ@mail.gmail.com>
	<Pine.LNX.4.64.1504081242410.4839@mepstein0.ncsa.illinois.edu>
Message-ID: <CAF8bMcbSwgY7QzrdknjAevm3ozmA7w1AyR0bxH6VxM_40-SjUQ@mail.gmail.com>

> > args <- commandArgs(TRUE)
> > num <- args[1]

and then you get a complaint about something not being numeric.
commandArgs() returns a character vector so try
   num <- as.numeric(args[1])
and you may as well preface it with
   stopifnot(length(args)>0)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Apr 8, 2015 at 11:20 AM, Milt Epstein <mepstein at illinois.edu> wrote:

> OK, this suggestion brings up some interesting results.  No solution,
> however.  But it's interesting ... and maybe some helpful leads.
>
> The basic/short answer to your question is no, it doesn't work with "R
> -f script".
>
> The longer answer: Note that the script is currently set up to be
> called with a command line argument, "./affinity_propagation.R 3".  So
> first I tried "R -f affinity_propagation.R 3".  That failed, but
> because it wasn't using the "3" as an argument.  So I modified the
> code to hard-code the value 3 in there and not read the command line
> argument using commandArgs(TRUE).  Then I ran the script using
> "./affinity_propagation.R" -- and it worked!  "R -f
> affinity_propagation.R" also worked.
>
> Then I noticed the --args command line option for R, and I ran "R -f
> affinity_propagation.R --args 3" on the original script, and it
> failed, the same error as I described below.
>
> Also, when you say "Try loading methods", do you mean just a line like
> the following?:
>
> library(methods)
>
> I tried that as well, and it didn't help, same error.
>
> So, given all that, any new ideas?  Is the call to commandArgs()
> screwing something up?  Can that be fixed somehow?  Is there another
> library/function I could/should use to read command line arguments?
>
> Hmmm, playing around with things some more, it looks like if I do:
>
> num <- as.integer(args[1])
>
> rather than:
>
> num <- args[1]
>
> things work.  So maybe this is an issue with types, scalar vs. array,
> number vs. string?
>
> Milt Epstein
> Programmer in Computational Genomics
> Institute for Genomic Biology (IGB)
> University of Illinois at Urbana-Champaign (UIUC)
> mepstein at illinois.edu
>
>
> On Wed, 8 Apr 2015, Henrik Bengtsson wrote:
>
> > Does it work with R -f script?  If so, then it's because Rscript does not
> > attaching methods package by default, but R does. Try loading methods at
> > the top of your script.
> >
> > My $.02
> >
> > Henrik
> > On Apr 8, 2015 07:41, "Milt Epstein" <mepstein at illinois.edu> wrote:
> >
> > > Greetings.  I am new to R, but have quite a bit of experience
> > > programming with other languages (e.g., Perl, Java, Python, shell
> > > scripting).  I'm now working on a project where I need to use R.  A
> > > colleague wrote a number of small scripts that work fine in Rstudio,
> > > but a couple of them don't work when run using Rscript (which we're
> > > planning on doing).  The behavior is basically the same on a few
> > > different machines (two of them are Linux, one I think is a Mac).  To
> > > run the scripts using Rscript, we put one of the following lines at
> > > the top of the script:
> > >
> > > #!/usr/bin/Rscript
> > > #!/usr/bin/env Rscript
> > >
> > > or called the script using Rscript:
> > >
> > > Rscript scriptname
> > >
> > > In all cases, the behavior is the same.
> > >
> > > Here's one of the scripts:
> > >
> > > #!/usr/bin/env Rscript
> > >
> > > library(apcluster)
> > > options(stringsAsFactors = FALSE)
> > >
> > > args <- commandArgs(TRUE)
> > > num <- args[1]
> > >
> > > numClusters <- num
> > > mydata <- read.csv("input_data.csv")
> > > xData <- mydata[, 1]
> > > yData <- mydata[, 2]
> > >
> > > fit <- apclusterK(negDistMat(r=2), mydata, K = numClusters)
> > > #Leave the rest commented for now
> > > #output <- data.frame(xData, yData, c(as.data.frame(fit[1]),
> > > as.data.frame(fit[2]), as.data.frame(fit[3])))
> > > #write.csv <- write.table(output, file = "output_AP.csv", sep = ",",
> > > row.names = FALSE, col.names = FALSE)
> > >
> > > Here's a call to the script:
> > >
> > > $ ./affinity_propagation.R 3
> > >
> > > Attaching
> > >
> > > The following object is masked package::
> > >
> > >     heatmap
> > >
> > > Trying p = -15.41969
> > >    Number of clusters: 17
> > > Error in tmpk - K : non-numeric argument to binary operator
> > > Calls: apclusterK ... apclusterK -> .local -> apclusterK -> apclusterK
> ->
> > > .local
> > > Execution halted
> > >
> > > The line with the expression "tmpk - K" is from the code for the
> > > apclusterK() function (from the apcluster library).  The
> > > definition/value of tmpk is set using a call to the function length().
> > > I mention this because the failure we're getting with the other script
> > > also seems to involve an expression with call to length().  Here's the
> > > error from calling that script:
> > >
> > > $ ./spectral_clustering.R 3
> > > Loading required package: methods
> > > Error in length(tmpsig) * nc : non-numeric argument to binary operator
> > > Calls: specc -> specc -> .local -> matrix
> > > Execution halted
> > >
> > > The script is calling the specc() function in the kernlab library.
> > >
> > > Any ideas what's going on here, why it's not working and what we can
> > > do to get it to work?  Is there something that needs to be set or run
> > > in .Renviron or .Rprofile, say?
> > >
> > > Thanks.
> > >
> > > Milt Epstein
> > > Programmer in Computational Genomics
> > > Institute for Genomic Biology (IGB)
> > > University of Illinois at Urbana-Champaign (UIUC)
> > > mepstein at illinois.edu
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pisicandru at hotmail.com  Wed Apr  8 23:07:59 2015
From: pisicandru at hotmail.com (Monica Pisica)
Date: Wed, 8 Apr 2015 21:07:59 +0000
Subject: [R]  extracting slot "coords" from a Polygons class object
Message-ID: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>


Hi,

 

I am struggling to extract the polygon vertices from a list of an object class "Polygons", specifically the slot "coords".

 

 I have a point, and i "draw" a buffer around with gBuffer, i am "extracting" the polygon form the SpatialPolygons class and i end up with a list of 1 one object Polygons class that seems to have slots, but if i try to extract them i get an error. 

 

So here it goes after i load the respective libraries: sp, maptools, rgdal, rgeos

pt1 <- data.frame(x=217680.2, y = 3817555)

coordinates(pt1) <- c("x", "y")

crs = "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"

 

proj4string(pt1) <- CRS(crs)

pt1.cpoly <- gBuffer(pt1, width = 100, byid = TRUE)

 

pt1.cpoly

class       : SpatialPolygons 

features    : 1 

extent      : 217580.2, 217780.2, 3817455, 3817655  (xmin, xmax, ymin, ymax)

coord. ref. : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0

 

pt1.poly <- pt1.cpoly at polygons

 

pt1.poly

[[1]]

An object of class "Polygons"

Slot "Polygons":

[[1]]

An object of class "Polygon"

Slot "labpt":

[1]  217680.2 3817554.7

 

Slot "area":

[1] 30901.7

 

Slot "hole":

[1] FALSE

 

Slot "ringDir":

[1] 1

 

Slot "coords":

             x       y

 [1,] 217780.2 3817555

 [2,] 217775.3 3817524

 [3,] 217761.1 3817496

 [4,] 217739.0 3817474

Etc. ?..

 

pt1.crd <- pt1.poly[[1]]@coords

Error: no slot of name "coords" for this object of class "Polygons"

 

So my question is: How do i access the "coords" slot i clearly see when i print pt1.poly on the screen? 



Thanks for any help,



Monica 		 	   		  

From macqueen1 at llnl.gov  Thu Apr  9 00:55:31 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 8 Apr 2015 22:55:31 +0000
Subject: [R] extracting slot "coords" from a Polygons class object
In-Reply-To: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>
References: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>
Message-ID: <D14AFFA7.124E87%macqueen1@llnl.gov>

It would be better to ask this question on r-sig-geo. More people there
are more familiar with the structure of Spatial{*} classes.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/8/15, 2:07 PM, "Monica Pisica" <pisicandru at hotmail.com> wrote:

>
>Hi,
>
> 
>
>I am struggling to extract the polygon vertices from a list of an object
>class "Polygons", specifically the slot "coords".
>
> 
>
> I have a point, and i "draw" a buffer around with gBuffer, i am
>"extracting" the polygon form the SpatialPolygons class and i end up with
>a list of 1 one object Polygons class that seems to have slots, but if i
>try to extract them i get an error.
>
> 
>
>So here it goes after i load the respective libraries: sp, maptools,
>rgdal, rgeos
>
>pt1 <- data.frame(x=217680.2, y = 3817555)
>
>coordinates(pt1) <- c("x", "y")
>
>crs = "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80
>+towgs84=0,0,0"
>
> 
>
>proj4string(pt1) <- CRS(crs)
>
>pt1.cpoly <- gBuffer(pt1, width = 100, byid = TRUE)
>
> 
>
>pt1.cpoly
>
>class       : SpatialPolygons
>
>features    : 1 
>
>extent      : 217580.2, 217780.2, 3817455, 3817655  (xmin, xmax, ymin,
>ymax)
>
>coord. ref. : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs
>+ellps=GRS80 +towgs84=0,0,0
>
> 
>
>pt1.poly <- pt1.cpoly at polygons
>
> 
>
>pt1.poly
>
>[[1]]
>
>An object of class "Polygons"
>
>Slot "Polygons":
>
>[[1]]
>
>An object of class "Polygon"
>
>Slot "labpt":
>
>[1]  217680.2 3817554.7
>
> 
>
>Slot "area":
>
>[1] 30901.7
>
> 
>
>Slot "hole":
>
>[1] FALSE
>
> 
>
>Slot "ringDir":
>
>[1] 1
>
> 
>
>Slot "coords":
>
>             x       y
>
> [1,] 217780.2 3817555
>
> [2,] 217775.3 3817524
>
> [3,] 217761.1 3817496
>
> [4,] 217739.0 3817474
>
>Etc. ?..
>
> 
>
>pt1.crd <- pt1.poly[[1]]@coords
>
>Error: no slot of name "coords" for this object of class "Polygons"
>
> 
>
>So my question is: How do i access the "coords" slot i clearly see when i
>print pt1.poly on the screen?
>
>
>
>Thanks for any help,
>
>
>
>Monica 		 	   		  
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at ucsf.edu  Thu Apr  9 02:17:18 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 8 Apr 2015 17:17:18 -0700
Subject: [R] script works in Rstudio but not with Rscript
In-Reply-To: <Pine.LNX.4.64.1504081242410.4839@mepstein0.ncsa.illinois.edu>
References: <Pine.LNX.4.64.1504080917001.805@mepstein0.ncsa.illinois.edu>
	<CAFDcVCThPD3keMOC-hit=L8-dLv+9sNT7Mg=rT=Jp3EqLc1LxQ@mail.gmail.com>
	<Pine.LNX.4.64.1504081242410.4839@mepstein0.ncsa.illinois.edu>
Message-ID: <CAFDcVCR2dtUBA-aVqhJMnYLjfd_kT2-oa7tU+d3-FUF16cLB+Q@mail.gmail.com>

On Wed, Apr 8, 2015 at 11:20 AM, Milt Epstein <mepstein at illinois.edu> wrote:
> OK, this suggestion brings up some interesting results.  No solution,
> however.  But it's interesting ... and maybe some helpful leads.
>
> The basic/short answer to your question is no, it doesn't work with "R
> -f script".
>
> The longer answer: Note that the script is currently set up to be
> called with a command line argument, "./affinity_propagation.R 3".  So
> first I tried "R -f affinity_propagation.R 3".  That failed, but
> because it wasn't using the "3" as an argument.  So I modified the
> code to hard-code the value 3 in there and not read the command line
> argument using commandArgs(TRUE).  Then I ran the script using
> "./affinity_propagation.R" -- and it worked!  "R -f
> affinity_propagation.R" also worked.
>
> Then I noticed the --args command line option for R, and I ran "R -f
> affinity_propagation.R --args 3" on the original script, and it
> failed, the same error as I described below.
>
> Also, when you say "Try loading methods", do you mean just a line like
> the following?:
>
> library(methods)
>
> I tried that as well, and it didn't help, same error.

Yes, that's what I meant.  My suggestion was just a guess given that
it is not that uncommon to see cases where a script works with 'R' but
not with 'Rscript'.  From your answers/tests, it's seems clear that
your problem now has to do with parsing arguments.

/Henrik

>
> So, given all that, any new ideas?  Is the call to commandArgs()
> screwing something up?  Can that be fixed somehow?  Is there another
> library/function I could/should use to read command line arguments?
>
> Hmmm, playing around with things some more, it looks like if I do:
>
> num <- as.integer(args[1])
>
> rather than:
>
> num <- args[1]
>
> things work.  So maybe this is an issue with types, scalar vs. array,
> number vs. string?
>
> Milt Epstein
> Programmer in Computational Genomics
> Institute for Genomic Biology (IGB)
> University of Illinois at Urbana-Champaign (UIUC)
> mepstein at illinois.edu
>
>
> On Wed, 8 Apr 2015, Henrik Bengtsson wrote:
>
>> Does it work with R -f script?  If so, then it's because Rscript does not
>> attaching methods package by default, but R does. Try loading methods at
>> the top of your script.
>>
>> My $.02
>>
>> Henrik
>> On Apr 8, 2015 07:41, "Milt Epstein" <mepstein at illinois.edu> wrote:
>>
>> > Greetings.  I am new to R, but have quite a bit of experience
>> > programming with other languages (e.g., Perl, Java, Python, shell
>> > scripting).  I'm now working on a project where I need to use R.  A
>> > colleague wrote a number of small scripts that work fine in Rstudio,
>> > but a couple of them don't work when run using Rscript (which we're
>> > planning on doing).  The behavior is basically the same on a few
>> > different machines (two of them are Linux, one I think is a Mac).  To
>> > run the scripts using Rscript, we put one of the following lines at
>> > the top of the script:
>> >
>> > #!/usr/bin/Rscript
>> > #!/usr/bin/env Rscript
>> >
>> > or called the script using Rscript:
>> >
>> > Rscript scriptname
>> >
>> > In all cases, the behavior is the same.
>> >
>> > Here's one of the scripts:
>> >
>> > #!/usr/bin/env Rscript
>> >
>> > library(apcluster)
>> > options(stringsAsFactors = FALSE)
>> >
>> > args <- commandArgs(TRUE)
>> > num <- args[1]
>> >
>> > numClusters <- num
>> > mydata <- read.csv("input_data.csv")
>> > xData <- mydata[, 1]
>> > yData <- mydata[, 2]
>> >
>> > fit <- apclusterK(negDistMat(r=2), mydata, K = numClusters)
>> > #Leave the rest commented for now
>> > #output <- data.frame(xData, yData, c(as.data.frame(fit[1]),
>> > as.data.frame(fit[2]), as.data.frame(fit[3])))
>> > #write.csv <- write.table(output, file = "output_AP.csv", sep = ",",
>> > row.names = FALSE, col.names = FALSE)
>> >
>> > Here's a call to the script:
>> >
>> > $ ./affinity_propagation.R 3
>> >
>> > Attaching
>> >
>> > The following object is masked package::
>> >
>> >     heatmap
>> >
>> > Trying p = -15.41969
>> >    Number of clusters: 17
>> > Error in tmpk - K : non-numeric argument to binary operator
>> > Calls: apclusterK ... apclusterK -> .local -> apclusterK -> apclusterK ->
>> > .local
>> > Execution halted
>> >
>> > The line with the expression "tmpk - K" is from the code for the
>> > apclusterK() function (from the apcluster library).  The
>> > definition/value of tmpk is set using a call to the function length().
>> > I mention this because the failure we're getting with the other script
>> > also seems to involve an expression with call to length().  Here's the
>> > error from calling that script:
>> >
>> > $ ./spectral_clustering.R 3
>> > Loading required package: methods
>> > Error in length(tmpsig) * nc : non-numeric argument to binary operator
>> > Calls: specc -> specc -> .local -> matrix
>> > Execution halted
>> >
>> > The script is calling the specc() function in the kernlab library.
>> >
>> > Any ideas what's going on here, why it's not working and what we can
>> > do to get it to work?  Is there something that needs to be set or run
>> > in .Renviron or .Rprofile, say?
>> >
>> > Thanks.
>> >
>> > Milt Epstein
>> > Programmer in Computational Genomics
>> > Institute for Genomic Biology (IGB)
>> > University of Illinois at Urbana-Champaign (UIUC)
>> > mepstein at illinois.edu
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu Apr  9 02:42:56 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 8 Apr 2015 20:42:56 -0400
Subject: [R] extracting slot "coords" from a Polygons class object
In-Reply-To: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>
References: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>
Message-ID: <CAM_vju=hw5BF6A54q6Yn4JSDLp0XR94_s_JwXA7N72Uq5sb8-g@mail.gmail.com>

You didn't parse the output you pasted in correctly:

pt1.cpoly at polygons[[1]]@Polygons[[1]]@coords

or

coordinates(pt1.cpoly at polygons[[1]]@Polygons[[1]])

> class(pt1.cpoly)
[1] "SpatialPolygons"
attr(,"package")
[1] "sp"

So see
 ?"SpatialPolygons-class"
for details.

Sarah

On Wed, Apr 8, 2015 at 5:07 PM, Monica Pisica <pisicandru at hotmail.com> wrote:
>
> Hi,
>
>
>
> I am struggling to extract the polygon vertices from a list of an object class "Polygons", specifically the slot "coords".
>
>
>
>  I have a point, and i "draw" a buffer around with gBuffer, i am "extracting" the polygon form the SpatialPolygons class and i end up with a list of 1 one object Polygons class that seems to have slots, but if i try to extract them i get an error.
>
>
>
> So here it goes after i load the respective libraries: sp, maptools, rgdal, rgeos
>
> pt1 <- data.frame(x=217680.2, y = 3817555)
>
> coordinates(pt1) <- c("x", "y")
>
> crs = "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
>
>
>
> proj4string(pt1) <- CRS(crs)
>
> pt1.cpoly <- gBuffer(pt1, width = 100, byid = TRUE)
>
>
>
> pt1.cpoly
>
> class       : SpatialPolygons
>
> features    : 1
>
> extent      : 217580.2, 217780.2, 3817455, 3817655  (xmin, xmax, ymin, ymax)
>
> coord. ref. : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0
>
>
>
> pt1.poly <- pt1.cpoly at polygons
>
>
>
> pt1.poly
>
> [[1]]
>
> An object of class "Polygons"
>
> Slot "Polygons":
>
> [[1]]
>
> An object of class "Polygon"
>
> Slot "labpt":
>
> [1]  217680.2 3817554.7
>
>
>
> Slot "area":
>
> [1] 30901.7
>
>
>
> Slot "hole":
>
> [1] FALSE
>
>
>
> Slot "ringDir":
>
> [1] 1
>
>
>
> Slot "coords":
>
>              x       y
>
>  [1,] 217780.2 3817555
>
>  [2,] 217775.3 3817524
>
>  [3,] 217761.1 3817496
>
>  [4,] 217739.0 3817474
>
> Etc. ?..
>
>
>
> pt1.crd <- pt1.poly[[1]]@coords
>
> Error: no slot of name "coords" for this object of class "Polygons"
>
>
>
> So my question is: How do i access the "coords" slot i clearly see when i print pt1.poly on the screen?
>
>
>
> Thanks for any help,
>
>
>
> Monica
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From samarvir1996 at gmail.com  Thu Apr  9 02:57:43 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Thu, 9 Apr 2015 06:27:43 +0530
Subject: [R] how to Subset based on partial matching of columns?
Message-ID: <CAOpgo6iAaycz90p2zCFTd-zxD2O=cSc1NfDmvPH4eByFGRgPxg@mail.gmail.com>

So I have a list that contains certain characters as shown below

`list <- c("MY","GM+" ,"TY","RS","LG")`

And I have a variable named "CODE" in the data frame as follows

`code <- c("MY GM+", ,"LGTY", "RS","TY")`
'x <- c(1:5)
`df <- data.frame(x,code)`

df

     x code
    1 MY GM+
    2
    3 LGTY
    4 RS
    5 TY


Now I want to create 5 new variables named "MY","GM+","TY","RS","LG"

Which takes binary value, 1 if there's a match case in the CODE variable

    df
     x  code         MY GM+ TY RS LG
    1  MY GM+  1     1      0    0   0
    2                  0     0      0    0   0
    3  LGTY       0     0     1     0   1
    4  RS           0     0      0    1    0
    5  TY           0     0      1    0    0

Really appreciate your help. Thank you.

	[[alternative HTML version deleted]]


From unginun at gmail.com  Thu Apr  9 04:35:13 2015
From: unginun at gmail.com (=?UTF-8?B?7KCV7KeE7ISg?=)
Date: Thu, 9 Apr 2015 11:35:13 +0900
Subject: [R] fUtilities error
Message-ID: <CAKYcn+15LuAXK29iuP219ZhXg3Fdps4Lw9AkrWaOM-DpHyB1VA@mail.gmail.com>

Hi, there.

I'd like to run OCAP program to analyse iTRAQ data, but i failed to run due
to error of fUtilities.

It only could run under the R 2.0.0 version.

However i couldn't install R program under the R.2.0.0 version.

While i'm trying to figure out the problem, I found that fUtilities were
removed from the CRAN , but it was replaced to fBascis.

Then I run the OCAP by using the fBasics instead of fUtilities, but i also
failed.

How could i solve these problem?


-- 

*Jin Sun Jung*

*Research Scientist*

Wide River Institute of Immunology <http://youtu.be/BqWlbbNAXo8>

Seoul National University College of Medicine



101 Dabyeonbat-gil, Hwachon-myeon,

Hongcheon-gun, Gangwon-do 250-812 South KOREA

*Office) +82-33-439-8083 Fax) +82-33-439-8037 Mobile) +82-10-6440-5765*

****************************************************************************************

*This e-mail (including any attachments) is intended for the addressee(s) *

*stated above only and may contain confidential information protected
by law. *

*You are hereby notified that any unauthorized reading, disclosure, copying
or *

*distribution of this e-mail or use of information contained herein is
strictly prohibited *

*and may violate rights to proprietary information. If you are not an
intended recipient, *

*please return this e-mail to the sender and delete it immediately
hereafter.*

*Thank you.*

	[[alternative HTML version deleted]]


From luysgarcia at gmail.com  Thu Apr  9 08:11:37 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Thu, 9 Apr 2015 03:11:37 -0300
Subject: [R] sorting means for plot in descending order
Message-ID: <CANxP2S6U3u3NDum+uTvOaggqrsgT6EVWV3z70S_-xC7rAa_rWA@mail.gmail.com>

Dear R experts,

I am newbie on the R use, now I want to sort my data by mean in a
descending and not acending order (like I have done so far).  If any of you
could help me with this, it would be really appreciated!

Thanks!


Please find the script attached with the summary of the dat object


pt<-summarySE(dat, measurevar="Time", groupvars=("Prey"))#

pt

   Prey  N     Time       sd       se       ci
1 cochinilla 10 351.6000 99.34103 31.41439 71.06429
2    hormiga 17 193.2353 92.50014 22.43458 47.55918
3      larva 18 259.0667 93.84009 22.11832 46.66558
4    termita 19 144.6316 65.30895 14.98290 31.47791

pt$Prey=c("Isopoda","Formicidae","Lepidoptera","Isoptera")

bymean <- with(pt, reorder(Prey, Time, mean))# REordenar por promedio


library(ggplot2)

png(filename = "plotloxo1.png", width = 500, height = 500)

e <- qplot(bymean, pt$Time,size=3)+theme(panel.grid.major =
element_blank(), panel.grid.minor = element_blank(),
                                           panel.background =
element_blank(), axis.line = element_line(colour = "black"))#


e<-e+theme(legend.position="none")#
e+  geom_errorbar(data = pt, aes(x = pt$Prey, y = pt$Time, ymin = pt$Time -
pt$ci, ymax = pt$Time + pt$ci),
                  colour = "black", width = 0.4, size=0.5)+ #A?adir barras
de error
  xlab("Prey") +
  ylab("Time (Seconds)") +
  ggtitle("Total PM25 emissions")

dev.off()#

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Apr  9 08:21:23 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 09 Apr 2015 07:21:23 +0100
Subject: [R] Statistics course: Darwin, Australia
Message-ID: <55261A63.1050809@highstat.com>

Apologies for cross-posting


There are 8 remaining seats on the following course:

Course: Data exploration, regression, GLM & GAM with introduction to R
When: 3-7 August 2015
Where: Darwin, Australia
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08Darwin_regression_GLM_GAM.pdf
URL: http://www.highstat.com/statscourse.htm




Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From pdalgd at gmail.com  Thu Apr  9 09:30:45 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 9 Apr 2015 09:30:45 +0200
Subject: [R] sorting means for plot in descending order
In-Reply-To: <CANxP2S6U3u3NDum+uTvOaggqrsgT6EVWV3z70S_-xC7rAa_rWA@mail.gmail.com>
References: <CANxP2S6U3u3NDum+uTvOaggqrsgT6EVWV3z70S_-xC7rAa_rWA@mail.gmail.com>
Message-ID: <194A69FD-5FD0-4FD4-92EE-830CE6252462@gmail.com>


> On 09 Apr 2015, at 08:11 , Luis Fernando Garc?a <luysgarcia at gmail.com> wrote:
> 
> Dear R experts,
> 
> I am newbie on the R use, now I want to sort my data by mean in a
> descending and not acending order (like I have done so far).  If any of you
> could help me with this, it would be really appreciated!

How about replacing "mean" with "function(x) -mean(x)" ?

-pd 

> 
> Thanks!
> 
> 
> Please find the script attached with the summary of the dat object
> 
> 
> pt<-summarySE(dat, measurevar="Time", groupvars=("Prey"))#
> 
> pt
> 
>   Prey  N     Time       sd       se       ci
> 1 cochinilla 10 351.6000 99.34103 31.41439 71.06429
> 2    hormiga 17 193.2353 92.50014 22.43458 47.55918
> 3      larva 18 259.0667 93.84009 22.11832 46.66558
> 4    termita 19 144.6316 65.30895 14.98290 31.47791
> 
> pt$Prey=c("Isopoda","Formicidae","Lepidoptera","Isoptera")
> 
> bymean <- with(pt, reorder(Prey, Time, mean))# REordenar por promedio
> 
> 
> library(ggplot2)
> 
> png(filename = "plotloxo1.png", width = 500, height = 500)
> 
> e <- qplot(bymean, pt$Time,size=3)+theme(panel.grid.major =
> element_blank(), panel.grid.minor = element_blank(),
>                                           panel.background =
> element_blank(), axis.line = element_line(colour = "black"))#
> 
> 
> e<-e+theme(legend.position="none")#
> e+  geom_errorbar(data = pt, aes(x = pt$Prey, y = pt$Time, ymin = pt$Time -
> pt$ci, ymax = pt$Time + pt$ci),
>                  colour = "black", width = 0.4, size=0.5)+ #A?adir barras
> de error
>  xlab("Prey") +
>  ylab("Time (Seconds)") +
>  ggtitle("Total PM25 emissions")
> 
> dev.off()#
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From amado at cambrasabadell.org  Thu Apr  9 12:25:39 2015
From: amado at cambrasabadell.org (=?iso-8859-1?Q?Manel_Amado_Mart=ED?=)
Date: Thu, 9 Apr 2015 10:25:39 +0000
Subject: [R] sorting means for plot in descending order (Luis Fernando
	Garc?a)
Message-ID: <AM2PR05MB1202DF13EFD6543EF0E1EE63C6FB0@AM2PR05MB1202.eurprd05.prod.outlook.com>

Re:

Try with sort() function
sort(x, decreasing = FALSE, ...)  As you can see, u can set the argument decreasing=TRUE, then, it'll sort by decreasing order.
For more details, call:
help(sort)  under R console


Message: 23
Date: Thu, 9 Apr 2015 03:11:37 -0300
From: Luis Fernando Garc?a <luysgarcia at gmail.com>
To: r-help at r-project.org
Subject: [R] sorting means for plot in descending order
Message-ID:
	<CANxP2S6U3u3NDum+uTvOaggqrsgT6EVWV3z70S_-xC7rAa_rWA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Dear R experts,

I am newbie on the R use, now I want to sort my data by mean in a
descending and not acending order (like I have done so far).  If any of you
could help me with this, it would be really appreciated!

Thanks!


Please find the script attached with the summary of the dat object


pt<-summarySE(dat, measurevar="Time", groupvars=("Prey"))#

pt

   Prey  N     Time       sd       se       ci
1 cochinilla 10 351.6000 99.34103 31.41439 71.06429
2    hormiga 17 193.2353 92.50014 22.43458 47.55918
3      larva 18 259.0667 93.84009 22.11832 46.66558
4    termita 19 144.6316 65.30895 14.98290 31.47791

pt$Prey=c("Isopoda","Formicidae","Lepidoptera","Isoptera")

bymean <- with(pt, reorder(Prey, Time, mean))# REordenar por promedio


library(ggplot2)

png(filename = "plotloxo1.png", width = 500, height = 500)

e <- qplot(bymean, pt$Time,size=3)+theme(panel.grid.major =
element_blank(), panel.grid.minor = element_blank(),
                                           panel.background =
element_blank(), axis.line = element_line(colour = "black"))#


e<-e+theme(legend.position="none")#
e+  geom_errorbar(data = pt, aes(x = pt$Prey, y = pt$Time, ymin = pt$Time -
pt$ci, ymax = pt$Time + pt$ci),
                  colour = "black", width = 0.4, size=0.5)+ #A?adir barras
de error
  xlab("Prey") +
  ylab("Time (Seconds)") +
  ggtitle("Total PM25 emissions")

dev.off()#

	[[alternative HTML version deleted]]








Manel Amado i Mart?
Cap d'Assessoria de Comer? Interior
amado at cambrasabadell.org
Tel. 93 745 12 63 ? Fax 93 745 12 64 
? ? 
Av. Francesc Maci?, 35 ? 08206 Sabadell
Apt. corr. 119 ? www.cambrasabadell.org


From therneau at mayo.edu  Thu Apr  9 14:26:44 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 09 Apr 2015 07:26:44 -0500
Subject: [R] Coxme penalized log-likelihood mismatch
In-Reply-To: <mailman.1.1428573602.30041.r-help@r-project.org>
References: <mailman.1.1428573602.30041.r-help@r-project.org>
Message-ID: <2f3a88$dhoop@ironport10.mayo.edu>

The perils of backwards compatability....

During computation the important quantity is  loglik + penalty.  That is what is contained 
in the third element of the loglik vector.

Originally that is also what was printed, but I later realized that for statistical 
inference one wants the loglik and penalty to be separate, e.g. the AIC is based on the 
loglik and the degrees of freedom.  So I changed the printout to give
    loglik at beta=0,  integrated loglik at solution,  ordinary loglik at solution
(Integrated and ordinary are the same at beta=0).

But, because I was worried that some people would have been reading the results in a 
program (like you are), I didn't want to break their code so left the internal variable 
alone.  It appears that I traded "maybe safer" for "certain confusion".

Terry Therneau


On 04/09/2015 05:00 AM, r-help-request at r-project.org wrote:
> Hi,?
>
> I need to extract the penalized log-likehood term from coxme objects but I find the values stored whitin the object different than the penalized term given in the summary output of coxme function. Both the Null and the Integrated values are identical but the penalized is always off.?
>
> Any thoughts on why and how i can extract the right value to compute the AIC myself? (I know an AIC value is given in the output but I need to compute it myself inside a loop)?
>
> Many thanks,?
>
> Alexandre Lafontaine
>


From Rainer at krugs.de  Thu Apr  9 14:39:14 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 09 Apr 2015 14:39:14 +0200
Subject: [R] Convert numerical value into function which returns numerical
	value
Message-ID: <m2mw2h4gst.fsf@krugs.de>


Hi

I want convert, in a function, an argument from a numerical value to a
function which returns this value.:

My Code:

--8<---------------cut here---------------start------------->8---
dep <- 13
dep <- function() {dep}
dep
--8<---------------cut here---------------end--------------->8---

This is what I get:
#+RESULTS:
,----
| function(PAI) { dep }
`----

This is what I want
,----
| function(PAI) { 13 }
`----

I thought about using eval(dep), but this gives me the effectively the
same.

Is it possible to achieve what I want? I somehow have the feeling this
is not that easily possible, as the code in the function definition is
only evaluated when the function is evaluated.

I could obviously do something like

--8<---------------cut here---------------start------------->8---
dep <- 13
depVal <- dep
dep <- function() {depVal}
dep()
--8<---------------cut here---------------end--------------->8---

But is there a better solution? 

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150409/6b756ac3/attachment.bin>

From pisicandru at hotmail.com  Thu Apr  9 14:55:31 2015
From: pisicandru at hotmail.com (Monica Pisica)
Date: Thu, 9 Apr 2015 12:55:31 +0000
Subject: [R] extracting slot "coords" from a Polygons class object
In-Reply-To: <CAM_vju=hw5BF6A54q6Yn4JSDLp0XR94_s_JwXA7N72Uq5sb8-g@mail.gmail.com>
References: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>,
	<CAM_vju=hw5BF6A54q6Yn4JSDLp0XR94_s_JwXA7N72Uq5sb8-g@mail.gmail.com>
Message-ID: <BAY168-W70B77336FA66BC75F937E9C3FB0@phx.gbl>

Hi Sarah,


Thank you so much. This is exactly what i need it. I was wondering if my parsing was totally wrong. I read the SpatialPolygons-class help, but obviously i didn't understand it. 


Again, thanks so much,


Monica

----------------------------------------
> Date: Wed, 8 Apr 2015 20:42:56 -0400
> Subject: Re: [R] extracting slot "coords" from a Polygons class object
> From: sarah.goslee at gmail.com
> To: pisicandru at hotmail.com
> CC: r-help at r-project.org
>
> You didn't parse the output you pasted in correctly:
>
> pt1.cpoly at polygons[[1]]@Polygons[[1]]@coords
>
> or
>
> coordinates(pt1.cpoly at polygons[[1]]@Polygons[[1]])
>
>> class(pt1.cpoly)
> [1] "SpatialPolygons"
> attr(,"package")
> [1] "sp"
>
> So see
> ?"SpatialPolygons-class"
> for details.
>
> Sarah
>
> On Wed, Apr 8, 2015 at 5:07 PM, Monica Pisica <pisicandru at hotmail.com> wrote:
>>
>> Hi,
>>
>>
>>
>> I am struggling to extract the polygon vertices from a list of an object class "Polygons", specifically the slot "coords".
>>
>>
>>
>> I have a point, and i "draw" a buffer around with gBuffer, i am "extracting" the polygon form the SpatialPolygons class and i end up with a list of 1 one object Polygons class that seems to have slots, but if i try to extract them i get an error.
>>
>>
>>
>> So here it goes after i load the respective libraries: sp, maptools, rgdal, rgeos
>>
>> pt1 <- data.frame(x=217680.2, y = 3817555)
>>
>> coordinates(pt1) <- c("x", "y")
>>
>> crs = "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
>>
>>
>>
>> proj4string(pt1) <- CRS(crs)
>>
>> pt1.cpoly <- gBuffer(pt1, width = 100, byid = TRUE)
>>
>>
>>
>> pt1.cpoly
>>
>> class : SpatialPolygons
>>
>> features : 1
>>
>> extent : 217580.2, 217780.2, 3817455, 3817655 (xmin, xmax, ymin, ymax)
>>
>> coord. ref. : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0
>>
>>
>>
>> pt1.poly <- pt1.cpoly at polygons
>>
>>
>>
>> pt1.poly
>>
>> [[1]]
>>
>> An object of class "Polygons"
>>
>> Slot "Polygons":
>>
>> [[1]]
>>
>> An object of class "Polygon"
>>
>> Slot "labpt":
>>
>> [1] 217680.2 3817554.7
>>
>>
>>
>> Slot "area":
>>
>> [1] 30901.7
>>
>>
>>
>> Slot "hole":
>>
>> [1] FALSE
>>
>>
>>
>> Slot "ringDir":
>>
>> [1] 1
>>
>>
>>
>> Slot "coords":
>>
>> x y
>>
>> [1,] 217780.2 3817555
>>
>> [2,] 217775.3 3817524
>>
>> [3,] 217761.1 3817496
>>
>> [4,] 217739.0 3817474
>>
>> Etc. ?..
>>
>>
>>
>> pt1.crd <- pt1.poly[[1]]@coords
>>
>> Error: no slot of name "coords" for this object of class "Polygons"
>>
>>
>>
>> So my question is: How do i access the "coords" slot i clearly see when i print pt1.poly on the screen?
>>
>>
>>
>> Thanks for any help,
>>
>>
>>
>> Monica
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org 		 	   		  

From sarah.goslee at gmail.com  Thu Apr  9 15:24:04 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 9 Apr 2015 09:24:04 -0400
Subject: [R] how to Subset based on partial matching of columns?
In-Reply-To: <CAOpgo6iAaycz90p2zCFTd-zxD2O=cSc1NfDmvPH4eByFGRgPxg@mail.gmail.com>
References: <CAOpgo6iAaycz90p2zCFTd-zxD2O=cSc1NfDmvPH4eByFGRgPxg@mail.gmail.com>
Message-ID: <CAM_vjun0FRAoZ1eMqSsRACHWm+DxmVGwA96z6s=T1wFG_QLOMA@mail.gmail.com>

Hi,

Please don't put quotes around your code. It makes it hard to copy and
paste. Alternatively, don't post in HTML, because it screws up your
code.

On Wed, Apr 8, 2015 at 8:57 PM, samarvir singh <samarvir1996 at gmail.com> wrote:
> So I have a list that contains certain characters as shown below
>
> `list <- c("MY","GM+" ,"TY","RS","LG")`

That's a character vector, not a list. A list is a specific type of object in R.

> And I have a variable named "CODE" in the data frame as follows
>
> `code <- c("MY GM+", ,"LGTY", "RS","TY")`

That doesn't work, and I have no idea what you expect to have there,
so I'm deleting the extra comma. Also, your vector is named code, not
CODE.

code <- c("MY GM+", "LGTY", "RS","TY")
x <- c(1:4)

> 'x <- c(1:5)
> `df <- data.frame(x,code)`

You problably actually want
mydf <- data.frame(x, code, stringsAsFactors=FALSE)

Note I changed the name, because df() is a base R function.


> Now I want to create 5 new variables named "MY","GM+","TY","RS","LG"
>
> Which takes binary value, 1 if there's a match case in the CODE variable
>
>     df
>      x  code         MY GM+ TY RS LG
>     1  MY GM+  1     1      0    0   0
>     2                  0     0      0    0   0
>     3  LGTY       0     0     1     0   1
>     4  RS           0     0      0    1    0
>     5  TY           0     0      1    0    0

grepl() will give you a logical match

data.frame(mydf, sapply(code, function(x)grepl(x, mydf$code)),
stringsAsFactors=FALSE, check.names=FALSE)

Sarah


-- 
Sarah Goslee
http://www.functionaldiversity.org


From samarvir1996 at gmail.com  Thu Apr  9 15:49:52 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Thu, 09 Apr 2015 13:49:52 +0000
Subject: [R] how to Subset based on partial matching of columns?
In-Reply-To: <CAM_vjun0FRAoZ1eMqSsRACHWm+DxmVGwA96z6s=T1wFG_QLOMA@mail.gmail.com>
References: <CAOpgo6iAaycz90p2zCFTd-zxD2O=cSc1NfDmvPH4eByFGRgPxg@mail.gmail.com>
	<CAM_vjun0FRAoZ1eMqSsRACHWm+DxmVGwA96z6s=T1wFG_QLOMA@mail.gmail.com>
Message-ID: <CAOpgo6iWEH9HgTyzd2FwXYYmLBwJoG1=9VpsDVAxuuxOn+5pqw@mail.gmail.com>

Thank you. Sarah Goslee. I am rather new in learning R. So people like you
are great support. Really appreciate you, taking the time to correct my
mistakes. Thanks

On Thu 9 Apr, 2015 6:54 pm Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> Please don't put quotes around your code. It makes it hard to copy and
> paste. Alternatively, don't post in HTML, because it screws up your
> code.
>
> On Wed, Apr 8, 2015 at 8:57 PM, samarvir singh <samarvir1996 at gmail.com>
> wrote:
> > So I have a list that contains certain characters as shown below
> >
> > `list <- c("MY","GM+" ,"TY","RS","LG")`
>
> That's a character vector, not a list. A list is a specific type of object
> in R.
>
> > And I have a variable named "CODE" in the data frame as follows
> >
> > `code <- c("MY GM+", ,"LGTY", "RS","TY")`
>
> That doesn't work, and I have no idea what you expect to have there,
> so I'm deleting the extra comma. Also, your vector is named code, not
> CODE.
>
> code <- c("MY GM+", "LGTY", "RS","TY")
> x <- c(1:4)
>
> > 'x <- c(1:5)
> > `df <- data.frame(x,code)`
>
> You problably actually want
> mydf <- data.frame(x, code, stringsAsFactors=FALSE)
>
> Note I changed the name, because df() is a base R function.
>
>
> > Now I want to create 5 new variables named "MY","GM+","TY","RS","LG"
> >
> > Which takes binary value, 1 if there's a match case in the CODE variable
> >
> >     df
> >      x  code         MY GM+ TY RS LG
> >     1  MY GM+  1     1      0    0   0
> >     2                  0     0      0    0   0
> >     3  LGTY       0     0     1     0   1
> >     4  RS           0     0      0    1    0
> >     5  TY           0     0      1    0    0
>
> grepl() will give you a logical match
>
> data.frame(mydf, sapply(code, function(x)grepl(x, mydf$code)),
> stringsAsFactors=FALSE, check.names=FALSE)
>
> Sarah
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Apr  9 16:57:50 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Apr 2015 07:57:50 -0700
Subject: [R] Convert numerical value into function which returns
	numerical value
In-Reply-To: <m2mw2h4gst.fsf@krugs.de>
References: <m2mw2h4gst.fsf@krugs.de>
Message-ID: <CAF8bMcaeR_DTqk48Erdo9wUhDwnHdAMnZTxSdQbCDD+v=crD5g@mail.gmail.com>

You can make such functions by using the fact that a function
(really, a 'closure') always has access to the environment in
which the function was created.  E.g.
  makeConstantFunction <- function(constant) {
      force(constant) # evaluate the argument now
      function(PAI) {
          constant
      }
  }
  f17 <- makeConstantFunction(17)
  flog17 <- makeConstantFunction(log(17))
  f17(111)
  # [1] 17
  flog17(111)
  # [1] 2.833213

If you print f17 and flog17 they will look the same, except for
their environments and you have to inspect those to see why
they act differently.

  ls.str(environment(f17))
  # constant :  num 17
  ls.str(environment(flog17))
  # constant :  num 2.83

If you really want the functions to look different you can use
substittute or bquote, but that is also a bit mysterious (you need the
eval()
their outputs):
  g17 <- eval(substitute(function(PAI)x, list(x=17)))
  h17 <- eval(bquote(function(PAI).(x), list(x=17)))
  g17(10)
  [1] 17
  h17(10:1)
  [1] 17




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 9, 2015 at 5:39 AM, Rainer M Krug <Rainer at krugs.de> wrote:

>
> Hi
>
> I want convert, in a function, an argument from a numerical value to a
> function which returns this value.:
>
> My Code:
>
> --8<---------------cut here---------------start------------->8---
> dep <- 13
> dep <- function() {dep}
> dep
> --8<---------------cut here---------------end--------------->8---
>
> This is what I get:
> #+RESULTS:
> ,----
> | function(PAI) { dep }
> `----
>
> This is what I want
> ,----
> | function(PAI) { 13 }
> `----
>
> I thought about using eval(dep), but this gives me the effectively the
> same.
>
> Is it possible to achieve what I want? I somehow have the feeling this
> is not that easily possible, as the code in the function definition is
> only evaluated when the function is evaluated.
>
> I could obviously do something like
>
> --8<---------------cut here---------------start------------->8---
> dep <- 13
> depVal <- dep
> dep <- function() {depVal}
> dep()
> --8<---------------cut here---------------end--------------->8---
>
> But is there a better solution?
>
> Thanks,
>
> Rainer
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Thu Apr  9 19:20:55 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 9 Apr 2015 13:20:55 -0400
Subject: [R] recommended references/tutorials for Rmpi (particularly on
 Windows), please?
Message-ID: <CACxE24ngn6SVgU3ik53N7U+d-J-Lm-AEEC_4ZSeTBQWxuB-wVA@mail.gmail.com>

Hello!

Has anyone worked with Rmpi on Windows, please?

I have downloaded it and also got the Microsoft MPI.

The tests work fine.

I have worked with MPI on a cluster, using C and have done some work with
Rmpi on Linux/Ubuntu.

However, I was wondering if someone had a favorite site or text he/she
could recommend, please.

This would be for Windows 8, Rmpi 0.6-5, on R-3.13

Thanks,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From maurizio.gibin at jrc.ec.europa.eu  Thu Apr  9 13:11:14 2015
From: maurizio.gibin at jrc.ec.europa.eu (Maurizio GIBIN)
Date: Thu, 09 Apr 2015 13:11:14 +0200
Subject: [R] KDE on a large dataset (15 million points)
In-Reply-To: <CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
	<CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
Message-ID: <55265E52.80707@jrc.ec.europa.eu>

Hello everyone,
I am having some troubles in calculating a kde surface from a datatable.
The code is efficient in my opionion, but I have a problem on the output.
After some modelling that is not relevant for the purpose of my question 
I obtain a data.table of around 15 million records (for half a year, I 
forecast around 50 millions for the entire year).
The data.table is pretty simple, just lat and lon.
Let's forget for a second the problems related to projection, and focus 
on the K(ernel)D(ensity)E(stimation). Do you have any suggestion on a 
library that could be able to cope with so many points?
I know I could calculate the density in different ways and through 
different platforms, however, I would like to stick to R as it is 
commonly diffused in research.
I also know that probably subsetting the dataset is a wise choice...
Thanks.




-- 

*MAURIZIO GIBIN **
*Scientific/Technical Project Officer

*
**European Commission**
*Joint Research Centre

Institute for the Protection and Security of the Citizen (IPSC)

Maritime Affairs Unit*
*TP05A

Via Enrico Fermi 2749*
*I-21027 Ispra (VA)*
*+39 0332 786770*
maurizio.gibin at jrc.ec.europa.eu*
***


**<mailto:maurizio.gibin at jrc.ec.europa.eu> *


From loos at leuphana.de  Thu Apr  9 15:23:53 2015
From: loos at leuphana.de (Jacqueline)
Date: Thu, 9 Apr 2015 06:23:53 -0700 (PDT)
Subject: [R] Using randtest in rlq works for one dataset,
 but not for the other....
Message-ID: <1428585833738-4705655.post@n4.nabble.com>

Dear knowledgeable people, 

I am running rlq analyses for two different datasets. Even though these
datasets are quite similar, for one of them I receive the error: "Error in
randtest.rlq(xtest, modeltype = 2, nrepet = nrepet, ...) : 
  Not yet available" when applying randtest(pres.rlq) 

My first dataset, for which the test works, looks like this: 
> str(birdsX)
'data.frame':	116 obs. of  51 variables:
 $ Acrocephalus_palustris       : int  1 0 0 0 0 0 0 0 0 0 ...
 $ Aegithalos_caudatus          : int  0 0 0 0 0 0 0 0 1 1 ...
 $ Alauda_arvensis              : int  0 1 0 1 1 1 0 0 0 0 ...
 $ Anthus_campestris            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Anthus_trivialis             : int  0 1 0 0 0 1 1 0 0 0 ...
 $ Carduelis_cannabina          : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Carduelis_carduelis          : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Carduelis_chloris            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Coccothraustes_coccothraustes: int  0 1 0 0 0 0 1 0 0 1 ...
 $ Columba_palumbus             : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Crex_crex                    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Emberiza_calandra            : int  0 1 0 0 0 0 0 0 0 0 ...
 $ Emberiza_citrinella          : int  0 1 1 0 1 1 1 0 1 0 ...
 $ Erithacus_rubecula           : int  0 0 1 0 0 0 0 0 0 0 ...
 $ Fringilla_coelebs            : int  0 0 0 0 0 0 0 0 1 0 ...
 $ Garrulus_glandarius          : int  0 0 0 0 0 0 0 0 1 0 ...
 $ Hippolais_pallida            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Lanius_collurio              : int  0 0 1 0 0 1 0 0 0 0 ...
 $ Lanius_excubitor             : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Lanius_minor                 : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Locustella_fluviatilis       : int  0 0 0 0 0 0 0 0 1 0 ...
 $ Lullula_arborea              : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Luscinia_luscinia            : int  0 0 0 0 0 0 0 0 1 1 ...
 $ Motacilla_alba               : int  1 0 0 0 0 0 0 0 0 0 ...
 $ Motacilla_flava              : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Oriolus_oriolus              : int  1 0 0 0 0 0 0 0 0 0 ...
 $ Parus_caeruleus              : int  0 0 0 0 0 0 0 0 1 0 ...
 $ Parus_major                  : int  1 1 1 0 0 0 1 0 1 0 ...
 $ Parus_palustris              : int  0 0 1 0 0 0 0 0 1 0 ...
 $ Passer_domesticus            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Passer_montanus              : int  0 0 1 0 0 0 0 0 0 0 ...
 $ Phylloscopus_collybita       : int  0 1 0 0 0 0 1 0 1 0 ...
 $ Phylloscopus_sibilatrix      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Phylloscopus_trochilus       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Pica_pica                    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Picus_canus                  : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Picus_viridis                : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Saxicola_rubetra             : int  0 0 0 0 1 0 0 1 0 0 ...
 $ Saxicola_torquata            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Sitta_europea                : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Sturnus_vulgaris             : int  0 0 0 0 0 0 0 0 1 1 ...
 $ Sylvia_atricapilla           : int  1 0 1 0 0 0 0 0 1 0 ...
 $ Sylvia_borin                 : int  1 0 0 0 0 0 1 0 0 1 ...
 $ Sylvia_communis              : int  1 1 0 0 0 0 0 0 0 0 ...
 $ Sylvia_curruca               : int  0 0 0 0 0 0 0 0 0 1 ...
 $ Sylvia_nisoria               : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Troglodytes_troglodytes      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Turdus_merula                : int  0 0 0 0 0 0 1 0 0 0 ...
 $ Turdus_philomelos            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Turdus_viscivorus            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Upupa_epops                  : int  0 0 0 0 0 0 0 0 0 0 ...
> str(traitX)
'data.frame':	51 obs. of  15 variables:
 $ family               : Factor w/ 25 levels "Buntings","Chats",..: 23 20 7
13 13 4 4 4 21 4 ...
 $ habitat              : Factor w/ 5 levels "aquatic","forest",..: 3 3 4 4
3 4 3 3 2 3 ...
 $ nest_location.cosmin : Factor w/ 4 levels "ground","herbaceous",..: 2 4 1
1 1 3 4 3 4 4 ...
 $ type_of_nest_._cosmin: Factor w/ 4 levels
"build_nest","escavate_hollow",..: 4 1 4 4 4 4 4 4 3 4 ...
 $ diet                 : Factor w/ 8 levels "Aerial_insect",..: 8 2 6 4 2 7
7 6 2 7 ...
 $ diet.cosmin          : Factor w/ 4 levels "carnivorous",..: 2 3 3 2 2 4 4
3 2 4 ...
 $ migratory_Cosmin     : Factor w/ 3 levels "long","resident",..: 1 2 1 1 1
2 2 2 2 2 ...
 $ foraging_technique.  : Factor w/ 12 levels "bark_forager",..: 12 12 6 6 6
11 11 10 1 11 ...
 $ homerange            : Factor w/ 3 levels "1-4ha","less1ha",..: 2 2 2 2 2
2 2 2 2 2 ...
 $ bodysize             : Factor w/ 6 levels "100-500g","15-24g",..: 5 5 3 2
2 2 2 3 5 4 ...
 $ clutchsize           : Factor w/ 3 levels "3-6eggs","less3eggs",..: 1 3 1
1 1 1 1 1 1 1 ...
 $ laying_date          : Factor w/ 7 levels "Early_April",..: 6 1 1 6 2 3 3
3 6 1 ...
 $ rarity               : Factor w/ 3 levels "75-95%","less75%",..: 2 1 1 1
2 3 3 3 2 1 ...
 $ national_trend       : Factor w/ 5 levels "increasing","Increasing",..: 4
4 3 4 4 1 4 3 4 4 ...
 $ Ecological_type      : Factor w/ 4 levels
"Farmland_whit_bushes_and_trees",..: 3 2 3 3 1 1 1 1 2 2 ...
> str(envir)
'data.frame':	116 obs. of  13 variables:
 $ woody_1ha    : num  0.349 0.247 0.439 -1.24 -1.24 ...
 $ spot_1ha     : num  -0.154 -0.308 0.91 -0.308 1.263 ...
 $ TWI          : num  1.773 -0.641 -0.297 0.459 1.21 ...
 $ heatload     : num  0.788 -0.986 -1.24 0.366 0.704 ...
 $ sidi_50ha    : num  -1.846 0.622 -1.115 -1.267 0.346 ...
 $ woody_50ha   : num  -0.381 1.443 0.476 -1.857 -1.286 ...
 $ rugg_50ha    : num  -1.2455 0.6073 0.197 -0.6771 -0.0291 ...
 $ ed_50ha      : num  -1.122 0.715 -0.407 -0.509 0.409 ...
 $ woodypercatch: num  0.586 0.586 0.586 -1.063 -1.063 ...
 $ catch_rugged : num  0.227 0.227 0.227 2.048 2.048 ...
 $ Edfine       : num  0.902 0.902 0.902 0.434 0.434 ...
 $ SIDIfine     : num  0.739 0.739 0.739 -0.407 -0.407 ...
 $ pastpercatch : num  -1.141 -1.141 -1.141 0.679 0.679 ...

> summary(pres.rlq)

Eigenvalues decomposition:
        eig     covar      sdR      sdQ      corr
1 1.9050088 1.3802205 1.730708 2.194411 0.3634181
2 0.3471101 0.5891605 1.156380 1.889246 0.2696775

Inertia & coinertia R:
    inertia      max     ratio
1  2.995351 3.379328 0.8863749
12 4.332566 5.234932 0.8276260

Inertia & coinertia Q:
    inertia      max     ratio
1  4.815442  6.36944 0.7560228
12 8.384691 12.42140 0.6750197

Correlation L:
       corr       max     ratio
1 0.3634181 0.7633403 0.4760892
2 0.2696775 0.6986529 0.3859963




The second one, for which it doesn?t work, looks like this: 

str(buttX)
'data.frame':	120 obs. of  88 variables:
 $ Aglais_urticae       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Antocharis_cardamines: num  0 0 0 0 0 0 0 0 0 0 ...
 $ Apatura_ilia         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Apatura_iris         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Aphantopus_hyperantus: num  0 1 1 1 0 1 1 0 1 1 ...
 $ Aporia_crataegi      : num  0 0 1 0 0 0 0 0 0 0 ...
 $ Araschnia_levana     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Argynnis_adippe      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Argynnis_aglaja      : num  0 0 0 1 0 1 1 0 0 0 ...
 $ Argynnis_niobe       : num  0 0 0 0 0 1 0 0 0 0 ...
 $ Argynnis_paphia      : num  1 1 0 0 0 0 1 0 1 0 ...
 $ Aricia_agestis       : num  0 0 0 0 0 0 0 0 1 0 ...
 $ Aricia_artaxerxes    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Boloria_dia          : num  0 0 0 0 1 1 1 0 0 0 ...
 $ Boloria_euphrosyne   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Boloria_selene       : num  0 0 1 0 0 1 0 0 0 0 ...
 $ Brenthis_daphne      : num  0 0 0 0 0 0 0 0 1 0 ...
 $ Brenthis_ino         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Aulocera_circe       : num  0 0 0 0 0 1 0 0 0 0 ...
 $ Callophrys_rubi      : num  0 0 0 0 1 0 0 0 0 0 ...
 $ Celastrina_argiolus  : num  0 0 0 0 0 0 0 0 1 0 ...
 $ Coenonympha_arcania  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Coenonympha_glycerion: num  0 1 1 1 1 1 0 0 1 1 ...
 $ Coenonympha_pamphilus: num  1 1 1 1 1 1 1 0 1 1 ...
 $ Colias_alfacariensis : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Colias_croceus       : num  1 0 0 0 1 0 0 0 0 0 ...
 $ Colias_hyale         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Cupido_minimus       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Cyaniris_semiargus   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Erebia_medusa        : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Erynnis_tages        : num  0 0 0 0 1 0 1 1 1 0 ...
 $ Aricia_eumedon       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Euphydryas_aurinia   : num  0 0 0 0 0 1 0 0 0 0 ...
 $ Cupido_argiades      : num  0 1 1 1 1 0 0 0 1 0 ...
 $ Glaucopsyche_alexis  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Gonepteryx_rhamni    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Hamearis_lucina      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Hesperia_comma       : num  0 1 1 1 1 1 0 0 0 0 ...
 $ Heteropterus_morpheus: num  0 0 0 0 0 0 0 0 1 0 ...
 $ Inachis_io           : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Iphiclides_podalirius: num  0 0 0 1 1 0 1 0 0 0 ...
 $ Issoria_lathonia     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Lasiommata_megera    : num  0 0 0 0 0 0 1 0 0 0 ...
 $ Leptidea_sinapis     : num  1 1 1 1 1 1 1 0 0 1 ...
 $ Limenitis_camilla    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Lopinga_achine       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Lycaena_alciphron    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Lycaena_dispar       : num  0 0 0 0 0 0 0 0 0 1 ...
 $ Lycaena_phlaeas      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Lycaena_tityrus      : num  0 1 0 0 0 0 0 0 0 0 ...
 $ Lycaena_virgaureae   : num  0 1 0 0 0 0 0 0 0 0 ...
 $ Polyommatus_bellargus: num  0 0 0 0 0 0 0 0 0 0 ...
 $ Maculinea_arion      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Maniola_jurtina      : num  1 1 1 1 1 1 1 1 1 1 ...
 $ Melanargia_galathea  : num  0 1 1 1 1 1 1 0 1 1 ...
 $ Polyommatus_daphnis  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Melitaea_athalia     : num  0 0 1 0 0 1 0 0 1 1 ...
 $ Melitaea_aurelia     : num  0 0 0 0 0 0 1 0 1 1 ...
 $ Melitaea_britomartis : num  0 0 1 0 0 0 0 0 0 0 ...
 $ Melitaea_cinxia      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Melitaea_diamina     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Melitaea_didyma      : num  0 0 0 0 0 0 1 0 0 0 ...
 $ Melitaea_phoebe      : num  0 0 0 0 0 1 0 0 0 0 ...
 $ Minois_dryas         : num  1 0 1 0 0 1 1 0 0 0 ...
 $ Nymphalis_antiopa    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Ochlodes_sylvanus    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Papilio_machaon      : num  0 0 0 1 0 0 0 0 0 0 ...
 $ Pieris_brassicae     : num  1 0 0 0 0 0 0 1 0 0 ...
 $ Pieris_napi          : num  0 0 1 0 0 0 0 0 0 0 ...
 $ Pieris_rapae         : num  1 1 0 1 0 0 0 0 1 0 ...
 $ Plebejus_argus       : num  1 1 1 1 1 1 1 1 1 1 ...
 $ Plebejus_argyrognomon: num  0 1 0 0 0 0 0 0 0 0 ...
 $ Plebejus_idas        : num  0 1 0 0 0 0 1 0 0 0 ...
 $ Polygonia_calbum     : num  1 0 0 0 0 0 0 0 1 0 ...
 $ Polyommatus_amandus  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Polyommatus_coridon  : num  0 0 0 0 0 1 0 0 0 0 ...
 $ Polyommatus_dorylas  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Polyommatus_icarus   : num  1 1 1 1 1 1 1 0 1 1 ...
 $ Polyommatus_thersites: num  0 0 0 0 0 1 0 0 0 0 ...
 $ Pyrgus_armoricanus   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Pyrgus_alveus        : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Pyrgus_malvae        : num  0 0 1 0 0 0 1 0 0 1 ...
 $ Satyrium_acaciae     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Satyrium_ilicis      : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Thymelicus_lineola   : num  0 1 1 1 1 0 1 1 1 0 ...
 $ Thymelicus_sylvestris: num  0 1 1 0 0 0 1 0 1 1 ...
 $ Vanessa_atalanta     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Vanessa_cardui       : num  0 0 0 0 0 0 0 0 0 0 ...
> str(envir)
'data.frame':	120 obs. of  13 variables:
 $ woody_1ha    : num  0.36 0.257 0.451 -1.245 -1.245 ...
 $ spot_1ha     : num  -0.159 -0.313 0.909 -0.313 1.265 ...
 $ TWI          : num  1.635 -0.636 -0.312 0.398 1.105 ...
 $ heatload     : num  0.789 -1.001 -1.257 0.363 0.704 ...
 $ sidi_50ha    : num  -1.879 0.621 -1.139 -1.292 0.341 ...
 $ woody_50ha   : num  -0.374 1.437 0.477 -1.838 -1.272 ...
 $ rugg_50ha    : num  -1.271 0.609 0.192 -0.695 -0.037 ...
 $ ed_50ha      : num  -1.125 0.704 -0.414 -0.516 0.399 ...
 $ woodypercatch: num  0.566 0.566 0.566 -1.076 -1.076 ...
 $ catch_rugged : num  0.236 0.236 0.236 2.084 2.084 ...
 $ Edfine       : num  0.926 0.926 0.926 0.453 0.453 ...
 $ SIDIfine     : num  0.719 0.719 0.719 -0.401 -0.401 ...
 $ pastpercatch : num  -1.111 -1.111 -1.111 0.703 0.703 ...
> str(butttraitX)
'data.frame':	88 obs. of  11 variables:
 $ Winglength : Factor w/ 25 levels "11","12","13",..: 13 10 20 22 11 19 7
16 14 15 ...
 $ Eggs_pot   : Factor w/ 52 levels "64","65","70",..: 51 33 20 22 28 33 37
32 30 25 ...
 $ Generations: Factor w/ 5 levels "2","3","4","5",..: 2 1 1 1 1 1 4 1 1 1
...
 $ Winterstage: Factor w/ 5 levels "adult","egg",..: 1 5 3 3 3 3 5 2 3 2 ...
 $ Eggdevtime : Factor w/ 32 levels "3","4","5","6",..: 6 3 10 12 14 14 3 27
15 30 ...
 $ Larvdevtime: Factor w/ 40 levels "16","17","18",..: 3 1 13 38 38 40 7 25
32 19 ...
 $ Pupdevtime : Factor w/ 23 levels "8","10","11",..: 2 23 8 7 10 8 4 12 9 6
...
 $ Imagotime  : Factor w/ 14 levels "10","12","14",..: 12 3 8 8 7 1 3 10 7 5
...
 $ r.K        : Factor w/ 2 levels "K","r": 2 1 1 1 1 2 2 1 1 1 ...
 $ Diet       : Factor w/ 3 levels "m","o","p": 1 2 2 1 3 2 1 1 1 1 ...
 $ Mobility   : Factor w/ 8 levels "1","2","3","4",..: 6 4 4 3 3 5 5 4 3 3
...

summary(pres.rlq)

Eigenvalues decomposition:
        eig     covar      sdR      sdQ      corr
1 0.6267516 0.7916764 1.724234 2.008068 0.2286511
2 0.2434880 0.4934451 1.153176 1.944874 0.2200148

Inertia & coinertia R:
    inertia      max     ratio
1  2.972982 3.249839 0.9148091
12 4.302797 5.171932 0.8319515

Inertia & coinertia Q:
    inertia       max     ratio
1  4.032335  7.669151 0.5257864
12 7.814868 13.948402 0.5602698

Correlation L:
       corr       max     ratio
1 0.2286511 0.4422966 0.5169633
2 0.2200148 0.4046466 0.5437207

I have been trying to find the mistake for hours already and I just can?t
get a clue why the test works for one example but not for the other. I would
be happy about recommendations how to solve this problem. 

Best wishes, 
Jacqueline




--
View this message in context: http://r.789695.n4.nabble.com/Using-randtest-in-rlq-works-for-one-dataset-but-not-for-the-other-tp4705655.html
Sent from the R help mailing list archive at Nabble.com.


From ejb6 at cornell.edu  Thu Apr  9 15:42:56 2015
From: ejb6 at cornell.edu (Elliot Joel Bernstein)
Date: Thu, 9 Apr 2015 09:42:56 -0400
Subject: [R] Windows Installation Without Third-Party Packages
Message-ID: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>

I am trying to install R for Windows, but when I use the installer provided
on CRAN, a number of third-party packages are installed by default (i.e.
lattice, Matrix, codetools, etc.). If R is installed with administrator
privileges, so it's available for all users, non-administrators can't
update those packages. Is there any way to just install R without any
third-party packages, and let individual users install the packages they
want?

Thanks.

- Elliot

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Apr  9 16:44:48 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 09 Apr 2015 14:44:48 +0000
Subject: [R] extracting slot "coords" from a Polygons class object
In-Reply-To: <BAY168-W70B77336FA66BC75F937E9C3FB0@phx.gbl>
References: <BAY168-W56C89230D254BEB978FB37C3FC0@phx.gbl>
	<CAM_vju=hw5BF6A54q6Yn4JSDLp0XR94_s_JwXA7N72Uq5sb8-g@mail.gmail.com>
	<BAY168-W70B77336FA66BC75F937E9C3FB0@phx.gbl>
Message-ID: <CAAcGz9-R-cM=knUDmG9ZigST3TyrBa5YDgNE2R5Tijzzz0ZEZQ@mail.gmail.com>

Note that you can get everything (without recording its structure) with
coordinates(as(as(x, "SpatialLines"), "SpatialPoints")) - also  ggplot2
uses fortify methods to turn these objects into tables.

Cheers, Mike.

On Thu, 9 Apr 2015 at 22:57 Monica Pisica <pisicandru at hotmail.com> wrote:

> Hi Sarah,
>
>
> Thank you so much. This is exactly what i need it. I was wondering if my
> parsing was totally wrong. I read the SpatialPolygons-class help, but
> obviously i didn't understand it.
>
>
> Again, thanks so much,
>
>
> Monica
>
> ----------------------------------------
> > Date: Wed, 8 Apr 2015 20:42:56 -0400
> > Subject: Re: [R] extracting slot "coords" from a Polygons class object
> > From: sarah.goslee at gmail.com
> > To: pisicandru at hotmail.com
> > CC: r-help at r-project.org
> >
> > You didn't parse the output you pasted in correctly:
> >
> > pt1.cpoly at polygons[[1]]@Polygons[[1]]@coords
> >
> > or
> >
> > coordinates(pt1.cpoly at polygons[[1]]@Polygons[[1]])
> >
> >> class(pt1.cpoly)
> > [1] "SpatialPolygons"
> > attr(,"package")
> > [1] "sp"
> >
> > So see
> > ?"SpatialPolygons-class"
> > for details.
> >
> > Sarah
> >
> > On Wed, Apr 8, 2015 at 5:07 PM, Monica Pisica <pisicandru at hotmail.com>
> wrote:
> >>
> >> Hi,
> >>
> >>
> >>
> >> I am struggling to extract the polygon vertices from a list of an
> object class "Polygons", specifically the slot "coords".
> >>
> >>
> >>
> >> I have a point, and i "draw" a buffer around with gBuffer, i am
> "extracting" the polygon form the SpatialPolygons class and i end up with a
> list of 1 one object Polygons class that seems to have slots, but if i try
> to extract them i get an error.
> >>
> >>
> >>
> >> So here it goes after i load the respective libraries: sp, maptools,
> rgdal, rgeos
> >>
> >> pt1 <- data.frame(x=217680.2, y = 3817555)
> >>
> >> coordinates(pt1) <- c("x", "y")
> >>
> >> crs = "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80
> +towgs84=0,0,0"
> >>
> >>
> >>
> >> proj4string(pt1) <- CRS(crs)
> >>
> >> pt1.cpoly <- gBuffer(pt1, width = 100, byid = TRUE)
> >>
> >>
> >>
> >> pt1.cpoly
> >>
> >> class : SpatialPolygons
> >>
> >> features : 1
> >>
> >> extent : 217580.2, 217780.2, 3817455, 3817655 (xmin, xmax, ymin, ymax)
> >>
> >> coord. ref. : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs
> +ellps=GRS80 +towgs84=0,0,0
> >>
> >>
> >>
> >> pt1.poly <- pt1.cpoly at polygons
> >>
> >>
> >>
> >> pt1.poly
> >>
> >> [[1]]
> >>
> >> An object of class "Polygons"
> >>
> >> Slot "Polygons":
> >>
> >> [[1]]
> >>
> >> An object of class "Polygon"
> >>
> >> Slot "labpt":
> >>
> >> [1] 217680.2 3817554.7
> >>
> >>
> >>
> >> Slot "area":
> >>
> >> [1] 30901.7
> >>
> >>
> >>
> >> Slot "hole":
> >>
> >> [1] FALSE
> >>
> >>
> >>
> >> Slot "ringDir":
> >>
> >> [1] 1
> >>
> >>
> >>
> >> Slot "coords":
> >>
> >> x y
> >>
> >> [1,] 217780.2 3817555
> >>
> >> [2,] 217775.3 3817524
> >>
> >> [3,] 217761.1 3817496
> >>
> >> [4,] 217739.0 3817474
> >>
> >> Etc. ?..
> >>
> >>
> >>
> >> pt1.crd <- pt1.poly[[1]]@coords
> >>
> >> Error: no slot of name "coords" for this object of class "Polygons"
> >>
> >>
> >>
> >> So my question is: How do i access the "coords" slot i clearly see when
> i print pt1.poly on the screen?
> >>
> >>
> >>
> >> Thanks for any help,
> >>
> >>
> >>
> >> Monica
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Thu Apr  9 20:13:45 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 9 Apr 2015 13:13:45 -0500
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
Message-ID: <CAAJSdjhJqh6QQP5sw=Y63qjnZ0KFMO=zQPUHKRt0cEZ6Kh+juQ@mail.gmail.com>

On Thu, Apr 9, 2015 at 8:42 AM, Elliot Joel Bernstein <ejb6 at cornell.edu>
wrote:

> I am trying to install R for Windows, but when I use the installer provided
> on CRAN, a number of third-party packages are installed by default (i.e.
> lattice, Matrix, codetools, etc.). If R is installed with administrator
> privileges, so it's available for all users, non-administrators can't
> update those packages. Is there any way to just install R without any
> third-party packages, and let individual users install the packages they
> want?
>
> Thanks.
>
> - Elliot
>
>         [[alternative HTML version deleted]]
>

?Please try to not post in HTML, per forum standards.

I don't know if this will help, but I hope so. I think what I did will be
self explanatory

> install.packages('plyr',lib=.libPaths()[1])
trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/plyr_1.8.1.zip'
Content type 'application/zip' length 1154715 bytes (1.1 Mb)
opened URL
downloaded 1.1 Mb

package ?plyr? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\john.mckown\AppData\Local\Temp\RtmpWIjtdm\downloaded_packages
> .libPaths()
[1] "C:/Users/john.mckown/Documents/R/win-library/3.1"
[2] "C:/Program Files/R/R-3.1.1/library"
> .libPaths()
[1] "C:/Users/john.mckown/Documents/R/win-library/3.1"
[2] "C:/Program Files/R/R-3.1.1/library"
> list.dirs(.libPaths()[1])
  [1] "C:/Users/john.mckown/Documents/R/win-library/3.1"

...
[116] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr"

[117] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/data"

[118] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/help"

[119] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/html"

[120] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs"

[121] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs/i386"

[122] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs/x64"

[123] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/Meta"

[124] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/R"

[125] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/tests"

[126] "C:/Users/john.mckown/Documents/R/win-library/3.1/R6"

...

As you can see, "plyr" got installed in my personal area. And it is still
on the system directory:

> list.dirs(.libPaths()[2])[seq(from=1050,to=1061)]
 [1] "C:/Program Files/R/R-3.1.1/library/parallel/tests"
 [2] "C:/Program Files/R/R-3.1.1/library/plyr"
 [3] "C:/Program Files/R/R-3.1.1/library/plyr/data"
 [4] "C:/Program Files/R/R-3.1.1/library/plyr/help"
 [5] "C:/Program Files/R/R-3.1.1/library/plyr/html"
 [6] "C:/Program Files/R/R-3.1.1/library/plyr/libs"
 [7] "C:/Program Files/R/R-3.1.1/library/plyr/libs/i386"
 [8] "C:/Program Files/R/R-3.1.1/library/plyr/libs/x64"
 [9] "C:/Program Files/R/R-3.1.1/library/plyr/Meta"
[10] "C:/Program Files/R/R-3.1.1/library/plyr/R"
[11] "C:/Program Files/R/R-3.1.1/library/plyr/tests"
[12] "C:/Program Files/R/R-3.1.1/library/proto"
>

Pardon the weird subscript, but the list was way to big to cut, paste, and
edit. So your users should be able to force any package, even a "system"
package, into their personal R directory using the "lib=" parameter of the
install.packages() function. This will allow them to update their copy of
any R package from CRAN.

I hope.?


-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Apr  9 21:03:23 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 09 Apr 2015 12:03:23 -0700
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <CAAJSdjhJqh6QQP5sw=Y63qjnZ0KFMO=zQPUHKRt0cEZ6Kh+juQ@mail.gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
	<CAAJSdjhJqh6QQP5sw=Y63qjnZ0KFMO=zQPUHKRt0cEZ6Kh+juQ@mail.gmail.com>
Message-ID: <87737865-12CC-42EB-994C-A953AD08A53A@dcn.davis.CA.us>

John's answer is correct but you might like one of the following summaries better.

The short (baby bear) answer is no. A longer (papa bear) answer is that anything is possible if you dig deep enough. But the just-right (mama bear) answer is that you don't need to worry about it since users should normally be updating their personal libraries which will take precedence over the system-wide library.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 9, 2015 11:13:45 AM PDT, John McKown <john.archie.mckown at gmail.com> wrote:
>On Thu, Apr 9, 2015 at 8:42 AM, Elliot Joel Bernstein
><ejb6 at cornell.edu>
>wrote:
>
>> I am trying to install R for Windows, but when I use the installer
>provided
>> on CRAN, a number of third-party packages are installed by default
>(i.e.
>> lattice, Matrix, codetools, etc.). If R is installed with
>administrator
>> privileges, so it's available for all users, non-administrators can't
>> update those packages. Is there any way to just install R without any
>> third-party packages, and let individual users install the packages
>they
>> want?
>>
>> Thanks.
>>
>> - Elliot
>>
>>         [[alternative HTML version deleted]]
>>
>
>?Please try to not post in HTML, per forum standards.
>
>I don't know if this will help, but I hope so. I think what I did will
>be
>self explanatory
>
>> install.packages('plyr',lib=.libPaths()[1])
>trying URL
>'http://cran.rstudio.com/bin/windows/contrib/3.1/plyr_1.8.1.zip'
>Content type 'application/zip' length 1154715 bytes (1.1 Mb)
>opened URL
>downloaded 1.1 Mb
>
>package ?plyr? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>C:\Users\john.mckown\AppData\Local\Temp\RtmpWIjtdm\downloaded_packages
>> .libPaths()
>[1] "C:/Users/john.mckown/Documents/R/win-library/3.1"
>[2] "C:/Program Files/R/R-3.1.1/library"
>> .libPaths()
>[1] "C:/Users/john.mckown/Documents/R/win-library/3.1"
>[2] "C:/Program Files/R/R-3.1.1/library"
>> list.dirs(.libPaths()[1])
>  [1] "C:/Users/john.mckown/Documents/R/win-library/3.1"
>
>...
>[116] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr"
>
>[117] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/data"
>
>[118] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/help"
>
>[119] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/html"
>
>[120] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs"
>
>[121] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs/i386"
>
>[122] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/libs/x64"
>
>[123] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/Meta"
>
>[124] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/R"
>
>[125] "C:/Users/john.mckown/Documents/R/win-library/3.1/plyr/tests"
>
>[126] "C:/Users/john.mckown/Documents/R/win-library/3.1/R6"
>
>...
>
>As you can see, "plyr" got installed in my personal area. And it is
>still
>on the system directory:
>
>> list.dirs(.libPaths()[2])[seq(from=1050,to=1061)]
> [1] "C:/Program Files/R/R-3.1.1/library/parallel/tests"
> [2] "C:/Program Files/R/R-3.1.1/library/plyr"
> [3] "C:/Program Files/R/R-3.1.1/library/plyr/data"
> [4] "C:/Program Files/R/R-3.1.1/library/plyr/help"
> [5] "C:/Program Files/R/R-3.1.1/library/plyr/html"
> [6] "C:/Program Files/R/R-3.1.1/library/plyr/libs"
> [7] "C:/Program Files/R/R-3.1.1/library/plyr/libs/i386"
> [8] "C:/Program Files/R/R-3.1.1/library/plyr/libs/x64"
> [9] "C:/Program Files/R/R-3.1.1/library/plyr/Meta"
>[10] "C:/Program Files/R/R-3.1.1/library/plyr/R"
>[11] "C:/Program Files/R/R-3.1.1/library/plyr/tests"
>[12] "C:/Program Files/R/R-3.1.1/library/proto"
>>
>
>Pardon the weird subscript, but the list was way to big to cut, paste,
>and
>edit. So your users should be able to force any package, even a
>"system"
>package, into their personal R directory using the "lib=" parameter of
>the
>install.packages() function. This will allow them to update their copy
>of
>any R package from CRAN.
>
>I hope.?
>
>
>-- 
>If you sent twitter messages while exploring, are you on a
>textpedition?
>
>He's about as useful as a wax frying pan.
>
>10 to the 12th power microphones = 1 Megaphone
>
>Maranatha! <><
>John McKown
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Apr  9 21:56:29 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 9 Apr 2015 19:56:29 +0000
Subject: [R] how to Subset based on partial matching of columns?
In-Reply-To: <CAOpgo6iWEH9HgTyzd2FwXYYmLBwJoG1=9VpsDVAxuuxOn+5pqw@mail.gmail.com>
References: <CAOpgo6iAaycz90p2zCFTd-zxD2O=cSc1NfDmvPH4eByFGRgPxg@mail.gmail.com>
	<CAM_vjun0FRAoZ1eMqSsRACHWm+DxmVGwA96z6s=T1wFG_QLOMA@mail.gmail.com>
	<CAOpgo6iWEH9HgTyzd2FwXYYmLBwJoG1=9VpsDVAxuuxOn+5pqw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67D2EC@mb02.ads.tamu.edu>

>From Sarah's data frame you can get what you want directly with the table() function which will create a table object, mydf.tbl. If you want a data frame you need to convert the table using as.data.frame.matrix() to make mydf.df. Finally combine the two data frames if your x column consists of unique values in ascending order to make mydf.all.

> mydf.tbl <- table(mydf$x, mydf$code)
> mydf.tbl
   
    LGTY MY GM+ RS TY
  1    0      1  0  0
  2    1      0  0  0
  3    0      0  1  0
  4    0      0  0  1
> mydf.df <- as.data.frame.matrix(mydf.tbl)
> mydf.df
  LGTY MY GM+ RS TY
1    0      1  0  0
2    1      0  0  0
3    0      0  1  0
4    0      0  0  1
> mydf.all <- data.frame(mydf, mydf.df)
> mydf.all
  x   code LGTY MY.GM. RS TY
1 1 MY GM+    0      1  0  0
2 2   LGTY    1      0  0  0
3 3     RS    0      0  1  0
4 4     TY    0      0  0  1


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of samarvir singh
Sent: Thursday, April 9, 2015 8:50 AM
To: Sarah Goslee
Cc: r-help
Subject: Re: [R] how to Subset based on partial matching of columns?

Thank you. Sarah Goslee. I am rather new in learning R. So people like you
are great support. Really appreciate you, taking the time to correct my
mistakes. Thanks

On Thu 9 Apr, 2015 6:54 pm Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> Please don't put quotes around your code. It makes it hard to copy and
> paste. Alternatively, don't post in HTML, because it screws up your
> code.
>
> On Wed, Apr 8, 2015 at 8:57 PM, samarvir singh <samarvir1996 at gmail.com>
> wrote:
> > So I have a list that contains certain characters as shown below
> >
> > `list <- c("MY","GM+" ,"TY","RS","LG")`
>
> That's a character vector, not a list. A list is a specific type of object
> in R.
>
> > And I have a variable named "CODE" in the data frame as follows
> >
> > `code <- c("MY GM+", ,"LGTY", "RS","TY")`
>
> That doesn't work, and I have no idea what you expect to have there,
> so I'm deleting the extra comma. Also, your vector is named code, not
> CODE.
>
> code <- c("MY GM+", "LGTY", "RS","TY")
> x <- c(1:4)
>
> > 'x <- c(1:5)
> > `df <- data.frame(x,code)`
>
> You problably actually want
> mydf <- data.frame(x, code, stringsAsFactors=FALSE)
>
> Note I changed the name, because df() is a base R function.
>
>
> > Now I want to create 5 new variables named "MY","GM+","TY","RS","LG"
> >
> > Which takes binary value, 1 if there's a match case in the CODE variable
> >
> >     df
> >      x  code         MY GM+ TY RS LG
> >     1  MY GM+  1     1      0    0   0
> >     2                  0     0      0    0   0
> >     3  LGTY       0     0     1     0   1
> >     4  RS           0     0      0    1    0
> >     5  TY           0     0      1    0    0
>
> grepl() will give you a logical match
>
> data.frame(mydf, sapply(code, function(x)grepl(x, mydf$code)),
> stringsAsFactors=FALSE, check.names=FALSE)
>
> Sarah
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mbressan at arpa.veneto.it  Thu Apr  9 21:58:32 2015
From: mbressan at arpa.veneto.it (maxbre)
Date: Thu, 9 Apr 2015 12:58:32 -0700 (PDT)
Subject: [R] recursively rename dir and files
Message-ID: <1428609512106-4705667.post@n4.nabble.com>

this is my reproducible example

setwd(".")
dir.create("./my dir with space")
dir.create("./my dir with space/my sub dir with space")
file.create("./my dir with space/my dir file with space.txt")
file.create("./my dir with space/my sub dir with space/my sub dir file with
space.txt")

now I need to rename recursively all dirs and files in order to get rid of
spaces

the following attempt is not getting to the point...

mylist<-dir(".", full.names=TRUE, recursive=TRUE, include.dirs=TRUE)

for (i in mylist){
  file.rename(i, gsub(" ", "_", i))
}

#or more simply...
file.rename(mydirs, gsub(" ", "_", mydirs))

...because (clearly) I got some warning messages like "can not rename file
.... because it is not existing";
and I definitely understand that because in the process of renaming of the
the upper level directory the full path of the nested directories and files
is changed and any longer visible to the procedure...

the problem now is that I'm not enough clear how to proceed with an
alternative strategy in order to properly sort out the problem...

for reasons I'm not mentioning here I must stick with a solution in R
language

any hint much appreciated

thanks






--
View this message in context: http://r.789695.n4.nabble.com/recursively-rename-dir-and-files-tp4705667.html
Sent from the R help mailing list archive at Nabble.com.


From jpasa at innovativejournal.org  Thu Apr  9 21:00:36 2015
From: jpasa at innovativejournal.org (jpasa)
Date: Thu, 9 Apr 2015 14:00:36 -0500
Subject: [R] Journal of Pure Algebra & Statistical Analysis (Call for Paper
	Publication)
Message-ID: <00f5deb3b4b4d8316f859f75ea59551c@innovativejournal.org>

** Journal of Pure Algebra & Statistical Analysis </jpasa>
**
Accepting submissions; please use the online submission system to
submit your manuscript
.

Call for Paper

DOI prefix: 10.15520

CrossRef Membership

**All the papers are Check by ithenticate / writecheck for
Plagiarism**

Submission Deadline: April 20 2015,

Publication Charges: 100 USD for NRI | 30 USD for Indian

Dear All, 

JPASA (Journal of Pure Algebra & Statistical Analysis) is an
international peer reviewed online journal which makes sincere efforts
in bringing original and quality publication. JPASA is an official
publication of Innovative Journal

Our endeavor is to revolutionize the publication process by adopting
fast track publication concept with the help of our dedicated
reviewers and editors. Our journal takes utmost care of your valuable
work by publishing it in secured format.

JPASA welcome the submission of manuscripts [Mathematics, Pure Algebra
& Statistical Analysis] that meet the criteria of scientific
excellence. Our editors will evaluate the submitted manuscripts prior
to its publication in order to maintain and improve the quality of
research work.

Manuscript can be submitted at Online Submission
or through email given below.

jpasa at innovativejournal.in <mailto:jpasa at innovativejournal.in>
and jpasa at innovativejournal.org

Join Our Editorial Board 

With Greetings,

Editor in chief

Dr S Gandhi,

33, thamesvale close, Lampton road, Hounslow,

Middlesex, TW3 4D E, United Kingdom

Website: JPASA | Innovative Journal
<http://innovativejournal.org/jpasa/lt.php?id=YBgBGVcNGQ1TVAk>



--

 This message was sent to r-help at lists.r-project.org by
jpasa at innovativejournal.org

 To forward this message, please do not use the forward button of your
email application, because this message was made specifically for you
only. Instead use the forward page
<http://innovativejournal.org/jpasa/lt.php?id=YBgPGVcNGQ1TVAk>
in our newsletter system.

 To change your details and to choose which lists to be subscribed to,
visit your personal preferences page
<http://innovativejournal.org/jpasa/lt.php?id=YBgFGVcNGQ1TVAk>

 Or you can opt-out completely
<http://innovativejournal.org/jpasa/lt.php?id=YBgCGVcNGQ1TVAk>
from all future mailings.

 


-- powered by phpList, www.phplist.com --



From jpasa at innovativejournal.org  Thu Apr  9 21:54:06 2015
From: jpasa at innovativejournal.org (jpasa)
Date: Thu, 9 Apr 2015 14:54:06 -0500
Subject: [R] Journal of Pure Algebra & Statistical Analysis (Call for Paper
	Publication)
Message-ID: <3aa25dcdf9790094702a2e6497c14133@innovativejournal.org>

** Journal of Pure Algebra & Statistical Analysis </jpasa>
**
Accepting submissions; please use the online submission system to
submit your manuscript
..

Call for Paper

DOI prefix: 10.15520

CrossRef Membership

**All the papers are Check by ithenticate / writecheck for
Plagiarism**

Submission Deadline: April 20 2015,

Publication Charges: 100 USD for NRI | 30 USD for Indian

Dear All, 

JPASA (Journal of Pure Algebra & Statistical Analysis) is an
international peer reviewed online journal which makes sincere efforts
in bringing original and quality publication. JPASA is an official
publication of Innovative Journal

Our endeavor is to revolutionize the publication process by adopting
fast track publication concept with the help of our dedicated
reviewers and editors. Our journal takes utmost care of your valuable
work by publishing it in secured format.

JPASA welcome the submission of manuscripts [Mathematics, Pure Algebra
& Statistical Analysis] that meet the criteria of scientific
excellence. Our editors will evaluate the submitted manuscripts prior
to its publication in order to maintain and improve the quality of
research work.

Manuscript can be submitted at Online Submission
or through email given below.

jpasa at innovativejournal.in <mailto:jpasa at innovativejournal.in>
and jpasa at innovativejournal.org

Join Our Editorial Board 

With Greetings,

Editor in chief

Dr S Gandhi,

33, thamesvale close, Lampton road, Hounslow,

Middlesex, TW3 4D E, United Kingdom

Website: JPASA | Innovative Journal
<http://innovativejournal.org/jpasa/lt.php?id=YBgBGVcNGQ1WUQ8>



--

 This message was sent to r-help at r-project.org by
jpasa at innovativejournal.org

 To forward this message, please do not use the forward button of your
email application, because this message was made specifically for you
only. Instead use the forward page
<http://innovativejournal.org/jpasa/lt.php?id=YBgPGVcNGQ1WUQ8>
in our newsletter system.

 To change your details and to choose which lists to be subscribed to,
visit your personal preferences page
<http://innovativejournal.org/jpasa/lt.php?id=YBgFGVcNGQ1WUQ8>

 Or you can opt-out completely
<http://innovativejournal.org/jpasa/lt.php?id=YBgCGVcNGQ1WUQ8>
from all future mailings.

 


-- powered by phpList, www.phplist.com --



From frainj at gmail.com  Thu Apr  9 23:16:56 2015
From: frainj at gmail.com (John C Frain)
Date: Thu, 9 Apr 2015 22:16:56 +0100
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
Message-ID: <CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>

My understanding is that the packages installed with the windows installer
were only updated by installing a new version of R or the  patched install
file for the current version. If this is the case you you do not need to be
concerned about updates to these packages. Perhaps some one wiser that I
can confirm if my assumption is right or wrong.

John

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 9 April 2015 at 14:42, Elliot Joel Bernstein <ejb6 at cornell.edu> wrote:

> I am trying to install R for Windows, but when I use the installer provided
> on CRAN, a number of third-party packages are installed by default (i.e.
> lattice, Matrix, codetools, etc.). If R is installed with administrator
> privileges, so it's available for all users, non-administrators can't
> update those packages. Is there any way to just install R without any
> third-party packages, and let individual users install the packages they
> want?
>
> Thanks.
>
> - Elliot
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Thu Apr  9 23:26:46 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 09 Apr 2015 23:26:46 +0200
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
	<CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>
Message-ID: <5526EE96.4080402@statistik.tu-dortmund.de>



On 09.04.2015 23:16, John C Frain wrote:
> My understanding is that the packages installed with the windows installer
> were only updated by installing a new version of R or the  patched install
> file for the current version. If this is the case you you do not need to be
> concerned about updates to these packages. Perhaps some one wiser that I
> can confirm if my assumption is right or wrong.


No, updates of such recommended packages may be available between R 
releases. But individual users can install new versions using 
install.packages() into their private libraries, e.g. those that are 
first on the search path (given by .libPaths()) so that they are loaded 
first.

Best,
Uwe Ligges





> John
>
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
> On 9 April 2015 at 14:42, Elliot Joel Bernstein <ejb6 at cornell.edu> wrote:
>
>> I am trying to install R for Windows, but when I use the installer provided
>> on CRAN, a number of third-party packages are installed by default (i.e.
>> lattice, Matrix, codetools, etc.). If R is installed with administrator
>> privileges, so it's available for all users, non-administrators can't
>> update those packages. Is there any way to just install R without any
>> third-party packages, and let individual users install the packages they
>> want?
>>
>> Thanks.
>>
>> - Elliot
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Thu Apr  9 23:53:29 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 9 Apr 2015 23:53:29 +0200
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <5526EE96.4080402@statistik.tu-dortmund.de>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
	<CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>
	<5526EE96.4080402@statistik.tu-dortmund.de>
Message-ID: <AF168557-52A1-438C-8413-DEF246ED4F2B@gmail.com>


> On 09 Apr 2015, at 23:26 , Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
> 
> 
> On 09.04.2015 23:16, John C Frain wrote:
>> My understanding is that the packages installed with the windows installer
>> were only updated by installing a new version of R or the  patched install
>> file for the current version. If this is the case you you do not need to be
>> concerned about updates to these packages. Perhaps some one wiser that I
>> can confirm if my assumption is right or wrong.
> 
> 
> No, updates of such recommended packages may be available between R releases. But individual users can install new versions using install.packages() into their private libraries, e.g. those that are first on the search path (given by .libPaths()) so that they are loaded first.

However, little care is needed since the version in a private library may override the system one even after an R upgrade has updated it; i.e. an older version can end up in front of a newer one, which may cause some confusion.

> 
> Best,
> Uwe Ligges
> 
> 
> 
> 
> 
>> John
>> 
>> John C Frain
>> 3 Aranleigh Park
>> Rathfarnham
>> Dublin 14
>> Ireland
>> www.tcd.ie/Economics/staff/frainj/home.html
>> mailto:frainj at tcd.ie
>> mailto:frainj at gmail.com
>> 
>> On 9 April 2015 at 14:42, Elliot Joel Bernstein <ejb6 at cornell.edu> wrote:
>> 
>>> I am trying to install R for Windows, but when I use the installer provided
>>> on CRAN, a number of third-party packages are installed by default (i.e.
>>> lattice, Matrix, codetools, etc.). If R is installed with administrator
>>> privileges, so it's available for all users, non-administrators can't
>>> update those packages. Is there any way to just install R without any
>>> third-party packages, and let individual users install the packages they
>>> want?
>>> 
>>> Thanks.
>>> 
>>> - Elliot
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Fri Apr 10 00:25:15 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 09 Apr 2015 15:25:15 -0700
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <AF168557-52A1-438C-8413-DEF246ED4F2B@gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
	<CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>
	<5526EE96.4080402@statistik.tu-dortmund.de>
	<AF168557-52A1-438C-8413-DEF246ED4F2B@gmail.com>
Message-ID: <F8D08907-F81A-43CF-925D-EAEC8C43657E@dcn.davis.CA.us>

I would suggest that the scenario suggested by Peter is exactly as it should be... with the user fully in charge of which packages they use. A simple update can correct any version "inversion" if it occurs, and the user need not blame the sysadmin if their scripts stop working because of a system update.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 9, 2015 2:53:29 PM PDT, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 09 Apr 2015, at 23:26 , Uwe Ligges
><ligges at statistik.tu-dortmund.de> wrote:
>> 
>> 
>> 
>> On 09.04.2015 23:16, John C Frain wrote:
>>> My understanding is that the packages installed with the windows
>installer
>>> were only updated by installing a new version of R or the  patched
>install
>>> file for the current version. If this is the case you you do not
>need to be
>>> concerned about updates to these packages. Perhaps some one wiser
>that I
>>> can confirm if my assumption is right or wrong.
>> 
>> 
>> No, updates of such recommended packages may be available between R
>releases. But individual users can install new versions using
>install.packages() into their private libraries, e.g. those that are
>first on the search path (given by .libPaths()) so that they are loaded
>first.
>
>However, little care is needed since the version in a private library
>may override the system one even after an R upgrade has updated it;
>i.e. an older version can end up in front of a newer one, which may
>cause some confusion.
>
>> 
>> Best,
>> Uwe Ligges
>> 
>> 
>> 
>> 
>> 
>>> John
>>> 
>>> John C Frain
>>> 3 Aranleigh Park
>>> Rathfarnham
>>> Dublin 14
>>> Ireland
>>> www.tcd.ie/Economics/staff/frainj/home.html
>>> mailto:frainj at tcd.ie
>>> mailto:frainj at gmail.com
>>> 
>>> On 9 April 2015 at 14:42, Elliot Joel Bernstein <ejb6 at cornell.edu>
>wrote:
>>> 
>>>> I am trying to install R for Windows, but when I use the installer
>provided
>>>> on CRAN, a number of third-party packages are installed by default
>(i.e.
>>>> lattice, Matrix, codetools, etc.). If R is installed with
>administrator
>>>> privileges, so it's available for all users, non-administrators
>can't
>>>> update those packages. Is there any way to just install R without
>any
>>>> third-party packages, and let individual users install the packages
>they
>>>> want?
>>>> 
>>>> Thanks.
>>>> 
>>>> - Elliot
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Apr 10 01:44:29 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Apr 2015 09:44:29 +1000
Subject: [R] recursively rename dir and files
In-Reply-To: <1428609512106-4705667.post@n4.nabble.com>
References: <1428609512106-4705667.post@n4.nabble.com>
Message-ID: <CA+8X3fWnYmRi31x56xyo-vLqHM73=NTV0L-tw2W35aFX4shmKA@mail.gmail.com>

Hi maxbre,
Try this:

recursive_replace<-function(path=".",replace=" ",with="_") {
 filelist<-list.files(path,full.names=TRUE)
 for(filename in filelist) {
  if(length(grep(replace,filename)))
   file.rename(filename,gsub(replace,with,filename))
 }
 dirlist<-list.dirs(path,full.names=TRUE,recursive=FALSE)
 if(length(dirlist)) {
  for(dirname in dirlist)
   recursive_replace(dirname,replace=replace,with=with)
 }
}

Jim


On Fri, Apr 10, 2015 at 5:58 AM, maxbre <mbressan at arpa.veneto.it> wrote:

> this is my reproducible example
>
> setwd(".")
> dir.create("./my dir with space")
> dir.create("./my dir with space/my sub dir with space")
> file.create("./my dir with space/my dir file with space.txt")
> file.create("./my dir with space/my sub dir with space/my sub dir file with
> space.txt")
>
> now I need to rename recursively all dirs and files in order to get rid of
> spaces
>
> the following attempt is not getting to the point...
>
> mylist<-dir(".", full.names=TRUE, recursive=TRUE, include.dirs=TRUE)
>
> for (i in mylist){
>   file.rename(i, gsub(" ", "_", i))
> }
>
> #or more simply...
> file.rename(mydirs, gsub(" ", "_", mydirs))
>
> ...because (clearly) I got some warning messages like "can not rename file
> .... because it is not existing";
> and I definitely understand that because in the process of renaming of the
> the upper level directory the full path of the nested directories and files
> is changed and any longer visible to the procedure...
>
> the problem now is that I'm not enough clear how to proceed with an
> alternative strategy in order to properly sort out the problem...
>
> for reasons I'm not mentioning here I must stick with a solution in R
> language
>
> any hint much appreciated
>
> thanks
>
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/recursively-rename-dir-and-files-tp4705667.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Apr 10 09:12:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 10 Apr 2015 09:12:28 +0200
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
Message-ID: <CAJuCY5xcjGbvYsGhMwvK5jMrYC7rds2SnZ_TGyf76Q-j55zzEw@mail.gmail.com>

Dear Eliot,

Users cannot update those packages because they don't have the correct
privileges to the library directory inside the R installation. If the
administrator gives enough priviliges to the users so that they can modify
all within the library directory, then the users should be able to update
those packages.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-09 15:42 GMT+02:00 Elliot Joel Bernstein <ejb6 at cornell.edu>:

> I am trying to install R for Windows, but when I use the installer provided
> on CRAN, a number of third-party packages are installed by default (i.e.
> lattice, Matrix, codetools, etc.). If R is installed with administrator
> privileges, so it's available for all users, non-administrators can't
> update those packages. Is there any way to just install R without any
> third-party packages, and let individual users install the packages they
> want?
>
> Thanks.
>
> - Elliot
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Fri Apr 10 09:34:00 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 10 Apr 2015 07:34:00 +0000
Subject: [R] HELP SURVIVAL ANALYSIS
Message-ID: <7B64C8E017B948419F014C915AA6D7342A052083@mail-mbx-03.UNINE.CH>

Dear members,



Does anyone of you know a book about SURVIVAL ANALYSIS in R? for very begginers?



Thank you for the information,



Xavier



PD. all I've found so far are complicated...


From xavier.chiriboga at unine.ch  Fri Apr 10 10:36:03 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 10 Apr 2015 08:36:03 +0000
Subject: [R] SURVIVAL A
Message-ID: <7B64C8E017B948419F014C915AA6D7342A05209B@mail-mbx-03.UNINE.CH>

Dear members: I am trying to run a survival analysis with "survreg". Apparently it worked, but when I aim to fin diff?rences between groups of the mdoel I got an erro message: Please see below.

I do not know What does it mean?



Thanks,



Xavier







model1<-survreg(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
> model2<-survreg(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
> anova(model1,model2)
                   Terms Resid. Df    -2*LL Test Df Deviance Pr(>Chi)
1 data$Soil * data$Caryo       248 2072.528      NA       NA       NA
2 data$Soil * data$Caryo       248 2072.528    =  0        0       NA
> summary(model1)

Call:
survreg(formula = Surv(data$Hours, data$State) ~ data$Soil *
    data$Caryo, data = data)
                                  Value Std. Error      z         p
(Intercept)                      4.3605     0.0417 104.51  0.00e+00
data$SoilCL                     -0.0784     0.0590  -1.33  1.84e-01
data$SoilCS                     -0.3865     0.0567  -6.81  9.59e-12
data$SoilSAND                   -0.1913     0.0579  -3.30  9.61e-04
data$Caryonocaryo               -0.1600     0.0579  -2.76  5.74e-03
data$SoilCL:data$Caryonocaryo    0.1320     0.0823   1.60  1.09e-01
data$SoilCS:data$Caryonocaryo    0.2679     0.0812   3.30  9.64e-04
data$SoilSAND:data$Caryonocaryo  0.0821     0.0809   1.01  3.10e-01
Log(scale)                      -1.4788     0.0442 -33.46 1.73e-245

Scale= 0.228

Weibull distribution
Loglik(model)= -1036.3   Loglik(intercept only)= -1065
        Chisq= 57.41 on 7 degrees of freedom, p= 5e-10
Number of Newton-Raphson Iterations: 5
n= 257

> diference1<-survdiff(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
Error in `[.data.frame`(m, ll) : undefined columns selected


From pdalgd at gmail.com  Fri Apr 10 11:06:33 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 10 Apr 2015 11:06:33 +0200
Subject: [R] Windows Installation Without Third-Party Packages
In-Reply-To: <AF168557-52A1-438C-8413-DEF246ED4F2B@gmail.com>
References: <CAP+O1p6wu1UJyxuaMFnWBR0jZq7qb_v2NnbFkv1yHu=bTvAVqQ@mail.gmail.com>
	<CAHrK514FzA42gje3bAWC2Nk7=D1FasAoEFMJv=8QQ4S=7rHdzw@mail.gmail.com>
	<5526EE96.4080402@statistik.tu-dortmund.de>
	<AF168557-52A1-438C-8413-DEF246ED4F2B@gmail.com>
Message-ID: <F41C0AE0-F23D-463A-A2B3-CCB7B55712D3@gmail.com>


On 09 Apr 2015, at 23:53 , peter dalgaard <pdalgd at gmail.com> wrote:

> However, little care is needed

Aaaargh. 

 _a_ little care is needed.

(The other thing means that you almost do not need to care.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From phaedrusv at gmail.com  Fri Apr 10 12:19:51 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 10 Apr 2015 11:19:51 +0100
Subject: [R] Removing words and initials with tm
Message-ID: <5527A3C7.7040700@gmail.com>

Hi list

Using the tm package, part of the pre-processing work is to remove 
words, etc. from the corpus.

I wish to remove people's names and also their initials which are 
peppered throughout the corpus. But, because some people's initials are 
the same as parts of common words - e.g. 'am' = 'became' => 'bec e' or 
'ec' = 'because' => 'b ause' or 'ar' = 'arrival' => 'rival' (which has a 
completely different meaning).

Is there any way of doing this without leaving a trail of nonsense 
half-terms behind? I suspect that it might have something to do with 
regular expressions, but to be honest, I'm (currently) pretty crap with 
those.

Would it make a difference if I removed initials and names *prior* to 
converting all text to lower case, so I remove 'AM' and because 'became' 
is lower case, it should remain unaffected?

Any recommendations on how best to proceed with this?

Thanks as always.
Sun


From drjimlemon at gmail.com  Fri Apr 10 12:38:21 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Apr 2015 20:38:21 +1000
Subject: [R] Removing words and initials with tm
In-Reply-To: <5527A3C7.7040700@gmail.com>
References: <5527A3C7.7040700@gmail.com>
Message-ID: <CA+8X3fU4Pn1Vrp567iPe2oksenqOyHXfF8wR=PDjdGwoZ53nKQ@mail.gmail.com>

Hi Sun,
In fact, case sensitivity is the default in functions like "sub". The
problem may then become separating initials from acronyms if they are
present in the corpus:

gsub("NM","","An NMR was performed on NM Jones")
[1] "An R was performed on  Jones"

How you are going to deal with names like York may also be tricky:

gsub("York","","Reginald York took a holiday in New York.")
[1] "Reginald  took a holiday in New ."

Jim


On Fri, Apr 10, 2015 at 8:19 PM, Sun Shine <phaedrusv at gmail.com> wrote:

> Hi list
>
> Using the tm package, part of the pre-processing work is to remove words,
> etc. from the corpus.
>
> I wish to remove people's names and also their initials which are peppered
> throughout the corpus. But, because some people's initials are the same as
> parts of common words - e.g. 'am' = 'became' => 'bec e' or 'ec' = 'because'
> => 'b ause' or 'ar' = 'arrival' => 'rival' (which has a completely
> different meaning).
>
> Is there any way of doing this without leaving a trail of nonsense
> half-terms behind? I suspect that it might have something to do with
> regular expressions, but to be honest, I'm (currently) pretty crap with
> those.
>
> Would it make a difference if I removed initials and names *prior* to
> converting all text to lower case, so I remove 'AM' and because 'became' is
> lower case, it should remain unaffected?
>
> Any recommendations on how best to proceed with this?
>
> Thanks as always.
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Fri Apr 10 13:17:35 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 10 Apr 2015 12:17:35 +0100
Subject: [R] Removing words and initials with tm
In-Reply-To: <CA+8X3fU4Pn1Vrp567iPe2oksenqOyHXfF8wR=PDjdGwoZ53nKQ@mail.gmail.com>
References: <5527A3C7.7040700@gmail.com>
	<CA+8X3fU4Pn1Vrp567iPe2oksenqOyHXfF8wR=PDjdGwoZ53nKQ@mail.gmail.com>
Message-ID: <5527B14F.3080602@gmail.com>

Hey Jim

So far I've re-run the process and sub'bed initials and proper names 
with blank space, and changed other names (including acronyms) to 
something less tricky (your e.g. #1 NMR is therefore "NucMagRes", etc.) 
*before* I converted to lower case. By and large, that seems to cut it, 
at least for my present purposes.

I don't have a workaround for your e.g. #2 though!

One really has to have a relatively decent handle on the scope of the 
variations and text content first. I'm not sure how one would do this 
kind of thing effectively on a large and unseen corpus.

Anyway, thanks for your reply and thoughts.

Sun

On 10/04/15 11:38, Jim Lemon wrote:
> Hi Sun,
> In fact, case sensitivity is the default in functions like "sub". The 
> problem may then become separating initials from acronyms if they are 
> present in the corpus:
>
> gsub("NM","","An NMR was performed on NM Jones")
> [1] "An R was performed on  Jones"
>
> How you are going to deal with names like York may also be tricky:
>
> gsub("York","","Reginald York took a holiday in New York.")
> [1] "Reginald  took a holiday in New ."
>
> Jim
>
>
> On Fri, Apr 10, 2015 at 8:19 PM, Sun Shine <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Hi list
>
>     Using the tm package, part of the pre-processing work is to remove
>     words, etc. from the corpus.
>
>     I wish to remove people's names and also their initials which are
>     peppered throughout the corpus. But, because some people's
>     initials are the same as parts of common words - e.g. 'am' =
>     'became' => 'bec e' or 'ec' = 'because' => 'b ause' or 'ar' =
>     'arrival' => 'rival' (which has a completely different meaning).
>
>     Is there any way of doing this without leaving a trail of nonsense
>     half-terms behind? I suspect that it might have something to do
>     with regular expressions, but to be honest, I'm (currently) pretty
>     crap with those.
>
>     Would it make a difference if I removed initials and names *prior*
>     to converting all text to lower case, so I remove 'AM' and because
>     'became' is lower case, it should remain unaffected?
>
>     Any recommendations on how best to proceed with this?
>
>     Thanks as always.
>     Sun
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr 10 13:30:55 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Apr 2015 21:30:55 +1000
Subject: [R] Removing words and initials with tm
In-Reply-To: <5527B14F.3080602@gmail.com>
References: <5527A3C7.7040700@gmail.com>
	<CA+8X3fU4Pn1Vrp567iPe2oksenqOyHXfF8wR=PDjdGwoZ53nKQ@mail.gmail.com>
	<5527B14F.3080602@gmail.com>
Message-ID: <CA+8X3fU_dCsVMfed8NW-e+sUVDgdqC_-j0zJg=KV7ybrt5S5Jg@mail.gmail.com>

Hi Sun,
Good thinking. Looking at your reply, I realized that you may be able to
run a spell checker over the output to pick up mangled words.

Jim


On Fri, Apr 10, 2015 at 9:17 PM, Sun Shine <phaedrusv at gmail.com> wrote:

>  Hey Jim
>
> So far I've re-run the process and sub'bed initials and proper names with
> blank space, and changed other names (including acronyms) to something less
> tricky (your e.g. #1 NMR is therefore "NucMagRes", etc.) *before* I
> converted to lower case. By and large, that seems to cut it, at least for
> my present purposes.
>
> I don't have a workaround for your e.g. #2 though!
>
> One really has to have a relatively decent handle on the scope of the
> variations and text content first. I'm not sure how one would do this kind
> of thing effectively on a large and unseen corpus.
>
> Anyway, thanks for your reply and thoughts.
>
> Sun
>
>
> On 10/04/15 11:38, Jim Lemon wrote:
>
> Hi Sun,
> In fact, case sensitivity is the default in functions like "sub". The
> problem may then become separating initials from acronyms if they are
> present in the corpus:
>
>  gsub("NM","","An NMR was performed on NM Jones")
> [1] "An R was performed on  Jones"
>
>  How you are going to deal with names like York may also be tricky:
>
>  gsub("York","","Reginald York took a holiday in New York.")
> [1] "Reginald  took a holiday in New ."
>
>  Jim
>
>
> On Fri, Apr 10, 2015 at 8:19 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>
>> Hi list
>>
>> Using the tm package, part of the pre-processing work is to remove words,
>> etc. from the corpus.
>>
>> I wish to remove people's names and also their initials which are
>> peppered throughout the corpus. But, because some people's initials are the
>> same as parts of common words - e.g. 'am' = 'became' => 'bec e' or 'ec' =
>> 'because' => 'b ause' or 'ar' = 'arrival' => 'rival' (which has a
>> completely different meaning).
>>
>> Is there any way of doing this without leaving a trail of nonsense
>> half-terms behind? I suspect that it might have something to do with
>> regular expressions, but to be honest, I'm (currently) pretty crap with
>> those.
>>
>> Would it make a difference if I removed initials and names *prior* to
>> converting all text to lower case, so I remove 'AM' and because 'became' is
>> lower case, it should remain unaffected?
>>
>> Any recommendations on how best to proceed with this?
>>
>> Thanks as always.
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From a.strelniece at eurotransplant.org  Fri Apr 10 11:42:45 2015
From: a.strelniece at eurotransplant.org (Agita Strelniece)
Date: Fri, 10 Apr 2015 11:42:45 +0200
Subject: [R] SURVIVAL A
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A05209B@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A05209B@mail-mbx-03.UNINE.CH>
Message-ID: <5527B7350200007200052746@mail5.local.eurotransplant.nl>

Only one model has here been defined. 
Please find some basic instructions on
http://www.personality-project.org/r/r.anova.html
 
Hope this helps!
Agita
 

>>> CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> 10-4-2015 10:36 >>>
Dear members: I am trying to run a survival analysis with "survreg".
Apparently it worked, but when I aim to fin diff?rences between groups
of the mdoel I got an erro message: Please see below.

I do not know What does it mean?



Thanks,



Xavier




model1<-survreg(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
>
model2<-survreg(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
> anova(model1,model2)
				   Terms Resid. Df    -2*LL Test Df
Deviance Pr(>Chi)
1 data$Soil * data$Caryo	   248 2072.528      NA 	  NA    
  NA
2 data$Soil * data$Caryo	   248 2072.528    =  0  	  0     
 NA
> summary(model1)

Call:
survreg(formula = Surv(data$Hours, data$State) ~ data$Soil *
    data$Caryo, data = data)
								  Value
Std. Error      z  	   p
(Intercept)					  4.3605     0.0417
104.51  0.00e+00
data$SoilCL					 -0.0784	 0.0590 
-1.33  1.84e-01
data$SoilCS					 -0.3865	 0.0567 
-6.81  9.59e-12
data$SoilSAND				   -0.1913     0.0579  -3.30 
9.61e-04
data$Caryonocaryo			   -0.1600     0.0579  -2.76 
5.74e-03
data$SoilCL:data$Caryonocaryo    0.1320     0.0823   1.60  1.09e-01
data$SoilCS:data$Caryonocaryo    0.2679     0.0812   3.30  9.64e-04
data$SoilSAND:data$Caryonocaryo  0.0821     0.0809   1.01  3.10e-01
Log(scale)					  -1.4788     0.0442
-33.46 1.73e-245

Scale= 0.228

Weibull distribution
Loglik(model)= -1036.3   Loglik(intercept only)= -1065
	    Chisq= 57.41 on 7 degrees of freedom, p= 5e-10
Number of Newton-Raphson Iterations: 5
n= 257

>
diference1<-survdiff(Surv(data$Hours,data$State)~data$Soil*data$Caryo,data=data)
Error in `[.data.frame`(m, ll) : undefined columns selected

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



De inhoud van dit bericht is uitsluitend bestemd voor de geadresseerde
en kan vertrouwelijke en/of persoonlijke informatie bevatten. Als dit
bericht niet voor u bestemd is, wordt u vriendelijk verzocht dit aan de
afzender te melden en het bericht (inclusief bijlagen) uit uw systeem te
verwijderen. Eurotransplant staat door de elektronische verzending van
dit bericht niet in voor de juiste en volledige overbrenging van de
inhoud, noch voor tijdige ontvangst daarvan. 
Voor informatie over Eurotransplant raadpleegt u:
www.eurotransplant.org. 

 

This message is intended for the addressee's eyes only and it may
contain confidential and/or personal information.
If you are not the intended recipient, you are hereby kindly requested
to notify the sender and delete this message (including attachments)
from your system immediately. In view of the electronic nature of this
communication, Eurotransplant is neither liable for the proper and
complete transmission of the information contained therein nor for any
delay in its receipt. For information on Eurotransplant please visit:
www.eurotransplant.org



From dqlpromise at gmail.com  Fri Apr 10 08:54:29 2015
From: dqlpromise at gmail.com (Qin Liu)
Date: Thu, 9 Apr 2015 23:54:29 -0700
Subject: [R] Please add me to r-help mailing list
Message-ID: <CAEtdP4iQNQ3_aKzZxc87O8zUh_8yoF4daSqPafG0ooZNzjuSiw@mail.gmail.com>

Hi there,
As described in the subject, can you add me to the mailing list?
Thanks a lot
Have a good night

Qin

	[[alternative HTML version deleted]]


From lutipilotto at yahoo.com.br  Fri Apr 10 12:15:43 2015
From: lutipilotto at yahoo.com.br (Luciane Maria Pilotto)
Date: Fri, 10 Apr 2015 03:15:43 -0700
Subject: [R] ordinal logistic regression with svyolr
Message-ID: <1428660943.11807.YahooMailBasic@web120204.mail.ne1.yahoo.com>

Hello,

I found in R-Help a question about how to test the assumption of proportional odds or parallel lines or slopes ordinal logistic regression with svyolr, but I did not see the answer. Will someone help?

Thanks, 

Luciane


From aurora.gonzalez2 at um.es  Fri Apr 10 13:22:24 2015
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Fri, 10 Apr 2015 13:22:24 +0200
Subject: [R] rmarkdown linux mint 17
Message-ID: <20150410132224.Horde.ZxsT5cwDvhHXKeKy7gpEpA4@webmail.um.es>

Hello.
I am trying to intstall the R package "rmarkdown" in my linux mint 17
quiana computer but I'm having strange problems:
install.packages("rmarkdown") returns errors when installing the
dependencies such as mime, digest, bitops, yaml, knitr...etc. And
installing one by one it happens the same.

The errors are:
* installing *source* package ?mime? ...
** package ?mime? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG????? -fpic? -O3
-pipe? -g? -c rawmatch.c -o rawmatch.o
In file included from rawmatch.c:1:0:
/usr/share/R/include/R.h:28:20: fatal error: stdlib.h: No existe el archivo
o el directorio
?#include <stdlib.h>
??????????????????? ^
compilation terminated.
make: *** [rawmatch.o] Error 1
ERROR: compilation failed for package ?mime?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/mime?
Warning in install.packages :
? installation of package ?mime? had non-zero exit status
* installing *source* package ?digest? ...
** package ?digest? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG????? -fpic? -O3
-pipe? -g? -c aes.c -o aes.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG????? -fpic? -O3
-pipe? -g? -c crc32.c -o crc32.o
In file included from crc32.c:23:0:
zutil.h:21:22: fatal error: string.h: No existe el archivo o el directorio
?#? include <string.h>
????????????????????? ^
compilation terminated.
make: *** [crc32.o] Error 1
ERROR: compilation failed for package ?digest?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/digest?
Warning in install.packages :
? installation of package ?digest? had non-zero exit status
* installing *source* package ?bitops? ...
** package ?bitops? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG????? -fpic? -O3
-pipe? -g? -c bit-ops.c -o bit-ops.o
In file included from bit-ops.c:1:0:
/usr/share/R/include/R.h:28:20: fatal error: stdlib.h: No existe el archivo
o el directorio
?#include <stdlib.h>
??????????????????? ^
compilation terminated.
make: *** [bit-ops.o] Error 1
ERROR: compilation failed for package ?bitops?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/bitops?
Warning in install.packages :
? installation of package ?bitops? had non-zero exit status
* installing *source* package ?yaml? ...
** package ?yaml? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG???? -fpic?
-O3 -pipe? -g? -c api.c -o api.o
In file included from yaml_private.h:6:0,
???????????????? from api.c:2:
yaml.h:18:20: fatal error: stdlib.h: No existe el archivo o el directorio
?#include <stdlib.h>
??????????????????? ^
compilation terminated.
make: *** [api.o] Error 1
ERROR: compilation failed for package ?yaml?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/yaml?
Warning in install.packages :
? installation of package ?yaml? had non-zero exit status
ERROR: dependency ?mime? is not available for package ?markdown?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/markdown?
Warning in install.packages :
? installation of package ?markdown? had non-zero exit status
ERROR: dependency ?digest? is not available for package ?htmltools?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/htmltools?
Warning in install.packages :
? installation of package ?htmltools? had non-zero exit status
ERROR: dependency ?bitops? is not available for package ?caTools?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/caTools?
Warning in install.packages :
? installation of package ?caTools? had non-zero exit status
ERROR: dependencies ?digest?, ?markdown? are not available for
package ?knitr?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/knitr?
Warning in install.packages :
? installation of package ?knitr? had non-zero exit status
ERROR: dependencies ?knitr?, ?yaml?, ?htmltools?, ?caTools?
are not available for package ?rmarkdown?
* removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/rmarkdown?
Warning in install.packages :
? installation of package ?rmarkdown? had non-zero exit status

This is my sessionInfo() in case that it could help:
R version 3.0.2 (2013-09-25)
Platform: i686-pc-linux-gnu (32-bit)

locale:
?[1] LC_CTYPE=es_ES.UTF-8?????? LC_NUMERIC=C????????????
?
?[3] LC_TIME=es_ES.UTF-8??????? LC_COLLATE=es_ES.UTF-8?? ?
?[5] LC_MONETARY=es_ES.UTF-8??? LC_MESSAGES=es_ES.UTF-8? ?
?[7] LC_PAPER=es_ES.UTF-8??????
LC_NAME=C??????????????? ?
?[9] LC_ADDRESS=C??????????????
LC_TELEPHONE=C?????????? ?
[11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C????? ?

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods??
base??? ?

loaded via a namespace (and not attached):
[1] tools_3.0.2

Thank you very much for any advice.


------
Aurora Gonz?lez Vidal

Secci?n Apoyo Estad?stico.
Servicio de Apoyo a la Investigaci?n (SAI).
Vicerrectorado de Investigaci?n.
Universidad de Murcia
Edif. SACE . Campus de Espinardo.
30100 Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7315
F. 868 88 7302
www.um.es/sai
www.um.es/ae

	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Fri Apr 10 13:37:48 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 10 Apr 2015 12:37:48 +0100
Subject: [R] Removing words and initials with tm
In-Reply-To: <CA+8X3fU_dCsVMfed8NW-e+sUVDgdqC_-j0zJg=KV7ybrt5S5Jg@mail.gmail.com>
References: <5527A3C7.7040700@gmail.com>	<CA+8X3fU4Pn1Vrp567iPe2oksenqOyHXfF8wR=PDjdGwoZ53nKQ@mail.gmail.com>	<5527B14F.3080602@gmail.com>
	<CA+8X3fU_dCsVMfed8NW-e+sUVDgdqC_-j0zJg=KV7ybrt5S5Jg@mail.gmail.com>
Message-ID: <5527B60C.7030803@gmail.com>

Thanks Jim

Can you say more about a R spell checker, or were you thinking of 
opening the parsed documents in a word processor, e.g. LibreOffice?

After stemming the documents, most of the words are mangled, e.g. 
'people' becomes 'peopl' so I think the spell checker would go crazy! I 
think a lot of this comes down to which sequence one runs the different 
transformations in.

Cheers
Sun

On 10/04/15 12:30, Jim Lemon wrote:
> Hi Sun,
> Good thinking. Looking at your reply, I realized that you may be able 
> to run a spell checker over the output to pick up mangled words.
>
> Jim
>
>
> On Fri, Apr 10, 2015 at 9:17 PM, Sun Shine <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Hey Jim
>
>     So far I've re-run the process and sub'bed initials and proper
>     names with blank space, and changed other names (including
>     acronyms) to something less tricky (your e.g. #1 NMR is therefore
>     "NucMagRes", etc.) *before* I converted to lower case. By and
>     large, that seems to cut it, at least for my present purposes.
>
>     I don't have a workaround for your e.g. #2 though!
>
>     One really has to have a relatively decent handle on the scope of
>     the variations and text content first. I'm not sure how one would
>     do this kind of thing effectively on a large and unseen corpus.
>
>     Anyway, thanks for your reply and thoughts.
>
>     Sun
>
>
>     On 10/04/15 11:38, Jim Lemon wrote:
>>     Hi Sun,
>>     In fact, case sensitivity is the default in functions like "sub".
>>     The problem may then become separating initials from acronyms if
>>     they are present in the corpus:
>>
>>     gsub("NM","","An NMR was performed on NM Jones")
>>     [1] "An R was performed on  Jones"
>>
>>     How you are going to deal with names like York may also be tricky:
>>
>>     gsub("York","","Reginald York took a holiday in New York.")
>>     [1] "Reginald  took a holiday in New ."
>>
>>     Jim
>>
>>
>>     On Fri, Apr 10, 2015 at 8:19 PM, Sun Shine <phaedrusv at gmail.com
>>     <mailto:phaedrusv at gmail.com>> wrote:
>>
>>         Hi list
>>
>>         Using the tm package, part of the pre-processing work is to
>>         remove words, etc. from the corpus.
>>
>>         I wish to remove people's names and also their initials which
>>         are peppered throughout the corpus. But, because some
>>         people's initials are the same as parts of common words -
>>         e.g. 'am' = 'became' => 'bec e' or 'ec' = 'because' => 'b
>>         ause' or 'ar' = 'arrival' => 'rival' (which has a completely
>>         different meaning).
>>
>>         Is there any way of doing this without leaving a trail of
>>         nonsense half-terms behind? I suspect that it might have
>>         something to do with regular expressions, but to be honest,
>>         I'm (currently) pretty crap with those.
>>
>>         Would it make a difference if I removed initials and names
>>         *prior* to converting all text to lower case, so I remove
>>         'AM' and because 'became' is lower case, it should remain
>>         unaffected?
>>
>>         Any recommendations on how best to proceed with this?
>>
>>         Thanks as always.
>>         Sun
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>
>>
>
>


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr 10 14:22:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 10 Apr 2015 14:22:14 +0200
Subject: [R] Please add me to r-help mailing list
In-Reply-To: <CAEtdP4iQNQ3_aKzZxc87O8zUh_8yoF4daSqPafG0ooZNzjuSiw@mail.gmail.com>
References: <CAEtdP4iQNQ3_aKzZxc87O8zUh_8yoF4daSqPafG0ooZNzjuSiw@mail.gmail.com>
Message-ID: <35A86A91-26DB-4FDD-9ED9-9714183125E8@gmail.com>

Follow the link in the footer (it works for subscriptions too). 

(And do check the posting guide or people will be on your back re. HTML postings.)

- Peter D.

On 10 Apr 2015, at 08:54 , Qin Liu <dqlpromise at gmail.com> wrote:

> Hi there,
> As described in the subject, can you add me to the mailing list?
> Thanks a lot
> Have a good night
> 
> Qin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From phaedrusv at gmail.com  Fri Apr 10 14:28:17 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 10 Apr 2015 13:28:17 +0100
Subject: [R] rmarkdown linux mint 17
In-Reply-To: <20150410132224.Horde.ZxsT5cwDvhHXKeKy7gpEpA4@webmail.um.es>
References: <20150410132224.Horde.ZxsT5cwDvhHXKeKy7gpEpA4@webmail.um.es>
Message-ID: <5527C1E1.4050706@gmail.com>

Hi Aurora

I wonder if the problem you are having concerns the GCC (GNU c) compiler 
rather than R itself? I know it doesn't help you, but using the exact 
same rig as yourself, rmarkdown installed successful after pulling down 
the dependencies it needs.

As sudo, check: apt-cache search gcc as it should already be installed.

If not, or just to be sure, run the following:

sudo apt-get update
sudo apt-get upgrade
sudo apt-get install build-essential
gcc -V
make -V

and then restart R and try the installation of rmarkdown again.

Hope this helps.
Sun

On 10/04/15 12:22, AURORA GONZALEZ VIDAL wrote:
> Hello.
> I am trying to intstall the R package "rmarkdown" in my linux mint 17
> quiana computer but I'm having strange problems:
> install.packages("rmarkdown") returns errors when installing the
> dependencies such as mime, digest, bitops, yaml, knitr...etc. And
> installing one by one it happens the same.
>
> The errors are:
> * installing *source* package ?mime? ...
> ** package ?mime? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3
> -pipe  -g  -c rawmatch.c -o rawmatch.o
> In file included from rawmatch.c:1:0:
> /usr/share/R/include/R.h:28:20: fatal error: stdlib.h: No existe el archivo
> o el directorio
>   #include <stdlib.h>
>                      ^
> compilation terminated.
> make: *** [rawmatch.o] Error 1
> ERROR: compilation failed for package ?mime?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/mime?
> Warning in install.packages :
>    installation of package ?mime? had non-zero exit status
> * installing *source* package ?digest? ...
> ** package ?digest? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3
> -pipe  -g  -c aes.c -o aes.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3
> -pipe  -g  -c crc32.c -o crc32.o
> In file included from crc32.c:23:0:
> zutil.h:21:22: fatal error: string.h: No existe el archivo o el directorio
>   #  include <string.h>
>                        ^
> compilation terminated.
> make: *** [crc32.o] Error 1
> ERROR: compilation failed for package ?digest?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/digest?
> Warning in install.packages :
>    installation of package ?digest? had non-zero exit status
> * installing *source* package ?bitops? ...
> ** package ?bitops? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3
> -pipe  -g  -c bit-ops.c -o bit-ops.o
> In file included from bit-ops.c:1:0:
> /usr/share/R/include/R.h:28:20: fatal error: stdlib.h: No existe el archivo
> o el directorio
>   #include <stdlib.h>
>                      ^
> compilation terminated.
> make: *** [bit-ops.o] Error 1
> ERROR: compilation failed for package ?bitops?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/bitops?
> Warning in install.packages :
>    installation of package ?bitops? had non-zero exit status
> * installing *source* package ?yaml? ...
> ** package ?yaml? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic
> -O3 -pipe  -g  -c api.c -o api.o
> In file included from yaml_private.h:6:0,
>                   from api.c:2:
> yaml.h:18:20: fatal error: stdlib.h: No existe el archivo o el directorio
>   #include <stdlib.h>
>                      ^
> compilation terminated.
> make: *** [api.o] Error 1
> ERROR: compilation failed for package ?yaml?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/yaml?
> Warning in install.packages :
>    installation of package ?yaml? had non-zero exit status
> ERROR: dependency ?mime? is not available for package ?markdown?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/markdown?
> Warning in install.packages :
>    installation of package ?markdown? had non-zero exit status
> ERROR: dependency ?digest? is not available for package ?htmltools?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/htmltools?
> Warning in install.packages :
>    installation of package ?htmltools? had non-zero exit status
> ERROR: dependency ?bitops? is not available for package ?caTools?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/caTools?
> Warning in install.packages :
>    installation of package ?caTools? had non-zero exit status
> ERROR: dependencies ?digest?, ?markdown? are not available for
> package ?knitr?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/knitr?
> Warning in install.packages :
>    installation of package ?knitr? had non-zero exit status
> ERROR: dependencies ?knitr?, ?yaml?, ?htmltools?, ?caTools?
> are not available for package ?rmarkdown?
> * removing ?/home/aurora/R/i686-pc-linux-gnu-library/3.0/rmarkdown?
> Warning in install.packages :
>    installation of package ?rmarkdown? had non-zero exit status
>
> This is my sessionInfo() in case that it could help:
> R version 3.0.2 (2013-09-25)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C
>   
>   [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=es_ES.UTF-8
>   [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=es_ES.UTF-8
>   [7] LC_PAPER=es_ES.UTF-8
> LC_NAME=C
>   [9] LC_ADDRESS=C
> LC_TELEPHONE=C
> [11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
> Thank you very much for any advice.
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Apr 10 15:32:41 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 10 Apr 2015 06:32:41 -0700
Subject: [R] Removing words and initials with tm
In-Reply-To: <5527A3C7.7040700@gmail.com>
References: <5527A3C7.7040700@gmail.com>
Message-ID: <97B581C3-DA93-455D-8451-89FA57EA0C8C@dcn.davis.CA.us>

"I suspect that it might have something to do with regular expressions, but to be honest, I'm (currently) pretty crap with those."

I cannot think of a better incentive to take action on this hole in your education and buckle down to learn regular expressions. There are many books and tutorials available.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 10, 2015 3:19:51 AM PDT, Sun Shine <phaedrusv at gmail.com> wrote:
>Hi list
>
>Using the tm package, part of the pre-processing work is to remove 
>words, etc. from the corpus.
>
>I wish to remove people's names and also their initials which are 
>peppered throughout the corpus. But, because some people's initials are
>
>the same as parts of common words - e.g. 'am' = 'became' => 'bec e' or 
>'ec' = 'because' => 'b ause' or 'ar' = 'arrival' => 'rival' (which has
>a 
>completely different meaning).
>
>Is there any way of doing this without leaving a trail of nonsense 
>half-terms behind? I suspect that it might have something to do with 
>regular expressions, but to be honest, I'm (currently) pretty crap with
>
>those.
>
>Would it make a difference if I removed initials and names *prior* to 
>converting all text to lower case, so I remove 'AM' and because
>'became' 
>is lower case, it should remain unaffected?
>
>Any recommendations on how best to proceed with this?
>
>Thanks as always.
>Sun
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From phaedrusv at gmail.com  Fri Apr 10 15:42:53 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 10 Apr 2015 14:42:53 +0100
Subject: [R] Removing words and initials with tm
In-Reply-To: <97B581C3-DA93-455D-8451-89FA57EA0C8C@dcn.davis.CA.us>
References: <5527A3C7.7040700@gmail.com>
	<97B581C3-DA93-455D-8451-89FA57EA0C8C@dcn.davis.CA.us>
Message-ID: <5527D35D.6080607@gmail.com>

Thanks Jeff.

I'll add that to the ever-growing list my current studies are generating 
daily. :-)

Cheers
S


On 10/04/15 14:32, Jeff Newmiller wrote:
> "I suspect that it might have something to do with regular expressions, but to be honest, I'm (currently) pretty crap with those."
>
> I cannot think of a better incentive to take action on this hole in your education and buckle down to learn regular expressions. There are many books and tutorials available.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 10, 2015 3:19:51 AM PDT, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hi list
>>
>> Using the tm package, part of the pre-processing work is to remove
>> words, etc. from the corpus.
>>
>> I wish to remove people's names and also their initials which are
>> peppered throughout the corpus. But, because some people's initials are
>>
>> the same as parts of common words - e.g. 'am' = 'became' => 'bec e' or
>> 'ec' = 'because' => 'b ause' or 'ar' = 'arrival' => 'rival' (which has
>> a
>> completely different meaning).
>>
>> Is there any way of doing this without leaving a trail of nonsense
>> half-terms behind? I suspect that it might have something to do with
>> regular expressions, but to be honest, I'm (currently) pretty crap with
>>
>> those.
>>
>> Would it make a difference if I removed initials and names *prior* to
>> converting all text to lower case, so I remove 'AM' and because
>> 'became'
>> is lower case, it should remain unaffected?
>>
>> Any recommendations on how best to proceed with this?
>>
>> Thanks as always.
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Fri Apr 10 15:49:59 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 10 Apr 2015 08:49:59 -0500
Subject: [R] recursively rename dir and files
In-Reply-To: <1428609512106-4705667.post@n4.nabble.com>
References: <1428609512106-4705667.post@n4.nabble.com>
Message-ID: <CAAJSdjjCHW-e1n4C+krsRvOnh4oCi63JOm911jjJ=gqdoAAGxw@mail.gmail.com>

On Thu, Apr 9, 2015 at 2:58 PM, maxbre <mbressan at arpa.veneto.it> wrote:

> this is my reproducible example
>
> setwd(".")
> dir.create("./my dir with space")
> dir.create("./my dir with space/my sub dir with space")
> file.create("./my dir with space/my dir file with space.txt")
> file.create("./my dir with space/my sub dir with space/my sub dir file with
> space.txt")
>
> now I need to rename recursively all dirs and files in order to get rid of
> spaces
>
> the following attempt is not getting to the point...
>
> mylist<-dir(".", full.names=TRUE, recursive=TRUE, include.dirs=TRUE)
>
> for (i in mylist){
>   file.rename(i, gsub(" ", "_", i))
> }
>
> #or more simply...
> file.rename(mydirs, gsub(" ", "_", mydirs))
>
> ...because (clearly) I got some warning messages like "can not rename file
> .... because it is not existing";
> and I definitely understand that because in the process of renaming of the
> the upper level directory the full path of the nested directories and files
> is changed and any longer visible to the procedure...
>
> the problem now is that I'm not enough clear how to proceed with an
> alternative strategy in order to properly sort out the problem...
>
> for reasons I'm not mentioning here I must stick with a solution in R
> language
>
> any hint much appreciated
>
> thanks
>
>
?You need to rename each file in each subdirectory. But you must first
split the file name from the directory name. You then rename the file,
keeping the directory name the same. In order for this to work, you must
first rename all files in a given directory _before_ attempting to rename
the directory. Once each file in a directory is renamed, then you can try
to rename the directory itself. I.e. you must process the files in "depth"
order. The following code does that.

filesAndDirs=dir(".", full.names=TRUE, recursive=TRUE, include.dirs=TRUE)
hasBlanks=filesAndDirs[grepl(" ",filesAndDirs)] #only things with blanks,
please
sortedBlankList=sort(hasBlanks,decreasing=TRUE)
for(file in sortedBlankList) {
    front=dirname(file)
    back=basename(file)
    newBack=gsub(" ","_",back)
    if(newBack != back) {
? #actually need to do a rename?
      newFile=file.path(front,newBack)
      file.rename(file,newFile)
    }
}?


?BTW - neat turban. Is it Sikh? Hope you don't mind my curiosity.?

-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Fri Apr 10 16:28:06 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 10 Apr 2015 07:28:06 -0700
Subject: [R] Convert numerical value into function which returns
	numerical value
In-Reply-To: <m2egnstmkj.fsf@krugs.de>
References: <m2mw2h4gst.fsf@krugs.de>
	<CAF8bMcaeR_DTqk48Erdo9wUhDwnHdAMnZTxSdQbCDD+v=crD5g@mail.gmail.com>
	<CACk-te3QYBrZZrjPARAh3VyM1G+G8--ui-VSx0hpCzFt12RrNg@mail.gmail.com>
	<m2egnstmkj.fsf@krugs.de>
Message-ID: <CACk-te3kjSbwrs-O+7p-Dd+dBOHfh=v9b2UNkc9d7omo7HSu8w@mail.gmail.com>

"Is there a good resource for these advanced programming techniques in R?"

1. I would not consider this "advanced."  I would consider "computing
on the language" techniques and manipulation of environments to be
advanced, for example.

2. But anyway, there are tons of R Programming resources. John
Chambers's books and even the venerable "S Programming" book of
Venables and Ripley might be worth checking; Hadley Wickham has
written quite a few web resources that are being developed into a book
(or have already been) -- you can probably find these by following
links from the R STudio website or checking his repositories at
Github. But there are many more both on the Web and in print, and you
would do better to search on your own to find something that suits
your learning style and needs rather than relying on my fairly
uninformed opinion (as I do not teach R and therefore have made no
effort to be current with the resources).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Apr 10, 2015 at 1:27 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Bert Gunter <gunter.berton at gene.com> writes:
>
>> 1. An important point that Bill uses but did not explicitly state is
>> that R is (essentially) a functional programming language, which means
>> among other things that functions can return functions as values.
>
> Yup - that is essential here. A function is also only an object in R,
> like characters or numeric values.
>
>>
>> 2. As a perhaps slightly amusing variant of Bill's construct that
>> illustrates this is the function below whose value is a function that
>> either returns a constant determined when it is defined or its
>> argument when called if no constant was given to it on definition:
>>
>> fconv <- function(arg=NULL){
>>   function(z)if(is.null(arg))z else arg
>> }
>
> You know, this is exactly what I want to do: I have a function, which
> takes either a numerical value or a function (from PAI) as the argument
> dep. So I have to check if the dep is a function or a value. At the
> moment, I am using is.function(), and when dep is not a function,
> convert it to a function which returns dep. If it is a function, I can
> leave it as it is. I could also replace, in your code, the is.null()
> with is.function() and do effectively the same here (some edits
> required).
>
> Very neat indeed.
>
> And a perfect way of making functions very versatile. IU really have to
> look closer into these things.
>
> Is there a good resource for these advanced programming techniques in R?
>
> Thanks,
>
> Rainer
>
>
>>> x <- 5
>>> g1 <- fconv(x) ## g1 will always return 5
>>> g1()
>> [1] 5
>>> g1(1)
>> [1] 5
>>
>>> x <- 2
>>> g1(x) ## Still uses the "x" in its defining environment
>> [1] 5
>>
>> ## But ...
>>> g2 <- fconv() ## No constant given to it in its definition
>>> g2(x)
>> [1] 2
>>> g2(1)
>> [1] 1
>>> g2()
>> Error in g2() : argument "z" is missing, with no default
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Thu, Apr 9, 2015 at 7:57 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>> You can make such functions by using the fact that a function
>>> (really, a 'closure') always has access to the environment in
>>> which the function was created.  E.g.
>>>   makeConstantFunction <- function(constant) {
>>>       force(constant) # evaluate the argument now
>>>       function(PAI) {
>>>           constant
>>>       }
>>>   }
>>>   f17 <- makeConstantFunction(17)
>>>   flog17 <- makeConstantFunction(log(17))
>>>   f17(111)
>>>   # [1] 17
>>>   flog17(111)
>>>   # [1] 2.833213
>>>
>>> If you print f17 and flog17 they will look the same, except for
>>> their environments and you have to inspect those to see why
>>> they act differently.
>>>
>>>   ls.str(environment(f17))
>>>   # constant :  num 17
>>>   ls.str(environment(flog17))
>>>   # constant :  num 2.83
>>>
>>> If you really want the functions to look different you can use
>>> substittute or bquote, but that is also a bit mysterious (you need the
>>> eval()
>>> their outputs):
>>>   g17 <- eval(substitute(function(PAI)x, list(x=17)))
>>>   h17 <- eval(bquote(function(PAI).(x), list(x=17)))
>>>   g17(10)
>>>   [1] 17
>>>   h17(10:1)
>>>   [1] 17
>>>
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Thu, Apr 9, 2015 at 5:39 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>>
>>>>
>>>> Hi
>>>>
>>>> I want convert, in a function, an argument from a numerical value to a
>>>> function which returns this value.:
>>>>
>>>> My Code:
>>>>
>>>> --8<---------------cut here---------------start------------->8---
>>>> dep <- 13
>>>> dep <- function() {dep}
>>>> dep
>>>> --8<---------------cut here---------------end--------------->8---
>>>>
>>>> This is what I get:
>>>> #+RESULTS:
>>>> ,----
>>>> | function(PAI) { dep }
>>>> `----
>>>>
>>>> This is what I want
>>>> ,----
>>>> | function(PAI) { 13 }
>>>> `----
>>>>
>>>> I thought about using eval(dep), but this gives me the effectively the
>>>> same.
>>>>
>>>> Is it possible to achieve what I want? I somehow have the feeling this
>>>> is not that easily possible, as the code in the function definition is
>>>> only evaluated when the function is evaluated.
>>>>
>>>> I could obviously do something like
>>>>
>>>> --8<---------------cut here---------------start------------->8---
>>>> dep <- 13
>>>> depVal <- dep
>>>> dep <- function() {depVal}
>>>> dep()
>>>> --8<---------------cut here---------------end--------------->8---
>>>>
>>>> But is there a better solution?
>>>>
>>>> Thanks,
>>>>
>>>> Rainer
>>>>
>>>> --
>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>>> Biology, UCT), Dipl. Phys. (Germany)
>>>>
>>>> Centre of Excellence for Invasion Biology
>>>> Stellenbosch University
>>>> South Africa
>>>>
>>>> Tel :       +33 - (0)9 53 10 27 44
>>>> Cell:       +33 - (0)6 85 62 59 98
>>>> Fax :       +33 - (0)9 58 10 27 44
>>>>
>>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>>>
>>>> email:      Rainer at krugs.de
>>>>
>>>> Skype:      RMkrug
>>>>
>>>> PGP: 0x0F52F982
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982


From h.wickham at gmail.com  Fri Apr 10 16:33:06 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 10 Apr 2015 09:33:06 -0500
Subject: [R] Convert numerical value into function which returns
	numerical value
In-Reply-To: <CACk-te3kjSbwrs-O+7p-Dd+dBOHfh=v9b2UNkc9d7omo7HSu8w@mail.gmail.com>
References: <m2mw2h4gst.fsf@krugs.de>
	<CAF8bMcaeR_DTqk48Erdo9wUhDwnHdAMnZTxSdQbCDD+v=crD5g@mail.gmail.com>
	<CACk-te3QYBrZZrjPARAh3VyM1G+G8--ui-VSx0hpCzFt12RrNg@mail.gmail.com>
	<m2egnstmkj.fsf@krugs.de>
	<CACk-te3kjSbwrs-O+7p-Dd+dBOHfh=v9b2UNkc9d7omo7HSu8w@mail.gmail.com>
Message-ID: <CABdHhvHNE9z6kAUBOGuGpnaWDt53e4b=87d42fYLxUUvnU4J6Q@mail.gmail.com>

> 2. But anyway, there are tons of R Programming resources. John
> Chambers's books and even the venerable "S Programming" book of
> Venables and Ripley might be worth checking; Hadley Wickham has
> written quite a few web resources that are being developed into a book
> (or have already been) -- you can probably find these by following
> links from the R STudio website or checking his repositories at
> Github. But there are many more both on the Web and in print, and you
> would do better to search on your own to find something that suits
> your learning style and needs rather than relying on my fairly
> uninformed opinion (as I do not teach R and therefore have made no
> effort to be current with the resources).

For this question in particular, I'd recommend starting at
http://adv-r.had.co.nz/Functional-programming.html

Hadley

-- 
http://had.co.nz/


From dnbarron at gmail.com  Fri Apr 10 17:49:56 2015
From: dnbarron at gmail.com (David Barron)
Date: Fri, 10 Apr 2015 16:49:56 +0100
Subject: [R] Convert numerical value into function which returns
	numerical value
In-Reply-To: <CACk-te3kjSbwrs-O+7p-Dd+dBOHfh=v9b2UNkc9d7omo7HSu8w@mail.gmail.com>
References: <m2mw2h4gst.fsf@krugs.de>
	<CAF8bMcaeR_DTqk48Erdo9wUhDwnHdAMnZTxSdQbCDD+v=crD5g@mail.gmail.com>
	<CACk-te3QYBrZZrjPARAh3VyM1G+G8--ui-VSx0hpCzFt12RrNg@mail.gmail.com>
	<m2egnstmkj.fsf@krugs.de>
	<CACk-te3kjSbwrs-O+7p-Dd+dBOHfh=v9b2UNkc9d7omo7HSu8w@mail.gmail.com>
Message-ID: <CAHuze_+8dNh5C0KOwpjXk1CtakY53QoPaSWP41vWWrcoAeua2A@mail.gmail.com>

I'd have a look at Hadley Wickham's online Advanced R here:
http://adv-r.had.co.nz/.  It has a section on Functional progamming
that deals with this kind of thing.

David

On 10 April 2015 at 15:28, Bert Gunter <gunter.berton at gene.com> wrote:
> "Is there a good resource for these advanced programming techniques in R?"
>
> 1. I would not consider this "advanced."  I would consider "computing
> on the language" techniques and manipulation of environments to be
> advanced, for example.
>
> 2. But anyway, there are tons of R Programming resources. John
> Chambers's books and even the venerable "S Programming" book of
> Venables and Ripley might be worth checking; Hadley Wickham has
> written quite a few web resources that are being developed into a book
> (or have already been) -- you can probably find these by following
> links from the R STudio website or checking his repositories at
> Github. But there are many more both on the Web and in print, and you
> would do better to search on your own to find something that suits
> your learning style and needs rather than relying on my fairly
> uninformed opinion (as I do not teach R and therefore have made no
> effort to be current with the resources).
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Fri, Apr 10, 2015 at 1:27 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Bert Gunter <gunter.berton at gene.com> writes:
>>
>>> 1. An important point that Bill uses but did not explicitly state is
>>> that R is (essentially) a functional programming language, which means
>>> among other things that functions can return functions as values.
>>
>> Yup - that is essential here. A function is also only an object in R,
>> like characters or numeric values.
>>
>>>
>>> 2. As a perhaps slightly amusing variant of Bill's construct that
>>> illustrates this is the function below whose value is a function that
>>> either returns a constant determined when it is defined or its
>>> argument when called if no constant was given to it on definition:
>>>
>>> fconv <- function(arg=NULL){
>>>   function(z)if(is.null(arg))z else arg
>>> }
>>
>> You know, this is exactly what I want to do: I have a function, which
>> takes either a numerical value or a function (from PAI) as the argument
>> dep. So I have to check if the dep is a function or a value. At the
>> moment, I am using is.function(), and when dep is not a function,
>> convert it to a function which returns dep. If it is a function, I can
>> leave it as it is. I could also replace, in your code, the is.null()
>> with is.function() and do effectively the same here (some edits
>> required).
>>
>> Very neat indeed.
>>
>> And a perfect way of making functions very versatile. IU really have to
>> look closer into these things.
>>
>> Is there a good resource for these advanced programming techniques in R?
>>
>> Thanks,
>>
>> Rainer
>>
>>
>>>> x <- 5
>>>> g1 <- fconv(x) ## g1 will always return 5
>>>> g1()
>>> [1] 5
>>>> g1(1)
>>> [1] 5
>>>
>>>> x <- 2
>>>> g1(x) ## Still uses the "x" in its defining environment
>>> [1] 5
>>>
>>> ## But ...
>>>> g2 <- fconv() ## No constant given to it in its definition
>>>> g2(x)
>>> [1] 2
>>>> g2(1)
>>> [1] 1
>>>> g2()
>>> Error in g2() : argument "z" is missing, with no default
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> Clifford Stoll
>>>
>>>
>>>
>>>
>>> On Thu, Apr 9, 2015 at 7:57 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> You can make such functions by using the fact that a function
>>>> (really, a 'closure') always has access to the environment in
>>>> which the function was created.  E.g.
>>>>   makeConstantFunction <- function(constant) {
>>>>       force(constant) # evaluate the argument now
>>>>       function(PAI) {
>>>>           constant
>>>>       }
>>>>   }
>>>>   f17 <- makeConstantFunction(17)
>>>>   flog17 <- makeConstantFunction(log(17))
>>>>   f17(111)
>>>>   # [1] 17
>>>>   flog17(111)
>>>>   # [1] 2.833213
>>>>
>>>> If you print f17 and flog17 they will look the same, except for
>>>> their environments and you have to inspect those to see why
>>>> they act differently.
>>>>
>>>>   ls.str(environment(f17))
>>>>   # constant :  num 17
>>>>   ls.str(environment(flog17))
>>>>   # constant :  num 2.83
>>>>
>>>> If you really want the functions to look different you can use
>>>> substittute or bquote, but that is also a bit mysterious (you need the
>>>> eval()
>>>> their outputs):
>>>>   g17 <- eval(substitute(function(PAI)x, list(x=17)))
>>>>   h17 <- eval(bquote(function(PAI).(x), list(x=17)))
>>>>   g17(10)
>>>>   [1] 17
>>>>   h17(10:1)
>>>>   [1] 17
>>>>
>>>>
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Thu, Apr 9, 2015 at 5:39 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>>>
>>>>>
>>>>> Hi
>>>>>
>>>>> I want convert, in a function, an argument from a numerical value to a
>>>>> function which returns this value.:
>>>>>
>>>>> My Code:
>>>>>
>>>>> --8<---------------cut here---------------start------------->8---
>>>>> dep <- 13
>>>>> dep <- function() {dep}
>>>>> dep
>>>>> --8<---------------cut here---------------end--------------->8---
>>>>>
>>>>> This is what I get:
>>>>> #+RESULTS:
>>>>> ,----
>>>>> | function(PAI) { dep }
>>>>> `----
>>>>>
>>>>> This is what I want
>>>>> ,----
>>>>> | function(PAI) { 13 }
>>>>> `----
>>>>>
>>>>> I thought about using eval(dep), but this gives me the effectively the
>>>>> same.
>>>>>
>>>>> Is it possible to achieve what I want? I somehow have the feeling this
>>>>> is not that easily possible, as the code in the function definition is
>>>>> only evaluated when the function is evaluated.
>>>>>
>>>>> I could obviously do something like
>>>>>
>>>>> --8<---------------cut here---------------start------------->8---
>>>>> dep <- 13
>>>>> depVal <- dep
>>>>> dep <- function() {depVal}
>>>>> dep()
>>>>> --8<---------------cut here---------------end--------------->8---
>>>>>
>>>>> But is there a better solution?
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Rainer
>>>>>
>>>>> --
>>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>>>> Biology, UCT), Dipl. Phys. (Germany)
>>>>>
>>>>> Centre of Excellence for Invasion Biology
>>>>> Stellenbosch University
>>>>> South Africa
>>>>>
>>>>> Tel :       +33 - (0)9 53 10 27 44
>>>>> Cell:       +33 - (0)6 85 62 59 98
>>>>> Fax :       +33 - (0)9 58 10 27 44
>>>>>
>>>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>>>>
>>>>> email:      Rainer at krugs.de
>>>>>
>>>>> Skype:      RMkrug
>>>>>
>>>>> PGP: 0x0F52F982
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>>
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>>
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>
>> email:      Rainer at krugs.de
>>
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Fri Apr 10 18:01:20 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Fri, 10 Apr 2015 16:01:20 +0000 (UTC)
Subject: [R] BIG difficulties in Using boot.ci (bot package)
Message-ID: <268701.626368.1428681680813.JavaMail.yahoo@mail.yahoo.com>

Dear R-Experts, 

I am trying to compute the BCa nonparametric bootstrap on regression coefficients. 

Here is the reproducible example :  

GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12) 
Quality.score <-c(12,11,13,14,15,16,12,10,9,9) 
Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7) 
fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score) 
confint(fit, level=.95) 
confint.default(fit, level=.95) 
confint(fit,level=.95,type="bca") 

I am not sure but I think that I can not get the nonparametric BCa bootstrap with the confint function. As you can see, I have tried the argument type="bca", I don?t get any error message, but the results don?t change, the results are exactly the same as confint(fit,level=.95). 
As I have understood, the default argument uses normal quantiles and the method for linear models uses T-quantiles instead. 
So, I have checked the boot package and the boot.ci function to calculate the BCa bootstrap on the regression coefficients, but I don?t really understand how to compute the code. 
So, any help from you would be highly appreciated. 

Best,
S


From xavier.chiriboga at unine.ch  Fri Apr 10 19:23:05 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 10 Apr 2015 17:23:05 +0000
Subject: [R] ESTIMATES SURVIVAL ANALYSIS WEIBULL
Message-ID: <7B64C8E017B948419F014C915AA6D7342A0520CF@mail-mbx-03.UNINE.CH>

Dear members,



I did a survival analysis, Weibul fits better for my data: this is the "head" of my data



 start stop state soil volatile hours replicate
1     0   48     1   ca       nc    48         3
2     0   48     1   ca       nc    48         4
3     0   48     1   ca       nc    48         5
4     0   48     1   ca       nc    48         8
5     0   60     1   ca        c    60         1
6     0   60     1   ca        c    60         1





I have 4 soils: ca, cs, cl and sand



and I have 2 volatiles: nc and c



However, when I get the stimates my soil "ca" does not appear and the volatile "c" neither



Call:
survreg(formula = Surv(hours, state) ~ soil * volatile, data = surgal,
    dist = "weibull")
                      Value Std. Error      z         p
(Intercept)          4.3605     0.0417 104.51  0.00e+00
soilcl              -0.0784     0.0590  -1.33  1.84e-01
soilcs              -0.3865     0.0567  -6.81  9.59e-12
soilsand            -0.1913     0.0579  -3.30  9.61e-04
volatilenc          -0.1600     0.0579  -2.76  5.74e-03
soilcl:volatilenc    0.1320     0.0823   1.60  1.09e-01
soilcs:volatilenc    0.2679     0.0812   3.30  9.64e-04
soilsand:volatilenc  0.0821     0.0809   1.01  3.10e-01
Log(scale)          -1.4788     0.0442 -33.46 1.73e-245

Scale= 0.228

Weibull distribution
Loglik(model)= -1036.3   Loglik(intercept only)= -1065
        Chisq= 57.41 on 7 degrees of freedom, p= 5e-10
Number of Newton-Raphson Iterations: 5
n= 257



Anyone knows why? or what does it mean? how should I interpret the values in the table?



Thanks for your help,



Xavier


From gunter.berton at gene.com  Fri Apr 10 20:02:41 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 10 Apr 2015 11:02:41 -0700
Subject: [R] ESTIMATES SURVIVAL ANALYSIS WEIBULL
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0520CF@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0520CF@mail-mbx-03.UNINE.CH>
Message-ID: <CACk-te0Dg1sA4O_xNHNkyyJH1HPWTu_6Vc8j=hr_fkKDFUT9WA@mail.gmail.com>

Consult a local statistician. You need to understand the concept of
contrasts for categorical variables, which is a basic statistical
issue, not an R issue. How R handles contrasts is explained (tersely)
in ?contrast.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Apr 10, 2015 at 10:23 AM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear members,
>
>
>
> I did a survival analysis, Weibul fits better for my data: this is the "head" of my data
>
>
>
>  start stop state soil volatile hours replicate
> 1     0   48     1   ca       nc    48         3
> 2     0   48     1   ca       nc    48         4
> 3     0   48     1   ca       nc    48         5
> 4     0   48     1   ca       nc    48         8
> 5     0   60     1   ca        c    60         1
> 6     0   60     1   ca        c    60         1
>
>
>
>
>
> I have 4 soils: ca, cs, cl and sand
>
>
>
> and I have 2 volatiles: nc and c
>
>
>
> However, when I get the stimates my soil "ca" does not appear and the volatile "c" neither
>
>
>
> Call:
> survreg(formula = Surv(hours, state) ~ soil * volatile, data = surgal,
>     dist = "weibull")
>                       Value Std. Error      z         p
> (Intercept)          4.3605     0.0417 104.51  0.00e+00
> soilcl              -0.0784     0.0590  -1.33  1.84e-01
> soilcs              -0.3865     0.0567  -6.81  9.59e-12
> soilsand            -0.1913     0.0579  -3.30  9.61e-04
> volatilenc          -0.1600     0.0579  -2.76  5.74e-03
> soilcl:volatilenc    0.1320     0.0823   1.60  1.09e-01
> soilcs:volatilenc    0.2679     0.0812   3.30  9.64e-04
> soilsand:volatilenc  0.0821     0.0809   1.01  3.10e-01
> Log(scale)          -1.4788     0.0442 -33.46 1.73e-245
>
> Scale= 0.228
>
> Weibull distribution
> Loglik(model)= -1036.3   Loglik(intercept only)= -1065
>         Chisq= 57.41 on 7 degrees of freedom, p= 5e-10
> Number of Newton-Raphson Iterations: 5
> n= 257
>
>
>
> Anyone knows why? or what does it mean? how should I interpret the values in the table?
>
>
>
> Thanks for your help,
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mbressan at arpa.veneto.it  Fri Apr 10 21:30:46 2015
From: mbressan at arpa.veneto.it (mbressan at arpa.veneto.it)
Date: Fri, 10 Apr 2015 21:30:46 +0200
Subject: [R] recursively rename dir and files
In-Reply-To: <CA+8X3fWnYmRi31x56xyo-vLqHM73=NTV0L-tw2W35aFX4shmKA@mail.gmail.com>
References: <1428609512106-4705667.post@n4.nabble.com>
	<CA+8X3fWnYmRi31x56xyo-vLqHM73=NTV0L-tw2W35aFX4shmKA@mail.gmail.com>
Message-ID: <8fefe3bad73b47ee584046107b557583.squirrel@89.96.234.216>

hi jim

thank you very much for your help: what a nice piece of code!

inspired by your neat solution let me here post a slight variation upon
your lines which is now also dealing also with caps in file and dir names
(a potentially useful function for the proper "housekeeping" of the wd)

it works but there is one potentially "dangerous" drawback (to be somehow
controlled): it renames the R code file eventually present in the wd which
is usually named something like *.R which is renamed as *.r

I definitely need to think a viable solution to avoid that problem...

####

setwd(".")
dir.create("./My Dir with Spaces and Caps")
dir.create("./My Dir with Spaces and Caps/My Sub Dir With Spaces and Caps")
file.create("./My Dir with Spaces and Caps/My Dir file With Spaces and
Caps.txt")
file.create("./My Dir with Spaces and Caps/My Sub Dir With Spaces and
Caps/My Sub Dir File With Spaces and Caps.txt")
file.create("./My Dir with Spaces and Caps/My Sub Dir With Spaces and
Caps/MySubDirFileJustWithCaps.txt")

#new function
recursive_replace_lowercase<-function(path=".", replace=" ", with="_",
lowercase=TRUE) {

  # this is the base case

  filelist<-list.files(path, full.names=TRUE)

  if (lowercase) {

    for(filename in filelist)
      file.rename(filename,gsub(replace,with,tolower(filename)))

  } else {

    for(filename in filelist)
      file.rename(filename,gsub(replace,with,filename))
  }

  # and this is the recursive part

  dirlist<-list.dirs(path, full.names=TRUE, recursive=FALSE)

  if(length(dirlist)) {

    for(dirname in dirlist)
      recursive_replace_lowercase(dirname, replace=replace, with=with,
lowercase=lowercase)
  }
}

recursive_replace_lowercase()


> Hi maxbre,
> Try this:
>
> recursive_replace<-function(path=".",replace=" ",with="_") {
>  filelist<-list.files(path,full.names=TRUE)
>  for(filename in filelist) {
>   if(length(grep(replace,filename)))
>    file.rename(filename,gsub(replace,with,filename))
>  }
>  dirlist<-list.dirs(path,full.names=TRUE,recursive=FALSE)
>  if(length(dirlist)) {
>   for(dirname in dirlist)
>    recursive_replace(dirname,replace=replace,with=with)
>  }
> }
>
> Jim
>
>
> On Fri, Apr 10, 2015 at 5:58 AM, maxbre <mbressan at arpa.veneto.it> wrote:
>
>> this is my reproducible example
>>
>> setwd(".")
>> dir.create("./my dir with space")
>> dir.create("./my dir with space/my sub dir with space")
>> file.create("./my dir with space/my dir file with space.txt")
>> file.create("./my dir with space/my sub dir with space/my sub dir file
>> with
>> space.txt")
>>
>> now I need to rename recursively all dirs and files in order to get rid
>> of
>> spaces
>>
>> the following attempt is not getting to the point...
>>
>> mylist<-dir(".", full.names=TRUE, recursive=TRUE, include.dirs=TRUE)
>>
>> for (i in mylist){
>>   file.rename(i, gsub(" ", "_", i))
>> }
>>
>> #or more simply...
>> file.rename(mydirs, gsub(" ", "_", mydirs))
>>
>> ...because (clearly) I got some warning messages like "can not rename
>> file
>> .... because it is not existing";
>> and I definitely understand that because in the process of renaming of
>> the
>> the upper level directory the full path of the nested directories and
>> files
>> is changed and any longer visible to the procedure...
>>
>> the problem now is that I'm not enough clear how to proceed with an
>> alternative strategy in order to properly sort out the problem...
>>
>> for reasons I'm not mentioning here I must stick with a solution in R
>> language
>>
>> any hint much appreciated
>>
>> thanks
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/recursively-rename-dir-and-files-tp4705667.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From luysgarcia at gmail.com  Fri Apr 10 22:24:35 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Fri, 10 Apr 2015 17:24:35 -0300
Subject: [R] Question on CCA and RDA analysis
Message-ID: <CANxP2S7nU6V+Y05eQrPtfRjSrFtOhpFBT3TEg0oTvFyZH5fJfg@mail.gmail.com>

Dear R experts,

I wanted to know if you can suggest me any website or tutorial just to
learn about how to make a RDA or CDA in R

Thanks in advance!

	[[alternative HTML version deleted]]


From amc5981 at gmail.com  Fri Apr 10 22:07:32 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Fri, 10 Apr 2015 13:07:32 -0700
Subject: [R] Finding values in a dataframe at a specified hour
Message-ID: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>

Hello,

I have a large dataframe (windHW) of wind speeds (ws) at each hour
from many days over a set of years.  Some of these values are
obviously wrong (600 m/s) and I want to get rid of all the values that
are larger than 5*sigma for each hour.  The 5*sigma (variable name
sigma5) values are located in different dataframes for each season,
with each dataframe titled as a season.  For example, in the
dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.

So my question is as follows: how can I get it so that the code will
be able to find all the wind speed values in the dataframe, windHW, of
a specific hour be higher than the 5*sigma value at that hour?
For example, I would like to find if any of the wind speed values at
hour 1 are higher than 79.6 m/s, and if so, then replace that value
with NA.

I have something like this but I can't seem to figure out how to get
it for specific hours:

windHW$ws[windHW$ws>=spring$sigma5] <- NA

I imported the data using readLines and into the dataframe windHW.  I
also have R version 3.1.1

Any help would be appreciated!

Thanks,
Alexandra


From bd10stats at googlemail.com  Fri Apr 10 22:20:52 2015
From: bd10stats at googlemail.com (B Dittmann)
Date: Fri, 10 Apr 2015 21:20:52 +0100
Subject: [R] multiple input files single output - lapply? - pls advise
Message-ID: <CAKdis6F36g-4npW7CEWCEtdeF=fJKYvDUnZy0zyhsLcsGO31SA@mail.gmail.com>

Dear R users,

hope you can point me in the right direction. I am stuck with the following
problem.

My function "f1" reads csv files, manipulates them into the right xts
format and returns the output at the end. This works perfectly fine. Now, I
need to run "f1" over a long list of various csv files, all of the same
format, but different dates (or time stamps) which is guaranteed by design.
All these individual results per each file I hope to combine into one xts
or zoo object.

I tried "lapply" as follows:

# all csv files start with "z1":
file.names <- list.files(pattern = "z1*", full.names = T, recursive = FALSE)

# my function:
f1 <- function(x, param){
# x: the csv file
# param: some parameter for calculation
# spits results out
return(results)
}

res <- lapply(file.names, function(x){f1(x, param)})

I wrote the output to "res" and by subsetting res[1], res[2], ... I can
retrieve the results of each individual csv file on which I applied my
function "f1".

How could I append or merge all individual results res[i] for my i csv
files into one xts or zoo object?

Many thanks in advance,

Bernard

	[[alternative HTML version deleted]]


From mahdiyeh.erfaniyan at gmail.com  Fri Apr 10 22:42:47 2015
From: mahdiyeh.erfaniyan at gmail.com (Mahdiyeh Erfaniyan)
Date: Sat, 11 Apr 2015 01:12:47 +0430
Subject: [R] How to complete this code
Message-ID: <CANBmxoj1TX6sFRrSHZDmRSSULhz_Ytfit-o0CngiSFsHF5Jwyw@mail.gmail.com>

Hi,


Consider the line below:



for(r in a)for (s in a) x=rbind(x,apply(replicate(1000,V(r,s)),1,mean))



V is a vector of (n-1) variables calculated by some rule and is a functions
of (r,s).  So the line above produces 1000 replicates of V for each (r,s),
puts them in a matrix, calculates the mean of them, and finally puts the
means for all (r,s) in a matrix. So the produced matrix, x, is the mean of
(n-1) V 's for each possible value of (r,s) in each row. Now for simplicity
fix (r,s) in just one point and let n=5. So in each replicate we have only
one V which is a vector consisted of 4 variables. Name the elements of V as
U1, U2, U3 and U4. Then we can let

V(i) = [U1i , U2i , U3i , U4i]



which shows each row of V produced per replicate (i=1,2,...,1000).
Therefore we can say



x=[x1 , x2 , x3 , x4]



which is the vector of means calculated at the end. Now what I need is to
first calculate the vector below per replicate (i=1,...,1000):



Er(i) = [ |Ui1-x1| , |Ui2-x2| , |Ui3-x3| , |Ui4-x4| ]



where |A| shows the absolute value of A. Then I should calculate mean of
Er(i) 's and put the result in a vector. I just don't know how I can
calculate Er(i) 's in the given line above. On the other words, I don't
know where I should add the required code in the given line. Thanks for any
help in advance!

	[[alternative HTML version deleted]]


From amc5981 at gmail.com  Fri Apr 10 23:06:42 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Fri, 10 Apr 2015 14:06:42 -0700
Subject: [R] Finding values in a dataframe at a specified hour
In-Reply-To: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
References: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
Message-ID: <CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>

Update:

I have this so far.  * The first column of windHW is the wind speed.
The 5th column of the dataframe, spring, is the 5*sigma value of every
hour.  hourRow gives out all the rows of wind speed at a given hour.

for (i in 0:23){
  hourRow = which(windHW$hour==i,arr.ind=TRUE)
  for (h in hourRow){
    if (windHW[h,1]>=spring[spring$hour==i,5]){
      windHW[h,1]<-NA}
  }
}

This then gives the error: Error in if (windHW[h, 1] >=
spring[spring$hour == i, 5]) { : argument is of length zero

*Note: The dataframe for each of the seasons have 24 rows
corresponding to each hour of the day 0:23.

Thanks,
Alexandra


On Fri, Apr 10, 2015 at 1:07 PM, Alexandra Catena <amc5981 at gmail.com> wrote:
> Hello,
>
> I have a large dataframe (windHW) of wind speeds (ws) at each hour
> from many days over a set of years.  Some of these values are
> obviously wrong (600 m/s) and I want to get rid of all the values that
> are larger than 5*sigma for each hour.  The 5*sigma (variable name
> sigma5) values are located in different dataframes for each season,
> with each dataframe titled as a season.  For example, in the
> dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.
>
> So my question is as follows: how can I get it so that the code will
> be able to find all the wind speed values in the dataframe, windHW, of
> a specific hour be higher than the 5*sigma value at that hour?
> For example, I would like to find if any of the wind speed values at
> hour 1 are higher than 79.6 m/s, and if so, then replace that value
> with NA.
>
> I have something like this but I can't seem to figure out how to get
> it for specific hours:
>
> windHW$ws[windHW$ws>=spring$sigma5] <- NA
>
> I imported the data using readLines and into the dataframe windHW.  I
> also have R version 3.1.1
>
> Any help would be appreciated!
>
> Thanks,
> Alexandra


From drjimlemon at gmail.com  Sat Apr 11 00:36:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 11 Apr 2015 08:36:22 +1000
Subject: [R] Removing words and initials with tm
In-Reply-To: <5527D35D.6080607@gmail.com>
References: <5527A3C7.7040700@gmail.com>
	<97B581C3-DA93-455D-8451-89FA57EA0C8C@dcn.davis.CA.us>
	<5527D35D.6080607@gmail.com>
Message-ID: <CA+8X3fW056THB5iz+Fue-pwdKbLGmV5-0sai99ajK-GouRfacg@mail.gmail.com>

Hi Sun,
No, I was thinking of something like hunspell, which seems to fit into the
sort of work that you are doing.

Jim


On Fri, Apr 10, 2015 at 11:42 PM, Sun Shine <phaedrusv at gmail.com> wrote:

> Thanks Jeff.
>
> I'll add that to the ever-growing list my current studies are generating
> daily. :-)
>
> Cheers
> S
>
>
>
> On 10/04/15 14:32, Jeff Newmiller wrote:
>
>> "I suspect that it might have something to do with regular expressions,
>> but to be honest, I'm (currently) pretty crap with those."
>>
>> I cannot think of a better incentive to take action on this hole in your
>> education and buckle down to learn regular expressions. There are many
>> books and tutorials available.
>> ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ------------------------------------------------------------
>> ---------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 10, 2015 3:19:51 AM PDT, Sun Shine <phaedrusv at gmail.com> wrote:
>>
>>> Hi list
>>>
>>> Using the tm package, part of the pre-processing work is to remove
>>> words, etc. from the corpus.
>>>
>>> I wish to remove people's names and also their initials which are
>>> peppered throughout the corpus. But, because some people's initials are
>>>
>>> the same as parts of common words - e.g. 'am' = 'became' => 'bec e' or
>>> 'ec' = 'because' => 'b ause' or 'ar' = 'arrival' => 'rival' (which has
>>> a
>>> completely different meaning).
>>>
>>> Is there any way of doing this without leaving a trail of nonsense
>>> half-terms behind? I suspect that it might have something to do with
>>> regular expressions, but to be honest, I'm (currently) pretty crap with
>>>
>>> those.
>>>
>>> Would it make a difference if I removed initials and names *prior* to
>>> converting all text to lower case, so I remove 'AM' and because
>>> 'became'
>>> is lower case, it should remain unaffected?
>>>
>>> Any recommendations on how best to proceed with this?
>>>
>>> Thanks as always.
>>> Sun
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Apr 11 00:43:44 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 11 Apr 2015 08:43:44 +1000
Subject: [R] Finding values in a dataframe at a specified hour
In-Reply-To: <CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
References: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
	<CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
Message-ID: <CA+8X3fVfcwSAwZQ5uYS_nitQ+iY2L4exLnvmBAsw8PJkHF2+qg@mail.gmail.com>

Hi Alexandra,
The error probably comes from the first iteration of i in 0:23. As indexing
in R begins at 1, there is no element 0. Try using:

for(i in 1:24) {
...

and see what happens.

Jim


On Sat, Apr 11, 2015 at 7:06 AM, Alexandra Catena <amc5981 at gmail.com> wrote:

> Update:
>
> I have this so far.  * The first column of windHW is the wind speed.
> The 5th column of the dataframe, spring, is the 5*sigma value of every
> hour.  hourRow gives out all the rows of wind speed at a given hour.
>
> for (i in 0:23){
>   hourRow = which(windHW$hour==i,arr.ind=TRUE)
>   for (h in hourRow){
>     if (windHW[h,1]>=spring[spring$hour==i,5]){
>       windHW[h,1]<-NA}
>   }
> }
>
> This then gives the error: Error in if (windHW[h, 1] >=
> spring[spring$hour == i, 5]) { : argument is of length zero
>
> *Note: The dataframe for each of the seasons have 24 rows
> corresponding to each hour of the day 0:23.
>
> Thanks,
> Alexandra
>
>
> On Fri, Apr 10, 2015 at 1:07 PM, Alexandra Catena <amc5981 at gmail.com>
> wrote:
> > Hello,
> >
> > I have a large dataframe (windHW) of wind speeds (ws) at each hour
> > from many days over a set of years.  Some of these values are
> > obviously wrong (600 m/s) and I want to get rid of all the values that
> > are larger than 5*sigma for each hour.  The 5*sigma (variable name
> > sigma5) values are located in different dataframes for each season,
> > with each dataframe titled as a season.  For example, in the
> > dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.
> >
> > So my question is as follows: how can I get it so that the code will
> > be able to find all the wind speed values in the dataframe, windHW, of
> > a specific hour be higher than the 5*sigma value at that hour?
> > For example, I would like to find if any of the wind speed values at
> > hour 1 are higher than 79.6 m/s, and if so, then replace that value
> > with NA.
> >
> > I have something like this but I can't seem to figure out how to get
> > it for specific hours:
> >
> > windHW$ws[windHW$ws>=spring$sigma5] <- NA
> >
> > I imported the data using readLines and into the dataframe windHW.  I
> > also have R version 3.1.1
> >
> > Any help would be appreciated!
> >
> > Thanks,
> > Alexandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Apr 10 23:36:11 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Apr 2015 21:36:11 +0000
Subject: [R] Question on CCA and RDA analysis
References: <CANxP2S7nU6V+Y05eQrPtfRjSrFtOhpFBT3TEg0oTvFyZH5fJfg@mail.gmail.com>
Message-ID: <loom.20150410T233550-74@post.gmane.org>

Luis Fernando Garc?a <luysgarcia <at> gmail.com> writes:

> 
> Dear R experts,
> 
> I wanted to know if you can suggest me any website or tutorial just to
> learn about how to make a RDA or CDA in R
> 
> Thanks in advance!

  I hate to ask, but did you try Googling

""canonical correspondence analysis" R" 

... ?



From amc5981 at gmail.com  Sat Apr 11 01:24:11 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Fri, 10 Apr 2015 16:24:11 -0700
Subject: [R] Finding values in a dataframe at a specified hour
In-Reply-To: <CA+8X3fVfcwSAwZQ5uYS_nitQ+iY2L4exLnvmBAsw8PJkHF2+qg@mail.gmail.com>
References: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
	<CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
	<CA+8X3fVfcwSAwZQ5uYS_nitQ+iY2L4exLnvmBAsw8PJkHF2+qg@mail.gmail.com>
Message-ID: <CAHpsUFYAs9VsPOcVtCKdxU1VdGDYcXB06k3FRY2E=VDaT0TPTg@mail.gmail.com>

Hi Jim,

Thanks for the response, but unfortunately it results in the same
error.  I think it is something wrong with the if statement.  I tried
it out manually for the first row and hour that it's testing and
indeed, the wind speed is not higher than the 5*sigma value.  Since it
is not higher than the 5*sigma value, I would think it would just pass
to the next loop, yet it doesn't. I will keep trying!

Thanks,
Alexandra

On Fri, Apr 10, 2015 at 3:43 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Alexandra,
> The error probably comes from the first iteration of i in 0:23. As indexing
> in R begins at 1, there is no element 0. Try using:
>
> for(i in 1:24) {
> ...
>
> and see what happens.
>
> Jim
>
>
> On Sat, Apr 11, 2015 at 7:06 AM, Alexandra Catena <amc5981 at gmail.com> wrote:
>>
>> Update:
>>
>> I have this so far.  * The first column of windHW is the wind speed.
>> The 5th column of the dataframe, spring, is the 5*sigma value of every
>> hour.  hourRow gives out all the rows of wind speed at a given hour.
>>
>> for (i in 0:23){
>>   hourRow = which(windHW$hour==i,arr.ind=TRUE)
>>   for (h in hourRow){
>>     if (windHW[h,1]>=spring[spring$hour==i,5]){
>>       windHW[h,1]<-NA}
>>   }
>> }
>>
>> This then gives the error: Error in if (windHW[h, 1] >=
>> spring[spring$hour == i, 5]) { : argument is of length zero
>>
>> *Note: The dataframe for each of the seasons have 24 rows
>> corresponding to each hour of the day 0:23.
>>
>> Thanks,
>> Alexandra
>>
>>
>> On Fri, Apr 10, 2015 at 1:07 PM, Alexandra Catena <amc5981 at gmail.com>
>> wrote:
>> > Hello,
>> >
>> > I have a large dataframe (windHW) of wind speeds (ws) at each hour
>> > from many days over a set of years.  Some of these values are
>> > obviously wrong (600 m/s) and I want to get rid of all the values that
>> > are larger than 5*sigma for each hour.  The 5*sigma (variable name
>> > sigma5) values are located in different dataframes for each season,
>> > with each dataframe titled as a season.  For example, in the
>> > dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.
>> >
>> > So my question is as follows: how can I get it so that the code will
>> > be able to find all the wind speed values in the dataframe, windHW, of
>> > a specific hour be higher than the 5*sigma value at that hour?
>> > For example, I would like to find if any of the wind speed values at
>> > hour 1 are higher than 79.6 m/s, and if so, then replace that value
>> > with NA.
>> >
>> > I have something like this but I can't seem to figure out how to get
>> > it for specific hours:
>> >
>> > windHW$ws[windHW$ws>=spring$sigma5] <- NA
>> >
>> > I imported the data using readLines and into the dataframe windHW.  I
>> > also have R version 3.1.1
>> >
>> > Any help would be appreciated!
>> >
>> > Thanks,
>> > Alexandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From luysgarcia at gmail.com  Sat Apr 11 04:38:18 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Fri, 10 Apr 2015 23:38:18 -0300
Subject: [R] Question on CCA and RDA analysis
In-Reply-To: <loom.20150410T233550-74@post.gmane.org>
References: <CANxP2S7nU6V+Y05eQrPtfRjSrFtOhpFBT3TEg0oTvFyZH5fJfg@mail.gmail.com>
	<loom.20150410T233550-74@post.gmane.org>
Message-ID: <CANxP2S7CraFGnkYMdJLUFG6HdmSp5hdH=cX3TEdE7Vy=FHp5YQ@mail.gmail.com>

Yeah,

 The most useful example I found was this.

 https://gist.github.com/perrygeo/7572735.

I always had the idea of this kind of forums was to provide sources not so
obvious in the web. If you have something better it would be great.

2015-04-10 18:36 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> Luis Fernando Garc?a <luysgarcia <at> gmail.com> writes:
>
> >
> > Dear R experts,
> >
> > I wanted to know if you can suggest me any website or tutorial just to
> > learn about how to make a RDA or CDA in R
> >
> > Thanks in advance!
>
>   I hate to ask, but did you try Googling
>
> ""canonical correspondence analysis" R"
>
> ... ?
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Apr 11 05:05:20 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 11 Apr 2015 13:05:20 +1000
Subject: [R] Finding values in a dataframe at a specified hour
In-Reply-To: <CAHpsUFYAs9VsPOcVtCKdxU1VdGDYcXB06k3FRY2E=VDaT0TPTg@mail.gmail.com>
References: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
	<CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
	<CA+8X3fVfcwSAwZQ5uYS_nitQ+iY2L4exLnvmBAsw8PJkHF2+qg@mail.gmail.com>
	<CAHpsUFYAs9VsPOcVtCKdxU1VdGDYcXB06k3FRY2E=VDaT0TPTg@mail.gmail.com>
Message-ID: <CA+8X3fWNm0th7a+tyMpe48UCOXxRPaCJgZ9=PPDc5FiJjy2q0A@mail.gmail.com>

Hi Alexandra,
I answered too quickly. Your response made me look for a deeper error: The
value of i doesn't matter, as it isn't being used as an index. However, the
first value of i=0 may cause the error in the second loop, where h is used
as an index.

for (i in 0:23){
  hourRow = which(windHW$hour==i,arr.ind=TRUE)
  for (h in hourRow){
    if (windHW[h+1,1]>=spring[spring$hour==i,5]){
      windHW[h+1,1]<-NA}
  }
}

Jim


On Sat, Apr 11, 2015 at 9:24 AM, Alexandra Catena <amc5981 at gmail.com> wrote:

> Hi Jim,
>
> Thanks for the response, but unfortunately it results in the same
> error.  I think it is something wrong with the if statement.  I tried
> it out manually for the first row and hour that it's testing and
> indeed, the wind speed is not higher than the 5*sigma value.  Since it
> is not higher than the 5*sigma value, I would think it would just pass
> to the next loop, yet it doesn't. I will keep trying!
>
> Thanks,
> Alexandra
>
> On Fri, Apr 10, 2015 at 3:43 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Alexandra,
> > The error probably comes from the first iteration of i in 0:23. As
> indexing
> > in R begins at 1, there is no element 0. Try using:
> >
> > for(i in 1:24) {
> > ...
> >
> > and see what happens.
> >
> > Jim
> >
> >
> > On Sat, Apr 11, 2015 at 7:06 AM, Alexandra Catena <amc5981 at gmail.com>
> wrote:
> >>
> >> Update:
> >>
> >> I have this so far.  * The first column of windHW is the wind speed.
> >> The 5th column of the dataframe, spring, is the 5*sigma value of every
> >> hour.  hourRow gives out all the rows of wind speed at a given hour.
> >>
> >> for (i in 0:23){
> >>   hourRow = which(windHW$hour==i,arr.ind=TRUE)
> >>   for (h in hourRow){
> >>     if (windHW[h,1]>=spring[spring$hour==i,5]){
> >>       windHW[h,1]<-NA}
> >>   }
> >> }
> >>
> >> This then gives the error: Error in if (windHW[h, 1] >=
> >> spring[spring$hour == i, 5]) { : argument is of length zero
> >>
> >> *Note: The dataframe for each of the seasons have 24 rows
> >> corresponding to each hour of the day 0:23.
> >>
> >> Thanks,
> >> Alexandra
> >>
> >>
> >> On Fri, Apr 10, 2015 at 1:07 PM, Alexandra Catena <amc5981 at gmail.com>
> >> wrote:
> >> > Hello,
> >> >
> >> > I have a large dataframe (windHW) of wind speeds (ws) at each hour
> >> > from many days over a set of years.  Some of these values are
> >> > obviously wrong (600 m/s) and I want to get rid of all the values that
> >> > are larger than 5*sigma for each hour.  The 5*sigma (variable name
> >> > sigma5) values are located in different dataframes for each season,
> >> > with each dataframe titled as a season.  For example, in the
> >> > dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.
> >> >
> >> > So my question is as follows: how can I get it so that the code will
> >> > be able to find all the wind speed values in the dataframe, windHW, of
> >> > a specific hour be higher than the 5*sigma value at that hour?
> >> > For example, I would like to find if any of the wind speed values at
> >> > hour 1 are higher than 79.6 m/s, and if so, then replace that value
> >> > with NA.
> >> >
> >> > I have something like this but I can't seem to figure out how to get
> >> > it for specific hours:
> >> >
> >> > windHW$ws[windHW$ws>=spring$sigma5] <- NA
> >> >
> >> > I imported the data using readLines and into the dataframe windHW.  I
> >> > also have R version 3.1.1
> >> >
> >> > Any help would be appreciated!
> >> >
> >> > Thanks,
> >> > Alexandra
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Sat Apr 11 07:04:39 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 11 Apr 2015 07:04:39 +0200
Subject: [R] searchTwitter with unicode- UTF8
Message-ID: <DUB125-W3123E8CE280BCE530372D7B3F90@phx.gbl>

Dear group
I uses 'searchTwitter'  to get users tweets it works  for English words such as ("iphone")
but when working with Arabic   text
example
searchTwitter("?????")   it gave me the following Error

Error in twInterfaceObj$doAPICall(cmd, params, "GET", ...) : 
  Error: Forbidden


my questions  are
how to make it understand the unicode characters?
and if It is a hashtag should I write it that way "#?????"

many thanks in advance
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Sat Apr 11 08:21:40 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Sat, 11 Apr 2015 07:21:40 +0100
Subject: [R] Removing words and initials with tm
In-Reply-To: <CA+8X3fW056THB5iz+Fue-pwdKbLGmV5-0sai99ajK-GouRfacg@mail.gmail.com>
References: <5527A3C7.7040700@gmail.com>	<97B581C3-DA93-455D-8451-89FA57EA0C8C@dcn.davis.CA.us>	<5527D35D.6080607@gmail.com>
	<CA+8X3fW056THB5iz+Fue-pwdKbLGmV5-0sai99ajK-GouRfacg@mail.gmail.com>
Message-ID: <5528BD74.2050209@gmail.com>

Hi Jim

The name's come up on my radar, but that's about it. I'll look into it.

Thanks for the reference.

All the best
S

On 10/04/15 23:36, Jim Lemon wrote:
> Hi Sun,
> No, I was thinking of something like hunspell, which seems to fit into 
> the sort of work that you are doing.
>
> Jim
>
>
> On Fri, Apr 10, 2015 at 11:42 PM, Sun Shine <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Thanks Jeff.
>
>     I'll add that to the ever-growing list my current studies are
>     generating daily. :-)
>
>     Cheers
>     S
>
>
>
>     On 10/04/15 14:32, Jeff Newmiller wrote:
>
>         "I suspect that it might have something to do with regular
>         expressions, but to be honest, I'm (currently) pretty crap
>         with those."
>
>         I cannot think of a better incentive to take action on this
>         hole in your education and buckle down to learn regular
>         expressions. There are many books and tutorials available.
>         ---------------------------------------------------------------------------
>         Jeff Newmiller                        The     .....    ..... 
>         Go Live...
>         DCN:<jdnewmil at dcn.davis.ca.us
>         <mailto:jdnewmil at dcn.davis.ca.us>>     Basics: ##.#.     
>          ##.#.  Live Go...
>                                                Live:   OO#.. Dead:
>         OO#..  Playing
>         Research Engineer (Solar/Batteries            O.O#.    #.O#.  with
>         /Software/Embedded Controllers)               .OO#.    .OO#. 
>         rocks...1k
>         ---------------------------------------------------------------------------
>         Sent from my phone. Please excuse my brevity.
>
>         On April 10, 2015 3:19:51 AM PDT, Sun Shine
>         <phaedrusv at gmail.com <mailto:phaedrusv at gmail.com>> wrote:
>
>             Hi list
>
>             Using the tm package, part of the pre-processing work is
>             to remove
>             words, etc. from the corpus.
>
>             I wish to remove people's names and also their initials
>             which are
>             peppered throughout the corpus. But, because some people's
>             initials are
>
>             the same as parts of common words - e.g. 'am' = 'became'
>             => 'bec e' or
>             'ec' = 'because' => 'b ause' or 'ar' = 'arrival' =>
>             'rival' (which has
>             a
>             completely different meaning).
>
>             Is there any way of doing this without leaving a trail of
>             nonsense
>             half-terms behind? I suspect that it might have something
>             to do with
>             regular expressions, but to be honest, I'm (currently)
>             pretty crap with
>
>             those.
>
>             Would it make a difference if I removed initials and names
>             *prior* to
>             converting all text to lower case, so I remove 'AM' and
>             because
>             'became'
>             is lower case, it should remain unaffected?
>
>             Any recommendations on how best to proceed with this?
>
>             Thanks as always.
>             Sun
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained,
>             reproducible code.
>
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From bd10stats at googlemail.com  Sat Apr 11 09:53:56 2015
From: bd10stats at googlemail.com (B Dittmann)
Date: Sat, 11 Apr 2015 08:53:56 +0100
Subject: [R] multiple input files single output - lapply? - pls advise
In-Reply-To: <CA+vqiLGHyTCKByVJ1=FB65iLhGnfs17RUwiMUXK_0YH=HhJgmA@mail.gmail.com>
References: <CAKdis6F36g-4npW7CEWCEtdeF=fJKYvDUnZy0zyhsLcsGO31SA@mail.gmail.com>
	<CA+vqiLGHyTCKByVJ1=FB65iLhGnfs17RUwiMUXK_0YH=HhJgmA@mail.gmail.com>
Message-ID: <CAKdis6EYZAv_biSoxdz9d_gXSy98jUwT5NjHzp_jAvh8Pr-G9g@mail.gmail.com>

Hi Ista

This works brilliantly and is so elegant!

Yes,  i googled quite a while but did not come across do.call till now.

Thanks again

Bernard
On 10 Apr 2015 22:46, "Ista Zahn" <istazahn at gmail.com> wrote:

> Hi Bernard,
>
> Did you try searching for an answer? This question (minus the xts part
> which I don't think will matter) has been asked and answered many times,
> with
>
> do.call("rbind", foo)
>
> being a common answer.
>
> Best,
> Ista
> On Apr 10, 2015 5:35 PM, "B Dittmann" <bd10stats at googlemail.com> wrote:
>
>> Dear R users,
>>
>> hope you can point me in the right direction. I am stuck with the
>> following
>> problem.
>>
>> My function "f1" reads csv files, manipulates them into the right xts
>> format and returns the output at the end. This works perfectly fine. Now,
>> I
>> need to run "f1" over a long list of various csv files, all of the same
>> format, but different dates (or time stamps) which is guaranteed by
>> design.
>> All these individual results per each file I hope to combine into one xts
>> or zoo object.
>>
>> I tried "lapply" as follows:
>>
>> # all csv files start with "z1":
>> file.names <- list.files(pattern = "z1*", full.names = T, recursive =
>> FALSE)
>>
>> # my function:
>> f1 <- function(x, param){
>> # x: the csv file
>> # param: some parameter for calculation
>> # spits results out
>> return(results)
>> }
>>
>> res <- lapply(file.names, function(x){f1(x, param)})
>>
>> I wrote the output to "res" and by subsetting res[1], res[2], ... I can
>> retrieve the results of each individual csv file on which I applied my
>> function "f1".
>>
>> How could I append or merge all individual results res[i] for my i csv
>> files into one xts or zoo object?
>>
>> Many thanks in advance,
>>
>> Bernard
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgreen at dyson.brisnet.org.au  Sat Apr 11 13:04:08 2015
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Sat, 11 Apr 2015 21:04:08 +1000
Subject: [R] Removing words and initials with tm
In-Reply-To: <mailman.1.1428746401.6797.r-help@r-project.org>
References: <mailman.1.1428746401.6797.r-help@r-project.org>
Message-ID: <20150411110408.136DC84E360@borg.pacgate.com>

Hello Sun,

The order of the TM transformations makes a lot of difference.

It isn't a shortcut, but if you identify all names you could create 
your own Stop words list:

corpus  <-tm_map(corpus , removeWords, c("english", "  "))

In the case of York,  Key Word in Context (KWIC) syntax could be used 
to check how certain words are used. You could identify the words 
useages you want to remove or retain and respectively rename the 
relevant instances.

This is labour intensive, but Greis in his Quantitative Corpus 
Linguistics, notes that sometimes time spent on trying to refine code 
might be better spent on manual analysis (p164). This book includes a 
KWIC type function (page 127), but I haven't been able to work out 
how to modify it to read more than six words either side of the 
specified word. Six should be adequate for your purpose. Jockers book 
also includes a KWIC function but I don't believe it searches the 
entire corpus, rather a specified text.

I recently checked and TM doesn't have a KWIC function, but for the R 
talented (which excludes me) it might be possible to write one. For 
example, Jim Holtman once wrote a KWIC function to identify word use 
in a csv file.

Bob


From ragia11 at hotmail.com  Sat Apr 11 18:50:36 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 11 Apr 2015 18:50:36 +0200
Subject: [R] searchTwitter
Message-ID: <DUB125-W29686E562F7CD9B7A919E0B3F90@phx.gbl>

Dear group 
I used the following code to download some tweets (1500)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)

## Windows users need to get this file
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")

requestURL <"https://api.twitter.com/oauth/request_token"
   accessURL = "https://api.twitter.com/oauth/access_token"
authURL = "https://api.twitter.com/oauth/authorize"
consumerKey = "secret"
consumerSecret = "secret"
Cred <- oauthfactory$new(consumerkey="">
                            consumerSecret=consumerSecret,
                         requestURL=requestURL,
                         accessURL=accessURL,
                         authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )

registerTwitterOAuth(Cred)
save(Cred, file="twitter authentication.Rdata")

###########################################################

# Chunk - 2 - Twitter Scrape  
############################################################

searchTwitter(  "alhazm", n=1500   , cainfo="cacert.pem" ) 

But I got the following error message

In doRppAPICall("search/tweets", n, params = params, retryOnRateLimit = retryOnRateLimit,  :
  500 tweets were requested but the API can only return 28

why ? and how I can Increase number of retreived tweets, many thanks


Ragia

 		 	   		  
	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Sat Apr 11 19:00:05 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 11 Apr 2015 19:00:05 +0200
Subject: [R] searchTwitter
In-Reply-To: <DUB125-W29686E562F7CD9B7A919E0B3F90@phx.gbl>
References: <DUB125-W29686E562F7CD9B7A919E0B3F90@phx.gbl>
Message-ID: <DUB125-W34AC15742CB62DB05B5092B3F90@phx.gbl>






Dear group ,


I used the following code to download some tweets (1500)

library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)

## Windows users need to get this file
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")

requestURL <"https://api.twitter.com/oauth/request_token"
   accessURL = "https://api.twitter.com/oauth/access_token"
authURL = "https://api.twitter.com/oauth/authorize"
consumerKey = "secret"
consumerSecret = "secret"
Cred <- oauthfactory$new(consumerkey="">
                            consumerSecret=consumerSecret,
                         requestURL=requestURL,
                         accessURL=accessURL,
                         authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )

registerTwitterOAuth(Cred)
save(Cred, file="twitter authentication.Rdata")

###########################################################

# Chunk - 2 - Twitter Scrape  
############################################################

searchTwitter(  "alhazm", n=1500   , cainfo="cacert.pem" ) 

But I got the following error message

In doRppAPICall("search/tweets", n, params = params, retryOnRateLimit = retryOnRateLimit,  :
  500 tweets were requested but the API can only return 28

why ? and how I can Increase number of retreived tweets, many thanks


Ragia

 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sat Apr 11 19:01:04 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sat, 11 Apr 2015 19:01:04 +0200
Subject: [R] Parallel processing
Message-ID: <CAJgdCD4W+6syJkKS+3FeQqoca4C8nrzEPke_ziE46ubPG2O57A@mail.gmail.com>

Dear community,

Sory for cross posting. Does anybody have an idea on how I can do parallel
in MATLAB?

thanks for your help

-- 
John Wasige

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sat Apr 11 19:36:09 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 11 Apr 2015 19:36:09 +0200
Subject: [R] Parallel processing
In-Reply-To: <CAJgdCD4W+6syJkKS+3FeQqoca4C8nrzEPke_ziE46ubPG2O57A@mail.gmail.com>
References: <CAJgdCD4W+6syJkKS+3FeQqoca4C8nrzEPke_ziE46ubPG2O57A@mail.gmail.com>
Message-ID: <CAJuCY5x7NDPXSL=pALVHfse-3is+Qjcw=Fzvg8FZqsYTW8d_aQ@mail.gmail.com>

Wrong mailinglist. This one is about R, not matlab.
Op 11-apr.-2015 19:03 schreef "John Wasige" <johnwasige at gmail.com>:

> Dear community,
>
> Sory for cross posting. Does anybody have an idea on how I can do parallel
> in MATLAB?
>
> thanks for your help
>
> --
> John Wasige
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Sat Apr 11 19:44:42 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 11 Apr 2015 12:44:42 -0500
Subject: [R] Parallel processing in Matlab (irrelevant to R)
In-Reply-To: <CAJgdCD4W+6syJkKS+3FeQqoca4C8nrzEPke_ziE46ubPG2O57A@mail.gmail.com>
References: <CAJgdCD4W+6syJkKS+3FeQqoca4C8nrzEPke_ziE46ubPG2O57A@mail.gmail.com>
Message-ID: <20150411124442.00b353013630dadb7f92060c@inbox.com>

Sorry, I think you posted to the wrong group. 

Ranjan 

On Sat, 11 Apr 2015 19:01:04 +0200 John Wasige <johnwasige at gmail.com> wrote:

> Dear community,
> 
> Sory for cross posting. Does anybody have an idea on how I can do parallel
> in MATLAB?
> 
> thanks for your help
> 
> -- 
> John Wasige
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From wegorkie at gmail.com  Sat Apr 11 19:39:41 2015
From: wegorkie at gmail.com (=?UTF-8?Q?Maciej_W=C4=99gorkiewicz?=)
Date: Sat, 11 Apr 2015 19:39:41 +0200
Subject: [R] Cannot run install binary package on Windows 8
Message-ID: <CAE2+5Rc3S_VwhfBBkjscK3Ka3ZYwDeMab2iYzNXuyc3gMTT3=g@mail.gmail.com>

Hi all,

I am just starting with R and cannot use "lmtest" package on Windows 8.
This package contains dwtest function that I am interested in.

I began with installing the core of R (with rgui) - version 3.1.3 64-bit.

Then I installed lmtest package using GUI menu, but after success
message I cannot run dwtest() getting message that the it cannot find
the function.

When I used installed.packages() function I saw lmtest on the list but
there was "yes" under the "NeedsCompilation" column. Does it mean I
need to compile the package in order to use it?

I uninstalled lmtest and tried to put binary Windows version by
downloading zip file from here:
http://cran.r-project.org/web/packages/lmtest/index.html

I took the file:
http://cran.r-project.org/bin/windows/contrib/3.1/lmtest_0.9-33.zip

downloaded it and tried to use the function of installing from local zip file.

However the effect was the same: "NeedsCompilation" set to true,
dwtest does not work.
The package contains binary file for 64-bit (DLLs).

What can I do in order to run this?


From jdnewmil at dcn.davis.CA.us  Sun Apr 12 00:04:12 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 11 Apr 2015 15:04:12 -0700
Subject: [R] Cannot run install binary package on Windows 8
In-Reply-To: <CAE2+5Rc3S_VwhfBBkjscK3Ka3ZYwDeMab2iYzNXuyc3gMTT3=g@mail.gmail.com>
References: <CAE2+5Rc3S_VwhfBBkjscK3Ka3ZYwDeMab2iYzNXuyc3gMTT3=g@mail.gmail.com>
Message-ID: <626D8C4B-ED41-4175-937D-D7F00BA79FD0@dcn.davis.CA.us>

Did you use the library function to load it into memory? You may need to practise with some simpler tasks using base R before you get too frustrated with using a contributed package. The Introduction to R document that is provided with R is worth your time.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 11, 2015 10:39:41 AM PDT, "Maciej W?gorkiewicz" <wegorkie at gmail.com> wrote:
>Hi all,
>
>I am just starting with R and cannot use "lmtest" package on Windows 8.
>This package contains dwtest function that I am interested in.
>
>I began with installing the core of R (with rgui) - version 3.1.3
>64-bit.
>
>Then I installed lmtest package using GUI menu, but after success
>message I cannot run dwtest() getting message that the it cannot find
>the function.
>
>When I used installed.packages() function I saw lmtest on the list but
>there was "yes" under the "NeedsCompilation" column. Does it mean I
>need to compile the package in order to use it?
>
>I uninstalled lmtest and tried to put binary Windows version by
>downloading zip file from here:
>http://cran.r-project.org/web/packages/lmtest/index.html
>
>I took the file:
>http://cran.r-project.org/bin/windows/contrib/3.1/lmtest_0.9-33.zip
>
>downloaded it and tried to use the function of installing from local
>zip file.
>
>However the effect was the same: "NeedsCompilation" set to true,
>dwtest does not work.
>The package contains binary file for 64-bit (DLLs).
>
>What can I do in order to run this?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Apr 12 02:02:38 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 11 Apr 2015 16:02:38 -0800
Subject: [R] Cannot run install binary package on Windows 8
In-Reply-To: <CAE2+5Rc3S_VwhfBBkjscK3Ka3ZYwDeMab2iYzNXuyc3gMTT3=g@mail.gmail.com>
Message-ID: <28810FEEAD6.000007E4jrkrideau@inbox.com>

You need to load the library after you have installed the package.  Only libraries in the base R installation load automatically. Thus every time you want to use contributed package XXX you need to issue the command
library(XXX) or require(XXX) 

So at the top of your program try

library(lmtest)

You should be good to go.  Newbies often miss this step.

Good luck with R

John Kane
Kingston ON Canada


> -----Original Message-----
> From: wegorkie at gmail.com
> Sent: Sat, 11 Apr 2015 19:39:41 +0200
> To: r-help at r-project.org
> Subject: [R] Cannot run install binary package on Windows 8
> 
> Hi all,
> 
> I am just starting with R and cannot use "lmtest" package on Windows 8.
> This package contains dwtest function that I am interested in.
> 
> I began with installing the core of R (with rgui) - version 3.1.3 64-bit.
> 
> Then I installed lmtest package using GUI menu, but after success
> message I cannot run dwtest() getting message that the it cannot find
> the function.
> 
> When I used installed.packages() function I saw lmtest on the list but
> there was "yes" under the "NeedsCompilation" column. Does it mean I
> need to compile the package in order to use it?
> 
> I uninstalled lmtest and tried to put binary Windows version by
> downloading zip file from here:
> http://cran.r-project.org/web/packages/lmtest/index.html
> 
> I took the file:
> http://cran.r-project.org/bin/windows/contrib/3.1/lmtest_0.9-33.zip
> 
> downloaded it and tried to use the function of installing from local zip
> file.
> 
> However the effect was the same: "NeedsCompilation" set to true,
> dwtest does not work.
> The package contains binary file for 64-bit (DLLs).
> 
> What can I do in order to run this?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From bbolker at gmail.com  Sat Apr 11 23:59:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Apr 2015 21:59:44 +0000
Subject: [R] Cannot run install binary package on Windows 8
References: <CAE2+5Rc3S_VwhfBBkjscK3Ka3ZYwDeMab2iYzNXuyc3gMTT3=g@mail.gmail.com>
Message-ID: <loom.20150411T235827-843@post.gmane.org>

Maciej W?gorkiewicz <wegorkie <at> gmail.com> writes:

> 
> Hi all,
> 
> I am just starting with R and cannot use "lmtest" package on Windows 8.
> This package contains dwtest function that I am interested in.
> 
> I began with installing the core of R (with rgui) - version 3.1.3 64-bit.
> 
> Then I installed lmtest package using GUI menu, but after success
> message I cannot run dwtest() getting message that the it cannot find
> the function.
> 

  This sounds like R FAQ 7.30
http://cran.r-project.org/doc/FAQ/R-FAQ.html#
    I-installed-a-package-but-the-functions-are-not-there

(URL broken to make gmane happy)

  Try library("lmtest").  Everything else you've done after 
initially installing the package sounds like a wild goose chase ...

From samarvir1996 at gmail.com  Sun Apr 12 10:31:14 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Sun, 12 Apr 2015 14:01:14 +0530
Subject: [R] Can't load CARET package, on Mac OS X (latest),
	on R version 3.1.2 (2014-10-31)
Message-ID: <CAOpgo6g7H9KRtaLgsS99PwWXOb-icfR=RgBNkYifWW-OAN6ftg@mail.gmail.com>

I installed CARET package, but when I try to load CARET. I see this error.
Please help. thank you


install.packages("caret")
trying URL '
http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/caret_6.0-41.tgz'
Content type 'application/x-gzip' length 3997718 bytes (3.8 Mb)
opened URL
==================================================
downloaded 3.8 Mb

tar: Failed to set default locale

The downloaded binary packages are in
/var/folders/wr/h77ghk5104d1l5xyx3v67yk80000gn/T//RtmpEqNi84/downloaded_packages

> library("caret")
Loading required package: lattice
Loading required package: ggplot2
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so':

dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so,
6): initializer function 0x0 not in mapped image for
/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so

In addition: Warning messages:
1: package 'lattice' was built under R version 3.1.3
2: package 'ggplot2' was built under R version 3.1.3
Error: package or namespace load failed for 'caret'

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun Apr 12 14:48:53 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 12 Apr 2015 04:48:53 -0800
Subject: [R] Can't load CARET package, on Mac OS X (latest),
 on R  version 3.1.2 (2014-10-31)
In-Reply-To: <CAOpgo6g7H9KRtaLgsS99PwWXOb-icfR=RgBNkYifWW-OAN6ftg@mail.gmail.com>
Message-ID: <2F31C7CF30E.000000DFjrkrideau@inbox.com>

Can you post the results of a 
sessionInfo()

It looks like you may have an old installation of R

John Kane
Kingston ON Canada


> -----Original Message-----
> From: samarvir1996 at gmail.com
> Sent: Sun, 12 Apr 2015 14:01:14 +0530
> To: r-help at r-project.org
> Subject: [R] Can't load CARET package, on Mac OS X (latest), on R version
> 3.1.2 (2014-10-31)
> 
> I installed CARET package, but when I try to load CARET. I see this
> error.
> Please help. thank you
> 
> 
> install.packages("caret")
> trying URL '
> http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/caret_6.0-41.tgz'
> Content type 'application/x-gzip' length 3997718 bytes (3.8 Mb)
> opened URL
> ==================================================
> downloaded 3.8 Mb
> 
> tar: Failed to set default locale
> 
> The downloaded binary packages are in
> /var/folders/wr/h77ghk5104d1l5xyx3v67yk80000gn/T//RtmpEqNi84/downloaded_packages
> 
>> library("caret")
> Loading required package: lattice
> Loading required package: ggplot2
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so':
> 
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so,
> 6): initializer function 0x0 not in mapped image for
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so
> 
> In addition: Warning messages:
> 1: package 'lattice' was built under R version 3.1.3
> 2: package 'ggplot2' was built under R version 3.1.3
> Error: package or namespace load failed for 'caret'
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From emorway at usgs.gov  Sun Apr 12 15:47:21 2015
From: emorway at usgs.gov (Morway, Eric)
Date: Sun, 12 Apr 2015 06:47:21 -0700
Subject: [R] nested for loops too slow
Message-ID: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>

The small example below works lighting-fast; however, when I run the same
script on my real problem, a 1Gb text file, the for loops have been running
for over 24 hrs and I have no idea if the processing is 10% done or 90%
done.  I have not been able to figure out a betteR way to code up the
material within the for loops at the end of the example below.  The
contents of divChng, the final product, are exactly what I'm after, but I
need help formulating more efficient R script, I've got two more 1Gb files
to process after the current one finishes, whenever that is...

I appreciate any insights/solutions, Eric

dat <- read.table(textConnection("ISEG  IRCH  div  gw
1  1  265  229
1  2  260  298
1  3  234  196
54  1  432  485
54  39  467  485
54  40  468  468
54  41  460  381
54  42  489  502
1  1  265  317
1  2  276  225
1  3  217  164
54  1  430  489
54  39  456  495
54  40  507  607
54  41  483  424
54  42  457  404
1  1  265  278
1  2  287  370
1  3  224  274
54  1  412  585
54  39  473  532
54  40  502  595
54  41  497  441
54  42  447  467
1  1  230  258
1  2  251  152
1  3  199  179
54  1  412  415
54  39  439  538
54  40  474  486
54  41  477  484
54  42  413  346
1  1  230  171
1  2  262  171
1  3  217  263
54  1  432  485
54  39  455  482
54  40  493  419
54  41  489  536
54  42  431  504
1  1  1002  1090
1  2  1222  1178
1  3  1198  1177
54  1  1432  1485
54  39  1876  1975
54  40  1565  1646
54  41  1455  1451
54  42  1427  1524
1  1  1002  968
1  2  1246  1306
1  3  1153  1158
54  1  1532  1585
54  39  1790  1889
54  40  1490  1461
54  41  1518  1536
54  42  1486  1585
1  1  1002  1081
1  2  1229  1262
1  3  1142  1241
54  1  1632  1659
54  39  1797  1730
54  40  1517  1466
54  41  1527  1589
54  42  1514  1612"),header=TRUE)

dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
tmp <- diff(dat[dat$seq==1,]$div)!=0
dat$idx <- 0
dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
dat$ts <- cumsum(dat$idx)
dat$iter <- ave(dat$seq, dat$ts,FUN=cumsum)
dat$ct <- seq(1:length(dat[,1]))

timeStep <- unique(dat$ts)
SEG <- unique(dat$ISEG)
divChng <- data.frame(ts=NA, ISEG=NA, divChng=NA, gwChng=NA, iter=NA)

#Can the following be rescripted for better harnessing R's processing power?

for (i in 1:length(timeStep)){
  for (j in 1:length(SEG)){
    datTS <- subset(dat,ts==timeStep[i] & ISEG==SEG[j] & IRCH==1)
    datGW <- subset(dat,ts==timeStep[i] & ISEG==SEG[j])
    grw <- aggregate(gw ~ iter, datGW, sum)

    DC <- max(datTS$div)-min(datTS$div)
    GRW <- max(grw$gw) - min(grw$gw)
    divChng <- rbind(divChng,c(datTS$ts[1], SEG[j], DC, GRW,
max(datTS$iter)))
  }
}
divChng <- divChng[!is.na(divChng$ISEG),]

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sun Apr 12 15:47:33 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 12 Apr 2015 14:47:33 +0100
Subject: [R] Can't load CARET package, on Mac OS X (latest),
 on R version 3.1.2 (2014-10-31)
In-Reply-To: <CAOpgo6g7H9KRtaLgsS99PwWXOb-icfR=RgBNkYifWW-OAN6ftg@mail.gmail.com>
References: <CAOpgo6g7H9KRtaLgsS99PwWXOb-icfR=RgBNkYifWW-OAN6ftg@mail.gmail.com>
Message-ID: <552A7775.4030003@stats.ox.ac.uk>

Several issues

1) The problem is with minqa, not caret (let alone CARET: R is 
case-sensitive).

2) As the posting guide says, update your R before posting.

3) We are missing the 'at a minimum' information, the output of 
sessionInfo().  You have not told us how you installed R, but my guess 
is that you used one of the two binary packages from CRAN (but we have 
no way to know which).  If so, you definitely should be using the 
R-sig-Mac mailing list.

So my advice is to

- update R
- reinstall your packages, especially minqa
- if problems persist, send a full report to R-sig-Mac following the 
posting guide.


On 12/04/2015 09:31, samarvir singh wrote:
> I installed CARET package, but when I try to load CARET. I see this error.
> Please help. thank you
>
>
> install.packages("caret")
> trying URL '
> http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/caret_6.0-41.tgz'
> Content type 'application/x-gzip' length 3997718 bytes (3.8 Mb)
> opened URL
> ==================================================
> downloaded 3.8 Mb
>
> tar: Failed to set default locale
>
> The downloaded binary packages are in
> /var/folders/wr/h77ghk5104d1l5xyx3v67yk80000gn/T//RtmpEqNi84/downloaded_packages
>
>> library("caret")
> Loading required package: lattice
> Loading required package: ggplot2
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>    unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so':
>
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so,
> 6): initializer function 0x0 not in mapped image for
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/minqa/libs/minqa.so
>
> In addition: Warning messages:
> 1: package 'lattice' was built under R version 3.1.3
> 2: package 'ggplot2' was built under R version 3.1.3
> Error: package or namespace load failed for 'caret'
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From luca.cerone at gmail.com  Sun Apr 12 17:11:46 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sun, 12 Apr 2015 17:11:46 +0200
Subject: [R] Obfuscate AES password
Message-ID: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>

Hi, I need some help with obfuscating AES key on Windows, Linux and Mac.
I have asked the same question on stackoverflow, but since I didn't
receive any input
I have decided to post it here too. You can find my question at:
http://stackoverflow.com/questions/29580742/protect-aes-key-used-in-r-code

The package I am writing interfaces R to various services we have
available in my company and some of these require to receive username
and password.

I ask the credentials to the users during the installation, and save them
in an encrypted using AES from the digest package and writeBin.

This way users don't need to hardcode their credentials and we can share the
code without issues.

The problem is that the AES key is saved as plain text on the machine,
so that an intruder has access to the machine he can easily decrypt the users
profile and get their credentials.

What is the best way to protect the key, so that even if somebody gets
the encrypted file he can't decrypt it easily?

Thanks a lot in advance for the help,
Cheers.
Luca


From jdnewmil at dcn.davis.CA.us  Sun Apr 12 17:33:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 12 Apr 2015 08:33:14 -0700
Subject: [R] Obfuscate AES password
In-Reply-To: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
Message-ID: <094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>

The topic of this list is R, not security. For the purposes of this mailing list the user needs to take responsibility for the password. If you want to take that responsibility (cache it) from the user then you need to talk to experts on security so you can become one yourself.

IMHO obfuscating a password is worse than leaving it plain, because that would be misleading the user about how securely the password is being managed.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 12, 2015 8:11:46 AM PDT, Luca Cerone <luca.cerone at gmail.com> wrote:
>Hi, I need some help with obfuscating AES key on Windows, Linux and
>Mac.
>I have asked the same question on stackoverflow, but since I didn't
>receive any input
>I have decided to post it here too. You can find my question at:
>http://stackoverflow.com/questions/29580742/protect-aes-key-used-in-r-code
>
>The package I am writing interfaces R to various services we have
>available in my company and some of these require to receive username
>and password.
>
>I ask the credentials to the users during the installation, and save
>them
>in an encrypted using AES from the digest package and writeBin.
>
>This way users don't need to hardcode their credentials and we can
>share the
>code without issues.
>
>The problem is that the AES key is saved as plain text on the machine,
>so that an intruder has access to the machine he can easily decrypt the
>users
>profile and get their credentials.
>
>What is the best way to protect the key, so that even if somebody gets
>the encrypted file he can't decrypt it easily?
>
>Thanks a lot in advance for the help,
>Cheers.
>Luca
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From robertsonburns at btinternet.com  Sun Apr 12 17:12:46 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Sun, 12 Apr 2015 16:12:46 +0100
Subject: [R] nested for loops too slow
In-Reply-To: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>
References: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>
Message-ID: <552A8B6E.1020908@btinternet.com>

You are certainly in Circle 2 of 'The R Inferno',
which I suspect is where almost all of the
computation time is coming from.

Instead of doing:

divChng <- rbind(divChng,c(datTS$ts[1], SEG[j], DC, GRW,
max(datTS$iter)))

it would be much better to create 'divChng' to
be the final length and then in the loop do:

divChng[count,] <- c(datTS$ts[1], SEG[j], DC, GRW,
max(datTS$iter))
count <- count + 1

You may also want to explore 'tapply'.
If this is something you will be doing
a lot of, then you should probably learn
the 'data.table' package.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat

On 12/04/2015 14:47, Morway, Eric wrote:
> The small example below works lighting-fast; however, when I run the same
> script on my real problem, a 1Gb text file, the for loops have been running
> for over 24 hrs and I have no idea if the processing is 10% done or 90%
> done.  I have not been able to figure out a betteR way to code up the
> material within the for loops at the end of the example below.  The
> contents of divChng, the final product, are exactly what I'm after, but I
> need help formulating more efficient R script, I've got two more 1Gb files
> to process after the current one finishes, whenever that is...
>
> I appreciate any insights/solutions, Eric
>
> dat <- read.table(textConnection("ISEG  IRCH  div  gw
> 1  1  265  229
> 1  2  260  298
> 1  3  234  196
> 54  1  432  485
> 54  39  467  485
> 54  40  468  468
> 54  41  460  381
> 54  42  489  502
> 1  1  265  317
> 1  2  276  225
> 1  3  217  164
> 54  1  430  489
> 54  39  456  495
> 54  40  507  607
> 54  41  483  424
> 54  42  457  404
> 1  1  265  278
> 1  2  287  370
> 1  3  224  274
> 54  1  412  585
> 54  39  473  532
> 54  40  502  595
> 54  41  497  441
> 54  42  447  467
> 1  1  230  258
> 1  2  251  152
> 1  3  199  179
> 54  1  412  415
> 54  39  439  538
> 54  40  474  486
> 54  41  477  484
> 54  42  413  346
> 1  1  230  171
> 1  2  262  171
> 1  3  217  263
> 54  1  432  485
> 54  39  455  482
> 54  40  493  419
> 54  41  489  536
> 54  42  431  504
> 1  1  1002  1090
> 1  2  1222  1178
> 1  3  1198  1177
> 54  1  1432  1485
> 54  39  1876  1975
> 54  40  1565  1646
> 54  41  1455  1451
> 54  42  1427  1524
> 1  1  1002  968
> 1  2  1246  1306
> 1  3  1153  1158
> 54  1  1532  1585
> 54  39  1790  1889
> 54  40  1490  1461
> 54  41  1518  1536
> 54  42  1486  1585
> 1  1  1002  1081
> 1  2  1229  1262
> 1  3  1142  1241
> 54  1  1632  1659
> 54  39  1797  1730
> 54  40  1517  1466
> 54  41  1527  1589
> 54  42  1514  1612"),header=TRUE)
>
> dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
> tmp <- diff(dat[dat$seq==1,]$div)!=0
> dat$idx <- 0
> dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
> dat$ts <- cumsum(dat$idx)
> dat$iter <- ave(dat$seq, dat$ts,FUN=cumsum)
> dat$ct <- seq(1:length(dat[,1]))
>
> timeStep <- unique(dat$ts)
> SEG <- unique(dat$ISEG)
> divChng <- data.frame(ts=NA, ISEG=NA, divChng=NA, gwChng=NA, iter=NA)
>
> #Can the following be rescripted for better harnessing R's processing power?
>
> for (i in 1:length(timeStep)){
>    for (j in 1:length(SEG)){
>      datTS <- subset(dat,ts==timeStep[i] & ISEG==SEG[j] & IRCH==1)
>      datGW <- subset(dat,ts==timeStep[i] & ISEG==SEG[j])
>      grw <- aggregate(gw ~ iter, datGW, sum)
>
>      DC <- max(datTS$div)-min(datTS$div)
>      GRW <- max(grw$gw) - min(grw$gw)
>      divChng <- rbind(divChng,c(datTS$ts[1], SEG[j], DC, GRW,
> max(datTS$iter)))
>    }
> }
> divChng <- divChng[!is.na(divChng$ISEG),]
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From luca.cerone at gmail.com  Sun Apr 12 19:59:02 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sun, 12 Apr 2015 19:59:02 +0200
Subject: [R] Obfuscate AES password
In-Reply-To: <094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
	<094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>
Message-ID: <CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>

Hi Jeff,
thanks, actually my question is how to do this in R, I don't think I am
being out of topic.

Other programming/scripting languages provide interfaces to the OS password
keyring that allows
users to encrypt files using the user master password, but I have no idea
how to do this in R.

Thanks again for your reply !

On Sun, Apr 12, 2015 at 5:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:
> The topic of this list is R, not security. For the purposes of this
mailing list the user needs to take responsibility for the password. If you
want to take that responsibility (cache it) from the user then you need to
talk to experts on security so you can become one yourself.
>
> IMHO obfuscating a password is worse than leaving it plain, because that
would be misleading the user about how securely the password is being
managed.
>
---------------------------------------------------------------------------
> Jeff Newmiller The ..... ..... Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#. ##.#. Live Go...
> Live: OO#.. Dead: OO#.. Playing
> Research Engineer (Solar/Batteries O.O#. #.O#. with
> /Software/Embedded Controllers) .OO#. .OO#. rocks...1k
>
---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 12, 2015 8:11:46 AM PDT, Luca Cerone <luca.cerone at gmail.com>
wrote:
>>Hi, I need some help with obfuscating AES key on Windows, Linux and
>>Mac.
>>I have asked the same question on stackoverflow, but since I didn't
>>receive any input
>>I have decided to post it here too. You can find my question at:
>>http://stackoverflow.com/questions/29580742/protect-aes-key-used-in-r-code
>>
>>The package I am writing interfaces R to various services we have
>>available in my company and some of these require to receive username
>>and password.
>>
>>I ask the credentials to the users during the installation, and save
>>them
>>in an encrypted using AES from the digest package and writeBin.
>>
>>This way users don't need to hardcode their credentials and we can
>>share the
>>code without issues.
>>
>>The problem is that the AES key is saved as plain text on the machine,
>>so that an intruder has access to the machine he can easily decrypt the
>>users
>>profile and get their credentials.
>>
>>What is the best way to protect the key, so that even if somebody gets
>>the encrypted file he can't decrypt it easily?
>>
>>Thanks a lot in advance for the help,
>>Cheers.
>>Luca
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Apr 12 22:17:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 12 Apr 2015 13:17:04 -0700
Subject: [R] Obfuscate AES password
In-Reply-To: <CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
	<094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>
	<CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>
Message-ID: <B4E14CA2-9609-454E-B7B6-0202C98D7317@dcn.davis.CA.us>

Sigh. I still disagree that your question is on topic, but someone else may offer something more helpful than I can.

You are being rather vague about this API... and if you identified it specifically then I would probably object that it was almost certainly very specific to a single operating system while R is OS-agnostic. However, if you were to narrow your scope to a specific operating system API, then you could probably use Rcpp as a stepping stone to calling any API you want. However, you will have left the generic R interpreter behind in order to create this tool for yourself, and interfacing R to compiled code generally is on topic on the R-devel mailing list, not here. 

So, some study on how to interface with compiled code seems like your best next step. Normally that is most effectively handled in a package, so you will need to learn about that as well. Then if you have specific questions that you can supply reproducible examples for then R-devel or one of the OS-specific R mailing lists would be more appropriate than this list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 12, 2015 10:59:02 AM PDT, Luca Cerone <luca.cerone at gmail.com> wrote:
>Hi Jeff,
>thanks, actually my question is how to do this in R, I don't think I am
>being out of topic.
>
>Other programming/scripting languages provide interfaces to the OS
>password
>keyring that allows
>users to encrypt files using the user master password, but I have no
>idea
>how to do this in R.
>
>Thanks again for your reply !
>
>On Sun, Apr 12, 2015 at 5:33 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>> The topic of this list is R, not security. For the purposes of this
>mailing list the user needs to take responsibility for the password. If
>you
>want to take that responsibility (cache it) from the user then you need
>to
>talk to experts on security so you can become one yourself.
>>
>> IMHO obfuscating a password is worse than leaving it plain, because
>that
>would be misleading the user about how securely the password is being
>managed.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller The ..... ..... Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#. ##.#. Live Go...
>> Live: OO#.. Dead: OO#.. Playing
>> Research Engineer (Solar/Batteries O.O#. #.O#. with
>> /Software/Embedded Controllers) .OO#. .OO#. rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 12, 2015 8:11:46 AM PDT, Luca Cerone <luca.cerone at gmail.com>
>wrote:
>>>Hi, I need some help with obfuscating AES key on Windows, Linux and
>>>Mac.
>>>I have asked the same question on stackoverflow, but since I didn't
>>>receive any input
>>>I have decided to post it here too. You can find my question at:
>>>http://stackoverflow.com/questions/29580742/protect-aes-key-used-in-r-code
>>>
>>>The package I am writing interfaces R to various services we have
>>>available in my company and some of these require to receive username
>>>and password.
>>>
>>>I ask the credentials to the users during the installation, and save
>>>them
>>>in an encrypted using AES from the digest package and writeBin.
>>>
>>>This way users don't need to hardcode their credentials and we can
>>>share the
>>>code without issues.
>>>
>>>The problem is that the AES key is saved as plain text on the
>machine,
>>>so that an intruder has access to the machine he can easily decrypt
>the
>>>users
>>>profile and get their credentials.
>>>
>>>What is the best way to protect the key, so that even if somebody
>gets
>>>the encrypted file he can't decrypt it easily?
>>>
>>>Thanks a lot in advance for the help,
>>>Cheers.
>>>Luca
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From thierry.onkelinx at inbo.be  Sun Apr 12 22:48:11 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 12 Apr 2015 22:48:11 +0200
Subject: [R] nested for loops too slow
In-Reply-To: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>
References: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>
Message-ID: <CAJuCY5y4G7GbPTDc6suuS+ROuwPHhq1QNoN3OCw3NJbddpKH=Q@mail.gmail.com>

You don't need loops at all.

    grw <- aggregate(gw ~ ts + ISEG + iter, data = dat, FUN = sum)
    GRW <- aggregate(gw ~ ts + ISEG, data = grw, FUN = function(x){max(x) -
min(x)})
    DC <- aggregate(div ~ ts + ISEG, data = subset(dat, IRCH == 1), FUN =
function(x){max(x) - min(x)})
    iter <- aggregate(iter ~ ts + ISEG, data = subset(dat, IRCH == 1), FUN
= max)
    tmp <- merge(DC, iter)
    merge(tmp, GRW)

another option is to use the plyr package

    library(plyr)
    merge(
      ddply(
        subset(dat, IRCH == 1),
        c("ts", "ISEG"),
        summarize,
        divChng = max(div) - min(div),
        max.iter = max(iter)
      ),
      ddply(
        dat,
        c("ts", "ISEG"),
        summarize,
        gwChng = diff(range(ave(gw, iter, FUN = sum)))
      )
    )

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-12 15:47 GMT+02:00 Morway, Eric <emorway at usgs.gov>:

> The small example below works lighting-fast; however, when I run the same
> script on my real problem, a 1Gb text file, the for loops have been running
> for over 24 hrs and I have no idea if the processing is 10% done or 90%
> done.  I have not been able to figure out a betteR way to code up the
> material within the for loops at the end of the example below.  The
> contents of divChng, the final product, are exactly what I'm after, but I
> need help formulating more efficient R script, I've got two more 1Gb files
> to process after the current one finishes, whenever that is...
>
> I appreciate any insights/solutions, Eric
>
> dat <- read.table(textConnection("ISEG  IRCH  div  gw
> 1  1  265  229
> 1  2  260  298
> 1  3  234  196
> 54  1  432  485
> 54  39  467  485
> 54  40  468  468
> 54  41  460  381
> 54  42  489  502
> 1  1  265  317
> 1  2  276  225
> 1  3  217  164
> 54  1  430  489
> 54  39  456  495
> 54  40  507  607
> 54  41  483  424
> 54  42  457  404
> 1  1  265  278
> 1  2  287  370
> 1  3  224  274
> 54  1  412  585
> 54  39  473  532
> 54  40  502  595
> 54  41  497  441
> 54  42  447  467
> 1  1  230  258
> 1  2  251  152
> 1  3  199  179
> 54  1  412  415
> 54  39  439  538
> 54  40  474  486
> 54  41  477  484
> 54  42  413  346
> 1  1  230  171
> 1  2  262  171
> 1  3  217  263
> 54  1  432  485
> 54  39  455  482
> 54  40  493  419
> 54  41  489  536
> 54  42  431  504
> 1  1  1002  1090
> 1  2  1222  1178
> 1  3  1198  1177
> 54  1  1432  1485
> 54  39  1876  1975
> 54  40  1565  1646
> 54  41  1455  1451
> 54  42  1427  1524
> 1  1  1002  968
> 1  2  1246  1306
> 1  3  1153  1158
> 54  1  1532  1585
> 54  39  1790  1889
> 54  40  1490  1461
> 54  41  1518  1536
> 54  42  1486  1585
> 1  1  1002  1081
> 1  2  1229  1262
> 1  3  1142  1241
> 54  1  1632  1659
> 54  39  1797  1730
> 54  40  1517  1466
> 54  41  1527  1589
> 54  42  1514  1612"),header=TRUE)
>
> dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
> tmp <- diff(dat[dat$seq==1,]$div)!=0
> dat$idx <- 0
> dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
> dat$ts <- cumsum(dat$idx)
> dat$iter <- ave(dat$seq, dat$ts,FUN=cumsum)
> dat$ct <- seq(1:length(dat[,1]))
>
> timeStep <- unique(dat$ts)
> SEG <- unique(dat$ISEG)
> divChng <- data.frame(ts=NA, ISEG=NA, divChng=NA, gwChng=NA, iter=NA)
>
> #Can the following be rescripted for better harnessing R's processing
> power?
>
> for (i in 1:length(timeStep)){
>   for (j in 1:length(SEG)){
>     datTS <- subset(dat,ts==timeStep[i] & ISEG==SEG[j] & IRCH==1)
>     datGW <- subset(dat,ts==timeStep[i] & ISEG==SEG[j])
>     grw <- aggregate(gw ~ iter, datGW, sum)
>
>     DC <- max(datTS$div)-min(datTS$div)
>     GRW <- max(grw$gw) - min(grw$gw)
>     divChng <- rbind(divChng,c(datTS$ts[1], SEG[j], DC, GRW,
> max(datTS$iter)))
>   }
> }
> divChng <- divChng[!is.na(divChng$ISEG),]
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Apr 12 23:32:09 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 12 Apr 2015 14:32:09 -0700
Subject: [R] nested for loops too slow
In-Reply-To: <CAJuCY5y4G7GbPTDc6suuS+ROuwPHhq1QNoN3OCw3NJbddpKH=Q@mail.gmail.com>
References: <CAPoqHzpx4sCKvnRZg2_HTU9CvW84PEdYrUNpuFk9zt6zMZsRRg@mail.gmail.com>
	<CAJuCY5y4G7GbPTDc6suuS+ROuwPHhq1QNoN3OCw3NJbddpKH=Q@mail.gmail.com>
Message-ID: <CACk-te2WE9Y+VemdNxNbCkBvFs+ysvwN_STzd=qVAa1J6ns-Qg@mail.gmail.com>

Well, sort of...

aggregate() is basically a wrapper for lapply(), which ultimately must loop
over the function call at the R interpreter level, as opposed to vectorized
functions that loop at the C level and hence can be orders of magnitude
faster. As a result, there is often little difference in efficiency between
explicit and *smart* (in the sense that Pat Burns has already pointed out
of not growing structures at each iteration,among other things)  for()
looping and apply-type calls. For some of us, the chief advantage of the
*apply idioms is that the code is more readable and maintainable, with R
handling fussy details of loop indexing, for example.lapply() is also more
in keeping with the functional programming paradigm.
?Others?
find both these "virtues" to be annoyances,
? ?
however, and prefer explicit *smart* looping. Chaque un ?
? ?
son go?
?t?
.

None of which necessarily denies the wisdom of the approach you've
suggested, however. It may indeed be considerably faster,
but timing will have to tell. I am just trying to correct
?(again) ?
the
? ?
widely held misperception
?that yo?
u
? seem to?
express
?.?


Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll



On Sun, Apr 12, 2015 at 1:48 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> You don't need loops at all.
>
>     grw <- aggregate(gw ~ ts + ISEG + iter, data = dat, FUN = sum)
>     GRW <- aggregate(gw ~ ts + ISEG, data = grw, FUN = function(x){max(x) -
> min(x)})
>     DC <- aggregate(div ~ ts + ISEG, data = subset(dat, IRCH == 1), FUN =
> function(x){max(x) - min(x)})
>     iter <- aggregate(iter ~ ts + ISEG, data = subset(dat, IRCH == 1), FUN
> = max)
>     tmp <- merge(DC, iter)
>     merge(tmp, GRW)
>
> another option is to use the plyr package
>
>     library(plyr)
>     merge(
>       ddply(
>         subset(dat, IRCH == 1),
>         c("ts", "ISEG"),
>         summarize,
>         divChng = max(div) - min(div),
>         max.iter = max(iter)
>       ),
>       ddply(
>         dat,
>         c("ts", "ISEG"),
>         summarize,
>         gwChng = diff(range(ave(gw, iter, FUN = sum)))
>       )
>     )
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-12 15:47 GMT+02:00 Morway, Eric <emorway at usgs.gov>:
>
> > The small example below works lighting-fast; however, when I run the same
> > script on my real problem, a 1Gb text file, the for loops have been
> running
> > for over 24 hrs and I have no idea if the processing is 10% done or 90%
> > done.  I have not been able to figure out a betteR way to code up the
> > material within the for loops at the end of the example below.  The
> > contents of divChng, the final product, are exactly what I'm after, but I
> > need help formulating more efficient R script, I've got two more 1Gb
> files
> > to process after the current one finishes, whenever that is...
> >
> > I appreciate any insights/solutions, Eric
> >
> > dat <- read.table(textConnection("ISEG  IRCH  div  gw
> > 1  1  265  229
> > 1  2  260  298
> > 1  3  234  196
> > 54  1  432  485
> > 54  39  467  485
> > 54  40  468  468
> > 54  41  460  381
> > 54  42  489  502
> > 1  1  265  317
> > 1  2  276  225
> > 1  3  217  164
> > 54  1  430  489
> > 54  39  456  495
> > 54  40  507  607
> > 54  41  483  424
> > 54  42  457  404
> > 1  1  265  278
> > 1  2  287  370
> > 1  3  224  274
> > 54  1  412  585
> > 54  39  473  532
> > 54  40  502  595
> > 54  41  497  441
> > 54  42  447  467
> > 1  1  230  258
> > 1  2  251  152
> > 1  3  199  179
> > 54  1  412  415
> > 54  39  439  538
> > 54  40  474  486
> > 54  41  477  484
> > 54  42  413  346
> > 1  1  230  171
> > 1  2  262  171
> > 1  3  217  263
> > 54  1  432  485
> > 54  39  455  482
> > 54  40  493  419
> > 54  41  489  536
> > 54  42  431  504
> > 1  1  1002  1090
> > 1  2  1222  1178
> > 1  3  1198  1177
> > 54  1  1432  1485
> > 54  39  1876  1975
> > 54  40  1565  1646
> > 54  41  1455  1451
> > 54  42  1427  1524
> > 1  1  1002  968
> > 1  2  1246  1306
> > 1  3  1153  1158
> > 54  1  1532  1585
> > 54  39  1790  1889
> > 54  40  1490  1461
> > 54  41  1518  1536
> > 54  42  1486  1585
> > 1  1  1002  1081
> > 1  2  1229  1262
> > 1  3  1142  1241
> > 54  1  1632  1659
> > 54  39  1797  1730
> > 54  40  1517  1466
> > 54  41  1527  1589
> > 54  42  1514  1612"),header=TRUE)
> >
> > dat$seq <- ifelse(dat$ISEG==1 & dat$IRCH==1, 1, 0)
> > tmp <- diff(dat[dat$seq==1,]$div)!=0
> > dat$idx <- 0
> > dat[dat$seq==1,][c(TRUE,tmp),]$idx <- 1
> > dat$ts <- cumsum(dat$idx)
> > dat$iter <- ave(dat$seq, dat$ts,FUN=cumsum)
> > dat$ct <- seq(1:length(dat[,1]))
> >
> > timeStep <- unique(dat$ts)
> > SEG <- unique(dat$ISEG)
> > divChng <- data.frame(ts=NA, ISEG=NA, divChng=NA, gwChng=NA, iter=NA)
> >
> > #Can the following be rescripted for better harnessing R's processing
> > power?
> >
> > for (i in 1:length(timeStep)){
> >   for (j in 1:length(SEG)){
> >     datTS <- subset(dat,ts==timeStep[i] & ISEG==SEG[j] & IRCH==1)
> >     datGW <- subset(dat,ts==timeStep[i] & ISEG==SEG[j])
> >     grw <- aggregate(gw ~ iter, datGW, sum)
> >
> >     DC <- max(datTS$div)-min(datTS$div)
> >     GRW <- max(grw$gw) - min(grw$gw)
> >     divChng <- rbind(divChng,c(datTS$ts[1], SEG[j], DC, GRW,
> > max(datTS$iter)))
> >   }
> > }
> > divChng <- divChng[!is.na(divChng$ISEG),]
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From anindya55 at gmail.com  Mon Apr 13 10:44:00 2015
From: anindya55 at gmail.com (Anindya Sankar Dey)
Date: Mon, 13 Apr 2015 14:14:00 +0530
Subject: [R] plm returning less number of variable than provided as input
Message-ID: <CAKC+_z9kZDDJNB=1qUPL4GTb9qBtVouy3+nWd10k61v8+eDKhQ@mail.gmail.com>

Hi,

I was trying a plm  model with around 400 variables, but after passing that
 to the plm function I am getting coefficients for 265 variables.

Can anyone explain me the reason? Is there a size restriction in plm?

-- 
Anindya Sankar Dey

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Apr 13 10:21:12 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 13 Apr 2015 08:21:12 +0000
Subject: [R] Finding values in a dataframe at a specified hour
In-Reply-To: <CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
References: <CAHpsUFb3x_aCUssnzVm9Ws1yTvbi06CwZ8+DdwGOH8Y-_kBxGg@mail.gmail.com>
	<CAHpsUFY3VQvAk6gBSfAdNTYy1HkHqyFwXU3rrA0-o-To-cedUg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C26C2E@SRVEXCHMBX.precheza.cz>

Hi

I presume your data frames are not big. What about merging them by hour and comparing appropriate columns?

something like

windMerged<-merge(windHW, spring, by = "hour", all=TRUE)
sel <- which(windMerged[, xx] >= windMerged[,yy])
windMerged[sel, xx] <- NA

Untested because lack of data.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Alexandra Catena
> Sent: Friday, April 10, 2015 11:07 PM
> To: r-help at r-project.org
> Subject: Re: [R] Finding values in a dataframe at a specified hour
>
> Update:
>
> I have this so far.  * The first column of windHW is the wind speed.
> The 5th column of the dataframe, spring, is the 5*sigma value of every
> hour.  hourRow gives out all the rows of wind speed at a given hour.
>
> for (i in 0:23){
>   hourRow = which(windHW$hour==i,arr.ind=TRUE)
>   for (h in hourRow){
>     if (windHW[h,1]>=spring[spring$hour==i,5]){
>       windHW[h,1]<-NA}
>   }
> }
>
> This then gives the error: Error in if (windHW[h, 1] >=
> spring[spring$hour == i, 5]) { : argument is of length zero
>
> *Note: The dataframe for each of the seasons have 24 rows corresponding
> to each hour of the day 0:23.
>
> Thanks,
> Alexandra
>
>
> On Fri, Apr 10, 2015 at 1:07 PM, Alexandra Catena <amc5981 at gmail.com>
> wrote:
> > Hello,
> >
> > I have a large dataframe (windHW) of wind speeds (ws) at each hour
> > from many days over a set of years.  Some of these values are
> > obviously wrong (600 m/s) and I want to get rid of all the values
> that
> > are larger than 5*sigma for each hour.  The 5*sigma (variable name
> > sigma5) values are located in different dataframes for each season,
> > with each dataframe titled as a season.  For example, in the
> > dataframe, spring, the 5*sigma value is 79.6 m/s for hour 1.
> >
> > So my question is as follows: how can I get it so that the code will
> > be able to find all the wind speed values in the dataframe, windHW,
> of
> > a specific hour be higher than the 5*sigma value at that hour?
> > For example, I would like to find if any of the wind speed values at
> > hour 1 are higher than 79.6 m/s, and if so, then replace that value
> > with NA.
> >
> > I have something like this but I can't seem to figure out how to get
> > it for specific hours:
> >
> > windHW$ws[windHW$ws>=spring$sigma5] <- NA
> >
> > I imported the data using readLines and into the dataframe windHW.  I
> > also have R version 3.1.1
> >
> > Any help would be appreciated!
> >
> > Thanks,
> > Alexandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From icn at fct.unl.pt  Mon Apr 13 11:12:59 2015
From: icn at fct.unl.pt (Isabel Natario)
Date: Mon, 13 Apr 2015 10:12:59 +0100
Subject: [R] Finding which seed resulted in a specific sample
Message-ID: <CAG8FheOLABuPEFMBWZ5GakFUGrBgibdTJc2bDLi=5qXAsus6Uw@mail.gmail.com>

Hello!

I was wanting to find out which random seed could generate the characters
in the word "love", for example, when I sample with replacement from the
vector of the letters. So I've written the code below:

seed=0
set.seed=0
x<-sample(letters,4,replace=T)
while (sum(x==c("l","o","v","e"))<4){
seed<-seed+1
set.seed=seed
x<-sample(letters,4,replace=T)
}

When I run this code I always get that the final x vector is
c("l","o","v","e"), but afterwards, when I try to set.seed iqual to the
value stored in object "seed" I can never reproduce this vector
c("l","o","v","e"), by doing sample(letters,4,replace=T). Why is that?

Thank you very much,

Isabel Natario
--
Dep. Matem?tica
Faculdade de Ci?ncias e Tecnologia
Universidade Nova de Lisboa
2829-516 Caparica, Portugal
icn at fct.unl.pt

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Mon Apr 13 08:26:42 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Mon, 13 Apr 2015 08:26:42 +0200
Subject: [R] Obfuscate AES password
In-Reply-To: <B4E14CA2-9609-454E-B7B6-0202C98D7317@dcn.davis.CA.us>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
	<094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>
	<CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>
	<B4E14CA2-9609-454E-B7B6-0202C98D7317@dcn.davis.CA.us>
Message-ID: <CAFnz2-_yHGwhnMXZDNgD35-WiZiMmPXFyBkgbScFGgXYFaDSHw@mail.gmail.com>

Thanks Jeff,
and OK I'll move next questions on the topic to the devel list :)

I was hoping there were packages that already dealt with this sort of
things, that's why I posted my question here in the first place..

Thanks a lot for helping me with this,

Cheers,
Luca

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 13 12:12:38 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 13 Apr 2015 12:12:38 +0200
Subject: [R] Finding which seed resulted in a specific sample
In-Reply-To: <CAG8FheOLABuPEFMBWZ5GakFUGrBgibdTJc2bDLi=5qXAsus6Uw@mail.gmail.com>
References: <CAG8FheOLABuPEFMBWZ5GakFUGrBgibdTJc2bDLi=5qXAsus6Uw@mail.gmail.com>
Message-ID: <CAJuCY5yakmZ9CZGVeEFG_CH0BpsyBqS3bNmazNQVpu7dx2pT=Q@mail.gmail.com>

you need set.seed(seed) instead of set.seed = seed

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-13 11:12 GMT+02:00 Isabel Natario <icn at fct.unl.pt>:

> Hello!
>
> I was wanting to find out which random seed could generate the characters
> in the word "love", for example, when I sample with replacement from the
> vector of the letters. So I've written the code below:
>
> seed=0
> set.seed=0
> x<-sample(letters,4,replace=T)
> while (sum(x==c("l","o","v","e"))<4){
> seed<-seed+1
> set.seed=seed
> x<-sample(letters,4,replace=T)
> }
>
> When I run this code I always get that the final x vector is
> c("l","o","v","e"), but afterwards, when I try to set.seed iqual to the
> value stored in object "seed" I can never reproduce this vector
> c("l","o","v","e"), by doing sample(letters,4,replace=T). Why is that?
>
> Thank you very much,
>
> Isabel Natario
> --
> Dep. Matem?tica
> Faculdade de Ci?ncias e Tecnologia
> Universidade Nova de Lisboa
> 2829-516 Caparica, Portugal
> icn at fct.unl.pt
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Apr 13 12:25:17 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Apr 2015 11:25:17 +0100
Subject: [R] Finding which seed resulted in a specific sample
In-Reply-To: <CAG8FheOLABuPEFMBWZ5GakFUGrBgibdTJc2bDLi=5qXAsus6Uw@mail.gmail.com>
References: <CAG8FheOLABuPEFMBWZ5GakFUGrBgibdTJc2bDLi=5qXAsus6Uw@mail.gmail.com>
Message-ID: <552B998D.9060105@stats.ox.ac.uk>

On 13/04/2015 10:12, Isabel Natario wrote:
> Hello!
>
> I was wanting to find out which random seed could generate the characters
> in the word "love", for example, when I sample with replacement from the
> vector of the letters. So I've written the code below:
>
> seed=0
> set.seed=0
> x<-sample(letters,4,replace=T)
> while (sum(x==c("l","o","v","e"))<4){
> seed<-seed+1
> set.seed=seed
> x<-sample(letters,4,replace=T)
> }
>
> When I run this code I always get that the final x vector is
> c("l","o","v","e"), but afterwards, when I try to set.seed iqual to the
> value stored in object "seed" I can never reproduce this vector
> c("l","o","v","e"), by doing sample(letters,4,replace=T). Why is that?

Because you never called the function set.seed(): assigning to a 
variable of that name does not help.

Also, there are far more values of the underlying seed than can be set 
using set.seed(), so this approach will not always work.  However

seed <- 0L
set.seed(seed)
x <- sample(letters,4L,replace=T)
while (sum(x == c("l","o","v","e"))<4L){ # I would have used identical()
   seed <- seed+1L
   set.seed(seed)
   x <- sample(letters,4L,replace=T)
}
seed

gave me an answer (543867)


>
> Thank you very much,
>
> Isabel Natario
> --
> Dep. Matem?tica
> Faculdade de Ci?ncias e Tecnologia
> Universidade Nova de Lisboa
> 2829-516 Caparica, Portugal
> icn at fct.unl.pt



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From thanoon.younis80 at gmail.com  Mon Apr 13 12:43:50 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Mon, 13 Apr 2015 13:43:50 +0300
Subject: [R] problem in replication
Message-ID: <CABLo8nFP5wNXC8g8YuPFuwG_Yrwb45UTPQVumzZrmuh0EKStUQ@mail.gmail.com>

Hi
I have a small problem with my code in R. The problem is the replication of
simulation didn't work as a sequence from r=1 to 100 but the results stop
at 1 and when i close the first results with r=1 the second results run and
so on. i want to leave my computer to run until finish 100 replication In
chronological order.

Many thanks

-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Apr 13 14:22:47 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 07:22:47 -0500
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <268701.626368.1428681680813.JavaMail.yahoo@mail.yahoo.com>
References: <268701.626368.1428681680813.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCFB13GC2w_sv=oYS8TBRk0kuMz3hf52DNGoSi+hU4OkyQ@mail.gmail.com>

S,

There is no mention of a type="bca" argument on the ?confint help file.

You can look here for an example of using the boot.ci() function in the
boot package:

http://www.statmethods.net/advstats/bootstrapping.html

?Jean?


On Fri, Apr 10, 2015 at 11:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:

> Dear R-Experts,
>
> I am trying to compute the BCa nonparametric bootstrap on regression
> coefficients.
>
> Here is the reproducible example :
>
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> confint(fit, level=.95)
> confint.default(fit, level=.95)
> confint(fit,level=.95,type="bca")
>
> I am not sure but I think that I can not get the nonparametric BCa
> bootstrap with the confint function. As you can see, I have tried the
> argument type="bca", I don?t get any error message, but the results don?t
> change, the results are exactly the same as confint(fit,level=.95).
> As I have understood, the default argument uses normal quantiles and the
> method for linear models uses T-quantiles instead.
> So, I have checked the boot package and the boot.ci function to calculate
> the BCa bootstrap on the regression coefficients, but I don?t really
> understand how to compute the code.
> So, any help from you would be highly appreciated.
>
> Best,
> S
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Apr 13 14:24:04 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 07:24:04 -0500
Subject: [R] How to complete this code
In-Reply-To: <CANBmxoj1TX6sFRrSHZDmRSSULhz_Ytfit-o0CngiSFsHF5Jwyw@mail.gmail.com>
References: <CANBmxoj1TX6sFRrSHZDmRSSULhz_Ytfit-o0CngiSFsHF5Jwyw@mail.gmail.com>
Message-ID: <CAN5YmCFyE0T9b5vdAiPACeFwJ0Nq4pfcRD_D8ZP=E9QuEWME0A@mail.gmail.com>

You will likely get more help answering your question if you provide
reproducible code of a simple example of your situation.

Jean

On Fri, Apr 10, 2015 at 3:42 PM, Mahdiyeh Erfaniyan <
mahdiyeh.erfaniyan at gmail.com> wrote:

> Hi,
>
>
> Consider the line below:
>
>
>
> for(r in a)for (s in a) x=rbind(x,apply(replicate(1000,V(r,s)),1,mean))
>
>
>
> V is a vector of (n-1) variables calculated by some rule and is a functions
> of (r,s).  So the line above produces 1000 replicates of V for each (r,s),
> puts them in a matrix, calculates the mean of them, and finally puts the
> means for all (r,s) in a matrix. So the produced matrix, x, is the mean of
> (n-1) V 's for each possible value of (r,s) in each row. Now for simplicity
> fix (r,s) in just one point and let n=5. So in each replicate we have only
> one V which is a vector consisted of 4 variables. Name the elements of V as
> U1, U2, U3 and U4. Then we can let
>
> V(i) = [U1i , U2i , U3i , U4i]
>
>
>
> which shows each row of V produced per replicate (i=1,2,...,1000).
> Therefore we can say
>
>
>
> x=[x1 , x2 , x3 , x4]
>
>
>
> which is the vector of means calculated at the end. Now what I need is to
> first calculate the vector below per replicate (i=1,...,1000):
>
>
>
> Er(i) = [ |Ui1-x1| , |Ui2-x2| , |Ui3-x3| , |Ui4-x4| ]
>
>
>
> where |A| shows the absolute value of A. Then I should calculate mean of
> Er(i) 's and put the result in a vector. I just don't know how I can
> calculate Er(i) 's in the given line above. On the other words, I don't
> know where I should add the required code in the given line. Thanks for any
> help in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From searl at vt.edu  Mon Apr 13 00:30:03 2015
From: searl at vt.edu (Steve E.)
Date: Sun, 12 Apr 2015 15:30:03 -0700 (PDT)
Subject: [R] operations on columns when data frames are in a list
Message-ID: <1428877803398-4705757.post@n4.nabble.com>

Hello R folks,

I have recently discovered the power of working with multiple data frames in
lists. However, I am having trouble understanding how to perform operations
on individual columns of data frames in the list. For example, I have a
water quality data set (sample data included below) that consists of roughly
a dozen data frames. Some of the data frames have a chr column called
'Month' that I need to to convert to a date with the proper format. I would
like to iterate through all of the data frames in the list and format all of
those that have the 'Month' column. I can accomplish this with a for-loop
(e.g., below) but I cannot figure out how to do this with the plyr or apply
families. This is just one example of the formatting that I have to perform
so I would really like to avoid loops, and I would love to learn how to
better work with lists as well.

I would appreciate greatly any guidance.


Thank you and regards,
Stevan


a for-loop like this works, but is not an ideal solution:

for (i in 1:length(data)) {if ("Month" %in% names(data[[i]]))
data[[i]]$Month<- as.POSIXct(data[[i]]$Month, format="%Y/%m/%d")}



sample data (head of two data frames from the list of all data frames):

structure(list(`3D_Fluorescence.csv` = structure(list(ID = 1:6, 
    Site_Number = c("R5", "R6a", "R8", "R9a", "R14", "R15"), 
    Month = c("2001/10/01", "2001/10/01", "2001/10/01", "2001/10/01", 
    "2001/10/01", "2001/10/01"), Exc_A = c(215L, 215L, NA, NA, 
    215L, 215L), Em_A = c(422.5, 410.5, NA, NA, 408.5, 408), 
    Fl_A = c(303, 296.86, NA, NA, 297.62, 174.75), Exc_B = c(325L, 
    325L, NA, NA, 325L, 325L), Em_B = c(416, 413, NA, NA, 418.5, 
    417.5), Fl_B = c(137.32, 116.1, NA, NA, 132.48, 77.44)), .Names =
c("ID", 
"Site_Number", "Month", "Exc_A", "Em_A", "Fl_A", "Exc_B", "Em_B", 
"Fl_B"), row.names = c(NA, 6L), class = "data.frame"), algae.csv =
structure(list(
    ID = 1:6, SiteNumber = c("R1", "R2A", "R2B", "R3", "R4", 
    "R5"), SiteLocation = c("CAP canal above Waddell Canal", 
    "Lake Pleasant integrated sample", "Lake Pleasant integrated sample", 
    "Waddell Canal", "Cap Canal at 7th St.", "Verde River btwn Horseshoe and
Bartlett"
    ), ClusterName = c("cap", "cap", "cap", "cap", "cap", "verde"
    ), SiteAcronym = c("cap-siphon", "pleasant-epi", "pleasant-hypo", 
    "waddell canal", "cap @ 7th st", "verde abv bartlett"), Date =
c("1999/08/18", 
    "1999/08/18", "1999/08/18", "1999/08/18", "1999/08/18", "1999/08/16"
    ), Month = c("1999/08/01", "1999/08/01", "1999/08/01", "1999/08/01", 
    "1999/08/01", "1999/08/01"), SampleType = c("", "", "", "", 
    "", ""), Conductance = c(800, 890, 850, 870, 830, 500), ChlA = c(0.3, 
    0.3, 0.6, 0.8, 1.1, 7.6), Phaeophytin = c(0, 0, 0, 0, 0.7, 
    4.7), PhaeophytinChlA = c(0.7, 0.7, 1.3, 5.3, 0.7, 4.7), 
    Chlorophyta = c(0L, 0L, 18L, 0L, 0L, 21L), Cyanophyta = c(8L, 
    0L, 0L, 0L, 7L, 79L), Bacillariophyta = c(135L, 76L, 0L, 
    18L, 54L, 195L), Total = c(147L, 76L, 18L, 18L, 61L, 302L
    ), AlgaeComments = c("", "", "", "", "", "")), .Names = c("ID", 
"SiteNumber", "SiteLocation", "ClusterName", "SiteAcronym", "Date", 
"Month", "SampleType", "Conductance", "ChlA", "Phaeophytin", 
"PhaeophytinChlA", "Chlorophyta", "Cyanophyta", "Bacillariophyta", 
"Total", "AlgaeComments"), row.names = c(NA, 6L), class = "data.frame")),
.Names = c("3D_Fluorescence.csv", 
"algae.csv")) 



--
View this message in context: http://r.789695.n4.nabble.com/operations-on-columns-when-data-frames-are-in-a-list-tp4705757.html
Sent from the R help mailing list archive at Nabble.com.


From rsm at agrisk.in  Mon Apr 13 12:11:03 2015
From: rsm at agrisk.in (ravimantha)
Date: Mon, 13 Apr 2015 03:11:03 -0700 (PDT)
Subject: [R] mutiple data sets
Message-ID: <1428919863923-4705763.post@n4.nabble.com>

Hi just started in R, this is the first time.

I have one Y & Multiple X variables.
was trying to do Correlation, managed it using cov( Y,X)
unable to plot the above.

further since the data sets is very large of about 20 years * 30 variables, 
end objective is to build a forecasting model Y.
have managed to do this , using excel, but its maddness, so thought will use
R.

Your help will be much appreciated please.







--
View this message in context: http://r.789695.n4.nabble.com/mutiple-data-sets-tp4705763.html
Sent from the R help mailing list archive at Nabble.com.


From jvadams at usgs.gov  Mon Apr 13 14:44:21 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 07:44:21 -0500
Subject: [R] problem in replication
In-Reply-To: <CABLo8nFP5wNXC8g8YuPFuwG_Yrwb45UTPQVumzZrmuh0EKStUQ@mail.gmail.com>
References: <CABLo8nFP5wNXC8g8YuPFuwG_Yrwb45UTPQVumzZrmuh0EKStUQ@mail.gmail.com>
Message-ID: <CAN5YmCE-iyzLMUVqO1K1Oax-YCM9k4GoqVsvyoL+UXjMQqtc+w@mail.gmail.com>

Why did you submit this post?
Are you asking for help with something?
Reporting an update on an earlier post?

Jean

On Mon, Apr 13, 2015 at 5:43 AM, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Hi
> I have a small problem with my code in R. The problem is the replication of
> simulation didn't work as a sequence from r=1 to 100 but the results stop
> at 1 and when i close the first results with r=1 the second results run and
> so on. i want to leave my computer to run until finish 100 replication In
> chronological order.
>
> Many thanks
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Apr 13 14:51:52 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 07:51:52 -0500
Subject: [R] operations on columns when data frames are in a list
In-Reply-To: <1428877803398-4705757.post@n4.nabble.com>
References: <1428877803398-4705757.post@n4.nabble.com>
Message-ID: <CAN5YmCHhkVwLSxCT-zmbw4+1FKKzZxDXf--dqrZHZFVvjYKLhA@mail.gmail.com>

If you write a function that takes a data frame as an argument and returns
a data frame, you can use lapply to carry out the tasks that you want.  For
example, if your list of data frames is called mydat ...

mon2date <- function(df) {
  if ("Month" %in% names(df)) {
    df$Month<- as.POSIXct(df$Month, format="%Y/%m/%d")
  }
  return(df)
}

mydat2 <- lapply(mydat, mon2date)

Jean

On Sun, Apr 12, 2015 at 5:30 PM, Steve E. <searl at vt.edu> wrote:

> Hello R folks,
>
> I have recently discovered the power of working with multiple data frames
> in
> lists. However, I am having trouble understanding how to perform operations
> on individual columns of data frames in the list. For example, I have a
> water quality data set (sample data included below) that consists of
> roughly
> a dozen data frames. Some of the data frames have a chr column called
> 'Month' that I need to to convert to a date with the proper format. I would
> like to iterate through all of the data frames in the list and format all
> of
> those that have the 'Month' column. I can accomplish this with a for-loop
> (e.g., below) but I cannot figure out how to do this with the plyr or apply
> families. This is just one example of the formatting that I have to perform
> so I would really like to avoid loops, and I would love to learn how to
> better work with lists as well.
>
> I would appreciate greatly any guidance.
>
>
> Thank you and regards,
> Stevan
>
>
> a for-loop like this works, but is not an ideal solution:
>
> for (i in 1:length(data)) {if ("Month" %in% names(data[[i]]))
> data[[i]]$Month<- as.POSIXct(data[[i]]$Month, format="%Y/%m/%d")}
>
>
>
> sample data (head of two data frames from the list of all data frames):
>
> structure(list(`3D_Fluorescence.csv` = structure(list(ID = 1:6,
>     Site_Number = c("R5", "R6a", "R8", "R9a", "R14", "R15"),
>     Month = c("2001/10/01", "2001/10/01", "2001/10/01", "2001/10/01",
>     "2001/10/01", "2001/10/01"), Exc_A = c(215L, 215L, NA, NA,
>     215L, 215L), Em_A = c(422.5, 410.5, NA, NA, 408.5, 408),
>     Fl_A = c(303, 296.86, NA, NA, 297.62, 174.75), Exc_B = c(325L,
>     325L, NA, NA, 325L, 325L), Em_B = c(416, 413, NA, NA, 418.5,
>     417.5), Fl_B = c(137.32, 116.1, NA, NA, 132.48, 77.44)), .Names =
> c("ID",
> "Site_Number", "Month", "Exc_A", "Em_A", "Fl_A", "Exc_B", "Em_B",
> "Fl_B"), row.names = c(NA, 6L), class = "data.frame"), algae.csv =
> structure(list(
>     ID = 1:6, SiteNumber = c("R1", "R2A", "R2B", "R3", "R4",
>     "R5"), SiteLocation = c("CAP canal above Waddell Canal",
>     "Lake Pleasant integrated sample", "Lake Pleasant integrated sample",
>     "Waddell Canal", "Cap Canal at 7th St.", "Verde River btwn Horseshoe
> and
> Bartlett"
>     ), ClusterName = c("cap", "cap", "cap", "cap", "cap", "verde"
>     ), SiteAcronym = c("cap-siphon", "pleasant-epi", "pleasant-hypo",
>     "waddell canal", "cap @ 7th st", "verde abv bartlett"), Date =
> c("1999/08/18",
>     "1999/08/18", "1999/08/18", "1999/08/18", "1999/08/18", "1999/08/16"
>     ), Month = c("1999/08/01", "1999/08/01", "1999/08/01", "1999/08/01",
>     "1999/08/01", "1999/08/01"), SampleType = c("", "", "", "",
>     "", ""), Conductance = c(800, 890, 850, 870, 830, 500), ChlA = c(0.3,
>     0.3, 0.6, 0.8, 1.1, 7.6), Phaeophytin = c(0, 0, 0, 0, 0.7,
>     4.7), PhaeophytinChlA = c(0.7, 0.7, 1.3, 5.3, 0.7, 4.7),
>     Chlorophyta = c(0L, 0L, 18L, 0L, 0L, 21L), Cyanophyta = c(8L,
>     0L, 0L, 0L, 7L, 79L), Bacillariophyta = c(135L, 76L, 0L,
>     18L, 54L, 195L), Total = c(147L, 76L, 18L, 18L, 61L, 302L
>     ), AlgaeComments = c("", "", "", "", "", "")), .Names = c("ID",
> "SiteNumber", "SiteLocation", "ClusterName", "SiteAcronym", "Date",
> "Month", "SampleType", "Conductance", "ChlA", "Phaeophytin",
> "PhaeophytinChlA", "Chlorophyta", "Cyanophyta", "Bacillariophyta",
> "Total", "AlgaeComments"), row.names = c(NA, 6L), class = "data.frame")),
> .Names = c("3D_Fluorescence.csv",
> "algae.csv"))
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/operations-on-columns-when-data-frames-are-in-a-list-tp4705757.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Apr 13 14:54:37 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 07:54:37 -0500
Subject: [R] mutiple data sets
In-Reply-To: <1428919863923-4705763.post@n4.nabble.com>
References: <1428919863923-4705763.post@n4.nabble.com>
Message-ID: <CAN5YmCHoxSmJue3D=D-1EbiiAy1QqT9oZjSjMut7VmBeOdbdOA@mail.gmail.com>

There are some examples of how to plot correlation matrices at this link.

http://stackoverflow.com/questions/5453336/plot-correlation-matrix-into-a-graph/26637268#26637268

Perhaps that will help get you started.

Jean

On Mon, Apr 13, 2015 at 5:11 AM, ravimantha <rsm at agrisk.in> wrote:

> Hi just started in R, this is the first time.
>
> I have one Y & Multiple X variables.
> was trying to do Correlation, managed it using cov( Y,X)
> unable to plot the above.
>
> further since the data sets is very large of about 20 years * 30 variables,
> end objective is to build a forecasting model Y.
> have managed to do this , using excel, but its maddness, so thought will
> use
> R.
>
> Your help will be much appreciated please.
>
>
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/mutiple-data-sets-tp4705763.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Mon Apr 13 15:38:45 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 13 Apr 2015 13:38:45 +0000 (UTC)
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <CAN5YmCFB13GC2w_sv=oYS8TBRk0kuMz3hf52DNGoSi+hU4OkyQ@mail.gmail.com>
References: <CAN5YmCFB13GC2w_sv=oYS8TBRk0kuMz3hf52DNGoSi+hU4OkyQ@mail.gmail.com>
Message-ID: <371393864.1766487.1428932325273.JavaMail.yahoo@mail.yahoo.com>

Hi Jean,

Many thanks, I got it but there is still a problem. When trying to bootstrap the confidence intervals, I get these messages. 
 

boot.ci(results,type="bca",index=1) 
[1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
NULL
> boot.ci(results,type="bca",index=2) 
[1] "All values of t are equal to  0.618293471234648 \n Cannot calculate confidence intervals"
NULL
> boot.ci(results,type="bca",index=3)
[1] "All values of t are equal to  0.148068842921784 \n Cannot calculate confidence intervals"
NULL


Here is the reproducible example :

GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)  
Quality.score <-c(12,11,13,14,15,16,12,10,9,9) 
Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score) 
install.packages("boot") 
library(boot) 
bs=function(formula,data,indices){ 
d=data[indices,] 
fit=lm(formula,data=Dataset) 
return(coef(fit)) 
} 
results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score) 
boot.ci(results,type="bca",index=1) 
boot.ci(results,type="bca",index=2) 
boot.ci(results,type="bca",index=3) 

How to solve that problem ?

Best,
S.



________________________________
De : "Adams, Jean" <jvadams at usgs.gov>

Cc : "r-help at r-project.org" <r-help at r-project.org> 
Envoy? le : Lundi 13 avril 2015 14h22
Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)



S,

There is no mention of a type="bca" argument on the ?confint help file.

You can look here for an example of using the boot.ci() function in the boot package: 
http://www.statmethods.net/advstats/bootstrapping.html
>
>?Jean?







Dear R-Experts,
>
>I am trying to compute the BCa nonparametric bootstrap on regression coefficients.
>
>Here is the reproducible example :
>
>GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
>Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
>Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
>fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
>confint(fit, level=.95)
>confint.default(fit, level=.95)
>confint(fit,level=.95,type="bca")
>
>I am not sure but I think that I can not get the nonparametric BCa bootstrap with the confint function. As you can see, I have tried the argument type="bca", I don?t get any error message, but the results don?t change, the results are exactly the same as confint(fit,level=.95).
>As I have understood, the default argument uses normal quantiles and the method for linear models uses T-quantiles instead.
>So, I have checked the boot package and the boot.ci function to calculate the BCa bootstrap on the regression coefficients, but I don?t really understand how to compute the code.
>So, any help from you would be highly appreciated.
>
>Best,
>S
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Apr 13 15:07:56 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 13 Apr 2015 08:07:56 -0500
Subject: [R] mutiple data sets
In-Reply-To: <552BBE74.2040706@agrisk.in>
References: <1428919863923-4705763.post@n4.nabble.com>
	<CAN5YmCHoxSmJue3D=D-1EbiiAy1QqT9oZjSjMut7VmBeOdbdOA@mail.gmail.com>
	<552BBE74.2040706@agrisk.in>
Message-ID: <CAN5YmCHL2x68uWLd_GgpZcnxmwV84JaCPQ_iqPtAZP0JBeF3jg@mail.gmail.com>

You should cc r-help in your reply to keep everyone in the loop.

Jean

On Mon, Apr 13, 2015 at 8:02 AM, rsm <rsm at agrisk.in> wrote:

>  Hi Jean
> Truly appreciate your guidance.
> honestly, finding it bit challenging to plot.
> before plotting.
> i have some basic q.
> have multiple data sets spanning over 15 years of One Y , the Independent,
> X about 30 dependent variables.
> am trying to build a forecasting program for Y , given changes in X.
> any thoughts, or documents that can help me do this step by step.
> am going thru the videows and documents, but not getting hang of managing
> the panel data concept.
>
> Thank you very much
>
> Regards
>
> Ravishankar Mantha
>
>
> On 4/13/2015 6:24 PM, Adams, Jean wrote:
>
>  There are some examples of how to plot correlation matrices at this
> link.
>
>
> http://stackoverflow.com/questions/5453336/plot-correlation-matrix-into-a-graph/26637268#26637268
>
> Perhaps that will help get you started.
>
>  Jean
>
> On Mon, Apr 13, 2015 at 5:11 AM, ravimantha <rsm at agrisk.in> wrote:
>
>> Hi just started in R, this is the first time.
>>
>> I have one Y & Multiple X variables.
>> was trying to do Correlation, managed it using cov( Y,X)
>> unable to plot the above.
>>
>> further since the data sets is very large of about 20 years * 30
>> variables,
>> end objective is to build a forecasting model Y.
>> have managed to do this , using excel, but its maddness, so thought will
>> use
>> R.
>>
>> Your help will be much appreciated please.
>>
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/mutiple-data-sets-tp4705763.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From rsm at agrisk.in  Mon Apr 13 15:10:12 2015
From: rsm at agrisk.in (rsm)
Date: Mon, 13 Apr 2015 18:40:12 +0530
Subject: [R] mutiple data sets
In-Reply-To: <CAN5YmCHL2x68uWLd_GgpZcnxmwV84JaCPQ_iqPtAZP0JBeF3jg@mail.gmail.com>
References: <1428919863923-4705763.post@n4.nabble.com>
	<CAN5YmCHoxSmJue3D=D-1EbiiAy1QqT9oZjSjMut7VmBeOdbdOA@mail.gmail.com>
	<552BBE74.2040706@agrisk.in>
	<CAN5YmCHL2x68uWLd_GgpZcnxmwV84JaCPQ_iqPtAZP0JBeF3jg@mail.gmail.com>
Message-ID: <552BC034.6040006@agrisk.in>

Hi

Truly appreciate your guidance.
honestly, finding it bit challenging to plot.
before plotting.
i have some basic q.

have multiple data sets spanning over 15 years of One Y , the 
Independent, X about 30 dependent variables.
am trying to build a forecasting program for Y , given changes in X.
any thoughts, or documents that can help me do this step by step.
am going thru the videos and documents, but not getting hang of managing 
the panel data concept to build the model

Thank you very much

Regards

Ravishankar Mantha

On 4/13/2015 6:37 PM, Adams, Jean wrote:
> You should cc r-help in your reply to keep everyone in the loop.
>
> Jean
>
> On Mon, Apr 13, 2015 at 8:02 AM, rsm <rsm at agrisk.in 
> <mailto:rsm at agrisk.in>> wrote:
>
>     Hi Jean
>     Truly appreciate your guidance.
>     honestly, finding it bit challenging to plot.
>     before plotting.
>     i have some basic q.
>     have multiple data sets spanning over 15 years of One Y , the
>     Independent, X about 30 dependent variables.
>     am trying to build a forecasting program for Y , given changes in X.
>     any thoughts, or documents that can help me do this step by step.
>     am going thru the videows and documents, but not getting hang of
>     managing the panel data concept.
>
>     Thank you very much
>
>     Regards
>
>     Ravishankar Mantha
>
>     On 4/13/2015 6:24 PM, Adams, Jean wrote:
>>     There are some examples of how to plot correlation matrices at
>>     this link.
>>
>>         http://stackoverflow.com/questions/5453336/plot-correlation-matrix-into-a-graph/26637268#26637268
>>
>>     Perhaps that will help get you started.
>>
>>     Jean
>>
>>     On Mon, Apr 13, 2015 at 5:11 AM, ravimantha <rsm at agrisk.in
>>     <mailto:rsm at agrisk.in>> wrote:
>>
>>         Hi just started in R, this is the first time.
>>
>>         I have one Y & Multiple X variables.
>>         was trying to do Correlation, managed it using cov( Y,X)
>>         unable to plot the above.
>>
>>         further since the data sets is very large of about 20 years *
>>         30 variables,
>>         end objective is to build a forecasting model Y.
>>         have managed to do this , using excel, but its maddness, so
>>         thought will use
>>         R.
>>
>>         Your help will be much appreciated please.
>>
>>
>>
>>
>>
>>
>>
>>         --
>>         View this message in context:
>>         http://r.789695.n4.nabble.com/mutiple-data-sets-tp4705763.html
>>         Sent from the R help mailing list archive at Nabble.com.
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>
>>
>
>


	[[alternative HTML version deleted]]


From sarada at greenhorizon.in  Mon Apr 13 15:33:19 2015
From: sarada at greenhorizon.in (Sarada Samantaray)
Date: Mon, 13 Apr 2015 06:33:19 -0700
Subject: [R] R (3.1.2) sub-setting code related to "NA" on Windows not
	working!
Message-ID: <SNT147-W86730D67197E8A996F6CB9A4E70@phx.gbl>

My AirQuality[4,1] is equal to 18 and AirQuality[5,1] is equal to NA.
When I type the following
> is.na(AirQuality[5,1])[1] FALSE> AirQuality[5,1][1] NA68 Levels: 1 10 108 11 110 115 118 12 122 13 135 ... NA> is.na(AirQuality[4,1])[1] FALSE> AirQuality[4,1][1] 1868 Levels: 1 10 108 11 110 115 118 12 122 13 135 ... NA> 
For is.na(AirQuality[5,1]) I am expecting a TRUE (but False is the output from R). Can you please help. Or Let me know what I am doing wrong!
RegardsSarada 		 	   		  
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Apr 13 16:00:29 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 13 Apr 2015 15:00:29 +0100
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <371393864.1766487.1428932325273.JavaMail.yahoo@mail.yahoo.com>
References: <CAN5YmCFB13GC2w_sv=oYS8TBRk0kuMz3hf52DNGoSi+hU4OkyQ@mail.gmail.com>
	<371393864.1766487.1428932325273.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <552BCBFD.70102@dewey.myzen.co.uk>

See in line

On 13/04/2015 14:38, varin sacha wrote:
> Hi Jean,
>
> Many thanks, I got it but there is still a problem. When trying to bootstrap the confidence intervals, I get these messages.
>
>
> boot.ci(results,type="bca",index=1)
> [1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
> NULL
>> boot.ci(results,type="bca",index=2)
> [1] "All values of t are equal to  0.618293471234648 \n Cannot calculate confidence intervals"
> NULL
>> boot.ci(results,type="bca",index=3)
> [1] "All values of t are equal to  0.148068842921784 \n Cannot calculate confidence intervals"
> NULL
>
>
> Here is the reproducible example :
>
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)

Did you mean at this point to put these into a data frame?

> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
> d=data[indices,]
> fit=lm(formula,data=Dataset)

In the code you sent there does not seem to be an object called Dataset.
Did you mean data = d?

> return(coef(fit))

You do not need to say return( ) at the end, just coef(fit) would work.

> }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
> boot.ci(results,type="bca",index=1)
> boot.ci(results,type="bca",index=2)
> boot.ci(results,type="bca",index=3)
>
> How to solve that problem ?
>
> Best,
> S.
>
>
>
> ________________________________
> De : "Adams, Jean" <jvadams at usgs.gov>
>
> Cc : "r-help at r-project.org" <r-help at r-project.org>
> Envoy? le : Lundi 13 avril 2015 14h22
> Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)
>
>
>
> S,
>
> There is no mention of a type="bca" argument on the ?confint help file.
>
> You can look here for an example of using the boot.ci() function in the boot package:
> http://www.statmethods.net/advstats/bootstrapping.html
>>
>> ?Jean?
>
>
>
>
>
>
>
> Dear R-Experts,
>>
>> I am trying to compute the BCa nonparametric bootstrap on regression coefficients.
>>
>> Here is the reproducible example :
>>
>> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
>> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
>> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
>> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
>> confint(fit, level=.95)
>> confint.default(fit, level=.95)
>> confint(fit,level=.95,type="bca")
>>
>> I am not sure but I think that I can not get the nonparametric BCa bootstrap with the confint function. As you can see, I have tried the argument type="bca", I don?t get any error message, but the results don?t change, the results are exactly the same as confint(fit,level=.95).
>> As I have understood, the default argument uses normal quantiles and the method for linear models uses T-quantiles instead.
>> So, I have checked the boot package and the boot.ci function to calculate the BCa bootstrap on the regression coefficients, but I don?t really understand how to compute the code.
>> So, any help from you would be highly appreciated.
>>
>> Best,
>> S
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From boris.steipe at utoronto.ca  Mon Apr 13 16:42:57 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 13 Apr 2015 10:42:57 -0400
Subject: [R] mutiple data sets
In-Reply-To: <552BC034.6040006@agrisk.in>
References: <1428919863923-4705763.post@n4.nabble.com>
	<CAN5YmCHoxSmJue3D=D-1EbiiAy1QqT9oZjSjMut7VmBeOdbdOA@mail.gmail.com>
	<552BBE74.2040706@agrisk.in>
	<CAN5YmCHL2x68uWLd_GgpZcnxmwV84JaCPQ_iqPtAZP0JBeF3jg@mail.gmail.com>
	<552BC034.6040006@agrisk.in>
Message-ID: <EAF42B64-3131-4089-9105-36A08156E4E7@utoronto.ca>

Jean gave you an excellent pointer for your original question.
To continue - 

- break down your task into small steps
- implement your steps piece by piece
- actually read (and follow) the posting guide for this list (http://www.R-project.org/posting-guide.html)
- see here for some additional hints on how to ask questions so that we can actually help.
    https://github.com/hadley/devtools/wiki/Reproducibility 
    http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Cheers,
B.



On Apr 13, 2015, at 9:10 AM, rsm <rsm at agrisk.in> wrote:

> Hi
> 
> Truly appreciate your guidance.
> honestly, finding it bit challenging to plot.
> before plotting.
> i have some basic q.
> 
> have multiple data sets spanning over 15 years of One Y , the 
> Independent, X about 30 dependent variables.
> am trying to build a forecasting program for Y , given changes in X.
> any thoughts, or documents that can help me do this step by step.
> am going thru the videos and documents, but not getting hang of managing 
> the panel data concept to build the model
> 
> Thank you very much
> 
> Regards
> 
> Ravishankar Mantha
> 
> On 4/13/2015 6:37 PM, Adams, Jean wrote:
>> You should cc r-help in your reply to keep everyone in the loop.
>> 
>> Jean
>> 
>> On Mon, Apr 13, 2015 at 8:02 AM, rsm <rsm at agrisk.in 
>> <mailto:rsm at agrisk.in>> wrote:
>> 
>>    Hi Jean
>>    Truly appreciate your guidance.
>>    honestly, finding it bit challenging to plot.
>>    before plotting.
>>    i have some basic q.
>>    have multiple data sets spanning over 15 years of One Y , the
>>    Independent, X about 30 dependent variables.
>>    am trying to build a forecasting program for Y , given changes in X.
>>    any thoughts, or documents that can help me do this step by step.
>>    am going thru the videows and documents, but not getting hang of
>>    managing the panel data concept.
>> 
>>    Thank you very much
>> 
>>    Regards
>> 
>>    Ravishankar Mantha
>> 
>>    On 4/13/2015 6:24 PM, Adams, Jean wrote:
>>>    There are some examples of how to plot correlation matrices at
>>>    this link.
>>> 
>>>        http://stackoverflow.com/questions/5453336/plot-correlation-matrix-into-a-graph/26637268#26637268
>>> 
>>>    Perhaps that will help get you started.
>>> 
>>>    Jean
>>> 
>>>    On Mon, Apr 13, 2015 at 5:11 AM, ravimantha <rsm at agrisk.in
>>>    <mailto:rsm at agrisk.in>> wrote:
>>> 
>>>        Hi just started in R, this is the first time.
>>> 
>>>        I have one Y & Multiple X variables.
>>>        was trying to do Correlation, managed it using cov( Y,X)
>>>        unable to plot the above.
>>> 
>>>        further since the data sets is very large of about 20 years *
>>>        30 variables,
>>>        end objective is to build a forecasting model Y.
>>>        have managed to do this , using excel, but its maddness, so
>>>        thought will use
>>>        R.
>>> 
>>>        Your help will be much appreciated please.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>        --
>>>        View this message in context:
>>>        http://r.789695.n4.nabble.com/mutiple-data-sets-tp4705763.html
>>>        Sent from the R help mailing list archive at Nabble.com.
>>> 
>>>        ______________________________________________
>>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>        list -- To UNSUBSCRIBE and more, see
>>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>>        PLEASE do read the posting guide
>>>        http://www.R-project.org/posting-guide.html
>>>        and provide commented, minimal, self-contained, reproducible
>>>        code.
>>> 
>>> 
>> 
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alej.c.s at gmail.com  Mon Apr 13 17:28:32 2015
From: alej.c.s at gmail.com (Alejo C.S.)
Date: Mon, 13 Apr 2015 12:28:32 -0300
Subject: [R] Convert color hex code to color names
Message-ID: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>

Hi all, I want to convert the output of:

> rainbow(6)

> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
"#FF00FFFF"

To a vector of color names. Any tip?


Thanks in advance

C.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Apr 13 17:32:10 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 13 Apr 2015 17:32:10 +0200
Subject: [R] R (3.1.2) sub-setting code related to "NA" on Windows not
	working!
In-Reply-To: <SNT147-W86730D67197E8A996F6CB9A4E70@phx.gbl>
References: <SNT147-W86730D67197E8A996F6CB9A4E70@phx.gbl>
Message-ID: <6EF232F1-5DD2-4D98-A840-E36028321822@gmail.com>

This is almost unreadable due to HTML posting (do read the posting guide!). However, it would seem that you somehow got your data converted to factors of which one level is NA. 

This may be surprising, but the difference is like that of

> factor(c("NA", 18))
[1] NA 18
Levels: 18 NA
> factor(c("NA", 18), exclude="NA")
[1] <NA> 18  
Levels: 18

Notice that NA can be a real factor level, for instance abbreviating "North America" or "Noradrenaline".

It is fairly easy to generate this situation during data input, e.g.

> read.table(text="
+ NA
+ 18", na.strings="")$V1
[1] NA 18
Levels: 18 NA
 
-pd

On 13 Apr 2015, at 15:33 , Sarada Samantaray <sarada at greenhorizon.in> wrote:

> My AirQuality[4,1] is equal to 18 and AirQuality[5,1] is equal to NA.
> When I type the following
>> is.na(AirQuality[5,1])[1] FALSE> AirQuality[5,1][1] NA68 Levels: 1 10 108 11 110 115 118 12 122 13 135 ... NA> is.na(AirQuality[4,1])[1] FALSE> AirQuality[4,1][1] 1868 Levels: 1 10 108 11 110 115 118 12 122 13 135 ... NA> 
> For is.na(AirQuality[5,1]) I am expecting a TRUE (but False is the output from R). Can you please help. Or Let me know what I am doing wrong!
> RegardsSarada 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Mon Apr 13 17:43:24 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 13 Apr 2015 07:43:24 -0800
Subject: [R] R (3.1.2) sub-setting code related to "NA" on Windows not
 working!
In-Reply-To: <SNT147-W86730D67197E8A996F6CB9A4E70@phx.gbl>
Message-ID: <3D4A8461331.00000656jrkrideau@inbox.com>


Below is what your code looked like in R-helpl.

I looked at it for about 5 seconds and said, "If the poster cannot understand something as simple as "DO NOT post in HTML" it's not worth my time to decypher the mess. 

You are lucky Peter is more tolerant.

Please do not post in HTML.

#### code as it appears in R-help
My AirQuality[4,1] is equal to 18 and AirQuality[5,1] is equal to NA. When I type the following > is.na(AirQuality[5,1])[1] FALSE> AirQuality[5,1][1] NA68 Levels: 1 10 108 11 110 115 118 > 12 122 13 135 ... NA> is.na(AirQuality[4,1])[1] FALSE> AirQuality[4,1][1] 1868 Levels: 1 > 10 108 11 110 115 118 12 122 13 135 ... NA>
####============


John Kane
Kingston ON Canada


> -----Original Message-----
> From: sarada at greenhorizon.in
> Sent: Mon, 13 Apr 2015 06:33:19 -0700
> To: r-help at r-project.org
> Subject: [R] R (3.1.2) sub-setting code related to "NA" on Windows not
> working!
> 
> My AirQuality[4,1] is equal to 18 and AirQuality[5,1] is equal to NA.
> When I type the following
>> is.na(AirQuality[5,1])[1] FALSE> AirQuality[5,1][1] NA68 Levels: 1 10
>> 108 11 110 115 118 12 122 13 135 ... NA> is.na(AirQuality[4,1])[1]
>> FALSE> AirQuality[4,1][1] 1868 Levels: 1 10 108 11 110 115 118 12 122 13
>> 135 ... NA>
> For is.na(AirQuality[5,1]) I am expecting a TRUE (but False is the output
> from R). Can you please help. Or Let me know what I am doing wrong!
> RegardsSarada
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From thierry.onkelinx at inbo.be  Mon Apr 13 17:45:03 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 13 Apr 2015 17:45:03 +0200
Subject: [R] Convert color hex code to color names
In-Reply-To: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
Message-ID: <CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>

A combination of rgb(), col2rgb() and colors() can gives hex values for the
named colors.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:

> Hi all, I want to convert the output of:
>
> > rainbow(6)
>
> > [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
> "#FF00FFFF"
>
> To a vector of color names. Any tip?
>
>
> Thanks in advance
>
> C.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From david at revolutionanalytics.com  Mon Apr 13 17:48:29 2015
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 13 Apr 2015 10:48:29 -0500
Subject: [R] Revolutions blog: March 2015 roundup
Message-ID: <CABgvEC_7J==C-xhnvF0VZtgvCin3bnP0SQPeitm2C_dpPbEbYw@mail.gmail.com>

Since 2008, Revolution Analytics staff and guests have written about R
every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

(By the way, Revolution Analytics is now officially part of Microsoft,
and the blog will continue. More details at http://bit.ly/1IFZBuo .)

In case you missed them, here are some articles related to R from the
month of March:

Overview of "Targeted learning" packages for R, including SuperLearner
and tmle: http://bit.ly/1IFZBun

The 7 most common R error messages, by frequency of mentions on
StackOverflow: http://bit.ly/1IFZBum

Slides and a webinar replay on reproducible data analysis with R and
the "checkpoint" package: http://bit.ly/1IFZA9W

Review of the book "Hands-On Programming with R" by Garrett Grolemund:
http://bit.ly/1IFZA9V

R users are invited to participate in the 2015 Rexer Data Mining
Survey: http://bit.ly/1IFZA9X

Using the "smbinning" package to discretize continuous data for
machine learning: http://bit.ly/1IFZBuq

Analyzing the nocturnal activities of New Yorkers via their Instagram
posts: http://bit.ly/1IFZBur

Gradient-boosted trees with the rxBTrees function in Revolution R
Enterprise: http://bit.ly/1IFZBut

New features in the updated "checkpoint" package for reproducible data
analysis: http://bit.ly/1IFZBus

Thoughts on using Vim as an interface to R: http://bit.ly/1IFZA9Y

An article on the impact of open source software on data science
features R: http://bit.ly/1IFZBuu

A new white paper describes the architecture of a DeployR server for
connecting R to other applications: http://bit.ly/1IFZA9Z

A surprising simulation to calculate pi: http://bit.ly/1IFZAa0

How to track the progress of parallel and distributed computations
with a progress bar: http://bit.ly/1IFZAa1

A brief summary of new features in R 3.1.3: http://bit.ly/1IFZAa2

An overview of the Hadleyverse, the collection of R packages by Hadley
Wickham: http://bit.ly/1IFZBuv

Analysis of activity in R user groups shows a recent spike in
meetings: http://bit.ly/1IFZBuw

Tools to extract and compare colors from images with R, and finding
the true colors of "that dress": http://bit.ly/1IFZAa3

Using Domino's new "R Notebook" to explore data with interactive
graphics: http://bit.ly/1IFZAqg

Computerworld's "R for Beginners" hands-on guide is now available as a
downloadable PDF: http://bit.ly/1IFZBux

General interest stories (not related to R) in the past month
included: a musical domino cascade (http://bit.ly/1IFZAqh), a deep
zoom into the Mandelbrot Set (http://bit.ly/1IFZBuy), a culinary
celebration of Pi day (http://bit.ly/1IFZAqi), and an unusual undersea
perspective (http://bit.ly/1IFZAqj).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid


From varinsacha at yahoo.fr  Mon Apr 13 18:06:31 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 13 Apr 2015 16:06:31 +0000 (UTC)
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <552BCBFD.70102@dewey.myzen.co.uk>
References: <552BCBFD.70102@dewey.myzen.co.uk>
Message-ID: <1968172778.1942537.1428941191884.JavaMail.yahoo@mail.yahoo.com>

Hi Michael,

Thanks for your response. About the data frame not necessary. I correct the code according to your comments. I still get the following warnings : 
[1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
NULL

I have found this on the Net :
"Note that boot.ci just gives a warning and returns NA values, if all values are equal. There is no error and if you can work with NAs, there is no need for the if condition.
The boot package assumes that the bootstrap
statistic has all ways the same dimension. 
Whenever you have a statistic with less dimensions you get an NA
or 0 or whatever you want".

The reproducible code :

GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12) 
Quality.score <-c(12,11,13,14,15,16,12,10,9,9) 
Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score) 
install.packages("boot") 
library(boot) 
bs=function(formula,data,indices){ 
d=data[indices,] 
fit=lm(formula,data=d) 
(coef(fit)) 
} 
results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score) 
boot.ci(results,type="bca",index=1) 
boot.ci(results,type="bca",index=2) 
boot.ci(results,type="bca",index=3) 

How is it possible to avoid that warning ?

Best,
S



----- Mail original -----
De : Michael Dewey <lists at dewey.myzen.co.uk>
? : varin sacha <varinsacha at yahoo.fr>; "Adams, Jean" <jvadams at usgs.gov>
Cc : "r-help at r-project.org" <r-help at r-project.org>
Envoy? le : Lundi 13 avril 2015 16h00
Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)

See in line

On 13/04/2015 14:38, varin sacha wrote:
> Hi Jean,
>
> Many thanks, I got it but there is still a problem. When trying to bootstrap the confidence intervals, I get these messages.
>
>
> boot.ci(results,type="bca",index=1)
> [1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
> NULL
>> boot.ci(results,type="bca",index=2)
> [1] "All values of t are equal to  0.618293471234648 \n Cannot calculate confidence intervals"
> NULL
>> boot.ci(results,type="bca",index=3)
> [1] "All values of t are equal to  0.148068842921784 \n Cannot calculate confidence intervals"
> NULL
>
>
> Here is the reproducible example :
>
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)

Did you mean at this point to put these into a data frame?

> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
> d=data[indices,]
> fit=lm(formula,data=Dataset)

In the code you sent there does not seem to be an object called Dataset.
Did you mean data = d?

> return(coef(fit))

You do not need to say return( ) at the end, just coef(fit) would work.


> }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
> boot.ci(results,type="bca",index=1)
> boot.ci(results,type="bca",index=2)
> boot.ci(results,type="bca",index=3)
>
> How to solve that problem ?
>
> Best,
> S.
>
>
>
> ________________________________
> De : "Adams, Jean" <jvadams at usgs.gov>
>
> Cc : "r-help at r-project.org" <r-help at r-project.org>
> Envoy? le : Lundi 13 avril 2015 14h22
> Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)
>
>
>
> S,
>
> There is no mention of a type="bca" argument on the ?confint help file.
>
> You can look here for an example of using the boot.ci() function in the boot package:
> http://www.statmethods.net/advstats/bootstrapping.html
>>
>> ?Jean?
>
>
>
>
>
>
>
> Dear R-Experts,
>>
>> I am trying to compute the BCa nonparametric bootstrap on regression coefficients.
>>
>> Here is the reproducible example :
>>
>> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
>> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
>> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
>> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
>> confint(fit, level=.95)
>> confint.default(fit, level=.95)
>> confint(fit,level=.95,type="bca")
>>
>> I am not sure but I think that I can not get the nonparametric BCa bootstrap with the confint function. As you can see, I have tried the argument type="bca", I don?t get any error message, but the results don?t change, the results are exactly the same as confint(fit,level=.95).
>> As I have understood, the default argument uses normal quantiles and the method for linear models uses T-quantiles instead.
>> So, I have checked the boot package and the boot.ci function to calculate the BCa bootstrap on the regression coefficients, but I don?t really understand how to compute the code.
>> So, any help from you would be highly appreciated.
>>
>> Best,
>> S
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From lindsay.hanford at gmail.com  Mon Apr 13 18:17:32 2015
From: lindsay.hanford at gmail.com (lindsay hanford)
Date: Mon, 13 Apr 2015 12:17:32 -0400
Subject: [R] friedman.test error: not an unreplicated complete block design
Message-ID: <CAOn4ZfeRWQnyAepk_G=6W69Oe_ph9vkbQW1ywDP--y4KR2cZLQ@mail.gmail.com>

Hello R Community,

I am using the friedman.test() function to test differences in a non-normally
distributed dataset, with a dependent variable that either a
continuous variable or a ratio and has 2+ groups.

I am using the friedman.test instead of a repeated measures ANOVA because
my dataset violated the assumptions for using an ANOVA. I am looking to
compare response means on an emotion-labelling task, between groups (HR,
HC) and emotions (Happy, Sad, Angry, Fearful) where these variables are my
group and block variables, respectively.

When I use the following command:
> friedman.test(Response~Group|Emotion, data=dataset)
I get the following error:
Error in friedman.test.default(c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,  :
  not an unreplicated complete block design

I believe I have set up my dataset correctly.. where Subject ID is repeated for
the four categories of emotion. The variable Error contains the number of
incorrect response corresponding to each emotion.


*Subj  Group Emotion Response*94    HR    Happy  2
119   HC   Happy 0
....
3   HR   Sad   4
61 HC   Sad   2
64  HC  Sad   0
....etc

I think the error c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,... ) corresponds
to my Response variable and might not be happy about is the number of 0's that
appear in that variable. However, this is the reason my dataset is not normally
distributed and I cannot use rmANOVA.

Any ideas how to deal with this error? Or whether I should be using a
different statistical test?
Thanks,

Lindsay
-- 
Lindsay Hanford, BSc, PhD Candidate
McMaster Integrative Neuroscience Discovery & Study | *Department of
Psychology, Neuroscience & Behaviour *
McMaster University *|* lindsay.hanford at gmail.com

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Mon Apr 13 18:27:25 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 13 Apr 2015 08:27:25 -0800
Subject: [R] friedman.test error: not an unreplicated complete block
 design
In-Reply-To: <CAOn4ZfeRWQnyAepk_G=6W69Oe_ph9vkbQW1ywDP--y4KR2cZLQ@mail.gmail.com>
Message-ID: <3DACE5BCDCE.00000735jrkrideau@inbox.com>

We really need " commented, minimal, self-contained, reproducible code' as asked for in the note at the end of each R-help message.

Have a look at http://adv-r.had.co.nz/Reproducibility.html and/or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example  for some hints.

In particular, in your case we almost certainly need some data.  Please use dput() to produce a useable data set. See Hakley's discussion at http://adv-r.had.co.nz/Reproducibility.html for an example of how to to this.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: lindsay.hanford at gmail.com
> Sent: Mon, 13 Apr 2015 12:17:32 -0400
> To: r-help at r-project.org
> Subject: [R] friedman.test error: not an unreplicated complete block
> design
> 
> Hello R Community,
> 
> I am using the friedman.test() function to test differences in a
> non-normally
> distributed dataset, with a dependent variable that either a
> continuous variable or a ratio and has 2+ groups.
> 
> I am using the friedman.test instead of a repeated measures ANOVA because
> my dataset violated the assumptions for using an ANOVA. I am looking to
> compare response means on an emotion-labelling task, between groups (HR,
> HC) and emotions (Happy, Sad, Angry, Fearful) where these variables are
> my
> group and block variables, respectively.
> 
> When I use the following command:
>> friedman.test(Response~Group|Emotion, data=dataset)
> I get the following error:
> Error in friedman.test.default(c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,
> :
>   not an unreplicated complete block design
> 
> I believe I have set up my dataset correctly.. where Subject ID is
> repeated for
> the four categories of emotion. The variable Error contains the number of
> incorrect response corresponding to each emotion.
> 
> 
> *Subj  Group Emotion Response*94    HR    Happy  2
> 119   HC   Happy 0
> ....
> 3   HR   Sad   4
> 61 HC   Sad   2
> 64  HC  Sad   0
> ....etc
> 
> I think the error c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,... )
> corresponds
> to my Response variable and might not be happy about is the number of 0's
> that
> appear in that variable. However, this is the reason my dataset is not
> normally
> distributed and I cannot use rmANOVA.
> 
> Any ideas how to deal with this error? Or whether I should be using a
> different statistical test?
> Thanks,
> 
> Lindsay
> --
> Lindsay Hanford, BSc, PhD Candidate
> McMaster Integrative Neuroscience Discovery & Study | *Department of
> Psychology, Neuroscience & Behaviour *
> McMaster University *|* lindsay.hanford at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From Efstathia.Defteraiou at student.uibk.ac.at  Mon Apr 13 18:07:54 2015
From: Efstathia.Defteraiou at student.uibk.ac.at (Efstathia Defteraiou)
Date: Mon, 13 Apr 2015 18:07:54 +0200
Subject: [R] PCA analysis and bootstraped loadings
Message-ID: <20150413180754.20996zowjdl5cdss@web-mail.uibk.ac.at>

Dear All,

I am relatively new in R.
Im working with the 'psych' package and 'principal' function.
I would like to know how to generate the bootstraped conf.intervals  
for loadings,
looking for sth similar to setting 'n.iter' argument for the 'fa' function.

If in 'psych' can't work and suggest me the 'boot' package please  
provide specific Rscript since I don't understand the commands and  
arguments that have to be used before calling the function 'boot'(  
what are indices? what to define as what inside function(){})

The names Im using are included in the following code:
'newdata3.1' is my data and provided as data.frame

makingtheanalysis3.1 <-principal(newdata3.1, nfactors =3,
                               residuals = FALSE,
                               covar=FALSE,rotate="varimax",scores=TRUE)


I am sorry for not providing a specific code but my data are too large

Any Help appreciated
Cheers!


From boris.steipe at utoronto.ca  Mon Apr 13 18:44:19 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 13 Apr 2015 12:44:19 -0400
Subject: [R] Convert color hex code to color names
In-Reply-To: <CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
	<CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
Message-ID: <1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>

To add slightly to that:

What you want to do is write a function that returns the named color that has the smallest difference to your input hex-triplet. But note that color difference is a large topic. Assuming you want to minimize *perceptual* differences, you want to calculate your differences in Lab color space. The function convertColor() has the option to convert hex to Lab. Example:
convertColor(t(col2rgb("thistle")), from="sRGB", to="Lab", scale.in=255)

Within Lab space, you can take the Euclidian distance.

That all said, I can't imagine why one would want to do this in the first place - color triplets are much more convenient than label strings :-)


B.




On Apr 13, 2015, at 11:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> A combination of rgb(), col2rgb() and colors() can gives hex values for the
> named colors.
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:
> 
>> Hi all, I want to convert the output of:
>> 
>>> rainbow(6)
>> 
>>> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
>> "#FF00FFFF"
>> 
>> To a vector of color names. Any tip?
>> 
>> 
>> Thanks in advance
>> 
>> C.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Apr 13 18:44:51 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 13 Apr 2015 17:44:51 +0100
Subject: [R] friedman.test error: not an unreplicated complete block
	design
In-Reply-To: <CAOn4ZfeRWQnyAepk_G=6W69Oe_ph9vkbQW1ywDP--y4KR2cZLQ@mail.gmail.com>
References: <CAOn4ZfeRWQnyAepk_G=6W69Oe_ph9vkbQW1ywDP--y4KR2cZLQ@mail.gmail.com>
Message-ID: <552BF283.80001@dewey.myzen.co.uk>

Dear Lindsay
If the problem is that you have an excess of zeroes you might look at 
the vignette for the package pscl which is called something like 
Regression models for count data.

On 13/04/2015 17:17, lindsay hanford wrote:
> Hello R Community,
>
> I am using the friedman.test() function to test differences in a non-normally
> distributed dataset, with a dependent variable that either a
> continuous variable or a ratio and has 2+ groups.
>
> I am using the friedman.test instead of a repeated measures ANOVA because
> my dataset violated the assumptions for using an ANOVA. I am looking to
> compare response means on an emotion-labelling task, between groups (HR,
> HC) and emotions (Happy, Sad, Angry, Fearful) where these variables are my
> group and block variables, respectively.
>
> When I use the following command:
>> friedman.test(Response~Group|Emotion, data=dataset)
> I get the following error:
> Error in friedman.test.default(c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,  :
>    not an unreplicated complete block design
>
> I believe I have set up my dataset correctly.. where Subject ID is repeated for
> the four categories of emotion. The variable Error contains the number of
> incorrect response corresponding to each emotion.
>
>
> *Subj  Group Emotion Response*94    HR    Happy  2
> 119   HC   Happy 0
> ....
> 3   HR   Sad   4
> 61 HC   Sad   2
> 64  HC  Sad   0
> ....etc
>
> I think the error c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,... ) corresponds
> to my Response variable and might not be happy about is the number of 0's that
> appear in that variable. However, this is the reason my dataset is not normally
> distributed and I cannot use rmANOVA.
>
> Any ideas how to deal with this error? Or whether I should be using a
> different statistical test?
> Thanks,
>
> Lindsay
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dcarlson at tamu.edu  Mon Apr 13 19:07:11 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 13 Apr 2015 17:07:11 +0000
Subject: [R] Convert color hex code to color names
In-Reply-To: <1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
	<CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
	<1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67DBF2@mb02.ads.tamu.edu>

And expanding at a more elementary level. The reason you need to find the smallest difference is 
that all of the possible colors do not have names. There are 256^3 = 16,777,216 possible rgb color designations, but only 657 named colors. You can create a data frame of the named colors and their rgb designations using

> clrs <- data.frame(Color=colors(), RGB=rgb(t(col2rgb(colors())),
    maxColorValue=255), stringsAsFactors=FALSE)
> str(clrs)
'data.frame':   657 obs. of  2 variables:
 $ Color: chr  "white" "aliceblue" "antiquewhite" "antiquewhite1" ...
 $ RGB  : chr  "#FFFFFF" "#F0F8FF" "#FAEBD7" "#FFEFDB" ...
> head(clrs)
          Color     RGB
1         white #FFFFFF
2     aliceblue #F0F8FF
3  antiquewhite #FAEBD7
4 antiquewhite1 #FFEFDB
5 antiquewhite2 #EEDFCC
6 antiquewhite3 #CDC0B0

So most colors do not have names. In your example, none of the colors in rainbow(6) have names: 

> rain <- rainbow(6)
> sum(clrs$RGB %in% rain)
[1] 0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris Steipe
Sent: Monday, April 13, 2015 11:44 AM
To: Alejo C.S.
Cc: r-help at r-project.org
Subject: Re: [R] Convert color hex code to color names

To add slightly to that:

What you want to do is write a function that returns the named color that has the smallest difference to your input hex-triplet. But note that color difference is a large topic. Assuming you want to minimize *perceptual* differences, you want to calculate your differences in Lab color space. The function convertColor() has the option to convert hex to Lab. Example:
convertColor(t(col2rgb("thistle")), from="sRGB", to="Lab", scale.in=255)

Within Lab space, you can take the Euclidian distance.

That all said, I can't imagine why one would want to do this in the first place - color triplets are much more convenient than label strings :-)


B.




On Apr 13, 2015, at 11:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> A combination of rgb(), col2rgb() and colors() can gives hex values for the
> named colors.
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:
> 
>> Hi all, I want to convert the output of:
>> 
>>> rainbow(6)
>> 
>>> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
>> "#FF00FFFF"
>> 
>> To a vector of color names. Any tip?
>> 
>> 
>> Thanks in advance
>> 
>> C.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From maechler at lynne.stat.math.ethz.ch  Mon Apr 13 19:10:45 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 13 Apr 2015 19:10:45 +0200
Subject: [R] Convert color hex code to color names
In-Reply-To: <1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
	<CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
	<1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
Message-ID: <21803.63637.844006.930310@stat.math.ethz.ch>


> To add slightly to that:
> What you want to do is write a function that returns the named color that has the smallest difference to your input hex-triplet. But note that color difference is a large topic. Assuming you want to minimize *perceptual* differences, you want to calculate your differences in Lab color space. The function convertColor() has the option to convert hex to Lab. Example:
> convertColor(t(col2rgb("thistle")), from="sRGB", to="Lab", scale.in=255)

> Within Lab space, you can take the Euclidian distance.

> That all said, I can't imagine why one would want to do this in the first place - color triplets are much more convenient than label strings :-)


> B.

About 1-2 years ago, I have improved the 

      demo("colors", package = "grDevices")

demo in R.... with inspiration from Marius Hofert.

The demo now features a  nearRcolor() function 
that was written for somewhat like that purpose.

 ##' Find close R colors() to a given color {original by Marius Hofert)
 ##' using Euclidean norm in (HSV / RGB / ...) color space
 nearRcolor <- function(rgb, cSpace = c("hsv", "rgb255", "Luv", "Lab"),
                        dist = switch(cSpace, "hsv" = 0.10, "rgb255" = 30,
                        "Luv" = 15, "Lab" = 12))
 .............
 .............

It allows to use different color spaces and a default set of
cutoffs, for defining what  "near" means.

I had thought at the time to make a regular function out of
it, but then did not follow up on myself :-)

Martin Maechler,
ETH Zurich and R core team


> On Apr 13, 2015, at 11:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> > A combination of rgb(), col2rgb() and colors() can gives hex values for the
> > named colors.
> > 
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> > 
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of data.
> > ~ John Tukey
> > 
> > 2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:
> > 
> >> Hi all, I want to convert the output of:
> >> 
> >>> rainbow(6)
> >> 
> >>> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
> >> "#FF00FFFF"
> >> 
> >> To a vector of color names. Any tip?
> >> 
> >> 
> >> Thanks in advance
> >> 
> >> C.


From pdalgd at gmail.com  Mon Apr 13 19:13:09 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 13 Apr 2015 19:13:09 +0200
Subject: [R] friedman.test error: not an unreplicated complete block
	design
In-Reply-To: <3DACE5BCDCE.00000735jrkrideau@inbox.com>
References: <3DACE5BCDCE.00000735jrkrideau@inbox.com>
Message-ID: <747D96D5-493F-405C-A096-9D1C9722091A@gmail.com>

By coincidence, there actually _is_ enough info to pinpoint the issue:


*Subj  Group Emotion Response*94    HR    Happy  2
119   HC   Happy 0
....
3   HR   Sad   4
61 HC   Sad   2
64  HC  Sad   0
....etc

An unreplicated complete block design has exactly 1 observation for each combination of the two grouping factors. The above clearly has 2 observations with "HC, Sad". So Friedman's test does not apply.


> On 13 Apr 2015, at 18:27 , John Kane <jrkrideau at inbox.com> wrote:
> 
> We really need " commented, minimal, self-contained, reproducible code' as asked for in the note at the end of each R-help message.
> 
> Have a look at http://adv-r.had.co.nz/Reproducibility.html and/or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example  for some hints.
> 
> In particular, in your case we almost certainly need some data.  Please use dput() to produce a useable data set. See Hakley's discussion at http://adv-r.had.co.nz/Reproducibility.html for an example of how to to this.
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: lindsay.hanford at gmail.com
>> Sent: Mon, 13 Apr 2015 12:17:32 -0400
>> To: r-help at r-project.org
>> Subject: [R] friedman.test error: not an unreplicated complete block
>> design
>> 
>> Hello R Community,
>> 
>> I am using the friedman.test() function to test differences in a
>> non-normally
>> distributed dataset, with a dependent variable that either a
>> continuous variable or a ratio and has 2+ groups.
>> 
>> I am using the friedman.test instead of a repeated measures ANOVA because
>> my dataset violated the assumptions for using an ANOVA. I am looking to
>> compare response means on an emotion-labelling task, between groups (HR,
>> HC) and emotions (Happy, Sad, Angry, Fearful) where these variables are
>> my
>> group and block variables, respectively.
>> 
>> When I use the following command:
>>> friedman.test(Response~Group|Emotion, data=dataset)
>> I get the following error:
>> Error in friedman.test.default(c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,
>> :
>>  not an unreplicated complete block design
>> 
>> I believe I have set up my dataset correctly.. where Subject ID is
>> repeated for
>> the four categories of emotion. The variable Error contains the number of
>> incorrect response corresponding to each emotion.
>> 
>> 
>> *Subj  Group Emotion Response*94    HR    Happy  2
>> 119   HC   Happy 0
>> ....
>> 3   HR   Sad   4
>> 61 HC   Sad   2
>> 64  HC  Sad   0
>> ....etc
>> 
>> I think the error c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,... )
>> corresponds
>> to my Response variable and might not be happy about is the number of 0's
>> that
>> appear in that variable. However, this is the reason my dataset is not
>> normally
>> distributed and I cannot use rmANOVA.
>> 
>> Any ideas how to deal with this error? Or whether I should be using a
>> different statistical test?
>> Thanks,
>> 
>> Lindsay
>> --
>> Lindsay Hanford, BSc, PhD Candidate
>> McMaster Integrative Neuroscience Discovery & Study | *Department of
>> Psychology, Neuroscience & Behaviour *
>> McMaster University *|* lindsay.hanford at gmail.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lindsay.hanford at gmail.com  Mon Apr 13 19:20:38 2015
From: lindsay.hanford at gmail.com (lindsay hanford)
Date: Mon, 13 Apr 2015 13:20:38 -0400
Subject: [R] friedman.test error: not an unreplicated complete block
	design
In-Reply-To: <747D96D5-493F-405C-A096-9D1C9722091A@gmail.com>
References: <3DACE5BCDCE.00000735jrkrideau@inbox.com>
	<747D96D5-493F-405C-A096-9D1C9722091A@gmail.com>
Message-ID: <CAOn4ZfeFj_ssan0=n5mQsNCjfiZ5OTHB-baWLwQJ_4c7hxz=sQ@mail.gmail.com>

Hi Peter,

I thought it was possible to have multiple subjects in each group, while
still specifying another factor, as is the case for repeated measures
ANOVA. If this is not the case, I guess I should look into Regression
models for count data as suggested by Micheal.


On Mon, Apr 13, 2015 at 1:13 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> By coincidence, there actually _is_ enough info to pinpoint the issue:
>
>
> *Subj  Group Emotion Response*94    HR    Happy  2
> 119   HC   Happy 0
> ....
> 3   HR   Sad   4
> 61 HC   Sad   2
> 64  HC  Sad   0
> ....etc
>
> An unreplicated complete block design has exactly 1 observation for each
> combination of the two grouping factors. The above clearly has 2
> observations with "HC, Sad". So Friedman's test does not apply.
>
>
> > On 13 Apr 2015, at 18:27 , John Kane <jrkrideau at inbox.com> wrote:
> >
> > We really need " commented, minimal, self-contained, reproducible code'
> as asked for in the note at the end of each R-help message.
> >
> > Have a look at http://adv-r.had.co.nz/Reproducibility.html and/or
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> for some hints.
> >
> > In particular, in your case we almost certainly need some data.  Please
> use dput() to produce a useable data set. See Hakley's discussion at
> http://adv-r.had.co.nz/Reproducibility.html for an example of how to to
> this.
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: lindsay.hanford at gmail.com
> >> Sent: Mon, 13 Apr 2015 12:17:32 -0400
> >> To: r-help at r-project.org
> >> Subject: [R] friedman.test error: not an unreplicated complete block
> >> design
> >>
> >> Hello R Community,
> >>
> >> I am using the friedman.test() function to test differences in a
> >> non-normally
> >> distributed dataset, with a dependent variable that either a
> >> continuous variable or a ratio and has 2+ groups.
> >>
> >> I am using the friedman.test instead of a repeated measures ANOVA
> because
> >> my dataset violated the assumptions for using an ANOVA. I am looking to
> >> compare response means on an emotion-labelling task, between groups (HR,
> >> HC) and emotions (Happy, Sad, Angry, Fearful) where these variables are
> >> my
> >> group and block variables, respectively.
> >>
> >> When I use the following command:
> >>> friedman.test(Response~Group|Emotion, data=dataset)
> >> I get the following error:
> >> Error in friedman.test.default(c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,
> >> :
> >>  not an unreplicated complete block design
> >>
> >> I believe I have set up my dataset correctly.. where Subject ID is
> >> repeated for
> >> the four categories of emotion. The variable Error contains the number
> of
> >> incorrect response corresponding to each emotion.
> >>
> >>
> >> *Subj  Group Emotion Response*94    HR    Happy  2
> >> 119   HC   Happy 0
> >> ....
> >> 3   HR   Sad   4
> >> 61 HC   Sad   2
> >> 64  HC  Sad   0
> >> ....etc
> >>
> >> I think the error c(1L, 1L, 0L, 0L, 0L, 1L, 0L, 2L, 0L, 0L,... )
> >> corresponds
> >> to my Response variable and might not be happy about is the number of
> 0's
> >> that
> >> appear in that variable. However, this is the reason my dataset is not
> >> normally
> >> distributed and I cannot use rmANOVA.
> >>
> >> Any ideas how to deal with this error? Or whether I should be using a
> >> different statistical test?
> >> Thanks,
> >>
> >> Lindsay
> >> --
> >> Lindsay Hanford, BSc, PhD Candidate
> >> McMaster Integrative Neuroscience Discovery & Study | *Department of
> >> Psychology, Neuroscience & Behaviour *
> >> McMaster University *|* lindsay.hanford at gmail.com
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ____________________________________________________________
> > Can't remember your password? Do you need a strong and secure password?
> > Use Password manager! It stores your passwords & protects your account.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


-- 
Lindsay Hanford, BSc, PhD Candidate
McMaster Integrative Neuroscience Discovery & Study | *Department of
Psychology, Neuroscience & Behaviour *
McMaster University *|* 1280 Main Street West, PC329 Psychology Building *|*
 Hamilton, ON, L8S 4L8
905 525 9140 x24784 *|* lindsay.hanford at gmail.com

	[[alternative HTML version deleted]]


From djnordlund at frontier.com  Mon Apr 13 19:26:36 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 13 Apr 2015 10:26:36 -0700
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <1968172778.1942537.1428941191884.JavaMail.yahoo@mail.yahoo.com>
References: <552BCBFD.70102@dewey.myzen.co.uk>
	<1968172778.1942537.1428941191884.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <552BFC4C.4010904@frontier.com>

On 4/13/2015 9:06 AM, varin sacha wrote:
> Hi Michael,
>
> Thanks for your response. About the data frame not necessary. I correct the code according to your comments. I still get the following warnings :
> [1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
> NULL
>
> I have found this on the Net :
> "Note that boot.ci just gives a warning and returns NA values, if all values are equal. There is no error and if you can work with NAs, there is no need for the if condition.
> The boot package assumes that the bootstrap
> statistic has all ways the same dimension.
> Whenever you have a statistic with less dimensions you get an NA
> or 0 or whatever you want".
>
> The reproducible code :
>
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
> d=data[indices,]
> fit=lm(formula,data=d)
> (coef(fit))
> }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
> boot.ci(results,type="bca",index=1)
> boot.ci(results,type="bca",index=2)
> boot.ci(results,type="bca",index=3)
>
> How is it possible to avoid that warning ?
>
> Best,
> S
>
>
>

The first problem is that this is not reproducible code.  This is what I 
get when I run your code on my computer:

> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> #####install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
+ d=data[indices,]
+ fit=lm(formula,data=d)
+ (coef(fit))
+ }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
Error in NROW(data) : object 'Dataset' not found
> boot.ci(results,type="bca",index=1)
Error in boot.ci(results, type = "bca", index = 1) :
   object 'results' not found
> boot.ci(results,type="bca",index=2)
Error in boot.ci(results, type = "bca", index = 2) :
   object 'results' not found
> boot.ci(results,type="bca",index=3)
Error in boot.ci(results, type = "bca", index = 3) :
   object 'results' not found
>


A reproducible example means that when I run your code on my machine, I 
get the same results / warnings / errors that you get.  I got something 
different.


Dan

-- 
Daniel Nordlund
Bothell, WA USA


From dcarlson at tamu.edu  Mon Apr 13 19:42:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 13 Apr 2015 17:42:57 +0000
Subject: [R] Convert color hex code to color names
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67DBF2@mb02.ads.tamu.edu>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
	<CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
	<1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67DBF2@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67DC2F@mb02.ads.tamu.edu>

Actually all 6 colors in rainbow(6) do have names. I missed the fact that rainbow() adds an alpha value that we need to strip off before comparing to the values in clrs$RGB:

> rain <- substr(rain, 1, 7)
> sum(clrs$RGB %in% rain)
[1] 12

So there are two color names for each color in rainbow(6):

> for (i in 1:6) cat(i, colors()[clrs$RGB==rain[i]], "\n")
1 red red1 
2 yellow yellow1 
3 green green1 
4 cyan cyan1 
5 blue blue1 
6 magenta magenta1

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Monday, April 13, 2015 12:07 PM
To: Boris Steipe; Alejo C.S.
Cc: r-help at r-project.org
Subject: Re: [R] Convert color hex code to color names

And expanding at a more elementary level. The reason you need to find the smallest difference is 
that all of the possible colors do not have names. There are 256^3 = 16,777,216 possible rgb color designations, but only 657 named colors. You can create a data frame of the named colors and their rgb designations using

> clrs <- data.frame(Color=colors(), RGB=rgb(t(col2rgb(colors())),
    maxColorValue=255), stringsAsFactors=FALSE)
> str(clrs)
'data.frame':   657 obs. of  2 variables:
 $ Color: chr  "white" "aliceblue" "antiquewhite" "antiquewhite1" ...
 $ RGB  : chr  "#FFFFFF" "#F0F8FF" "#FAEBD7" "#FFEFDB" ...
> head(clrs)
          Color     RGB
1         white #FFFFFF
2     aliceblue #F0F8FF
3  antiquewhite #FAEBD7
4 antiquewhite1 #FFEFDB
5 antiquewhite2 #EEDFCC
6 antiquewhite3 #CDC0B0

So most colors do not have names. In your example, none of the colors in rainbow(6) have names: 

> rain <- rainbow(6)
> sum(clrs$RGB %in% rain)
[1] 0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris Steipe
Sent: Monday, April 13, 2015 11:44 AM
To: Alejo C.S.
Cc: r-help at r-project.org
Subject: Re: [R] Convert color hex code to color names

To add slightly to that:

What you want to do is write a function that returns the named color that has the smallest difference to your input hex-triplet. But note that color difference is a large topic. Assuming you want to minimize *perceptual* differences, you want to calculate your differences in Lab color space. The function convertColor() has the option to convert hex to Lab. Example:
convertColor(t(col2rgb("thistle")), from="sRGB", to="Lab", scale.in=255)

Within Lab space, you can take the Euclidian distance.

That all said, I can't imagine why one would want to do this in the first place - color triplets are much more convenient than label strings :-)


B.




On Apr 13, 2015, at 11:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> A combination of rgb(), col2rgb() and colors() can gives hex values for the
> named colors.
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:
> 
>> Hi all, I want to convert the output of:
>> 
>>> rainbow(6)
>> 
>>> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
>> "#FF00FFFF"
>> 
>> To a vector of color names. Any tip?
>> 
>> 
>> Thanks in advance
>> 
>> C.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Mon Apr 13 20:55:21 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 13 Apr 2015 18:55:21 +0000 (UTC)
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <552BFC4C.4010904@frontier.com>
References: <552BFC4C.4010904@frontier.com>
Message-ID: <2076144842.2131690.1428951321816.JavaMail.yahoo@mail.yahoo.com>

Hi Daniel,

Sorry for that, once more.... ;=(

Here is the reproducible code and this time IT WORKS FINALLY !!!

GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)  
Quality.score <-c(12,11,13,14,15,16,12,10,9,9) 
Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7) 
df=data.frame(GDP.LOG,Quality.score,Competitivness.score) 

fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)  
install.packages("boot") 
library(boot) 
bs=function(formula,data,indices){ 
d=data[indices,] 
fit=lm(formula,data=d)
(coef(fit)) 
}  
results=boot(data=df,statistic=bs, R=2000,formula= GDP.LOG ~ 
Quality.score + Competitivness.score)  
boot.ci(results,type="bca",index=1)  
boot.ci(results,type="bca",index=2) 
boot.ci(results,type="bca",index=3) 

Best,
S



----- Mail original -----
De : Daniel Nordlund <djnordlund at frontier.com>
? : r-help at r-project.org
Cc : 
Envoy? le : Lundi 13 avril 2015 19h26
Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)

On 4/13/2015 9:06 AM, varin sacha wrote:
> Hi Michael,
>
> Thanks for your response. About the data frame not necessary. I correct the code according to your comments. I still get the following warnings :
> [1] "All values of t are equal to  5.75620151906917 \n Cannot calculate confidence intervals"
> NULL
>
> I have found this on the Net :
> "Note that boot.ci just gives a warning and returns NA values, if all values are equal. There is no error and if you can work with NAs, there is no need for the if condition.
> The boot package assumes that the bootstrap
> statistic has all ways the same dimension.
> Whenever you have a statistic with less dimensions you get an NA
> or 0 or whatever you want".
>
> The reproducible code :
>
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
> d=data[indices,]
> fit=lm(formula,data=d)
> (coef(fit))
> }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
> boot.ci(results,type="bca",index=1)
> boot.ci(results,type="bca",index=2)
> boot.ci(results,type="bca",index=3)
>
> How is it possible to avoid that warning ?
>
> Best,
> S
>
>
>

The first problem is that this is not reproducible code.  This is what I 
get when I run your code on my computer:

> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> #####install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
+ d=data[indices,]
+ fit=lm(formula,data=d)
+ (coef(fit))
+ }
> results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~ Quality.score + Competitivness.score)
Error in NROW(data) : object 'Dataset' not found
> boot.ci(results,type="bca",index=1)
Error in boot.ci(results, type = "bca", index = 1) :
   object 'results' not found
> boot.ci(results,type="bca",index=2)
Error in boot.ci(results, type = "bca", index = 2) :
   object 'results' not found
> boot.ci(results,type="bca",index=3)
Error in boot.ci(results, type = "bca", index = 3) :
   object 'results' not found
>


A reproducible example means that when I run your code on my machine, I 
get the same results / warnings / errors that you get.  I got something 
different.


Dan

-- 
Daniel Nordlund
Bothell, WA USA


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mahdiyeh.erfaniyan at gmail.com  Mon Apr 13 20:51:30 2015
From: mahdiyeh.erfaniyan at gmail.com (Mahdiyeh Erfaniyan)
Date: Mon, 13 Apr 2015 23:21:30 +0430
Subject: [R] question
Message-ID: <CANBmxog=MvuxW9NoFeWrCx6DfvDarUPviC6O8A3Z8+kv_=0Zng@mail.gmail.com>

Hi all,
Recently I sent an email and I was asked to provide reproducible code of a
simple example of my situation. Instead of providing the code, I decided to
describe what I need in my code.
I've written a function V, which is a function of (r,s); so I have a
function V(r,s) in fact. The output of V is a (n-1) dimensional vector,
where n is the sample size. What I need is to calculate the following
steps *for
all possible values of (r,s)*:


1- Calculate V(r,s) for m replicates.
2- Calculate the mean of these m replicates.
3- Calculate the difference of each of m V(r,s) and the mean in step 3.
4- Calculate the absolute values of the differences in step 3.
5- Calculate the mean of the m differences calculated in step 4.

So at the end I'll have r0*s0  vectors (with dimension n-1), where r0 and
s0 are the number of possible values of r and s respectively.

My main problem is that I don't know how I should keep the replicates of
V's (produced in step 2) for calculating the differences in step 3 ,
regarding that I should consider all possible values of r and s. Some
people suggested using arrays, but some other said it could work very
slowly. I've never used arrays, so I don't know if it's a good idea or
there are better ideas as well.

Thanks for any help in advance

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Apr 13 21:21:57 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 13 Apr 2015 15:21:57 -0400
Subject: [R] question
In-Reply-To: <CANBmxog=MvuxW9NoFeWrCx6DfvDarUPviC6O8A3Z8+kv_=0Zng@mail.gmail.com>
References: <CANBmxog=MvuxW9NoFeWrCx6DfvDarUPviC6O8A3Z8+kv_=0Zng@mail.gmail.com>
Message-ID: <6ACCDAEE-BD0C-4A78-A9FD-853B6FB241A1@utoronto.ca>

That all sounds so straightforward I wonder why you don't just code it up and try it out.
You might profit from the advice of chapter 2 of the R-Inferno for your "main problem".

If "some people" who you ask for advice think that arrays in R are intrinsically slow, you might also want to look for other people.

Cheers,
B.
(Did I mention: don't post in HTML? No. Ok. Don't post in HTML.)


On Apr 13, 2015, at 2:51 PM, Mahdiyeh Erfaniyan <mahdiyeh.erfaniyan at gmail.com> wrote:

> Hi all,
> Recently I sent an email and I was asked to provide reproducible code of a
> simple example of my situation. Instead of providing the code, I decided to
> describe what I need in my code.
> I've written a function V, which is a function of (r,s); so I have a
> function V(r,s) in fact. The output of V is a (n-1) dimensional vector,
> where n is the sample size. What I need is to calculate the following
> steps *for
> all possible values of (r,s)*:
> 
> 
> 1- Calculate V(r,s) for m replicates.
> 2- Calculate the mean of these m replicates.
> 3- Calculate the difference of each of m V(r,s) and the mean in step 3.
> 4- Calculate the absolute values of the differences in step 3.
> 5- Calculate the mean of the m differences calculated in step 4.
> 
> So at the end I'll have r0*s0  vectors (with dimension n-1), where r0 and
> s0 are the number of possible values of r and s respectively.
> 
> My main problem is that I don't know how I should keep the replicates of
> V's (produced in step 2) for calculating the differences in step 3 ,
> regarding that I should consider all possible values of r and s. Some
> people suggested using arrays, but some other said it could work very
> slowly. I've never used arrays, so I don't know if it's a good idea or
> there are better ideas as well.
> 
> Thanks for any help in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From antoviral at gmail.com  Mon Apr 13 21:25:56 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Mon, 13 Apr 2015 21:25:56 +0200
Subject: [R] 'metafor' - standardized mean difference in pre-post design
	studies
Message-ID: <CAPmpGDvF64ovqY1qnCAqhc+cdPAr9Uuh4pycapHG3rr5amPxgA@mail.gmail.com>

Hi, I have a quesite on meta-analysis with 'metafor'.
I would like to calculate the standardized mean difference (SMD), as
Hedges' g, in pre-post design studies.
I have data on baseline (sample size, mean and SD in both the experimental
and the control group) and at end of treatment (same as before).
The 'metafor' site report a calculation based on Morris (2008).
However, I would like to calculate the SMD as in Comprehensive
Meta-analysis according to Borenstein:

d = (mean.pre - mean.post) / SD_within

SD_within = SD.diff / square root (2(1-r)

r = correlation between pairs of observation (often it is not reported, and
suggestion is to use r = 0.70)

The variance of d (Vd) is calculated as (1/n + d^2/2n)2(1-r), where n =
number of pairs

To derive Hedges' g from d, the correction 'J' is used:

J = 1 - (3/4df - 1), where df = degrees of freedom, which in two
independent groups is n1+n2-2

Essentially, J = 1 - (3/4*((n1+n2)-2) - 1)

Ultimately, g = J x d, and variance of g (Vg) = J^2 x Vd


I had some hint by Wolfgang Viechtbauer, but I'm stucked on here
(essentially, because my poor programming abilities)
I was stuck on applying the Viechtbauer's hint to my dataset.
Probably I'm doing something wrong. However, what I get it is not what I
found with Comprehensive Meta-Analysis.
In CMA I've found g = -0.49 (95%CI: -0.64 to -0.33).

Moreover, I do not know how to apply the J correction for calculating the
Hedges'g.
My request is: can anyone check the codes?
Can anyone help me in adding the J correction?
What should I multiply for J?
Should I use the final yi and vi as measures of d and Variance of d?


Thank you in advance,
Antonello Preti


This is my dataset (with imputed r = 0.70, put in the 'ri' variable):

##### the data

dat <- structure(list(study = structure(c(11L, 8L, 7L, 12L, 13L, 4L,
5L, 1L, 10L, 3L, 6L, 9L, 2L), .Label = c("Study A, 2012",
"Study B, 2013", "Study C, 2013", "Study D, 2010",
"Study E, 2012", "Study F, 2013", "Study G, 2006",
"Study H, 2005", "Study I, 2013", "Study L, 2012",
"Study M, 2003", "Study N, 2007", "Study P, 2007"
), class = "factor"), c_pre_mean = c(4.9, 15.18, 19.01, 5.1,
16.5, 27.35, 18.1, 2.4, 14.23, 0.08, 21.26, 21.5, 21.73), c_pre_sd = c(2.6,
2.21, 7.1, 1.5, 7.2, 13.92, 5.4, 0.13, 4.89, 0.94, 7.65, 5.22,
8.43), c_post_mean = c(6.1, 13.98, 18.5, 4.53, 15.9, 23, 16.9,
2.2, 16.58, -0.02, 16, 16.84, 23.54), c_post_sd = c(2.06, 3.24,
7, 2.06, 6.8, 12.06, 3.8, 0.13, 6.35, 0.88, 4.69, 4.64, 6.74),
    c_sample = c(14, 13, 19, 15, 34, 20, 24, 35, 31, 26, 49,
    21, 22), e_pre_mean = c(4.6, 13.81, 19.9, 5.3, 18.7, 22.71,
    19.2, 2.7, 15.97, -0.22, 20.9, 20.43, 21.94), e_pre_sd = c(2.1,
    6.64, 8.1, 2.9, 7.3, 7.82, 4.1, 0.13, 6.73, 0.93, 5.18, 4.87,
    7.02), e_post_mean = c(4.64, 15.86, 18.1, 4.33, 17.2, 24.89,
    17.6, 2.8, 13.6, 0.06, 17.41, 16.05, 19.29), e_post_sd = c(2.34,
    7.76, 7.8, 2.26, 7.4, 11.89, 3.7, 0.13, 5.79, 1.12, 5.16,
    4.17, 6.58), e_sample = c(14, 18, 16, 16, 33, 28, 29, 36,
    38, 27, 43, 25, 17), ri = c(.70,
.70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70)), .Names = c("study",
"c_pre_mean", "c_pre_sd",
"c_post_mean", "c_post_sd", "c_sample", "e_pre_mean", "e_pre_sd",
"e_post_mean", "e_post_sd", "e_sample", "ri"), class = "data.frame",
row.names = c(NA,
-13L))


### check the data

dim(dat)
head(dat)
str(dat)

### to make easy the operations (I know it should'nt be done)

attach(dat)


### call the library

library('metafor')

### The hint by Viechtbauer is that CMA computes the d value for a pre-post
design in a slightly different way than metafor. CMA computes:

### d = (m_1 - m_2) / (SD_diff / sqrt(2*(1-r)))

### To do this, I should calculate something like this (first the control
group):

sd1i= c_pre_sd
sd2i = c_post_sd
ni = c_sample

dat$sdi_c <- with(dat, sqrt((sd1i^2 + sd2i^2 -
2*ri*sd1i*sd2i))/sqrt(2*(1-ri)))

### Then apply the usual calculation with escalc:

datC <- escalc(measure="SMCR", m1i=c_pre_mean, m2i=c_post_mean, sd1i=sdi_c,
ni=ni, ri=ri, data=dat)
summary(datC)


#### The same on the experimental group

sd1i= e_pre_sd
sd2i = e_post_sd
ni = e_sample


dat$sdi_e <- with(dat, sqrt((sd1i^2 + sd2i^2 -
2*ri*sd1i*sd2i))/sqrt(2*(1-ri)))

datE <- escalc(measure="SMCR", m1i=e_pre_mean, m2i=e_post_mean, sd1i=sdi_e,
ni=ni, ri=ri, data=dat)
summary(datE)


#### Computing the Difference in the Standardized Mean Change

datFin <- data.frame(yi = datE$yi - datC$yi, vi = datE$vi + datC$vi)
round(datFin, 2)



###############################################
#
# fixed-effects model
#
###############################################

model.FE <- rma(yi, vi, data=datFin, method="FE", digits=2)

summary(model.FE)

# plot globale

plot(model.FE, slab=paste(study))


###
###

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Apr 13 21:38:17 2015
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 13 Apr 2015 14:38:17 -0500
Subject: [R] PCA analysis and bootstraped loadings
In-Reply-To: <20150413180754.20996zowjdl5cdss@web-mail.uibk.ac.at>
References: <20150413180754.20996zowjdl5cdss@web-mail.uibk.ac.at>
Message-ID: <CADKEMqhAXAA9uciZL89OUeRu9vsPQAGY0v7AWn8DmFtUHAJp3A@mail.gmail.com>

Hi,

Please search the mailing list archives for this, or type bootstrapped PCA
R into google. Please provide a minimal self-contained example of what you
are trying to solve. Please read the posting guide that is referenced at
the end of every email.
kind regards,

Stephen

On Mon, Apr 13, 2015 at 11:07 AM, Efstathia Defteraiou <
Efstathia.Defteraiou at student.uibk.ac.at> wrote:

> Dear All,
>
> I am relatively new in R.
> Im working with the 'psych' package and 'principal' function.
> I would like to know how to generate the bootstraped conf.intervals for
> loadings,
> looking for sth similar to setting 'n.iter' argument for the 'fa' function.
>
> If in 'psych' can't work and suggest me the 'boot' package please provide
> specific Rscript since I don't understand the commands and arguments that
> have to be used before calling the function 'boot'( what are indices? what
> to define as what inside function(){})
>
> The names Im using are included in the following code:
> 'newdata3.1' is my data and provided as data.frame
>
> makingtheanalysis3.1 <-principal(newdata3.1, nfactors =3,
>                               residuals = FALSE,
>                               covar=FALSE,rotate="varimax",scores=TRUE)
>
>
> I am sorry for not providing a specific code but my data are too large
>
> Any Help appreciated
> Cheers!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From antoviral at gmail.com  Mon Apr 13 21:46:55 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Mon, 13 Apr 2015 21:46:55 +0200
Subject: [R] metafor - Cochrane on change score in pre-post design
Message-ID: <CAPmpGDtex294Rg31n0Ke76qMWS_fCVeR2wNHfUeJX0Gd_0wOyg@mail.gmail.com>

Hi, this is another quesite related to the use of 'metafor' for calculation
of standardized mean change in pre-post design studies.
Essentially, my aim is to compare different method to arrive at the same
conclusion: Does the treatment work?

The Cochrane manual advise not to calculate change score:

"9.4.5.2  Meta-analysis of change scores

In some circumstances an analysis based on changes from baseline will be
more efficient and powerful than comparison of final values,
as it removes a component of between-person variability from the analysis.
However, calculation of a change score requires measurement of the outcome
twice
and in practice may be less efficient for outcomes which are unstable or
difficult to measure precisely,
where the measurement error may be larger than true between-person baseline
variability.
Change-from-baseline outcomes may also be preferred if they have a less
skewed distribution than final measurement outcomes.
Although sometimes used as a device to ?correct? for unlucky randomization,
this practice is not recommended.

The preferred statistical approach to accounting for baseline measurements
of the outcome variable
is to include the baseline outcome measurements as a covariate in a
regression model or analysis of covariance (ANCOVA)".

My question is: how do include both baseline (experimental and control
group)  in the analysis as a covariate in 'metafor'?
So, far, this is what I did.
I kinly request some help tp add the baseline as covariate to comply with
the Cochrane suggestion-
How can I add the baseline mean in both groups?
Should I consider baseline standard deviation, and if yes, how?
Should I take into account dropouts? I mean, in some sample at baseline n =
30 and 35 and at end of treatment n was 28 and 29...



Thank you in advance,
Antonello Preti




This is my dataset (with imputed r = 0.70 for pre-post correlation, put in
the 'ri' variable):

##### the data

dat <- structure(list(study = structure(c(11L, 8L, 7L, 12L, 13L, 4L,
5L, 1L, 10L, 3L, 6L, 9L, 2L), .Label = c("Study A, 2012",
"Study B, 2013", "Study C, 2013", "Study D, 2010",
"Study E, 2012", "Study F, 2013", "Study G, 2006",
"Study H, 2005", "Study I, 2013", "Study L, 2012",
"Study M, 2003", "Study N, 2007", "Study P, 2007"
), class = "factor"), c_pre_mean = c(4.9, 15.18, 19.01, 5.1,
16.5, 27.35, 18.1, 2.4, 14.23, 0.08, 21.26, 21.5, 21.73), c_pre_sd = c(2.6,
2.21, 7.1, 1.5, 7.2, 13.92, 5.4, 0.13, 4.89, 0.94, 7.65, 5.22,
8.43), c_post_mean = c(6.1, 13.98, 18.5, 4.53, 15.9, 23, 16.9,
2.2, 16.58, -0.02, 16, 16.84, 23.54), c_post_sd = c(2.06, 3.24,
7, 2.06, 6.8, 12.06, 3.8, 0.13, 6.35, 0.88, 4.69, 4.64, 6.74),
    c_sample = c(14, 13, 19, 15, 34, 20, 24, 35, 31, 26, 49,
    21, 22), e_pre_mean = c(4.6, 13.81, 19.9, 5.3, 18.7, 22.71,
    19.2, 2.7, 15.97, -0.22, 20.9, 20.43, 21.94), e_pre_sd = c(2.1,
    6.64, 8.1, 2.9, 7.3, 7.82, 4.1, 0.13, 6.73, 0.93, 5.18, 4.87,
    7.02), e_post_mean = c(4.64, 15.86, 18.1, 4.33, 17.2, 24.89,
    17.6, 2.8, 13.6, 0.06, 17.41, 16.05, 19.29), e_post_sd = c(2.34,
    7.76, 7.8, 2.26, 7.4, 11.89, 3.7, 0.13, 5.79, 1.12, 5.16,
    4.17, 6.58), e_sample = c(14, 18, 16, 16, 33, 28, 29, 36,
    38, 27, 43, 25, 17), ri = c(.70,
.70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70)), .Names = c("study",
"c_pre_mean", "c_pre_sd",
"c_post_mean", "c_post_sd", "c_sample", "e_pre_mean", "e_pre_sd",
"e_post_mean", "e_post_sd", "e_sample", "ri"), class = "data.frame",
row.names = c(NA,
-13L))


### check the data

dim(dat)
head(dat)
str(dat)

attach(dat) #### yes, I know, do'nt do this....

# call the library

library(metafor)


# Computing Standardized Mean Difference (Hedges' g) for Each Group
(experimental and control) at post treatment
# use "SMD" for the standardized mean difference using raw score
standardization

datT <- escalc(measure="SMD", m1i=e_post_mean, sd1i=e_post_sd,
n1i=e_sample, m2i=c_post_mean, sd2i=c_post_sd, n2i=c_sample, vtype="UB",
data=dat, append=TRUE)


# Extract the effect size ( Standardized Mean Difference (Hedges' g)) and
its variance

yi <- datT$yi
vi <- datT$vi



###############################################
#
# fixed-effects model
#
###############################################

model.FE <- rma(yi, vi, method="FE", digits=2)

summary(model.FE)

# plot globale

plot(model.FE, slab=paste(study))

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Mon Apr 13 23:36:08 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Mon, 13 Apr 2015 21:36:08 +0000
Subject: [R] BIG difficulties in Using boot.ci (bot package)
In-Reply-To: <2076144842.2131690.1428951321816.JavaMail.yahoo@mail.yahoo.com>
References: <552BFC4C.4010904@frontier.com>
	<2076144842.2131690.1428951321816.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED19ED8@WAXMXOLYMB025.WAX.wa.lcl>

That is probably the number one reason for requesting a reproducible example when writing to R-help. In the proce3ss of working that out, you often solve your own problem.

Best of luck with your bootstrapping,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of varin
> sacha
> Sent: Monday, April 13, 2015 11:55 AM
> To: Daniel Nordlund; r-help at r-project.org
> Subject: Re: [R] BIG difficulties in Using boot.ci (bot package)
> 
> Hi Daniel,
> 
> Sorry for that, once more.... ;=(
> 
> Here is the reproducible code and this time IT WORKS FINALLY !!!
> 
> GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> df=data.frame(GDP.LOG,Quality.score,Competitivness.score)
> 
> fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> install.packages("boot")
> library(boot)
> bs=function(formula,data,indices){
> d=data[indices,]
> fit=lm(formula,data=d)
> (coef(fit))
> }
> results=boot(data=df,statistic=bs, R=2000,formula= GDP.LOG ~
> Quality.score + Competitivness.score)
> boot.ci(results,type="bca",index=1)
> boot.ci(results,type="bca",index=2)
> boot.ci(results,type="bca",index=3)
> 
> Best,
> S
> 
> 
> 
> ----- Mail original -----
> De : Daniel Nordlund <djnordlund at frontier.com>
> ? : r-help at r-project.org
> Cc :
> Envoy? le : Lundi 13 avril 2015 19h26
> Objet : Re: [R] BIG difficulties in Using boot.ci (bot package)
> 
> On 4/13/2015 9:06 AM, varin sacha wrote:
> > Hi Michael,
> >
> > Thanks for your response. About the data frame not necessary. I
> correct the code according to your comments. I still get the following
> warnings :
> > [1] "All values of t are equal to  5.75620151906917 \n Cannot
> calculate confidence intervals"
> > NULL
> >
> > I have found this on the Net :
> > "Note that boot.ci just gives a warning and returns NA values, if all
> values are equal. There is no error and if you can work with NAs, there
> is no need for the if condition.
> > The boot package assumes that the bootstrap
> > statistic has all ways the same dimension.
> > Whenever you have a statistic with less dimensions you get an NA
> > or 0 or whatever you want".
> >
> > The reproducible code :
> >
> > GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> > Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> > Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> > fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> > install.packages("boot")
> > library(boot)
> > bs=function(formula,data,indices){
> > d=data[indices,]
> > fit=lm(formula,data=d)
> > (coef(fit))
> > }
> > results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~
> Quality.score + Competitivness.score)
> > boot.ci(results,type="bca",index=1)
> > boot.ci(results,type="bca",index=2)
> > boot.ci(results,type="bca",index=3)
> >
> > How is it possible to avoid that warning ?
> >
> > Best,
> > S
> >
> >
> >
> 
> The first problem is that this is not reproducible code.  This is what
> I
> get when I run your code on my computer:
> 
> > GDP.LOG <-c(14,12,13,15.5,16,17,16.5,13.5,12.5,12)
> > Quality.score <-c(12,11,13,14,15,16,12,10,9,9)
> > Competitivness.score=c(8,6,7,5,6.5,7,8,4.5,6,7)
> > fit <- lm(formula = GDP.LOG ~ Quality.score + Competitivness.score)
> > #####install.packages("boot")
> > library(boot)
> > bs=function(formula,data,indices){
> + d=data[indices,]
> + fit=lm(formula,data=d)
> + (coef(fit))
> + }
> > results=boot(data=Dataset,statistic=bs, R=2000,formula= GDP.LOG ~
> Quality.score + Competitivness.score)
> Error in NROW(data) : object 'Dataset' not found
> > boot.ci(results,type="bca",index=1)
> Error in boot.ci(results, type = "bca", index = 1) :
>    object 'results' not found
> > boot.ci(results,type="bca",index=2)
> Error in boot.ci(results, type = "bca", index = 2) :
>    object 'results' not found
> > boot.ci(results,type="bca",index=3)
> Error in boot.ci(results, type = "bca", index = 3) :
>    object 'results' not found
> >
> 
> 
> A reproducible example means that when I run your code on my machine, I
> get the same results / warnings / errors that you get.  I got something
> different.
> 
> 
> Dan
> 
> --
> Daniel Nordlund
> Bothell, WA USA
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drjimlemon at gmail.com  Mon Apr 13 23:45:13 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 14 Apr 2015 07:45:13 +1000
Subject: [R] Convert color hex code to color names
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67DC2F@mb02.ads.tamu.edu>
References: <CAEeP31t6Hgm7n6sd_tL8v4d+Lke+uErviELSABGnBzb20XSSEQ@mail.gmail.com>
	<CAJuCY5xDHSE=uq=DkNT-xLT+MPwvAnkk4QG3Y-8YfaiyJHrV5A@mail.gmail.com>
	<1E8A4447-78B6-4FE6-BEF2-BAABEEF8159E@utoronto.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67DBF2@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67DC2F@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fWsAEAMgA2tyj76EY5hQn_q6kqw-KZ+9z8UJe4XVs8SMg@mail.gmail.com>

Hi Alejo,
The color.id function in plotrix will do this, one color at a time:

sapply(rainbow(6),color.id)
     #FF0000FF #FFFF00FF #00FF00FF #00FFFFFF #0000FFFF #FF00FFFF
[1,] "red"     "yellow"  "green"   "cyan"    "blue"    "magenta"
[2,] "red1"    "yellow1" "green1"  "cyan1"   "blue1"   "magenta1"

Jim


On Tue, Apr 14, 2015 at 3:42 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Actually all 6 colors in rainbow(6) do have names. I missed the fact that
> rainbow() adds an alpha value that we need to strip off before comparing to
> the values in clrs$RGB:
>
> > rain <- substr(rain, 1, 7)
> > sum(clrs$RGB %in% rain)
> [1] 12
>
> So there are two color names for each color in rainbow(6):
>
> > for (i in 1:6) cat(i, colors()[clrs$RGB==rain[i]], "\n")
> 1 red red1
> 2 yellow yellow1
> 3 green green1
> 4 cyan cyan1
> 5 blue blue1
> 6 magenta magenta1
>
> David C
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L
> Carlson
> Sent: Monday, April 13, 2015 12:07 PM
> To: Boris Steipe; Alejo C.S.
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert color hex code to color names
>
> And expanding at a more elementary level. The reason you need to find the
> smallest difference is
> that all of the possible colors do not have names. There are 256^3 =
> 16,777,216 possible rgb color designations, but only 657 named colors. You
> can create a data frame of the named colors and their rgb designations using
>
> > clrs <- data.frame(Color=colors(), RGB=rgb(t(col2rgb(colors())),
>     maxColorValue=255), stringsAsFactors=FALSE)
> > str(clrs)
> 'data.frame':   657 obs. of  2 variables:
>  $ Color: chr  "white" "aliceblue" "antiquewhite" "antiquewhite1" ...
>  $ RGB  : chr  "#FFFFFF" "#F0F8FF" "#FAEBD7" "#FFEFDB" ...
> > head(clrs)
>           Color     RGB
> 1         white #FFFFFF
> 2     aliceblue #F0F8FF
> 3  antiquewhite #FAEBD7
> 4 antiquewhite1 #FFEFDB
> 5 antiquewhite2 #EEDFCC
> 6 antiquewhite3 #CDC0B0
>
> So most colors do not have names. In your example, none of the colors in
> rainbow(6) have names:
>
> > rain <- rainbow(6)
> > sum(clrs$RGB %in% rain)
> [1] 0
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris
> Steipe
> Sent: Monday, April 13, 2015 11:44 AM
> To: Alejo C.S.
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert color hex code to color names
>
> To add slightly to that:
>
> What you want to do is write a function that returns the named color that
> has the smallest difference to your input hex-triplet. But note that color
> difference is a large topic. Assuming you want to minimize *perceptual*
> differences, you want to calculate your differences in Lab color space. The
> function convertColor() has the option to convert hex to Lab. Example:
> convertColor(t(col2rgb("thistle")), from="sRGB", to="Lab", scale.in=255)
>
> Within Lab space, you can take the Euclidian distance.
>
> That all said, I can't imagine why one would want to do this in the first
> place - color triplets are much more convenient than label strings :-)
>
>
> B.
>
>
>
>
> On Apr 13, 2015, at 11:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> > A combination of rgb(), col2rgb() and colors() can gives hex values for
> the
> > named colors.
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-04-13 17:28 GMT+02:00 Alejo C.S. <alej.c.s at gmail.com>:
> >
> >> Hi all, I want to convert the output of:
> >>
> >>> rainbow(6)
> >>
> >>> [1] "#FF0000FF" "#FFFF00FF" "#00FF00FF" "#00FFFFFF" "#0000FFFF"
> >> "#FF00FFFF"
> >>
> >> To a vector of color names. Any tip?
> >>
> >>
> >> Thanks in advance
> >>
> >> C.
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Tue Apr 14 00:00:34 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 13 Apr 2015 23:00:34 +0100
Subject: [R] calculate Cy0 with qpcR package when fitting is failed
Message-ID: <CAMk+s2RS9Unk8nRvkwy1XdSqYbmivRZvz0kMWqJZeXfBdm52Ug@mail.gmail.com>

Dear all,
i am trying to calculate the Cy0 from a series of PCR runs in the
384-well. I can create the regression model using the modlist
function:
   ml<-modlist(
      obj,
      cyc = 1,
      model = l4,
      norm = "FALSE",
      remove = "none"
    )

where obj is the dataframe with the fluorescence data and ml is the
resulting vector with 384 elements, but when i try to create the Cy0
values i get the error:
> Cy0(ml, plot = "FALSE")
Error in seq.default(MIN, MAX, by = DIVS) :
  'from' cannot be NA, NaN or infinite


I reckon that this is due to failed amplification data but i don't
know how to screen the function from these abnormal values. when i run
the modlist with arguments remove = "fit" i get the 372 elements but
Cy0 returns the same error.

How can i overcome this issue?
Many thanks,
Luigi


From lists at revelle.net  Tue Apr 14 00:01:25 2015
From: lists at revelle.net (William Revelle)
Date: Mon, 13 Apr 2015 17:01:25 -0500
Subject: [R] PCA analysis and bootstraped loadings
In-Reply-To: <CADKEMqhAXAA9uciZL89OUeRu9vsPQAGY0v7AWn8DmFtUHAJp3A@mail.gmail.com>
References: <20150413180754.20996zowjdl5cdss@web-mail.uibk.ac.at>
	<CADKEMqhAXAA9uciZL89OUeRu9vsPQAGY0v7AWn8DmFtUHAJp3A@mail.gmail.com>
Message-ID: <64FEFE4A-D71D-4A8C-9615-119FE073B8B6@revelle.net>

psych does not currently have bootstrapped confidence intervals for loadings.  That is a reasonable request and I will try to add it, perhaps in the ?real soon now? version of 1.5.4 (almost finished), perhaps in the next release,

Bill

> On Apr 13, 2015, at 2:38 PM, stephen sefick <ssefick at gmail.com> wrote:
> 
> Hi,
> 
> Please search the mailing list archives for this, or type bootstrapped PCA
> R into google. Please provide a minimal self-contained example of what you
> are trying to solve. Please read the posting guide that is referenced at
> the end of every email.
> kind regards,
> 
> Stephen
> 
> On Mon, Apr 13, 2015 at 11:07 AM, Efstathia Defteraiou <
> Efstathia.Defteraiou at student.uibk.ac.at> wrote:
> 
>> Dear All,
>> 
>> I am relatively new in R.
>> Im working with the 'psych' package and 'principal' function.
>> I would like to know how to generate the bootstraped conf.intervals for
>> loadings,
>> looking for sth similar to setting 'n.iter' argument for the 'fa' function.
>> 
>> If in 'psych' can't work and suggest me the 'boot' package please provide
>> specific Rscript since I don't understand the commands and arguments that
>> have to be used before calling the function 'boot'( what are indices? what
>> to define as what inside function(){})
>> 
>> The names Im using are included in the following code:
>> 'newdata3.1' is my data and provided as data.frame
>> 
>> makingtheanalysis3.1 <-principal(newdata3.1, nfactors =3,
>>                              residuals = FALSE,
>>                              covar=FALSE,rotate="varimax",scores=TRUE)
>> 
>> 
>> I am sorry for not providing a specific code but my data are too large
>> 
>> Any Help appreciated
>> Cheers!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
> 
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
> 
>                                -K. Mullis
> 
> "A big computer, a complex algorithm and a long time does not equal
> science."
> 
>                              -Robert Gentleman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From ntfredo at gmail.com  Tue Apr 14 09:46:51 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 14 Apr 2015 10:46:51 +0300
Subject: [R] Sum of some months totals
Message-ID: <CAGh51gR9DqAk19-KybiXCgxN+SLOzL0OQ_vofW4Oez7yYr4tZg@mail.gmail.com>

I want to compute monthly summaries from daily data. I want to choose which
month to start and how many months to total over.  Default could be to
start in January and total over 3 months.  For the number of rain days the
default threshold is 0.85mm.

I tried to make a function which sum all months not some of months. I will
appreciate any help from you guys. Thanks.
Here is the data and the code I used.

> dput(head(kitale))structure(list(Year = c(1979L, 1979L, 1979L, 1979L, 1979L, 1979L
), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Rain = c(0,
0, 0, 0, 0, 0)), .Names = c("Year", "Month", "Day", "Rain"), row.names = c(NA,
6L), class = "data.frame")

here is the function:

total = function(data, threshold = 0.85){
  month_tot=matrix(NA,31,12)
  rownames(month_tot)=as.character(1979:2009)
  colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
  raindays=month_tot
  # loop over months and years to get summary statistics
  for (mon in 1:12) {
    rain=data[data[2]==mon,c(1,4)]   # rain just for a specific month
    for (yr in 1979:2009) {
      month_tot[yr-1978,mon]=sum(rain[rain[,1]==yr,2])
      raindays[yr-1978,mon]=sum(rain[rain[,1]==yr,2]>threshold)
    }
  }
  month_tot
}

Regards,

Frederic.



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Apr 14 10:34:11 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 14 Apr 2015 09:34:11 +0100
Subject: [R] metafor - Cochrane on change score in pre-post design
In-Reply-To: <CAPmpGDtex294Rg31n0Ke76qMWS_fCVeR2wNHfUeJX0Gd_0wOyg@mail.gmail.com>
References: <CAPmpGDtex294Rg31n0Ke76qMWS_fCVeR2wNHfUeJX0Gd_0wOyg@mail.gmail.com>
Message-ID: <552CD103.7010007@dewey.myzen.co.uk>

Comment below

On 13/04/2015 20:46, Antonello Preti wrote:
> Hi, this is another quesite related to the use of 'metafor' for calculation
> of standardized mean change in pre-post design studies.
> Essentially, my aim is to compare different method to arrive at the same
> conclusion: Does the treatment work?
>
> The Cochrane manual advise not to calculate change score:
>
> "9.4.5.2  Meta-analysis of change scores
>
> In some circumstances an analysis based on changes from baseline will be
> more efficient and powerful than comparison of final values,
> as it removes a component of between-person variability from the analysis.
> However, calculation of a change score requires measurement of the outcome
> twice
> and in practice may be less efficient for outcomes which are unstable or
> difficult to measure precisely,
> where the measurement error may be larger than true between-person baseline
> variability.
> Change-from-baseline outcomes may also be preferred if they have a less
> skewed distribution than final measurement outcomes.
> Although sometimes used as a device to ?correct? for unlucky randomization,
> this practice is not recommended.
>
> The preferred statistical approach to accounting for baseline measurements
> of the outcome variable
> is to include the baseline outcome measurements as a covariate in a
> regression model or analysis of covariance (ANCOVA)".
>

As I read Cochrane this is a comment about which data you should extract 
from the primary studies if you have a choice. It is not a 
recommendation to you the meta-analyst about how you subsequently 
conduct the meta-analysis of the extracted data.

> My question is: how do include both baseline (experimental and control
> group)  in the analysis as a covariate in 'metafor'?
> So, far, this is what I did.
> I kinly request some help tp add the baseline as covariate to comply with
> the Cochrane suggestion-
> How can I add the baseline mean in both groups?
> Should I consider baseline standard deviation, and if yes, how?
> Should I take into account dropouts? I mean, in some sample at baseline n =
> 30 and 35 and at end of treatment n was 28 and 29...
>
>
>
> Thank you in advance,
> Antonello Preti
>
>
>
>
> This is my dataset (with imputed r = 0.70 for pre-post correlation, put in
> the 'ri' variable):
>
> ##### the data
>
> dat <- structure(list(study = structure(c(11L, 8L, 7L, 12L, 13L, 4L,
> 5L, 1L, 10L, 3L, 6L, 9L, 2L), .Label = c("Study A, 2012",
> "Study B, 2013", "Study C, 2013", "Study D, 2010",
> "Study E, 2012", "Study F, 2013", "Study G, 2006",
> "Study H, 2005", "Study I, 2013", "Study L, 2012",
> "Study M, 2003", "Study N, 2007", "Study P, 2007"
> ), class = "factor"), c_pre_mean = c(4.9, 15.18, 19.01, 5.1,
> 16.5, 27.35, 18.1, 2.4, 14.23, 0.08, 21.26, 21.5, 21.73), c_pre_sd = c(2.6,
> 2.21, 7.1, 1.5, 7.2, 13.92, 5.4, 0.13, 4.89, 0.94, 7.65, 5.22,
> 8.43), c_post_mean = c(6.1, 13.98, 18.5, 4.53, 15.9, 23, 16.9,
> 2.2, 16.58, -0.02, 16, 16.84, 23.54), c_post_sd = c(2.06, 3.24,
> 7, 2.06, 6.8, 12.06, 3.8, 0.13, 6.35, 0.88, 4.69, 4.64, 6.74),
>      c_sample = c(14, 13, 19, 15, 34, 20, 24, 35, 31, 26, 49,
>      21, 22), e_pre_mean = c(4.6, 13.81, 19.9, 5.3, 18.7, 22.71,
>      19.2, 2.7, 15.97, -0.22, 20.9, 20.43, 21.94), e_pre_sd = c(2.1,
>      6.64, 8.1, 2.9, 7.3, 7.82, 4.1, 0.13, 6.73, 0.93, 5.18, 4.87,
>      7.02), e_post_mean = c(4.64, 15.86, 18.1, 4.33, 17.2, 24.89,
>      17.6, 2.8, 13.6, 0.06, 17.41, 16.05, 19.29), e_post_sd = c(2.34,
>      7.76, 7.8, 2.26, 7.4, 11.89, 3.7, 0.13, 5.79, 1.12, 5.16,
>      4.17, 6.58), e_sample = c(14, 18, 16, 16, 33, 28, 29, 36,
>      38, 27, 43, 25, 17), ri = c(.70,
> .70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70,.70)), .Names = c("study",
> "c_pre_mean", "c_pre_sd",
> "c_post_mean", "c_post_sd", "c_sample", "e_pre_mean", "e_pre_sd",
> "e_post_mean", "e_post_sd", "e_sample", "ri"), class = "data.frame",
> row.names = c(NA,
> -13L))
>
>
> ### check the data
>
> dim(dat)
> head(dat)
> str(dat)
>
> attach(dat) #### yes, I know, do'nt do this....
>
> # call the library
>
> library(metafor)
>
>
> # Computing Standardized Mean Difference (Hedges' g) for Each Group
> (experimental and control) at post treatment
> # use "SMD" for the standardized mean difference using raw score
> standardization
>
> datT <- escalc(measure="SMD", m1i=e_post_mean, sd1i=e_post_sd,
> n1i=e_sample, m2i=c_post_mean, sd2i=c_post_sd, n2i=c_sample, vtype="UB",
> data=dat, append=TRUE)
>
>
> # Extract the effect size ( Standardized Mean Difference (Hedges' g)) and
> its variance
>
> yi <- datT$yi
> vi <- datT$vi
>
>
>
> ###############################################
> #
> # fixed-effects model
> #
> ###############################################
>
> model.FE <- rma(yi, vi, method="FE", digits=2)
>
> summary(model.FE)
>
> # plot globale
>
> plot(model.FE, slab=paste(study))
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr 14 10:58:09 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 14 Apr 2015 10:58:09 +0200
Subject: [R] 'metafor' - standardized mean difference in pre-post
	design	studies
In-Reply-To: <CAPmpGDvF64ovqY1qnCAqhc+cdPAr9Uuh4pycapHG3rr5amPxgA@mail.gmail.com>
References: <CAPmpGDvF64ovqY1qnCAqhc+cdPAr9Uuh4pycapHG3rr5amPxgA@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F09A20701@UM-MAIL4112.unimaas.nl>

> Hi, I have a quesite on meta-analysis with 'metafor'.
> I would like to calculate the standardized mean difference (SMD), as
> Hedges' g, in pre-post design studies.
> I have data on baseline (sample size, mean and SD in both the
> experimental
> and the control group) and at end of treatment (same as before).
> The 'metafor' site report a calculation based on Morris (2008).
> However, I would like to calculate the SMD as in Comprehensive
> Meta-analysis according to Borenstein:
> 
> d = (mean.pre - mean.post) / SD_within
> 
> SD_within = SD.diff / square root (2(1-r)

Note that this assumes that the SDs are the same at baseline and at the end of the treatment. Also, it is not how d values for pre-post designs are typically computed. There are several articles that describe various approaches, in particular:

Becker, B. J. (1988). Synthesizing standardized mean-change measures. British Journal of Mathematical and Statistical Psychology, 41(2), 257-278.

Gibbons, R. D., Hedeker, D. R., & Davis, J. M. (1993). Estimation of effect size from a series of experiments involving paired comparisons. Journal of Educational Statistics, 18(3), 271-279.

Morris, S. B. (2000). Distribution of the standardized mean change effect size for meta-analysis on repeated measures. British Journal of Mathematical and Statistical Psychology, 53(1), 17-29.

Morris, S. B., & DeShon, R. P. (2002). Combining effect size estimates in meta-analysis with repeated measures and independent-groups designs. Psychological Methods, 7(1), 105-125.

Morris, S. B. (2008). Estimating effect sizes from pretest-posttest-control group designs. Organizational Research Methods, 11(2), 364-386.

The two approaches that have been most thoroughly studied and described are:

d = (mean.pre - mean.post) / SD.diff

(standardization by the change score SD) and

d = (mean.pre - mean.post) / SD.pre

(standardization by the pre-test SD; one could also use the post-test SD).

The method described in the book is a bit of a juxtaposition, where SD.diff is 'corrected' by 1/sqrt(2*(1-r)), which is identical to SD.pre (or SD.post) when SD.pre = SD.post. But that's never exactly the case. Plus I am not aware of any proper derivations of the large-sample distribution of d computed in this manner.

> r = correlation between pairs of observation (often it is not reported,
> and suggestion is to use r = 0.70)

Suggested where? I hope this is not a general "if you don't know the correlation, just use .70" suggestion, because that would be nonsense. If you don't know r for the sample, then you could try to make a reasonable guess that is informed by the characteristic or attribute that is being measured (some things are much more stable than other things) and the timelag between baseline and the follow-up measurement. Also, if some treatment happens between baseline and follow-up -- and some people are more likely to respond to the treatment than others -- then this is likely to reduce the correlation to some extent, depending on how much variability there is in treatment responses. These are at least some of the considerations that should go into making a proper guess about r.

> The variance of d (Vd) is calculated as (1/n + d^2/2n)2(1-r), where n =
> number of pairs

As mentioned above, I am not aware of any derivation of that equation. One can show that 2(1-r)/n + d^2/2n is an estimate of the asymptotic sampling variance of d when d is computed as (mean.pre - mean.post) / SD.pre (or with SD.post). So, when d is computed in the manner above, it is a bit like (mean.pre - mean.post) / SD.pre -- except for the way that SD.pre is actually estimated. So, if anything, the equation should look more like the one above and not the one in the book. I have actually communicated with Michael and Larry (Hedges) about this and Michael indicated that changes may need to be made to CMA.

> To derive Hedges' g from d, the correction 'J' is used:
> 
> J = 1 - (3/4df - 1), where df = degrees of freedom, which in two
> independent groups is n1+n2-2
> 
> Essentially, J = 1 - (3/4*((n1+n2)-2) - 1)
> 
> Ultimately, g = J x d, and variance of g (Vg) = J^2 x Vd
> 
> I had some hint by Wolfgang Viechtbauer, but I'm stucked on here
> (essentially, because my poor programming abilities)
> I was stuck on applying the Viechtbauer's hint to my dataset.
> Probably I'm doing something wrong. However, what I get it is not what I
> found with Comprehensive Meta-Analysis.
> In CMA I've found g = -0.49 (95%CI: -0.64 to -0.33).

You won't get the same thing, as CMA does what is described in the book, but that's not what metafor does (due to the reasons described above).

> Moreover, I do not know how to apply the J correction for calculating the
> Hedges'g.
> My request is: can anyone check the codes?
> Can anyone help me in adding the J correction?
> What should I multiply for J?
> Should I use the final yi and vi as measures of d and Variance of d?

Why don't you just use what escalc() gives you?

> Thank you in advance,
> Antonello Preti

[code snipped]

Best,
Wolfgang


From sojoodmlk1990 at gmail.com  Tue Apr 14 10:45:05 2015
From: sojoodmlk1990 at gmail.com (Sojood Malkawi)
Date: Tue, 14 Apr 2015 11:45:05 +0300
Subject: [R] R studio installation
Message-ID: <CAFKhfauizOVx8MH+M6DGj1DKw4=0LoLkYQn_zLZs0FOqDARxHw@mail.gmail.com>

I installed R and then R studio but it doesn't open every time i try to
open it it gives me this message  "Rstudio requires an existing
installation of R in order to work. please select the version of R to use ".
i'm using R i386 3.1.3 and downloaded RStudio 0.98.1103 - Windows
XP/Vista/7/8. do you have any idea what the problem is??

	[[alternative HTML version deleted]]


From bahrami.afsaneh at gmail.com  Tue Apr 14 02:21:30 2015
From: bahrami.afsaneh at gmail.com (Afsaneh Bahrami)
Date: Tue, 14 Apr 2015 10:21:30 +1000
Subject: [R] Using Markov Regime Switching Model to Forecast
Message-ID: <CAFCiDbbjmN8nbLykaJ_f4JEGd7P3+HOEVxmf6vRRNBepAfDtPg@mail.gmail.com>

Dear R Users,

Is there any package in R that use Markov Regime switching model to forecast
?

I need to do one-step ahead forecast using a Markov Regime switching  model.
I have one predictor variable that switches across  2 regimes. I had a
look, but I couldn't find a package in R which use a Markov Regime
switching model for forecasting. Would you please let me know if there is
any package to do that?

I really appreciate any information.

Regards
Afsaneh

	[[alternative HTML version deleted]]


From Efstathia.Defteraiou at student.uibk.ac.at  Tue Apr 14 12:03:11 2015
From: Efstathia.Defteraiou at student.uibk.ac.at (Efstathia Defteraiou)
Date: Tue, 14 Apr 2015 12:03:11 +0200
Subject: [R] PCA analysis and bootstraped loadings
In-Reply-To: <64FEFE4A-D71D-4A8C-9615-119FE073B8B6@revelle.net>
References: <20150413180754.20996zowjdl5cdss@web-mail.uibk.ac.at>
	<CADKEMqhAXAA9uciZL89OUeRu9vsPQAGY0v7AWn8DmFtUHAJp3A@mail.gmail.com>
	<64FEFE4A-D71D-4A8C-9615-119FE073B8B6@revelle.net>
Message-ID: <20150414120311.181221h2t0kuga9w@web-mail.uibk.ac.at>

Dear All,
Thank You for the quick responses.
Managed to solve my problem through:
http://www.faculty.biol.ttu.edu/strauss/multivar/R/SamplePCABootstrap.R.txt
or
http://r.789695.n4.nabble.com/bootstrapped-eigenvector-method-following-prcomp-td877655.html
Used the first one however, code is too long since everything is  
manually done.
The suggestion of Bill would be very kind and save a lot of time in  
the future.
Thanks William for clearing this up.

Cheers
Efi


Zitat von William Revelle <lists at revelle.net>:

> psych does not currently have bootstrapped confidence intervals for  
> loadings.  That is a reasonable request and I will try to add it,  
> perhaps in the ?real soon now? version of 1.5.4 (almost finished),  
> perhaps in the next release,
>
> Bill
>
>> On Apr 13, 2015, at 2:38 PM, stephen sefick <ssefick at gmail.com> wrote:
>>
>> Hi,
>>
>> Please search the mailing list archives for this, or type bootstrapped PCA
>> R into google. Please provide a minimal self-contained example of what you
>> are trying to solve. Please read the posting guide that is referenced at
>> the end of every email.
>> kind regards,
>>
>> Stephen
>>
>> On Mon, Apr 13, 2015 at 11:07 AM, Efstathia Defteraiou <
>> Efstathia.Defteraiou at student.uibk.ac.at> wrote:
>>
>>> Dear All,
>>>
>>> I am relatively new in R.
>>> Im working with the 'psych' package and 'principal' function.
>>> I would like to know how to generate the bootstraped conf.intervals for
>>> loadings,
>>> looking for sth similar to setting 'n.iter' argument for the 'fa' function.
>>>
>>> If in 'psych' can't work and suggest me the 'boot' package please provide
>>> specific Rscript since I don't understand the commands and arguments that
>>> have to be used before calling the function 'boot'( what are indices? what
>>> to define as what inside function(){})
>>>
>>> The names Im using are included in the following code:
>>> 'newdata3.1' is my data and provided as data.frame
>>>
>>> makingtheanalysis3.1 <-principal(newdata3.1, nfactors =3,
>>>                              residuals = FALSE,
>>>                              covar=FALSE,rotate="varimax",scores=TRUE)
>>>
>>>
>>> I am sorry for not providing a specific code but my data are too large
>>>
>>> Any Help appreciated
>>> Cheers!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>>
>>                                -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                              -Robert Gentleman
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> William Revelle		           http://personality-project.org/revelle.html
> Professor			           http://personality-project.org
> Department of Psychology   http://www.wcas.northwestern.edu/psych/
> Northwestern University	   http://www.northwestern.edu/
> Use R for psychology             http://personality-project.org/r
> It is 3 minutes to midnight	   http://www.thebulletin.org
>
>
>
>
>
>
>


From dasolexa at hotmail.com  Tue Apr 14 12:48:53 2015
From: dasolexa at hotmail.com (David)
Date: Tue, 14 Apr 2015 12:48:53 +0200
Subject: [R] help assigning values to matrix
In-Reply-To: <DUB130-W723AA68EC7D67BC7DA4982C6090@phx.gbl>
References: <DUB130-W723AA68EC7D67BC7DA4982C6090@phx.gbl>
Message-ID: <DUB130-W4F1DDB2BD1D55E2F272D8C6E60@phx.gbl>



Hi group,
 
I am automatically creating several matrices to store results from different analyses on vectors of different lengths. The matrices are named according  to each vector, so I can trace back results. I am using the following commands, which give me an error. My idea is to populate the for loop to include several steps and keep adding results to the matrices. But to start with:
 
> ls()
[1] "PS013_1" "PS056_1" "PS058_1" "PS080_1" "PS117_1" "PS193_1" "PS194_1"
 
> mynames<- c("PS013","PS056","PS058","PS080","PS117","PS193","PS194")
 
> for (j in 1:length(mynames))    {
 
#create as many 13x3 matrices as vectors I have. The rowname of the last row will be the length of the vector
> assign(paste("results",mynames[j],"1",sep="_"),matrix(data=NA,nrow=13,ncol=3,dimnames = list(c(10,20,30,35,40,50,60,70,80,90,100,120,print(length(get(paste(mynames[j],1,sep="_"))))),c("col1","col2","col3")))) 
 
# Example: assign three values in the last row of the created matrices
>assign(paste("results",mynames[j],"1",sep="_")[13,],c(3,4,5))

}
 
Error in paste("results", mynames[j], "1", sep = "_")[13, ] : 
  incorrect number of dimensions
 
 
I have noticed that to access the positions of a matrix I cannot use [row,column] coordinates, but actual "count" positions like:
 
#let's write something  in one of the matrices, since they are all NAs
> results_PS013_1[1,]<-c(1,14,27)
> get(paste("results",mynames[1],"1",sep="_"))
    col1 col2     col3      
10  1 14 27
20  NA     NA      NA       
30  NA     NA      NA       
35  NA     NA      NA       
40  NA     NA      NA       
50  NA     NA      NA       
60  NA     NA      NA       
70  NA     NA      NA       
80  NA     NA      NA       
90  NA     NA      NA       
100 NA     NA      NA       
120 NA     NA      NA       
295 NA     NA      NA
 
> get(paste("results",mynames[1],"1",sep="_"))[1]
[1] 1
> get(paste("results",mynames[1],"1",sep="_"))[2]
[1] NA
> get(paste("results",mynames[1],"1",sep="_"))[14]
[1] 14
> get(paste("results",mynames[1],"1",sep="_"))[c(1,14,27)]
[1] 1    14   27
 
So if I try to write three other values to the first row of the first matrix, I now try the following
 
> assign(get(paste("results",mynames[1],"1",sep="_"))[c(1,14,27)],c(3,4,5))
Error in assign(get(paste("results", mynames[1], "1", sep = "_"))[c(1,  : 
  invalid first argument

 
Can anyone explain to me why I cannot assign the values in this way and how is it that I cannot use [row,column] coordinates?
 
Thanks in advance for your help
 
Dave
            
 		 	   		  
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Apr 14 12:52:23 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 14 Apr 2015 05:52:23 -0500
Subject: [R] Sum of some months totals
In-Reply-To: <CAGh51gR9DqAk19-KybiXCgxN+SLOzL0OQ_vofW4Oez7yYr4tZg@mail.gmail.com>
References: <CAGh51gR9DqAk19-KybiXCgxN+SLOzL0OQ_vofW4Oez7yYr4tZg@mail.gmail.com>
Message-ID: <CAN5YmCF7_RsBARJy67GxO8KPHA58sexebu=er1LK1FLjA4m8Og@mail.gmail.com>

If you want to calculate the number of days having greater than a certain
threshold of rain within a range of months, a function like this might
serve your needs.

raindays <- function(data, monStart=1, monEnd=3, threshold=0.85) {
  with(data, {
    selRows <- Month >= monStart & Month <= monEnd & Rain > threshold
    days <- tapply(selRows, Year, sum)
    return(days)
  })
}

raindays(kitale)

Jean

On Tue, Apr 14, 2015 at 2:46 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> I want to compute monthly summaries from daily data. I want to choose which
> month to start and how many months to total over.  Default could be to
> start in January and total over 3 months.  For the number of rain days the
> default threshold is 0.85mm.
>
> I tried to make a function which sum all months not some of months. I will
> appreciate any help from you guys. Thanks.
> Here is the data and the code I used.
>
> > dput(head(kitale))structure(list(Year = c(1979L, 1979L, 1979L, 1979L,
> 1979L, 1979L
> ), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Rain = c(0,
> 0, 0, 0, 0, 0)), .Names = c("Year", "Month", "Day", "Rain"), row.names =
> c(NA,
> 6L), class = "data.frame")
>
> here is the function:
>
> total = function(data, threshold = 0.85){
>   month_tot=matrix(NA,31,12)
>   rownames(month_tot)=as.character(1979:2009)
>
> colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
>   raindays=month_tot
>   # loop over months and years to get summary statistics
>   for (mon in 1:12) {
>     rain=data[data[2]==mon,c(1,4)]   # rain just for a specific month
>     for (yr in 1979:2009) {
>       month_tot[yr-1978,mon]=sum(rain[rain[,1]==yr,2])
>       raindays[yr-1978,mon]=sum(rain[rain[,1]==yr,2]>threshold)
>     }
>   }
>   month_tot
> }
>
> Regards,
>
> Frederic.
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Apr 14 13:10:01 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 14 Apr 2015 14:10:01 +0300
Subject: [R] Sum of some months totals
In-Reply-To: <CAN5YmCF7_RsBARJy67GxO8KPHA58sexebu=er1LK1FLjA4m8Og@mail.gmail.com>
References: <CAGh51gR9DqAk19-KybiXCgxN+SLOzL0OQ_vofW4Oez7yYr4tZg@mail.gmail.com>
	<CAN5YmCF7_RsBARJy67GxO8KPHA58sexebu=er1LK1FLjA4m8Og@mail.gmail.com>
Message-ID: <CAGh51gR=i=DKPmjnBPpcg7tMuHgoNzrQYMWSV1pou5XC2sQ-6g@mail.gmail.com>

Hi Jean,

Thanks for the help!
How can I compute monthly total of rainfall?

I want to compute both monthly total of rainfall and number of raindays. In
below function month_tot is a table and I want to some month. default is 3
months. The loop for quarter is not working and I am wondering why it is
not working.

total = function(data, threshold = 0.85){
  month_tot=matrix(NA,length(unique(data$Year)),12)
  rownames(month_tot)=as.character(unique(data$Year))

colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
  raindays=month_tot
  # loop over months and years to get summary statistics
  for (mon in 1:12) {
    rain=data[data[2]==mon,c(1,4)]   # rain just for a specific month
    for (yr in unique(data$Year)) {
      month_tot[yr-min(unique(data$Year)-1),mon]=sum(rain[rain[,1]==yr,2])
      #print(sum(rain[rain[,1]==yr,2]))

raindays[yr-min(unique(data$Year)-1),mon]=sum(rain[rain[,1]==yr,2]>threshold)
    }
  }
  month_tot
  1:ncol(month_tot)
  #month_tot[,1] + month_tot[,2] + month_tot[,3]
  quarter <-c()
  i = 3
  for (i in 1:ncol(month_tot)){

    quarter[i] = sum(month_tot[,i])
  }
  quarter
}

total(kitale)

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Apr 14, 2015 at 1:52 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> If you want to calculate the number of days having greater than a certain
> threshold of rain within a range of months, a function like this might
> serve your needs.
>
> raindays <- function(data, monStart=1, monEnd=3, threshold=0.85) {
>   with(data, {
>     selRows <- Month >= monStart & Month <= monEnd & Rain > threshold
>     days <- tapply(selRows, Year, sum)
>     return(days)
>   })
> }
>
> raindays(kitale)
>
> Jean
>
> On Tue, Apr 14, 2015 at 2:46 AM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
>
>> I want to compute monthly summaries from daily data. I want to choose
>> which
>> month to start and how many months to total over.  Default could be to
>> start in January and total over 3 months.  For the number of rain days the
>> default threshold is 0.85mm.
>>
>> I tried to make a function which sum all months not some of months. I will
>> appreciate any help from you guys. Thanks.
>> Here is the data and the code I used.
>>
>> > dput(head(kitale))structure(list(Year = c(1979L, 1979L, 1979L, 1979L,
>> 1979L, 1979L
>>
>> ), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Rain = c(0,
>> 0, 0, 0, 0, 0)), .Names = c("Year", "Month", "Day", "Rain"), row.names =
>> c(NA,
>> 6L), class = "data.frame")
>>
>> here is the function:
>>
>> total = function(data, threshold = 0.85){
>>   month_tot=matrix(NA,31,12)
>>   rownames(month_tot)=as.character(1979:2009)
>>
>> colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
>>   raindays=month_tot
>>   # loop over months and years to get summary statistics
>>   for (mon in 1:12) {
>>     rain=data[data[2]==mon,c(1,4)]   # rain just for a specific month
>>     for (yr in 1979:2009) {
>>       month_tot[yr-1978,mon]=sum(rain[rain[,1]==yr,2])
>>       raindays[yr-1978,mon]=sum(rain[rain[,1]==yr,2]>threshold)
>>     }
>>   }
>>   month_tot
>> }
>>
>> Regards,
>>
>> Frederic.
>>
>>
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Apr 14 13:16:31 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 14 Apr 2015 06:16:31 -0500
Subject: [R] help assigning values to matrix
In-Reply-To: <DUB130-W4F1DDB2BD1D55E2F272D8C6E60@phx.gbl>
References: <DUB130-W723AA68EC7D67BC7DA4982C6090@phx.gbl>
	<DUB130-W4F1DDB2BD1D55E2F272D8C6E60@phx.gbl>
Message-ID: <CAN5YmCGQznSp38arKK3tUcBuXWmtnN9ytXgf=3AZ5OdGdjhF6A@mail.gmail.com>

I think it would be easier to keep track of what you're doing, if you save
the assignment to the very end of your for() loop.  For example ...

# create an empty matrix to be used as a template
Mtemplate <- matrix(data=NA, nrow=13, ncol=3,
    dimnames=list(c(10,20,30,35,40,50,60,70,80,90,100,120,999),
      c("col1", "col2", "col3")))

# create as many 13x3 matrices as vectors I have.
for (j in 1:length(mynames))    {

  # do all your work with the matrix Mnew
  Mnew <- Mtemplate
  # The rowname of the last row will be the length of the vector
  dimnames(Mnew)[[1]][dim(Mnew)[1]] <- length(get(mynames[j]))

  # Example: assign three values in the last row of the created matrices
  Mnew[13, ] <- c(3, 4, 5)

  # then, when you're all done, assign Mnew to the name you want to keep
  Mname <- paste("results", mynames[j], 1, sep="_")
  assign(Mname, Mnew)

}

Jean

On Tue, Apr 14, 2015 at 5:48 AM, David <dasolexa at hotmail.com> wrote:

>
>
> Hi group,
>
> I am automatically creating several matrices to store results from
> different analyses on vectors of different lengths. The matrices are named
> according  to each vector, so I can trace back results. I am using the
> following commands, which give me an error. My idea is to populate the for
> loop to include several steps and keep adding results to the matrices. But
> to start with:
>
> > ls()
> [1] "PS013_1" "PS056_1" "PS058_1" "PS080_1" "PS117_1" "PS193_1" "PS194_1"
>
> > mynames<- c("PS013","PS056","PS058","PS080","PS117","PS193","PS194")
>
> > for (j in 1:length(mynames))    {
>
> #create as many 13x3 matrices as vectors I have. The rowname of the last
> row will be the length of the vector
> >
> assign(paste("results",mynames[j],"1",sep="_"),matrix(data=NA,nrow=13,ncol=3,dimnames
> =
> list(c(10,20,30,35,40,50,60,70,80,90,100,120,print(length(get(paste(mynames[j],1,sep="_"))))),c("col1","col2","col3"))))
>
> # Example: assign three values in the last row of the created matrices
> >assign(paste("results",mynames[j],"1",sep="_")[13,],c(3,4,5))
>
> }
>
> Error in paste("results", mynames[j], "1", sep = "_")[13, ] :
>   incorrect number of dimensions
>
>
> I have noticed that to access the positions of a matrix I cannot use
> [row,column] coordinates, but actual "count" positions like:
>
> #let's write something  in one of the matrices, since they are all NAs
> > results_PS013_1[1,]<-c(1,14,27)
> > get(paste("results",mynames[1],"1",sep="_"))
>     col1 col2     col3
> 10  1 14 27
> 20  NA     NA      NA
> 30  NA     NA      NA
> 35  NA     NA      NA
> 40  NA     NA      NA
> 50  NA     NA      NA
> 60  NA     NA      NA
> 70  NA     NA      NA
> 80  NA     NA      NA
> 90  NA     NA      NA
> 100 NA     NA      NA
> 120 NA     NA      NA
> 295 NA     NA      NA
>
> > get(paste("results",mynames[1],"1",sep="_"))[1]
> [1] 1
> > get(paste("results",mynames[1],"1",sep="_"))[2]
> [1] NA
> > get(paste("results",mynames[1],"1",sep="_"))[14]
> [1] 14
> > get(paste("results",mynames[1],"1",sep="_"))[c(1,14,27)]
> [1] 1    14   27
>
> So if I try to write three other values to the first row of the first
> matrix, I now try the following
>
> > assign(get(paste("results",mynames[1],"1",sep="_"))[c(1,14,27)],c(3,4,5))
> Error in assign(get(paste("results", mynames[1], "1", sep = "_"))[c(1,  :
>   invalid first argument
>
>
> Can anyone explain to me why I cannot assign the values in this way and
> how is it that I cannot use [row,column] coordinates?
>
> Thanks in advance for your help
>
> Dave
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Apr 14 14:14:21 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 14 Apr 2015 04:14:21 -0800
Subject: [R] R studio installation
In-Reply-To: <CAFKhfauizOVx8MH+M6DGj1DKw4=0LoLkYQn_zLZs0FOqDARxHw@mail.gmail.com>
Message-ID: <4809E258EB1.000013FEjrkrideau@inbox.com>

You probably should go to the RStudio help/blog rather than here. This is not an RStudio list and the expertise is at the RStudoi site.

Does R load on its own?

What OS are you using?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sojoodmlk1990 at gmail.com
> Sent: Tue, 14 Apr 2015 11:45:05 +0300
> To: r-help at r-project.org
> Subject: [R] R studio installation
> 
> I installed R and then R studio but it doesn't open every time i try to
> open it it gives me this message  "Rstudio requires an existing
> installation of R in order to work. please select the version of R to use
> ".
> i'm using R i386 3.1.3 and downloaded RStudio 0.98.1103 - Windows
> XP/Vista/7/8. do you have any idea what the problem is?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From highstat at highstat.com  Tue Apr 14 14:21:09 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 14 Apr 2015 13:21:09 +0100
Subject: [R] Statistics course in Palermo
Message-ID: <552D0635.3030102@highstat.com>

Apologies for cross-posting


There are 4 remaining seats on the following course:

Course: Data exploration, regression, GLM & GAM with introduction to R
When:  4-8 May 2015
Where: University of Palermo, Italy
Course flyer: http://www.highstat.com/Courses/Flyer2015_05Palermo.pdf
URL: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From jdnewmil at dcn.davis.CA.us  Tue Apr 14 14:43:24 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Apr 2015 05:43:24 -0700
Subject: [R] R studio installation
In-Reply-To: <4809E258EB1.000013FEjrkrideau@inbox.com>
References: <4809E258EB1.000013FEjrkrideau@inbox.com>
Message-ID: <82F0C7FB-EC8A-4A2D-ABCA-9850B60EC10B@dcn.davis.CA.us>

But if the answer to the question "Does R load on its own?" is "no" then this probably is the right place to ask for help. Of course, I would probably just suggest re-installing R, but someone else here might have better answers.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 14, 2015 5:14:21 AM PDT, John Kane <jrkrideau at inbox.com> wrote:
>You probably should go to the RStudio help/blog rather than here. This
>is not an RStudio list and the expertise is at the RStudoi site.
>
>Does R load on its own?
>
>What OS are you using?
>
>John Kane
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: sojoodmlk1990 at gmail.com
>> Sent: Tue, 14 Apr 2015 11:45:05 +0300
>> To: r-help at r-project.org
>> Subject: [R] R studio installation
>> 
>> I installed R and then R studio but it doesn't open every time i try
>to
>> open it it gives me this message  "Rstudio requires an existing
>> installation of R in order to work. please select the version of R to
>use
>> ".
>> i'm using R i386 3.1.3 and downloaded RStudio 0.98.1103 - Windows
>> XP/Vista/7/8. do you have any idea what the problem is?
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>Can't remember your password? Do you need a strong and secure password?
>Use Password manager! It stores your passwords & protects your account.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rbaer at atsu.edu  Tue Apr 14 15:15:27 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Tue, 14 Apr 2015 08:15:27 -0500
Subject: [R] Obfuscate AES password
In-Reply-To: <CAFnz2-_yHGwhnMXZDNgD35-WiZiMmPXFyBkgbScFGgXYFaDSHw@mail.gmail.com>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>	<094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>	<CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>	<B4E14CA2-9609-454E-B7B6-0202C98D7317@dcn.davis.CA.us>
	<CAFnz2-_yHGwhnMXZDNgD35-WiZiMmPXFyBkgbScFGgXYFaDSHw@mail.gmail.com>
Message-ID: <552D12EF.3050103@atsu.edu>

I'm not sure I completely understand your authentication needs, but 
perhaps the RCurl package could be of some use to you.

Rob

On 4/13/2015 1:26 AM, Luca Cerone wrote:
> Thanks Jeff,
> and OK I'll move next questions on the topic to the devel list :)
>
> I was hoping there were packages that already dealt with this sort of
> things, that's why I posted my question here in the first place..
>
> Thanks a lot for helping me with this,
>
> Cheers,
> Luca
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
rbaer(at)atsu.edu


From dcarlson at tamu.edu  Tue Apr 14 15:16:58 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Apr 2015 13:16:58 +0000
Subject: [R] R studio installation
In-Reply-To: <82F0C7FB-EC8A-4A2D-ABCA-9850B60EC10B@dcn.davis.CA.us>
References: <4809E258EB1.000013FEjrkrideau@inbox.com>
	<82F0C7FB-EC8A-4A2D-ABCA-9850B60EC10B@dcn.davis.CA.us>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67E0EB@mb02.ads.tamu.edu>

R Studio loads R if it can find it. Since you have installed R, the error message means that R Studio can't find it or is not sure which version to use. The part of the message that says "please select the version of R to use" should give you a dialog box to use to navigate to the directory that contains R. Once you have done this, R Studio will remember where it is. The most likely explanation is one of these:

1. You installed R in the default location "C:\Program Files\R" but you have multiple installations as a result of updating R. By default R creates a new subdirectory for each new version. As a result R Studio does not know which one you want.

2. You installed both 32-bit and 64-bit versions of R so R Studio does not know which one to use.

3. You installed R in a location other than the default location and R Studio cannot fine it.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Tuesday, April 14, 2015 7:43 AM
To: John Kane; Sojood Malkawi; r-help at r-project.org
Subject: Re: [R] R studio installation

But if the answer to the question "Does R load on its own?" is "no" then this probably is the right place to ask for help. Of course, I would probably just suggest re-installing R, but someone else here might have better answers.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On April 14, 2015 5:14:21 AM PDT, John Kane <jrkrideau at inbox.com> wrote:
>You probably should go to the RStudio help/blog rather than here. This
>is not an RStudio list and the expertise is at the RStudoi site.
>
>Does R load on its own?
>
>What OS are you using?
>
>John Kane
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: sojoodmlk1990 at gmail.com
>> Sent: Tue, 14 Apr 2015 11:45:05 +0300
>> To: r-help at r-project.org
>> Subject: [R] R studio installation
>> 
>> I installed R and then R studio but it doesn't open every time i try
>to
>> open it it gives me this message  "Rstudio requires an existing
>> installation of R in order to work. please select the version of R to
>use
>> ".
>> i'm using R i386 3.1.3 and downloaded RStudio 0.98.1103 - Windows
>> XP/Vista/7/8. do you have any idea what the problem is?
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>Can't remember your password? Do you need a strong and secure password?
>Use Password manager! It stores your passwords & protects your account.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Apr 14 15:17:47 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Apr 2015 06:17:47 -0700
Subject: [R] Using Markov Regime Switching Model to Forecast
In-Reply-To: <CAFCiDbbjmN8nbLykaJ_f4JEGd7P3+HOEVxmf6vRRNBepAfDtPg@mail.gmail.com>
References: <CAFCiDbbjmN8nbLykaJ_f4JEGd7P3+HOEVxmf6vRRNBepAfDtPg@mail.gmail.com>
Message-ID: <F8C1F54B-ADEC-43C2-A881-391DA5790271@dcn.davis.CA.us>

Perhaps you should learn to use Google? It came up easily there for me. There is also an R package called "sos" that can help you find capabilities among the thousands of contributed packages on CRAN.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 13, 2015 5:21:30 PM PDT, Afsaneh Bahrami <bahrami.afsaneh at gmail.com> wrote:
>Dear R Users,
>
>Is there any package in R that use Markov Regime switching model to
>forecast
>?
>
>I need to do one-step ahead forecast using a Markov Regime switching 
>model.
>I have one predictor variable that switches across  2 regimes. I had a
>look, but I couldn't find a package in R which use a Markov Regime
>switching model for forecasting. Would you please let me know if there
>is
>any package to do that?
>
>I really appreciate any information.
>
>Regards
>Afsaneh
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jahhsep at gmail.com  Tue Apr 14 01:28:36 2015
From: jahhsep at gmail.com (Hiroki Hosonuma)
Date: Mon, 13 Apr 2015 16:28:36 -0700
Subject: [R] RHive and compression
Message-ID: <CAA+805Gp0YVpGP6pE2JTJ_FU+ZZjnKyra4MbpqTP=tmwU-MOWQ@mail.gmail.com>

Hi all,

If I run the following command in hive shell, I can get a compressed
output(e.g. 000000_0.gz) in HDFS because I already changed Hadoop and Hive
configuration files to achieve this.

*command:*
insert overwrite directory '/testdata' select * from tbl;

However, if I run the same command using RHive like the below, the output
is not compressed(e.g. 000000_0).

*command:*
rhive.query("insert overwrite directory '/testdata' select * from tbl")

It seems that RHive failed to read configuration files even though I set
HADOOP_CONF_DIR. Could anybody tell me what I am missing? Thank you in
advance!

Hiroki

	[[alternative HTML version deleted]]


From Joachim.Audenaert at pcsierteelt.be  Tue Apr 14 10:07:49 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Tue, 14 Apr 2015 10:07:49 +0200
Subject: [R] : automated levene test and other tests for variable datasets
Message-ID: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>

Hello all,

I am writing a script for statistical comparison of means. I'm doing many 
field trials with plants, where we have to compare the efficacy of 
different treatments on, different groups of plants. Therefore I would 
like to automate this script so it can be used for different datasets of 
different experiments (which will have different dimensions). An example 
dataset is given here under, I would like to compare if the data of 5 
columns (A,B,C,D,E) are statistically different from each other, where A, 
B, C, D and A are different treatments of my plants and I have 5 
replications for this experiment

dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61, 
19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E = 
c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names = 
c(NA, 5L), class = "data.frame")

1) First I would like to do a levene test to check the equality of 
variances of my datasets. Currently I do this as follows:

library("car")
attach(dataset)
y <- c(A,B,C,D,E)
group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3, 
length(C)), rep(4, length(D)),rep(5, length(E))))
leveneTest(y, group)

Is there a way to automate this for all types of datasets, so that I can 
use the same script for a datasets with any number of columns of data to 
compare? My above script only works for a dataset with 5 columns to 
compare

2) For my boxplots I use

boxplot(dataset) 

which gives me all the boxplots of each dataset, so this is how I want it

3) To check normality I currently use the kolmogorov smirnov test as 
follows

ks.test(A,pnorm)
ks.test(B,pnorm)
ks.test(C,pnorm)
ks.test(D,pnorm)
ks.test(E,pnorm)

Is there a way to replace the A, B, C, ... on the five lines into one line 
of entry so that the kolmogorov smirnov test is done on all columns of my 
dataset at once?

4) if data is normally distributed and the variances are equal I want to 
do a t-test and do pairwise comparison, currently like this

pairwise.t.test(y,group,p.adjust.method = "none")

if data is not normally distributed or variances are unequal I do a 
pairwise comparison with the wilcoxon test

pairwise.wilcox.test(y,group,p.adjust.method = "none")

But again I would like to make this easier, is there a way to replace the 
y and group in my datalineby something so it works for any size of 
dataset?

5) Once I have my paiwise comparison results I know which groups are 
statistically different from others, so I can add a and b and c to 
different groups in my graph. Currently I do this on a sheet of paper by 
comparing them one by one. Is there also a way to automate this? So R 
gives me for example something like this

A: a
B: a
C: b
D: ab
E: c

All help and commentys are welcome. I'm quite new to R and not a 
statistical genious, so if I'm overseeing things or thinking in a wrong 
way please let me know how I can improve my way of working. In short I 
would like to build a script that can compare the means of different 
groups of data and check if they are statistically diiferent

Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be   

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!
	[[alternative HTML version deleted]]


From deltaquattro at gmail.com  Tue Apr 14 11:51:52 2015
From: deltaquattro at gmail.com (deltaquattro at gmail.com)
Date: Tue, 14 Apr 2015 11:51:52 +0200
Subject: [R] Fwd: Can't get CVlm from DAAG package to work on my data - R
 3.1.3, DAAG 1.20
In-Reply-To: <CALxOh09GVoQXqETP1QAxBVovAJbRWadapOiq-aFdjANzm-i7cg@mail.gmail.com>
References: <CALxOh09GVoQXqETP1QAxBVovAJbRWadapOiq-aFdjANzm-i7cg@mail.gmail.com>
Message-ID: <CALxOh09zC=dpH6Uo3ykdXui0ckHjn4cm0jWSu9Pybt0PdTRVVQ@mail.gmail.com>

Hi,

I'm trying to get cross validation error for a simple linear regression
model, using function CVlm from package DAAG. I would need also the MSE
errors for each fold, because I want to test the one standard error rule.
My code is

a=c(0.0056, 0.0088, 0.0148, 0.0247, 0.0392, 0.0556, 0.0632, 0.0686, 0.0786,
0.0855, 0.0937)
b=c(6.0813, 9.5011, 15.5194, 23.9409, 32.8492, 40.8399, 43.8760, 45.5270,
46.7668, 46.1587, 43.4524)
dataset=data.frame(x=a,y=b)
CV.list=CVlm(df=dataset,form.lm = formula(y ~ poly(x,2)), m=5)

The error I get is

Error in xy.coords(x, y, xlabel, ylabel, log) :
  'x' and 'y' lengths differ

which must refer to internally created x, y, variables, since the variables
x and y inside my dataframe have the same length.

Thanks

Sergio

	[[alternative HTML version deleted]]


From pisicandru at hotmail.com  Tue Apr 14 16:48:07 2015
From: pisicandru at hotmail.com (Monica Pisica)
Date: Tue, 14 Apr 2015 14:48:07 +0000
Subject: [R]  plotting rasters - no plot, no error
Message-ID: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>


Hi,

 

I have the current version of R installed on 2 different Windows computers. On one i can plot using the plot function a raster in geotif format, on the other it plots only the axis, an empty color bar and no raster what so ever without generating any errors or warnings. So i suspect something is not installed properly, but i don't know what. Do you have any clues? I would really appreciate any insights. I need some instructions i can pass on to an IT person since i don't have rights on the computer that does not plot the raster.

 

On both computers i can plot lines, points, polygons, as graphic objects or shapefiles.

 

Thanks so much, Monica

 

The first PC that plots the raster:

Sys.info()

                     sysname                      release                      version 

                   "Windows"                      "7 x64" "build 7601, Service Pack 1" 

                    nodename                      machine                        login 

            "NODENAME"                     "x86-64"                       "LOGIN" 

                        user               effective_user 

                      "MONICA"                       "MONICA"

 

R.Version()

$platform

[1] "x86_64-w64-mingw32"

 

$arch

[1] "x86_64"

 

$os

[1] "mingw32"

 

$system

[1] "x86_64, mingw32"

 

$status

[1] ""

 

$major

[1] "3"

 

$minor

[1] "1.3"

 

$year

[1] "2015"

 

$month

[1] "03"

 

$day

[1] "09"

 

$`svn rev`

[1] "67962"

 

$language

[1] "R"

 

$version.string

[1] "R version 3.1.3 (2015-03-09)"

 

$nickname

[1] "Smooth Sidewalk"

 

Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr

 

The computer that does not plot the raster:

Sys.info()

                     sysname                      release                      version                     nodename 

                   "Windows"            "Server 2008 x64" "build 7601, Service Pack 1"              "NODENAME" 

                     machine                        login                         user               effective_user 

                    "x86-64"                       "MONICA"                       "MONICA"                       "MONICA"

 

R.Version()

$platform

[1] "x86_64-w64-mingw32"

 

$arch

[1] "x86_64"

 

$os

[1] "mingw32"

 

$system

[1] "x86_64, mingw32"

 

$status

[1] ""

 

$major

[1] "3"

 

$minor

[1] "1.3"

 

$year

[1] "2015"

 

$month

[1] "03"

 

$day

[1] "09"

 

$`svn rev`

[1] "67962"

 

$language

[1] "R"

 

$version.string

[1] "R version 3.1.3 (2015-03-09)"

 

$nickname

[1] "Smooth Sidewalk"

 

Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr



again thanks so much,

Monica

  		 	   		  

From mdsumner at gmail.com  Tue Apr 14 17:16:20 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 14 Apr 2015 15:16:20 +0000
Subject: [R] plotting rasters - no plot, no error
In-Reply-To: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>
References: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>
Message-ID: <CAAcGz9-q+Tku=Lk-7R6QSuUeNXxYZRG6QnWUq05NoKem8WkNag@mail.gmail.com>

On Wed, 15 Apr 2015 at 00:50 Monica Pisica <pisicandru at hotmail.com> wrote:

>
> Hi,
>
>
>
> I have the current version of R installed on 2 different Windows
> computers. On one i can plot using the plot function a raster in geotif
> format, on the other it plots only the axis, an empty color bar and no
> raster what so ever without generating any errors or warnings. So i suspect
> something is not installed properly, but i don't know what. Do you have any
> clues? I would really appreciate any insights. I need some instructions i
> can pass on to an IT person since i don't have rights on the computer that
> does not plot the raster.
>
>
>
Hello, can you try these on both systems and see if there's a difference?

 library(raster)
plot(raster(volcano))

plot(raster(volcano), useRaster = TRUE)

the useRaster argument refers to use of graphics::rasterImage rather than
image.defaul under (package) raster's hood.

Cheers, Mike.


> On both computers i can plot lines, points, polygons, as graphic objects
> or shapefiles.
>
>
>
> Thanks so much, Monica
>
>
>
> The first PC that plots the raster:
>
> Sys.info()
>
>                      sysname                      release
>     version
>
>                    "Windows"                      "7 x64" "build 7601,
> Service Pack 1"
>
>                     nodename                      machine
>       login
>
>             "NODENAME"                     "x86-64"
>  "LOGIN"
>
>                         user               effective_user
>
>                       "MONICA"                       "MONICA"
>
>
>
> R.Version()
>
> $platform
>
> [1] "x86_64-w64-mingw32"
>
>
>
> $arch
>
> [1] "x86_64"
>
>
>
> $os
>
> [1] "mingw32"
>
>
>
> $system
>
> [1] "x86_64, mingw32"
>
>
>
> $status
>
> [1] ""
>
>
>
> $major
>
> [1] "3"
>
>
>
> $minor
>
> [1] "1.3"
>
>
>
> $year
>
> [1] "2015"
>
>
>
> $month
>
> [1] "03"
>
>
>
> $day
>
> [1] "09"
>
>
>
> $`svn rev`
>
> [1] "67962"
>
>
>
> $language
>
> [1] "R"
>
>
>
> $version.string
>
> [1] "R version 3.1.3 (2015-03-09)"
>
>
>
> $nickname
>
> [1] "Smooth Sidewalk"
>
>
>
> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr
>
>
>
> The computer that does not plot the raster:
>
> Sys.info()
>
>                      sysname                      release
>     version                     nodename
>
>                    "Windows"            "Server 2008 x64" "build 7601,
> Service Pack 1"              "NODENAME"
>
>                      machine                        login
>        user               effective_user
>
>                     "x86-64"                       "MONICA"
>        "MONICA"                       "MONICA"
>
>
>
> R.Version()
>
> $platform
>
> [1] "x86_64-w64-mingw32"
>
>
>
> $arch
>
> [1] "x86_64"
>
>
>
> $os
>
> [1] "mingw32"
>
>
>
> $system
>
> [1] "x86_64, mingw32"
>
>
>
> $status
>
> [1] ""
>
>
>
> $major
>
> [1] "3"
>
>
>
> $minor
>
> [1] "1.3"
>
>
>
> $year
>
> [1] "2015"
>
>
>
> $month
>
> [1] "03"
>
>
>
> $day
>
> [1] "09"
>
>
>
> $`svn rev`
>
> [1] "67962"
>
>
>
> $language
>
> [1] "R"
>
>
>
> $version.string
>
> [1] "R version 3.1.3 (2015-03-09)"
>
>
>
> $nickname
>
> [1] "Smooth Sidewalk"
>
>
>
> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr
>
>
>
> again thanks so much,
>
> Monica
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Apr 14 17:18:01 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 14 Apr 2015 15:18:01 +0000
Subject: [R] plotting rasters - no plot, no error
In-Reply-To: <CAAcGz9-q+Tku=Lk-7R6QSuUeNXxYZRG6QnWUq05NoKem8WkNag@mail.gmail.com>
References: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>
	<CAAcGz9-q+Tku=Lk-7R6QSuUeNXxYZRG6QnWUq05NoKem8WkNag@mail.gmail.com>
Message-ID: <CAAcGz98hOf-FaJuZgmzq7q710NtHS=WtDduO__5dGAHqBkKrLA@mail.gmail.com>

On Wed, 15 Apr 2015 at 01:16 Michael Sumner <mdsumner at gmail.com> wrote:

> On Wed, 15 Apr 2015 at 00:50 Monica Pisica <pisicandru at hotmail.com> wrote:
>
>>
>> Hi,
>>
>>
>>
>> I have the current version of R installed on 2 different Windows
>> computers. On one i can plot using the plot function a raster in geotif
>> format, on the other it plots only the axis, an empty color bar and no
>> raster what so ever without generating any errors or warnings. So i suspect
>> something is not installed properly, but i don't know what. Do you have any
>> clues? I would really appreciate any insights. I need some instructions i
>> can pass on to an IT person since i don't have rights on the computer that
>> does not plot the raster.
>>
>>
>>
> Hello, can you try these on both systems and see if there's a difference?
>
>  library(raster)
> plot(raster(volcano))
>
> plot(raster(volcano), useRaster = TRUE)
>
>

Ugh, sorry I meant to try this:

plot(raster(volcano), useRaster = FALSE)

  otherwise both calls are equivalent.

Cheers, Mike.


the useRaster argument refers to use of graphics::rasterImage rather than
> image.defaul under (package) raster's hood.
>
> Cheers, Mike.
>
>
>> On both computers i can plot lines, points, polygons, as graphic objects
>> or shapefiles.
>>
>>
>>
>> Thanks so much, Monica
>>
>>
>>
>> The first PC that plots the raster:
>>
>> Sys.info()
>>
>>                      sysname                      release
>>       version
>>
>>                    "Windows"                      "7 x64" "build 7601,
>> Service Pack 1"
>>
>>                     nodename                      machine
>>         login
>>
>>             "NODENAME"                     "x86-64"
>>  "LOGIN"
>>
>>                         user               effective_user
>>
>>                       "MONICA"                       "MONICA"
>>
>>
>>
>> R.Version()
>>
>> $platform
>>
>> [1] "x86_64-w64-mingw32"
>>
>>
>>
>> $arch
>>
>> [1] "x86_64"
>>
>>
>>
>> $os
>>
>> [1] "mingw32"
>>
>>
>>
>> $system
>>
>> [1] "x86_64, mingw32"
>>
>>
>>
>> $status
>>
>> [1] ""
>>
>>
>>
>> $major
>>
>> [1] "3"
>>
>>
>>
>> $minor
>>
>> [1] "1.3"
>>
>>
>>
>> $year
>>
>> [1] "2015"
>>
>>
>>
>> $month
>>
>> [1] "03"
>>
>>
>>
>> $day
>>
>> [1] "09"
>>
>>
>>
>> $`svn rev`
>>
>> [1] "67962"
>>
>>
>>
>> $language
>>
>> [1] "R"
>>
>>
>>
>> $version.string
>>
>> [1] "R version 3.1.3 (2015-03-09)"
>>
>>
>>
>> $nickname
>>
>> [1] "Smooth Sidewalk"
>>
>>
>>
>> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr
>>
>>
>>
>> The computer that does not plot the raster:
>>
>> Sys.info()
>>
>>                      sysname                      release
>>       version                     nodename
>>
>>                    "Windows"            "Server 2008 x64" "build 7601,
>> Service Pack 1"              "NODENAME"
>>
>>                      machine                        login
>>          user               effective_user
>>
>>                     "x86-64"                       "MONICA"
>>          "MONICA"                       "MONICA"
>>
>>
>>
>> R.Version()
>>
>> $platform
>>
>> [1] "x86_64-w64-mingw32"
>>
>>
>>
>> $arch
>>
>> [1] "x86_64"
>>
>>
>>
>> $os
>>
>> [1] "mingw32"
>>
>>
>>
>> $system
>>
>> [1] "x86_64, mingw32"
>>
>>
>>
>> $status
>>
>> [1] ""
>>
>>
>>
>> $major
>>
>> [1] "3"
>>
>>
>>
>> $minor
>>
>> [1] "1.3"
>>
>>
>>
>> $year
>>
>> [1] "2015"
>>
>>
>>
>> $month
>>
>> [1] "03"
>>
>>
>>
>> $day
>>
>> [1] "09"
>>
>>
>>
>> $`svn rev`
>>
>> [1] "67962"
>>
>>
>>
>> $language
>>
>> [1] "R"
>>
>>
>>
>> $version.string
>>
>> [1] "R version 3.1.3 (2015-03-09)"
>>
>>
>>
>> $nickname
>>
>> [1] "Smooth Sidewalk"
>>
>>
>>
>> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr
>>
>>
>>
>> again thanks so much,
>>
>> Monica
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Apr 14 17:32:56 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 14 Apr 2015 08:32:56 -0700
Subject: [R] : automated levene test and other tests for variable
	datasets
In-Reply-To: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
References: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
Message-ID: <CACk-te1-G+xXO2s-u4zbrmX9HJVWV2MyQEmU0tpEbMn4ZRdV8g@mail.gmail.com>

Sounds like you need to do some of your own "homework"... In
particular, you need to learn how to write your own functions in R to
carry out such tasks.

There are many good tutorials on how to program in R, e.g. the Intro
to R that ships with R and many others that can be found by searching.
Choose one that suits your tastes/learning style and have at it!

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Apr 14, 2015 at 1:07 AM, Joachim Audenaert
<Joachim.Audenaert at pcsierteelt.be> wrote:
> Hello all,
>
> I am writing a script for statistical comparison of means. I'm doing many
> field trials with plants, where we have to compare the efficacy of
> different treatments on, different groups of plants. Therefore I would
> like to automate this script so it can be used for different datasets of
> different experiments (which will have different dimensions). An example
> dataset is given here under, I would like to compare if the data of 5
> columns (A,B,C,D,E) are statistically different from each other, where A,
> B, C, D and A are different treatments of my plants and I have 5
> replications for this experiment
>
> dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61,
> 19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E =
> c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names =
> c(NA, 5L), class = "data.frame")
>
> 1) First I would like to do a levene test to check the equality of
> variances of my datasets. Currently I do this as follows:
>
> library("car")
> attach(dataset)
> y <- c(A,B,C,D,E)
> group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3,
> length(C)), rep(4, length(D)),rep(5, length(E))))
> leveneTest(y, group)
>
> Is there a way to automate this for all types of datasets, so that I can
> use the same script for a datasets with any number of columns of data to
> compare? My above script only works for a dataset with 5 columns to
> compare
>
> 2) For my boxplots I use
>
> boxplot(dataset)
>
> which gives me all the boxplots of each dataset, so this is how I want it
>
> 3) To check normality I currently use the kolmogorov smirnov test as
> follows
>
> ks.test(A,pnorm)
> ks.test(B,pnorm)
> ks.test(C,pnorm)
> ks.test(D,pnorm)
> ks.test(E,pnorm)
>
> Is there a way to replace the A, B, C, ... on the five lines into one line
> of entry so that the kolmogorov smirnov test is done on all columns of my
> dataset at once?
>
> 4) if data is normally distributed and the variances are equal I want to
> do a t-test and do pairwise comparison, currently like this
>
> pairwise.t.test(y,group,p.adjust.method = "none")
>
> if data is not normally distributed or variances are unequal I do a
> pairwise comparison with the wilcoxon test
>
> pairwise.wilcox.test(y,group,p.adjust.method = "none")
>
> But again I would like to make this easier, is there a way to replace the
> y and group in my datalineby something so it works for any size of
> dataset?
>
> 5) Once I have my paiwise comparison results I know which groups are
> statistically different from others, so I can add a and b and c to
> different groups in my graph. Currently I do this on a sheet of paper by
> comparing them one by one. Is there also a way to automate this? So R
> gives me for example something like this
>
> A: a
> B: a
> C: b
> D: ab
> E: c
>
> All help and commentys are welcome. I'm quite new to R and not a
> statistical genious, so if I'm overseeing things or thinking in a wrong
> way please let me know how I can improve my way of working. In short I
> would like to build a script that can compare the means of different
> groups of data and check if they are statistically diiferent
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think green,
> keep it on the screen!
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Tue Apr 14 18:17:53 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 14 Apr 2015 17:17:53 +0100
Subject: [R] : automated levene test and other tests for variable
	datasets
In-Reply-To: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
References: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
Message-ID: <552D3DB1.6060301@dewey.myzen.co.uk>

You ask quite a lot of questions, I have given some hints about your 
first example inline

On 14/04/2015 09:07, Joachim Audenaert wrote:
> Hello all,
>
> I am writing a script for statistical comparison of means. I'm doing many
> field trials with plants, where we have to compare the efficacy of
> different treatments on, different groups of plants. Therefore I would
> like to automate this script so it can be used for different datasets of
> different experiments (which will have different dimensions). An example
> dataset is given here under, I would like to compare if the data of 5
> columns (A,B,C,D,E) are statistically different from each other, where A,
> B, C, D and A are different treatments of my plants and I have 5
> replications for this experiment
>
> dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61,
> 19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E =
> c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names =
> c(NA, 5L), class = "data.frame")
>
> 1) First I would like to do a levene test to check the equality of
> variances of my datasets. Currently I do this as follows:
>
> library("car")
> attach(dataset)
Usually best to avoid this and use the data=parameter or with or within

> y <- c(A,B,C,D,E)
you could use unlist( ) here
> group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3,
> length(C)), rep(4, length(D)),rep(5, length(E))))
you can get the lengths which you need with
lengtha <- lapply(dataset, length)
or
lengths <- sapply(dataset, length)
depending

then
rep(letters[1:length(lengths)], lengths)
should get you the group variable you want.


I have just typed all those in so there may be typos but at least you 
know where to look. I am not suggesting that I think automating all 
statistical analyses is necessarily a good idea either.

> leveneTest(y, group)
>
> Is there a way to automate this for all types of datasets, so that I can
> use the same script for a datasets with any number of columns of data to
> compare? My above script only works for a dataset with 5 columns to
> compare
>
> 2) For my boxplots I use
>
> boxplot(dataset)
>
> which gives me all the boxplots of each dataset, so this is how I want it
>
> 3) To check normality I currently use the kolmogorov smirnov test as
> follows
>
> ks.test(A,pnorm)
> ks.test(B,pnorm)
> ks.test(C,pnorm)
> ks.test(D,pnorm)
> ks.test(E,pnorm)
>
> Is there a way to replace the A, B, C, ... on the five lines into one line
> of entry so that the kolmogorov smirnov test is done on all columns of my
> dataset at once?
>
> 4) if data is normally distributed and the variances are equal I want to
> do a t-test and do pairwise comparison, currently like this
>
> pairwise.t.test(y,group,p.adjust.method = "none")
>
> if data is not normally distributed or variances are unequal I do a
> pairwise comparison with the wilcoxon test
>
> pairwise.wilcox.test(y,group,p.adjust.method = "none")
>
> But again I would like to make this easier, is there a way to replace the
> y and group in my datalineby something so it works for any size of
> dataset?
>
> 5) Once I have my paiwise comparison results I know which groups are
> statistically different from others, so I can add a and b and c to
> different groups in my graph. Currently I do this on a sheet of paper by
> comparing them one by one. Is there also a way to automate this? So R
> gives me for example something like this
>
> A: a
> B: a
> C: b
> D: ab
> E: c
>
> All help and commentys are welcome. I'm quite new to R and not a
> statistical genious, so if I'm overseeing things or thinking in a wrong
> way please let me know how I can improve my way of working. In short I
> would like to build a script that can compare the means of different
> groups of data and check if they are statistically diiferent
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think green,
> keep it on the screen!
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From pisicandru at hotmail.com  Tue Apr 14 18:49:31 2015
From: pisicandru at hotmail.com (Monica Pisica)
Date: Tue, 14 Apr 2015 16:49:31 +0000
Subject: [R] plotting rasters - no plot, no error
In-Reply-To: <CAAcGz98hOf-FaJuZgmzq7q710NtHS=WtDduO__5dGAHqBkKrLA@mail.gmail.com>
References: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>
	<CAAcGz9-q+Tku=Lk-7R6QSuUeNXxYZRG6QnWUq05NoKem8WkNag@mail.gmail.com>,
	<CAAcGz98hOf-FaJuZgmzq7q710NtHS=WtDduO__5dGAHqBkKrLA@mail.gmail.com>
Message-ID: <BAY168-W4520A096FFFC350F41189BC3E60@phx.gbl>

Hi Mike,


Very interesting. The plot itself on the computer that does not plot - still does not plot - no surprise there. But the command with useRaster = FALSE actually plots the raster. So that means it is something wrong with the raster package? Did i forget to install some dependency, although i though i ask for all to be installed?


I still don't know how to solve the problem, but thanks so much for an alternative way to actually plot my rasters.


Monica
________________________________
> From: mdsumner at gmail.com 
> Date: Tue, 14 Apr 2015 15:18:01 +0000 
> Subject: Re: [R] plotting rasters - no plot, no error 
> To: pisicandru at hotmail.com; r-help at r-project.org 
> 

> On Wed, 15 Apr 2015 at 01:16 Michael Sumner 
> <mdsumner at gmail.com<mailto:mdsumner at gmail.com>> wrote: 
> On Wed, 15 Apr 2015 at 00:50 Monica Pisica 
> <pisicandru at hotmail.com<mailto:pisicandru at hotmail.com>> wrote: 
> 
> Hi, 


> computers. On one i can plot using the plot function a raster in geotif 
> format, on the other it plots only the axis, an empty color bar and no 
> raster what so ever without generating any errors or warnings. So i 
> suspect something is not installed properly, but i don't know what. Do
> you have any clues? I would really appreciate any insights. I need some 
> instructions i can pass on to an IT person since i don't have rights on 
> the computer that does not plot the raster. 

> Hello, can you try these on both systems and see if there's a difference? 
> 
> library(raster) 
> plot(raster(volcano)) 
> 
> plot(raster(volcano), useRaster = TRUE) 

> Ugh, sorry I meant to try this: 
> 
> plot(raster(volcano), useRaster = FALSE) 
> 
> otherwise both calls are equivalent. 
> 
> Cheers, Mike. 
> 

> the useRaster argument refers to use of graphics::rasterImage rather 
> than image.defaul under (package) raster's hood. 
> 
> Cheers, Mike. 

> On both computers i can plot lines, points, polygons, as graphic 
> objects or shapefiles. 

> Thanks so much, Monica 

> The first PC that plots the raster: 
> 
> Sys.info() 
> 
> sysname release 
> version 
> 

> Service Pack 1" 
> 
> nodename machine 
> login 
> 
> "NODENAME" "x86-64" 
> "LOGIN" 
> 
> user effective_user 
> 
> "MONICA" "MONICA" 

> R.Version() 
> 
> $platform 
> 
> [1] "x86_64-w64-mingw32" 

> $arch 
> 
> [1] "x86_64" 

> $os 
> 
> [1] "mingw32" 

> $system 
> 
> [1] "x86_64, mingw32" 

> $status 
> 
> [1] "" 

> $major 
> 
> [1] "3" 

> $minor 
> 
> [1] "1.3" 

> $year 
> 
> [1] "2015" 

> $month 
> 
> [1] "03" 

> $day 
> 
> [1] "09" 

> $`svn rev` 
> 
> [1] "67962" 

> $language 
> 
> [1] "R" 

>
> $version.string 
> 
> [1] "R version 3.1.3 (2015-03-09)" 

> $nickname 
> 
> [1] "Smooth Sidewalk" 

> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr 

> The computer that does not plot the raster: 
> 
> Sys.info() 
> 
> sysname release 
> version nodename 
> 

> Service Pack 1" "NODENAME" 
> 
> machine login 
> user effective_user 
> 
> "x86-64" "MONICA" 
> "MONICA" "MONICA" 

> R.Version() 
> 
> $platform 
> 
> [1] "x86_64-w64-mingw32" 

> $arch 
> 
> [1] "x86_64" 

> $os 
> 
> [1] "mingw32" 

> $system 
> 
> [1] "x86_64, mingw32" 
> 

> $status 
> 
> [1] "" 
> 

> $major 
> 
> [1] "3" 

> $minor 
> 
> [1] "1.3" 
> 

> $year 
> 
> [1] "2015" 

> $month 
> 
> [1] "03" 
> 

> $day 
> 
> [1] "09" 

> $`svn rev` 
> 
> [1] "67962" 
> 

> $language 
> 
> [1] "R" 

> $version.string 
> 
> [1] "R version 3.1.3 (2015-03-09)" 

> $nickname 
> 
> [1] "Smooth Sidewalk" 

> Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos, stringr 

> again thanks so much, 
> 
> Monica 

> ______________________________________________ 
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.  		 	   		  

From haenlein at escpeurope.eu  Tue Apr 14 18:57:28 2015
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 14 Apr 2015 18:57:28 +0200
Subject: [R] Running R Remotely on LINUX
Message-ID: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>

Dear all,

I am used to running R locally on my Windows-based PC. Since some of my
computations are taking a lot of time I am now trying to move to a remote R
session on a LINUX server but I am having trouble to getting things work.

I am able to access the LINUX server using PuTTY and SSH. Once I have
access I can log in with my username and password (which is asked through
keyboard-interactive authentication). I can then open an R session.

Since I am not used to working with LINUX, I have several questions:

(1) Ideally I am looking for a Windows-based software that would allow me
to work on R as I am used to with the difference that the computations are
run remotely on the LINUX server. Does a software like this exist? Please
note that I do not think that I can install any software on the LINUX
server. But I can install stuff on my Windows-based PC.

(2) I am running an extensive simulation that takes about one week to run.
Right now it seems that when I log out of R on LINUX and close PuTTY, the R
session closes as well. Is there a way to let R run in the background for
the week and just check into the progress 1-2 times a day?

(3) Can I open several instances of R in parallel? On my PC I sometimes
have 2-3 windows open in parallel that work on different calculations to
save time. Not sure to which extent this is possible on LINUX.

I assume that this questions are very na?ve. But since I?m only used to
working with Windows I?m quite stuck at the moment. Any help would be very
appreciated!

Thanks in advance,

Michael




Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Apr 14 19:09:16 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 14 Apr 2015 13:09:16 -0400
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
Message-ID: <CAM_vjukTPyPksBVhnZmJid=eJsRjb3Fq-akVP7zPC9Sy0oA+3g@mail.gmail.com>

Hi Michael,

On Tue, Apr 14, 2015 at 12:57 PM, Michael Haenlein
<haenlein at escpeurope.eu> wrote:
> Dear all,
>
> I am used to running R locally on my Windows-based PC. Since some of my
> computations are taking a lot of time I am now trying to move to a remote R
> session on a LINUX server but I am having trouble to getting things work.
>
> I am able to access the LINUX server using PuTTY and SSH. Once I have
> access I can log in with my username and password (which is asked through
> keyboard-interactive authentication). I can then open an R session.
>
> Since I am not used to working with LINUX, I have several questions:
>
> (1) Ideally I am looking for a Windows-based software that would allow me
> to work on R as I am used to with the difference that the computations are
> run remotely on the LINUX server. Does a software like this exist? Please
> note that I do not think that I can install any software on the LINUX
> server. But I can install stuff on my Windows-based PC.

I'm not even sure what this question means, sorry.

> (2) I am running an extensive simulation that takes about one week to run.
> Right now it seems that when I log out of R on LINUX and close PuTTY, the R
> session closes as well. Is there a way to let R run in the background for
> the week and just check into the progress 1-2 times a day?

Start screen on the linux system, then start R. Once the R job is
running, you can disconnect from the screen with Ctrl-A Ctrl-D and the
R job will continue in the background. Google linux screen for more
information.

> (3) Can I open several instances of R in parallel? On my PC I sometimes
> have 2-3 windows open in parallel that work on different calculations to
> save time. Not sure to which extent this is possible on LINUX.

Sure. Using screen you can have multiple sessions going.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From arnaud.gaboury at gmail.com  Tue Apr 14 19:16:36 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Tue, 14 Apr 2015 19:16:36 +0200
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <CAM_vjukTPyPksBVhnZmJid=eJsRjb3Fq-akVP7zPC9Sy0oA+3g@mail.gmail.com>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
	<CAM_vjukTPyPksBVhnZmJid=eJsRjb3Fq-akVP7zPC9Sy0oA+3g@mail.gmail.com>
Message-ID: <CAK1hC9syQ5nSNU=S5ncVYA_3a4oFzMRS0tUZos8yH78zu=6e+w@mail.gmail.com>

On Tue, Apr 14, 2015 at 7:09 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> Hi Michael,
>
> On Tue, Apr 14, 2015 at 12:57 PM, Michael Haenlein
> <haenlein at escpeurope.eu> wrote:
> > Dear all,
> >
> > I am used to running R locally on my Windows-based PC. Since some of my
> > computations are taking a lot of time I am now trying to move to a remote R
> > session on a LINUX server but I am having trouble to getting things work.

Please have a look at this link[0]. It may help
>
>
>
> > I am able to access the LINUX server using PuTTY and SSH. Once I have
> > access I can log in with my username and password (which is asked through
> > keyboard-interactive authentication). I can then open an R session.
> >
> > Since I am not used to working with LINUX, I have several questions:
> >
> > (1) Ideally I am looking for a Windows-based software that would allow me
> > to work on R as I am used to with the difference that the computations are
> > run remotely on the LINUX server. Does a software like this exist? Please
> > note that I do not think that I can install any software on the LINUX
> > server. But I can install stuff on my Windows-based PC.
>
> I'm not even sure what this question means, sorry.
>
> > (2) I am running an extensive simulation that takes about one week to run.
> > Right now it seems that when I log out of R on LINUX and close PuTTY, the R
> > session closes as well. Is there a way to let R run in the background for
> > the week and just check into the progress 1-2 times a day?
>
> Start screen on the linux system, then start R. Once the R job is
> running, you can disconnect from the screen with Ctrl-A Ctrl-D and the
> R job will continue in the background. Google linux screen for more
> information.
>
> > (3) Can I open several instances of R in parallel? On my PC I sometimes
> > have 2-3 windows open in parallel that work on different calculations to
> > save time. Not sure to which extent this is possible on LINUX.
>
> Sure. Using screen you can have multiple sessions going.
>
> Sarah
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org

[0]https://www.opencpu.org/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 

google.com/+arnaudgabourygabx


From hannah.hlx at gmail.com  Tue Apr 14 19:23:34 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 14 Apr 2015 13:23:34 -0400
Subject: [R] Wrong results from anova
Message-ID: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>

Hi all,
  I have following data. When I perform an anova, the residual sum of
square returns to be zero.
But this is wrong, since we can hand calculate the RSS to be around 0.0308.
  Did anyone come across the same problem before? Any suggestions?
  Thanks.
    Hanna

> ydata
        Y sample.Y
1   0.477      0.5
2   0.477      0.5
3   0.478      0.5
4  27.320       27
5  27.420       27
6  27.300       27
7  29.440       29
8  29.620       29
9  29.610       29
10 35.840       35
11 35.900       35
12 35.850       35
> fit.Y <- aov(Y~sample.Y, data=ydata)
> summary(fit.Y)
            Df Sum Sq Mean Sq F value Pr(>F)
sample.Y     3   2203   734.2  190706 <2e-16 ***
Residuals    8      0     0.0
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

	[[alternative HTML version deleted]]


From liuwensui at gmail.com  Tue Apr 14 19:25:59 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 14 Apr 2015 12:25:59 -0500
Subject: [R] any way to write sas7bdat with R
Message-ID: <CAKyN3iA+PLwtOFMra7eAvtfcoisH+0OPpPajka_vHUUxEmjxOA@mail.gmail.com>

I know R can read / write SAS data in xpt format and can also read SAS data
in sas7bdat format.

However, I am wondering if I can write sas7bdat with R.

thanks.

	[[alternative HTML version deleted]]


From asi9 at pitt.edu  Tue Apr 14 18:20:09 2015
From: asi9 at pitt.edu (Singh, Ashima)
Date: Tue, 14 Apr 2015 16:20:09 +0000
Subject: [R] Cost-effectiveness Analysis using R
Message-ID: <1429028410116.91766@pitt.edu>

?Hi, I was wondering if R has a provision of performing cost-effectiveness analyses using decision trees and markov models.


Thanks!

Ashima

	[[alternative HTML version deleted]]


From asi9 at pitt.edu  Tue Apr 14 19:01:31 2015
From: asi9 at pitt.edu (Singh, Ashima)
Date: Tue, 14 Apr 2015 17:01:31 +0000
Subject: [R] Cost-effectiveness Analysis in R
Message-ID: <1429030892043.80515@pitt.edu>

?

Hi All,


I was wondering if R has a provision of performing cost-effectiveness analyses using decision trees and markov models. And if anyone has used it before.


Thanks!

Ashima

	[[alternative HTML version deleted]]


From spector at stat.berkeley.edu  Tue Apr 14 19:40:13 2015
From: spector at stat.berkeley.edu (Phil Spector)
Date: Tue, 14 Apr 2015 10:40:13 -0700 (PDT)
Subject: [R] Wrong results from anova
In-Reply-To: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
References: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1504141037200.7327@sauron.Berkeley.EDU>

Li Li -
    I belive it's a rounding error -- try setting

options(digits=8)

    before displaying the output:

> summary(fit.Y)
             Df Sum Sq Mean Sq F value Pr(>F) 
sample.Y     3   2203     734  190706 <2e-16 ***
Residuals    8      0       0 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> summary(fit.Y)
             Df  Sum Sq Mean Sq F value    Pr(>F) 
sample.Y     3 2202.70  734.23  190706 < 2.2e-16 ***
Residuals    8    0.03    0.00 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

 					- Phil Spector
 					 Statistical Computing Facility
 					 Department of Statistics
 					 UC Berkeley
 					 spector at stat.berkeley.edu




On Tue, 14 Apr 2015, li li wrote:

> Hi all,
>  I have following data. When I perform an anova, the residual sum of
> square returns to be zero.
> But this is wrong, since we can hand calculate the RSS to be around 0.0308.
>  Did anyone come across the same problem before? Any suggestions?
>  Thanks.
>    Hanna
>
>> ydata
>        Y sample.Y
> 1   0.477      0.5
> 2   0.477      0.5
> 3   0.478      0.5
> 4  27.320       27
> 5  27.420       27
> 6  27.300       27
> 7  29.440       29
> 8  29.620       29
> 9  29.610       29
> 10 35.840       35
> 11 35.900       35
> 12 35.850       35
>> fit.Y <- aov(Y~sample.Y, data=ydata)
>> summary(fit.Y)
>            Df Sum Sq Mean Sq F value Pr(>F)
> sample.Y     3   2203   734.2  190706 <2e-16 ***
> Residuals    8      0     0.0
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Tue Apr 14 19:40:32 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 14 Apr 2015 10:40:32 -0700
Subject: [R] Wrong results from anova
In-Reply-To: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
References: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
Message-ID: <CAF8bMcbehSra7GOKAMM36Ui3hoa=0d8Sox7A8t3AhbinEkNNeg@mail.gmail.com>

It is a printing problem - the default number of digits in print.summary.aov
is max(3L, getOption("digits") - 3L).   Set options(digits=7) instead of
your current 6 (?) or try print(summary(fit.Y), digits=7) to see more
digits.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 14, 2015 at 10:23 AM, li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>   I have following data. When I perform an anova, the residual sum of
> square returns to be zero.
> But this is wrong, since we can hand calculate the RSS to be around 0.0308.
>   Did anyone come across the same problem before? Any suggestions?
>   Thanks.
>     Hanna
>
> > ydata
>         Y sample.Y
> 1   0.477      0.5
> 2   0.477      0.5
> 3   0.478      0.5
> 4  27.320       27
> 5  27.420       27
> 6  27.300       27
> 7  29.440       29
> 8  29.620       29
> 9  29.610       29
> 10 35.840       35
> 11 35.900       35
> 12 35.850       35
> > fit.Y <- aov(Y~sample.Y, data=ydata)
> > summary(fit.Y)
>             Df Sum Sq Mean Sq F value Pr(>F)
> sample.Y     3   2203   734.2  190706 <2e-16 ***
> Residuals    8      0     0.0
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Apr 14 19:44:03 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 14 Apr 2015 18:44:03 +0100
Subject: [R] Wrong results from anova
In-Reply-To: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
References: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
Message-ID: <552D51E3.7020504@dewey.myzen.co.uk>

See in-line

On 14/04/2015 18:23, li li wrote:
> Hi all,
>    I have following data. When I perform an anova, the residual sum of
> square returns to be zero.
> But this is wrong, since we can hand calculate the RSS to be around 0.0308.
>    Did anyone come across the same problem before? Any suggestions?
>    Thanks.
>      Hanna
>
>> ydata
>          Y sample.Y
> 1   0.477      0.5
> 2   0.477      0.5
> 3   0.478      0.5
> 4  27.320       27
> 5  27.420       27
> 6  27.300       27
> 7  29.440       29
> 8  29.620       29
> 9  29.610       29
> 10 35.840       35
> 11 35.900       35
> 12 35.850       35
>> fit.Y <- aov(Y~sample.Y, data=ydata)
>> summary(fit.Y)
>              Df Sum Sq Mean Sq F value Pr(>F)
> sample.Y     3   2203   734.2  190706 <2e-16 ***
> Residuals    8      0     0.0
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>

  734.2 / 197096
[1] 0.003725088

Did you mean 0.0038 above?
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From hannah.hlx at gmail.com  Tue Apr 14 19:46:30 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 14 Apr 2015 13:46:30 -0400
Subject: [R] Wrong results from anova
In-Reply-To: <552D51E3.7020504@dewey.myzen.co.uk>
References: <CAHLnndaKvr5nkHycpXBnLv9Q_RND7Wz=As+6Vnb-Lgt8KLE=FA@mail.gmail.com>
	<552D51E3.7020504@dewey.myzen.co.uk>
Message-ID: <CAHLnndYRu8G_aFMaGS40i7Om4vQpWKrEfHSyig+d2co9QP8o=Q@mail.gmail.com>

0.003725088 is the mean square error.





2015-04-14 13:44 GMT-04:00 Michael Dewey <lists at dewey.myzen.co.uk>:

> See in-line
>
>
> On 14/04/2015 18:23, li li wrote:
>
>> Hi all,
>>    I have following data. When I perform an anova, the residual sum of
>> square returns to be zero.
>> But this is wrong, since we can hand calculate the RSS to be around
>> 0.0308.
>>    Did anyone come across the same problem before? Any suggestions?
>>    Thanks.
>>      Hanna
>>
>> ydata
>>>
>>          Y sample.Y
>> 1   0.477      0.5
>> 2   0.477      0.5
>> 3   0.478      0.5
>> 4  27.320       27
>> 5  27.420       27
>> 6  27.300       27
>> 7  29.440       29
>> 8  29.620       29
>> 9  29.610       29
>> 10 35.840       35
>> 11 35.900       35
>> 12 35.850       35
>>
>>> fit.Y <- aov(Y~sample.Y, data=ydata)
>>> summary(fit.Y)
>>>
>>              Df Sum Sq Mean Sq F value Pr(>F)
>> sample.Y     3   2203   734.2  190706 <2e-16 ***
>> Residuals    8      0     0.0
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>  734.2 / 197096
> [1] 0.003725088
>
> Did you mean 0.0038 above?
>
>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Apr 14 20:20:35 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 14 Apr 2015 13:20:35 -0500
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
Message-ID: <CAAJSdjgCQnOxS9AYW_mEoqPrpadgdwsyLwqZN_SRHkRmoVfnvA@mail.gmail.com>

On Tue, Apr 14, 2015 at 11:57 AM, Michael Haenlein <haenlein at escpeurope.eu>
wrote:

> Dear all,
>
> ?<snip>
>

>
> (3) Can I open several instances of R in parallel? On my PC I sometimes
> have 2-3 windows open in parallel that work on different calculations to
> save time. Not sure to which extent this is possible on LINUX.
>

?In addition to my off-list reply, you might want to talk to your Linux
person to see if you can use VNC no NoMachine (https://www.nomachine.com/)
to get a Linux graphical desktop ?connection (similar in concept to Windows
Remote Desktop) going. If you can do this, and can get KDE as the desktop
environment, then you can have a very Windows-ish Linux desktop displayed
on your Windows machine. But it will still be nice even with Gnome, or
XFCE, or even one of the other desktops (Linux has a lot of them, but I
think KDE is most similar to Windows U.I.) This will allow you to use
RStudio on Linux or have multiple terminal sessions going for multiple R
sessions. But this will _not_ allow you to disconnect from Linux while
maintaining the graphical desktop. At least, I don't think you can do that.
I could be wrong.



>
> I assume that this questions are very na?ve. But since I?m only used to
> working with Windows I?m quite stuck at the moment. Any help would be very
> appreciated!
>
> Thanks in advance,
>
> Michael
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
>
>
-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Apr 14 20:29:22 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Apr 2015 18:29:22 +0000
Subject: [R] Sum of some months totals
In-Reply-To: <CAGh51gTmEdsw7DuEr9PvB+_9iMy55P5tL9kwKSqwj0Py+n5+CQ@mail.gmail.com>
References: <CAGh51gR9DqAk19-KybiXCgxN+SLOzL0OQ_vofW4Oez7yYr4tZg@mail.gmail.com>
	<CAN5YmCF7_RsBARJy67GxO8KPHA58sexebu=er1LK1FLjA4m8Og@mail.gmail.com>
	<CAGh51gR=i=DKPmjnBPpcg7tMuHgoNzrQYMWSV1pou5XC2sQ-6g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67E123@mb02.ads.tamu.edu>
	<CAGh51gTmEdsw7DuEr9PvB+_9iMy55P5tL9kwKSqwj0Py+n5+CQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67E2BB@mb02.ads.tamu.edu>

Don't use html formatted emails and always copy the list on your replies.

For example?

rainstats <- function(data, months=3) {
     if (! months %in% c(1, 2, 3, 4, 6, 12)) stop("Months must divide into 12!")
     period <- 12/months
     grps <- rep(1:period, each=months)
     Group <- grps[rainfall$Month]
     aggregate(Rain~Year+Group, rainfall, function(x) c(sum=sum(x),
         days=sum(x>0)))
}

> rainstats(rainfall)
  Year Group Rain.sum Rain.days
1 1979     1        0         0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



From: Frederic Ntirenganya [mailto:ntfredo at gmail.com] 
Sent: Tuesday, April 14, 2015 9:27 AM
To: David L Carlson
Subject: Re: [R] Sum of some months totals

Hi David,
I understand what you did. My aim is to make a function which takes a quarter as a default. i.e I can compute lets say for 4 motnhs by specifying it in the arguments of the function.
Regards,
Frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email:?fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Apr 14, 2015 at 4:44 PM, David L Carlson <dcarlson at tamu.edu> wrote:
You should read some beginning tutorials for R before you go further. You are wasting a lot of time writing complicated loops that you do not need. R is probably very different from the programming languages you are used to. In these examples I called your data "rainfall."

To get the sum of the rain for each month you need only:

aggregate(Rain~Year+Month, rainfall, sum)

To get the number of days with rain is slightly more complicated:

aggregate(Rain~Year+Month, rainfall, function(x) sum(x>0))

To get the sum for a quarter, you need to add quarters to your data frame, eg. Notice that it does not require a loop to add an entire column to your existing data frame.

rainfall$Quarter <- (rainfall$Month+2) %/% 3
aggregate(Rain~Year+Quarter, rainfall, sum)

The command ?aggregate will bring up a manual page on the aggregate() function.

Read
"Introduction to R" at http://cran.r-project.org/manuals.html
and one or more of the contributed manuals at
http://cran.r-project.org/other-docs.html

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Frederic Ntirenganya
Sent: Tuesday, April 14, 2015 6:10 AM
To: Adams, Jean
Cc: r-help at r-project.org
Subject: Re: [R] Sum of some months totals

Hi Jean,

Thanks for the help!
How can I compute monthly total of rainfall?

I want to compute both monthly total of rainfall and number of raindays. In
below function month_tot is a table and I want to some month. default is 3
months. The loop for quarter is not working and I am wondering why it is
not working.

total = function(data, threshold = 0.85){
? month_tot=matrix(NA,length(unique(data$Year)),12)
? rownames(month_tot)=as.character(unique(data$Year))

colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
? raindays=month_tot
? # loop over months and years to get summary statistics
? for (mon in 1:12) {
? ? rain=data[data[2]==mon,c(1,4)]? ?# rain just for a specific month
? ? for (yr in unique(data$Year)) {
? ? ? month_tot[yr-min(unique(data$Year)-1),mon]=sum(rain[rain[,1]==yr,2])
? ? ? #print(sum(rain[rain[,1]==yr,2]))

raindays[yr-min(unique(data$Year)-1),mon]=sum(rain[rain[,1]==yr,2]>threshold)
? ? }
? }
? month_tot
? 1:ncol(month_tot)
? #month_tot[,1] + month_tot[,2] + month_tot[,3]
? quarter <-c()
? i = 3
? for (i in 1:ncol(month_tot)){

? ? quarter[i] = sum(month_tot[,i])
? }
? quarter
}

total(kitale)

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Apr 14, 2015 at 1:52 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> If you want to calculate the number of days having greater than a certain
> threshold of rain within a range of months, a function like this might
> serve your needs.
>
> raindays <- function(data, monStart=1, monEnd=3, threshold=0.85) {
>? ?with(data, {
>? ? ?selRows <- Month >= monStart & Month <= monEnd & Rain > threshold
>? ? ?days <- tapply(selRows, Year, sum)
>? ? ?return(days)
>? ?})
> }
>
> raindays(kitale)
>
> Jean
>
> On Tue, Apr 14, 2015 at 2:46 AM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
>
>> I want to compute monthly summaries from daily data. I want to choose
>> which
>> month to start and how many months to total over.? Default could be to
>> start in January and total over 3 months.? For the number of rain days the
>> default threshold is 0.85mm.
>>
>> I tried to make a function which sum all months not some of months. I will
>> appreciate any help from you guys. Thanks.
>> Here is the data and the code I used.
>>
>> > dput(head(kitale))structure(list(Year = c(1979L, 1979L, 1979L, 1979L,
>> 1979L, 1979L
>>
>> ), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, Rain = c(0,
>> 0, 0, 0, 0, 0)), .Names = c("Year", "Month", "Day", "Rain"), row.names =
>> c(NA,
>> 6L), class = "data.frame")
>>
>> here is the function:
>>
>> total = function(data, threshold = 0.85){
>>? ?month_tot=matrix(NA,31,12)
>>? ?rownames(month_tot)=as.character(1979:2009)
>>
>> colnames(month_tot)=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
>>? ?raindays=month_tot
>>? ?# loop over months and years to get summary statistics
>>? ?for (mon in 1:12) {
>>? ? ?rain=data[data[2]==mon,c(1,4)]? ?# rain just for a specific month
>>? ? ?for (yr in 1979:2009) {
>>? ? ? ?month_tot[yr-1978,mon]=sum(rain[rain[,1]==yr,2])
>>? ? ? ?raindays[yr-1978,mon]=sum(rain[rain[,1]==yr,2]>threshold)
>>? ? ?}
>>? ?}
>>? ?month_tot
>> }
>>
>> Regards,
>>
>> Frederic.
>>
>>
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>? ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lisagandy07 at gmail.com  Tue Apr 14 20:32:15 2015
From: lisagandy07 at gmail.com (Lisa Gandy)
Date: Tue, 14 Apr 2015 14:32:15 -0400
Subject: [R] Help with RUSBoost
Message-ID: <CANdPHu6GZtZFqRF=Y0Tf5xV5mqELSG_MAAQNjjmroxJt+AyFhg@mail.gmail.com>

I am considering using RUSBoost (https://github.com/SteveOhh/RUSBoost) and
was wondering if anyone has used this package, and could give me some
insight and help.  The help would be on more of the machine learning side,
I just have a few questions about implementation.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Apr 14 20:53:31 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Apr 2015 11:53:31 -0700
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
Message-ID: <BB1ABE3C-7497-4E68-A563-086168ED7705@dcn.davis.CA.us>

You should investigate using the parallel package. You have to have R installed on the Linux machine along with any contributed packages you use, but you can delegate tasks to it from within an Rgui or RStudio session running on your Windows box. There are even tutorials online that step you through setting up a "cloud" computer to serve this purpose.

It is possible to install R under your own account on a Linux server, but there are more hiccups to overcome in doing so. There is a small charge for using cloud servers, but if you use it right then the cost can be quite cheap.

Note that while you can set up Windows servers in the cloud, they are not as well suited to this remote use as Linux servers are, so it is worth the effort to learn enough to do that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 14, 2015 9:57:28 AM PDT, Michael Haenlein <haenlein at escpeurope.eu> wrote:
>Dear all,
>
>I am used to running R locally on my Windows-based PC. Since some of my
>computations are taking a lot of time I am now trying to move to a
>remote R
>session on a LINUX server but I am having trouble to getting things
>work.
>
>I am able to access the LINUX server using PuTTY and SSH. Once I have
>access I can log in with my username and password (which is asked
>through
>keyboard-interactive authentication). I can then open an R session.
>
>Since I am not used to working with LINUX, I have several questions:
>
>(1) Ideally I am looking for a Windows-based software that would allow
>me
>to work on R as I am used to with the difference that the computations
>are
>run remotely on the LINUX server. Does a software like this exist?
>Please
>note that I do not think that I can install any software on the LINUX
>server. But I can install stuff on my Windows-based PC.
>
>(2) I am running an extensive simulation that takes about one week to
>run.
>Right now it seems that when I log out of R on LINUX and close PuTTY,
>the R
>session closes as well. Is there a way to let R run in the background
>for
>the week and just check into the progress 1-2 times a day?
>
>(3) Can I open several instances of R in parallel? On my PC I sometimes
>have 2-3 windows open in parallel that work on different calculations
>to
>save time. Not sure to which extent this is possible on LINUX.
>
>I assume that this questions are very na?ve. But since I?m only used to
>working with Windows I?m quite stuck at the moment. Any help would be
>very
>appreciated!
>
>Thanks in advance,
>
>Michael
>
>
>
>
>Michael Haenlein
>Professor of Marketing
>ESCP Europe
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From fisher at plessthan.com  Tue Apr 14 21:35:31 2015
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 14 Apr 2015 12:35:31 -0700
Subject: [R] Vectorizing a task
Message-ID: <896D2B85-B168-4BAC-8E0B-F901D8BB6CB7@plessthan.com>

R 3.1.3
OS X

Colleagues

I have data of this sort:
	START	<- c(1, 2, 3, 4, 8, 14, 15, 118, 118, 119, 202, 202, 203, 204)
	END	<- c(1, 2, 3, 6, 13, 14, 117, 118, 118, 201, 202, 202, 203, 204)
I would like to create a vector that looks like this:
	START.to.END	<- c(1:1,2:2,3:3,4:6,8:13,14:14,15:117,118:118,118:118,119:201,202:202,202:202,203:203,204:204)
i.e., each pair of entries is link with ?:?, then these are concatenated.

Ultimately, this will be expanded into:
EXPANDED	<- c(1L, 2L, 3L, 4L, 5L, 6L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 
55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 
81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 
106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 
127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 
149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 
171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 
193L, 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 202L, 203L, 204L)

The final step will be to find which values are missing from the sequence:
	setdiff(1:max(EXPANDED), EXPANDED)

The command:
	paste0("c(", paste(paste(ALLSTART, ALLEND, sep=":"), collapse=","), ")") 
creates the text for START.to.END, but I can?t figure out how to evaluate that expression.  I could build the vector step-by-step but that seems quite inefficient.

Any suggestions?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From crypticlineage at gmail.com  Tue Apr 14 21:39:50 2015
From: crypticlineage at gmail.com (Vikram Chhatre)
Date: Tue, 14 Apr 2015 15:39:50 -0400
Subject: [R] Extracting unique entries by a column
Message-ID: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>

I have a data frame of dim 3x600.  There are pairs of rows which have the
exact same value in column 3.

head(df)
                POP1         POP2   ABSDIFF
L0005.01 0.98484848 0.688118812 0.2967297
L0005.03 0.01515152 0.311881188 0.2967297
L0008.02 0.97727273 0.004424779 0.9728479
L0008.04 0.02272727 0.995575221 0.9728479
L0012.03 0.98684211 0.004385965 0.9824561
L0012.01 0.01315789 0.995614035 0.9824561

I want to unique sort on df$ABSDIFF so that only one row per pair remains
in the subset.

>df_subset <- df[df(!duplicated(df$ABSDIFF), ]

This does not work. So I literally checked:

>identical(df[1,3], df[2,3])
FALSE

How is 0.2967297 different from 0.2967297?  I am puzzled.

Thanks for any insight.

Vikram

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Apr 14 21:53:37 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Apr 2015 19:53:37 +0000
Subject: [R] Extracting unique entries by a column
In-Reply-To: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>
References: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67E3E9@mb02.ads.tamu.edu>

Try all.equal(df[1,3], df[2,3])

This relates to how decimal numbers are stored in computers. It is not an R only issue, but it is described in the R-FAQ:

>From the R-FAQ - http://cran.r-project.org/doc/FAQ/R-FAQ.html

7.31 Why doesn't R think these numbers are equal?

The only numbers that can be represented exactly in R's numeric type are integers and fractions whose denominator is a power of 2. Other numbers have to be rounded to (typically) 53 binary digits accuracy. As a result, two floating point numbers will not reliably be equal unless they have been computed by the same algorithm, and not always even then. For example

R> a <- sqrt(2)
R> a * a == 2
[1] FALSE
R> a * a - 2
[1] 4.440892e-16

The function all.equal() compares two objects using a numeric tolerance of .Machine$double.eps ^ 0.5. If you want much greater accuracy than this you will need to consider error propagation carefully.

For more information, see e.g. David Goldberg (1991), "What Every Computer Scientist Should Know About Floating-Point Arithmetic", ACM Computing Surveys, 23/1, 5-48, also available via http://www.validlab.com/goldberg/paper.pdf.

To quote from "The Elements of Programming Style" by Kernighan and Plauger:

    10.0 times 0.1 is hardly ever 1.0.


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vikram Chhatre
Sent: Tuesday, April 14, 2015 2:40 PM
To: r-help
Subject: [R] Extracting unique entries by a column

I have a data frame of dim 3x600.  There are pairs of rows which have the
exact same value in column 3.

head(df)
                POP1         POP2   ABSDIFF
L0005.01 0.98484848 0.688118812 0.2967297
L0005.03 0.01515152 0.311881188 0.2967297
L0008.02 0.97727273 0.004424779 0.9728479
L0008.04 0.02272727 0.995575221 0.9728479
L0012.03 0.98684211 0.004385965 0.9824561
L0012.01 0.01315789 0.995614035 0.9824561

I want to unique sort on df$ABSDIFF so that only one row per pair remains
in the subset.

>df_subset <- df[df(!duplicated(df$ABSDIFF), ]

This does not work. So I literally checked:

>identical(df[1,3], df[2,3])
FALSE

How is 0.2967297 different from 0.2967297?  I am puzzled.

Thanks for any insight.

Vikram

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Apr 14 22:03:39 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Apr 2015 20:03:39 +0000
Subject: [R] Vectorizing a task
In-Reply-To: <896D2B85-B168-4BAC-8E0B-F901D8BB6CB7@plessthan.com>
References: <896D2B85-B168-4BAC-8E0B-F901D8BB6CB7@plessthan.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67E409@mb02.ads.tamu.edu>

It is not vectorized, but it is simple:

EXPANDED <- unlist(mapply(":", START, END))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dennis Fisher
Sent: Tuesday, April 14, 2015 2:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Vectorizing a task

R 3.1.3
OS X

Colleagues

I have data of this sort:
	START	<- c(1, 2, 3, 4, 8, 14, 15, 118, 118, 119, 202, 202, 203, 204)
	END	<- c(1, 2, 3, 6, 13, 14, 117, 118, 118, 201, 202, 202, 203, 204)
I would like to create a vector that looks like this:
	START.to.END	<- c(1:1,2:2,3:3,4:6,8:13,14:14,15:117,118:118,118:118,119:201,202:202,202:202,203:203,204:204)
i.e., each pair of entries is link with ?:?, then these are concatenated.

Ultimately, this will be expanded into:
EXPANDED	<- c(1L, 2L, 3L, 4L, 5L, 6L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 
55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 
81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 
106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 
127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 
149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 
171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 
193L, 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 202L, 203L, 204L)

The final step will be to find which values are missing from the sequence:
	setdiff(1:max(EXPANDED), EXPANDED)

The command:
	paste0("c(", paste(paste(ALLSTART, ALLEND, sep=":"), collapse=","), ")") 
creates the text for START.to.END, but I can?t figure out how to evaluate that expression.  I could build the vector step-by-step but that seems quite inefficient.

Any suggestions?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jsorkin at grecc.umaryland.edu  Tue Apr 14 22:09:43 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 14 Apr 2015 16:09:43 -0400
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <BB1ABE3C-7497-4E68-A563-086168ED7705@dcn.davis.CA.us>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
	<BB1ABE3C-7497-4E68-A563-086168ED7705@dcn.davis.CA.us>
Message-ID: <552D3BC7020000CB001295E4@smtp.medicine.umaryland.edu>

 I suggest that you investigate installing RStudio server on the Linux
Box. If you do this, you can logon to RStudio (on the Linux server), and
it will look exactly like RStudio running on a windows box. You may need
some help configuring the Linux box to allow access to port 8787, which
is the default port that RStudio Server uses. You may also have to set
port forwarding on your cable modem or firewall.
John  


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/14/15 2:54 PM >>>
You should investigate using the parallel package. You have to have R
installed on the Linux machine along with any contributed packages you
use, but you can delegate tasks to it from within an Rgui or RStudio
session running on your Windows box. There are even tutorials online
that step you through setting up a "cloud" computer to serve this
purpose.

It is possible to install R under your own account on a Linux server,
but there are more hiccups to overcome in doing so. There is a small
charge for using cloud servers, but if you use it right then the cost
can be quite cheap.

Note that while you can set up Windows servers in the cloud, they are
not as well suited to this remote use as Linux servers are, so it is
worth the effort to learn enough to do that.
---------------------------------------------------------------------------
Jeff Newmiller The ..... ..... Go Live...
DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#. ##.#. Live Go...
 Live: OO#.. Dead: OO#.. Playing
Research Engineer (Solar/Batteries O.O#. #.O#. with
/Software/Embedded Controllers) .OO#. .OO#. rocks...1k
---------------------------------------------------------------------------

Sent from my phone. Please excuse my brevity.

On April 14, 2015 9:57:28 AM PDT, Michael Haenlein
<haenlein at escpeurope.eu> wrote:
>Dear all,
>
>I am used to running R locally on my Windows-based PC. Since some of my
>computations are taking a lot of time I am now trying to move to a
>remote R
>session on a LINUX server but I am having trouble to getting things
>work.
>
>I am able to access the LINUX server using PuTTY and SSH. Once I have
>access I can log in with my username and password (which is asked
>through
>keyboard-interactive authentication). I can then open an R session.
>
>Since I am not used to working with LINUX, I have several questions:
>
>(1) Ideally I am looking for a Windows-based software that would allow
>me
>to work on R as I am used to with the difference that the computations
>are
>run remotely on the LINUX server. Does a software like this exist?
>Please
>note that I do not think that I can install any software on the LINUX
>server. But I can install stuff on my Windows-based PC.
>
>(2) I am running an extensive simulation that takes about one week to
>run.
>Right now it seems that when I log out of R on LINUX and close PuTTY,
>the R
>session closes as well. Is there a way to let R run in the background
>for
>the week and just check into the progress 1-2 times a day?
>
>(3) Can I open several instances of R in parallel? On my PC I sometimes
>have 2-3 windows open in parallel that work on different calculations
>to
>save time. Not sure to which extent this is possible on LINUX.
>
>I assume that this questions are very na?ve. But since I?m only used to
>working with Windows I?m quite stuck at the moment. Any help would be
>very
>appreciated!
>
>Thanks in advance,
>
>Michael
>
>
>
>
>Michael Haenlein
>Professor of Marketing
>ESCP Europe
>
>    [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/m>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From Douglas.Federman at utoledo.edu  Tue Apr 14 22:19:05 2015
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Tue, 14 Apr 2015 20:19:05 +0000
Subject: [R] Cost-effectiveness Analysis in R
In-Reply-To: <1429030892043.80515@pitt.edu>
References: <1429030892043.80515@pitt.edu>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AED692C@msgdb20.utad.utoledo.edu>

I've not seen much and most of the responses relate to classification trees and not clinical decision trees.  See this post: https://stat.ethz.ch/pipermail/r-help/2012-July/318597.html .  I was unable to run arvore on a recent version of R.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Singh, Ashima
Sent: Tuesday, April 14, 2015 1:02 PM
To: r-help at R-project.org
Subject: [R] Cost-effectiveness Analysis in R

?

Hi All,


I was wondering if R has a provision of performing cost-effectiveness analyses using decision trees and markov models. And if anyone has used it before.


Thanks!

Ashima

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From crypticlineage at gmail.com  Tue Apr 14 22:32:37 2015
From: crypticlineage at gmail.com (Vikram Chhatre)
Date: Tue, 14 Apr 2015 16:32:37 -0400
Subject: [R] Extracting unique entries by a column
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67E3E9@mb02.ads.tamu.edu>
References: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D67E3E9@mb02.ads.tamu.edu>
Message-ID: <CAJZnH0mmAuiPF5+oTMJyeaceWz91LHHpSOb8z_in=j0YT4swZg@mail.gmail.com>

Hi David,

Thanks.  That was enlightening.

Whoop.

V

On Tue, Apr 14, 2015 at 3:53 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Try all.equal(df[1,3], df[2,3])
>
> This relates to how decimal numbers are stored in computers. It is not an
> R only issue, but it is described in the R-FAQ:
>
> From the R-FAQ - http://cran.r-project.org/doc/FAQ/R-FAQ.html
>
> 7.31 Why doesn't R think these numbers are equal?
>
> The only numbers that can be represented exactly in R's numeric type are
> integers and fractions whose denominator is a power of 2. Other numbers
> have to be rounded to (typically) 53 binary digits accuracy. As a result,
> two floating point numbers will not reliably be equal unless they have been
> computed by the same algorithm, and not always even then. For example
>
> R> a <- sqrt(2)
> R> a * a == 2
> [1] FALSE
> R> a * a - 2
> [1] 4.440892e-16
>
> The function all.equal() compares two objects using a numeric tolerance of
> .Machine$double.eps ^ 0.5. If you want much greater accuracy than this you
> will need to consider error propagation carefully.
>
> For more information, see e.g. David Goldberg (1991), "What Every Computer
> Scientist Should Know About Floating-Point Arithmetic", ACM Computing
> Surveys, 23/1, 5-48, also available via
> http://www.validlab.com/goldberg/paper.pdf.
>
> To quote from "The Elements of Programming Style" by Kernighan and Plauger:
>
>     10.0 times 0.1 is hardly ever 1.0.
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vikram
> Chhatre
> Sent: Tuesday, April 14, 2015 2:40 PM
> To: r-help
> Subject: [R] Extracting unique entries by a column
>
> I have a data frame of dim 3x600.  There are pairs of rows which have the
> exact same value in column 3.
>
> head(df)
>                 POP1         POP2   ABSDIFF
> L0005.01 0.98484848 0.688118812 0.2967297
> L0005.03 0.01515152 0.311881188 0.2967297
> L0008.02 0.97727273 0.004424779 0.9728479
> L0008.04 0.02272727 0.995575221 0.9728479
> L0012.03 0.98684211 0.004385965 0.9824561
> L0012.01 0.01315789 0.995614035 0.9824561
>
> I want to unique sort on df$ABSDIFF so that only one row per pair remains
> in the subset.
>
> >df_subset <- df[df(!duplicated(df$ABSDIFF), ]
>
> This does not work. So I literally checked:
>
> >identical(df[1,3], df[2,3])
> FALSE
>
> How is 0.2967297 different from 0.2967297?  I am puzzled.
>
> Thanks for any insight.
>
> Vikram
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Tue Apr 14 22:40:10 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 14 Apr 2015 16:40:10 -0400
Subject: [R] Reading .LIST files into R
Message-ID: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>

Is it possible to read a LIST file into R? Any package?

I've done some googling, but there are just too many hits for a regular 'list'.
Appreciate any pointers!

-- 
Dimitri Liakhovitski


From sarah.goslee at gmail.com  Tue Apr 14 22:48:07 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 14 Apr 2015 16:48:07 -0400
Subject: [R] Reading .LIST files into R
In-Reply-To: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>
References: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>
Message-ID: <CAM_vjunbf-w28b=rzoeJatrCABkdvkerc8cee4qL4EiAP9tidg@mail.gmail.com>

What produced this file?

On Tue, Apr 14, 2015 at 4:40 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Is it possible to read a LIST file into R? Any package?
>
> I've done some googling, but there are just too many hits for a regular 'list'.
> Appreciate any pointers!
>
> --
> Dimitri Liakhovitski
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Tue Apr 14 22:59:46 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 14 Apr 2015 13:59:46 -0700
Subject: [R] Reading .LIST files into R
In-Reply-To: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>
References: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>
Message-ID: <CAF8bMcbL0wN+Xw-4_CN_52NudPQG6Dy4OnK3uptdvv_5H+k0uQ@mail.gmail.com>

Try Googling for
   ".list" file extension

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 14, 2015 at 1:40 PM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Is it possible to read a LIST file into R? Any package?
>
> I've done some googling, but there are just too many hits for a regular
> 'list'.
> Appreciate any pointers!
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Tue Apr 14 23:15:51 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 14 Apr 2015 17:15:51 -0400
Subject: [R] Reading .LIST files into R
In-Reply-To: <CAM_vjunbf-w28b=rzoeJatrCABkdvkerc8cee4qL4EiAP9tidg@mail.gmail.com>
References: <CAN2xGJYbkNm0pNdVJ=3oxXXaay_nnbCOiPVbmnc1t8Jnz3icJA@mail.gmail.com>
	<CAM_vjunbf-w28b=rzoeJatrCABkdvkerc8cee4qL4EiAP9tidg@mail.gmail.com>
Message-ID: <CAN2xGJa+f-8PjPhTr=BF67QSS8D7zz2teDG+dOsZCc4AwKJABg@mail.gmail.com>

IMDB. I guess I'll just have to open it as any text file.

On Tue, Apr 14, 2015 at 4:48 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> What produced this file?
>
> On Tue, Apr 14, 2015 at 4:40 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Is it possible to read a LIST file into R? Any package?
>>
>> I've done some googling, but there are just too many hits for a regular 'list'.
>> Appreciate any pointers!
>>
>> --
>> Dimitri Liakhovitski
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org



-- 
Dimitri Liakhovitski


From jdnewmil at dcn.davis.CA.us  Tue Apr 14 23:26:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Apr 2015 14:26:04 -0700
Subject: [R] Extracting unique entries by a column
In-Reply-To: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>
References: <CAJZnH0kp=sME6yuiYRZiWc852_fg-7MLUUCe6ekuzVpmD9Oniw@mail.gmail.com>
Message-ID: <B4760DE9-B0DB-4BA3-B391-5705ED57F5E3@dcn.davis.CA.us>

In the same way they would be different in any programming language. See R FAQ 7.31.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 14, 2015 12:39:50 PM PDT, Vikram Chhatre <crypticlineage at gmail.com> wrote:
>I have a data frame of dim 3x600.  There are pairs of rows which have
>the
>exact same value in column 3.
>
>head(df)
>                POP1         POP2   ABSDIFF
>L0005.01 0.98484848 0.688118812 0.2967297
>L0005.03 0.01515152 0.311881188 0.2967297
>L0008.02 0.97727273 0.004424779 0.9728479
>L0008.04 0.02272727 0.995575221 0.9728479
>L0012.03 0.98684211 0.004385965 0.9824561
>L0012.01 0.01315789 0.995614035 0.9824561
>
>I want to unique sort on df$ABSDIFF so that only one row per pair
>remains
>in the subset.
>
>>df_subset <- df[df(!duplicated(df$ABSDIFF), ]
>
>This does not work. So I literally checked:
>
>>identical(df[1,3], df[2,3])
>FALSE
>
>How is 0.2967297 different from 0.2967297?  I am puzzled.
>
>Thanks for any insight.
>
>Vikram
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From msuzen at gmail.com  Tue Apr 14 23:55:23 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Tue, 14 Apr 2015 22:55:23 +0100
Subject: [R] any way to write sas7bdat with R
In-Reply-To: <CAKyN3iA+PLwtOFMra7eAvtfcoisH+0OPpPajka_vHUUxEmjxOA@mail.gmail.com>
References: <CAKyN3iA+PLwtOFMra7eAvtfcoisH+0OPpPajka_vHUUxEmjxOA@mail.gmail.com>
Message-ID: <CAPtbhHx2gv7U40r8=8dHUC-Wg8rp_X3LJwLOecGN-HMqJh6cMw@mail.gmail.com>

I didn't try this but there is an experimental package from Dr. Shotwell.
http://cran.r-project.org/web/packages/sas7bdat/index.html
if it can read, maybe you can modify to write as well?


From msuzen at gmail.com  Wed Apr 15 00:30:31 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Tue, 14 Apr 2015 23:30:31 +0100
Subject: [R] Cost-effectiveness Analysis in R
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AED692C@msgdb20.utad.utoledo.edu>
References: <1429030892043.80515@pitt.edu>
	<F1065E5D886F4D429259CDEAE3F83CB61AED692C@msgdb20.utad.utoledo.edu>
Message-ID: <CAPtbhHybKQfSqcJvWsurCkm91A7Cu-PZiTXVMjvQPJaaWPz9bw@mail.gmail.com>

Do you have specific example that you have tried to implement in R?
Can you post your codes too?

There are high quality package BCEA and BayesTree, that could be helpful;
http://cran.r-project.org/web/packages/BCEA/index.html
http://cran.r-project.org/web/packages/BayesTree/index.html


From mdsumner at gmail.com  Wed Apr 15 01:16:45 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 14 Apr 2015 23:16:45 +0000
Subject: [R] plotting rasters - no plot, no error
In-Reply-To: <BAY168-W4520A096FFFC350F41189BC3E60@phx.gbl>
References: <BAY168-W83A557B196359D739E40D8C3E60@phx.gbl>
	<CAAcGz9-q+Tku=Lk-7R6QSuUeNXxYZRG6QnWUq05NoKem8WkNag@mail.gmail.com>
	<CAAcGz98hOf-FaJuZgmzq7q710NtHS=WtDduO__5dGAHqBkKrLA@mail.gmail.com>
	<BAY168-W4520A096FFFC350F41189BC3E60@phx.gbl>
Message-ID: <CAAcGz986sg-vE4wRjfq1jJq1Qcmg+9tVR5Vf79FErfzcGUryeg@mail.gmail.com>

On Wed, 15 Apr 2015 at 02:49 Monica Pisica <pisicandru at hotmail.com> wrote:

> Hi Mike,
>
>
> Very interesting. The plot itself on the computer that does not plot -
> still does not plot - no surprise there. But the command with useRaster =
> FALSE actually plots the raster. So that means it is something wrong with
> the raster package? Did i forget to install some dependency, although i
> though i ask for all to be installed?
>
>
>
Is this through Windows Remote Desktop? There's a note in ?rasterImage:

" Problems with the rendering of raster images have been
     reported by users of ?windows()? devices under Remote Desktop, at
     least under its default settings.
"

and see here:

https://stat.ethz.ch/pipermail/r-help//2013-July/357287.html

Note that raster::plot has arguments for the underlying image functions
 graphics::image and graphics::rasterImage - these are "interpolate" and
"useRaster".  The terminology is confusing, partly because rasterImage()
and its underlying code was put in base R at around the same time as the
extension package "raster" appeared. (rasterImage was originally called
"raster" so it's less confusing than it might have been)

The details get hidden because of the high-level plot() and image()
functions (and raster's additional methods for those), but essentially for
tracking down the ultimate cause you should see if you can reproduce with
the following four lines (without raster loaded):

data(volcano)
vn <- (volcano - min(volcano)) / diff(range(volcano))

## for each 1-4, close any open graphics windows first
## just to be sure (use dev.off() for convenience)

# 1.  image.default
image(vn)

# 2. rasterImage via image.default
image(vn, useRaster = TRUE)

# 3. rasterImage with interpolation
plot(0, xlim = c(0, 1),ylim = c(0,1), type = "n")
rasterImage(vn, 0, 0, 1, 1)

# 4. rasterImage without interpolation
plot(0, xlim = c(0, 1),ylim = c(0,1), type = "n")
rasterImage(vn, 0, 0, 1, 1,  interpolate = FALSE)

If you can reproduce the problem with these four cases, you have a clearer
basis to work from. These are the components from with raster's plot
methods are built, and I don't think raster is to blame here.

There might be settings for colour you can control with Remote Desktop.

Cheers, Mike.

I still don't know how to solve the problem, but thanks so much for an
> alternative way to actually plot my rasters.
>
>
> Monica
> ________________________________
> > From: mdsumner at gmail.com
> > Date: Tue, 14 Apr 2015 15:18:01 +0000
> > Subject: Re: [R] plotting rasters - no plot, no error
> > To: pisicandru at hotmail.com; r-help at r-project.org
> >
>
> > On Wed, 15 Apr 2015 at 01:16 Michael Sumner
> > <mdsumner at gmail.com<mailto:mdsumner at gmail.com>> wrote:
> > On Wed, 15 Apr 2015 at 00:50 Monica Pisica
> > <pisicandru at hotmail.com<mailto:pisicandru at hotmail.com>> wrote:
> >
> > Hi,
>
> > I have the current version of R installed on 2 different Windows
> > computers. On one i can plot using the plot function a raster in geotif
> > format, on the other it plots only the axis, an empty color bar and no
> > raster what so ever without generating any errors or warnings. So i
> > suspect something is not installed properly, but i don't know what. Do
> > you have any clues? I would really appreciate any insights. I need some
> > instructions i can pass on to an IT person since i don't have rights on
> > the computer that does not plot the raster.
>
> > Hello, can you try these on both systems and see if there's a difference?
> >
> > library(raster)
> > plot(raster(volcano))
> >
> > plot(raster(volcano), useRaster = TRUE)
>
> > Ugh, sorry I meant to try this:
> >
> > plot(raster(volcano), useRaster = FALSE)
> >
> > otherwise both calls are equivalent.
> >
> > Cheers, Mike.
> >
>
> > the useRaster argument refers to use of graphics::rasterImage rather
> > than image.defaul under (package) raster's hood.
> >
> > Cheers, Mike.
>
> > On both computers i can plot lines, points, polygons, as graphic
> > objects or shapefiles.
>
> > Thanks so much, Monica
>
> > The first PC that plots the raster:
> >
> > Sys.info()
> >
> > sysname release
> > version
> >
> > "Windows" "7 x64" "build 7601,
> > Service Pack 1"
> >
> > nodename machine
> > login
> >
> > "NODENAME" "x86-64"
> > "LOGIN"
> >
> > user effective_user
> >
> > "MONICA" "MONICA"
>
> > R.Version()
> >
> > $platform
> >
> > [1] "x86_64-w64-mingw32"
>
> > $arch
> >
> > [1] "x86_64"
>
> > $os
> >
> > [1] "mingw32"
>
> > $system
> >
> > [1] "x86_64, mingw32"
>
> > $status
> >
> > [1] ""
>
> > $major
> >
> > [1] "3"
>
> > $minor
> >
> > [1] "1.3"
>
> > $year
> >
> > [1] "2015"
>
> > $month
> >
> > [1] "03"
>
> > $day
> >
> > [1] "09"
>
> > $`svn rev`
> >
> > [1] "67962"
>
> > $language
> >
> > [1] "R"
>
> >
> > $version.string
> >
> > [1] "R version 3.1.3 (2015-03-09)"
>
> > $nickname
> >
> > [1] "Smooth Sidewalk"
>
> > Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos,
> stringr
>
> > The computer that does not plot the raster:
> >
> > Sys.info()
> >
> > sysname release
> > version nodename
> >
> > "Windows" "Server 2008 x64" "build 7601,
> > Service Pack 1" "NODENAME"
> >
> > machine login
> > user effective_user
> >
> > "x86-64" "MONICA"
> > "MONICA" "MONICA"
>
> > R.Version()
> >
> > $platform
> >
> > [1] "x86_64-w64-mingw32"
>
> > $arch
> >
> > [1] "x86_64"
>
> > $os
> >
> > [1] "mingw32"
>
> > $system
> >
> > [1] "x86_64, mingw32"
> >
>
> > $status
> >
> > [1] ""
> >
>
> > $major
> >
> > [1] "3"
>
> > $minor
> >
> > [1] "1.3"
> >
>
> > $year
> >
> > [1] "2015"
>
> > $month
> >
> > [1] "03"
> >
>
> > $day
> >
> > [1] "09"
>
> > $`svn rev`
> >
> > [1] "67962"
> >
>
> > $language
> >
> > [1] "R"
>
> > $version.string
> >
> > [1] "R version 3.1.3 (2015-03-09)"
>
> > $nickname
> >
> > [1] "Smooth Sidewalk"
>
> > Libraries i loaded: maptools, raster, rgdal, sp, CircStats, rgeos,
> stringr
>
> > again thanks so much,
> >
> > Monica
>
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Wed Apr 15 05:54:13 2015
From: miaojpm at gmail.com (jpm miao)
Date: Wed, 15 Apr 2015 11:54:13 +0800
Subject: [R] Make a Excel chart by R code
Message-ID: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>

Hi,

   I understand that there're many great graphic packages in R (e.g.,
ggplot2) . Nevertheless, my office uses Excel extensively. Is there any
package in R that produces Excel graphs by R codes? Thanks!

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Apr 15 07:08:01 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Apr 2015 15:08:01 +1000
Subject: [R] Make a Excel chart by R code
In-Reply-To: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>
References: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>
Message-ID: <CA+8X3fXbi3L1nQ2aueL6btDUuCbqrZfpEYuEKDuXNL3URFqpkA@mail.gmail.com>

Hi jpm miao,
What sort of "Excel" graphs do you want to produce? There are a few
varieties, you know.

Jim


On Wed, Apr 15, 2015 at 1:54 PM, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
>
>    I understand that there're many great graphic packages in R (e.g.,
> ggplot2) . Nevertheless, my office uses Excel extensively. Is there any
> package in R that produces Excel graphs by R codes? Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nabble.com at eshwar.in  Wed Apr 15 07:10:32 2015
From: nabble.com at eshwar.in (Eshwar)
Date: Tue, 14 Apr 2015 22:10:32 -0700 (PDT)
Subject: [R] SOLVED: Repeated failures to install "caret" package (of
 Max Kuhn)
In-Reply-To: <552026D8.20301@ischool.utexas.edu>
References: <552026D8.20301@ischool.utexas.edu>
Message-ID: <1429074632962-4705878.post@n4.nabble.com>

Thanks so much. I was struggling to install caret package on my upgraded R.
It was failing to compile lme4 and threw up an error about llapack and lbas. 
I never realized that I needed to install lbas(I already had llapack)
through SPM. Once I did that, I could install caret using install.packages
as the other depencies were taken care of by R.



--
View this message in context: http://r.789695.n4.nabble.com/SOLVED-Repeated-failures-to-install-caret-package-of-Max-Kuhn-tp4705503p4705878.html
Sent from the R help mailing list archive at Nabble.com.


From hnorpois at gmail.com  Tue Apr 14 23:34:37 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 14 Apr 2015 23:34:37 +0200
Subject: [R] scan - open text file as list
Message-ID: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>

Hello,

I try to open a text file test.txt with the content

* a b d
* z u i h hh
* h bh kk

so that I get a list with each line as a vector with the letters as
elements of the the vector.

My approach ...
test <- scan ("test.txt", what="character", sep="\n")
Read 3 items
> test.list <- lapply (test, function (x) {a <- unlist (strsplit(x," ")); a
<- a[-1]})
> test.list
[[1]]
[1] "a" "b" "d"

[[2]]
[1] "z"  "u"  "i"  "h"  "hh"

[[3]]
[1] "h"  "bh" "kk"

... the result is okay but I dont think it is an elegant solution. One
comment: I dont know how many lines my "real" test.txt will have.
Thanks Hermann

	[[alternative HTML version deleted]]


From mehmet.suzen at physics.org  Tue Apr 14 23:42:48 2015
From: mehmet.suzen at physics.org (Suzen, Mehmet)
Date: Tue, 14 Apr 2015 22:42:48 +0100
Subject: [R] Cost-effectiveness Analysis using R
In-Reply-To: <1429028410116.91766@pitt.edu>
References: <1429028410116.91766@pitt.edu>
Message-ID: <CAPtbhHxTu-M=RLOGh4Oiocv08QXpDMO9-cafdyHyU4k7dmZz5A@mail.gmail.com>

Yes.


From asi9 at pitt.edu  Tue Apr 14 23:46:53 2015
From: asi9 at pitt.edu (Singh, Ashima)
Date: Tue, 14 Apr 2015 21:46:53 +0000
Subject: [R] Cost-effectiveness Analysis using R
In-Reply-To: <CAPtbhHxTu-M=RLOGh4Oiocv08QXpDMO9-cafdyHyU4k7dmZz5A@mail.gmail.com>
References: <1429028410116.91766@pitt.edu>,
	<CAPtbhHxTu-M=RLOGh4Oiocv08QXpDMO9-cafdyHyU4k7dmZz5A@mail.gmail.com>
Message-ID: <1429048012588.9663@pitt.edu>

I looked around online but could not figure out how to build decision trees and specify probabilities at each node along with payoffs. Can you please help ?

________________________________________
From: mehmet.suzen at gmail.com <mehmet.suzen at gmail.com> on behalf of Suzen, Mehmet <mehmet.suzen at physics.org>
Sent: Tuesday, April 14, 2015 5:42 PM
To: Singh, Ashima
Cc: r-help at R-project.org
Subject: Re: [R] Cost-effectiveness Analysis using R

Yes.


From puetz at psych.mpg.de  Wed Apr 15 00:49:58 2015
From: puetz at psych.mpg.de (=?Windows-1252?Q?P=FCtz=2C_Benno?=)
Date: Tue, 14 Apr 2015 22:49:58 +0000
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
Message-ID: <371AF4E4-380E-4DC3-A4F6-9A72D910F403@psych.mpg.de>

Hi Michael,


> On 14 Apr 2015, at 18:59, Michael Haenlein <haenlein at escpeurope.eu> wrote:
> 
> Dear all,
> 
> I am used to running R locally on my Windows-based PC. Since some of my
> computations are taking a lot of time I am now trying to move to a remote R
> session on a LINUX server but I am having trouble to getting things work.
> 
> I am able to access the LINUX server using PuTTY and SSH. Once I have
> access I can log in with my username and password (which is asked through
> keyboard-interactive authentication). I can then open an R session.
> 
> Since I am not used to working with LINUX, I have several questions:
> 
> (1) Ideally I am looking for a Windows-based software that would allow me
> to work on R as I am used to with the difference that the computations are
> run remotely on the LINUX server. Does a software like this exist? Please
> note that I do not think that I can install any software on the LINUX
> server. But I can install stuff on my Windows-based PC.
> 
Can't help you on the windows side

> (2) I am running an extensive simulation that takes about one week to run.
> Right now it seems that when I log out of R on LINUX and close PuTTY, the R
> session closes as well. Is there a way to let R run in the background for
> the week and just check into the progress 1-2 times a day?
There is "screen", a utility that acts as a layer between your login and the actual shell(s) you open.
It allows to detach from and reattach to a session and would nicely fit this requirement.
I'll assume you are not producing any graphics output to screen, that would be difficult.

> 
> (3) Can I open several instances of R in parallel? On my PC I sometimes
> have 2-3 windows open in parallel that work on different calculations to
> save time. Not sure to which extent this is possible on LINUX.
2 or 3 should be no problem - you'll only be limited by memory (and cores to stay efficient).
open as many connections (or consoles in screen) as needed and start an R in each.

> 
> I assume that this questions are very na?ve. But since I?m only used to
> working with Windows I?m quite stuck at the moment. Any help would be very
> appreciated!
> 
> Thanks in advance,
> 
> Michael
> 
> 
> 
> 
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From twn2103 at columbia.edu  Wed Apr 15 00:57:25 2015
From: twn2103 at columbia.edu (Thomas Nyberg)
Date: Tue, 14 Apr 2015 18:57:25 -0400
Subject: [R] Custom error handling without stopping execution?
Message-ID: <552D9B55.3010203@columbia.edu>

Hello I've been trying to produce a general error logging/handling
framework that I can live with. I'll post the code first:

example.R
---------------------------
good_main <- function() {
    for (i in 1:2) {
        bad_function()
    }
}

bad_main <- function() {
    for (i in 1:2) {
        try(bad_function())
    }
}

Stop <- function() {
    call_stack <- sys.calls()
    err_message <- geterrmessage()
    # Drop the final function (which is this one) from the
    # call_stack.
    call_stack <- head(call_stack, length(call_stack) - 1)
    # Convert to strings.
    call_stack <- lapply(call_stack, capture.output)
    call_stack <- unlist(call_stack)
    call_stack <- paste(call_stack, collapse="\n")

    print(call_stack)
}

options(error = Stop)

bad_function <- function() {
    stop("Bad function.")
}

good_main()
bad_main()
---------------------------

The following is the result of running this on my end:

---------------------------
$ Rscript example.R
Error in bad_function() : Bad function.
Calls: good_main -> bad_function
[1] "good_main()\nbad_function()\nstop(\"Bad function.\")"
Error in bad_function() : Bad function.
Error in bad_function() : Bad function.
---------------------------

My problem is the following line:

	[1] "good_main()\nbad_function()\nstop(\"Bad function.\")"

This is only printed once because the good_main() function is ending its
execution when the error occurs. The bad_main() function does not, but
that one seems to kill my stack_trace (which is the whole point of my
doing this). How to I use a custom error handler (as in good_main())
_without_ stopping execution (as is occurring in bad_main())?

Thanks for any help.

Cheers,
Thomas


From dotlundberg at gmail.com  Wed Apr 15 02:04:48 2015
From: dotlundberg at gmail.com (Dot Lundberg)
Date: Tue, 14 Apr 2015 20:04:48 -0400
Subject: [R] (no subject)
Message-ID: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>

New to R. Having trouble with the xaxis in this code. The tick marks are
crazy and the labels repeat. Any suggestions?

par(mar=c(5,5,5,5))

plot(LPB_PPT_R$newdate,LPB_PPT_R$Rain_cm,pch=0,type="l",col="black",yaxt="n",ylim=c(0,8),ylab="")
axis(side=2, at=c(0,2,4,6,8))
mtext("Precipitation (cm)", side = 2, line=2.5, at=4)
mtext("Date", side=1, line=2.5)
axis.Date(1, at=seq(min(LPB_PPT_R$newdate),
max(LPB_PPT_R$newdate),las=2,by="1 weeks"),format="%m-%Y")

par(new=TRUE)

plot(LPB_PPT_R$newdate,LPB_PPT_R$Cum_PPT,pch=1,type="l",col="grey",yaxt="n",ylim=c(0,100),
ylab="")
axis(side=4, at=c(0,50,100))
mtext("Cumulative Precipitation (cm)", side=4, line=2.5, at=50, col="grey")

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Apr 15 08:33:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Apr 2015 23:33:10 -0700
Subject: [R] (no subject)
In-Reply-To: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>
References: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>
Message-ID: <7E3243BB-2116-4E55-858F-4C55DD1072F8@dcn.davis.CA.us>

A wild guess is that you have not converted your newdate column into a time metric such as Date or POSIXt. Our responses can be ever so much more helpful if you follow the Posting Guide (mentioned in the footer), e.g. posting using plain text so the code gets through the mailing list successfully, and if you make your example reproducible [1].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 14, 2015 5:04:48 PM PDT, Dot Lundberg <dotlundberg at gmail.com> wrote:
>New to R. Having trouble with the xaxis in this code. The tick marks
>are
>crazy and the labels repeat. Any suggestions?
>
>par(mar=c(5,5,5,5))
>
>plot(LPB_PPT_R$newdate,LPB_PPT_R$Rain_cm,pch=0,type="l",col="black",yaxt="n",ylim=c(0,8),ylab="")
>axis(side=2, at=c(0,2,4,6,8))
>mtext("Precipitation (cm)", side = 2, line=2.5, at=4)
>mtext("Date", side=1, line=2.5)
>axis.Date(1, at=seq(min(LPB_PPT_R$newdate),
>max(LPB_PPT_R$newdate),las=2,by="1 weeks"),format="%m-%Y")
>
>par(new=TRUE)
>
>plot(LPB_PPT_R$newdate,LPB_PPT_R$Cum_PPT,pch=1,type="l",col="grey",yaxt="n",ylim=c(0,100),
>ylab="")
>axis(side=4, at=c(0,50,100))
>mtext("Cumulative Precipitation (cm)", side=4, line=2.5, at=50,
>col="grey")
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From arnaud.gaboury at gmail.com  Wed Apr 15 08:39:03 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Wed, 15 Apr 2015 08:39:03 +0200
Subject: [R] Running R Remotely on LINUX
In-Reply-To: <552D3BC7020000CB001295E4@smtp.medicine.umaryland.edu>
References: <CAOyz9G6gapPPXDAiQMAPjpBYb=avfXXHB+rt96-vWE-PEvREHw@mail.gmail.com>
	<BB1ABE3C-7497-4E68-A563-086168ED7705@dcn.davis.CA.us>
	<552D3BC7020000CB001295E4@smtp.medicine.umaryland.edu>
Message-ID: <CAK1hC9uWn-o7SxGcPLA0qZ8pWsayO5ZoZx7Obr2Q+wTx7eyP8Q@mail.gmail.com>

On Tue, Apr 14, 2015 at 10:09 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
>  I suggest that you investigate installing RStudio server on the Linux
> Box. If you do this, you can logon to RStudio (on the Linux server), and
> it will look exactly like RStudio running on a windows box. You may need
> some help configuring the Linux box to allow access to port 8787, which
> is the default port that RStudio Server uses. You may also have to set
> port forwarding on your cable modem or firewall.
> John

In case you just need a R server, with no IDE (like Rstudio provides
it), please have a look at this project[0]

[0]http://www.obiba.org/?q=node/63
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/14/15 2:54 PM >>>
> You should investigate using the parallel package. You have to have R
> installed on the Linux machine along with any contributed packages you
> use, but you can delegate tasks to it from within an Rgui or RStudio
> session running on your Windows box. There are even tutorials online
> that step you through setting up a "cloud" computer to serve this
> purpose.
>
> It is possible to install R under your own account on a Linux server,
> but there are more hiccups to overcome in doing so. There is a small
> charge for using cloud servers, but if you use it right then the cost
> can be quite cheap.
>
> Note that while you can set up Windows servers in the cloud, they are
> not as well suited to this remote use as Linux servers are, so it is
> worth the effort to learn enough to do that.
> ---------------------------------------------------------------------------
> Jeff Newmiller The ..... ..... Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#. ##.#. Live Go...
>  Live: OO#.. Dead: OO#.. Playing
> Research Engineer (Solar/Batteries O.O#. #.O#. with
> /Software/Embedded Controllers) .OO#. .OO#. rocks...1k
> ---------------------------------------------------------------------------
>
> Sent from my phone. Please excuse my brevity.
>
> On April 14, 2015 9:57:28 AM PDT, Michael Haenlein
> <haenlein at escpeurope.eu> wrote:
>>Dear all,
>>
>>I am used to running R locally on my Windows-based PC. Since some of my
>>computations are taking a lot of time I am now trying to move to a
>>remote R
>>session on a LINUX server but I am having trouble to getting things
>>work.
>>
>>I am able to access the LINUX server using PuTTY and SSH. Once I have
>>access I can log in with my username and password (which is asked
>>through
>>keyboard-interactive authentication). I can then open an R session.
>>
>>Since I am not used to working with LINUX, I have several questions:
>>
>>(1) Ideally I am looking for a Windows-based software that would allow
>>me
>>to work on R as I am used to with the difference that the computations
>>are
>>run remotely on the LINUX server. Does a software like this exist?
>>Please
>>note that I do not think that I can install any software on the LINUX
>>server. But I can install stuff on my Windows-based PC.
>>
>>(2) I am running an extensive simulation that takes about one week to
>>run.
>>Right now it seems that when I log out of R on LINUX and close PuTTY,
>>the R
>>session closes as well. Is there a way to let R run in the background
>>for
>>the week and just check into the progress 1-2 times a day?
>>
>>(3) Can I open several instances of R in parallel? On my PC I sometimes
>>have 2-3 windows open in parallel that work on different calculations
>>to
>>save time. Not sure to which extent this is possible on LINUX.
>>
>>I assume that this questions are very na?ve. But since I?m only used to
>>working with Windows I?m quite stuck at the moment. Any help would be
>>very
>>appreciated!
>>
>>Thanks in advance,
>>
>>Michael
>>
>>
>>
>>
>>Michael Haenlein
>>Professor of Marketing
>>ESCP Europe
>>
>>    [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/m>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:18}}


From drjimlemon at gmail.com  Wed Apr 15 11:02:38 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Apr 2015 19:02:38 +1000
Subject: [R] (no subject)
In-Reply-To: <7E3243BB-2116-4E55-858F-4C55DD1072F8@dcn.davis.CA.us>
References: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>
	<7E3243BB-2116-4E55-858F-4C55DD1072F8@dcn.davis.CA.us>
Message-ID: <CA+8X3fVRQN96OjtN3SxKka38shVA89XQ5ndRG8Fg=kaxvTuX7g@mail.gmail.com>

Hi Dot,
Jeff's guess is probably correct, but perhaps you could describe the
crazy tick marks and the repeating labels a little more. I suspect
that if "newdate" was a character variable you wouldn't get a plot at
all, and if it is a factor, a few of the labels might identify what
went wrong.

Jim

> On April 14, 2015 5:04:48 PM PDT, Dot Lundberg <dotlundberg at gmail.com>
> wrote:
>>New to R. Having trouble with the xaxis in this code. The tick marks
>>are
>>crazy and the labels repeat. Any suggestions?
>>
>>par(mar=c(5,5,5,5))
>>
>>plot(LPB_PPT_R$newdate,LPB_PPT_R$Rain_cm,pch=0,type="l",col="black",yaxt="n",ylim=c(0,8),ylab="")
>>axis(side=2, at=c(0,2,4,6,8))
>>mtext("Precipitation (cm)", side = 2, line=2.5, at=4)
>>mtext("Date", side=1, line=2.5)
>>axis.Date(1, at=seq(min(LPB_PPT_R$newdate),
>>max(LPB_PPT_R$newdate),las=2,by="1 weeks"),format="%m-%Y")
>>
>>par(new=TRUE)
>>
>>plot(LPB_PPT_R$newdate,LPB_PPT_R$Cum_PPT,pch=1,type="l",col="grey",yaxt="n",ylim=c(0,100),
>>ylab="")
>>axis(side=4, at=c(0,50,100))
>>mtext("Cumulative Precipitation (cm)", side=4, line=2.5, at=50,
>>col="grey")
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Apr 15 11:29:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Apr 2015 19:29:32 +1000
Subject: [R] scan - open text file as list
In-Reply-To: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>
References: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>
Message-ID: <CA+8X3fX0ovPZkcnFBb6URLa1=YD7L+pea3O4xgABscRLvHK0-A@mail.gmail.com>

Hi Hermann,
This isn't much more elegant, but

test.list<-sapply(test,function(x) { strsplit(x," ") },simplify=TRUE)
names(test.list)<-NULL

Jim


On 4/15/15, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> I try to open a text file test.txt with the content
>
> * a b d
> * z u i h hh
> * h bh kk
>
> so that I get a list with each line as a vector with the letters as
> elements of the the vector.
>
> My approach ...
> test <- scan ("test.txt", what="character", sep="\n")
> Read 3 items
>> test.list <- lapply (test, function (x) {a <- unlist (strsplit(x," ")); a
> <- a[-1]})
>> test.list
> [[1]]
> [1] "a" "b" "d"
>
> [[2]]
> [1] "z"  "u"  "i"  "h"  "hh"
>
> [[3]]
> [1] "h"  "bh" "kk"
>
> ... the result is okay but I dont think it is an elegant solution. One
> comment: I dont know how many lines my "real" test.txt will have.
> Thanks Hermann
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thierry.onkelinx at inbo.be  Wed Apr 15 13:30:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 15 Apr 2015 13:30:30 +0200
Subject: [R] : automated levene test and other tests for variable
	datasets
In-Reply-To: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
References: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
Message-ID: <CAJuCY5zL3AMpTS6OTLWbqFc3WhQ2Vq1o19+rWiVyTQYvd+kBVA@mail.gmail.com>

Dear Joachim,

Storing your data in a long format will make this a lot easier.

library(reshape2)
long.data <- melt(dataset, measure.var = c("A", "B", "C", "D", "E"))
library(car)
leveneTest(value ~ variable, data = long.data)

library(plyr)
ddply(long.data, "variable", function(x){ks.test(x$value})

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-14 10:07 GMT+02:00 Joachim Audenaert <
Joachim.Audenaert at pcsierteelt.be>:

> Hello all,
>
> I am writing a script for statistical comparison of means. I'm doing many
> field trials with plants, where we have to compare the efficacy of
> different treatments on, different groups of plants. Therefore I would
> like to automate this script so it can be used for different datasets of
> different experiments (which will have different dimensions). An example
> dataset is given here under, I would like to compare if the data of 5
> columns (A,B,C,D,E) are statistically different from each other, where A,
> B, C, D and A are different treatments of my plants and I have 5
> replications for this experiment
>
> dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61,
> 19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E =
> c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names =
> c(NA, 5L), class = "data.frame")
>
> 1) First I would like to do a levene test to check the equality of
> variances of my datasets. Currently I do this as follows:
>
> library("car")
> attach(dataset)
> y <- c(A,B,C,D,E)
> group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3,
> length(C)), rep(4, length(D)),rep(5, length(E))))
> leveneTest(y, group)
>
> Is there a way to automate this for all types of datasets, so that I can
> use the same script for a datasets with any number of columns of data to
> compare? My above script only works for a dataset with 5 columns to
> compare
>
> 2) For my boxplots I use
>
> boxplot(dataset)
>
> which gives me all the boxplots of each dataset, so this is how I want it
>
> 3) To check normality I currently use the kolmogorov smirnov test as
> follows
>
> ks.test(A,pnorm)
> ks.test(B,pnorm)
> ks.test(C,pnorm)
> ks.test(D,pnorm)
> ks.test(E,pnorm)
>
> Is there a way to replace the A, B, C, ... on the five lines into one line
> of entry so that the kolmogorov smirnov test is done on all columns of my
> dataset at once?
>
> 4) if data is normally distributed and the variances are equal I want to
> do a t-test and do pairwise comparison, currently like this
>
> pairwise.t.test(y,group,p.adjust.method = "none")
>
> if data is not normally distributed or variances are unequal I do a
> pairwise comparison with the wilcoxon test
>
> pairwise.wilcox.test(y,group,p.adjust.method = "none")
>
> But again I would like to make this easier, is there a way to replace the
> y and group in my datalineby something so it works for any size of
> dataset?
>
> 5) Once I have my paiwise comparison results I know which groups are
> statistically different from others, so I can add a and b and c to
> different groups in my graph. Currently I do this on a sheet of paper by
> comparing them one by one. Is there also a way to automate this? So R
> gives me for example something like this
>
> A: a
> B: a
> C: b
> D: ab
> E: c
>
> All help and commentys are welcome. I'm quite new to R and not a
> statistical genious, so if I'm overseeing things or thinking in a wrong
> way please let me know how I can improve my way of working. In short I
> would like to build a script that can compare the means of different
> groups of data and check if they are statistically diiferent
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think green,
> keep it on the screen!
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From givolis at gmail.com  Wed Apr 15 13:57:46 2015
From: givolis at gmail.com (Simon Givoli)
Date: Wed, 15 Apr 2015 14:57:46 +0300
Subject: [R] ClickStream package: How to expand mc plot?
Message-ID: <CAN=5oGj6DF-4pixFLT_K_s9NcmB_=1eJpHDjNcWs=6B+ZKcunQ@mail.gmail.com>

Hi,

I produced a mc plot with this package, but the plot is cluttered in
the middle. Is there a way to expand the plot so its parts are more
clear?

Simon


From david.stevens at usu.edu  Wed Apr 15 14:17:02 2015
From: david.stevens at usu.edu (David Stevens)
Date: Wed, 15 Apr 2015 06:17:02 -0600
Subject: [R] Make a Excel chart by R code
In-Reply-To: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>
References: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>
Message-ID: <552E56BE.8040909@usu.edu>

By this, do you mean you want to use R to send data to Excel and have 
Excel create the graph without your intervention, or to use R to create 
a graph that looks like one of those that Excel produces?

David

On 4/14/2015 9:54 PM, jpm miao wrote:
> Hi,
>
>     I understand that there're many great graphic packages in R (e.g.,
> ggplot2) . Nevertheless, my office uses Excel extensively. Is there any
> package in R that produces Excel graphs by R codes? Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From Joachim.Audenaert at pcsierteelt.be  Wed Apr 15 14:23:34 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Wed, 15 Apr 2015 14:23:34 +0200
Subject: [R] : automated levene test and other tests for variable
	datasets
In-Reply-To: <CAJuCY5zL3AMpTS6OTLWbqFc3WhQ2Vq1o19+rWiVyTQYvd+kBVA@mail.gmail.com>
References: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
	<CAJuCY5zL3AMpTS6OTLWbqFc3WhQ2Vq1o19+rWiVyTQYvd+kBVA@mail.gmail.com>
Message-ID: <OF38E62AFC.EA2C8CEF-ONC1257E28.0043AEEC-C1257E28.00441391@pcsierteelt.be>

Thank you very much for the reply Thierry,

It was very useful for me, currently I updated my script as follows, to be 
able to use the same script for different datasets:

adapting my dataset : y <- melt(dataset, na.rm=TRUE) where "na.rm = true" 
ommits missing data points

variable <- y[,1] 
value <- y[,2]

and then for the tests

leveneTest(value~variable,y)
apply(dataset,MARGIN=2,FUN=function(x) ks.test(x,pnorm)$p.value)

pairwise.t.test(value,variable,p.adjust.method = "none")
pairwise.wilcox.test(value,variable,p.adjust.method = "none")

Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:   Thierry Onkelinx <thierry.onkelinx at inbo.be>
To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>
Cc:     "r-help at r-project.org" <r-help at r-project.org>
Date:   15/04/2015 13:31
Subject:        Re: [R] : automated levene test and other tests for 
variable datasets



Dear Joachim,

Storing your data in a long format will make this a lot easier.

library(reshape2)
long.data <- melt(dataset, measure.var = c("A", "B", "C", "D", "E"))
library(car)
leveneTest(value ~ variable, data = long.data)

library(plyr)
ddply(long.data, "variable", function(x){ks.test(x$value})

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and 
Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more 
than asking him to perform a post-mortem examination: he may be able to 
say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not 
ensure that a reasonable answer can be extracted from a given body of 
data. ~ John Tukey

2015-04-14 10:07 GMT+02:00 Joachim Audenaert <
Joachim.Audenaert at pcsierteelt.be>:
Hello all,

I am writing a script for statistical comparison of means. I'm doing many
field trials with plants, where we have to compare the efficacy of
different treatments on, different groups of plants. Therefore I would
like to automate this script so it can be used for different datasets of
different experiments (which will have different dimensions). An example
dataset is given here under, I would like to compare if the data of 5
columns (A,B,C,D,E) are statistically different from each other, where A,
B, C, D and A are different treatments of my plants and I have 5
replications for this experiment

dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61,
19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E =
c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names =
c(NA, 5L), class = "data.frame")

1) First I would like to do a levene test to check the equality of
variances of my datasets. Currently I do this as follows:

library("car")
attach(dataset)
y <- c(A,B,C,D,E)
group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3,
length(C)), rep(4, length(D)),rep(5, length(E))))
leveneTest(y, group)

Is there a way to automate this for all types of datasets, so that I can
use the same script for a datasets with any number of columns of data to
compare? My above script only works for a dataset with 5 columns to
compare

2) For my boxplots I use

boxplot(dataset)

which gives me all the boxplots of each dataset, so this is how I want it

3) To check normality I currently use the kolmogorov smirnov test as
follows

ks.test(A,pnorm)
ks.test(B,pnorm)
ks.test(C,pnorm)
ks.test(D,pnorm)
ks.test(E,pnorm)

Is there a way to replace the A, B, C, ... on the five lines into one line
of entry so that the kolmogorov smirnov test is done on all columns of my
dataset at once?

4) if data is normally distributed and the variances are equal I want to
do a t-test and do pairwise comparison, currently like this

pairwise.t.test(y,group,p.adjust.method = "none")

if data is not normally distributed or variances are unequal I do a
pairwise comparison with the wilcoxon test

pairwise.wilcox.test(y,group,p.adjust.method = "none")

But again I would like to make this easier, is there a way to replace the
y and group in my datalineby something so it works for any size of
dataset?

5) Once I have my paiwise comparison results I know which groups are
statistically different from others, so I can add a and b and c to
different groups in my graph. Currently I do this on a sheet of paper by
comparing them one by one. Is there also a way to automate this? So R
gives me for example something like this

A: a
B: a
C: b
D: ab
E: c

All help and commentys are welcome. I'm quite new to R and not a
statistical genious, so if I'm overseeing things or thinking in a wrong
way please let me know how I can improve my way of working. In short I
would like to build a script that can compare the means of different
groups of data and check if they are statistically diiferent

Met vriendelijke groeten - With kind regards,

Joachim Audenaert
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green,
keep it on the screen!
        [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green,
keep it on the screen!
	[[alternative HTML version deleted]]


From Joachim.Audenaert at pcsierteelt.be  Wed Apr 15 14:25:51 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Wed, 15 Apr 2015 14:25:51 +0200
Subject: [R] : automated levene test and other tests for variable
	datasets
In-Reply-To: <552D3DB1.6060301@dewey.myzen.co.uk>
References: <OF30176015.FCA5F300-ONC1257E27.0028B389-C1257E27.002CA8FF@pcsierteelt.be>
	<552D3DB1.6060301@dewey.myzen.co.uk>
Message-ID: <OFD88C907D.48706971-ONC1257E28.00442320-C1257E28.004448C1@pcsierteelt.be>

Hello Michael,

thank you for the reply, it realy helped me to simplify my script. 
Basically all my questions are a bit the same, but with your hint I could 
solve most of my problems. 

Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:   Michael Dewey <lists at dewey.myzen.co.uk>
To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>, 
r-help at r-project.org
Date:   14/04/2015 18:17
Subject:        Re: [R] : automated levene test and other tests for 
variable datasets



You ask quite a lot of questions, I have given some hints about your 
first example inline

On 14/04/2015 09:07, Joachim Audenaert wrote:
> Hello all,
>
> I am writing a script for statistical comparison of means. I'm doing 
many
> field trials with plants, where we have to compare the efficacy of
> different treatments on, different groups of plants. Therefore I would
> like to automate this script so it can be used for different datasets of
> different experiments (which will have different dimensions). An example
> dataset is given here under, I would like to compare if the data of 5
> columns (A,B,C,D,E) are statistically different from each other, where 
A,
> B, C, D and A are different treatments of my plants and I have 5
> replications for this experiment
>
> dataset <- structure(list(A = c(62, 55, 57, 103, 59), B = c(36, 24, 61,
> 19, 79), C = c(33, 97, 54, 48, 166), D = c(106, 82, 116, 85, 94), E =
> c(32, 16, 9, 7, 46)), .Names = c("A", "B", "C", "D",    "E"), row.names 
=
> c(NA, 5L), class = "data.frame")
>
> 1) First I would like to do a levene test to check the equality of
> variances of my datasets. Currently I do this as follows:
>
> library("car")
> attach(dataset)
Usually best to avoid this and use the data=parameter or with or within

> y <- c(A,B,C,D,E)
you could use unlist( ) here
> group <- as.factor(c(rep(1, length(A)), rep(2, length(B)),rep(3,
> length(C)), rep(4, length(D)),rep(5, length(E))))
you can get the lengths which you need with
lengtha <- lapply(dataset, length)
or
lengths <- sapply(dataset, length)
depending

then
rep(letters[1:length(lengths)], lengths)
should get you the group variable you want.


I have just typed all those in so there may be typos but at least you 
know where to look. I am not suggesting that I think automating all 
statistical analyses is necessarily a good idea either.

> leveneTest(y, group)
>
> Is there a way to automate this for all types of datasets, so that I can
> use the same script for a datasets with any number of columns of data to
> compare? My above script only works for a dataset with 5 columns to
> compare
>
> 2) For my boxplots I use
>
> boxplot(dataset)
>
> which gives me all the boxplots of each dataset, so this is how I want 
it
>
> 3) To check normality I currently use the kolmogorov smirnov test as
> follows
>
> ks.test(A,pnorm)
> ks.test(B,pnorm)
> ks.test(C,pnorm)
> ks.test(D,pnorm)
> ks.test(E,pnorm)
>
> Is there a way to replace the A, B, C, ... on the five lines into one 
line
> of entry so that the kolmogorov smirnov test is done on all columns of 
my
> dataset at once?
>
> 4) if data is normally distributed and the variances are equal I want to
> do a t-test and do pairwise comparison, currently like this
>
> pairwise.t.test(y,group,p.adjust.method = "none")
>
> if data is not normally distributed or variances are unequal I do a
> pairwise comparison with the wilcoxon test
>
> pairwise.wilcox.test(y,group,p.adjust.method = "none")
>
> But again I would like to make this easier, is there a way to replace 
the
> y and group in my datalineby something so it works for any size of
> dataset?
>
> 5) Once I have my paiwise comparison results I know which groups are
> statistically different from others, so I can add a and b and c to
> different groups in my graph. Currently I do this on a sheet of paper by
> comparing them one by one. Is there also a way to automate this? So R
> gives me for example something like this
>
> A: a
> B: a
> C: b
> D: ab
> E: c
>
> All help and commentys are welcome. I'm quite new to R and not a
> statistical genious, so if I'm overseeing things or thinking in a wrong
> way please let me know how I can improve my way of working. In short I
> would like to build a script that can compare the means of different
> groups of data and check if they are statistically diiferent
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think 
green,
> keep it on the screen!
>                [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Apr 15 14:51:24 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 15 Apr 2015 04:51:24 -0800
Subject: [R] Make a Excel chart by R code
In-Reply-To: <CABcx46BijTK85WUtezr5EzgrSfzpNTwAAo+3qtpFbA=SjfjJhQ@mail.gmail.com>
Message-ID: <54EF5BA8C76.000010A2jrkrideau@inbox.com>



John Kane
Kingston ON Canada


> -----Original Message-----
> From: miaojpm at gmail.com
> Sent: Wed, 15 Apr 2015 11:54:13 +0800
> To: r-help at r-project.org
> Subject: [R] Make a Excel chart by R code
> 
> Hi,
> 
>    I understand that there're many great graphic packages in R (e.g.,
> ggplot2) . Nevertheless, my office uses Excel extensively. 

Oh dear what a pity Cryer, Jonathan D. ?Problems with Using Microsoft Excel for Statistics.? In Joint Statistical Meetings, 2001. http://www.amstat.org/sections/srms/proceedings/y2001/proceed/00470.pdf.


Unless you need to have the graphs updating all the time in Calc would it not be just as handy to produce the charts/graphs in R and just import them into your final product.

A little bit more work but far superiour graphics and easier maintenance of the graphs.  It is much easier to change one line (or one word of code) than to start frenzied clicking all over again.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From anniek at brinkonline.nl  Wed Apr 15 13:11:24 2015
From: anniek at brinkonline.nl (Anniek)
Date: Wed, 15 Apr 2015 04:11:24 -0700 (PDT)
Subject: [R] What does exp(-coef) mean?
Message-ID: <1429096284336-4705897.post@n4.nabble.com>

I know that exp(coef) is the Hazard Ratio, but in a certain output posted
down here also a exp(-coef) is present. 

               exp(coef) exp(-coef) lower .95 upper .95
ns(CD4, 4)1      0.29058     3.4413  0.144075    0.5861
ns(CD4, 4)2      0.09870    10.1316  0.029075    0.3351
ns(CD4, 4)3      0.03475    28.7806  0.007375    0.1637
ns(CD4, 4)4      0.10211     9.7933  0.019234    0.5421
drug[T.ddI]      1.31900     0.7582  0.989748    1.7578
AZT[T.failure]   1.46116     0.6844  1.087839    1.9626

What does exp(-coef) mean? 

Thank you in advance! 



--
View this message in context: http://r.789695.n4.nabble.com/What-does-exp-coef-mean-tp4705897.html
Sent from the R help mailing list archive at Nabble.com.


From bilelfathalli at yahoo.fr  Wed Apr 15 12:15:46 2015
From: bilelfathalli at yahoo.fr (fathalli bilel)
Date: Wed, 15 Apr 2015 10:15:46 +0000 (UTC)
Subject: [R] adding a bravais  pearson test to spplot
Message-ID: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>

Dear all,
My name is Bilel and I'am a PhD student from Tunisia working on climate modelling. My issue today is how to add a Bravais Pearson test as a contour plot to an existing spplot map. Precisely, I have plotted a SpatialPixelsDataFrame of Pearson correlation coefficients between simulated and observed precipitation over the Mediterranean basin using spplot and I need to now add a contour line of the statically significant correlation coefficient at 95% CI.I have been vainly trying for several days to solve this issue, so I really need your help please
Best regards?Bilel?
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Apr 15 15:54:50 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 15 Apr 2015 15:54:50 +0200
Subject: [R] What does exp(-coef) mean?
In-Reply-To: <1429096284336-4705897.post@n4.nabble.com>
References: <1429096284336-4705897.post@n4.nabble.com>
Message-ID: <2C48B9FC-D66C-4825-8CE9-E0F89F39A318@gmail.com>


On 15 Apr 2015, at 13:11 , Anniek <anniek at brinkonline.nl> wrote:

> I know that exp(coef) is the Hazard Ratio, but in a certain output posted
> down here also a exp(-coef) is present. 
> 
>               exp(coef) exp(-coef) lower .95 upper .95
> ns(CD4, 4)1      0.29058     3.4413  0.144075    0.5861
> ns(CD4, 4)2      0.09870    10.1316  0.029075    0.3351
> ns(CD4, 4)3      0.03475    28.7806  0.007375    0.1637
> ns(CD4, 4)4      0.10211     9.7933  0.019234    0.5421
> drug[T.ddI]      1.31900     0.7582  0.989748    1.7578
> AZT[T.failure]   1.46116     0.6844  1.087839    1.9626
> 
> What does exp(-coef) mean? 
> 

The inverse hazard ratio. (As in e^-x = 1/e^x).


> Thank you in advance! 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/What-does-exp-coef-mean-tp4705897.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Wed Apr 15 16:40:30 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Apr 2015 07:40:30 -0700
Subject: [R] scan - open text file as list
In-Reply-To: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>
References: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>
Message-ID: <CAF8bMcaTu_eTxhM+hoktHD6couMqfo02kcBePKfEwdU8fJUfMQ@mail.gmail.com>

> strsplit(x=sub(pattern="^\\* ", replacement="", x=test), split=" ")
[[1]]
[1] "a" "b" "d"

[[2]]
[1] "z"  "u"  "i"  "h"  "hh"

[[3]]
[1] "h"  "bh" "kk"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 14, 2015 at 2:34 PM, Hermann Norpois <hnorpois at gmail.com> wrote:

> Hello,
>
> I try to open a text file test.txt with the content
>
> * a b d
> * z u i h hh
> * h bh kk
>
> so that I get a list with each line as a vector with the letters as
> elements of the the vector.
>
> My approach ...
> test <- scan ("test.txt", what="character", sep="\n")
> Read 3 items
> > test.list <- lapply (test, function (x) {a <- unlist (strsplit(x," ")); a
> <- a[-1]})
> > test.list
> [[1]]
> [1] "a" "b" "d"
>
> [[2]]
> [1] "z"  "u"  "i"  "h"  "hh"
>
> [[3]]
> [1] "h"  "bh" "kk"
>
> ... the result is okay but I dont think it is an elegant solution. One
> comment: I dont know how many lines my "real" test.txt will have.
> Thanks Hermann
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Apr 15 16:40:58 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Apr 2015 07:40:58 -0700
Subject: [R] adding a bravais  pearson test to spplot
In-Reply-To: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>
References: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6CC95048-5EFF-47C4-AA93-02281D403844@dcn.davis.CA.us>

Well, creating an example from scratch to show you how it is done can be a lot of work, and depending on your specific data such code can end up being wasted work. For this reason the polite thing to do is to provide a minimal reproducible example that list readers can use to start from. [1]

Also, you should read the Posting Guide, which warns you that the R mailing lists are plain text only, so if you post HTML as you did then at best we don't see what you see and at worst it is corrupted. The Guide also mentions that there are different lists with different topics, and the topic of your question is probably best addressed on the R-sig-geo mailing list. It looks nontrivial to me, but there might be a canned solution out there.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 15, 2015 3:15:46 AM PDT, fathalli bilel <bilelfathalli at yahoo.fr> wrote:
>Dear all,
>My name is Bilel and I'am a PhD student from Tunisia working on climate
>modelling. My issue today is how to add a Bravais Pearson test as a
>contour plot to an existing spplot map. Precisely, I have plotted a
>SpatialPixelsDataFrame of Pearson correlation coefficients between
>simulated and observed precipitation over the Mediterranean basin using
>spplot and I need to now add a contour line of the statically
>significant correlation coefficient at 95% CI.I have been vainly trying
>for several days to solve this issue, so I really need your help please
>Best regards?Bilel?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Apr 15 17:39:08 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Apr 2015 08:39:08 -0700
Subject: [R] adding a bravais  pearson test to spplot
In-Reply-To: <1170215877.4221321.1429110260307.JavaMail.yahoo@mail.yahoo.com>
References: <6CC95048-5EFF-47C4-AA93-02281D403844@dcn.davis.CA.us>
	<1170215877.4221321.1429110260307.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4DD3FD61-489A-4123-AD90-AAD676A004BA@dcn.davis.CA.us>

I think you did not read my answer very carefully... there is a better mailing list for your question. The rest of my comments were intended to educate you, not chastise you. Mailing lists require careful communication, and you do need to improve on your end or you will have "bad luck" getting help in the lists because few people will guess right about what you really need.

I did fail to put in the reference [1] which is very helpful; I am sorry for that omission.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 15, 2015 8:04:20 AM PDT, fathalli bilel <bilelfathalli at yahoo.fr> wrote:
>Hi,First : thanks for your answerThis is my first post on the R-help
>forum and I'm not familiar with the way how to should post.?I am not
>searching for "an example from scratch" as you said, I am able to build
>my own codes so I'm only looking for tips ?: packages, functions that
>can help my issue?(help that does not mean a "code" ready for use")I'm
>very polite and I'am shocked by the way your give your answer
>Bilel ?
>
>
>Le Mercredi 15 avril 2015 15h40, Jeff Newmiller
><jdnewmil at dcn.davis.CA.us> a ?crit :
>   
>
>Well, creating an example from scratch to show you how it is done can
>be a lot of work, and depending on your specific data such code can end
>up being wasted work. For this reason the polite thing to do is to
>provide a minimal reproducible example that list readers can use to
>start from. [1]
>
>Also, you should read the Posting Guide, which warns you that the R
>mailing lists are plain text only, so if you post HTML as you did then
>at best we don't see what you see and at worst it is corrupted. The
>Guide also mentions that there are different lists with different
>topics, and the topic of your question is probably best addressed on
>the R-sig-geo mailing list. It looks nontrivial to me, but there might
>be a canned solution out there.
>---------------------------------------------------------------------------
>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>Go...
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.?
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On April 15, 2015 3:15:46 AM PDT, fathalli bilel
><bilelfathalli at yahoo.fr> wrote:
>>Dear all,
>>My name is Bilel and I'am a PhD student from Tunisia working on
>climate
>>modelling. My issue today is how to add a Bravais Pearson test as a
>>contour plot to an existing spplot map. Precisely, I have plotted a
>>SpatialPixelsDataFrame of Pearson correlation coefficients between
>>simulated and observed precipitation over the Mediterranean basin
>using
>>spplot and I need to now add a contour line of the statically
>>significant correlation coefficient at 95% CI.I have been vainly
>trying
>>for several days to solve this issue, so I really need your help
>please
>>Best regards?Bilel?
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed Apr 15 19:26:09 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 15 Apr 2015 09:26:09 -0800
Subject: [R] adding a bravais pearson test to spplot
In-Reply-To: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <575577485CE.00000112jrkrideau@inbox.com>

I think we need basic code and sample data to see what you are doing. 
Have a look at http://adv-r.had.co.nz/Reproducibility.html and/or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example  for some hints. For this last link it is a good idea to follow the " reproducible example  " link for more concrete suggestions.

As Jeff has pointed out, this is not likely to be the best place to post.  A more specialized group as he suggested is more likely to be able to help.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bilelfathalli at yahoo.fr
> Sent: Wed, 15 Apr 2015 10:15:46 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] adding a bravais pearson test to spplot
> 
> Dear all,
> My name is Bilel and I'am a PhD student from Tunisia working on climate
> modelling. My issue today is how to add a Bravais Pearson test as a
> contour plot to an existing spplot map. Precisely, I have plotted a
> SpatialPixelsDataFrame of Pearson correlation coefficients between
> simulated and observed precipitation over the Mediterranean basin using
> spplot and I need to now add a contour line of the statically significant
> correlation coefficient at 95% CI.I have been vainly trying for several
> days to solve this issue, so I really need your help please
> Best regards?Bilel
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From macqueen1 at llnl.gov  Wed Apr 15 20:58:24 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 15 Apr 2015 18:58:24 +0000
Subject: [R] adding a bravais  pearson test to spplot
In-Reply-To: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>
References: <582911725.3904716.1429092946118.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D154014E.12560D%macqueen1@llnl.gov>

I also suggest you take this question to R-Sig-geo.

Since spplot() is built on the lattice package, adding new elements to an
existing plot is, in my experience, difficult to learn how to do. If you
can possibly start with plot() instead of spplot() you will, I think, find
it much easier to add contour lines.

It will all depend on what kind of objects your data are.

Here is an example that might help, or at least give you a few more things
to look at.

> library(sp)
> library(maptools)
Checking rgeos availability: TRUE
> data(meuse.grid)
> coordinates(meuse.grid) <- c('x','y')
> meuse.grid <- as(meuse.grid, 'SpatialPixelsDataFrame')
> im <- as.image.SpatialGridDataFrame(meuse.grid['dist'])
> cl <- ContourLines2SLDF(contourLines(im))
> spplot(cl)



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/15/15, 3:15 AM, "fathalli bilel" <bilelfathalli at yahoo.fr> wrote:

>Dear all,
>My name is Bilel and I'am a PhD student from Tunisia working on climate
>modelling. My issue today is how to add a Bravais Pearson test as a
>contour plot to an existing spplot map. Precisely, I have plotted a
>SpatialPixelsDataFrame of Pearson correlation coefficients between
>simulated and observed precipitation over the Mediterranean basin using
>spplot and I need to now add a contour line of the statically significant
>correlation coefficient at 95% CI.I have been vainly trying for several
>days to solve this issue, so I really need your help please
>Best regards Bilel
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bilelfathalli at yahoo.fr  Wed Apr 15 17:04:20 2015
From: bilelfathalli at yahoo.fr (fathalli bilel)
Date: Wed, 15 Apr 2015 15:04:20 +0000 (UTC)
Subject: [R] adding a bravais  pearson test to spplot
In-Reply-To: <6CC95048-5EFF-47C4-AA93-02281D403844@dcn.davis.CA.us>
References: <6CC95048-5EFF-47C4-AA93-02281D403844@dcn.davis.CA.us>
Message-ID: <1170215877.4221321.1429110260307.JavaMail.yahoo@mail.yahoo.com>

Hi,First : thanks for your answerThis is my first post on the R-help forum and I'm not familiar with the way how to should post.?I am not searching for "an example from scratch" as you said, I am able to build my own codes so I'm only looking for tips ?: packages, functions that can help my issue?(help that does not mean a "code" ready for use")I'm very polite and I'am shocked by the way your give your answer
Bilel ?


     Le Mercredi 15 avril 2015 15h40, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> a ?crit :
   

 Well, creating an example from scratch to show you how it is done can be a lot of work, and depending on your specific data such code can end up being wasted work. For this reason the polite thing to do is to provide a minimal reproducible example that list readers can use to start from. [1]

Also, you should read the Posting Guide, which warns you that the R mailing lists are plain text only, so if you post HTML as you did then at best we don't see what you see and at worst it is corrupted. The Guide also mentions that there are different lists with different topics, and the topic of your question is probably best addressed on the R-sig-geo mailing list. It looks nontrivial to me, but there might be a canned solution out there.
---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.


rote:
>Dear all,
>My name is Bilel and I'am a PhD student from Tunisia working on climate
>modelling. My issue today is how to add a Bravais Pearson test as a
>contour plot to an existing spplot map. Precisely, I have plotted a
>SpatialPixelsDataFrame of Pearson correlation coefficients between
>simulated and observed precipitation over the Mediterranean basin using
>spplot and I need to now add a contour line of the statically
>significant correlation coefficient at 95% CI.I have been vainly trying
>for several days to solve this issue, so I really need your help please
>Best regards?Bilel?
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From arunikarunarathne at gmail.com  Wed Apr 15 19:47:53 2015
From: arunikarunarathne at gmail.com (aruni karunarathne)
Date: Wed, 15 Apr 2015 23:17:53 +0530
Subject: [R] REngine hangs when called within java code
Message-ID: <CAMVs1ir+4--nX5ux2-L_=jXi+s1ajcDufVCfiFeqTYGgXd1Ecg@mail.gmail.com>

Dear All,

I'm creating a project which uses both java and R.

I created the java class named MyClass and within that wrote two
separate methods (graphing1() and fitness()) to call the r scripts.

public void graphing1() throws IOException {

    String newargs1[] = {"--no-save"};

    Rengine r1 = new Rengine(newargs1, false, null);

    r1.eval("source('test2.R')");

    r1.end();

}



public void fitness() throws IOException {

    String newargs1[] = {"--no-save"};

    Rengine r3 = new Rengine(newargs1, false, null);

    r3.eval("source('A.R')");

    r3.eval("source('B.R')");

    r3.end();

}

Both of the above methods are in java class MyClass.

>From another class in the same project for which I created a gui, I
accessed the fitness() function and it worked fine. But when I try to
call the graphing1() function it did not work. (both were called
through the gui) The programme hangs at ;

Rengine r1 = new Rengine(newargs1, false, null);

without any notification. In both instances I called the function as follows:

1st instance:

MyClass test=new MyClass();

    test.fitness() ;

2nd instance:

MyClass test1 = new MyClass();

        test1.graphing1();



All the 3 scripts are coded to create png files. test2.R and A.R
scripts use the ROCR library and B.R do not use any. All the 3 files
end with dev.off() statement.

I have installed R 3.1.3. I?m using netbeans as the editor and working
in windows environment.

The 3 scripts work fine when executed in R environment. The issue
arises when it?s called from the java code.

I'm a student who is new to R and was struggling to solve this issue
for several weeks. Your help is greatly appreciated.

Thanks in advance.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: REngine hangs when called within java code -- problem.pdf
Type: application/pdf
Size: 48699 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150415/bfed9259/attachment.pdf>

From hnorpois at gmail.com  Wed Apr 15 21:47:11 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Wed, 15 Apr 2015 21:47:11 +0200
Subject: [R] scan - open text file as list
In-Reply-To: <CAF8bMcaTu_eTxhM+hoktHD6couMqfo02kcBePKfEwdU8fJUfMQ@mail.gmail.com>
References: <CAKyZeBuwXtKKX73RuYwGzsJv=0adkxm7EdyyYgU6RPoizGWayA@mail.gmail.com>
	<CAF8bMcaTu_eTxhM+hoktHD6couMqfo02kcBePKfEwdU8fJUfMQ@mail.gmail.com>
Message-ID: <CAKyZeBuQEvRmgJ+3t-TSPzrOT8qe1SSrLBTq-xNPrF199VZfgg@mail.gmail.com>

Thanks.
Actually, I thought there was a way to do it with scan only ...


2015-04-15 16:40 GMT+02:00 William Dunlap <wdunlap at tibco.com>:

> > strsplit(x=sub(pattern="^\\* ", replacement="", x=test), split=" ")
> [[1]]
> [1] "a" "b" "d"
>
> [[2]]
> [1] "z"  "u"  "i"  "h"  "hh"
>
> [[3]]
> [1] "h"  "bh" "kk"
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 14, 2015 at 2:34 PM, Hermann Norpois <hnorpois at gmail.com>
> wrote:
>
>> Hello,
>>
>> I try to open a text file test.txt with the content
>>
>> * a b d
>> * z u i h hh
>> * h bh kk
>>
>> so that I get a list with each line as a vector with the letters as
>> elements of the the vector.
>>
>> My approach ...
>> test <- scan ("test.txt", what="character", sep="\n")
>> Read 3 items
>> > test.list <- lapply (test, function (x) {a <- unlist (strsplit(x," "));
>> a
>> <- a[-1]})
>> > test.list
>> [[1]]
>> [1] "a" "b" "d"
>>
>> [[2]]
>> [1] "z"  "u"  "i"  "h"  "hh"
>>
>> [[3]]
>> [1] "h"  "bh" "kk"
>>
>> ... the result is okay but I dont think it is an elegant solution. One
>> comment: I dont know how many lines my "real" test.txt will have.
>> Thanks Hermann
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Apr 16 04:20:04 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 15 Apr 2015 22:20:04 -0400
Subject: [R] Question with uniroot function
Message-ID: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>

Hi all,
   In the following code, I am trying to use uniroot function to solve for
the root (a and b in code below) for function f1.
I am not sure why uniroot function does not give the answer since when we
look the graph, the function does cross 0 twice.
Any suggestion?
   Thanks.
       Hanna

u1 <- -3
u2 <- 4
pi0 <- 0.8

f1 <- function(lambda,z,p1){
lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}

a <- uniroot(f1, lower =-10, upper = 0,
           tol = 1e-20,p1=0.15,lambda=0.998)$root

b <- uniroot(f1, lower =0, upper = 10,
           tol = 1e-20,p1=0.15,lambda=0.998)$root

x <- seq(-20,20, by=0.1)
y <- numeric(length(x))
for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
plot(y ~ x, ylim=c(-1,1))
abline(h=0)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Apr 16 04:57:33 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Apr 2015 19:57:33 -0700
Subject: [R] Question with uniroot function
In-Reply-To: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>
References: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>
Message-ID: <D805D2AC-BE55-4F6A-AD71-81E1642801C1@dcn.davis.CA.us>

You really need to read the help page for uniroot. The sign needs to be different at the ends of the starting interval. This is a typical limitation of numerical root finders.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 15, 2015 7:20:04 PM PDT, li li <hannah.hlx at gmail.com> wrote:
>Hi all,
>In the following code, I am trying to use uniroot function to solve for
>the root (a and b in code below) for function f1.
>I am not sure why uniroot function does not give the answer since when
>we
>look the graph, the function does cross 0 twice.
>Any suggestion?
>   Thanks.
>       Hanna
>
>u1 <- -3
>u2 <- 4
>pi0 <- 0.8
>
>f1 <- function(lambda,z,p1){
>lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
>
>a <- uniroot(f1, lower =-10, upper = 0,
>           tol = 1e-20,p1=0.15,lambda=0.998)$root
>
>b <- uniroot(f1, lower =0, upper = 10,
>           tol = 1e-20,p1=0.15,lambda=0.998)$root
>
>x <- seq(-20,20, by=0.1)
>y <- numeric(length(x))
>for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
>plot(y ~ x, ylim=c(-1,1))
>abline(h=0)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pionescu at student.unimelb.edu.au  Thu Apr 16 00:17:30 2015
From: pionescu at student.unimelb.edu.au (merm)
Date: Wed, 15 Apr 2015 15:17:30 -0700 (PDT)
Subject: [R] assign variables to function output
Message-ID: <1429136250774-4705920.post@n4.nabble.com>

Hi!

So I'm trying as the header suggests to assign the value(s) output by a
function to a variable, say 'y'

Problem is from what I gather any variables introduced within the function
are contained and the only output I can get is "return(value)" which is
awkward to work with. Any suggestions?

Cheers!



--
View this message in context: http://r.789695.n4.nabble.com/assign-variables-to-function-output-tp4705920.html
Sent from the R help mailing list archive at Nabble.com.


From paul.domaskis at gmail.com  Thu Apr 16 06:23:53 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 04:23:53 +0000
Subject: [R] "R" help leaves out lines of text
Message-ID: <loom.20150416T062323-599@post.gmane.org>

I am ramping up on the R statistical analysis environment.  I find
that the help leaves out entire lines of text.  The pager is
/usr/lib/R/bin/pager.  I changed it to /bin/less, but I see the same
symptom.  The problem shows up both in xterm and mintty.  The computer
is in a locked down environment, so a straight update of cygwin
packages is not an option.  

Is there anything further I can try to circumvent the problem?

My version info is:

   64-bit Cygwin DLL version 1.7.28
   R version 3.0.1-1


From sergio.fonda99 at gmail.com  Thu Apr 16 11:21:04 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Thu, 16 Apr 2015 11:21:04 +0200
Subject: [R] assign variables to function output
In-Reply-To: <1429136250774-4705920.post@n4.nabble.com>
References: <1429136250774-4705920.post@n4.nabble.com>
Message-ID: <CAJRuHop3aS6_Hc26DCFDsiLX2-nFsW1fSbEE_8K_uAfxbU+BHA@mail.gmail.com>

Collect in a vector or dataframe or list the variables of interest and
output it.
Il 16/apr/2015 10:57, "merm" <pionescu at student.unimelb.edu.au> ha scritto:

> Hi!
>
> So I'm trying as the header suggests to assign the value(s) output by a
> function to a variable, say 'y'
>
> Problem is from what I gather any variables introduced within the function
> are contained and the only output I can get is "return(value)" which is
> awkward to work with. Any suggestions?
>
> Cheers!
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/assign-variables-to-function-output-tp4705920.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Joachim.Audenaert at pcsierteelt.be  Thu Apr 16 11:36:38 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Thu, 16 Apr 2015 11:36:38 +0200
Subject: [R]  melt function chooses wrong id variable with large datasets
Message-ID: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>

Hello all,

I'm using a large dataset consisting of 2 groups of data, 2 columns in 
excel with a header (group name) and 15 000 rows of data. I would like 
like to compare this data, so I transform my dataset with the melt 
function to get 1 column of data and 1 column of ID variables, then I can 
apply different statistical tests. With small datasets this works great, 
the melt function automatically chooses the name in row 1 as ID variable 
and melts the data, thus giving me a matrix with all ID variables in 
column one and the data accordingly in column 2. 
With this big dataset however it chooses the whole first column as ID 
variables in stead of the first row. Is there a reason why this happens 
and how can I make sure the first row is chosen as ID variabele and the 
lower rows as data? 

If I specify that I want the first row to be the id variable I also get 
error. 

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

Error: id variables not found in data: norm, jaar

Are there alternative ways to create a good reshaped dataset?

Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be   

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Apr 16 12:13:20 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Apr 2015 10:13:20 +0000
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>

Hi

There is something weird with your data and melt function.

AFAIK melt does not use first row as id.variables.

What is result of

str(dataset)

Instead of

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

melt expects something like

melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)

If you want more specific answer you shall show us part of your data, preferably copy output of

dput(dataset[1:20,])

into your mail.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 16, 2015 11:37 AM
> To: r-help at r-project.org
> Subject: [R] melt function chooses wrong id variable with large
> datasets
>
> Hello all,
>
> I'm using a large dataset consisting of 2 groups of data, 2 columns in
> excel with a header (group name) and 15 000 rows of data. I would like
> like to compare this data, so I transform my dataset with the melt
> function to get 1 column of data and 1 column of ID variables, then I
> can apply different statistical tests. With small datasets this works
> great, the melt function automatically chooses the name in row 1 as ID
> variable and melts the data, thus giving me a matrix with all ID
> variables in column one and the data accordingly in column 2.
> With this big dataset however it chooses the whole first column as ID
> variables in stead of the first row. Is there a reason why this happens
> and how can I make sure the first row is chosen as ID variabele and the
> lower rows as data?
>
> If I specify that I want the first row to be the id variable I also get
> error.
>
> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
> Error: id variables not found in data: norm, jaar
>
> Are there alternative ways to create a good reshaped dataset?
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
> Het PCS op LinkedIn Disclaimer | Please consider the environment before
> printing. Think green, keep it on the screen!
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Rainer at krugs.de  Thu Apr 16 12:19:25 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 16 Apr 2015 12:19:25 +0200
Subject: [R] "function" as variable name - probably better error message
Message-ID: <m23840gytu.fsf@krugs.de>

Hi

The following code works as expected:


list(plot="Not any more!")

,----
| > plot <- "Not any more!")
| [1] "Not any more!"
`----

But for this I get an error:

,----
| > function <- "Not any more!"
| Error: unexpected assignment in "function <-"
`----

The error message is quite cryptic and does not help much further. Would
it be possible to provide a more useful error message in this case that
(presumably) "function" is a reserved word?

Along the same lines - is there a list of reserved words which can not
be used in R as variable names (not even as elements in a a list())?

This is not a huge problem, but it cost me a few minutes of figuring
out.

Thanks,

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150416/a23c0afc/attachment.bin>

From pd.mes at cbs.dk  Thu Apr 16 11:29:41 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 16 Apr 2015 11:29:41 +0200
Subject: [R]  R 3.2.0 is released
Message-ID: <4EAB40EE-2C15-4886-A593-EF8D34E932EA@cbs.dk>

The build system rolled up R-3.2.0.tar.gz (codename "Full of Ingredients") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = a699fa0eeef280b78134f0abe0b1c1b0
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 99876f56fc07a7eb20825b85add9b66e
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 66fa17ad457d7e618191aa0f52fc402e
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = a59076c1ac7e9bab0f0a38b3f57a3914
MD5 (THANKS) = ba00f6cc68a823e1741cfa6011f40ccb
MD5 (R-3/R-3.2.0.tar.gz) = 66fa17ad457d7e618191aa0f52fc402e


This is the relevant part of the NEWS file

CHANGES IN 3.2.0:

 NEW FEATURES:

   * anyNA() gains a recursive argument.

   * When x is missing and names is not false (including the default
     value), Sys.getenv(x, names) returns an object of class "Dlist"
     and hence prints tidily.

   * (Windows.)  shell() no longer consults the environment variable
     SHELL: too many systems have been encountered where it was set
     incorrectly (usually to a path where software was compiled, not
     where it was installed).  R_SHELL, the preferred way to select a
     non-default shell, can be used instead.

   * Some unusual arguments to embedFonts() can now be specified as
     character vectors, and the defaults have been changed
     accordingly.

   * Functions in the Summary group duplicate less.  (PR#15798)

   * (Unix-alikes.) system(cmd, input = ) now uses
     'shell-execution-environment' redirection, which will be more
     natural if cmd is not a single command (but requires a
     POSIX-compliant shell). (Wish of PR#15508)

   * read.fwf() and read.DIF() gain a fileEncoding argument, for
     convenience.

   * Graphics devices can add attributes to their description in
     .Device and .Devices.  Several of those included with R use a
     "filepath" attribute.

   * pmatch() uses hashing in more cases and so is faster at the
     expense of using more memory. (PR#15697)

   * pairs() gains new arguments to select sets of variables to be
     plotted against each other.

   * file.info(, extra_cols = FALSE) allows a minimal set of columns
     to be computed on Unix-alikes: on some systems without
     properly-configured caching this can be significantly faster with
     large file lists.

   * New function dir.exists() in package base to test efficiently
     whether one or more paths exist and are directories.

   * dput() and friends gain new controls hexNumeric and digits17
     which output double and complex quantities as, respectively,
     binary fractions (exactly, see sprintf("%a")) and as decimals
     with up to 17 significant digits.

   * save(), saveRDS() and serialize() now support ascii = NA which
     writes ASCII files using sprintf("%a") for double/complex
     quantities.  This is read-compatible with ascii = TRUE but avoids
     binary->decimal->binary conversions with potential loss of
     precision.  Unfortunately the Windows C runtime's lack of C99
     compliance means that the format cannot be read correctly there
     in R before 3.1.2.

   * The default for formatC(decimal.mark =) has been changed to be
     getOption("OutDec"); this makes it more consistent with format()
     and suitable for use in print methods, e.g. those for classes
     "density", "ecdf", "stepfun" and "summary.lm".

     getOption("OutDec") is now consulted by the print method for
     class "kmeans", by cut(), dendrogram(), plot.ts() and quantile()
     when constructing labels and for the report from legend(trace =
     TRUE).

     (In part, wish of PR#15819.)

   * printNum() and hence format() and formatC() give a warning if
     big.mark and decimal.mark are set to the same value (period and
     comma are not uncommonly used for each, and this is a check that
     conventions have not got mixed).

   * merge() can create a result which uses long vectors on 64-bit
     platforms.

   * dget() gains a new argument keep.source which defaults to FALSE
     for speed (dput() and dget() are most often used for data objects
     where this can make dget() many times faster).

   * Packages may now use a file of common macro definitions in their
     help files, and may import definitions from other packages.

   * A number of macros have been added in the new share/Rd directory
     for use in package overview help pages, and promptPackage() now
     makes use of them.

   * tools::parse_Rd() gains a new permissive argument which converts
     unrecognized macros into text.  This is used by
     utils:::format.bibentry to allow LaTeX markup to be ignored.

   * options(OutDec =) can now specify a multi-byte character, e.g.,
     options(OutDec = "\u00b7") in a UTF-8 locale.

   * is.recursive(x) is no longer true when x is an external pointer,
     a weak reference or byte code; the first enables all.equal(x, x)
     when x <- getClass(.).

   * ls() (aka objects()) and as.list.environment() gain a new
     argument sorted.

   * The "source" attribute (which has not been added to functions by
     R since before R version 2.14.0) is no longer treated as special.

   * Function returnValue() has been added to give on.exit() code
     access to a function's return value for debugging purposes.

   * crossprod(x, y) allows more matrix coercions when x or y are
     vectors, now equalling t(x) %*% y in these cases (also reported
     by Radford Neal).  Similarly, tcrossprod(x,y) and %*% work in
     more cases with vector arguments.

   * Utility function dynGet() useful for detecting cycles, aka
     infinite recursions.

   * The byte-code compiler and interpreter include new instructions
     that allow many scalar subsetting and assignment and scalar
     arithmetic operations to be handled more efficiently. This can
     result in significant performance improvements in scalar
     numerical code.

   * apply(m, 2, identity) is now the same as the matrix m when it has
     _named_ row names.

   * A new function debuggingState() has been added, allowing to
     temporarily turn off debugging.

   * example() gets a new optional argument run.donttest and
     tools::Rd2ex() a corresponding commentDonttest, with a default
     such that example(..) in help examples will run \donttest code
     only if used interactively (a change in behaviour).

   * rbind.data.frame() gains an optional argument make.row.names, for
     potential speedup.

   * New function extSoftVersion() to report on the versions of
     third-party software in use in this session.  Currently reports
     versions of zlib, bzlib, the liblzma from xz, PCRE, ICU, TRE and
     the iconv implementation.

     A similar function grSoftVersion() in package grDevices reports
     on third-party graphics software.

     Function tcltk::tclVersion() reports the Tcl/Tk version.

   * Calling callGeneric() without arguments now works with primitive
     generics to some extent.

   * vapply(x, FUN, FUN.VALUE) is more efficient notably for large
     length(FUN.VALUE); as extension of PR#16061.

   * as.table() now allows tables with one or more dimensions of
     length 0 (such as as.table(integer())).

   * names(x) <- NULL now clears the names of call and ... objects.

   * library() will report a warning when an insufficient dependency
     version is masking a sufficient one later on the library search
     path.

   * A new plot() method for class "raster" has been added.

   * New check_packages_in_dir_changes() function in package tools for
     conveniently analyzing how changing sources impacts the check
     results of their reverse dependencies.

   * Speed-up from Peter Haverty for ls() and
     methods:::.requirePackage() speeding up package loading.
     (PR#16133)

   * New get0() function, combining exists() and get() in one call,
     for efficiency.

   * match.call() gains an envir argument for specifying the
     environment from which to retrieve the ... in the call, if any;
     this environment was wrong (or at least undesirable) when the
     definition argument was a function.

   * topenv() has been made .Internal() for speedup, based on Peter
     Haverty's proposal in PR#16140.

   * getOption() no longer calls options() in the main case.

   * Optional use of libcurl (version 7.28.0 from Oct 2012 or later)
     for Internet access:

       * capabilities("libcurl") reports if this is available.

       * libcurlVersion() reports the version in use, and other
         details of the "libcurl" build including which URL schemes it
         supports.

       * curlGetHeaders() retrieves the headers for http://, https://,
         ftp:// and ftps:// URLs: analysis of these headers can
         provide insights into the `existence' of a URL (it might for
         example be permanently redirected) and is so used in R CMD
         check --as-cran.

       * download.file() has a new optional method "libcurl" which
         will handle more URL schemes, follow redirections, and allows
         simultaneous downloads of multiple URLs.

       * url() has a new method "libcurl" which handles more URL
         schemes and follows redirections.  The default method is
         controlled by a new option url.method, which applies also to
         the opening of URLs _via_ file() (which happens implicitly in
         functions such as read.table.)

       * When file() or url() is invoked with a https:// or ftps://
         URL which the current method cannot handle, it switches to a
         suitable method if one is available.

   * (Windows.) The DLLs internet.dll and internet2.dll have been
     merged.  In this version it is safe to switch (repeatedly)
     between the internal and Windows internet functions within an R
     session.

     The Windows internet functions are still selected by flag
     --internet2 or setInternet2().  This can be overridden for an
     url() connection _via_ its new method argument.

     download.file() has new method "wininet", selected as the default
     by --internet2 or setInternet2().

   * parent.env<- can no longer modify the parent of a locked
     namespace or namespace imports environment.  Contributed by Karl
     Millar.

   * New function isLoadedNamespace() for readability and speed.

   * names(env) now returns all the object names of an environment
     env, equivalently to ls(env, all.names = TRUE, sorted = FALSE)
     and also to the names of the corresponding list,
     names(as.list(env, all.names = TRUE)).  Note that although
     names() returns a character vector, the names have no particular
     ordering.

   * The memory manager now grows the heap more aggressively. This
     reduces the number of garbage collections, in particular while
     data or code are loaded, at the expense of slightly increasing
     the memory footprint.

   * New function trimws() for removing leading/trailing whitespace.

   * cbind() and rbind() now consider S4 inheritance during S3
     dispatch and also obey deparse.level.

   * cbind() and rbind() will delegate recursively to methods::cbind2
     (methods::rbind2) when at least one argument is an S4 object and
     S3 dispatch fails (due to ambiguity).

   * (Windows.)  download.file(quiet = FALSE) now uses text rather
     than Windows progress bars in non-interactive use.

   * New function hsearch_db() in package utils for building and
     retrieving the help search database used by help.search(), along
     with functions for inspecting the concepts and keywords in the
     help search database.

   * New function .getNamespaceInfo(), a no-check version of
     getNamespaceInfo() mostly for internal speedups.

   * The help search system now takes \keyword entries in Rd files
     which are not standard keywords (as given in KEYWORDS in the R
     documentation directory) as concepts.  For standard keyword
     entries the corresponding descriptions are additionally taken as
     concepts.

   * New lengths() function for getting the lengths of all elements in
     a list.

   * New function toTitleCase() in package tools, tailored to package
     titles.

   * The matrix methods of cbind() and rbind() allow matrices as
     inputs which have 2^31 or more elements.  (For cbind(), wish of
     PR#16198.)

   * The default method of image() has an explicit check for a numeric
     or logical matrix (which was always required).

   * URLencode() will not by default encode further URLs which appear
     to be already encoded.

   * BIC(mod) and BIC(mod, mod2) now give non-NA numbers for arima()
     fitted models, as nobs(mod) now gives the number of "used"
     observations for such models.  This fixes PR#16198, quite
     differently than proposed there.

   * The print() methods for "htest", "pairwise.htest" and
     "power.htest" objects now have a digits argument defaulting to (a
     function of) getOption("digits"), and influencing all printed
     numbers coherently.  Unavoidably, this changes the display of
     such test results in some cases.

   * Code completion for namespaces now recognizes all loaded
     namespaces, rather than only the ones that are also attached.

   * The code completion mechanism can now be replaced by a
     user-specified completer function, for (temporary) situations
     where the usual code completion is inappropriate.

   * unzip() will now warn if it is able to detect truncation when
     unpacking a file of 4GB or more (related to PR#16243).

   * methods() reports S4 in addition to S3 methods; output is
     simplified when the class argument is used.  .S3methods() and
     methods::.S4methods() report S3 and S4 methods separately.

   * Higher order functions such as the apply functions and Reduce()
     now force arguments to the functions they apply in order to
     eliminate undesirable interactions between lazy evaluation and
     variable capture in closures.  This resolves PR#16093.

 INSTALLATION and INCLUDED SOFTWARE:

   * The \donttest sections of R's help files can be tested by
     make check TEST_DONTTEST=TRUE .

   * It is possible to request the use of system valgrind headers
     _via_ configure option --with-system-valgrind-headers: note the
     possible future incompatibility of such headers discussed in the
     'R Installation and Administration' manual. (Wish of PR#16068.)

   * The included version of liblzma has been updated to xz-utils
     5.0.7 (minor bug fixes from 5.0.5).

   * configure options --with-system-zlib, --with-system-bzlib and
     --with-system-pcre are now the default.  For the time being there
     is fallback to the versions included in the R sources if no
     system versions are found or (unlikely) if they are too old.

     Linux users should check that the -devel or -dev versions of
     packages zlib, bzip2/libbz2 and pcre as well as
     xz-devel/liblzma-dev (or similar names) are installed.

   * configure by default looks for the texi2any script from texinfo
     5.1 or later, rather than the makeinfo program.  (makeinfo is a
     link to the Perl script texi2any in texinfo 5.x.)

   * R CMD INSTALL gains an option --built-timestamp=STAMP allowing
     100% reproducible package building, thanks to Dirk Eddelbuettel.

 UTILITIES:

   * There is support for testing the \dontrun and \donttest parts of
     examples in packages.

     tools::testInstalledPackage() accepts new arguments
     commentDontrun = FALSE and commentDonttest = FALSE.

     R CMD check gains options --run-dontrun and --run-donttest.

   * The HTML generated by tools::Rd2HTML() and tools::toHTML()
     methods is now 'XHTML 1.0 Strict'.

   * The compiler package's utility function setCompilerOptions() now
     returns the old values invisibly. The initial optimization level
     can also be set with the environment variable
     R_COMPILER_OPTIMIZE.

   * R CMD build adds a NeedsCompilation field if one is not already
     present in the DESCRIPTION file.

   * R CMD check gains option --test-dir to specify an alternative set
     of tests to run.

   * R CMD check will now by default continue with testing after many
     types of errors, and will output a summary count of errors at the
     end if any have occurred.

   * R CMD check now checks that the Title and Description fields are
     correctly terminated.

   * R CMD check --as-cran now:

       * checks a README.md file can be processed: this needs pandoc
         installed.

       * checks the existence and accessibility of URLs in the
         DESCRIPTION, CITATION, NEWS.Rd and README.md files and in the
         help files (provided the build has libcurl support).

       * reports non-ASCII characters in R source files when there is
         no package encoding declared in the DESCRIPTION file.

       * reports (apparent) S3 methods exported but not registered.

       * reports overwriting registered S3 methods from
         base/recommended packages.  (Such methods are replaced in the
         affected package for the rest of the session, even if the
         replacing namespace is unloaded.)

       * reports if the Title field does not appear to be in title
         case (see 'Writing R Extensions': there may be false
         positives, but note that technical words should be
         single-quoted and will then be accepted).

     Most of these checks can also be selected by environment
     variables: see the 'R Internals' manual.

 C-LEVEL FACILITIES:

   * New C API utility logspace_sum(logx[], n).

   * Entry points rbinom_mu, rnbinom_mu and rmultinom are remapped (by
     default) to Rf_rbinom_mu etc.  This requires packages using them
     to be re-installed.

   * .C(DUP = FALSE) and .Fortran(DUP = FALSE) are now ignored, so
     arguments are duplicated if DUP = TRUE would do so.  As their
     help has long said, .Call() is much preferred.

   * New entry point R_allocLD, like R_alloc but guaranteed to have
     sufficient alignment for long double pointers.

   * isPairList() now returns TRUE for DOTSXP.

 WINDOWS BUILD CHANGES:

 A number of changes to the Windows build system are in development.
 The following are currently in place.

   * Installation using external binary distributions of zlib, bzip2,
     liblzma, pcre, libpng, jpeglib and libtiff is now required, and
     the build instructions have been revised.

   * A new make target rsync-extsoft has been added to obtain copies
     of the external libraries from CRAN.

   * Building the manuals now requires texi2any from texinfo 5.1 or
     later.  CRAN binary builds include the manuals, but by default
     builds from source will not, and they will be accessed from CRAN.
     See the comments in src/gnuwin32/MkRules.dist for how to specify
     the location of texi2any.

   * (Windows) Changes have been made to support an experimental
     Windows toolchain based on GCC 4.9.2.  The default toolchain
     continues to be based on GCC 4.6.3, as the new toolchain is not
     yet stable enough.  A change to a new toolchain is expected
     during the R 3.2.x lifetime.

 PACKAGE INSTALLATION:

   * (Windows) The use of macro ZLIB_LIBS in file src/Makevars.win
     (which has not been documented for a long time) now requires an
     external libz.a to be available (it is part of the 'goodies' used
     to compile Windows binary packages).  It would be simpler to use
     -lz instead.

   * The default for option pkgType on platforms using binary packages
     is now "both", so source packages will be tried if binary
     versions are not available or not up to date.

     There are options for what install.packages(type = "both")
     (possibly called _via_ update.packages()) will do if compilation
     of a source package is desirable: see ?options (under utils).

     If you intend not to accept updates as source packages, you
     should use update.packages(type = "binary").

 DEPRECATED AND DEFUNCT:

   * download.file(method = "lynx") is defunct.

   * Building R using the included versions of zlib, bzip2, xz and
     PCRE is deprecated: these are frozen (bar essential bug-fixes)
     and will be removed for R 3.3.0.

   * The configure option --with-valgrind-instrumentation=3 has been
     withdrawn, as it did not work with recent valgrind headers: it is
     now treated as level 2.

   * The MethodsList class in package methods had been deprecated in R
     2.11.0 and is defunct now.  Functions using it are defunct if
     they had been deprecated in R 2.11.0, and are deprecated now,
     otherwise.

 BUG FIXES:

   * Fixed two obscure bugs in pairlist subassignment, reported by
     Radford Neal as part of pqR issue 16.

   * Fixes for bugs in handling empty arguments and argument matching
     by name in log().

   * all.equal() gains methods for environments and refClasses.

   * [<- and [[<- gain S4 data.frame methods to avoid corruption of S4
     class information by the S3 methods.

   * callNextMethod() should now work within a .local call when ... is
     absent from formals(.local).

   * dput(pairlist(x)) generates a call to the pairlist constructor
     instead of the list constructor.

   * Fix missing() when arguments are propagated through ... .
     (PR#15707)

   * eigen(m) now defaults to symmetric = TRUE even when the dimnames
     are asymmetric if the matrix is otherwise symmetric.  (PR#16151)

   * Fix issues with forwarding ... through callGeneric() and
     callNextMethod().  (PR#16141)

   * callGeneric() now works after a callNextMethod().

   * Subclass information is kept consistent when replacing an
     ordinary S4 class with an "old class" _via_ the S4Class argument
     to setOldClass(). Thus, for example, a data.frame is valid for a
     list argument in the signature, and a factor is valid for vector
     arguments.

   * In qbeta() the inversion of pbeta() is much more sophisticated.
     This works better in corner cases some of which failed completely
     previously (PR#15755), or were using too many iterations.

   * Auto-printing no longer duplicates objects when printing is
     dispatched to a method.

   * kmeans(x, k) would fail when nrow(x) >= 42949673.  (Comment 6 of
     PR#15364)

   * 'Abbreviated' locale-specific day and month names could have been
     truncated in those rare locales where there are the same as the
     full names.

   * An irrelevant warning message from updating subclass information
     was silenced (the namespace would not be writable in this case).

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From Joachim.Audenaert at pcsierteelt.be  Thu Apr 16 13:12:54 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Thu, 16 Apr 2015 13:12:54 +0200
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
Message-ID: <OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>

Hello,

This is a part of my dataset:

structure(list(januari = c(38.1, 32.4, 34.5, 20.7, 21.5, 23.1, 
29.7, 36.6, 36.1, 20.6, 20.4, 30.1, 38.7, 41.4, 37, 36, 37, 38, 
23, 26.7), februari = c(31.5, 36.2, 38.2, 26.4, 20.9, 21.5, 30.2, 
33.4, 32.6, 22.2, 21.7, 30, 35.7, 32.8, 39.3, 25.5, 23, 19.9, 
21.3, 20.8), maart = c(34.2, 27, 24.2, 19.9, 19.7, 21.5, 30.6, 
30, 19, 19.6, 20.6, 23.6, 17.9, 17.3, 21.4, 24.1, 20.9, 30.1, 
32.6, 21.3), april = c(26.3, 29.6, 30.3, 23.6, 28.4, 20.7, 24.1, 
27.3, 23.2, 18.3, 24.6, 27.4, 20.4, 18.1, 25.2, 19.8, 21, 23.7, 
19.6, 18.1), mei = c(23.7, 24, 17.2, 23.2, 25.2, 17.2, 16, 15.6, 
13.4, 16, 16.8, 14.6, 19.4, 21, 19.5, 18.5, 13.3, 13.7, 14.3, 
14.1), juni = c(17.7, 14.2, 16.6, 15.7, 13.7, 14.7, 13.1, 12.9, 
15.4, 11.9, 15.2, 15.3, 16.5, 16.1, 11.7, 11.2, 11.5, 10.8, 16.1, 
14.8), juli = c(15.7, 14.5, 10.8, 10.5, 13.4, 12.2, 13.2, 13, 
12.4, 13.1, 9.8, 10.5, 13.4, 11, 13.1, 15, 16.7, 16.1, 18.2, 
15.7), augustus = c(12.9, 12.8, 15.2, 14.5, 17.2, 14.5, 14.4, 
11, 13.1, 13.6, 14.6, 12.7, 13.6, 12.7, 15.5, 17.4, 15.2, 14.2, 
17.7, 19.2), september = c(15.6, 15.5, 15.9, 15.1, 16, 19.4, 
21.5, 23.7, 18.7, 23.8, 18, 16.2, 18.5, 20.6, 18.3, 22.5, 26.9, 
19.4, 15.9, 20.5), oktober = c(21.4, 20.8, 14, 17, 23, 26.4, 
19.6, 22.7, 26.9, 14.7, 15.2, 19.8, 26.9, 20.2, 14.3, 14.8, 18.5, 
21.7, 21.4, 21.8), november = c(24.7, 26.2, 29, 21.6, 17.1, 16.9, 
19.1, 24.7, 25.4, 19.8, 18.2, 16.3, 17, 17.7, 15.5, 14.7, 15.8, 
19.9, 20.4, 23.3), december = c(19.8, 27, 21, 33, 22.6, 28.3, 
21.1, 19, 17.3, 27, 30.2, 24.8, 17.9, 17.9, 20.7, 30.9, 36.2, 
21, 20.2, 21.3), norm = c("45.8713463281901", "24.047250681782984", 
"3.7533684144746324", "38.594241119279324", "26.391897460120358", 
"61.746470001194638", "6.8321020448487992", "11.933109250115226", 
"51.951891096493924", "37.424611852237945", "5.1587836676942374", 
"36.552835044409434", "31.781209673851027", "29.09146215582853", 
"4.856812959269508", "5.3982910143166514", "46.553976273304215", 
"17.566272518985429", "20.552451905814117", "61.894775704479279"
)), .Names = c("januari", "februari", "maart", "april", "mei", 
"juni", "juli", "augustus", "september", "oktober", "november", 
"december", "norm"), row.names = c(NA, 20L), class = "data.frame")

I transform my dataset with the following script:

y <- melt(dataset,na.rm=TRUE)
variable <- y[,1] 
value <- y[,2]

and can then perform a levene test as follows:

LEVENE <- leveneTest(value~variable,y)

When the dataset is small, lets say less than 100 values per column 
everything works great. I get the message: 

No id variables; using all as measure variables

When the dataset is much bigger I get the following message

Using norm as id variables, why does this function pick norm as id 
variable? and how can I tell R that each column title is my variable

 
Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:   PIKAL Petr <petr.pikal at precheza.cz>
To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>, 
"r-help at r-project.org" <r-help at r-project.org>
Date:   16/04/2015 12:13
Subject:        RE: [R]  melt function chooses wrong id variable with 
large datasets



Hi

There is something weird with your data and melt function.

AFAIK melt does not use first row as id.variables.

What is result of

str(dataset)

Instead of

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

melt expects something like

melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)

If you want more specific answer you shall show us part of your data, 
preferably copy output of

dput(dataset[1:20,])

into your mail.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 16, 2015 11:37 AM
> To: r-help at r-project.org
> Subject: [R] melt function chooses wrong id variable with large
> datasets
>
> Hello all,
>
> I'm using a large dataset consisting of 2 groups of data, 2 columns in
> excel with a header (group name) and 15 000 rows of data. I would like
> like to compare this data, so I transform my dataset with the melt
> function to get 1 column of data and 1 column of ID variables, then I
> can apply different statistical tests. With small datasets this works
> great, the melt function automatically chooses the name in row 1 as ID
> variable and melts the data, thus giving me a matrix with all ID
> variables in column one and the data accordingly in column 2.
> With this big dataset however it chooses the whole first column as ID
> variables in stead of the first row. Is there a reason why this happens
> and how can I make sure the first row is chosen as ID variabele and the
> lower rows as data?
>
> If I specify that I want the first row to be the id variable I also get
> error.
>
> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
> Error: id variables not found in data: norm, jaar
>
> Are there alternative ways to create a good reshaped dataset?
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
> Het PCS op LinkedIn Disclaimer | Please consider the environment before
> printing. Think green, keep it on the screen!
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green,
keep it on the screen!
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Apr 16 13:31:29 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Apr 2015 07:31:29 -0400
Subject: [R] "R" help leaves out lines of text
In-Reply-To: <loom.20150416T062323-599@post.gmane.org>
References: <loom.20150416T062323-599@post.gmane.org>
Message-ID: <552F9D91.5020609@gmail.com>

On 16/04/2015 12:23 AM, paul wrote:
> I am ramping up on the R statistical analysis environment.  I find
> that the help leaves out entire lines of text.  The pager is
> /usr/lib/R/bin/pager.  I changed it to /bin/less, but I see the same
> symptom.  The problem shows up both in xterm and mintty.  The computer
> is in a locked down environment, so a straight update of cygwin
> packages is not an option.  
> 
> Is there anything further I can try to circumvent the problem?
> 
> My version info is:
> 
>    64-bit Cygwin DLL version 1.7.28
>    R version 3.0.1-1
> 

The Cygwin release is not supported by us, and is known to be buggy,
because it doesn't handle line endings properly.

You'll need to talk to the Cygwin folks if you can't reproduce this in
one of our releases available from cran.r-project.org/bin/windows/base.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Apr 16 13:38:27 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Apr 2015 07:38:27 -0400
Subject: [R] "function" as variable name - probably better error message
In-Reply-To: <m23840gytu.fsf@krugs.de>
References: <m23840gytu.fsf@krugs.de>
Message-ID: <552F9F33.4090806@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 16/04/2015 6:19 AM, Rainer M Krug wrote:
> Hi
> 
> The following code works as expected:
> 
> 
> list(plot="Not any more!")
> 
> ,---- | > plot <- "Not any more!") | [1] "Not any more!" `----
> 
> But for this I get an error:
> 
> ,---- | > function <- "Not any more!" | Error: unexpected
> assignment in "function <-" `----
> 
> The error message is quite cryptic and does not help much further.
> Would it be possible to provide a more useful error message in this
> case that (presumably) "function" is a reserved word?
> 
> Along the same lines - is there a list of reserved words which can
> not be used in R as variable names (not even as elements in a a
> list())?

The R Language Definition lists the reserved words (see section
10.3.3).  It oversimplifies things, saying they can't be used as
variable names, when in fact almost any string can be used with proper
quoting.  For example, both of these work:

"function" <- "Not any more!"
`function` <- "Not any more!"

Duncan Murdoch

> 
> This is not a huge problem, but it cost me a few minutes of
> figuring out.
> 
> Thanks,
> 
> Rainer
> 
> 
> 
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and
> provide commented, minimal, self-contained, reproducible code.
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJVL58yAAoJEHE2Kz23YMZyyv0H/jKjwwkQ1v7jIRsZ9hxcJECU
HHHuAEusv+pgJTybdxn66XykCXQOgaLmGPGksK+CcJrBgLW2WgAh4C0CUpN36DPn
TOYpos9i3wZ8k0Idr8xiEeQ/PcD0pkMEwd6oYY0lL2Ikribu8maVKxcoYvjNIJOE
3E3qrrpZfH9U2a9ws9jxJk8O3n+OQ7x8GQqUNTQHthd5McHZ63F7uIEBH/tHT7Tn
x3gXAFbuSBJ6TtqaOZdPYFh3tV7CNyvJOso8yreSWK+0ZksXGKBtqElDJM0atrAj
bOwEAJe6gGrEPx92NUWkTWeILDa6v96WZzprwLDi+cwt7jItILFligaXlookbf0=
=vKWN
-----END PGP SIGNATURE-----


From petr.pikal at precheza.cz  Thu Apr 16 13:41:47 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Apr 2015 11:41:47 +0000
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
	<OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28BDC@SRVEXCHMBX.precheza.cz>

Hi

With this dataset I get

> dd.m0<-melt(dataset, na.rm=T)
Using norm as id variables
> head(dd.m0)
                norm variable value
1   45.8713463281901  januari  38.1
2 24.047250681782984  januari  32.4
3 3.7533684144746324  januari  34.5
4 38.594241119279324  januari  20.7
5 26.391897460120358  januari  21.5
6 61.746470001194638  januari  23.1
>
or

dd.m<-melt(dataset, id.vars=NULL, na.rm=T)

> head(dd.m)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m)
    variable              value
255     norm  4.856812959269508
256     norm 5.3982910143166514
257     norm 46.553976273304215
258     norm 17.566272518985429
259     norm 20.552451905814117
260     norm 61.894775704479279

The latter will put norm to the same column as months. Is it intended?

Maybe you want

> dd.m1<-melt(dataset[,-13], na.rm=T)
No id variables; using all as measure variables
> head(dd.m1)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m1)
    variable value
235 december  20.7
236 december  30.9
237 december  36.2
238 december  21.0
239 december  20.2
240 december  21.3

Cheers
Petr

From: Joachim Audenaert [mailto:Joachim.Audenaert at pcsierteelt.be]
Sent: Thursday, April 16, 2015 1:13 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: RE: [R] melt function chooses wrong id variable with large datasets

Hello,

This is a part of my dataset:

structure(list(januari = c(38.1, 32.4, 34.5, 20.7, 21.5, 23.1,
29.7, 36.6, 36.1, 20.6, 20.4, 30.1, 38.7, 41.4, 37, 36, 37, 38,
23, 26.7), februari = c(31.5, 36.2, 38.2, 26.4, 20.9, 21.5, 30.2,
33.4, 32.6, 22.2, 21.7, 30, 35.7, 32.8, 39.3, 25.5, 23, 19.9,
21.3, 20.8), maart = c(34.2, 27, 24.2, 19.9, 19.7, 21.5, 30.6,
30, 19, 19.6, 20.6, 23.6, 17.9, 17.3, 21.4, 24.1, 20.9, 30.1,
32.6, 21.3), april = c(26.3, 29.6, 30.3, 23.6, 28.4, 20.7, 24.1,
27.3, 23.2, 18.3, 24.6, 27.4, 20.4, 18.1, 25.2, 19.8, 21, 23.7,
19.6, 18.1), mei = c(23.7, 24, 17.2, 23.2, 25.2, 17.2, 16, 15.6,
13.4, 16, 16.8, 14.6, 19.4, 21, 19.5, 18.5, 13.3, 13.7, 14.3,
14.1), juni = c(17.7, 14.2, 16.6, 15.7, 13.7, 14.7, 13.1, 12.9,
15.4, 11.9, 15.2, 15.3, 16.5, 16.1, 11.7, 11.2, 11.5, 10.8, 16.1,
14.8), juli = c(15.7, 14.5, 10.8, 10.5, 13.4, 12.2, 13.2, 13,
12.4, 13.1, 9.8, 10.5, 13.4, 11, 13.1, 15, 16.7, 16.1, 18.2,
15.7), augustus = c(12.9, 12.8, 15.2, 14.5, 17.2, 14.5, 14.4,
11, 13.1, 13.6, 14.6, 12.7, 13.6, 12.7, 15.5, 17.4, 15.2, 14.2,
17.7, 19.2), september = c(15.6, 15.5, 15.9, 15.1, 16, 19.4,
21.5, 23.7, 18.7, 23.8, 18, 16.2, 18.5, 20.6, 18.3, 22.5, 26.9,
19.4, 15.9, 20.5), oktober = c(21.4, 20.8, 14, 17, 23, 26.4,
19.6, 22.7, 26.9, 14.7, 15.2, 19.8, 26.9, 20.2, 14.3, 14.8, 18.5,
21.7, 21.4, 21.8), november = c(24.7, 26.2, 29, 21.6, 17.1, 16.9,
19.1, 24.7, 25.4, 19.8, 18.2, 16.3, 17, 17.7, 15.5, 14.7, 15.8,
19.9, 20.4, 23.3), december = c(19.8, 27, 21, 33, 22.6, 28.3,
21.1, 19, 17.3, 27, 30.2, 24.8, 17.9, 17.9, 20.7, 30.9, 36.2,
21, 20.2, 21.3), norm = c("45.8713463281901", "24.047250681782984",
"3.7533684144746324", "38.594241119279324", "26.391897460120358",
"61.746470001194638", "6.8321020448487992", "11.933109250115226",
"51.951891096493924", "37.424611852237945", "5.1587836676942374",
"36.552835044409434", "31.781209673851027", "29.09146215582853",
"4.856812959269508", "5.3982910143166514", "46.553976273304215",
"17.566272518985429", "20.552451905814117", "61.894775704479279"
)), .Names = c("januari", "februari", "maart", "april", "mei",
"juni", "juli", "augustus", "september", "oktober", "november",
"december", "norm"), row.names = c(NA, 20L), class = "data.frame")

I transform my dataset with the following script:

y <- melt(dataset,na.rm=TRUE)
variable <- y[,1]
value <- y[,2]

and can then perform a levene test as follows:

LEVENE <- leveneTest(value~variable,y)

When the dataset is small, lets say less than 100 values per column everything works great. I get the message:

No id variables; using all as measure variables

When the dataset is much bigger I get the following message

Using norm as id variables, why does this function pick norm as id variable? and how can I tell R that each column title is my variable


Met vriendelijke groeten - With kind regards,

Joachim Audenaert
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research
________________________________

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be<mailto:joachim.audenaert at pcsierteelt.be> | W: www.pcsierteelt.be<http://www.pcsierteelt.be/>



From:        PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
To:        Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be<mailto:Joachim.Audenaert at pcsierteelt.be>>, "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Date:        16/04/2015 12:13
Subject:        RE: [R]  melt function chooses wrong id variable with large datasets
________________________________



Hi

There is something weird with your data and melt function.

AFAIK melt does not use first row as id.variables.

What is result of

str(dataset)

Instead of

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

melt expects something like

melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)

If you want more specific answer you shall show us part of your data, preferably copy output of

dput(dataset[1:20,])

into your mail.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 16, 2015 11:37 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] melt function chooses wrong id variable with large
> datasets
>
> Hello all,
>
> I'm using a large dataset consisting of 2 groups of data, 2 columns in
> excel with a header (group name) and 15 000 rows of data. I would like
> like to compare this data, so I transform my dataset with the melt
> function to get 1 column of data and 1 column of ID variables, then I
> can apply different statistical tests. With small datasets this works
> great, the melt function automatically chooses the name in row 1 as ID
> variable and melts the data, thus giving me a matrix with all ID
> variables in column one and the data accordingly in column 2.
> With this big dataset however it chooses the whole first column as ID
> variables in stead of the first row. Is there a reason why this happens
> and how can I make sure the first row is chosen as ID variabele and the
> lower rows as data?
>
> If I specify that I want the first row to be the id variable I also get
> error.
>
> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
> Error: id variables not found in data: norm, jaar
>
> Are there alternative ways to create a good reshaped dataset?
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be<mailto:joachim.audenaert at pcsierteelt.be> | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
> Het PCS op LinkedIn Disclaimer | Please consider the environment before
> printing. Think green, keep it on the screen!
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd?<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/32795D6E62E2F6A8C1257DCE002F4A44?opendocument> | Het PCS op LinkedIn<http://www.linkedin.com/company/proefcentrum-voor-sierteelt>
Disclaimer<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/EABE6EFE9E0C1C55C1257AD100322499> | Please consider the environment before printing. Think green, keep it on the screen!

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From Joachim.Audenaert at pcsierteelt.be  Thu Apr 16 13:59:47 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Thu, 16 Apr 2015 13:59:47 +0200
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28BDC@SRVEXCHMBX.precheza.cz>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
	<OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28BDC@SRVEXCHMBX.precheza.cz>
Message-ID: <OFDA62F7C3.F0D0FEC2-ONC1257E29.0041ABB6-C1257E29.0041E57B@pcsierteelt.be>

Thanks,

indeed norm should be in the same group as as the months. everything works 
fine when the number of data is quite small, but with big datasets (15 000 
values) things seem to go wrong and I can't explain why. It puts norm as 
an individual column in stead of in the group of months as it does when 
the dataset is small.

Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:   PIKAL Petr <petr.pikal at precheza.cz>
To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>
Cc:     "r-help at r-project.org" <r-help at r-project.org>
Date:   16/04/2015 13:41
Subject:        RE: [R]  melt function chooses wrong id variable with 
large datasets



Hi
 
With this dataset I get
 
> dd.m0<-melt(dataset, na.rm=T)
Using norm as id variables
> head(dd.m0)
                norm variable value
1   45.8713463281901  januari  38.1
2 24.047250681782984  januari  32.4
3 3.7533684144746324  januari  34.5
4 38.594241119279324  januari  20.7
5 26.391897460120358  januari  21.5
6 61.746470001194638  januari  23.1
> 
or
 
dd.m<-melt(dataset, id.vars=NULL, na.rm=T)
 
> head(dd.m)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m)
    variable              value
255     norm  4.856812959269508
256     norm 5.3982910143166514
257     norm 46.553976273304215
258     norm 17.566272518985429
259     norm 20.552451905814117
260     norm 61.894775704479279
 
The latter will put norm to the same column as months. Is it intended?
 
Maybe you want
 
> dd.m1<-melt(dataset[,-13], na.rm=T)
No id variables; using all as measure variables
> head(dd.m1)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m1)
    variable value
235 december  20.7
236 december  30.9
237 december  36.2
238 december  21.0
239 december  20.2
240 december  21.3
 
Cheers
Petr
 
From: Joachim Audenaert [mailto:Joachim.Audenaert at pcsierteelt.be] 
Sent: Thursday, April 16, 2015 1:13 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: RE: [R] melt function chooses wrong id variable with large 
datasets
 
Hello, 

This is a part of my dataset: 

structure(list(januari = c(38.1, 32.4, 34.5, 20.7, 21.5, 23.1, 
29.7, 36.6, 36.1, 20.6, 20.4, 30.1, 38.7, 41.4, 37, 36, 37, 38, 
23, 26.7), februari = c(31.5, 36.2, 38.2, 26.4, 20.9, 21.5, 30.2, 
33.4, 32.6, 22.2, 21.7, 30, 35.7, 32.8, 39.3, 25.5, 23, 19.9, 
21.3, 20.8), maart = c(34.2, 27, 24.2, 19.9, 19.7, 21.5, 30.6, 
30, 19, 19.6, 20.6, 23.6, 17.9, 17.3, 21.4, 24.1, 20.9, 30.1, 
32.6, 21.3), april = c(26.3, 29.6, 30.3, 23.6, 28.4, 20.7, 24.1, 
27.3, 23.2, 18.3, 24.6, 27.4, 20.4, 18.1, 25.2, 19.8, 21, 23.7, 
19.6, 18.1), mei = c(23.7, 24, 17.2, 23.2, 25.2, 17.2, 16, 15.6, 
13.4, 16, 16.8, 14.6, 19.4, 21, 19.5, 18.5, 13.3, 13.7, 14.3, 
14.1), juni = c(17.7, 14.2, 16.6, 15.7, 13.7, 14.7, 13.1, 12.9, 
15.4, 11.9, 15.2, 15.3, 16.5, 16.1, 11.7, 11.2, 11.5, 10.8, 16.1, 
14.8), juli = c(15.7, 14.5, 10.8, 10.5, 13.4, 12.2, 13.2, 13, 
12.4, 13.1, 9.8, 10.5, 13.4, 11, 13.1, 15, 16.7, 16.1, 18.2, 
15.7), augustus = c(12.9, 12.8, 15.2, 14.5, 17.2, 14.5, 14.4, 
11, 13.1, 13.6, 14.6, 12.7, 13.6, 12.7, 15.5, 17.4, 15.2, 14.2, 
17.7, 19.2), september = c(15.6, 15.5, 15.9, 15.1, 16, 19.4, 
21.5, 23.7, 18.7, 23.8, 18, 16.2, 18.5, 20.6, 18.3, 22.5, 26.9, 
19.4, 15.9, 20.5), oktober = c(21.4, 20.8, 14, 17, 23, 26.4, 
19.6, 22.7, 26.9, 14.7, 15.2, 19.8, 26.9, 20.2, 14.3, 14.8, 18.5, 
21.7, 21.4, 21.8), november = c(24.7, 26.2, 29, 21.6, 17.1, 16.9, 
19.1, 24.7, 25.4, 19.8, 18.2, 16.3, 17, 17.7, 15.5, 14.7, 15.8, 
19.9, 20.4, 23.3), december = c(19.8, 27, 21, 33, 22.6, 28.3, 
21.1, 19, 17.3, 27, 30.2, 24.8, 17.9, 17.9, 20.7, 30.9, 36.2, 
21, 20.2, 21.3), norm = c("45.8713463281901", "24.047250681782984", 
"3.7533684144746324", "38.594241119279324", "26.391897460120358", 
"61.746470001194638", "6.8321020448487992", "11.933109250115226", 
"51.951891096493924", "37.424611852237945", "5.1587836676942374", 
"36.552835044409434", "31.781209673851027", "29.09146215582853", 
"4.856812959269508", "5.3982910143166514", "46.553976273304215", 
"17.566272518985429", "20.552451905814117", "61.894775704479279"
)), .Names = c("januari", "februari", "maart", "april", "mei", 
"juni", "juli", "augustus", "september", "oktober", "november", 
"december", "norm"), row.names = c(NA, 20L), class = "data.frame") 

I transform my dataset with the following script: 

y <- melt(dataset,na.rm=TRUE) 
variable <- y[,1] 
value <- y[,2] 

and can then perform a levene test as follows: 

LEVENE <- leveneTest(value~variable,y) 

When the dataset is small, lets say less than 100 values per column 
everything works great. I get the message: 

No id variables; using all as measure variables 

When the dataset is much bigger I get the following message 

Using norm as id variables, why does this function pick norm as id 
variable? and how can I tell R that each column title is my variable 

  
Met vriendelijke groeten - With kind regards, 

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research 


Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:        PIKAL Petr <petr.pikal at precheza.cz> 
To:        Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>, "
r-help at r-project.org" <r-help at r-project.org> 
Date:        16/04/2015 12:13 
Subject:        RE: [R]  melt function chooses wrong id variable with 
large datasets 




Hi

There is something weird with your data and melt function.

AFAIK melt does not use first row as id.variables.

What is result of

str(dataset)

Instead of

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

melt expects something like

melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)

If you want more specific answer you shall show us part of your data, 
preferably copy output of

dput(dataset[1:20,])

into your mail.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 16, 2015 11:37 AM
> To: r-help at r-project.org
> Subject: [R] melt function chooses wrong id variable with large
> datasets
>
> Hello all,
>
> I'm using a large dataset consisting of 2 groups of data, 2 columns in
> excel with a header (group name) and 15 000 rows of data. I would like
> like to compare this data, so I transform my dataset with the melt
> function to get 1 column of data and 1 column of ID variables, then I
> can apply different statistical tests. With small datasets this works
> great, the melt function automatically chooses the name in row 1 as ID
> variable and melts the data, thus giving me a matrix with all ID
> variables in column one and the data accordingly in column 2.
> With this big dataset however it chooses the whole first column as ID
> variables in stead of the first row. Is there a reason why this happens
> and how can I make sure the first row is chosen as ID variabele and the
> lower rows as data?
>
> If I specify that I want the first row to be the id variable I also get
> error.
>
> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
> Error: id variables not found in data: norm, jaar
>
> Are there alternative ways to create a good reshaped dataset?
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
> Het PCS op LinkedIn Disclaimer | Please consider the environment before
> printing. Think green, keep it on the screen!
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green,
keep it on the screen!

Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green,
keep it on the screen!
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 16 14:12:31 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Apr 2015 22:12:31 +1000
Subject: [R] assign variables to function output
In-Reply-To: <CAJRuHop3aS6_Hc26DCFDsiLX2-nFsW1fSbEE_8K_uAfxbU+BHA@mail.gmail.com>
References: <1429136250774-4705920.post@n4.nabble.com>
	<CAJRuHop3aS6_Hc26DCFDsiLX2-nFsW1fSbEE_8K_uAfxbU+BHA@mail.gmail.com>
Message-ID: <CA+8X3fUDa4UYKPOM0nT30oxkYDjYQcBVQ6bL62-rQvapd38eyg@mail.gmail.com>

Hi merm,
In case Sergio's message is a little cryptic:

return_a_list<-function() {
 a<-"First item of list"
 b<-c(2,4,6,8)
 c<-matrix(1:9,nrow=3)
 return(list(a,b,c))
}

x<-return_a_list()
x

Jim

On Thu, Apr 16, 2015 at 7:21 PM, Sergio Fonda <sergio.fonda99 at gmail.com> wrote:
> Collect in a vector or dataframe or list the variables of interest and
> output it.
> Il 16/apr/2015 10:57, "merm" <pionescu at student.unimelb.edu.au> ha scritto:
>
>> Hi!
>>
>> So I'm trying as the header suggests to assign the value(s) output by a
>> function to a variable, say 'y'
>>
>> Problem is from what I gather any variables introduced within the function
>> are contained and the only output I can get is "return(value)" which is
>> awkward to work with. Any suggestions?
>>
>> Cheers!
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/assign-variables-to-function-output-tp4705920.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Apr 16 14:53:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 16 Apr 2015 05:53:14 -0700
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <OFDA62F7C3.F0D0FEC2-ONC1257E29.0041ABB6-C1257E29.0041E57B@pcsierteelt.be>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
	<OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28BDC@SRVEXCHMBX.precheza.cz>
	<OFDA62F7C3.F0D0FEC2-ONC1257E29.0041ABB6-C1257E29.0041E57B@pcsierteelt.be>
Message-ID: <7D13748E-5F34-49DF-B8A9-332ECF9A2461@dcn.davis.CA.us>

Maybe what you really want is the ?stack function.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 16, 2015 4:59:47 AM PDT, Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be> wrote:
>Thanks,
>
>indeed norm should be in the same group as as the months. everything
>works 
>fine when the number of data is quite small, but with big datasets (15
>000 
>values) things seem to go wrong and I can't explain why. It puts norm
>as 
>an individual column in stead of in the group of months as it does when
>
>the dataset is small.
>
>Met vriendelijke groeten - With kind regards,
>
>Joachim Audenaert 
>onderzoeker gewasbescherming - crop protection researcher
>
>PCS | proefcentrum voor sierteelt - ornamental plant research
>
>Schaessestraat 18, 9070 Destelbergen, Belgi?
>T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
>E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 
>
>
>
>From:   PIKAL Petr <petr.pikal at precheza.cz>
>To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>
>Cc:     "r-help at r-project.org" <r-help at r-project.org>
>Date:   16/04/2015 13:41
>Subject:        RE: [R]  melt function chooses wrong id variable with 
>large datasets
>
>
>
>Hi
> 
>With this dataset I get
> 
>> dd.m0<-melt(dataset, na.rm=T)
>Using norm as id variables
>> head(dd.m0)
>                norm variable value
>1   45.8713463281901  januari  38.1
>2 24.047250681782984  januari  32.4
>3 3.7533684144746324  januari  34.5
>4 38.594241119279324  januari  20.7
>5 26.391897460120358  januari  21.5
>6 61.746470001194638  januari  23.1
>> 
>or
> 
>dd.m<-melt(dataset, id.vars=NULL, na.rm=T)
> 
>> head(dd.m)
>  variable value
>1  januari  38.1
>2  januari  32.4
>3  januari  34.5
>4  januari  20.7
>5  januari  21.5
>6  januari  23.1
>> tail(dd.m)
>    variable              value
>255     norm  4.856812959269508
>256     norm 5.3982910143166514
>257     norm 46.553976273304215
>258     norm 17.566272518985429
>259     norm 20.552451905814117
>260     norm 61.894775704479279
> 
>The latter will put norm to the same column as months. Is it intended?
> 
>Maybe you want
> 
>> dd.m1<-melt(dataset[,-13], na.rm=T)
>No id variables; using all as measure variables
>> head(dd.m1)
>  variable value
>1  januari  38.1
>2  januari  32.4
>3  januari  34.5
>4  januari  20.7
>5  januari  21.5
>6  januari  23.1
>> tail(dd.m1)
>    variable value
>235 december  20.7
>236 december  30.9
>237 december  36.2
>238 december  21.0
>239 december  20.2
>240 december  21.3
> 
>Cheers
>Petr
> 
>From: Joachim Audenaert [mailto:Joachim.Audenaert at pcsierteelt.be] 
>Sent: Thursday, April 16, 2015 1:13 PM
>To: PIKAL Petr
>Cc: r-help at r-project.org
>Subject: RE: [R] melt function chooses wrong id variable with large 
>datasets
> 
>Hello, 
>
>This is a part of my dataset: 
>
>structure(list(januari = c(38.1, 32.4, 34.5, 20.7, 21.5, 23.1, 
>29.7, 36.6, 36.1, 20.6, 20.4, 30.1, 38.7, 41.4, 37, 36, 37, 38, 
>23, 26.7), februari = c(31.5, 36.2, 38.2, 26.4, 20.9, 21.5, 30.2, 
>33.4, 32.6, 22.2, 21.7, 30, 35.7, 32.8, 39.3, 25.5, 23, 19.9, 
>21.3, 20.8), maart = c(34.2, 27, 24.2, 19.9, 19.7, 21.5, 30.6, 
>30, 19, 19.6, 20.6, 23.6, 17.9, 17.3, 21.4, 24.1, 20.9, 30.1, 
>32.6, 21.3), april = c(26.3, 29.6, 30.3, 23.6, 28.4, 20.7, 24.1, 
>27.3, 23.2, 18.3, 24.6, 27.4, 20.4, 18.1, 25.2, 19.8, 21, 23.7, 
>19.6, 18.1), mei = c(23.7, 24, 17.2, 23.2, 25.2, 17.2, 16, 15.6, 
>13.4, 16, 16.8, 14.6, 19.4, 21, 19.5, 18.5, 13.3, 13.7, 14.3, 
>14.1), juni = c(17.7, 14.2, 16.6, 15.7, 13.7, 14.7, 13.1, 12.9, 
>15.4, 11.9, 15.2, 15.3, 16.5, 16.1, 11.7, 11.2, 11.5, 10.8, 16.1, 
>14.8), juli = c(15.7, 14.5, 10.8, 10.5, 13.4, 12.2, 13.2, 13, 
>12.4, 13.1, 9.8, 10.5, 13.4, 11, 13.1, 15, 16.7, 16.1, 18.2, 
>15.7), augustus = c(12.9, 12.8, 15.2, 14.5, 17.2, 14.5, 14.4, 
>11, 13.1, 13.6, 14.6, 12.7, 13.6, 12.7, 15.5, 17.4, 15.2, 14.2, 
>17.7, 19.2), september = c(15.6, 15.5, 15.9, 15.1, 16, 19.4, 
>21.5, 23.7, 18.7, 23.8, 18, 16.2, 18.5, 20.6, 18.3, 22.5, 26.9, 
>19.4, 15.9, 20.5), oktober = c(21.4, 20.8, 14, 17, 23, 26.4, 
>19.6, 22.7, 26.9, 14.7, 15.2, 19.8, 26.9, 20.2, 14.3, 14.8, 18.5, 
>21.7, 21.4, 21.8), november = c(24.7, 26.2, 29, 21.6, 17.1, 16.9, 
>19.1, 24.7, 25.4, 19.8, 18.2, 16.3, 17, 17.7, 15.5, 14.7, 15.8, 
>19.9, 20.4, 23.3), december = c(19.8, 27, 21, 33, 22.6, 28.3, 
>21.1, 19, 17.3, 27, 30.2, 24.8, 17.9, 17.9, 20.7, 30.9, 36.2, 
>21, 20.2, 21.3), norm = c("45.8713463281901", "24.047250681782984", 
>"3.7533684144746324", "38.594241119279324", "26.391897460120358", 
>"61.746470001194638", "6.8321020448487992", "11.933109250115226", 
>"51.951891096493924", "37.424611852237945", "5.1587836676942374", 
>"36.552835044409434", "31.781209673851027", "29.09146215582853", 
>"4.856812959269508", "5.3982910143166514", "46.553976273304215", 
>"17.566272518985429", "20.552451905814117", "61.894775704479279"
>)), .Names = c("januari", "februari", "maart", "april", "mei", 
>"juni", "juli", "augustus", "september", "oktober", "november", 
>"december", "norm"), row.names = c(NA, 20L), class = "data.frame") 
>
>I transform my dataset with the following script: 
>
>y <- melt(dataset,na.rm=TRUE) 
>variable <- y[,1] 
>value <- y[,2] 
>
>and can then perform a levene test as follows: 
>
>LEVENE <- leveneTest(value~variable,y) 
>
>When the dataset is small, lets say less than 100 values per column 
>everything works great. I get the message: 
>
>No id variables; using all as measure variables 
>
>When the dataset is much bigger I get the following message 
>
>Using norm as id variables, why does this function pick norm as id 
>variable? and how can I tell R that each column title is my variable 
>
>  
>Met vriendelijke groeten - With kind regards, 
>
>Joachim Audenaert 
>onderzoeker gewasbescherming - crop protection researcher
>
>PCS | proefcentrum voor sierteelt - ornamental plant research 
>
>
>Schaessestraat 18, 9070 Destelbergen, Belgi?
>T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
>E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 
>
>
>
>From:        PIKAL Petr <petr.pikal at precheza.cz> 
>To:        Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>, "
>r-help at r-project.org" <r-help at r-project.org> 
>Date:        16/04/2015 12:13 
>Subject:        RE: [R]  melt function chooses wrong id variable with 
>large datasets 
>
>
>
>
>Hi
>
>There is something weird with your data and melt function.
>
>AFAIK melt does not use first row as id.variables.
>
>What is result of
>
>str(dataset)
>
>Instead of
>
>melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
>melt expects something like
>
>melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)
>
>If you want more specific answer you shall show us part of your data, 
>preferably copy output of
>
>dput(dataset[1:20,])
>
>into your mail.
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Joachim
>> Audenaert
>> Sent: Thursday, April 16, 2015 11:37 AM
>> To: r-help at r-project.org
>> Subject: [R] melt function chooses wrong id variable with large
>> datasets
>>
>> Hello all,
>>
>> I'm using a large dataset consisting of 2 groups of data, 2 columns
>in
>> excel with a header (group name) and 15 000 rows of data. I would
>like
>> like to compare this data, so I transform my dataset with the melt
>> function to get 1 column of data and 1 column of ID variables, then I
>> can apply different statistical tests. With small datasets this works
>> great, the melt function automatically chooses the name in row 1 as
>ID
>> variable and melts the data, thus giving me a matrix with all ID
>> variables in column one and the data accordingly in column 2.
>> With this big dataset however it chooses the whole first column as ID
>> variables in stead of the first row. Is there a reason why this
>happens
>> and how can I make sure the first row is chosen as ID variabele and
>the
>> lower rows as data?
>>
>> If I specify that I want the first row to be the id variable I also
>get
>> error.
>>
>> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>>
>> Error: id variables not found in data: norm, jaar
>>
>> Are there alternative ways to create a good reshaped dataset?
>>
>> Met vriendelijke groeten - With kind regards,
>>
>> Joachim Audenaert
>> onderzoeker gewasbescherming - crop protection researcher
>>
>> PCS | proefcentrum voor sierteelt - ornamental plant research
>>
>> Schaessestraat 18, 9070 Destelbergen, Belgi
>> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
>> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>>
>> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
>> Het PCS op LinkedIn Disclaimer | Please consider the environment
>before
>> printing. Think green, keep it on the screen!
>>       [[alternative HTML version deleted]]
>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam?len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email 
>jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi 
>?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; 
>Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
>p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are 
>intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its 
>sender. Delete the contents of this e-mail with all attachments and its
>
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not 
>authorized to use, disseminate, copy or disclose this e-mail in any 
>manner.
>The sender of this e-mail shall not be liable for any possible damage 
>caused by modifications of the e-mail or by delay with transfer of the 
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a 
>contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to 
>immediately accept such offer; The sender of this e-mail (offer)
>excludes 
>any acceptance of the offer on the part of the recipient containing any
>
>amendment or variation.
>- the sender insists on that the respective contract is concluded only 
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter
>into any contracts on behalf of the company except for cases in which 
>he/she is expressly authorized to do so in writing, and such
>authorization
>or power of attorney is submitted to the recipient or the person 
>represented by the recipient, or the existence of such authorization is
>
>known to the recipient of the person represented by the recipient.
>
>
>
>Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
>Het 
>PCS op LinkedIn
>Disclaimer | Please consider the environment before printing. Think
>green,
>keep it on the screen!
>
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam?len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email 
>jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi 
>?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; 
>Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
>p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are 
>intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its 
>sender. Delete the contents of this e-mail with all attachments and its
>
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not 
>authorized to use, disseminate, copy or disclose this e-mail in any 
>manner.
>The sender of this e-mail shall not be liable for any possible damage 
>caused by modifications of the e-mail or by delay with transfer of the 
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a 
>contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to 
>immediately accept such offer; The sender of this e-mail (offer)
>excludes 
>any acceptance of the offer on the part of the recipient containing any
>
>amendment or variation.
>- the sender insists on that the respective contract is concluded only 
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter
>into any contracts on behalf of the company except for cases in which 
>he/she is expressly authorized to do so in writing, and such
>authorization
>or power of attorney is submitted to the recipient or the person 
>represented by the recipient, or the existence of such authorization is
>
>known to the recipient of the person represented by the recipient.
>
>
>Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
>Het 
>PCS op LinkedIn
>Disclaimer | Please consider the environment before printing. Think
>green,
>keep it on the screen!
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From arnaud.gaboury at gmail.com  Thu Apr 16 15:25:28 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 16 Apr 2015 15:25:28 +0200
Subject: [R] Error when loading shared library - stringini()
Message-ID: <CAK1hC9usC_Hw0EPabGFqK-txs3bhdWraKMxrrXr+nSZOEDf=_w@mail.gmail.com>

On a Linux 64 bits, R.3.1.2, with tidyr() loaded.

gabx at hortensia [R] separate(rawStats, 'toto')
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/developement/language/r/library/stringi/libs/stringi.so':
  libicui18n.so.54: cannot open shared object file: No such file or directory
----------------------------------------------------

When trying to upgrade stringini(), it is not available for 3.1.2

My box run :icu 55.1-1 & :lib32-icu 55.1-1

If I am right, I need to downgrade to 54 to be able to run separate()
from tidyr package? Or is there any other way?

Thank you for hint.


-- 

google.com/+arnaudgabourygabx


From hannah.hlx at gmail.com  Thu Apr 16 16:47:21 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 16 Apr 2015 10:47:21 -0400
Subject: [R] Question with uniroot function
In-Reply-To: <D805D2AC-BE55-4F6A-AD71-81E1642801C1@dcn.davis.CA.us>
References: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>
	<D805D2AC-BE55-4F6A-AD71-81E1642801C1@dcn.davis.CA.us>
Message-ID: <CAHLnndYyL2gGTu-TBPN6v1-2wu2Aq-yRb9pF9+P_x6CpNkwX9A@mail.gmail.com>

Hi Jeff,
  Thanks for the reply. I am aware that the sign needs to be different at
the ends of the starting interval.

   Another question:

Is there a way to set the right end point ( (the "upper" argument in the
uniroot function below) as the point where the function takes on its
minimun, for example my function f1 below?

Thanks very much!



u1 <- -3
u2 <- 4
pi0 <- 0.8

f1 <- function(lambda,z,p1){
lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}

 x <- seq(-20,20, by=0.1)
y <- numeric(length(x))
for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
plot(y ~ x, ylim=c(-1,1))
abline(h=0)


a <- uniroot(f1, lower =-10, upper = 0,
           tol = 1e-20,p1=0.15,lambda=0.998)$root





2015-04-15 22:57 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> You really need to read the help page for uniroot. The sign needs to be
> different at the ends of the starting interval. This is a typical
> limitation of numerical root finders.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 15, 2015 7:20:04 PM PDT, li li <hannah.hlx at gmail.com> wrote:
> >Hi all,
> >In the following code, I am trying to use uniroot function to solve for
> >the root (a and b in code below) for function f1.
> >I am not sure why uniroot function does not give the answer since when
> >we
> >look the graph, the function does cross 0 twice.
> >Any suggestion?
> >   Thanks.
> >       Hanna
> >
> >u1 <- -3
> >u2 <- 4
> >pi0 <- 0.8
> >
> >f1 <- function(lambda,z,p1){
> >lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
> >
> >a <- uniroot(f1, lower =-10, upper = 0,
> >           tol = 1e-20,p1=0.15,lambda=0.998)$root
> >
> >b <- uniroot(f1, lower =0, upper = 10,
> >           tol = 1e-20,p1=0.15,lambda=0.998)$root
> >
> >x <- seq(-20,20, by=0.1)
> >y <- numeric(length(x))
> >for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
> >plot(y ~ x, ylim=c(-1,1))
> >abline(h=0)
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Apr 16 16:58:33 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Apr 2015 16:58:33 +0200
Subject: [R] "function" as variable name - probably better error message
In-Reply-To: <552F9F33.4090806@gmail.com>
References: <m23840gytu.fsf@krugs.de> <552F9F33.4090806@gmail.com>
Message-ID: <594DC0F9-88B4-437D-81AC-C555090A7AE5@gmail.com>

Actually, to split a few hairs, I think the documentation is essentially correct. 

Reserved words are not the same as quoted strings. You cannot use them in syntactically the same way that you usually use variable names, as unquoted strings in expressions. They can BE variable names, or more precisely: object names. In fact they often are; you get in deep trouble if you redefine  `for`, `function`, or `if` -- as functions, at least. That goes for things like `{` too, by the way.

-pd

On 16 Apr 2015, at 13:38 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
> 
> On 16/04/2015 6:19 AM, Rainer M Krug wrote:
>> Hi
>> 
>> The following code works as expected:
>> 
>> 
>> list(plot="Not any more!")
>> 
>> ,---- | > plot <- "Not any more!") | [1] "Not any more!" `----
>> 
>> But for this I get an error:
>> 
>> ,---- | > function <- "Not any more!" | Error: unexpected
>> assignment in "function <-" `----
>> 
>> The error message is quite cryptic and does not help much further.
>> Would it be possible to provide a more useful error message in this
>> case that (presumably) "function" is a reserved word?
>> 
>> Along the same lines - is there a list of reserved words which can
>> not be used in R as variable names (not even as elements in a a
>> list())?
> 
> The R Language Definition lists the reserved words (see section
> 10.3.3).  It oversimplifies things, saying they can't be used as
> variable names, when in fact almost any string can be used with proper
> quoting.  For example, both of these work:
> 
> "function" <- "Not any more!"
> `function` <- "Not any more!"
> 
> Duncan Murdoch
> 
>> 
>> This is not a huge problem, but it cost me a few minutes of
>> figuring out.
>> 
>> Thanks,
>> 
>> Rainer
>> 
>> 
>> 
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
> Comment: GPGTools - https://gpgtools.org
> 
> iQEcBAEBCgAGBQJVL58yAAoJEHE2Kz23YMZyyv0H/jKjwwkQ1v7jIRsZ9hxcJECU
> HHHuAEusv+pgJTybdxn66XykCXQOgaLmGPGksK+CcJrBgLW2WgAh4C0CUpN36DPn
> TOYpos9i3wZ8k0Idr8xiEeQ/PcD0pkMEwd6oYY0lL2Ikribu8maVKxcoYvjNIJOE
> 3E3qrrpZfH9U2a9ws9jxJk8O3n+OQ7x8GQqUNTQHthd5McHZ63F7uIEBH/tHT7Tn
> x3gXAFbuSBJ6TtqaOZdPYFh3tV7CNyvJOso8yreSWK+0ZksXGKBtqElDJM0atrAj
> bOwEAJe6gGrEPx92NUWkTWeILDa6v96WZzprwLDi+cwt7jItILFligaXlookbf0=
> =vKWN
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sergio.fonda99 at gmail.com  Thu Apr 16 17:31:11 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Thu, 16 Apr 2015 17:31:11 +0200
Subject: [R] assign variables to function output
In-Reply-To: <CA+8X3fUDa4UYKPOM0nT30oxkYDjYQcBVQ6bL62-rQvapd38eyg@mail.gmail.com>
References: <1429136250774-4705920.post@n4.nabble.com>
	<CAJRuHop3aS6_Hc26DCFDsiLX2-nFsW1fSbEE_8K_uAfxbU+BHA@mail.gmail.com>
	<CA+8X3fUDa4UYKPOM0nT30oxkYDjYQcBVQ6bL62-rQvapd38eyg@mail.gmail.com>
Message-ID: <CAJRuHorqgyemdvbazr82r9vN63FB01XCnOQ=gsJXDqMo1pyQTQ@mail.gmail.com>

That's it ! Sorry for writing in a hurry, Merm!
Il 16/apr/2015 14:14, "Jim Lemon" <drjimlemon at gmail.com> ha scritto:

> Hi merm,
> In case Sergio's message is a little cryptic:
>
> return_a_list<-function() {
>  a<-"First item of list"
>  b<-c(2,4,6,8)
>  c<-matrix(1:9,nrow=3)
>  return(list(a,b,c))
> }
>
> x<-return_a_list()
> x
>
> Jim
>
> On Thu, Apr 16, 2015 at 7:21 PM, Sergio Fonda <sergio.fonda99 at gmail.com>
> wrote:
> > Collect in a vector or dataframe or list the variables of interest and
> > output it.
> > Il 16/apr/2015 10:57, "merm" <pionescu at student.unimelb.edu.au> ha
> scritto:
> >
> >> Hi!
> >>
> >> So I'm trying as the header suggests to assign the value(s) output by a
> >> function to a variable, say 'y'
> >>
> >> Problem is from what I gather any variables introduced within the
> function
> >> are contained and the only output I can get is "return(value)" which is
> >> awkward to work with. Any suggestions?
> >>
> >> Cheers!
> >>
> >>
> >>
> >> --
> >> View this message in context:
> >>
> http://r.789695.n4.nabble.com/assign-variables-to-function-output-tp4705920.html
> >> Sent from the R help mailing list archive at Nabble.com.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t.jombart at imperial.ac.uk  Thu Apr 16 18:01:23 2015
From: t.jombart at imperial.ac.uk (Jombart, Thibaut)
Date: Thu, 16 Apr 2015 16:01:23 +0000
Subject: [R] FW: New package apex 1.0.0 released on CRAN
In-Reply-To: <2CB2DA8E426F3541AB1907F98ABA6570ABF13213@icexch-m1.ic.ac.uk>
References: <2CB2DA8E426F3541AB1907F98ABA6570ABF13213@icexch-m1.ic.ac.uk>
Message-ID: <2CB2DA8E426F3541AB1907F98ABA6570ABF13238@icexch-m1.ic.ac.uk>


Dear all,

(apologies for multiple posting)

On behalf of the apex development team (E. Paradis, K. Schliep, Z. Kamvar, R. Harris and myself), I am happy to announce that apex has been released on CRAN:
http://cran.r-project.org/web/packages/apex/index.html

This package provides tools for reading, storing, handling and analysing genetic sequences from multiple genes, and is compatible with both ape and phangorn.

For more information on apex, questions, requests, or to join us, check our github project at:
https://github.com/thibautjombart/apex

Best regards
Thibaut

==============================
Dr Thibaut Jombart
MRC Centre for Outbreak Analysis and Modelling
Department of Infectious Disease Epidemiology
Imperial College - School of Public Health
Norfolk Place, London W2 1PG, UK
Tel. : 0044 (0)20 7594 3658
http://sites.google.com/site/thibautjombart/
http://sites.google.com/site/therepiproject/
http://adegenet.r-forge.r-project.org/
Twitter: @thibautjombart


_______________________________________________
R-sig-genetics mailing list
R-sig-genetics at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-genetics


From gunter.berton at gene.com  Thu Apr 16 18:20:29 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 16 Apr 2015 09:20:29 -0700
Subject: [R] FW: New package apex 1.0.0 released on CRAN
In-Reply-To: <2CB2DA8E426F3541AB1907F98ABA6570ABF13238@icexch-m1.ic.ac.uk>
References: <2CB2DA8E426F3541AB1907F98ABA6570ABF13213@icexch-m1.ic.ac.uk>
	<2CB2DA8E426F3541AB1907F98ABA6570ABF13238@icexch-m1.ic.ac.uk>
Message-ID: <CACk-te1F=T4_P0Ju7-GY+m4q6dEcR178ZbYsWzHHwDN28VNY1A@mail.gmail.com>

This sounds more appropriate for Bioconductor, if you haven't already
submitted/announced it there.

Cheers,
Bert

On Thursday, April 16, 2015, Jombart, Thibaut <t.jombart at imperial.ac.uk>
wrote:

>
> Dear all,
>
> (apologies for multiple posting)
>
> On behalf of the apex development team (E. Paradis, K. Schliep, Z. Kamvar,
> R. Harris and myself), I am happy to announce that apex has been released
> on CRAN:
> http://cran.r-project.org/web/packages/apex/index.html
>
> This package provides tools for reading, storing, handling and analysing
> genetic sequences from multiple genes, and is compatible with both ape and
> phangorn.
>
> For more information on apex, questions, requests, or to join us, check
> our github project at:
> https://github.com/thibautjombart/apex
>
> Best regards
> Thibaut
>
> ==============================
> Dr Thibaut Jombart
> MRC Centre for Outbreak Analysis and Modelling
> Department of Infectious Disease Epidemiology
> Imperial College - School of Public Health
> Norfolk Place, London W2 1PG, UK
> Tel. : 0044 (0)20 7594 3658
> thibautjombart <http://sites.google.com/site/thibautjombart/>
> therepiproject <http://sites.google.com/site/therepiproject/>
> http://adegenet.r-forge.r-project.org/
> Twitter: @thibautjombart
>
>
> _______________________________________________
> R-sig-genetics mailing list
> R-sig-genetics at r-project.org <javascript:;>
> https://stat.ethz.ch/mailman/listinfo/r-sig-genetics
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Apr 16 18:33:43 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Apr 2015 09:33:43 -0700
Subject: [R] Question with uniroot function
In-Reply-To: <CAHLnndYyL2gGTu-TBPN6v1-2wu2Aq-yRb9pF9+P_x6CpNkwX9A@mail.gmail.com>
References: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>
	<D805D2AC-BE55-4F6A-AD71-81E1642801C1@dcn.davis.CA.us>
	<CAHLnndYyL2gGTu-TBPN6v1-2wu2Aq-yRb9pF9+P_x6CpNkwX9A@mail.gmail.com>
Message-ID: <CAF8bMcYZwzSJXGNc7vWK4QoYNY1ietU3Wr+FDBTS1NMUoMjBEQ@mail.gmail.com>

Use optimize() to find the minimum and feed that value into uniroot().

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 16, 2015 at 7:47 AM, li li <hannah.hlx at gmail.com> wrote:

> Hi Jeff,
>   Thanks for the reply. I am aware that the sign needs to be different at
> the ends of the starting interval.
>
>    Another question:
>
> Is there a way to set the right end point ( (the "upper" argument in the
> uniroot function below) as the point where the function takes on its
> minimun, for example my function f1 below?
>
> Thanks very much!
>
>
>
> u1 <- -3
> u2 <- 4
> pi0 <- 0.8
>
> f1 <- function(lambda,z,p1){
> lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
>
>  x <- seq(-20,20, by=0.1)
> y <- numeric(length(x))
> for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
> plot(y ~ x, ylim=c(-1,1))
> abline(h=0)
>
>
> a <- uniroot(f1, lower =-10, upper = 0,
>            tol = 1e-20,p1=0.15,lambda=0.998)$root
>
>
>
>
>
> 2015-04-15 22:57 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
> > You really need to read the help page for uniroot. The sign needs to be
> > different at the ends of the starting interval. This is a typical
> > limitation of numerical root finders.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On April 15, 2015 7:20:04 PM PDT, li li <hannah.hlx at gmail.com> wrote:
> > >Hi all,
> > >In the following code, I am trying to use uniroot function to solve for
> > >the root (a and b in code below) for function f1.
> > >I am not sure why uniroot function does not give the answer since when
> > >we
> > >look the graph, the function does cross 0 twice.
> > >Any suggestion?
> > >   Thanks.
> > >       Hanna
> > >
> > >u1 <- -3
> > >u2 <- 4
> > >pi0 <- 0.8
> > >
> > >f1 <- function(lambda,z,p1){
> > >lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
> > >
> > >a <- uniroot(f1, lower =-10, upper = 0,
> > >           tol = 1e-20,p1=0.15,lambda=0.998)$root
> > >
> > >b <- uniroot(f1, lower =0, upper = 10,
> > >           tol = 1e-20,p1=0.15,lambda=0.998)$root
> > >
> > >x <- seq(-20,20, by=0.1)
> > >y <- numeric(length(x))
> > >for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
> > >plot(y ~ x, ylim=c(-1,1))
> > >abline(h=0)
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > <http://www.r-project.org/posting-guide.html>
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From arnaud.gaboury at gmail.com  Thu Apr 16 18:35:17 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 16 Apr 2015 18:35:17 +0200
Subject: [R] Error when loading shared library - stringini()
In-Reply-To: <CAK1hC9usC_Hw0EPabGFqK-txs3bhdWraKMxrrXr+nSZOEDf=_w@mail.gmail.com>
References: <CAK1hC9usC_Hw0EPabGFqK-txs3bhdWraKMxrrXr+nSZOEDf=_w@mail.gmail.com>
Message-ID: <CAK1hC9tEj6iSVc1ZYkciiqi0h0b+moaDKMbbNthvETUYdjzmXw@mail.gmail.com>

On Thu, Apr 16, 2015 at 3:25 PM, arnaud gaboury <arnaud.gaboury at gmail.com>
wrote:

> On a Linux 64 bits, R.3.1.2, with tidyr() loaded.
>
> gabx at hortensia [R] separate(rawStats, 'toto')
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object
> '/developement/language/r/library/stringi/libs/stringi.so':
>   libicui18n.so.54: cannot open shared object file: No such file or
> directory
> ----------------------------------------------------
>
> When trying to upgrade stringini(), it is not available for 3.1.2
>

> install_github('Rexamine/stringi')

did the trick

>
> My box run :icu 55.1-1 & :lib32-icu 55.1-1
>
> If I am right, I need to downgrade to 54 to be able to run separate()
> from tidyr package? Or is there any other way?
>
> Thank you for hint.
>
>
> --
>
> google.com/+arnaudgabourygabx
>



-- 

google.com/+arnaudgabourygabx
<https://plus.google.com/_/notifications/emlink?emr=05814804238976922326&emid=CKiv-v6PvboCFcfoQgod6msAAA&path=%2F116159236040461325607%2Fop%2Fu&dt=1383086841306&ub=50>

	[[alternative HTML version deleted]]


From giuseppe.amatulli at gmail.com  Thu Apr 16 17:05:14 2015
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Thu, 16 Apr 2015 11:05:14 -0400
Subject: [R] Fwd: Using Geographic Information Systems and Remote Sensing to
 study disease vector habitat
In-Reply-To: <CAKoiDHJ4886WsWCEAtudT0BS6s_SULFXBybb36h_fsxaL5+jCw@mail.gmail.com>
References: <CAKoiDHJ4886WsWCEAtudT0BS6s_SULFXBybb36h_fsxaL5+jCw@mail.gmail.com>
Message-ID: <CAKoiDHLSgKqwC33Qh8uPTScCrHZmwydW4OZmxPoEc4rTMfaGYw@mail.gmail.com>

HI,
Apologies for cross-posting:
This is a good opportunity for start to learn GIS and Statistical Analysis
(R) with open-source software.

*Workshop: **Using Geographic Information Systems and Remote Sensing to
study disease vector habitat*

Biotechonology Research Institute
<http://www.kalro.org/Biotechnology_Research_Institute> (BRI) in
collaboration with  Yale University (School of Public Helath
<http://publichealth.yale.edu/>, Institute for Biospehric Studies
<http://yibs.yale.edu/> and the Department of Ecology and Evolutionary
Biology <http://eeb.yale.edu/>) invites applications for a geospatial
analysis workshop to be held on June  *1 - 6,  2015 *at TRC Campus in
Muguga Kenya.

*The workshop will *introduce participants to Geographic Information
Systems (GIS) and satellite-based remote sensing technologies.   Students
will use the provided suite of *open-source software* (GRASS, R, QGIS,
PKTOOLS) to manipulate GIS data and satellite images to create basic
species habitat models with R ( library(hSDM) ) .  There will be a special
focus on identifying and mapping tsetse fly habitat.

Registration info and contact persons at
http://www.funai.edu.ng/call-for-applications
Best
Rigards

-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>



-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
165 PROSPECT ST
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>

	[[alternative HTML version deleted]]


From mabrouk.abaza.1 at ulaval.ca  Thu Apr 16 17:03:37 2015
From: mabrouk.abaza.1 at ulaval.ca (maaba)
Date: Thu, 16 Apr 2015 08:03:37 -0700 (PDT)
Subject: [R] problem in the ensemblaBMA package of R
Message-ID: <1429196617001-4705946.post@n4.nabble.com>

hello,

I'm working in ensembleBMA package of R and i need to use the
ensembleBMAgamma0 function to correct my precipitation.
How can i change my training period ?. I have to chose a training period for
4 days which contains a 2 days before the specific day and 2 days after the
specific day. I don't need to chose only the days before my specific day.

Someone have an idea how i can do that ?

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/problem-in-the-ensemblaBMA-package-of-R-tp4705946.html
Sent from the R help mailing list archive at Nabble.com.


From paul.domaskis at gmail.com  Thu Apr 16 16:17:59 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 14:17:59 +0000
Subject: [R] (no subject)
References: <loom.20150416T062323-599@post.gmane.org>
	<552F9D91.5020609@gmail.com>
Message-ID: <loom.20150416T161421-264@post.gmane.org>

Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> The Cygwin release is not supported by us, and is known to be buggy,
> because it doesn't handle line endings properly.
>
> You'll need to talk to the Cygwin folks if you can't reproduce this
> in one of our releases available from
> cran.r-project.org/bin/windows/base.

Installing things is always challenging in a locked down environment.
I'll post on a cygwin forum.  Thanks.


From paul.domaskis at gmail.com  Thu Apr 16 16:48:15 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 14:48:15 +0000
Subject: [R] vi[m] editing of past commands in R command line
Message-ID: <loom.20150416T164743-425@post.gmane.org>

When I use bash + readline and ~/.inputrc contains "editing-mode vi", I can 
press "v" to switch to from the command line editing to a full vi session 
editing of a command.  This doesn't seem to happen in R.  Is there a 
configuration setting/file that I can set to get this behaviour?

Furthermore, when using bash, the fc command allows me to edit the history 
of commands, and when I exit the editor, all the remaining (and likely 
modified) commands are submitted to the bash shell as if I typed them at 
the prompt.  Is there a way to get similar functionality in R?


From paul.domaskis at gmail.com  Thu Apr 16 17:04:17 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 15:04:17 +0000
Subject: [R] "R" help leaves out lines of text
References: <loom.20150416T062323-599@post.gmane.org>
Message-ID: <loom.20150416T170400-96@post.gmane.org>

Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> The Cygwin release is not supported by us, and is known to be buggy,
> because it doesn't handle line endings properly.
>
> You'll need to talk to the Cygwin folks if you can't reproduce this
> in one of our releases available from
> cran.r-project.org/bin/windows/base.

Paul <paul.domaskis <at> gmail.com> wrote:
> Installing things is always challenging in a locked down
> environment.  I'll post on a cygwin forum.  Thanks.

By the way, if it's just a DOS vs. UNIX line-ending issue, are the
help files stored in such a way that I can simply run them through
unix2dos (or vice-versa), or possibly use the unix tr command to
perform some other kind of conversion?


From luca.cerone at gmail.com  Thu Apr 16 19:50:14 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Thu, 16 Apr 2015 19:50:14 +0200
Subject: [R] Obfuscate AES password
In-Reply-To: <552D12EF.3050103@atsu.edu>
References: <CAFnz2--OigPYGEwF4e0Jfh+1M6rZzKnn4bMqKs6JH4OATgU9sw@mail.gmail.com>
	<094E8F78-5A9C-4D5D-B9CF-7A1FD9473FE0@dcn.davis.CA.us>
	<CAFnz2-95oR5bLeWx5A7Hj+z-oBOAt8p6yQzfgnOEJfxGo4jLyg@mail.gmail.com>
	<B4E14CA2-9609-454E-B7B6-0202C98D7317@dcn.davis.CA.us>
	<CAFnz2-_yHGwhnMXZDNgD35-WiZiMmPXFyBkgbScFGgXYFaDSHw@mail.gmail.com>
	<552D12EF.3050103@atsu.edu>
Message-ID: <CAFnz2-91G6ogHpHD-Uc15j_U7cWMwhi002o_sN5FR3kCwSqTbw@mail.gmail.com>

Thanks Robert, but is not exactly what I need :)

I am simply trying to find a way to encrypt some data in a way that
doesn't require the user to type any password (if not only the first
time)
but that is secure enough in a multi-user environment.

E.g. I do not want super user to be able to access my data because
they can read the AES key.

Hope this is a bit clearer,

Thanks a lot for your help!

Cheers,
Luca

On Tue, Apr 14, 2015 at 3:15 PM, Robert Baer <rbaer at atsu.edu> wrote:
> I'm not sure I completely understand your authentication needs, but perhaps
> the RCurl package could be of some use to you.
>
> Rob
>
>
> On 4/13/2015 1:26 AM, Luca Cerone wrote:
>>
>> Thanks Jeff,
>> and OK I'll move next questions on the topic to the devel list :)
>>
>> I was hoping there were packages that already dealt with this sort of
>> things, that's why I posted my question here in the first place..
>>
>> Thanks a lot for helping me with this,
>>
>> Cheers,
>> Luca
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
>
>
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> rbaer(at)atsu.edu
>


From johnwasige at gmail.com  Thu Apr 16 21:00:03 2015
From: johnwasige at gmail.com (John Wasige)
Date: Thu, 16 Apr 2015 21:00:03 +0200
Subject: [R] regression of values in one stack with another
Message-ID: <CAJgdCD5Ycw9N4c5sW+KMdbm=w4DcGMN8qBNVAdf2BGkLV89G4w@mail.gmail.com>

D
?ear community,

This is to kindly request for your help.
 I have an error from regression of values in one stack with another
# s1 and s2 have 720 layers; coefficients[2] is the slope


### script
rstack1 <- stack(s1,s2)
s <- stack('D:/Correlation/rstack.tif')
fun <- function(x) { lm(x[1:360] ~ x[361:720])$coefficients[2] }
x1 <- calc(s, fun)

I get the following error:

Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : cannot
use this function

Many thanks for your help in sloving this problem

John

?

	[[alternative HTML version deleted]]


From G.Rudge at bham.ac.uk  Thu Apr 16 19:57:44 2015
From: G.Rudge at bham.ac.uk (Gavin Rudge)
Date: Thu, 16 Apr 2015 17:57:44 +0000
Subject: [R] Extracting xml data to data frames
Message-ID: <B8D87DA108D62D448DBE22A7775AB6BB881574CA@EX7.adf.bham.ac.uk>

Hi Rgonauts,

I am trying to parse some xml files of transport data using the TransExchange format (in this case bus routing information) and obtain some data.frames for onward processing for a GIS related task.  Ideally I need them in .csv files.

Each file (an example is attached) contains up to 8 tables of information about transport operators and routing information.  I have uploaded an example that contains all 8.  In fact I have some hundreds of similar files that will need processing. So when I've solved this I will need to be able to loop through a bunch of them.

I'm new to handling xml data and to the xml package so I don't really know what I'm doing, this is my first stab at using the xml package.
So far the workflow goes something like this.

#get the file
doc=xmlTreeParse("cen_18-23-D-y11-2.xml")
top=xmlRoot(doc)

#look at the names
top=xmlRoot(doc)

#pick one of them to use, in this case the forth one, 'routes', a table of information about this particular bus route. using some code from another forum post, I can get a data.frame with the info i need in it.  OK I need to do some reshaping but I can handle that later

fr4<-(top[[4]])
fr4
xmlSApply(fr4,function(x) xmlSApply(x,xmlValue))
df<-as.data.frame(xmlSApply(fr4,function(x) xmlSApply(x,xmlValue)))
df

#this works but when I try it with another table, the fifth one say, that captures information about the parts of the journey between stops, it falls over.

fr5<-(top[[5]])
fr5
xmlSApply(fr5,function(x) xmlSApply(x,xmlValue))
df<-as.data.frame(xmlSApply(fr5,function(x) xmlSApply(x,xmlValue)))
df

Now I guess there is an irregularity in the xml causing this.  I gather from other posts I should use Xpath functionality to interrogate this section of the data. I've tried reverse engineering some of these commands I've seen in solutions to irregular xml problems on other forums but not got to what I want. I'm not really up on xml, but I am assuming it is something to do with the <JourneySectionPattern id=****> part of the file is what is causing the problem?  This looks like there should be a field called JouneyPattern ID (only I guess without the space) and then the ID code as the actual field contents.

So my question is, is there a way to parse this table correctly and output the resulting df as a csv?

All help gratefully recieved.  BTW the link to the searhable r-help archives seems to be broken. 

GavinR





From paul.domaskis at gmail.com  Thu Apr 16 20:58:12 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 18:58:12 +0000
Subject: [R] "R": Redefine default parameter values for help.start()
Message-ID: <loom.20150416T205313-272@post.gmane.org>

Because of the setup of R in cygwin, help.start() requires the
following parameter values:

help.start(browser="cygstart",remote=R.home())

Is it possible to make these values the default?

I do not want cygstart to be the browser except as a parameter for
help.start().


From hannah.hlx at gmail.com  Thu Apr 16 22:05:43 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 16 Apr 2015 16:05:43 -0400
Subject: [R] Question with uniroot function
In-Reply-To: <CAF8bMcYZwzSJXGNc7vWK4QoYNY1ietU3Wr+FDBTS1NMUoMjBEQ@mail.gmail.com>
References: <CAHLnndYRtLrcW=CkwGFUCfQHqzQWFGUXkSjCem_VNsHkYvG=+Q@mail.gmail.com>
	<D805D2AC-BE55-4F6A-AD71-81E1642801C1@dcn.davis.CA.us>
	<CAHLnndYyL2gGTu-TBPN6v1-2wu2Aq-yRb9pF9+P_x6CpNkwX9A@mail.gmail.com>
	<CAF8bMcYZwzSJXGNc7vWK4QoYNY1ietU3Wr+FDBTS1NMUoMjBEQ@mail.gmail.com>
Message-ID: <CAHLnndYR_r6DBp0PJJv8XMQbX1-T+cdpFcJKTrz2EtxtZc6qag@mail.gmail.com>

Thank you.



2015-04-16 12:33 GMT-04:00 William Dunlap <wdunlap at tibco.com>:

> Use optimize() to find the minimum and feed that value into uniroot().
>
>  Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>  On Thu, Apr 16, 2015 at 7:47 AM, li li <hannah.hlx at gmail.com> wrote:
>
>>  Hi Jeff,
>>   Thanks for the reply. I am aware that the sign needs to be different at
>> the ends of the starting interval.
>>
>>    Another question:
>>
>> Is there a way to set the right end point ( (the "upper" argument in the
>> uniroot function below) as the point where the function takes on its
>> minimun, for example my function f1 below?
>>
>> Thanks very much!
>>
>>
>>
>> u1 <- -3
>> u2 <- 4
>> pi0 <- 0.8
>>
>> f1 <- function(lambda,z,p1){
>> lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
>>
>>  x <- seq(-20,20, by=0.1)
>> y <- numeric(length(x))
>> for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
>> plot(y ~ x, ylim=c(-1,1))
>> abline(h=0)
>>
>>
>> a <- uniroot(f1, lower =-10, upper = 0,
>>            tol = 1e-20,p1=0.15,lambda=0.998)$root
>>
>>
>>
>>
>>
>> 2015-04-15 22:57 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>
>> > You really need to read the help page for uniroot. The sign needs to be
>> > different at the ends of the starting interval. This is a typical
>> > limitation of numerical root finders.
>> >
>> ---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> > Go...
>> >                                       Live:   OO#.. Dead: OO#..  Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> >
>> ---------------------------------------------------------------------------
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On April 15, 2015 7:20:04 PM PDT, li li <hannah.hlx at gmail.com> wrote:
>> > >Hi all,
>> > >In the following code, I am trying to use uniroot function to solve for
>> > >the root (a and b in code below) for function f1.
>> > >I am not sure why uniroot function does not give the answer since when
>> > >we
>> > >look the graph, the function does cross 0 twice.
>> > >Any suggestion?
>> > >   Thanks.
>> > >       Hanna
>> > >
>> > >u1 <- -3
>> > >u2 <- 4
>> > >pi0 <- 0.8
>> > >
>> > >f1 <- function(lambda,z,p1){
>> > >lambda*(p1*exp(u1*z-u1^2/2)+(0.2-p1)*exp(u2*z-u2^2/2))-(1-lambda)*pi0}
>> > >
>> > >a <- uniroot(f1, lower =-10, upper = 0,
>> > >           tol = 1e-20,p1=0.15,lambda=0.998)$root
>> > >
>> > >b <- uniroot(f1, lower =0, upper = 10,
>> > >           tol = 1e-20,p1=0.15,lambda=0.998)$root
>> > >
>> > >x <- seq(-20,20, by=0.1)
>> > >y <- numeric(length(x))
>> > >for (i in 1:length(x)){y[i] <- f1(x[i],p1=0.15,lambda=0.998)}
>> > >plot(y ~ x, ylim=c(-1,1))
>> > >abline(h=0)
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> > <http://www.r-project.org/posting-guide.html>
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Apr 16 23:17:28 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 16 Apr 2015 13:17:28 -0800
Subject: [R] Extracting xml data to data frames
In-Reply-To: <B8D87DA108D62D448DBE22A7775AB6BB881574CA@EX7.adf.bham.ac.uk>
Message-ID: <65ED24BEE7E.000008A9jrkrideau@inbox.com>

No attachment : R-help is rather fussy about the files it will accept. You are probably okay with .txt .pdf, or png but even .csv is likely to get stripped.  

The best way to supply data is by using dput()  .  Type ?dput for information or have a look at  http://adv-r.had.co.nz/Reproducibility.html for some hints.  


John Kane
Kingston ON Canada


> -----Original Message-----
> From: g.rudge at bham.ac.uk
> Sent: Thu, 16 Apr 2015 17:57:44 +0000
> To: r-help at r-project.org
> Subject: [R] Extracting xml data to data frames
> 
> Hi Rgonauts,
> 
> I am trying to parse some xml files of transport data using the
> TransExchange format (in this case bus routing information) and obtain
> some data.frames for onward processing for a GIS related task.  Ideally I
> need them in .csv files.
> 
> Each file (an example is attached) contains up to 8 tables of information
> about transport operators and routing information.  I have uploaded an
> example that contains all 8.  In fact I have some hundreds of similar
> files that will need processing. So when I've solved this I will need to
> be able to loop through a bunch of them.
> 
> I'm new to handling xml data and to the xml package so I don't really
> know what I'm doing, this is my first stab at using the xml package.
> So far the workflow goes something like this.
> 
> #get the file
> doc=xmlTreeParse("cen_18-23-D-y11-2.xml")
> top=xmlRoot(doc)
> 
> #look at the names
> top=xmlRoot(doc)
> 
> #pick one of them to use, in this case the forth one, 'routes', a table
> of information about this particular bus route. using some code from
> another forum post, I can get a data.frame with the info i need in it.
> OK I need to do some reshaping but I can handle that later
> 
> fr4<-(top[[4]])
> fr4
> xmlSApply(fr4,function(x) xmlSApply(x,xmlValue))
> df<-as.data.frame(xmlSApply(fr4,function(x) xmlSApply(x,xmlValue)))
> df
> 
> #this works but when I try it with another table, the fifth one say, that
> captures information about the parts of the journey between stops, it
> falls over.
> 
> fr5<-(top[[5]])
> fr5
> xmlSApply(fr5,function(x) xmlSApply(x,xmlValue))
> df<-as.data.frame(xmlSApply(fr5,function(x) xmlSApply(x,xmlValue)))
> df
> 
> Now I guess there is an irregularity in the xml causing this.  I gather
> from other posts I should use Xpath functionality to interrogate this
> section of the data. I've tried reverse engineering some of these
> commands I've seen in solutions to irregular xml problems on other forums
> but not got to what I want. I'm not really up on xml, but I am assuming
> it is something to do with the <JourneySectionPattern id=****> part of
> the file is what is causing the problem?  This looks like there should be
> a field called JouneyPattern ID (only I guess without the space) and then
> the ID code as the actual field contents.
> 
> So my question is, is there a way to parse this table correctly and
> output the resulting df as a csv?
> 
> All help gratefully recieved.  BTW the link to the searhable r-help
> archives seems to be broken.
> 
> GavinR
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From maechler at lynne.stat.math.ethz.ch  Fri Apr 17 09:02:14 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Apr 2015 09:02:14 +0200
Subject: [R] "R": Redefine default parameter values for help.start()
In-Reply-To: <loom.20150416T205313-272@post.gmane.org>
References: <loom.20150416T205313-272@post.gmane.org>
Message-ID: <21808.45046.152428.633822@stat.math.ethz.ch>

>>>>> paul  <paul.domaskis at gmail.com>
>>>>>     on Thu, 16 Apr 2015 18:58:12 +0000 writes:

    > Because of the setup of R in cygwin, help.start() requires
    > the following parameter values:

    > help.start(browser="cygstart",remote=R.home())

    > Is it possible to make these values the default?

You are building R from the sources, right?

Then, of course it is easily possible: Just modify your version
of the R source code appropriately:

It is file  <R>/src/library/utils/R/help.start.R

(And you need more changes anyway to make things work under Cygwin;
 but don't ask me about it: I do run R on Windows only very rarely)

    > I do not want cygstart to be the browser except as a
    > parameter for help.start().


From petr.pikal at precheza.cz  Fri Apr 17 11:07:13 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Apr 2015 09:07:13 +0000
Subject: [R] melt function chooses wrong id variable with large datasets
In-Reply-To: <OF29C20A09.8356477D-ONC1257E2A.0022F95A-C1257E2A.00231377@pcsierteelt.be>
References: <OF6BBDE1DA.46038133-ONC1257E29.0031BC9E-C1257E29.0034CA82@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28A1A@SRVEXCHMBX.precheza.cz>
	<OFAB76DB94.FB8826D3-ONC1257E29.003C2C7B-C1257E29.003D9AAE@pcsierteelt.be>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28BDC@SRVEXCHMBX.precheza.cz>
	<OF29C20A09.8356477D-ONC1257E2A.0022F95A-C1257E2A.00231377@pcsierteelt.be>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C28D75@SRVEXCHMBX.precheza.cz>

Yes

It could be. But anyway, if you wanted to melt your frame and be sure to have norm column added to months column you shall use

melt(dataset, id.vars=NULL, na.rm=TRUE)

construction.

Without it and considering data you sent I get

> head(dd.m0)
                norm variable value
1   45.8713463281901  januari  38.1
2 24.047250681782984  januari  32.4
3 3.7533684144746324  januari  34.5
4 38.594241119279324  januari  20.7
5 26.391897460120358  januari  21.5
6 61.746470001194638  januari  23.1
...
without this id.vars=NULL parameter.

Cheers
Petr

PS. Keep your post to Rhelp - others may learn from it and anothers can provide you with more elaborated explanation.


From: Joachim Audenaert [mailto:Joachim.Audenaert at pcsierteelt.be]
Sent: Friday, April 17, 2015 8:23 AM
To: PIKAL Petr
Subject: RE: [R] melt function chooses wrong id variable with large datasets

Hello,

I upgraded R tot version 3.1.3 and now everything in the script works perfectly. Could the troubles be due to the fact that I was running an older version?

Met vriendelijke groeten - With kind regards,

Joachim Audenaert
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research
________________________________

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be<mailto:joachim.audenaert at pcsierteelt.be> | W: www.pcsierteelt.be<http://www.pcsierteelt.be/>



From:        PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
To:        Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be<mailto:Joachim.Audenaert at pcsierteelt.be>>
Cc:        "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Date:        16/04/2015 13:41
Subject:        RE: [R]  melt function chooses wrong id variable with large datasets
________________________________



Hi

With this dataset I get

> dd.m0<-melt(dataset, na.rm=T)
Using norm as id variables
> head(dd.m0)
                norm variable value
1   45.8713463281901  januari  38.1
2 24.047250681782984  januari  32.4
3 3.7533684144746324  januari  34.5
4 38.594241119279324  januari  20.7
5 26.391897460120358  januari  21.5
6 61.746470001194638  januari  23.1
>
or

dd.m<-melt(dataset, id.vars=NULL, na.rm=T)

> head(dd.m)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m)
    variable              value
255     norm  4.856812959269508
256     norm 5.3982910143166514
257     norm 46.553976273304215
258     norm 17.566272518985429
259     norm 20.552451905814117
260     norm 61.894775704479279

The latter will put norm to the same column as months. Is it intended?

Maybe you want

> dd.m1<-melt(dataset[,-13], na.rm=T)
No id variables; using all as measure variables
> head(dd.m1)
  variable value
1  januari  38.1
2  januari  32.4
3  januari  34.5
4  januari  20.7
5  januari  21.5
6  januari  23.1
> tail(dd.m1)
    variable value
235 december  20.7
236 december  30.9
237 december  36.2
238 december  21.0
239 december  20.2
240 december  21.3

Cheers
Petr

From: Joachim Audenaert [mailto:Joachim.Audenaert at pcsierteelt.be]
Sent: Thursday, April 16, 2015 1:13 PM
To: PIKAL Petr
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: RE: [R] melt function chooses wrong id variable with large datasets

Hello,

This is a part of my dataset:

structure(list(januari = c(38.1, 32.4, 34.5, 20.7, 21.5, 23.1,
29.7, 36.6, 36.1, 20.6, 20.4, 30.1, 38.7, 41.4, 37, 36, 37, 38,
23, 26.7), februari = c(31.5, 36.2, 38.2, 26.4, 20.9, 21.5, 30.2,
33.4, 32.6, 22.2, 21.7, 30, 35.7, 32.8, 39.3, 25.5, 23, 19.9,
21.3, 20.8), maart = c(34.2, 27, 24.2, 19.9, 19.7, 21.5, 30.6,
30, 19, 19.6, 20.6, 23.6, 17.9, 17.3, 21.4, 24.1, 20.9, 30.1,
32.6, 21.3), april = c(26.3, 29.6, 30.3, 23.6, 28.4, 20.7, 24.1,
27.3, 23.2, 18.3, 24.6, 27.4, 20.4, 18.1, 25.2, 19.8, 21, 23.7,
19.6, 18.1), mei = c(23.7, 24, 17.2, 23.2, 25.2, 17.2, 16, 15.6,
13.4, 16, 16.8, 14.6, 19.4, 21, 19.5, 18.5, 13.3, 13.7, 14.3,
14.1), juni = c(17.7, 14.2, 16.6, 15.7, 13.7, 14.7, 13.1, 12.9,
15.4, 11.9, 15.2, 15.3, 16.5, 16.1, 11.7, 11.2, 11.5, 10.8, 16.1,
14.8), juli = c(15.7, 14.5, 10.8, 10.5, 13.4, 12.2, 13.2, 13,
12.4, 13.1, 9.8, 10.5, 13.4, 11, 13.1, 15, 16.7, 16.1, 18.2,
15.7), augustus = c(12.9, 12.8, 15.2, 14.5, 17.2, 14.5, 14.4,
11, 13.1, 13.6, 14.6, 12.7, 13.6, 12.7, 15.5, 17.4, 15.2, 14.2,
17.7, 19.2), september = c(15.6, 15.5, 15.9, 15.1, 16, 19.4,
21.5, 23.7, 18.7, 23.8, 18, 16.2, 18.5, 20.6, 18.3, 22.5, 26.9,
19.4, 15.9, 20.5), oktober = c(21.4, 20.8, 14, 17, 23, 26.4,
19.6, 22.7, 26.9, 14.7, 15.2, 19.8, 26.9, 20.2, 14.3, 14.8, 18.5,
21.7, 21.4, 21.8), november = c(24.7, 26.2, 29, 21.6, 17.1, 16.9,
19.1, 24.7, 25.4, 19.8, 18.2, 16.3, 17, 17.7, 15.5, 14.7, 15.8,
19.9, 20.4, 23.3), december = c(19.8, 27, 21, 33, 22.6, 28.3,
21.1, 19, 17.3, 27, 30.2, 24.8, 17.9, 17.9, 20.7, 30.9, 36.2,
21, 20.2, 21.3), norm = c("45.8713463281901", "24.047250681782984",
"3.7533684144746324", "38.594241119279324", "26.391897460120358",
"61.746470001194638", "6.8321020448487992", "11.933109250115226",
"51.951891096493924", "37.424611852237945", "5.1587836676942374",
"36.552835044409434", "31.781209673851027", "29.09146215582853",
"4.856812959269508", "5.3982910143166514", "46.553976273304215",
"17.566272518985429", "20.552451905814117", "61.894775704479279"
)), .Names = c("januari", "februari", "maart", "april", "mei",
"juni", "juli", "augustus", "september", "oktober", "november",
"december", "norm"), row.names = c(NA, 20L), class = "data.frame")

I transform my dataset with the following script:

y <- melt(dataset,na.rm=TRUE)
variable <- y[,1]
value <- y[,2]

and can then perform a levene test as follows:

LEVENE <- leveneTest(value~variable,y)

When the dataset is small, lets say less than 100 values per column everything works great. I get the message:

No id variables; using all as measure variables

When the dataset is much bigger I get the following message

Using norm as id variables, why does this function pick norm as id variable? and how can I tell R that each column title is my variable


Met vriendelijke groeten - With kind regards,

Joachim Audenaert
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

________________________________


Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be<mailto:joachim.audenaert at pcsierteelt.be> | W: www.pcsierteelt.be<http://www.pcsierteelt.be/>



From:        PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
To:        Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be<mailto:Joachim.Audenaert at pcsierteelt.be>>, "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Date:        16/04/2015 12:13
Subject:        RE: [R]  melt function chooses wrong id variable with large datasets

________________________________




Hi

There is something weird with your data and melt function.

AFAIK melt does not use first row as id.variables.

What is result of

str(dataset)

Instead of

melt(dataset,id.vars=dataset[1,], na.rm=TRUE)

melt expects something like

melt(dataset, id.vars=c("norm, "jaar"), na.rm=TRUE)

If you want more specific answer you shall show us part of your data, preferably copy output of

dput(dataset[1:20,])

into your mail.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 16, 2015 11:37 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] melt function chooses wrong id variable with large
> datasets
>
> Hello all,
>
> I'm using a large dataset consisting of 2 groups of data, 2 columns in
> excel with a header (group name) and 15 000 rows of data. I would like
> like to compare this data, so I transform my dataset with the melt
> function to get 1 column of data and 1 column of ID variables, then I
> can apply different statistical tests. With small datasets this works
> great, the melt function automatically chooses the name in row 1 as ID
> variable and melts the data, thus giving me a matrix with all ID
> variables in column one and the data accordingly in column 2.
> With this big dataset however it chooses the whole first column as ID
> variables in stead of the first row. Is there a reason why this happens
> and how can I make sure the first row is chosen as ID variabele and the
> lower rows as data?
>
> If I specify that I want the first row to be the id variable I also get
> error.
>
> melt(dataset,id.vars=dataset[1,], na.rm=TRUE)
>
> Error: id variables not found in data: norm, jaar
>
> Are there alternative ways to create a good reshaped dataset?
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be<mailto:joachim.audenaert at pcsierteelt.be> | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? |
> Het PCS op LinkedIn Disclaimer | Please consider the environment before
> printing. Think green, keep it on the screen!
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd?<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/32795D6E62E2F6A8C1257DCE002F4A44?opendocument> | Het PCS op LinkedIn<http://www.linkedin.com/company/proefcentrum-voor-sierteelt>
Disclaimer<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/EABE6EFE9E0C1C55C1257AD100322499> | Please consider the environment before printing. Think green, keep it on the screen!



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd?<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/32795D6E62E2F6A8C1257DCE002F4A44?opendocument> | Het PCS op LinkedIn<http://www.linkedin.com/company/proefcentrum-voor-sierteelt>
Disclaimer<http://www.pcsierteelt.be/hosting/pcs/pcs_site.nsf/0/EABE6EFE9E0C1C55C1257AD100322499> | Please consider the environment before printing. Think green, keep it on the screen!

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Fri Apr 17 11:36:02 2015
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 17 Apr 2015 17:36:02 +0800
Subject: [R] [off-topic] R Homepage
Message-ID: <5530D402.6000907@yeah.net>

Hi there,

It's a off-topic post. It seems that the R home page changed a lot. 
There are no plot at the right frame. Why are they removed? Will it or 
an alternative be back in future?

Another question is about the ``What's New?'' page. The latest 
announcement is not archived in that page. In the last year, I always 
checked the latest announcement from that page. It's updated in time 
than http://cran.r-project.org/doc/manuals/r-release/NEWS.html

Best,
Jinsong


From petr.pikal at precheza.cz  Fri Apr 17 11:40:31 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Apr 2015 09:40:31 +0000
Subject: [R] How to calculate vif of each term of model in R?
In-Reply-To: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29994@SRVEXCHMBX.precheza.cz>

Hi

I did not see any answer so I try.

Your question lacks some info:

Which vif - car or HH?

answers and comments in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Methekar, Pushpa (GE Transportation, Non-GE)
> Sent: Wednesday, April 08, 2015 10:24 AM
> To: r-help at r-project.org
> Subject: [R] How to calculate vif of each term of model in R?
>
>
> I am beginner in R doing modelling in R, I loaded excel sheet in R, i
> have chosen x elements and y elements then fitted model for linear and
> second order regression. Now I have both models. I am bit confused how
> to calculate vif for each term in model like
>
> e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package then it's
> giving me like
>
>     vif(model1)
>
>        x1         x2         x3         x4         x5         x6
> x7
>
>  6.679692   1.520271   1.667125   3.618439   4.931810   2.073879
> 13.870630
>
>         x8         x9
>
>    220.969628 214.034135
>
> now i want to compare each term with std vif as vif>=10 and which will
> satisfy this condition i want to delete that term and update model1. i
> have done something like this
>
> fun = function(model1) {
>
>  for(i in 1:length(model1))    {
>
>       v=vif(model1)
>
>          ss=any(v[i]>=10)

here you select only one item from vif, Why do you use any?

>
>                 if(ss==1){update(model1,.~.,-v[i])}
>
>                 else{print("no update")}
>

Why do you change i here?

>                  i<-i+1
>
>     }
>
>
>
>         return(model1)
>
>       }
>

if you want to get rid of all terms bigger than some threshold in once you can use

sel <- which(vif(model1)>10)

and select values for update possibly by

update(model1,.~. - names(vif(model1))[sel])

or if you want to get rid one by one you can use

vmax <- which.max(vif(model1))
and check if max vif value is bigger than 10.

vif(model1)[vmax]>=10

If it is just update with

- names(vif(model1))[vmax])

if it is not do not update.

All of this untested.

Cheers
Petr

> fun(model1)
>
> but giving error as
>
> Error in if (ss == 1) { : missing value where TRUE/FALSE needed.
>
> please tell me how do i solve this problem.
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Apr 17 12:07:34 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Apr 2015 10:07:34 +0000
Subject: [R] How to calculate vif of each term of model in R?
In-Reply-To: <9C74639432B50946BF93B535048331619D883E@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29994@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D883E@LONURLNA15.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C299D7@SRVEXCHMBX.precheza.cz>

Did you follow my advice/comments?

Cheers
Petr


> -----Original Message-----
> From: Methekar, Pushpa (GE Transportation, Non-GE)
> [mailto:pushpa.methekar at ge.com]
> Sent: Friday, April 17, 2015 11:43 AM
> To: PIKAL Petr
> Subject: RE: How to calculate vif of each term of model in R?
>
> Car package
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, April 17, 2015 3:11 PM
> To: Methekar, Pushpa (GE Transportation, Non-GE); r-help at r-project.org
> Subject: RE: How to calculate vif of each term of model in R?
>
> Hi
>
> I did not see any answer so I try.
>
> Your question lacks some info:
>
> Which vif - car or HH?
>
> answers and comments in line
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Methekar, Pushpa (GE Transportation, Non-GE)
> > Sent: Wednesday, April 08, 2015 10:24 AM
> > To: r-help at r-project.org
> > Subject: [R] How to calculate vif of each term of model in R?
> >
> >
> > I am beginner in R doing modelling in R, I loaded excel sheet in R, i
> > have chosen x elements and y elements then fitted model for linear
> and
> > second order regression. Now I have both models. I am bit confused
> how
> > to calculate vif for each term in model like
> >
> > e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package then
> it's
> > giving me like
> >
> >     vif(model1)
> >
> >        x1         x2         x3         x4         x5         x6
> > x7
> >
> >  6.679692   1.520271   1.667125   3.618439   4.931810   2.073879
> > 13.870630
> >
> >         x8         x9
> >
> >    220.969628 214.034135
> >
> > now i want to compare each term with std vif as vif>=10 and which
> will
> > satisfy this condition i want to delete that term and update model1.
> i
> > have done something like this
> >
> > fun = function(model1) {
> >
> >  for(i in 1:length(model1))    {
> >
> >       v=vif(model1)
> >
> >          ss=any(v[i]>=10)
>
> here you select only one item from vif, Why do you use any?
>
> >
> >                 if(ss==1){update(model1,.~.,-v[i])}
> >
> >                 else{print("no update")}
> >
>
> Why do you change i here?
>
> >                  i<-i+1
> >
> >     }
> >
> >
> >
> >         return(model1)
> >
> >       }
> >
>
> if you want to get rid of all terms bigger than some threshold in once
> you can use
>
> sel <- which(vif(model1)>10)
>
> and select values for update possibly by
>
> update(model1,.~. - names(vif(model1))[sel])
>
> or if you want to get rid one by one you can use
>
> vmax <- which.max(vif(model1))
> and check if max vif value is bigger than 10.
>
> vif(model1)[vmax]>=10
>
> If it is just update with
>
> - names(vif(model1))[vmax])
>
> if it is not do not update.
>
> All of this untested.
>
> Cheers
> Petr
>
> > fun(model1)
> >
> > but giving error as
> >
> > Error in if (ss == 1) { : missing value where TRUE/FALSE needed.
> >
> > please tell me how do i solve this problem.
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From g.rudge at bham.ac.uk  Fri Apr 17 13:19:01 2015
From: g.rudge at bham.ac.uk (gavinr)
Date: Fri, 17 Apr 2015 04:19:01 -0700 (PDT)
Subject: [R] Extracting xml data to data frames
In-Reply-To: <B8D87DA108D62D448DBE22A7775AB6BB881574CA@EX7.adf.bham.ac.uk>
References: <B8D87DA108D62D448DBE22A7775AB6BB881574CA@EX7.adf.bham.ac.uk>
Message-ID: <1429269541664-4705981.post@n4.nabble.com>

Hi I will re-post using dput to recreate the xml file.  I will need some time
to find a small enough file that demonstrates the problem.

Gavin R.



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-xml-data-to-data-frames-tp4705964p4705981.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Fri Apr 17 13:55:01 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Apr 2015 11:55:01 +0000
Subject: [R] How to calculate vif of each term of model in R?
In-Reply-To: <9C74639432B50946BF93B535048331619D8874@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29994@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D883E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C299D7@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D885E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29A0D@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D8874@LONURLNA15.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29AAB@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: Methekar, Pushpa (GE Transportation, Non-GE)
> [mailto:pushpa.methekar at ge.com]
> Sent: Friday, April 17, 2015 1:12 PM
> To: PIKAL Petr
> Subject: RE: How to calculate vif of each term of model in R?
>
> Hi Petr,
> You got my problem ,the solution which u specified is little good but
> with
>
>
> >update(model1,.~. - names(vif(model1))[vmax])
>
>
>
> I won't be able to update my model .
> Instead I have to write like
>
>
> > update(model1,.~. - x8)
>

maybe something like

fun = function(model1) {

vmax <- which.max(vif(model1))

while( vif(model1)[vmax]>=10) {

model1 <- update(model1,.~. - names(vif(model1))[vmax]))
vmax <- which.max(vif(model1))

}

return(model1)

}

I am not sure about cycle (i did not use while in R for a while).

Without some data I cannot check syntax so it is up to you.

Cheers
Petr


>
> i.e my x which having highest vif value.
> Each time for removing highest x .i  have to explicitly write ......-
> x8) So is there any way to avoid this?
>
>
>
>
> Thanks,
> Pushpa
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, April 17, 2015 4:16 PM
> To: Methekar, Pushpa (GE Transportation, Non-GE)
> Subject: RE: How to calculate vif of each term of model in R?
>
> Comments to your first mail which are among lines and directly related
> to your code.
>
> I specifically mentioned it
>
> > answers and comments in line
>
> If you have my first respond you can find them easier then now as they
> are buried within your mail.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > [mailto:pushpa.methekar at ge.com]
> > Sent: Friday, April 17, 2015 12:10 PM
> > To: PIKAL Petr
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > What comments are you talking about?
> >
> > -----Original Message-----
> > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > Sent: Friday, April 17, 2015 3:38 PM
> > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > Cc: r-help at r-project.org
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > Did you follow my advice/comments?
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > [mailto:pushpa.methekar at ge.com]
> > > Sent: Friday, April 17, 2015 11:43 AM
> > > To: PIKAL Petr
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > Car package
> > >
> > > -----Original Message-----
> > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > Sent: Friday, April 17, 2015 3:11 PM
> > > To: Methekar, Pushpa (GE Transportation, Non-GE); r-help at r-
> > project.org
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > Hi
> > >
> > > I did not see any answer so I try.
> > >
> > > Your question lacks some info:
> > >
> > > Which vif - car or HH?
> > >
> > > answers and comments in line
> > >
> > > > -----Original Message-----
> > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > > Methekar, Pushpa (GE Transportation, Non-GE)
> > > > Sent: Wednesday, April 08, 2015 10:24 AM
> > > > To: r-help at r-project.org
> > > > Subject: [R] How to calculate vif of each term of model in R?
> > > >
> > > >
> > > > I am beginner in R doing modelling in R, I loaded excel sheet in
> > > > R, i have chosen x elements and y elements then fitted model for
> > linear
> > > and
> > > > second order regression. Now I have both models. I am bit
> confused
> > > how
> > > > to calculate vif for each term in model like
> > > >
> > > > e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package then
> > > it's
> > > > giving me like
> > > >
> > > >     vif(model1)
> > > >
> > > >        x1         x2         x3         x4         x5         x6
> > > > x7
> > > >
> > > >  6.679692   1.520271   1.667125   3.618439   4.931810   2.073879
> > > > 13.870630
> > > >
> > > >         x8         x9
> > > >
> > > >    220.969628 214.034135
> > > >
> > > > now i want to compare each term with std vif as vif>=10 and which
> > > will
> > > > satisfy this condition i want to delete that term and update
> > model1.
> > > i
> > > > have done something like this
> > > >
> > > > fun = function(model1) {
> > > >
> > > >  for(i in 1:length(model1))    {
> > > >
> > > >       v=vif(model1)
> > > >
> > > >          ss=any(v[i]>=10)
> > >
> > > here you select only one item from vif, Why do you use any?
> > >
> > > >
> > > >                 if(ss==1){update(model1,.~.,-v[i])}
> > > >
> > > >                 else{print("no update")}
> > > >
> > >
> > > Why do you change i here?
> > >
> > > >                  i<-i+1
> > > >
> > > >     }
> > > >
> > > >
> > > >
> > > >         return(model1)
> > > >
> > > >       }
> > > >
> > >
> > > if you want to get rid of all terms bigger than some threshold in
> > once
> > > you can use
> > >
> > > sel <- which(vif(model1)>10)
> > >
> > > and select values for update possibly by
> > >
> > > update(model1,.~. - names(vif(model1))[sel])
> > >
> > > or if you want to get rid one by one you can use
> > >
> > > vmax <- which.max(vif(model1))
> > > and check if max vif value is bigger than 10.
> > >
> > > vif(model1)[vmax]>=10
> > >
> > > If it is just update with
> > >
> > > - names(vif(model1))[vmax])
> > >
> > > if it is not do not update.
> > >
> > > All of this untested.
> > >
> > > Cheers
> > > Petr
> > >
> > > > fun(model1)
> > > >
> > > > but giving error as
> > > >
> > > > Error in if (ss == 1) { : missing value where TRUE/FALSE needed.
> > > >
> > > > please tell me how do i solve this problem.
> > > >
> > > >
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> > > > guide.html and provide commented, minimal, self-contained,
> > > > reproducible code.
> > >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From macqueen1 at llnl.gov  Fri Apr 17 17:27:38 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Apr 2015 15:27:38 +0000
Subject: [R] assign variables to function output
In-Reply-To: <1429136250774-4705920.post@n4.nabble.com>
References: <1429136250774-4705920.post@n4.nabble.com>
Message-ID: <D156716C.125BFD%macqueen1@llnl.gov>

I don't disagree with the other answers, but I'd like to talk about what I
see as a more underlying issue.

Generally speaking, functions return the value of the last expression
within them.

myfun <- function(x) {
  z <- sqrt(x)
  2
}

Then
 y <- myfun(7)
assigns 2 to y because 2 was the last expression in the function.

myfun <- function(z) {
 cat('inside myfun\n')
 y <- z-7
 x <- 2*z
 sqrt(z)
}

  y <- myfun(c(1,4,9))

assigns c(1,2,3) to y because sqrt(z) was the last expression. x and y are
lost and gone forever.

Note that return() was not used, and does not need to be used.

Thus, if you want to return something that includes some of the variables
introduced inside the function, you gather them into a suitable structure
and make that the last expression in the function.

myfun <- function(z) {
  y <- z-7
  x <- 2*z
  list(x=x, y=y, rtz=sqrt(z))
}

Then y <- myfun(4) returns a list with three elements whose values are -3,
8, and 2.

Again no use of return(). There are cases where return() is useful, but it
is not needed in simple cases like these.
(and I can't imagine what's awkward about using return(value), but that's
another question)


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/15/15, 3:17 PM, "merm" <pionescu at student.unimelb.edu.au> wrote:

>Hi!
>
>So I'm trying as the header suggests to assign the value(s) output by a
>function to a variable, say 'y'
>
>Problem is from what I gather any variables introduced within the function
>are contained and the only output I can get is "return(value)" which is
>awkward to work with. Any suggestions?
>
>Cheers!
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/assign-variables-to-function-output-tp470592
>0.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From iryna.v.nikolayeva at gmail.com  Fri Apr 17 11:25:39 2015
From: iryna.v.nikolayeva at gmail.com (Iryna Nikolayeva)
Date: Fri, 17 Apr 2015 11:25:39 +0200
Subject: [R] issue with package updates
Message-ID: <2DCFECB3-B87C-42D9-A65F-495210097E78@gmail.com>

Dear R project members,
I have an issue while automatically updating packages.
For the packages installed in my second library, while automatically updating I get the following "Permission denied? messages(details below).
I suppose I know where this problem comes from:
I had installed a few different versions of R. 
And now I have 2 library paths: 
> .libPaths()
[1] "/Users/iryna/Library/R/3.1/library"                                      
[2] "/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library?

And for some reason R just doesn?t have rights to update packages in my second library.
Do you know why is that? How should I fix this issue? 

Here is the error message:

* installing *source* package ?mgcv? ...
** package ?mgcv? successfully unpacked and MD5 sums checked
mv: rename /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/00LOCK-mgcv/mgcv: Permission denied
Warning in file.copy(f, instdir, TRUE) :
  problem copying ./NAMESPACE to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/NAMESPACE: Permission denied
Warning in file(file, ifelse(append, "a", "w")) :
  cannot open file '/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/DESCRIPTION': Permission denied
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
ERROR: installing package DESCRIPTION failed for package ?mgcv?
* removing ?/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv?




Here are some additional information on my settings:
> version
               _                           
platform       x86_64-apple-darwin13.4.0   
arch           x86_64                      
os             darwin13.4.0                
system         x86_64, darwin13.4.0        
status                                     
major          3                           
minor          1.2                         
year           2014                        
month          10                          
day            31                          
svn rev        66913                       
language       R                           
version.string R version 3.1.2 (2014-10-31)
nickname       Pumpkin Helmet  

Thanks in advance for your help,
?

Iryna Nikolayeva


From assaf at uw.edu  Fri Apr 17 17:50:46 2015
From: assaf at uw.edu (Assaf P. Oron)
Date: Fri, 17 Apr 2015 08:50:46 -0700
Subject: [R] Are '1st decimal' R rollouts (e.g. 3.2.0) qualitatively
	different?
Message-ID: <CAEGxr5Dr81T+GGhe9=Gs7HtVWQQ4jrkOVtFQFq9GhE5pLrtEQw@mail.gmail.com>

Hi all,

With the upcoming 3.2.0 upgrade, the question came up among my students,
how often a regular user who is not a cutting-edge developer "must" upgrade
their R, given that on Windows/Mac this includes the inconvenience of
re-installing dozens of packages.

In this context, I was wondering whether the annual '1st decimal' upgrade
like 3.2.0 is qualitatively different from the interim ones like 3.1.3. In
other words, whether some changes are reserved for those annual upgrades,
or whether all upgrades are essentially equivalent.

Thanks!

Assaf

-- 
Assaf P. Oron, Ph.D.
Senior Statistician, Children's Core for Biomedical Statistics
(206)884-1236, assaf.oron at seattlechildrens.org
------------
Consulting statistician, Seattle DEEDS Project
http://www.duwamishdiesel.org/
Instructor, UW Certificate for Statistical Analysis with R
assaf at uw.edu

	[[alternative HTML version deleted]]


From kshav.91 at gmail.com  Fri Apr 17 18:44:05 2015
From: kshav.91 at gmail.com (Keshav Dhandhania)
Date: Fri, 17 Apr 2015 16:44:05 +0000
Subject: [R] Fast multiple match function
In-Reply-To: <1DABB053-C0EE-4EC8-916F-F5ED2ACB95FB@dcn.davis.CA.us>
References: <CAO3abBpqzoi+6M+e+NBhPHd_wy6tRnLCB_yb79CvzRiMZYHYmQ@mail.gmail.com>
	<55243C5F.7060000@fredhutch.org>
	<CAO3abBrSASVERgRScjW=Ujp1J_U0x9K9AyPiXGQHmsZJ-tLR+Q@mail.gmail.com>
	<1DABB053-C0EE-4EC8-916F-F5ED2ACB95FB@dcn.davis.CA.us>
Message-ID: <CAO3abBq2EXRN_3i=R+3Qqzqg5eC1woQJ8UFD9E0txEFJb5iebg@mail.gmail.com>

Hi Jeff,

Indeed the data.table package does provide a much cleaner way to achieve
the same functionality, and a lot of other functionality as bonus.

Thanks for letting me know about it.

On Tue, 7 Apr 2015 at 15:41 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> You might find the data.table package helpful. It uses an index sorted
> with a radix sort and minimizes moving the data around in memory.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 7, 2015 1:50:39 PM PDT, Keshav Dhandhania <kshav.91 at gmail.com>
> wrote:
> >Hi all,
> >
> >Thanks for the responses.
> >Herve's example is a good small size example of what I wanted.
> >
> >> y <- c(16, -3, -2, 15, 15, 0, 8, 15, -2)
> >> someCoolFunc(-2, y)
> >[1] 3 9
> >> someCoolFunc(15, y)
> >[1] 4 5 8
> >
> >The requirement is that I want someCoolFunc() to run in O(number of
> >matches) time, instead of O(size of y).
> >This is because y is big. And I don't know all the queries I want to
> >do up-front. And the results of some queries might change the queries
> >I want to do in the future.
> >
> >@David: I hope the above description is more clear.
> >@Enrico, Herve: I want both the functionality provided by one function.
> >- On repeated calls, fmatch() does give O(1) performance, but it does
> >not give all matches.
> >- findMatches() gives all matches, but I need to know the entire
> >vector x beforehand. I don't have that luxury.
> >
> >
> >I do have something that works now, using split and fmatch (package
> >fastmatch). So just posting that in case anyone in the future has the
> >same problem.
> >> y.unique <- unique(y)
> >>
> >> # create a map from the unique elements of y to the locations of all
> >occurrences of the element
> >> y.map <- split(1:length(y), match(y, y.unique))
> >>
> >> # write a wrapper function that does a look-up on the unique list.
> >and then returns all matches using the map.
> >> someCoolFunc <- function(x) { y.map[[ fmatch(x, y.unique) ]] }
> >
> >
> >
> >On Tue, 7 Apr 2015 at 13:21 Herv? Pag?s <hpages at fredhutch.org> wrote:
> >>
> >> Hi Keshav,
> >>
> >> findMatches() in the S4Vectors/IRanges packages (Bioconductor) I
> >think
> >> does what you want:
> >>
> >>    library(IRanges)
> >>    y <- c(16L, -3L, -2L, 15L, 15L, 0L, 8L, 15L, -2L)
> >>    x <- c(unique(y), 999L)
> >>    hits <- findMatches(x, y)
> >>
> >> Then:
> >>
> >>    > hits
> >>    Hits object with 9 hits and 0 metadata columns:
> >>          queryHits subjectHits
> >>          <integer>   <integer>
> >>      [1]         1           1
> >>      [2]         2           2
> >>      [3]         3           3
> >>      [4]         3           9
> >>      [5]         4           4
> >>      [6]         4           5
> >>      [7]         4           8
> >>      [8]         5           6
> >>      [9]         6           7
> >>      -------
> >>      queryLength: 7
> >>      subjectLength: 9
> >>
> >> The Hits object can be turned into a list with:
> >>
> >>    > as.list(hits)
> >>    [[1]]
> >>    [1] 1
> >>
> >>    [[2]]
> >>    [1] 2
> >>
> >>    [[3]]
> >>    [1] 3 9
> >>
> >>    [[4]]
> >>    [1] 4 5 8
> >>
> >>    [[5]]
> >>    [1] 6
> >>
> >>    [[6]]
> >>    [1] 7
> >>
> >>    [[7]]
> >>    integer(0)
> >>
> >> H.
> >>
> >>  > sessionInfo()
> >> R version 3.2.0 beta (2015-04-05 r68151)
> >> Platform: x86_64-unknown-linux-gnu (64-bit)
> >> Running under: Ubuntu 14.04.2 LTS
> >>
> >> locale:
> >>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] parallel  stats4    stats     graphics  grDevices utils
> >datasets
> >> [8] methods   base
> >>
> >> other attached packages:
> >> [1] IRanges_2.1.43       S4Vectors_0.5.22     BiocGenerics_0.13.11
> >>
> >> loaded via a namespace (and not attached):
> >> [1] tools_3.2.0
> >>
> >> On 04/06/2015 01:56 PM, Keshav Dhandhania wrote:
> >> > Hi,
> >> >
> >> > I know that one can find all occurrences of x in a vector v by
> >doing
> >> >> which(x == v).
> >> >
> >> > However, if I need to do this again and again, where v is remaining
> >the
> >> > same, then this is quite inefficient. In my particular case, I need
> >to do
> >> > this millions of times, and length(v) = 100 million.
> >> >
> >> > Does anyone have suggestion on how to go about it?
> >> > I know of a package called fmatch that does the above for the match
> >> > function. But they don't handle multiple matches.
> >> >
> >> > Thanks
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >> --
> >> Herv? Pag?s
> >>
> >> Program in Computational Biology
> >> Division of Public Health Sciences
> >> Fred Hutchinson Cancer Research Center
> >> 1100 Fairview Ave. N, M1-B514
> >> P.O. Box 19024
> >> Seattle, WA 98109-1024
> >>
> >> E-mail: hpages at fredhutch.org
> >> Phone:  (206) 667-5791
> >> Fax:    (206) 667-1319
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From paul.domaskis at gmail.com  Thu Apr 16 21:30:07 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 19:30:07 +0000
Subject: [R] =?utf-8?q?R=3A_Idea_behind_=2EFirst=28=29_vs=2E_=7E/=2ERprofi?=
	=?utf-8?q?le?=
Message-ID: <loom.20150416T212859-247@post.gmane.org>

I'm ramping up on R, and reading
http://stuff.mit.edu/afs/sipb/project/r-
project/lib/R/library/base/html/Startup.html.
I'm probably wrong about this, but ~/.Rprofile seems to serve the same
purpose as a .First() function.  Why do both exist, and what
considerations go into a decision to choose one over the other for
startup code?


From paul.domaskis at gmail.com  Thu Apr 16 23:02:00 2015
From: paul.domaskis at gmail.com (paul)
Date: Thu, 16 Apr 2015 21:02:00 +0000
Subject: [R] Need online version of R help pages
Message-ID: <loom.20150416T230116-747@post.gmane.org>

The help for the cygwin port of R is buggy and hides random lines of
text.  Consquently, I've been relying on Google, but it is often not
clear how directly relevant the info is for the specific command that
I'm using.  For example, reshape is complicated, and has more than 1
version.

Is there an online version of the help pages?

I tried looking for html versions of the help pages by ferruting
through the R.home() subtree.  Haven't found them so far.  There are
package pages in subdirectories <package>/html/00Index.html, but they
just contain links to html files that don't reside in my R.home()
subtree.  There are also subdirectories <package>/help, but they
contain pages that I don't recognize (*.rds, *.rdb, *.rdx).

Getting desparate here, and realizing how the web is not in any way a
substituted for locally available help pages that you can be confident
is right for your installation.


From paul.domaskis at gmail.com  Fri Apr 17 16:17:11 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 10:17:11 -0400
Subject: [R] vi[m] editing of past commands in R command line
Message-ID: <CABSksF_0k39E5VHYZxqthbZe-xpKqZwe5sP_Ms7Mmmo1evODcQ@mail.gmail.com>

I've been told that my messages are being rejected because it is being
posted via nabble in HTML format.  I was advised to re-send this
directly to r-help at r-project.org.  My apologies if you get this twice.

When I use bash + readline and ~/.inputrc contains "editing-mode vi",
I can press "v" to switch to from the command line editing to a full
vi session editing of a command.  This doesn't seem to happen in R.
Is there a configuration setting/file that I can set to get this
behaviour?

Furthermore, when using bash, the fc command allows me to edit the
history of commands, and when I exit the editor, all the remaining
(and likely modified) commands are submitted to the bash shell as if I
typed them at the prompt.  Is there a way to get similar functionality
in R?


From paul.domaskis at gmail.com  Fri Apr 17 16:39:22 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 10:39:22 -0400
Subject: [R] "R": Redefine default parameter values for help.start()
Message-ID: <CABSksF_FoYQNzuj+oGGmEBuVUpnBXUeEEv3beA+0_coA_BdZew@mail.gmail.com>

Martin Maechler <maechler <at> lynne.stat.math.ethz.ch> writes:
> >>>>> paul  <paul.domaskis <at> gmail.com>
> >>>>>     on Thu, 16 Apr 2015 18:58:12 +0000 writes:
>
>     > Because of the setup of R in cygwin, help.start() requires
>     > the following parameter values:
>
>     > help.start(browser="cygstart",remote=R.home())
>
>     > Is it possible to make these values the default?
>
> You are building R from the sources, right?

No.  I haven't compiled code in a decade, but maybe I should get
back into that.  It won't happen soon, though -- the situation is
that the current cygwin install can't be changed, so installing isn't
an option, at least in the immediate term.  Also, expectations in
terms of time is such that getting a Windows based R would be
preferrable over compiling from scratch, though I must admit that
the latter won't happen any time soon either.

> Then, of course it is easily possible: Just modify your version
> of the R source code appropriately:
>
> It is file  <R>/src/library/utils/R/help.start.R
>
> (And you need more changes anyway to make things work under Cygwin;
>  but don't ask me about it: I do run R on Windows only very rarely)

OK, so now I'm not sure I follow.  By source, I normally think C.  But
the file extension above is *.R.  So I tried to take a look at the
file to see what kind of source it is. I can only descend down to
/usr/lib/R/library/utils/R/utils because
/usr/lib/R/library/utils/R/utils is not a directory.  It is a file:

   #  File share/R/nspackloader.R
   #  Part of the R package, http://www.R-project.org
   #
   #  Copyright (C) 1995-2012 The R Core Team
   #
   #  This program is free software; you can redistribute it and/or modify
   #  it under the terms of the GNU General Public License as published by
   #  the Free Software Foundation; either version 2 of the License, or
   #  (at your option) any later version.
   #
   #  This program is distributed in the hope that it will be useful,
   #  but WITHOUT ANY WARRANTY; without even the implied warranty of
   #  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   #  GNU General Public License for more details.
   #
   #  A copy of the GNU General Public License is available at
   #  http://www.r-project.org/Licenses/

   local({
       info <- loadingNamespaceInfo()
       pkg <- info$pkgname
       ns <- .getNamespace(as.name(pkg))
       if (is.null(ns))
           stop("cannot find namespace environment for ", pkg, domain = NA);
       dbbase <- file.path(info$libname, pkg, "R", pkg)
       lazyLoad(dbbase, ns, filter = function(n) n != ".__NAMESPACE__.")
   })

I know that I have a lot to learn about R.

Anyway, for now, I am getting around the problem via the following
~/.Rprofile:

   options(papersize="letter")
   options(browser="cygstart")
   options(help_type="html")
   helpstart <- function(){help.start(browser="cygstart",remote=R.home())}
   require(astsa)

>     > I do not want cygstart to be the browser except as a
>     > parameter for help.start().


From paul.domaskis at gmail.com  Fri Apr 17 16:54:16 2015
From: paul.domaskis at gmail.com (paul)
Date: Fri, 17 Apr 2015 14:54:16 +0000
Subject: [R] "R": Redefine default parameter values for help.start()
References: <loom.20150416T205313-272@post.gmane.org>
	<21808.45046.152428.633822@stat.math.ethz.ch>
Message-ID: <loom.20150417T165359-166@post.gmane.org>

Martin Maechler <maechler <at> lynne.stat.math.ethz.ch> writes:
> >>>>> paul  <paul.domaskis <at> gmail.com>
> >>>>>     on Thu, 16 Apr 2015 18:58:12 +0000 writes:
>
>     > Because of the setup of R in cygwin, help.start() requires
>     > the following parameter values:
>
>     > help.start(browser="cygstart",remote=R.home())
>
>     > Is it possible to make these values the default?
>
> You are building R from the sources, right?

No.  I haven't compiled code in a decade, but maybe I should get
back into that.  It won't happen soon, though -- the situation is
that the current cygwin install can't be changed, so installing isn't
an option, at least in the immediate term.  Also, expectations in
terms of time is such that getting a Windows based R would be
preferrable over compiling from scratch, though I must admit that
the latter won't happen any time soon either.

> Then, of course it is easily possible: Just modify your version
> of the R source code appropriately:
>
> It is file  <R>/src/library/utils/R/help.start.R
>
> (And you need more changes anyway to make things work under Cygwin;
>  but don't ask me about it: I do run R on Windows only very rarely)

OK, so now I'm not sure I follow.  By source, I normally think C.  But
the file extension above is *.R.  So I tried to take a look at the
file to see what kind of source it is. I can only descend down to
/usr/lib/R/library/utils/R/utils because
/usr/lib/R/library/utils/R/utils is not a directory.  It is a file:

   #  File share/R/nspackloader.R
   #  Part of the R package, http://www.R-project.org
   #
   #  Copyright (C) 1995-2012 The R Core Team
   #
   #  This program is free software; you can redistribute it and/or modify
   #  it under the terms of the GNU General Public License as published by
   #  the Free Software Foundation; either version 2 of the License, or
   #  (at your option) any later version.
   #
   #  This program is distributed in the hope that it will be useful,
   #  but WITHOUT ANY WARRANTY; without even the implied warranty of
   #  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   #  GNU General Public License for more details.
   #
   #  A copy of the GNU General Public License is available at
   #  http://www.r-project.org/Licenses/

   local({
       info <- loadingNamespaceInfo()
       pkg <- info$pkgname
       ns <- .getNamespace(as.name(pkg))
       if (is.null(ns))
           stop("cannot find namespace environment for ", pkg, domain = NA);
       dbbase <- file.path(info$libname, pkg, "R", pkg)
       lazyLoad(dbbase, ns, filter = function(n) n != ".__NAMESPACE__.")
   })

I know that I have a lot to learn about R.

Anyway, for now, I am getting around the problem via the following
~/.Rprofile:

   options(papersize="letter")
   options(browser="cygstart")
   options(help_type="html")
   helpstart <- function(){help.start(browser="cygstart",remote=R.home())}
   require(astsa)

>     > I do not want cygstart to be the browser except as a
>     > parameter for help.start().


From paul.domaskis at gmail.com  Fri Apr 17 17:10:55 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 11:10:55 -0400
Subject: [R] project.org help mailing list the same as ethz.ch mailing list?
Message-ID: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>

The page http://www.r-project.org/mail.html says that the mailing list
is r-help_AT_R-project.org (with @ in place of _AT_), but the gmane
page http://gmane.org/list-address.php?group=gmane.comp.lang.r.general
has the mailing list as r-help_AT_stat.math.ethz.ch.

Are these different mailing lists?


From cflynch at ncsu.edu  Fri Apr 17 21:22:37 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Fri, 17 Apr 2015 15:22:37 -0400
Subject: [R] Need online version of R help pages
In-Reply-To: <loom.20150416T230116-747@post.gmane.org>
References: <loom.20150416T230116-747@post.gmane.org>
Message-ID: <CAE=6FXbonyKBOxf+mOqghwe8pgFZ4yAkBzQxVzXU5JjKU7D95Q@mail.gmail.com>

Hi Paul a quick search popped up these:

http://astrostatistics.psu.edu/datasets/R/html/index.html
http://finzi.psych.upenn.edu/
http://r.789695.n4.nabble.com/Online-R-documentation-td1009656.html

Are they what you are looking for?

    Collin.

On Thu, Apr 16, 2015 at 5:02 PM, paul <paul.domaskis at gmail.com> wrote:
> The help for the cygwin port of R is buggy and hides random lines of
> text.  Consquently, I've been relying on Google, but it is often not
> clear how directly relevant the info is for the specific command that
> I'm using.  For example, reshape is complicated, and has more than 1
> version.
>
> Is there an online version of the help pages?
>
> I tried looking for html versions of the help pages by ferruting
> through the R.home() subtree.  Haven't found them so far.  There are
> package pages in subdirectories <package>/html/00Index.html, but they
> just contain links to html files that don't reside in my R.home()
> subtree.  There are also subdirectories <package>/help, but they
> contain pages that I don't recognize (*.rds, *.rdb, *.rdx).
>
> Getting desparate here, and realizing how the web is not in any way a
> substituted for locally available help pages that you can be confident
> is right for your installation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul.domaskis at gmail.com  Fri Apr 17 21:30:17 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 15:30:17 -0400
Subject: [R] Need online version of R help pages
In-Reply-To: <CAE=6FXbonyKBOxf+mOqghwe8pgFZ4yAkBzQxVzXU5JjKU7D95Q@mail.gmail.com>
References: <loom.20150416T230116-747@post.gmane.org>
	<CAE=6FXbonyKBOxf+mOqghwe8pgFZ4yAkBzQxVzXU5JjKU7D95Q@mail.gmail.com>
Message-ID: <CABSksF8rUv_4cSxsY06RVR_S0gGUmpB_jfa3nwzq-zYi5N8t9w@mail.gmail.com>

On Fri, Apr 17, 2015 at 3:22 PM, Collin Lynch <cflynch at ncsu.edu> wrote:
> Hi Paul a quick search popped up these:
>
> http://astrostatistics.psu.edu/datasets/R/html/index.html
> http://finzi.psych.upenn.edu/
> http://r.789695.n4.nabble.com/Online-R-documentation-td1009656.html
>
> Are they what you are looking for?
>
>     Collin.

I was looking for a site where I could simply punch in the command and
get the "man" page without navigating & searching.  But I found a way
around my problem with the help in Cygwin's R port.  In ~/.Rprofile, I
have:

   options(browser="cygstart")
   options(help_type="html")


From sarah.goslee at gmail.com  Fri Apr 17 22:25:01 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 17 Apr 2015 16:25:01 -0400
Subject: [R] R: Idea behind .First() vs. ~/.Rprofile
In-Reply-To: <loom.20150416T212859-247@post.gmane.org>
References: <loom.20150416T212859-247@post.gmane.org>
Message-ID: <CAM_vjum9_EjaCtPNcdcLHtiny+jpL4TE5cJBCPpz395WVRHsOg@mail.gmail.com>

Hi,

On Thursday, April 16, 2015, paul <paul.domaskis at gmail.com> wrote:

> I'm ramping up on R, and reading
> http://stuff.mit.edu/afs/sipb/project/r-
> project/lib/R/library/base/html/Startup.html.
> I'm probably wrong about this, but ~/.Rprofile seems to serve the same
> purpose as a .First() function.  Why do both exist, and what
> considerations go into a decision to choose one over the other for
> startup code?


It's the timing and where the info comes from, as that document explains in
great detail.

.Rprofile is read on start-up unless R is specifically told to skip it.

.First() is sourced after it's loaded, and thus must be loaded from
somewhere such as an existing .RData file or a package.

~/.Rprofile is thus most convenient for things you want to have happen in
every R session, while .First() is useful for specific sessions loaded from
saved objects, or for constructing packages. Though on linux, I use a local
.Rprofile if I need per-session options, because I often don't have a saved
.RData file.

Sarah


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Apr 17 22:29:41 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 17 Apr 2015 16:29:41 -0400
Subject: [R] project.org help mailing list the same as ethz.ch mailing
	list?
In-Reply-To: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>
References: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>
Message-ID: <CAM_vjumyYEsM9grxDiXQMkELY_N96nQtL2DteyK755JC1h=eRQ@mail.gmail.com>

On Friday, April 17, 2015, Paul Domaskis <paul.domaskis at gmail.com> wrote:

> The page http://www.r-project.org/mail.html says that the mailing list
> is r-help_AT_R-project.org (with @ in place of _AT_), but the gmane
> page http://gmane.org/list-address.php?group=gmane.comp.lang.r.general
> has the mailing list as r-help_AT_stat.math.ethz.ch.
>
> Are these different mailing lists?


They are the same. r-help at r-project.org is the preferred address, but the
mailserver is run out of stat.ethz.ch.

Sarah

Useful info vvvv

> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Apr 17 22:29:41 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 17 Apr 2015 16:29:41 -0400
Subject: [R] project.org help mailing list the same as ethz.ch mailing
	list?
In-Reply-To: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>
References: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>
Message-ID: <CAM_vjumyYEsM9grxDiXQMkELY_N96nQtL2DteyK755JC1h=eRQ@mail.gmail.com>

On Friday, April 17, 2015, Paul Domaskis <paul.domaskis at gmail.com> wrote:

> The page http://www.r-project.org/mail.html says that the mailing list
> is r-help_AT_R-project.org (with @ in place of _AT_), but the gmane
> page http://gmane.org/list-address.php?group=gmane.comp.lang.r.general
> has the mailing list as r-help_AT_stat.math.ethz.ch.
>
> Are these different mailing lists?


They are the same. r-help at r-project.org is the preferred address, but the
mailserver is run out of stat.ethz.ch.

Sarah

Useful info vvvv

> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From paul.domaskis at gmail.com  Fri Apr 17 22:32:04 2015
From: paul.domaskis at gmail.com (paul)
Date: Fri, 17 Apr 2015 20:32:04 +0000
Subject: [R]
	=?utf-8?q?R=3A_Idea_behind_=2EFirst=28=29_vs=2E_=7E/=2ERprofi?=
	=?utf-8?q?le?=
References: <loom.20150416T212859-247@post.gmane.org>
	<CAM_vjum9_EjaCtPNcdcLHtiny+jpL4TE5cJBCPpz395WVRHsOg@mail.gmail.com>
Message-ID: <loom.20150417T222929-258@post.gmane.org>

Sarah Goslee <sarah.goslee <at> gmail.com> writes:
|On Thursday, April 16, 2015, paul <paul.domaskis <at> gmail.com>
|wrote:
|> I'm ramping up on R, and reading
|> http://stuff.mit.edu/afs/sipb/project/r-
|> project/lib/R/library/base/html/Startup.html.  I'm probably wrong
|> about this, but ~/.Rprofile seems to serve the same purpose as a
|> .First() function.  Why do both exist, and what considerations go
|> into a decision to choose one over the other for startup code?
|
| It's the timing and where the info comes from, as that document
| explains in great detail.
|
| .Rprofile is read on start-up unless R is specifically told to skip
| it.
|
| .First() is sourced after it's loaded, and thus must be loaded from
| somewhere such as an existing .RData file or a package.
|
| ~/.Rprofile is thus most convenient for things you want to have
| happen in every R session, while .First() is useful for specific
| sessions loaded from saved objects, or for constructing packages.
| Though on linux, I use a local .Rprofile if I need per-session
| options, because I often don't have a saved .RData file.

Thanks, Sarah.  Yes, the documentation has a great deal of detail, but
I needed was your explanation in the final paragraph of your response.


From paul.domaskis at gmail.com  Fri Apr 17 22:36:13 2015
From: paul.domaskis at gmail.com (paul)
Date: Fri, 17 Apr 2015 20:36:13 +0000
Subject: [R]
	=?utf-8?q?project=2Eorg_help_mailing_list_the_same_as_ethz=2E?=
	=?utf-8?q?ch_mailing=09list=3F?=
References: <CABSksF91UGU7rLfuo1NmK3bRuOQjbPMd5mAuMtZ4XFkLdn1Mwg@mail.gmail.com>
	<CAM_vjumyYEsM9grxDiXQMkELY_N96nQtL2DteyK755JC1h=eRQ@mail.gmail.com>
Message-ID: <loom.20150417T223439-138@post.gmane.org>

Sarah Goslee <sarah.goslee <at> gmail.com> writes:
>On Friday, April 17, 2015, Paul Domaskis <paul.domaskis <at>
>gmail.com> wrote:
>> The page http://www.r-project.org/mail.html says that the mailing
>> list is r-help_AT_R-project.org (with  <at>  in place of _AT_), but
>> the gmane page
>> http://gmane.org/list-address.php?group=gmane.comp.lang.r.general
>> has the mailing list as r-help_AT_stat.math.ethz.ch.
>>
>> Are these different mailing lists?
>
> They are the same. r-help <at> r-project.org is the preferred
> address, but the mailserver is run out of stat.ethz.ch.

Thanks again, Sarah.  Imagine my shock when that suspicion dawned on
me.  I expected to be banned for life for duplicate posts.


From marongiu.luigi at gmail.com  Sat Apr 18 00:23:34 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 17 Apr 2015 23:23:34 +0100
Subject: [R] Handling NA values in a if statement
Message-ID: <CAMk+s2SQ=Ggh8WGdjE-7XJmoirCpXKchb=xDx-AHSfT1dOa3Cg@mail.gmail.com>

Dear all,
I have a vector with a certain range of values including infinity and
NA. I would like to remove the values that are outside a given range
(lower level = ll and upper level = ul) but I am getting the error due
to the NA values (missing value where TRUE/FALSE needed). I then
included the !is.na() but now the resulting error is all NA, as in the
example.
In addition, here I have implemented a for loop to scan all the
elements of the vector, but I should be able to use the sapply();
however I don't know how to send the ll and ul arguments to sapply().
Could you please help?
best regards
Luigi

EXAMPLE

x <- c(-Inf,  Inf,    NA,    5.9,    6.08,    5281391136138.75,
4.35,    4.79,
       9474097322.96,    3.64,    16.42,    -12211.11,    4.37,
-1097.79,    4.78,
       3.71,    32.59,    4.01,    35.36,    3.17,    1.61,
-3678.28,    2.9,    4.67,
       4.1,    348410866.78,    5.35,    4.3101519459837E+016,
1467030866.75,
       1.10376094956278E+018,    32.55,    1.17,    5339028670388.94,
  34.14,
       33205967009.57,    4.42,    1.76,    7.08,    -8428.84,
-113491.08,    17.81)
ll <- 1
ul <- 45

clipper <- function(x, ll, ul) {
  for(i in 1:length(x)) {
    if(x[i] < ll) {
      x[i] <- NA
    } else if(x[i] > ul) {
      x[i] <- NA
    } else {
      x[i] <- x[i]
    }
  }
return(x)
}
(X<-clipper(x, ll, ul))
> missing value where TRUE/FALSE needed


clipper <- function(x, ll, ul) {
  for(i in 1:length(x)) {
    if(!is.na(x[i]) < ll) {
      x[i] <- NA
    } else if(!is.na(x[i]) > ul) {
      x[i] <- NA
    } else {
      x[i] <- x[i]
    }
  }
return(x)
}
(X<-clipper(x, ll, ul))

 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
NA NA NA NA NA
[28] NA NA NA NA NA NA NA NA NA NA NA NA NA NA


From marc_schwartz at me.com  Sat Apr 18 00:43:57 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 17 Apr 2015 17:43:57 -0500
Subject: [R] Handling NA values in a if statement
In-Reply-To: <CAMk+s2SQ=Ggh8WGdjE-7XJmoirCpXKchb=xDx-AHSfT1dOa3Cg@mail.gmail.com>
References: <CAMk+s2SQ=Ggh8WGdjE-7XJmoirCpXKchb=xDx-AHSfT1dOa3Cg@mail.gmail.com>
Message-ID: <62FA2704-3C5A-4E5D-8D23-058E211411A6@me.com>

On Apr 17, 2015, at 5:23 PM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Dear all,
> I have a vector with a certain range of values including infinity and
> NA. I would like to remove the values that are outside a given range
> (lower level = ll and upper level = ul) but I am getting the error due
> to the NA values (missing value where TRUE/FALSE needed). I then
> included the !is.na() but now the resulting error is all NA, as in the
> example.
> In addition, here I have implemented a for loop to scan all the
> elements of the vector, but I should be able to use the sapply();
> however I don't know how to send the ll and ul arguments to sapply().
> Could you please help?
> best regards
> Luigi
> 
> EXAMPLE
> 
> x <- c(-Inf,  Inf,    NA,    5.9,    6.08,    5281391136138.75,
> 4.35,    4.79,
>       9474097322.96,    3.64,    16.42,    -12211.11,    4.37,
> -1097.79,    4.78,
>       3.71,    32.59,    4.01,    35.36,    3.17,    1.61,
> -3678.28,    2.9,    4.67,
>       4.1,    348410866.78,    5.35,    4.3101519459837E+016,
> 1467030866.75,
>       1.10376094956278E+018,    32.55,    1.17,    5339028670388.94,
>  34.14,
>       33205967009.57,    4.42,    1.76,    7.08,    -8428.84,
> -113491.08,    17.81)
> ll <- 1
> ul <- 45
> 
> clipper <- function(x, ll, ul) {
>  for(i in 1:length(x)) {
>    if(x[i] < ll) {
>      x[i] <- NA
>    } else if(x[i] > ul) {
>      x[i] <- NA
>    } else {
>      x[i] <- x[i]
>    }
>  }
> return(x)
> }
> (X<-clipper(x, ll, ul))
>> missing value where TRUE/FALSE needed
> 
> 
> clipper <- function(x, ll, ul) {
>  for(i in 1:length(x)) {
>    if(!is.na(x[i]) < ll) {
>      x[i] <- NA
>    } else if(!is.na(x[i]) > ul) {
>      x[i] <- NA
>    } else {
>      x[i] <- x[i]
>    }
>  }
> return(x)
> }
> (X<-clipper(x, ll, ul))
> 
> [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA NA NA NA
> [28] NA NA NA NA NA NA NA NA NA NA NA NA NA NA


Hi,

Something along the lines of:

> subset(x, is.finite(x) & (x > ll) & (x < ul))
 [1]  5.90  6.08  4.35  4.79  3.64 16.42  4.37  4.78  3.71 32.59  4.01
[12] 35.36  3.17  1.61  2.90  4.67  4.10  5.35 32.55  1.17 34.14  4.42
[23]  1.76  7.08 17.81

or:

> x[is.finite(x) & (x > ll) & (x < ul)]
 [1]  5.90  6.08  4.35  4.79  3.64 16.42  4.37  4.78  3.71 32.59  4.01
[12] 35.36  3.17  1.61  2.90  4.67  4.10  5.35 32.55  1.17 34.14  4.42
[23]  1.76  7.08 17.81


See ?subset and ?is.finite:

> is.finite(x)
 [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[12]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[23]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[34]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE


Regards,

Marc Schwartz


From paul.domaskis at gmail.com  Sat Apr 18 00:52:37 2015
From: paul.domaskis at gmail.com (paul)
Date: Fri, 17 Apr 2015 22:52:37 +0000
Subject: [R] Smart detection of wrap width?
Message-ID: <loom.20150418T005218-827@post.gmane.org>

I suspect that the answer is "no", but just in case, is there a way to
have R detect the window width and wrap accordingly?  I don't want to
set an option every time I dock a window or shrink it.

In my ideal paradise, R would not only format output according to
window width, but it would also me to specify a virtual window width.
So if I specify a virtual window width of 200 characters, and the
actual window width is 100, then the output has a carriage return at
the 200 character mark but I only see the 1st 100 characters of each
line of text (the rest being truncated from view).  And of course, the
user would be able to specify when the virtual width mirrors the
actual window width.

I know that this is dreaming in technicolour (which is not that
fantastical these days), but I would be pleasantly surprised if there
was a way to simply have the output wrap according to the actual
window width.


From macqueen1 at llnl.gov  Sat Apr 18 01:20:55 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Apr 2015 23:20:55 +0000
Subject: [R] Smart detection of wrap width?
In-Reply-To: <loom.20150418T005218-827@post.gmane.org>
References: <loom.20150418T005218-827@post.gmane.org>
Message-ID: <D156E1A1.125D06%macqueen1@llnl.gov>

A lot of this depends on what context you are running R in, e.g., Windows
console, Mac console, or command line in a unix-alike. Or within ESS in
emacs. Those are different interfaces supported by, to some extent,
different people, and are based on the underlying capabilities provided by
the operating system.

Have you yet encountered
  options()$width
?
For example,
  options(width=100)
will cause wrapping at 100, at least for certain kinds of output.

In an xterm shell running in an X windows context, I frequently use

setwid <- function ()
{
    if (!interactive())
        return(invisible(NULL))
    scon <- pipe("stty -a")
    stty <- scan(scon, what = "", sep = ";", quiet = T)
    close(scon)
    cstr <- stty[grep("columns", stty)]
    options(width = as.numeric(gsub("[^0-9]", "", cstr, ignore.case = T)))
    paste("width =", options()$width, "\n")
}


A function I wrote that resets the width option to match the window
widths, and therefore adjusts the wrapping after I resize a windwo.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/17/15, 3:52 PM, "paul" <paul.domaskis at gmail.com> wrote:

>I suspect that the answer is "no", but just in case, is there a way to
>have R detect the window width and wrap accordingly?  I don't want to
>set an option every time I dock a window or shrink it.
>
>In my ideal paradise, R would not only format output according to
>window width, but it would also me to specify a virtual window width.
>So if I specify a virtual window width of 200 characters, and the
>actual window width is 100, then the output has a carriage return at
>the 200 character mark but I only see the 1st 100 characters of each
>line of text (the rest being truncated from view).  And of course, the
>user would be able to specify when the virtual width mirrors the
>actual window width.
>
>I know that this is dreaming in technicolour (which is not that
>fantastical these days), but I would be pleasantly surprised if there
>was a way to simply have the output wrap according to the actual
>window width.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From paul.domaskis at gmail.com  Sat Apr 18 01:36:11 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 19:36:11 -0400
Subject: [R] Smart detection of wrap width?
In-Reply-To: <D156E1A1.125D06%macqueen1@llnl.gov>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
Message-ID: <CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>

Yes, I found the width option in the help pages, but I was wondering
if there was automatic setting of the wrapping according to the
current window width.

Your function works exactly as I wished.  I'll probably get smarter
with time (I hope) but would it be reasonably good practice to stick
this into ~/.Rprofile?  I don't suppose there is a way to have it
automatically invoked when the window size/positition changes?  (It's
still priceless even without automatic triggering).

On Fri, Apr 17, 2015 at 7:20 PM, MacQueen, Don <macqueen1 at llnl.gov>
wrote:
> A lot of this depends on what context you are running R in, e.g.,
> Windows console, Mac console, or command line in a unix-alike. Or
> within ESS in emacs. Those are different interfaces supported by, to
> some extent, different people, and are based on the underlying
> capabilities provided by the operating system.
>
> Have you yet encountered
>   options()$width
> ?
> For example,
>   options(width=100)
> will cause wrapping at 100, at least for certain kinds of output.
>
> In an xterm shell running in an X windows context, I frequently use
>
> setwid <- function ()
> {
>     if (!interactive())
>         return(invisible(NULL))
>     scon <- pipe("stty -a")
>     stty <- scan(scon, what = "", sep = ";", quiet = T)
>     close(scon)
>     cstr <- stty[grep("columns", stty)]
>     options(width = as.numeric(gsub("[^0-9]", "", cstr, ignore.case = T)))
>     paste("width =", options()$width, "\n")
> }
>
> A function I wrote that resets the width option to match the window
> widths, and therefore adjusts the wrapping after I resize a windwo.


From drjimlemon at gmail.com  Sat Apr 18 02:04:35 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 18 Apr 2015 10:04:35 +1000
Subject: [R] issue with package updates
In-Reply-To: <2DCFECB3-B87C-42D9-A65F-495210097E78@gmail.com>
References: <2DCFECB3-B87C-42D9-A65F-495210097E78@gmail.com>
Message-ID: <CA+8X3fU9nFkWdTg8nJrxxyAPMGCqWP2VDr1GJBR2QXJhb6xwsw@mail.gmail.com>

Hi Iryna,
The two paths seem to be a "user" path (one beneath your home
directory) and a "system" path (one in another branch of the directory
tree). You usually have to have superuser privileges to write files in
the second. In most *NIX systems you use "su" to become "root" (the
superuser), and if you can do this, then perform the update.

Jim

On Fri, Apr 17, 2015 at 7:25 PM, Iryna Nikolayeva
<iryna.v.nikolayeva at gmail.com> wrote:
> Dear R project members,
> I have an issue while automatically updating packages.
> For the packages installed in my second library, while automatically updating I get the following "Permission denied? messages(details below).
> I suppose I know where this problem comes from:
> I had installed a few different versions of R.
> And now I have 2 library paths:
>> .libPaths()
> [1] "/Users/iryna/Library/R/3.1/library"
> [2] "/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library?
>
> And for some reason R just doesn?t have rights to update packages in my second library.
> Do you know why is that? How should I fix this issue?
>
> Here is the error message:
>
> * installing *source* package ?mgcv? ...
> ** package ?mgcv? successfully unpacked and MD5 sums checked
> mv: rename /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/00LOCK-mgcv/mgcv: Permission denied
> Warning in file.copy(f, instdir, TRUE) :
>   problem copying ./NAMESPACE to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/NAMESPACE: Permission denied
> Warning in file(file, ifelse(append, "a", "w")) :
>   cannot open file '/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/DESCRIPTION': Permission denied
> Error in file(file, ifelse(append, "a", "w")) :
>   cannot open the connection
> ERROR: installing package DESCRIPTION failed for package ?mgcv?
> * removing ?/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv?
>
>
>
>
> Here are some additional information on my settings:
>> version
>                _
> platform       x86_64-apple-darwin13.4.0
> arch           x86_64
> os             darwin13.4.0
> system         x86_64, darwin13.4.0
> status
> major          3
> minor          1.2
> year           2014
> month          10
> day            31
> svn rev        66913
> language       R
> version.string R version 3.1.2 (2014-10-31)
> nickname       Pumpkin Helmet
>
> Thanks in advance for your help,
> ?
>
> Iryna Nikolayeva
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Apr 18 03:02:25 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Apr 2015 21:02:25 -0400
Subject: [R] Are '1st decimal' R rollouts (e.g. 3.2.0) qualitatively
	different?
In-Reply-To: <CAEGxr5Dr81T+GGhe9=Gs7HtVWQQ4jrkOVtFQFq9GhE5pLrtEQw@mail.gmail.com>
References: <CAEGxr5Dr81T+GGhe9=Gs7HtVWQQ4jrkOVtFQFq9GhE5pLrtEQw@mail.gmail.com>
Message-ID: <5531AD21.40205@gmail.com>

On 17/04/2015 11:50 AM, Assaf P. Oron wrote:
> Hi all,
> 
> With the upcoming 3.2.0 upgrade, the question came up among my students,
> how often a regular user who is not a cutting-edge developer "must" upgrade
> their R, given that on Windows/Mac this includes the inconvenience of
> re-installing dozens of packages.
> 
> In this context, I was wondering whether the annual '1st decimal' upgrade
> like 3.2.0 is qualitatively different from the interim ones like 3.1.3. In
> other words, whether some changes are reserved for those annual upgrades,
> or whether all upgrades are essentially equivalent.

In an x.y.z upgrade, our policy is that a change to z should not break
any well-behaved code, but a change to y or x might do so.  In the case
of 3.2.0, I don't know of anything that is broken relative to 3.1.3, but
there are probably a few obscure things.

Changes to z are almost always a good idea to adopt.  They shouldn't
break anything that isn't taking advantage of bugs, but should fix bugs.

So I would say regular users should *always* adopt changes where z
becomes a value greater than 0.

The question of z=0 is harder.  There are likely to be changes in x.y.0
which are not as well tested as those in other versions.  However, R is
an open source project.  You aren't paying anything for using it.  The
reason it works so well is because so many people use it, and report bugs.

If you choose not to use a z=0 version, you are essentially stealing the
effort of the rest of the community who contribute to testing and
development.  You are also making the z=1 version worse, by not
reporting bugs in the z=0 version.

In the particular case of 3.2.0, there are not a lot of new changes, so
probably not a lot of new bugs, and you may well be better off from a
reliability point of view using it instead of 3.1.3.  This isn't always
true, so you should pay attention to the news about changes in the new
version, and make your decision based on your own circumstances.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Apr 18 03:04:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Apr 2015 21:04:18 -0400
Subject: [R] Need online version of R help pages
In-Reply-To: <loom.20150416T230116-747@post.gmane.org>
References: <loom.20150416T230116-747@post.gmane.org>
Message-ID: <5531AD92.6080205@gmail.com>

On 16/04/2015 5:02 PM, paul wrote:
> The help for the cygwin port of R is buggy and hides random lines of
> text.

You've already been told not to use the Cygwin port.  It's buggy in the
help pages, and probably in many other respects as well.  It doesn't
pass the R self-tests.  Don't use it.

Duncan Murdoch

  Consquently, I've been relying on Google, but it is often not
> clear how directly relevant the info is for the specific command that
> I'm using.  For example, reshape is complicated, and has more than 1
> version.
> 
> Is there an online version of the help pages?
> 
> I tried looking for html versions of the help pages by ferruting
> through the R.home() subtree.  Haven't found them so far.  There are
> package pages in subdirectories <package>/html/00Index.html, but they
> just contain links to html files that don't reside in my R.home()
> subtree.  There are also subdirectories <package>/help, but they
> contain pages that I don't recognize (*.rds, *.rdb, *.rdx).
> 
> Getting desparate here, and realizing how the web is not in any way a
> substituted for locally available help pages that you can be confident
> is right for your installation.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paul.domaskis at gmail.com  Sat Apr 18 03:17:27 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 21:17:27 -0400
Subject: [R] Need online version of R help pages
In-Reply-To: <5531AD92.6080205@gmail.com>
References: <loom.20150416T230116-747@post.gmane.org>
	<5531AD92.6080205@gmail.com>
Message-ID: <CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>

With all due respect, Duncan, I can't find the message advising
against using the Cygwin port.  I did find a message about the
mishandling of line endings, and I've asked on the cygwin forum
(as advised).
As I mentioned, I'm in an environment where updates are not possible,
and I'm clarifying now that this means installations are even more
impossible, at least not without extensive adminstrative delay.
Basically, this is what I have to work with.  If anyone can suggest
good ideas for the challenges as-is, that would be much appreciated.
However, given your posts, I fully understand if the answer is "no".
On the other hand, simply demanding a solution consisting of a course
of action which is impossible at present...well, it's just impossible.
Having said that, I'll just say that I've managed to exort the powers
that be to install a Windows based version of R, but I have to work
with what I currently have for at least a week.  I should also mention
that I've submitted an update to the mailing list on a workaround for
the R help problem on cygwin.  It might not have propagated to
recipients yet.
I appreciate the further info on the extent of the bugginess of the
cygwin port.
On Fri, Apr 17, 2015 at 9:04 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>On 16/04/2015 5:02 PM, paul wrote:
>> The help for the cygwin port of R is buggy and hides random lines
>> of text.
>
> You've already been told not to use the Cygwin port.  It's buggy in
> the help pages, and probably in many other respects as well.  It
> doesn't pass the R self-tests.  Don't use it.
>
>>  Consquently, I've been relying on Google, but it is often not
>>  clear how directly relevant the info is for the specific command
>>  that I'm using.  For example, reshape is complicated, and has more
>>  than 1 version.
>>
>> Is there an online version of the help pages?
>>
>> I tried looking for html versions of the help pages by ferruting
>> through the R.home() subtree.  Haven't found them so far.  There
>> are package pages in subdirectories <package>/html/00Index.html,
>> but they just contain links to html files that don't reside in my
>> R.home() subtree.  There are also subdirectories <package>/help,
>> but they contain pages that I don't recognize (*.rds, *.rdb,
>> *.rdx).
>>
>> Getting desparate here, and realizing how the web is not in any way
>> a substituted for locally available help pages that you can be
>> confident is right for your installation.


From r.turner at auckland.ac.nz  Sat Apr 18 03:42:21 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 18 Apr 2015 13:42:21 +1200
Subject: [R] issue with package updates
In-Reply-To: <CA+8X3fU9nFkWdTg8nJrxxyAPMGCqWP2VDr1GJBR2QXJhb6xwsw@mail.gmail.com>
References: <2DCFECB3-B87C-42D9-A65F-495210097E78@gmail.com>
	<CA+8X3fU9nFkWdTg8nJrxxyAPMGCqWP2VDr1GJBR2QXJhb6xwsw@mail.gmail.com>
Message-ID: <5531B67D.2020305@auckland.ac.nz>


See below.

On 18/04/15 12:04, Jim Lemon wrote:

> Hi Iryna,
> The two paths seem to be a "user" path (one beneath your home
> directory) and a "system" path (one in another branch of the directory
> tree). You usually have to have superuser privileges to write files in
> the second. In most *NIX systems you use "su" to become "root" (the
> superuser), and if you can do this, then perform the update.

Jim:

(1) The OP seems to be using a Mac OSX system (which has Unix underlying 
a great deal of gloppedy obfuscating point-and-click crap).

(2) My reading of the help for install.packages() leads me to believe 
that by default the requested package should be installed into the 
*first* entry of .libPaths(), whence no superuser privileges should be 
required.  It is mysterious to me why the system seems to be intent on 
using the *second* entry of .libPaths() so that superuser privileges 
*are* required.

(3) Since this is Mac OSX stuff, the OP might get better mileage by 
posting on R-Sig-Mac.

cheers,

Rolf

>
> Jim
>
> On Fri, Apr 17, 2015 at 7:25 PM, Iryna Nikolayeva
> <iryna.v.nikolayeva at gmail.com> wrote:
>> Dear R project members,
>> I have an issue while automatically updating packages.
>> For the packages installed in my second library, while automatically updating I get the following "Permission denied? messages(details below).
>> I suppose I know where this problem comes from:
>> I had installed a few different versions of R.
>> And now I have 2 library paths:
>>> .libPaths()
>> [1] "/Users/iryna/Library/R/3.1/library"
>> [2] "/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library?
>>
>> And for some reason R just doesn?t have rights to update packages in my second library.
>> Do you know why is that? How should I fix this issue?
>>
>> Here is the error message:
>>
>> * installing *source* package ?mgcv? ...
>> ** package ?mgcv? successfully unpacked and MD5 sums checked
>> mv: rename /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/00LOCK-mgcv/mgcv: Permission denied
>> Warning in file.copy(f, instdir, TRUE) :
>>    problem copying ./NAMESPACE to /opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/NAMESPACE: Permission denied
>> Warning in file(file, ifelse(append, "a", "w")) :
>>    cannot open file '/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv/DESCRIPTION': Permission denied
>> Error in file(file, ifelse(append, "a", "w")) :
>>    cannot open the connection
>> ERROR: installing package DESCRIPTION failed for package ?mgcv?
>> * removing ?/opt/local/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mgcv?
>>
>>
>>
>>
>> Here are some additional information on my settings:
>>> version
>>                 _
>> platform       x86_64-apple-darwin13.4.0
>> arch           x86_64
>> os             darwin13.4.0
>> system         x86_64, darwin13.4.0
>> status
>> major          3
>> minor          1.2
>> year           2014
>> month          10
>> day            31
>> svn rev        66913
>> language       R
>> version.string R version 3.1.2 (2014-10-31)
>> nickname       Pumpkin Helmet
>>
>> Thanks in advance for your help,
>> ?
>>
>> Iryna Nikolayeva

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From paul.domaskis at gmail.com  Sat Apr 18 04:30:16 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Fri, 17 Apr 2015 22:30:16 -0400
Subject: [R] "lag1.plot {astsa}" vs. "lag.plot {stats}"
Message-ID: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>

I'm following http://www.stat.pitt.edu/stoffer/tsa3/R_toot.htm to ramp
up on both time series and R.  About 40% of the way down, the tutorial
uses lag1.plot from astsa and lag.plot from stats.  The positioning of
the dots look different between the two.  Nothing jumps out at me from
the help pages that explains why they would be different.  Can anyone
confirm this difference, and hopefully suggest explanations?


From roy.mendelssohn at noaa.gov  Sat Apr 18 04:56:27 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 17 Apr 2015 19:56:27 -0700
Subject: [R] "lag1.plot {astsa}" vs. "lag.plot {stats}"
In-Reply-To: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
References: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
Message-ID: <ECD1DD0B-1E3F-4DAD-BFD0-B3F18289BED0@noaa.gov>

Not certain which plot you are looking at, but my guess is the answer is contained somewhere here:

http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm

in particular perhaps issues 4-5.

-Roy M.
> On Apr 17, 2015, at 7:30 PM, Paul Domaskis <paul.domaskis at gmail.com> wrote:
> 
> I'm following http://www.stat.pitt.edu/stoffer/tsa3/R_toot.htm to ramp
> up on both time series and R.  About 40% of the way down, the tutorial
> uses lag1.plot from astsa and lag.plot from stats.  The positioning of
> the dots look different between the two.  Nothing jumps out at me from
> the help pages that explains why they would be different.  Can anyone
> confirm this difference, and hopefully suggest explanations?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From brant.inman at me.com  Sat Apr 18 06:14:46 2015
From: brant.inman at me.com (Brant Inman)
Date: Sat, 18 Apr 2015 00:14:46 -0400
Subject: [R] Programming R to avoid loops
Message-ID: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>

I have two large data frames with the following structure:

> df1
  id       date test1.result
1  a 2009-08-28      1
2  a 2009-09-16      1
3  b 2008-08-06      0
4  c 2012-02-02      1
5  c 2010-08-03      1
6  c 2012-08-02      0

> df2
  id       date test2.result
1  a 2011-02-03      1
2  b 2011-09-27      0
3  b 2011-09-01      1
4  c 2009-07-16      0
5  c 2009-04-15      0
6  c 2010-08-10      1

I need to match items in df2 to those in df1 with specific matching criteria. I have written a looped matching algorithm that works, but it is very slow with my large datasets. I am requesting help on making a version of this code that is faster and ?vectorized" so to speak.

My algorithm is currently something like this code. It works but is damn slow.

findTestPairs <- function(test1, id1, date1, test2, id2, date2, predays=-30, 
                          lagdays=30){
  # Function to find, within subjects, two tests that occur with a timeframe
  #
  # test1 = the reference test result for which matching second tests are sought
  # test2 = the second test result
  # date1 = the date of test1
  # date2 = the date of test2
  # id1   = unique identifier for subject undergoing test 1
  # id2   = unique identifier for subject undergoing test 2
  # predays  = maximum number of days prior to test1 date that test2 date might occur
  # lagdays  = maximum number of days after test1 date that test2 date might occur
    
  result <- data.frame(matrix(ncol=5, nrow=length(test1)))
    colnames(result) <- c('id','test1','date','test2count',?test2lag.result')
    result$id    <- id1
    result$test1 <- test1
    result$date  <- date1
    
  for(i in 1:length(test1)){
    l <- 0    # Counter of test2 results that matches test1 within lag interval
    m <- NA   # Indicator of positive test2 within lag interval
        
    for(j in 1:length(test2)){
      if(id1[i] == id2[j]){               # STEP1: Match IDs
        interval <- date2[j] - date1[i]
        intmatch <- ifelse(interval >= predays && interval <= lagdays, 1, 0)

        if(intmatch == 1){                # STEP2: Does test2 fall within lag interval?
          l <- l+1                        # If test2 within lag interval, count it

          if(test2[j] == 1) {             # STEP3: Is test 2 positive?
            m <- 1                        # If test2 is positive, set indicator to 1
          } else {
            m <- 0
          }
        }
      }
    }  
    result$test2count[i] <- l
    result$test2lag.result[i] <- m
  }  
  return(result)
}  

I would appreciate help on building a faster matching algorithm. I am pretty certain that R functions can be used to do this but I do not have a good grasp of how to make it work.

Brant Inman
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Apr 18 09:24:11 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 18 Apr 2015 17:24:11 +1000
Subject: [R] Programming R to avoid loops
In-Reply-To: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
References: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
Message-ID: <CA+8X3fUPiG7Uxe2sGRm_y37BzCZ18ND2O0rWRg-vu4vHiQkJYQ@mail.gmail.com>

Hi Brant,
I'm a bit confused about which data frame is the one to match to, but
the following, while still including loops, should run much faster
than the above as it only matches dates within id matches.

df1<-read.table(text="id date test1.result
  a 2009-08-28      1
  a 2009-09-16      1
  b 2008-08-06      0
  c 2012-02-02      1
  c 2010-08-03      1
  c 2012-08-02      0",header=TRUE)
df2<-read.table(text="id date test2.result
  a 2011-02-03      1
  b 2011-09-27      0
  b 2011-09-01      1
  c 2009-07-16      0
  c 2009-04-15      0
  c 2010-08-10      1",header=TRUE)

bi.match<-function(x1,x2,maxdaydiff=30) {
 # convert the character strings to dates (may not be necessary)
 x1$dates<-as.Date(x1$date,"%Y-%m-%d")
 x2$dates<-as.Date(x2$date,"%Y-%m-%d")
 # initialize the l and m variables
 x1$l<-x1$m<-0
 # get all the id codes
 ids<-unique(x2$id)
 # step through the id codes
 for(id1 in ids) {
  x1ind<-which(x1$id == id1)
  x2ind<-which(x2$id == id1)
  for(id2 in 1:length(x1ind)) {
   # get the indices of the x2 dates that are within maxdaydiff days
of this x1 date
   diffok<-which(abs(x1$dates[x1ind[id2]]-x2$dates[x2ind])<=30)
   # set the date diff match indicator to 1
   x1$l[x1ind[id2]]<-length(diffok) > 0
   # set the positive test indicator to 1
   x1$m[x1ind[id2]]<-any(x2$test2.result[x2ind[diffok]] > 0)
  }
 }
 return(x1)
}

bi.match(df1,df2)

Jim


On Sat, Apr 18, 2015 at 2:14 PM, Brant Inman <brant.inman at me.com> wrote:
> I have two large data frames with the following structure:
>
>> df1
>   id       date test1.result
> 1  a 2009-08-28      1
> 2  a 2009-09-16      1
> 3  b 2008-08-06      0
> 4  c 2012-02-02      1
> 5  c 2010-08-03      1
> 6  c 2012-08-02      0
>
>> df2
>   id       date test2.result
> 1  a 2011-02-03      1
> 2  b 2011-09-27      0
> 3  b 2011-09-01      1
> 4  c 2009-07-16      0
> 5  c 2009-04-15      0
> 6  c 2010-08-10      1
>
> I need to match items in df2 to those in df1 with specific matching criteria. I have written a looped matching algorithm that works, but it is very slow with my large datasets. I am requesting help on making a version of this code that is faster and ?vectorized" so to speak.
>
> My algorithm is currently something like this code. It works but is damn slow.
>
> findTestPairs <- function(test1, id1, date1, test2, id2, date2, predays=-30,
>                           lagdays=30){
>   # Function to find, within subjects, two tests that occur with a timeframe
>   #
>   # test1 = the reference test result for which matching second tests are sought
>   # test2 = the second test result
>   # date1 = the date of test1
>   # date2 = the date of test2
>   # id1   = unique identifier for subject undergoing test 1
>   # id2   = unique identifier for subject undergoing test 2
>   # predays  = maximum number of days prior to test1 date that test2 date might occur
>   # lagdays  = maximum number of days after test1 date that test2 date might occur
>
>   result <- data.frame(matrix(ncol=5, nrow=length(test1)))
>     colnames(result) <- c('id','test1','date','test2count',?test2lag.result')
>     result$id    <- id1
>     result$test1 <- test1
>     result$date  <- date1
>
>   for(i in 1:length(test1)){
>     l <- 0    # Counter of test2 results that matches test1 within lag interval
>     m <- NA   # Indicator of positive test2 within lag interval
>
>     for(j in 1:length(test2)){
>       if(id1[i] == id2[j]){               # STEP1: Match IDs
>         interval <- date2[j] - date1[i]
>         intmatch <- ifelse(interval >= predays && interval <= lagdays, 1, 0)
>
>         if(intmatch == 1){                # STEP2: Does test2 fall within lag interval?
>           l <- l+1                        # If test2 within lag interval, count it
>
>           if(test2[j] == 1) {             # STEP3: Is test 2 positive?
>             m <- 1                        # If test2 is positive, set indicator to 1
>           } else {
>             m <- 0
>           }
>         }
>       }
>     }
>     result$test2count[i] <- l
>     result$test2lag.result[i] <- m
>   }
>   return(result)
> }
>
> I would appreciate help on building a faster matching algorithm. I am pretty certain that R functions can be used to do this but I do not have a good grasp of how to make it work.
>
> Brant Inman
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Sat Apr 18 14:10:50 2015
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sat, 18 Apr 2015 20:10:50 +0800
Subject: [R] Where is the R Graph Gallery?
Message-ID: <553249CA.1070306@yeah.net>

Hi there,

Does anyone here know where does the R Graph Gallery 
(http://addictedtor.free.fr/graphiques/) move to? I googled, but don't 
find any useful hints.

Any help? Thanks in advance!

Best,
Jinsong


From f.fabiogama88 at gmail.com  Fri Apr 17 22:22:37 2015
From: f.fabiogama88 at gmail.com (Fernando Gama)
Date: Fri, 17 Apr 2015 17:22:37 -0300
Subject: [R] suggestion of regex pattern
Message-ID: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>

Hello,

I have benn problems to construct the pattern for this:

municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300

I would like:

municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
*& **trechoklmetros
<= *12.300
?
?Any suggestion??


-- 
Att,

Fernando Gama da Mata

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat Apr 18 14:27:53 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 18 Apr 2015 13:27:53 +0100
Subject: [R] Need online version of R help pages
In-Reply-To: <CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
References: <loom.20150416T230116-747@post.gmane.org>	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
Message-ID: <55324DC9.9070006@dewey.myzen.co.uk>

I am not sure how helpful this is going to be but Appendix C7 in the 
Installation and Administration manual is pretty bleak about your 
prospects with Cygwin.

On 18/04/2015 02:17, Paul Domaskis wrote:
> With all due respect, Duncan, I can't find the message advising
> against using the Cygwin port.  I did find a message about the
> mishandling of line endings, and I've asked on the cygwin forum
> (as advised).
> As I mentioned, I'm in an environment where updates are not possible,
> and I'm clarifying now that this means installations are even more
> impossible, at least not without extensive adminstrative delay.
> Basically, this is what I have to work with.  If anyone can suggest
> good ideas for the challenges as-is, that would be much appreciated.
> However, given your posts, I fully understand if the answer is "no".
> On the other hand, simply demanding a solution consisting of a course
> of action which is impossible at present...well, it's just impossible.
> Having said that, I'll just say that I've managed to exort the powers
> that be to install a Windows based version of R, but I have to work
> with what I currently have for at least a week.  I should also mention
> that I've submitted an update to the mailing list on a workaround for
> the R help problem on cygwin.  It might not have propagated to
> recipients yet.
> I appreciate the further info on the extent of the bugginess of the
> cygwin port.
> On Fri, Apr 17, 2015 at 9:04 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 16/04/2015 5:02 PM, paul wrote:
>>> The help for the cygwin port of R is buggy and hides random lines
>>> of text.
>>
>> You've already been told not to use the Cygwin port.  It's buggy in
>> the help pages, and probably in many other respects as well.  It
>> doesn't pass the R self-tests.  Don't use it.
>>
>>>   Consquently, I've been relying on Google, but it is often not
>>>   clear how directly relevant the info is for the specific command
>>>   that I'm using.  For example, reshape is complicated, and has more
>>>   than 1 version.
>>>
>>> Is there an online version of the help pages?
>>>
>>> I tried looking for html versions of the help pages by ferruting
>>> through the R.home() subtree.  Haven't found them so far.  There
>>> are package pages in subdirectories <package>/html/00Index.html,
>>> but they just contain links to html files that don't reside in my
>>> R.home() subtree.  There are also subdirectories <package>/help,
>>> but they contain pages that I don't recognize (*.rds, *.rdb,
>>> *.rdx).
>>>
>>> Getting desparate here, and realizing how the web is not in any way
>>> a substituted for locally available help pages that you can be
>>> confident is right for your installation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From charles.santana at gmail.com  Sat Apr 18 14:55:42 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sat, 18 Apr 2015 14:55:42 +0200
Subject: [R] Problems combining two plots using par(mfrow=)
Message-ID: <CAH-FEngxzN5aLAjfY4sG=+sRX8XjFxC+kMKu5Uhihm72Bj5+Wg@mail.gmail.com>

Dear all,

I am trying to plot 4 different plots in the same figure using
par(mfrow=...) and igraph::plot.igraph. The code below reproduces more or
less what I am doing:

library(igraph)

g<-erdos.renyi.game(30,0.4)
x<-1:100;

par(mfrow=c(2,2))

hist(degree(g),main="A");
plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="B")
plot(g,main="C");box();
plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="D")

My problem is that the curve plotted in "D" is shown out of the margins. As
it is exactly the same plot as in "B" and in "B" there is no problem with
margins I suppose this is somehow related to the plot of the graph in "C".

I tried to use the function graphics::layout instead of par(mfrow) and the
same problem persists.

I am using R "3.0.2" and Igraph "0.7.1" installed in a machine with Ubuntu
14.04.

I sent this message to Igraph mailing-list but so far nobody could help me.
I wonder if this problem happens also with other combinations of
"par(mfrow)" and other kinds of plots, so I am sending this message also to
this broader mailing list.

Does any of you have any clue about how to solve this?

Thanks for your attention and for any help,

Charles

-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Apr 18 15:29:10 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 18 Apr 2015 05:29:10 -0800
Subject: [R] Where is the R Graph Gallery?
In-Reply-To: <553249CA.1070306@yeah.net>
Message-ID: <7AFBBA3D4A0.000009D5jrkrideau@inbox.com>

I think it moved to http://rgraphgallery.blogspot.com/ with a different interface.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jszhao at yeah.net
> Sent: Sat, 18 Apr 2015 20:10:50 +0800
> To: r-help at r-project.org
> Subject: [R] Where is the R Graph Gallery?
> 
> Hi there,
> 
> Does anyone here know where does the R Graph Gallery
> (http://addictedtor.free.fr/graphiques/) move to? I googled, but don't
> find any useful hints.
> 
> Any help? Thanks in advance!
> 
> Best,
> Jinsong
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From edd at debian.org  Sat Apr 18 15:41:25 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 18 Apr 2015 08:41:25 -0500
Subject: [R] Where is the R Graph Gallery?
In-Reply-To: <553249CA.1070306@yeah.net>
References: <553249CA.1070306@yeah.net>
Message-ID: <21810.24325.135996.394284@max.nulle.part>


On 18 April 2015 at 20:10, Jinsong Zhao wrote:
| Does anyone here know where does the R Graph Gallery 
| (http://addictedtor.free.fr/graphiques/) move to? I googled, but don't 
| find any useful hints.

It went down due to (IIRC) hardware failure. It was said that it would come
back. That was a while back so, but it hasn't happened. I would not hold up
any hope for a quick change in that matter.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From boris.steipe at utoronto.ca  Sat Apr 18 16:04:39 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Apr 2015 10:04:39 -0400
Subject: [R] suggestion of regex pattern
In-Reply-To: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
References: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
Message-ID: <32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>

This is not a regular expression but simply a conjunction (sequence of '&') of logical expressions. Moreover it's not wrong. Consider:

xyz <- data.frame(municipio = c('Limeira'), mesincident = c('marco'), trechoklmetros = c(3.00, -4.00, 30))
xyz

  municipio mesincident trechoklmetros
1   Limeira       marco              3
2   Limeira       marco             -4
3   Limeira       marco             30


xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00
[1]  TRUE FALSE  TRUE

xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00 & xyz$trechoklmetros <= 12.3
[1]  TRUE FALSE FALSE


If there's a problem it seems to be elsewhere.
Cheers,
Boris


On Apr 17, 2015, at 4:22 PM, Fernando Gama <f.fabiogama88 at gmail.com> wrote:

> Hello,
> 
> I have benn problems to construct the pattern for this:
> 
> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300
> 
> I would like:
> 
> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> *& **trechoklmetros
> <= *12.300
> ?
> ?Any suggestion??
> 
> 
> -- 
> Att,
> 
> Fernando Gama da Mata
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Sat Apr 18 16:16:44 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 18 Apr 2015 09:16:44 -0500
Subject: [R] Where is the R Graph Gallery?
In-Reply-To: <7AFBBA3D4A0.000009D5jrkrideau@inbox.com>
References: <553249CA.1070306@yeah.net>
	<7AFBBA3D4A0.000009D5jrkrideau@inbox.com>
Message-ID: <21810.26444.716972.902649@max.nulle.part>


On 18 April 2015 at 05:29, John Kane wrote:
| I think it moved to http://rgraphgallery.blogspot.com/ with a different interface.

I don't think so. Something I contributed years ago to the original Graph
Gallery is not on this site. 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From boris.steipe at utoronto.ca  Sat Apr 18 16:20:36 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Apr 2015 10:20:36 -0400
Subject: [R] Problems combining two plots using par(mfrow=)
In-Reply-To: <CAH-FEngxzN5aLAjfY4sG=+sRX8XjFxC+kMKu5Uhihm72Bj5+Wg@mail.gmail.com>
References: <CAH-FEngxzN5aLAjfY4sG=+sRX8XjFxC+kMKu5Uhihm72Bj5+Wg@mail.gmail.com>
Message-ID: <DE80D2BF-1298-48CD-A1B1-CBDD5023CE8F@utoronto.ca>

I can reproduce your problem. It affects both sine-waves if the graph is plotted as the second plot, so it seems that plotting the graph affects all subsequent plots. It affects all plots in subsequent plots to the same window. The window needs to be closed to correct this. I would file a bug report.

Two quick workarounds: plot only the x-values contained in your xlim range, or plot the graph last.

Cheers,
B.



On Apr 18, 2015, at 8:55 AM, Charles Novaes de Santana <charles.santana at gmail.com> wrote:

> Dear all,
> 
> I am trying to plot 4 different plots in the same figure using
> par(mfrow=...) and igraph::plot.igraph. The code below reproduces more or
> less what I am doing:
> 
> library(igraph)
> 
> g<-erdos.renyi.game(30,0.4)
> x<-1:100;
> 
> par(mfrow=c(2,2))
> 
> hist(degree(g),main="A");
> plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="B")
> plot(g,main="C");box();
> plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="D")
> 
> My problem is that the curve plotted in "D" is shown out of the margins. As
> it is exactly the same plot as in "B" and in "B" there is no problem with
> margins I suppose this is somehow related to the plot of the graph in "C".
> 
> I tried to use the function graphics::layout instead of par(mfrow) and the
> same problem persists.
> 
> I am using R "3.0.2" and Igraph "0.7.1" installed in a machine with Ubuntu
> 14.04.
> 
> I sent this message to Igraph mailing-list but so far nobody could help me.
> I wonder if this problem happens also with other combinations of
> "par(mfrow)" and other kinds of plots, so I am sending this message also to
> this broader mailing list.
> 
> Does any of you have any clue about how to solve this?
> 
> Thanks for your attention and for any help,
> 
> Charles
> 
> -- 
> Um ax?! :)
> 
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Apr 18 16:39:02 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 18 Apr 2015 06:39:02 -0800
Subject: [R] Where is the R Graph Gallery?
In-Reply-To: <21810.26444.716972.902649@max.nulle.part>
References: <7afbba3d4a0.000009d5jrkrideau@inbox.com>
	<553249ca.1070306@yeah.net>
Message-ID: <7B97E150426.00000A59jrkrideau@inbox.com>

I thought I'd read about a migration. Well so much for memory.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: edd at debian.org
> Sent: Sat, 18 Apr 2015 09:16:44 -0500
> To: jrkrideau at inbox.com
> Subject: Re: [R] Where is the R Graph Gallery?
> 
> 
> On 18 April 2015 at 05:29, John Kane wrote:
> | I think it moved to http://rgraphgallery.blogspot.com/ with a different
> interface.
> 
> I don't think so. Something I contributed years ago to the original Graph
> Gallery is not on this site.
> 
> Dirk
> 
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From f.fabiogama88 at gmail.com  Sat Apr 18 17:10:29 2015
From: f.fabiogama88 at gmail.com (Fernando Gama)
Date: Sat, 18 Apr 2015 12:10:29 -0300
Subject: [R] suggestion of regex pattern
In-Reply-To: <32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>
References: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
	<32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>
Message-ID: <CAOwqRytEwuYUSBx8bj0jK0MEGS-Cdnu-WFEfrVYsheNEV4R25w@mail.gmail.com>

Hello Boris,

thanks for your response.

So, firstly considered that  i've been input a set of serches strings (.txt
format) and i'm using regex to transform in a suitable  format to my
script. This part is a final part of my code and i wish putting in input to
a subset.

(.txt formatted)

---- STRINGS (INPUT)

*[1]  "municipio =='Limeira' "*
*[2]  "municipio =='Limeira' & mesincident =='marco' "*
*[3]  "?municipio =='Limeira' & mesincident =='marco' & trechoklmetros >
1.00 12.300"*
*...*
*..*
*..*
*..*
*[n] "......"*

*--------------*

desired_fomart <-
?it will reveice all strings to filter in a dataset by subset below:



a loop each line:

subset(dataset_read, *desired_fomart[i]*)

My question: taking into consideration this cenario, in your oppinion your
reply is my suitable for my problem, whereas i will to map each value in
database?

Once again, thank so much! :)

2015-04-18 11:04 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:

> This is not a regular expression but simply a conjunction (sequence of
> '&') of logical expressions. Moreover it's not wrong. Consider:
>
> xyz <- data.frame(municipio = c('Limeira'), mesincident = c('marco'),
> trechoklmetros = c(3.00, -4.00, 30))
> xyz
>
>   municipio mesincident trechoklmetros
> 1   Limeira       marco              3
> 2   Limeira       marco             -4
> 3   Limeira       marco             30
>
>
> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros
> > 1.00
> [1]  TRUE FALSE  TRUE
>
> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros
> > 1.00 & xyz$trechoklmetros <= 12.3
> [1]  TRUE FALSE FALSE
>
>
> If there's a problem it seems to be elsewhere.
> Cheers,
> Boris
>
>
> On Apr 17, 2015, at 4:22 PM, Fernando Gama <f.fabiogama88 at gmail.com>
> wrote:
>
> > Hello,
> >
> > I have benn problems to construct the pattern for this:
> >
> > municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> 12.300
> >
> > I would like:
> >
> > municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> > *& **trechoklmetros
> > <= *12.300
> > ?
> > ?Any suggestion??
> >
> >
> > --
> > Att,
> >
> > Fernando Gama da Mata
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Att,

Fernando Gama da Mata

	[[alternative HTML version deleted]]


From charles.santana at gmail.com  Sat Apr 18 17:28:00 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sat, 18 Apr 2015 17:28:00 +0200
Subject: [R] Problems combining two plots using par(mfrow=)
In-Reply-To: <DE80D2BF-1298-48CD-A1B1-CBDD5023CE8F@utoronto.ca>
References: <CAH-FEngxzN5aLAjfY4sG=+sRX8XjFxC+kMKu5Uhihm72Bj5+Wg@mail.gmail.com>
	<DE80D2BF-1298-48CD-A1B1-CBDD5023CE8F@utoronto.ca>
Message-ID: <CAH-FEnjPWaRfoQ+5mKk14V2MxhUpcioN-KOfFU765Dw7-zmq9g@mail.gmail.com>

Dear Boris,

Thank you for your message! I had experienced exactly what you describe in
your message. I just didn't write in my previous message in order to avoid
a long message :) I will definitely file a bug report to Igraph. Thanks for
your suggestion.

In the meanwhile, I will try the first workaround you suggested. It worked
fine for what I am doing.

library(igraph)

g<-erdos.renyi.game(30,0.4)
x<-1:100;

par(mfrow=c(2,2));
hist(degree(g),main="A");
plot(x[40:90],sin(x[40:90]),type="l",xlab="x",ylab="sin(x)",xlim=c(40,90),main="D")
plot(g,main="C");box();
plot(x[40:90],sin(x[40:90]),type="l",xlab="x",ylab="sin(x)",xlim=c(40,90),main="D")

Thanks for your time! Have a nice weekend!

Charles



On Sat, Apr 18, 2015 at 4:20 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> I can reproduce your problem. It affects both sine-waves if the graph is
> plotted as the second plot, so it seems that plotting the graph affects all
> subsequent plots. It affects all plots in subsequent plots to the same
> window. The window needs to be closed to correct this. I would file a bug
> report.
>
> Two quick workarounds: plot only the x-values contained in your xlim
> range, or plot the graph last.
>
> Cheers,
> B.
>
>
>
> On Apr 18, 2015, at 8:55 AM, Charles Novaes de Santana <
> charles.santana at gmail.com> wrote:
>
> > Dear all,
> >
> > I am trying to plot 4 different plots in the same figure using
> > par(mfrow=...) and igraph::plot.igraph. The code below reproduces more or
> > less what I am doing:
> >
> > library(igraph)
> >
> > g<-erdos.renyi.game(30,0.4)
> > x<-1:100;
> >
> > par(mfrow=c(2,2))
> >
> > hist(degree(g),main="A");
> > plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="B")
> > plot(g,main="C");box();
> > plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="D")
> >
> > My problem is that the curve plotted in "D" is shown out of the margins.
> As
> > it is exactly the same plot as in "B" and in "B" there is no problem with
> > margins I suppose this is somehow related to the plot of the graph in
> "C".
> >
> > I tried to use the function graphics::layout instead of par(mfrow) and
> the
> > same problem persists.
> >
> > I am using R "3.0.2" and Igraph "0.7.1" installed in a machine with
> Ubuntu
> > 14.04.
> >
> > I sent this message to Igraph mailing-list but so far nobody could help
> me.
> > I wonder if this problem happens also with other combinations of
> > "par(mfrow)" and other kinds of plots, so I am sending this message also
> to
> > this broader mailing list.
> >
> > Does any of you have any clue about how to solve this?
> >
> > Thanks for your attention and for any help,
> >
> > Charles
> >
> > --
> > Um ax?! :)
> >
> > --
> > Charles Novaes de Santana, PhD
> > http://www.imedea.uib-csic.es/~charles
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From charles.santana at gmail.com  Sat Apr 18 18:49:00 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sat, 18 Apr 2015 18:49:00 +0200
Subject: [R] Problems combining two plots using par(mfrow=)
In-Reply-To: <CAH-FEnjPWaRfoQ+5mKk14V2MxhUpcioN-KOfFU765Dw7-zmq9g@mail.gmail.com>
References: <CAH-FEngxzN5aLAjfY4sG=+sRX8XjFxC+kMKu5Uhihm72Bj5+Wg@mail.gmail.com>
	<DE80D2BF-1298-48CD-A1B1-CBDD5023CE8F@utoronto.ca>
	<CAH-FEnjPWaRfoQ+5mKk14V2MxhUpcioN-KOfFU765Dw7-zmq9g@mail.gmail.com>
Message-ID: <CAH-FEngN05tjxX9HBO1h=J0+GgVYUM_E3oRRSZCc37H87aUW5A@mail.gmail.com>

Just open this issue: https://github.com/igraph/rigraph/issues/69

Thanks again for your suggestion!

Best,

Charles

On Sat, Apr 18, 2015 at 5:28 PM, Charles Novaes de Santana <
charles.santana at gmail.com> wrote:

> Dear Boris,
>
> Thank you for your message! I had experienced exactly what you describe in
> your message. I just didn't write in my previous message in order to avoid
> a long message :) I will definitely file a bug report to Igraph. Thanks for
> your suggestion.
>
> In the meanwhile, I will try the first workaround you suggested. It worked
> fine for what I am doing.
>
> library(igraph)
>
> g<-erdos.renyi.game(30,0.4)
> x<-1:100;
>
> par(mfrow=c(2,2));
> hist(degree(g),main="A");
>
> plot(x[40:90],sin(x[40:90]),type="l",xlab="x",ylab="sin(x)",xlim=c(40,90),main="D")
> plot(g,main="C");box();
>
> plot(x[40:90],sin(x[40:90]),type="l",xlab="x",ylab="sin(x)",xlim=c(40,90),main="D")
>
> Thanks for your time! Have a nice weekend!
>
> Charles
>
>
>
> On Sat, Apr 18, 2015 at 4:20 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> I can reproduce your problem. It affects both sine-waves if the graph is
>> plotted as the second plot, so it seems that plotting the graph affects all
>> subsequent plots. It affects all plots in subsequent plots to the same
>> window. The window needs to be closed to correct this. I would file a bug
>> report.
>>
>> Two quick workarounds: plot only the x-values contained in your xlim
>> range, or plot the graph last.
>>
>> Cheers,
>> B.
>>
>>
>>
>> On Apr 18, 2015, at 8:55 AM, Charles Novaes de Santana <
>> charles.santana at gmail.com> wrote:
>>
>> > Dear all,
>> >
>> > I am trying to plot 4 different plots in the same figure using
>> > par(mfrow=...) and igraph::plot.igraph. The code below reproduces more
>> or
>> > less what I am doing:
>> >
>> > library(igraph)
>> >
>> > g<-erdos.renyi.game(30,0.4)
>> > x<-1:100;
>> >
>> > par(mfrow=c(2,2))
>> >
>> > hist(degree(g),main="A");
>> > plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="B")
>> > plot(g,main="C");box();
>> > plot(x,sin(x),type="l",xlab="x",ylab="sin(x)",xlim=c(10,60),main="D")
>> >
>> > My problem is that the curve plotted in "D" is shown out of the
>> margins. As
>> > it is exactly the same plot as in "B" and in "B" there is no problem
>> with
>> > margins I suppose this is somehow related to the plot of the graph in
>> "C".
>> >
>> > I tried to use the function graphics::layout instead of par(mfrow) and
>> the
>> > same problem persists.
>> >
>> > I am using R "3.0.2" and Igraph "0.7.1" installed in a machine with
>> Ubuntu
>> > 14.04.
>> >
>> > I sent this message to Igraph mailing-list but so far nobody could help
>> me.
>> > I wonder if this problem happens also with other combinations of
>> > "par(mfrow)" and other kinds of plots, so I am sending this message
>> also to
>> > this broader mailing list.
>> >
>> > Does any of you have any clue about how to solve this?
>> >
>> > Thanks for your attention and for any help,
>> >
>> > Charles
>> >
>> > --
>> > Um ax?! :)
>> >
>> > --
>> > Charles Novaes de Santana, PhD
>> > http://www.imedea.uib-csic.es/~charles
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
>



-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Sat Apr 18 18:56:29 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 18 Apr 2015 09:56:29 -0700
Subject: [R] xtractomatic package
Message-ID: <7A8B3FB2-CF72-4806-9CAE-17210048F0B0@noaa.gov>

xtractomatic R package for accessing environmental data

xtractomatic is an R package developed to subset and extract satellite and other oceanographic related data from a remote server. The program can extract data for a moving point in time along a user-supplied set of longitude, latitude and time points; in a 3D bounding box; or within a polygon (through time). The xtractomatic functions were originally developed for the marine biology tagging community, to match up environmental data available from satellites (sea-surface temperature, sea-surface chlorophyll, sea-surface height, sea-surface salinity, vector winds) to track data from various tagged animals or shiptracks (xtracto). The package has since been extended to include the routines that extract data a 3D bounding box (xtracto_3D) or within a polygon (xtractogon). The xtractomatic package accesses data that are served through the ERDDAP (Environmental Research Division Data Access Program) server at the NOAA/SWFSC Environmental Research Division in Santa Cruz, California. The ERDDAP server can also be directly accessed at http://coastwatch.pfeg.noaa.gov/erddap. ERDDAP is a simple to use yet powerful web data service developed by Bob Simons. 

At present the package can access well over 100TB of data.  Due to some problems with certain required packages and CRAN  (most notably ncdf4) xtractomatic at present is only available through Github.  Instructions for installation are at:

https://github.com/rmendels/xtractomatic

-Roy M.


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From istazahn at gmail.com  Sat Apr 18 19:26:08 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 18 Apr 2015 13:26:08 -0400
Subject: [R] Smart detection of wrap width?
In-Reply-To: <CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
Message-ID: <CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>

For ESS see https://github.com/gaborcsardi/dot-emacs/blob/master/.emacs

Best,
Ista

On Apr 17, 2015 7:37 PM, "Paul Domaskis" <paul.domaskis at gmail.com> wrote:
>
> Yes, I found the width option in the help pages, but I was wondering
> if there was automatic setting of the wrapping according to the
> current window width.
>
> Your function works exactly as I wished.  I'll probably get smarter
> with time (I hope) but would it be reasonably good practice to stick
> this into ~/.Rprofile?  I don't suppose there is a way to have it
> automatically invoked when the window size/positition changes?  (It's
> still priceless even without automatic triggering).
>
> On Fri, Apr 17, 2015 at 7:20 PM, MacQueen, Don <macqueen1 at llnl.gov>
> wrote:
> > A lot of this depends on what context you are running R in, e.g.,
> > Windows console, Mac console, or command line in a unix-alike. Or
> > within ESS in emacs. Those are different interfaces supported by, to
> > some extent, different people, and are based on the underlying
> > capabilities provided by the operating system.
> >
> > Have you yet encountered
> >   options()$width
> > ?
> > For example,
> >   options(width=100)
> > will cause wrapping at 100, at least for certain kinds of output.
> >
> > In an xterm shell running in an X windows context, I frequently use
> >
> > setwid <- function ()
> > {
> >     if (!interactive())
> >         return(invisible(NULL))
> >     scon <- pipe("stty -a")
> >     stty <- scan(scon, what = "", sep = ";", quiet = T)
> >     close(scon)
> >     cstr <- stty[grep("columns", stty)]
> >     options(width = as.numeric(gsub("[^0-9]", "", cstr, ignore.case = T)))
> >     paste("width =", options()$width, "\n")
> > }
> >
> > A function I wrote that resets the width option to match the window
> > widths, and therefore adjusts the wrapping after I resize a windwo.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Sat Apr 18 19:48:17 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Sat, 18 Apr 2015 10:48:17 -0700
Subject: [R] Programming R to avoid loops
In-Reply-To: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
References: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
Message-ID: <alpine.OSX.2.00.1504181023110.684@charles-berrys-macbook.local>

On Sat, 18 Apr 2015, Brant Inman wrote:

> I have two large data frames with the following structure:
>
>> df1
>  id       date test1.result
> 1  a 2009-08-28      1
> 2  a 2009-09-16      1
> 3  b 2008-08-06      0
> 4  c 2012-02-02      1
> 5  c 2010-08-03      1
> 6  c 2012-08-02      0
>
>> df2
>  id       date test2.result
> 1  a 2011-02-03      1
> 2  b 2011-09-27      0
> 3  b 2011-09-01      1
> 4  c 2009-07-16      0
> 5  c 2009-04-15      0
> 6  c 2010-08-10      1
>

> I need to match items in df2 to those in df1 with specific matching 
> criteria. I have written a looped matching algorithm that works, but it 
> is very slow with my large datasets. I am requesting help on making a 
> version of this code that is faster and ?vectorized" so to speak.

As I see in your posted code, you match id's exactly, dates according to a 
range, and count the number of positive test result in the second 
data.frame.

For this, the countOverlaps() function of the GenomicRanges package will 
do the trick with suitably defined GRanges objects. Something like:

require(GenomicRanges)

date1 <- as.integer( as.Date( df1$date, "%Y-%m-%d" ))
date2 <- as.integer( as.Date( df2$date, "%Y-%m-%d" ))

lagdays <- 30L
predays <- -30L

gr1 <- GRanges(seqnames=df1$id, IRanges(start=date1,width=1),strand="*")

gr2 <- GRanges(seqnames=df2$id,
                IRanges(start=date2+predays,end=date2+lagdays),
                strand="*")[ df2$test2.result==1,]

df1$test2.count <- countOverlaps(gr1,gr2)


For the example data.frames (as rendered by Jim Lemon's code), this yields

> df1
   id       date test1.result test2.count
1  a 2009-08-28            1           0
2  a 2009-09-16            1           0
3  b 2008-08-06            0           0
4  c 2012-02-02            1           0
5  c 2010-08-03            1           1
6  c 2012-08-02            0           0

The GenomicRanges package is at

http://www.bioconductor.org/packages/release/bioc/html/GenomicRanges.html

where you will find installation instructions and links to vignettes.

HTH,

Chuck

From ana-santos-gomez-94 at hotmail.com  Sat Apr 18 20:34:24 2015
From: ana-santos-gomez-94 at hotmail.com (=?iso-8859-1?B?YW5hIHNhbnRvcyBn821leg==?=)
Date: Sat, 18 Apr 2015 20:34:24 +0200
Subject: [R] =?iso-8859-1?q?Error_en_=60*tmp*=60=5B=5Bi=5D=5D_=3A_sub=EDnd?=
 =?iso-8859-1?q?ice_fuera_de__los_l=EDmites?=
Message-ID: <DUB115-W1920AF9E28B671A41A403FEFE20@phx.gbl>

I get this error when I try to execute the following order: repressed.genes.KO.WT.table <- aafTableAnn(repressed.genes.KO.WT, "mouse4302.db", aaf.handler())

I execute the same instruction with other circumstances such as "activated genes" and I don't get that error.

How can I solutionate this? Because I can't continue with the study without this information saved as html and txt.

Thank you very much
 		 	   		  
	[[alternative HTML version deleted]]


From paul-gowder at uiowa.edu  Sat Apr 18 19:14:31 2015
From: paul-gowder at uiowa.edu (Gowder, Paul)
Date: Sat, 18 Apr 2015 17:14:31 +0000
Subject: [R] basic q re: parsing functions, declaration order
Message-ID: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>

Hi there, 

So I?m doing some serious coding in R for the first time?writing a strategic simulation to run for a few (or many) thousand iterations,* and doing so in proper functional programming form, i.e., with a bunch of wrapper functions calling other wrapper functions calling the stuff that does the real work.  So, like: 

simulate.strat <- function(runs) {
  results <- # blah blah blah
  for (i in 1:runs) {
  run.res <- c(i,outer.wrapper())
  rbind(results,run.res)
  }
  write.table(results, file="simul_results.csv", row.names=TRUE, col.names=TRUE, sep=",?) 
# bonus question: there?s probably a vastly more efficient way to do this final write, any suggestions welcomed
}

outer.wrapper <- function() {
  goods <- dist.goods()
  power <- dist.power()
# blah blah blah
one.run <- inner.wrapper(goods, power, subgroups.num, subgroups.dist, trust, trust.errorvar)
  return(one.run)
}

dist.goods <- function() {
  elite.goods <- sample(1000:4000, 1)
# blah blah blah 
  goods.dist <- c(elite.dist, mass.dist)
  return(goods.dist)
}

and so forth.  

I?m just putting it all in one source file, which I plan to load using source(), and then actual execution will be via console input > simulate.strat(number of runs), leave town for the weekend, hopefully come back to find a csv with a bunch of results. 

But I?m not quite sure how the parser works with respect to defining all these functions.  Do I have to define them from inside out like one would in python?  (So, on the code above, that would mean defining, say, dist.goods() and dist.power() first, then outer.wrapper(), then simulate.strat().)  Or is there a way to prototype them like one would in C?  Or--- and I really hope this is the answer so I don?t have untangle the tangled web of functions I?m writing? is R smart enough/lazy enough to accept that the function defined at line K can call a function defined at line K+N and not stress about it?  

thanks so much!  My google-fu is failing me on this one.

-Paul


* why on earth, you might ask, am I doing this in R, rather than C or something?  Because I have a ton of computing resources and a huge workload. CPU time is cheap and my time is expensive? 

From sammankin at gmail.com  Sat Apr 18 19:55:14 2015
From: sammankin at gmail.com (Jim Mankin)
Date: Sat, 18 Apr 2015 10:55:14 -0700
Subject: [R] Programming R to avoid loops
In-Reply-To: <alpine.OSX.2.00.1504181023110.684@charles-berrys-macbook.local>
References: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
	<alpine.OSX.2.00.1504181023110.684@charles-berrys-macbook.local>
Message-ID: <6DCE0F24-3FE5-4CB9-8C24-E8BC52B3E1F3@gmail.com>

Jim Mankin liked your message with Boxer. On April 18, 2015 at 10:48:17 AM MST, Charles C. Berry <ccberry at ucsd.edu> wrote:On Sat, 18 Apr 2015, Brant Inman wrote:> I have two large data frames with the following structure:>>> df1> id date test1.result> 1 a 2009-08-28 1> 2 a 2009-09-16 1> 3 b 2008-08-06 0> 4 c 2012-02-02 1> 5 c 2010-08-03 1> 6 c 2012-08-02 0>>> df2> id date test2.result> 1 a 2011-02-03 1> 2 b 2011-09-27 0> 3 b 2011-09-01 1> 4 c 2009-07-16 0> 5 c 2009-04-15 0> 6 c 2010-08-10 1>> I need to match items in df2 to those in df1 with specific matching > criteria. I have written a looped matching algorithm that works, but it > is very slow with my large datasets. I am requesting help on making a > version of this code that is faster and ?vectorized" so to speak.As I see in your posted code, you match id's exactly, dates according to a range, and count the number of positive test result in the second data.frame.For this, the countOverlaps() function of the GenomicRanges package will do the trick with suitably defined GRanges objects. Something like:require(GenomicRanges)date1 date2 lagdays predays gr1 gr2  IRanges(start=date2+predays,end=date2+lagdays), strand="*")[ df2$test2.result==1,]df1$test2.count For the example data.frames (as rendered by Jim Lemon's code), this yields> df1 id date test1.result test2.count1 a 2009-08-28 1 02 a 2009-09-16 1 03 b 2008-08-06 0 04 c 2012-02-02 1 05 c 2010-08-03 1 16 c 2012-08-02 0 0The GenomicRanges package is athttp://www.bioconductor.org/packages/release/bioc/html/GenomicRanges.htmlwhere you will find installation instructions and links to vignettes.HTH,Chuck______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.     
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Apr 18 21:30:18 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 18 Apr 2015 12:30:18 -0700
Subject: [R] Programming R to avoid loops
In-Reply-To: <6DCE0F24-3FE5-4CB9-8C24-E8BC52B3E1F3@gmail.com>
References: <D5A19A7E-A4D1-4CA3-97A9-43484D36F696@me.com>
	<alpine.OSX.2.00.1504181023110.684@charles-berrys-macbook.local>
	<6DCE0F24-3FE5-4CB9-8C24-E8BC52B3E1F3@gmail.com>
Message-ID: <DEC06FF4-8251-4B8B-84F1-86A93CD50856@dcn.davis.CA.us>

Oh, great. An app [1] that introduces "me too" emails with a click and uses HTML to tell us all about it. Jim, this is probably not a good place to use that function. Read the posting guide about mailing list nettiquette.

[1] http://readwrite.com/2013/06/05/new-boxer-ios-email-app-is-all-about-adding-features
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 18, 2015 10:55:14 AM PDT, Jim Mankin <sammankin at gmail.com> wrote:
>Jim Mankin liked your message with Boxer. On April 18, 2015 at 10:48:17
>AM MST, Charles C. Berry <ccberry at ucsd.edu> wrote:On Sat, 18 Apr 2015,
>Brant Inman wrote:> I have two large data frames with the following
>structure:>>> df1> id date test1.result> 1 a 2009-08-28 1> 2 a
>2009-09-16 1> 3 b 2008-08-06 0> 4 c 2012-02-02 1> 5 c 2010-08-03 1> 6 c
>2012-08-02 0>>> df2> id date test2.result> 1 a 2011-02-03 1> 2 b
>2011-09-27 0> 3 b 2011-09-01 1> 4 c 2009-07-16 0> 5 c 2009-04-15 0> 6 c
>2010-08-10 1>> I need to match items in df2 to those in df1 with
>specific matching > criteria. I have written a looped matching
>algorithm that works, but it > is very slow with my large datasets. I
>am requesting help on making a > version of this code that is faster
>and ?vectorized" so to speak.As I see in your posted code, you match
>id's exactly, dates according to a range, and count the number of
>positive test result in the second data.frame.For this, the
>countOverlaps() function of the GenomicRanges package will do the trick
>with suitably defined GRanges objects. Something
>like:require(GenomicRanges)date1 date2 lagdays predays gr1 gr2 
>IRanges(start=date2+predays,end=date2+lagdays), strand="*")[
>df2$test2.result==1,]df1$test2.count For the example data.frames (as
>rendered by Jim Lemon's code), this yields> df1 id date test1.result
>test2.count1 a 2009-08-28 1 02 a 2009-09-16 1 03 b 2008-08-06 0 04 c
>2012-02-02 1 05 c 2010-08-03 1 16 c 2012-08-02 0 0The GenomicRanges
>package is
>athttp://www.bioconductor.org/packages/release/bioc/html/GenomicRanges.htmlwhere
>you will find installation instructions and links to
>vignettes.HTH,Chuck______________________________________________R-help at r-project.org
>mailing list -- To UNSUBSCRIBE and more,
>seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the
>posting guide http://www.R-project.org/posting-guide.htmland provide
>commented, minimal, self-contained, reproducible code.     
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Apr 18 21:40:18 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 18 Apr 2015 12:40:18 -0700
Subject: [R] basic q re: parsing functions, declaration order
In-Reply-To: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>
References: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>
Message-ID: <F8DAB7A4-A02B-404E-8DF0-AEBBFB4254E0@dcn.davis.CA.us>

You will eventually learn that scope in R is rather different than any of those other languages. However, if you don't think too hard about it, you should find it quite natural. So yes, you can call "forward" if you like to think of it that way.

However, your reference to a mess of functions does not portend well for leaving it running over the weekend successfully. I highly recommend testing your code on progressively larger amounts of data to test it out. Functional programs can be built systematically in R even if you are still getting the hang of it, but each function should have a clear goal and as few side effects as possible.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 18, 2015 10:14:31 AM PDT, "Gowder, Paul" <paul-gowder at uiowa.edu> wrote:
>Hi there, 
>
>So I?m doing some serious coding in R for the first time?writing a
>strategic simulation to run for a few (or many) thousand iterations,*
>and doing so in proper functional programming form, i.e., with a bunch
>of wrapper functions calling other wrapper functions calling the stuff
>that does the real work.  So, like: 
>
>simulate.strat <- function(runs) {
>  results <- # blah blah blah
>  for (i in 1:runs) {
>  run.res <- c(i,outer.wrapper())
>  rbind(results,run.res)
>  }
>write.table(results, file="simul_results.csv", row.names=TRUE,
>col.names=TRUE, sep=",?) 
># bonus question: there?s probably a vastly more efficient way to do
>this final write, any suggestions welcomed
>}
>
>outer.wrapper <- function() {
>  goods <- dist.goods()
>  power <- dist.power()
># blah blah blah
>one.run <- inner.wrapper(goods, power, subgroups.num, subgroups.dist,
>trust, trust.errorvar)
>  return(one.run)
>}
>
>dist.goods <- function() {
>  elite.goods <- sample(1000:4000, 1)
># blah blah blah 
>  goods.dist <- c(elite.dist, mass.dist)
>  return(goods.dist)
>}
>
>and so forth.  
>
>I?m just putting it all in one source file, which I plan to load using
>source(), and then actual execution will be via console input >
>simulate.strat(number of runs), leave town for the weekend, hopefully
>come back to find a csv with a bunch of results. 
>
>But I?m not quite sure how the parser works with respect to defining
>all these functions.  Do I have to define them from inside out like one
>would in python?  (So, on the code above, that would mean defining,
>say, dist.goods() and dist.power() first, then outer.wrapper(), then
>simulate.strat().)  Or is there a way to prototype them like one would
>in C?  Or--- and I really hope this is the answer so I don?t have
>untangle the tangled web of functions I?m writing? is R smart
>enough/lazy enough to accept that the function defined at line K can
>call a function defined at line K+N and not stress about it?  
>
>thanks so much!  My google-fu is failing me on this one.
>
>-Paul
>
>
>* why on earth, you might ask, am I doing this in R, rather than C or
>something?  Because I have a ton of computing resources and a huge
>workload. CPU time is cheap and my time is expensive? 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Sat Apr 18 22:07:09 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 18 Apr 2015 16:07:09 -0400
Subject: [R] =?utf-8?q?library=28xlsx=29_fails_with_an_error=3A_Error=3A_p?=
 =?utf-8?q?ackage_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
Message-ID: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103


I am having difficulty loading and installing the xlsx package. The
loading occurred without any problem, however the library command
library(xlsx) produced an error related to rJava. I tried to install
rJava seperately, re-loaded the xlsx package, and entered the
library(xlsx) command but received the same error message about rJave.
Please see terminal messages below. Any suggestion that would allow me
to load and run xlsx would be appreciated.
Thank you,
John


> install.packages("xlsx")
Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
trying URL
'http://cran.rstudio.com/bin/windows/contrib/3.1/xlsx_0.5.7.zip'
Content type 'application/zip' length 400944 bytes (391 KB)
opened URL
downloaded 391 KB


package ?xlsx? successfully unpacked and MD5 sums checked


The downloaded binary packages are in
	C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
> library(xlsx)
Loading required package: rJava
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: unable to load shared object
'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
  LoadLibrary failure:  The specified module could not be found.


Error: package ?rJava? could not be loaded
> install.packages("rJava")
Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
trying URL
'http://cran.rstudio.com/bin/windows/contrib/3.1/rJava_0.9-6.zip'
Content type 'application/zip' length 759396 bytes (741 KB)
opened URL
downloaded 741 KB


package ?rJava? successfully unpacked and MD5 sums checked


The downloaded binary packages are in
	C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
> library(rJava)
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: unable to load shared object
'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
  LoadLibrary failure:  The specified module could not be found.


Error: package or namespace load failed for ?rJava?
> library(xlsx)
Loading required package: rJava
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: unable to load shared object
'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
  LoadLibrary failure:  The specified module could not be found.


Error: package ?rJava? could not be loaded


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From peter.crowther at melandra.com  Sat Apr 18 22:41:01 2015
From: peter.crowther at melandra.com (Peter Crowther)
Date: Sat, 18 Apr 2015 21:41:01 +0100
Subject: [R] Smart detection of wrap width?
In-Reply-To: <CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
	<CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
Message-ID: <CALhdq6viSZYVMiu8=ZTQEwsccnBrMCV3GMKOtyA_WJ0k=gC66Q@mail.gmail.com>

On Apr 17, 2015 7:37 PM, "Paul Domaskis" <paul.domaskis at gmail.com> wrote:
> I don't suppose there is a way to have it
> automatically invoked when the window size/positition changes?

Possibly, though it would take a little building.  If you were to
launch R directly when you start the xterm (loosely xterm R rather
than the default) then R would receive a SIGWINCH signal whenever the
xterm window size changes (xterm automatically sends this to its child
process).  R doesn't directly enable handling of the signal, but
there's nothing to stop you loading a dynamic library with a little C
code that set up a handler for SIGWINCH and, when it got one, ran the
equivalent of the stty command to get the new width.  The thing I've
not been able to figure out is how the C code would ever then hand
that to R asynchronously.  Anyone?

Cheers,

- Peter


From boris.steipe at utoronto.ca  Sat Apr 18 19:30:47 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Apr 2015 13:30:47 -0400
Subject: [R] suggestion of regex pattern
In-Reply-To: <CAOwqRytEwuYUSBx8bj0jK0MEGS-Cdnu-WFEfrVYsheNEV4R25w@mail.gmail.com>
References: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
	<32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>
	<CAOwqRytEwuYUSBx8bj0jK0MEGS-Cdnu-WFEfrVYsheNEV4R25w@mail.gmail.com>
Message-ID: <EF70BB75-CEBE-4481-8754-009F6EA07C19@utoronto.ca>

Sorry - it's not entirely clear to me what you need to do.

See here for some hints on how to ask questions on this list. I'm sure we'll be able to help quickly.
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
(and don't post in HTML   :-)


B.

On Apr 18, 2015, at 11:10 AM, Fernando Gama <f.fabiogama88 at gmail.com> wrote:

> Hello Boris,
> 
> thanks for your response. 
> 
> So, firstly considered that  i've been input a set of serches strings (.txt format) and i'm using regex to transform in a suitable  format to my script. This part is a final part of my code and i wish putting in input to a subset.
> 
> (.txt formatted)
> 
> ---- STRINGS (INPUT)
>  
> [1]  "municipio =='Limeira' "
> [2]  "municipio =='Limeira' & mesincident =='marco' "
> [3]  "?municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300"
> ...
> ..
> ..
> ..
> [n] "......"
> 
> --------------
> 
> desired_fomart <- ?it will reveice all strings to filter in a dataset by subset below:
> 
> 
> a loop each line:
> 
> subset(dataset_read, desired_fomart[i])
> 
> My question: taking into consideration this cenario, in your oppinion your reply is my suitable for my problem, whereas i will to map each value in database?
> 
> Once again, thank so much! :)
> 
> 2015-04-18 11:04 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> This is not a regular expression but simply a conjunction (sequence of '&') of logical expressions. Moreover it's not wrong. Consider:
> 
> xyz <- data.frame(municipio = c('Limeira'), mesincident = c('marco'), trechoklmetros = c(3.00, -4.00, 30))
> xyz
> 
>   municipio mesincident trechoklmetros
> 1   Limeira       marco              3
> 2   Limeira       marco             -4
> 3   Limeira       marco             30
> 
> 
> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00
> [1]  TRUE FALSE  TRUE
> 
> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00 & xyz$trechoklmetros <= 12.3
> [1]  TRUE FALSE FALSE
> 
> 
> If there's a problem it seems to be elsewhere.
> Cheers,
> Boris
> 
> 
> On Apr 17, 2015, at 4:22 PM, Fernando Gama <f.fabiogama88 at gmail.com> wrote:
> 
> > Hello,
> >
> > I have benn problems to construct the pattern for this:
> >
> > municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300
> >
> > I would like:
> >
> > municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> > *& **trechoklmetros
> > <= *12.300
> > ?
> > ?Any suggestion??
> >
> >
> > --
> > Att,
> >
> > Fernando Gama da Mata
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> -- 
> Att,
> 
> Fernando Gama da Mata
> 
> 


From boris.steipe at utoronto.ca  Sat Apr 18 22:54:04 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Apr 2015 16:54:04 -0400
Subject: [R]
 =?iso-8859-1?q?Error_en_=60*tmp*=60=5B=5Bi=5D=5D_=3A_sub=EDnd?=
 =?iso-8859-1?q?ice_fuera_de__los_l=EDmites?=
In-Reply-To: <DUB115-W1920AF9E28B671A41A403FEFE20@phx.gbl>
References: <DUB115-W1920AF9E28B671A41A403FEFE20@phx.gbl>
Message-ID: <B1F337BF-14D8-4B99-A4FA-203245BA048A@utoronto.ca>

You haven't provided nearly enough information for us to be able to help.
Please see here for some hints on how to ask questions productively:
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide and don't post in HTML.

B.


On Apr 18, 2015, at 2:34 PM, ana santos g?mez <ana-santos-gomez-94 at hotmail.com> wrote:

> I get this error when I try to execute the following order: repressed.genes.KO.WT.table <- aafTableAnn(repressed.genes.KO.WT, "mouse4302.db", aaf.handler())
> 
> I execute the same instruction with other circumstances such as "activated genes" and I don't get that error.
> 
> How can I solutionate this? Because I can't continue with the study without this information saved as html and txt.
> 
> Thank you very much
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Apr 18 22:59:30 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 18 Apr 2015 13:59:30 -0700
Subject: [R] basic q re: parsing functions, declaration order
In-Reply-To: <F8DAB7A4-A02B-404E-8DF0-AEBBFB4254E0@dcn.davis.CA.us>
References: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>
	<F8DAB7A4-A02B-404E-8DF0-AEBBFB4254E0@dcn.davis.CA.us>
Message-ID: <CACk-te0-yHKJBudOnVz=TZqWSNOQ23LutBehX8Pqn0fmarUn_Q@mail.gmail.com>

1. You should read a suitable R tutorial before proceeding. Is it not
advisable to learn a language's syntax before attempting to program in
it? An Intro to R ships with R, but there are many others available on
the Web. Choose that which suits. You may also wish to look at the R
Language manual; specifically your questions *may* have to do with
"lazy evaluation" in function calls (one aspect of which is: a default
argument in a function call is not evaluated until needed and can be
given a value in the body of a function that can depend on other
function arguments).

2. As Jeff intimated, you can use not -yet -defined functions in a
function definition (line # is a meaningless concept in R, though I
get your meaning). But the issue is: what is used when the function is
called.  This is all about scope, which in its full details is rather
complicated. But as Jeff intimated, in your situation, not worrying
about it may work fine.

Cheers,

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Apr 18, 2015 at 12:40 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You will eventually learn that scope in R is rather different than any of those other languages. However, if you don't think too hard about it, you should find it quite natural. So yes, you can call "forward" if you like to think of it that way.
>
> However, your reference to a mess of functions does not portend well for leaving it running over the weekend successfully. I highly recommend testing your code on progressively larger amounts of data to test it out. Functional programs can be built systematically in R even if you are still getting the hang of it, but each function should have a clear goal and as few side effects as possible.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 18, 2015 10:14:31 AM PDT, "Gowder, Paul" <paul-gowder at uiowa.edu> wrote:
>>Hi there,
>>
>>So I?m doing some serious coding in R for the first time?writing a
>>strategic simulation to run for a few (or many) thousand iterations,*
>>and doing so in proper functional programming form, i.e., with a bunch
>>of wrapper functions calling other wrapper functions calling the stuff
>>that does the real work.  So, like:
>>
>>simulate.strat <- function(runs) {
>>  results <- # blah blah blah
>>  for (i in 1:runs) {
>>  run.res <- c(i,outer.wrapper())
>>  rbind(results,run.res)
>>  }
>>write.table(results, file="simul_results.csv", row.names=TRUE,
>>col.names=TRUE, sep=",?)
>># bonus question: there?s probably a vastly more efficient way to do
>>this final write, any suggestions welcomed
>>}
>>
>>outer.wrapper <- function() {
>>  goods <- dist.goods()
>>  power <- dist.power()
>># blah blah blah
>>one.run <- inner.wrapper(goods, power, subgroups.num, subgroups.dist,
>>trust, trust.errorvar)
>>  return(one.run)
>>}
>>
>>dist.goods <- function() {
>>  elite.goods <- sample(1000:4000, 1)
>># blah blah blah
>>  goods.dist <- c(elite.dist, mass.dist)
>>  return(goods.dist)
>>}
>>
>>and so forth.
>>
>>I?m just putting it all in one source file, which I plan to load using
>>source(), and then actual execution will be via console input >
>>simulate.strat(number of runs), leave town for the weekend, hopefully
>>come back to find a csv with a bunch of results.
>>
>>But I?m not quite sure how the parser works with respect to defining
>>all these functions.  Do I have to define them from inside out like one
>>would in python?  (So, on the code above, that would mean defining,
>>say, dist.goods() and dist.power() first, then outer.wrapper(), then
>>simulate.strat().)  Or is there a way to prototype them like one would
>>in C?  Or--- and I really hope this is the answer so I don?t have
>>untangle the tangled web of functions I?m writing? is R smart
>>enough/lazy enough to accept that the function defined at line K can
>>call a function defined at line K+N and not stress about it?
>>
>>thanks so much!  My google-fu is failing me on this one.
>>
>>-Paul
>>
>>
>>* why on earth, you might ask, am I doing this in R, rather than C or
>>something?  Because I have a ton of computing resources and a huge
>>workload. CPU time is cheap and my time is expensive?
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Apr 18 23:45:48 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 19 Apr 2015 07:45:48 +1000
Subject: [R] Where is the R Graph Gallery?
In-Reply-To: <7B97E150426.00000A59jrkrideau@inbox.com>
References: <7afbba3d4a0.000009d5jrkrideau@inbox.com>
	<553249ca.1070306@yeah.net>
	<21810.26444.716972.902649@max.nulle.part>
	<7B97E150426.00000A59jrkrideau@inbox.com>
Message-ID: <CA+8X3fWLB4GHRW5k65HjnYb70WiZbsrH+3LFNTfpC4XVjMUmdA@mail.gmail.com>

Hi all,
http://rgraphgallery.blogspot.com/ contains much of what was on
addictedtor, and if one wants to add more examples, it isn't too hard.

Jim

On Sun, Apr 19, 2015 at 12:39 AM, John Kane <jrkrideau at inbox.com> wrote:
> I thought I'd read about a migration. Well so much for memory.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: edd at debian.org
>> Sent: Sat, 18 Apr 2015 09:16:44 -0500
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] Where is the R Graph Gallery?
>>
>>
>> On 18 April 2015 at 05:29, John Kane wrote:
>> | I think it moved to http://rgraphgallery.blogspot.com/ with a different
>> interface.
>>
>> I don't think so. Something I contributed years ago to the original Graph
>> Gallery is not on this site.
>>
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sat Apr 18 23:55:20 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Apr 2015 17:55:20 -0400
Subject: [R] suggestion of regex pattern
In-Reply-To: <EF70BB75-CEBE-4481-8754-009F6EA07C19@utoronto.ca>
References: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
	<32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>
	<CAOwqRytEwuYUSBx8bj0jK0MEGS-Cdnu-WFEfrVYsheNEV4R25w@mail.gmail.com>
	<EF70BB75-CEBE-4481-8754-009F6EA07C19@utoronto.ca>
Message-ID: <61774DD2-40F2-4A74-B70D-3F9D9AAA1C16@utoronto.ca>

Re-reading your question and taking a wild guess, perhaps you are looking for parse() and eval() ...

xyz <- data.frame( a=c(1,2), b=c(3,4))
xyz

  a b
1 1 3
2 2 4

expp <- parse(text="xyz$a > 1 & xyz$b == 4")   # turn a string into an expression
expp

expression(xyz$a > 1 & xyz$b == 4)

xyz[eval(expp), ]                              # evaluate an expression in place
  a b
2 2 4

... but really, it's just a guess at what you might be trying to do.

B.



 
On Apr 18, 2015, at 1:30 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> Sorry - it's not entirely clear to me what you need to do.
> 
> See here for some hints on how to ask questions on this list. I'm sure we'll be able to help quickly.
> http://adv-r.had.co.nz/Reproducibility.html
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> (and don't post in HTML   :-)
> 
> 
> B.
> 
> On Apr 18, 2015, at 11:10 AM, Fernando Gama <f.fabiogama88 at gmail.com> wrote:
> 
>> Hello Boris,
>> 
>> thanks for your response. 
>> 
>> So, firstly considered that  i've been input a set of serches strings (.txt format) and i'm using regex to transform in a suitable  format to my script. This part is a final part of my code and i wish putting in input to a subset.
>> 
>> (.txt formatted)
>> 
>> ---- STRINGS (INPUT)
>> 
>> [1]  "municipio =='Limeira' "
>> [2]  "municipio =='Limeira' & mesincident =='marco' "
>> [3]  "?municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300"
>> ...
>> ..
>> ..
>> ..
>> [n] "......"
>> 
>> --------------
>> 
>> desired_fomart <- ?it will reveice all strings to filter in a dataset by subset below:
>> 
>> 
>> a loop each line:
>> 
>> subset(dataset_read, desired_fomart[i])
>> 
>> My question: taking into consideration this cenario, in your oppinion your reply is my suitable for my problem, whereas i will to map each value in database?
>> 
>> Once again, thank so much! :)
>> 
>> 2015-04-18 11:04 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> This is not a regular expression but simply a conjunction (sequence of '&') of logical expressions. Moreover it's not wrong. Consider:
>> 
>> xyz <- data.frame(municipio = c('Limeira'), mesincident = c('marco'), trechoklmetros = c(3.00, -4.00, 30))
>> xyz
>> 
>>  municipio mesincident trechoklmetros
>> 1   Limeira       marco              3
>> 2   Limeira       marco             -4
>> 3   Limeira       marco             30
>> 
>> 
>> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00
>> [1]  TRUE FALSE  TRUE
>> 
>> xyz$municipio =='Limeira' & xyz$mesincident =='marco' & xyz$trechoklmetros > 1.00 & xyz$trechoklmetros <= 12.3
>> [1]  TRUE FALSE FALSE
>> 
>> 
>> If there's a problem it seems to be elsewhere.
>> Cheers,
>> Boris
>> 
>> 
>> On Apr 17, 2015, at 4:22 PM, Fernando Gama <f.fabiogama88 at gmail.com> wrote:
>> 
>>> Hello,
>>> 
>>> I have benn problems to construct the pattern for this:
>>> 
>>> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00 12.300
>>> 
>>> I would like:
>>> 
>>> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
>>> *& **trechoklmetros
>>> <= *12.300
>>> ?
>>> ?Any suggestion??
>>> 
>>> 
>>> --
>>> Att,
>>> 
>>> Fernando Gama da Mata
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> -- 
>> Att,
>> 
>> Fernando Gama da Mata
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Sun Apr 19 03:41:08 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 18 Apr 2015 21:41:08 -0400
Subject: [R] Smart detection of wrap width?
In-Reply-To: <CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
	<CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
Message-ID: <CA+vqiLFb2unNS57K_h6cMeRXOizE=s7ci6xueBW2vQin=10aQg@mail.gmail.com>

I see now that the link I gave for configuring this is ESS doesn't
give the whole enchilada. Here is what I currently have in my emacs
config:

  (defun my-ess-execute-screen-options (foo)
                (ess-execute-screen-options))
  (add-hook 'inferior-ess-mode-hook
            (lambda()
              (setq-local
               window-size-change-functions
               '(my-ess-execute-screen-options))))

This should give the desired functionality.

Best,
Ista

On Sat, Apr 18, 2015 at 1:26 PM, Ista Zahn <istazahn at gmail.com> wrote:
> For ESS see https://github.com/gaborcsardi/dot-emacs/blob/master/.emacs
>
> Best,
> Ista
>
> On Apr 17, 2015 7:37 PM, "Paul Domaskis" <paul.domaskis at gmail.com> wrote:
>>
>> Yes, I found the width option in the help pages, but I was wondering
>> if there was automatic setting of the wrapping according to the
>> current window width.
>>
>> Your function works exactly as I wished.  I'll probably get smarter
>> with time (I hope) but would it be reasonably good practice to stick
>> this into ~/.Rprofile?  I don't suppose there is a way to have it
>> automatically invoked when the window size/positition changes?  (It's
>> still priceless even without automatic triggering).
>>
>> On Fri, Apr 17, 2015 at 7:20 PM, MacQueen, Don <macqueen1 at llnl.gov>
>> wrote:
>> > A lot of this depends on what context you are running R in, e.g.,
>> > Windows console, Mac console, or command line in a unix-alike. Or
>> > within ESS in emacs. Those are different interfaces supported by, to
>> > some extent, different people, and are based on the underlying
>> > capabilities provided by the operating system.
>> >
>> > Have you yet encountered
>> >   options()$width
>> > ?
>> > For example,
>> >   options(width=100)
>> > will cause wrapping at 100, at least for certain kinds of output.
>> >
>> > In an xterm shell running in an X windows context, I frequently use
>> >
>> > setwid <- function ()
>> > {
>> >     if (!interactive())
>> >         return(invisible(NULL))
>> >     scon <- pipe("stty -a")
>> >     stty <- scan(scon, what = "", sep = ";", quiet = T)
>> >     close(scon)
>> >     cstr <- stty[grep("columns", stty)]
>> >     options(width = as.numeric(gsub("[^0-9]", "", cstr, ignore.case = T)))
>> >     paste("width =", options()$width, "\n")
>> > }
>> >
>> > A function I wrote that resets the width option to match the window
>> > widths, and therefore adjusts the wrapping after I resize a windwo.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Sun Apr 19 05:06:26 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 18 Apr 2015 22:06:26 -0500
Subject: [R] R code/package for calculation of Wasserstein distance between
 two densities
Message-ID: <20150418220626.7dfa9e3976764f8a01a121b2@inbox.com>

Dear friends, 

Before reinventing the wheel, I was wondering if anyone can point me to code for calculating the Wasserstein distance between two densities. I am particularly interested in mixture densities (in functional form). I know that we have the earthmovers distance in R via the emdist package but it appears to me upon a quick look that this can not handle densities in functional form. So, I was wondering if anyone had any ideas on code for this problem. 

Many thanks and best wishes,
Ranjan

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From JSorkin at grecc.umaryland.edu  Sun Apr 19 05:12:41 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 18 Apr 2015 23:12:41 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
 . . . . ., n, n, n, n
Message-ID: <5532E4E9020000CB00129DE4@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103



I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.


1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n


(The spaces in the list are added only for clarity.)


 I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!


c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))


Can anyone help me?


Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From rhurlin at gwdg.de  Sun Apr 19 12:02:44 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 19 Apr 2015 12:02:44 +0200
Subject: [R]
 =?utf-8?q?library=28xlsx=29_fails_with_an_error=3A_Error=3A_p?=
 =?utf-8?q?ackage_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
References: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
Message-ID: <55337D44.1030604@gwdg.de>

Hi John,

Am 18.04.2015 um 22:07 schrieb John Sorkin:
> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
> 
> 
> I am having difficulty loading and installing the xlsx package. The
> loading occurred without any problem, however the library command
> library(xlsx) produced an error related to rJava. I tried to install
> rJava seperately, re-loaded the xlsx package, and entered the
> library(xlsx) command but received the same error message about rJave.
> Please see terminal messages below. Any suggestion that would allow me
> to load and run xlsx would be appreciated.
> Thank you,
> John
> 
> 
>> install.packages("xlsx")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/xlsx_0.5.7.zip'
> Content type 'application/zip' length 400944 bytes (391 KB)
> opened URL
> downloaded 391 KB
> 
> 
> package ?xlsx? successfully unpacked and MD5 sums checked
> 
> 
> The downloaded binary packages are in
> 	C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
>> library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error: package ?rJava? could not be loaded
>> install.packages("rJava")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/rJava_0.9-6.zip'
> Content type 'application/zip' length 759396 bytes (741 KB)
> opened URL
> downloaded 741 KB
> 
> 
> package ?rJava? successfully unpacked and MD5 sums checked
> 
> 
> The downloaded binary packages are in
> 	C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
>> library(rJava)
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error: package or namespace load failed for ?rJava?
>> library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error: package ?rJava? could not be loaded

There are several possibilities, why your rJava does not find rJava.dll.
A good start give [1] to [3].

Did you have the right installation of JAVA itself?

I think, in your case, the JAVA installation itself should be the 64bit
version, and probably better version 1.8 than 1.7 [3] (someone please
correct me, if I am wrong here).

You get some hints about parameters with
R CMD javareconf --help

HTH.
Regards,
Rainer Hurling


[1]
http://cran.at.r-project.org/doc/manuals/r-release/R-admin.html#Java-support
[2]
http://cran.at.r-project.org/bin/windows/base/rw-FAQ.html#Loading-a-package-fails_002e
[3]
http://stackoverflow.com/questions/7019912/using-the-rjava-package-on-win7-64-bit-with-r


> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


From marongiu.luigi at gmail.com  Sun Apr 19 10:17:11 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sun, 19 Apr 2015 09:17:11 +0100
Subject: [R] Handling NA values in a if statement
In-Reply-To: <62FA2704-3C5A-4E5D-8D23-058E211411A6@me.com>
References: <CAMk+s2SQ=Ggh8WGdjE-7XJmoirCpXKchb=xDx-AHSfT1dOa3Cg@mail.gmail.com>
	<62FA2704-3C5A-4E5D-8D23-058E211411A6@me.com>
Message-ID: <CAMk+s2Sna=ADgobEzD0e37Pp7AEF80tiQ5D0MnGwAh5GEw04sA@mail.gmail.com>

Dear David and Mark,
thank you for your reply. I have implemented the suggestions you have
made in the following:
x <- c(-Inf,  Inf,    NA,    5.9,    6.08,    5281391136138.75,
       4.35,    4.79,
       9474097322.96,    3.64,    16.42,    -12211.11,    4.37,
       -1097.79,    4.78,
       3.71,    32.59,    4.01,    35.36,    3.17,    1.61,
       -3678.28,    2.9,    4.67,
       4.1,    348410866.78,    5.35,    4.3101519459837E+016,
       1467030866.75,
       1.10376094956278E+018,    32.55,    1.17,    5339028670388.94,
       34.14,
       33205967009.57,    4.42,    1.76,    7.08,    -8428.84,
       -113491.08,    17.81)
ll <- 1
ul <- 45

clipper <- function(x, ll, ul) {
  for(i in 1:length(x)) {
    if(is.finite(x[i]) < ll & is.finite(x[i]) > ul) {
      x[i] <- NA
    } else if (is.infinite(x[i]) == "TRUE") {
      x[i] <- NA
    } else {
      x[i] <- x[i]
    }
  }
  return(x)
}
(X<-clipper(x, ll, ul))

that works all right.
Best regards
Luigi


On Fri, Apr 17, 2015 at 11:43 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Apr 17, 2015, at 5:23 PM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Dear all,
>> I have a vector with a certain range of values including infinity and
>> NA. I would like to remove the values that are outside a given range
>> (lower level = ll and upper level = ul) but I am getting the error due
>> to the NA values (missing value where TRUE/FALSE needed). I then
>> included the !is.na() but now the resulting error is all NA, as in the
>> example.
>> In addition, here I have implemented a for loop to scan all the
>> elements of the vector, but I should be able to use the sapply();
>> however I don't know how to send the ll and ul arguments to sapply().
>> Could you please help?
>> best regards
>> Luigi
>>
>> EXAMPLE
>>
>> x <- c(-Inf,  Inf,    NA,    5.9,    6.08,    5281391136138.75,
>> 4.35,    4.79,
>>       9474097322.96,    3.64,    16.42,    -12211.11,    4.37,
>> -1097.79,    4.78,
>>       3.71,    32.59,    4.01,    35.36,    3.17,    1.61,
>> -3678.28,    2.9,    4.67,
>>       4.1,    348410866.78,    5.35,    4.3101519459837E+016,
>> 1467030866.75,
>>       1.10376094956278E+018,    32.55,    1.17,    5339028670388.94,
>>  34.14,
>>       33205967009.57,    4.42,    1.76,    7.08,    -8428.84,
>> -113491.08,    17.81)
>> ll <- 1
>> ul <- 45
>>
>> clipper <- function(x, ll, ul) {
>>  for(i in 1:length(x)) {
>>    if(x[i] < ll) {
>>      x[i] <- NA
>>    } else if(x[i] > ul) {
>>      x[i] <- NA
>>    } else {
>>      x[i] <- x[i]
>>    }
>>  }
>> return(x)
>> }
>> (X<-clipper(x, ll, ul))
>>> missing value where TRUE/FALSE needed
>>
>>
>> clipper <- function(x, ll, ul) {
>>  for(i in 1:length(x)) {
>>    if(!is.na(x[i]) < ll) {
>>      x[i] <- NA
>>    } else if(!is.na(x[i]) > ul) {
>>      x[i] <- NA
>>    } else {
>>      x[i] <- x[i]
>>    }
>>  }
>> return(x)
>> }
>> (X<-clipper(x, ll, ul))
>>
>> [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
>> NA NA NA NA NA
>> [28] NA NA NA NA NA NA NA NA NA NA NA NA NA NA
>
>
> Hi,
>
> Something along the lines of:
>
>> subset(x, is.finite(x) & (x > ll) & (x < ul))
>  [1]  5.90  6.08  4.35  4.79  3.64 16.42  4.37  4.78  3.71 32.59  4.01
> [12] 35.36  3.17  1.61  2.90  4.67  4.10  5.35 32.55  1.17 34.14  4.42
> [23]  1.76  7.08 17.81
>
> or:
>
>> x[is.finite(x) & (x > ll) & (x < ul)]
>  [1]  5.90  6.08  4.35  4.79  3.64 16.42  4.37  4.78  3.71 32.59  4.01
> [12] 35.36  3.17  1.61  2.90  4.67  4.10  5.35 32.55  1.17 34.14  4.42
> [23]  1.76  7.08 17.81
>
>
> See ?subset and ?is.finite:
>
>> is.finite(x)
>  [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> [12]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> [23]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> [34]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
>
>
> Regards,
>
> Marc Schwartz
>


From marongiu.luigi at gmail.com  Sun Apr 19 11:27:54 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sun, 19 Apr 2015 10:27:54 +0100
Subject: [R] high density plots using lattice dotplot()
Message-ID: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>

Dear all,
I am trying to plot the results of a PCR experiments that involves 384
individual plots. Admittedly the space for the plots will be tiny, but
I just nedd some icon to have a feeling of the layout of the
experiment and a quick comparison of the plots.
I believe that lattice would be the right tool, but when I tried to
implement i got an error. Specifically the output would be a A4 pdf,
so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
each plot; removing the labels that might just work.
So I have the y values = 'fluorescence', x 'values' = cycles and 384
'well' data. I implemented to begin with:

xyplot(fluorescence ~ cycles | well,
         ylab="Fluorescence",
         xlab="Cycles",
         main=list(draw = FALSE),
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         layout = c(24,16),
         par.settings = list(strip.background=list(col="white")),
         pch = "."
  )

but the  the individual graphs show only the writing "data" instead of
the actual plots.
How can I overcome this error?
Thank you
Best regards
Luigi


From JSorkin at grecc.umaryland.edu  Sun Apr 19 14:56:39 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 08:56:39 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
 . . . . ., n, n, n, n
Message-ID: <55336DC7020000CB00129E2A@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103


I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.

1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n

(The spaces in the list are added only for clarity.)

 I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!

c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))

Can anyone help me?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From JSorkin at grecc.umaryland.edu  Sun Apr 19 15:20:28 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 09:20:28 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
 . . . . ., n, n, n, n
References: 5532E4E9.medlxdom.medlxpo.200.20000CB.1.129DE4.1
Message-ID: <5533735C020000CB00129E34@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103


I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.

1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n

(The spaces in the list are added only for clarity.)

 I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!

c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))

Can anyone help me?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From JSorkin at grecc.umaryland.edu  Sun Apr 19 15:44:28 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 09:44:28 -0400
Subject: [R] error using by, Error in tapply(response, list(x.factor,
 trace.factor), fun) : argument "trace.factor" is missing, with no default
Message-ID: <553378FC020000CB00129E41@smtp.medicine.umaryland.edu>



I am receiving an error message from the by function that I don't understand:
Error in tapply(response, list(x.factor, trace.factor), fun) : 
  argument "trace.factor" is missing, with no default



My code follows:


> summary(ipd)
 group      values            time      subjects     weaned disp  
 1:55   Min.   :0.0000   Min.   :0   Min.   :115.0   1:65   2:45  
 2:35   1st Qu.:0.1950   1st Qu.:1   1st Qu.:121.0   2:25   3: 5  
        Median :0.3400   Median :2   Median :126.0          4:20  
        Mean   :0.3479   Mean   :2   Mean   :127.6          5:20  
        3rd Qu.:0.5000   3rd Qu.:3   3rd Qu.:134.0                
        Max.   :0.7300   Max.   :4   Max.   :144.0                
        NA's   :48                                                
> by(ipd[,c("time","subjects","values")],ipd[,"group"],interaction.plot)
Error in tapply(response, list(x.factor, trace.factor), fun) : 
  argument "trace.factor" is missing, with no default




These are my data.
> ipd
   group values time subjects weaned disp
1      1   0.00    0      115      1    2
2      1   0.00    1      115      1    2
3      1   0.18    2      115      1    2
4      1   0.17    3      115      1    2
5      1     NA    4      115      1    2
6      1   0.62    0      116      1    2
7      1     NA    1      116      1    2
8      1     NA    2      116      1    2
9      1     NA    3      116      1    2
10     1     NA    4      116      1    2
11     1   0.00    0      118      1    2
12     1   0.21    1      118      1    2
13     1   0.34    2      118      1    2
14     1   0.49    3      118      1    2
15     1     NA    4      118      1    2
16     2   0.52    0      119      2    4
17     2     NA    1      119      2    4
18     2     NA    2      119      2    4
19     2     NA    3      119      2    4
20     2     NA    4      119      2    4
21     2   0.35    0      121      2    3
22     2   0.53    1      121      2    3
23     2   0.35    2      121      2    3
24     2   0.44    3      121      2    3
25     2   0.56    4      121      2    3
26     1   0.16    0      122      1    5
27     1   0.22    1      122      1    5
28     1     NA    2      122      1    5
29     1     NA    3      122      1    5
30     1     NA    4      122      1    5
31     1   0.19    0      123      2    5
32     1     NA    1      123      2    5
33     1     NA    2      123      2    5
34     1     NA    3      123      2    5
35     1     NA    4      123      2    5
36     2   0.29    0      124      1    4
37     2   0.22    1      124      1    4
38     2     NA    2      124      1    4
39     2     NA    3      124      1    4
40     2     NA    4      124      1    4
41     1   0.38    0      125      1    4
42     1   0.45    1      125      1    4
43     1     NA    2      125      1    4
44     1     NA    3      125      1    4
45     1     NA    4      125      1    4
46     1   0.22    0      127      1    2
47     1   0.37    1      127      1    2
48     1   0.28    2      127      1    2
49     1   0.50    3      127      1    2
50     1     NA    4      127      1    2
51     1   0.30    0      130      1    2
52     1   0.49    1      130      1    2
53     1     NA    2      130      1    2
54     1     NA    3      130      1    2
55     1     NA    4      130      1    2
56     1   0.70    0      131      1    2
57     1     NA    1      131      1    2
58     1     NA    2      131      1    2
59     1     NA    3      131      1    2
60     1     NA    4      131      1    2
61     2   0.00    0      133      1    2
62     2   0.50    1      133      1    2
63     2   0.56    2      133      1    2
64     2   0.73    3      133      1    2
65     2     NA    4      133      1    2
66     1   0.22    0      134      1    2
67     1   0.65    1      134      1    2
68     1     NA    2      134      1    2
69     1     NA    3      134      1    2
70     1     NA    4      134      1    2
71     2   0.34    0      135      1    2
72     2   0.73    1      135      1    2
73     2   0.71    2      135      1    2
74     2     NA    3      135      1    2
75     2     NA    4      135      1    2
76     2   0.26    0      139      2    5
77     2     NA    1      139      2    5
78     2     NA    2      139      2    5
79     2     NA    3      139      2    5
80     2     NA    4      139      2    5
81     1   0.00    0      140      1    5
82     1   0.19    1      140      1    5
83     1     NA    2      140      1    5
84     1     NA    3      140      1    5
85     1     NA    4      140      1    5
86     2   0.19    0      144      2    4
87     2     NA    1      144      2    4
88     2     NA    2      144      2    4
89     2     NA    3      144      2    4
90     2     NA    4      144      2    4


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From JSorkin at grecc.umaryland.edu  Sun Apr 19 15:44:56 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 09:44:56 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
 . . . . ., n, n, n, n
References: 55336DC7.medlxdom.medlxpo.200.20000CB.1.129E2A.1
Message-ID: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103


I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.

1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n

(The spaces in the list are added only for clarity.)

 I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!

c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))

Can anyone help me?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From JSorkin at grecc.umaryland.edu  Sun Apr 19 16:33:50 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 10:33:50 -0400
Subject: [R] error using by, Error in tapply(response, list(x.factor,
 trace.factor), fun) : argument "trace.factor" is missing, with no default
References: 55337892.medlxdom.medlxpo.200.20000CB.1.129E3B.1
Message-ID: <5533848E020000CB00129E51@smtp.medicine.umaryland.edu>



I am receiving an error message from the by function that I don't understand:
Error in tapply(response, list(x.factor, trace.factor), fun) : 
  argument "trace.factor" is missing, with no default



My code follows:


> summary(ipd)
 group      values            time      subjects     weaned disp  
 1:55   Min.   :0.0000   Min.   :0   Min.   :115.0   1:65   2:45  
 2:35   1st Qu.:0.1950   1st Qu.:1   1st Qu.:121.0   2:25   3: 5  
        Median :0.3400   Median :2   Median :126.0          4:20  
        Mean   :0.3479   Mean   :2   Mean   :127.6          5:20  
        3rd Qu.:0.5000   3rd Qu.:3   3rd Qu.:134.0                
        Max.   :0.7300   Max.   :4   Max.   :144.0                
        NA's   :48                                                
> by(ipd[,c("time","subjects","values")],ipd[,"group"],interaction.plot)
Error in tapply(response, list(x.factor, trace.factor), fun) : 
  argument "trace.factor" is missing, with no default




These are my data.
> ipd
   group values time subjects weaned disp
1      1   0.00    0      115      1    2
2      1   0.00    1      115      1    2
3      1   0.18    2      115      1    2
4      1   0.17    3      115      1    2
5      1     NA    4      115      1    2
6      1   0.62    0      116      1    2
7      1     NA    1      116      1    2
8      1     NA    2      116      1    2
9      1     NA    3      116      1    2
10     1     NA    4      116      1    2
11     1   0.00    0      118      1    2
12     1   0.21    1      118      1    2
13     1   0.34    2      118      1    2
14     1   0.49    3      118      1    2
15     1     NA    4      118      1    2
16     2   0.52    0      119      2    4
17     2     NA    1      119      2    4
18     2     NA    2      119      2    4
19     2     NA    3      119      2    4
20     2     NA    4      119      2    4
21     2   0.35    0      121      2    3
22     2   0.53    1      121      2    3
23     2   0.35    2      121      2    3
24     2   0.44    3      121      2    3
25     2   0.56    4      121      2    3
26     1   0.16    0      122      1    5
27     1   0.22    1      122      1    5
28     1     NA    2      122      1    5
29     1     NA    3      122      1    5
30     1     NA    4      122      1    5
31     1   0.19    0      123      2    5
32     1     NA    1      123      2    5
33     1     NA    2      123      2    5
34     1     NA    3      123      2    5
35     1     NA    4      123      2    5
36     2   0.29    0      124      1    4
37     2   0.22    1      124      1    4
38     2     NA    2      124      1    4
39     2     NA    3      124      1    4
40     2     NA    4      124      1    4
41     1   0.38    0      125      1    4
42     1   0.45    1      125      1    4
43     1     NA    2      125      1    4
44     1     NA    3      125      1    4
45     1     NA    4      125      1    4
46     1   0.22    0      127      1    2
47     1   0.37    1      127      1    2
48     1   0.28    2      127      1    2
49     1   0.50    3      127      1    2
50     1     NA    4      127      1    2
51     1   0.30    0      130      1    2
52     1   0.49    1      130      1    2
53     1     NA    2      130      1    2
54     1     NA    3      130      1    2
55     1     NA    4      130      1    2
56     1   0.70    0      131      1    2
57     1     NA    1      131      1    2
58     1     NA    2      131      1    2
59     1     NA    3      131      1    2
60     1     NA    4      131      1    2
61     2   0.00    0      133      1    2
62     2   0.50    1      133      1    2
63     2   0.56    2      133      1    2
64     2   0.73    3      133      1    2
65     2     NA    4      133      1    2
66     1   0.22    0      134      1    2
67     1   0.65    1      134      1    2
68     1     NA    2      134      1    2
69     1     NA    3      134      1    2
70     1     NA    4      134      1    2
71     2   0.34    0      135      1    2
72     2   0.73    1      135      1    2
73     2   0.71    2      135      1    2
74     2     NA    3      135      1    2
75     2     NA    4      135      1    2
76     2   0.26    0      139      2    5
77     2     NA    1      139      2    5
78     2     NA    2      139      2    5
79     2     NA    3      139      2    5
80     2     NA    4      139      2    5
81     1   0.00    0      140      1    5
82     1   0.19    1      140      1    5
83     1     NA    2      140      1    5
84     1     NA    3      140      1    5
85     1     NA    4      140      1    5
86     2   0.19    0      144      2    4
87     2     NA    1      144      2    4
88     2     NA    2      144      2    4
89     2     NA    3      144      2    4
90     2     NA    4      144      2    4


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 





John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From xavier.chiriboga at unine.ch  Sun Apr 19 16:37:05 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Sun, 19 Apr 2015 14:37:05 +0000
Subject: [R] ABOUT STATS FORUM
Message-ID: <7B64C8E017B948419F014C915AA6D7342A056504@mail-mbx-04.UNINE.CH>

Dear members,



Since this is not a Forum for Stats questions...does anyone can recomend me a good forum to post questions about statistics?



Thank you for info,



Xavier


From r.turner at auckland.ac.nz  Mon Apr 20 00:22:41 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 20 Apr 2015 10:22:41 +1200
Subject: [R] error using by, Error in tapply(response, list(x.factor,
 trace.factor), fun) : argument "trace.factor" is missing, with no default
In-Reply-To: <553378FC020000CB00129E41@smtp.medicine.umaryland.edu>
References: <553378FC020000CB00129E41@smtp.medicine.umaryland.edu>
Message-ID: <55342AB1.1000503@auckland.ac.nz>

On 20/04/15 01:44, John Sorkin wrote:
>
>
> I am receiving an error message from the by function that I don't understand:
> Error in tapply(response, list(x.factor, trace.factor), fun) :
>    argument "trace.factor" is missing, with no default
>
>
>
> My code follows:
>
>
>> summary(ipd)
>   group      values            time      subjects     weaned disp
>   1:55   Min.   :0.0000   Min.   :0   Min.   :115.0   1:65   2:45
>   2:35   1st Qu.:0.1950   1st Qu.:1   1st Qu.:121.0   2:25   3: 5
>          Median :0.3400   Median :2   Median :126.0          4:20
>          Mean   :0.3479   Mean   :2   Mean   :127.6          5:20
>          3rd Qu.:0.5000   3rd Qu.:3   3rd Qu.:134.0
>          Max.   :0.7300   Max.   :4   Max.   :144.0
>          NA's   :48
>> by(ipd[,c("time","subjects","values")],ipd[,"group"],interaction.plot)
> Error in tapply(response, list(x.factor, trace.factor), fun) :
>    argument "trace.factor" is missing, with no default

<SNIP>

The error is not from tapply(), it is from interaction.plot().  You 
cannot supply a dataframe to this function, you must supply the three
arguments x.factor, trace.factor and response.

You could do:

  by(ipd[,c("time","subjects","values")],ipd[,"group"],
     function(x){names(x) <- c("x.factor","trace.factor",
                               "response");
     do.call(interaction.plot,x)})


There are several other ways of organizing the syntax, but somehow you 
have to make the arguments to interaction.plot() explicit.

I was somewhat surprised to find that do.call() does not work with 
positional matching of arguments.  I.e.

by(ipd[,c("time","subjects","values")],ipd[,"group"],
     function(x){do.call(interaction.plot,x)})

does *not* work.  The names of "x" have to match the names of the 
arguments to interaction.plot().

I'm sure this makes sense .... but I don't understand it.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From btupper at bigelow.org  Mon Apr 20 00:22:37 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 19 Apr 2015 18:22:37 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
	3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: 55336DC7.medlxdom.medlxpo.200.20000CB.1.129E2A.1
	<55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <CD5FDD70-1123-4428-B99D-9586A8560B9D@bigelow.org>


On Apr 19, 2015, at 9:44 AM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
> 
> 
> I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.
> 
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
> 

Hi,

Like this?

> x <- 1:4
> xx <- rep(x, each = 4)
> xx
 [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4

Cheers,
Ben



> (The spaces in the list are added only for clarity.)
> 
> I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!
> 
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
> 
> Can anyone help me?
> 
> Thank you,
> John
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:25}}


From JSorkin at grecc.umaryland.edu  Sun Apr 19 16:34:08 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 19 Apr 2015 10:34:08 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
 . . . . ., n, n, n, n
References: 5533735C.medlxdom.medlxpo.200.20000CB.1.129E34.1
Message-ID: <553384A0020000CB00129E56@smtp.medicine.umaryland.edu>

Windows 7 64-bit
R 3.1.3
RStudio 0.98.1103


I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.

1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n

(The spaces in the list are added only for clarity.)

 I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!

c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))

Can anyone help me?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Call
Send SMS
Add to Skype
You'll need Skype CreditFree via Skype

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From nevil.amos at gmail.com  Mon Apr 20 08:54:41 2015
From: nevil.amos at gmail.com (nevil amos)
Date: Mon, 20 Apr 2015 16:54:41 +1000
Subject: [R] clusterR (fun=aggregate) error "number of items to replace is
 not a multiple of replacement length"
Message-ID: <CAN9eD7mkTq5=arfkOc7Gqk=XB+oUxfySmnddKWHmazKAyRRYBg@mail.gmail.com>

I am getting the above  error with clusterR and aggregate:

works fine without parralell:

library(raster)
r<-raster(matrix(data = sample(c(1:10,NA),10000,replace=T),100,100),xmn=0,
xmx=1000,ymn=0,ymx=1000)
beginCluster()
Parr_agg<-clusterR(r,fun=aggregate,args=list(fact=3,fun=modal,expand=TRUE,na.rm=TRUE))
endCluster()
agg<-aggregate(r,3,fun=modal,na.rm=TRUE)
plot(agg)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Apr 20 01:14:15 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 19 Apr 2015 16:14:15 -0700
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
	3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: 55336DC7.medlxdom.medlxpo.200.20000CB.1.129E2A.1
	<55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <61CCB25A-BC6D-44B4-A1DC-C2678A273AC3@dcn.davis.CA.us>

You are not generating lists, you are generating vectors.

Try

rep( seq.int( n ), each= 4 )
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 19, 2015 6:44:56 AM PDT, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
>Windows 7 64-bit
>R 3.1.3
>RStudio 0.98.1103
>
>
>I am trying to generate a list of  length 4n which consists of the
>integers 1 to n repeated in groups of four, i.e.
>
>1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
>(The spaces in the list are added only for clarity.)
>
>I can generate the list as follows, but the code must be modified for
>any value n, and the code is UGLY!
>
>c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
>
>Can anyone help me?
>
>Thank you,
>John
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>
>Call
>Send SMS
>Add to Skype
>You'll need Skype CreditFree via Skype
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>
>
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:12}}


From lists at dewey.myzen.co.uk  Mon Apr 20 11:34:55 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 20 Apr 2015 10:34:55 +0100
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
 3, . . . . ., n, n, n, n
In-Reply-To: <553384A0020000CB00129E56@smtp.medicine.umaryland.edu>
References: 5533735C.medlxdom.medlxpo.200.20000CB.1.129E34.1
	<553384A0020000CB00129E56@smtp.medicine.umaryland.edu>
Message-ID: <5534C83F.8020804@dewey.myzen.co.uk>



On 19/04/2015 15:34, John Sorkin wrote:
> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.
>
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
> (The spaces in the list are added only for clarity.)
>
>   I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!
>
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
That gives a vector not a list?

Does
rep((1:n), each = 4)
do what you want?
>
> Can anyone help me?
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From arnaud.gaboury at gmail.com  Mon Apr 20 11:46:09 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Mon, 20 Apr 2015 11:46:09 +0200
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
Message-ID: <CAK1hC9usHwpxJ3tYzgFob_HspgfSxsJrtDCZTsSyOvnJReG-kg@mail.gmail.com>

On Mon, Apr 20, 2015 at 9:10 AM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> R 3.2.0 on Linux
> --------------------------------
>
> library(tidyr)
>
> playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
> Portals Visited 1,038",
> "XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed 11,126",
> "Links Created 1,744", "Control Fields Created 294", "Mind Units
> Captured 2,995,484 MUs",
> "Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
> "XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
> Captured 486",
> "Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
> Links Destroyed 3,169",
> "Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
> "Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
> "Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
> "Largest Field MUs x Days 83,226 MU-days")
>
> -----------------------------------------------------------------------------------------------
>  extract_numeric(playerStats)
>  [1]             10 56714486000000           1038       15327123
>    14268          11126           1744            294        2995484
> [10]             75         189731        3006364           1204
>      486          12481           1240           3169           1394
> [19]            230            240             15             NA
>        4             NA
>
> ------------------------------------------------------------------------------------------------
>  playerStats[c(22,24)]
> [1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
> Days 83,226 MU-days"
> --------------------------------------------------------------------------------------------
>
> I do not understand why these two vectors return NA when the function
> extract_numeric() works well for others,
>
> Any wrong settings in my env?

-------------------------------------------------------------------------
 as.numeric(gsub("[^0-9]", "",playerStats))
 [1]             10 56714486000000           1038       15327123
   14268          11126           1744            294        2995484
[10]             75         189731        3006364           1204
     486          12481           1240           3169           1394
[19]            230            240             15            276
       4          83226
--------------------------------------------------------------------

The above command does the job, but I still can not figure out why
extract_numeric() returns two NA

>
> Thank you for hints.
>
>
>
> --
>
> google.com/+arnaudgabourygabx



-- 

google.com/+arnaudgabourygabx


From rmh at temple.edu  Mon Apr 20 02:50:20 2015
From: rmh at temple.edu (Rmh)
Date: Sun, 19 Apr 2015 20:50:20 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
	3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <EF934F9C-108D-4036-8E26-2F234EEAE870@temple.edu>

rep(1:n, each=4)

Sent from my iPhone

> On Apr 19, 2015, at 09:44, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
> 
> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
> 
> 
> I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.
> 
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
> 
> (The spaces in the list are added only for clarity.)
> 
> I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!
> 
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
> 
> Can anyone help me?
> 
> Thank you,
> John
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From arnaud.gaboury at gmail.com  Mon Apr 20 09:10:10 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Mon, 20 Apr 2015 09:10:10 +0200
Subject: [R] misbehavior with extract_numeric() from tidyr
Message-ID: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>

R 3.2.0 on Linux
--------------------------------

library(tidyr)

playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
Portals Visited 1,038",
"XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed 11,126",
"Links Created 1,744", "Control Fields Created 294", "Mind Units
Captured 2,995,484 MUs",
"Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
"XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
Captured 486",
"Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
Links Destroyed 3,169",
"Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
"Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
"Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
"Largest Field MUs x Days 83,226 MU-days")

-----------------------------------------------------------------------------------------------
 extract_numeric(playerStats)
 [1]             10 56714486000000           1038       15327123
   14268          11126           1744            294        2995484
[10]             75         189731        3006364           1204
     486          12481           1240           3169           1394
[19]            230            240             15             NA
       4             NA

------------------------------------------------------------------------------------------------
 playerStats[c(22,24)]
[1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
Days 83,226 MU-days"
--------------------------------------------------------------------------------------------

I do not understand why these two vectors return NA when the function
extract_numeric() works well for others,

Any wrong settings in my env?

Thank you for hints.



-- 

google.com/+arnaudgabourygabx


From sven.templer at gmail.com  Mon Apr 20 08:55:50 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 20 Apr 2015 08:55:50 +0200
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
 3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <CAHuTOvqVTQqggwVBqYcss46RiNErc=-c+PSZir4yvP0OBGos-Q@mail.gmail.com>

In '?rep' find out about the 'each' argument.
Also there is the function 'gl' which creates a factor and offers a shorter
syntax for your problem.

If n equals 5 use one of:

rep(seq(5), each = 4)
gl(5,4)

On 19 April 2015 at 15:44, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am trying to generate a list of  length 4n which consists of the
> integers 1 to n repeated in groups of four, i.e.
>
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
> (The spaces in the list are added only for clarity.)
>
>  I can generate the list as follows, but the code must be modified for any
> value n, and the code is UGLY!
>
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
>
> Can anyone help me?
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From nevil.amos at gmail.com  Mon Apr 20 09:15:30 2015
From: nevil.amos at gmail.com (nevil amos)
Date: Mon, 20 Apr 2015 17:15:30 +1000
Subject: [R] clusterR (fun=aggregate) error "number of items to replace
 is not a multiple of replacement length"
In-Reply-To: <CAN9eD7mkTq5=arfkOc7Gqk=XB+oUxfySmnddKWHmazKAyRRYBg@mail.gmail.com>
References: <CAN9eD7mkTq5=arfkOc7Gqk=XB+oUxfySmnddKWHmazKAyRRYBg@mail.gmail.com>
Message-ID: <CAN9eD7=MXg0JHX3qoP49nLQyALfcpoq==Wp1U7-1Yk2kwvP-YQ@mail.gmail.com>

Apoligies.  did not read help properly it states:
"Among other functions, it does _not_ work with ... (dis)aggregate"

On Mon, Apr 20, 2015 at 4:54 PM, nevil amos <nevil.amos at gmail.com> wrote:

> I am getting the above  error with clusterR and aggregate:
>
> works fine without parralell:
>
> library(raster)
> r<-raster(matrix(data = sample(c(1:10,NA),10000,replace=T),100,100),xmn=0,
> xmx=1000,ymn=0,ymx=1000)
> beginCluster()
>
> Parr_agg<-clusterR(r,fun=aggregate,args=list(fact=3,fun=modal,expand=TRUE,na.rm=TRUE))
> endCluster()
> agg<-aggregate(r,3,fun=modal,na.rm=TRUE)
> plot(agg)
>

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Mon Apr 20 09:28:01 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 20 Apr 2015 08:28:01 +0100
Subject: [R] select portion of text file using R
Message-ID: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>

Dear all,
I have a flat file (tab delimited) derived from an excel file which is
subdivided in different parts: a first part is reporting metadata,
then there is a first spreadsheet indicated by [ ], then the actual
data and the second spreadsheet with the same format [ ] and then the
data.
How can I import such file using for instance read.table()?
Many thanks
regards
Luigi

Here is a sample of the file:
* Experiment Barcode =
* Experiment Comments =
* Experiment File Name = F:\array 59
* Experiment Name = 2015-04-13 171216
* Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
...
[Amplification Data]
Well    Cycle    Target Name    Rn    Delta Rn
1    1    Adeno 1-Adeno 1    0.820    -0.051
1    2    Adeno 1-Adeno 1    0.827    -0.042
1    3    Adeno 1-Adeno 1    0.843    -0.025
1    4    Adeno 1-Adeno 1    0.852    -0.015
1    5    Adeno 1-Adeno 1    0.858    -0.008
1    6    Adeno 1-Adeno 1    0.862    -0.002
...
[Results]
Well    Well Position    Omit    Sample Name    Target Name    Task
Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
Automatic Ct Threshold    Ct Threshold    Automatic Baseline
Baseline Start    Baseline End    Efficiency    Comments    Custom1
Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
EXPFAIL
1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
NFQ-MGB                Undetermined                            false
 0.200    true    3    44    1.000    N/A                            N
   Y
2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
NFQ-MGB                Undetermined


From Gerrit.Eichner at math.uni-giessen.de  Mon Apr 20 12:07:41 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 20 Apr 2015 12:07:41 +0200
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
	3, . . . . ., n, n, n, n
In-Reply-To: <5532E4E9020000CB00129DE4@smtp.medicine.umaryland.edu>
References: <5532E4E9020000CB00129DE4@smtp.medicine.umaryland.edu>
Message-ID: <Pine.SOC.4.64.1504201206210.29332@solcom.hrz.uni-giessen.de>

Hi, John,

doesn't

n <- <your number>
lapply( 1:n, rep, each = 4)

do what you need?

  Hth  --  Gerrit


On Sat, 18 Apr 2015, John Sorkin wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
>
> I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.
>
>
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
>
> (The spaces in the list are added only for clarity.)
>
>
> I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!
>
>
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
>
>
> Can anyone help me?
>
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Apr 20 12:09:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 20 Apr 2015 20:09:16 +1000
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CAK1hC9usHwpxJ3tYzgFob_HspgfSxsJrtDCZTsSyOvnJReG-kg@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
	<CAK1hC9usHwpxJ3tYzgFob_HspgfSxsJrtDCZTsSyOvnJReG-kg@mail.gmail.com>
Message-ID: <CA+8X3fUG4fasJed8pSBw0_dDa+_eA5u7mcTn+P1mfxeiez4tsw@mail.gmail.com>

Hi arnaud,
At a guess, it is the two hyphens that are present in those strings. I
think that the function you are using interprets them as subtraction
operators and since the string following the hyphen would produce NA,
the result would be NA.

Jim


On Mon, Apr 20, 2015 at 7:46 PM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> On Mon, Apr 20, 2015 at 9:10 AM, arnaud gaboury
> <arnaud.gaboury at gmail.com> wrote:
>> R 3.2.0 on Linux
>> --------------------------------
>>
>> library(tidyr)
>>
>> playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
>> Portals Visited 1,038",
>> "XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed 11,126",
>> "Links Created 1,744", "Control Fields Created 294", "Mind Units
>> Captured 2,995,484 MUs",
>> "Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
>> "XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
>> Captured 486",
>> "Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
>> Links Destroyed 3,169",
>> "Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
>> "Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
>> "Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
>> "Largest Field MUs x Days 83,226 MU-days")
>>
>> -----------------------------------------------------------------------------------------------
>>  extract_numeric(playerStats)
>>  [1]             10 56714486000000           1038       15327123
>>    14268          11126           1744            294        2995484
>> [10]             75         189731        3006364           1204
>>      486          12481           1240           3169           1394
>> [19]            230            240             15             NA
>>        4             NA
>>
>> ------------------------------------------------------------------------------------------------
>>  playerStats[c(22,24)]
>> [1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
>> Days 83,226 MU-days"
>> --------------------------------------------------------------------------------------------
>>
>> I do not understand why these two vectors return NA when the function
>> extract_numeric() works well for others,
>>
>> Any wrong settings in my env?
>
> -------------------------------------------------------------------------
>  as.numeric(gsub("[^0-9]", "",playerStats))
>  [1]             10 56714486000000           1038       15327123
>    14268          11126           1744            294        2995484
> [10]             75         189731        3006364           1204
>      486          12481           1240           3169           1394
> [19]            230            240             15            276
>        4          83226
> --------------------------------------------------------------------
>
> The above command does the job, but I still can not figure out why
> extract_numeric() returns two NA
>
>>
>> Thank you for hints.
>>
>>
>>
>> --
>>
>> google.com/+arnaudgabourygabx
>
>
>
> --
>
> google.com/+arnaudgabourygabx
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Apr 20 03:05:23 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 19 Apr 2015 21:05:23 -0400
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
	3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: 55336DC7.medlxdom.medlxpo.200.20000CB.1.129E2A.1
	<55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <A4692003-844F-4A2F-A69C-813A03ED8F8D@utoronto.ca>

That would be the "each" argument to rep()...
n <- 5
rep(1:n, each=4)
 [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5

Cheers,
B.


On Apr 19, 2015, at 9:44 AM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
> 
> 
> I am trying to generate a list of  length 4n which consists of the integers 1 to n repeated in groups of four, i.e.
> 
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
> 
> (The spaces in the list are added only for clarity.)
> 
> I can generate the list as follows, but the code must be modified for any value n, and the code is UGLY!
> 
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
> 
> Can anyone help me?
> 
> Thank you,
> John
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From arnaud.gaboury at gmail.com  Mon Apr 20 12:28:58 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Mon, 20 Apr 2015 12:28:58 +0200
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CA+8X3fUG4fasJed8pSBw0_dDa+_eA5u7mcTn+P1mfxeiez4tsw@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
	<CAK1hC9usHwpxJ3tYzgFob_HspgfSxsJrtDCZTsSyOvnJReG-kg@mail.gmail.com>
	<CA+8X3fUG4fasJed8pSBw0_dDa+_eA5u7mcTn+P1mfxeiez4tsw@mail.gmail.com>
Message-ID: <CAK1hC9vdP_P7JoZHoeDPsB262VMpNafH1hgika2g-FGZUUGNnA@mail.gmail.com>

On Mon, Apr 20, 2015 at 12:09 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi arnaud,
> At a guess, it is the two hyphens that are present in those strings. I
> think that the function you are using interprets them as subtraction
> operators and since the string following the hyphen would produce NA,
> the result would be NA.

I was thinking of 'x' as being the culprit (interpreted as multiply)
but you are right indeed

noHyphens <- str_replace(playerStats[c(22,24)],'-','')
 extract_numeric(noHyphens)
[1]   276 83226


in fact:
---------------------------------------------------------
 extract_numeric
function (x)
{
    as.numeric(gsub("[^0-9.-]+", "", as.character(x)))
}
<environment: namespace:tidyr>
---------------------------------------------------------

Is there any particular reason for the hyphen in gsub() ? Why not
remove it thus ?

TY much Jim

>
> Jim
>
>
> On Mon, Apr 20, 2015 at 7:46 PM, arnaud gaboury
> <arnaud.gaboury at gmail.com> wrote:
>> On Mon, Apr 20, 2015 at 9:10 AM, arnaud gaboury
>> <arnaud.gaboury at gmail.com> wrote:
>>> R 3.2.0 on Linux
>>> --------------------------------
>>>
>>> library(tidyr)
>>>
>>> playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
>>> Portals Visited 1,038",
>>> "XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed 11,126",
>>> "Links Created 1,744", "Control Fields Created 294", "Mind Units
>>> Captured 2,995,484 MUs",
>>> "Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
>>> "XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
>>> Captured 486",
>>> "Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
>>> Links Destroyed 3,169",
>>> "Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
>>> "Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
>>> "Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
>>> "Largest Field MUs x Days 83,226 MU-days")
>>>
>>> -----------------------------------------------------------------------------------------------
>>>  extract_numeric(playerStats)
>>>  [1]             10 56714486000000           1038       15327123
>>>    14268          11126           1744            294        2995484
>>> [10]             75         189731        3006364           1204
>>>      486          12481           1240           3169           1394
>>> [19]            230            240             15             NA
>>>        4             NA
>>>
>>> ------------------------------------------------------------------------------------------------
>>>  playerStats[c(22,24)]
>>> [1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
>>> Days 83,226 MU-days"
>>> --------------------------------------------------------------------------------------------
>>>
>>> I do not understand why these two vectors return NA when the function
>>> extract_numeric() works well for others,
>>>
>>> Any wrong settings in my env?
>>
>> -------------------------------------------------------------------------
>>  as.numeric(gsub("[^0-9]", "",playerStats))
>>  [1]             10 56714486000000           1038       15327123
>>    14268          11126           1744            294        2995484
>> [10]             75         189731        3006364           1204
>>      486          12481           1240           3169           1394
>> [19]            230            240             15            276
>>        4          83226
>> --------------------------------------------------------------------
>>
>> The above command does the job, but I still can not figure out why
>> extract_numeric() returns two NA
>>
>>>
>>> Thank you for hints.
>>>
>>>
>>>
>>> --
>>>
>>> google.com/+arnaudgabourygabx
>>
>>
>>
>> --
>>
>> google.com/+arnaudgabourygabx
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 

google.com/+arnaudgabourygabx


From bansouvik at gmail.com  Mon Apr 20 06:58:22 2015
From: bansouvik at gmail.com (SOUVIK BANDYOPADHYAY)
Date: Mon, 20 Apr 2015 10:28:22 +0530
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
 3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <CAA7y_Lco5TUuZr5a7hP=MwB_LddQz61gxdtDW6CMGnNgejAiRA@mail.gmail.com>

Hi,
You can use the apply group of functions

n<-5
k<-4

unlist(lapply(1:n,rep, each=k)) # For vector output:
sapply(1:n,rep, each=k) # For a matrix output

Hope this helps
Souvik

On Sun, Apr 19, 2015 at 7:14 PM, John Sorkin <JSorkin at grecc.umaryland.edu>
wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am trying to generate a list of  length 4n which consists of the
> integers 1 to n repeated in groups of four, i.e.
>
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
> (The spaces in the list are added only for clarity.)
>
>  I can generate the list as follows, but the code must be modified for any
> value n, and the code is UGLY!
>
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
>
> Can anyone help me?
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:24}}


From xavier.chiriboga at unine.ch  Mon Apr 20 12:59:16 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Mon, 20 Apr 2015 10:59:16 +0000
Subject: [R] RODBC did not found
Message-ID: <7B64C8E017B948419F014C915AA6D7342A0575A8@mail-mbx-04.UNINE.CH>

Dear members,



What can I do if I get this message: ?



library(RODBC)
Error in library(RODBC) : aucun package nomm? ?RODBC? n'est trouv?





Thanks in advcance,



Xavier


From xavier.chiriboga at unine.ch  Mon Apr 20 13:01:50 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Mon, 20 Apr 2015 11:01:50 +0000
Subject: [R] RODBC package not found (in English)
Message-ID: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>

Dear members,



What can I do if I get this message: ?



library(RODBC)
Error in library(RODBC) : any package called ?RODBC? was found





Thanks in advcance,



Xavier


From murdoch.duncan at gmail.com  Mon Apr 20 13:17:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 Apr 2015 07:17:48 -0400
Subject: [R] select portion of text file using R
In-Reply-To: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>
Message-ID: <5534E05C.2010407@gmail.com>

On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
> Dear all,
> I have a flat file (tab delimited) derived from an excel file which is
> subdivided in different parts: a first part is reporting metadata,
> then there is a first spreadsheet indicated by [ ], then the actual
> data and the second spreadsheet with the same format [ ] and then the
> data.
> How can I import such file using for instance read.table()?

read.table() by itself can't recognize where the data starts, but it has
arguments "skip" and "nrows" to control how much gets read.  If you
don't know the values for those arguments, you can use readLines() to
read the entire file, then use grep() to recognize your table data, and
either re-read the file, or just extract those lines and read from them
as a textConnection.

Duncan Murdoch

> Many thanks
> regards
> Luigi
> 
> Here is a sample of the file:
> * Experiment Barcode =
> * Experiment Comments =
> * Experiment File Name = F:\array 59
> * Experiment Name = 2015-04-13 171216
> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> ...
> [Amplification Data]
> Well    Cycle    Target Name    Rn    Delta Rn
> 1    1    Adeno 1-Adeno 1    0.820    -0.051
> 1    2    Adeno 1-Adeno 1    0.827    -0.042
> 1    3    Adeno 1-Adeno 1    0.843    -0.025
> 1    4    Adeno 1-Adeno 1    0.852    -0.015
> 1    5    Adeno 1-Adeno 1    0.858    -0.008
> 1    6    Adeno 1-Adeno 1    0.862    -0.002
> ...
> [Results]
> Well    Well Position    Omit    Sample Name    Target Name    Task
> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
> Baseline Start    Baseline End    Efficiency    Comments    Custom1
> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
> EXPFAIL
> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
> NFQ-MGB                Undetermined                            false
>  0.200    true    3    44    1.000    N/A                            N
>    Y
> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
> NFQ-MGB                Undetermined
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From guillaumechaumet at gmail.com  Mon Apr 20 13:18:35 2015
From: guillaumechaumet at gmail.com (guillaume chaumet)
Date: Mon, 20 Apr 2015 13:18:35 +0200
Subject: [R] RODBC package not found (in English)
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
Message-ID: <CAGg8SkJh1KwfeMSCxyHs2Ey8HF6VSRRi-oxgTV8YMdosCRLweg@mail.gmail.com>

Dear Xavier,
Perhaps, you should read the faq:
http://cran.r-project.org/doc/FAQ/R-FAQ.html
And also "un livre en fran?ais sur R* : R pour les d?butants *par Emmanuel
Paradis ou *Introduction ? R par *Julien Barnier"

> install.packages("RODBC")

Un dernier petit mot : M?fiez vous! La patience des membres de la mailing
list R est limit?e surtout pour les questions qui ont ?t? pos?es mille fois
et dont les r?ponses sont dans le FAQ.

A bon entendeur, Bonne journ?e

Guillaume


2015-04-20 13:01 GMT+02:00 CHIRIBOGA Xavier <xavier.chiriboga at unine.ch>:

> Dear members,
>
>
>
> What can I do if I get this message: ?
>
>
>
> library(RODBC)
> Error in library(RODBC) : any package called ?RODBC? was found
>
>
>
>
>
> Thanks in advcance,
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Apr 20 13:19:48 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 20 Apr 2015 07:19:48 -0400
Subject: [R] RODBC package not found (in English)
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
Message-ID: <CA+vqiLFDR4NwvdCxmxMRxF4UVaKPqPdAMobsEbKiDB_8Mka0Jg@mail.gmail.com>

Install it with

install.packages("RODBC")

Best,
Ista
On Apr 20, 2015 7:02 AM, "CHIRIBOGA Xavier" <xavier.chiriboga at unine.ch>
wrote:

> Dear members,
>
>
>
> What can I do if I get this message: ?
>
>
>
> library(RODBC)
> Error in library(RODBC) : any package called ?RODBC? was found
>
>
>
>
>
> Thanks in advcance,
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Apr 20 13:20:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 Apr 2015 07:20:19 -0400
Subject: [R] RODBC package not found (in English)
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0575B4@mail-mbx-04.UNINE.CH>
Message-ID: <5534E0F3.9000600@gmail.com>

On 20/04/2015 7:01 AM, CHIRIBOGA Xavier wrote:
> Dear members,
> 
> 
> 
> What can I do if I get this message: ?
> 
> 
> 
> library(RODBC)
> Error in library(RODBC) : any package called ?RODBC? was found

That means that you haven't installed it.  You need to run

install.packages("RODBC")

first.  Depending on which platform you're working on, this might fail;
in that case, you'll need to give us more details.

Duncan Murdoch


From boris.steipe at utoronto.ca  Mon Apr 20 13:32:01 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 20 Apr 2015 07:32:01 -0400
Subject: [R] ABOUT STATS FORUM
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A056504@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A056504@mail-mbx-04.UNINE.CH>
Message-ID: <B6F4B5DA-0FC9-47CC-B0D1-003416FA09F2@utoronto.ca>

Cross Validated at http://stats.stackexchange.com/

B.



On Apr 19, 2015, at 10:37 AM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:

> Dear members,
> 
> 
> 
> Since this is not a Forum for Stats questions...does anyone can recomend me a good forum to post questions about statistics?
> 
> 
> 
> Thank you for info,
> 
> 
> 
> Xavier
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Apr 20 13:58:16 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 20 Apr 2015 06:58:16 -0500
Subject: [R] RODBC did not found
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0575A8@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0575A8@mail-mbx-04.UNINE.CH>
Message-ID: <CAAJSdjghoEf7ujekC8Bgr7Nggffp4Jqp00YSGaxyO02U2jDG5A@mail.gmail.com>

On Mon, Apr 20, 2015 at 5:59 AM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch
> wrote:

> Dear members,
>
> What can I do if I get this message: ?
>
> library(RODBC)
> Error in library(RODBC) : aucun package nomm? ?RODBC? n'est trouv?
>
> Thanks in advcance,
>
> Xavier
>

?If I understand the message correctly, it is saying that the RODBC package
is "not found", just as you said in the subject. That either means that you
have not installed it, or it is not on the library path. Perhaps the
simplest thing to try is to reinstall the RODBC package with the R
statement:

install.packages('RODBC')

then try again. If you need more help, you might want to post the output
from the commands: Sys.info() and .libPaths() and the value of the .Library
variable?


-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Mon Apr 20 14:15:12 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Mon, 20 Apr 2015 12:15:12 +0000
Subject: [R] erv.inv NOT FOUND
Message-ID: <7B64C8E017B948419F014C915AA6D7342A0575F9@mail-mbx-04.UNINE.CH>

Dear members, in this case



Error: could not find function "erf.inv"



Anyone knows the package?

Thanks a lot!



Xavier


From ripley at stats.ox.ac.uk  Mon Apr 20 14:32:38 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Apr 2015 13:32:38 +0100
Subject: [R] erv.inv NOT FOUND
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0575F9@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0575F9@mail-mbx-04.UNINE.CH>
Message-ID: <5534F1E6.2060100@stats.ox.ac.uk>

On 20/04/2015 13:15, CHIRIBOGA Xavier wrote:
> Dear members, in this case
>
> Error: could not find function "erf.inv"
>
> Anyone knows the package?

See ?pnorm for a definition of erfinv, which also exists in package 
pracma.  'erf.inv' is not in any of the packages I have installed (which 
includes all of CRAN).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From arunikarunarathne at gmail.com  Sun Apr 19 03:51:24 2015
From: arunikarunarathne at gmail.com (aruni karunarathne)
Date: Sun, 19 Apr 2015 07:21:24 +0530
Subject: [R] Fwd: REngine hangs when called within java code
In-Reply-To: <CAMVs1ir+4--nX5ux2-L_=jXi+s1ajcDufVCfiFeqTYGgXd1Ecg@mail.gmail.com>
References: <CAMVs1ir+4--nX5ux2-L_=jXi+s1ajcDufVCfiFeqTYGgXd1Ecg@mail.gmail.com>
Message-ID: <CAMVs1iqR7UBrV5Fbm=2mfbsGyJT2zfP6TA37wNK+EVnA1ne=5w@mail.gmail.com>

Dear All,

I fixed my issue.

 String newargs1[] = {"--no-save"};

        Rengine r1 = Rengine.getMainEngine();
       if (r1 == null) {
           r1 = new Rengine(newargs1, false, null);
       }

i added/modified the above part when setting up the rengine.
Somehow, now it works.
may be that in the previous coding, one instance of rengine do not
really end.hence it hangs when it comes to another instance.

Many thanks.


---------- Forwarded message ----------
From: aruni karunarathne <arunikarunarathne at gmail.com>
Date: Wed, Apr 15, 2015 at 11:17 PM
Subject: REngine hangs when called within java code
To: r-help at r-project.org


Dear All,

I'm creating a project which uses both java and R.

I created the java class named MyClass and within that wrote two
separate methods (graphing1() and fitness()) to call the r scripts.

public void graphing1() throws IOException {

    String newargs1[] = {"--no-save"};

    Rengine r1 = new Rengine(newargs1, false, null);

    r1.eval("source('test2.R')");

    r1.end();

}



public void fitness() throws IOException {

    String newargs1[] = {"--no-save"};

    Rengine r3 = new Rengine(newargs1, false, null);

    r3.eval("source('A.R')");

    r3.eval("source('B.R')");

    r3.end();

}

Both of the above methods are in java class MyClass.

>From another class in the same project for which I created a gui, I
accessed the fitness() function and it worked fine. But when I try to
call the graphing1() function it did not work. (both were called
through the gui) The programme hangs at ;

Rengine r1 = new Rengine(newargs1, false, null);

without any notification. In both instances I called the function as follows:

1st instance:

MyClass test=new MyClass();

    test.fitness() ;

2nd instance:

MyClass test1 = new MyClass();

        test1.graphing1();



All the 3 scripts are coded to create png files. test2.R and A.R
scripts use the ROCR library and B.R do not use any. All the 3 files
end with dev.off() statement.

I have installed R 3.1.3. I?m using netbeans as the editor and working
in windows environment.

The 3 scripts work fine when executed in R environment. The issue
arises when it?s called from the java code.

I'm a student who is new to R and was struggling to solve this issue
for several weeks. Your help is greatly appreciated.

Thanks in advance.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: REngine hangs when called within java code -- problem.pdf
Type: application/pdf
Size: 48699 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150419/c56015b6/attachment.pdf>

From f.fabiogama88 at gmail.com  Sun Apr 19 02:44:50 2015
From: f.fabiogama88 at gmail.com (Fernando Gama)
Date: Sat, 18 Apr 2015 21:44:50 -0300
Subject: [R] suggestion of regex pattern
In-Reply-To: <61774DD2-40F2-4A74-B70D-3F9D9AAA1C16@utoronto.ca>
References: <CAOwqRyv7Joo3NtLCXBRzUqJxV5cMOj7Lo3pW7gVomU8Ow0Li3A@mail.gmail.com>
	<32E68473-2F59-4DA9-8DC3-B013EEC8C194@utoronto.ca>
	<CAOwqRytEwuYUSBx8bj0jK0MEGS-Cdnu-WFEfrVYsheNEV4R25w@mail.gmail.com>
	<EF70BB75-CEBE-4481-8754-009F6EA07C19@utoronto.ca>
	<61774DD2-40F2-4A74-B70D-3F9D9AAA1C16@utoronto.ca>
Message-ID: <CAOwqRyv7r9iyP8fyx_rQCxY4QREtbEUj-nGOaHyrv7cD+rkWNw@mail.gmail.com>

Ok, I'll try to do this...

Thanks :D

2015-04-18 18:55 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:

> Re-reading your question and taking a wild guess, perhaps you are looking
> for parse() and eval() ...
>
> xyz <- data.frame( a=c(1,2), b=c(3,4))
> xyz
>
>   a b
> 1 1 3
> 2 2 4
>
> expp <- parse(text="xyz$a > 1 & xyz$b == 4")   # turn a string into an
> expression
> expp
>
> expression(xyz$a > 1 & xyz$b == 4)
>
> xyz[eval(expp), ]                              # evaluate an expression in
> place
>   a b
> 2 2 4
>
> ... but really, it's just a guess at what you might be trying to do.
>
> B.
>
>
>
>
> On Apr 18, 2015, at 1:30 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
> > Sorry - it's not entirely clear to me what you need to do.
> >
> > See here for some hints on how to ask questions on this list. I'm sure
> we'll be able to help quickly.
> > http://adv-r.had.co.nz/Reproducibility.html
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> > (and don't post in HTML   :-)
> >
> >
> > B.
> >
> > On Apr 18, 2015, at 11:10 AM, Fernando Gama <f.fabiogama88 at gmail.com>
> wrote:
> >
> >> Hello Boris,
> >>
> >> thanks for your response.
> >>
> >> So, firstly considered that  i've been input a set of serches strings
> (.txt format) and i'm using regex to transform in a suitable  format to my
> script. This part is a final part of my code and i wish putting in input to
> a subset.
> >>
> >> (.txt formatted)
> >>
> >> ---- STRINGS (INPUT)
> >>
> >> [1]  "municipio =='Limeira' "
> >> [2]  "municipio =='Limeira' & mesincident =='marco' "
> >> [3]  "?municipio =='Limeira' & mesincident =='marco' & trechoklmetros >
> 1.00 12.300"
> >> ...
> >> ..
> >> ..
> >> ..
> >> [n] "......"
> >>
> >> --------------
> >>
> >> desired_fomart <- ?it will reveice all strings to filter in a dataset
> by subset below:
> >>
> >>
> >> a loop each line:
> >>
> >> subset(dataset_read, desired_fomart[i])
> >>
> >> My question: taking into consideration this cenario, in your oppinion
> your reply is my suitable for my problem, whereas i will to map each value
> in database?
> >>
> >> Once again, thank so much! :)
> >>
> >> 2015-04-18 11:04 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> >> This is not a regular expression but simply a conjunction (sequence of
> '&') of logical expressions. Moreover it's not wrong. Consider:
> >>
> >> xyz <- data.frame(municipio = c('Limeira'), mesincident = c('marco'),
> trechoklmetros = c(3.00, -4.00, 30))
> >> xyz
> >>
> >>  municipio mesincident trechoklmetros
> >> 1   Limeira       marco              3
> >> 2   Limeira       marco             -4
> >> 3   Limeira       marco             30
> >>
> >>
> >> xyz$municipio =='Limeira' & xyz$mesincident =='marco' &
> xyz$trechoklmetros > 1.00
> >> [1]  TRUE FALSE  TRUE
> >>
> >> xyz$municipio =='Limeira' & xyz$mesincident =='marco' &
> xyz$trechoklmetros > 1.00 & xyz$trechoklmetros <= 12.3
> >> [1]  TRUE FALSE FALSE
> >>
> >>
> >> If there's a problem it seems to be elsewhere.
> >> Cheers,
> >> Boris
> >>
> >>
> >> On Apr 17, 2015, at 4:22 PM, Fernando Gama <f.fabiogama88 at gmail.com>
> wrote:
> >>
> >>> Hello,
> >>>
> >>> I have benn problems to construct the pattern for this:
> >>>
> >>> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> 12.300
> >>>
> >>> I would like:
> >>>
> >>> municipio =='Limeira' & mesincident =='marco' & trechoklmetros > 1.00
> >>> *& **trechoklmetros
> >>> <= *12.300
> >>> ?
> >>> ?Any suggestion??
> >>>
> >>>
> >>> --
> >>> Att,
> >>>
> >>> Fernando Gama da Mata
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >> --
> >> Att,
> >>
> >> Fernando Gama da Mata
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Att,

Fernando Gama da Mata

Vale of Institute Technology

	[[alternative HTML version deleted]]


From jitvi648 at student.liu.se  Sun Apr 19 10:18:13 2015
From: jitvi648 at student.liu.se (jitvis)
Date: Sun, 19 Apr 2015 01:18:13 -0700 (PDT)
Subject: [R] Predict in glmnet for cox family
Message-ID: <1429431493476-4706070.post@n4.nabble.com>

Dear All, 

I am in some difficulty with predicting 'expected time of survival' for each
observation for a glmnet cox family with LASSO. 

I have two dataset 50000 * 450 (obs * Var) and 8000 * 450 (obs * var), I
considered first one as train and second one as test. 

I got the predict output and I am bit lost here,   

pre <- predict(fit,type="response", newx =selectedVar[1:20,]) 

         s0 
1  0.9454985 
2  0.6684135                   
3  0.5941740 
4  0.5241938 
5  0.5376783 

This is the output I am getting - I understood with type "response" gives
the fitted relative-risk for "cox" family. 

I would like to know how I can convert it or change the fitted relative-risk
to 'expected time of survival' ? 

Any help would be great, thanks for all your time and effort.

Sincerely,



--
View this message in context: http://r.789695.n4.nabble.com/Predict-in-glmnet-for-cox-family-tp4706070.html
Sent from the R help mailing list archive at Nabble.com.


From mdsumner at gmail.com  Mon Apr 20 00:24:14 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 19 Apr 2015 22:24:14 +0000
Subject: [R] xtractomatic package
In-Reply-To: <7A8B3FB2-CF72-4806-9CAE-17210048F0B0@noaa.gov>
References: <7A8B3FB2-CF72-4806-9CAE-17210048F0B0@noaa.gov>
Message-ID: <CAAcGz98PW8kkZN47eCoeDEOsO1q9=0d=J=4ofOBs6FxbNAM4dQ@mail.gmail.com>

Wow, thank you! This is a very important contribution to our research
community.

Cheers,  Mike

On Sun, 19 Apr 2015 02:58 Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> xtractomatic R package for accessing environmental data
>
> xtractomatic is an R package developed to subset and extract satellite and
> other oceanographic related data from a remote server. The program can
> extract data for a moving point in time along a user-supplied set of
> longitude, latitude and time points; in a 3D bounding box; or within a
> polygon (through time). The xtractomatic functions were originally
> developed for the marine biology tagging community, to match up
> environmental data available from satellites (sea-surface temperature,
> sea-surface chlorophyll, sea-surface height, sea-surface salinity, vector
> winds) to track data from various tagged animals or shiptracks (xtracto).
> The package has since been extended to include the routines that extract
> data a 3D bounding box (xtracto_3D) or within a polygon (xtractogon). The
> xtractomatic package accesses data that are served through the ERDDAP
> (Environmental Research Division Data Access Program) server at the
> NOAA/SWFSC Environmental Research Division in Santa Cruz, California!
>  . The ERDDAP server can also be directly accessed at
> http://coastwatch.pfeg.noaa.gov/erddap. ERDDAP is a simple to use yet
> powerful web data service developed by Bob Simons.
>
> At present the package can access well over 100TB of data.  Due to some
> problems with certain required packages and CRAN  (most notably ncdf4)
> xtractomatic at present is only available through Github.  Instructions for
> installation are at:
>
> https://github.com/rmendels/xtractomatic
>
> -Roy M.
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From milos.zarkovic at gmail.com  Sun Apr 19 07:59:58 2015
From: milos.zarkovic at gmail.com (=?UTF-8?B?TWlsb8WhIMW9YXJrb3ZpxIc=?=)
Date: Sun, 19 Apr 2015 07:59:58 +0200
Subject: [R]
	=?utf-8?q?library=28xlsx=29_fails_with_an_error=3A_Error=3A_p?=
	=?utf-8?q?ackage_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
References: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
Message-ID: <CANgWSHAVLiqavbMsrXdBLUCH-=DPaAoXm0yOax-K_7VGP63qYg@mail.gmail.com>

Do you have 64-bit Java installed?

Regards
Milo?


On Saturday, April 18, 2015, John Sorkin <JSorkin at grecc.umaryland.edu>
wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am having difficulty loading and installing the xlsx package. The
> loading occurred without any problem, however the library command
> library(xlsx) produced an error related to rJava. I tried to install
> rJava seperately, re-loaded the xlsx package, and entered the
> library(xlsx) command but received the same error message about rJave.
> Please see terminal messages below. Any suggestion that would allow me
> to load and run xlsx would be appreciated.
> Thank you,
> John
>
>
> > install.packages("xlsx")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/xlsx_0.5.7.zip'
> Content type 'application/zip' length 400944 bytes (391 KB)
> opened URL
> downloaded 391 KB
>
>
> package ?xlsx? successfully unpacked and MD5 sums checked
>
>
> The downloaded binary packages are in
>         C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
> > library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package ?rJava? could not be loaded
> > install.packages("rJava")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/rJava_0.9-6.zip'
> Content type 'application/zip' length 759396 bytes (741 KB)
> opened URL
> downloaded 741 KB
>
>
> package ?rJava? successfully unpacked and MD5 sums checked
>
>
> The downloaded binary packages are in
>         C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
> > library(rJava)
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package or namespace load failed for ?rJava?
> > library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package ?rJava? could not be loaded
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From rhelpmaillist at 163.com  Sun Apr 19 21:42:29 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 20 Apr 2015 03:42:29 +0800 (CST)
Subject: [R]  Two stage cluster in R(two step in spss),
 which package implement it  ?
Message-ID: <5538fb6f.8c6f.14cd3341ab9.Coremail.rhelpmaillist@163.com>


Dear, expeRts,
? I am confused in finding an implementation of two stage cluster in R(which is two step cluster in spss), i do some searching, but still can not find it. Has someone happen to know it ?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From robertsonburns at btinternet.com  Sun Apr 19 03:55:14 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Sun, 19 Apr 2015 02:55:14 +0100
Subject: [R] basic q re: parsing functions, declaration order
In-Reply-To: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>
References: <7069209C-CDDF-430B-9382-DC6BBBCC8FAC@uiowa.edu>
Message-ID: <55330B02.3000300@btinternet.com>

On 18/04/2015 18:14, Gowder, Paul wrote:
> Hi there,
>
> So I?m doing some serious coding in R for the first time?writing a strategic simulation to run for a few (or many) thousand iterations,* and doing so in proper functional programming form,

[...]

>    write.table(results, file="simul_results.csv", row.names=TRUE, col.names=TRUE, sep=",?)
> # bonus question: there?s probably a vastly more efficient way to do this final write, any suggestions welcomed

Unless your results are massive, this is not worth
worrying about.

> }
>

[...]

>   
>
> I?m just putting it all in one source file, which I plan to load using source(), and then actual execution will be via console input > simulate.strat(number of runs), leave town for the weekend, hopefully come back to find a csv with a bunch of results.
>
> But I?m not quite sure how the parser works with respect to defining all these functions.  Do I have to define them from inside out like one would in python?  (So, on the code above, that would mean defining, say, dist.goods() and dist.power() first, then outer.wrapper(), then simulate.strat().)  Or is there a way to prototype them like one would in C?  Or--- and I really hope this is the answer so I don?t have untangle the tangled web of functions I?m writing? is R smart enough/lazy enough to accept that the function defined at line K can call a function defined at line K+N and not stress about it?

Yes.  Functions just need to be defined at the
time they are used.

>
> thanks so much!  My google-fu is failing me on this one.
>
> -Paul
>
>
> * why on earth, you might ask, am I doing this in R, rather than C or something?  Because I have a ton of computing resources and a huge workload. CPU time is cheap and my time is expensive?

Correct.  Not a line of thinking that you are
likely to need to defend among this crowd.

An answer to the question that you didn't ask is:

http://www.burns-stat.com/documents/books/the-r-inferno/

That question is:  Where do I look when I discover
it isn't doing what I intend it to do?

Pat

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Apr 20 01:26:17 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 19 Apr 2015 16:26:17 -0700
Subject: [R] generate a list as follows: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
 3, . . . . ., n, n, n, n
In-Reply-To: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
References: <55337918020000CB00129E46@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcYwvb6nr+3-Onksh77qs1kfHd0NixvoYZ9R1aYRw2XFFw@mail.gmail.com>

Look more at help(rep) and help(seq):
   > n <- 7
   > rep(seq_len(n), each=4)
    [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5 6 6 6 6 7 7 7 7


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Apr 19, 2015 at 6:44 AM, John Sorkin <JSorkin at grecc.umaryland.edu>
wrote:

> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am trying to generate a list of  length 4n which consists of the
> integers 1 to n repeated in groups of four, i.e.
>
> 1,1,1,1,  2,2,2,2,  3,3,3,3, . . . . , n,n,n,n
>
> (The spaces in the list are added only for clarity.)
>
>  I can generate the list as follows, but the code must be modified for any
> value n, and the code is UGLY!
>
> c(rep(1,4), rep(2,4), rep(3,4), . . . ,c(n,4))
>
> Can anyone help me?
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Call
> Send SMS
> Add to Skype
> You'll need Skype CreditFree via Skype
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From ivan.calandra at univ-reims.fr  Mon Apr 20 15:32:14 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 20 Apr 2015 15:32:14 +0200
Subject: [R] list server problem?
Message-ID: <5534FFDE.8090707@univ-reims.fr>

Dear all,

I use Thunderbird 31.6.0 on Mac OS 10.6.8 to download my e-mails.
Since this morning, Thunderbird downloads several times the same e-mails 
from the list, some even being from yesterday. It occurs only with 
e-mails from the R-help and not with my other professional and private 
e-mails.

I also checked that it was not a problem with the server on which I get 
e-mails from the R-help: the problematic e-mails are erased every time 
from the server but are received several times. So I would say that the 
R-help server has sent these e-mails several times.

I am wondering if there is currently an issue with the R-help server. Is 
someone else having the same problem?

Thanks!
Ivan

-- 
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra


From dimitri.liakhovitski at gmail.com  Mon Apr 20 15:59:12 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Apr 2015 09:59:12 -0400
Subject: [R] regexpr - ignore all special characters and punctuation in a
	string
Message-ID: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>

Hello!

Please point me in the right direction.
I need to match 2 strings, but focusing ONLY on characters, ignoring
all special characters and punctuation signs, including (), "", etc..

For example:
I want the following to return: TRUE

"What a nice day today! - Story of happiness: Part 2." ==
   "What a nice day today: Story of happiness (Part 2)"


-- 
Thank you!
Dimitri Liakhovitski


From maechler at lynne.stat.math.ethz.ch  Mon Apr 20 16:03:01 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Apr 2015 16:03:01 +0200
Subject: [R] list server problem?
In-Reply-To: <5534FFDE.8090707@univ-reims.fr>
References: <5534FFDE.8090707@univ-reims.fr>
Message-ID: <21813.1813.471446.941372@stat.math.ethz.ch>


> Dear all,
> I use Thunderbird 31.6.0 on Mac OS 10.6.8 to download my e-mails.
> Since this morning, Thunderbird downloads several times the same e-mails 
> from the list, some even being from yesterday. It occurs only with 
> e-mails from the R-help and not with my other professional and private 
> e-mails.

> I also checked that it was not a problem with the server on which I get 
> e-mails from the R-help: the problematic e-mails are erased every time 
> from the server but are received several times. So I would say that the 
> R-help server has sent these e-mails several times.

> I am wondering if there is currently an issue with the R-help server. Is 
> someone else having the same problem?

Not having the same problem, but an explanation
from the place where the server runs:

The R mailing list server indeed has had hard times, as it seems
since early Sunday (CEST), and a complete time out for a few
hours during this morning.  The symptoms have been that some e-mails
were badly delayed.... and --- as you have experienced --- mail
server timeouts do lead to e-mail being sent more than once.
This is the consequence of a safe e-mail server behavior:  If an
e-mail "may have been lost", rather send it again.
As some say:  Better error on the safe side.

Martin Maechler
ETH Zurich


> Thanks!
> Ivan

> -- 
> Ivan Calandra, ATER
> University of Reims Champagne-Ardenne
> 51100 Reims, France


From dimitri.liakhovitski at gmail.com  Mon Apr 20 16:05:01 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Apr 2015 10:05:01 -0400
Subject: [R] regexpr - ignore all special characters and punctuation in
	a string
In-Reply-To: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
Message-ID: <CAN2xGJZsP8WDhsvCQt2tjvEbcW_OT3QVsyMvBqTVqLu+hfZD=g@mail.gmail.com>

I think I found a partial answer:

str_replace_all(x, "[[:punct:]]", " ")

On Mon, Apr 20, 2015 at 9:59 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> Please point me in the right direction.
> I need to match 2 strings, but focusing ONLY on characters, ignoring
> all special characters and punctuation signs, including (), "", etc..
>
> For example:
> I want the following to return: TRUE
>
> "What a nice day today! - Story of happiness: Part 2." ==
>    "What a nice day today: Story of happiness (Part 2)"
>
>
> --
> Thank you!
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From marc_schwartz at me.com  Mon Apr 20 16:08:59 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 20 Apr 2015 09:08:59 -0500
Subject: [R] regexpr - ignore all special characters and punctuation in
	a	string
In-Reply-To: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
Message-ID: <5FBCD1CB-E85C-4D2A-882B-CB81A3A5C6D3@me.com>


> On Apr 20, 2015, at 8:59 AM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
> 
> Hello!
> 
> Please point me in the right direction.
> I need to match 2 strings, but focusing ONLY on characters, ignoring
> all special characters and punctuation signs, including (), "", etc..
> 
> For example:
> I want the following to return: TRUE
> 
> "What a nice day today! - Story of happiness: Part 2." ==
>   "What a nice day today: Story of happiness (Part 2)"
> 
> 
> -- 
> Thank you!
> Dimitri Liakhovitski


Look at ?agrep:

Vec1 <- "What a nice day today! - Story of happiness: Part 2."
Vec2 <- "What a nice day today: Story of happiness (Part 2)?

# Match the words, not the punctuation.
# Not fully tested

> agrep("What a nice day today Story of happiness Part 2", c(Vec1, Vec2))
[1] 1 2

> agrep("What a nice day today Story of happiness Part 2", c(Vec1, Vec2), 
        value = TRUE)
[1] "What a nice day today! - Story of happiness: Part 2."
[2] "What a nice day today: Story of happiness (Part 2)?  


Also, possibly:

  http://cran.r-project.org/web/packages/stringdist


Regards,

Marc Schwartz


From sven.templer at gmail.com  Mon Apr 20 16:10:14 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 20 Apr 2015 16:10:14 +0200
Subject: [R] regexpr - ignore all special characters and punctuation in
	a string
In-Reply-To: <CAN2xGJZsP8WDhsvCQt2tjvEbcW_OT3QVsyMvBqTVqLu+hfZD=g@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
	<CAN2xGJZsP8WDhsvCQt2tjvEbcW_OT3QVsyMvBqTVqLu+hfZD=g@mail.gmail.com>
Message-ID: <CAHuTOvokcsRix09GaAe6U07gbkSOODtiHyBZZYh6rih9PLWFvA@mail.gmail.com>

Hi Dimitri,

str_replace_all is not in the base libraries, you could use 'gsub' as well,
for example:

a = "What a nice day today! - Story of happiness: Part 2."
b = "What a nice day today: Story of happiness (Part 2)"
sa = gsub("[^A-Za-z0-9]", "", a)
sb = gsub("[^A-Za-z0-9]", "", b)
a==b
# [1] FALSE
sa==sb
# [1] TRUE

Take care of the extra space in a after the '-', so also replace spaces...

Best,
Sven.

On 20 April 2015 at 16:05, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> I think I found a partial answer:
>
> str_replace_all(x, "[[:punct:]]", " ")
>
> On Mon, Apr 20, 2015 at 9:59 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
> > Hello!
> >
> > Please point me in the right direction.
> > I need to match 2 strings, but focusing ONLY on characters, ignoring
> > all special characters and punctuation signs, including (), "", etc..
> >
> > For example:
> > I want the following to return: TRUE
> >
> > "What a nice day today! - Story of happiness: Part 2." ==
> >    "What a nice day today: Story of happiness (Part 2)"
> >
> >
> > --
> > Thank you!
> > Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Apr 20 16:10:53 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 Apr 2015 10:10:53 -0400
Subject: [R] regexpr - ignore all special characters and punctuation in
 a string
In-Reply-To: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
Message-ID: <553508ED.6070407@gmail.com>

On 20/04/2015 9:59 AM, Dimitri Liakhovitski wrote:
> Hello!
> 
> Please point me in the right direction.
> I need to match 2 strings, but focusing ONLY on characters, ignoring
> all special characters and punctuation signs, including (), "", etc..
> 
> For example:
> I want the following to return: TRUE
> 
> "What a nice day today! - Story of happiness: Part 2." ==
>    "What a nice day today: Story of happiness (Part 2)"
> 
> 

I would transform both strings using gsub(), then compare.

e.g.

clean <- function(s)
  gsub("[[:punct:][:blank:]]", "", s)

clean("What a nice day today! - Story of happiness: Part 2.") ==
clean("What a nice day today: Story of happiness (Part 2)")

This completely ignores spaces; you might want something more
sophisticated if you consider "today" and "to day" to be different, e.g.

clean <- function(s) {
  s <- gsub("[[:punct:]]", "", s)
  gsub("[[:blank:]]+", " ", s)
}

which converts multiple blanks into single spaces.

Duncan Murdoch


From john.archie.mckown at gmail.com  Mon Apr 20 16:11:53 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 20 Apr 2015 09:11:53 -0500
Subject: [R] regexpr - ignore all special characters and punctuation in
	a string
In-Reply-To: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
Message-ID: <CAAJSdjiAiR6N5qkKzivhzHLZvDTmiAZHn4UYt3mG3A-yxdkvYQ@mail.gmail.com>

On Mon, Apr 20, 2015 at 8:59 AM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Hello!
>
> Please point me in the right direction.
> I need to match 2 strings, but focusing ONLY on characters, ignoring
> all special characters and punctuation signs, including (), "", etc..
>
> For example:
> I want the following to return: TRUE
>
> "What a nice day today! - Story of happiness: Part 2." ==
>    "What a nice day today: Story of happiness (Part 2)"
>
>
> --
> Thank you!
> Dimitri Liakhovitski
>
>
>
?Perhaps a variation on:

> str1<-"What a nice day today! - Story of happiness: Part 2."
> str2<- "What a nice day today: Story of happiness (Part 2)"
> gsub('[^[:alpha:]]','',str1)==gsub('[^[:alpha:]]','',str2)
[1] TRUE
>

The gsub() removes all characters which are not alphabetic from each string
and then compares them.?


-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Mon Apr 20 16:15:18 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 20 Apr 2015 09:15:18 -0500
Subject: [R] regexpr - ignore all special characters and punctuation in
	a string
In-Reply-To: <CAHuTOvokcsRix09GaAe6U07gbkSOODtiHyBZZYh6rih9PLWFvA@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
	<CAN2xGJZsP8WDhsvCQt2tjvEbcW_OT3QVsyMvBqTVqLu+hfZD=g@mail.gmail.com>
	<CAHuTOvokcsRix09GaAe6U07gbkSOODtiHyBZZYh6rih9PLWFvA@mail.gmail.com>
Message-ID: <CAKxd1KNoe3-QQ8k2PK9TH5TrfMuiY2Oncr01MzjGBNk+oAL2fg@mail.gmail.com>

You can use the [:alnum:] regex class with gsub.

str1 <- "What a nice day today! - Story of happiness: Part 2."
str2 <- "What a nice day today: Story of happiness (Part 2)"

gsub("[^[:alnum:]]", "", str1) == gsub("[^[:alnum:]]", "", str2)
[1] TRUE

The same can be done with the stringr package if you really are partial to
it.

library(stringr)





On Mon, Apr 20, 2015 at 9:10 AM, Sven E. Templer <sven.templer at gmail.com>
wrote:

> Hi Dimitri,
>
> str_replace_all is not in the base libraries, you could use 'gsub' as well,
> for example:
>
> a = "What a nice day today! - Story of happiness: Part 2."
> b = "What a nice day today: Story of happiness (Part 2)"
> sa = gsub("[^A-Za-z0-9]", "", a)
> sb = gsub("[^A-Za-z0-9]", "", b)
> a==b
> # [1] FALSE
> sa==sb
> # [1] TRUE
>
> Take care of the extra space in a after the '-', so also replace spaces...
>
> Best,
> Sven.
>
> On 20 April 2015 at 16:05, Dimitri Liakhovitski <
> dimitri.liakhovitski at gmail.com> wrote:
>
> > I think I found a partial answer:
> >
> > str_replace_all(x, "[[:punct:]]", " ")
> >
> > On Mon, Apr 20, 2015 at 9:59 AM, Dimitri Liakhovitski
> > <dimitri.liakhovitski at gmail.com> wrote:
> > > Hello!
> > >
> > > Please point me in the right direction.
> > > I need to match 2 strings, but focusing ONLY on characters, ignoring
> > > all special characters and punctuation signs, including (), "", etc..
> > >
> > > For example:
> > > I want the following to return: TRUE
> > >
> > > "What a nice day today! - Story of happiness: Part 2." ==
> > >    "What a nice day today: Story of happiness (Part 2)"
> > >
> > >
> > > --
> > > Thank you!
> > > Dimitri Liakhovitski
> >
> >
> >
> > --
> > Dimitri Liakhovitski
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Apr 20 16:35:02 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Apr 2015 09:35:02 -0500
Subject: [R]
	=?utf-8?q?library=28xlsx=29_fails_with_an_error=3A_Error=3A_p?=
	=?utf-8?q?ackage_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
References: <5532812D020000CB00129DAB@smtp.medicine.umaryland.edu>
Message-ID: <CABdHhvF1yzG54Lg2oGfJ3XNrf0JAtuXr+MctsWo=h98eoPGHwg@mail.gmail.com>

You might want to try readxl instead, as it doesn't have any external
dependencies.
Hadley

On Sat, Apr 18, 2015 at 3:07 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Windows 7 64-bit
> R 3.1.3
> RStudio 0.98.1103
>
>
> I am having difficulty loading and installing the xlsx package. The
> loading occurred without any problem, however the library command
> library(xlsx) produced an error related to rJava. I tried to install
> rJava seperately, re-loaded the xlsx package, and entered the
> library(xlsx) command but received the same error message about rJave.
> Please see terminal messages below. Any suggestion that would allow me
> to load and run xlsx would be appreciated.
> Thank you,
> John
>
>
>> install.packages("xlsx")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/xlsx_0.5.7.zip'
> Content type 'application/zip' length 400944 bytes (391 KB)
> opened URL
> downloaded 391 KB
>
>
> package ?xlsx? successfully unpacked and MD5 sums checked
>
>
> The downloaded binary packages are in
>         C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
>> library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package ?rJava? could not be loaded
>> install.packages("rJava")
> Installing package into ?C:/Users/John/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL
> 'http://cran.rstudio.com/bin/windows/contrib/3.1/rJava_0.9-6.zip'
> Content type 'application/zip' length 759396 bytes (741 KB)
> opened URL
> downloaded 741 KB
>
>
> package ?rJava? successfully unpacked and MD5 sums checked
>
>
> The downloaded binary packages are in
>         C:\Users\John\AppData\Local\Temp\Rtmp4CO5m7\downloaded_packages
>> library(rJava)
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package or namespace load failed for ?rJava?
>> library(xlsx)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object
> 'C:/Users/John/Documents/R/win-library/3.1/rJava/libs/x64/rJava.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package ?rJava? could not be loaded
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:17}}


From macqueen1 at llnl.gov  Mon Apr 20 16:40:57 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 20 Apr 2015 14:40:57 +0000
Subject: [R] Smart detection of wrap width?
In-Reply-To: <CALhdq6viSZYVMiu8=ZTQEwsccnBrMCV3GMKOtyA_WJ0k=gC66Q@mail.gmail.com>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
	<CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
	<CALhdq6viSZYVMiu8=ZTQEwsccnBrMCV3GMKOtyA_WJ0k=gC66Q@mail.gmail.com>
Message-ID: <D15A5C2A.125F47%macqueen1@llnl.gov>

At this point, and since we are in an X windows context, I think it might
be easier to use the window manager's features and write a little macro or
something that will send my setwid() command to the active window, then
assign it to a simple keystroke. Then:  resize the window; hit the
keystroke, and you're done. True, it's not fully automatic, but it would
be pretty quick and easy.

Either that or give ESS a try, using the bit that Ista offered. Or maybe
Rstudio?

Peter's got a good start, but I too would be stymied at the last step;
definitely beyond my skill.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/18/15, 1:41 PM, "Peter Crowther" <peter.crowther at melandra.com> wrote:

>On Apr 17, 2015 7:37 PM, "Paul Domaskis" <paul.domaskis at gmail.com> wrote:
>> I don't suppose there is a way to have it
>> automatically invoked when the window size/positition changes?
>
>Possibly, though it would take a little building.  If you were to
>launch R directly when you start the xterm (loosely xterm R rather
>than the default) then R would receive a SIGWINCH signal whenever the
>xterm window size changes (xterm automatically sends this to its child
>process).  R doesn't directly enable handling of the signal, but
>there's nothing to stop you loading a dynamic library with a little C
>code that set up a handler for SIGWINCH and, when it got one, ran the
>equivalent of the stty command to get the new width.  The thing I've
>not been able to figure out is how the C code would ever then hand
>that to R asynchronously.  Anyone?
>
>Cheers,
>
>- Peter
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Paul.Domaskis at gmail.com  Mon Apr 20 16:43:25 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 14:43:25 +0000
Subject: [R] Need online version of R help pages
References: <loom.20150416T230116-747@post.gmane.org>	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
	<55324DC9.9070006@dewey.myzen.co.uk>
Message-ID: <loom.20150420T163527-340@post.gmane.org>

Acknowledged, Michael.  I appreciate the pointer to the info.

For at least a short while, however, this is my only access to R, so I
am using this environment to ramp up on times series and R as much a
possible.  I think it should suffice for that purpose, and the real
analysis can occur in a more reliable installation R.  I've managed to
work the ropes on a better installation, but the solution won't be
immediate.

Michael Dewey <lists <at> dewey.myzen.co.uk> writes:
| I am not sure how helpful this is going to be but Appendix C7 in the
| Installation and Administration manual is pretty bleak about your
| prospects with Cygwin.
|
|On 18/04/2015 02:17, Paul Domaskis wrote:
|> With all due respect, Duncan, I can't find the message advising
|> against using the Cygwin port.  I did find a message about the
|> mishandling of line endings, and I've asked on the cygwin forum (as
|> advised).
|>
|> As I mentioned, I'm in an environment where updates are not
|> possible, and I'm clarifying now that this means installations are
|> even more impossible, at least not without extensive adminstrative
|> delay.  Basically, this is what I have to work with.  If anyone can
|> suggest good ideas for the challenges as-is, that would be much
|> appreciated.  However, given your posts, I fully understand if the
|> answer is "no".  On the other hand, simply demanding a solution
|> consisting of a course of action which is impossible at
|> present...well, it's just impossible.  Having said that, I'll just
|> say that I've managed to exort the powers that be to install a
|> Windows based version of R, but I have to work with what I
|> currently have for at least a week.  I should also mention that
|> I've submitted an update to the mailing list on a workaround for
|> the R help problem on cygwin.  It might not have propagated to
|> recipients yet.
|>
|> I appreciate the further info on the extent of the bugginess of the
|> cygwin port.
|>
|> On Fri, Apr 17, 2015 at 9:04 PM, Duncan Murdoch
|><murdoch.duncan <at> gmail.com> wrote:
|>>On 16/04/2015 5:02 PM, paul wrote:
|>>> The help for the cygwin port of R is buggy and hides random lines
|>>> of text.
|>>
|>> You've already been told not to use the Cygwin port.  It's buggy
|>> in the help pages, and probably in many other respects as well.
|>> It doesn't pass the R self-tests.  Don't use it.
|>>
|>>>   Consquently, I've been relying on Google, but it is often not
|>>>   clear how directly relevant the info is for the specific
|>>>   command that I'm using.  For example, reshape is complicated,
|>>>   and has more than 1 version.
|>>>
|>>> Is there an online version of the help pages?
|>>>
|>>> I tried looking for html versions of the help pages by ferruting
|>>> through the R.home() subtree.  Haven't found them so far.  There
|>>> are package pages in subdirectories <package>/html/00Index.html,
|>>> but they just contain links to html files that don't reside in my
|>>> R.home() subtree.  There are also subdirectories <package>/help,
|>>> but they contain pages that I don't recognize (*.rds, *.rdb,
|>>> *.rdx).
|>>>
|>>> Getting desparate here, and realizing how the web is not in any
|>>> way a substituted for locally available help pages that you can
|>>> be confident is right for your installation.


From Paul.Domaskis at gmail.com  Mon Apr 20 16:55:08 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 14:55:08 +0000
Subject: [R] Smart detection of wrap width?
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
	<CA+vqiLFMbfdsFuMVTkOq9HxMjj4dyf32gc3VMHArtKMEkvhmww@mail.gmail.com>
	<CALhdq6viSZYVMiu8=ZTQEwsccnBrMCV3GMKOtyA_WJ0k=gC66Q@mail.gmail.com>
	<D15A5C2A.125F47%macqueen1@llnl.gov>
Message-ID: <loom.20150420T165454-105@post.gmane.org>

Paul Domaskis <paul.domaskis <at> gmail.com> writes:
> Yes, I found the width option in the help pages, but I was wondering
> if there was automatic setting of the wrapping according to the
> current window width.
> 
> Your function works exactly as I wished.  I'll probably get smarter
> with time (I hope) but would it be reasonably good practice to stick
> this into ~/.Rprofile?  I don't suppose there is a way to have it
> automatically invoked when the window size/positition changes?
> (It's still priceless even without automatic triggering).

Ista Zahn <istazahn <at> gmail.com> writes:
> For ESS see
> https://github.com/gaborcsardi/dot-emacs/blob/master/.emacs

Thanks, Ista....I'm...err....I'm a vim user <<cowers>>....

Peter Crowther <peter.crowther <at> melandra.com> writes:
> Possibly, though it would take a little building.  If you were to
> launch R directly when you start the xterm (loosely xterm R rather
> than the default) then R would receive a SIGWINCH signal whenever
> the xterm window size changes (xterm automatically sends this to its
> child process).  R doesn't directly enable handling of the signal,
> but there's nothing to stop you loading a dynamic library with a
> little C code that set up a handler for SIGWINCH and, when it got
> one, ran the equivalent of the stty command to get the new width.
> The thing I've not been able to figure out is how the C code would
> ever then hand that to R asynchronously.  Anyone?

MacQueen, Don <macqueen1 <at> llnl.gov> writes:
> At this point, and since we are in an X windows context, I think it
> might be easier to use the window manager's features and write a
> little macro or something that will send my setwid() command to the
> active window, then assign it to a simple keystroke. Then:  resize
> the window; hit the keystroke, and you're done. True, it's not fully
> automatic, but it would be pretty quick and easy.
> 
> Either that or give ESS a try, using the bit that Ista offered. Or
> maybe Rstudio?
> 
> Peter's got a good start, but I too would be stymied at the last
> step; definitely beyond my skill.

Peter, Don,

Considering that I've been using Matlab, VBA, and Access for the last
decade, I think that venturing down this path might take quite some
time.  I appreciate the ideas, and if I'm ever in the zone with
programming under the hood with X-windows (which I use), I'll refer
back.  Thanks.


From macqueen1 at llnl.gov  Mon Apr 20 16:59:56 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 20 Apr 2015 14:59:56 +0000
Subject: [R] Smart detection of wrap width?
In-Reply-To: <CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
Message-ID: <D15A5E1D.125F59%macqueen1@llnl.gov>

I'm glad it's helpful!

Defining it and then invoking it in ~/.Rprofile would work, but then you
will need to be careful about managing both ./.Rprofile and ~/.Rprofile
files. If you have one of the former, then the latter does not get sourced
at startup (see ?Startup). Of course, you can put source('~/.Rprofile') in
a local ./.Rprofile to take care of that if you want.

But in the long run, it would be a better practice to put personal helper
functions like this in a package and then load it in your .Rprofile
file(s). Most of my ./.Rprofile files have
  require(rmacq)
  setwid()
in them (along with whatever other directory-specific startup actions I
want). The more personal helper functions you have, the more valuable it
will be to put them in a package instead of defining them in ~/.Rprofile.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/17/15, 4:36 PM, "Paul Domaskis" <paul.domaskis at gmail.com> wrote:

>Yes, I found the width option in the help pages, but I was wondering
>if there was automatic setting of the wrapping according to the
>current window width.
>
>Your function works exactly as I wished.  I'll probably get smarter
>with time (I hope) but would it be reasonably good practice to stick
>this into ~/.Rprofile?  I don't suppose there is a way to have it
>automatically invoked when the window size/positition changes?  (It's
>still priceless even without automatic triggering).
>
>On Fri, Apr 17, 2015 at 7:20 PM, MacQueen, Don <macqueen1 at llnl.gov>
>wrote:
>> A lot of this depends on what context you are running R in, e.g.,
>> Windows console, Mac console, or command line in a unix-alike. Or
>> within ESS in emacs. Those are different interfaces supported by, to
>> some extent, different people, and are based on the underlying
>> capabilities provided by the operating system.
>>
>> Have you yet encountered
>>   options()$width
>> ?
>> For example,
>>   options(width=100)
>> will cause wrapping at 100, at least for certain kinds of output.
>>
>> In an xterm shell running in an X windows context, I frequently use
>>
>> setwid <- function ()
>> {
>>     if (!interactive())
>>         return(invisible(NULL))
>>     scon <- pipe("stty -a")
>>     stty <- scan(scon, what = "", sep = ";", quiet = T)
>>     close(scon)
>>     cstr <- stty[grep("columns", stty)]
>>     options(width = as.numeric(gsub("[^0-9]", "", cstr, ignore.case =
>>T)))
>>     paste("width =", options()$width, "\n")
>> }
>>
>> A function I wrote that resets the width option to match the window
>> widths, and therefore adjusts the wrapping after I resize a windwo.


From veedeehjay at googlemail.com  Mon Apr 20 17:01:46 2015
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Mon, 20 Apr 2015 17:01:46 +0200
Subject: [R] color handling in `barplot' inconsistent betwen `beside=FALSE'
 and `beside=TRUE'
Message-ID: <op.xxeb0814p7eajd@marco.fz-rossendorf.de>

hi,

consider the following example:

8<-------------------------------------
x <- matrix(1:6, 3, 2)
layout(1:2)
barplot(x, beside = TRUE, col = 1:6)
barplot(x, beside = FALSE, col = 1:6)
8<-------------------------------------

it seems, it is not possible to make `beside=FAlSE' plots behave the same  
as `beside=TRUE' plots (i.e. use unique colors for all bars or bar  
components), or is it? if I do not miss something, I would say the present  
behaviour (as of 3.1.3) is not (or not always, anyway) desirable. rather,  
`beside=FALSE' should use the same color for all bars or bar components as  
`beside=TRUE'.

any opionions on that?

in case someone needs this, the following patch achieves what I would  
expect from `barplot(beside=FALSE, ...)' -- at least w.r.t. colors, if not  
shading ... -- in the first place:

8<-----------------------------------
@@ -96,12 +96,12 @@
      if (beside)
          w.m <- matrix(w.m, ncol = NC)
      if (plot) {
-        dev.hold()
+        ###dev.hold()
          opar <- if (horiz)
              par(xaxs = "i", xpd = xpd)
          else par(yaxs = "i", xpd = xpd)
          on.exit({
-            dev.flush()
+            ###dev.flush()
              par(opar)
          })
          if (!add) {
@@ -119,10 +119,16 @@
                  w.r, horizontal = horiz, angle = angle, density = density,
                  col = col, border = border)
          else {
+            numelements <- length(height[-1,])
+            numcols <- length(col)
+            if (numelements != numcols)
+               col <- rep_len(col, ceiling(numelements/numcols))
+            col <- col[1:numelements]
+            attr(col, "dim") <- dim(height[-1,])
              for (i in 1L:NC) {
                  xyrect(height[1L:NR, i] + offset[i], w.l[i],
                    height[-1, i] + offset[i], w.r[i], horizontal = horiz,
-                  angle = angle, density = density, col = col,
+                  angle = angle, density = density, col = col[1:NR, i],
                    border = border)
              }
          }
8<-----------------------------------

(please note that this is the diff for the representation of the function  
as it appears in `edit(barplot)', rather than as it appears in the R  
source code ...)

@devs: would it be desirable to change the "official" `barplot' behaviour  
accordingly in the future?


thanks

joerg



--


From paul.domaskis at gmail.com  Mon Apr 20 17:04:23 2015
From: paul.domaskis at gmail.com (Paul Domaskis)
Date: Mon, 20 Apr 2015 11:04:23 -0400
Subject: [R] Smart detection of wrap width?
In-Reply-To: <D15A5E1D.125F59%macqueen1@llnl.gov>
References: <loom.20150418T005218-827@post.gmane.org>
	<D156E1A1.125D06%macqueen1@llnl.gov>
	<CABSksF8xbnVC6BC1QPVbqLBOetyf3biDPVyzMUBcxoxMZbNHfw@mail.gmail.com>
	<D15A5E1D.125F59%macqueen1@llnl.gov>
Message-ID: <CABSksF-YwhK80kDpe2en-6X_vZ37Luz3k+t6BoO5+HSzvg5ENA@mail.gmail.com>

On Mon, Apr 20, 2015 at 10:59 AM, MacQueen, Don <macqueen1 at llnl.gov>
wrote:
> I'm glad it's helpful!
>
> Defining it and then invoking it in ~/.Rprofile would work, but then
> you will need to be careful about managing both ./.Rprofile and
> ~/.Rprofile files. If you have one of the former, then the latter
> does not get sourced at startup (see ?Startup). Of course, you can
> put source('~/.Rprofile') in a local ./.Rprofile to take care of
> that if you want.
>
> But in the long run, it would be a better practice to put personal
> helper functions like this in a package and then load it in your
> .Rprofile file(s). Most of my ./.Rprofile files have
>
>   require(rmacq)
>   setwid()
>
> in them (along with whatever other directory-specific startup
> actions I want). The more personal helper functions you have, the
> more valuable it will be to put them in a package instead of
> defining them in ~/.Rprofile.

Thanks, I'll keep it in mind, Don.  I'm sort of careening at breakneck
speed into time series and R, so I know I'll be rough around the edges
for a while, with the more refined aspects such as sensible
organization of customizations following in the rear.  Not ideal, I
know, but 'tis what it is...


From john.archie.mckown at gmail.com  Mon Apr 20 17:13:26 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 20 Apr 2015 10:13:26 -0500
Subject: [R] Need online version of R help pages
In-Reply-To: <loom.20150420T163527-340@post.gmane.org>
References: <loom.20150416T230116-747@post.gmane.org>
	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
	<55324DC9.9070006@dewey.myzen.co.uk>
	<loom.20150420T163527-340@post.gmane.org>
Message-ID: <CAAJSdjh355WMsyhQF6mOCG66BVC+3=1uUtW465Aw4MDc2UJaUQ@mail.gmail.com>

On Mon, Apr 20, 2015 at 9:43 AM, Paul <Paul.Domaskis at gmail.com> wrote:

> Acknowledged, Michael.  I appreciate the pointer to the info.
>
> For at least a short while, however, this is my only access to R, so I
> am using this environment to ramp up on times series and R as much a
> possible.  I think it should suffice for that purpose, and the real
> analysis can occur in a more reliable installation R.  I've managed to
> work the ropes on a better installation, but the solution won't be
> immediate.
>
>
?I am not really familiar with the site referenced below. But maybe it
would be helpful to you? It allows you to edit and run R code through a
browser on the _their_ site. It appears to be absolutely free. And has
other languages available as well.

http://www.tutorialspoint.com/execute_r_online.php
?


-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Mon Apr 20 17:20:16 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Apr 2015 11:20:16 -0400
Subject: [R] regexpr - ignore all special characters and punctuation in
	a string
In-Reply-To: <CAKxd1KNoe3-QQ8k2PK9TH5TrfMuiY2Oncr01MzjGBNk+oAL2fg@mail.gmail.com>
References: <CAN2xGJb=n+jVyQGih_mgrjiHXEBiDtm0xeCUEDrVTrzhYu9w+g@mail.gmail.com>
	<CAN2xGJZsP8WDhsvCQt2tjvEbcW_OT3QVsyMvBqTVqLu+hfZD=g@mail.gmail.com>
	<CAHuTOvokcsRix09GaAe6U07gbkSOODtiHyBZZYh6rih9PLWFvA@mail.gmail.com>
	<CAKxd1KNoe3-QQ8k2PK9TH5TrfMuiY2Oncr01MzjGBNk+oAL2fg@mail.gmail.com>
Message-ID: <CAN2xGJZE35yxEd6B1so1j-+L=0+VPirBQZce5Uy=rBCcLtA9sg@mail.gmail.com>

Thanks a lot, everybody for excellent suggestions!

On Mon, Apr 20, 2015 at 10:15 AM, Charles Determan
<cdetermanjr at gmail.com> wrote:
> You can use the [:alnum:] regex class with gsub.
>
> str1 <- "What a nice day today! - Story of happiness: Part 2."
> str2 <- "What a nice day today: Story of happiness (Part 2)"
>
> gsub("[^[:alnum:]]", "", str1) == gsub("[^[:alnum:]]", "", str2)
> [1] TRUE
>
> The same can be done with the stringr package if you really are partial to
> it.
>
> library(stringr)
>
>
>
>
>
> On Mon, Apr 20, 2015 at 9:10 AM, Sven E. Templer <sven.templer at gmail.com>
> wrote:
>>
>> Hi Dimitri,
>>
>> str_replace_all is not in the base libraries, you could use 'gsub' as
>> well,
>> for example:
>>
>> a = "What a nice day today! - Story of happiness: Part 2."
>> b = "What a nice day today: Story of happiness (Part 2)"
>> sa = gsub("[^A-Za-z0-9]", "", a)
>> sb = gsub("[^A-Za-z0-9]", "", b)
>> a==b
>> # [1] FALSE
>> sa==sb
>> # [1] TRUE
>>
>> Take care of the extra space in a after the '-', so also replace spaces...
>>
>> Best,
>> Sven.
>>
>> On 20 April 2015 at 16:05, Dimitri Liakhovitski <
>> dimitri.liakhovitski at gmail.com> wrote:
>>
>> > I think I found a partial answer:
>> >
>> > str_replace_all(x, "[[:punct:]]", " ")
>> >
>> > On Mon, Apr 20, 2015 at 9:59 AM, Dimitri Liakhovitski
>> > <dimitri.liakhovitski at gmail.com> wrote:
>> > > Hello!
>> > >
>> > > Please point me in the right direction.
>> > > I need to match 2 strings, but focusing ONLY on characters, ignoring
>> > > all special characters and punctuation signs, including (), "", etc..
>> > >
>> > > For example:
>> > > I want the following to return: TRUE
>> > >
>> > > "What a nice day today! - Story of happiness: Part 2." ==
>> > >    "What a nice day today: Story of happiness (Part 2)"
>> > >
>> > >
>> > > --
>> > > Thank you!
>> > > Dimitri Liakhovitski
>> >
>> >
>> >
>> > --
>> > Dimitri Liakhovitski
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dimitri Liakhovitski


From Paul.Domaskis at gmail.com  Mon Apr 20 17:24:28 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 15:24:28 +0000
Subject: [R] Need online version of R help pages
References: <loom.20150416T230116-747@post.gmane.org>
	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
	<55324DC9.9070006@dewey.myzen.co.uk>
	<loom.20150420T163527-340@post.gmane.org>
	<CAAJSdjh355WMsyhQF6mOCG66BVC+3=1uUtW465Aw4MDc2UJaUQ@mail.gmail.com>
Message-ID: <loom.20150420T172410-753@post.gmane.org>

John McKown <john.archie.mckown <at> gmail.com> writes:
>On Mon, Apr 20, 2015 at 9:43 AM, Paul <Paul.Domaskis <at> gmail.com>
>wrote:
> 
> http://www.tutorialspoint.com/execute_r_online.php

John, I appreciate the pointer.  I wish the post quoted below had
made it to the mailing list, as I could have saved you the trouble of
trying to seek a solution on my behalf.  I'm quite happy using vim
and in fact consider it to be my right hand (even though I don't dive
under the hood much).  So this post was really about getting around
the broken cygwin help facility for R rather than editing.  Also,
at work, we have to keep the work on-site.

For those unfortunate enough to have no option but to use cygwin's R,
here is the posting re. a workaround to the broken help facility,
posted via nabble (which probably explains why it didn't make it to
the mailing list):

> Sent: April-16-15 5:51 PM
> Subject: Re: Need online version of R help pages
> 
> I was able to get the help info for many of the commands from the
> link for "The R Reference Index" at
> http://cran.r-project.org/manuals.html. 
> 
> However, I found that I could also get help from the R prompt via 
> 
>    help(myHelpTopic,help_type="html") 
> 
> To make that work, I needed options(browser="cygstart") in
> ~/.Rprofile. 
> 
> Very puzzling to a non-web-developer like myself: The URL for the
> help content is (for example)
> http://127.0.0.1:16086/library/stats/html/reshape.html.  This is a
> loop-back address.  I did *not* see any file named reshape.html in
> subdirectory library/stats/html/reshape.html when I went to
> R.home(). 
> 
> I thought that perhaps the file was being composed on the fly.
> However, I was under the distinct impression that my account did not
> have the ability to set up servers (and I assume that the page that
> is composed on the fly must be served out by a server).


From xavier.chiriboga at unine.ch  Mon Apr 20 17:50:11 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Mon, 20 Apr 2015 15:50:11 +0000
Subject: [R] groupedData HELP!
Message-ID: <7B64C8E017B948419F014C915AA6D7342A05764E@mail-mbx-04.UNINE.CH>

Dear members,



what to do when this appears ?



Error: could not find function "groupedData"



Thanks a lot,

Xavier


From wdunlap at tibco.com  Mon Apr 20 18:09:23 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 20 Apr 2015 09:09:23 -0700
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
Message-ID: <CAF8bMcb2Gjdewc28CVhNQQrxV3txrQXhEAb3r=7MYV1gxkrMLw@mail.gmail.com>

The hyphen without a following digit confuses tidyr::extract_numeric().
E.g.,
   > extract_numeric("23 ft-lbs")
   Warning message:
   In extract_numeric("23 ft-lbs") : NAs introduced by coercion
   [1] NA
   > extract_numeric("23 ft*lbs")
   [1] 23
Contact the BugReports address for the package
   > packageDescription("tidyr")$BugReports
   [1] "https://github.com/hadley/tidyr/issues"
or package's maintainer
   > maintainer("tidyr")
   [1] "Hadley Wickham <hadley at rstudio.com>"
to report problems in a user-contributed package.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Apr 20, 2015 at 12:10 AM, arnaud gaboury <arnaud.gaboury at gmail.com>
wrote:

> R 3.2.0 on Linux
> --------------------------------
>
> library(tidyr)
>
> playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
> Portals Visited 1,038",
> "XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed 11,126",
> "Links Created 1,744", "Control Fields Created 294", "Mind Units
> Captured 2,995,484 MUs",
> "Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
> "XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
> Captured 486",
> "Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
> Links Destroyed 3,169",
> "Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
> "Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
> "Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
> "Largest Field MUs x Days 83,226 MU-days")
>
>
> -----------------------------------------------------------------------------------------------
>  extract_numeric(playerStats)
>  [1]             10 56714486000000           1038       15327123
>    14268          11126           1744            294        2995484
> [10]             75         189731        3006364           1204
>      486          12481           1240           3169           1394
> [19]            230            240             15             NA
>        4             NA
>
>
> ------------------------------------------------------------------------------------------------
>  playerStats[c(22,24)]
> [1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
> Days 83,226 MU-days"
>
> --------------------------------------------------------------------------------------------
>
> I do not understand why these two vectors return NA when the function
> extract_numeric() works well for others,
>
> Any wrong settings in my env?
>
> Thank you for hints.
>
>
>
> --
>
> google.com/+arnaudgabourygabx
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Apr 20 18:10:10 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 20 Apr 2015 11:10:10 -0500
Subject: [R] color handling in `barplot' inconsistent betwen
 `beside=FALSE' and `beside=TRUE'
In-Reply-To: <op.xxeb0814p7eajd@marco.fz-rossendorf.de>
References: <op.xxeb0814p7eajd@marco.fz-rossendorf.de>
Message-ID: <54857762-5463-4C05-8300-34F68DF20691@me.com>

On Apr 20, 2015, at 10:01 AM, j. van den hoff <veedeehjay at googlemail.com> wrote:
> 
> hi,
> 
> consider the following example:
> 
> 8<-------------------------------------
> x <- matrix(1:6, 3, 2)
> layout(1:2)
> barplot(x, beside = TRUE, col = 1:6)
> barplot(x, beside = FALSE, col = 1:6)
> 8<-------------------------------------
> 
> it seems, it is not possible to make `beside=FAlSE' plots behave the same as `beside=TRUE' plots (i.e. use unique colors for all bars or bar components), or is it? if I do not miss something, I would say the present behaviour (as of 3.1.3) is not (or not always, anyway) desirable. rather, `beside=FALSE' should use the same color for all bars or bar components as `beside=TRUE'.
> 
> any opionions on that?
> 
> in case someone needs this, the following patch achieves what I would expect from `barplot(beside=FALSE, ...)' -- at least w.r.t. colors, if not shading ... -- in the first place:
> 
> 8<-----------------------------------
> @@ -96,12 +96,12 @@
>     if (beside)
>         w.m <- matrix(w.m, ncol = NC)
>     if (plot) {
> -        dev.hold()
> +        ###dev.hold()
>         opar <- if (horiz)
>             par(xaxs = "i", xpd = xpd)
>         else par(yaxs = "i", xpd = xpd)
>         on.exit({
> -            dev.flush()
> +            ###dev.flush()
>             par(opar)
>         })
>         if (!add) {
> @@ -119,10 +119,16 @@
>                 w.r, horizontal = horiz, angle = angle, density = density,
>                 col = col, border = border)
>         else {
> +            numelements <- length(height[-1,])
> +            numcols <- length(col)
> +            if (numelements != numcols)
> +               col <- rep_len(col, ceiling(numelements/numcols))
> +            col <- col[1:numelements]
> +            attr(col, "dim") <- dim(height[-1,])
>             for (i in 1L:NC) {
>                 xyrect(height[1L:NR, i] + offset[i], w.l[i],
>                   height[-1, i] + offset[i], w.r[i], horizontal = horiz,
> -                  angle = angle, density = density, col = col,
> +                  angle = angle, density = density, col = col[1:NR, i],
>                   border = border)
>             }
>         }
> 8<-----------------------------------
> 
> (please note that this is the diff for the representation of the function as it appears in `edit(barplot)', rather than as it appears in the R source code ...)
> 
> @devs: would it be desirable to change the "official" `barplot' behaviour accordingly in the future?
> 
> 
> thanks
> 
> joerg


Hi,

You can go the other way:

  layout(1:2)
  barplot(x, beside = FALSE, col = 1:3)
  barplot(x, beside = TRUE, col = rep(1:3, 2))


You could use the following workaround:

  barplot(cbind(1:3, c(NA, NA, NA)), beside = FALSE, col = 1:3, ylim = c(0, 15))
  barplot(cbind(c(NA, NA, NA), 4:6), beside = FALSE, col = 4:6, add = TRUE)

That essentially plots each stack separately, using the respective NA columns to space the two stacks in the plot. In the first call, also setting the y axis limits to handle both stacks. In the second call, using ?add = TRUE? so that the second plot does not overwrite the first.

The use of stacked bar plots is typical when trying to visually compare the same categories across groupings, thus the same colors in each stack by default. This is not always easy if the differences are subtle, similar to the issues with pie charts.

I would not advocate changing the current behavior, as a lot of long standing code would break, including functions in packages that are built on top of barplot() and expect certain default behaviors.

You can always make a local modification of barplot() for your own use and/or consider that there might be a logical CRAN package for graphics extensions where it could be included as an add-on function.

Regards,

Marc Schwartz


From soniaamin5 at gmail.com  Mon Apr 20 18:33:38 2015
From: soniaamin5 at gmail.com (Sonia Amin)
Date: Mon, 20 Apr 2015 18:33:38 +0200
Subject: [R] Problem with col
Message-ID: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>

Dear All,

I have written the following lines:

 data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
= FALSE, sep = "")
 colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
 result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
summary(result.model1)

I obtained the following message:


Call:
lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)

Residuals:
Error in quantile.default(resid) : factors are not allowed
In addition: warning message:
In Ops.factor(r, 2) :
  ?^? This is not relevant for factors


Where is the problem?
Thank you in advance

	[[alternative HTML version deleted]]


From veedeehjay at googlemail.com  Mon Apr 20 18:34:47 2015
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Mon, 20 Apr 2015 18:34:47 +0200
Subject: [R] color handling in `barplot' inconsistent betwen
 `beside=FALSE' and `beside=TRUE'
In-Reply-To: <54857762-5463-4C05-8300-34F68DF20691@me.com>
References: <op.xxeb0814p7eajd@marco.fz-rossendorf.de>
	<54857762-5463-4C05-8300-34F68DF20691@me.com>
Message-ID: <op.xxegb9lzp7eajd@marco.fz-rossendorf.de>

On Mon, 20 Apr 2015 18:10:10 +0200, Marc Schwartz <marc_schwartz at me.com>  
wrote:

> On Apr 20, 2015, at 10:01 AM, j. van den hoff  
> <veedeehjay at googlemail.com> wrote:
>>
>> hi,
>>
>> consider the following example:
>>
>> 8<-------------------------------------
>> x <- matrix(1:6, 3, 2)
>> layout(1:2)
>> barplot(x, beside = TRUE, col = 1:6)
>> barplot(x, beside = FALSE, col = 1:6)
>> 8<-------------------------------------
>>
>> it seems, it is not possible to make `beside=FAlSE' plots behave the  
>> same as `beside=TRUE' plots (i.e. use unique colors for all bars or bar  
>> components), or is it? if I do not miss something, I would say the  
>> present behaviour (as of 3.1.3) is not (or not always, anyway)  
>> desirable. rather, `beside=FALSE' should use the same color for all  
>> bars or bar components as `beside=TRUE'.
>>
>> any opionions on that?
>>
>> in case someone needs this, the following patch achieves what I would  
>> expect from `barplot(beside=FALSE, ...)' -- at least w.r.t. colors, if  
>> not shading ... -- in the first place:
>>
>> 8<-----------------------------------
>> @@ -96,12 +96,12 @@
>>     if (beside)
>>         w.m <- matrix(w.m, ncol = NC)
>>     if (plot) {
>> -        dev.hold()
>> +        ###dev.hold()
>>         opar <- if (horiz)
>>             par(xaxs = "i", xpd = xpd)
>>         else par(yaxs = "i", xpd = xpd)
>>         on.exit({
>> -            dev.flush()
>> +            ###dev.flush()
>>             par(opar)
>>         })
>>         if (!add) {
>> @@ -119,10 +119,16 @@
>>                 w.r, horizontal = horiz, angle = angle, density =  
>> density,
>>                 col = col, border = border)
>>         else {
>> +            numelements <- length(height[-1,])
>> +            numcols <- length(col)
>> +            if (numelements != numcols)
>> +               col <- rep_len(col, ceiling(numelements/numcols))
>> +            col <- col[1:numelements]
>> +            attr(col, "dim") <- dim(height[-1,])
>>             for (i in 1L:NC) {
>>                 xyrect(height[1L:NR, i] + offset[i], w.l[i],
>>                   height[-1, i] + offset[i], w.r[i], horizontal = horiz,
>> -                  angle = angle, density = density, col = col,
>> +                  angle = angle, density = density, col = col[1:NR, i],
>>                   border = border)
>>             }
>>         }
>> 8<-----------------------------------
>>
>> (please note that this is the diff for the representation of the  
>> function as it appears in `edit(barplot)', rather than as it appears in  
>> the R source code ...)
>>
>> @devs: would it be desirable to change the "official" `barplot'  
>> behaviour accordingly in the future?
>>
>>
>> thanks
>>
>> joerg
>
>
> Hi,
>
hi,

thanks for responding.

> You can go the other way:
>
>   layout(1:2)
>   barplot(x, beside = FALSE, col = 1:3)
>   barplot(x, beside = TRUE, col = rep(1:3, 2))

well, that would make it "consistent" but it is not what I want, actually  
...

>
>
> You could use the following workaround:
>
>   barplot(cbind(1:3, c(NA, NA, NA)), beside = FALSE, col = 1:3, ylim =  
> c(0, 15))
>   barplot(cbind(c(NA, NA, NA), 4:6), beside = FALSE, col = 4:6, add =  
> TRUE)
>
> That essentially plots each stack separately, using the respective NA  
> columns to space the two stacks in the plot. In the first call, also  
> setting the y axis limits to handle both stacks. In the second call,  
> using ?add = TRUE? so that the second plot does not overwrite the first.

yes, I see. that indeed would work. however, in my actual use case, I have  
a looong time series with dozens of bars. so it would become quite ugly  
(looping over all the bars subsetting the color vector etc). but yes, one  
could do it this way.

>
> The use of stacked bar plots is typical when trying to visually compare  
> the same categories across groupings, thus the same colors in each stack  
> by default. This is not always easy if the differences are subtle,  
> similar to the issues with pie charts.
>
> I would not advocate changing the current behavior, as a lot of long  
> standing code would break, including functions in packages that are  
> built on top of barplot() and expect certain default behaviors.

yes, I was expecting this answer and I understand it, of course. on the  
other hand, it would be rather straightforward to add another argument to  
`barplot' to control the behaviour (while defaulting to the present one).  
I would think this would be a good addition: in my use case, e.g. I do  
have such categorized and grouped data and just want to be able to plot  
them after sorting within each group according to value while maintaining   
unique color assignments independent of whether the data are sorted within  
each group or not. and with `beside=FALSE'  this is completely  
straightforward (just resort the color vector together with the data),  
while it fails with `beside=TRUE'.

>
> You can always make a local modification of barplot() for your own use

yes, that's what I did. but I wonder how many people would benefit from  
the ability of easily plotting the same data with the same color vs. data  
correspondence independent of the `beside' setting. but it's for the devs  
to decide...

> and/or consider that there might be a logical CRAN package for graphics  
> extensions where it could be included as an add-on function.

yes, maybe I check whether this would make sense.

thank you,

joerg

>
> Regards,
>
> Marc Schwartz
>
>


-- 
Using Opera's revolutionary email client: http://www.opera.com/mail/


From pdalgd at gmail.com  Mon Apr 20 18:37:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 20 Apr 2015 18:37:14 +0200
Subject: [R] groupedData HELP!
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A05764E@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A05764E@mail-mbx-04.UNINE.CH>
Message-ID: <79810255-D9E0-426A-9633-BA758BDCDB96@gmail.com>


On 20 Apr 2015, at 17:50 , CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:

> Dear members,
> 
> 
> 
> what to do when this appears ?
> 
> 
> 
> Error: could not find function "groupedData"
> 
> 

This should be a good start:

RSiteSearch("groupedData")


> 
> Thanks a lot,
> 
> Xavier
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sarah.goslee at gmail.com  Mon Apr 20 18:40:59 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 20 Apr 2015 12:40:59 -0400
Subject: [R] Problem with col
In-Reply-To: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>
References: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>
Message-ID: <CAM_vjunxEuqL8qPSGTH4BLVZjD4AgTJhUgnPBx9cO3P5rjhpNw@mail.gmail.com>

What is the problem? One or more of your columns was read as factor, as

str(data)

would show you. To avoid this, you can add stringsAsFactors=FALSE to
the read.table command, but if you expect your data to be entirely
numeric then there's something wrong with it that you need to hunt
down.

Sarah

On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com> wrote:
> Dear All,
>
> I have written the following lines:
>
>  data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
> = FALSE, sep = "")
>  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
>  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
> summary(result.model1)
>
> I obtained the following message:
>
>
> Call:
> lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
>
> Residuals:
> Error in quantile.default(resid) : factors are not allowed
> In addition: warning message:
> In Ops.factor(r, 2) :
>   ?^? This is not relevant for factors
>
>
> Where is the problem?
> Thank you in advance
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From henrik.bengtsson at ucsf.edu  Mon Apr 20 18:52:33 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Mon, 20 Apr 2015 09:52:33 -0700
Subject: [R] Need online version of R help pages
In-Reply-To: <loom.20150420T172410-753@post.gmane.org>
References: <loom.20150416T230116-747@post.gmane.org>
	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
	<55324DC9.9070006@dewey.myzen.co.uk>
	<loom.20150420T163527-340@post.gmane.org>
	<CAAJSdjh355WMsyhQF6mOCG66BVC+3=1uUtW465Aw4MDc2UJaUQ@mail.gmail.com>
	<loom.20150420T172410-753@post.gmane.org>
Message-ID: <CAFDcVCQX=H9XnJvXjc1X4ZDjCwe6m_4NUFc1pRMAxJXvXY_F5Q@mail.gmail.com>

I don't want to rub it in more, but whatever dark forces are upon you,
they'd have a hard time preventing you from installing R to your user
account, which requires minimal privileges(*).

Just wanted to make sure you're aware of your options

/Henrik

(*) The R Windows installer detects and adjusts for this
automatically. The only things I can think of that prevents this
approach is that the computer is completely disconnected from the
world,  users have extremely limited disk space, the user account is
wiped at every login, ... what else?  Also, AFAIK, the only thing you
miss out on is that R won't be added to the Windows Registry meaning
.RData files are not associated with R, but that's a very low price to
pay considered it's a better option than Cygwin.

On Mon, Apr 20, 2015 at 8:24 AM, Paul <Paul.Domaskis at gmail.com> wrote:
> John McKown <john.archie.mckown <at> gmail.com> writes:
>>On Mon, Apr 20, 2015 at 9:43 AM, Paul <Paul.Domaskis <at> gmail.com>
>>wrote:
>>
>> http://www.tutorialspoint.com/execute_r_online.php
>
> John, I appreciate the pointer.  I wish the post quoted below had
> made it to the mailing list, as I could have saved you the trouble of
> trying to seek a solution on my behalf.  I'm quite happy using vim
> and in fact consider it to be my right hand (even though I don't dive
> under the hood much).  So this post was really about getting around
> the broken cygwin help facility for R rather than editing.  Also,
> at work, we have to keep the work on-site.
>
> For those unfortunate enough to have no option but to use cygwin's R,
> here is the posting re. a workaround to the broken help facility,
> posted via nabble (which probably explains why it didn't make it to
> the mailing list):
>
>> Sent: April-16-15 5:51 PM
>> Subject: Re: Need online version of R help pages
>>
>> I was able to get the help info for many of the commands from the
>> link for "The R Reference Index" at
>> http://cran.r-project.org/manuals.html.
>>
>> However, I found that I could also get help from the R prompt via
>>
>>    help(myHelpTopic,help_type="html")
>>
>> To make that work, I needed options(browser="cygstart") in
>> ~/.Rprofile.
>>
>> Very puzzling to a non-web-developer like myself: The URL for the
>> help content is (for example)
>> http://127.0.0.1:16086/library/stats/html/reshape.html.  This is a
>> loop-back address.  I did *not* see any file named reshape.html in
>> subdirectory library/stats/html/reshape.html when I went to
>> R.home().
>>
>> I thought that perhaps the file was being composed on the fly.
>> However, I was under the distinct impression that my account did not
>> have the ability to set up servers (and I assume that the page that
>> is composed on the fly must be served out by a server).
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From soniaamin5 at gmail.com  Mon Apr 20 18:56:19 2015
From: soniaamin5 at gmail.com (Sonia Amin)
Date: Mon, 20 Apr 2015 18:56:19 +0200
Subject: [R] Problem with col
In-Reply-To: <CAM_vjunxEuqL8qPSGTH4BLVZjD4AgTJhUgnPBx9cO3P5rjhpNw@mail.gmail.com>
References: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>
	<CAM_vjunxEuqL8qPSGTH4BLVZjD4AgTJhUgnPBx9cO3P5rjhpNw@mail.gmail.com>
Message-ID: <CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>

Sorry Sarah  for my basic question: what does "a column was read as factor"
mean?

When I type data , I obtain all the numeric values and the headears  I
added (Consommation,Cylindre,Puissance,Poids)

Thanks



2015-04-20 18:40 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:

> What is the problem? One or more of your columns was read as factor, as
>
> str(data)
>
> would show you. To avoid this, you can add stringsAsFactors=FALSE to
> the read.table command, but if you expect your data to be entirely
> numeric then there's something wrong with it that you need to hunt
> down.
>
> Sarah
>
> On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com> wrote:
> > Dear All,
> >
> > I have written the following lines:
> >
> >
> data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
> > = FALSE, sep = "")
> >  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
> >  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
> > summary(result.model1)
> >
> > I obtained the following message:
> >
> >
> > Call:
> > lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
> >
> > Residuals:
> > Error in quantile.default(resid) : factors are not allowed
> > In addition: warning message:
> > In Ops.factor(r, 2) :
> >   ?^? This is not relevant for factors
> >
> >
> > Where is the problem?
> > Thank you in advance
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Apr 20 19:05:44 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 20 Apr 2015 13:05:44 -0400
Subject: [R] Problem with col
In-Reply-To: <CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>
References: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>
	<CAM_vjunxEuqL8qPSGTH4BLVZjD4AgTJhUgnPBx9cO3P5rjhpNw@mail.gmail.com>
	<CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>
Message-ID: <CAM_vjumfa3GDSXs+kdp+evbL=-7iNG3dzYW5pa9d=YiNWJui6A@mail.gmail.com>

On Mon, Apr 20, 2015 at 12:56 PM, Sonia Amin <soniaamin5 at gmail.com> wrote:
> Sorry Sarah  for my basic question: what does "a column was read as factor"
> mean?

A factor is one of the basic types of data in R, and in statistics
generally, eg M/F or red/white/blue - a predetermined set of
categories that may or may not have an order.

More relevantly, if there's something wrong in your data, a stray
letter or quote mark for instance, that column is no longer numeric,
and R will read it as a factor by default, otherwise as character.

str(data)

which is NOT the same as just typing data, will show you the classes
of your columns, among other things.

> When I type data , I obtain all the numeric values and the headears  I added
> (Consommation,Cylindre,Puissance,Poids)

If you just look at data directly, you'll see what look like numbers,
perhaps, but according to R one or more columns are not actually
numbers. That's why you need str(data).

Your problem looks like a lack of basic understanding of how R works.
Here are a couple of sources that might help you get started:
http://www.burns-stat.com/documents/tutorials/impatient-r/
http://cyclismo.org/tutorial/R/


For more help, you should provide at least the output of str(data) to
the list, and ideally a reproducible example. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

> Thanks
>
>
>
> 2015-04-20 18:40 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
>>
>> What is the problem? One or more of your columns was read as factor, as
>>
>> str(data)
>>
>> would show you. To avoid this, you can add stringsAsFactors=FALSE to
>> the read.table command, but if you expect your data to be entirely
>> numeric then there's something wrong with it that you need to hunt
>> down.
>>
>> Sarah
>>
>> On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com> wrote:
>> > Dear All,
>> >
>> > I have written the following lines:
>> >
>> >
>> > data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
>> > = FALSE, sep = "")
>> >  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
>> >  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
>> > summary(result.model1)
>> >
>> > I obtained the following message:
>> >
>> >
>> > Call:
>> > lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
>> >
>> > Residuals:
>> > Error in quantile.default(resid) : factors are not allowed
>> > In addition: warning message:
>> > In Ops.factor(r, 2) :
>> >   ?^? This is not relevant for factors
>> >
>> >
>> > Where is the problem?
>> > Thank you in advance
>> >
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>
>


From Paul.Domaskis at gmail.com  Mon Apr 20 19:05:54 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 17:05:54 +0000
Subject: [R] Need online version of R help pages
References: <loom.20150416T230116-747@post.gmane.org>
	<5531AD92.6080205@gmail.com>
	<CABSksF92VctZAzq7aDSZcDrcXgpaY+zuUmy9Lp68wL=nG9zY0w@mail.gmail.com>
	<55324DC9.9070006@dewey.myzen.co.uk>
	<loom.20150420T163527-340@post.gmane.org>
	<CAAJSdjh355WMsyhQF6mOCG66BVC+3=1uUtW465Aw4MDc2UJaUQ@mail.gmail.com>
	<loom.20150420T172410-753@post.gmane.org>
	<CAFDcVCQX=H9XnJvXjc1X4ZDjCwe6m_4NUFc1pRMAxJXvXY_F5Q@mail.gmail.com>
Message-ID: <loom.20150420T190243-801@post.gmane.org>

Henrik Bengtsson <henrik.bengtsson <at> ucsf.edu> writes:
> I don't want to rub it in more, but whatever dark forces are upon
> you, they'd have a hard time preventing you from installing R to
> your user account, which requires minimal privileges(*).
> 
> Just wanted to make sure you're aware of your options
> 
> /Henrik
> 
> (*) The R Windows installer detects and adjusts for this
> automatically. The only things I can think of that prevents this
> approach is that the computer is completely disconnected from the
> world,  users have extremely limited disk space, the user account is
> wiped at every login, ... what else?  Also, AFAIK, the only thing
> you miss out on is that R won't be added to the Windows Registry
> meaning .RData files are not associated with R, but that's a very
> low price to pay considered it's a better option than Cygwin.

It's simply not allowed.  However, as I said, this is being worked
out.

It is *very* useful to know that when things work out, it *can* be
installed as non-administrator.  That would be infinitely less
headache.  Thanks.


From Paul.Domaskis at gmail.com  Mon Apr 20 19:20:24 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 17:20:24 +0000
Subject: [R] =?utf-8?b?ImxhZzEucGxvdCB7YXN0c2F9IiB2cy4gImxhZy5wbG90IHtz?=
	=?utf-8?b?dGF0c30i?=
References: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
	<ECD1DD0B-1E3F-4DAD-BFD0-B3F18289BED0@noaa.gov>
Message-ID: <loom.20150420T190712-471@post.gmane.org>

On Apr 17, 2015, at 7:30 PM, Paul Domaskis <paul.domaskis <at>
gmail.com> wrote:
> I'm following http://www.stat.pitt.edu/stoffer/tsa3/R_toot.htm to
> ramp up on both time series and R.  About 40% of the way down, the
> tutorial uses lag1.plot from astsa and lag.plot from stats.  The
> positioning of the dots look different between the two.  Nothing
> jumps out at me from the help pages that explains why they would be
> different.  Can anyone confirm this difference, and hopefully
> suggest explanations?

Roy Mendelssohn - NOAA Federal <roy.mendelssohn <at> noaa.gov> writes:
> Not certain which plot you are looking at, but my guess is the
> answer is contained somewhere here:
> http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm in particular
> perhaps issues 4-5.

Yup, that's it.  What the stats package refers to as lag is
time-advancement.  I assume that this odd definition is due to the
fact that we read from left to right, so a time plot that shifts right
looks like it's racing ahead, even though it is sliding backward along
the time axis.  Heck, it's even infused in the way we refer to
advancing in time, which *often* refers to time progression, i.e.
moving rightward along the time access.

Anyway, the point where this wrinkle occurs in the aforementioned
tutorial is 

   lag.plot(dljj, 9, do.lines=FALSE)  
   lag1.plot(dljj, 9)  # if you have astsa loaded (not shown) 

The following code shows the correction to the use of lag.plot so that
it matches lag1.plot:

   # From tutorial
   lag.plot(dljj, 9, do.lines=FALSE)

   # Correction
   deve.new()
   lag.plot(dljj, set.lags=-1:-9, do.lines=FALSE)

   # astsa's implementation matches above Correctoion
   dev.new()
   lag1.plot(dljj, 9)


From Paul.Domaskis at gmail.com  Mon Apr 20 19:25:45 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 17:25:45 +0000
Subject: [R] =?utf-8?b?ImxhZzEucGxvdCB7YXN0c2F9IiB2cy4gImxhZy5wbG90IHtz?=
	=?utf-8?b?dGF0c30i?=
References: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
	<ECD1DD0B-1E3F-4DAD-BFD0-B3F18289BED0@noaa.gov>
	<loom.20150420T190712-471@post.gmane.org>
Message-ID: <loom.20150420T192526-461@post.gmane.org>

Roy Mendelssohn - NOAA Federal <roy.mendelssohn <at> noaa.gov> writes:
| Not certain which plot you are looking at, but my guess is the
| answer is contained somewhere here:
| http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm in particular
| perhaps issues 4-5.

On Apr 20, 2015, Paul Domaskis <paul.domaskis <at> gmail.com> wrote:
| Yup, that's it.  What the stats package refers to as lag is
| time-advancement.  I assume that this odd definition is due to the
| fact that we read from left to right, so a time plot that shifts
| right looks like it's racing ahead, even though it is sliding
| backward along the time axis.  Heck, it's even infused in the way we
| refer to advancing in time, which *often* refers to time
| progression, i.e.  moving rightward along the time access.
| 
| Anyway, the point where this wrinkle occurs in the aforementioned
| tutorial is 
| 
|    lag.plot(dljj, 9, do.lines=FALSE)  
|    lag1.plot(dljj, 9)  # if you have astsa loaded (not shown) 
| 
| The following code shows the correction to the use of lag.plot so
| that it matches lag1.plot:
| 
|    # From tutorial
|    lag.plot(dljj, 9, do.lines=FALSE)
| 
|    # Correction
|    deve.new()
|    lag.plot(dljj, set.lags=-1:-9, do.lines=FALSE)
| 
|    # astsa's implementation matches above Correctoion
|    dev.new()
|    lag1.plot(dljj, 9)

By the way, the tsa3 issues page that you reference above...it's
indicates the problems with existing time series functions as the
reason for developing corrected functsion in astsa/tsa3.  But the
actual documentation for these corrected functions are extremely
sparse.  Is there another source of documentation that actually
explains the corrections done?


From jrkrideau at inbox.com  Mon Apr 20 19:38:24 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 20 Apr 2015 09:38:24 -0800
Subject: [R] Problem with col
In-Reply-To: <CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>
References: <cam_vjunxeuql8qpsgth4blvzjd4agtjhugnpbx9co3p5rjhpnw@mail.gmail.com>
	<calxf2c3jvs8uafho3d27ryaeu1uuxhzns_dtgxu3qen92ens9a@mail.gmail.com>
Message-ID: <964E17DC324.000008BDjrkrideau@inbox.com>




> -----Original Message-----
> From: soniaamin5 at gmail.com
> Sent: Mon, 20 Apr 2015 18:56:19 +0200
> To: sarah.goslee at gmail.com
> Subject: Re: [R] Problem with col

 --- clip--
> 
> When I type data , I obtain all the numeric values and the headears  I
> added (Consommation,Cylindre,Puissance,Poids)

No you probably do not, as Sarah explained.

As a quick example of the issue look at the two data sets below. Just copy and paste into your R editor.  Both data sets are in dput() format which is how you should supply sample data to R-help.

ddat1  <-   structure(list(aa = structure(1:4, .Label = c("a", "b", "c",
"d"), class = "factor"), bb = 1:4), .Names = c("aa", "bb"), row.names = c(NA,
-4L), class = "data.frame")

ddat2 <- structure(list(aa = c("a", "b", "c", "d"), bb = c("1", "2", "3", "4")), .Names = c("aa", "bb"), row.names = c(NA, -4L), class = "data.frame")

If yo do
dat1
dat2
they look the same on the screen but if you do str()  they are not the same.
str(dat1) 
str(dat2)

Also try 
ddat1$bb * 5  #works
ddat2$bb * 5 # error!


They look the same on the computer screen but they are quite different.

John Kane
Kingston ON Canada



> 
> Thanks
> 
> 
> 
> 2015-04-20 18:40 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
> 
>> What is the problem? One or more of your columns was read as factor, as
>> 
>> str(data)
>> 
>> would show you. To avoid this, you can add stringsAsFactors=FALSE to
>> the read.table command, but if you expect your data to be entirely
>> numeric then there's something wrong with it that you need to hunt
>> down.
>> 
>> Sarah
>> 
>> On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com>
>> wrote:
>>> Dear All,
>>> 
>>> I have written the following lines:
>>> 
>>> 
>> data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
>>> = FALSE, sep = "")
>>>  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
>>>  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
>>> summary(result.model1)
>>> 
>>> I obtained the following message:
>>> 
>>> 
>>> Call:
>>> lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
>>> 
>>> Residuals:
>>> Error in quantile.default(resid) : factors are not allowed
>>> In addition: warning message:
>>> In Ops.factor(r, 2) :
>>>   ?^? This is not relevant for factors
>>> 
>>> 
>>> Where is the problem?
>>> Thank you in advance
>>> 
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From roy.mendelssohn at noaa.gov  Mon Apr 20 19:43:23 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 20 Apr 2015 10:43:23 -0700
Subject: [R] "lag1.plot {astsa}" vs. "lag.plot {stats}"
In-Reply-To: <loom.20150420T192526-461@post.gmane.org>
References: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
	<ECD1DD0B-1E3F-4DAD-BFD0-B3F18289BED0@noaa.gov>
	<loom.20150420T190712-471@post.gmane.org>
	<loom.20150420T192526-461@post.gmane.org>
Message-ID: <4732A5ED-55EB-44BF-96D9-A1309F0AEBDF@noaa.gov>

<snip>
> 
> By the way, the tsa3 issues page that you reference above...it's
> indicates the problems with existing time series functions as the
> reason for developing corrected functsion in astsa/tsa3.  But the
> actual documentation for these corrected functions are extremely
> sparse.  Is there another source of documentation that actually
> explains the corrections done?
> 
> ______________________________________________

I would suggest contacting the author. astsa is an R package on CRAN, but I don?t think the manual discusses the differences.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From soniaamin5 at gmail.com  Mon Apr 20 19:46:02 2015
From: soniaamin5 at gmail.com (Sonia Amin)
Date: Mon, 20 Apr 2015 19:46:02 +0200
Subject: [R] Problem with col
In-Reply-To: <CAM_vjumfa3GDSXs+kdp+evbL=-7iNG3dzYW5pa9d=YiNWJui6A@mail.gmail.com>
References: <CALxf2c3jvS8UAfHO3d27rYaeU1uuxHzNs_Dtgxu3qen92ENS9A@mail.gmail.com>
	<CAM_vjunxEuqL8qPSGTH4BLVZjD4AgTJhUgnPBx9cO3P5rjhpNw@mail.gmail.com>
	<CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>
	<CAM_vjumfa3GDSXs+kdp+evbL=-7iNG3dzYW5pa9d=YiNWJui6A@mail.gmail.com>
Message-ID: <CALxf2c33AnhYnxEmTGMvUH8p2V417PcJ3j6zPcR+9YFGwqNRew@mail.gmail.com>

Thank you very much Sarah

2015-04-20 19:05 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:

> On Mon, Apr 20, 2015 at 12:56 PM, Sonia Amin <soniaamin5 at gmail.com> wrote:
> > Sorry Sarah  for my basic question: what does "a column was read as
> factor"
> > mean?
>
> A factor is one of the basic types of data in R, and in statistics
> generally, eg M/F or red/white/blue - a predetermined set of
> categories that may or may not have an order.
>
> More relevantly, if there's something wrong in your data, a stray
> letter or quote mark for instance, that column is no longer numeric,
> and R will read it as a factor by default, otherwise as character.
>
> str(data)
>
> which is NOT the same as just typing data, will show you the classes
> of your columns, among other things.
>
> > When I type data , I obtain all the numeric values and the headears  I
> added
> > (Consommation,Cylindre,Puissance,Poids)
>
> If you just look at data directly, you'll see what look like numbers,
> perhaps, but according to R one or more columns are not actually
> numbers. That's why you need str(data).
>
> Your problem looks like a lack of basic understanding of how R works.
> Here are a couple of sources that might help you get started:
> http://www.burns-stat.com/documents/tutorials/impatient-r/
> http://cyclismo.org/tutorial/R/
>
>
> For more help, you should provide at least the output of str(data) to
> the list, and ideally a reproducible example. Here are some
> suggestions for creating a good reproducible example:
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Sarah
>
> > Thanks
> >
> >
> >
> > 2015-04-20 18:40 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
> >>
> >> What is the problem? One or more of your columns was read as factor, as
> >>
> >> str(data)
> >>
> >> would show you. To avoid this, you can add stringsAsFactors=FALSE to
> >> the read.table command, but if you expect your data to be entirely
> >> numeric then there's something wrong with it that you need to hunt
> >> down.
> >>
> >> Sarah
> >>
> >> On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com>
> wrote:
> >> > Dear All,
> >> >
> >> > I have written the following lines:
> >> >
> >> >
> >> >
> data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
> >> > = FALSE, sep = "")
> >> >  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
> >> >  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
> >> > summary(result.model1)
> >> >
> >> > I obtained the following message:
> >> >
> >> >
> >> > Call:
> >> > lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
> >> >
> >> > Residuals:
> >> > Error in quantile.default(resid) : factors are not allowed
> >> > In addition: warning message:
> >> > In Ops.factor(r, 2) :
> >> >   ?^? This is not relevant for factors
> >> >
> >> >
> >> > Where is the problem?
> >> > Thank you in advance
> >> >
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >
> >
>

	[[alternative HTML version deleted]]


From soniaamin5 at gmail.com  Mon Apr 20 19:48:02 2015
From: soniaamin5 at gmail.com (Sonia Amin)
Date: Mon, 20 Apr 2015 19:48:02 +0200
Subject: [R] Problem with col
In-Reply-To: <964E17DC324.000008BDjrkrideau@inbox.com>
References: <cam_vjunxeuql8qpsgth4blvzjd4agtjhugnpbx9co3p5rjhpnw@mail.gmail.com>
	<calxf2c3jvs8uafho3d27ryaeu1uuxhzns_dtgxu3qen92ens9a@mail.gmail.com>
	<CALxf2c2+gMV__Frewd_CS8zG4gMGkQ7RtDeaMrtvW10hMUpDfA@mail.gmail.com>
	<964E17DC324.000008BDjrkrideau@inbox.com>
Message-ID: <CALxf2c3vG=6Gs=MA-X86bTggTBGZpYtfyOcXBgE7=-c8W+pO1Q@mail.gmail.com>

Thank you very much John I understand the problem.

2015-04-20 19:38 GMT+02:00 John Kane <jrkrideau at inbox.com>:

>
>
>
> > -----Original Message-----
> > From: soniaamin5 at gmail.com
> > Sent: Mon, 20 Apr 2015 18:56:19 +0200
> > To: sarah.goslee at gmail.com
> > Subject: Re: [R] Problem with col
>
>  --- clip--
> >
> > When I type data , I obtain all the numeric values and the headears  I
> > added (Consommation,Cylindre,Puissance,Poids)
>
> No you probably do not, as Sarah explained.
>
> As a quick example of the issue look at the two data sets below. Just copy
> and paste into your R editor.  Both data sets are in dput() format which is
> how you should supply sample data to R-help.
>
> ddat1  <-   structure(list(aa = structure(1:4, .Label = c("a", "b", "c",
> "d"), class = "factor"), bb = 1:4), .Names = c("aa", "bb"), row.names =
> c(NA,
> -4L), class = "data.frame")
>
> ddat2 <- structure(list(aa = c("a", "b", "c", "d"), bb = c("1", "2", "3",
> "4")), .Names = c("aa", "bb"), row.names = c(NA, -4L), class = "data.frame")
>
> If yo do
> dat1
> dat2
> they look the same on the screen but if you do str()  they are not the
> same.
> str(dat1)
> str(dat2)
>
> Also try
> ddat1$bb * 5  #works
> ddat2$bb * 5 # error!
>
>
> They look the same on the computer screen but they are quite different.
>
> John Kane
> Kingston ON Canada
>
>
>
> >
> > Thanks
> >
> >
> >
> > 2015-04-20 18:40 GMT+02:00 Sarah Goslee <sarah.goslee at gmail.com>:
> >
> >> What is the problem? One or more of your columns was read as factor, as
> >>
> >> str(data)
> >>
> >> would show you. To avoid this, you can add stringsAsFactors=FALSE to
> >> the read.table command, but if you expect your data to be entirely
> >> numeric then there's something wrong with it that you need to hunt
> >> down.
> >>
> >> Sarah
> >>
> >> On Mon, Apr 20, 2015 at 12:33 PM, Sonia Amin <soniaamin5 at gmail.com>
> >> wrote:
> >>> Dear All,
> >>>
> >>> I have written the following lines:
> >>>
> >>>
> >>
> data<-read.table("C:\\Users\\intel\\Documents\\SIIID\\datamultiplereg.txt",header
> >>> = FALSE, sep = "")
> >>>  colnames(data)<-c("Consommation","Cylindre","Puissance","Poids")
> >>>  result.model1<-lm(Consommation~Cylindre+Puissance+Poids, data=data)
> >>> summary(result.model1)
> >>>
> >>> I obtained the following message:
> >>>
> >>>
> >>> Call:
> >>> lm(formula = Consommation ~ Cylindre + Puissance + Poids, data = data)
> >>>
> >>> Residuals:
> >>> Error in quantile.default(resid) : factors are not allowed
> >>> In addition: warning message:
> >>> In Ops.factor(r, 2) :
> >>>   ?^? This is not relevant for factors
> >>>
> >>>
> >>> Where is the problem?
> >>> Thank you in advance
> >>>
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>

	[[alternative HTML version deleted]]


From djmuser at gmail.com  Mon Apr 20 20:27:22 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 20 Apr 2015 11:27:22 -0700
Subject: [R] R code/package for calculation of Wasserstein distance
 between two densities
In-Reply-To: <20150418220626.7dfa9e3976764f8a01a121b2@inbox.com>
References: <20150418220626.7dfa9e3976764f8a01a121b2@inbox.com>
Message-ID: <CADv2QyHx2wRHow4nEZapcRLqR-6mQNJbBjsJkyEfpcTR83t7qQ@mail.gmail.com>

Hi Ranjan:

Try this:

library(sos)
findFn("Wasserstein")

It appears there are three packages that might be relevant:
HistDAWass, transport and TDA.

HTH,
Dennis

On Sat, Apr 18, 2015 at 8:06 PM, Ranjan Maitra
<maitra.mbox.ignored at inbox.com> wrote:
> Dear friends,
>
> Before reinventing the wheel, I was wondering if anyone can point me to code for calculating the Wasserstein distance between two densities. I am particularly interested in mixture densities (in functional form). I know that we have the earthmovers distance in R via the emdist package but it appears to me upon a quick look that this can not handle densities in functional form. So, I was wondering if anyone had any ideas on code for this problem.
>
> Many thanks and best wishes,
> Ranjan
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arnaud.gaboury at gmail.com  Mon Apr 20 20:57:20 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Mon, 20 Apr 2015 20:57:20 +0200
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CAF8bMcb2Gjdewc28CVhNQQrxV3txrQXhEAb3r=7MYV1gxkrMLw@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
	<CAF8bMcb2Gjdewc28CVhNQQrxV3txrQXhEAb3r=7MYV1gxkrMLw@mail.gmail.com>
Message-ID: <CAK1hC9uZyvmAS1yseyoVYOOsssu81kAEGyxX1uf-RyOu2Z70kw@mail.gmail.com>

On Mon, Apr 20, 2015 at 6:09 PM, William Dunlap <wdunlap at tibco.com> wrote:

> The hyphen without a following digit confuses tidyr::extract_numeric().
> E.g.,
>    > extract_numeric("23 ft-lbs")
>    Warning message:
>    In extract_numeric("23 ft-lbs") : NAs introduced by coercion
>    [1] NA
>    > extract_numeric("23 ft*lbs")
>    [1] 23
>

See[0] for the reason on the minus in the regex. It is not a bug but a wish.
I am honestly very surprised the maintainer decided to go with such a so
simple solution for negative numbers.

[0]https://github.com/hadley/tidyr/issues/20

Contact the BugReports address for the package
>    > packageDescription("tidyr")$BugReports
>    [1] "https://github.com/hadley/tidyr/issues"
> or package's maintainer
>    > maintainer("tidyr")
>    [1] "Hadley Wickham <hadley at rstudio.com>"
> to report problems in a user-contributed package.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Apr 20, 2015 at 12:10 AM, arnaud gaboury <arnaud.gaboury at gmail.com
> > wrote:
>
>> R 3.2.0 on Linux
>> --------------------------------
>>
>> library(tidyr)
>>
>> playerStats <- c("LVL 10", "5,671,448 AP l6,000,000 AP", "Unique
>> Portals Visited 1,038",
>> "XM Collected 15,327,123 XM", "Hacks 14,268", "Resonators Deployed
>> 11,126",
>> "Links Created 1,744", "Control Fields Created 294", "Mind Units
>> Captured 2,995,484 MUs",
>> "Longest Link Ever Created 75 km", "Largest Control Field 189,731 MUs",
>> "XM Recharged 3,006,364 XM", "Portals Captured 1,204", "Unique Portals
>> Captured 486",
>> "Resonators Destroyed 12,481", "Portals Neutralized 1,240", "Enemy
>> Links Destroyed 3,169",
>> "Enemy Control Fields Destroyed 1,394", "Distance Walked 230 km",
>> "Max Time Portal Held 240 days", "Max Time Link Maintained 15 days",
>> "Max Link Length x Days 276 km-days", "Max Time Field Held 4days",
>> "Largest Field MUs x Days 83,226 MU-days")
>>
>>
>> -----------------------------------------------------------------------------------------------
>>  extract_numeric(playerStats)
>>  [1]             10 56714486000000           1038       15327123
>>    14268          11126           1744            294        2995484
>> [10]             75         189731        3006364           1204
>>      486          12481           1240           3169           1394
>> [19]            230            240             15             NA
>>        4             NA
>>
>>
>> ------------------------------------------------------------------------------------------------
>>  playerStats[c(22,24)]
>> [1] "Max Link Length x Days 276 km-days"      "Largest Field MUs x
>> Days 83,226 MU-days"
>>
>> --------------------------------------------------------------------------------------------
>>
>> I do not understand why these two vectors return NA when the function
>> extract_numeric() works well for others,
>>
>> Any wrong settings in my env?
>>
>> Thank you for hints.
>>
>>
>>
>> --
>>
>> google.com/+arnaudgabourygabx
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 

google.com/+arnaudgabourygabx
<https://plus.google.com/_/notifications/emlink?emr=05814804238976922326&emid=CKiv-v6PvboCFcfoQgod6msAAA&path=%2F116159236040461325607%2Fop%2Fu&dt=1383086841306&ub=50>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Apr 20 21:10:44 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Apr 2015 14:10:44 -0500
Subject: [R] misbehavior with extract_numeric() from tidyr
In-Reply-To: <CAK1hC9uZyvmAS1yseyoVYOOsssu81kAEGyxX1uf-RyOu2Z70kw@mail.gmail.com>
References: <CAK1hC9sYO_0PZTUvtcPBzapaGcazjmLrL951U-o1rb0zoZK5hw@mail.gmail.com>
	<CAF8bMcb2Gjdewc28CVhNQQrxV3txrQXhEAb3r=7MYV1gxkrMLw@mail.gmail.com>
	<CAK1hC9uZyvmAS1yseyoVYOOsssu81kAEGyxX1uf-RyOu2Z70kw@mail.gmail.com>
Message-ID: <CABdHhvEvmCT7LxRkhDm2gKrCpwEOJeWEhpSHUrXEnVGvc2Cc-Q@mail.gmail.com>

On Mon, Apr 20, 2015 at 1:57 PM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> On Mon, Apr 20, 2015 at 6:09 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> The hyphen without a following digit confuses tidyr::extract_numeric().
>> E.g.,
>>    > extract_numeric("23 ft-lbs")
>>    Warning message:
>>    In extract_numeric("23 ft-lbs") : NAs introduced by coercion
>>    [1] NA
>>    > extract_numeric("23 ft*lbs")
>>    [1] 23
>>
>
> See[0] for the reason on the minus in the regex. It is not a bug but a wish.
> I am honestly very surprised the maintainer decided to go with such a so
> simple solution for negative numbers.
>
> [0]https://github.com/hadley/tidyr/issues/20

Any heuristic is going to fail in some circumstances. If you want to
be sure it's doing what you want for your use case, write the regular
expression yourself.

Hadley

-- 
http://had.co.nz/


From nino.jordan.13 at ucl.ac.uk  Mon Apr 20 17:15:39 2015
From: nino.jordan.13 at ucl.ac.uk (Nino David Jordan)
Date: Mon, 20 Apr 2015 08:15:39 -0700 (PDT)
Subject: [R] problem with CSV and R
In-Reply-To: <CALDs+F=5HGX=gSL20Qf58-5KmHhBeY2v96DZ1BQ0nuaqx5bUsA@mail.gmail.com>
References: <CALDs+F=5HGX=gSL20Qf58-5KmHhBeY2v96DZ1BQ0nuaqx5bUsA@mail.gmail.com>
Message-ID: <1429542939225-4706148.post@n4.nabble.com>

I get the same error message when I try to edit a data frame on the basis of
a .csv file.



--
View this message in context: http://r.789695.n4.nabble.com/problem-with-CSV-and-R-tp4680979p4706148.html
Sent from the R help mailing list archive at Nabble.com.


From ismaelhakki54 at hotmail.com  Mon Apr 20 19:19:40 2015
From: ismaelhakki54 at hotmail.com (=?windows-1254?B?aXNtYWlsIGhha2v9IHNvbmFsY2Fu?=)
Date: Mon, 20 Apr 2015 20:19:40 +0300
Subject: [R] feature selection
Message-ID: <DUB128-W54117F8BAA4AC883768B4EB1E00@phx.gbl>

Hi,

I want to make feature selection.
Could you help me.

Thanks.
 		 	   		  

From Paul.Domaskis at gmail.com  Mon Apr 20 20:45:17 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 18:45:17 +0000
Subject: [R] (no subject)
References: <CABSksF9FBpo+XsaueyOKi_qq0s+3_ZFmkZOtpHUxJDWM+Pqqzw@mail.gmail.com>
	<ECD1DD0B-1E3F-4DAD-BFD0-B3F18289BED0@noaa.gov>
	<loom.20150420T190712-471@post.gmane.org>
	<loom.20150420T192526-461@post.gmane.org>
	<4732A5ED-55EB-44BF-96D9-A1309F0AEBDF@noaa.gov>
Message-ID: <loom.20150420T204402-479@post.gmane.org>

Roy Mendelssohn - NOAA Federal <roy.mendelssohn <at> noaa.gov> writes:
|> By the way, the tsa3 issues page that you reference above...it's
|> indicates the problems with existing time series functions as the
|> reason for developing corrected functsion in astsa/tsa3.  But the
|> actual documentation for these corrected functions are extremely
|> sparse.  Is there another source of documentation that actually
|> explains the corrections done?
|
| I would suggest contacting the author. astsa is an R package on
| CRAN, but I don?t think the manual discusses the differences.

Will do.  Thanks.

From cdetermanjr at gmail.com  Mon Apr 20 21:37:15 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 20 Apr 2015 14:37:15 -0500
Subject: [R] feature selection
In-Reply-To: <DUB128-W54117F8BAA4AC883768B4EB1E00@phx.gbl>
References: <DUB128-W54117F8BAA4AC883768B4EB1E00@phx.gbl>
Message-ID: <CAKxd1KPgFOk9Yk7JZFcSgrj_Nf45FVhUJBz53Qv71R9amESQvQ@mail.gmail.com>

Although I am sure many here would be happy to help you your question is
far too vague.  There are many methods for feature selection.  You should
review the literature and see what would work best for you or consult a
statistician.  Once you have selected a method and began an initial attempt
at the R code then this list will be far more helpful to you.  This help
list is meant to help people with their R programming not design their
analysis for them.

Some places to start with R include the very popular 'caret' package.  Max
Kuhn (the author) has a wonderful website with many tutorials.  Here is the
front page for feature selection,
http://topepo.github.io/caret/featureselection.html

I also have developed a package on Bioconductor called 'OmicsMarkeR' which
you can find at
http://bioconductor.org/packages/release/bioc/html/OmicsMarkeR.html that
you may find useful depending upon the data you possess.

Regards,
Charles

On Mon, Apr 20, 2015 at 12:19 PM, ismail hakk? sonalcan <
ismaelhakki54 at hotmail.com> wrote:

> Hi,
>
> I want to make feature selection.
> Could you help me.
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wibbeltjec at hotmail.com  Mon Apr 20 22:05:11 2015
From: wibbeltjec at hotmail.com (Carlijn Wibbelink)
Date: Mon, 20 Apr 2015 22:05:11 +0200
Subject: [R] Metafor - rma.mv function - variance components
Message-ID: <DUB122-W12696F41D3AF95CE489B13C0E00@phx.gbl>

Hi all,

I have a question about metafor and the rma.mv function. I have fitted a multivariate model (effect sizes are nested within studies) and I've found two variances: 

Variance Components: 
                      estim    sqrt     nlvls  fixed  factor
sigma^2.1  0.0257  0.1602     72     no       y
sigma^2.2  0.0694  0.2635     10     no      ID 

I want to test whether there is significant variantion between the effect sizes within studies (sigma^2.1: 0.0257) and/or between studies (sigma^2.2: 0.0694). In metaSEM you can fix for example the variance within studies (sigma^2.1) to zero to test whether there is a significant difference in fit between the models (and if so, then there is significant heterogeneity between the effect sizes within studies). I was wondering if this is also possible in metafor. If I fix sigma2 to zero, then both variances are fixed to zero. However, I want to fix only one variance to zero. 
I hope that someone can help me. Thank you in advance!
 		 	   		  
	[[alternative HTML version deleted]]


From Lists at dewey.myzen.co.uk  Mon Apr 20 22:24:48 2015
From: Lists at dewey.myzen.co.uk (Lists at dewey.myzen.co.uk)
Date: Mon, 20 Apr 2015 20:24:48 +0000
Subject: [R] Metafor - rma.mv function - variance components
Message-ID: <Zen-1YkIFM-0003HD-UI@smarthost01d.mail.zen.net.uk>

Carlijn Wibbelink <wibbeltjec at hotmail.com> wrote :

Dear Carlijn
I think that if you set sigma2 to a vector of length 2 it will be possible.

> Hi all,
> 
> I have a question about metafor and the rma.mv function. I have fitted a
> multivariate model (effect sizes are nested within studies) and I've found two
> variances: 
> 
> Variance Components: 
>                       estim    sqrt     nlvls  fixed  factor
> sigma^2.1  0.0257  0.1602     72     no       y
> sigma^2.2  0.0694  0.2635     10     no      ID 
> 
> I want to test whether there is significant variantion between the effect sizes
> within studies (sigma^2.1: 0.0257) and/or between studies (sigma^2.2: 0.0694).
> In metaSEM you can fix for example the variance within studies (sigma^2.1) to
> zero to test whether there is a significant difference in fit between the models
> (and if so, then there is significant heterogeneity between the effect sizes
> within studies). I was wondering if this is also possible in metafor. If I fix
> sigma2 to zero, then both variances are fixed to zero. However, I want to fix
> only one variance to zero. 
> I hope that someone can help me. Thank you in advance!
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Paul.Domaskis at gmail.com  Tue Apr 21 01:04:45 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Mon, 20 Apr 2015 23:04:45 +0000
Subject: [R] How numerical data is stored inside ts time series objects
Message-ID: <loom.20150421T010112-378@post.gmane.org>

I'm getting familiar with the stl function in the stats packcage by
trying it on an example from Brockwell & Davis's 2002 "Introduction to
Times Series and Forcasting".  Specifically, I'm using a subset of his
red wine sales data.  It's a detour from the stl material at
http://www.stat.pitt.edu/stoffer/tsa3/R_toot.htm (at some point, I
have to stop simply following and try to make it work with new data).

I need a minimum of 36 wine sales data points in the series, since stl
otherwise complains about the data being less than 2 cycles.  The data
is in ~/tmp/wine.txt:

    464
    675
    703
    887
    1139
    1077
    1318
    1260
    1120
    963
    996
    960
    530
    883
    894
    1045
    1199
    1287
    1565
    1577
    1076
    918
    1008
    1063
    544
    635
    804
    980
    1018
    1064
    1404
    1286
    1104
    999
    996
    1015

My sourced test code is buried in a repeat loop so that I can use a
break command to circumvent the final error-causing statement that I'm
trying to figure out:

    repeat{

        # Clear variables (from stackexchange)
        rm( list=setdiff( ls( all.names=TRUE ), lsf.str(all.names=TRUE ) ) )
        ls()

        head( wine <- read.table("~/tmp/wine.txt") )
        ( x <- ts(wine[[1]],frequency=12) )
        ( y <- ts(wine,frequency=12) )
        ( a=stl(x,"per") )
        #break
        ( b=stl(y,"per") )
    }

The final statement causes the error 'Error in stl(y, "per") : only
univariate series are allowed'.  I found an explanation at
http://stackoverflow.com/questions/10492155/time-series-and-stl-in-r-error-
only-univariate-series-are-allowed.
That's how I came up with the assignment to x using wine[[1]].  I
found an explanation to the need for
double square brackets at
http://www.r-tutor.com/r-introduction/list/named-list-members.

My problem is that it's not very clear what is happening inside the ts
structures x and y.  If I simply print them, they look 100% identical:

    | > x
    |    Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
    | 1  464  675  703  887 1139 1077 1318 1260 1120  963  996  960
    | 2  530  883  894 1045 1199 1287 1565 1577 1076  918 1008 1063
    | 3  544  635  804  980 1018 1064 1404 1286 1104  999  996 1015
    | > y
    |    Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
    | 1  464  675  703  887 1139 1077 1318 1260 1120  963  996  960
    | 2  530  883  894 1045 1199 1287 1565 1577 1076  918 1008 1063
    | 3  544  635  804  980 1018 1064 1404 1286 1104  999  996 1015

Whatever their differences, it's not causing R to misinterpret the
data; that is, they each look like in single series of numerical data.

Can anyone illuminate the difference in the data inside the ts data
structures?  The potential incompatibility with stl is just one
symptom.  Right now, the "solution" is black magic to me, and I would
like to get a clearer picture so that I know when else (and how) to
watch out for this.

I've posted this to the R Help mailing list
http://news.gmane.org/gmane.comp.lang.r.general and to stackoverflow
at
http://stackoverflow.com/questions/29759928/how-numerical-data-is-stored-
inside-ts-time-series-objects.


From dulcalma at bigpond.com  Tue Apr 21 01:35:14 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 21 Apr 2015 09:35:14 +1000
Subject: [R] high density plots using lattice dotplot()
In-Reply-To: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>
References: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>
Message-ID: <000001d07bc2$a73b7d30$f5b27790$@bigpond.com>

Hi Luigi

Strips take up space so if you are willing to not have strip and put the
strip values within the plot area then

      xyplot(y ~ x|cond.factor, data = ...,
             as.table = T,
             groups   = ...,
             layout   = ...,
             drop.unused = T,
             par.settings = list(axis.text = list(cex = 0.6),
                                 par.xlab.text = list(cex = 0.75),
                                 par.ylab.text = list(cex = 0.75)
                                 superpose.symbol = list(pch = ".", cex = 2)
                            ),
             strip    = FALSE,
             scales   = list(x = list(alternating = 2),
                             y = list(alternating = FALSE)
                             ),
             type = "p",
             panel = function(x,y, subscripts, groups,...){
                                panel.superpose(x,y,subscripts,groups,...,
col = ...)
                                panel.text(x,y,...,cex = 0.6)
                            }
      )

if the text values are a vector
      stext = ...
      xyplot(y ~ x|cond.factor, data = ...,
             as.table = T,
             groups   = ...,
             layout   = ...,
             drop.unused = T,
             par.settings = list(axis.text = list(cex = 0.6),
                                 par.xlab.text = list(cex = 0.75),
                                 par.ylab.text = list(cex = 0.75)
                                 superpose.symbol = list(pch = ".", cex = 2)
                            ),
             strip    = FALSE,
             scales   = list(x = list(alternating = 2),
                             y = list(alternating = FALSE)
                             ),
             type = "p",
             panel = function(x,y, subscripts, groups,...){
                               pnl = panel.number()
                                panel.superpose(x,y,subscripts,groups,...,
col = ...)
                                panel.text(x,y,stext[pnl],cex = 0.6)
                            }
      )

you could also you group.number instead of pnl if it is needed elsewhere.
text position could be done in a similar fashion if needed to be in
different places for some panels.

If you require the strip then an additional par.settings is
layout.heights = list(strip = 0.8)
or even untested in this situation
strip = FALSE
strip.left  = TRUE

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Sunday, 19 April 2015 19:28
To: r-help
Subject: [R] high density plots using lattice dotplot()

Dear all,
I am trying to plot the results of a PCR experiments that involves 384
individual plots. Admittedly the space for the plots will be tiny, but
I just nedd some icon to have a feeling of the layout of the
experiment and a quick comparison of the plots.
I believe that lattice would be the right tool, but when I tried to
implement i got an error. Specifically the output would be a A4 pdf,
so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
each plot; removing the labels that might just work.
So I have the y values = 'fluorescence', x 'values' = cycles and 384
'well' data. I implemented to begin with:

xyplot(fluorescence ~ cycles | well,
         ylab="Fluorescence",
         xlab="Cycles",
         main=list(draw = FALSE),
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         layout = c(24,16),
         par.settings = list(strip.background=list(col="white")),
         pch = "."
  )

but the  the individual graphs show only the writing "data" instead of
the actual plots.
How can I overcome this error?
Thank you
Best regards
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Apr 21 02:00:09 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 20 Apr 2015 17:00:09 -0700
Subject: [R] How numerical data is stored inside ts time series objects
In-Reply-To: <loom.20150421T010112-378@post.gmane.org>
References: <loom.20150421T010112-378@post.gmane.org>
Message-ID: <CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>

Use the str() function to see the internal structure of most objects.  In
your case it would show something like:

> Data <- data.frame(theData=round(sin(1:38),1))
> x <- ts(Data[[1]], frequency=12) # or Data[,1]
> y <- ts(Data, frequency=12)
> str(x)
 Time-Series [1:38] from 1 to 4.08: 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -0.5
...
> str(y)
 ts [1:38, 1] 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -0.5 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr "theData"
 - attr(*, "tsp")= num [1:3] 1 4.08 12

'x' contains a vector of data and 'y' contains a 1-column matrix of data.
stl(x,"per") and stl(y, "per") give similar results as you got.

Evidently, stl() does not know that 1-column matrices can be treated much
the same as vectors and gives an error message.  Thus you must extract
the one column into a vector: stl(y[,1], "per").




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Apr 20, 2015 at 4:04 PM, Paul <Paul.Domaskis at gmail.com> wrote:

> I'm getting familiar with the stl function in the stats packcage by
> trying it on an example from Brockwell & Davis's 2002 "Introduction to
> Times Series and Forcasting".  Specifically, I'm using a subset of his
> red wine sales data.  It's a detour from the stl material at
> http://www.stat.pitt.edu/stoffer/tsa3/R_toot.htm (at some point, I
> have to stop simply following and try to make it work with new data).
>
> I need a minimum of 36 wine sales data points in the series, since stl
> otherwise complains about the data being less than 2 cycles.  The data
> is in ~/tmp/wine.txt:
>
>     464
>     675
>     703
>     887
>     1139
>     1077
>     1318
>     1260
>     1120
>     963
>     996
>     960
>     530
>     883
>     894
>     1045
>     1199
>     1287
>     1565
>     1577
>     1076
>     918
>     1008
>     1063
>     544
>     635
>     804
>     980
>     1018
>     1064
>     1404
>     1286
>     1104
>     999
>     996
>     1015
>
> My sourced test code is buried in a repeat loop so that I can use a
> break command to circumvent the final error-causing statement that I'm
> trying to figure out:
>
>     repeat{
>
>         # Clear variables (from stackexchange)
>         rm( list=setdiff( ls( all.names=TRUE ), lsf.str(all.names=TRUE ) )
> )
>         ls()
>
>         head( wine <- read.table("~/tmp/wine.txt") )
>         ( x <- ts(wine[[1]],frequency=12) )
>         ( y <- ts(wine,frequency=12) )
>         ( a=stl(x,"per") )
>         #break
>         ( b=stl(y,"per") )
>     }
>
> The final statement causes the error 'Error in stl(y, "per") : only
> univariate series are allowed'.  I found an explanation at
> http://stackoverflow.com/questions/10492155/time-series-and-stl-in-r-error-
> only-univariate-series-are-allowed.
> That's how I came up with the assignment to x using wine[[1]].  I
> found an explanation to the need for
> double square brackets at
> http://www.r-tutor.com/r-introduction/list/named-list-members.
>
> My problem is that it's not very clear what is happening inside the ts
> structures x and y.  If I simply print them, they look 100% identical:
>
>     | > x
>     |    Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
>     | 1  464  675  703  887 1139 1077 1318 1260 1120  963  996  960
>     | 2  530  883  894 1045 1199 1287 1565 1577 1076  918 1008 1063
>     | 3  544  635  804  980 1018 1064 1404 1286 1104  999  996 1015
>     | > y
>     |    Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
>     | 1  464  675  703  887 1139 1077 1318 1260 1120  963  996  960
>     | 2  530  883  894 1045 1199 1287 1565 1577 1076  918 1008 1063
>     | 3  544  635  804  980 1018 1064 1404 1286 1104  999  996 1015
>
> Whatever their differences, it's not causing R to misinterpret the
> data; that is, they each look like in single series of numerical data.
>
> Can anyone illuminate the difference in the data inside the ts data
> structures?  The potential incompatibility with stl is just one
> symptom.  Right now, the "solution" is black magic to me, and I would
> like to get a clearer picture so that I know when else (and how) to
> watch out for this.
>
> I've posted this to the R Help mailing list
> http://news.gmane.org/gmane.comp.lang.r.general and to stackoverflow
> at
> http://stackoverflow.com/questions/29759928/how-numerical-data-is-stored-
> inside-ts-time-series-objects.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Apr 21 02:21:18 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 21 Apr 2015 12:21:18 +1200
Subject: [R] feature selection
In-Reply-To: <DUB128-W54117F8BAA4AC883768B4EB1E00@phx.gbl>
References: <DUB128-W54117F8BAA4AC883768B4EB1E00@phx.gbl>
Message-ID: <553597FE.8090200@auckland.ac.nz>

On 21/04/15 05:19, ismail hakk? sonalcan wrote:
> Hi,
>
> I want to make feature selection.
> Could you help me.
>
> Thanks.

This posting should win some sort of prize for inanity.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From alaios at yahoo.com  Tue Apr 21 09:50:26 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 21 Apr 2015 07:50:26 +0000 (UTC)
Subject: [R] Multinomial Fitting Distrbution
Message-ID: <1091470601.1036823.1429602626805.JavaMail.yahoo@mail.yahoo.com>

Dear all,I am trying to fit a heavy tailed distribution and I have tried working with the mix function of the mixdist package.It looks like that this package allows fitting two distributions (or move) of the same family? and not combining different distributions (so mixing a geometric with a normal and so on).
After trying with the mix tool all the different combinations have failed. (I am not know if images are allowed here as attachments and thus I am sharing a link with the uploaded image )
http://alexpal.smugmug.com/photos/i-N76qWsM/0/O/i-N76qWsM.jpg
You can see that the three different families of distribution failed to capture correct the heavy tail at the end.
Can you please sugest me which functions (package) I could try in R for combining two different distributions for a fit?
I would like to thank you for your reply


| ? |
| ? |  | ? | ? | ? | ? | ? |
|  |
|  |
| View on alexpal.smugmug.com | Preview by Yahoo |
|  |
| ? |



	[[alternative HTML version deleted]]


From wibbeltjec at hotmail.com  Tue Apr 21 10:42:53 2015
From: wibbeltjec at hotmail.com (Carlijn Wibbelink)
Date: Tue, 21 Apr 2015 10:42:53 +0200
Subject: [R] Metafor - rma.mv function - variance components
In-Reply-To: <Zen-1YkIFM-0003HD-UI@smarthost01d.mail.zen.net.uk>
References: <Zen-1YkIFM-0003HD-UI@smarthost01d.mail.zen.net.uk>
Message-ID: <DUB122-W279FF33ADA868121E17D0DC0EF0@phx.gbl>

Thank you for your reaction, it worked.
However, I'm wondering if this is the right way to test whether there is significant variation on one of the two levels. The results of the anova tests do not correspond to the results of the Z-test in metaSEM. (In metaSEM only one of the variances is significant, but when I use the anova test in metafor, both variances are significant). But maybe I made a mistake. This is my syntax:
model2 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), data=dat)
model3 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(NA,0), data=dat)
model4 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(0,NA), data=dat)
anova(model2,model3)
anova(model2,model4)

Is it possible to receive the standard errors of the variances in metafor (and do a Z-test)?


> To: wibbeltjec at hotmail.com; r-help at r-project.org
> Subject: Re: [R] Metafor - rma.mv function - variance components
> From: Lists at dewey.myzen.co.uk
> Date: Mon, 20 Apr 2015 20:24:48 +0000
> 
> Carlijn Wibbelink <wibbeltjec at hotmail.com> wrote :
> 
> Dear Carlijn
> I think that if you set sigma2 to a vector of length 2 it will be possible.
> 
> > Hi all,
> > 
> > I have a question about metafor and the rma.mv function. I have fitted a
> > multivariate model (effect sizes are nested within studies) and I've found two
> > variances: 
> > 
> > Variance Components: 
> >                       estim    sqrt     nlvls  fixed  factor
> > sigma^2.1  0.0257  0.1602     72     no       y
> > sigma^2.2  0.0694  0.2635     10     no      ID 
> > 
> > I want to test whether there is significant variantion between the effect sizes
> > within studies (sigma^2.1: 0.0257) and/or between studies (sigma^2.2: 0.0694).
> > In metaSEM you can fix for example the variance within studies (sigma^2.1) to
> > zero to test whether there is a significant difference in fit between the models
> > (and if so, then there is significant heterogeneity between the effect sizes
> > within studies). I was wondering if this is also possible in metafor. If I fix
> > sigma2 to zero, then both variances are fixed to zero. However, I want to fix
> > only one variance to zero. 
> > I hope that someone can help me. Thank you in advance!
> >  		 	   		  
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org
> > mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
 		 	   		  
	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Apr 21 12:25:42 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 21 Apr 2015 12:25:42 +0200
Subject: [R] Metafor - rma.mv function - variance components
In-Reply-To: <DUB122-W279FF33ADA868121E17D0DC0EF0@phx.gbl>
References: <Zen-1YkIFM-0003HD-UI@smarthost01d.mail.zen.net.uk>
	<DUB122-W279FF33ADA868121E17D0DC0EF0@phx.gbl>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0BB07BC4@UM-MAIL4112.unimaas.nl>

This is correct (for getting likelihood ratio tests). Manually setting a component to 0 is also the same as just leaving out the corresponding random effect. So, you could also do:

model2 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), data=dat)
model3 <- rma.mv(y, v, random = ~ 1 | y, data=dat)
model4 <- rma.mv(y, v, random = ~ 1 | ID, data=dat)
anova(model2,model3)
anova(model2,model4)

That should give you identical results.

At the moment, rma.mv() does not compute SEs for the variance components. It may at some point in the future, but it is unclear what one would do with those SEs. Wald-type tests (z-tests) should generally be avoided when testing variance components.

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Neuropsychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Carlijn
> Wibbelink
> Sent: Tuesday, April 21, 2015 10:43
> To: Lists at dewey.myzen.co.uk; r-help at r-project.org
> Subject: Re: [R] Metafor - rma.mv function - variance components
> 
> Thank you for your reaction, it worked.
> However, I'm wondering if this is the right way to test whether there is
> significant variation on one of the two levels. The results of the anova
> tests do not correspond to the results of the Z-test in metaSEM. (In
> metaSEM only one of the variances is significant, but when I use the
> anova test in metafor, both variances are significant). But maybe I made
> a mistake. This is my syntax:
> model2 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), data=dat)
> model3 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(NA,0),
> data=dat)
> model4 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(0,NA),
> data=dat)
> anova(model2,model3)
> anova(model2,model4)
> 
> Is it possible to receive the standard errors of the variances in metafor
> (and do a Z-test)?
> 
> > To: wibbeltjec at hotmail.com; r-help at r-project.org
> > Subject: Re: [R] Metafor - rma.mv function - variance components
> > From: Lists at dewey.myzen.co.uk
> > Date: Mon, 20 Apr 2015 20:24:48 +0000
> >
> > Carlijn Wibbelink <wibbeltjec at hotmail.com> wrote :
> >
> > Dear Carlijn
> > I think that if you set sigma2 to a vector of length 2 it will be
> possible.
> >
> > > Hi all,
> > >
> > > I have a question about metafor and the rma.mv function. I have
> fitted a
> > > multivariate model (effect sizes are nested within studies) and I've
> found two
> > > variances:
> > >
> > > Variance Components:
> > >                       estim    sqrt     nlvls  fixed  factor
> > > sigma^2.1  0.0257  0.1602     72     no       y
> > > sigma^2.2  0.0694  0.2635     10     no      ID
> > >
> > > I want to test whether there is significant variantion between the
> effect sizes
> > > within studies (sigma^2.1: 0.0257) and/or between studies (sigma^2.2:
> 0.0694).
> > > In metaSEM you can fix for example the variance within studies
> (sigma^2.1) to
> > > zero to test whether there is a significant difference in fit between
> the models
> > > (and if so, then there is significant heterogeneity between the
> effect sizes
> > > within studies). I was wondering if this is also possible in metafor.
> If I fix
> > > sigma2 to zero, then both variances are fixed to zero. However, I
> want to fix
> > > only one variance to zero.
> > > I hope that someone can help me. Thank you in advance!
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org
> > > mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Tue Apr 21 14:32:52 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 21 Apr 2015 07:32:52 -0500
Subject: [R] Predict in glmnet for Cox family
In-Reply-To: <mailman.1.1429610401.30052.r-help@r-project.org>
References: <mailman.1.1429610401.30052.r-help@r-project.org>
Message-ID: <2f3a88$fud6n@ironport10.mayo.edu>



On 04/21/2015 05:00 AM, r-help-request at r-project.org wrote:
> Dear All,
>
> I am in some difficulty with predicting 'expected time of survival' for each
> observation for a glmnet cox family with LASSO.
>
> I have two dataset 50000 * 450 (obs * Var) and 8000 * 450 (obs * var), I
> considered first one as train and second one as test.
>
> I got the predict output and I am bit lost here,
>
> pre <- predict(fit,type="response", newx =selectedVar[1:20,])
>
>           s0
> 1  0.9454985
> 2  0.6684135
> 3  0.5941740
> 4  0.5241938
> 5  0.5376783
>
> This is the output I am getting - I understood with type "response" gives
> the fitted relative-risk for "cox" family.
>
> I would like to know how I can convert it or change the fitted relative-risk
> to 'expected time of survival' ?
>
> Any help would be great, thanks for all your time and effort.
>
> Sincerely,

The answer is that you cannot predict survival time, in general.  The reason is that most 
studies do not follow the subjects for a sufficiently long time.  For instance, say that 
the data set comes from a study that enrolled subjects and then followed them for up to 5 
years, at which time 35% had experienced mortality (using the usual Kaplan-Meier).  Fit a 
model to the data and ask "what is the predicted survival time for a low risk subject". 
The answer will at best be "greater than 5 years".   The program cannot say if it is 6 or 
10 or even 1000.  A bigger data set does not help.

Terry Therneau


From lists at dewey.myzen.co.uk  Tue Apr 21 14:43:44 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 21 Apr 2015 13:43:44 +0100
Subject: [R] Metafor - rma.mv function - variance components
In-Reply-To: <DUB122-W279FF33ADA868121E17D0DC0EF0@phx.gbl>
References: <Zen-1YkIFM-0003HD-UI@smarthost01d.mail.zen.net.uk>
	<DUB122-W279FF33ADA868121E17D0DC0EF0@phx.gbl>
Message-ID: <55364600.5080002@dewey.myzen.co.uk>

Dear Carlijn

You might shed some light on what is going on by using
profile.rma.mv

Michael

On 21/04/2015 09:42, Carlijn Wibbelink wrote:
> Thank you for your reaction, it worked.
> However, I'm wondering if this is the right way to test whether there is
> significant variation on one of the two levels. The results of the anova
> tests do not correspond to the results of the Z-test in metaSEM. (In
> metaSEM only one of the variances is significant, but when I use the
> anova test in metafor, both variances are significant). But maybe I made
> a mistake. This is my syntax:
> model2 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), data=dat)
> model3 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(NA,0),
> data=dat)
> model4 <- rma.mv(y, v, random = list(~ 1 | y, ~ 1 | ID), sigma2=c(0,NA),
> data=dat)
> anova(model2,model3)
> anova(model2,model4)
>
> Is it possible to receive the standard errors of the variances in
> metafor (and do a Z-test)?
>
>
>  > To: wibbeltjec at hotmail.com; r-help at r-project.org
>  > Subject: Re: [R] Metafor - rma.mv function - variance components
>  > From: Lists at dewey.myzen.co.uk
>  > Date: Mon, 20 Apr 2015 20:24:48 +0000
>  >
>  > Carlijn Wibbelink <wibbeltjec at hotmail.com> wrote :
>  >
>  > Dear Carlijn
>  > I think that if you set sigma2 to a vector of length 2 it will be
> possible.
>  >
>  > > Hi all,
>  > >
>  > > I have a question about metafor and the rma.mv function. I have
> fitted a
>  > > multivariate model (effect sizes are nested within studies) and
> I've found two
>  > > variances:
>  > >
>  > > Variance Components:
>  > > estim sqrt nlvls fixed factor
>  > > sigma^2.1 0.0257 0.1602 72 no y
>  > > sigma^2.2 0.0694 0.2635 10 no ID
>  > >
>  > > I want to test whether there is significant variantion between the
> effect sizes
>  > > within studies (sigma^2.1: 0.0257) and/or between studies
> (sigma^2.2: 0.0694).
>  > > In metaSEM you can fix for example the variance within studies
> (sigma^2.1) to
>  > > zero to test whether there is a significant difference in fit
> between the models
>  > > (and if so, then there is significant heterogeneity between the
> effect sizes
>  > > within studies). I was wondering if this is also possible in
> metafor. If I fix
>  > > sigma2 to zero, then both variances are fixed to zero. However, I
> want to fix
>  > > only one variance to zero.
>  > > I hope that someone can help me. Thank you in advance!
>  > >
>  > > [[alternative HTML version deleted]]
>  > >
>  > > ______________________________________________
>  > > R-help at r-project.org
>  > > mailing list -- To UNSUBSCRIBE and more, see
>  > > https://stat.ethz.ch/mailman/listinfo/r-help
>  > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>  > > and provide commented, minimal, self-contained, reproducible code.
>  >
>  >
>  >
>  >
>  >

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From darcy.m.trimpe at wmich.edu  Mon Apr 20 22:50:19 2015
From: darcy.m.trimpe at wmich.edu (Darcy Trimpe)
Date: Mon, 20 Apr 2015 13:50:19 -0700 (PDT)
Subject: [R] Two Factorial Experiment with a Single Control Group
In-Reply-To: <1429556981749-4706176.post@n4.nabble.com>
References: <1429546901645-4706153.post@n4.nabble.com>
	<1429556981749-4706176.post@n4.nabble.com>
Message-ID: <1208548894.29970785.1429563831720.JavaMail.root@wmich.edu>

The statistical analysis I want to conduct is a 2x2 factorial analysis with a single control group. There are 3 animals per group.The low n is accepted in my area of research. My factors are Treatment (No Treatment and Treatment) and Duration (Acute and 3 weeks). The No Treatment level represents an internal control. There is a treatment and no treatment value from each animal. My external control group does not fit into the factor treatment/no treatment but is actually no treatment/no treatment. Thus, the need for the single external control group in the analysis. I have found the manual way of doing this in a textbook and I am told it is widely used so I was hoping to find a way to do it in R. Please let me know if you have any further questions. 


Thanks in advance for your assistance. 


Darcy 

----- Original Message -----


From: "c06n [via R]" <ml-node+s789695n4706176h62 at n4.nabble.com> 
To: "Darcy Trimpe" <darcy.m.trimpe at wmich.edu> 
Sent: Monday, April 20, 2015 3:09:41 PM 
Subject: Re: Two Factorial Experiment with a Single Control Group 

Hi, 

you will have to provide more information. 

* What is the statistical analysis you want to conduct? 
* What exactly are your factors? What are the factors composed of? 
* What do you mean by "single" control group? 




If you reply to this email, your message will be added to the discussion below: http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706176.html 
To unsubscribe from Two Factorial Experiment with a Single Control Group, click here . 
NAML 






--
View this message in context: http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706181.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From darcy.m.trimpe at wmich.edu  Tue Apr 21 12:49:43 2015
From: darcy.m.trimpe at wmich.edu (Darcy Trimpe)
Date: Tue, 21 Apr 2015 03:49:43 -0700 (PDT)
Subject: [R] Two Factorial Experiment with a Single Control Group
In-Reply-To: <1429594588482-4706187.post@n4.nabble.com>
References: <1429546901645-4706153.post@n4.nabble.com>
	<1429556981749-4706176.post@n4.nabble.com>
	<1208548894.29970785.1429563831720.JavaMail.root@wmich.edu>
	<1429594588482-4706187.post@n4.nabble.com>
Message-ID: <808429842.30079683.1429614212947.JavaMail.root@wmich.edu>

Good Morning, 

I am not asking for a method by how to implement, if possible, the method in R. I am pretty confident of my statistical approach, I do not want to do it by hand :-). Although, I do have the formulas to do it by hand. The groups are measured once. The animal is treated short or long term unilaterally and not at all on the contralateral side. Each animal provides a no tx and tx value taken at the same end point. The external controls have had neither side treated. I have included a sample data table below: 

	Treatment 
	Duration 	No Tx 	TX 
	acute 	7 	9 
	acute 	5 	8 
	acute 	4 	7 
	3 weeks 	21 	23 
	3 weeks 	28 	27 
	3 weeks 	26 	29 
			
		No Tx 	No Tx 
	Control 	3 	2 
	Control 	4 	5 
	Control 	7 	9 

Thanks for your continued help. 
----- Original Message -----

> From: "c06n [via R]" <ml-node+s789695n4706187h3 at n4.nabble.com>
> To: "Darcy Trimpe" <darcy.m.trimpe at wmich.edu>
> Sent: Tuesday, April 21, 2015 1:36:28 AM
> Subject: Re: Two Factorial Experiment with a Single Control Group

> Hi,

> I'm not 100% sure I understand your approach. Right now it sounds
> more of a methods question than a R question.

> Here's what I understood so far:
> 1. you have 3 groups: no treatment at all, acute treatment, treatment
> over 3 weeks.
> 2. you measure those 3 groups: initially, after 3 weeks.

> That sounds to me that you have only 1 factor with 3 levels, and
> measure your dependent variable twice. This would yield a typical
> one factorial within-design.

> But I somehow feel that is not really your design. Can you provide an
> example table for the factor combinations with example data (can be
> made up)?

> If you reply to this email, your message will be added to the
> discussion below:
> http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706187.html
> To unsubscribe from Two Factorial Experiment with a Single Control
> Group, click here .
> NAML




--
View this message in context: http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706194.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From ranjanmano167 at gmail.com  Tue Apr 21 16:50:23 2015
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Tue, 21 Apr 2015 15:50:23 +0100
Subject: [R] R_Calculating Thiessen weights for an area with irregular
	boundary
Message-ID: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>

Hi R users,

I want to calculate Thiessen weights to compute areal rainfall from number
of point measurements. I am using R and thanks to some previous question in
the same topic, I got to know that I can usedeldir. But the problem is my
boundary polygon is not a rectangle; it's an irregular polygon (it's a
catchment boundary derived using ArcGIS). But in deldir the boundary can
only be a rectangle. Are there any other packages where I can calculate
Thiessen weights of an area covered by an irregular boundary?

Given below are my measurement points (meas_points) and coordinates of a
(simplified) boundary polygon(boundary)

> meas_points
          X      Y[1,] 415720 432795[2,] 415513 432834[3,] 415325
432740[4,] 415356 432847[5,] 415374 432858[6,] 415426 432774[7,]
415395 432811[8,] 415626 432762
> boundary
          x      y[1,] 415491 432947[2,] 415269 432919[3,] 415211
432776[4,] 415247 432657[5,] 415533 432657[6,] 415781 432677[7,]
415795 432836[8,] 415746 432937

Any help is really appreciated. Thanks.

cheers,

Mano

	[[alternative HTML version deleted]]


From yelin at lbl.gov  Tue Apr 21 19:01:17 2015
From: yelin at lbl.gov (Ye Lin)
Date: Tue, 21 Apr 2015 10:01:17 -0700
Subject: [R] cannot find package colbycol in R 3.2.0
Message-ID: <CAAvu=bmjh5OhGWoYKaeg8fSuUgz0Tac+gV52stTT3aNcrSUzUA@mail.gmail.com>

Hi All, after installing the new version of R (3.2.0), I cannot find
package "colbycol", is there anyway to use it with the new version?

I want to use function cbc.read.table, which is in package "colbycol". If
this package is no longer available in the new version, is there anyway
around it?

Thanks!

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Apr 21 19:20:22 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 21 Apr 2015 12:20:22 -0500
Subject: [R] cannot find package colbycol in R 3.2.0
In-Reply-To: <CAAvu=bmjh5OhGWoYKaeg8fSuUgz0Tac+gV52stTT3aNcrSUzUA@mail.gmail.com>
References: <CAAvu=bmjh5OhGWoYKaeg8fSuUgz0Tac+gV52stTT3aNcrSUzUA@mail.gmail.com>
Message-ID: <ABA5D930-DCE3-407F-83CA-B3CBADF10D17@me.com>


> On Apr 21, 2015, at 12:01 PM, Ye Lin <yelin at lbl.gov> wrote:
> 
> Hi All, after installing the new version of R (3.2.0), I cannot find
> package "colbycol", is there anyway to use it with the new version?
> 
> I want to use function cbc.read.table, which is in package "colbycol". If
> this package is no longer available in the new version, is there anyway
> around it?
> 
> Thanks!


It would appear that the package was archived last year due to a failure to abide by CRAN policies with respect to Java sources:

  http://cran.r-project.org/web/packages/colbycol/index.html

There are older versions of the package source tarballs in the linked archive that may or may not work. It looks like the package has not been updated in over a year, so there may be associated issues and you may be better off contacting the package maintainer (http://colbycol.r-forge.r-project.org) to see where they stand on package updates. 

Presumably the CRAN maintainers have already attempted that without success or without a commitment to keep the package compliant with CRAN policies, hence the archiving.

You might want to look at the HPC CRAN task view to see if there are any alternatives that would work for you:

  http://cran.r-project.org/web/views/HighPerformanceComputing.html

Regards,

Marc Schwartz


From yelin at lbl.gov  Tue Apr 21 19:21:53 2015
From: yelin at lbl.gov (Ye Lin)
Date: Tue, 21 Apr 2015 10:21:53 -0700
Subject: [R] cannot find package colbycol in R 3.2.0
In-Reply-To: <ABA5D930-DCE3-407F-83CA-B3CBADF10D17@me.com>
References: <CAAvu=bmjh5OhGWoYKaeg8fSuUgz0Tac+gV52stTT3aNcrSUzUA@mail.gmail.com>
	<ABA5D930-DCE3-407F-83CA-B3CBADF10D17@me.com>
Message-ID: <CAAvu=bn-yb42esgm4=Ph4ByrOdrsWUXU_7EXJQsSfBCMDoMBPg@mail.gmail.com>

Thanks! The package still cannot be installed and I've found an alternative
way which is using package "limma"

On Tue, Apr 21, 2015 at 10:20 AM, Marc Schwartz <marc_schwartz at me.com>
wrote:

>
> > On Apr 21, 2015, at 12:01 PM, Ye Lin <yelin at lbl.gov> wrote:
> >
> > Hi All, after installing the new version of R (3.2.0), I cannot find
> > package "colbycol", is there anyway to use it with the new version?
> >
> > I want to use function cbc.read.table, which is in package "colbycol". If
> > this package is no longer available in the new version, is there anyway
> > around it?
> >
> > Thanks!
>
>
> It would appear that the package was archived last year due to a failure
> to abide by CRAN policies with respect to Java sources:
>
>   http://cran.r-project.org/web/packages/colbycol/index.html
>
> There are older versions of the package source tarballs in the linked
> archive that may or may not work. It looks like the package has not been
> updated in over a year, so there may be associated issues and you may be
> better off contacting the package maintainer (
> http://colbycol.r-forge.r-project.org) to see where they stand on package
> updates.
>
> Presumably the CRAN maintainers have already attempted that without
> success or without a commitment to keep the package compliant with CRAN
> policies, hence the archiving.
>
> You might want to look at the HPC CRAN task view to see if there are any
> alternatives that would work for you:
>
>   http://cran.r-project.org/web/views/HighPerformanceComputing.html
>
> Regards,
>
> Marc Schwartz
>
>
>


-- 
Ye Lin
Sr. Research Associate
Energy Efficiency Standards Group
Lawrence Berkeley National Laboratory

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*****This is intended for the addressee only and may contain confidential
business information. It may not be copied without LBNL permission. If you
are not the intended recipient, please contact the sender as soon as
possible and delete the material from any computer.*****

	[[alternative HTML version deleted]]


From lucianolasala at yahoo.com.ar  Tue Apr 21 20:05:28 2015
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Tue, 21 Apr 2015 15:05:28 -0300
Subject: [R] Question on funcion and npar
In-Reply-To: <alpine.DEB.2.00.1002111656090.10326@paninaro.stat-math.wu-wien.ac.at>
References: <DA00B3605BF64094961E2BD9A1224392@Negro1>
	<alpine.DEB.2.00.1002111656090.10326@paninaro.stat-math.wu-wien.ac.at>
Message-ID: <55369168.3020302@yahoo.com.ar>

Dear everyone,

The following function, taken from Quick-R, gets measures of central 
tendency and spread for a numeric vector x.

I can't figure out what the argument npar means in each instance.
Any tips will be most appreciated.

mysummary <- function(x, npar=TRUE, print=TRUE) {
   if (!npar) {
     center <- mean(x); spread <- sd(x)
   } else {
     center <- median(x); spread <- mad(x)
   }
   if (print & !npar) {
     cat("Mean=", center, "\n", "SD=", spread, "\n")
   } else if (print & npar) {
     cat("Median=", center, "\n", "MAD=", spread, "\n")
   }
   result <- list(center=center,spread=spread)
   return(result)
}


-- 
Luciano F. La Sala
Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
C?tedra de Epidemiolog?a
Departamento de Biolog?a, Bioqu?mica y Farmacia
Universidad Nacional del Sur
San Juan 670
Bah?a Blanca (8000)
Argentina


From marc_schwartz at me.com  Tue Apr 21 20:13:13 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 21 Apr 2015 13:13:13 -0500
Subject: [R] Question on funcion and npar
In-Reply-To: <55369168.3020302@yahoo.com.ar>
References: <DA00B3605BF64094961E2BD9A1224392@Negro1>
	<alpine.DEB.2.00.1002111656090.10326@paninaro.stat-math.wu-wien.ac.at>
	<55369168.3020302@yahoo.com.ar>
Message-ID: <5D81B808-7B75-4688-8B57-2F43579B2458@me.com>


> On Apr 21, 2015, at 1:05 PM, Luciano La Sala <lucianolasala at yahoo.com.ar> wrote:
> 
> Dear everyone,
> 
> The following function, taken from Quick-R, gets measures of central tendency and spread for a numeric vector x.
> 
> I can't figure out what the argument npar means in each instance.
> Any tips will be most appreciated.
> 
> mysummary <- function(x, npar=TRUE, print=TRUE) {
>  if (!npar) {
>    center <- mean(x); spread <- sd(x)
>  } else {
>    center <- median(x); spread <- mad(x)
>  }
>  if (print & !npar) {
>    cat("Mean=", center, "\n", "SD=", spread, "\n")
>  } else if (print & npar) {
>    cat("Median=", center, "\n", "MAD=", spread, "\n")
>  }
>  result <- list(center=center,spread=spread)
>  return(result)
> }
> 


Presumably ?nonparametric?, since median()/mad() is used in lieu of mean()/sd(), if npar = TRUE.

Regards,

Marc Schwartz


From gunter.berton at gene.com  Tue Apr 21 20:17:35 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 21 Apr 2015 11:17:35 -0700
Subject: [R] Question on funcion and npar
In-Reply-To: <55369168.3020302@yahoo.com.ar>
References: <DA00B3605BF64094961E2BD9A1224392@Negro1>
	<alpine.DEB.2.00.1002111656090.10326@paninaro.stat-math.wu-wien.ac.at>
	<55369168.3020302@yahoo.com.ar>
Message-ID: <CACk-te3HBL4au19taD0puaaknAh+kEaLyKeiMR785JS7bXkLdg@mail.gmail.com>

Have you gone thruway any T tutorials yet? This is a very basic question
that I do not believe would arise if you had done so.

The answer is that it is a logical that controls whether means and sd's or
medians and mads are calculated and returned. But I don't think this answer
will be comprehensible if you asked the question in the first place. Some
minimum effort must be made to learn the language details to understand
even simple function code.

Cheers,
Bert

On Tuesday, April 21, 2015, Luciano La Sala <lucianolasala at yahoo.com.ar>
wrote:

> Dear everyone,
>
> The following function, taken from Quick-R, gets measures of central
> tendency and spread for a numeric vector x.
>
> I can't figure out what the argument npar means in each instance.
> Any tips will be most appreciated.
>
> mysummary <- function(x, npar=TRUE, print=TRUE) {
>   if (!npar) {
>     center <- mean(x); spread <- sd(x)
>   } else {
>     center <- median(x); spread <- mad(x)
>   }
>   if (print & !npar) {
>     cat("Mean=", center, "\n", "SD=", spread, "\n")
>   } else if (print & npar) {
>     cat("Median=", center, "\n", "MAD=", spread, "\n")
>   }
>   result <- list(center=center,spread=spread)
>   return(result)
> }
>
>
> --
> Luciano F. La Sala
> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
> C?tedra de Epidemiolog?a
> Departamento de Biolog?a, Bioqu?mica y Farmacia
> Universidad Nacional del Sur
> San Juan 670
> Bah?a Blanca (8000)
> Argentina
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From michael.grant at colorado.edu  Tue Apr 21 21:38:16 2015
From: michael.grant at colorado.edu (Michael Grant)
Date: Tue, 21 Apr 2015 13:38:16 -0600
Subject: [R] Exhaustive CHAID package
Message-ID: <52BD8206AE274C449268B7D6AC44D0740154F2C68BCA@EXC4.ad.colorado.edu>

Dear R-Help:

>From multiple sources comparing methods of tree classification and tree regressions on various data sets, it seems that Exhaustive CHAID (distinct from CHAID), most commonly generates the most useful tree results and, in particular, is more effective than ctree or rpart which are implemented in R.  I see that CHAID, but not Exhaustive CHAID, is in the R-forge, and I write to ask if there are plans to create a package which employs the Exhaustive CHAID strategy.  Right now the best source I can find is in SPSS-IBM and I feel a bit disloyal to R using it.

Michael Grant
Professor
University of Colorado Boulder

	[[alternative HTML version deleted]]


From kpmainali at gmail.com  Tue Apr 21 22:34:47 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Tue, 21 Apr 2015 16:34:47 -0400
Subject: [R] Phi coefficient matrix (package psych)
Message-ID: <CABK368i4w4fv1BQu=eetMN94OA-r=VK7a=UPQ1F7te6o1JBU3A@mail.gmail.com>

I want to calculate phi coefficient for every pair of the columns. Is there
a way to generate a matrix like a correlation matrix? I know cor function
in the case below gives same answer as phi coefficient.

?x <- sample(c(0,1), 10, replace=TRUE)
y <- sample(c(0,1), 10, replace=TRUE)
z <- sample(c(0,1), 10, replace=TRUE)
df <- data.frame(x,y,z)
cor(df)
library(psych)
phi(df)?

Thank you,
Kumar Mainali
Postdoctoral Associate
Department of Biology
University of Maryland
?

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr 21 23:31:33 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 22 Apr 2015 07:31:33 +1000
Subject: [R] Phi coefficient matrix (package psych)
In-Reply-To: <CABK368i4w4fv1BQu=eetMN94OA-r=VK7a=UPQ1F7te6o1JBU3A@mail.gmail.com>
References: <CABK368i4w4fv1BQu=eetMN94OA-r=VK7a=UPQ1F7te6o1JBU3A@mail.gmail.com>
Message-ID: <CA+8X3fWWM0tbAVjm4MBd7KHcOg4LN_qzpJSyeHC7KbBFZRDEwg@mail.gmail.com>

HI Kumar,
A simple way is:

phimat<-function(x) {
 xcol<-dim(x)[2]
 newx<-matrix(NA,nrow=xcol,ncol=xcol)
 for(i in 1:xcol) {
  for(j in 1:xcol) newx[i,j]<-phi(table(x[,i],x[,j]))
 }
 rownames(newx)<-colnames(newx)<-colnames(x)
 return(newx)
}
phimat(df)

Jim


On Wed, Apr 22, 2015 at 6:34 AM, Kumar Mainali <kpmainali at gmail.com> wrote:
> I want to calculate phi coefficient for every pair of the columns. Is there
> a way to generate a matrix like a correlation matrix? I know cor function
> in the case below gives same answer as phi coefficient.
>
> x <- sample(c(0,1), 10, replace=TRUE)
> y <- sample(c(0,1), 10, replace=TRUE)
> z <- sample(c(0,1), 10, replace=TRUE)
> df <- data.frame(x,y,z)
> cor(df)
> library(psych)
> phi(df)
>
> Thank you,
> Kumar Mainali
> Postdoctoral Associate
> Department of Biology
> University of Maryland
> ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Apr 22 00:33:18 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Apr 2015 10:33:18 +1200
Subject: [R] R_Calculating Thiessen weights for an area with irregular
 boundary
In-Reply-To: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>
References: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>
Message-ID: <5536D02E.4070001@auckland.ac.nz>


(1) The manner in which you presented your data was a total mess.
If you ask for help, please have the courtesy to present your data in 
such a manner that a potential "helper" can access it without needing to 
do a great deal of editing and processing.  Like so:

pts <- as.data.frame(matrix(c(415720,432795,415513,432834,415325,
                               432740,415356,432847,415374,432858,
                               415426,432774,415395,432811,415626,
                               432762),ncol=2,byrow=TRUE))
names(pts) <- c("x","y")

bdry <- as.data.frame(matrix(c(415491,432947,415269,432919,415211,
                                432776,415247,432657,415533,432657,
                                415781,432677,415795,432836,415746,
                                432937),ncol=2,byrow=TRUE))
names(bdry) <- c("x","y")

(2) Well, at least you presented a usable data set (even though the 
presentation was lousy) which is better than what most posters do.  And 
you asked a "partially" clear question.

(3) I do not know what you mean by "Thiessen weights".  I am guessing 
that these are the areas of the Dirichlet tiles (Thiessen polygons), 
intersected with the "boundary polygon" (i.e. observation window).

(4) If my guess is correct, the following should accomplish the desired 
task:

require(spatstat) # You will (probably) need to install spatstat first.
W <- owin(poly=bdry)
X <- as.ppp(pts,W=W)
plot(X) # Just to make sure it looks right.
dX <- dirichlet(X)
plot(dX) # Just to make sure .....
sapply(tiles(dX),area.owin)

HTH

cheers,

Rolf Turner


On 22/04/15 02:50, Manoranjan Muthusamy wrote:

> Hi R users,
>
> I want to calculate Thiessen weights to compute areal rainfall from number
> of point measurements. I am using R and thanks to some previous question in
> the same topic, I got to know that I can usedeldir. But the problem is my
> boundary polygon is not a rectangle; it's an irregular polygon (it's a
> catchment boundary derived using ArcGIS). But in deldir the boundary can
> only be a rectangle. Are there any other packages where I can calculate
> Thiessen weights of an area covered by an irregular boundary?
>
> Given below are my measurement points (meas_points) and coordinates of a
> (simplified) boundary polygon(boundary)
>
>> meas_points
>            X      Y[1,] 415720 432795[2,] 415513 432834[3,] 415325
> 432740[4,] 415356 432847[5,] 415374 432858[6,] 415426 432774[7,]
> 415395 432811[8,] 415626 432762
>> boundary
>            x      y[1,] 415491 432947[2,] 415269 432919[3,] 415211
> 432776[4,] 415247 432657[5,] 415533 432657[6,] 415781 432677[7,]
> 415795 432836[8,] 415746 432937
>
> Any help is really appreciated. Thanks.


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From hadley at rstudio.com  Wed Apr 22 01:05:30 2015
From: hadley at rstudio.com (Hadley Wickham)
Date: Tue, 21 Apr 2015 18:05:30 -0500
Subject: [R] Rtools 3.3 is not compatible with R 3.2.0.?
In-Reply-To: <1690232006.1604951.1429657301961.JavaMail.yahoo@mail.yahoo.com>
References: <1690232006.1604951.1429657301961.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CABdHhvEywjrYrdUO0pPW_RwmCBgHODUg69LGfjxX1U+U1-0RZw@mail.gmail.com>

It's been fixed in the dev version, and I'm planning on submitting to
CRAN in the near future.
Hadley

On Tue, Apr 21, 2015 at 6:01 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
> hi list,
>
> Any updates on this issue?  Thank you very much!
>
> Tao
>
>
>> devtools::install_github("rstudio/packrat")
> WARNING: Rtools 3.3 found on the path at c:/Rtools is not compatible with R 3.2.0.
>
> Please download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools().
> Downloading github repo rstudio/packrat at master
> Installing packrat
> "C:/PROGRA~1/R/R-32~1.0/bin/x64/R" --vanilla CMD INSTALL  \
> "C:/Users/tshi/AppData/Local/Temp/Rtmp6VYlhX/devtools25dc273e706c/rstudio-packrat-42b76ad" --library="C:/Program Files/R/R-3.2.0/library"  \
> --install-tests
>
> * installing *source* package 'packrat' ...
> ** R
> ** inst
> ** tests
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (packrat)
>
>> find_rtools()
> WARNING: Rtools 3.3 found on the path at c:/Rtools is not compatible with R 3.2.0.
>
> Please download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools().
>
>> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] devtools_1.7.0   packrat_0.4.3-19
>
> loaded via a namespace (and not attached):
> [1] httr_0.6.1     tools_3.2.0    RCurl_1.95-4.5 stringr_0.6.2  bitops_1.0-6



-- 
http://had.co.nz/


From kpmainali at gmail.com  Wed Apr 22 02:21:45 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Tue, 21 Apr 2015 20:21:45 -0400
Subject: [R] Phi coefficient matrix (package psych)
In-Reply-To: <CA+8X3fWWM0tbAVjm4MBd7KHcOg4LN_qzpJSyeHC7KbBFZRDEwg@mail.gmail.com>
References: <CABK368i4w4fv1BQu=eetMN94OA-r=VK7a=UPQ1F7te6o1JBU3A@mail.gmail.com>
	<CA+8X3fWWM0tbAVjm4MBd7KHcOg4LN_qzpJSyeHC7KbBFZRDEwg@mail.gmail.com>
Message-ID: <CABK368h0e_RDHS9r14oT9LXjWK_xsM4iCtdpE_ufEmzryY=tuw@mail.gmail.com>

Hi Jim,

That solves my problem. Than you.

-- Kumar
?

Postdoctoral Associate
Fagan Lab, Department of Biology
University of Maryland

On Tue, Apr 21, 2015 at 5:31 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> HI Kumar,
> A simple way is:
>
> phimat<-function(x) {
>  xcol<-dim(x)[2]
>  newx<-matrix(NA,nrow=xcol,ncol=xcol)
>  for(i in 1:xcol) {
>   for(j in 1:xcol) newx[i,j]<-phi(table(x[,i],x[,j]))
>  }
>  rownames(newx)<-colnames(newx)<-colnames(x)
>  return(newx)
> }
> phimat(df)
>
> Jim
>
>
> On Wed, Apr 22, 2015 at 6:34 AM, Kumar Mainali <kpmainali at gmail.com>
> wrote:
> > I want to calculate phi coefficient for every pair of the columns. Is
> there
> > a way to generate a matrix like a correlation matrix? I know cor function
> > in the case below gives same answer as phi coefficient.
> >
> > x <- sample(c(0,1), 10, replace=TRUE)
> > y <- sample(c(0,1), 10, replace=TRUE)
> > z <- sample(c(0,1), 10, replace=TRUE)
> > df <- data.frame(x,y,z)
> > cor(df)
> > library(psych)
> > phi(df)
> >
> > Thank you,
> > Kumar Mainali
> > Postdoctoral Associate
> > Department of Biology
> > University of Maryland
> > ?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Wed Apr 22 02:27:26 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 22 Apr 2015 10:27:26 +1000
Subject: [R] high density plots using lattice dotplot()
In-Reply-To: <CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>
References: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>	<000001d07bc2$a73b7d30$f5b27790$@bigpond.com>
	<CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>
Message-ID: <000301d07c93$1c60b140$552213c0$@bigpond.com>

Hi Luigi

The layout.heights is in the wrong place try

         par.settings = list(
           strip.background=list(col="white"),
           axis.text = list(cex = 0.6),
           par.xlab.text = list(cex = 0.75),
           par.ylab.text = list(cex = 0.75),
           superpose.symbol = list(pch = ".", cex = 2),
           layout.widths(main = 0.9,sub = 0), # see below 
           layout.heights = list(strip = 0.8)
         ),
Space is important so every 0.05 you can get away with is vital.
see 
names(trellis.par.get())
trellis.par.get()$layout.widths 
for more that may be changed and the same for layout.heights, it is amazing what small changes will create extra panel space

I modified a script that I did a few years ago so there may have been some changes 
For the panel function if the following
 
        panel = function(x,y, subscripts, groups,...){
           panel.superpose(x,y,subscripts,groups,...,
                           col = ...)
           panel.text(x,y,...,cex = 0.6)
         }

does not work you will have to use panel.groups

eg untested (it?s a while since I have used this)

panel = panel.superpose,
panel.groups = function(x,y,...){
panel.xyplot(x,y,yourtext, cex = 0.6) # I meant with the... to put in a suitable object/code

})

Duncan



-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Wednesday, 22 April 2015 08:24
To: Duncan Mackay
Subject: Re: [R] high density plots using lattice dotplot()

Dear Duncan,
thank you for your reply. I tried to implement your suggestions but as
is on your reply did not work (actually R crashed) and a slight
elaboration returned the figure attached, which is essentially still
displaying text and not drawing the data. Here is what I wrote:

xyplot(Delta.Rn ~ Cycle | Well,
         data = PLATE,
         ylab="Fluorescence (Delta Rn)",
         xlab="Cycles",
         main=TITLE,
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         as.table = TRUE,
         layout = c(24,16),
         par.settings = list(
           strip.background=list(col="white"),
           axis.text = list(cex = 0.6),
           par.xlab.text = list(cex = 0.75),
           par.ylab.text = list(cex = 0.75),
           superpose.symbol = list(pch = ".", cex = 2)
         ),
         strip    = FALSE,
         type = "p",
         layout.heights = list(strip = 0.8),
         panel = function(x,y, subscripts, groups,...){
           panel.superpose(x,y,subscripts,groups,...,
                           col = ...)
           panel.text(x,y,...,cex = 0.6)
         }
  )


How can I improve the script?
Many thanks
Luigi

On Tue, Apr 21, 2015 at 12:35 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Strips take up space so if you are willing to not have strip and put the
> strip values within the plot area then
>
>       xyplot(y ~ x|cond.factor, data = ...,
>              as.table = T,
>              groups   = ...,
>              layout   = ...,
>              drop.unused = T,
>              par.settings = list(axis.text = list(cex = 0.6),
>                                  par.xlab.text = list(cex = 0.75),
>                                  par.ylab.text = list(cex = 0.75)
>                                  superpose.symbol = list(pch = ".", cex = 2)
>                             ),
>              strip    = FALSE,
>              scales   = list(x = list(alternating = 2),
>                              y = list(alternating = FALSE)
>                              ),
>              type = "p",
>              panel = function(x,y, subscripts, groups,...){
>                                 panel.superpose(x,y,subscripts,groups,...,
> col = ...)
>                                 panel.text(x,y,...,cex = 0.6)
>                             }
>       )
>
> if the text values are a vector
>       stext = ...
>       xyplot(y ~ x|cond.factor, data = ...,
>              as.table = T,
>              groups   = ...,
>              layout   = ...,
>              drop.unused = T,
>              par.settings = list(axis.text = list(cex = 0.6),
>                                  par.xlab.text = list(cex = 0.75),
>                                  par.ylab.text = list(cex = 0.75)
>                                  superpose.symbol = list(pch = ".", cex = 2)
>                             ),
>              strip    = FALSE,
>              scales   = list(x = list(alternating = 2),
>                              y = list(alternating = FALSE)
>                              ),
>              type = "p",
>              panel = function(x,y, subscripts, groups,...){
>                                pnl = panel.number()
>                                 panel.superpose(x,y,subscripts,groups,...,
> col = ...)
>                                 panel.text(x,y,stext[pnl],cex = 0.6)
>                             }
>       )
>
> you could also you group.number instead of pnl if it is needed elsewhere.
> text position could be done in a similar fashion if needed to be in
> different places for some panels.
>
> If you require the strip then an additional par.settings is
> layout.heights = list(strip = 0.8)
> or even untested in this situation
> strip = FALSE
> strip.left  = TRUE
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Sunday, 19 April 2015 19:28
> To: r-help
> Subject: [R] high density plots using lattice dotplot()
>
> Dear all,
> I am trying to plot the results of a PCR experiments that involves 384
> individual plots. Admittedly the space for the plots will be tiny, but
> I just nedd some icon to have a feeling of the layout of the
> experiment and a quick comparison of the plots.
> I believe that lattice would be the right tool, but when I tried to
> implement i got an error. Specifically the output would be a A4 pdf,
> so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
> each plot; removing the labels that might just work.
> So I have the y values = 'fluorescence', x 'values' = cycles and 384
> 'well' data. I implemented to begin with:
>
> xyplot(fluorescence ~ cycles | well,
>          ylab="Fluorescence",
>          xlab="Cycles",
>          main=list(draw = FALSE),
>          scales = list(
>            x = list(draw = FALSE),
>            y = list(draw = FALSE),
>            relation="same",
>            alternating=TRUE),
>          layout = c(24,16),
>          par.settings = list(strip.background=list(col="white")),
>          pch = "."
>   )
>
> but the  the individual graphs show only the writing "data" instead of
> the actual plots.
> How can I overcome this error?
> Thank you
> Best regards
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Paul.Domaskis at gmail.com  Wed Apr 22 03:39:16 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Wed, 22 Apr 2015 01:39:16 +0000
Subject: [R] How numerical data is stored inside ts time series objects
References: <loom.20150421T010112-378@post.gmane.org>
	<CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>
Message-ID: <loom.20150422T032037-943@post.gmane.org>

William Dunlap <wdunlap <at> tibco.com> writes:
> Use the str() function to see the internal structure of most
> objects.  In your case it would show something like:
>
> > Data <- data.frame(theData=round(sin(1:38),1))
> > x <- ts(Data[[1]], frequency=12) # or Data[,1]
> > y <- ts(Data, frequency=12)
> > str(x)
>  Time-Series [1:38] from 1 to 4.08: 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -
0.5
> ...
> > str(y)
>  ts [1:38, 1] 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -0.5 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : NULL
>   ..$ : chr "theData"
>  - attr(*, "tsp")= num [1:3] 1 4.08 12
>
> 'x' contains a vector of data and 'y' contains a 1-column matrix of
> data.  stl(x,"per") and stl(y, "per") give similar results as you
> got.
>
> Evidently, stl() does not know that 1-column matrices can be treated
> much the same as vectors and gives an error message.  Thus you must
> extract the one column into a vector: stl(y[,1], "per").

Thanks, William.

Interesting that a 2D matrix of size Nx1 is treated as a different
animal from a length N vector.  It's a departure from math convention,
and from what I'm accustomed to in Matlab.  that R's vector seems
more akin to a list, where the notion of orientation doesn't apply.

I rummaged around the help files for str, summary, dput, args.  This
seems like a more complicated language than Matlab, VBA, or even C++'s
STL of old (which was pretty thoroughly documented).  A function like
str() returns an object description, and I'm guessing the conventions
with which the object is described depends a lot on the person who
wrote the handling code for the class.  The description for the
variable y seems particularly elaborate.

Would I be right in assuming that the notation is ad-hoc and not
documented?  For example, the two invocations str(x) and str(y) show a
Time-Series and a ts.  And there are many lines of output for str(y)
that is heavy in punctuation.


From wdunlap at tibco.com  Wed Apr 22 04:16:10 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Apr 2015 19:16:10 -0700
Subject: [R] How numerical data is stored inside ts time series objects
In-Reply-To: <loom.20150422T032037-943@post.gmane.org>
References: <loom.20150421T010112-378@post.gmane.org>
	<CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>
	<loom.20150422T032037-943@post.gmane.org>
Message-ID: <CAF8bMcb0pwbjCs6Tb7CJjNVQpHJPa_fXBvPzDbF9bdWSEUWf_A@mail.gmail.com>

> Interesting that a 2D matrix of size Nx1 is treated as a different
> animal from a length N vector.

I think we can call this a bug in stl().

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 21, 2015 at 6:39 PM, Paul <Paul.Domaskis at gmail.com> wrote:

> William Dunlap <wdunlap <at> tibco.com> writes:
> > Use the str() function to see the internal structure of most
> > objects.  In your case it would show something like:
> >
> > > Data <- data.frame(theData=round(sin(1:38),1))
> > > x <- ts(Data[[1]], frequency=12) # or Data[,1]
> > > y <- ts(Data, frequency=12)
> > > str(x)
> >  Time-Series [1:38] from 1 to 4.08: 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -
> 0.5
> > ...
> > > str(y)
> >  ts [1:38, 1] 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -0.5 ...
> >  - attr(*, "dimnames")=List of 2
> >   ..$ : NULL
> >   ..$ : chr "theData"
> >  - attr(*, "tsp")= num [1:3] 1 4.08 12
> >
> > 'x' contains a vector of data and 'y' contains a 1-column matrix of
> > data.  stl(x,"per") and stl(y, "per") give similar results as you
> > got.
> >
> > Evidently, stl() does not know that 1-column matrices can be treated
> > much the same as vectors and gives an error message.  Thus you must
> > extract the one column into a vector: stl(y[,1], "per").
>
> Thanks, William.
>
> Interesting that a 2D matrix of size Nx1 is treated as a different
> animal from a length N vector.  It's a departure from math convention,
> and from what I'm accustomed to in Matlab.  that R's vector seems
> more akin to a list, where the notion of orientation doesn't apply.
>
> I rummaged around the help files for str, summary, dput, args.  This
> seems like a more complicated language than Matlab, VBA, or even C++'s
> STL of old (which was pretty thoroughly documented).  A function like
> str() returns an object description, and I'm guessing the conventions
> with which the object is described depends a lot on the person who
> wrote the handling code for the class.  The description for the
> variable y seems particularly elaborate.
>
> Would I be right in assuming that the notation is ad-hoc and not
> documented?  For example, the two invocations str(x) and str(y) show a
> Time-Series and a ts.  And there are many lines of output for str(y)
> that is heavy in punctuation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From shidaxia at yahoo.com  Wed Apr 22 01:01:41 2015
From: shidaxia at yahoo.com (Shi, Tao)
Date: Tue, 21 Apr 2015 23:01:41 +0000 (UTC)
Subject: [R] Rtools 3.3 is not compatible with R 3.2.0.?
Message-ID: <1690232006.1604951.1429657301961.JavaMail.yahoo@mail.yahoo.com>

hi list,

Any updates on this issue?  Thank you very much!

Tao


> devtools::install_github("rstudio/packrat") 
WARNING: Rtools 3.3 found on the path at c:/Rtools is not compatible with R 3.2.0. 

Please download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools(). 
Downloading github repo rstudio/packrat at master 
Installing packrat 
"C:/PROGRA~1/R/R-32~1.0/bin/x64/R" --vanilla CMD INSTALL  \ 
"C:/Users/tshi/AppData/Local/Temp/Rtmp6VYlhX/devtools25dc273e706c/rstudio-packrat-42b76ad" --library="C:/Program Files/R/R-3.2.0/library"  \ 
--install-tests 

* installing *source* package 'packrat' ... 
** R 
** inst 
** tests 
** preparing package for lazy loading 
** help 
*** installing help indices 
** building package indices 
** testing if installed package can be loaded 
* DONE (packrat) 

> find_rtools() 
WARNING: Rtools 3.3 found on the path at c:/Rtools is not compatible with R 3.2.0. 

Please download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools(). 

> sessionInfo() 
R version 3.2.0 (2015-04-16) 
Platform: x86_64-w64-mingw32/x64 (64-bit) 
Running under: Windows 7 x64 (build 7601) Service Pack 1 

locale: 
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252 

attached base packages: 
[1] stats     graphics  grDevices utils     datasets  methods   base 

other attached packages: 
[1] devtools_1.7.0   packrat_0.4.3-19 

loaded via a namespace (and not attached): 
[1] httr_0.6.1     tools_3.2.0    RCurl_1.95-4.5 stringr_0.6.2  bitops_1.0-6


From dulcalma at bigpond.com  Wed Apr 22 07:46:25 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 22 Apr 2015 15:46:25 +1000
Subject: [R] high density plots using lattice dotplot()
In-Reply-To: <CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>
References: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>	<000001d07bc2$a73b7d30$f5b27790$@bigpond.com>
	<CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>
Message-ID: <001101d07cbf$ac8ace00$05a06a00$@bigpond.com>


Hi Luigi

I should have made up an example to make things easier when I replied today

This should get you going

set.seed(1)

PLATE <-
data.frame(Delta.Rn = rnorm(500),
           Cycle = rnorm(500),
           Well  = rep(1:50, each = 10))
head(PLATE)

xyplot(Delta.Rn ~ Cycle | Well,
         data = PLATE,
         groups = Well,
         ylab="Fluorescence (Delta Rn)",
         xlab="Cycles",
         main="TITLE",
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         as.table = TRUE,
         layout = c(10,5),
         par.settings = list(
           strip.background=list(col="white"),
           # layout.heights = list(strip = 0.8),
           axis.text = list(cex = 0.6),
           par.xlab.text = list(cex = 0.75),
           par.ylab.text = list(cex = 0.75),
          par.main.text = list(cex = 0.8)
           superpose.symbol = list(pch = ".", cex = 2)
         ),
         strip    = FALSE,
         type = "p",
         col = 1,
         panel = panel.superpose,
         panel.groups = function(x,y,...,group.number){

                   panel.xyplot(x,y,... )

                   # text argument can be a vector of values not
                   # necessarily the group name
                   grid.text(c(LETTERS,letters)[group.number],
                             y = 0.93, x = 0.5,
                             default.units = "npc",
                             just = c("left", "bottom"),
                             gp = gpar(fontsize = 7) )

         }
  )

You could use panel.text instead of grid.text
Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Wednesday, 22 April 2015 08:24
To: Duncan Mackay
Subject: Re: [R] high density plots using lattice dotplot()

Dear Duncan,
thank you for your reply. I tried to implement your suggestions but as
is on your reply did not work (actually R crashed) and a slight
elaboration returned the figure attached, which is essentially still
displaying text and not drawing the data. Here is what I wrote:

xyplot(Delta.Rn ~ Cycle | Well,
         data = PLATE,
         ylab="Fluorescence (Delta Rn)",
         xlab="Cycles",
         main=TITLE,
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         as.table = TRUE,
         layout = c(24,16),
         par.settings = list(
           strip.background=list(col="white"),
           axis.text = list(cex = 0.6),
           par.xlab.text = list(cex = 0.75),
           par.ylab.text = list(cex = 0.75),
           superpose.symbol = list(pch = ".", cex = 2)
         ),
         strip    = FALSE,
         type = "p",
         layout.heights = list(strip = 0.8),
         panel = function(x,y, subscripts, groups,...){
           panel.superpose(x,y,subscripts,groups,...,
                           col = ...)
           panel.text(x,y,...,cex = 0.6)
         }
  )


How can I improve the script?
Many thanks
Luigi

On Tue, Apr 21, 2015 at 12:35 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Strips take up space so if you are willing to not have strip and put the
> strip values within the plot area then
>
>       xyplot(y ~ x|cond.factor, data = ...,
>              as.table = T,
>              groups   = ...,
>              layout   = ...,
>              drop.unused = T,
>              par.settings = list(axis.text = list(cex = 0.6),
>                                  par.xlab.text = list(cex = 0.75),
>                                  par.ylab.text = list(cex = 0.75)
>                                  superpose.symbol = list(pch = ".", cex = 2)
>                             ),
>              strip    = FALSE,
>              scales   = list(x = list(alternating = 2),
>                              y = list(alternating = FALSE)
>                              ),
>              type = "p",
>              panel = function(x,y, subscripts, groups,...){
>                                 panel.superpose(x,y,subscripts,groups,...,
> col = ...)
>                                 panel.text(x,y,...,cex = 0.6)
>                             }
>       )
>
> if the text values are a vector
>       stext = ...
>       xyplot(y ~ x|cond.factor, data = ...,
>              as.table = T,
>              groups   = ...,
>              layout   = ...,
>              drop.unused = T,
>              par.settings = list(axis.text = list(cex = 0.6),
>                                  par.xlab.text = list(cex = 0.75),
>                                  par.ylab.text = list(cex = 0.75)
>                                  superpose.symbol = list(pch = ".", cex = 2)
>                             ),
>              strip    = FALSE,
>              scales   = list(x = list(alternating = 2),
>                              y = list(alternating = FALSE)
>                              ),
>              type = "p",
>              panel = function(x,y, subscripts, groups,...){
>                                pnl = panel.number()
>                                 panel.superpose(x,y,subscripts,groups,...,
> col = ...)
>                                 panel.text(x,y,stext[pnl],cex = 0.6)
>                             }
>       )
>
> you could also you group.number instead of pnl if it is needed elsewhere.
> text position could be done in a similar fashion if needed to be in
> different places for some panels.
>
> If you require the strip then an additional par.settings is
> layout.heights = list(strip = 0.8)
> or even untested in this situation
> strip = FALSE
> strip.left  = TRUE
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Sunday, 19 April 2015 19:28
> To: r-help
> Subject: [R] high density plots using lattice dotplot()
>
> Dear all,
> I am trying to plot the results of a PCR experiments that involves 384
> individual plots. Admittedly the space for the plots will be tiny, but
> I just nedd some icon to have a feeling of the layout of the
> experiment and a quick comparison of the plots.
> I believe that lattice would be the right tool, but when I tried to
> implement i got an error. Specifically the output would be a A4 pdf,
> so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
> each plot; removing the labels that might just work.
> So I have the y values = 'fluorescence', x 'values' = cycles and 384
> 'well' data. I implemented to begin with:
>
> xyplot(fluorescence ~ cycles | well,
>          ylab="Fluorescence",
>          xlab="Cycles",
>          main=list(draw = FALSE),
>          scales = list(
>            x = list(draw = FALSE),
>            y = list(draw = FALSE),
>            relation="same",
>            alternating=TRUE),
>          layout = c(24,16),
>          par.settings = list(strip.background=list(col="white")),
>          pch = "."
>   )
>
> but the  the individual graphs show only the writing "data" instead of
> the actual plots.
> How can I overcome this error?
> Thank you
> Best regards
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Lalitha.Kristipati at techmahindra.com  Wed Apr 22 06:54:36 2015
From: Lalitha.Kristipati at techmahindra.com (Lalitha Kristipati)
Date: Wed, 22 Apr 2015 04:54:36 +0000
Subject: [R] Suggest method
Message-ID: <aa68dc648a4e459fb6c381f39401aa35@BLREXCHMBX001.TechMahindra.com>

Hi,

I want to do a use case in R language. My problem statement is to upgrade the passengers from one membership level to another membership level in airlines based on their characteristics. It is like customer profiling based on their usage characteristics. Suggest a method that intakes a large amount of data and cluster them based on their characteristics and helps in knowing the passengers who are upgraded to another level .
Any help is appreciated.

Regards,
Lalitha Kristipati
Associate Software Engineer



============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From rob at dijital.ca  Wed Apr 22 06:43:19 2015
From: rob at dijital.ca (Rob Skelly)
Date: Wed, 22 Apr 2015 04:43:19 +0000
Subject: [R] rgdal installation with two versions of GDAL
Message-ID: <CAKk5Q9Xsa_HywXRLWLUw04c1HvmQ0WfTMtMaMxfsO_MeNyqY6Q@mail.gmail.com>

Hello,

I am using GDAL 2.0 for most of my work, but rgdal depends on GDAL < 2. I
have built and installed GDAL 1.11.2 in /opt/gdal-1.11.2, and rgdal
compiles and installs into R, using the following command:

sudo R CMD INSTALL
--configure-args="--with-gdal-config=/opt/gdal.1.11.2/bin/gdal-config"
rgdal-0.9-2.tar.gz

However when R attempts to load rgdal at the end of the installation, it
fails with the error,

Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/usr/local/lib/R/site-library/rgdal/libs/rgdal.so':
  /usr/local/lib/R/site-library/rgdal/libs/rgdal.so: undefined symbol:
_ZN10OGRPolygon7addRingEP13OGRLinearRing

The addRing method on OGRPolygon seems to be a relic of GDAL 1.11.2 and no
longer exists in 2.0, so R is loading libgdal from /usr/local/lib, not
/opt/gdal-1.11.2/lib. I have confirmed this by temporarily moving the
1.11.2 libs into /usr/local, where it works fine.

So, the question is, how to I convince R to use the new library search
path? I'm on xubuntu, and R is installed using apt.

Thanks,
Rob

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Wed Apr 22 11:30:19 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 22 Apr 2015 11:30:19 +0200 (CEST)
Subject: [R] Exhaustive CHAID package
In-Reply-To: <52BD8206AE274C449268B7D6AC44D0740154F2C68BCA@EXC4.ad.colorado.edu>
References: <52BD8206AE274C449268B7D6AC44D0740154F2C68BCA@EXC4.ad.colorado.edu>
Message-ID: <alpine.DEB.2.11.1504221119180.5524@paninaro.uibk.ac.at>

On Tue, 21 Apr 2015, Michael Grant wrote:

> Dear R-Help:
>
> From multiple sources comparing methods of tree classification and tree 
> regressions on various data sets, it seems that Exhaustive CHAID 
> (distinct from CHAID), most commonly generates the most useful tree 
> results and, in particular, is more effective than ctree or rpart which 
> are implemented in R.

I searched a bit on the web for "exhaustive CHAID" and didn't find any 
convincing evidence that this method is "most commonly" the "most useful". 
I doubt that such evidence exists because the methods are applicable to so 
many different situations that uniformly better results are essentially 
never obtained. Nevertheless, if you have references of comparison 
studies, I would still be interested. Possibly these provide insight in 
which situations exhaustive CHAID performs particularly well.

> I see that CHAID, but not Exhaustive CHAID, is in the R-forge, and I 
> write to ask if there are plans to create a package which employs the 
> Exhaustive CHAID strategy.

I wouldn't know of any such plans. But if you want to adapt/extend the 
code from the CHAID package, this is freely available.

> Right now the best source I can find is in SPSS-IBM and I feel a bit 
> disloyal to R using it.

I wouldn't be concerned about disloyalty. If you feel that exhaustive 
CHAID is the most appropriate tool for your problem and you have access to 
it in SPSS, why not use it? Possibly you can also export it from SPSS and 
import it into R using PMML. The "partykit" package has an example with an 
imported QUEST tree from SPSS.

> Michael Grant
> Professor
> University of Colorado Boulder
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michael.eisenring at agroscope.admin.ch  Wed Apr 22 11:32:11 2015
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Wed, 22 Apr 2015 09:32:11 +0000
Subject: [R] =?windows-1252?q?modifications_using_=93stat=5Fsummary=94_in_?=
	=?windows-1252?q?ggplot?=
Message-ID: <9EFCA4A987B0494CBFFB5CD071756D004B80457E@WBF-C7002.bk.evdad.admin.ch>

Dear R-list members
I am using ?stat_summary? in ggplot to plot a  error bar graph comparing three treatmens (damage, see code below).
I would like to change the shape of the three symbols displaying the mean values (e.g one symbol should be a point (default) one should be a triangle and one should be a square). Furthermore, I would like that the outlines of my error bars are black (and that I can fill them with whatever color I want ( I used white, black and gray65).

Does Anyone of you know how to solve these problems?

I use the following code:

line<-ggplot(data,aes(leaf,cor_average,fill=damage, colour=damage))
#define x (leaf) and y (cor_average) variables within aes() and that they should be colored according to damage type
line+stat_summary(fun.y=mean, geom="point", size=3)+
#add mean as point symbol
stat_summary(fun.data=mean_cl_boot,geom="errorbar",width=0.3, size=0.75)+
scale_colour_manual(values=c("white","black","gray65"))+
#add CI : width=width of CI whiskers, size=widht of the CI bar
labs(x="Leaf",y="Average nr. glands corrected for leaf sz.")


Thank you very much,
Michael

Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Institute of Sustainability Sciences ISS
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Wed Apr 22 12:25:33 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 22 Apr 2015 12:25:33 +0200
Subject: [R] Random Forest in Caret
Message-ID: <20150422102533.GC2554@localhost.localdomain>

Dear All,
I am a bit concerned about the memory consumption of randomForest in
caret.
This seems to e due to the fact that the option keep.forest=FALSE does
not work in caret.
Does anybody know a workaround for that?
Many thanks

Lorenzo


From Joachim.Audenaert at pcsierteelt.be  Wed Apr 22 13:14:06 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Wed, 22 Apr 2015 13:14:06 +0200
Subject: [R]  - dunn.test gives strange output
Message-ID: <OF1148E733.FC83E1F5-ONC1257E2F.003D8B32-C1257E2F.003DB756@pcsierteelt.be>

Dear all,

I have a question concerning my output of the dunn.test function in R. I 
like to compare different datasets, which are not distributed normally, so 
I use the Dunn.test to do pairwise comparison. I have 2 questions 
concerning the output:

- why are my groupnames changed, the output gives 4 times swirskii, 
although my groupnames are longer (see my dataset)
- secondly when I check the p-values, I see something very odd: I see that 
p values where the same groups are compared sometimes indicate that they 
are different, why are not all those p-values = 1 ?

This is my dataset:

structure(list(controle = c(111, 88, 216, 169), chemie = c(47, 31, 35, 
30), IPM = c(0, 0, 0, 1), gallicus = c(102, 152, 102, 75), swirskii3 = 
c(1, 0, 0, 0), swirskiiA = c(0, 0, 1, 3), swirskiiP = c(0, 0, 1, 6), 
swirskii1x = c(12, 2, 75, 46)), .Names = c("controle", "chemie", "IPM", 
"gallicus", "swirskii3", "swirskiiA", "swirskiiP", "swirskii1x"), 
row.names = c(NA, 4L), class = "data.frame")

I get the following output:

 DUNN <- dunn.test(value, variable, method = "none",kw=TRUE)
 
  Kruskal-Wallis rank sum test

data: value and variable
Kruskal-Wallis chi-squared = 26.8894, df = 7, p-value = 0


                        Comparison of value by variable  
                                (No adjustment)  
Col Mean-|
Row Mean |   controle     chemie        IPM   gallicus   swirskii swirskii
---------+------------------------------------------------------------------
  chemie |  -1.341044  -3.410083  -2.069039  -0.325682   1.015361 3.084401
         |     0.0900     0.0003     0.0193     0.3723     0.1550 0.0010
         |
     IPM |  -3.410083  -2.069039  -0.325682   1.015361   3.084401 
-3.410083
         |     0.0003     0.0193     0.3723     0.1550     0.0010 0.0003
         |
gallicus |  -0.325682   1.015361   3.084401  -3.410083  -2.069039 0.000000
         |     0.3723     0.1550     0.0010     0.0003     0.0193 0.5000
         |
swirskii |  -3.410083  -2.069039   0.000000  -3.084401  -3.007770 
-1.666726
         |     0.0003     0.0193     0.5000     0.0010     0.0013 0.0478
         |
swirskii |  -3.007770  -1.666726   0.402313  -2.682088   0.402313 
-2.969454
         |     0.0013     0.0478     0.3437     0.0037     0.3437     
0.0015
         |
swirskii |  -2.969454  -1.628410   0.440628  -2.643772   0.440628 0.038315
         |     0.0015     0.0517     0.3297     0.0041     0.3297 0.4847
         |
swirskii |  -1.475148  -0.134104   1.934935  -1.149466   1.934935 1.532621
         |     0.0701     0.4467     0.0265     0.1252     0.0265 0.0627
Col Mean-|
Row Mean |   swirskii
---------+-----------
  chemie |  -3.410083
         |     0.0003
         |
     IPM |  -2.069039
         |     0.0193
         |
gallicus |  -3.084401
         |     0.0010
         |
swirskii |   0.402313
         |     0.3437
         |
swirskii |  -1.628410
         |     0.0517
         |
swirskii |  -1.475148
         |     0.0701
         |
swirskii |   1.494306
         |     0.0675 




Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be   

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!
	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed Apr 22 13:16:49 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 22 Apr 2015 11:16:49 +0000
Subject: [R] rgdal installation with two versions of GDAL
References: <CAKk5Q9Xsa_HywXRLWLUw04c1HvmQ0WfTMtMaMxfsO_MeNyqY6Q@mail.gmail.com>
Message-ID: <loom.20150422T130559-708@post.gmane.org>

Rob Skelly <rob <at> dijital.ca> writes:

> 
> Hello,
> 
> I am using GDAL 2.0 for most of my work, but rgdal depends on GDAL < 2. I
> have built and installed GDAL 1.11.2 in /opt/gdal-1.11.2, and rgdal
> compiles and installs into R, using the following command:
> 
> sudo R CMD INSTALL
> --configure-args="--with-gdal-config=/opt/gdal.1.11.2/bin/gdal-config"
> rgdal-0.9-2.tar.gz
> 

There are several questions here. Firstly, R-sig-geo is the appropriate list
for questions of this kind, if we ignore the need to understand library
search path management under a particular linux distribution.

GDAL 2.0 has not been released yet, and is not backward compatible with GDAL
1 (they use different object models). It is true that a release date at the
end of this month was proposed, but has not yet been confirmed. Given the
uncertain status of GDAL 2, there is no pressing reason to divert maintainer
assets to implementing changes in rgdal that may need frequent revision
tracking changes in GDAL 2, and keeping a parallel object structure for
released GDAL 1.*.

You do not say why GDAL 2 is essential for your work - maybe you could
simply use GDAL 1* until GDAL 2 stabilises? Neither your motivation nor your
affiliation are very convincing.

Please never post HTML-formatted mail.

Roger

> 
> So, the question is, how to I convince R to use the new library search
> path? I'm on xubuntu, and R is installed using apt.
> 
> Thanks,
> Rob
> 
> 	[[alternative HTML version deleted]]
> 
>


From jrkrideau at inbox.com  Wed Apr 22 14:50:21 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 22 Apr 2015 04:50:21 -0800
Subject: [R] =?utf-8?q?modifications_using_=E2=80=9Cstat=5Fsummary?=
 =?utf-8?q?=E2=80=9D_in_ggplot?=
In-Reply-To: <9EFCA4A987B0494CBFFB5CD071756D004B80457E@WBF-C7002.bk.evdad.admin.ch>
Message-ID: <ACEF94E52AD.0000113Ejrkrideau@inbox.com>

It would really help to have some sample data to see what is happening.  The best way to supply data to the help group is to use dput().  Type >dput for some basic information on using it

Have a look at and/or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example  for some hints. For this last link it is a good idea to follow the " reproducible example  " link for more concrete suggestions.


By the way calling a data.frame "data" is not a good idea.  Data is a predefined function in R . Type ?data to see what I mean.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: michael.eisenring at agroscope.admin.ch
> Sent: Wed, 22 Apr 2015 09:32:11 +0000
> To: r-help at r-project.org
> Subject: [R] modifications using ?stat_summary? in ggplot
> 
> Dear R-list members
> I am using stat_summary in ggplot to plot a  error bar graph comparing
> three treatmens (damage, see code below).
> I would like to change the shape of the three symbols displaying the mean
> values (e.g one symbol should be a point (default) one should be a
> triangle and one should be a square). Furthermore, I would like that the
> outlines of my error bars are black (and that I can fill them with
> whatever color I want ( I used white, black and gray65).
> 
> Does Anyone of you know how to solve these problems?
> 
> I use the following code:
> 
> line<-ggplot(data,aes(leaf,cor_average,fill=damage, colour=damage))
> #define x (leaf) and y (cor_average) variables within aes() and that they
> should be colored according to damage type
> line+stat_summary(fun.y=mean, geom="point", size=3)+
> #add mean as point symbol
> stat_summary(fun.data=mean_cl_boot,geom="errorbar",width=0.3, size=0.75)+
> scale_colour_manual(values=c("white","black","gray65"))+
> #add CI : width=width of CI whiskers, size=widht of the CI bar
> labs(x="Leaf",y="Average nr. glands corrected for leaf sz.")
> 
> 
> Thank you very much,
> Michael
> 
> Eisenring Michael, Msc.
> PhD Student
> 
> Federal Department of Economic Affairs, Education and Research
> EAER
> Institute of Sustainability Sciences ISS
> Biosafety
> 
> Reckenholzstrasse 191, CH-8046 Zrich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From maechler at lynne.stat.math.ethz.ch  Wed Apr 22 15:15:32 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Apr 2015 15:15:32 +0200
Subject: [R] How numerical data is stored inside ts time series objects
In-Reply-To: <loom.20150422T032037-943@post.gmane.org>
References: <loom.20150421T010112-378@post.gmane.org>
	<CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>
	<loom.20150422T032037-943@post.gmane.org>
Message-ID: <21815.40692.877513.907813@stat.math.ethz.ch>

>>>>> Paul  <Paul.Domaskis at gmail.com>
>>>>>     on Wed, 22 Apr 2015 01:39:16 +0000 writes:

    > William Dunlap <wdunlap <at> tibco.com> writes:
    >> Use the str() function to see the internal structure of most
    >> objects.  In your case it would show something like:
    >> 
    >> > Data <- data.frame(theData=round(sin(1:38),1))
    >> > x <- ts(Data[[1]], frequency=12) # or Data[,1]
    >> > y <- ts(Data, frequency=12)
    >> > str(x)
    >> Time-Series [1:38] from 1 to 4.08: 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -
    > 0.5
    >> ...
    >> > str(y)
    >> ts [1:38, 1] 0.8 0.9 0.1 -0.8 -1 -0.3 0.7 1 0.4 -0.5 ...
    >> - attr(*, "dimnames")=List of 2
    >> ..$ : NULL
    >> ..$ : chr "theData"
    >> - attr(*, "tsp")= num [1:3] 1 4.08 12
    >> 
    >> 'x' contains a vector of data and 'y' contains a 1-column matrix of
    >> data.  stl(x,"per") and stl(y, "per") give similar results as you
    >> got.
    >> 
    >> Evidently, stl() does not know that 1-column matrices can be treated
    >> much the same as vectors and gives an error message.  Thus you must
    >> extract the one column into a vector: stl(y[,1], "per").

    > Thanks, William.

    > Interesting that a 2D matrix of size Nx1 is treated as a different
    > animal from a length N vector.  It's a departure from math convention,
    > and from what I'm accustomed to in Matlab.  

Ha -- Not at all!
The above is exactly the misconception I have been fighting --
mostly in vane -- for years.

Matlab's convention of treating a vector as an  N x 1 matrix is
a BIG confusion to much of math teaching :

The vector space  |R^n  is not all the same space as the space  |R^{n x 1}
even though of course there's a trivial mapping between the
objects (and the metrics) of the two.
A vector *is NOT* a matrix -- but in some matrix calculus
notations there is a convention to *treat* n-vectors as  (n x 1) matrices.

Good linear algebra teaching does distinguish vectors from
one-column or one-row matrices -- I'm sure still the case in all
good math departments around the globe -- but maybe not in math
teaching to engineers and others who only need applied math.
Yes, linear algebra teaching will also make a point that in
the usual matrix product notations, it is convenient and useful to treat
vectors as if they were 1-column matrices.

    > That R's vector seems
    > more akin to a list, where the notion of orientation doesn't apply.

Sorry, but again:  not at all in the sense 'list's are used in R.

Fortunately, well thought out languages such as S, R, Julia, Python,
all do make a good distinction between vectors and matrices
i.e. 1D and 2D arrays.  If Matlab still does not do that, it's
just another sign that Matlab users should flee and start using julia
or R or python.

  {and well yes, we could start bitchering about S' and hence R's distinction
   between a 1D array and a vector ... which I think has been a
   clear design error... but that's not the topic here}


From boris.steipe at utoronto.ca  Wed Apr 22 17:37:52 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 22 Apr 2015 11:37:52 -0400
Subject: [R] Suggest method
In-Reply-To: <aa68dc648a4e459fb6c381f39401aa35@BLREXCHMBX001.TechMahindra.com>
References: <aa68dc648a4e459fb6c381f39401aa35@BLREXCHMBX001.TechMahindra.com>
Message-ID: <62799E77-9CA2-42D7-BBCE-3E0A337E4248@utoronto.ca>

That does not sound like a clustering problem at all since you already know the desired characteristics and are not trying to discover structure in your data. Simply define a score as a suitably weighted sum of individual features, order your passengers by that score, and pick the top few, or any that exceed a threshold etc.

Not really an R problem at this point though.


B.

On Apr 22, 2015, at 12:54 AM, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:

> Hi,
> 
> I want to do a use case in R language. My problem statement is to upgrade the passengers from one membership level to another membership level in airlines based on their characteristics. It is like customer profiling based on their usage characteristics. Suggest a method that intakes a large amount of data and cluster them based on their characteristics and helps in knowing the passengers who are upgraded to another level .
> Any help is appreciated.
> 
> Regards,
> Lalitha Kristipati
> Associate Software Engineer
> 
> 
> 
> ============================================================================================================================
> Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
> ============================================================================================================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Apr 22 17:43:56 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Apr 2015 16:43:56 +0100
Subject: [R] rgdal installation with two versions of GDAL
In-Reply-To: <CAKk5Q9Xsa_HywXRLWLUw04c1HvmQ0WfTMtMaMxfsO_MeNyqY6Q@mail.gmail.com>
References: <CAKk5Q9Xsa_HywXRLWLUw04c1HvmQ0WfTMtMaMxfsO_MeNyqY6Q@mail.gmail.com>
Message-ID: <5537C1BC.8090704@stats.ox.ac.uk>

On 22/04/2015 05:43, Rob Skelly wrote:
> Hello,
>
> I am using GDAL 2.0 for most of my work, but rgdal depends on GDAL < 2. I
> have built and installed GDAL 1.11.2 in /opt/gdal-1.11.2, and rgdal
> compiles and installs into R, using the following command:
>
> sudo R CMD INSTALL
> --configure-args="--with-gdal-config=/opt/gdal.1.11.2/bin/gdal-config"
> rgdal-0.9-2.tar.gz
>
> However when R attempts to load rgdal at the end of the installation, it
> fails with the error,
>
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>    unable to load shared object
> '/usr/local/lib/R/site-library/rgdal/libs/rgdal.so':
>    /usr/local/lib/R/site-library/rgdal/libs/rgdal.so: undefined symbol:
> _ZN10OGRPolygon7addRingEP13OGRLinearRing
>
> The addRing method on OGRPolygon seems to be a relic of GDAL 1.11.2 and no
> longer exists in 2.0, so R is loading libgdal from /usr/local/lib, not
> /opt/gdal-1.11.2/lib. I have confirmed this by temporarily moving the
> 1.11.2 libs into /usr/local, where it works fine.

You can *really* confirm where things are found via R CMD ldd ... see 
the manual.

> So, the question is, how to I convince R to use the new library search
> path? I'm on xubuntu, and R is installed using apt.

You either use the ld options when building rgdal.so (e.g. for your OS 
-Wl,-rpath=/opt/gdal-1.11.2/lib) or you link statically.  The latter is 
easier and safer ... just build a static GDAL.

Many projects set -R/-rpath flags in their config scripts: it is 
something you could suggest to the GDAL maintainers (and finding them is 
part of libtool which GDAL uses).

But (see the posting guide) the generic question belonged on R-devel and 
questions about rgdal on R-sig-geo.

> Thanks,
> Rob

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From drf at vims.edu  Wed Apr 22 18:06:41 2015
From: drf at vims.edu (David R Forrest)
Date: Wed, 22 Apr 2015 16:06:41 +0000
Subject: [R] How numerical data is stored inside ts time series objects
In-Reply-To: <loom.20150422T032037-943@post.gmane.org>
References: <loom.20150421T010112-378@post.gmane.org>
	<CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>
	<loom.20150422T032037-943@post.gmane.org>
Message-ID: <280E8F92-96E1-4C08-94B8-CC9F99068BAC@vims.edu>


> On Apr 21, 2015, at 9:39 PM, Paul <Paul.Domaskis at gmail.com> wrote:
...
> I rummaged around the help files for str, summary, dput, args.  This
> seems like a more complicated language than Matlab, VBA, or even C++'s
> STL of old (which was pretty thoroughly documented).  A function like
> str() returns an object description, and I'm guessing the conventions
> with which the object is described depends a lot on the person who
> wrote the handling code for the class.  The description for the
> variable y seems particularly elaborate.
> 
> Would I be right in assuming that the notation is ad-hoc and not
> documented?  For example, the two invocations str(x) and str(y) show a
> Time-Series and a ts.  And there are many lines of output for str(y)
> that is heavy in punctuation.
> 

The details of how str() represents your x and y variables is within the utils::stl.default() function.  You can hunt this down and see the code with:

  methods(class=class(x))  # Find the class-specific handlers -- no str()
  methods(str)             # Find the methods for the generic
  getAnywhere(str.default)   # or getFromNamespace('str.default','utils')
  

Within the utils::str.default code, this 'Time-Series' specific code only triggers if the object doesn't match a long list of other items (for example: is.function(), is.list(), is.vector(object) || (is.array(object) && is.atomic(object)) ...)   

        else if (stats::is.ts(object)) {
            tsp.a <- stats::tsp(object)
            str1 <- paste0(" Time-Series ", le.str, " from ", 
                format(tsp.a[1L]), " to ", format(tsp.a[2L]), 
                ":")
            std.attr <- c("tsp", "class")
        }

This handling is not dependent on who wrote the ts class, but on who wrote the str.default function.  

A more explict way to look at the difference without the str() summarization is with dput(x) and dput(y):

> dput(x)
structure(c(464L, 675L, 703L, 887L, 1139L, 1077L, 1318L, 1260L, 
1120L, 963L, 996L, 960L, 530L, 883L, 894L, 1045L, 1199L, 1287L, 
1565L, 1577L, 1076L, 918L, 1008L, 1063L, 544L, 635L, 804L, 980L, 
1018L, 1064L, 1404L, 1286L, 1104L, 999L, 996L, 1015L), .Tsp = c(1, 
3.91666666666667, 12), class = "ts")
> dput(y)
structure(c(464L, 675L, 703L, 887L, 1139L, 1077L, 1318L, 1260L, 
1120L, 963L, 996L, 960L, 530L, 883L, 894L, 1045L, 1199L, 1287L, 
1565L, 1577L, 1076L, 918L, 1008L, 1063L, 544L, 635L, 804L, 980L, 
1018L, 1064L, 1404L, 1286L, 1104L, 999L, 996L, 1015L), .Dim = c(36L, 
1L), .Dimnames = list(NULL, "V1"), .Tsp = c(1, 3.91666666666667, 
12), class = "ts")


Also, Matlab sometimes needs a squeeze() to drop degenerate dimensions, and R's drop() is similar, and is less-black-magic looking than the [[1]] code:


> str(drop(x))
 Time-Series [1:36] from 1 to 3.92: 464 675 703 887 1139 1077 1318 1260 1120 963 ...
> str(drop(y))
 Time-Series [1:36] from 1 to 3.92: 464 675 703 887 1139 1077 1318 1260 1120 963 ...

stl(drop(x),s.window='per')
stl(drop(y),s.window='per') 

Maybe str.default() should do Time-Series interpretation of is.ts() objects for matrices as well as vectors.

Dave


From rob at dijital.ca  Wed Apr 22 19:58:01 2015
From: rob at dijital.ca (Rob Skelly)
Date: Wed, 22 Apr 2015 17:58:01 +0000
Subject: [R] rgdal installation with two versions of GDAL
In-Reply-To: <5537C1BC.8090704@stats.ox.ac.uk>
References: <CAKk5Q9Xsa_HywXRLWLUw04c1HvmQ0WfTMtMaMxfsO_MeNyqY6Q@mail.gmail.com>
	<5537C1BC.8090704@stats.ox.ac.uk>
Message-ID: <CAKk5Q9X9JwWprVrvgQi_+v+hpK28uuSm=-+y2prQEPa5puEVvg@mail.gmail.com>

>
> You can *really* confirm where things are found via R CMD ldd ... see
> the manual.
>
> Yes of course. I had done that, and received the hoped-for response:

libgdal.so.1 => /opt/gdal-1.11.2/lib/libgdal.so.1 (0x00007fd9e0175000)

But I realize now that this was with LD_LIBRARY_PATH set. Of course R
modifies LD_LIBRARY_PATH, erasing any paths set by the user, so that while
the installation succeeds, the load doesn't.

I've temporarily modified ldpaths and it works. So there's the answer for
now.

But (see the posting guide) the generic question belonged on R-devel and
> questions about rgdal on R-sig-geo.
>

Apologies. I'll ask there next time.

Rob

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Wed Apr 22 20:06:40 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 22 Apr 2015 20:06:40 +0200 (CEST)
Subject: [R] Exhaustive CHAID package
In-Reply-To: <52BD8206AE274C449268B7D6AC44D0740154F2C68C1A@EXC4.ad.colorado.edu>
References: <52BD8206AE274C449268B7D6AC44D0740154F2C68BCA@EXC4.ad.colorado.edu>
	<alpine.DEB.2.11.1504221119180.5524@paninaro.uibk.ac.at>
	<52BD8206AE274C449268B7D6AC44D0740154F2C68C1A@EXC4.ad.colorado.edu>
Message-ID: <alpine.DEB.2.11.1504221958200.5524@paninaro.uibk.ac.at>

On Wed, 22 Apr 2015, Michael Grant wrote:

> Many thanks for your response, sir.
>
> Here are two of the references to which I referred.  I've also 
> personally explored several data sets in which the outcomes are 'known' 
> and have seen high variability in the topology of the trees being 
> produced but, typically Exhaustive CHAID predictions match the 'known' 
> results better than any of the others, using default settings.
>
> http://www.hindawi.com/journals/jam/2014/929768/
> http://interstat.statjournals.net/YEAR/2010/articles/1007001.pdf

Thanks for the references, I wasn't aware of these. Both of these appear 
to use the SPSS implementations of CHAID, exhaustive CHAID, CART, and 
QUEST with default settings (as you did above). As I have never used these 
myself in SPSS, I cannot say how the implementations compare but it's well 
possible that these are different from other implementations. E.g., for 
CART the pruning rule may make a difference (with or without 
crossvalidation; with 1-SE or 0-SE rule etc.). Similarly, for QUEST I 
think that Loh's own implementation uses somewhat different default 
settings.

So it may be advisable to go beyond defaults.

> By inference, many research papers are choosing Exhaustive CHAID.

My experience is that this is determined to a good degree by the software 
available and what others in the same literature use.

> My concern is not that these procedures produce mildly variant trees but 
> dramatically variant, with not even the same set of variables included.

Yes, instability of the tree structure is one of the drawbacks of 
tree-based procedures. Of course, the tree structure can be very different 
while producing very similar predictions.

> Is CHAID available for use as an R package?

Yes.

> I thought R-FORGE was solely for developers?

See: https://R-Forge.R-project.org/R/?group_id=343

You can easily install the package from R-Forge and also check out the 
entire source code anonymously.

> Again, many thanks.
>
> MCG
>
> -----Original Message-----
> From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at]
> Sent: Wednesday, April 22, 2015 3:30 AM
> To: Michael Grant
> Cc: r-help at R-project.org
> Subject: Re: [R] Exhaustive CHAID package
>
> On Tue, 21 Apr 2015, Michael Grant wrote:
>
>> Dear R-Help:
>>
>> From multiple sources comparing methods of tree classification and
>> tree regressions on various data sets, it seems that Exhaustive CHAID
>> (distinct from CHAID), most commonly generates the most useful tree
>> results and, in particular, is more effective than ctree or rpart
>> which are implemented in R.
>
> I searched a bit on the web for "exhaustive CHAID" and didn't find any convincing evidence that this method is "most commonly" the "most useful".
> I doubt that such evidence exists because the methods are applicable to so many different situations that uniformly better results are essentially never obtained. Nevertheless, if you have references of comparison studies, I would still be interested. Possibly these provide insight in which situations exhaustive CHAID performs particularly well.
>
>> I see that CHAID, but not Exhaustive CHAID, is in the R-forge, and I
>> write to ask if there are plans to create a package which employs the
>> Exhaustive CHAID strategy.
>
> I wouldn't know of any such plans. But if you want to adapt/extend the code from the CHAID package, this is freely available.
>
>> Right now the best source I can find is in SPSS-IBM and I feel a bit
>> disloyal to R using it.
>
> I wouldn't be concerned about disloyalty. If you feel that exhaustive CHAID is the most appropriate tool for your problem and you have access to it in SPSS, why not use it? Possibly you can also export it from SPSS and import it into R using PMML. The "partykit" package has an example with an imported QUEST tree from SPSS.
>
>> Michael Grant
>> Professor
>> University of Colorado Boulder
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ispanyolcom at gmail.com  Wed Apr 22 18:37:48 2015
From: ispanyolcom at gmail.com (=?UTF-8?Q?Temel_=C4=B0spanyolca?=)
Date: Wed, 22 Apr 2015 18:37:48 +0200
Subject: [R] Basic structural time series
Message-ID: <CAMUSX8r-GXiZEcL5QhYwr4rivtE9O3YrWHrLkadDByP6WgpUiA@mail.gmail.com>

Hello
I try to forecast with BSM.
My data is in the annex.
 I dont understand why my forecasting result very interesting.
You can see in annex (result.png)
I expect that forecasting  result must be increasing

my code ;

(fit <- StructTS(log10(x), type = "BSM"))
plot(cbind(fitted(fit), resids=resid(fit)), main = "Data")
library(forecast)
plot(forecast(fit))

is there any idea?

Thanks
-------------- next part --------------
A non-text attachment was scrubbed...
Name: result.PNG
Type: image/png
Size: 18297 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150422/89607d82/attachment.png>

From jitvi648 at student.liu.se  Wed Apr 22 13:06:53 2015
From: jitvi648 at student.liu.se (jitvis)
Date: Wed, 22 Apr 2015 04:06:53 -0700 (PDT)
Subject: [R] Predict in glmnet for Cox family
In-Reply-To: <2f3a88$fud6n@ironport10.mayo.edu>
References: <1429431493476-4706070.post@n4.nabble.com>
	<2f3a88$fud6n@ironport10.mayo.edu>
Message-ID: <1429700813668-4706248.post@n4.nabble.com>

Dear Terry,

Thank you for your reply, I understood its difficult to predict survival
time, in general. 

I have tried another approach and I would like to know whether my approach
is correct.

I have clustered my dataset based on some similarity and reduced the number
of variables using LASSO and some expert opinion. And then I applied
Accelerated failure time model - using weibull, used survival package -
survreg and then I predicted the survival time. 

The accuracy is little less due to the uncertainty and complexity in
survival time of individual observations, and I checked the quantile 5% and
95% and almost 95% observations falls in the confidence interval even if the
interval is little wide.

     Actual Predicted     Lower     Upper
1      91  83.01901 10.497993 178.65750
2      90  62.66257  7.923863 134.85030
3     115  57.59236  7.282720 123.93918
4      20  50.72860  6.414777 109.16830
5      81  83.42176 10.548922 179.52423
6     113  57.10106  7.220593 122.88188
7       8  58.29399  7.371442 125.44907
8      88  53.19866  6.727124 114.48390
9      17  34.80713  4.401461  74.90518
10      5  45.90169  5.804401  98.78076
11     20  58.99832  7.460507 126.96480
12     34  64.05572  8.100031 137.84837
13     27  39.25003  4.963279  84.46635
14     56  41.03611  5.189134  88.31000
15     60  69.70944  8.814959 150.01520

Is my approach correct ? Can I say this model is good ? 

Will I be able to some more testing so that I can get a probability survival
curve ?

Sincerely,




--
View this message in context: http://r.789695.n4.nabble.com/Predict-in-glmnet-for-cox-family-tp4706070p4706248.html
Sent from the R help mailing list archive at Nabble.com.


From kalsbab at yahoo.ca  Wed Apr 22 18:09:43 2015
From: kalsbab at yahoo.ca (Kalsbab)
Date: Wed, 22 Apr 2015 12:09:43 -0400
Subject: [R] R installation issues
Message-ID: <58BFCF69-E80F-4AE8-934B-7F36A91C497F@yahoo.ca>

Hi, 

Please help me on this. 

I have installed "R" 3.1.2 version (64 bit) and receiving the follwowing
error message while launching the Rx64 desktop icon. 

"R for Windows GUI front-end has stopped working. Close the program. The
application was unable to start correctly (0xc0000005) " 

I tried the latest version 3.2 (64 bit R ) too and receiving the same error
message. (I do not have any issues with the 32 bit installations. Its
working perfectly fine. )


Here is the infoFrom the event log: 
Faulting applicaiton name: Rgui.exe 
Faulting Module name: ntdll.dll 
Exception code: 0xc0000005 
Faulting Process id:0x1bf4 
Fautling applicatio path:C:\Programfiles\R\R-3.1.3\bin\x64\rgui.exe 
Faulting Module path:C:\Windows\System32\ntdll.dl 

Please let me know whats causing this issue. Please let me know how to fix
this issue



--
View this message in context: http://r.789695.n4.nabble.com/R-64-Bit-installation-Issues-tp4706259.html
Sent from the R help mailing list archive at Nabble.com.

Sent from my iPhone
	[[alternative HTML version deleted]]


From michael.grant at colorado.edu  Wed Apr 22 16:50:02 2015
From: michael.grant at colorado.edu (Michael Grant)
Date: Wed, 22 Apr 2015 08:50:02 -0600
Subject: [R] Exhaustive CHAID package
In-Reply-To: <alpine.DEB.2.11.1504221119180.5524@paninaro.uibk.ac.at>
References: <52BD8206AE274C449268B7D6AC44D0740154F2C68BCA@EXC4.ad.colorado.edu>
	<alpine.DEB.2.11.1504221119180.5524@paninaro.uibk.ac.at>
Message-ID: <52BD8206AE274C449268B7D6AC44D0740154F2C68C1A@EXC4.ad.colorado.edu>

Many thanks for your response, sir.

Here are two of the references to which I referred.  I've also personally explored several data sets in which the outcomes are 'known' and have seen high variability in the topology of the trees being produced but, typically Exhaustive CHAID predictions match the 'known' results better than any of the others, using default settings.

http://www.hindawi.com/journals/jam/2014/929768/
http://interstat.statjournals.net/YEAR/2010/articles/1007001.pdf

By inference, many research papers are choosing Exhaustive CHAID.

My concern is not that these procedures produce mildly variant trees but dramatically variant, with not even the same set of variables included.

Is CHAID available for use as an R package?  I thought R-FORGE was solely for developers?

Again, many thanks.

MCG

-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at] 
Sent: Wednesday, April 22, 2015 3:30 AM
To: Michael Grant
Cc: r-help at R-project.org
Subject: Re: [R] Exhaustive CHAID package

On Tue, 21 Apr 2015, Michael Grant wrote:

> Dear R-Help:
>
> From multiple sources comparing methods of tree classification and 
> tree regressions on various data sets, it seems that Exhaustive CHAID 
> (distinct from CHAID), most commonly generates the most useful tree 
> results and, in particular, is more effective than ctree or rpart 
> which are implemented in R.

I searched a bit on the web for "exhaustive CHAID" and didn't find any convincing evidence that this method is "most commonly" the "most useful". 
I doubt that such evidence exists because the methods are applicable to so many different situations that uniformly better results are essentially never obtained. Nevertheless, if you have references of comparison studies, I would still be interested. Possibly these provide insight in which situations exhaustive CHAID performs particularly well.

> I see that CHAID, but not Exhaustive CHAID, is in the R-forge, and I 
> write to ask if there are plans to create a package which employs the 
> Exhaustive CHAID strategy.

I wouldn't know of any such plans. But if you want to adapt/extend the code from the CHAID package, this is freely available.

> Right now the best source I can find is in SPSS-IBM and I feel a bit 
> disloyal to R using it.

I wouldn't be concerned about disloyalty. If you feel that exhaustive CHAID is the most appropriate tool for your problem and you have access to it in SPSS, why not use it? Possibly you can also export it from SPSS and import it into R using PMML. The "partykit" package has an example with an imported QUEST tree from SPSS.

> Michael Grant
> Professor
> University of Colorado Boulder
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mikehall at y7mail.com  Wed Apr 22 20:52:45 2015
From: mikehall at y7mail.com (Mike)
Date: Wed, 22 Apr 2015 18:52:45 +0000 (UTC)
Subject: [R] Why is removeSparseTerms() not doing anything?
Message-ID: <1451051007.2249683.1429728765369.JavaMail.yahoo@mail.yahoo.com>

Here's the code and results.? The corpus is the text version of a single book.?? (r vs. 3.2)
> docs <- tm_map(docs, stemDocument)
> dtm <- DocumentTermMatrix(docs)
> freq <- colSums(as.matrix(dtm))
> ord <- order(freq)
> freq[tail(ord)]
one experi   will   can lucid dream
287   312   363   452   1018   2413
> freq[head(ord)]
abbey abdomin   abdu abraham absent   abus
  1       1       1       1       1       1
> dim(dtm)
[1]   1 5265
> dtms <- removeSparseTerms(dtm, 0.1)
> dim(dtms)
[1]   1 5265
> dtms <- removeSparseTerms(dtm, 0.001)
> dim(dtms)
[1]   1 5265
> dtms <- removeSparseTerms(dtm, 0.9)
> dim(dtms)
[1]   1 5265
> 

	[[alternative HTML version deleted]]


From pablofleurquin at gmail.com  Wed Apr 22 18:03:24 2015
From: pablofleurquin at gmail.com (Pablo Fleurquin)
Date: Wed, 22 Apr 2015 18:03:24 +0200
Subject: [R] R lattice bwplot: Fill boxplots with specific color depending
 on factor level
Message-ID: <CABggTg6LS4Txqh8CKofu4hJLd7wsGRv5iuBiY6ZbvXUeXfXjxA@mail.gmail.com>

Hi,

I thoroughly looked for an answer to this problem with no luck.

I have a dataframe with 3 factor levels: YY, NN, YN

*>mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))*

Being Col3 of factor type with 3 levels: NN YY YN

I want to make a boxplot using lattice bwplot and assign to each level a
specific color:






*# NN:>red=rgb(249/255, 21/255, 47/255)# YN:>amber=rgb(255/255, 126/255,
0/255)# YY:>green=rgb(39/255, 232/255, 51/255)*

Using bwplot function:


* >pl<-bwplot(mydata$Col1~mydata$Col3 |
mydata$Col2,data=mydata,ylab=expression(italic(R)),panel=function(...){panel.bwplot(...,groups=mydata$Col3,
fill=c(red,amber,green))})*

IF YOU REPRODUCE THE EXAMPLE YOU WILL SEE THAT THE COLORS ARE NOT RELATED
TO THE LEVELS IN MY DATAFRAME AS YY BOX IS NOT ALWAYS GREEN.

IS THERE A WAY TO ASSIGN YY:green, NN:red, YN:amber?

You can see the resulting figure in:
http://stackoverflow.com/questions/29802129/r-lattice-bwplot-fill-boxplots-with-specific-color-depending-on-factor-level

Thank you in advance!
Pablo

	[[alternative HTML version deleted]]


From ranjanmano167 at gmail.com  Wed Apr 22 12:43:33 2015
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Wed, 22 Apr 2015 11:43:33 +0100
Subject: [R] R_Calculating Thiessen weights for an area with irregular
	boundary
In-Reply-To: <5536D02E.4070001@auckland.ac.nz>
References: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>
	<5536D02E.4070001@auckland.ac.nz>
Message-ID: <CANqyHbQ4fyX5ULvBk0G0g3G6Ur4=avpYx9dgp1_s0NkuQ-WTZA@mail.gmail.com>

1. Apologies for the lousy presentation of the data and thank you for your
feedback. I promise it will not happen again.

2. Thank you

3. Yes, exactly!

4. Exactly what I wanted without much hassle. Thank you very much. Time to
explore the package 'spatstat'.
    How can I show the Dirichlet tile names (i.e. 1,2,3,....,8) in the plot?

Cheers,
Mano

On Tue, Apr 21, 2015 at 11:33 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> (1) The manner in which you presented your data was a total mess.
> If you ask for help, please have the courtesy to present your data in such
> a manner that a potential "helper" can access it without needing to do a
> great deal of editing and processing.  Like so:
>
> pts <- as.data.frame(matrix(c(415720,432795,415513,432834,415325,
>                               432740,415356,432847,415374,432858,
>                               415426,432774,415395,432811,415626,
>                               432762),ncol=2,byrow=TRUE))
> names(pts) <- c("x","y")
>
> bdry <- as.data.frame(matrix(c(415491,432947,415269,432919,415211,
>                                432776,415247,432657,415533,432657,
>                                415781,432677,415795,432836,415746,
>                                432937),ncol=2,byrow=TRUE))
> names(bdry) <- c("x","y")
>
> (2) Well, at least you presented a usable data set (even though the
> presentation was lousy) which is better than what most posters do.  And you
> asked a "partially" clear question.
>
> (3) I do not know what you mean by "Thiessen weights".  I am guessing that
> these are the areas of the Dirichlet tiles (Thiessen polygons), intersected
> with the "boundary polygon" (i.e. observation window).
>
> (4) If my guess is correct, the following should accomplish the desired
> task:
>
> require(spatstat) # You will (probably) need to install spatstat first.
> W <- owin(poly=bdry)
> X <- as.ppp(pts,W=W)
> plot(X) # Just to make sure it looks right.
> dX <- dirichlet(X)
> plot(dX) # Just to make sure .....
> sapply(tiles(dX),area.owin)
>
> HTH
>
> cheers,
>
> Rolf Turner
>
>
>
> On 22/04/15 02:50, Manoranjan Muthusamy wrote:
>
>  Hi R users,
>>
>> I want to calculate Thiessen weights to compute areal rainfall from number
>> of point measurements. I am using R and thanks to some previous question
>> in
>> the same topic, I got to know that I can usedeldir. But the problem is my
>> boundary polygon is not a rectangle; it's an irregular polygon (it's a
>> catchment boundary derived using ArcGIS). But in deldir the boundary can
>> only be a rectangle. Are there any other packages where I can calculate
>> Thiessen weights of an area covered by an irregular boundary?
>>
>> Given below are my measurement points (meas_points) and coordinates of a
>> (simplified) boundary polygon(boundary)
>>
>>  meas_points
>>>
>>            X      Y[1,] 415720 432795[2,] 415513 432834[3,] 415325
>> 432740[4,] 415356 432847[5,] 415374 432858[6,] 415426 432774[7,]
>> 415395 432811[8,] 415626 432762
>>
>>> boundary
>>>
>>            x      y[1,] 415491 432947[2,] 415269 432919[3,] 415211
>> 432776[4,] 415247 432657[5,] 415533 432657[6,] 415781 432677[7,]
>> 415795 432836[8,] 415746 432937
>>
>> Any help is really appreciated. Thanks.
>>
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
>

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Wed Apr 22 22:05:03 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 22 Apr 2015 16:05:03 -0400
Subject: [R]  converting Twitter data from txt file
Message-ID: <CACxE24mo7cRqaAPHYDRQUvntX_mWD+NL9NLGSk2qTW8TwHF0tA@mail.gmail.com>

Hello!

Someone gave me a text file of Twitter data to look at.  I've used the
twitter package to do the actual downloading and getting the data into nice
R form.

Is anyone familiar with a function to convert the twitter text into that
good form please?

Thanks,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Wed Apr 22 22:12:38 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 22 Apr 2015 13:12:38 -0700
Subject: [R] converting Twitter data from txt file
In-Reply-To: <CACxE24mo7cRqaAPHYDRQUvntX_mWD+NL9NLGSk2qTW8TwHF0tA@mail.gmail.com>
References: <CACxE24mo7cRqaAPHYDRQUvntX_mWD+NL9NLGSk2qTW8TwHF0tA@mail.gmail.com>
Message-ID: <CAP+bYWCCc-UMB84+Mjv=F985eDYB6Bq=O0UdqSokwsxD=azwSw@mail.gmail.com>

On 22 April 2015 at 13:05, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
>
> Someone gave me a text file of Twitter data to look at.  I've used the
> twitter package to do the actual downloading and getting the data into nice
> R form.
>
> Is anyone familiar with a function to convert the twitter text into that
> good form please?
>

Would it be possible to post a sample of this data? -- H

>
> Thanks,
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Wed Apr 22 23:06:17 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 22 Apr 2015 17:06:17 -0400
Subject: [R]  weird behavior when starting R-3.2.0 in Windows 8
Message-ID: <CACxE24n7x383_-im=cLRZ2KNcBL_LiJqRV9td7SGwAm3-NKE6g@mail.gmail.com>

Hello again!

First this afternoon, I attempted to install R-3.2.0 from source on Windows
8.  I thought it went fine.  Then when I tried to start it, it starts for a
second, and closes.

Ok.  I figured that I had done something wrong with the source
installation.  Now I just installed the binary.  But the exact same thing
happens!

Has anyone else run into this, please?  For what it's worth, all is well on
my Ubuntu 14.04.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Wed Apr 22 23:20:17 2015
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 22 Apr 2015 14:20:17 -0700
Subject: [R] Script to workflow conversion
Message-ID: <CAN_e6XsXoqptDj=24zQyKTnkefzStqN0-fWChCZaLSJ+UdX8GA@mail.gmail.com>

Dear Rxperts..

Sorry.. i don't have data for my query..

Is there a way that an R script can be converted to a workflow? or if not a
workflow, converted into a flowchart or anything close to that effect.


Regards,
Santosh

	[[alternative HTML version deleted]]


From ucfagls at gmail.com  Thu Apr 23 00:06:30 2015
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 22 Apr 2015 16:06:30 -0600
Subject: [R] Question on CCA and RDA analysis
In-Reply-To: <CANxP2S7CraFGnkYMdJLUFG6HdmSp5hdH=cX3TEdE7Vy=FHp5YQ@mail.gmail.com>
References: <CANxP2S7nU6V+Y05eQrPtfRjSrFtOhpFBT3TEg0oTvFyZH5fJfg@mail.gmail.com>
	<loom.20150410T233550-74@post.gmane.org>
	<CANxP2S7CraFGnkYMdJLUFG6HdmSp5hdH=cX3TEdE7Vy=FHp5YQ@mail.gmail.com>
Message-ID: <CAAHES9yaix0gDPzRvc7CVJ1Ygg9HCnE_ON-UD=i4DEgsoG7tuQ@mail.gmail.com>

You didn't look that hard...

Start with the Environmetrics Task View:

http://cran.r-project.org/web/views/Environmetrics.html

That might point you to the **vegan** pkg:

http://cran.r-project.org/web/packages/vegan/index.html

And that has a vignette on ordination which you might find useful.

I have been wondering if a blog post on such basic topics might be
worthwhile. Your email suggests perhaps it is. Once I'm done teaching I
will try to find some time to write some posts on these basic analyses.

HTH

G

On 10 April 2015 at 20:38, Luis Fernando Garc?a <luysgarcia at gmail.com>
wrote:

> Yeah,
>
>  The most useful example I found was this.
>
>  https://gist.github.com/perrygeo/7572735.
>
> I always had the idea of this kind of forums was to provide sources not so
> obvious in the web. If you have something better it would be great.
>
> 2015-04-10 18:36 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>
> > Luis Fernando Garc?a <luysgarcia <at> gmail.com> writes:
> >
> > >
> > > Dear R experts,
> > >
> > > I wanted to know if you can suggest me any website or tutorial just to
> > > learn about how to make a RDA or CDA in R
> > >
> > > Thanks in advance!
> >
> >   I hate to ask, but did you try Googling
> >
> > ""canonical correspondence analysis" R"
> >
> > ... ?
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From msuzen at gmail.com  Thu Apr 23 00:14:52 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 22 Apr 2015 23:14:52 +0100
Subject: [R] Multinomial Fitting Distrbution
In-Reply-To: <1091470601.1036823.1429602626805.JavaMail.yahoo@mail.yahoo.com>
References: <1091470601.1036823.1429602626805.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAPtbhHzkJVZNp9AKXc4JAUb1yP7MmR-OBNRHcvKPVKd=R-V9cg@mail.gmail.com>

mixtools package has mixture of Gaussian fitting, maybe that might help?


From msuzen at gmail.com  Thu Apr 23 00:17:08 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 22 Apr 2015 23:17:08 +0100
Subject: [R] Random Forest in Caret
In-Reply-To: <20150422102533.GC2554@localhost.localdomain>
References: <20150422102533.GC2554@localhost.localdomain>
Message-ID: <CAPtbhHx7APm_H8A8cs_SG5oni4sgwpBk0OuTEQbvxq-UxoyXUw@mail.gmail.com>

Can you post your memory profile and codes?


From r.turner at auckland.ac.nz  Thu Apr 23 01:02:57 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 23 Apr 2015 11:02:57 +1200
Subject: [R] R_Calculating Thiessen weights for an area with irregular
 boundary
In-Reply-To: <CANqyHbQ4fyX5ULvBk0G0g3G6Ur4=avpYx9dgp1_s0NkuQ-WTZA@mail.gmail.com>
References: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>	<5536D02E.4070001@auckland.ac.nz>
	<CANqyHbQ4fyX5ULvBk0G0g3G6Ur4=avpYx9dgp1_s0NkuQ-WTZA@mail.gmail.com>
Message-ID: <553828A1.4000904@auckland.ac.nz>

On 22/04/15 22:43, Manoranjan Muthusamy wrote:

<SNIP>

> 4. <SNIP>
>      How can I show the Dirichlet tile names (i.e. 1,2,3,....,8) in the
> plot?

There's no built-in way at the moment as far as I can tell.

One way to get the tiles to be labelled/numbered in the plot would be:

plot(dX)
text(X,labels=1:npoints(X))

Slightly sexier:

cents <- as.data.frame(t(sapply(tiles(dX),centroid.owin)))
plot(dX)
text(cents,labels=1:nrow(cents))

Is this satisfactory?

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From bioprogrammer at gmail.com  Thu Apr 23 01:30:17 2015
From: bioprogrammer at gmail.com (bioprogrammer)
Date: Wed, 22 Apr 2015 16:30:17 -0700
Subject: [R] Possible bug in CRAN mirror selection.
Message-ID: <07c4r3h2fltyok7ojscg0lkf.1429745417182@email.android.com>

Hi all.

Using R 3.2.0 on a WinXP machine, I attempted to update my installed packages. After selecting the nearest mirror, I was again prompted to select a mirror. This process repeated itself 2 additional times before I cancelled the most recent mirror selection thereby allowing the packages to download and install.

This seems to reflect a bug in the most recent version of R.

Thanks,

~Caitlin



Sent from my T-Mobile 4G LTE Device
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Apr 23 02:08:31 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 22 Apr 2015 20:08:31 -0400
Subject: [R] Script to workflow conversion
In-Reply-To: <CAN_e6XsXoqptDj=24zQyKTnkefzStqN0-fWChCZaLSJ+UdX8GA@mail.gmail.com>
References: <CAN_e6XsXoqptDj=24zQyKTnkefzStqN0-fWChCZaLSJ+UdX8GA@mail.gmail.com>
Message-ID: <CAN5YmCEUxiQzsLHmV+VMuyLpK=tYeKCMFHcaZhvE7hu1X-kvOA@mail.gmail.com>

Santosh,

I know nothing about this personally, but I found this site with an
internet search.
http://www.ef-prime.com/products/ranalyticflow_en/features.html

Jean

On Wed, Apr 22, 2015 at 5:20 PM, Santosh <santosh2005 at gmail.com> wrote:

> Dear Rxperts..
>
> Sorry.. i don't have data for my query..
>
> Is there a way that an R script can be converted to a workflow? or if not a
> workflow, converted into a flowchart or anything close to that effect.
>
>
> Regards,
> Santosh
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Thu Apr 23 03:26:22 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 23 Apr 2015 11:26:22 +1000
Subject: [R] R lattice bwplot: Fill boxplots with specific color
	depending on factor level
In-Reply-To: <CABggTg6LS4Txqh8CKofu4hJLd7wsGRv5iuBiY6ZbvXUeXfXjxA@mail.gmail.com>
References: <CABggTg6LS4Txqh8CKofu4hJLd7wsGRv5iuBiY6ZbvXUeXfXjxA@mail.gmail.com>
Message-ID: <000c01d07d64$82dfefe0$889fcfa0$@bigpond.com>

hi Pablo

set.seed(1) # for reproducibility of data.frame
mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))
mydata$Col2 <- factor(mydata$Col2)

In future please do not put * at end makes it harder to copy

red=rgb(249/255, 21/255, 47/255)
amber=rgb(255/255, 200/255,0/255) # amended to reveal a colour difference
green=rgb(39/255, 232/255, 51/255)

# As  Deepayan Sarkar said bwplot is different to others

bwplot(mydata$Col1~mydata$Col3 | mydata$Col2,data=mydata,
       groups = Col3,
       as.table = TRUE, # added to make it easier for factor levels
       layout = c(3,1), # looks nicer and easier to read 
       panel = panel.superpose,
       panel.groups = panel.bwplot,
       fill = c(red,amber,green)
)

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pablo
Fleurquin
Sent: Thursday, 23 April 2015 02:03
To: r-help at r-project.org
Subject: [R] R lattice bwplot: Fill boxplots with specific color depending
on factor level

Hi,

I thoroughly looked for an answer to this problem with no luck.

I have a dataframe with 3 factor levels: YY, NN, YN

*>mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))*

Being Col3 of factor type with 3 levels: NN YY YN

I want to make a boxplot using lattice bwplot and assign to each level a
specific color:






*# NN:>red=rgb(249/255, 21/255, 47/255)# YN:>amber=rgb(255/255, 126/255,
0/255)# YY:>green=rgb(39/255, 232/255, 51/255)*

Using bwplot function:


* >pl<-bwplot(mydata$Col1~mydata$Col3 |
mydata$Col2,data=mydata,ylab=expression(italic(R)),panel=function(...){panel
.bwplot(...,groups=mydata$Col3,
fill=c(red,amber,green))})*

IF YOU REPRODUCE THE EXAMPLE YOU WILL SEE THAT THE COLORS ARE NOT RELATED
TO THE LEVELS IN MY DATAFRAME AS YY BOX IS NOT ALWAYS GREEN.

IS THERE A WAY TO ASSIGN YY:green, NN:red, YN:amber?

You can see the resulting figure in:
http://stackoverflow.com/questions/29802129/r-lattice-bwplot-fill-boxplots-w
ith-specific-color-depending-on-factor-level

Thank you in advance!
Pablo

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Apr 23 04:08:41 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 23 Apr 2015 12:08:41 +1000
Subject: [R] high density plots using lattice dotplot()
In-Reply-To: <CAMk+s2RJYHEs1qvd3UDY1dhqqiRecUv6UiRzVcirX9yk9F7HRA@mail.gmail.com>
References: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>	<000001d07bc2$a73b7d30$f5b27790$@bigpond.com>	<CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>	<001101d07cbf$ac8ace00$05a06a00$@bigpond.com>
	<CAMk+s2RJYHEs1qvd3UDY1dhqqiRecUv6UiRzVcirX9yk9F7HRA@mail.gmail.com>
Message-ID: <001301d07d6a$6b938620$42ba9260$@bigpond.com>

Hi Luigi

Try

set.seed(1)

PLATE <-
data.frame(Delta.Rn = rnorm(500),
           Cycle = rnorm(500),
           Delta2 = rnorm(500)+1,
           Well  = rep(1:50, each = 10))
head(PLATE,10)

xyplot(Delta.Rn+Delta2 ~ Cycle | Well,
         data = subset(PLATE, Well %in% 1:49),
         allow.multiple = TRUE,
         ylab="Fluorescence (Delta Rn)",
         xlab="Cycles",
         main="TITLE",
         scales = list(
           x = list(draw = FALSE),
           y = list(draw = FALSE),
           relation="same",
           alternating=TRUE),
         as.table = TRUE,
         layout = c(10,5),
         par.settings = list(
           strip.background=list(col="white"),
           # layout.heights = list(strip = 0.8),
           axis.text = list(cex = 0.6),
           par.xlab.text = list(cex = 0.75),
           par.ylab.text = list(cex = 0.75),
           par.main.text = list(cex = 0.8),
           superpose.symbol = list(pch = ".", cex = 2,
                                   col = c(2,4) )
         ),
         strip    = FALSE,
         type = "p",
         key = list(text = list(label = c("Delta.Rn","Delta2")),
                    points = list(cex = 0.6, pch = 16, col = c(2,4)),
                    cex = 0.6,
                    x = 0.9,
                    y = 0.1),
         panel = panel.superpose,
         panel.groups = function(x,y,...){

                   panel.xyplot(x,y,... )

                   # text argument can be a vector of values not
                   # necessarily the group name
                   pnl = panel.number()  # needed as group.number if added is now either 1 or 2
                  
                   grid.text(c(LETTERS,letters)[pnl],
                             y = 0.93, x = 0.5,
                             default.units = "npc",
                             just = c("left", "bottom"),
                             gp = gpar(fontsize = 7) )

         }
  )

Remember to delete the group argument (I forgot to at first as the groups are now Delta.Rn Delta2)
You may have 1+ empty panels so put the legend there where ever it is just amend the x and y or fine tune them
you can have the pch = "." and increase cex but  it will become as square with large cex
Duncan


-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Thursday, 23 April 2015 10:05
To: Duncan Mackay
Subject: Re: [R] high density plots using lattice dotplot()

Dear Duncan,
sorry to come back so soon, but i wanted to ask you whether it would
be  possible to plot two sets of lines within each box, let's say a
main value A and a secondary value B. In normal plots I could use a
plot() followed by points(); what would be the strategy here?
Thank you again,
best regards,
Luigi


On Wed, Apr 22, 2015 at 6:46 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>
> Hi Luigi
>
> I should have made up an example to make things easier when I replied today
>
> This should get you going
>
> set.seed(1)
>
> PLATE <-
> data.frame(Delta.Rn = rnorm(500),
>            Cycle = rnorm(500),
>            Well  = rep(1:50, each = 10))
> head(PLATE)
>
> xyplot(Delta.Rn ~ Cycle | Well,
>          data = PLATE,
>          groups = Well,
>          ylab="Fluorescence (Delta Rn)",
>          xlab="Cycles",
>          main="TITLE",
>          scales = list(
>            x = list(draw = FALSE),
>            y = list(draw = FALSE),
>            relation="same",
>            alternating=TRUE),
>          as.table = TRUE,
>          layout = c(10,5),
>          par.settings = list(
>            strip.background=list(col="white"),
>            # layout.heights = list(strip = 0.8),
>            axis.text = list(cex = 0.6),
>            par.xlab.text = list(cex = 0.75),
>            par.ylab.text = list(cex = 0.75),
>           par.main.text = list(cex = 0.8)
>            superpose.symbol = list(pch = ".", cex = 2)
>          ),
>          strip    = FALSE,
>          type = "p",
>          col = 1,
>          panel = panel.superpose,
>          panel.groups = function(x,y,...,group.number){
>
>                    panel.xyplot(x,y,... )
>
>                    # text argument can be a vector of values not
>                    # necessarily the group name
>                    grid.text(c(LETTERS,letters)[group.number],
>                              y = 0.93, x = 0.5,
>                              default.units = "npc",
>                              just = c("left", "bottom"),
>                              gp = gpar(fontsize = 7) )
>
>          }
>   )
>
> You could use panel.text instead of grid.text
> Duncan
>
> -----Original Message-----
> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
> Sent: Wednesday, 22 April 2015 08:24
> To: Duncan Mackay
> Subject: Re: [R] high density plots using lattice dotplot()
>
> Dear Duncan,
> thank you for your reply. I tried to implement your suggestions but as
> is on your reply did not work (actually R crashed) and a slight
> elaboration returned the figure attached, which is essentially still
> displaying text and not drawing the data. Here is what I wrote:
>
> xyplot(Delta.Rn ~ Cycle | Well,
>          data = PLATE,
>          ylab="Fluorescence (Delta Rn)",
>          xlab="Cycles",
>          main=TITLE,
>          scales = list(
>            x = list(draw = FALSE),
>            y = list(draw = FALSE),
>            relation="same",
>            alternating=TRUE),
>          as.table = TRUE,
>          layout = c(24,16),
>          par.settings = list(
>            strip.background=list(col="white"),
>            axis.text = list(cex = 0.6),
>            par.xlab.text = list(cex = 0.75),
>            par.ylab.text = list(cex = 0.75),
>            superpose.symbol = list(pch = ".", cex = 2)
>          ),
>          strip    = FALSE,
>          type = "p",
>          layout.heights = list(strip = 0.8),
>          panel = function(x,y, subscripts, groups,...){
>            panel.superpose(x,y,subscripts,groups,...,
>                            col = ...)
>            panel.text(x,y,...,cex = 0.6)
>          }
>   )
>
>
> How can I improve the script?
> Many thanks
> Luigi
>
> On Tue, Apr 21, 2015 at 12:35 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> Hi Luigi
>>
>> Strips take up space so if you are willing to not have strip and put the
>> strip values within the plot area then
>>
>>       xyplot(y ~ x|cond.factor, data = ...,
>>              as.table = T,
>>              groups   = ...,
>>              layout   = ...,
>>              drop.unused = T,
>>              par.settings = list(axis.text = list(cex = 0.6),
>>                                  par.xlab.text = list(cex = 0.75),
>>                                  par.ylab.text = list(cex = 0.75)
>>                                  superpose.symbol = list(pch = ".", cex = 2)
>>                             ),
>>              strip    = FALSE,
>>              scales   = list(x = list(alternating = 2),
>>                              y = list(alternating = FALSE)
>>                              ),
>>              type = "p",
>>              panel = function(x,y, subscripts, groups,...){
>>                                 panel.superpose(x,y,subscripts,groups,...,
>> col = ...)
>>                                 panel.text(x,y,...,cex = 0.6)
>>                             }
>>       )
>>
>> if the text values are a vector
>>       stext = ...
>>       xyplot(y ~ x|cond.factor, data = ...,
>>              as.table = T,
>>              groups   = ...,
>>              layout   = ...,
>>              drop.unused = T,
>>              par.settings = list(axis.text = list(cex = 0.6),
>>                                  par.xlab.text = list(cex = 0.75),
>>                                  par.ylab.text = list(cex = 0.75)
>>                                  superpose.symbol = list(pch = ".", cex = 2)
>>                             ),
>>              strip    = FALSE,
>>              scales   = list(x = list(alternating = 2),
>>                              y = list(alternating = FALSE)
>>                              ),
>>              type = "p",
>>              panel = function(x,y, subscripts, groups,...){
>>                                pnl = panel.number()
>>                                 panel.superpose(x,y,subscripts,groups,...,
>> col = ...)
>>                                 panel.text(x,y,stext[pnl],cex = 0.6)
>>                             }
>>       )
>>
>> you could also you group.number instead of pnl if it is needed elsewhere.
>> text position could be done in a similar fashion if needed to be in
>> different places for some panels.
>>
>> If you require the strip then an additional par.settings is
>> layout.heights = list(strip = 0.8)
>> or even untested in this situation
>> strip = FALSE
>> strip.left  = TRUE
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>> Marongiu
>> Sent: Sunday, 19 April 2015 19:28
>> To: r-help
>> Subject: [R] high density plots using lattice dotplot()
>>
>> Dear all,
>> I am trying to plot the results of a PCR experiments that involves 384
>> individual plots. Admittedly the space for the plots will be tiny, but
>> I just nedd some icon to have a feeling of the layout of the
>> experiment and a quick comparison of the plots.
>> I believe that lattice would be the right tool, but when I tried to
>> implement i got an error. Specifically the output would be a A4 pdf,
>> so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
>> each plot; removing the labels that might just work.
>> So I have the y values = 'fluorescence', x 'values' = cycles and 384
>> 'well' data. I implemented to begin with:
>>
>> xyplot(fluorescence ~ cycles | well,
>>          ylab="Fluorescence",
>>          xlab="Cycles",
>>          main=list(draw = FALSE),
>>          scales = list(
>>            x = list(draw = FALSE),
>>            y = list(draw = FALSE),
>>            relation="same",
>>            alternating=TRUE),
>>          layout = c(24,16),
>>          par.settings = list(strip.background=list(col="white")),
>>          pch = "."
>>   )
>>
>> but the  the individual graphs show only the writing "data" instead of
>> the actual plots.
>> How can I overcome this error?
>> Thank you
>> Best regards
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From erinm.hodgess at gmail.com  Thu Apr 23 04:21:28 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 22 Apr 2015 22:21:28 -0400
Subject: [R]  Having trouble with twitter API
Message-ID: <CACxE24mfXTz_zr4eLLWF3nUUv9=EcXK9q-dcifsyr3qP2S_tzA@mail.gmail.com>

Hello one more time!

I'm switching over one of my packages from Ubuntu to Windows.

Part of it uses twitter data, as gathered by the twitteR program.

So this is what I have so far:

 library(twitteR)
library(ROAuth)
 requestURL <- "https://api.twitter.com/oauth/request_token"
   accessURL = "https://api.twitter.com/oauth/access_token"
 authURL = "https://api.twitter.com/oauth/authorize"
 library(RCurl)

I got my consumerKey and my consumerSecret from my Twitter developer's
account.

So I have:
Cred <- OAuthFactory$new(consumerKey=consumerKey,
+                              consumerSecret=consumerSecret,
+                           requestURL=requestURL,
+                           authURL=authURL)


Now the next thing is where everything goes wrong.

Cred$handshake(cainfo="cacert.pem")
To enable the connection, please direct your web browser to:
https://api.twitter.com/oauth/authorize?oauth_token=TgGQ1xBifkqusiYyyz34oVKYMcybb0rq
When complete, record the PIN given to you and provide it here: "0172575"
Error in function (type, msg, asError = TRUE)  :
  Could not resolve host: 

Cred$handshake(cainfo="cacert.pem")
To enable the connection, please direct your web browser to:
https://api.twitter.com/oauth/authorize?oauth_token=TgGQ1xBifkqusiYyyz34oVKYMcybb0rq
When complete, record the PIN given to you and provide it here: "0172575"
Error in function (type, msg, asError = TRUE)  :
  Could not resolve host: 


I have done this many times, but to no avail.  Sometimes I leave the quotes
off.  Sometimes I leave a space.  Nothing works.

Has anyone run into this before, please?

This is on R version 3-1.3, Windows 8.

thanks,
Erin




-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From Paul.Domaskis at gmail.com  Thu Apr 23 04:32:26 2015
From: Paul.Domaskis at gmail.com (Paul)
Date: Thu, 23 Apr 2015 02:32:26 +0000
Subject: [R] How numerical data is stored inside ts time series objects
References: <loom.20150421T010112-378@post.gmane.org>
	<CAF8bMcYcnNtDm=wBVY_E1dz40PzuCyhM7u9Vx3bwC6cvXeSB5g@mail.gmail.com>
	<loom.20150422T032037-943@post.gmane.org>
	<280E8F92-96E1-4C08-94B8-CC9F99068BAC@vims.edu>
Message-ID: <loom.20150423T043204-878@post.gmane.org>

William Dunlap <wdunlap <at> tibco.com> writes:
> I think we can call this a bug in stl().

I used what I learned from the responses to this thread, I looked at
the code for stl.  As they say in Microsoft, "this is expected
behaviour" according to the code.  And it doesn't look like an
inadvertent coding oversight.
-----------------------------------------------
Martin Maechler <maechler <at> lynne.stat.math.ethz.ch> writes:
>> Paul  <Paul.Domaskis <at> gmail.com> Interesting that a 2D matrix
>> of size Nx1 is treated as a different animal from a length N
>> vector.  It's a departure from math convention, and from what I'm
>> accustomed to in Matlab.
>
> The vector space  |R^n  is not all the same space as the space
> |R^{n x 1} even though of course there's a trivial mapping between
> the objects (and the metrics) of the two.  A vector *is NOT* a
> matrix -- but in some matrix calculus notations there is a
> convention to *treat* n-vectors as  (n x 1) matrices.
>
> Good linear algebra teaching does distinguish vectors from
> one-column or one-row matrices -- I'm sure still the case in all
> good math departments around the globe -- but maybe not in math
> teaching to engineers and others who only need applied math.  Yes,
> linear algebra teaching will also make a point that in the usual
> matrix product notations, it is convenient and useful to treat
> vectors as if they were 1-column matrices.

The distinction in math is new me, with academic training in
engineering, even at the post grad level.  I haven't seen the
distinction in the math for Comp. Sci., either, and that's in the meat
grinder of Canada.  Admittedly, it's not quite as geeky as some meat
grinders in other countries.  And admittedly, I only took C.S. courses
that were geared to applications.  So I had always considered such a
distinction to a practicality in coding implementation of
vector/matrix classes, e.g., in C, a vector being a single pointer to
a number, while in a 2D array is a pointer to a vector and hence a
different type.

>> That R's vector seems more akin to a list, where the notion of
>> orientation doesn't apply.
>
> Sorry, but again:  not at all in the sense 'list's are used in R.

No need to apologize.  To clarify, being new to R, I was referring to
the general use of the term "list".  Specifically, I was referring to
an ordered collection without orientation, so it is consistent with
what you say above about distinguishing between length N vectors vs.
2D matrices of size Nx1 or 1xN.

> Fortunately, well thought out languages such as S, R, Julia, Python,
> all do make a good distinction between vectors and matrices i.e. 1D
> and 2D arrays.  If Matlab still does not do that, it's just another
> sign that Matlab users should flee and start using julia or R or
> python.

Matlab pretty well only deals with 2D arrays, some of which have size
Nx1 or 1xN.  I haven't seen an example of a 1-D data structure that
doesn't have an orientation, implied or otherwise.  Though of course,
if someone proves me wrong, then I stand corrected (and smarter
because of it).

>  {and well yes, we could start bitchering about S' and hence R's
>  distinction between a 1D array and a vector ... which I think has
>  been a clear design error... but that's not the topic here}

Big fan of python's readability, though I've only dabbled.  And
I won't start bitchering about R & S cuz I'm a newcomer and it's all
an eye popping wonderland.
-----------------------------------------------
David R Forrest <drf <at> vims.edu> writes:
> The details of how str() represents your x and y variables is within
> the utils::stl.default() function.  You can hunt this down and see

I'm assuming that you meant utils.str.default() above.  I can follow
the rest of your post makes sense if I make that assumption.

I snipped the majority of your response because I'm not responding to
anything specific.  However, it was an extremely educational post.
Thank you for that.

> Also, Matlab sometimes needs a squeeze() to drop degenerate
> dimensions, and R's drop() is similar, and is less-black-magic
> looking than the [[1]] code:
>
> > str(drop(x))
>  Time-Series [1:36] from 1 to 3.92: 464 675 703 887 1139 1077 1318
>  1260 1120 963 ...
> > str(drop(y))
>  Time-Series [1:36] from 1 to 3.92: 464 675 703 887 1139 1077 1318
>  1260 1120 963 ...
>
> stl(drop(x),s.window='per')
> stl(drop(y),s.window='per')
>
> Maybe str.default() should do Time-Series interpretation of is.ts()
> objects for matrices as well as vectors.

I'm assuming that you mean stl(), since str() already works on both?
Maybe it's the version I have, however, but I find that the R code for
stl() doesn't have have a section for is.ts().  Instead, it seems to
run through a series of checks for pathological input, with the check
for matrix data consisting of is.matrix(na.action(as.ts(x))), where x
is the time series.  Somehow, the fact that the na.action(time series
argument) returns a matrix implies that the time series data is a
matrix rather than a vector.  In attempting to get insight, I found
that the ts class has no na.action method, and that the default method
for the generic na.action is not visible using getAnywhere (nor is it
visible by entering it at the command line without brackets).

Anyway, pretty educational.  Thanks again.


From rmh at temple.edu  Thu Apr 23 05:46:59 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 22 Apr 2015 23:46:59 -0400
Subject: [R] R lattice bwplot: Fill boxplots with specific color
 depending on factor level
In-Reply-To: <000c01d07d64$82dfefe0$889fcfa0$@bigpond.com>
References: <CABggTg6LS4Txqh8CKofu4hJLd7wsGRv5iuBiY6ZbvXUeXfXjxA@mail.gmail.com>
	<000c01d07d64$82dfefe0$889fcfa0$@bigpond.com>
Message-ID: <CAGx1TMADRbQOLcs_FvDi-CWUdQmB41GKCCCD+mbT6ve4J1yb0Q@mail.gmail.com>

Pablo,

I would do it similarly.  I would also place the box and whiskers in
the specified colors.

## install.packages(HH)  ## if you don't have it
library(HH)

bwplot(mydata$Col1~mydata$Col3 | mydata$Col2,data=mydata,
       groups = Col3,
       as.table = TRUE, # added to make it easier for factor levels
       layout = c(3,1), # looks nicer and easier to read
       panel = panel.bwplot.superpose,
       col = c(red,"darkorange",green),
       fill = c(red,"darkorange",green), fill.alpha=.6)

I changed your amber to "darkorange" as the amber lines are almost invisible.

Rich

On Wed, Apr 22, 2015 at 9:26 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> hi Pablo
>
> set.seed(1) # for reproducibility of data.frame
> mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
> each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
> rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))
> mydata$Col2 <- factor(mydata$Col2)
>
> In future please do not put * at end makes it harder to copy
>
> red=rgb(249/255, 21/255, 47/255)
> amber=rgb(255/255, 200/255,0/255) # amended to reveal a colour difference
> green=rgb(39/255, 232/255, 51/255)
>
> # As  Deepayan Sarkar said bwplot is different to others
>
> bwplot(mydata$Col1~mydata$Col3 | mydata$Col2,data=mydata,
>        groups = Col3,
>        as.table = TRUE, # added to make it easier for factor levels
>        layout = c(3,1), # looks nicer and easier to read
>        panel = panel.superpose,
>        panel.groups = panel.bwplot,
>        fill = c(red,amber,green)
> )
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pablo
> Fleurquin
> Sent: Thursday, 23 April 2015 02:03
> To: r-help at r-project.org
> Subject: [R] R lattice bwplot: Fill boxplots with specific color depending
> on factor level
>
> Hi,
>
> I thoroughly looked for an answer to this problem with no luck.
>
> I have a dataframe with 3 factor levels: YY, NN, YN
>
> *>mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
> each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
> rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))*
>
> Being Col3 of factor type with 3 levels: NN YY YN
>
> I want to make a boxplot using lattice bwplot and assign to each level a
> specific color:
>
>
>
>
>
>
> *# NN:>red=rgb(249/255, 21/255, 47/255)# YN:>amber=rgb(255/255, 126/255,
> 0/255)# YY:>green=rgb(39/255, 232/255, 51/255)*
>
> Using bwplot function:
>
>
> * >pl<-bwplot(mydata$Col1~mydata$Col3 |
> mydata$Col2,data=mydata,ylab=expression(italic(R)),panel=function(...){panel
> .bwplot(...,groups=mydata$Col3,
> fill=c(red,amber,green))})*
>
> IF YOU REPRODUCE THE EXAMPLE YOU WILL SEE THAT THE COLORS ARE NOT RELATED
> TO THE LEVELS IN MY DATAFRAME AS YY BOX IS NOT ALWAYS GREEN.
>
> IS THERE A WAY TO ASSIGN YY:green, NN:red, YN:amber?
>
> You can see the resulting figure in:
> http://stackoverflow.com/questions/29802129/r-lattice-bwplot-fill-boxplots-w
> ith-specific-color-depending-on-factor-level
>
> Thank you in advance!
> Pablo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cbbaniya at gmail.com  Thu Apr 23 05:49:17 2015
From: cbbaniya at gmail.com (Chitra Baniya)
Date: Thu, 23 Apr 2015 09:34:17 +0545
Subject: [R] vegan-help
Message-ID: <CAGu6_6jMJhg69NHkZURHqR9V5JOwZtTGccgLYzKKmZfu=2s_Lg@mail.gmail.com>

Hi,
Greetings from Nepal.
I am using

R version 3.1.3 (2015-03-09) -- "Smooth Sidewalk"

and

vegan 2.2-1


I have been using and teaching R to my students some years.
I am more used to with simple vegetation data sets. Now I am facing
difficulties to handle with temporal scale, site wise variation
data.
One of my colleagues had fish abundance and water chemistry data of
five sites for 4 years each site samled monthly.

Data with 5 sites x 4 years x 12 months.

I am searching such kind of data and analysis in vegan, but yet could
not get. If any of this list have any idea please with example where I can
look please provide me link I will be happy to
search and learn it.
Thank you in advance.

Chitra Baniya
Nepal

	[[alternative HTML version deleted]]


From kris.angelovski at solutionmetrics.com.au  Thu Apr 23 07:36:39 2015
From: kris.angelovski at solutionmetrics.com.au (Kris Angelovski)
Date: Thu, 23 Apr 2015 05:36:39 +0000
Subject: [R] R and S+ Courses: Sydney, Melbourne, Brisbane in May 2015
Message-ID: <SIXPR06MB0969BE56DC00623695B57273C5ED0@SIXPR06MB0969.apcprd06.prod.outlook.com>

Hi, (apologies for cross-posting)

SolutionMetrics is presenting R and S+ courses in Sydney, Melbourne & Brisbane -  May, 2015

To book, please email enquiries at solutionmetrics.com.au<mailto:enquiries at solutionmetrics.com.au> or call +61 2 9233 6888

Getting Started with R (1 Day)

Confidently use R for data analysis, graphics & reporting. Content includes introduction to R, Data objects & Classes, Data Import/Export, Data Manipulation, Graphics, Basic Statistical models, avoiding repetitive typing/clicking & file management. More Info<http://bit.ly/11qFxpO>

Date: 5 May, 2015 - Sydney (Tue)
          7 May, 2015 - Melbourne (Thu)
          12 May, 2015 - Brisbane (Tue)

Intermediate R (1 Day)

Efficient use of R language functions & objects, Big Data, Advanced Visualisations, Data Mining - Logistic Regression/Tree models. More Info<http://bit.ly/YBsT5b>

Date: 19 May, 2015 - Sydney (Tue)
          21 May, 2015 - Melbourne (Thu)
          26 May, 2015 - Brisbane (Tue)

Getting Started with S+ (1 Day)

Course provides users with the knowledge to perform all day to day data analysis & graphics tasks with just a click of a mouse (No Programming Required). Data objects & Classes, Data Import/Export, Data Manipulation, Graphics & Basic Statistical models - Regression. Course Outline<http://bit.ly/Xf8im1>

Date: 28 May, 2015 - Sydney (Thu)
       .
For more information, please email enquiries at solutionmetrics.com.au<mailto:enquiries at solutionmetrics.com.au> or call +61 2 9233 6888

Cheers
Kris Angelovski | Director| SolutionMetrics
T +61 2 9233 6888 | F +61 2 9233 4099
Suite 44, Level 9, 88 Pitt Street, Sydney NSW 2000
solutionmetrics.com.au<http://www.solutionmetrics.com.au/>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Apr 23 08:00:24 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 23 Apr 2015 02:00:24 -0400
Subject: [R] Suggest method
In-Reply-To: <421065f9064c43308fdea475e21fe08c@BLREXCHMBX001.TechMahindra.com>
References: <aa68dc648a4e459fb6c381f39401aa35@BLREXCHMBX001.TechMahindra.com>
	<62799E77-9CA2-42D7-BBCE-3E0A337E4248@utoronto.ca>
	<421065f9064c43308fdea475e21fe08c@BLREXCHMBX001.TechMahindra.com>
Message-ID: <12BA292F-9BCE-45CA-82CC-7A3DA138C431@utoronto.ca>

Please keep the conversation on the list ...

Here is a toy example to help you think this through:


set.seed(11235)

# artifical random data ...
# miles: normalized between 0 and 1
# flights: number of flights within last year
# since: how many days ago was the last flight booked
# score: just placeholder zeros for now
pList <- data.frame(miles=runif(100), 
                    flights=sample(0:12,100, replace=TRUE), 
                    since=sample(1:365, 100, replace=TRUE), 
                    score=0)
                    
# make up some weigthing scheme
fScore <- function(x) {
	m <- x[1]          # reward high number of miles
	f <- x[2]/3        # reward large number of flights
	s <- 10 / x[3]     # penalize if last flight was long ago
	return( m + f + s) # return score as sum of these factors
}

# calculate the scores and put the values into the data frame
pList$score <- apply(pList, MARGIN=1, FUN=fScore)

# Get the top three scoring passengers
pList[order(pList$score, decreasing=TRUE)[1:3], ]

        miles flights since    score
78 0.58376271       5     2 7.250429
94 0.01534421      12     7 5.443916
53 0.93216146      10    11 5.174586

# #78 flew very recently, #94 had lots of flights, #53 has lots of miles ...
# ... upgrade them to receive a free bag of peanuts each.


Note that the logic of selecting depends entirely on the way the score function is constructed. Clustering would not contribute anything useful.

That's as much as I'll write about this. This looks like a homework problem anyway and none of this is really an R problem.

B.  







On Apr 23, 2015, at 12:57 AM, Lalitha Kristipati <Lalitha.Kristipati at TechMahindra.com> wrote:

> Thanks for replying but how can i upgrade them from one level to another level. How to define a score?
> The attributes to  my use case are as follows:
> Customer name
> Distance travelled
> Status Credits
> Loyalty tier
> Usage characteristics
>  Based on the distance travelled, status credits, characteristics I need to cluster them. Then I can upgrade the passengers from one level to another level. But I don't know what method exactly need to follow .
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Wednesday, April 22, 2015 9:08 PM
> To: Lalitha Kristipati
> Cc: R-help at r-project.org
> Subject: Re: [R] Suggest method
> 
> That does not sound like a clustering problem at all since you already know the desired characteristics and are not trying to discover structure in your data. Simply define a score as a suitably weighted sum of individual features, order your passengers by that score, and pick the top few, or any that exceed a threshold etc.
> 
> Not really an R problem at this point though.
> 
> 
> B.
> 
> On Apr 22, 2015, at 12:54 AM, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:
> 
>> Hi,
>> 
>> I want to do a use case in R language. My problem statement is to upgrade the passengers from one membership level to another membership level in airlines based on their characteristics. It is like customer profiling based on their usage characteristics. Suggest a method that intakes a large amount of data and cluster them based on their characteristics and helps in knowing the passengers who are upgraded to another level .
>> Any help is appreciated.
>> 
>> Regards,
>> Lalitha Kristipati
>> Associate Software Engineer
>> 
>> 
>> 
>> ======================================================================
>> ======================================================
>> Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
>> ======================================================================
>> ======================================================
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ============================================================================================================================
> Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
> ============================================================================================================================
> 


From phaedrusv at gmail.com  Thu Apr 23 08:45:56 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Thu, 23 Apr 2015 07:45:56 +0100
Subject: [R] Warning message when starting RStudio
Message-ID: <55389524.4070008@gmail.com>

Hi list

Recently, when starting up RStudio, the following warning is being 
displayed:

"Error in tools:::httpdPort <= 0L :
  comparison (4) is possible only for atomic and list types"

I think that this is specific to RStudio because starting R in a 
terminal window doesn't produce this message.

Does anyone have an idea on how to clear the conditions that are giving 
rise to this warning?

Many thanks
Sun


From bhh at xs4all.nl  Thu Apr 23 09:57:20 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 23 Apr 2015 09:57:20 +0200
Subject: [R] Warning message when starting RStudio
In-Reply-To: <55389524.4070008@gmail.com>
References: <55389524.4070008@gmail.com>
Message-ID: <1F16A9E7-28F6-404E-8E7E-421C0B7C3D98@xs4all.nl>


> On 23-04-2015, at 08:45, Sun Shine <phaedrusv at gmail.com> wrote:
> 
> Hi list
> 
> Recently, when starting up RStudio, the following warning is being displayed:
> 
> "Error in tools:::httpdPort <= 0L :
> comparison (4) is possible only for atomic and list types"
> 
> I think that this is specific to RStudio because starting R in a terminal window doesn't produce this message.
> 
> Does anyone have an idea on how to clear the conditions that are giving rise to this warning?
> 

Not me.
But this doesn?t belong here. You should post on a Rstudio forum.

Berend

> Many thanks
> Sun
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Joachim.Audenaert at pcsierteelt.be  Thu Apr 23 11:57:56 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Thu, 23 Apr 2015 11:57:56 +0200
Subject: [R] - Obtaining superscripts to affix to means that are not
 significantly different from each other with R
Message-ID: <OF08D24A2A.37A9F44A-ONC1257E30.00366C83-C1257E30.0036BE89@pcsierteelt.be>

Hello all,

It is often time consuming to interpret p-values of multiple pairwise 
comparisons of groups and assign them a letter code for publication 
purposes. So I found this interesting link to a program that does this for 
you. 

http://www.jerrydallal.com/lhsp/similar.htm

I was wondering if something similar exists in R?


Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be   

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!
	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Thu Apr 23 12:06:36 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 23 Apr 2015 06:06:36 -0400
Subject: [R] geom_errorbar() issue in ggplot2
Message-ID: <CAAyVsXJBpEhUFrTFTqEOOsh6t49U=GJhFhiS_GcxY2t=6r=ffA@mail.gmail.com>

Hello,

I'm getting a warning message from the reproducible example below.

Why would geom_errorbar() remove 2 cases in this case? Both upper and lower
limits of the error bar contain var1 and are within the axis limits.


df <- data.frame(var1 = seq(0, 1, 0.1), var2 = seq(0, 1, 0.1))
df$ll <- ifelse(df$var1 == 0, 0, df$var1 - 0.05)
df$ul <- ifelse(df$var1 == 1, 1, df$var1 + 0.05)
pp1 <- ggplot(data = df,
            aes(x = var2, y = var1)) +
            geom_line() + geom_point() +
            scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
            scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
pp1
pp2 <- pp1 + geom_errorbar(data=df,
              aes(ymin=ll,ymax=ul), width=0.02)
pp2
Warning message:
In loop_apply(n, do.ply) :
  Removed 2 rows containing missing values (geom_path).
>

Thanks for any pointers.

Best,
Axel.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Apr 23 12:17:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Apr 2015 12:17:30 +0200
Subject: [R] geom_errorbar() issue in ggplot2
In-Reply-To: <CAAyVsXJBpEhUFrTFTqEOOsh6t49U=GJhFhiS_GcxY2t=6r=ffA@mail.gmail.com>
References: <CAAyVsXJBpEhUFrTFTqEOOsh6t49U=GJhFhiS_GcxY2t=6r=ffA@mail.gmail.com>
Message-ID: <CAJuCY5x8paP=gX2qzWrNBVm958c=Xe0g6bHFXNy-hBRv=PA++Q@mail.gmail.com>

The limits are more narrow than the data. ggplot2 treats data outside the
limits as NA.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-23 12:06 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:

> Hello,
>
> I'm getting a warning message from the reproducible example below.
>
> Why would geom_errorbar() remove 2 cases in this case? Both upper and lower
> limits of the error bar contain var1 and are within the axis limits.
>
>
> df <- data.frame(var1 = seq(0, 1, 0.1), var2 = seq(0, 1, 0.1))
> df$ll <- ifelse(df$var1 == 0, 0, df$var1 - 0.05)
> df$ul <- ifelse(df$var1 == 1, 1, df$var1 + 0.05)
> pp1 <- ggplot(data = df,
>             aes(x = var2, y = var1)) +
>             geom_line() + geom_point() +
>             scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
>             scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
> pp1
> pp2 <- pp1 + geom_errorbar(data=df,
>               aes(ymin=ll,ymax=ul), width=0.02)
> pp2
> Warning message:
> In loop_apply(n, do.ply) :
>   Removed 2 rows containing missing values (geom_path).
> >
>
> Thanks for any pointers.
>
> Best,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Thu Apr 23 12:23:22 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 23 Apr 2015 06:23:22 -0400
Subject: [R] geom_errorbar() issue in ggplot2
In-Reply-To: <CAJuCY5x8paP=gX2qzWrNBVm958c=Xe0g6bHFXNy-hBRv=PA++Q@mail.gmail.com>
References: <CAAyVsXJBpEhUFrTFTqEOOsh6t49U=GJhFhiS_GcxY2t=6r=ffA@mail.gmail.com>
	<CAJuCY5x8paP=gX2qzWrNBVm958c=Xe0g6bHFXNy-hBRv=PA++Q@mail.gmail.com>
Message-ID: <CAAyVsX+78_vfiGz2Nu0=fVZ4G7R0CYYMm+yLevZaTBrHEK5KPg@mail.gmail.com>

Thanks Thierry. So if a variable x = a, and the limits for x are [a, a+b],
is that data point considered outside the limits?

Thanks,
Axel.

On Thu, Apr 23, 2015 at 6:17 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> The limits are more narrow than the data. ggplot2 treats data outside the
> limits as NA.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-23 12:06 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
>
>> Hello,
>>
>> I'm getting a warning message from the reproducible example below.
>>
>> Why would geom_errorbar() remove 2 cases in this case? Both upper and
>> lower
>> limits of the error bar contain var1 and are within the axis limits.
>>
>>
>> df <- data.frame(var1 = seq(0, 1, 0.1), var2 = seq(0, 1, 0.1))
>> df$ll <- ifelse(df$var1 == 0, 0, df$var1 - 0.05)
>> df$ul <- ifelse(df$var1 == 1, 1, df$var1 + 0.05)
>> pp1 <- ggplot(data = df,
>>             aes(x = var2, y = var1)) +
>>             geom_line() + geom_point() +
>>             scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
>> +
>>             scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
>> pp1
>> pp2 <- pp1 + geom_errorbar(data=df,
>>               aes(ymin=ll,ymax=ul), width=0.02)
>> pp2
>> Warning message:
>> In loop_apply(n, do.ply) :
>>   Removed 2 rows containing missing values (geom_path).
>> >
>>
>> Thanks for any pointers.
>>
>> Best,
>> Axel.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Apr 23 13:07:13 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Apr 2015 13:07:13 +0200
Subject: [R] geom_errorbar() issue in ggplot2
In-Reply-To: <CAAyVsX+78_vfiGz2Nu0=fVZ4G7R0CYYMm+yLevZaTBrHEK5KPg@mail.gmail.com>
References: <CAAyVsXJBpEhUFrTFTqEOOsh6t49U=GJhFhiS_GcxY2t=6r=ffA@mail.gmail.com>
	<CAJuCY5x8paP=gX2qzWrNBVm958c=Xe0g6bHFXNy-hBRv=PA++Q@mail.gmail.com>
	<CAAyVsX+78_vfiGz2Nu0=fVZ4G7R0CYYMm+yLevZaTBrHEK5KPg@mail.gmail.com>
Message-ID: <CAJuCY5wjsoE9peufyUwUaxM-b67=jnn3D-3qVmZ6TrZs6CVChA@mail.gmail.com>

In this case the horizontal lines of the errorbars go output the limits.
And are therefore not displayed. Use coord_cartesian(xlim = 0:1) instead of
setting the limits in scale_x_continuous().

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-23 12:23 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:

> Thanks Thierry. So if a variable x = a, and the limits for x are [a, a+b],
> is that data point considered outside the limits?
>
> Thanks,
> Axel.
>
> On Thu, Apr 23, 2015 at 6:17 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> The limits are more narrow than the data. ggplot2 treats data outside the
>> limits as NA.
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-04-23 12:06 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
>>
>>> Hello,
>>>
>>> I'm getting a warning message from the reproducible example below.
>>>
>>> Why would geom_errorbar() remove 2 cases in this case? Both upper and
>>> lower
>>> limits of the error bar contain var1 and are within the axis limits.
>>>
>>>
>>> df <- data.frame(var1 = seq(0, 1, 0.1), var2 = seq(0, 1, 0.1))
>>> df$ll <- ifelse(df$var1 == 0, 0, df$var1 - 0.05)
>>> df$ul <- ifelse(df$var1 == 1, 1, df$var1 + 0.05)
>>> pp1 <- ggplot(data = df,
>>>             aes(x = var2, y = var1)) +
>>>             geom_line() + geom_point() +
>>>             scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1,
>>> 0.1)) +
>>>             scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
>>> pp1
>>> pp2 <- pp1 + geom_errorbar(data=df,
>>>               aes(ymin=ll,ymax=ul), width=0.02)
>>> pp2
>>> Warning message:
>>> In loop_apply(n, do.ply) :
>>>   Removed 2 rows containing missing values (geom_path).
>>> >
>>>
>>> Thanks for any pointers.
>>>
>>> Best,
>>> Axel.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From samarvir1996 at gmail.com  Thu Apr 23 13:36:41 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Thu, 23 Apr 2015 17:06:41 +0530
Subject: [R] Selecting cell values with XLSX package
Message-ID: <CAOpgo6gbtb8be4iNY6AwH2q5qQ0iydfbta=8Nw5fbWremNyuVQ@mail.gmail.com>

Hello,

I am working with some 2700 files in .xlsx format
Like the one attached below

I want to transform all tabular data to a single row as shown below in
example or in attachment
so that all data can be used as a variable.
and replicate all to make a single csv file which has all the data

EXAMPLE

  company SALE-9 SALE-8 SALE-7 SALE-6 SALE-5 SALE-4 SALE-3 SALE-2 SALE-1
SALE op-9  MARUTI SUZUKI INDIA LIMITED 11046.3 12197.9 14806.4 18066.8
20729.4 29317.7 36618.4 35587.1 43587.9 43700.6 1570.3  Nextcompany name ?

Thanks for your help. help me however you can.
 Really appreciate you taking the time.
please see the attachment. thank you.
I would love to share the findings, Whatever I can find.
P.S - every file is of same format

 thank you.

From Keith.Jewell at campdenbri.co.uk  Thu Apr 23 14:01:23 2015
From: Keith.Jewell at campdenbri.co.uk (Keith.Jewell at campdenbri.co.uk)
Date: Thu, 23 Apr 2015 12:01:23 +0000
Subject: [R] Hmisc::rcorr inconsistency?
Message-ID: <5F22AFBADFE10342ABECF0281DE99218181393B2@EXCH001.campden.co.uk>

(Copied to maintainer)

I'm not going to say there's an error in such an established and respected package but I think there's an inconsistency between the help text and the example:

> ?rcorr
   <snip>
Value
   <snip>
The diagonals of n are the number of non-NAs for the single variable corresponding to that row and column.

> example(rcorr)
   <snip>
rcorr> z <- c(1,   2, 3, 4, NA)  # number of non-NAs for z = 4
   <snip>
n
  x y z v
x 5 5 4 5
y 5 5 4 5
z 4 4 5 4  # diagonal for z = 5
v 5 5 4 5

Is this an error in the documentation or the code?
Or am I misunderstanding something?

Keith Jewell ?Statistics Group
Campden BRI Group
www.campdenbri.co.uk

________________________________

The information in this document and attachments is given after the exercise of all reasonable care and skill in its compilation, preparation and issue, but is provided without liability in its application or use. It may contain privileged information that is exempt from disclosure by law and may be confidential. If you are not the intended recipient you must not copy, distribute or take any action in reliance on it. If you have received this document in error please notify us and delete this message from your system immediately.

Unless otherwise expressly agreed in writing and signed by a duly authorised representative of Campden BRI, all goods & services procured and provided by Campden BRI shall be subject to our relevant Standard Terms and Conditions copies of which are available on request or can be downloaded from our website at http://www.campdenbri.co.uk/campdenbri/terms.php

? In the event of supplying technical services, such services shall be subject to Campden BRI Standard Terms and Conditions of Supply of Goods/Services.

? In the event of supplying training, conferences, seminars and events, such services shall be subject to Campden BRI Standard Terms and Condition for the Supply of Training including Conferences, Seminars and Events.

? In the event of our procurement of goods and services, such goods and services shall be provided subject to Campden BRI Standard Terms and Conditions of Purchase of Goods and/or Services.

Companies (trading) within the Campden BRI Group:
Campden BRI (private company limited by guarantee, registered number 510618)
Campden BRI (Chipping Campden) Limited (private company limited by shares, registered number 3836922)
Campden BRI (Nutfield) (private company limited by guarantee, registered number 2690377)

All companies are registered in England and Wales with the registered office at Station Road, Chipping Campden, Gloucestershire, GL55 6LD.

The Campden BRI Group may monitor e-mail traffic data and also the content of e-mail for the purposes of security and staff training.

____________________________________________________________
This e-mail has been scanned for all viruses by MessageLabs.
____________________________________________________________

From drjimlemon at gmail.com  Thu Apr 23 14:09:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 23 Apr 2015 22:09:27 +1000
Subject: [R] Selecting cell values with XLSX package
In-Reply-To: <CAOpgo6gbtb8be4iNY6AwH2q5qQ0iydfbta=8Nw5fbWremNyuVQ@mail.gmail.com>
References: <CAOpgo6gbtb8be4iNY6AwH2q5qQ0iydfbta=8Nw5fbWremNyuVQ@mail.gmail.com>
Message-ID: <CA+8X3fXgucwsjtc1kAmbLi_WF0g9KrqB7o9uFLkN03AXVxwYKA@mail.gmail.com>

Hi samarvir,
Your attachment didn't make it through the list filter. From your
example, you seem to want something like this:

# assume you are using the readxl package to read the data in
mydf<-read_excel("mydata.xlsx",col_types=rep("character",11))
mydatavector<-as.vector(as.matrix(mydf))

This is probably not what you need, as each spreadsheet file will be
turned into a long vector of character (string) values. What you
probably should think of is reading in the spreadsheets:

mydf1<-read_excel("mydata1.xlsx")
mydf2...

and merging the resulting data frames. With that many data files, you
will probably have to do this in stages.

Jim


On Thu, Apr 23, 2015 at 9:36 PM, samarvir singh <samarvir1996 at gmail.com> wrote:
> Hello,
>
> I am working with some 2700 files in .xlsx format
> Like the one attached below
>
> I want to transform all tabular data to a single row as shown below in
> example or in attachment
> so that all data can be used as a variable.
> and replicate all to make a single csv file which has all the data
>
> EXAMPLE
>
>   company SALE-9 SALE-8 SALE-7 SALE-6 SALE-5 SALE-4 SALE-3 SALE-2 SALE-1
> SALE op-9  MARUTI SUZUKI INDIA LIMITED 11046.3 12197.9 14806.4 18066.8
> 20729.4 29317.7 36618.4 35587.1 43587.9 43700.6 1570.3  Nextcompany name ?
>
> Thanks for your help. help me however you can.
>  Really appreciate you taking the time.
> please see the attachment. thank you.
> I would love to share the findings, Whatever I can find.
> P.S - every file is of same format
>
>  thank you.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From albin.blaschka at standortsanalyse.net  Thu Apr 23 14:41:31 2015
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Thu, 23 Apr 2015 14:41:31 +0200
Subject: [R] Warning message when starting RStudio
In-Reply-To: <1F16A9E7-28F6-404E-8E7E-421C0B7C3D98@xs4all.nl>
References: <55389524.4070008@gmail.com>
	<1F16A9E7-28F6-404E-8E7E-421C0B7C3D98@xs4all.nl>
Message-ID: <5538E87B.1080009@standortsanalyse.net>

Hello

Am 23.04.2015 um 09:57 schrieb Berend Hasselman:
>
>> On 23-04-2015, at 08:45, Sun Shine <phaedrusv at gmail.com> wrote:
>>
>> Hi list
>>
>> Recently, when starting up RStudio, the following warning is being displayed:
>>
>> "Error in tools:::httpdPort <= 0L :
>> comparison (4) is possible only for atomic and list types"
>>
>> I think that this is specific to RStudio because starting R in a terminal window doesn't produce this message.
>>
>> Does anyone have an idea on how to clear the conditions that are giving rise to this warning?

Upgrade R-Studio, it is a problem in the interaction between R and 
R-Studio, which was solved with the new version of R-Studio... I had the 
same problem...

HTH,
Albin


-- 
| Dr.rer.nat. Albin Blaschka
| Etrichstrasse 26, A-5020 Salzburg
| * www.albinblaschka.info *
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From marongiu.luigi at gmail.com  Thu Apr 23 14:50:01 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 23 Apr 2015 13:50:01 +0100
Subject: [R] create function to plot high density data using lattice
Message-ID: <CAMk+s2RMuTsN_4LctF1c0zgEuBOuj2Xm0a-Z9Z-cW6D59-KPLw@mail.gmail.com>

Dear all,
with the most useful help of Duncan I updated a script to plot high
density data in the form of 384 squares containing tiny plots. The
function works and it is possible to create a pdf version of the
output. but when i try to make a function out of this script, the
resulting pdf file is empty.
Any tips?
Thank you and best regards,
Luigi


 >>> here is the example:


DF <-  data.frame(Y = rnorm(17280),
             X = rnorm(1:45),
             Y2 = rnorm(17280)+2,
             Z  = 1:384)
plot.layout <- function(DF) {

# this works from here...
pdf(
  file = "TITLE-amp outlook.pdf",
  width = 15,
  height = 11,
  onefile = TRUE,
  family = "Helvetica",
  paper = "a4r"
)
xyplot(Y ~ X | Z,
       data = DF,
       groups = Z,
       allow.multiple = TRUE,
       ylab= "Y VALUES",
       xlab="X VALUES",
       main="TITLE",
       scales = list(
         x = list(draw = FALSE),
         y = list(draw = FALSE),
         relation="same",
         alternating=TRUE),
       as.table = TRUE,
       layout = c(24,16),
       par.settings = list(
         strip.background=list(col="white"),
         axis.text = list(cex = 0.6),
         par.xlab.text = list(cex = 0.75),
         par.ylab.text = list(cex = 0.75),
         par.main.text = list(cex = 0.8),
         superpose.symbol = list(type = "l", cex = 1)
       ),
       strip    = FALSE,
       type = "l",
       col = 3,
       panel = panel.superpose
)
dev.off()
#... till here

}
plot.layout(DF)


From dcarlson at tamu.edu  Thu Apr 23 14:51:34 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 23 Apr 2015 12:51:34 +0000
Subject: [R] - Obtaining superscripts to affix to means that are not
 significantly different from each other with R
In-Reply-To: <OF08D24A2A.37A9F44A-ONC1257E30.00366C83-C1257E30.0036BE89@pcsierteelt.be>
References: <OF08D24A2A.37A9F44A-ONC1257E30.00366C83-C1257E30.0036BE89@pcsierteelt.be>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68680B@mb02.ads.tamu.edu>

The function cld() in package multcomp generates compact letter displays, but does not format them as exponents of the group names.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim Audenaert
Sent: Thursday, April 23, 2015 4:58 AM
To: r-help at r-project.org
Subject: [R] - Obtaining superscripts to affix to means that are not significantly different from each other with R

Hello all,

It is often time consuming to interpret p-values of multiple pairwise 
comparisons of groups and assign them a letter code for publication 
purposes. So I found this interesting link to a program that does this for 
you. 

http://www.jerrydallal.com/lhsp/similar.htm

I was wondering if something similar exists in R?


Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be   

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!
	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Thu Apr 23 15:01:05 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Thu, 23 Apr 2015 13:01:05 +0000
Subject: [R] problem setting default timezone
Message-ID: <0765308CD028654885F30322557308D81EE2EC23@NYCSM0208.rth.ad.rothschild.com>

Dear All,

I would like to learn the proper way to set the default time zone so I get the correct date for my files.  The code below is non-reproducible (sorry) because it is based on a file on my system, but I hope someone will be able to help me anyway.

I have a file that was last modified on 4/21/2015:

> file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime
[1] "2015-04-21 20:26:33 EDT"

When I convert that to a date, I gives me 2015-04-22.  I read about timezones and saw that there are two possible places to set the default values: One as a system variable and one as an option.  To be safe I set both:

>     Sys.setenv(TZ='America/New_York')
>     Sys.getenv("TZ")
[1] "America/New_York"
>     options(tz='America/New_York')
>     getOption("tz")
[1] "America/New_York"
>     as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime)
[1] "2015-04-22"

But as you can see R still gives me the wrong date.  I can get the correct date as follows:

>     as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime, tz='America/New_York')
[1] "2015-04-21"

But my question is why is the as.Date function not using the timezone I have set?

Thank you in advance,
Roger


***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



From Joachim.Audenaert at pcsierteelt.be  Thu Apr 23 15:02:44 2015
From: Joachim.Audenaert at pcsierteelt.be (Joachim Audenaert)
Date: Thu, 23 Apr 2015 15:02:44 +0200
Subject: [R] - Obtaining superscripts to affix to means that are not
 significantly different from each other with R
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68680B@mb02.ads.tamu.edu>
References: <OF08D24A2A.37A9F44A-ONC1257E30.00366C83-C1257E30.0036BE89@pcsierteelt.be>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68680B@mb02.ads.tamu.edu>
Message-ID: <OF8860DA7E.2E8F2BA1-ONC1257E30.00478D42-C1257E30.0047A99B@pcsierteelt.be>

Is there also a version for non parametric tests like: 

pairwise.wilcox.test {stats} 



Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 



From:   David L Carlson <dcarlson at tamu.edu>
To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>, 
"r-help at r-project.org" <r-help at r-project.org>
Date:   23/04/2015 14:51
Subject:        RE: [R] - Obtaining superscripts to affix to means that 
are not significantly different from each other with R



The function cld() in package multcomp generates compact letter displays, 
but does not format them as exponents of the group names.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim 
Audenaert
Sent: Thursday, April 23, 2015 4:58 AM
To: r-help at r-project.org
Subject: [R] - Obtaining superscripts to affix to means that are not 
significantly different from each other with R

Hello all,

It is often time consuming to interpret p-values of multiple pairwise 
comparisons of groups and assign them a letter code for publication 
purposes. So I found this interesting link to a program that does this for 

you. 

http://www.jerrydallal.com/lhsp/similar.htm

I was wondering if something similar exists in R?


Met vriendelijke groeten - With kind regards,

Joachim Audenaert 
onderzoeker gewasbescherming - crop protection researcher

PCS | proefcentrum voor sierteelt - ornamental plant research

Schaessestraat 18, 9070 Destelbergen, Belgi?
T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be 

Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 

keep it on the screen!
                 [[alternative HTML version deleted]]




Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het 
PCS op LinkedIn
Disclaimer | Please consider the environment before printing. Think green, 
keep it on the screen!

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Apr 23 15:15:02 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 23 Apr 2015 09:15:02 -0400
Subject: [R] reshape data frame when one column has unequal number of entries
Message-ID: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>

Hello!

I have my data frame x with 2 character columns:

x <- data.frame(a = numeric(), b = I(list()))
x[1:3,"a"] = 1:3
x[[1, "b"]] <- "a, b, c"
x[[2, "b"]] <- "d, e"
x[[3, "b"]] <- "f"
x$a = as.character(x$a)
x$b = as.character(x$b)
x
str(x)

I need to produce this data frame:

1  a
1  b
1  c
2  d
2  e
3  f

Is it possible without looping?
Thank you!


-- 
Dimitri Liakhovitski


From lists at dewey.myzen.co.uk  Thu Apr 23 15:17:30 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 23 Apr 2015 14:17:30 +0100
Subject: [R] create function to plot high density data using lattice
In-Reply-To: <CAMk+s2RMuTsN_4LctF1c0zgEuBOuj2Xm0a-Z9Z-cW6D59-KPLw@mail.gmail.com>
References: <CAMk+s2RMuTsN_4LctF1c0zgEuBOuj2Xm0a-Z9Z-cW6D59-KPLw@mail.gmail.com>
Message-ID: <5538F0EA.9020302@dewey.myzen.co.uk>

I suspect Luigi that if you wrap the call to xyplot in print(      ) 
matters might be improved.

On 23/04/2015 13:50, Luigi Marongiu wrote:
> Dear all,
> with the most useful help of Duncan I updated a script to plot high
> density data in the form of 384 squares containing tiny plots. The
> function works and it is possible to create a pdf version of the
> output. but when i try to make a function out of this script, the
> resulting pdf file is empty.
> Any tips?
> Thank you and best regards,
> Luigi
>
>
>   >>> here is the example:
>
>
> DF <-  data.frame(Y = rnorm(17280),
>               X = rnorm(1:45),
>               Y2 = rnorm(17280)+2,
>               Z  = 1:384)
> plot.layout <- function(DF) {
>
> # this works from here...
> pdf(
>    file = "TITLE-amp outlook.pdf",
>    width = 15,
>    height = 11,
>    onefile = TRUE,
>    family = "Helvetica",
>    paper = "a4r"
> )
> xyplot(Y ~ X | Z,
>         data = DF,
>         groups = Z,
>         allow.multiple = TRUE,
>         ylab= "Y VALUES",
>         xlab="X VALUES",
>         main="TITLE",
>         scales = list(
>           x = list(draw = FALSE),
>           y = list(draw = FALSE),
>           relation="same",
>           alternating=TRUE),
>         as.table = TRUE,
>         layout = c(24,16),
>         par.settings = list(
>           strip.background=list(col="white"),
>           axis.text = list(cex = 0.6),
>           par.xlab.text = list(cex = 0.75),
>           par.ylab.text = list(cex = 0.75),
>           par.main.text = list(cex = 0.8),
>           superpose.symbol = list(type = "l", cex = 1)
>         ),
>         strip    = FALSE,
>         type = "l",
>         col = 3,
>         panel = panel.superpose
> )
> dev.off()
> #... till here
>
> }
> plot.layout(DF)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From john.archie.mckown at gmail.com  Thu Apr 23 15:21:29 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 23 Apr 2015 08:21:29 -0500
Subject: [R] problem setting default timezone
In-Reply-To: <0765308CD028654885F30322557308D81EE2EC23@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EE2EC23@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAAJSdjjETVYqKuEzVqM-NcydU1vobLuO1VaV=tj_=w4v0Au_tg@mail.gmail.com>

On Thu, Apr 23, 2015 at 8:01 AM, Bos, Roger <roger.bos at rothschild.com>
wrote:

> Dear All,
>
> I would like to learn the proper way to set the default time zone so I get
> the correct date for my files.  The code below is non-reproducible (sorry)
> because it is based on a file on my system, but I hope someone will be able
> to help me anyway.
>
> I have a file that was last modified on 4/21/2015:
>
> > file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime
> [1] "2015-04-21 20:26:33 EDT"
>
> When I convert that to a date, I gives me 2015-04-22.  I read about
> timezones and saw that there are two possible places to set the default
> values: One as a system variable and one as an option.  To be safe I set
> both:
>
> >     Sys.setenv(TZ='America/New_York')
> >     Sys.getenv("TZ")
> [1] "America/New_York"
> >     options(tz='America/New_York')
> >     getOption("tz")
> [1] "America/New_York"
> >     as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+%
> ".txt")$mtime)
> [1] "2015-04-22"
>
> But as you can see R still gives me the wrong date.  I can get the correct
> date as follows:
>
> >     as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+%
> ".txt")$mtime, tz='America/New_York')
> [1] "2015-04-21"
>
> But my question is why is the as.Date function not using the timezone I
> have set?
>
> Thank you in advance,
> Roger
>
>
?Doing a ?file.info told me that the mtime variable is a POSIXct value.
Doing a ?as.Date told me that when a POSIXct value is given to it, the time
zone defaults to GMT, _not_ to the local time. That is my interpretation of
the documentation.?


<quote>
The ?as.Date? methods accept character strings, factors, logical
     ?NA? and objects of classes ?"POSIXlt"? and ?"POSIXct"?.  (The
     last is converted to days by ignoring the time after midnight in
     the representation of the time in specified time zone, default
     UTC.)  Also objects of class ?"date"? (from package ?date?) and
     ?"dates"? (from package ?chron?).  Character strings are processed
     as far as necessary for the format specified: any trailing
     characters are ignored.
</quote>

?What I would do is:

as.Date(file.info("..."),tz=getOption("tz"))?

-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Apr 23 15:23:56 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 23 Apr 2015 14:23:56 +0100
Subject: [R] problem setting default timezone
In-Reply-To: <0765308CD028654885F30322557308D81EE2EC23@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EE2EC23@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <5538F26C.2090202@dewey.myzen.co.uk>

In-line below

On 23/04/2015 14:01, Bos, Roger wrote:
> Dear All,
>
> I would like to learn the proper way to set the default time zone so I get the correct date for my files.  The code below is non-reproducible (sorry) because it is based on a file on my system, but I hope someone will be able to help me anyway.
>
> I have a file that was last modified on 4/21/2015:
>
>> file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime
> [1] "2015-04-21 20:26:33 EDT"
>
> When I convert that to a date, I gives me 2015-04-22.  I read about timezones and saw that there are two possible places to set the default values: One as a system variable and one as an option.  To be safe I set both:
>
>>      Sys.setenv(TZ='America/New_York')
>>      Sys.getenv("TZ")
> [1] "America/New_York"
>>      options(tz='America/New_York')
>>      getOption("tz")
> [1] "America/New_York"
>>      as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime)
> [1] "2015-04-22"
>
> But as you can see R still gives me the wrong date.  I can get the correct date as follows:
>
>>      as.Date(file.info("E:/snap/q/snap_q_q1_" %+% endPeriod %+% ".txt")$mtime, tz='America/New_York')
> [1] "2015-04-21"
>
> But my question is why is the as.Date function not using the timezone I have set?

Because it has a tz= parameter which sets its time zone. I think you 
need to write your own wrapper function to pick up your preferred timezone.

>
> Thank you in advance,
> Roger
>
>
> ***************************************************************
> This message and any attachments are for the named person's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies. You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From petr.pikal at precheza.cz  Thu Apr 23 15:45:03 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 23 Apr 2015 13:45:03 +0000
Subject: [R] How to calculate vif of each term of model in R?
In-Reply-To: <9C74639432B50946BF93B535048331619D888E@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29994@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D883E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C299D7@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D885E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29A0D@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D8874@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29AAB@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D888E@LONURLNA15.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B4A1@SRVEXCHMBX.precheza.cz>

Well. Your function results in error.

> f1<-function(model){
+ vfs<<-vif(model)
+ vfs
+ ex<<-subset(vfs,vfs>=10)
+ print(ex)
+ maxx<<-which.max(ex)
+ print(maxx)
+ mm<<-vector(mode = "numeric",length = 50)
+
+ mm<<-maxx
+ maxindex<<-which.max(ex)
+ print(maxindex)
+
+ }
> F1(model1)
Error: could not find function "F1"
>
> f1(model1)
Error in vcov(fit, regcoef.only = TRUE) : object 'model1' not found
>

Beside, why do you use global assignment.

<<-

within your function? I use R for more than 10 years and do not remember that I needed to use it.

You did not provide any data nor try to work on my suggestions. If you kept your mail copies to list you probably would get the answer more quickly.

You can use as.formula construction to programmatically select terms for update.

> fit

Call:
lm(formula = barviv ~ rutil + sio2 + teklat + fe, data = prov)

Coefficients:
(Intercept)        rutil         sio2       teklat           fe
   1230.154        5.956       15.123       55.322     5571.923

> vif(fit)
   rutil     sio2   teklat       fe
1.249975 1.702475 1.504633 1.094505
> which.max(vif(fit))
sio2
   2
> wmvif <- which.max(vif(fit))
> update(fit, as.formula(paste(". ~ . -",names(vif(fit)[wmvif]))))

Call:
lm(formula = barviv ~ rutil + teklat + fe, data = prov)

Coefficients:
(Intercept)        rutil       teklat           fe
    1220.25         6.04        97.44      5802.31

Cheers
Petr

> -----Original Message-----
> From: Methekar, Pushpa (GE Transportation, Non-GE)
> [mailto:pushpa.methekar at ge.com]
> Sent: Friday, April 17, 2015 2:47 PM
> To: PIKAL Petr
> Subject: RE: How to calculate vif of each term of model in R?
>
> Hey ,
> .........- names(vif(model1))[vmax])
> Is not working actually
> Instead
> Update(model1,.~.-x8) is working fine.
>
>
>
> For that any option would you tell me.
> As per your concern
> Update(model1,.~.-names(vif(model1))[vmax] means
>
> Update(model1,.~.-"x8")
> But it's not going to work.
>
> Look here is my program
>
> > require(rms)
> f1<-function(model){
> vfs<<-vif(model)
> vfs
> ex<<-subset(vfs,vfs>=10)
> print(ex)
> maxx<<-which.max(ex)
> print(maxx)
> mm<<-vector(mode = "numeric",length = 50)
>
> mm<<-maxx
> maxindex<<-which.max(ex)
> print(maxindex)
>
> }
> F1(model1)
>
>
>
> Output:
>    f1(model1)
>        x7        x8        x9
>  13.87063 220.96963 214.03413
> [1] 220.9696
> x8
>  2
>
>
> Now I have to do outside function explicitly
> model1<-update(model1,.~.-x8)
> then only I can remove my variable x8
>
> but I want to do in inside function so that automatically maximum
> element get eliminated .
>
>
> Thanks,
> Pushpa
>
>
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, April 17, 2015 5:25 PM
> To: Methekar, Pushpa (GE Transportation, Non-GE)
> Cc: r-help at r-project.org
> Subject: RE: How to calculate vif of each term of model in R?
>
> Hi
>
> > -----Original Message-----
> > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > [mailto:pushpa.methekar at ge.com]
> > Sent: Friday, April 17, 2015 1:12 PM
> > To: PIKAL Petr
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > Hi Petr,
> > You got my problem ,the solution which u specified is little good but
> > with
> >
> >
> > >update(model1,.~. - names(vif(model1))[vmax])
> >
> >
> >
> > I won't be able to update my model .
> > Instead I have to write like
> >
> >
> > > update(model1,.~. - x8)
> >
>
> maybe something like
>
> fun = function(model1) {
>
> vmax <- which.max(vif(model1))
>
> while( vif(model1)[vmax]>=10) {
>
> model1 <- update(model1,.~. - names(vif(model1))[vmax])) vmax <-
> which.max(vif(model1))
>
> }
>
> return(model1)
>
> }
>
> I am not sure about cycle (i did not use while in R for a while).
>
> Without some data I cannot check syntax so it is up to you.
>
> Cheers
> Petr
>
>
> >
> > i.e my x which having highest vif value.
> > Each time for removing highest x .i  have to explicitly write ......-
> > x8) So is there any way to avoid this?
> >
> >
> >
> >
> > Thanks,
> > Pushpa
> >
> > -----Original Message-----
> > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > Sent: Friday, April 17, 2015 4:16 PM
> > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > Comments to your first mail which are among lines and directly
> related
> > to your code.
> >
> > I specifically mentioned it
> >
> > > answers and comments in line
> >
> > If you have my first respond you can find them easier then now as
> they
> > are buried within your mail.
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > [mailto:pushpa.methekar at ge.com]
> > > Sent: Friday, April 17, 2015 12:10 PM
> > > To: PIKAL Petr
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > What comments are you talking about?
> > >
> > > -----Original Message-----
> > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > Sent: Friday, April 17, 2015 3:38 PM
> > > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > > Cc: r-help at r-project.org
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > Did you follow my advice/comments?
> > >
> > > Cheers
> > > Petr
> > >
> > >
> > > > -----Original Message-----
> > > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > > [mailto:pushpa.methekar at ge.com]
> > > > Sent: Friday, April 17, 2015 11:43 AM
> > > > To: PIKAL Petr
> > > > Subject: RE: How to calculate vif of each term of model in R?
> > > >
> > > > Car package
> > > >
> > > > -----Original Message-----
> > > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > > Sent: Friday, April 17, 2015 3:11 PM
> > > > To: Methekar, Pushpa (GE Transportation, Non-GE); r-help at r-
> > > project.org
> > > > Subject: RE: How to calculate vif of each term of model in R?
> > > >
> > > > Hi
> > > >
> > > > I did not see any answer so I try.
> > > >
> > > > Your question lacks some info:
> > > >
> > > > Which vif - car or HH?
> > > >
> > > > answers and comments in line
> > > >
> > > > > -----Original Message-----
> > > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > > > Methekar, Pushpa (GE Transportation, Non-GE)
> > > > > Sent: Wednesday, April 08, 2015 10:24 AM
> > > > > To: r-help at r-project.org
> > > > > Subject: [R] How to calculate vif of each term of model in R?
> > > > >
> > > > >
> > > > > I am beginner in R doing modelling in R, I loaded excel sheet
> in
> > > > > R, i have chosen x elements and y elements then fitted model
> for
> > > linear
> > > > and
> > > > > second order regression. Now I have both models. I am bit
> > confused
> > > > how
> > > > > to calculate vif for each term in model like
> > > > >
> > > > > e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package
> > > > > then
> > > > it's
> > > > > giving me like
> > > > >
> > > > >     vif(model1)
> > > > >
> > > > >        x1         x2         x3         x4         x5
> x6
> > > > > x7
> > > > >
> > > > >  6.679692   1.520271   1.667125   3.618439   4.931810
> 2.073879
> > > > > 13.870630
> > > > >
> > > > >         x8         x9
> > > > >
> > > > >    220.969628 214.034135
> > > > >
> > > > > now i want to compare each term with std vif as vif>=10 and
> > > > > which
> > > > will
> > > > > satisfy this condition i want to delete that term and update
> > > model1.
> > > > i
> > > > > have done something like this
> > > > >
> > > > > fun = function(model1) {
> > > > >
> > > > >  for(i in 1:length(model1))    {
> > > > >
> > > > >       v=vif(model1)
> > > > >
> > > > >          ss=any(v[i]>=10)
> > > >
> > > > here you select only one item from vif, Why do you use any?
> > > >
> > > > >
> > > > >                 if(ss==1){update(model1,.~.,-v[i])}
> > > > >
> > > > >                 else{print("no update")}
> > > > >
> > > >
> > > > Why do you change i here?
> > > >
> > > > >                  i<-i+1
> > > > >
> > > > >     }
> > > > >
> > > > >
> > > > >
> > > > >         return(model1)
> > > > >
> > > > >       }
> > > > >
> > > >
> > > > if you want to get rid of all terms bigger than some threshold in
> > > once
> > > > you can use
> > > >
> > > > sel <- which(vif(model1)>10)
> > > >
> > > > and select values for update possibly by
> > > >
> > > > update(model1,.~. - names(vif(model1))[sel])
> > > >
> > > > or if you want to get rid one by one you can use
> > > >
> > > > vmax <- which.max(vif(model1))
> > > > and check if max vif value is bigger than 10.
> > > >
> > > > vif(model1)[vmax]>=10
> > > >
> > > > If it is just update with
> > > >
> > > > - names(vif(model1))[vmax])
> > > >
> > > > if it is not do not update.
> > > >
> > > > All of this untested.
> > > >
> > > > Cheers
> > > > Petr
> > > >
> > > > > fun(model1)
> > > > >
> > > > > but giving error as
> > > > >
> > > > > Error in if (ss == 1) { : missing value where TRUE/FALSE
> needed.
> > > > >
> > > > > please tell me how do i solve this problem.
> > > > >
> > > > >
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-
> > project.org/posting-
> > > > > guide.html and provide commented, minimal, self-contained,
> > > > > reproducible code.
> > > >
> > >
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any
> reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dulcalma at bigpond.com  Thu Apr 23 16:26:25 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 24 Apr 2015 00:26:25 +1000
Subject: [R] high density plots using lattice dotplot()
In-Reply-To: <CAMk+s2Q59gkr506N6yYCHk_=at+aCRRGKf6zonizLQ1hoe0fgw@mail.gmail.com>
References: <CAMk+s2SAZSggkR6opJb=areVk25ir_tEs7jW45C0tU+a9L==2A@mail.gmail.com>	<000001d07bc2$a73b7d30$f5b27790$@bigpond.com>	<CAMk+s2RbwZXMw+erk3-NesYEKEGJsT8U-TWmAF07+XDnqKHP9g@mail.gmail.com>	<001101d07cbf$ac8ace00$05a06a00$@bigpond.com>	<CAMk+s2RJYHEs1qvd3UDY1dhqqiRecUv6UiRzVcirX9yk9F7HRA@mail.gmail.com>	<001301d07d6a$6b938620$42ba9260$@bigpond.com>
	<CAMk+s2Q59gkr506N6yYCHk_=at+aCRRGKf6zonizLQ1hoe0fgw@mail.gmail.com>
Message-ID: <000901d07dd1$7b9b8150$72d283f0$@bigpond.com>

Hi Luigi

Michael answered your question about printing 

lattice and ggplot require their graphics to be in print()

If you have problems in printing you may have to use 

trellis.device(device = pdf,  # or what ever the actual device is
                        file = ####,
                        <remainder of script>)
? trellis.device for info
I occasionally have to use it sometimes instead of pdf etc

Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Thursday, 23 April 2015 22:56
To: Duncan Mackay
Subject: Re: [R] high density plots using lattice dotplot()

Dear Duncan,
many thanks for the precious help! I have rearranged what you sent me
with a bit of stuff I wrote already for another project and the
results seems to work fine.
Best regards,
Luigi

>>> example
DF <-
  data.frame(Y = rnorm(17280),
             X = rnorm(1:45),
             Y2 = rnorm(17280)+2,
             Z  = 1:384)
head(df,10)
xyplot(Y ~ X | Z,
       data = DF,
       groups = Z,
       allow.multiple = TRUE,
       ylab= "Y VALUES",
       xlab="X VALUES",
       main="TITLE",
       scales = list(
         x = list(draw = FALSE),
         y = list(draw = FALSE),
         relation="same",
         alternating=TRUE),
       as.table = TRUE,
       layout = c(24,16),
       par.settings = list(
         strip.background=list(col="white"),
         axis.text = list(cex = 0.6),
         par.xlab.text = list(cex = 0.75),
         par.ylab.text = list(cex = 0.75),
         par.main.text = list(cex = 0.8),
         superpose.symbol = list(type = "l", cex = 1)
       ),
       strip    = FALSE,
       type = "l",
       col = 3,
       panel = panel.superpose
)

On Thu, Apr 23, 2015 at 3:08 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> Try
>
> set.seed(1)
>
> PLATE <-
> data.frame(Delta.Rn = rnorm(500),
>            Cycle = rnorm(500),
>            Delta2 = rnorm(500)+1,
>            Well  = rep(1:50, each = 10))
> head(PLATE,10)
>
> xyplot(Delta.Rn+Delta2 ~ Cycle | Well,
>          data = subset(PLATE, Well %in% 1:49),
>          allow.multiple = TRUE,
>          ylab="Fluorescence (Delta Rn)",
>          xlab="Cycles",
>          main="TITLE",
>          scales = list(
>            x = list(draw = FALSE),
>            y = list(draw = FALSE),
>            relation="same",
>            alternating=TRUE),
>          as.table = TRUE,
>          layout = c(10,5),
>          par.settings = list(
>            strip.background=list(col="white"),
>            # layout.heights = list(strip = 0.8),
>            axis.text = list(cex = 0.6),
>            par.xlab.text = list(cex = 0.75),
>            par.ylab.text = list(cex = 0.75),
>            par.main.text = list(cex = 0.8),
>            superpose.symbol = list(pch = ".", cex = 2,
>                                    col = c(2,4) )
>          ),
>          strip    = FALSE,
>          type = "p",
>          key = list(text = list(label = c("Delta.Rn","Delta2")),
>                     points = list(cex = 0.6, pch = 16, col = c(2,4)),
>                     cex = 0.6,
>                     x = 0.9,
>                     y = 0.1),
>          panel = panel.superpose,
>          panel.groups = function(x,y,...){
>
>                    panel.xyplot(x,y,... )
>
>                    # text argument can be a vector of values not
>                    # necessarily the group name
>                    pnl = panel.number()  # needed as group.number if added is now either 1 or 2
>
>                    grid.text(c(LETTERS,letters)[pnl],
>                              y = 0.93, x = 0.5,
>                              default.units = "npc",
>                              just = c("left", "bottom"),
>                              gp = gpar(fontsize = 7) )
>
>          }
>   )
>
> Remember to delete the group argument (I forgot to at first as the groups are now Delta.Rn Delta2)
> You may have 1+ empty panels so put the legend there where ever it is just amend the x and y or fine tune them
> you can have the pch = "." and increase cex but  it will become as square with large cex
> Duncan
>
>
> -----Original Message-----
> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
> Sent: Thursday, 23 April 2015 10:05
> To: Duncan Mackay
> Subject: Re: [R] high density plots using lattice dotplot()
>
> Dear Duncan,
> sorry to come back so soon, but i wanted to ask you whether it would
> be  possible to plot two sets of lines within each box, let's say a
> main value A and a secondary value B. In normal plots I could use a
> plot() followed by points(); what would be the strategy here?
> Thank you again,
> best regards,
> Luigi
>
>
> On Wed, Apr 22, 2015 at 6:46 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>>
>> Hi Luigi
>>
>> I should have made up an example to make things easier when I replied today
>>
>> This should get you going
>>
>> set.seed(1)
>>
>> PLATE <-
>> data.frame(Delta.Rn = rnorm(500),
>>            Cycle = rnorm(500),
>>            Well  = rep(1:50, each = 10))
>> head(PLATE)
>>
>> xyplot(Delta.Rn ~ Cycle | Well,
>>          data = PLATE,
>>          groups = Well,
>>          ylab="Fluorescence (Delta Rn)",
>>          xlab="Cycles",
>>          main="TITLE",
>>          scales = list(
>>            x = list(draw = FALSE),
>>            y = list(draw = FALSE),
>>            relation="same",
>>            alternating=TRUE),
>>          as.table = TRUE,
>>          layout = c(10,5),
>>          par.settings = list(
>>            strip.background=list(col="white"),
>>            # layout.heights = list(strip = 0.8),
>>            axis.text = list(cex = 0.6),
>>            par.xlab.text = list(cex = 0.75),
>>            par.ylab.text = list(cex = 0.75),
>>           par.main.text = list(cex = 0.8)
>>            superpose.symbol = list(pch = ".", cex = 2)
>>          ),
>>          strip    = FALSE,
>>          type = "p",
>>          col = 1,
>>          panel = panel.superpose,
>>          panel.groups = function(x,y,...,group.number){
>>
>>                    panel.xyplot(x,y,... )
>>
>>                    # text argument can be a vector of values not
>>                    # necessarily the group name
>>                    grid.text(c(LETTERS,letters)[group.number],
>>                              y = 0.93, x = 0.5,
>>                              default.units = "npc",
>>                              just = c("left", "bottom"),
>>                              gp = gpar(fontsize = 7) )
>>
>>          }
>>   )
>>
>> You could use panel.text instead of grid.text
>> Duncan
>>
>> -----Original Message-----
>> From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com]
>> Sent: Wednesday, 22 April 2015 08:24
>> To: Duncan Mackay
>> Subject: Re: [R] high density plots using lattice dotplot()
>>
>> Dear Duncan,
>> thank you for your reply. I tried to implement your suggestions but as
>> is on your reply did not work (actually R crashed) and a slight
>> elaboration returned the figure attached, which is essentially still
>> displaying text and not drawing the data. Here is what I wrote:
>>
>> xyplot(Delta.Rn ~ Cycle | Well,
>>          data = PLATE,
>>          ylab="Fluorescence (Delta Rn)",
>>          xlab="Cycles",
>>          main=TITLE,
>>          scales = list(
>>            x = list(draw = FALSE),
>>            y = list(draw = FALSE),
>>            relation="same",
>>            alternating=TRUE),
>>          as.table = TRUE,
>>          layout = c(24,16),
>>          par.settings = list(
>>            strip.background=list(col="white"),
>>            axis.text = list(cex = 0.6),
>>            par.xlab.text = list(cex = 0.75),
>>            par.ylab.text = list(cex = 0.75),
>>            superpose.symbol = list(pch = ".", cex = 2)
>>          ),
>>          strip    = FALSE,
>>          type = "p",
>>          layout.heights = list(strip = 0.8),
>>          panel = function(x,y, subscripts, groups,...){
>>            panel.superpose(x,y,subscripts,groups,...,
>>                            col = ...)
>>            panel.text(x,y,...,cex = 0.6)
>>          }
>>   )
>>
>>
>> How can I improve the script?
>> Many thanks
>> Luigi
>>
>> On Tue, Apr 21, 2015 at 12:35 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>>> Hi Luigi
>>>
>>> Strips take up space so if you are willing to not have strip and put the
>>> strip values within the plot area then
>>>
>>>       xyplot(y ~ x|cond.factor, data = ...,
>>>              as.table = T,
>>>              groups   = ...,
>>>              layout   = ...,
>>>              drop.unused = T,
>>>              par.settings = list(axis.text = list(cex = 0.6),
>>>                                  par.xlab.text = list(cex = 0.75),
>>>                                  par.ylab.text = list(cex = 0.75)
>>>                                  superpose.symbol = list(pch = ".", cex = 2)
>>>                             ),
>>>              strip    = FALSE,
>>>              scales   = list(x = list(alternating = 2),
>>>                              y = list(alternating = FALSE)
>>>                              ),
>>>              type = "p",
>>>              panel = function(x,y, subscripts, groups,...){
>>>                                 panel.superpose(x,y,subscripts,groups,...,
>>> col = ...)
>>>                                 panel.text(x,y,...,cex = 0.6)
>>>                             }
>>>       )
>>>
>>> if the text values are a vector
>>>       stext = ...
>>>       xyplot(y ~ x|cond.factor, data = ...,
>>>              as.table = T,
>>>              groups   = ...,
>>>              layout   = ...,
>>>              drop.unused = T,
>>>              par.settings = list(axis.text = list(cex = 0.6),
>>>                                  par.xlab.text = list(cex = 0.75),
>>>                                  par.ylab.text = list(cex = 0.75)
>>>                                  superpose.symbol = list(pch = ".", cex = 2)
>>>                             ),
>>>              strip    = FALSE,
>>>              scales   = list(x = list(alternating = 2),
>>>                              y = list(alternating = FALSE)
>>>                              ),
>>>              type = "p",
>>>              panel = function(x,y, subscripts, groups,...){
>>>                                pnl = panel.number()
>>>                                 panel.superpose(x,y,subscripts,groups,...,
>>> col = ...)
>>>                                 panel.text(x,y,stext[pnl],cex = 0.6)
>>>                             }
>>>       )
>>>
>>> you could also you group.number instead of pnl if it is needed elsewhere.
>>> text position could be done in a similar fashion if needed to be in
>>> different places for some panels.
>>>
>>> If you require the strip then an additional par.settings is
>>> layout.heights = list(strip = 0.8)
>>> or even untested in this situation
>>> strip = FALSE
>>> strip.left  = TRUE
>>>
>>> Regards
>>>
>>> Duncan
>>>
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>>> Marongiu
>>> Sent: Sunday, 19 April 2015 19:28
>>> To: r-help
>>> Subject: [R] high density plots using lattice dotplot()
>>>
>>> Dear all,
>>> I am trying to plot the results of a PCR experiments that involves 384
>>> individual plots. Admittedly the space for the plots will be tiny, but
>>> I just nedd some icon to have a feeling of the layout of the
>>> experiment and a quick comparison of the plots.
>>> I believe that lattice would be the right tool, but when I tried to
>>> implement i got an error. Specifically the output would be a A4 pdf,
>>> so with about 600 cm2 of drawing space, which gives about 1.5 cm2 for
>>> each plot; removing the labels that might just work.
>>> So I have the y values = 'fluorescence', x 'values' = cycles and 384
>>> 'well' data. I implemented to begin with:
>>>
>>> xyplot(fluorescence ~ cycles | well,
>>>          ylab="Fluorescence",
>>>          xlab="Cycles",
>>>          main=list(draw = FALSE),
>>>          scales = list(
>>>            x = list(draw = FALSE),
>>>            y = list(draw = FALSE),
>>>            relation="same",
>>>            alternating=TRUE),
>>>          layout = c(24,16),
>>>          par.settings = list(strip.background=list(col="white")),
>>>          pch = "."
>>>   )
>>>
>>> but the  the individual graphs show only the writing "data" instead of
>>> the actual plots.
>>> How can I overcome this error?
>>> Thank you
>>> Best regards
>>> Luigi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From petr.pikal at precheza.cz  Thu Apr 23 16:35:10 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 23 Apr 2015 14:35:10 +0000
Subject: [R] reshape data frame when one column has unequal number of
 entries
In-Reply-To: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>
References: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B4F5@SRVEXCHMBX.precheza.cz>

Hi

I am not sure if this is more efficient than some loop

I just gave your data another column names.
> names(x)<-c("one", "two")
> x
  one     two
1   1 a, b, c
2   2    d, e
3   3       f

> s<-(strsplit(x$two, ","))
> s
[[1]]
[1] "a"  " b" " c"

[[2]]
[1] "d"  " e"

[[3]]
[1] "f"

> first<-rep(x$one     ,unlist(lapply(s, length)))

> data.frame(first, second=unlist(s))
  first second
1     1      a
2     1      b
3     1      c
4     2      d
5     2      e
6     3      f

Maybe you want to remove extra white space form your values. It is mentioned somewhere in help pages to regular expressions

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri
> Liakhovitski
> Sent: Thursday, April 23, 2015 3:15 PM
> To: r-help
> Subject: [R] reshape data frame when one column has unequal number of
> entries
>
> Hello!
>
> I have my data frame x with 2 character columns:
>
> x <- data.frame(a = numeric(), b = I(list()))
> x[1:3,"a"] = 1:3
> x[[1, "b"]] <- "a, b, c"
> x[[2, "b"]] <- "d, e"
> x[[3, "b"]] <- "f"
> x$a = as.character(x$a)
> x$b = as.character(x$b)
> x
> str(x)
>
> I need to produce this data frame:
>
> 1  a
> 1  b
> 1  c
> 2  d
> 2  e
> 3  f
>
> Is it possible without looping?
> Thank you!
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dulcalma at bigpond.com  Thu Apr 23 16:38:53 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 24 Apr 2015 00:38:53 +1000
Subject: [R] reshape data frame when one column has unequal number of
	entries
In-Reply-To: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>
References: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>
Message-ID: <000a01d07dd3$38d74d70$aa85e850$@bigpond.com>

Hi Dimitri

here is a quick crude way (needs some polishing)

data.frame(a = rep(x$a,sapply(sapply(x$b, strsplit, ", "), length)), b=
unlist(sapply(x$b, strsplit, ", ")))

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri
Liakhovitski
Sent: Thursday, 23 April 2015 23:15
To: r-help
Subject: [R] reshape data frame when one column has unequal number of
entries

Hello!

I have my data frame x with 2 character columns:

x <- data.frame(a = numeric(), b = I(list()))
x[1:3,"a"] = 1:3
x[[1, "b"]] <- "a, b, c"
x[[2, "b"]] <- "d, e"
x[[3, "b"]] <- "f"
x$a = as.character(x$a)
x$b = as.character(x$b)
x
str(x)

I need to produce this data frame:

1  a
1  b
1  c
2  d
2  e
3  f

Is it possible without looping?
Thank you!


-- 
Dimitri Liakhovitski

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mikehall at y7mail.com  Wed Apr 22 22:26:09 2015
From: mikehall at y7mail.com (Mike)
Date: Wed, 22 Apr 2015 20:26:09 +0000 (UTC)
Subject: [R] Why is findAssocs() not working?
Message-ID: <638186530.2330677.1429734369554.JavaMail.yahoo@mail.yahoo.com>

findAssocs() is not working, as is seen below. "Lucid" and "dreaming" occur together quite often in the book. 

The corpus is a single document, the text version of a book.? Does this function require at least two documents?? If so, if I split the book in half will I get the correlations regarding the book as a whole, or in regards to how the two halves compare to each other?
> docs <- tm_map(docs, stemDocument)
> dtm <- DocumentTermMatrix(docs)
> freq <- colSums(as.matrix(dtm))
> ord <- order(freq)
> freq[tail(ord)]
one experi   will   can lucid dream
287   312   363   452   1018   2413
> freq[head(ord)]
abbey abdomin   abdu abraham absent   abus
1       1       1       1       1       1
> findAssocs(dtm, "dream", corlimit=0.6)
$dream
numeric(0)
> findAssocs(dtm, "dream", corlimit=0.1)
$dream
numeric(0)
> findAssocs(dtm, "lucid", corlimit=0.01)
$lucid
numeric(0)
> findAssocs(dtm, "lucid", corlimit=0.6)
$lucid
numeric(0)
> 
 

	[[alternative HTML version deleted]]


From erikduhaime at gmail.com  Wed Apr 22 23:11:47 2015
From: erikduhaime at gmail.com (Erik Duhaime)
Date: Wed, 22 Apr 2015 14:11:47 -0700 (PDT)
Subject: [R] R Freezes (Mac) using file.choose()
In-Reply-To: <COL127-W39C7DD80E2DA259D8E7767CC0D0@phx.gbl>
References: <COL127-W39C7DD80E2DA259D8E7767CC0D0@phx.gbl>
Message-ID: <35750d2f-f372-4fcb-bc5c-24f97f0eb0da@googlegroups.com>

Hi,

Did you ever get an answer about this?  It has been so so frustrating for 
me...

Thanks!


On Sunday, March 22, 2015 at 11:29:28 PM UTC-4, Vindoggy ! wrote:
>
> I'm using a mac with OSX Yosemite (10.10.2), running the latest version of 
> R (3.1.3). But I've been having this same issue since Mavericks came out, 
> using all of  the different versions of R that have come out since 
> Mavericks. 
>
> Often (approximately 15% of the time I would say), whenever I use a 
> function in R that pulls up a mac finder window, R will freeze and I am 
> left with the spinning beach ball until I force-quit R. This happens most 
> frequently when using "file.choose()" to open a file, but has happened to 
> me when changing the working directory through the "Misc" tab as well: 
>
> Misc-> Change Working Directory 
>
>
> This has happened on at least three different Mac machines of varying 
> ages, so I don't think this is a computer specific issue. And as much of 
> the scripts I have written use "file.choose()", this happens on a regular 
> basis. 
>
> Have other people run into this same issue? If so, is there a fix for it? 
>                                                 
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From andrees.mendez at gmail.com  Thu Apr 23 06:24:37 2015
From: andrees.mendez at gmail.com (=?UTF-8?B?QW5kcsOpcyBN?=)
Date: Wed, 22 Apr 2015 23:24:37 -0500
Subject: [R] Error in solve.default(-val)
Message-ID: <CAM5J=1kd-=2H_5BstzkrYUb-TFKwxmMnzHLVWAESG_ieXF8zPA@mail.gmail.com>

Buenas noches,
comedidamente me dirijo a ustedes para hacerles una consulta respecto a un
error que me ha salido al ejecutar R. Soy estudiante de Ingenier?a y estoy
basando mi tesis en un estudio estad?stico usando R Studio.
Estoy trabajando una base de datos con 12 variables y 1433 datos en cada
una de ellas. Al generar un modelo con la siguiente instrucci?n :

> m2.C1F<-lme(C1F ~ 1, data = facultades, random = ~1|Programa/Facultad,
method = "ML")


donde m2.C1F hace referencia al nombre del modelo, C1F a la variable y
facultades, al data frame. El error que me sale es el siguiente:

Error in solve.default(-val) :
  system is computationally singular: reciprocal condition number =
5.50424e-20


No se a que se debe y me seria muy ?til una sugerencia, opini?n o ayuda que
me puedan brindar.

Muchas Gracias,

Andr?s M.

	[[alternative HTML version deleted]]


From pablofleurquin at gmail.com  Thu Apr 23 10:08:28 2015
From: pablofleurquin at gmail.com (Pablo Fleurquin)
Date: Thu, 23 Apr 2015 10:08:28 +0200
Subject: [R] R lattice bwplot: Fill boxplots with specific color
 depending on factor level
In-Reply-To: <CAGx1TMADRbQOLcs_FvDi-CWUdQmB41GKCCCD+mbT6ve4J1yb0Q@mail.gmail.com>
References: <CABggTg6LS4Txqh8CKofu4hJLd7wsGRv5iuBiY6ZbvXUeXfXjxA@mail.gmail.com>
	<000c01d07d64$82dfefe0$889fcfa0$@bigpond.com>
	<CAGx1TMADRbQOLcs_FvDi-CWUdQmB41GKCCCD+mbT6ve4J1yb0Q@mail.gmail.com>
Message-ID: <CABggTg6mC=mvfYJX3ZjAaPJEBhjhxFSsrRKkFRjgoxMd5Gf57w@mail.gmail.com>

Thank you both.

I just wanted to point out that before assigning the order of colors in
vector col, one should check that it corresponds with how levels are
ordered in levels(mydata$Col3).

Best,
Pablo

2015-04-23 5:46 GMT+02:00 Richard M. Heiberger <rmh at temple.edu>:

> Pablo,
>
> I would do it similarly.  I would also place the box and whiskers in
> the specified colors.
>
> ## install.packages(HH)  ## if you don't have it
> library(HH)
>
> bwplot(mydata$Col1~mydata$Col3 | mydata$Col2,data=mydata,
>        groups = Col3,
>        as.table = TRUE, # added to make it easier for factor levels
>        layout = c(3,1), # looks nicer and easier to read
>        panel = panel.bwplot.superpose,
>        col = c(red,"darkorange",green),
>        fill = c(red,"darkorange",green), fill.alpha=.6)
>
> I changed your amber to "darkorange" as the amber lines are almost
> invisible.
>
> Rich
>
> On Wed, Apr 22, 2015 at 9:26 PM, Duncan Mackay <dulcalma at bigpond.com>
> wrote:
> > hi Pablo
> >
> > set.seed(1) # for reproducibility of data.frame
> > mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
> > each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
> > rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))
> > mydata$Col2 <- factor(mydata$Col2)
> >
> > In future please do not put * at end makes it harder to copy
> >
> > red=rgb(249/255, 21/255, 47/255)
> > amber=rgb(255/255, 200/255,0/255) # amended to reveal a colour difference
> > green=rgb(39/255, 232/255, 51/255)
> >
> > # As  Deepayan Sarkar said bwplot is different to others
> >
> > bwplot(mydata$Col1~mydata$Col3 | mydata$Col2,data=mydata,
> >        groups = Col3,
> >        as.table = TRUE, # added to make it easier for factor levels
> >        layout = c(3,1), # looks nicer and easier to read
> >        panel = panel.superpose,
> >        panel.groups = panel.bwplot,
> >        fill = c(red,amber,green)
> > )
> >
> > Duncan
> >
> > Duncan Mackay
> > Department of Agronomy and Soil Science
> > University of New England
> > Armidale NSW 2351
> > Email: home: mackay at northnet.com.au
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pablo
> > Fleurquin
> > Sent: Thursday, 23 April 2015 02:03
> > To: r-help at r-project.org
> > Subject: [R] R lattice bwplot: Fill boxplots with specific color
> depending
> > on factor level
> >
> > Hi,
> >
> > I thoroughly looked for an answer to this problem with no luck.
> >
> > I have a dataframe with 3 factor levels: YY, NN, YN
> >
> > *>mydata <- rbind(data.frame(Col1 = rnorm(2*1000),Col2 =rep(c("A", "C"),
> > each=1000),Col3=factor(rep(c("YY","NN"), 1000))),data.frame(Col1 =
> > rnorm(1000),Col2 =rep(c("B")),Col3=factor(rep(c("YY","YN"), 500))))*
> >
> > Being Col3 of factor type with 3 levels: NN YY YN
> >
> > I want to make a boxplot using lattice bwplot and assign to each level a
> > specific color:
> >
> >
> >
> >
> >
> >
> > *# NN:>red=rgb(249/255, 21/255, 47/255)# YN:>amber=rgb(255/255, 126/255,
> > 0/255)# YY:>green=rgb(39/255, 232/255, 51/255)*
> >
> > Using bwplot function:
> >
> >
> > * >pl<-bwplot(mydata$Col1~mydata$Col3 |
> >
> mydata$Col2,data=mydata,ylab=expression(italic(R)),panel=function(...){panel
> > .bwplot(...,groups=mydata$Col3,
> > fill=c(red,amber,green))})*
> >
> > IF YOU REPRODUCE THE EXAMPLE YOU WILL SEE THAT THE COLORS ARE NOT RELATED
> > TO THE LEVELS IN MY DATAFRAME AS YY BOX IS NOT ALWAYS GREEN.
> >
> > IS THERE A WAY TO ASSIGN YY:green, NN:red, YN:amber?
> >
> > You can see the resulting figure in:
> >
> http://stackoverflow.com/questions/29802129/r-lattice-bwplot-fill-boxplots-w
> > ith-specific-color-depending-on-factor-level
> >
> > Thank you in advance!
> > Pablo
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From darcy.m.trimpe at wmich.edu  Thu Apr 23 12:06:07 2015
From: darcy.m.trimpe at wmich.edu (Darcy Trimpe)
Date: Thu, 23 Apr 2015 03:06:07 -0700 (PDT)
Subject: [R] Two Factorial Experiment with a Single Control Group
In-Reply-To: <1429771654892-4706293.post@n4.nabble.com>
References: <1429546901645-4706153.post@n4.nabble.com>
	<1429556981749-4706176.post@n4.nabble.com>
	<1208548894.29970785.1429563831720.JavaMail.root@wmich.edu>
	<1429594588482-4706187.post@n4.nabble.com>
	<808429842.30079683.1429614212947.JavaMail.root@wmich.edu>
	<1429771654892-4706293.post@n4.nabble.com>
Message-ID: <1800188185.30705811.1429784396187.JavaMail.root@wmich.edu>

Thank you for the correction and the code. I had just discovered the repeated measure error myself yesterday :-). I had not thought of using a manova. This may work better than what I was going to do. Thanks again. 
----- Original Message -----

> From: "c06n [via R]" <ml-node+s789695n4706293h89 at n4.nabble.com>
> To: "Darcy Trimpe" <darcy.m.trimpe at wmich.edu>
> Sent: Thursday, April 23, 2015 2:47:35 AM
> Subject: Re: Two Factorial Experiment with a Single Control Group

> Hi,

> do you mean you didn't take any measurements before treatment, only
> after the fact? If so you used an inappropriate design.

> It should have been a repeated measures design (
> https://en.wikipedia.org/wiki/Repeated_measures_design ) and looked
> like this:

> no treatment | acute | 3 weeks
> day 1 measurement t1 | measurement t1 | measurements t1
> ...
> day 27 measurement t2 | measurement t2 | measurement t2

> Coming back to your question: Of course you can test the group
> differences from the measurements with a MANOVA (
> https://en.wikipedia.org/wiki/Multivariate_analysis_of_variance ,
> http://statmethods.net/stats/anova.html ). Treatment (acute, 3 week,
> no treatment) would be the 3-level-factor.

> Below the R code:

> # make data frame
> dataset <- data.frame(
> "treatment" = c("acute", "acute", "acute",
> "3weeks", "3weeks", "3weeks",
> "no", "no", "no"),
> "noTX" = c(7, 5, 4, 21, 28, 26, 3, 4, 7),
> "TX" = c(9, 8, 7, 23, 27, 29, 2, 5, 9),
> stringsAsFactors = TRUE
> )

> # plot
> # http://www.statmethods.net/advgraphs/ggplot2.html
> install.packages("ggplot2")
> require(ggplot2)
> p1 <- qplot(treatment, noTX, data = dataset, geom = c("boxplot",
> "jitter"),
> fill = treatment, main = "noTX", ylab = "Value")
> p2 <- qplot(treatment, TX, data = dataset, geom = c("boxplot",
> "jitter"),
> fill = treatment, main = "TX", ylab = "Value")
> p1; p2

> # MANOVA
> # http://statmethods.net/stats/anova.html
> #
> http://cran.r-project.org/web/packages/HSAUR/vignettes/Ch_analysis_of_variance.pdf
> fit <- manova(cbind(noTX, TX) ~ treatment, data = dataset)
> summary(fit)

> If you reply to this email, your message will be added to the
> discussion below:
> http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706293.html
> To unsubscribe from Two Factorial Experiment with a Single Control
> Group, click here .
> NAML




--
View this message in context: http://r.789695.n4.nabble.com/Two-Factorial-Experiment-with-a-Single-Control-Group-tp4706153p4706299.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From sales-rexcel at statconn.com  Thu Apr 23 13:03:17 2015
From: sales-rexcel at statconn.com (Sales RExcel)
Date: Thu, 23 Apr 2015 13:03:17 +0200
Subject: [R] install.packages problem
Message-ID: <0513F581-787F-464C-B725-F67CC5D66D5C@statconn.com>

It seems that installed.packages has changed behavior in 3.2.0.
We have a local package repository containing only binaries of packages (for Windows).

Since 3.2.0, using install.packages for a package form such a repository does not work any more.
The solution is to add the parameter type=?binary?.

The documentation mentions that

options(install.packages.check.source = "no?)

suppresses check for source version of the packages, but
using this and install.packages without type=?binary? produces an error because
seemingly there still is a check for the source version of the package.





	[[alternative HTML version deleted]]


From Francis.Bursa at quantics.co.uk  Thu Apr 23 15:09:28 2015
From: Francis.Bursa at quantics.co.uk (Francis Bursa)
Date: Thu, 23 Apr 2015 14:09:28 +0100
Subject: [R] Possible bug in rlm
Message-ID: <0C52EDD1A3F3744598A6749A094A805901717530F2EB@QUANTICSSERVER.quantics.local>

Dear all,

I believe I have found a bug in rlm in the MASS package. Specifically, the scale estimate can be wrong when there are no outliers. The following code snippet is an example:

dose <- c(0,1,2,0,1,2)
response <- c(0.659,1.633,3.621,1.803,3.093,4.424)
line <- c(1,1,1,2,2,2)
k2 <- seq(1.5,5,by=0.01)
repNA <- rep(NA,length(k2))
scale <- repNA
niter <- repNA
for (i in 1:length(k2)){
  rlm.fit <- rlm(response~dose+factor(line), psi=psi.huber,k=1.345,
                         scale.est="proposal 2",k2=k2[i])
  scale[i] <- rlm.fit$s
  niter[i] <- length(rlm.fit$conv)
}
plot(k2,scale,type="b",col=niter)

For this dataset there are no outliers, so I would expect the scale to be a smooth function of k2 once k2 is reasonably large, certainly for k2 > 2. However, there is a funny jump in the scale estimate around k2 = 2.4, just at the point where the number of iterations to convergence falls from 3 to 1.

Looking at the source code, it appears that on each iteration, the scale is updated, then the parameters, and then a check for convergence is carried out just for the parameters, not the scale. So I would guess that in the range around k2=2.5 convergence is being reached when in fact the scale estimate hasn't converged.

I am using MASS version 7.3-33 and R version 3.1.0 on Windows.

I am not sure how common this issue is but there does not seem to be anything special about my dataset so it could be quite generic. Am I right that this is a bug?

Many thanks,
Francis Bursa

------------------ 
Francis Bursa
Statistician

Quantics Consulting Ltd
28 Drumsheugh Gardens
Edinburgh
EH3 7RN
?
Telephone: +44 (0) 131 440 2781 ext 207
?
Quantics - complex data into clear results???????????? ?? ?????????
Quantics is an ISO 9001 registered?company?????????????????????? ??????????? 
www.quantics.co.uk

Please note that the contents of this e-mail (including any attachments) are confidential and may be legally privileged. If you are not the intended recipient you may not read, copy, distribute or make any other use of this email or its contents. If received in error, please tell us immediately by telephone on +44 (0) 131 440 2781 quoting the name of the sender and the intended recipient, then delete it from your system. Thank you.


From jitvi648 at student.liu.se  Thu Apr 23 16:46:51 2015
From: jitvi648 at student.liu.se (jitvis)
Date: Thu, 23 Apr 2015 07:46:51 -0700 (PDT)
Subject: [R] Predict in glmnet for Cox family
In-Reply-To: <1429700813668-4706248.post@n4.nabble.com>
References: <1429431493476-4706070.post@n4.nabble.com>
	<2f3a88$fud6n@ironport10.mayo.edu>
	<1429700813668-4706248.post@n4.nabble.com>
Message-ID: <1429800411955-4706320.post@n4.nabble.com>

Will I be able to do a prediction similar to above with random forest and
compare both the predict survival time result from AFT model and the
Survival Random forest model ?

Sincerely,



--
View this message in context: http://r.789695.n4.nabble.com/Predict-in-glmnet-for-cox-family-tp4706070p4706320.html
Sent from the R help mailing list archive at Nabble.com.


From ranjanmano167 at gmail.com  Thu Apr 23 17:19:05 2015
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Thu, 23 Apr 2015 16:19:05 +0100
Subject: [R] R_Calculating Thiessen weights for an area with irregular
	boundary
In-Reply-To: <553828A1.4000904@auckland.ac.nz>
References: <CANqyHbTBtcnW1=m+EeQhW5kmVQvkTAuB4ExGjo-2v4V7T1oZtQ@mail.gmail.com>
	<5536D02E.4070001@auckland.ac.nz>
	<CANqyHbQ4fyX5ULvBk0G0g3G6Ur4=avpYx9dgp1_s0NkuQ-WTZA@mail.gmail.com>
	<553828A1.4000904@auckland.ac.nz>
Message-ID: <CANqyHbSsXvQVNoW5UhY1TSLBHXKQrn7L0m09k8H5bxkdkFiwSw@mail.gmail.com>

It certainly is! Thank you.

Cheers,
Mano

On Thu, Apr 23, 2015 at 12:02 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 22/04/15 22:43, Manoranjan Muthusamy wrote:
>
> <SNIP>
>
>  4. <SNIP>
>>      How can I show the Dirichlet tile names (i.e. 1,2,3,....,8) in the
>> plot?
>>
>
> There's no built-in way at the moment as far as I can tell.
>
> One way to get the tiles to be labelled/numbered in the plot would be:
>
> plot(dX)
> text(X,labels=1:npoints(X))
>
> Slightly sexier:
>
> cents <- as.data.frame(t(sapply(tiles(dX),centroid.owin)))
> plot(dX)
> text(cents,labels=1:nrow(cents))
>
> Is this satisfactory?
>
> cheers,
>
> Rolf Turner
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Apr 23 18:19:20 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 23 Apr 2015 17:19:20 +0100
Subject: [R] Error in solve.default(-val)
In-Reply-To: <CAM5J=1kd-=2H_5BstzkrYUb-TFKwxmMnzHLVWAESG_ieXF8zPA@mail.gmail.com>
References: <CAM5J=1kd-=2H_5BstzkrYUb-TFKwxmMnzHLVWAESG_ieXF8zPA@mail.gmail.com>
Message-ID: <55391B88.9000907@dewey.myzen.co.uk>

Andr?s
Si prefieres escribir en espa?ol
https://stat.ethz.ch/mailman/listinfo/r-help-es
seria mejor

(That is a link to the Spanish language version of R-help)

On 23/04/2015 05:24, Andr?s M wrote:
> Buenas noches,
> comedidamente me dirijo a ustedes para hacerles una consulta respecto a un
> error que me ha salido al ejecutar R. Soy estudiante de Ingenier?a y estoy
> basando mi tesis en un estudio estad?stico usando R Studio.
> Estoy trabajando una base de datos con 12 variables y 1433 datos en cada
> una de ellas. Al generar un modelo con la siguiente instrucci?n :
>
>> m2.C1F<-lme(C1F ~ 1, data = facultades, random = ~1|Programa/Facultad,
> method = "ML")
>
>
> donde m2.C1F hace referencia al nombre del modelo, C1F a la variable y
> facultades, al data frame. El error que me sale es el siguiente:
>
> Error in solve.default(-val) :
>    system is computationally singular: reciprocal condition number =
> 5.50424e-20
>
>
> No se a que se debe y me seria muy ?til una sugerencia, opini?n o ayuda que
> me puedan brindar.
>
> Muchas Gracias,
>
> Andr?s M.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From nickmatzke.ncse at gmail.com  Thu Apr 23 18:51:31 2015
From: nickmatzke.ncse at gmail.com (Nick Matzke)
Date: Thu, 23 Apr 2015 12:51:31 -0400
Subject: [R] run Rscript and ignore errors?
Message-ID: <CAJdu7BBgsDZPVNJTENUbaVhnw_10CciFbm4tyVZjVuOGxhse4A@mail.gmail.com>

Hi R-help,

I've looked at google, the Rscript documentation and the Rscript --help
output and haven't found much on this.  So, here's my question:

I have a rather long script that runs on various input datasets.  It is
quite convenient to run the script from the Terminal command line with
"Rscript scriptname.R"

However, some datasets will cause errors. These are non-essential errors --
just some datasets don't have certain columns so certain parts of the
overall analysis don't produce figures etc.  Yes, I could go through the
whole script and insert try() statements, etc.  But I'm lazy.

So, is there a way to run Rscript or something similar, and just have it
ignore all errors (i.e., keep running through the script)?  I.e., just like
what happens if you just copy-paste the whole script into the R window --
errors happen and are noted but the rest of the script keeps running.

Thanks very much for any help!!

Cheers!
Nick

	[[alternative HTML version deleted]]


From kiangati at gmail.com  Thu Apr 23 21:17:48 2015
From: kiangati at gmail.com (Keniajin Wambui)
Date: Thu, 23 Apr 2015 22:17:48 +0300
Subject: [R] Power calculation
Message-ID: <CAE=fH8GO4=FbhBUz6xx8Tb7HvDt65Wh2wix-iZsiJ5tggF=wZA@mail.gmail.com>

I am are currently evaluating risk factors associated with a virus A ,
incidence among patients with a follow-up sample of 312. Overall, the
virus incidence rate is estimated at 4.7 per 100 pyr, 95% CI
(3.0-7.4), with a total follow-up time of 383.9 person years and 18
incidence cases.

How can I do a power calculation based on assumptions of the virus
acquisition in patients who have virus B?
For a rate that is twice as high, four times as high, and even eight
times higher.


Virus B
Yes- 203 No-109

I have tried using which gives a very suscpicious power?

v <- qnorm(0.975)
mu <- 0.047
muEst <- 0.094 #for a rate twice as high
n <- 312

#top
left <-  (n*((muEst-mu)^2))/mu
left <- sqrt(left)
ucalc<-left -v
ucalc
pnorm(ucalc)

The formula used is at Essential Medical Statistics Book by Betty R
Kirkwood et al pg 420 formula 2.


From highstat at highstat.com  Thu Apr 23 21:20:01 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 23 Apr 2015 20:20:01 +0100
Subject: [R] GLM course in Palm Cove
Message-ID: <553945E1.6050207@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course in Palm Cove, 
Australia.

Course1:  GLM with R (Bayesian and frequentist)
Location: Palm Cove, Australia
Date:       11-14 August 2015
Price:       475 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08PalmCoveI.pdf


Keywords:
Bayesian statistics, MCMC and JAGS. Overdispersion and solutions. 
Poisson, negative binomial, Bernoulli, binomial,
beta, gamma, inverse Gaussian, lognormal, and binomial distributions. 
GLMs for count data and continuous data. Underdispersion. Truncated 
data. Power analysis.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From mark at markdrummond.ca  Thu Apr 23 19:23:24 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Thu, 23 Apr 2015 13:23:24 -0400
Subject: [R] Predictions on training set shorter than training set
Message-ID: <CAAb4XW18x1SSHihrtZnwLFtLkOOLX+nLsQMJjMfFdyFxojje4A@mail.gmail.com>

Hi all,

Given a simple logistic regression on a training data set using glm,
the number of predicted values is less than the number of observations
in the training set:

> fit.train.pred <- predict(fit, type = "response")
> nrow(train)
[1] 62660
> length(fit.train.pred)
[1] 58152
>

As a relative newcomer, I've run lots of simple glm, CART etc. models
but this is the first time I have seen this happen.

Is this a common issue and is there a fix? An option to predict() perhaps?

-- 
Cheers, Mark

Mark Drummond
mark at markdrummond.ca

When I get sad, I stop being sad and be Awesome instead. TRUE STORY.


From matzke at nimbios.org  Thu Apr 23 18:28:19 2015
From: matzke at nimbios.org (Nick Matzke)
Date: Thu, 23 Apr 2015 12:28:19 -0400
Subject: [R] Run Rscript and ignore errors?
Message-ID: <CAJdu7BADVVz20kEMXLuu5-mOCz3wb_qNA_Ne9brc013KhSXfbQ@mail.gmail.com>

Hi R-help,

I've looked at google, the Rscript documentation and the Rscript --help
output and haven't found much on this.  So, here's my question:

I have a rather long script that runs on various input datasets.  It is
quite convenient to run the script from the Terminal command line with
"Rscript scriptname.R"

However, some datasets will cause errors. These are non-essential errors --
just some datasets don't have certain columns so certain parts of the
overall analysis don't produce figures etc.  Yes, I could go through the
whole script and insert try() statements, etc.  But I'm lazy.

So, is there a way to run Rscript or something similar, and just have it
ignore all errors (i.e., keep running through the script)?  I.e., just like
what happens if you just copy-paste the whole script into the R window --
errors happen and are noted but the rest of the script keeps running.

Thanks very much for any help!!

Cheers!
Nick

	[[alternative HTML version deleted]]


From mikehall at y7mail.com  Thu Apr 23 22:10:41 2015
From: mikehall at y7mail.com (Mike)
Date: Thu, 23 Apr 2015 20:10:41 +0000 (UTC)
Subject: [R] Need content_transformer() called by tm_map() to change
 non-letters to spaces
Message-ID: <266420185.3145264.1429819841325.JavaMail.yahoo@mail.yahoo.com>

Hello,
In the following code, any characters matching? "/|@| \\|") will be changed to a space. 
> library(tm)
> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
> docs <- tm_map(docs, toSpace, "/|@| \\|")

What code would transform all non-letters to a space?? (What goes where the xxxxx's are.)It is very difficult to put all non-letters in a string...? So I'm doing the opposite of the above.
> toSpace_2 <- content_transformer(function xxxxxxxxxxxxxxxxxxxxxxx))
> docs <- tm_map(docs, toSpace_2, "abcdefghijklmnopqrstuvwxyz")

This needs to be done by a content_transformer() function to maintain the integrity of docs.

Thanks
?
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Apr 23 22:42:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Apr 2015 13:42:01 -0700
Subject: [R] Predictions on training set shorter than training set
In-Reply-To: <CAAb4XW18x1SSHihrtZnwLFtLkOOLX+nLsQMJjMfFdyFxojje4A@mail.gmail.com>
References: <CAAb4XW18x1SSHihrtZnwLFtLkOOLX+nLsQMJjMfFdyFxojje4A@mail.gmail.com>
Message-ID: <CAF8bMcbackxWQA5H-g+aKiF_kmwphxdOf55UgbetqpBOXe599g@mail.gmail.com>

Are there missing values in your data?  If so, try adding
the argument
   na.action = na.exclude
to your original call to glm or lm.  It is like the default
na.omit except that it records which rows were omitted
(because they contained missing values) and fills in
the corresponding entries in the predictions, residuals, etc.
with NA's.

You can also set
   options(na.action = "na.exclude")
to make it the default na.action in lm() and similar functions.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 23, 2015 at 10:23 AM, Mark Drummond <mark at markdrummond.ca>
wrote:

> Hi all,
>
> Given a simple logistic regression on a training data set using glm,
> the number of predicted values is less than the number of observations
> in the training set:
>
> > fit.train.pred <- predict(fit, type = "response")
> > nrow(train)
> [1] 62660
> > length(fit.train.pred)
> [1] 58152
> >
>
> As a relative newcomer, I've run lots of simple glm, CART etc. models
> but this is the first time I have seen this happen.
>
> Is this a common issue and is there a fix? An option to predict() perhaps?
>
> --
> Cheers, Mark
>
> Mark Drummond
> mark at markdrummond.ca
>
> When I get sad, I stop being sad and be Awesome instead. TRUE STORY.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Fri Apr 24 00:25:12 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 23 Apr 2015 18:25:12 -0400
Subject: [R] reshape data frame when one column has unequal number of
	entries
In-Reply-To: <000a01d07dd3$38d74d70$aa85e850$@bigpond.com>
References: <CAN2xGJZkPF1mSvFpMmRdfjHHN_5rrQTyb_-y_vyvDpCys0rGPA@mail.gmail.com>
	<000a01d07dd3$38d74d70$aa85e850$@bigpond.com>
Message-ID: <CAN2xGJYm8pib89x58E5gyJK9UFeoa1Ghz_Qg2V0YLm2H3D8V-A@mail.gmail.com>

Thank you very much, everybody!

On Thu, Apr 23, 2015 at 10:38 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Dimitri
>
> here is a quick crude way (needs some polishing)
>
> data.frame(a = rep(x$a,sapply(sapply(x$b, strsplit, ", "), length)), b=
> unlist(sapply(x$b, strsplit, ", ")))
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri
> Liakhovitski
> Sent: Thursday, 23 April 2015 23:15
> To: r-help
> Subject: [R] reshape data frame when one column has unequal number of
> entries
>
> Hello!
>
> I have my data frame x with 2 character columns:
>
> x <- data.frame(a = numeric(), b = I(list()))
> x[1:3,"a"] = 1:3
> x[[1, "b"]] <- "a, b, c"
> x[[2, "b"]] <- "d, e"
> x[[3, "b"]] <- "f"
> x$a = as.character(x$a)
> x$b = as.character(x$b)
> x
> str(x)
>
> I need to produce this data frame:
>
> 1  a
> 1  b
> 1  c
> 2  d
> 2  e
> 3  f
>
> Is it possible without looping?
> Thank you!
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dimitri Liakhovitski


From erinm.hodgess at gmail.com  Fri Apr 24 00:41:05 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 23 Apr 2015 18:41:05 -0400
Subject: [R]  cbind question, please
Message-ID: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>

Hello!

I have a cbind type question, please:  Suppose I have the following:

dog <- 1:3
cat <- 2:4
tree <- 5:7

and a character vector
big.char <- c("dog","cat","tree")

I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
This is a toy example.  There will be a bunch of variables.

I experimented with "do.call", but all I got was
1
2
3

Any suggestions would be much appreciated.  I still think that do.call
might be the key, but I'm not sure.

R Version 3-1.3, Windows 7.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Fri Apr 24 01:09:38 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Thu, 23 Apr 2015 16:09:38 -0700
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <CACdH2ZZpDg90TNwCd60tydm+PP+LNBY04W4vdwn00ykWrQ4QLA@mail.gmail.com>

Is this what you're looking for?

> dog <- 1:3

> bat <- 2:4

> tree <- 5:7

> big.char <- c("dog","bat","tree")

> do.call(cbind,lapply(big.char, get))
     [,1] [,2] [,3]
[1,]    1    2    5
[2,]    2    3    6
[3,]    3    4    7
>


On Thu, Apr 23, 2015 at 3:41 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.
>
> Thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Apr 24 01:14:30 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Apr 2015 16:14:30 -0700
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <CAF8bMcYYDOU6cjA9+jC1Dn4zi61_kzwDQX3D+Xn3i2LOZ6EneQ@mail.gmail.com>

You could do something tricky like
  > do.call(cbind, lapply(big.char, as.name))
       dog cat tree
  [1,]   1   2    5
  [2,]   2   3    6
  [3,]   3   4    7
but you are usually better off creating these things as part of a list
and passing that to do.call(cbind, list).

There is a slight danger of using do.call with cbind.  If your
list has a component with the unlikely name 'deparse.level',
then that will be taken as cbind's deparse.level argument,
not as a column of the matrix to be made.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 23, 2015 at 3:41 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.
>
> Thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Fri Apr 24 01:30:39 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 23 Apr 2015 16:30:39 -0700
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1504231629510.5521@aeolus.ecy.wa.gov>

Perhaps:

> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
> big.char <- cbind(dog,cat,tree)
> big.char
      dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7
> colnames(big.char)<-c("dog","cat","tree")
> big.char
      dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7



Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 23 Apr 2015, Erin Hodgess wrote:

> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.
>
> Thanks,
> Erin
>
>
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From erinm.hodgess at gmail.com  Fri Apr 24 01:28:55 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 23 Apr 2015 19:28:55 -0400
Subject: [R] cbind question, please
In-Reply-To: <CAF8bMcYYDOU6cjA9+jC1Dn4zi61_kzwDQX3D+Xn3i2LOZ6EneQ@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
	<CAF8bMcYYDOU6cjA9+jC1Dn4zi61_kzwDQX3D+Xn3i2LOZ6EneQ@mail.gmail.com>
Message-ID: <CACxE24nHcQ-eMeroyeS05c5s0B3WUBAfmpBtaqr0svOn2sCR1w@mail.gmail.com>

These are great! Thank you!



On Thu, Apr 23, 2015 at 7:14 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You could do something tricky like
>   > do.call(cbind, lapply(big.char, as.name))
>        dog cat tree
>   [1,]   1   2    5
>   [2,]   2   3    6
>   [3,]   3   4    7
> but you are usually better off creating these things as part of a list
> and passing that to do.call(cbind, list).
>
> There is a slight danger of using do.call with cbind.  If your
> list has a component with the unlikely name 'deparse.level',
> then that will be taken as cbind's deparse.level argument,
> not as a column of the matrix to be made.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Apr 23, 2015 at 3:41 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
>> Hello!
>>
>> I have a cbind type question, please:  Suppose I have the following:
>>
>> dog <- 1:3
>> cat <- 2:4
>> tree <- 5:7
>>
>> and a character vector
>> big.char <- c("dog","cat","tree")
>>
>> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
>> This is a toy example.  There will be a bunch of variables.
>>
>> I experimented with "do.call", but all I got was
>> 1
>> 2
>> 3
>>
>> Any suggestions would be much appreciated.  I still think that do.call
>> might be the key, but I'm not sure.
>>
>> R Version 3-1.3, Windows 7.
>>
>> Thanks,
>> Erin
>>
>>
>> --
>> Erin Hodgess
>> Associate Professor
>> Department of Mathematical and Statistics
>> University of Houston - Downtown
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr 24 01:32:26 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Apr 2015 09:32:26 +1000
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <CA+8X3fXKMNenqjdUBTPHRVEFKbs9i5Od3T8eAoPQPGnO=jvSeg@mail.gmail.com>

Hi Erin,
Well, if I do this:

dog <- 1:3
cat <- 2:4
tree <- 5:7
dct<-cbind(dog,cat,tree)

I get this:

dct
     dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7

If I assume that you want to include the character vector as well:

rownames(dct)<-big.char
dct

Jim

On Fri, Apr 24, 2015 at 8:41 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.
>
> Thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From steve.taylor at aut.ac.nz  Fri Apr 24 01:32:00 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Thu, 23 Apr 2015 23:32:00 +0000
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C9A6CC41E@Lewis.autuni.aut.ac.nz>

This works for me...

get0 = function(x) get(x,pos=1)
sapply(big.char, get0)

The extra step seems necessary because without it, get() gets base::cat() instead of cat.

cheers,
    Steve

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: Friday, 24 April 2015 10:41a
To: R help
Subject: [R] cbind question, please

Hello!

I have a cbind type question, please:  Suppose I have the following:

dog <- 1:3
cat <- 2:4
tree <- 5:7

and a character vector
big.char <- c("dog","cat","tree")

I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
This is a toy example.  There will be a bunch of variables.

I experimented with "do.call", but all I got was
1
2
3

Any suggestions would be much appreciated.  I still think that do.call
might be the key, but I'm not sure.

R Version 3-1.3, Windows 7.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Fri Apr 24 01:44:04 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 23 Apr 2015 15:44:04 -0800
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <BF376343F12.00000067jrkrideau@inbox.com>

What are you expecting?

dog <- 1:3
cat <- 2:4
tree <- 5:7
big.char <- c("dog","cat","tree")

xx <-  cbind(dog, cat, tree, big.char)

gives me 
xx1  <-  structure(c("1", "2", "3", "2", "3", "4", "5", "6", "7", "dog", 
"cat", "tree"), .Dim = 3:4, .Dimnames = list(NULL, c("dog", "cat", 
"tree", "big.char")))



John Kane
Kingston ON Canada


> -----Original Message-----
> From: erinm.hodgess at gmail.com
> Sent: Thu, 23 Apr 2015 18:41:05 -0400
> To: r-help at stat.math.ethz.ch
> Subject: [R] cbind question, please
> 
> Hello!
> 
> I have a cbind type question, please:  Suppose I have the following:
> 
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
> 
> and a character vector
> big.char <- c("dog","cat","tree")
> 
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
> 
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
> 
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
> 
> R Version 3-1.3, Windows 7.
> 
> Thanks,
> Erin
> 
> 
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From wickedpuppy at gmail.com  Fri Apr 24 02:22:28 2015
From: wickedpuppy at gmail.com (billy am)
Date: Fri, 24 Apr 2015 08:22:28 +0800
Subject: [R] R MSI Installer
Message-ID: <CAJ_FNV6oFNU84qwJxFj2U-SPF+UJJgCb797NNgOQCmv_D=uOXQ@mail.gmail.com>

Hi Everyone ,

Is there a place where I can download msi installer for latest version of
R?

Thanks
Billy

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Apr 24 06:09:59 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Apr 2015 21:09:59 -0700
Subject: [R] Need content_transformer() called by tm_map() to change
	non-letters to spaces
In-Reply-To: <266420185.3145264.1429819841325.JavaMail.yahoo@mail.yahoo.com>
References: <266420185.3145264.1429819841325.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4FE1357A-D993-4F96-88A0-93F92161BFD8@dcn.davis.CA.us>

Regex "[^a-zA-Z]" reads as "not a letter". 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 23, 2015 1:10:41 PM PDT, Mike <mikehall at y7mail.com> wrote:
>Hello,
>In the following code, any characters matching? "/|@| \\|") will be
>changed to a space. 
>> library(tm)
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, "
>", x))
>> docs <- tm_map(docs, toSpace, "/|@| \\|")
>
>What code would transform all non-letters to a space?? (What goes where
>the xxxxx's are.)It is very difficult to put all non-letters in a
>string...? So I'm doing the opposite of the above.
>> toSpace_2 <- content_transformer(function xxxxxxxxxxxxxxxxxxxxxxx))
>> docs <- tm_map(docs, toSpace_2, "abcdefghijklmnopqrstuvwxyz")
>
>This needs to be done by a content_transformer() function to maintain
>the integrity of docs.
>
>Thanks
>?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kehld at ktk.pte.hu  Fri Apr 24 09:34:50 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Fri, 24 Apr 2015 07:34:50 +0000
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14406FC5@EMAIL.ktkdom.pte.hu>

Hello,

I am not sure what you mean by a matrix. If you want to have a matrix, use the function matrix, (matrix(c(dog,cat,tree),3))
but I have the feeling you really want a data frame as you are talking about variables.
In that case simply use 

mydataframe <- data.frame(dog,cat,tree)

If you are not sure what you want, please read the intro to R pdf which is included in your installed R library.

Best regards,
daniel
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Erin Hodgess [erinm.hodgess at gmail.com]
K?ldve: 2015. ?prilis 24. 0:41
To: R help
T?rgy: [R]  cbind question, please

Hello!

I have a cbind type question, please:  Suppose I have the following:

dog <- 1:3
cat <- 2:4
tree <- 5:7

and a character vector
big.char <- c("dog","cat","tree")

I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
This is a toy example.  There will be a bunch of variables.

I experimented with "do.call", but all I got was
1
2
3

Any suggestions would be much appreciated.  I still think that do.call
might be the key, but I'm not sure.

R Version 3-1.3, Windows 7.

Thanks,
Erin


--
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Apr 24 04:49:16 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Apr 2015 21:49:16 -0500
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <4C6D426D-0830-4627-AB2C-272624D2B6BB@me.com>

On Apr 23, 2015, at 5:41 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> Hello!
> 
> I have a cbind type question, please:  Suppose I have the following:
> 
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
> 
> and a character vector
> big.char <- c("dog","cat","tree")
> 
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
> 
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
> 
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
> 
> R Version 3-1.3, Windows 7.
> 
> Thanks,
> Erin
> 


Hi Erin,

One approach could be:

> sapply(big.char, get, mode = "integer")
     dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7

or

> sapply(big.char, get, mode = "numeric")
     dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7


Note that I used the ?mode' argument to get(). You used ?cat? as the name of one of the objects and of course, there is an R function cat(). By default for get(), mode = ?any?, which would otherwise result in:

> sapply(big.char, get)
$dog
[1] 1 2 3

$cat
function (..., file = "", sep = " ", fill = FALSE, labels = NULL, 
    append = FALSE) 
{
    if (is.character(file)) 
        if (file == "") 
            file <- stdout()
        else if (substring(file, 1L, 1L) == "|") {
            file <- pipe(substring(file, 2L), "w")
            on.exit(close(file))
        }
        else {
            file <- file(file, ifelse(append, "a", "w"))
            on.exit(close(file))
        }
    .Internal(cat(list(...), file, sep, fill, labels, append))
}
<bytecode: 0x7fe942d78f78>
<environment: namespace:base>

$tree
[1] 5 6 7


In the above, the cat() function body is returned, instead of the vector cat. So just need to be cautious.

An alternative approach, depending upon where your vectors are stored, might be:

> sapply(big.char, get, pos = 1)
     dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7


which specifies which environment to search for the named objects and the cat() function is not returned since it is in namespace:base.

See ?get

Regards,

Marc Schwartz


From erinm.hodgess at gmail.com  Fri Apr 24 02:51:18 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 23 Apr 2015 20:51:18 -0400
Subject: [R] cbind question, please
In-Reply-To: <BF376343F12.00000067jrkrideau@inbox.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
	<BF376343F12.00000067jrkrideau@inbox.com>
Message-ID: <CACxE24nDFQFM3jAypSVJus2DcoULXZN9oOyOAe0NK4Ek6Uuh2A@mail.gmail.com>

Here is the big picture.  I have a character vector with all of the names
of the variables in it.

I want to "cbind" all of the variables to create a matrix.

Doing 3 is straightforward, but many, not so much.

Hence my question.

Thanks so much for your answers!

Sincerely,
Erin


On Thu, Apr 23, 2015 at 7:44 PM, John Kane <jrkrideau at inbox.com> wrote:

> What are you expecting?
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
> big.char <- c("dog","cat","tree")
>
> xx <-  cbind(dog, cat, tree, big.char)
>
> gives me
> xx1  <-  structure(c("1", "2", "3", "2", "3", "4", "5", "6", "7", "dog",
> "cat", "tree"), .Dim = 3:4, .Dimnames = list(NULL, c("dog", "cat",
> "tree", "big.char")))
>
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: erinm.hodgess at gmail.com
> > Sent: Thu, 23 Apr 2015 18:41:05 -0400
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] cbind question, please
> >
> > Hello!
> >
> > I have a cbind type question, please:  Suppose I have the following:
> >
> > dog <- 1:3
> > cat <- 2:4
> > tree <- 5:7
> >
> > and a character vector
> > big.char <- c("dog","cat","tree")
> >
> > I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> > This is a toy example.  There will be a bunch of variables.
> >
> > I experimented with "do.call", but all I got was
> > 1
> > 2
> > 3
> >
> > Any suggestions would be much appreciated.  I still think that do.call
> > might be the key, but I'm not sure.
> >
> > R Version 3-1.3, Windows 7.
> >
> > Thanks,
> > Erin
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Apr 24 03:10:01 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 24 Apr 2015 13:10:01 +1200
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <553997E9.9090602@auckland.ac.nz>

On 24/04/15 10:41, Erin Hodgess wrote:
> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3

I don't understand how you managed to get *that*.  When I did the 
"obvious" thing --- do.call(cbind,as.list(big.char)) --- I got
(as expected :-) )

      [,1]  [,2]  [,3]
[1,] "dog" "cat" "tree"

>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.

do.call(cbind,lapply(big.char,get,envir=.GlobalEnv))

Note:  I had to throw in the specification of "envir" otherwise get() 
got the cat() function from "base" rather than your vector "cat".

Probably not a problem for your real application; shouldn't hurt, but.

Another salutary example of why it's not a good idea to give data sets 
names that are names of R built-ins.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jdnewmil at dcn.davis.CA.us  Fri Apr 24 06:15:50 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Apr 2015 21:15:50 -0700
Subject: [R] run Rscript and ignore errors?
In-Reply-To: <CAJdu7BBgsDZPVNJTENUbaVhnw_10CciFbm4tyVZjVuOGxhse4A@mail.gmail.com>
References: <CAJdu7BBgsDZPVNJTENUbaVhnw_10CciFbm4tyVZjVuOGxhse4A@mail.gmail.com>
Message-ID: <ECAF97E0-60A0-4C97-8C33-37B71156C2F8@dcn.davis.CA.us>

This seems like a recipe for garbage results to me, but there may be I something you can set the error option to. See ?options.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 23, 2015 9:51:31 AM PDT, Nick Matzke <nickmatzke.ncse at gmail.com> wrote:
>Hi R-help,
>
>I've looked at google, the Rscript documentation and the Rscript --help
>output and haven't found much on this.  So, here's my question:
>
>I have a rather long script that runs on various input datasets.  It is
>quite convenient to run the script from the Terminal command line with
>"Rscript scriptname.R"
>
>However, some datasets will cause errors. These are non-essential
>errors --
>just some datasets don't have certain columns so certain parts of the
>overall analysis don't produce figures etc.  Yes, I could go through
>the
>whole script and insert try() statements, etc.  But I'm lazy.
>
>So, is there a way to run Rscript or something similar, and just have
>it
>ignore all errors (i.e., keep running through the script)?  I.e., just
>like
>what happens if you just copy-paste the whole script into the R window
>--
>errors happen and are noted but the rest of the script keeps running.
>
>Thanks very much for any help!!
>
>Cheers!
>Nick
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From phaedrusv at gmail.com  Fri Apr 24 09:02:49 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Fri, 24 Apr 2015 08:02:49 +0100
Subject: [R] Warning message when starting RStudio
In-Reply-To: <5538E87B.1080009@standortsanalyse.net>
References: <55389524.4070008@gmail.com>	<1F16A9E7-28F6-404E-8E7E-421C0B7C3D98@xs4all.nl>
	<5538E87B.1080009@standortsanalyse.net>
Message-ID: <5539EA99.4080600@gmail.com>

On 23/04/15 13:41, Albin Blaschka wrote:
> Hello
>
> Am 23.04.2015 um 09:57 schrieb Berend Hasselman:
>>
>>> On 23-04-2015, at 08:45, Sun Shine <phaedrusv at gmail.com> wrote:
>>>
>>> Hi list
>>>
>>> Recently, when starting up RStudio, the following warning is being 
>>> displayed:
>>>
>>> "Error in tools:::httpdPort <= 0L :
>>> comparison (4) is possible only for atomic and list types"
>>>
>>> I think that this is specific to RStudio because starting R in a 
>>> terminal window doesn't produce this message.
>>>
>>> Does anyone have an idea on how to clear the conditions that are 
>>> giving rise to this warning?
>
> Upgrade R-Studio, it is a problem in the interaction between R and 
> R-Studio, which was solved with the new version of R-Studio... I had 
> the same problem...
>
> HTH,
> Albin
>
>
Hi Albin

That did help - thanks so much!

Cheers

Sun


From ripley at stats.ox.ac.uk  Fri Apr 24 10:28:38 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Apr 2015 09:28:38 +0100
Subject: [R] R MSI Installer
In-Reply-To: <CAJ_FNV6oFNU84qwJxFj2U-SPF+UJJgCb797NNgOQCmv_D=uOXQ@mail.gmail.com>
References: <CAJ_FNV6oFNU84qwJxFj2U-SPF+UJJgCb797NNgOQCmv_D=uOXQ@mail.gmail.com>
Message-ID: <5539FEB6.7060603@stats.ox.ac.uk>

On 24/04/2015 01:22, billy am wrote:
> Hi Everyone ,
>
> Is there a place where I can download msi installer for latest version of
> R?

I believe not: certainly not an official one.  Consult the manual as to 
how to build one if you really need one.

>
> Thanks
> Billy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do: no HTML for a start.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From Berwin.Turlach at gmail.com  Fri Apr 24 11:23:17 2015
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Fri, 24 Apr 2015 17:23:17 +0800
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nDFQFM3jAypSVJus2DcoULXZN9oOyOAe0NK4Ek6Uuh2A@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
	<BF376343F12.00000067jrkrideau@inbox.com>
	<CACxE24nDFQFM3jAypSVJus2DcoULXZN9oOyOAe0NK4Ek6Uuh2A@mail.gmail.com>
Message-ID: <20150424172317.5fd693ca@bossiaea>

G'day Erin,

On Thu, 23 Apr 2015 20:51:18 -0400
Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Here is the big picture.  I have a character vector with all of the
> names of the variables in it.
> 
> I want to "cbind" all of the variables to create a matrix.
> 
> Doing 3 is straightforward, but many, not so much.

So I guess you want something like:

R> do.call(cbind, sapply(big.char, as.name))
     dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7

Which does not seem to have the problem of confusing the numeric vector
`cat' with the function 'cat'.

HTH.

Cheers,

	Berwin


From r.turner at auckland.ac.nz  Fri Apr 24 11:33:57 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 24 Apr 2015 21:33:57 +1200
Subject: [R] cbind question, please
In-Reply-To: <4C6D426D-0830-4627-AB2C-272624D2B6BB@me.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
	<4C6D426D-0830-4627-AB2C-272624D2B6BB@me.com>
Message-ID: <553A0E05.2010604@auckland.ac.nz>


I am amazed at the number of rather obtuse misunderstandings of the 
actual nature of Erin's question.

The suggestion that Erin should read the intro to R made me smile.  Erin 
is a long time and highly sophisticated user of R; she has no need to 
read the intro.  The person who made that suggestion should have read 
her question more thoughtfully.

Also I liked Steve Taylor's and Marc Swartz's nifty solutions that use 
sapply(); much sexier than my rather kludgy effort using do.call(). 
Berwin Turlach's combination of do.call() and sapply() is pretty sexy too.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From maechler at lynne.stat.math.ethz.ch  Fri Apr 24 11:34:56 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Apr 2015 11:34:56 +0200
Subject: [R] cbind question, please
In-Reply-To: <CCE952776B6679469977532BD863C39C9A6CC41E@Lewis.autuni.aut.ac.nz>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C9A6CC41E@Lewis.autuni.aut.ac.nz>
Message-ID: <21818.3648.987780.650869@stat.math.ethz.ch>

>>>>> Steve Taylor <steve.taylor at aut.ac.nz>
>>>>>     on Thu, 23 Apr 2015 23:32:00 +0000 writes:

    > This works for me...
    > get0 = function(x) get(x,pos=1)
    > sapply(big.char, get0)

Note that  get0() is a _ somewhat important for efficient code _
new function since R 3.2.0
so you'd rather call your functions differently...

    > The extra step seems necessary because without it, get() gets base::cat() instead of cat.

    > cheers,
    > Steve

    > -----Original Message-----
    > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
    > Sent: Friday, 24 April 2015 10:41a
    > To: R help
    > Subject: [R] cbind question, please

    > Hello!

    > I have a cbind type question, please:  Suppose I have the following:

    > dog <- 1:3
    > cat <- 2:4
    > tree <- 5:7

    > and a character vector
    > big.char <- c("dog","cat","tree")

    > I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
    > This is a toy example.  There will be a bunch of variables.

    > I experimented with "do.call", but all I got was
    > 1
    > 2
    > 3

    > Any suggestions would be much appreciated.  I still think that do.call
    > might be the key, but I'm not sure.

    > R Version 3-1.3, Windows 7.

    > Thanks,
    > Erin


    > -- 
    > Erin Hodgess
    > Associate Professor
    > Department of Mathematical and Statistics
    > University of Houston - Downtown
    > mailto: erinm.hodgess at gmail.com

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From jl.iccp at gmail.com  Fri Apr 24 12:47:51 2015
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Fri, 24 Apr 2015 12:47:51 +0200
Subject: [R] Mean of dates
Message-ID: <CAAMkPW9ysHD2DEHC-RrNBO-KJsO0AZipkxaqZmjhF__mZ1MvLA@mail.gmail.com>

Dear fellow R-help members,

If my data is

YYYY MM DD HH
2015 04 24 01
2015 04 24 02
2015 04 24 06

Where

YYYY: year
MM:month
DD:day
HH: hour

How could I calculate the mean of the ISOdatetime(YYYY,MM,DD,HH,0,0) of
these?

Note: I set minutes and seconds to 0, as I don't have data for them.

?Thank you in advance!?

-- 
Jue Lin-Ye

---------------------------------------------------------------
Civil Engineering phD candidate
Maritime Engineering Laboratory (LIM)
Universitat Polit?cnica de Catalunya (UPC)
C/Jordi Girona 1-3, Barcelona 08034 (Spain)
-----------------------------------------------------------------

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Fri Apr 24 12:59:52 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 24 Apr 2015 12:59:52 +0200 (CEST)
Subject: [R] Mean of dates
In-Reply-To: <CAAMkPW9ysHD2DEHC-RrNBO-KJsO0AZipkxaqZmjhF__mZ1MvLA@mail.gmail.com>
References: <CAAMkPW9ysHD2DEHC-RrNBO-KJsO0AZipkxaqZmjhF__mZ1MvLA@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1504241259240.9567@paninaro.uibk.ac.at>



On Fri, 24 Apr 2015, Jue Lin-Ye wrote:

> Dear fellow R-help members,
>
> If my data is
>
> YYYY MM DD HH
> 2015 04 24 01
> 2015 04 24 02
> 2015 04 24 06
>
> Where
>
> YYYY: year
> MM:month
> DD:day
> HH: hour
>
> How could I calculate the mean of the ISOdatetime(YYYY,MM,DD,HH,0,0) of
> these?

With the mean() method? On my machine:

R> mean(ISOdatetime(YYYY,MM,DD,HH,0,0))
[1] "2015-04-24 03:00:00 CEST"

hth,
Z

> Note: I set minutes and seconds to 0, as I don't have data for them.
>
> ?Thank you in advance!?
>
> -- 
> Jue Lin-Ye
>
> ---------------------------------------------------------------
> Civil Engineering phD candidate
> Maritime Engineering Laboratory (LIM)
> Universitat Polit?cnica de Catalunya (UPC)
> C/Jordi Girona 1-3, Barcelona 08034 (Spain)
> -----------------------------------------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drjimlemon at gmail.com  Fri Apr 24 13:22:38 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Apr 2015 21:22:38 +1000
Subject: [R] - Obtaining superscripts to affix to means that are not
 significantly different from each other with R
In-Reply-To: <OF8860DA7E.2E8F2BA1-ONC1257E30.00478D42-C1257E30.0047A99B@pcsierteelt.be>
References: <OF08D24A2A.37A9F44A-ONC1257E30.00366C83-C1257E30.0036BE89@pcsierteelt.be>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68680B@mb02.ads.tamu.edu>
	<OF8860DA7E.2E8F2BA1-ONC1257E30.00478D42-C1257E30.0047A99B@pcsierteelt.be>
Message-ID: <CA+8X3fXiqkWv0+vhrWbzwX+JpOa_CU4ARo1OyoVKANrrZJ5BUQ@mail.gmail.com>

Hi Joachim,
This function allows the user to set some characters in a string to
superscript or subscript. If sup or sub are set to one or more numbers
corresponding to an index in the string, those letters will be placed
appropriately. I can't properly test this as there is some problem
with X11 fonts that has appeared with the upgrade to R 3.2.0 and the
cex argument seems to have no effect.

supsubtext<-function(x,y,label,sup=NA,sub=NA,cex=1,sscex=0.8,xadj=0,...) {
 nlabchar<-nchar(label)
 yadj<-rep(0.5,nlabchar)
 if(!is.na(sup)) yadj[sup]<-0
 if(!is.na(sub)) yadj[sub]<-1
 labbits<-strsplit(label,"")[[1]]
 currentx<-x
 for(labchar in 1:nlabchar) {
  text(x,y,labbits[labchar],adj=c(xadj,yadj[labchar]),
   cex=ifelse(yadj[labchar]!=0.5,sscex,cex),...)
  x<-x+strwidth(labbits[labchar])
 }
}

Jim


On Thu, Apr 23, 2015 at 11:02 PM, Joachim Audenaert
<Joachim.Audenaert at pcsierteelt.be> wrote:
> Is there also a version for non parametric tests like:
>
> pairwise.wilcox.test {stats}
>
>
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
>
>
> From:   David L Carlson <dcarlson at tamu.edu>
> To:     Joachim Audenaert <Joachim.Audenaert at pcsierteelt.be>,
> "r-help at r-project.org" <r-help at r-project.org>
> Date:   23/04/2015 14:51
> Subject:        RE: [R] - Obtaining superscripts to affix to means that
> are not significantly different from each other with R
>
>
>
> The function cld() in package multcomp generates compact letter displays,
> but does not format them as exponents of the group names.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joachim
> Audenaert
> Sent: Thursday, April 23, 2015 4:58 AM
> To: r-help at r-project.org
> Subject: [R] - Obtaining superscripts to affix to means that are not
> significantly different from each other with R
>
> Hello all,
>
> It is often time consuming to interpret p-values of multiple pairwise
> comparisons of groups and assign them a letter code for publication
> purposes. So I found this interesting link to a program that does this for
>
> you.
>
> http://www.jerrydallal.com/lhsp/similar.htm
>
> I was wondering if something similar exists in R?
>
>
> Met vriendelijke groeten - With kind regards,
>
> Joachim Audenaert
> onderzoeker gewasbescherming - crop protection researcher
>
> PCS | proefcentrum voor sierteelt - ornamental plant research
>
> Schaessestraat 18, 9070 Destelbergen, Belgi?
> T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95
> E: joachim.audenaert at pcsierteelt.be | W: www.pcsierteelt.be
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think green,
>
> keep it on the screen!
>                  [[alternative HTML version deleted]]
>
>
>
>
> Heb je je individuele begeleiding bemesting (CVBB) al aangevraagd? | Het
> PCS op LinkedIn
> Disclaimer | Please consider the environment before printing. Think green,
> keep it on the screen!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jl.iccp at gmail.com  Fri Apr 24 13:47:30 2015
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Fri, 24 Apr 2015 13:47:30 +0200
Subject: [R] Mean of dates
In-Reply-To: <alpine.DEB.2.11.1504241259240.9567@paninaro.uibk.ac.at>
References: <CAAMkPW9ysHD2DEHC-RrNBO-KJsO0AZipkxaqZmjhF__mZ1MvLA@mail.gmail.com>
	<alpine.DEB.2.11.1504241259240.9567@paninaro.uibk.ac.at>
Message-ID: <CAAMkPW8VhhQ9yo5qT=D7Y5n6ZqBXVaoLWBEaKWE-Px9ttUM+TQ@mail.gmail.com>

On 24 April 2015 at 12:59, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:

>
>
> On Fri, 24 Apr 2015, Jue Lin-Ye wrote:
>
>  Dear fellow R-help members,
>>
>> If my data is
>>
>> YYYY MM DD HH
>> 2015 04 24 01
>> 2015 04 24 02
>> 2015 04 24 06
>>
>> Where
>>
>> YYYY: year
>> MM:month
>> DD:day
>> HH: hour
>>
>> How could I calculate the mean of the ISOdatetime(YYYY,MM,DD,HH,0,0) of
>> these?
>>
>
> With the mean() method? On my machine:
>
> R> mean(ISOdatetime(YYYY,MM,DD,HH,0,0))
> [1] "2015-04-24 03:00:00 CEST"
>
>
?Hi! Maybe the problem is when I try to create the vector that I am looking
for. Please ?check this code out.


?X_season1<-matrix(c(2015, 04, 24, 01, 2015 ,04, 24, 02,
  2015 ,04 ,24 ,03 ,2015 ,04 ,24 ,05,
  2015, 04, 24 ,06 ,2015, 04 ,24
,10),3,8,byrow=T);colnames(X_season1)<-c("AAi","MMi","DDi","HHi","AAf","MMf","DDf","HHf")
time2<-NULL
for(i5 in 1:nrow(X_season1)){
  time2[i5]<-mean(

as.Date(c(ISOdatetime(X_season1[i5,"AAi"],X_season1[i5,"MMi"],X_season1[i5,"DDi"],X_season1[i5,"HHi"],0,0),

ISOdatetime(X_season1[i5,"AAf"],X_season1[i5,"MMf"],X_season1[i5,"DDf"],X_season1[i5,"HHf"],0,0)),
                          format="%YYYY-%mm-%dd %H:%m:%s"),trim=0)}?

?Thanks!?



> hth,
> Z
>
>  Note: I set minutes and seconds to 0, as I don't have data for them.
>>
>> ?Thank you in advance!?
>>
>> --
>> Jue Lin-Ye
>>
>> ---------------------------------------------------------------
>> Civil Engineering phD candidate
>> Maritime Engineering Laboratory (LIM)
>> Universitat Polit?cnica de Catalunya (UPC)
>> C/Jordi Girona 1-3, Barcelona 08034 (Spain)
>> -----------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Jue Lin-Ye

---------------------------------------------------------------
Civil Engineering phD candidate
Maritime Engineering Laboratory (LIM)
Universitat Polit?cnica de Catalunya (UPC)
C/Jordi Girona 1-3, Barcelona 08034 (Spain)
-----------------------------------------------------------------

	[[alternative HTML version deleted]]


From laurent.franckx at vito.be  Fri Apr 24 15:49:31 2015
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Fri, 24 Apr 2015 13:49:31 +0000
Subject: [R] some general advice sought on the use of gctorture()
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF87159510DA@vitomail4.vito.local>

Dear all

I have bumped into the dreaded 'segfault' error type when running some C++ code using .Call().

I have already undertaken several attempts to debug the C++ code with gdb(), but until now I have been unable to pinpoint the origin of the problem. There are two elements that I think are puzzling (a) this .Call() has worked fine for about three years, for a variety of data (b)  the actual crash occurs at random points during the execution of the function (well, random from a human eye's point of view).

>From what I understand in the "R extensions" manual, the actual problem may have been around for a while before the actual call to the C++ code. As recommended in the manual, I am now using  gctorture() to try to pinpoint the origins of the problem. I can, alas, only confirm that gctorture() has an enormous impact on execution time, even for operations that are normally executed within the blink of an eye. From what I have seen until now, executing all the R code before the crash with gctorture(TRUE) could take months.

I suppose then that the best way to proceed would be to proceed backward from the point where the crash occurs when gctorture(FALSE).

I have tried to find some concrete examples of good practices in the use of gctorture() to identify memory problems in R, but most of what I have found on the web is simply a copy of the help page. Does anybody know more concrete and elaborated examples that could give an indication on how to best proceed further?





Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From david.kienle at uni-bayreuth.de  Fri Apr 24 09:32:59 2015
From: david.kienle at uni-bayreuth.de (David Kienle)
Date: Fri, 24 Apr 2015 09:32:59 +0200
Subject: [R] cbind question, please
In-Reply-To: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
References: <CACxE24nfuh+JWDqiGOrTJ81UbdoyWJQEScPB95Kzuxy5KstuAg@mail.gmail.com>
Message-ID: <5539F1AB.9090105@uni-bayreuth.de>

Hello Erin,

I think you have explain your goal more detailed. Maybe I am completely 
lost but as far as I understand now you only need the command cbind:

m1 <- cbind(dog, dat, tree)

  dog cat tree
[1,]   1   2    5
[2,]   2   3    6
[3,]   3   4    7

But I can't imagine that is the solution you are looking for.

Cheers
David


On 24.04.2015 00:41, Erin Hodgess wrote:
> Hello!
>
> I have a cbind type question, please:  Suppose I have the following:
>
> dog <- 1:3
> cat <- 2:4
> tree <- 5:7
>
> and a character vector
> big.char <- c("dog","cat","tree")
>
> I want to end up with a matrix that is a "cbind" of dog, cat, and tree.
> This is a toy example.  There will be a bunch of variables.
>
> I experimented with "do.call", but all I got was
> 1
> 2
> 3
>
> Any suggestions would be much appreciated.  I still think that do.call
> might be the key, but I'm not sure.
>
> R Version 3-1.3, Windows 7.
>
> Thanks,
> Erin
>
>

-- 
David Kienle

Department of Biogeography
University of Bayreuth

GEO II, Rm 003


From richard.perry3 at gmail.com  Fri Apr 24 12:42:58 2015
From: richard.perry3 at gmail.com (Richard Perry)
Date: Fri, 24 Apr 2015 11:42:58 +0100
Subject: [R] Possible bug in rlm
In-Reply-To: <0C52EDD1A3F3744598A6749A094A805901717530F2EB@QUANTICSSERVER.quantics.local>
References: <0C52EDD1A3F3744598A6749A094A805901717530F2EB@QUANTICSSERVER.quantics.local>
Message-ID: <CA+YFvuZQ+U-PxWG1f7xmi90-N8Wjpuv+JNqyzEZpGUNXB86qWw@mail.gmail.com>

Have just checked with R 3.2.0 and MASS 7.3-40 and there still appears to
be a problem/strangeness at around k=2.5



On 23 April 2015 at 14:09, Francis Bursa <Francis.Bursa at quantics.co.uk>
wrote:

> Dear all,
>
> I believe I have found a bug in rlm in the MASS package. Specifically, the
> scale estimate can be wrong when there are no outliers. The following code
> snippet is an example:
>
> dose <- c(0,1,2,0,1,2)
> response <- c(0.659,1.633,3.621,1.803,3.093,4.424)
> line <- c(1,1,1,2,2,2)
> k2 <- seq(1.5,5,by=0.01)
> repNA <- rep(NA,length(k2))
> scale <- repNA
> niter <- repNA
> for (i in 1:length(k2)){
>   rlm.fit <- rlm(response~dose+factor(line), psi=psi.huber,k=1.345,
>                          scale.est="proposal 2",k2=k2[i])
>   scale[i] <- rlm.fit$s
>   niter[i] <- length(rlm.fit$conv)
> }
> plot(k2,scale,type="b",col=niter)
>
> For this dataset there are no outliers, so I would expect the scale to be
> a smooth function of k2 once k2 is reasonably large, certainly for k2 > 2.
> However, there is a funny jump in the scale estimate around k2 = 2.4, just
> at the point where the number of iterations to convergence falls from 3 to
> 1.
>
> Looking at the source code, it appears that on each iteration, the scale
> is updated, then the parameters, and then a check for convergence is
> carried out just for the parameters, not the scale. So I would guess that
> in the range around k2=2.5 convergence is being reached when in fact the
> scale estimate hasn't converged.
>
> I am using MASS version 7.3-33 and R version 3.1.0 on Windows.
>
> I am not sure how common this issue is but there does not seem to be
> anything special about my dataset so it could be quite generic. Am I right
> that this is a bug?
>
> Many thanks,
> Francis Bursa
>
> ------------------
> Francis Bursa
> Statistician
>
> Quantics Consulting Ltd
> 28 Drumsheugh Gardens
> Edinburgh
> EH3 7RN
>
> Telephone: +44 (0) 131 440 2781 ext 207
>
> Quantics - complex data into clear results
> Quantics is an ISO 9001 registered company
>
> www.quantics.co.uk
>
> Please note that the contents of this e-mail (including any attachments)
> are confidential and may be legally privileged. If you are not the intended
> recipient you may not read, copy, distribute or make any other use of this
> email or its contents. If received in error, please tell us immediately by
> telephone on +44 (0) 131 440 2781 quoting the name of the sender and the
> intended recipient, then delete it from your system. Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From darth.pathos at gmail.com  Fri Apr 24 12:53:45 2015
From: darth.pathos at gmail.com (Chris Battiston)
Date: Fri, 24 Apr 2015 06:53:45 -0400
Subject: [R] Error increasing font size in R 3.2.0
Message-ID: <357B061D-53BD-4265-BB47-A2A7892A938D@gmail.com>

I wanted to increase the size of the font in R, but when I do, I get the error message below.  I've searched on Google, and the only thing I saw is about changing the version of X11.  I'm running the current version of X11, and running OS X Yosemite 10.10.3.  I'm using a Mac Desktop, 3.2 Ghz processor.

Any thoughts on how I can fix this?  Because I have 21.5 inch monitor, the default size of 8 is a little small for my liking.

2015-04-23 20:45:07.429 R[4458:2481342] Layout still needs update after calling -[NSScrollView layout].  NSScrollView or one of its superclasses may have overridden -layout without calling super. Or, something may have dirtied layout in the middle of updating it.  Both are programming errors in Cocoa Autolayout.  The former is pretty likely to arise if some pre-Cocoa Autolayout class had a method called layout, but it should be fixed.

Thanks so much for your help,
Chris
	[[alternative HTML version deleted]]


From mamadounsene at gmail.com  Fri Apr 24 14:26:32 2015
From: mamadounsene at gmail.com (Mamadou Ndiaye SENE)
Date: Fri, 24 Apr 2015 13:26:32 +0100
Subject: [R] help
Message-ID: <CAPSP91=giO6vhxNvVKOLE=N24EkouQSkA+BJHB8+yOAY=TtEeA@mail.gmail.com>

Bonjour, je suis un nouveau dans R. Je fais actuellement mon m?moire de
mast?re et je voudrais appliquer le Package BCDating. Mail il se trouve que
je re?ois toujours le message d'erreur suivant:
Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
mat_tp[r,  :
  l'argument est de longueur nulle
J'ai suivi les ?tapes suivantes:
LGDPTUND.ts= ts(data=LGDPTUND, start=c(2000,1), end=c(2014,3), frequency=4)
class(LGDPTUND.ts)
dat <-BBQ(LGDPTUND,name="Datation du Cycle Eco Tunisien")
Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
mat_tp[r,  :
  l'argument est de longueur nulle
Pour me pr?senter, je suis un jeune ?tudiant s?n?galais qui fais
actuellement ses ?tudes en Tunisie, en Economie Quantitative. Merci
Cordialement!!!

	[[alternative HTML version deleted]]


From pcubesingh at gmail.com  Fri Apr 24 14:38:14 2015
From: pcubesingh at gmail.com (Praveen kr singh)
Date: Fri, 24 Apr 2015 18:08:14 +0530
Subject: [R] lm() funtion
Message-ID: <CAARBARpEh-oLanm_8Wkafzqq_o-QpLE1YRrUarAYftje_a_UWQ@mail.gmail.com>

Hi,

Currently i am working with the lm() function for some regressions required
for my project.

suppose the formula parameter in that is given by "response ~  terms",after
some testing i found out that when  the number of observations under terms
is less than  the number of columns or features under terms, the
coefficients of regression generated from the linear model object contains
NA which makes it useless.

right now i am in situation where the number of observation is less than
the number of features , can someone help me how to apply regression in
this case.

-- 
*Praveen Kr Singh*
*Dept-CSE*
*HIT-K*

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Fri Apr 24 16:03:41 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Fri, 24 Apr 2015 07:03:41 -0700
Subject: [R] some general advice sought on the use of gctorture()
In-Reply-To: <3FA7C532AA08284AB2ACA7B0AB56EF87159510DA@vitomail4.vito.local>
References: <3FA7C532AA08284AB2ACA7B0AB56EF87159510DA@vitomail4.vito.local>
Message-ID: <553A4D3D.6050909@fredhutch.org>

On 04/24/2015 06:49 AM, Franckx Laurent wrote:
> Dear all
>
> I have bumped into the dreaded 'segfault' error type when running some C++
> code using .Call().

segfaults often involve invalid memory access at the C level that are best 
discovered via valgrind or similar rather than gctorture. A good way to spot 
these is to

(a) come up with a _minimal_ reproducible script test.R that takes just a few 
seconds to run and that tickles, at least some times, the segfault

(b) make sure that your package is compiled without optimizations and with 
debugging symbols, e.g., in  ~/.R/Makevars add the lines

   CFLAGS="-ggdb -O0"
   CXXFLAGS="-ggdb -O0"

(c) run the code under 'valgrind'

   R -d valgrind -f test.r

Look especially for 'invalid read' or 'invalid write' messages, and isolate 
_your_ code in the callback that the message produces.

There is a 'worked example' at

   http://bioconductor.org/developers/how-to/c-debugging/#case-study

Of course this might lead to nothing, and then you'll be back to your original 
question about using gctorture or other strategies.

Martin Morgan

>
> I have already undertaken several attempts to debug the C++ code with gdb(),
> but until now I have been unable to pinpoint the origin of the problem. There
> are two elements that I think are puzzling (a) this .Call() has worked fine
> for about three years, for a variety of data (b)  the actual crash occurs at
> random points during the execution of the function (well, random from a human
> eye's point of view).
>
>> From what I understand in the "R extensions" manual, the actual problem may
>> have been around for a while before the actual call to the C++ code. As
>> recommended in the manual, I am now using  gctorture() to try to pinpoint
>> the origins of the problem. I can, alas, only confirm that gctorture() has
>> an enormous impact on execution time, even for operations that are normally
>> executed within the blink of an eye. From what I have seen until now,
>> executing all the R code before the crash with gctorture(TRUE) could take
>> months.
>
> I suppose then that the best way to proceed would be to proceed backward from
> the point where the crash occurs when gctorture(FALSE).
>
> I have tried to find some concrete examples of good practices in the use of
> gctorture() to identify memory problems in R, but most of what I have found
> on the web is simply a copy of the help page. Does anybody know more concrete
> and elaborated examples that could give an indication on how to best proceed
> further?
>
>
>
>
>
> Laurent Franckx, PhD Senior researcher sustainable mobility VITO NV |
> Boeretang 200 | 2400 Mol Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 |
> Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx
>
>
>
>
> VITO Disclaimer: http://www.vito.be/e-maildisclaimer
>
> ______________________________________________ R-help at r-project.org mailing
> list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From jl.iccp at gmail.com  Fri Apr 24 16:06:00 2015
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Fri, 24 Apr 2015 16:06:00 +0200
Subject: [R] run Rscript and ignore errors?
Message-ID: <CAAMkPW_Vz9OZApHREmxOePEw1fRh-QmWcFVnM0Zy-q_tFrD+Tg@mail.gmail.com>

Jeff Newmiller <jdnewmil <at> dcn.davis.ca.us> writes:

>
> This seems like a recipe for garbage results to me, but there may be I
something you can set the error option
> to. See ?options.
>
---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
Live...
> DCN:<jdnewmil <at> dcn.davis.ca.us>        Basics: ##.#.       ##.#.
Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
rocks...1k
>
---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 23, 2015 9:51:31 AM PDT, Nick Matzke <nickmatzke.ncse <at>
gmail.com> wrote:
> >Hi R-help,
> >
> >I've looked at google, the Rscript documentation and the Rscript --help
> >output and haven't found much on this.  So, here's my question:
> >
> >I have a rather long script that runs on various input datasets.  It is
> >quite convenient to run the script from the Terminal command line with
> >"Rscript scriptname.R"
> >
> >However, some datasets will cause errors. These are non-essential
> >errors --
> >just some datasets don't have certain columns so certain parts of the
> >overall analysis don't produce figures etc.  Yes, I could go through
> >the
> >whole script and insert try() statements, etc.  But I'm lazy.
> >
> >So, is there a way to run Rscript or something similar, and just have
> >it
> >ignore all errors (i.e., keep running through the script)?  I.e., just
> >like
> >what happens if you just copy-paste the whole script into the R window
> >--
> >errors happen and are noted but the rest of the script keeps running.
> >
> >Thanks very much for any help!!
> >
> >Cheers!
> >Nick
> >

This is a really, really simple "life-hack" of mine after failed past
attemps to solve this
? issue?
:
Option
?1?
: Write an if(foreseen error){empty} so if _that_ happens, the code just
ignores it.
??Option 2: Try to run same code for the different initial values in
different windows, so if one stops, another one keeps running.?
I am interested in finding a real solution
? (like the one proposed above by Mr. Newmiller)?
, so I am looking forward to some more expert's say.

Best regards.

Jue

> >    [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Apr 24 16:09:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 24 Apr 2015 07:09:46 -0700
Subject: [R] some general advice sought on the use of gctorture()
In-Reply-To: <3FA7C532AA08284AB2ACA7B0AB56EF87159510DA@vitomail4.vito.local>
References: <3FA7C532AA08284AB2ACA7B0AB56EF87159510DA@vitomail4.vito.local>
Message-ID: <CFAF99BF-3C5A-45D1-BC06-1745D8E72B7E@dcn.davis.CA.us>

This is very off-topic here. My suggestion would be to do as the Posting Guide says and ask this on R-devel, or perhaps even a gdb forum. From what little I know, valgrind might help also.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 24, 2015 6:49:31 AM PDT, Franckx Laurent <laurent.franckx at vito.be> wrote:
>Dear all
>
>I have bumped into the dreaded 'segfault' error type when running some
>C++ code using .Call().
>
>I have already undertaken several attempts to debug the C++ code with
>gdb(), but until now I have been unable to pinpoint the origin of the
>problem. There are two elements that I think are puzzling (a) this
>.Call() has worked fine for about three years, for a variety of data
>(b)  the actual crash occurs at random points during the execution of
>the function (well, random from a human eye's point of view).
>
>>From what I understand in the "R extensions" manual, the actual
>problem may have been around for a while before the actual call to the
>C++ code. As recommended in the manual, I am now using  gctorture() to
>try to pinpoint the origins of the problem. I can, alas, only confirm
>that gctorture() has an enormous impact on execution time, even for
>operations that are normally executed within the blink of an eye. From
>what I have seen until now, executing all the R code before the crash
>with gctorture(TRUE) could take months.
>
>I suppose then that the best way to proceed would be to proceed
>backward from the point where the crash occurs when gctorture(FALSE).
>
>I have tried to find some concrete examples of good practices in the
>use of gctorture() to identify memory problems in R, but most of what I
>have found on the web is simply a copy of the help page. Does anybody
>know more concrete and elaborated examples that could give an
>indication on how to best proceed further?
>
>
>
>
>
>Laurent Franckx, PhD
>Senior researcher sustainable mobility
>VITO NV | Boeretang 200 | 2400 Mol
>Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx
>| laurent.franckx at vito.be | Twitter @LaurentFranckx
>
>
>
>
>VITO Disclaimer: http://www.vito.be/e-maildisclaimer
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sudipanalyst at gmail.com  Fri Apr 24 16:12:16 2015
From: sudipanalyst at gmail.com (Sudip Chatterjee)
Date: Fri, 24 Apr 2015 19:42:16 +0530
Subject: [R] Plots without X11 in CentOS
Message-ID: <CAP33S-8e9MUGN--w-M4Zby73uLV4rShsNo4-V+TUT0w552U5qw@mail.gmail.com>

Hi All,

 I am wondering how to save plots in R at CentOS when X11 is not available,
any suggestion would be appreciated.

 Warm Regards
 Sudip

	[[alternative HTML version deleted]]


From msuzen at gmail.com  Fri Apr 24 16:15:05 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Fri, 24 Apr 2015 15:15:05 +0100
Subject: [R] lm() funtion
In-Reply-To: <CAARBARpEh-oLanm_8Wkafzqq_o-QpLE1YRrUarAYftje_a_UWQ@mail.gmail.com>
References: <CAARBARpEh-oLanm_8Wkafzqq_o-QpLE1YRrUarAYftje_a_UWQ@mail.gmail.com>
Message-ID: <CAPtbhHyKXHG7y=CqYNZ5ZSMo1vvn5GM7Q1dS+ZW4KRB+7EeOcw@mail.gmail.com>

try lm.ridge from MASS package.


From pdalgd at gmail.com  Fri Apr 24 16:41:19 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 24 Apr 2015 16:41:19 +0200
Subject: [R] Plots without X11 in CentOS
In-Reply-To: <CAP33S-8e9MUGN--w-M4Zby73uLV4rShsNo4-V+TUT0w552U5qw@mail.gmail.com>
References: <CAP33S-8e9MUGN--w-M4Zby73uLV4rShsNo4-V+TUT0w552U5qw@mail.gmail.com>
Message-ID: <ECB98775-E9F5-43BA-A863-6319415CB09B@gmail.com>

Plot directly to the appropriate device, e.g. 

pdf(file="my.pdf")
plot(rnorm(500))
dev.off()

This is often recommendable even if you do have an on-screen graphics device because some subtleties can get lost in translation for one device to another. (The prototypical example is that a legend box is sized to hold the text in the font used on the screen device. Then, saving to PDF causes the box to be scaled and the font to change, but it can happen that the text now overruns the box extents.)

Peter D.

On 24 Apr 2015, at 16:12 , Sudip Chatterjee <sudipanalyst at gmail.com> wrote:

> Hi All,
> 
> I am wondering how to save plots in R at CentOS when X11 is not available,
> any suggestion would be appreciated.
> 
> Warm Regards
> Sudip
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Fri Apr 24 17:18:58 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 24 Apr 2015 08:18:58 -0700
Subject: [R] lm() funtion
In-Reply-To: <CAARBARpEh-oLanm_8Wkafzqq_o-QpLE1YRrUarAYftje_a_UWQ@mail.gmail.com>
References: <CAARBARpEh-oLanm_8Wkafzqq_o-QpLE1YRrUarAYftje_a_UWQ@mail.gmail.com>
Message-ID: <CACk-te3am9LbXNUy5TX90pGUFrE=pOcwQ87w+nfMRhgVqZkxgA@mail.gmail.com>

You really really really need to work with a local statistical expert, as
your post indicates fundamental confusion. Furthermore, statistical issues
are off topic here.

Cheers,
Bert

On Friday, April 24, 2015, Praveen kr singh <pcubesingh at gmail.com> wrote:

> Hi,
>
> Currently i am working with the lm() function for some regressions required
> for my project.
>
> suppose the formula parameter in that is given by "response ~  terms",after
> some testing i found out that when  the number of observations under terms
> is less than  the number of columns or features under terms, the
> coefficients of regression generated from the linear model object contains
> NA which makes it useless.
>
> right now i am in situation where the number of observation is less than
> the number of features , can someone help me how to apply regression in
> this case.
>
> --
> *Praveen Kr Singh*
> *Dept-CSE*
> *HIT-K*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From francois.morneau at ign.fr  Fri Apr 24 17:46:25 2015
From: francois.morneau at ign.fr (=?windows-1252?Q?Fran=E7ois_Morneau?=)
Date: Fri, 24 Apr 2015 17:46:25 +0200
Subject: [R] help
In-Reply-To: <CAPSP91=giO6vhxNvVKOLE=N24EkouQSkA+BJHB8+yOAY=TtEeA@mail.gmail.com>
References: <CAPSP91=giO6vhxNvVKOLE=N24EkouQSkA+BJHB8+yOAY=TtEeA@mail.gmail.com>
Message-ID: <553A6551.2040807@ign.fr>

Hello,
Please, read and follow the posting guide and provide a minimal 
reproducible example as you are encouraged to do. Moreover, write to the 
list in english.
Just a quick test : have you looked at your object 'mat_tp' :
 >  str(mat_tp)
Bon courage,
Fran?ois


Le 24/04/2015 14:26, Mamadou Ndiaye SENE a ?crit :
> Bonjour, je suis un nouveau dans R. Je fais actuellement mon m?moire de
> mast?re et je voudrais appliquer le Package BCDating. Mail il se trouve que
> je re?ois toujours le message d'erreur suivant:
> Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
> mat_tp[r,  :
>    l'argument est de longueur nulle
> J'ai suivi les ?tapes suivantes:
> LGDPTUND.ts= ts(data=LGDPTUND, start=c(2000,1), end=c(2014,3), frequency=4)
> class(LGDPTUND.ts)
> dat <-BBQ(LGDPTUND,name="Datation du Cycle Eco Tunisien")
> Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
> mat_tp[r,  :
>    l'argument est de longueur nulle
> Pour me pr?senter, je suis un jeune ?tudiant s?n?galais qui fais
> actuellement ses ?tudes en Tunisie, en Economie Quantitative. Merci
> Cordialement!!!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matzke at nimbios.org  Fri Apr 24 18:47:58 2015
From: matzke at nimbios.org (Nick Matzke)
Date: Fri, 24 Apr 2015 12:47:58 -0400
Subject: [R] run Rscript and ignore errors?
In-Reply-To: <CAAMkPW_Vz9OZApHREmxOePEw1fRh-QmWcFVnM0Zy-q_tFrD+Tg@mail.gmail.com>
References: <CAAMkPW_Vz9OZApHREmxOePEw1fRh-QmWcFVnM0Zy-q_tFrD+Tg@mail.gmail.com>
Message-ID: <CAJdu7BDgQiJpDsh8EzWX5gKAoo3fo7gsW0zeY8dDBmpaqOf6kg@mail.gmail.com>

Hi,

Thanks so much for the hints, I think I've cracked it!  The key is to
create a dummy function, "continue_on_error" which gets run instead of
"stop" when an error occurs, then reference it
with options(error=continue_on_error).  Here's an example:


==========================
continue_on_error <- function()
{
print("NOTE: THERE WAS AN ERROR HERE. We are continuing because we have set
'options(error=continue_on_error())'")
}

testfunc <- function(a,b)
{
print(a+b)
}

# This is the key option
options(error=continue_on_error)

print(1)
print(2)

# This should work
testfunc(a=10, b=10)

print(3)

# This should produce an error and stop the Rscript run normally
testfunc(a=1)

print(4)
print(5)
==========================


Running this via Rscript completes:

Rscript continue_on_error.R
================
[1] 1
[1] 2
[1] 20
[1] 3
Error in print(a + b) : argument "b" is missing, with no default
Calls: testfunc -> print
[1] "NOTE: THERE WAS AN ERROR HERE. We are continuing because we have set
'options(error=continue_on_error())'"
[1] 4
[1] 5
================

If you comment out the options() line you get:

Rscript continue_on_error.R
================
[1] 1
[1] 2
[1] 20
[1] 3
Error in print(a + b) : argument "b" is missing, with no default
Calls: testfunc -> print
Execution halted
================

...which was what was annoying me before.

So, life hack FTW.  (Of course, yes, it would be better to write code good
n stuff, but for quick and dirty things this is handy.)

Cheers!
Nick



On Fri, Apr 24, 2015 at 10:06 AM, Jue Lin-Ye <jl.iccp at gmail.com> wrote:

> Jeff Newmiller <jdnewmil <at> dcn.davis.ca.us> writes:
>
> >
> > This seems like a recipe for garbage results to me, but there may be I
> something you can set the error option
> > to. See ?options.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil <at> dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> Live Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On April 23, 2015 9:51:31 AM PDT, Nick Matzke <nickmatzke.ncse <at>
> gmail.com> wrote:
> > >Hi R-help,
> > >
> > >I've looked at google, the Rscript documentation and the Rscript --help
> > >output and haven't found much on this.  So, here's my question:
> > >
> > >I have a rather long script that runs on various input datasets.  It is
> > >quite convenient to run the script from the Terminal command line with
> > >"Rscript scriptname.R"
> > >
> > >However, some datasets will cause errors. These are non-essential
> > >errors --
> > >just some datasets don't have certain columns so certain parts of the
> > >overall analysis don't produce figures etc.  Yes, I could go through
> > >the
> > >whole script and insert try() statements, etc.  But I'm lazy.
> > >
> > >So, is there a way to run Rscript or something similar, and just have
> > >it
> > >ignore all errors (i.e., keep running through the script)?  I.e., just
> > >like
> > >what happens if you just copy-paste the whole script into the R window
> > >--
> > >errors happen and are noted but the rest of the script keeps running.
> > >
> > >Thanks very much for any help!!
> > >
> > >Cheers!
> > >Nick
> > >
>
> This is a really, really simple "life-hack" of mine after failed past
> attemps to solve this
> ? issue?
> :
> Option
> ?1?
> : Write an if(foreseen error){empty} so if _that_ happens, the code just
> ignores it.
> ??Option 2: Try to run same code for the different initial values in
> different windows, so if one stops, another one keeps running.?
> I am interested in finding a real solution
> ? (like the one proposed above by Mr. Newmiller)?
> , so I am looking forward to some more expert's say.
>
> Best regards.
>
> Jue
>
> > >    [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Apr 24 19:34:27 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 24 Apr 2015 09:34:27 -0800
Subject: [R] help
In-Reply-To: <CAPSP91=giO6vhxNvVKOLE=N24EkouQSkA+BJHB8+yOAY=TtEeA@mail.gmail.com>
Message-ID: <C88FDF675FA.00000B19jrkrideau@inbox.com>

Bonjour,

We need more information.  See Reproducibility http://adv-r.had.co.nz/Reproducibility.html  for some suggestions on how to ask a question.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: mamadounsene at gmail.com
> Sent: Fri, 24 Apr 2015 13:26:32 +0100
> To: r-help at r-project.org
> Subject: [R] help
> 
> Bonjour, je suis un nouveau dans R. Je fais actuellement mon m?moire de
> mast?re et je voudrais appliquer le Package BCDating. Mail il se trouve
> que
> je re?ois toujours le message d'erreur suivant:
> Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
> mat_tp[r,  :
>   l'argument est de longueur nulle
> J'ai suivi les ?tapes suivantes:
> LGDPTUND.ts= ts(data=LGDPTUND, start=c(2000,1), end=c(2014,3),
> frequency=4)
> class(LGDPTUND.ts)
> dat <-BBQ(LGDPTUND,name="Datation du Cycle Eco Tunisien")
> Erreur dans if (mat_tp[r, 1] < n) mat_tp <- rbind(mat_tp, c(n, 1 -
> mat_tp[r,  :
>   l'argument est de longueur nulle
> Pour me pr?senter, je suis un jeune ?tudiant s?n?galais qui fais
> actuellement ses ?tudes en Tunisie, en Economie Quantitative. Merci
> Cordialement!!!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From fisher at plessthan.com  Fri Apr 24 20:01:26 2015
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 24 Apr 2015 11:01:26 -0700
Subject: [R] JPEG command not responding to size options
Message-ID: <A17B4666-400E-4B56-AE59-7DB9607E985D@plessthan.com>

R 3.2.0
OS X

Colleagues

I have a script that has been unchanged for years but I just noticed a difference in the output.  A minimal example is:
	jpeg(file="xxx.jpeg", width=4, height=2, unit="in", pointsize=12, bg="white", res=150, quality=100)
	plot(1)
	graphics.off()
	system("open xxx.jpeg")	## works in OS X -- use 'start' instead of 'open' in Windows

In the past (probably more than several months ago, although I can?t identify when the change occurred), this yielded a graphic that appears to be the intended size (4 x 2).  I assess this based on the size on the screen and the size when I drag the file to a Word document.

With R 3.2.0 (and 3.1.3), the image is appreciably larger, i.e., the width and height options appear to be ignored.  
OS X?s Preview application includes an inspector that provided information about the images.
In the earlier incarnations, Inspector reported that the image has 150 pixels / inch.  With 3.2.0, it shows 72 pixels / inch.

I think that the problem is as follows ? the image is created with the correct number of pixels ? but the info as to pixels / inch is not being handled correctly.
I can confirm this by replacing 
	res=150
with 
	res=72
The resulting image is the intended size.

Is this a bug?  The workaround appears to be restoring res=72 but that does not seem to be an ideal solution.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From alej.c.s at gmail.com  Sat Apr 25 00:46:50 2015
From: alej.c.s at gmail.com (Alejo C.S.)
Date: Fri, 24 Apr 2015 19:46:50 -0300
Subject: [R] Extract latitude and longitude from several geottaged jpeg files
Message-ID: <CAEeP31t-7My-wSbAj7Wzo2w+QgL=QT6w6oHhay4xaJ-eFbHe=g@mail.gmail.com>

Hi all, I have several jpeg files with lat long information. I want to make
a lat long table whit this info. Anyone knows how to do it? Can't find
anything in google.

Thanks a lot in advance

A.

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Sat Apr 25 01:42:21 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 24 Apr 2015 23:42:21 +0000
Subject: [R] Extract latitude and longitude from several geottaged jpeg
 files
In-Reply-To: <CAEeP31t-7My-wSbAj7Wzo2w+QgL=QT6w6oHhay4xaJ-eFbHe=g@mail.gmail.com>
References: <CAEeP31t-7My-wSbAj7Wzo2w+QgL=QT6w6oHhay4xaJ-eFbHe=g@mail.gmail.com>
Message-ID: <D1602272.126AC8%macqueen1@llnl.gov>

That's a pretty vague question, but you might be able to do it with
functions from the raster package.

Followup on this topic should be to R-sig-geo.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/24/15, 3:46 PM, "Alejo C.S." <alej.c.s at gmail.com> wrote:

>Hi all, I have several jpeg files with lat long information. I want to
>make
>a lat long table whit this info. Anyone knows how to do it? Can't find
>anything in google.
>
>Thanks a lot in advance
>
>A.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Sat Apr 25 02:52:06 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 25 Apr 2015 00:52:06 +0000
Subject: [R] Extract latitude and longitude from several geottaged jpeg
	files
In-Reply-To: <CAEeP31t-7My-wSbAj7Wzo2w+QgL=QT6w6oHhay4xaJ-eFbHe=g@mail.gmail.com>
References: <CAEeP31t-7My-wSbAj7Wzo2w+QgL=QT6w6oHhay4xaJ-eFbHe=g@mail.gmail.com>
Message-ID: <CAAcGz9_g8RYkHYEA5pfpfHaGJv0qOyp9O+BfX9Lj1SF4paQjfw@mail.gmail.com>

Geospatial image maps or just exif tags?

Search for "r exif" for several leads.

Cheers, Mike

On Sat, Apr 25, 2015, 08:48 Alejo C.S. <alej.c.s at gmail.com> wrote:

> Hi all, I have several jpeg files with lat long information. I want to make
> a lat long table whit this info. Anyone knows how to do it? Can't find
> anything in google.
>
> Thanks a lot in advance
>
> A.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Fri Apr 24 21:17:47 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 24 Apr 2015 19:17:47 +0000
Subject: [R] obtaining the sum of lagged variables
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536E024@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,
I am trying to replicate the formula shown in the attachment. I want to estimate tau using a macroeconomic variable X at month t using k lags of the variable X.
My code so far looks as follows:

psi <- fn(...)
k <- 1:K
ltau <- m + theta*sum(psi*X[t-k])

Unfortunately, if I run the code as shown the result I get is NA but I want to obtain a list of ltaus at month t.
ltau <- m + theta*sum(psi*X[t-k])
> ltau
[1] NA


Hence I defined t and ran X[t-k] and get following results. That is, X[t-k] provides every third element in my data table three times instead of calculating the sum of the lagged observations multiplied with psi

t<-1:15



> t

 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15

> X[t-k]

 [1] -0.25 -0.25 -0.25  0.50  0.50  0.50 -0.44 -0.44 -0.44  0.15  0.15  0.15

How do I get the list of taus at month t based on the sum of lagged observations as shown in the attachment?
Thanks in advance

-------------- next part --------------
A non-text attachment was scrubbed...
Name: tau.png
Type: image/png
Size: 8142 bytes
Desc: tau.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150424/f6171af4/attachment.png>

From aasdelat at aim.com  Sat Apr 25 00:37:35 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Fri, 24 Apr 2015 18:37:35 -0400
Subject: [R] Interactive maps
Message-ID: <14ced9434a5-238a-16312@webprd-a80.mail.aol.com>


 Hello, all:

   I am new here, and have a challenge to present some graphical data to the user in a convenient way.

   The challenge is to present a map to the user which is coloured with the value of a variable. Say for example, temperature. This is a preexisting graph that I can generate in any format, including svg. I don't have to produce it using R.

   When the user clicks anywhere in the map, the coordinates (longitude and latitude) have to be passed to R so that this, R, can look for the values of other variables in that location and make another graph with them.

   Does anyubody know how could I accomplish this?.

   Thanks in advance.

 

Antonio Serrano
aasdelat at aim.com
?


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Apr 24 02:51:31 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 23 Apr 2015 16:51:31 -0800
Subject: [R] Why is removeSparseTerms() not doing anything?
In-Reply-To: <1451051007.2249683.1429728765369.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <BFCE248E7BD.00000116jrkrideau@inbox.com>

Reproducibility
http://adv-r.had.co.nz/Reproducibility.html  
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


John Kane
Kingston ON Canada


> -----Original Message-----
> From: mikehall at y7mail.com
> Sent: Wed, 22 Apr 2015 18:52:45 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Why is removeSparseTerms() not doing anything?
> 
> Here's the code and results.? The corpus is the text version of a single
> book.?? (r vs. 3.2)
>> docs <- tm_map(docs, stemDocument)
>> dtm <- DocumentTermMatrix(docs)
>> freq <- colSums(as.matrix(dtm))
>> ord <- order(freq)
>> freq[tail(ord)]
> one experi   will   can lucid dream
> 287   312   363   452   1018   2413
>> freq[head(ord)]
> abbey abdomin   abdu abraham absent   abus
>   1       1       1       1       1       1
>> dim(dtm)
> [1]   1 5265
>> dtms <- removeSparseTerms(dtm, 0.1)
>> dim(dtms)
> [1]   1 5265
>> dtms <- removeSparseTerms(dtm, 0.001)
>> dim(dtms)
> [1]   1 5265
>> dtms <- removeSparseTerms(dtm, 0.9)
>> dim(dtms)
> [1]   1 5265
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From drjimlemon at gmail.com  Sat Apr 25 05:47:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 25 Apr 2015 13:47:23 +1000
Subject: [R] Interactive maps
In-Reply-To: <14ced9434a5-238a-16312@webprd-a80.mail.aol.com>
References: <14ced9434a5-238a-16312@webprd-a80.mail.aol.com>
Message-ID: <CA+8X3fU2yj5M-kFd24haVuAA8jEpR_W8dpg7A7ueAT45yT4WDA@mail.gmail.com>

Hi Antonio,
If you do create the map in R, you can use locator().

Jim


On Sat, Apr 25, 2015 at 8:37 AM, Antonio Serrano via R-help
<r-help at r-project.org> wrote:
>
>  Hello, all:
>
>    I am new here, and have a challenge to present some graphical data to the user in a convenient way.
>
>    The challenge is to present a map to the user which is coloured with the value of a variable. Say for example, temperature. This is a preexisting graph that I can generate in any format, including svg. I don't have to produce it using R.
>
>    When the user clicks anywhere in the map, the coordinates (longitude and latitude) have to be passed to R so that this, R, can look for the values of other variables in that location and make another graph with them.
>
>    Does anyubody know how could I accomplish this?.
>
>    Thanks in advance.
>
>
>
> Antonio Serrano
> aasdelat at aim.com
> ?
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sudipanalyst at gmail.com  Sat Apr 25 05:57:33 2015
From: sudipanalyst at gmail.com (Sudip Chatterjee)
Date: Sat, 25 Apr 2015 09:27:33 +0530
Subject: [R] Plots without X11 in CentOS
In-Reply-To: <ECB98775-E9F5-43BA-A863-6319415CB09B@gmail.com>
References: <CAP33S-8e9MUGN--w-M4Zby73uLV4rShsNo4-V+TUT0w552U5qw@mail.gmail.com>
	<ECB98775-E9F5-43BA-A863-6319415CB09B@gmail.com>
Message-ID: <CAP33S-_x4O04gHOv1=3MHZ+2vFo6gOXRm2kJE-fghSLz1JXHxw@mail.gmail.com>

Hi Peter,

 I did the same but I received an error stating X11 is not available.

On Fri, Apr 24, 2015 at 8:11 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> Plot directly to the appropriate device, e.g.
>
> pdf(file="my.pdf")
> plot(rnorm(500))
> dev.off()
>
> This is often recommendable even if you do have an on-screen graphics
> device because some subtleties can get lost in translation for one device
> to another. (The prototypical example is that a legend box is sized to hold
> the text in the font used on the screen device. Then, saving to PDF causes
> the box to be scaled and the font to change, but it can happen that the
> text now overruns the box extents.)
>
> Peter D.
>
> On 24 Apr 2015, at 16:12 , Sudip Chatterjee <sudipanalyst at gmail.com>
> wrote:
>
> > Hi All,
> >
> > I am wondering how to save plots in R at CentOS when X11 is not
> available,
> > any suggestion would be appreciated.
> >
> > Warm Regards
> > Sudip
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Apr 25 09:43:24 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 25 Apr 2015 09:43:24 +0200
Subject: [R] Plots without X11 in CentOS
In-Reply-To: <CAP33S-_x4O04gHOv1=3MHZ+2vFo6gOXRm2kJE-fghSLz1JXHxw@mail.gmail.com>
References: <CAP33S-8e9MUGN--w-M4Zby73uLV4rShsNo4-V+TUT0w552U5qw@mail.gmail.com>
	<ECB98775-E9F5-43BA-A863-6319415CB09B@gmail.com>
	<CAP33S-_x4O04gHOv1=3MHZ+2vFo6gOXRm2kJE-fghSLz1JXHxw@mail.gmail.com>
Message-ID: <CFCA50CF-6512-475B-9745-5F0C401E2A96@gmail.com>


> On 25 Apr 2015, at 05:57 , Sudip Chatterjee <sudipanalyst at gmail.com> wrote:
> 
> Hi Peter, 
> 
>  I did the same but I received an error stating X11 is not available.

Hm?? Did something change while I wasn't looking? I'd expect PDF to be handled by the postscript driver and be independent of X11. 

Could you show a transcript of exactly what you did? Maybe include capabilities() and value of dev.cur() just before plotting.

-pd


> 
> On Fri, Apr 24, 2015 at 8:11 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> Plot directly to the appropriate device, e.g.
> 
> pdf(file="my.pdf")
> plot(rnorm(500))
> dev.off()
> 
> This is often recommendable even if you do have an on-screen graphics device because some subtleties can get lost in translation for one device to another. (The prototypical example is that a legend box is sized to hold the text in the font used on the screen device. Then, saving to PDF causes the box to be scaled and the font to change, but it can happen that the text now overruns the box extents.)
> 
> Peter D.
> 
> On 24 Apr 2015, at 16:12 , Sudip Chatterjee <sudipanalyst at gmail.com> wrote:
> 
> > Hi All,
> >
> > I am wondering how to save plots in R at CentOS when X11 is not available,
> > any suggestion would be appreciated.
> >
> > Warm Regards
> > Sudip
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From aasdelat at aim.com  Sat Apr 25 08:19:17 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Sat, 25 Apr 2015 02:19:17 -0400
Subject: [R] Interactive maps
In-Reply-To: <CA+8X3fU2yj5M-kFd24haVuAA8jEpR_W8dpg7A7ueAT45yT4WDA@mail.gmail.com>
Message-ID: <14cef3aea05-67b0-18e91@webprd-m87.mail.aol.com>


Thank you, Jim.

I didn't know the existence of the locator() function. But I can see now that I don't know how to read a graphic image into R to work with it.
How can I read a pre-exisiting image into R?.

Thanks again

 

 

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com>
To: Antonio Serrano <aasdelat at aim.com>
Cc: r-help mailing list <r-help at r-project.org>
Sent: Sat, Apr 25, 2015 5:47 am
Subject: Re: [R] Interactive maps


Hi Antonio,
If you do create the map in R, you can use
locator().

Jim


On Sat, Apr 25, 2015 at 8:37 AM, Antonio Serrano via
R-help
<r-help at r-project.org> wrote:
>
>  Hello, all:
>
>    I am new here,
and have a challenge to present some graphical data to the user in a convenient
way.
>
>    The challenge is to present a map to the user which is coloured
with the value of a variable. Say for example, temperature. This is a
preexisting graph that I can generate in any format, including svg. I don't have
to produce it using R.
>
>    When the user clicks anywhere in the map, the
coordinates (longitude and latitude) have to be passed to R so that this, R, can
look for the values of other variables in that location and make another graph
with them.
>
>    Does anyubody know how could I accomplish this?.
>
>   
Thanks in advance.
>
>
>
> Antonio Serrano
> aasdelat at aim.com
> ?
>
>
>
[[alternative HTML version deleted]]
>
>
______________________________________________
> R-help at r-project.org mailing
list -- To UNSUBSCRIBE and more, see
>
https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal,
self-contained, reproducible code.



	[[alternative HTML version deleted]]


From s.f.jalaei at gmail.com  Sat Apr 25 15:46:34 2015
From: s.f.jalaei at gmail.com (s f jalaei)
Date: Sat, 25 Apr 2015 15:46:34 +0200
Subject: [R] download
Message-ID: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>

I am a student from Sweden.
I would like to download and install R program to work on statistics.
If I want to download 2014 version, how I can do this.
Also, do I need to choose Sweden in Cran Mirrors list?

Regards,

Fatemeh

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Apr 26 00:26:41 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 26 Apr 2015 10:26:41 +1200
Subject: [R] download
In-Reply-To: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
References: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
Message-ID: <553C14A1.6030404@auckland.ac.nz>



On 26/04/15 01:46, s f jalaei wrote:

> I am a student from Sweden.

My heartiest condolences to you! :-)

> I would like to download and install R program to work on statistics.

Go for it!  No home should be without one! :-)

> If I want to download 2014 version, how I can do this.

Why on earth not use the latest and greatest, which is simple and easy?

If you insist on using an antiquated version you will have to install 
from source, which can be a little bit of a challenge --- particularly 
if you are using Windoze, which I presume (Psigh!!!) that you are.

To get a source tar ball for an antiquated version, go to the R web 
site, click on CRAN, choose your mirror, click on

     "Source code of older versions of R is available here."

and then choose "R3" for 2014 releases.

> Also, do I need to choose Sweden in Cran Mirrors list?

Why don't you just try, and see?  No one will shoot you.  But the answer 
is no, you don't need to.  It's supposed to be somewhat quicker/more 
efficient to choose a mirror that is geographically close to you, but I 
doubt that you'd really notice much difference in performance between a 
Swedish mirror and an Australian one.  OTOH you *might as well* use a 
Swedish mirror.  I mean, like, why not?  Are you trying to hide your 
tracks from the NSA? :-)

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From ligges at statistik.tu-dortmund.de  Sun Apr 26 00:52:53 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 26 Apr 2015 00:52:53 +0200
Subject: [R] download
In-Reply-To: <553C14A1.6030404@auckland.ac.nz>
References: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
	<553C14A1.6030404@auckland.ac.nz>
Message-ID: <553C1AC5.2040202@statistik.tu-dortmund.de>



On 26.04.2015 00:26, Rolf Turner wrote:
>
>
> On 26/04/15 01:46, s f jalaei wrote:
>
>> I am a student from Sweden.
>
> My heartiest condolences to you! :-)
>
>> I would like to download and install R program to work on statistics.
>
> Go for it!  No home should be without one! :-)
>
>> If I want to download 2014 version, how I can do this.
>
> Why on earth not use the latest and greatest, which is simple and easy?
>
> If you insist on using an antiquated version you will have to install
> from source, which can be a little bit of a challenge --- particularly
> if you are using Windoze, which I presume (Psigh!!!) that you are.


Well, even then, the binaries are there for old releases of R. Just 
click on "R Binaries"->"windows"->"base"->"Previous releases" and select 
the right one for you. No idea wha you need that as a student who learns R.

Best,
Uwe Ligges



> To get a source tar ball for an antiquated version, go to the R web
> site, click on CRAN, choose your mirror, click on
>
>      "Source code of older versions of R is available here."
>
> and then choose "R3" for 2014 releases.
>
>> Also, do I need to choose Sweden in Cran Mirrors list?
>
> Why don't you just try, and see?  No one will shoot you.  But the answer
> is no, you don't need to.  It's supposed to be somewhat quicker/more
> efficient to choose a mirror that is geographically close to you, but I
> doubt that you'd really notice much difference in performance between a
> Swedish mirror and an Australian one.  OTOH you *might as well* use a
> Swedish mirror.  I mean, like, why not?  Are you trying to hide your
> tracks from the NSA? :-)
>
> cheers,
>
> Rolf Turner
>


From jrkrideau at inbox.com  Sun Apr 26 01:54:08 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 25 Apr 2015 15:54:08 -0800
Subject: [R] download
In-Reply-To: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
Message-ID: <D87334E712D.000007EBjrkrideau@inbox.com>


> -----Original Message-----
> From: s.f.jalaei at gmail.com
> Sent: Sat, 25 Apr 2015 15:46:34 +0200
> To: r-help at r-project.org
> Subject: [R] download
> 
> I am a student from Sweden.

Welcome from Canada

> I would like to download and install R program to work on statistics.
> If I want to download 2014 version, how I can do this.

That is not a version. That is a year.  The most recent version is R 3.2.0  with the date of (2015-04-16).  

> Also, do I need to choose Sweden in Cran Mirrors list?

No but it is better to do so. Less traffic on the web.

> Regards,
>  Fatemeh

Welcome to R and the R-help list

____________________________________________________________
Publish your photos in seconds for FREE
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if4


From mdsumner at gmail.com  Sun Apr 26 02:48:54 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 26 Apr 2015 00:48:54 +0000
Subject: [R] Interactive maps
In-Reply-To: <14cef3aea05-67b0-18e91@webprd-m87.mail.aol.com>
References: <CA+8X3fU2yj5M-kFd24haVuAA8jEpR_W8dpg7A7ueAT45yT4WDA@mail.gmail.com>
	<14cef3aea05-67b0-18e91@webprd-m87.mail.aol.com>
Message-ID: <CAAcGz9-z2xgybJKjbJA9qg2fGTGep5M8kCrNZMNjTRYSmCuyjw@mail.gmail.com>

On Sun, 26 Apr 2015 at 00:56 Antonio Serrano via R-help <
r-help at r-project.org> wrote:

>
> Thank you, Jim.
>
> I didn't know the existence of the locator() function. But I can see now
> that I don't know how to read a graphic image into R to work with it.
> How can I read a pre-exisiting image into R?.
>
> See the raster (and possibly rgdal - depending on your format/s) package
to read in images that are georeferenced. Depending on the provenance of
your files, it might be as simple as doing
library(raster)
r <- raster(filename)
plort(r)
xy <- locator(, type = "p")  ## click on the map

If the values of these are not right you'll need further digging, and
perhaps if your image is not in longitude/latitude you'll need to transform
the locator points.

Also check out ?getGraphics event in grDevices, which can be used (with
care) to build quite complex interactive applications.

Another promising option is to use a Shiny application, where each plot
gives a simple way to get click events from the user - but then you really
are building an application out in the frontier edges of R land.

Cheers, Mike.

Thanks again
>
>
>
>
>
> Antonio Serrano
> aasdelat at aim.com
> ?
>
>
>
>
>
> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> To: Antonio Serrano <aasdelat at aim.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Sent: Sat, Apr 25, 2015 5:47 am
> Subject: Re: [R] Interactive maps
>
>
> Hi Antonio,
> If you do create the map in R, you can use
> locator().
>
> Jim
>
>
> On Sat, Apr 25, 2015 at 8:37 AM, Antonio Serrano via
> R-help
> <r-help at r-project.org> wrote:
> >
> >  Hello, all:
> >
> >    I am new here,
> and have a challenge to present some graphical data to the user in a
> convenient
> way.
> >
> >    The challenge is to present a map to the user which is coloured
> with the value of a variable. Say for example, temperature. This is a
> preexisting graph that I can generate in any format, including svg. I
> don't have
> to produce it using R.
> >
> >    When the user clicks anywhere in the map, the
> coordinates (longitude and latitude) have to be passed to R so that this,
> R, can
> look for the values of other variables in that location and make another
> graph
> with them.
> >
> >    Does anyubody know how could I accomplish this?.
> >
> >
> Thanks in advance.
> >
> >
> >
> > Antonio Serrano
> > aasdelat at aim.com
> > ?
> >
> >
> >
> [[alternative HTML version deleted]]
> >
> >
> ______________________________________________
> > R-help at r-project.org mailing
> list -- To UNSUBSCRIBE and more, see
> >
> https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal,
> self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mariojmaaz at gmail.com  Sun Apr 26 17:12:14 2015
From: mariojmaaz at gmail.com (=?UTF-8?Q?Mario_Jos=C3=A9_Marques=2DAzevedo?=)
Date: Sun, 26 Apr 2015 12:12:14 -0300
Subject: [R] Contrast anova multi factor
Message-ID: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>

Hi all,

I am doing anova multi factor and I found different Intercept when model
has interaction term.

I have the follow data:

set.seed(42)
dt <- data.frame(f1=c(rep("a",5),rep("b",5)),
                 f2=rep(c("I","II"),5),
                 y=rnorm(10))

When I run

summary.lm(aov(y ~ f1 * f2, data = dt))

The Intercept term is the mean of first level of f1 and f2. I can confirm
that with:

tapply(dt$y, list(dt$f1, dt$f2), mean)

I know that others terms are difference of levels with Intercept.

But I do not know what is Intercept when the model do not have interaction
term:

summary.lm(aov(y ~f1 + f2, data = dt))

I know that I can create a specific contrast table, by I would like
understand the default R output.

I read contrast sub-chapter on Crawley 2012 (The R book) and in his example
the Intercept is different when model has or not interaction term, but he
explain that Intercept is mean of first level of the factors.

Best regards,

Mario

.............................................................
Mario Jos? Marques-Azevedo
Ph.D. Candidate in Ecology
Dept. Plant Biology, Institute of Biology
University of Campinas - UNICAMP
Campinas, S?o Paulo, Brazil

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sun Apr 26 17:30:32 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 26 Apr 2015 17:30:32 +0200
Subject: [R] Contrast anova multi factor
In-Reply-To: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>
References: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>
Message-ID: <CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>

Dear Mario,

The interpretation is the same: the average at the reference situation
which is the group that has f1 == "f1 level1" and f2 == "f2 level1".

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-26 17:12 GMT+02:00 Mario Jos? Marques-Azevedo <mariojmaaz at gmail.com>
:

> Hi all,
>
> I am doing anova multi factor and I found different Intercept when model
> has interaction term.
>
> I have the follow data:
>
> set.seed(42)
> dt <- data.frame(f1=c(rep("a",5),rep("b",5)),
>                  f2=rep(c("I","II"),5),
>                  y=rnorm(10))
>
> When I run
>
> summary.lm(aov(y ~ f1 * f2, data = dt))
>
> The Intercept term is the mean of first level of f1 and f2. I can confirm
> that with:
>
> tapply(dt$y, list(dt$f1, dt$f2), mean)
>
> I know that others terms are difference of levels with Intercept.
>
> But I do not know what is Intercept when the model do not have interaction
> term:
>
> summary.lm(aov(y ~f1 + f2, data = dt))
>
> I know that I can create a specific contrast table, by I would like
> understand the default R output.
>
> I read contrast sub-chapter on Crawley 2012 (The R book) and in his example
> the Intercept is different when model has or not interaction term, but he
> explain that Intercept is mean of first level of the factors.
>
> Best regards,
>
> Mario
>
> .............................................................
> Mario Jos? Marques-Azevedo
> Ph.D. Candidate in Ecology
> Dept. Plant Biology, Institute of Biology
> University of Campinas - UNICAMP
> Campinas, S?o Paulo, Brazil
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mariojmaaz at gmail.com  Sun Apr 26 17:40:08 2015
From: mariojmaaz at gmail.com (=?UTF-8?Q?Mario_Jos=C3=A9_Marques=2DAzevedo?=)
Date: Sun, 26 Apr 2015 12:40:08 -0300
Subject: [R] Contrast anova multi factor
In-Reply-To: <CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>
References: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>
	<CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>
Message-ID: <CANFObyx73XZBxDVWNRQnqc86wqXzF9X8b1cRPCW2nx4anHwRRA@mail.gmail.com>

?Dear Thierry,

That is the problem. I read that interpretation is the same, but the
Intercept value of summary is different:

The mean of level "a" of f1 and level "I" of f2 (first level of each
factor) is 0.7127851.

When I run model with interaction term:

summary.lm(aov(y~f1*f2,data=dt))

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.7128     0.2884   2.471   0.0484 *
f1b           1.0522     0.4560   2.307   0.0605 .
f2II         -0.6787     0.4560  -1.488   0.1872
f1b:f2II     -1.1741     0.6449  -1.821   0.1185

I check that Intercept is mean of level "a" of f1 and level "I" of f2.

But when I run the model without interaction term, the Intercept value is
different:

summary.lm(aov(y~f1+f2,data=dt))

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.9476     0.2976   3.185   0.0154 *
f1b           0.4651     0.3720   1.251   0.2513
f2II         -1.2658     0.3720  -3.403   0.0114 *

I do not know what is Intercept value in this case. I expected that it is
mean of level "a" of f1 and level "I" of f2, but not.

Best regards,

Mario


On 26 April 2015 at 12:30, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Mario,
>
> The interpretation is the same: the average at the reference situation
> which is the group that has f1 == "f1 level1" and f2 == "f2 level1".
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-26 17:12 GMT+02:00 Mario Jos? Marques-Azevedo <
> mariojmaaz at gmail.com>:
>
>> Hi all,
>>
>> I am doing anova multi factor and I found different Intercept when model
>> has interaction term.
>>
>> I have the follow data:
>>
>> set.seed(42)
>> dt <- data.frame(f1=c(rep("a",5),rep("b",5)),
>>                  f2=rep(c("I","II"),5),
>>                  y=rnorm(10))
>>
>> When I run
>>
>> summary.lm(aov(y ~ f1 * f2, data = dt))
>>
>> The Intercept term is the mean of first level of f1 and f2. I can confirm
>> that with:
>>
>> tapply(dt$y, list(dt$f1, dt$f2), mean)
>>
>> I know that others terms are difference of levels with Intercept.
>>
>> But I do not know what is Intercept when the model do not have interaction
>> term:
>>
>> summary.lm(aov(y ~f1 + f2, data = dt))
>>
>> I know that I can create a specific contrast table, by I would like
>> understand the default R output.
>>
>> I read contrast sub-chapter on Crawley 2012 (The R book) and in his
>> example
>> the Intercept is different when model has or not interaction term, but he
>> explain that Intercept is mean of first level of the factors.
>>
>> Best regards,
>>
>> Mario
>>
>> .............................................................
>> Mario Jos? Marques-Azevedo
>> Ph.D. Candidate in Ecology
>> Dept. Plant Biology, Institute of Biology
>> University of Campinas - UNICAMP
>> Campinas, S?o Paulo, Brazil
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sun Apr 26 18:08:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 26 Apr 2015 18:08:30 +0200
Subject: [R] Contrast anova multi factor
In-Reply-To: <CANFObyx73XZBxDVWNRQnqc86wqXzF9X8b1cRPCW2nx4anHwRRA@mail.gmail.com>
References: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>
	<CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>
	<CANFObyx73XZBxDVWNRQnqc86wqXzF9X8b1cRPCW2nx4anHwRRA@mail.gmail.com>
Message-ID: <CAJuCY5xVu3X4tsaSRv6ZN4VArk_Hu9vhbWa6r0BDxGt0YZCeKA@mail.gmail.com>

The parameter is different because the model without intercept assumes that
effect of f1 is independent on the effect of f2. So you force f1b:f2ll to
be 0.

The interpretation is the same. The fit is conditional on the model
(interaction or no interaction).

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-26 17:40 GMT+02:00 Mario Jos? Marques-Azevedo <mariojmaaz at gmail.com>
:

> ?Dear Thierry,
>
> That is the problem. I read that interpretation is the same, but the
> Intercept value of summary is different:
>
> The mean of level "a" of f1 and level "I" of f2 (first level of each
> factor) is 0.7127851.
>
> When I run model with interaction term:
>
> summary.lm(aov(y~f1*f2,data=dt))
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.7128     0.2884   2.471   0.0484 *
> f1b           1.0522     0.4560   2.307   0.0605 .
> f2II         -0.6787     0.4560  -1.488   0.1872
> f1b:f2II     -1.1741     0.6449  -1.821   0.1185
>
> I check that Intercept is mean of level "a" of f1 and level "I" of f2.
>
> But when I run the model without interaction term, the Intercept value is
> different:
>
> summary.lm(aov(y~f1+f2,data=dt))
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.9476     0.2976   3.185   0.0154 *
> f1b           0.4651     0.3720   1.251   0.2513
> f2II         -1.2658     0.3720  -3.403   0.0114 *
>
> I do not know what is Intercept value in this case. I expected that it is
> mean of level "a" of f1 and level "I" of f2, but not.
>
> Best regards,
>
> Mario
>
>
> On 26 April 2015 at 12:30, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> > Dear Mario,
> >
> > The interpretation is the same: the average at the reference situation
> > which is the group that has f1 == "f1 level1" and f2 == "f2 level1".
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-04-26 17:12 GMT+02:00 Mario Jos? Marques-Azevedo <
> > mariojmaaz at gmail.com>:
> >
> >> Hi all,
> >>
> >> I am doing anova multi factor and I found different Intercept when model
> >> has interaction term.
> >>
> >> I have the follow data:
> >>
> >> set.seed(42)
> >> dt <- data.frame(f1=c(rep("a",5),rep("b",5)),
> >>                  f2=rep(c("I","II"),5),
> >>                  y=rnorm(10))
> >>
> >> When I run
> >>
> >> summary.lm(aov(y ~ f1 * f2, data = dt))
> >>
> >> The Intercept term is the mean of first level of f1 and f2. I can
> confirm
> >> that with:
> >>
> >> tapply(dt$y, list(dt$f1, dt$f2), mean)
> >>
> >> I know that others terms are difference of levels with Intercept.
> >>
> >> But I do not know what is Intercept when the model do not have
> interaction
> >> term:
> >>
> >> summary.lm(aov(y ~f1 + f2, data = dt))
> >>
> >> I know that I can create a specific contrast table, by I would like
> >> understand the default R output.
> >>
> >> I read contrast sub-chapter on Crawley 2012 (The R book) and in his
> >> example
> >> the Intercept is different when model has or not interaction term, but
> he
> >> explain that Intercept is mean of first level of the factors.
> >>
> >> Best regards,
> >>
> >> Mario
> >>
> >> .............................................................
> >> Mario Jos? Marques-Azevedo
> >> Ph.D. Candidate in Ecology
> >> Dept. Plant Biology, Institute of Biology
> >> University of Campinas - UNICAMP
> >> Campinas, S?o Paulo, Brazil
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Sun Apr 26 19:39:22 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Sun, 26 Apr 2015 13:39:22 -0400
Subject: [R] Run Rscript and ignore errors?
In-Reply-To: <CAJdu7BADVVz20kEMXLuu5-mOCz3wb_qNA_Ne9brc013KhSXfbQ@mail.gmail.com>
References: <CAJdu7BADVVz20kEMXLuu5-mOCz3wb_qNA_Ne9brc013KhSXfbQ@mail.gmail.com>
Message-ID: <CAN5YmCHMuJhYsMzW_VZAoewuLavVz+n5-Tn7o4mchk3uzDYWWA@mail.gmail.com>

Nick,

I don't know of a way to do what you want ... tell R to ignore all errors
... but, I do have a suggestion.

Since you regard these errors as "non-essential", why not edit your code to
reflect that?  For example, instead of writing
     plot(df$x1, df$y1)
write
     if ("x1" %in% names(df) & "y1" %in% names(df)) plot(df$x1, df$y1)

... or something like that.

Jean

On Thu, Apr 23, 2015 at 12:28 PM, Nick Matzke <matzke at nimbios.org> wrote:

> Hi R-help,
>
> I've looked at google, the Rscript documentation and the Rscript --help
> output and haven't found much on this.  So, here's my question:
>
> I have a rather long script that runs on various input datasets.  It is
> quite convenient to run the script from the Terminal command line with
> "Rscript scriptname.R"
>
> However, some datasets will cause errors. These are non-essential errors --
> just some datasets don't have certain columns so certain parts of the
> overall analysis don't produce figures etc.  Yes, I could go through the
> whole script and insert try() statements, etc.  But I'm lazy.
>
> So, is there a way to run Rscript or something similar, and just have it
> ignore all errors (i.e., keep running through the script)?  I.e., just like
> what happens if you just copy-paste the whole script into the R window --
> errors happen and are noted but the rest of the script keeps running.
>
> Thanks very much for any help!!
>
> Cheers!
> Nick
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matzke at nimbios.org  Sun Apr 26 20:13:48 2015
From: matzke at nimbios.org (Nick Matzke)
Date: Sun, 26 Apr 2015 14:13:48 -0400
Subject: [R] Run Rscript and ignore errors?
In-Reply-To: <CAN5YmCHMuJhYsMzW_VZAoewuLavVz+n5-Tn7o4mchk3uzDYWWA@mail.gmail.com>
References: <CAJdu7BADVVz20kEMXLuu5-mOCz3wb_qNA_Ne9brc013KhSXfbQ@mail.gmail.com>
	<CAN5YmCHMuJhYsMzW_VZAoewuLavVz+n5-Tn7o4mchk3uzDYWWA@mail.gmail.com>
Message-ID: <CAJdu7BAfuWMRiAp6_XhAtXr5hNfOk8c6y2EW3+XPn-dONoaGUA@mail.gmail.com>

On Sun, Apr 26, 2015 at 1:39 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Nick,
>
> I don't know of a way to do what you want ... tell R to ignore all errors
> ... but, I do have a suggestion.
>
> Since you regard these errors as "non-essential", why not edit your code
> to reflect that?  For example, instead of writing
>      plot(df$x1, df$y1)
> write
>      if ("x1" %in% names(df) & "y1" %in% names(df)) plot(df$x1, df$y1)
>
> ... or something like that.
>
> Jean
>

Hi! I could, but you can imagine that doing that several dozen times,
reducing readability and increasing the chance of making some other
mistake.  As originally mentioned, I'm lazy.

I did find a super-easy solution, posted here:
http://r.789695.n4.nabble.com/run-Rscript-and-ignore-errors-tc4706333.html#a4706395

Cheers!
Nick








>
> On Thu, Apr 23, 2015 at 12:28 PM, Nick Matzke <matzke at nimbios.org> wrote:
>
>> Hi R-help,
>>
>> I've looked at google, the Rscript documentation and the Rscript --help
>> output and haven't found much on this.  So, here's my question:
>>
>> I have a rather long script that runs on various input datasets.  It is
>> quite convenient to run the script from the Terminal command line with
>> "Rscript scriptname.R"
>>
>> However, some datasets will cause errors. These are non-essential errors
>> --
>> just some datasets don't have certain columns so certain parts of the
>> overall analysis don't produce figures etc.  Yes, I could go through the
>> whole script and insert try() statements, etc.  But I'm lazy.
>>
>> So, is there a way to run Rscript or something similar, and just have it
>> ignore all errors (i.e., keep running through the script)?  I.e., just
>> like
>> what happens if you just copy-paste the whole script into the R window --
>> errors happen and are noted but the rest of the script keeps running.
>>
>> Thanks very much for any help!!
>>
>> Cheers!
>> Nick
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Sun Apr 26 22:28:49 2015
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 26 Apr 2015 22:28:49 +0200
Subject: [R] How get list element name in R 3.2.0
Message-ID: <553D4A81.5080306@yahoo.fr>

Dear list-members,
I find a annoying difference between R 3.1.3 and R 3.2.

To get the element name of a list within lapply() or mclapply() call, I 
used the trick below:
For example:

essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
lapply(essai, function(x) plot(x, main= names(essai)[substitute(x)[[3]]]))

It works fins in R 3.1.3 however in R 3.2 it produces an error:
 > essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
 > lapply(essai, function(x) plot(x, main= 
names(essai)[substitute(x)[[3]]]))

  Error in names(essai)[substitute(x)[[3]]] :
   type 'symbol' d'indice incorrect

I don't see if this difference is noted is the list of changes:
http://cran.r-project.org/doc/manuals/r-devel/NEWS.html

If it is not a bug but a feature, what is the new way to get the list 
element name within a lapply or mclappy function.

Thanks a lot

Marc Girondot


From mark at markdrummond.ca  Sun Apr 26 22:41:32 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Sun, 26 Apr 2015 16:41:32 -0400
Subject: [R] knittr: non-numeric argument to binary operator
Message-ID: <CAAb4XW0xAA0se2d4T3zBkc6TMa1U_Tsbg1Lk-j7EQsmLjTg3Og@mail.gmail.com>

knittr is giving me the above error. The code it is failing on is
multiplying two numeric features of a data frame. I can run the code
by hand and it works fine, but when I try to knit my document, knittr
chokes on the same line.

When kitting:

Quitting from lines 161-175 (RepData_PeerAssessment2.Rmd)
Error in storm_data$PROPDMG * storm_data$property_damage_cost_factor :
  non-numeric argument to binary operator
Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible ->
eval -> eval
Execution halted

Running the same lines manually (CTRL+Enter) from the .Rmd file:

> storm_data$total_damage <-
+ (storm_data$PROPDMG * storm_data$property_damage_cost_factor) +
+ (storm_data$CROPDMG * storm_data$crop_damage_cost_factor)
> str(storm_data$total_damage)
 num [1:902297] 25 2.5 25 2.5 2.5 2.5 2.5 2.5 25 25 ...
>

Call me baffled. Any pointers are greatly appreciated at this point.

-- 
Cheers, Mark

Mark Drummond
mark at markdrummond.ca

When I get sad, I stop being sad and be Awesome instead. TRUE STORY.


From henrik.bengtsson at ucsf.edu  Sun Apr 26 23:05:09 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sun, 26 Apr 2015 14:05:09 -0700
Subject: [R] How get list element name in R 3.2.0
In-Reply-To: <553D4A81.5080306@yahoo.fr>
References: <553D4A81.5080306@yahoo.fr>
Message-ID: <CAFDcVCRiDakm6-=zyXL2Mc0W39C9xGozdKcj0BxHz2oV6iv3OQ@mail.gmail.com>

I'd say what you did in the past was definitely a hack that made too
strong assumptions on the internal implementation of lapply() etc.  It
basically relied on *apply() to loop over the elements using an index
variable.  There any many ways to do this and it seems like in R 3.2.0
there was change.  Actually, it does also not work as you expect in R
3.1.3 (but you don't get the error).  This is what you basically did:

## R 3.0.3:
> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> idxs <- lapply(essai, function(x) substitute(x)[[3]])
> idxs
$T2345
[1] 1

$T5664
[1] 2


## R 3.1.3:
> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> idxs <- lapply(essai, function(x) substitute(x)[[3]])
> idxs
$T2345
[1] 2

$T5664
[1] 2

NOTE how you don't get indices you expect, and therefor not the names either.

## R 3.2.0:
> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> idxs <- lapply(essai, function(x) substitute(x)[[3]])
> idxs
$T2345
i

$T5664
i

The latter will obviously not work as indices.

My rule of thumb: Anytime you find yourself using substitute() and
get()/assign(), there's probably a better way to do it.  Example:

> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> lapply(seq_along(essai), function(idx) plot(essai[[idx]], main=names(essai)[idx]))

or

> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> mapply(essai, names(essai), FUN=function(x, name) plot(x, main=name))

If names are unique, this also works:

> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> lapply(names(essai), function(name) plot(essai[[name]], main=name))

/Henrik

On Sun, Apr 26, 2015 at 1:28 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Dear list-members,
> I find a annoying difference between R 3.1.3 and R 3.2.
>
> To get the element name of a list within lapply() or mclapply() call, I used
> the trick below:
> For example:
>
> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
> lapply(essai, function(x) plot(x, main= names(essai)[substitute(x)[[3]]]))
>
> It works fins in R 3.1.3 however in R 3.2 it produces an error:
>> essai <- list(T2345=c(5, 6, 7), T5664=c(9, 12, 17, 16))
>> lapply(essai, function(x) plot(x, main= names(essai)[substitute(x)[[3]]]))
>
>  Error in names(essai)[substitute(x)[[3]]] :
>   type 'symbol' d'indice incorrect
>
> I don't see if this difference is noted is the list of changes:
> http://cran.r-project.org/doc/manuals/r-devel/NEWS.html
>
> If it is not a bug but a feature, what is the new way to get the list
> element name within a lapply or mclappy function.
>
> Thanks a lot
>
> Marc Girondot
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Apr 26 23:39:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 26 Apr 2015 14:39:00 -0700
Subject: [R] knittr: non-numeric argument to binary operator
In-Reply-To: <CAAb4XW0xAA0se2d4T3zBkc6TMa1U_Tsbg1Lk-j7EQsmLjTg3Og@mail.gmail.com>
References: <CAAb4XW0xAA0se2d4T3zBkc6TMa1U_Tsbg1Lk-j7EQsmLjTg3Og@mail.gmail.com>
Message-ID: <0139C3E3-6AE5-4BFD-BA1B-AC050A68E305@dcn.davis.CA.us>

Not reproducible [1], so any response likely to be a guess. However, you likely have not put everything that is in your interactive environment into the knitr document, so you are not working with the same data in those two environments.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 26, 2015 1:41:32 PM PDT, Mark Drummond <mark at markdrummond.ca> wrote:
>knittr is giving me the above error. The code it is failing on is
>multiplying two numeric features of a data frame. I can run the code
>by hand and it works fine, but when I try to knit my document, knittr
>chokes on the same line.
>
>When kitting:
>
>Quitting from lines 161-175 (RepData_PeerAssessment2.Rmd)
>Error in storm_data$PROPDMG * storm_data$property_damage_cost_factor :
>  non-numeric argument to binary operator
>Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible ->
>eval -> eval
>Execution halted
>
>Running the same lines manually (CTRL+Enter) from the .Rmd file:
>
>> storm_data$total_damage <-
>+ (storm_data$PROPDMG * storm_data$property_damage_cost_factor) +
>+ (storm_data$CROPDMG * storm_data$crop_damage_cost_factor)
>> str(storm_data$total_damage)
> num [1:902297] 25 2.5 25 2.5 2.5 2.5 2.5 2.5 25 25 ...
>>
>
>Call me baffled. Any pointers are greatly appreciated at this point.


From r.turner at auckland.ac.nz  Mon Apr 27 00:02:47 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 27 Apr 2015 10:02:47 +1200
Subject: [R] download
In-Reply-To: <553C1AC5.2040202@statistik.tu-dortmund.de>
References: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
	<553C14A1.6030404@auckland.ac.nz>
	<553C1AC5.2040202@statistik.tu-dortmund.de>
Message-ID: <553D6087.3010909@auckland.ac.nz>

On 26/04/15 10:52, Uwe Ligges wrote:
>
>
> On 26.04.2015 00:26, Rolf Turner wrote:

<SNIP>

>> If you insist on using an antiquated version you will have to install
>> from source, which can be a little bit of a challenge --- particularly
>> if you are using Windoze, which I presume (Psigh!!!) that you are.
>
>
> Well, even then, the binaries are there for old releases of R. Just
> click on "R Binaries"->"windows"->"base"->"Previous releases" and select
> the right one for you. No idea wha you need that as a student who learns R.

Thanks Ewe.  Didn't notice/know about that particular track.  I guess 
it's because I never use binaries ....

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From r.turner at auckland.ac.nz  Mon Apr 27 00:04:58 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 27 Apr 2015 10:04:58 +1200
Subject: [R] download
In-Reply-To: <553C1AC5.2040202@statistik.tu-dortmund.de>
References: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
	<553C14A1.6030404@auckland.ac.nz>
	<553C1AC5.2040202@statistik.tu-dortmund.de>
Message-ID: <553D610A.80603@auckland.ac.nz>



I meant "Thanks Uwe" .... That was a fumble-fingered typo; I wasn't 
trying to be funny.

Sorry 'bout that!

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From pdalgd at gmail.com  Mon Apr 27 00:07:37 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 27 Apr 2015 00:07:37 +0200
Subject: [R] Contrast anova multi factor
In-Reply-To: <CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>
References: <CANFObywH4rMp4DTDM=zaA=rov7kAgpJwwdWpyetfVqb24bh1kg@mail.gmail.com>
	<CAJuCY5yizE3PpSZif6G=u37=VGb+7G0fXUxkmgZKY=h+nyXKtw@mail.gmail.com>
Message-ID: <10F5E8A0-03E4-4CC1-8C85-AC129A0485F8@gmail.com>


> On 26 Apr 2015, at 17:30 , Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Mario,
> 
> The interpretation is the same: the average at the reference situation
> which is the group that has f1 == "f1 level1" and f2 == "f2 level1".

A little more precisely: It is the estimate of the expected value at the reference situation. 

In a balanced two-way design, this can be worked out explicitly: It is the average of the first row + the average of the first column - the total average. E.g. 

> library(ISwR) 
> lm(hr~subj+time, heart.rate)

Call:
lm(formula = hr ~ subj + time, data = heart.rate)

Coefficients:
(Intercept)        subj2        subj3        subj4        subj5        subj6  
     94.917       18.000       -5.750       -8.000       30.500        6.500  
      subj7        subj8        subj9       time30       time60      time120  
    -22.000      -16.000       11.500       -4.000       -5.444       -4.222  

> with(heart.rate, tapply(hr, subj, mean))
     1      2      3      4      5      6      7      8      9 
 91.50 109.50  85.75  83.50 122.00  98.00  69.50  75.50 103.00 
> with(heart.rate, tapply(hr, time, mean))
       0       30       60      120 
96.55556 92.55556 91.11111 92.33333 
> with(heart.rate, mean(hr))
[1] 93.13889
> 91.5+96.55556 - 93.13889
[1] 94.91667

In an unbalanced design, the calculation of the intercept gets a bit lost in matrix-calculus land; there is no simple formula, but it is still an estimate of the same thing. 

- Peter D

> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2015-04-26 17:12 GMT+02:00 Mario Jos? Marques-Azevedo <mariojmaaz at gmail.com>
> :
> 
>> Hi all,
>> 
>> I am doing anova multi factor and I found different Intercept when model
>> has interaction term.
>> 
>> I have the follow data:
>> 
>> set.seed(42)
>> dt <- data.frame(f1=c(rep("a",5),rep("b",5)),
>>                 f2=rep(c("I","II"),5),
>>                 y=rnorm(10))
>> 
>> When I run
>> 
>> summary.lm(aov(y ~ f1 * f2, data = dt))
>> 
>> The Intercept term is the mean of first level of f1 and f2. I can confirm
>> that with:
>> 
>> tapply(dt$y, list(dt$f1, dt$f2), mean)
>> 
>> I know that others terms are difference of levels with Intercept.
>> 
>> But I do not know what is Intercept when the model do not have interaction
>> term:
>> 
>> summary.lm(aov(y ~f1 + f2, data = dt))
>> 
>> I know that I can create a specific contrast table, by I would like
>> understand the default R output.
>> 
>> I read contrast sub-chapter on Crawley 2012 (The R book) and in his example
>> the Intercept is different when model has or not interaction term, but he
>> explain that Intercept is mean of first level of the factors.
>> 
>> Best regards,
>> 
>> Mario
>> 
>> .............................................................
>> Mario Jos? Marques-Azevedo
>> Ph.D. Candidate in Ecology
>> Dept. Plant Biology, Institute of Biology
>> University of Campinas - UNICAMP
>> Campinas, S?o Paulo, Brazil
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Mon Apr 27 00:24:22 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 27 Apr 2015 00:24:22 +0200
Subject: [R] download
In-Reply-To: <553D610A.80603@auckland.ac.nz>
References: <CAKPGmC1xTw5DXx5JqVGEZxtD5NG+tt6yrHv7VDgaKShjAzso=g@mail.gmail.com>
	<553C14A1.6030404@auckland.ac.nz>
	<553C1AC5.2040202@statistik.tu-dortmund.de>
	<553D610A.80603@auckland.ac.nz>
Message-ID: <553D6596.7030009@statistik.tu-dortmund.de>



On 27.04.2015 00:04, Rolf Turner wrote:
>
>
> I meant "Thanks Uwe" .... That was a fumble-fingered typo; I wasn't
> trying to be funny.
>
> Sorry 'bout that!

Don't worry, when quickly typing mails, I typically generate lots of 
worse typos, Ralf. ;-)
[Sorry, but I could not resist.]

Best wishes from Ewe




>
> cheers,
>
> Rolf
>


From jrkrideau at inbox.com  Mon Apr 27 01:10:10 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 26 Apr 2015 15:10:10 -0800
Subject: [R] knittr: non-numeric argument to binary operator
In-Reply-To: <CAAb4XW0xAA0se2d4T3zBkc6TMa1U_Tsbg1Lk-j7EQsmLjTg3Og@mail.gmail.com>
Message-ID: <E4A390719B1.000007DDjrkrideau@inbox.com>

We need some idea of what you were actually doing (i.e code, data, ... )

See http://adv-r.had.co.nz/Reproducibility.html for some suggestions.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: mark at markdrummond.ca
> Sent: Sun, 26 Apr 2015 16:41:32 -0400
> To: r-help at stat.math.ethz.ch
> Subject: [R] knittr: non-numeric argument to binary operator
> 
> knittr is giving me the above error. The code it is failing on is
> multiplying two numeric features of a data frame. I can run the code
> by hand and it works fine, but when I try to knit my document, knittr
> chokes on the same line.
> 
> When kitting:
> 
> Quitting from lines 161-175 (RepData_PeerAssessment2.Rmd)
> Error in storm_data$PROPDMG * storm_data$property_damage_cost_factor :
>   non-numeric argument to binary operator
> Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible ->
> eval -> eval
> Execution halted
> 
> Running the same lines manually (CTRL+Enter) from the .Rmd file:
> 
>> storm_data$total_damage <-
> + (storm_data$PROPDMG * storm_data$property_damage_cost_factor) +
> + (storm_data$CROPDMG * storm_data$crop_damage_cost_factor)
>> str(storm_data$total_damage)
>  num [1:902297] 25 2.5 25 2.5 2.5 2.5 2.5 2.5 25 25 ...
>> 
> 
> Call me baffled. Any pointers are greatly appreciated at this point.
> 
> --
> Cheers, Mark
> 
> Mark Drummond
> mark at markdrummond.ca
> 
> When I get sad, I stop being sad and be Awesome instead. TRUE STORY.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mepstein at illinois.edu  Mon Apr 27 01:22:13 2015
From: mepstein at illinois.edu (Milt Epstein)
Date: Sun, 26 Apr 2015 18:22:13 -0500
Subject: [R] knittr: non-numeric argument to binary operator
In-Reply-To: <E4A390719B1.000007DDjrkrideau@inbox.com>
References: <E4A390719B1.000007DDjrkrideau@inbox.com>
Message-ID: <Pine.LNX.4.64.1504261816450.27336@mepstein0.ncsa.illinois.edu>

I was getting pretty much the same error recently, when I joined this
list (I'm new to R), and the solution turned out to be that I needed
to call as.integer() on a certain value, before passing it to a
function.  In my case it was a value read/returned from commandArgs(),
but I suppose there are other situations where this could arise.

Milt Epstein
Programmer in Computational Genomics
Institute for Genomic Biology (IGB)
University of Illinois at Urbana-Champaign (UIUC)
mepstein at illinois.edu


On Sun, 26 Apr 2015, John Kane wrote:

> We need some idea of what you were actually doing (i.e code, data, ... )
> 
> See http://adv-r.had.co.nz/Reproducibility.html for some suggestions.
> John Kane
> Kingston ON Canada
> 
> 
> > -----Original Message-----
> > From: mark at markdrummond.ca
> > Sent: Sun, 26 Apr 2015 16:41:32 -0400
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] knittr: non-numeric argument to binary operator
> > 
> > knittr is giving me the above error. The code it is failing on is
> > multiplying two numeric features of a data frame. I can run the code
> > by hand and it works fine, but when I try to knit my document, knittr
> > chokes on the same line.
> > 
> > When kitting:
> > 
> > Quitting from lines 161-175 (RepData_PeerAssessment2.Rmd)
> > Error in storm_data$PROPDMG * storm_data$property_damage_cost_factor :
> >   non-numeric argument to binary operator
> > Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible ->
> > eval -> eval
> > Execution halted
> > 
> > Running the same lines manually (CTRL+Enter) from the .Rmd file:
> > 
> >> storm_data$total_damage <-
> > + (storm_data$PROPDMG * storm_data$property_damage_cost_factor) +
> > + (storm_data$CROPDMG * storm_data$crop_damage_cost_factor)
> >> str(storm_data$total_damage)
> >  num [1:902297] 25 2.5 25 2.5 2.5 2.5 2.5 2.5 25 25 ...
> >> 
> > 
> > Call me baffled. Any pointers are greatly appreciated at this point.
> > 
> > --
> > Cheers, Mark
> > 
> > Mark Drummond
> > mark at markdrummond.ca
> > 
> > When I get sad, I stop being sad and be Awesome instead. TRUE STORY.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mark at markdrummond.ca  Mon Apr 27 02:58:30 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Sun, 26 Apr 2015 20:58:30 -0400
Subject: [R] knittr: non-numeric argument to binary operator
In-Reply-To: <0139C3E3-6AE5-4BFD-BA1B-AC050A68E305@dcn.davis.CA.us>
References: <CAAb4XW0xAA0se2d4T3zBkc6TMa1U_Tsbg1Lk-j7EQsmLjTg3Og@mail.gmail.com>
	<0139C3E3-6AE5-4BFD-BA1B-AC050A68E305@dcn.davis.CA.us>
Message-ID: <CAAb4XW3DWqD+pk-vktxHCyvyRn-dxMGsZTtNydO6NWA20xy8-w@mail.gmail.com>

Thanks all for the responses. As Murphy would have it, after posting
my query I found the problem. I had a function defined that did some
value mapping and I had a stray line of code in the function. Actually
a legitimate line of code that was just in the wrong place.

Cheers,
Mark


On Sun, Apr 26, 2015 at 5:39 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Not reproducible [1], so any response likely to be a guess. However, you likely have not put everything that is in your interactive environment into the knitr document, so you are not working with the same data in those two environments.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 26, 2015 1:41:32 PM PDT, Mark Drummond <mark at markdrummond.ca> wrote:
>>knittr is giving me the above error. The code it is failing on is
>>multiplying two numeric features of a data frame. I can run the code
>>by hand and it works fine, but when I try to knit my document, knittr
>>chokes on the same line.
>>
>>When kitting:
>>
>>Quitting from lines 161-175 (RepData_PeerAssessment2.Rmd)
>>Error in storm_data$PROPDMG * storm_data$property_damage_cost_factor :
>>  non-numeric argument to binary operator
>>Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible ->
>>eval -> eval
>>Execution halted
>>
>>Running the same lines manually (CTRL+Enter) from the .Rmd file:
>>
>>> storm_data$total_damage <-
>>+ (storm_data$PROPDMG * storm_data$property_damage_cost_factor) +
>>+ (storm_data$CROPDMG * storm_data$crop_damage_cost_factor)
>>> str(storm_data$total_damage)
>> num [1:902297] 25 2.5 25 2.5 2.5 2.5 2.5 2.5 25 25 ...
>>>
>>
>>Call me baffled. Any pointers are greatly appreciated at this point.
>



-- 
Cheers, Mark

Mark Drummond
mark at markdrummond.ca

When I get sad, I stop being sad and be Awesome instead. TRUE STORY.


From lists at revelle.net  Mon Apr 27 05:05:37 2015
From: lists at revelle.net (William Revelle)
Date: Sun, 26 Apr 2015 22:05:37 -0500
Subject: [R] Phi coefficient matrix (package psych)
In-Reply-To: <C8B9C3AA-C121-4034-86A0-B132DF6E2038@northwestern.edu>
References: <CABK368i4w4fv1BQu=eetMN94OA-r=VK7a=UPQ1F7te6o1JBU3A@mail.gmail.com>
	<C8B9C3AA-C121-4034-86A0-B132DF6E2038@northwestern.edu>
Message-ID: <5E8DD6DF-A19A-4C36-A18C-21BB9AB02126@revelle.net>


> 
> Kumar and Jim,
>  The phi coefficient is identical to the Pearson coefficient in the case of a 2 x 2 data set.
> 
> As it says in the help file for phi:
> 
> "Since the phi coefficient is just a Pearson correlation applied to dichotomous data, to find a matrix of phis from a data set involves just finding the correlations using cor or lowerCor or corr.test.?
> 
> So,  you can do a cor(df)  and you do not need the phi(df)
> 
> If you want the tetrachoric (which estimates what a Pearson would be if you had not artificially dichotomized the data) try tetrachoric(df)
> 
> Bill
> 


> 
> 
> 
>> On Apr 21, 2015, at 3:34 PM, Kumar Mainali <kpmainali at gmail.com> wrote:
>> 
>> I want to calculate phi coefficient for every pair of the columns. Is there
>> a way to generate a matrix like a correlation matrix? I know cor function
>> in the case below gives same answer as phi coefficient.
>> 
>> ?x <- sample(c(0,1), 10, replace=TRUE)
>> y <- sample(c(0,1), 10, replace=TRUE)
>> z <- sample(c(0,1), 10, replace=TRUE)
>> df <- data.frame(x,y,z)
>> cor(df)
>> library(psych)
>> phi(df)?
>> 
>> Thank you,
>> Kumar Mainali
>> Postdoctoral Associate
>> Department of Biology
>> University of Maryland
>> ?
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> William Revelle		           http://personality-project.org/revelle.html
> Professor			           http://personality-project.org
> Department of Psychology   http://www.wcas.northwestern.edu/psych/
> Northwestern University	   http://www.northwestern.edu/
> Use R for psychology             http://personality-project.org/r
> It is 3 minutes to midnight	   http://www.thebulletin.org
> 
> 
> 
> 
> 
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From bonitajo at gmail.com  Mon Apr 27 04:55:38 2015
From: bonitajo at gmail.com (Bonita Willams)
Date: Sun, 26 Apr 2015 22:55:38 -0400
Subject: [R] Help needed with Traininig a Neural Network
Message-ID: <CANQqSub=fRGGDJBhE2RM-Uiv8F0VEEpqqLWnyXDNz=pUbhriwg@mail.gmail.com>

I am attempting to train a dataset but am having a hard time. I am using a
dataset from UCI *archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records
<http://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records>  *. I
am attempting to replicate a study which predicts the political party of
Congress members based on their voting records.

Below is some of what I have accomplished.

>dataset <- read.csv(?ucidatasethouse.vote.84.data?)

> trainset <- dataset[1:305,]

>testset <- dataset[306:435, ]



(1.) *I trained the neural net model*

> polpartynet <- neuralnet(Party ~ HandInfants + WaterProject + AdoptBudget
+ DocFeeFreeze + ElSalvadorAid + ReligiousGroupsSchools + AntiSatellTestBan
+ AidNicaraguaContras + MXMissile + Immigration + SynCorpCutback +
EducationSpending + SuperfundRighttoSue + Crime + DutyFreeExports +
ExportAdminSouthAfrica, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)

hidden: 4    thresh: 0.1    rep: 1/1    steps:      16       error:
58.57427 time: 0.16 secs





(2.) *I put this together but not sure of what I was supposed to get*

> polpartynettestset.results <- compute(polpartynet, testset)







(3.) * The Training set which contains all of the columns is ?trainset?



> colnames(trainset)

 [1] "Party"                  "HandInfants"            "WaterProject"

 [4] "AdoptBudget"            "DocFeeFreeze"           "ElSalvadorAid"

 [7] "ReligiousGroupsSchools" "AntiSatellTestBan"      "AidNicaraguaContras"

[10] "MXMissile"              "Immigration"            "SynCorpCutback"

[13] "EducationSpending"      "SuperfundRighttoSue"    "Crime"

[16] "DutyFreeExports"        "ExportAdminSouthAfrica"



(4.) *I removed ?Party? column from the testset based but this may
have been a bad move?*** What should I do????



> colnames(testset)

 [1] "HandInfants"            "WaterProject"           "AdoptBudget"

 [4] "DocFeeFreeze"           "ElSalvadorAid"          "ReligiousGroupsSchools"

 [7] "AntiSatellTestBan"      "AidNicaraguaContras"    "MXMissile"

[10] "Immigration"            "SynCorpCutback"         "EducationSpending"

[13] "SuperfundRighttoSue"    "Crime"                  "DutyFreeExports"

[16] "ExportAdminSouthAfrica"



(5.) ***I would like to create a formula which will provide me neural
network results***



> results <- data.frame(actual = testset$Party, prediction = polpartynettestset.results)

Error in data.frame(actual = testset$Party, prediction =
polpartynettestset.results) :

  arguments imply differing number of rows: 0, 130



(6.) I would like to be able to round to the nearest integer to
improve readability. This is what I have tried so far?



> results$Party <- round(results$Party)

Error: object 'results' not found

> results[306:435]

Error: object 'results' not found

> polpartynettestset.results$Party <- round(polpartynettestset.results$Party)

Error in round(polpartynettestset.results$Party) :

  non-numeric argument to mathematical function





I appreciate any help that you can provide. It is possible that I am
missing something but will happily add it if you ask. I feel like a
dog chasing its tail.





 Bonita Williams

bonitajo at gmail.com

	[[alternative HTML version deleted]]


From dominic.roye at gmail.com  Sun Apr 26 14:44:53 2015
From: dominic.roye at gmail.com (Dominic Roye)
Date: Sun, 26 Apr 2015 14:44:53 +0200
Subject: [R] Number formatting of labels in directlabels with stat_contour
	(ggplot2)
Message-ID: <CALvVS-HWq1DTXeoxwH1M3RH7oHGJHZ-J-Rh2=DsphTB8ds2PLg@mail.gmail.com>

How can I customize the number formatting of labels in directlabels?
It should be integer as in the original dataset.

    p <- ggplot(temp,aes(lon,lat,z=Pres,colour=..level..))+
    stat_contour(bins=30,size=0.5,colour="black")+theme_bw()

    direct.label(p,list("top.pieces",cex=0.7,colour="red"))

Dataset:

    dput(temp)
    structure(list(lon = c(-30, -27.5, -25, -22.5, -20, -17.5, -15,
    -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30, -27.5, -25,
    -22.5, -20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5,
    7.5, 10, -30, -27.5, -25, -22.5, -20, -17.5, -15, -12.5, -10,
    -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30, -27.5, -25, -22.5, -20,
    -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30,
    -27.5, -25, -22.5, -20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5,
    0, 2.5, 5, 7.5, 10, -30, -27.5, -25, -22.5, -20, -17.5, -15,
    -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30, -27.5, -25,
    -22.5, -20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5,
    7.5, 10, -30, -27.5, -25, -22.5, -20, -17.5, -15, -12.5, -10,
    -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30, -27.5, -25, -22.5, -20,
    -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30,
    -27.5, -25, -22.5, -20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5,
    0, 2.5, 5, 7.5, 10, -30, -27.5, -25, -22.5, -20, -17.5, -15,
    -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, -30, -27.5, -25,
    -22.5, -20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5,
    7.5, 10, -30, -27.5, -25, -22.5, -20, -17.5, -15, -12.5, -10,
    -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10), lat = c(60, 60, 60, 60,
    60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 57.5, 57.5,
    57.5, 57.5, 57.5, 57.5, 57.5, 57.5, 57.5, 57.5, 57.5, 57.5, 57.5,
    57.5, 57.5, 57.5, 57.5, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,
    55, 55, 55, 55, 55, 55, 55, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5,
    52.5, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5, 52.5,
    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
    50, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5,
    47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 45, 45, 45, 45, 45,
    45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 42.5, 42.5, 42.5,
    42.5, 42.5, 42.5, 42.5, 42.5, 42.5, 42.5, 42.5, 42.5, 42.5, 42.5,
    42.5, 42.5, 42.5, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,
    40, 40, 40, 40, 40, 40, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5,
    37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 37.5, 35,
    35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,
    32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5,
    32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 30, 30, 30, 30, 30, 30, 30,
    30, 30, 30, 30, 30, 30, 30, 30, 30, 30), Pres = c(990, 992, 993,
    995, 996, 997, 998, 1000, 1001, 1002, 1003, 1004, 1005, 1007,
    1008, 1010, 1011, 998, 999, 1000, 1001, 1002, 1004, 1005, 1007,
    1008, 1009, 1009, 1010, 1011, 1011, 1012, 1012, 1013, 1005, 1006,
    1007, 1009, 1010, 1011, 1012, 1014, 1015, 1016, 1016, 1017, 1016,
    1016, 1016, 1016, 1016, 1011, 1012, 1013, 1014, 1016, 1017, 1018,
    1020, 1021, 1022, 1022, 1022, 1022, 1021, 1021, 1021, 1020, 1015,
    1016, 1017, 1019, 1021, 1022, 1024, 1025, 1026, 1026, 1026, 1026,
    1025, 1025, 1025, 1024, 1024, 1019, 1020, 1022, 1023, 1025, 1027,
    1027, 1028, 1029, 1029, 1029, 1028, 1028, 1027, 1026, 1026, 1026,
    1022, 1023, 1025, 1027, 1028, 1029, 1030, 1030, 1030, 1030, 1030,
    1029, 1029, 1027, 1025, 1023, 1022, 1025, 1026, 1028, 1029, 1030,
    1031, 1031, 1031, 1030, 1029, 1030, 1029, 1028, 1025, 1022, 1019,
    1019, 1026, 1027, 1028, 1029, 1030, 1030, 1030, 1029, 1028, 1028,
    1029, 1028, 1025, 1024, 1022, 1020, 1019, 1026, 1028, 1028, 1029,
    1029, 1029, 1029, 1028, 1027, 1025, 1025, 1025, 1025, 1024, 1023,
    1022, 1019, 1026, 1027, 1027, 1027, 1027, 1027, 1027, 1026, 1025,
    1024, 1024, 1025, 1025, 1025, 1024, 1022, 1021, 1025, 1025, 1025,
    1026, 1026, 1025, 1025, 1025, 1023, 1023, 1024, 1024, 1024, 1024,
    1023, 1022, 1021, 1024, 1024, 1024, 1024, 1024, 1024, 1023, 1023,
    1022, 1023, 1023, 1023, 1023, 1023, 1023, 1022, 1022)), .Names =
c("lon",
    "lat", "Pres"), row.names = c(NA, -221L), class = "data.frame")

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Sun Apr 26 10:17:48 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 26 Apr 2015 08:17:48 +0000
Subject: [R] Question about base::rank results
Message-ID: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>

Hi,

I cannot understand why rank(x) behaves as outlined below.
Based on the results of first x vector values ranking, which is as expected in my opinion,
I cannot explain the following results.

> x <- c(12,34,15,77,78)
> x[rank(x)]
[1] 12 15 34 77 78      (OK)

> x <- c(12,34,15,77,78,22)
> x[rank(x)]
[1] 12 77 34 78 22 15   (?)

> x <- c(12,34,77,15,78)
> x[rank(x)]
[1] 12 77 15 34 78      (?)

Please any feedback ? Thanks.

BR,

Giorgio Garziano



	[[alternative HTML version deleted]]


From joshuamichaeldixon at gmail.com  Mon Apr 27 02:26:24 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Mon, 27 Apr 2015 01:26:24 +0100
Subject: [R] Help Interpreting Linear Mixed Model
Message-ID: <CAOkeKBJt-WVwTt1nemyxHSkZ1CnwK36Q+_neG2yKy_4pM2RgQw@mail.gmail.com>

Hello!

Very new to R (10 days), and I've run the linear mixed model, below.
Attempting to interpret what it means...  What do I need to look for?
Residuals, correlations of fixed effects?!

How would I look at very specific interactions, such as PREMIER_LEAGUE
(Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18  GK?

For reference my data set looks like this:

Id Level AgeGr   Position Height Weight BMI YoYo
7451 CHAMPIONSHIP 14 M NA 63 NA 80
148 PREMIER_LEAGUE 16 D NA 64 NA 80
10393 CONFERENCE 10 D NA 36 NA 160
10200 CHAMPIONSHIP 10 F NA 46 NA 160
1961 LEAGUE_TWO 13 GK NA 67 NA 160
10428 CHAMPIONSHIP 10 GK NA 40 NA 160
10541 LEAGUE_ONE 10 F NA 25 NA 160
10012 CHAMPIONSHIP 10 GK NA 30 NA 160
9895 CHAMPIONSHIP 10 D NA 36 NA 160


Many thanks in advance for time and help.  Really appreciate it.

Josh


> summary(lmer(YoYo~AgeGr+Position+(1|Id)))
Linear mixed model fit by REML ['lmerMod']
Formula: YoYo ~ AgeGr + Position + (1 | Id)

REML criterion at convergence: 125712.2

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.4407 -0.5288 -0.0874  0.4531  4.8242

Random effects:
 Groups   Name        Variance Std.Dev.
 Id       (Intercept) 15300    123.7
 Residual             16530    128.6
Number of obs: 9609, groups:  Id, 6071

Fixed effects:
             Estimate Std. Error t value
(Intercept) -521.6985    16.8392  -30.98
AgeGr         62.6786     0.9783   64.07
PositionD    139.4682     7.8568   17.75
PositionM    141.2227     7.7072   18.32
PositionF    135.1241     8.1911   16.50

Correlation of Fixed Effects:
          (Intr) AgeGr  PostnD PostnM
AgeGr     -0.910
PositionD -0.359 -0.009
PositionM -0.375  0.001  0.810
PositionF -0.349 -0.003  0.756  0.782
> model=lmer(YoYo~AgeGr+Position+(1|Id))
> summary(glht(model,linfct=mcp(Position="Tukey")))

 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))

Linear Hypotheses:
            Estimate Std. Error z value Pr(>|z|)
D - GK == 0  139.468      7.857  17.751   <1e-04 ***
M - GK == 0  141.223      7.707  18.323   <1e-04 ***
F - GK == 0  135.124      8.191  16.496   <1e-04 ***
M - D == 0     1.754      4.799   0.366    0.983
F - D == 0    -4.344      5.616  -0.774    0.862
F - M == 0    -6.099      5.267  -1.158    0.645
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 27 09:06:19 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Apr 2015 09:06:19 +0200
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAOkeKBJt-WVwTt1nemyxHSkZ1CnwK36Q+_neG2yKy_4pM2RgQw@mail.gmail.com>
References: <CAOkeKBJt-WVwTt1nemyxHSkZ1CnwK36Q+_neG2yKy_4pM2RgQw@mail.gmail.com>
Message-ID: <CAJuCY5zm6Meb=dMNO6TcQPGPQux2021T3mJ7wpkifeA6ZC8ZnA@mail.gmail.com>

Dear Josh,

Is this homework? Because the list has a no homework policy.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:

> Hello!
>
> Very new to R (10 days), and I've run the linear mixed model, below.
> Attempting to interpret what it means...  What do I need to look for?
> Residuals, correlations of fixed effects?!
>
> How would I look at very specific interactions, such as PREMIER_LEAGUE
> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18  GK?
>
> For reference my data set looks like this:
>
> Id Level AgeGr   Position Height Weight BMI YoYo
> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
> 10393 CONFERENCE 10 D NA 36 NA 160
> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
> 10541 LEAGUE_ONE 10 F NA 25 NA 160
> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>
>
> Many thanks in advance for time and help.  Really appreciate it.
>
> Josh
>
>
> > summary(lmer(YoYo~AgeGr+Position+(1|Id)))
> Linear mixed model fit by REML ['lmerMod']
> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>
> REML criterion at convergence: 125712.2
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Id       (Intercept) 15300    123.7
>  Residual             16530    128.6
> Number of obs: 9609, groups:  Id, 6071
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) -521.6985    16.8392  -30.98
> AgeGr         62.6786     0.9783   64.07
> PositionD    139.4682     7.8568   17.75
> PositionM    141.2227     7.7072   18.32
> PositionF    135.1241     8.1911   16.50
>
> Correlation of Fixed Effects:
>           (Intr) AgeGr  PostnD PostnM
> AgeGr     -0.910
> PositionD -0.359 -0.009
> PositionM -0.375  0.001  0.810
> PositionF -0.349 -0.003  0.756  0.782
> > model=lmer(YoYo~AgeGr+Position+(1|Id))
> > summary(glht(model,linfct=mcp(Position="Tukey")))
>
>  Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>
> Linear Hypotheses:
>             Estimate Std. Error z value Pr(>|z|)
> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
> M - D == 0     1.754      4.799   0.366    0.983
> F - D == 0    -4.344      5.616  -0.774    0.862
> F - M == 0    -6.099      5.267  -1.158    0.645
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> (Adjusted p values reported -- single-step method)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Apr 27 09:24:01 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 27 Apr 2015 19:24:01 +1200
Subject: [R] Question about base::rank results
In-Reply-To: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
Message-ID: <553DE411.2080703@auckland.ac.nz>

On 26/04/15 20:17, Giorgio Garziano wrote:
> Hi,
>
> I cannot understand why rank(x) behaves as outlined below. Based on
> the results of first x vector values ranking, which is as expected in
> my opinion, I cannot explain the following results.
>
>> x <- c(12,34,15,77,78)
>> x[rank(x)]
> [1] 12 15 34 77 78      (OK)
>
>> x <- c(12,34,15,77,78,22)
>> x[rank(x)]
> [1] 12 77 34 78 22 15   (?)
>
>> x <- c(12,34,77,15,78)
>> x[rank(x)]
> [1] 12 77 15 34 78      (?)
>
> Please any feedback ? Thanks.


What did you expect to get?

To take your 2nd example:

x <- c(12,34,15,77,78,22)
x[rank(x)]
[1] 12 77 34 78 22 15   (?)

Why (?) ?

The rank of 12 is 1.
The rank of 34 is 4.
The rank of 15 is 2.
The rank of 77 is 5.
The rank of 78 is 6.
The rank of 22 is 3.

Thus x[rank(x)] gives you the 1st, 4th, 2nd, 5th, 6th and 3rd
entries of x.  In that order.

What on earth is puzzling you?

I can think of no good reason for ever looking at x[rank(x)].

Perhaps, judging from your first example which you say is "OK",
you want x[order(x)].

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From joshuamichaeldixon at gmail.com  Mon Apr 27 09:54:51 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Mon, 27 Apr 2015 08:54:51 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAJuCY5zm6Meb=dMNO6TcQPGPQux2021T3mJ7wpkifeA6ZC8ZnA@mail.gmail.com>
References: <CAOkeKBJt-WVwTt1nemyxHSkZ1CnwK36Q+_neG2yKy_4pM2RgQw@mail.gmail.com>
	<CAJuCY5zm6Meb=dMNO6TcQPGPQux2021T3mJ7wpkifeA6ZC8ZnA@mail.gmail.com>
Message-ID: <03F37599-48EE-4518-BF71-2C324E8C3A9E@gmail.com>

Hello Thierry,

No, this isn't homework. Not that young unfortunately. 

Josh

> On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Josh,
> 
> Is this homework? Because the list has a no homework policy.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>> Hello!
>> 
>> Very new to R (10 days), and I've run the linear mixed model, below.
>> Attempting to interpret what it means...  What do I need to look for?
>> Residuals, correlations of fixed effects?!
>> 
>> How would I look at very specific interactions, such as PREMIER_LEAGUE
>> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18  GK?
>> 
>> For reference my data set looks like this:
>> 
>> Id Level AgeGr   Position Height Weight BMI YoYo
>> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
>> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
>> 10393 CONFERENCE 10 D NA 36 NA 160
>> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
>> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
>> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>> 10541 LEAGUE_ONE 10 F NA 25 NA 160
>> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>> 
>> 
>> Many thanks in advance for time and help.  Really appreciate it.
>> 
>> Josh
>> 
>> 
>> > summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>> 
>> REML criterion at convergence: 125712.2
>> 
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>> 
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Id       (Intercept) 15300    123.7
>>  Residual             16530    128.6
>> Number of obs: 9609, groups:  Id, 6071
>> 
>> Fixed effects:
>>              Estimate Std. Error t value
>> (Intercept) -521.6985    16.8392  -30.98
>> AgeGr         62.6786     0.9783   64.07
>> PositionD    139.4682     7.8568   17.75
>> PositionM    141.2227     7.7072   18.32
>> PositionF    135.1241     8.1911   16.50
>> 
>> Correlation of Fixed Effects:
>>           (Intr) AgeGr  PostnD PostnM
>> AgeGr     -0.910
>> PositionD -0.359 -0.009
>> PositionM -0.375  0.001  0.810
>> PositionF -0.349 -0.003  0.756  0.782
>> > model=lmer(YoYo~AgeGr+Position+(1|Id))
>> > summary(glht(model,linfct=mcp(Position="Tukey")))
>> 
>>  Simultaneous Tests for General Linear Hypotheses
>> 
>> Multiple Comparisons of Means: Tukey Contrasts
>> 
>> 
>> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>> 
>> Linear Hypotheses:
>>             Estimate Std. Error z value Pr(>|z|)
>> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>> M - D == 0     1.754      4.799   0.366    0.983
>> F - D == 0    -4.344      5.616  -0.774    0.862
>> F - M == 0    -6.099      5.267  -1.158    0.645
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Adjusted p values reported -- single-step method)
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Apr 27 10:15:39 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Apr 2015 08:15:39 +0000
Subject: [R] How to calculate vif of each term of model in R?
In-Reply-To: <9C74639432B50946BF93B535048331619D98D5@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619D4D4C@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29994@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D883E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C299D7@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D885E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29A0D@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D8874@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C29AAB@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D888E@LONURLNA15.e2k.ad.ge.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B4A1@SRVEXCHMBX.precheza.cz>
	<9C74639432B50946BF93B535048331619D98D5@LONURLNA15.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B960@SRVEXCHMBX.precheza.cz>

Hi

Better to use dput(xsys) output as it preserves your actual data.

Other answers see in line

> -----Original Message-----
> From: Methekar, Pushpa (GE Transportation, Non-GE)
> [mailto:pushpa.methekar at ge.com]
> Sent: Monday, April 27, 2015 8:37 AM
> To: PIKAL Petr
> Subject: RE: How to calculate vif of each term of model in R?
>
> Hi petr,
> Thanks for your help ,I really appreciate it.
> My data is confidential so I am attaching sample data.
> Hope it would be useful for u to solve my problem.
>
> I ll tell u in brief what are my tasks.......
>
> ###### read in data
> xsys=read.csv(file.choose(),header = T)
>
> ####   x and y elements
> y1=xsys$Pre.Turb.Temp.L


<snip>


> y9=xsys$Emiss..1..EPA.MAF..Dry.
> ####
> x1=xsys$Engine.Speed


<snip>


> x9=xsys$NG.LHV
>
>
> ##### making models
> model1<-lm(y1~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)

your variables x and y are defined outside your original data frame hence no need for data argument. If you renamed your variables inside your data frame instead, you could use their position in creating models.

vif(model1)
Error in vif.default(model1) :
  there are aliased coefficients in the model

probably due to fewer data than terms.

I would use list for creating models. There is plenty of examples how to use lists.

Something like (untested)

for (i in 1:9) {
models[[i]] <- lm(xsys[,i]~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
}

which can be somehow polished by as.formula together with paste construction (see ?formula examples)

and after that something like this may work.

final.model <- vector(mode="list", 9)
for(i in 1:9) {
v <- vif(models[[i]])
while(v>=10) {
wmvif <- which.max(v)
models[[i]] <- update(models[[i]], as.formula(paste(". ~ . -",names(v)[wmvif]))
v <- vif(models[[i]])
}
final.model[[i]] <-models[[i]]
}

further operations like saving and plotting are easily done with lists and/or their manipulation.

Cheers
Petr



> model2<-lm(y2~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model3<-lm(y3~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model4<-lm(y4~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model5<-lm(y5~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model6<-lm(y6~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model7<-lm(y7~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model8<-lm(y8~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
> model9<-lm(y9~x1+x2+x3+x4+x5+x6+x7+x8+x9,data=xsys)
>
>
> ###making secondary models
> secmodel1<-lm(y1
> ~poly(x1,2)+poly(x2,2)+poly(x3,2)+poly(x4,2)+poly(x5,2)+poly(x6,2)
>               +poly(x7,2)+poly(x8,2)+poly(x9,2)
>               +x1*(x2+x3+x4+x5+x6+x7+x8+x9)
>               +x2*(x3+x4+x5+x6+x7+x8+x9)
>               +x3*(x4+x5+x6+x7+x8+x9)
>               +x4*(x5+x6+x7+x8+x9)
>               +x5*(x6+x7+x8+x9)
>               +x6*(x7+x8+x9)
>               +x7*(x8+x9)
>               +x8*(x9),data=xsys)
>
>                ,data=xsys)
> secmodel2<-lm(y2
> ~poly(x1,2)+poly(x2,2)+poly(x3,2)+poly(x4,2)+poly(x5,2)+poly(x6,2)
>               +poly(x7,2)+poly(x8,2)+poly(x9,2)
>               +x1*(x2+x3+x4+x5+x6+x7+x8+x9)
>               +x2*(x3+x4+x5+x6+x7+x8+x9)
>               +x3*(x4+x5+x6+x7+x8+x9)
>               +x4*(x5+x6+x7+x8+x9)
>               +x5*(x6+x7+x8+x9)
>               +x6*(x7+x8+x9)
>               +x7*(x8+x9)
>               +x8*(x9),data=xsys)
> ...........................up to
> Secmodel9<-lm(y9
> ~poly(x1,2)+poly(x2,2)+poly(x3,2)+poly(x4,2)+poly(x5,2)+poly(x6,2)
>               +poly(x7,2)+poly(x8,2)+poly(x9,2)
>               +x1*(x2+x3+x4+x5+x6+x7+x8+x9)
>               +x2*(x3+x4+x5+x6+x7+x8+x9)
>               +x3*(x4+x5+x6+x7+x8+x9)
>               +x4*(x5+x6+x7+x8+x9)
>               +x5*(x6+x7+x8+x9)
>               +x6*(x7+x8+x9)
>               +x7*(x8+x9)
>               +x8*(x9),data=xsys)
>
>
>
> ### now find out vif of each term until vif(term)<=10 and remove
> maximum vif term .
>
>
> My problem-
> I want to take each model in loop so that I can find out one maximum
> vif term in all terms .and remove it .again I ll find out, again remove
> it till vif(term)<=10 and stop.
>
>
> What u said in last mail is working fine.................for one time .
> I have to check it every time...
> Also I want to save each maximum vif in array  and plot() it.
> Hope you will understand my problem.
>
>
>
> Thanks,
> Pushpa
>
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Thursday, April 23, 2015 7:15 PM
> To: Methekar, Pushpa (GE Transportation, Non-GE)
> Cc: r-help at r-project.org
> Subject: RE: How to calculate vif of each term of model in R?
>
> Well. Your function results in error.
>
> > f1<-function(model){
> + vfs<<-vif(model)
> + vfs
> + ex<<-subset(vfs,vfs>=10)
> + print(ex)
> + maxx<<-which.max(ex)
> + print(maxx)
> + mm<<-vector(mode = "numeric",length = 50)
> +
> + mm<<-maxx
> + maxindex<<-which.max(ex)
> + print(maxindex)
> +
> + }
> > F1(model1)
> Error: could not find function "F1"
> >
> > f1(model1)
> Error in vcov(fit, regcoef.only = TRUE) : object 'model1' not found
> >
>
> Beside, why do you use global assignment.
>
> <<-
>
> within your function? I use R for more than 10 years and do not
> remember that I needed to use it.
>
> You did not provide any data nor try to work on my suggestions. If you
> kept your mail copies to list you probably would get the answer more
> quickly.
>
> You can use as.formula construction to programmatically select terms
> for update.
>
> > fit
>
> Call:
> lm(formula = barviv ~ rutil + sio2 + teklat + fe, data = prov)
>
> Coefficients:
> (Intercept)        rutil         sio2       teklat           fe
>    1230.154        5.956       15.123       55.322     5571.923
>
> > vif(fit)
>    rutil     sio2   teklat       fe
> 1.249975 1.702475 1.504633 1.094505
> > which.max(vif(fit))
> sio2
>    2
> > wmvif <- which.max(vif(fit))
> > update(fit, as.formula(paste(". ~ . -",names(vif(fit)[wmvif]))))
>
> Call:
> lm(formula = barviv ~ rutil + teklat + fe, data = prov)
>
> Coefficients:
> (Intercept)        rutil       teklat           fe
>     1220.25         6.04        97.44      5802.31
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > [mailto:pushpa.methekar at ge.com]
> > Sent: Friday, April 17, 2015 2:47 PM
> > To: PIKAL Petr
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > Hey ,
> > .........- names(vif(model1))[vmax])
> > Is not working actually
> > Instead
> > Update(model1,.~.-x8) is working fine.
> >
> >
> >
> > For that any option would you tell me.
> > As per your concern
> > Update(model1,.~.-names(vif(model1))[vmax] means
> >
> > Update(model1,.~.-"x8")
> > But it's not going to work.
> >
> > Look here is my program
> >
> > > require(rms)
> > f1<-function(model){
> > vfs<<-vif(model)
> > vfs
> > ex<<-subset(vfs,vfs>=10)
> > print(ex)
> > maxx<<-which.max(ex)
> > print(maxx)
> > mm<<-vector(mode = "numeric",length = 50)
> >
> > mm<<-maxx
> > maxindex<<-which.max(ex)
> > print(maxindex)
> >
> > }
> > F1(model1)
> >
> >
> >
> > Output:
> >    f1(model1)
> >        x7        x8        x9
> >  13.87063 220.96963 214.03413
> > [1] 220.9696
> > x8
> >  2
> >
> >
> > Now I have to do outside function explicitly
> > model1<-update(model1,.~.-x8)
> > then only I can remove my variable x8
> >
> > but I want to do in inside function so that automatically maximum
> > element get eliminated .
> >
> >
> > Thanks,
> > Pushpa
> >
> >
> >
> > -----Original Message-----
> > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > Sent: Friday, April 17, 2015 5:25 PM
> > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > Cc: r-help at r-project.org
> > Subject: RE: How to calculate vif of each term of model in R?
> >
> > Hi
> >
> > > -----Original Message-----
> > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > [mailto:pushpa.methekar at ge.com]
> > > Sent: Friday, April 17, 2015 1:12 PM
> > > To: PIKAL Petr
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > Hi Petr,
> > > You got my problem ,the solution which u specified is little good
> > > but with
> > >
> > >
> > > >update(model1,.~. - names(vif(model1))[vmax])
> > >
> > >
> > >
> > > I won't be able to update my model .
> > > Instead I have to write like
> > >
> > >
> > > > update(model1,.~. - x8)
> > >
> >
> > maybe something like
> >
> > fun = function(model1) {
> >
> > vmax <- which.max(vif(model1))
> >
> > while( vif(model1)[vmax]>=10) {
> >
> > model1 <- update(model1,.~. - names(vif(model1))[vmax])) vmax <-
> > which.max(vif(model1))
> >
> > }
> >
> > return(model1)
> >
> > }
> >
> > I am not sure about cycle (i did not use while in R for a while).
> >
> > Without some data I cannot check syntax so it is up to you.
> >
> > Cheers
> > Petr
> >
> >
> > >
> > > i.e my x which having highest vif value.
> > > Each time for removing highest x .i  have to explicitly write
> > > ......-
> > > x8) So is there any way to avoid this?
> > >
> > >
> > >
> > >
> > > Thanks,
> > > Pushpa
> > >
> > > -----Original Message-----
> > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > Sent: Friday, April 17, 2015 4:16 PM
> > > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > > Subject: RE: How to calculate vif of each term of model in R?
> > >
> > > Comments to your first mail which are among lines and directly
> > related
> > > to your code.
> > >
> > > I specifically mentioned it
> > >
> > > > answers and comments in line
> > >
> > > If you have my first respond you can find them easier then now as
> > they
> > > are buried within your mail.
> > >
> > > Cheers
> > > Petr
> > >
> > >
> > > > -----Original Message-----
> > > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > > [mailto:pushpa.methekar at ge.com]
> > > > Sent: Friday, April 17, 2015 12:10 PM
> > > > To: PIKAL Petr
> > > > Subject: RE: How to calculate vif of each term of model in R?
> > > >
> > > > What comments are you talking about?
> > > >
> > > > -----Original Message-----
> > > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > > Sent: Friday, April 17, 2015 3:38 PM
> > > > To: Methekar, Pushpa (GE Transportation, Non-GE)
> > > > Cc: r-help at r-project.org
> > > > Subject: RE: How to calculate vif of each term of model in R?
> > > >
> > > > Did you follow my advice/comments?
> > > >
> > > > Cheers
> > > > Petr
> > > >
> > > >
> > > > > -----Original Message-----
> > > > > From: Methekar, Pushpa (GE Transportation, Non-GE)
> > > > > [mailto:pushpa.methekar at ge.com]
> > > > > Sent: Friday, April 17, 2015 11:43 AM
> > > > > To: PIKAL Petr
> > > > > Subject: RE: How to calculate vif of each term of model in R?
> > > > >
> > > > > Car package
> > > > >
> > > > > -----Original Message-----
> > > > > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > > > > Sent: Friday, April 17, 2015 3:11 PM
> > > > > To: Methekar, Pushpa (GE Transportation, Non-GE); r-help at r-
> > > > project.org
> > > > > Subject: RE: How to calculate vif of each term of model in R?
> > > > >
> > > > > Hi
> > > > >
> > > > > I did not see any answer so I try.
> > > > >
> > > > > Your question lacks some info:
> > > > >
> > > > > Which vif - car or HH?
> > > > >
> > > > > answers and comments in line
> > > > >
> > > > > > -----Original Message-----
> > > > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf
> > > > > > Of Methekar, Pushpa (GE Transportation, Non-GE)
> > > > > > Sent: Wednesday, April 08, 2015 10:24 AM
> > > > > > To: r-help at r-project.org
> > > > > > Subject: [R] How to calculate vif of each term of model in R?
> > > > > >
> > > > > >
> > > > > > I am beginner in R doing modelling in R, I loaded excel sheet
> > in
> > > > > > R, i have chosen x elements and y elements then fitted model
> > for
> > > > linear
> > > > > and
> > > > > > second order regression. Now I have both models. I am bit
> > > confused
> > > > > how
> > > > > > to calculate vif for each term in model like
> > > > > >
> > > > > > e.g model1<-lm(y1~x1+x2+.....x9) when I am using rms package
> > > > > > then
> > > > > it's
> > > > > > giving me like
> > > > > >
> > > > > >     vif(model1)
> > > > > >
> > > > > >        x1         x2         x3         x4         x5
> > x6
> > > > > > x7
> > > > > >
> > > > > >  6.679692   1.520271   1.667125   3.618439   4.931810
> > 2.073879
> > > > > > 13.870630
> > > > > >
> > > > > >         x8         x9
> > > > > >
> > > > > >    220.969628 214.034135
> > > > > >
> > > > > > now i want to compare each term with std vif as vif>=10 and
> > > > > > which
> > > > > will
> > > > > > satisfy this condition i want to delete that term and update
> > > > model1.
> > > > > i
> > > > > > have done something like this
> > > > > >
> > > > > > fun = function(model1) {
> > > > > >
> > > > > >  for(i in 1:length(model1))    {
> > > > > >
> > > > > >       v=vif(model1)
> > > > > >
> > > > > >          ss=any(v[i]>=10)
> > > > >
> > > > > here you select only one item from vif, Why do you use any?
> > > > >
> > > > > >
> > > > > >                 if(ss==1){update(model1,.~.,-v[i])}
> > > > > >
> > > > > >                 else{print("no update")}
> > > > > >
> > > > >
> > > > > Why do you change i here?
> > > > >
> > > > > >                  i<-i+1
> > > > > >
> > > > > >     }
> > > > > >
> > > > > >
> > > > > >
> > > > > >         return(model1)
> > > > > >
> > > > > >       }
> > > > > >
> > > > >
> > > > > if you want to get rid of all terms bigger than some threshold
> > > > > in
> > > > once
> > > > > you can use
> > > > >
> > > > > sel <- which(vif(model1)>10)
> > > > >
> > > > > and select values for update possibly by
> > > > >
> > > > > update(model1,.~. - names(vif(model1))[sel])
> > > > >
> > > > > or if you want to get rid one by one you can use
> > > > >
> > > > > vmax <- which.max(vif(model1))
> > > > > and check if max vif value is bigger than 10.
> > > > >
> > > > > vif(model1)[vmax]>=10
> > > > >
> > > > > If it is just update with
> > > > >
> > > > > - names(vif(model1))[vmax])
> > > > >
> > > > > if it is not do not update.
> > > > >
> > > > > All of this untested.
> > > > >
> > > > > Cheers
> > > > > Petr
> > > > >
> > > > > > fun(model1)
> > > > > >
> > > > > > but giving error as
> > > > > >
> > > > > > Error in if (ss == 1) { : missing value where TRUE/FALSE
> > needed.
> > > > > >
> > > > > > please tell me how do i solve this problem.
> > > > > >
> > > > > >
> > > > > >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Apr 27 10:29:36 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Apr 2015 08:29:36 +0000
Subject: [R] Question about base::rank results
In-Reply-To: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B977@SRVEXCHMBX.precheza.cz>

Hi

You want to use order.

rank gives you position of x according their values.

> x <- c(12,34,15,77,78,22)

> rank(x)
[1] 1 4 2 5 6 3

order gives you sorting vector to get your values in ascending or descending order.

> order(x)
[1] 1 3 6 2 4 5
> x[order(x)]
[1] 12 15 22 34 77 78

You can see it as

as first element 12 is selected - 1
as second element 15 is selected - 3
as third element 22 is selected - 6
...

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Giorgio
> Garziano
> Sent: Sunday, April 26, 2015 10:18 AM
> To: r-help at r-project.org
> Subject: [R] Question about base::rank results
>
> Hi,
>
> I cannot understand why rank(x) behaves as outlined below.
> Based on the results of first x vector values ranking, which is as
> expected in my opinion, I cannot explain the following results.
>
> > x <- c(12,34,15,77,78)
> > x[rank(x)]
> [1] 12 15 34 77 78      (OK)
>
> > x <- c(12,34,15,77,78,22)
> > x[rank(x)]
> [1] 12 77 34 78 22 15   (?)
>
> > x <- c(12,34,77,15,78)
> > x[rank(x)]
> [1] 12 77 15 34 78      (?)
>
> Please any feedback ? Thanks.
>
> BR,
>
> Giorgio Garziano
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From thierry.onkelinx at inbo.be  Mon Apr 27 10:39:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Apr 2015 10:39:24 +0200
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <03F37599-48EE-4518-BF71-2C324E8C3A9E@gmail.com>
References: <CAOkeKBJt-WVwTt1nemyxHSkZ1CnwK36Q+_neG2yKy_4pM2RgQw@mail.gmail.com>
	<CAJuCY5zm6Meb=dMNO6TcQPGPQux2021T3mJ7wpkifeA6ZC8ZnA@mail.gmail.com>
	<03F37599-48EE-4518-BF71-2C324E8C3A9E@gmail.com>
Message-ID: <CAJuCY5xWSxZt3_u16fWhFdnkMFhcMWcXE_AiQ8nrDD+Y6WWyoA@mail.gmail.com>

Hello Josh,

One is never too old to study ;-)

Your question seems quite broad. You might be better off to read some books
on mixed models (e.g. Pinheiro & Bates (2000) or Zuur et al (2009)) or try
to find a local statistician. Email is not a suitable medium to teach
statistics.

Note that r-sig-mixed-models is a more suitable list for _specific_
questions on mixed models.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-27 9:54 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:

> Hello Thierry,
>
> No, this isn't homework. Not that young unfortunately.
>
> Josh
>
> On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Josh,
>
> Is this homework? Because the list has a no homework policy.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>
>> Hello!
>>
>> Very new to R (10 days), and I've run the linear mixed model, below.
>> Attempting to interpret what it means...  What do I need to look for?
>> Residuals, correlations of fixed effects?!
>>
>> How would I look at very specific interactions, such as PREMIER_LEAGUE
>> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18  GK?
>>
>> For reference my data set looks like this:
>>
>> Id Level AgeGr   Position Height Weight BMI YoYo
>> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
>> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
>> 10393 CONFERENCE 10 D NA 36 NA 160
>> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
>> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
>> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>> 10541 LEAGUE_ONE 10 F NA 25 NA 160
>> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>>
>>
>> Many thanks in advance for time and help.  Really appreciate it.
>>
>> Josh
>>
>>
>> > summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>>
>> REML criterion at convergence: 125712.2
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Id       (Intercept) 15300    123.7
>>  Residual             16530    128.6
>> Number of obs: 9609, groups:  Id, 6071
>>
>> Fixed effects:
>>              Estimate Std. Error t value
>> (Intercept) -521.6985    16.8392  -30.98
>> AgeGr         62.6786     0.9783   64.07
>> PositionD    139.4682     7.8568   17.75
>> PositionM    141.2227     7.7072   18.32
>> PositionF    135.1241     8.1911   16.50
>>
>> Correlation of Fixed Effects:
>>           (Intr) AgeGr  PostnD PostnM
>> AgeGr     -0.910
>> PositionD -0.359 -0.009
>> PositionM -0.375  0.001  0.810
>> PositionF -0.349 -0.003  0.756  0.782
>> > model=lmer(YoYo~AgeGr+Position+(1|Id))
>> > summary(glht(model,linfct=mcp(Position="Tukey")))
>>
>>  Simultaneous Tests for General Linear Hypotheses
>>
>> Multiple Comparisons of Means: Tukey Contrasts
>>
>>
>> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>>
>> Linear Hypotheses:
>>             Estimate Std. Error z value Pr(>|z|)
>> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>> M - D == 0     1.754      4.799   0.366    0.983
>> F - D == 0    -4.344      5.616  -0.774    0.862
>> F - M == 0    -6.099      5.267  -1.158    0.645
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Adjusted p values reported -- single-step method)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jl.iccp at gmail.com  Mon Apr 27 11:26:14 2015
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Mon, 27 Apr 2015 11:26:14 +0200
Subject: [R] Mean of dates
In-Reply-To: <CAAMkPW8VhhQ9yo5qT=D7Y5n6ZqBXVaoLWBEaKWE-Px9ttUM+TQ@mail.gmail.com>
References: <CAAMkPW9ysHD2DEHC-RrNBO-KJsO0AZipkxaqZmjhF__mZ1MvLA@mail.gmail.com>
	<alpine.DEB.2.11.1504241259240.9567@paninaro.uibk.ac.at>
	<CAAMkPW8VhhQ9yo5qT=D7Y5n6ZqBXVaoLWBEaKWE-Px9ttUM+TQ@mail.gmail.com>
Message-ID: <CAAMkPW9WQ3K8XUj3XPhS1Hbyv_y_h6XACPk+AThd=Ldq6iTPxA@mail.gmail.com>

On 24 April 2015 at 13:47, Jue Lin-Ye <jl.iccp at gmail.com> wrote:

>
>
> On 24 April 2015 at 12:59, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>
>>
>>
>> On Fri, 24 Apr 2015, Jue Lin-Ye wrote:
>>
>>  Dear fellow R-help members,
>>>
>>> If my data is
>>>
>>> YYYY MM DD HH
>>> 2015 04 24 01
>>> 2015 04 24 02
>>> 2015 04 24 06
>>>
>>> Where
>>>
>>> YYYY: year
>>> MM:month
>>> DD:day
>>> HH: hour
>>>
>>> How could I calculate the mean of the ISOdatetime(YYYY,MM,DD,HH,0,0) of
>>> these?
>>>
>>
>> With the mean() method? On my machine:
>>
>> R> mean(ISOdatetime(YYYY,MM,DD,HH,0,0))
>> [1] "2015-04-24 03:00:00 CEST"
>>
>>
> ?Hi! Maybe the problem is when I try to create the vector that I am
> looking for. Please ?check this code out.
>
>
> ?X_season1<-matrix(c(2015, 04, 24, 01, 2015 ,04, 24, 02,
>   2015 ,04 ,24 ,03 ,2015 ,04 ,24 ,05,
>   2015, 04, 24 ,06 ,2015, 04 ,24
> ,10),3,8,byrow=T);colnames(X_season1)<-c("AAi","MMi","DDi","HHi","AAf","MMf","DDf","HHf")
> time2<-NULL
> for(i5 in 1:nrow(X_season1)){
>   time2[i5]<-mean(
>
> as.Date(c(ISOdatetime(X_season1[i5,"AAi"],X_season1[i5,"MMi"],X_season1[i5,"DDi"],X_season1[i5,"HHi"],0,0),
>
> ISOdatetime(X_season1[i5,"AAf"],X_season1[i5,"MMf"],X_season1[i5,"DDf"],X_season1[i5,"HHf"],0,0)),
>                           format="%YYYY-%mm-%dd %H:%m:%s"),trim=0)}?
>
> ?Thanks!?
>
>
Dear Dr. Zeileis,

 Here is the solution that I finally came up with, I hope you agree with
it. From your suggestion, I saw that the problem was the creation of the
vector. It needed to be numeric. So I calculate the difftime from each date
to a reference date (1990/01/01 00:00:00). The units is "hours". I obtain a
vector of difference numbers. Then I add these numbers, transformed into
seconds, to the reference date. ?


?Thank you so much for your help!

Best regards,

Jue?


>
>> hth,
>> Z
>>
>>  Note: I set minutes and seconds to 0, as I don't have data for them.
>>>
>>> ?Thank you in advance!?
>>>
>>> --
>>> Jue Lin-Ye
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Mon Apr 27 13:37:10 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 27 Apr 2015 03:37:10 -0800
Subject: [R] Question about base::rank results
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2B977@SRVEXCHMBX.precheza.cz>
References: <248e6fa047a8c746ba491485764190f521fb388d@esessmb207.ericsson.se>
Message-ID: <EB293AAFD32.00000290jrkrideau@inbox.com>

Ah, thanks. That makes sense. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: petr.pikal at precheza.cz
> Sent: Mon, 27 Apr 2015 08:29:36 +0000
> To: giorgio.garziano at ericsson.com, r-help at r-project.org
> Subject: Re: [R] Question about base::rank results
> 
> Hi
> 
> You want to use order.
> 
> rank gives you position of x according their values.
> 
>> x <- c(12,34,15,77,78,22)
> 
>> rank(x)
> [1] 1 4 2 5 6 3
> 
> order gives you sorting vector to get your values in ascending or
> descending order.
> 
>> order(x)
> [1] 1 3 6 2 4 5
>> x[order(x)]
> [1] 12 15 22 34 77 78
> 
> You can see it as
> 
> as first element 12 is selected - 1
> as second element 15 is selected - 3
> as third element 22 is selected - 6
> ...
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Giorgio
>> Garziano
>> Sent: Sunday, April 26, 2015 10:18 AM
>> To: r-help at r-project.org
>> Subject: [R] Question about base::rank results
>> 
>> Hi,
>> 
>> I cannot understand why rank(x) behaves as outlined below.
>> Based on the results of first x vector values ranking, which is as
>> expected in my opinion, I cannot explain the following results.
>> 
>>> x <- c(12,34,15,77,78)
>>> x[rank(x)]
>> [1] 12 15 34 77 78      (OK)
>> 
>>> x <- c(12,34,15,77,78,22)
>>> x[rank(x)]
>> [1] 12 77 34 78 22 15   (?)
>> 
>>> x <- c(12,34,77,15,78)
>>> x[rank(x)]
>> [1] 12 77 15 34 78      (?)
>> 
>> Please any feedback ? Thanks.
>> 
>> BR,
>> 
>> Giorgio Garziano
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by the
> recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From giorgio.garziano at ericsson.com  Mon Apr 27 13:38:38 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 27 Apr 2015 11:38:38 +0000
Subject: [R] Question about base::rank results
In-Reply-To: <553DE411.2080703@auckland.ac.nz>
References: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
	<553DE411.2080703@auckland.ac.nz>
Message-ID: <248E6FA047A8C746BA491485764190F521FB3FF8@ESESSMB207.ericsson.se>

Ok. Thanks for your explanation.

Cheers,
Giorgio Garziano

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: luned? 27 aprile 2015 09:24
To: Giorgio Garziano; r-help at r-project.org
Subject: Re: [R] Question about base::rank results

On 26/04/15 20:17, Giorgio Garziano wrote:
> Hi,
>
> I cannot understand why rank(x) behaves as outlined below. Based on 
> the results of first x vector values ranking, which is as expected in 
> my opinion, I cannot explain the following results.
>
>> x <- c(12,34,15,77,78)
>> x[rank(x)]
> [1] 12 15 34 77 78      (OK)
>
>> x <- c(12,34,15,77,78,22)
>> x[rank(x)]
> [1] 12 77 34 78 22 15   (?)
>
>> x <- c(12,34,77,15,78)
>> x[rank(x)]
> [1] 12 77 15 34 78      (?)
>
> Please any feedback ? Thanks.


What did you expect to get?

To take your 2nd example:

x <- c(12,34,15,77,78,22)
x[rank(x)]
[1] 12 77 34 78 22 15   (?)

Why (?) ?

The rank of 12 is 1.
The rank of 34 is 4.
The rank of 15 is 2.
The rank of 77 is 5.
The rank of 78 is 6.
The rank of 22 is 3.

Thus x[rank(x)] gives you the 1st, 4th, 2nd, 5th, 6th and 3rd entries of x.  In that order.

What on earth is puzzling you?

I can think of no good reason for ever looking at x[rank(x)].

Perhaps, judging from your first example which you say is "OK", you want x[order(x)].

cheers,

Rolf Turner

--
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jrkrideau at inbox.com  Mon Apr 27 13:42:36 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 27 Apr 2015 03:42:36 -0800
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <03F37599-48EE-4518-BF71-2C324E8C3A9E@gmail.com>
References: <caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
Message-ID: <EB356122A2C.0000029Djrkrideau@inbox.com>



John Kane
Kingston ON Canada


> -----Original Message-----
> From: joshuamichaeldixon at gmail.com
> Sent: Mon, 27 Apr 2015 08:54:51 +0100
> To: thierry.onkelinx at inbo.be
> Subject: Re: [R] Help Interpreting Linear Mixed Model
> 
> Hello Thierry,
> 
> No, this isn't homework. Not that young unfortunately.
> 

A few years ago a friend of mine and her daughter were neck-in-neck on who got their Ph.D first. What's this "not that young" business?

BTW, a better way to supply sample data is to use the dput() command.

Do a dput(mydata), copy the results into the email and you have supplied us with an exact copy of your data.  

It is possible for many reasons that I will not read in your data, as you supplied it, in the format you have it in.  This can lead to real confusion.





> Josh
> 
>> On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>> 
>> Dear Josh,
>> 
>> Is this homework? Because the list has a no homework policy.
>> 
>> Best regards,
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data. ~ John Tukey
>> 
>> 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>>> Hello!
>>> 
>>> Very new to R (10 days), and I've run the linear mixed model, below.
>>> Attempting to interpret what it means...  What do I need to look for?
>>> Residuals, correlations of fixed effects?!
>>> 
>>> How would I look at very specific interactions, such as PREMIER_LEAGUE
>>> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>>> GK?
>>> 
>>> For reference my data set looks like this:
>>> 
>>> Id Level AgeGr   Position Height Weight BMI YoYo
>>> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
>>> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
>>> 10393 CONFERENCE 10 D NA 36 NA 160
>>> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
>>> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
>>> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>>> 10541 LEAGUE_ONE 10 F NA 25 NA 160
>>> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>>> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>>> 
>>> 
>>> Many thanks in advance for time and help.  Really appreciate it.
>>> 
>>> Josh
>>> 
>>> 
>>>> summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>>> Linear mixed model fit by REML ['lmerMod']
>>> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>>> 
>>> REML criterion at convergence: 125712.2
>>> 
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>>> 
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  Id       (Intercept) 15300    123.7
>>>  Residual             16530    128.6
>>> Number of obs: 9609, groups:  Id, 6071
>>> 
>>> Fixed effects:
>>>              Estimate Std. Error t value
>>> (Intercept) -521.6985    16.8392  -30.98
>>> AgeGr         62.6786     0.9783   64.07
>>> PositionD    139.4682     7.8568   17.75
>>> PositionM    141.2227     7.7072   18.32
>>> PositionF    135.1241     8.1911   16.50
>>> 
>>> Correlation of Fixed Effects:
>>>           (Intr) AgeGr  PostnD PostnM
>>> AgeGr     -0.910
>>> PositionD -0.359 -0.009
>>> PositionM -0.375  0.001  0.810
>>> PositionF -0.349 -0.003  0.756  0.782
>>>> model=lmer(YoYo~AgeGr+Position+(1|Id))
>>>> summary(glht(model,linfct=mcp(Position="Tukey")))
>>> 
>>>  Simultaneous Tests for General Linear Hypotheses
>>> 
>>> Multiple Comparisons of Means: Tukey Contrasts
>>> 
>>> 
>>> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>>> 
>>> Linear Hypotheses:
>>>             Estimate Std. Error z value Pr(>|z|)
>>> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>>> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>>> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>>> M - D == 0     1.754      4.799   0.366    0.983
>>> F - D == 0    -4.344      5.616  -0.774    0.862
>>> F - M == 0    -6.099      5.267  -1.158    0.645
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> (Adjusted p values reported -- single-step method)
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From lists at dewey.myzen.co.uk  Mon Apr 27 17:10:15 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 27 Apr 2015 16:10:15 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <EB356122A2C.0000029Djrkrideau@inbox.com>
References: <caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<EB356122A2C.0000029Djrkrideau@inbox.com>
Message-ID: <553E5157.10206@dewey.myzen.co.uk>

Dear Joshua

It would also help if you told us what your scientific question was. At 
the moment we know what R commands you used and have seen the head of 
your dataset but not why you are doing it.

I would summarise what you have given us as

1 - most ID only occur once
2 - goal keepers do worse than outfield players
3 - older people (presumably in fact age is in years as a continuous 
variable) do better

On 27/04/2015 12:42, John Kane wrote:
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: joshuamichaeldixon at gmail.com
>> Sent: Mon, 27 Apr 2015 08:54:51 +0100
>> To: thierry.onkelinx at inbo.be
>> Subject: Re: [R] Help Interpreting Linear Mixed Model
>>
>> Hello Thierry,
>>
>> No, this isn't homework. Not that young unfortunately.
>>
>
> A few years ago a friend of mine and her daughter were neck-in-neck on who got their Ph.D first. What's this "not that young" business?
>
> BTW, a better way to supply sample data is to use the dput() command.
>
> Do a dput(mydata), copy the results into the email and you have supplied us with an exact copy of your data.
>
> It is possible for many reasons that I will not read in your data, as you supplied it, in the format you have it in.  This can lead to real confusion.
>
>
>
>
>
>> Josh
>>
>>> On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>> Dear Josh,
>>>
>>> Is this homework? Because the list has a no homework policy.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data. ~ John Tukey
>>>
>>> 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>>>> Hello!
>>>>
>>>> Very new to R (10 days), and I've run the linear mixed model, below.
>>>> Attempting to interpret what it means...  What do I need to look for?
>>>> Residuals, correlations of fixed effects?!
>>>>
>>>> How would I look at very specific interactions, such as PREMIER_LEAGUE
>>>> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>>>> GK?
>>>>
>>>> For reference my data set looks like this:
>>>>
>>>> Id Level AgeGr   Position Height Weight BMI YoYo
>>>> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
>>>> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
>>>> 10393 CONFERENCE 10 D NA 36 NA 160
>>>> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
>>>> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
>>>> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>>>> 10541 LEAGUE_ONE 10 F NA 25 NA 160
>>>> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>>>> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>>>>
>>>>
>>>> Many thanks in advance for time and help.  Really appreciate it.
>>>>
>>>> Josh
>>>>
>>>>
>>>>> summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>>>> Linear mixed model fit by REML ['lmerMod']
>>>> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>>>>
>>>> REML criterion at convergence: 125712.2
>>>>
>>>> Scaled residuals:
>>>>      Min      1Q  Median      3Q     Max
>>>> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>>>>
>>>> Random effects:
>>>>   Groups   Name        Variance Std.Dev.
>>>>   Id       (Intercept) 15300    123.7
>>>>   Residual             16530    128.6
>>>> Number of obs: 9609, groups:  Id, 6071
>>>>
>>>> Fixed effects:
>>>>               Estimate Std. Error t value
>>>> (Intercept) -521.6985    16.8392  -30.98
>>>> AgeGr         62.6786     0.9783   64.07
>>>> PositionD    139.4682     7.8568   17.75
>>>> PositionM    141.2227     7.7072   18.32
>>>> PositionF    135.1241     8.1911   16.50
>>>>
>>>> Correlation of Fixed Effects:
>>>>            (Intr) AgeGr  PostnD PostnM
>>>> AgeGr     -0.910
>>>> PositionD -0.359 -0.009
>>>> PositionM -0.375  0.001  0.810
>>>> PositionF -0.349 -0.003  0.756  0.782
>>>>> model=lmer(YoYo~AgeGr+Position+(1|Id))
>>>>> summary(glht(model,linfct=mcp(Position="Tukey")))
>>>>
>>>>   Simultaneous Tests for General Linear Hypotheses
>>>>
>>>> Multiple Comparisons of Means: Tukey Contrasts
>>>>
>>>>
>>>> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>>>>
>>>> Linear Hypotheses:
>>>>              Estimate Std. Error z value Pr(>|z|)
>>>> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>>>> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>>>> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>>>> M - D == 0     1.754      4.799   0.366    0.983
>>>> F - D == 0    -4.344      5.616  -0.774    0.862
>>>> F - M == 0    -6.099      5.267  -1.158    0.645
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> (Adjusted p values reported -- single-step method)
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From aasdelat at aim.com  Mon Apr 27 17:55:01 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Mon, 27 Apr 2015 11:55:01 -0400
Subject: [R] Interactive maps
In-Reply-To: <14cfac25d5e-7c83-23d1a@webprd-a41.mail.aol.com>
Message-ID: <14cfb96babd-7c83-25462@webprd-a41.mail.aol.com>



Ok.

 
 The point now is that I have the sources (in Fortran) of the program that produces the graph with the map. And have to attach the information about the xrange and yrange to this graph in order for them to be read from R. Id est, I have to write: first longitude, first latitude, last longitude, last latitude, and also, the "figure" coordinates of the bounding box of the map in the figure.
 
 If I produce the map in eps, I can open it as a text file from the same fortran rogram, and modify the contents of the eps file in order to put the coordinates information into it.
 
 Then, once the fortran program has ended, I convert the eps to png using ImageMagic, because the EBImage library doesn't read eps, but png.
 
 In order for the png to contain the same properties as the eps, these have to be correctly defined in the eps.
 
 So, the question now is: how can I properly define properties in a eps, so that these are preserved in the convertion to png?.
 
 Perhaps this is not for this forum, but I haven't found information about it in the internet.
 
    
    
   
   
Antonio Serrano   
 aasdelat at aim.com   
    ?   
   
   
    
   
   
    
   
   
-----Original Message-----   
 From: Jim Lemon <drjimlemon at gmail.com>   
 To: Antonio Serrano <aasdelat at aim.com>   
 Sent: Sun, Apr 26, 2015 1:03 am   
 Subject: Re: [R] Interactive maps   
    
    
     
Hi Antonio,
If you mean the normalized figure coordinates (i.e. from 0 to 1)
then
you want something like
this:

loc_convert<-function(n=1,xrange=c(0,1),yrange=c(0,1)) {

plot_loc<-locator(n=n)
 plot_loc$x<-plot_loc$x/diff(xrange)+xrange[1]

plot_loc$y<-plot_loc$y/diff(yrange)+yrange[1]
 return(plot$loc)
}

where
xrange and yrange are the longitudes and latitudes respectively.

Jim


On
Sun, Apr 26, 2015 at 1:09 AM, Antonio Serrano <aasdelat at aim.com> wrote:
> Thank
you, Jim:
>
>    I have tried your suggestion and I get the following
error:
>
>   Error en rasterImage(image = "map.eps",  :
>    invalid color
name 'map.eps'
>
>  I have tried with three formats of the same image: svg,
gif and eps, with
> the same result.
>
> But I have found a possible better
way to accomplish this objective in the
> following thread:
>
http://r.789695.n4.nabble.com/Loading-an-image-picture-png-jpeg-to-screen-td2244923.html
>
>
In short:
>
> library(gridExtra)
> library(EBImage)
> library(RGraphics)
>
x <- readImage("http://www.google.com/logos/teachersday09.gif")
> g1 <-
ebimageGrob(x)
> dev.new(width=g1$width/72, height=g1$height/72)
>
plot.new()
> grid.draw(g1)
> c=locator(n=1, type="n")
>
> Then, when I click
on the map, I get the "figure" coordinates where I
> clicked, and still have to
translate these to longitude-latitude.
>
> And here comes another question:
How can I attach the first longitude, last
> longitude, fisrt latitude, last
latitude, to a JPEG, PNG or TIFF graphic?.
> These are the formats supported by
the EBImage package.
>
>
>
> Antonio Serrano
> aasdelat at aim.com
>
?
>
>
> -----Original Message-----
> From: Jim Lemon
<drjimlemon at gmail.com>
> To: Antonio Serrano <aasdelat at aim.com>
> Sent: Sat,
Apr 25, 2015 8:36 am
> Subject: Re: [R] Interactive maps
>
> Hi Antonio,
>
Try the rasterImage function.
>
> Jim
>
>
> On Sat, Apr 25, 2015 at
> 4:19
PM, Antonio Serrano <aasdelat at aim.com> wrote:
>> Thank you, Jim.
>>
>> I
>
didn't know the existence of the locator() function. But I can see now
>> that
I
> don't know how to read a graphic image into R to work with it.
>> How can
I read
> a pre-exisiting image into R?.
>>
>> Thanks again
>>
>>
>>
Antonio Serrano
>>
> aasdelat at aim.com
>> ?
>>
>>
>> -----Original
Message-----
>> From: Jim Lemon
> <drjimlemon at gmail.com>
>> To: Antonio
Serrano <aasdelat at aim.com>
>> Cc: r-help
> mailing list
<r-help at r-project.org>
>> Sent: Sat, Apr 25, 2015 5:47 am
>>
> Subject: Re:
[R] Interactive maps
>>
>> Hi Antonio,
>> If you do create the map
> in R,
you can use
>> locator().
>>
>> Jim
>>
>>
>> On Sat, Apr 25, 2015 at
8:37
> AM, Antonio Serrano via
>> R-help
>> <r-help at r-project.org>
wrote:
>>>
>>>
> Hello, all:
>>>
>>>    I am new here,
>> and have a
challenge to present some
> graphical data to the user in a
>> convenient
>>
way.
>>>
>>>    The challenge
> is to present a map to the user which is
coloured
>> with the value of a
> variable. Say for example, temperature. This
is a
>> preexisting graph that I
> can generate in any format, including svg.
I don't
>> have
>> to produce it
> using R.
>>>
>>>    When the user clicks
anywhere in the map, the
>> coordinates
> (longitude and latitude) have to be
passed to R so that this, R,
>> can
>> look
> for the values of other
variables in that location and make another
>> graph
>>
> with
them.
>>>
>>>    Does anyubody know how could I accomplish
>
this?.
>>>
>>>
>> Thanks in advance.
>>>
>>>
>>>
>>> Antonio
Serrano
>>>
> aasdelat at aim.com
>>> ?
>>>
>>>
>>>
>> [[alternative HTML
version
> deleted]]
>>>
>>>
>>
______________________________________________
>>>
> R-help at r-project.org
mailing
>> list -- To UNSUBSCRIBE and more, see
>>>
>>
>
https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting
>
guide
>> http://www.R-project.org/posting-guide.html
>>> and provide
commented,
> minimal,
>> self-contained, reproducible code.

    
   


	[[alternative HTML version deleted]]


From btupper at bigelow.org  Mon Apr 27 19:59:42 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 27 Apr 2015 13:59:42 -0400
Subject: [R] Interactive maps
In-Reply-To: <14cfb96babd-7c83-25462@webprd-a41.mail.aol.com>
References: <14cfb96babd-7c83-25462@webprd-a41.mail.aol.com>
Message-ID: <1FBF7FEA-EF16-408E-9A53-CD443BD064EC@bigelow.org>

Hi,

You may want to redirect your question to the R-sig-Geo mailing list: 

https://stat.ethz.ch/mailman/listinfo/r-sig-geo

In the meantime, you might consider writing to the 'rasterfile' format.  The 'rasterfile' format is very well documented and is to read/write from R; I suspect it would easy for you to write to this format from Fortran.  See the details here:

http://cran.r-project.org/web/packages/raster/vignettes/rasterfile.pdf

Cheers,
Ben

On Apr 27, 2015, at 11:55 AM, Antonio Serrano via R-help <r-help at r-project.org> wrote:

> 
> 
> Ok.
> 
> 
> The point now is that I have the sources (in Fortran) of the program that produces the graph with the map. And have to attach the information about the xrange and yrange to this graph in order for them to be read from R. Id est, I have to write: first longitude, first latitude, last longitude, last latitude, and also, the "figure" coordinates of the bounding box of the map in the figure.
> 
> If I produce the map in eps, I can open it as a text file from the same fortran rogram, and modify the contents of the eps file in order to put the coordinates information into it.
> 
> Then, once the fortran program has ended, I convert the eps to png using ImageMagic, because the EBImage library doesn't read eps, but png.
> 
> In order for the png to contain the same properties as the eps, these have to be correctly defined in the eps.
> 
> So, the question now is: how can I properly define properties in a eps, so that these are preserved in the convertion to png?.
> 
> Perhaps this is not for this forum, but I haven't found information about it in the internet.
> 
> 
> 
> 
> 
> Antonio Serrano   
> aasdelat at aim.com   
>    ?   
> 
> 
> 
> 
> 
> 
> 
> 
> -----Original Message-----   
> From: Jim Lemon <drjimlemon at gmail.com>   
> To: Antonio Serrano <aasdelat at aim.com>   
> Sent: Sun, Apr 26, 2015 1:03 am   
> Subject: Re: [R] Interactive maps   
> 
> 
> 
> Hi Antonio,
> If you mean the normalized figure coordinates (i.e. from 0 to 1)
> then
> you want something like
> this:
> 
> loc_convert<-function(n=1,xrange=c(0,1),yrange=c(0,1)) {
> 
> plot_loc<-locator(n=n)
> plot_loc$x<-plot_loc$x/diff(xrange)+xrange[1]
> 
> plot_loc$y<-plot_loc$y/diff(yrange)+yrange[1]
> return(plot$loc)
> }
> 
> where
> xrange and yrange are the longitudes and latitudes respectively.
> 
> Jim
> 
> 
> On
> Sun, Apr 26, 2015 at 1:09 AM, Antonio Serrano <aasdelat at aim.com> wrote:
>> Thank
> you, Jim:
>> 
>>   I have tried your suggestion and I get the following
> error:
>> 
>>  Error en rasterImage(image = "map.eps",  :
>>   invalid color
> name 'map.eps'
>> 
>> I have tried with three formats of the same image: svg,
> gif and eps, with
>> the same result.
>> 
>> But I have found a possible better
> way to accomplish this objective in the
>> following thread:
>> 
> http://r.789695.n4.nabble.com/Loading-an-image-picture-png-jpeg-to-screen-td2244923.html
>> 
>> 
> In short:
>> 
>> library(gridExtra)
>> library(EBImage)
>> library(RGraphics)
>> 
> x <- readImage("http://www.google.com/logos/teachersday09.gif")
>> g1 <-
> ebimageGrob(x)
>> dev.new(width=g1$width/72, height=g1$height/72)
>> 
> plot.new()
>> grid.draw(g1)
>> c=locator(n=1, type="n")
>> 
>> Then, when I click
> on the map, I get the "figure" coordinates where I
>> clicked, and still have to
> translate these to longitude-latitude.
>> 
>> And here comes another question:
> How can I attach the first longitude, last
>> longitude, fisrt latitude, last
> latitude, to a JPEG, PNG or TIFF graphic?.
>> These are the formats supported by
> the EBImage package.
>> 
>> 
>> 
>> Antonio Serrano
>> aasdelat at aim.com
>> 
> ?
>> 
>> 
>> -----Original Message-----
>> From: Jim Lemon
> <drjimlemon at gmail.com>
>> To: Antonio Serrano <aasdelat at aim.com>
>> Sent: Sat,
> Apr 25, 2015 8:36 am
>> Subject: Re: [R] Interactive maps
>> 
>> Hi Antonio,
>> 
> Try the rasterImage function.
>> 
>> Jim
>> 
>> 
>> On Sat, Apr 25, 2015 at
>> 4:19
> PM, Antonio Serrano <aasdelat at aim.com> wrote:
>>> Thank you, Jim.
>>> 
>>> I
>> 
> didn't know the existence of the locator() function. But I can see now
>>> that
> I
>> don't know how to read a graphic image into R to work with it.
>>> How can
> I read
>> a pre-exisiting image into R?.
>>> 
>>> Thanks again
>>> 
>>> 
>>> 
> Antonio Serrano
>>> 
>> aasdelat at aim.com
>>> ?
>>> 
>>> 
>>> -----Original
> Message-----
>>> From: Jim Lemon
>> <drjimlemon at gmail.com>
>>> To: Antonio
> Serrano <aasdelat at aim.com>
>>> Cc: r-help
>> mailing list
> <r-help at r-project.org>
>>> Sent: Sat, Apr 25, 2015 5:47 am
>>> 
>> Subject: Re:
> [R] Interactive maps
>>> 
>>> Hi Antonio,
>>> If you do create the map
>> in R,
> you can use
>>> locator().
>>> 
>>> Jim
>>> 
>>> 
>>> On Sat, Apr 25, 2015 at
> 8:37
>> AM, Antonio Serrano via
>>> R-help
>>> <r-help at r-project.org>
> wrote:
>>>> 
>>>> 
>> Hello, all:
>>>> 
>>>>   I am new here,
>>> and have a
> challenge to present some
>> graphical data to the user in a
>>> convenient
>>> 
> way.
>>>> 
>>>>   The challenge
>> is to present a map to the user which is
> coloured
>>> with the value of a
>> variable. Say for example, temperature. This
> is a
>>> preexisting graph that I
>> can generate in any format, including svg.
> I don't
>>> have
>>> to produce it
>> using R.
>>>> 
>>>>   When the user clicks
> anywhere in the map, the
>>> coordinates
>> (longitude and latitude) have to be
> passed to R so that this, R,
>>> can
>>> look
>> for the values of other
> variables in that location and make another
>>> graph
>>> 
>> with
> them.
>>>> 
>>>>   Does anyubody know how could I accomplish
>> 
> this?.
>>>> 
>>>> 
>>> Thanks in advance.
>>>> 
>>>> 
>>>> 
>>>> Antonio
> Serrano
>>>> 
>> aasdelat at aim.com
>>>> ?
>>>> 
>>>> 
>>>> 
>>> [[alternative HTML
> version
>> deleted]]
>>>> 
>>>> 
>>> 
> ______________________________________________
>>>> 
>> R-help at r-project.org
> mailing
>>> list -- To UNSUBSCRIBE and more, see
>>>> 
>>> 
>> 
> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting
>> 
> guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide
> commented,
>> minimal,
>>> self-contained, reproducible code.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From lalitha.viswanathan79 at gmail.com  Mon Apr 27 19:50:28 2015
From: lalitha.viswanathan79 at gmail.com (Lalitha Viswanathan)
Date: Mon, 27 Apr 2015 23:20:28 +0530
Subject: [R] Fwd: Distribution to use to calculate p values
In-Reply-To: <CAMeJHHBtAsBv8M+hzMbum7pF+nA5jvf1BSnfeB7buHVir+MEuw@mail.gmail.com>
References: <CAMeJHHBtAsBv8M+hzMbum7pF+nA5jvf1BSnfeB7buHVir+MEuw@mail.gmail.com>
Message-ID: <CAMeJHHBgA=eXioH6K6KaNL8zwNt2sFRdS9RAzhtDdPj=twdJ4Q@mail.gmail.com>

Hi
I have a dataset as below
Price Country Reliability Mileage Type Weight Disp. HP


8895 USA 4 33 Small 2560 97 113
(Hundreds of rows)

I am trying to find the best possible distribution to use, to find p-values
and compute which factors most influence efficiency.

Any starting points for the functions I could use, or similar examples I
could follow, would be a start.
I am a relative novice at R having used it many years ago and am now
getting back to it.
So looking for pointers

Thanks


>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Apr 27 21:07:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 27 Apr 2015 12:07:31 -0700
Subject: [R] Distribution to use to calculate p values
In-Reply-To: <CAMeJHHBgA=eXioH6K6KaNL8zwNt2sFRdS9RAzhtDdPj=twdJ4Q@mail.gmail.com>
References: <CAMeJHHBtAsBv8M+hzMbum7pF+nA5jvf1BSnfeB7buHVir+MEuw@mail.gmail.com>
	<CAMeJHHBgA=eXioH6K6KaNL8zwNt2sFRdS9RAzhtDdPj=twdJ4Q@mail.gmail.com>
Message-ID: <8E14F040-4167-4006-ABF9-E24CA4A19507@comcast.net>


On Apr 27, 2015, at 10:50 AM, Lalitha Viswanathan wrote:

> Hi
> I have a dataset as below
> Price Country Reliability Mileage Type Weight Disp. HP
> 
> 
> 8895 USA 4 33 Small 2560 97 113
> (Hundreds of rows)
> 
> I am trying to find the best possible distribution to use, to find p-values
> and compute which factors most influence efficiency.

"Finding p-values" is a task that requires research questions. You obviously have some sort of meaning attached to the word "efficiency" but have not stated what it is. This appears to be a request for a statistical tutorial an a topic that has not been described. (And if this is course homework, then it is off-topic for r-help.)

> 
> Any starting points for the functions I could use, or similar examples I
> could follow, would be a start.
> I am a relative novice at R having used it many years ago and am now
> getting back to it.
> So looking for pointers
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]

The Posting Guide suggests that you create a small example in R code and describe your question more clearly (if it's not homework.)

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From robertsonburns at btinternet.com  Mon Apr 27 21:34:05 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Mon, 27 Apr 2015 20:34:05 +0100
Subject: [R] Question about base::rank results
In-Reply-To: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
Message-ID: <553E8F2D.8010909@btinternet.com>

There is a blog post on this topic:

http://www.portfolioprobe.com/2012/07/26/r-inferno-ism-order-is-not-rank/

Pat

On 26/04/2015 09:17, Giorgio Garziano wrote:
> Hi,
>
> I cannot understand why rank(x) behaves as outlined below.
> Based on the results of first x vector values ranking, which is as expected in my opinion,
> I cannot explain the following results.
>
>> x <- c(12,34,15,77,78)
>> x[rank(x)]
> [1] 12 15 34 77 78      (OK)
>
>> x <- c(12,34,15,77,78,22)
>> x[rank(x)]
> [1] 12 77 34 78 22 15   (?)
>
>> x <- c(12,34,77,15,78)
>> x[rank(x)]
> [1] 12 77 15 34 78      (?)
>
> Please any feedback ? Thanks.
>
> BR,
>
> Giorgio Garziano
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From joshuamichaeldixon at gmail.com  Mon Apr 27 22:30:39 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Mon, 27 Apr 2015 21:30:39 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <553E5157.10206@dewey.myzen.co.uk>
References: <caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<EB356122A2C.0000029Djrkrideau@inbox.com>
	<553E5157.10206@dewey.myzen.co.uk>
Message-ID: <CAOkeKBJMP8hRs8TpfXvZxTsEVRwav_JMJn7HnGb3n18=4JjQgA@mail.gmail.com>

Apologies for my ignorance!

*Thierry* - thank you for the reading.  I'll look into those ASAP!

*John* - The data set I have is quite large, when using the dput() command
I'm unsure if it actually fits the whole output into the console.  I can't
scroll up far enough to see the actual command.  I can paste what is there
if that may help?  The bottom line:

Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI",
"YoYo"), class = "data.frame", row.names = c(NA, -9689L))

*Michael *- Essentially, I'm looking for differences between "YoYo" outcome
for "Positions", "Levels" and accounting for repeated measures using "Id"
as a random factor.  So I was able to figure out points 2 and 3.

I've searched for definitions of "Scaled residuals", "Random effects", "Fixed
effects", "Correlation of Fixed Effects".  However, I'm confused at the
different interpretations I've found.  Or quite possibly, I'm just
confused...  What should I be looking out for in these variables?

I've tried to take my analysis smaller, and just look at specifics, to make
it simpler.  Such as, comparing YoYo (outcome score) for a Premier_League
(Level), 22 (AgeGr) F (Position) with a Premier_League (Level), 22 (AgeGr)
M (Position).  How do I convert these into a factors for analysis?

Simple question maybe, but it's not when you can't find the answer!

Thank you,

Josh

On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Joshua
>
> It would also help if you told us what your scientific question was. At
> the moment we know what R commands you used and have seen the head of your
> dataset but not why you are doing it.
>
> I would summarise what you have given us as
>
> 1 - most ID only occur once
> 2 - goal keepers do worse than outfield players
> 3 - older people (presumably in fact age is in years as a continuous
> variable) do better
>
>
> On 27/04/2015 12:42, John Kane wrote:
>
>>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>  -----Original Message-----
>>> From: joshuamichaeldixon at gmail.com
>>> Sent: Mon, 27 Apr 2015 08:54:51 +0100
>>> To: thierry.onkelinx at inbo.be
>>> Subject: Re: [R] Help Interpreting Linear Mixed Model
>>>
>>> Hello Thierry,
>>>
>>> No, this isn't homework. Not that young unfortunately.
>>>
>>>
>> A few years ago a friend of mine and her daughter were neck-in-neck on
>> who got their Ph.D first. What's this "not that young" business?
>>
>> BTW, a better way to supply sample data is to use the dput() command.
>>
>> Do a dput(mydata), copy the results into the email and you have supplied
>> us with an exact copy of your data.
>>
>> It is possible for many reasons that I will not read in your data, as you
>> supplied it, in the format you have it in.  This can lead to real confusion.
>>
>>
>>
>>
>>
>>  Josh
>>>
>>>  On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>> wrote:
>>>>
>>>> Dear Josh,
>>>>
>>>> Is this homework? Because the list has a no homework policy.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to
>>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>>>>
>>>>> Hello!
>>>>>
>>>>> Very new to R (10 days), and I've run the linear mixed model, below.
>>>>> Attempting to interpret what it means...  What do I need to look for?
>>>>> Residuals, correlations of fixed effects?!
>>>>>
>>>>> How would I look at very specific interactions, such as PREMIER_LEAGUE
>>>>> (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>>>>> GK?
>>>>>
>>>>> For reference my data set looks like this:
>>>>>
>>>>> Id Level AgeGr   Position Height Weight BMI YoYo
>>>>> 7451 CHAMPIONSHIP 14 M NA 63 NA 80
>>>>> 148 PREMIER_LEAGUE 16 D NA 64 NA 80
>>>>> 10393 CONFERENCE 10 D NA 36 NA 160
>>>>> 10200 CHAMPIONSHIP 10 F NA 46 NA 160
>>>>> 1961 LEAGUE_TWO 13 GK NA 67 NA 160
>>>>> 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>>>>> 10541 LEAGUE_ONE 10 F NA 25 NA 160
>>>>> 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>>>>> 9895 CHAMPIONSHIP 10 D NA 36 NA 160
>>>>>
>>>>>
>>>>> Many thanks in advance for time and help.  Really appreciate it.
>>>>>
>>>>> Josh
>>>>>
>>>>>
>>>>>  summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>>>>>>
>>>>> Linear mixed model fit by REML ['lmerMod']
>>>>> Formula: YoYo ~ AgeGr + Position + (1 | Id)
>>>>>
>>>>> REML criterion at convergence: 125712.2
>>>>>
>>>>> Scaled residuals:
>>>>>      Min      1Q  Median      3Q     Max
>>>>> -3.4407 -0.5288 -0.0874  0.4531  4.8242
>>>>>
>>>>> Random effects:
>>>>>   Groups   Name        Variance Std.Dev.
>>>>>   Id       (Intercept) 15300    123.7
>>>>>   Residual             16530    128.6
>>>>> Number of obs: 9609, groups:  Id, 6071
>>>>>
>>>>> Fixed effects:
>>>>>               Estimate Std. Error t value
>>>>> (Intercept) -521.6985    16.8392  -30.98
>>>>> AgeGr         62.6786     0.9783   64.07
>>>>> PositionD    139.4682     7.8568   17.75
>>>>> PositionM    141.2227     7.7072   18.32
>>>>> PositionF    135.1241     8.1911   16.50
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>            (Intr) AgeGr  PostnD PostnM
>>>>> AgeGr     -0.910
>>>>> PositionD -0.359 -0.009
>>>>> PositionM -0.375  0.001  0.810
>>>>> PositionF -0.349 -0.003  0.756  0.782
>>>>>
>>>>>> model=lmer(YoYo~AgeGr+Position+(1|Id))
>>>>>> summary(glht(model,linfct=mcp(Position="Tukey")))
>>>>>>
>>>>>
>>>>>   Simultaneous Tests for General Linear Hypotheses
>>>>>
>>>>> Multiple Comparisons of Means: Tukey Contrasts
>>>>>
>>>>>
>>>>> Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>>>>>
>>>>> Linear Hypotheses:
>>>>>              Estimate Std. Error z value Pr(>|z|)
>>>>> D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>>>>> M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>>>>> F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>>>>> M - D == 0     1.754      4.799   0.366    0.983
>>>>> F - D == 0    -4.344      5.616  -0.774    0.862
>>>>> F - M == 0    -6.099      5.267  -1.158    0.645
>>>>> ---
>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> (Adjusted p values reported -- single-step method)
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
>> family!
>> Visit http://www.inbox.com/photosharing to find out more!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From walke554 at umn.edu  Mon Apr 27 22:34:54 2015
From: walke554 at umn.edu (walke554)
Date: Mon, 27 Apr 2015 13:34:54 -0700 (PDT)
Subject: [R] DeSolver giving "NA" as output, but running fully.
Message-ID: <1430166894068-4706497.post@n4.nabble.com>

Hello All,

I am currently looking on a transmission model for STD transmission within a
population.  I am able to run my full code and the ODE function, but when I
look at my output, all I get is "NA" for each time step beyond the first. 
There doesn't seem to be any syntax error, and I do get my entire program to
run.  Here is my code:

setwd("C:/Users/L/Documents/MastersThesis")

require(deSolve);

########
#Model 1
########

#The function
HPVInfection<-function(t,y,p){
	XFL = y[1]; #number of susceptible unvaccinated females low risk
	XFM = y[2]; #number of susceptible unvaccinated females medium risk
	XFH = y[3]; #number of susceptible unvaccinated females high risk
	XML = y[4]; #number of susceptible unvaccinated males low risk
	XMM = y[5]; #number of susceptible unvaccinated males medium risk
	XMH = y[6]; #number of susceptible unvaccinated males high risk
	Y1FL = y[7]; #number of infected unvaccinated females low risk infected
with vaccine strain
	Y1FM = y[8]; #number of infected unvaccinated females medium risk low risk
infected with vaccine strain
	Y1FH = y[9]; #number of infected unvaccinated females high risk low risk
infected with vaccine strain
	Y1ML = y[10]; #number of infected unvaccinated males low risk low risk
infected with vaccine strain
	Y1MM = y[11]; #number of infected unvaccinated males medium risk low risk
infected with vaccine strain
	Y1MH = y[12]; #number of infected unvaccinated males high risk low risk
infected with vaccine strain
	Y2FL = y[13]; #number of infected unvaccinated females low risk infected
with non-vaccine strain
	Y2FM = y[14]; #number of infected unvaccinated females medium risk low risk
infected with non-vaccine strain
	Y2FH = y[15]; #number of infected unvaccinated females high risk low risk
infected with non-vaccine strain
	Y2ML = y[16]; #number of infected unvaccinated males low risk low risk
infected with non-vaccine strain
	Y2MM = y[17]; #number of infected unvaccinated males medium risk low risk
infected with non-vaccine strain
	Y2MH = y[18]; #number of infected unvaccinated males high risk low risk
infected with non-vaccine strain
	ZFL = y[19]; #number of immune females low risk
	ZFM = y[20]; #number of immune females medium risk
	ZFH = y[21]; #number of immune females high risk
	ZML = y[22]; #number of immune males low risk
	ZMM = y[23]; #number of immune males medium risk
	ZMH = y[24]; #number of immune males high risk
	VFL = y[25]; #number of susceptible vaccinated females low risk
	VFM = y[26]; #number of susceptible vaccinated females medium risk
	VFH = y[27]; #number of susceptible vaccinated females high risk
	VML = y[28]; #number of susceptible vaccinated males low risk
	VMM = y[29]; #number of susceptible vaccinated males medium risk
	VMH = y[30]; #number of susceptible vaccinated males high risk
	W1FL = y[31]; #number of infected vaccinated females low risk infected with
vaccine strain
	W1FM = y[32]; #number of infected vaccinated females medium risk infected
with vaccine strain
	W1FH = y[33]; #number of infected vaccinated females high risk infected
with vaccine strain
	W1ML = y[34]; #number of infected vaccinated males low risk infected with
vaccine strain
	W1MM = y[35]; #number of infected vaccinated males medium risk infected
with vaccine strain
	W1MH = y[36]; #number of infected vaccinated males high risk infected with
vaccine strain
	W2FL = y[37]; #number of infected vaccinated females low risk infected with
non-vaccine strain
	W2FM = y[39]; #number of infected vaccinated females medium risk infected
with non-vaccine strain
	W2FH = y[40]; #number of infected vaccinated females high risk infected
with non-vaccine strain
	W2ML = y[41]; #number of infected vaccinated males low risk infected with
non-vaccine strain
	W2MM = y[42]; #number of infected vaccinated males medium risk infected
with non-vaccine strain
	W2MH = y[43]; #number of infected vaccinated males high risk infected with
non-vaccine strain
	with(as.list(p), {
		dXFL.dt = (0.5 * mew * omega[1,1] * (1-phi) * total) - ((partner[1,1] *
beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
population[1,2]) * rho[1,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) + (tau[1,2]
* W2MM))/population[2,2]) * rho[1,2]) + (((Y1MH + Y2MH + (tau[1,2] * W1MH) +
(tau[1,2] * W2MH)) / population[3,2]) * rho[1,3])) + mew) * XFL) + (sigma *
VFL);
		dXFM.dt = (0.5 * mew * omega[2,1] * (1-phi) * total) - ((partner[2,1] *
beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
population[1,2]) * rho[2,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) + (tau[1,2]
* W2MM))/population[2,2]) * rho[2,2]) + (((Y1MH + Y2MH + (tau[1,1] * W1MH) +
(tau[1,2] * W2MH)) / population[3,2]) * rho[2,3])) + mew) * XFM) + (sigma *
VFM);
		dXFH.dt = (0.5 * mew * omega[3,1] * (1-phi) * total) - ((partner[3,1] *
beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
population[1,2]) * rho[3,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) + (tau[1,2]
* W2MM))/population[2,2]) * rho[3,2]) + (((Y1MH + Y2MH + (tau[1,1] * W1MH) +
(tau[1,2] * W2MH)) / population[3,2]) * rho[3,3])) + mew) * XFH) + (sigma *
VFH);
		dXML.dt = (0.5 * mew * omega[1,1] * (1-phi) * total) - ((partner[1,1] *
beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
population[1,1]) * rho[1,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) + (tau[2,2]
* W2FM))/population[2,1]) * rho[1,2]) + (((Y1FH + Y2FH + (tau[2,1] * W1FH) +
(tau[2,2] * W2FH)) / population[3,1]) * rho[1,3])) + mew) * XML) + (sigma *
VML);
		dXMM.dt = (0.5 * mew * omega[2,1] * (1-phi) * total) - ((partner[2,1] *
beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
population[1,1]) * rho[2,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) + (tau[2,2]
* W2FM))/population[2,1]) * rho[2,2]) + (((Y1FH + Y2FH + (tau[2,1] * W1FH) +
(tau[2,2] * W2FH)) / population[3,1]) * rho[2,3])) + mew) * XMM) + (sigma *
VMM);
		dXMH.dt = (0.5 * mew * omega[3,1] * (1-phi) * total) - ((partner[3,1] *
beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
population[1,1]) * rho[3,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) + (tau[2,2]
* W2FM))/population[2,1]) * rho[3,2]) + (((Y1FH + Y2FH + (tau[2,1] * W1FH) +
(tau[2,2] * W2FH)) / population[3,1]) * rho[3,3])) + mew) * XMH) + (sigma *
VMH);
		dY1FL.dt = (XFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y1ML +
(tau[1,1] * W1ML)) / population[1,2])) + (rho[1,2] * ((Y1MM + (tau[1,1] *
W1MM)) / population[2,2])) + (rho[1,3] * ((Y1MH + (tau[1,1] * W1MH)) /
population[3,2]))))) - ((mew + gamma[2,1]) * Y1FL);
		dY1FM.dt = (XFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y1ML +
(tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,1] *
W1MM)) / population[2,2])) + (rho[2,3] * ((Y1MH + (tau[1,1] * W1MH)) /
population[3,2]))))) - ((mew + gamma[2,1]) * Y1FM);
		dY1FH.dt = (XFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y1ML +
(tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,1] *
W1MM)) / population[2,2])) + (rho[3,3] * ((Y1MH + (tau[1,1] * W1MH)) /
population[3,2]))))) - ((mew + gamma[2,1]) * Y1FH);
		dY1ML.dt = (XML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y1FL +
(tau[2,1] * W1FL)) / population[1,1])) + (rho[1,2] * ((Y1FM + (tau[2,1] *
W1FM)) / population[2,1])) + (rho[1,3] * ((Y1FH + (tau[2,1] * W1FH)) /
population[3,1]))))) - ((mew + gamma[1,1]) * Y1MM);
		dY1MM.dt = (XMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y1FL +
(tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,1] *
W1FM)) / population[2,1])) + (rho[2,3] * ((Y1FH + (tau[2,1] * W1FH)) /
population[3,1]))))) - ((mew + gamma[1,1]) * Y1MM);
		dY1MH.dt = (XMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y1FL +
(tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,1] *
W1FM)) / population[2,1])) + (rho[3,3] * ((Y1FH + (tau[2,1] * W1MH)) /
population[3,1]))))) - ((mew + gamma[1,1]) * Y1MH);
		dY2FL.dt = (XFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y2ML +
(tau[1,2] * W2ML)) / population[1,2])) + (rho[1,2] * ((Y1MM + (tau[1,2] *
W2MM)) / population[2,2])) + (rho[1,3] * ((Y2MH + (tau[1,2] * W2MH)) /
population[3,2]))))) - ((mew + gamma[2,2]) * Y1FL);
		dY2FM.dt = (XFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y2ML +
(tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,2] *
W2MM)) / population[2,2])) + (rho[2,3] * ((Y2MH + (tau[1,2] * W2MH)) /
population[3,2]))))) - ((mew + gamma[2,2]) * Y1FM);
		dY2FH.dt = (XFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y2ML +
(tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,2] *
W2MM)) / population[2,2])) + (rho[3,3] * ((Y2MH + (tau[1,2] * W2MH)) /
population[3,2]))))) - ((mew + gamma[2,2]) * Y1FH);
		dY2ML.dt = (XML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y2FL +
(tau[2,2] * W2FL)) / population[1,1])) + (rho[1,2] * ((Y1FM + (tau[2,2] *
W2FM)) / population[2,1])) + (rho[1,3] * ((Y2FH + (tau[2,2] * W2FH)) /
population[3,1]))))) - ((mew + gamma[1,2]) * Y1MM);
		dY2MM.dt = (XMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y2FL +
(tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,2] *
W2FM)) / population[2,1])) + (rho[2,3] * ((Y2FH + (tau[2,2] * W2FH)) /
population[3,1]))))) - ((mew + gamma[1,2]) * Y1MM);
		dY2MH.dt = (XMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y2FL +
(tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,2] *
W2FM)) / population[2,1])) + (rho[3,3] * ((Y2FH + (tau[2,2] * W2MH)) /
population[3,1]))))) - ((mew + gamma[1,2]) * Y1MH);
		dZFL.dt = ((gamma[2,1] * Y1FL) + (gamma[2,2] * Y2FL) + (gamma[4,1] * W1FL)
+ (gamma[4,2]*W2FL)) - (mew * ZFL);
		dZFM.dt = ((gamma[2,1] * Y1FM) + (gamma[2,2] * Y2FM) + (gamma[4,1] * W1FM)
+ (gamma[4,2]*W2FM)) - (mew * ZFM);
		dZFH.dt = ((gamma[2,1] * Y1FH) + (gamma[2,2] * Y2FH) + (gamma[4,1] * W1FH)
+ (gamma[4,2]*W2FH)) - (mew * ZFH);
		dZML.dt = ((gamma[1,1] * Y1ML) + (gamma[1,2] * Y2ML) + (gamma[3,1] * W1FM)
+ (gamma[3,2]*W2ML)) - (mew * ZML);
		dZMM.dt = ((gamma[1,1] * Y1MM) + (gamma[1,2] * Y2MM) + (gamma[3,1] * W1MM)
+ (gamma[3,2]*W2MM)) - (mew * ZMM);
		dZMH.dt = ((gamma[1,1] * Y1MH) + (gamma[1,2] * Y2MH) + (gamma[3,1] * W1MH)
+ (gamma[3,2]*W2MH)) - (mew * ZMH);
		dVFL.dt = (0.5 * mew * omega[1,1] * phi * total) - ((partner[1,1] *
beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) + (delta[1,2] *
tau[1,2] * W2ML)) / population[1,2]) * rho[1,1]) + (((Y1MM + Y2MM +
(delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
W2MM))/population[2,2]) * rho[1,2]) + (((Y1MH + Y2MH + (delta[1,1] *
tau[1,2] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
rho[1,3])) + mew) * VFL) - (sigma * VFL);
		dVFM.dt = (0.5 * mew * omega[2,1] * phi * total) - ((partner[2,1] *
beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) + (delta[1,2] *
tau[1,2] * W2ML)) / population[1,2]) * rho[2,1]) + (((Y1MM + Y2MM +
(delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
W2MM))/population[2,2]) * rho[2,2]) + (((Y1MH + Y2MH + (delta[1,1] *
tau[1,1] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
rho[2,3])) + mew) * VFM) - (sigma * VFM);
		dVFH.dt = (0.5 * mew * omega[3,1] * phi * total) - ((partner[3,1] *
beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) + (delta[1,2] *
tau[1,2] * W2ML)) / population[1,2]) * rho[3,1]) + (((Y1MM + Y2MM +
(delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
W2MM))/population[2,2]) * rho[3,2]) + (((Y1MH + Y2MH + (delta[1,1] *
tau[1,1] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
rho[3,3])) + mew) * VFH) - (sigma * VFH);
		dVML.dt = (0.5 * mew * omega[1,1] * phi * total) - ((partner[1,1] *
beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) + (delta[2,2] *
tau[2,2] * W2FL)) / population[1,1]) * rho[1,1]) + (((Y1FM + Y2FM +
(delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
W2FM))/population[2,1]) * rho[1,2]) + (((Y1FH + Y2FH + (delta[2,1] *
tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
rho[1,3])) + mew) * VML) - (sigma * VML);
		dVMM.dt = (0.5 * mew * omega[2,1] * phi * total) - ((partner[2,1] *
beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) + (delta[2,2] *
tau[2,2] * W2FL)) / population[1,1]) * rho[2,1]) + (((Y1FM + Y2FM +
(delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
W2FM))/population[2,1]) * rho[2,2]) + (((Y1FH + Y2FH + (delta[2,1] *
tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
rho[2,3])) + mew) * VMM) - (sigma * VMM);
		dVMH.dt = (0.5 * mew * omega[3,1] * phi * total) - ((partner[3,1] *
beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) + (delta[2,2] *
tau[2,2] * W2FL)) / population[1,1]) * rho[3,1]) + (((Y1FM + Y2FM +
(delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
W2FM))/population[2,1]) * rho[3,2]) + (((Y1FH + Y2FH + (delta[2,1] *
tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
rho[3,3])) + mew) * VMH) - (sigma * VMH);
		dW1FL.dt = (VFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y1ML +
(delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[1,2] * ((Y1MM +
(delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[1,3] * ((Y1MH +
(delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew + gamma[4,1])
* W1FL);
		dW1FM.dt = (VFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y1ML +
(delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM +
(delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[2,3] * ((Y1MH +
(delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew + gamma[4,1])
* W1FM);
		dW1FH.dt = (VFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y1ML +
(delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM +
(delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[3,3] * ((Y1MH +
(delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew + gamma[4,1])
* W1FH);
		dW1ML.dt = (VML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y1FL +
(delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[1,2] * ((Y1FM +
(delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[1,3] * ((Y1FH +
(delta[2,1] * tau[2,1] * W1FH)) / population[3,1]))))) - ((mew + gamma[3,1])
* W1MM);
		dW1MM.dt = (VMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y1FL +
(delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM +
(delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[2,3] * ((Y1FH +
(delta[2,1] * tau[2,1] * W1FH)) / population[3,1]))))) - ((mew + gamma[3,1])
* W1MM);
		dW1MH.dt = (VMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y1FL +
(delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM +
(delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[3,3] * ((Y1FH +
(delta[2,1] * tau[2,1] * W1MH)) / population[3,1]))))) - ((mew + gamma[3,1])
* W1MH);
		dW2FL.dt = (VFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y2ML +
(delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[1,2] * ((Y1MM +
(delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[1,3] * ((Y2MH +
(delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew + gamma[4,2])
* W1FL);
		dW2FM.dt = (VFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y2ML +
(delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM +
(delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[2,3] * ((Y2MH +
(delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew + gamma[4,2])
* W1FM);
		dW2FH.dt = (VFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y2ML +
(delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM +
(delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[3,3] * ((Y2MH +
(delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew + gamma[4,2])
* W1FH);
		dW2ML.dt = (VML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y2FL +
(delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[1,2] * ((Y1FM +
(delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[1,3] * ((Y2FH +
(delta[2,2] * tau[2,2] * W2FH)) / population[3,1]))))) - ((mew + gamma[3,2])
* W1MM);
		dW2MM.dt = (VMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y2FL +
(delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM +
(delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[2,3] * ((Y2FH +
(delta[2,2] * tau[2,2] * W2FH)) / population[3,1]))))) - ((mew + gamma[3,2])
* W1MM);
		dW2MH.dt = (VMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y2FL +
(delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM +
(delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[3,3] * ((Y2FH +
(delta[2,2] * tau[2,2] * W2MH)) / population[3,1]))))) - ((mew + gamma[3,2])
* W1MH);
		return(list(c(dXFL.dt, dXFM.dt, dXFH.dt, dXML.dt, dXMM.dt, dXMH.dt,
dY1FL.dt, dY1FM.dt, dY1FH.dt, dY1ML.dt, dY1MM.dt, dY1MH.dt, dY2FL.dt,
dY2FM.dt, dY2FH.dt, dY2ML.dt, dY2MM.dt, dY2MH.dt, dZFL.dt, dZFM.dt, dZFH.dt,
dZML.dt, dZMM.dt, dZMH.dt, dVFL.dt, dVFM.dt, dVFH.dt, dVML.dt, dVMM.dt,
dVMH.dt, dW1FL.dt, dW1FM.dt, dW1FH.dt, dW1ML.dt, dW1MM.dt, dW1MH.dt,
dW2FL.dt, dW2FM.dt, dW2FH.dt, dW2ML.dt, dW2MM.dt, dW2MH.dt)));
	})
}

#giving the parameters

mew = 1/15 																													#proportion of individuals entering
or exiting the sexually active group at a time
total = 60020																												#total population of sexually
active
phi = 0.9 																													#Proportion of individuals who are
successfully vaccinated
sigma = 1/10																												#loss of vaccination status
gamma = matrix(data=c(0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66),
ncol=2, nrow=4)																#Duration of infectiousness
omega = matrix(data=c(0.82, 0.15, 0.03))																								#proportion
of those in each sexual activity level
population = matrix(data=c(omega[1,1]*0.5*total, omega[2,1]*0.5*total,
omega[3,1]*0.5*total, omega[1,1]*0.5*total, omega[2,1]*0.5*total,
omega[3,1]*0.5*total), ncol=2, nrow=3)	#population in each sexual activity
level and gender group
partner = matrix(data=c(1.4, 3, 9))																									#average number
of partners per year by risk group
beta = matrix(data=c(0.8, 0.7))																									#Chance of infection
from partner given 1 sexual encounter
rho = matrix(data=c(1, 1, 1, 1, 1, 1, 1, 1, 1), ncol=3, nrow=3)																			
#preference for selecting sexual partner by activity group
tau = matrix(data=c(1, 1, 1, 1), ncol=2, nrow=2)	
delta = matrix(data=c(1, 1, 1, 1), ncol=2, nrow=2)																				
#reduction of infection from a vaccinated infected individual

XFL0 = 1850						#Initial number of females in the low risk group
unvaccinated susceptibles
XFM0 = 340						#Initial number of susceptible unvaccinated females medium
risk
XFH0 = 70						#Initial number of susceptible unvaccinated females high risk
XML0 = 1850						#Initial number of susceptible unvaccinated males low risk
XMM0 = 340						#Initial number of susceptible unvaccinated males medium
risk
XMH0 = 70						#Initial number of susceptible unvaccinated males high risk
Y1FL0 = 590						#Initial number of infected unvaccinated females low risk
Y1FM0 = 100						#Initial number of infected unvaccinated females medium
risk
Y1FH0 = 20						#Initial number of infected unvaccinated females high risk
Y1ML0 = 590						#Initial number of infected unvaccinated males low risk
Y1MM0 = 100						#Initial number of infected unvaccinated males medium risk
Y1MH0 = 20						#Initial number of infected unvaccinated males high risk
Y2FL0 = 590						#Initial number of infected unvaccinated females low risk
Y2FM0 = 100						#Initial number of infected unvaccinated females medium
risk
Y2FH0 = 20						#Initial number of infected unvaccinated females high risk
Y2ML0 = 590						#Initial number of infected unvaccinated males low risk
Y2MM0 = 100						#Initial number of infected unvaccinated males medium risk
Y2MH0 = 20						#Initial number of infected unvaccinated males high risk
ZFL0 = 0						#Initial number of immune females low risk
ZFM0 = 0	 					#Initial number of immune females medium risk
ZFH0 = 0 						#Initial number of immune females high risk
ZML0 = 0 						#Initial number of immune males low risk
ZMM0 = 0 						#Initial number of immune males medium risk
ZMH0 = 0 						#Initial number of immune males high risk
VFL0 = 21070					#Initial number of susceptible vaccinated females low risk
VFM0 = 3850						#Initial number of susceptible vaccinated females medium
risk
VFH0 = 770						#Initial number of susceptible vaccinated females high risk
VML0 = 21070					#Initial number of susceptible vaccinated males low risk
VMM0 = 3850						#Initial number of susceptible vaccinated males medium risk
VMH0 = 770						#Initial number of susceptible vaccinated males high risk
W1FL0 = 1110					#Initial number of infected vaccinated females low risk
W1FM0 = 200						#Initial number of infected vaccinated females medium risk
W1FH0 = 40						#Initial number of infected vaccinated females high risk
W1ML0 = 1110					#Initial number of infected vaccinated males low risk
W1MM0 = 200						#Initial number of infected vaccinated males medium risk
W1MH0 = 40						#Initial number of infected vaccinated males high risk
W2FL0 = 1110					#Initial number of infected vaccinated females low risk
W2FM0 = 200						#Initial number of infected vaccinated females medium risk
W2FH0 = 40						#Initial number of infected vaccinated females high risk
W2ML0 = 1110					#Initial number of infected vaccinated males low risk
W2MM0 = 200						#Initial number of infected vaccinated males medium risk
W2MH0 = 40						#Initial number of infected vaccinated males high risk

p = list(mew=mew, total=total, phi=phi, sigma=sigma, gamma=gamma,
omega=omega, population=population, partner=partner, beta=beta, rho=rho,
tau=tau, delta=delta)

y0 = c(XFL0, XFM0, XFH0, XML0, XMM0, XMH0, Y1FL0, Y1FM0, Y1FH0, Y1ML0,
Y1MM0, Y1MH0, Y2FL0, Y2FM0, Y2FH0, Y2ML0, Y2MM0, Y2MH0, ZFL0, ZFM0, ZFH0,
ZML0, ZMM0, ZMH0, VFL0, VFM0, VFH0, VML0, VMM0, VMH0, W1FL0, W1FM0, W1FH0,
W1ML0, W1MM0, W1MH0, W2FL0, W2FM0, W2FH0, W2ML0, W2MM0, W2MH0)

#Running the ode integrator

steps= 10;
t = seq(from=0, to=100, by=1);

Is anyone able to help?





--
View this message in context: http://r.789695.n4.nabble.com/DeSolver-giving-NA-as-output-but-running-fully-tp4706497.html
Sent from the R help mailing list archive at Nabble.com.


From dcarlson at tamu.edu  Mon Apr 27 23:14:35 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 27 Apr 2015 21:14:35 +0000
Subject: [R] Question about base::rank results
In-Reply-To: <553E8F2D.8010909@btinternet.com>
References: <248E6FA047A8C746BA491485764190F521FB388D@ESESSMB207.ericsson.se>
	<553E8F2D.8010909@btinternet.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D687382@mb02.ads.tamu.edu>

Apologies if this belabors the point, but let's look at your second example to see why order and rank are different:

> x <- c(12,34,15,77,78,22)
> names(x) <- 1:6
> x
 1  2  3  4  5  6 
12 34 15 77 78 22

I've added names to the values so we can watch how they change. If we sort the numbers we get them in increasing order with their original indices:

> sort(x)
 1  3  6  2  4  5 
12 15 22 34 77 78

The values in are order and the names show where each value came from originally. That sequence of index values is exactly what order(x) gives you:

> order(x)
[1] 1 3 6 2 4 5
> x[order(x)]
 1  3  6  2  4  5 
12 15 22 34 77 78

The rank function gives you the relative size of the value, not its position in the original vector:

> rank(x)
1 2 3 4 5 6 
1 4 2 5 6 3
> x[rank(x)]
 1  4  2  5  6  3 
12 77 34 78 22 15

The second value has rank 4, but that is not its index which is 2. The value with index 4 is 77 so it shows up in the second position.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of J Robertson-Burns
Sent: Monday, April 27, 2015 2:34 PM
To: Giorgio Garziano; r-help at r-project.org
Subject: Re: [R] Question about base::rank results

There is a blog post on this topic:

http://www.portfolioprobe.com/2012/07/26/r-inferno-ism-order-is-not-rank/

Pat

On 26/04/2015 09:17, Giorgio Garziano wrote:
> Hi,
>
> I cannot understand why rank(x) behaves as outlined below.
> Based on the results of first x vector values ranking, which is as expected in my opinion,
> I cannot explain the following results.
>
>> x <- c(12,34,15,77,78)
>> x[rank(x)]
> [1] 12 15 34 77 78      (OK)
>
>> x <- c(12,34,15,77,78,22)
>> x[rank(x)]
> [1] 12 77 34 78 22 15   (?)
>
>> x <- c(12,34,77,15,78)
>> x[rank(x)]
> [1] 12 77 15 34 78      (?)
>
> Please any feedback ? Thanks.
>
> BR,
>
> Giorgio Garziano
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Mon Apr 27 23:20:10 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 27 Apr 2015 22:20:10 +0100
Subject: [R] select portion of text file using R
In-Reply-To: <5534E05C.2010407@gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>
	<5534E05C.2010407@gmail.com>
Message-ID: <CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>

Dear Duncan,
thank you for your reply,
I tried to read the file using skip and nrows but it did not work.
Here i am pasting the code I wrote and the head of the file i need to
read. Probably the error is due to the fact that the column "well" has
duplication, but how can i add a row column with unique row names? How
can I overcome this error?
Best regards
Luigi

CODE
raw.data<-read.table(
      mydata,
      header=TRUE,
      row.names=31,
      dec=".",
      sep="\t",
      skip = 30,
      nrows = 17281,
      row.names = 1:17281
    )


HEAD OF MYDATA
* Block Type = Array Card Block
* Calibration Background is expired = No
* Calibration Background performed on = 2014-12-02 11:27:49 AM PST
* Calibration FAM is expired = No
* Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
* Calibration ROI is expired = No
* Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
* Calibration ROX is expired = No
* Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
* Calibration Uniformity is expired = No
* Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
* Calibration VIC is expired = No
* Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
* Chemistry = TAQMAN
* Experiment Barcode =
* Experiment Comments =
* Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
* Experiment Name = 2015-04-13 171216
* Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
* Experiment Type = Comparative C? (??C?)
* Experiment User Name =
* Instrument Name = 278882033
* Instrument Serial Number = 278882033
* Instrument Type = ViiA 7
* Passive Reference = ROX
* Quantification Cycle Method = Ct
* Signal Smoothing On = false
* Stage/ Cycle where Analysis is performed = Stage 3, Step 2

[Amplification Data]

Well \tCycle \tTarget \tName \tRn
\t1 \t1 \tAdeno 1 \t0.82
\t1 \t2 \tAdeno 1\ \t0.93
...
\t2 \t1 \tAdeno 2 \t0.78
...

On Mon, Apr 20, 2015 at 12:17 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
>> Dear all,
>> I have a flat file (tab delimited) derived from an excel file which is
>> subdivided in different parts: a first part is reporting metadata,
>> then there is a first spreadsheet indicated by [ ], then the actual
>> data and the second spreadsheet with the same format [ ] and then the
>> data.
>> How can I import such file using for instance read.table()?
>
> read.table() by itself can't recognize where the data starts, but it has
> arguments "skip" and "nrows" to control how much gets read.  If you
> don't know the values for those arguments, you can use readLines() to
> read the entire file, then use grep() to recognize your table data, and
> either re-read the file, or just extract those lines and read from them
> as a textConnection.
>
> Duncan Murdoch
>
>> Many thanks
>> regards
>> Luigi
>>
>> Here is a sample of the file:
>> * Experiment Barcode =
>> * Experiment Comments =
>> * Experiment File Name = F:\array 59
>> * Experiment Name = 2015-04-13 171216
>> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
>> ...
>> [Amplification Data]
>> Well    Cycle    Target Name    Rn    Delta Rn
>> 1    1    Adeno 1-Adeno 1    0.820    -0.051
>> 1    2    Adeno 1-Adeno 1    0.827    -0.042
>> 1    3    Adeno 1-Adeno 1    0.843    -0.025
>> 1    4    Adeno 1-Adeno 1    0.852    -0.015
>> 1    5    Adeno 1-Adeno 1    0.858    -0.008
>> 1    6    Adeno 1-Adeno 1    0.862    -0.002
>> ...
>> [Results]
>> Well    Well Position    Omit    Sample Name    Target Name    Task
>> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
>> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
>> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
>> Baseline Start    Baseline End    Efficiency    Comments    Custom1
>> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
>> EXPFAIL
>> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
>> NFQ-MGB                Undetermined                            false
>>  0.200    true    3    44    1.000    N/A                            N
>>    Y
>> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
>> NFQ-MGB                Undetermined
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From jrkrideau at inbox.com  Mon Apr 27 23:43:06 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 27 Apr 2015 13:43:06 -0800
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAOkeKBJMP8hRs8TpfXvZxTsEVRwav_JMJn7HnGb3n18=4JjQgA@mail.gmail.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
Message-ID: <F0739AC4AF7.00000E24jrkrideau@inbox.com>


Hi Josh,

Just a sample  is usually  fine. As long as it cover a representative (must be time for dinner---I was going to type reprehensibe) sample of the data then something like dput(head(mydata, 100) ) works well.  

Kingston ON Canada

-----Original Message-----
From: joshuamichaeldixon at gmail.com
Sent: Mon, 27 Apr 2015 21:30:39 +0100
To: lists at dewey.myzen.co.uk
Subject: Re: [R] Help Interpreting Linear Mixed Model

Apologies for my ignorance!

Thierry - thank you for the reading.? I'll look into those ASAP!

John - The data set I have is quite large, when using the dput() command I'm unsure if it actually fits the whole output into the console.? I can't scroll up far enough to see the actual command.? I can paste what is there if that may help?? The bottom line:?

Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI", "YoYo"), class = "data.frame", row.names = c(NA, -9689L))

Michael - Essentially, I'm looking for differences between "YoYo" outcome for "Positions", "Levels" and accounting for repeated measures using "Id" as a random factor.? So I was able to figure out points 2 and 3.

I've searched for definitions of "Scaled residuals",?"Random effects",?"Fixed effects",?"Correlation of Fixed Effects".? However, I'm confused at the different interpretations I've found.? Or quite possibly, I'm just confused...? What should I be?looking?out for in these variables?

I've tried to take my analysis smaller, and just look at specifics, to make it simpler.? Such as, comparing YoYo (outcome score) for a Premier_League (Level), 22 (AgeGr) F (Position) with a?Premier_League (Level), 22 (AgeGr) M (Position).? How do I convert these into a factors for analysis?

Simple question maybe, but it's not when you can't find the answer!

Thank you,

Josh

On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

	Dear Joshua

 It would also help if you told us what your scientific question was. At the moment we know what R commands you used and have seen the head of your dataset but not why you are doing it.

 I would summarise what you have given us as

 1 - most ID only occur once
 2 - goal keepers do worse than outfield players
 3 - older people (presumably in fact age is in years as a continuous variable) do better

 On 27/04/2015 12:42, John Kane wrote:

 John Kane
 Kingston ON Canada

	 -----Original Message-----
 From: joshuamichaeldixon at gmail.com
 Sent: Mon, 27 Apr 2015 08:54:51 +0100
 To: thierry.onkelinx at inbo.be
 Subject: Re: [R] Help Interpreting Linear Mixed Model

 Hello Thierry,

 No, this isn't homework. Not that young unfortunately.

 A few years ago a friend of mine and her daughter were neck-in-neck on who got their Ph.D first. What's this "not that young" business?

 BTW, a better way to supply sample data is to use the dput() command.

 Do a dput(mydata), copy the results into the email and you have supplied us with an exact copy of your data.

 It is possible for many reasons that I will not read in your data, as you supplied it, in the format you have it in.? This can lead to real confusion.

	 Josh

	 On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
 wrote:

 Dear Josh,

 Is this homework? Because the list has a no homework policy.

 Best regards,

 ir. Thierry Onkelinx
 Instituut voor natuur- en bosonderzoek / Research Institute for Nature
 and Forest
 team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
 Kliniekstraat 25
 1070 Anderlecht
 Belgium

 To call in the statistician after the experiment is done may be no more
 than asking him to perform a post-mortem examination: he may be able to
 say what the experiment died of. ~ Sir Ronald Aylmer Fisher
 The plural of anecdote is not data. ~ Roger Brinner
 The combination of some data and an aching desire for an answer does not
 ensure that a reasonable answer can be extracted from a given body of
 data. ~ John Tukey

 2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:

	 Hello!

 Very new to R (10 days), and I've run the linear mixed model, below.
 Attempting to interpret what it means...? What do I need to look for?
 Residuals, correlations of fixed effects?!

 How would I look at very specific interactions, such as PREMIER_LEAGUE
 (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
 GK?

 For reference my data set looks like this:

 Id Level AgeGr? ?Position Height Weight BMI YoYo
 7451 CHAMPIONSHIP 14 M NA 63 NA 80
 148 PREMIER_LEAGUE 16 D NA 64 NA 80
 10393 CONFERENCE 10 D NA 36 NA 160
 10200 CHAMPIONSHIP 10 F NA 46 NA 160
 1961 LEAGUE_TWO 13 GK NA 67 NA 160
 10428 CHAMPIONSHIP 10 GK NA 40 NA 160
 10541 LEAGUE_ONE 10 F NA 25 NA 160
 10012 CHAMPIONSHIP 10 GK NA 30 NA 160
 9895 CHAMPIONSHIP 10 D NA 36 NA 160

 Many thanks in advance for time and help.? Really appreciate it.

 Josh

	 summary(lmer(YoYo~AgeGr+Position+(1|Id)))

 Linear mixed model fit by REML ['lmerMod']
 Formula: YoYo ~ AgeGr + Position + (1 | Id)

 REML criterion at convergence: 125712.2

 Scaled residuals:
 ? ? ?Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
 -3.4407 -0.5288 -0.0874? 0.4531? 4.8242

 Random effects:
 ? Groups? ?Name? ? ? ? Variance Std.Dev.
 ? Id? ? ? ?(Intercept) 15300? ? 123.7
 ? Residual? ? ? ? ? ? ?16530? ? 128.6
 Number of obs: 9609, groups:? Id, 6071

 Fixed effects:
 ? ? ? ? ? ? ? Estimate Std. Error t value
 (Intercept) -521.6985? ? 16.8392? -30.98
 AgeGr? ? ? ? ?62.6786? ? ?0.9783? ?64.07
 PositionD? ? 139.4682? ? ?7.8568? ?17.75
 PositionM? ? 141.2227? ? ?7.7072? ?18.32
 PositionF? ? 135.1241? ? ?8.1911? ?16.50

 Correlation of Fixed Effects:
 ? ? ? ? ? ?(Intr) AgeGr? PostnD PostnM
 AgeGr? ? ?-0.910
 PositionD -0.359 -0.009
 PositionM -0.375? 0.001? 0.810
 PositionF -0.349 -0.003? 0.756? 0.782

	 model=lmer(YoYo~AgeGr+Position+(1|Id))
 summary(glht(model,linfct=mcp(Position="Tukey")))

 ? Simultaneous Tests for General Linear Hypotheses

 Multiple Comparisons of Means: Tukey Contrasts

 Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))

 Linear Hypotheses:
 ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
 D - GK == 0? 139.468? ? ? 7.857? 17.751? ?<1e-04 ***
 M - GK == 0? 141.223? ? ? 7.707? 18.323? ?<1e-04 ***
 F - GK == 0? 135.124? ? ? 8.191? 16.496? ?<1e-04 ***
 M - D == 0? ? ?1.754? ? ? 4.799? ?0.366? ? 0.983
 F - D == 0? ? -4.344? ? ? 5.616? -0.774? ? 0.862
 F - M == 0? ? -6.099? ? ? 5.267? -1.158? ? 0.645
 ---
 Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 (Adjusted p values reported -- single-step method)

 ? ? ? ? ?[[alternative HTML version deleted]]

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide
 http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

 ? ? ? ? [[alternative HTML version deleted]]

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide
 http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________
 FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] to find out more!

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

 -- 
 Michael
 http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html]

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Mon Apr 27 23:46:46 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 27 Apr 2015 13:46:46 -0800
Subject: [R] DeSolver giving "NA" as output, but running fully.
In-Reply-To: <1430166894068-4706497.post@n4.nabble.com>
Message-ID: <F07BCBA2037.00000E31jrkrideau@inbox.com>

Data?

Use deput()  (see ?dput) to provide some sample data.  Also you might find this useful http://adv-r.had.co.nz/Reproducibility.html 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: walke554 at umn.edu
> Sent: Mon, 27 Apr 2015 13:34:54 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] DeSolver giving "NA" as output, but running fully.
> 
> Hello All,
> 
> I am currently looking on a transmission model for STD transmission
> within a
> population.  I am able to run my full code and the ODE function, but when
> I
> look at my output, all I get is "NA" for each time step beyond the first.
> There doesn't seem to be any syntax error, and I do get my entire program
> to
> run.  Here is my code:
> 
> setwd("C:/Users/L/Documents/MastersThesis")
> 
> require(deSolve);
> 
> ########
> #Model 1
> ########
> 
> #The function
> HPVInfection<-function(t,y,p){
> 	XFL = y[1]; #number of susceptible unvaccinated females low risk
> 	XFM = y[2]; #number of susceptible unvaccinated females medium risk
> 	XFH = y[3]; #number of susceptible unvaccinated females high risk
> 	XML = y[4]; #number of susceptible unvaccinated males low risk
> 	XMM = y[5]; #number of susceptible unvaccinated males medium risk
> 	XMH = y[6]; #number of susceptible unvaccinated males high risk
> 	Y1FL = y[7]; #number of infected unvaccinated females low risk infected
> with vaccine strain
> 	Y1FM = y[8]; #number of infected unvaccinated females medium risk low
> risk
> infected with vaccine strain
> 	Y1FH = y[9]; #number of infected unvaccinated females high risk low risk
> infected with vaccine strain
> 	Y1ML = y[10]; #number of infected unvaccinated males low risk low risk
> infected with vaccine strain
> 	Y1MM = y[11]; #number of infected unvaccinated males medium risk low
> risk
> infected with vaccine strain
> 	Y1MH = y[12]; #number of infected unvaccinated males high risk low risk
> infected with vaccine strain
> 	Y2FL = y[13]; #number of infected unvaccinated females low risk infected
> with non-vaccine strain
> 	Y2FM = y[14]; #number of infected unvaccinated females medium risk low
> risk
> infected with non-vaccine strain
> 	Y2FH = y[15]; #number of infected unvaccinated females high risk low
> risk
> infected with non-vaccine strain
> 	Y2ML = y[16]; #number of infected unvaccinated males low risk low risk
> infected with non-vaccine strain
> 	Y2MM = y[17]; #number of infected unvaccinated males medium risk low
> risk
> infected with non-vaccine strain
> 	Y2MH = y[18]; #number of infected unvaccinated males high risk low risk
> infected with non-vaccine strain
> 	ZFL = y[19]; #number of immune females low risk
> 	ZFM = y[20]; #number of immune females medium risk
> 	ZFH = y[21]; #number of immune females high risk
> 	ZML = y[22]; #number of immune males low risk
> 	ZMM = y[23]; #number of immune males medium risk
> 	ZMH = y[24]; #number of immune males high risk
> 	VFL = y[25]; #number of susceptible vaccinated females low risk
> 	VFM = y[26]; #number of susceptible vaccinated females medium risk
> 	VFH = y[27]; #number of susceptible vaccinated females high risk
> 	VML = y[28]; #number of susceptible vaccinated males low risk
> 	VMM = y[29]; #number of susceptible vaccinated males medium risk
> 	VMH = y[30]; #number of susceptible vaccinated males high risk
> 	W1FL = y[31]; #number of infected vaccinated females low risk infected
> with
> vaccine strain
> 	W1FM = y[32]; #number of infected vaccinated females medium risk
> infected
> with vaccine strain
> 	W1FH = y[33]; #number of infected vaccinated females high risk infected
> with vaccine strain
> 	W1ML = y[34]; #number of infected vaccinated males low risk infected
> with
> vaccine strain
> 	W1MM = y[35]; #number of infected vaccinated males medium risk infected
> with vaccine strain
> 	W1MH = y[36]; #number of infected vaccinated males high risk infected
> with
> vaccine strain
> 	W2FL = y[37]; #number of infected vaccinated females low risk infected
> with
> non-vaccine strain
> 	W2FM = y[39]; #number of infected vaccinated females medium risk
> infected
> with non-vaccine strain
> 	W2FH = y[40]; #number of infected vaccinated females high risk infected
> with non-vaccine strain
> 	W2ML = y[41]; #number of infected vaccinated males low risk infected
> with
> non-vaccine strain
> 	W2MM = y[42]; #number of infected vaccinated males medium risk infected
> with non-vaccine strain
> 	W2MH = y[43]; #number of infected vaccinated males high risk infected
> with
> non-vaccine strain
> 	with(as.list(p), {
> 		dXFL.dt = (0.5 * mew * omega[1,1] * (1-phi) * total) - ((partner[1,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
> population[1,2]) * rho[1,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) +
> (tau[1,2]
> * W2MM))/population[2,2]) * rho[1,2]) + (((Y1MH + Y2MH + (tau[1,2] *
> W1MH) +
> (tau[1,2] * W2MH)) / population[3,2]) * rho[1,3])) + mew) * XFL) + (sigma
> *
> VFL);
> 		dXFM.dt = (0.5 * mew * omega[2,1] * (1-phi) * total) - ((partner[2,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
> population[1,2]) * rho[2,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) +
> (tau[1,2]
> * W2MM))/population[2,2]) * rho[2,2]) + (((Y1MH + Y2MH + (tau[1,1] *
> W1MH) +
> (tau[1,2] * W2MH)) / population[3,2]) * rho[2,3])) + mew) * XFM) + (sigma
> *
> VFM);
> 		dXFH.dt = (0.5 * mew * omega[3,1] * (1-phi) * total) - ((partner[3,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (tau[1,1] * W1ML) + (tau[1,2] * W2ML)) /
> population[1,2]) * rho[3,1]) + (((Y1MM + Y2MM + (tau[1,1]*W1MM) +
> (tau[1,2]
> * W2MM))/population[2,2]) * rho[3,2]) + (((Y1MH + Y2MH + (tau[1,1] *
> W1MH) +
> (tau[1,2] * W2MH)) / population[3,2]) * rho[3,3])) + mew) * XFH) + (sigma
> *
> VFH);
> 		dXML.dt = (0.5 * mew * omega[1,1] * (1-phi) * total) - ((partner[1,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
> population[1,1]) * rho[1,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) +
> (tau[2,2]
> * W2FM))/population[2,1]) * rho[1,2]) + (((Y1FH + Y2FH + (tau[2,1] *
> W1FH) +
> (tau[2,2] * W2FH)) / population[3,1]) * rho[1,3])) + mew) * XML) + (sigma
> *
> VML);
> 		dXMM.dt = (0.5 * mew * omega[2,1] * (1-phi) * total) - ((partner[2,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
> population[1,1]) * rho[2,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) +
> (tau[2,2]
> * W2FM))/population[2,1]) * rho[2,2]) + (((Y1FH + Y2FH + (tau[2,1] *
> W1FH) +
> (tau[2,2] * W2FH)) / population[3,1]) * rho[2,3])) + mew) * XMM) + (sigma
> *
> VMM);
> 		dXMH.dt = (0.5 * mew * omega[3,1] * (1-phi) * total) - ((partner[3,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (tau[2,1] * W1FL) + (tau[2,2] * W2FL)) /
> population[1,1]) * rho[3,1]) + (((Y1FM + Y2FM + (tau[2,1]*W1FM) +
> (tau[2,2]
> * W2FM))/population[2,1]) * rho[3,2]) + (((Y1FH + Y2FH + (tau[2,1] *
> W1FH) +
> (tau[2,2] * W2FH)) / population[3,1]) * rho[3,3])) + mew) * XMH) + (sigma
> *
> VMH);
> 		dY1FL.dt = (XFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y1ML +
> (tau[1,1] * W1ML)) / population[1,2])) + (rho[1,2] * ((Y1MM + (tau[1,1] *
> W1MM)) / population[2,2])) + (rho[1,3] * ((Y1MH + (tau[1,1] * W1MH)) /
> population[3,2]))))) - ((mew + gamma[2,1]) * Y1FL);
> 		dY1FM.dt = (XFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y1ML +
> (tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,1] *
> W1MM)) / population[2,2])) + (rho[2,3] * ((Y1MH + (tau[1,1] * W1MH)) /
> population[3,2]))))) - ((mew + gamma[2,1]) * Y1FM);
> 		dY1FH.dt = (XFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y1ML +
> (tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,1] *
> W1MM)) / population[2,2])) + (rho[3,3] * ((Y1MH + (tau[1,1] * W1MH)) /
> population[3,2]))))) - ((mew + gamma[2,1]) * Y1FH);
> 		dY1ML.dt = (XML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y1FL +
> (tau[2,1] * W1FL)) / population[1,1])) + (rho[1,2] * ((Y1FM + (tau[2,1] *
> W1FM)) / population[2,1])) + (rho[1,3] * ((Y1FH + (tau[2,1] * W1FH)) /
> population[3,1]))))) - ((mew + gamma[1,1]) * Y1MM);
> 		dY1MM.dt = (XMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y1FL +
> (tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,1] *
> W1FM)) / population[2,1])) + (rho[2,3] * ((Y1FH + (tau[2,1] * W1FH)) /
> population[3,1]))))) - ((mew + gamma[1,1]) * Y1MM);
> 		dY1MH.dt = (XMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y1FL +
> (tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,1] *
> W1FM)) / population[2,1])) + (rho[3,3] * ((Y1FH + (tau[2,1] * W1MH)) /
> population[3,1]))))) - ((mew + gamma[1,1]) * Y1MH);
> 		dY2FL.dt = (XFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y2ML +
> (tau[1,2] * W2ML)) / population[1,2])) + (rho[1,2] * ((Y1MM + (tau[1,2] *
> W2MM)) / population[2,2])) + (rho[1,3] * ((Y2MH + (tau[1,2] * W2MH)) /
> population[3,2]))))) - ((mew + gamma[2,2]) * Y1FL);
> 		dY2FM.dt = (XFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y2ML +
> (tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,2] *
> W2MM)) / population[2,2])) + (rho[2,3] * ((Y2MH + (tau[1,2] * W2MH)) /
> population[3,2]))))) - ((mew + gamma[2,2]) * Y1FM);
> 		dY2FH.dt = (XFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y2ML +
> (tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM + (tau[1,2] *
> W2MM)) / population[2,2])) + (rho[3,3] * ((Y2MH + (tau[1,2] * W2MH)) /
> population[3,2]))))) - ((mew + gamma[2,2]) * Y1FH);
> 		dY2ML.dt = (XML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y2FL +
> (tau[2,2] * W2FL)) / population[1,1])) + (rho[1,2] * ((Y1FM + (tau[2,2] *
> W2FM)) / population[2,1])) + (rho[1,3] * ((Y2FH + (tau[2,2] * W2FH)) /
> population[3,1]))))) - ((mew + gamma[1,2]) * Y1MM);
> 		dY2MM.dt = (XMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y2FL +
> (tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,2] *
> W2FM)) / population[2,1])) + (rho[2,3] * ((Y2FH + (tau[2,2] * W2FH)) /
> population[3,1]))))) - ((mew + gamma[1,2]) * Y1MM);
> 		dY2MH.dt = (XMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y2FL +
> (tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM + (tau[2,2] *
> W2FM)) / population[2,1])) + (rho[3,3] * ((Y2FH + (tau[2,2] * W2MH)) /
> population[3,1]))))) - ((mew + gamma[1,2]) * Y1MH);
> 		dZFL.dt = ((gamma[2,1] * Y1FL) + (gamma[2,2] * Y2FL) + (gamma[4,1] *
> W1FL)
> + (gamma[4,2]*W2FL)) - (mew * ZFL);
> 		dZFM.dt = ((gamma[2,1] * Y1FM) + (gamma[2,2] * Y2FM) + (gamma[4,1] *
> W1FM)
> + (gamma[4,2]*W2FM)) - (mew * ZFM);
> 		dZFH.dt = ((gamma[2,1] * Y1FH) + (gamma[2,2] * Y2FH) + (gamma[4,1] *
> W1FH)
> + (gamma[4,2]*W2FH)) - (mew * ZFH);
> 		dZML.dt = ((gamma[1,1] * Y1ML) + (gamma[1,2] * Y2ML) + (gamma[3,1] *
> W1FM)
> + (gamma[3,2]*W2ML)) - (mew * ZML);
> 		dZMM.dt = ((gamma[1,1] * Y1MM) + (gamma[1,2] * Y2MM) + (gamma[3,1] *
> W1MM)
> + (gamma[3,2]*W2MM)) - (mew * ZMM);
> 		dZMH.dt = ((gamma[1,1] * Y1MH) + (gamma[1,2] * Y2MH) + (gamma[3,1] *
> W1MH)
> + (gamma[3,2]*W2MH)) - (mew * ZMH);
> 		dVFL.dt = (0.5 * mew * omega[1,1] * phi * total) - ((partner[1,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) +
> (delta[1,2] *
> tau[1,2] * W2ML)) / population[1,2]) * rho[1,1]) + (((Y1MM + Y2MM +
> (delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
> W2MM))/population[2,2]) * rho[1,2]) + (((Y1MH + Y2MH + (delta[1,1] *
> tau[1,2] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
> rho[1,3])) + mew) * VFL) - (sigma * VFL);
> 		dVFM.dt = (0.5 * mew * omega[2,1] * phi * total) - ((partner[2,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) +
> (delta[1,2] *
> tau[1,2] * W2ML)) / population[1,2]) * rho[2,1]) + (((Y1MM + Y2MM +
> (delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
> W2MM))/population[2,2]) * rho[2,2]) + (((Y1MH + Y2MH + (delta[1,1] *
> tau[1,1] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
> rho[2,3])) + mew) * VFM) - (sigma * VFM);
> 		dVFH.dt = (0.5 * mew * omega[3,1] * phi * total) - ((partner[3,1] *
> beta[1,1] * ((((Y1ML + Y2ML + (delta[1,1] * tau[1,1] * W1ML) +
> (delta[1,2] *
> tau[1,2] * W2ML)) / population[1,2]) * rho[3,1]) + (((Y1MM + Y2MM +
> (delta[1,1] * tau[1,1]*W1MM) + (delta[1,2] * tau[1,2] *
> W2MM))/population[2,2]) * rho[3,2]) + (((Y1MH + Y2MH + (delta[1,1] *
> tau[1,1] * W1MH) + (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]) *
> rho[3,3])) + mew) * VFH) - (sigma * VFH);
> 		dVML.dt = (0.5 * mew * omega[1,1] * phi * total) - ((partner[1,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) +
> (delta[2,2] *
> tau[2,2] * W2FL)) / population[1,1]) * rho[1,1]) + (((Y1FM + Y2FM +
> (delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
> W2FM))/population[2,1]) * rho[1,2]) + (((Y1FH + Y2FH + (delta[2,1] *
> tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
> rho[1,3])) + mew) * VML) - (sigma * VML);
> 		dVMM.dt = (0.5 * mew * omega[2,1] * phi * total) - ((partner[2,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) +
> (delta[2,2] *
> tau[2,2] * W2FL)) / population[1,1]) * rho[2,1]) + (((Y1FM + Y2FM +
> (delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
> W2FM))/population[2,1]) * rho[2,2]) + (((Y1FH + Y2FH + (delta[2,1] *
> tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
> rho[2,3])) + mew) * VMM) - (sigma * VMM);
> 		dVMH.dt = (0.5 * mew * omega[3,1] * phi * total) - ((partner[3,1] *
> beta[2,1] * ((((Y1FL + Y2FL + (delta[2,1] * tau[2,1] * W1FL) +
> (delta[2,2] *
> tau[2,2] * W2FL)) / population[1,1]) * rho[3,1]) + (((Y1FM + Y2FM +
> (delta[2,1] * tau[2,1]*W1FM) + (delta[2,2] * tau[2,2] *
> W2FM))/population[2,1]) * rho[3,2]) + (((Y1FH + Y2FH + (delta[2,1] *
> tau[2,1] * W1FH) + (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]) *
> rho[3,3])) + mew) * VMH) - (sigma * VMH);
> 		dW1FL.dt = (VFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y1ML +
> (delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[1,2] * ((Y1MM
> +
> (delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[1,3] * ((Y1MH
> +
> (delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew +
> gamma[4,1])
> * W1FL);
> 		dW1FM.dt = (VFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y1ML +
> (delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM
> +
> (delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[2,3] * ((Y1MH
> +
> (delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew +
> gamma[4,1])
> * W1FM);
> 		dW1FH.dt = (VFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y1ML +
> (delta[1,1] * tau[1,1] * W1ML)) / population[1,2])) + (rho[2,2] * ((Y1MM
> +
> (delta[1,1] * tau[1,1] * W1MM)) / population[2,2])) + (rho[3,3] * ((Y1MH
> +
> (delta[1,1] * tau[1,1] * W1MH)) / population[3,2]))))) - ((mew +
> gamma[4,1])
> * W1FH);
> 		dW1ML.dt = (VML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y1FL +
> (delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[1,2] * ((Y1FM
> +
> (delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[1,3] * ((Y1FH
> +
> (delta[2,1] * tau[2,1] * W1FH)) / population[3,1]))))) - ((mew +
> gamma[3,1])
> * W1MM);
> 		dW1MM.dt = (VMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y1FL +
> (delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM
> +
> (delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[2,3] * ((Y1FH
> +
> (delta[2,1] * tau[2,1] * W1FH)) / population[3,1]))))) - ((mew +
> gamma[3,1])
> * W1MM);
> 		dW1MH.dt = (VMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y1FL +
> (delta[2,1] * tau[2,1] * W1FL)) / population[1,1])) + (rho[2,2] * ((Y1FM
> +
> (delta[2,1] * tau[2,1] * W1FM)) / population[2,1])) + (rho[3,3] * ((Y1FH
> +
> (delta[2,1] * tau[2,1] * W1MH)) / population[3,1]))))) - ((mew +
> gamma[3,1])
> * W1MH);
> 		dW2FL.dt = (VFL * (partner[1,1] * beta[1,1] * ((rho[1,1] * ((Y2ML +
> (delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[1,2] * ((Y1MM
> +
> (delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[1,3] * ((Y2MH
> +
> (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew +
> gamma[4,2])
> * W1FL);
> 		dW2FM.dt = (VFM * (partner[2,1] * beta[1,1] * ((rho[2,1] * ((Y2ML +
> (delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM
> +
> (delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[2,3] * ((Y2MH
> +
> (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew +
> gamma[4,2])
> * W1FM);
> 		dW2FH.dt = (VFH * (partner[3,1] * beta[1,1] * ((rho[3,1] * ((Y2ML +
> (delta[1,2] * tau[1,2] * W2ML)) / population[1,2])) + (rho[2,2] * ((Y1MM
> +
> (delta[1,2] * tau[1,2] * W2MM)) / population[2,2])) + (rho[3,3] * ((Y2MH
> +
> (delta[1,2] * tau[1,2] * W2MH)) / population[3,2]))))) - ((mew +
> gamma[4,2])
> * W1FH);
> 		dW2ML.dt = (VML * (partner[1,1] * beta[2,1] * ((rho[1,1] * ((Y2FL +
> (delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[1,2] * ((Y1FM
> +
> (delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[1,3] * ((Y2FH
> +
> (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]))))) - ((mew +
> gamma[3,2])
> * W1MM);
> 		dW2MM.dt = (VMM * (partner[2,1] * beta[2,1] * ((rho[2,1] * ((Y2FL +
> (delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM
> +
> (delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[2,3] * ((Y2FH
> +
> (delta[2,2] * tau[2,2] * W2FH)) / population[3,1]))))) - ((mew +
> gamma[3,2])
> * W1MM);
> 		dW2MH.dt = (VMH * (partner[3,1] * beta[2,1] * ((rho[3,1] * ((Y2FL +
> (delta[2,2] * tau[2,2] * W2FL)) / population[1,1])) + (rho[2,2] * ((Y1FM
> +
> (delta[2,2] * tau[2,2] * W2FM)) / population[2,1])) + (rho[3,3] * ((Y2FH
> +
> (delta[2,2] * tau[2,2] * W2MH)) / population[3,1]))))) - ((mew +
> gamma[3,2])
> * W1MH);
> 		return(list(c(dXFL.dt, dXFM.dt, dXFH.dt, dXML.dt, dXMM.dt, dXMH.dt,
> dY1FL.dt, dY1FM.dt, dY1FH.dt, dY1ML.dt, dY1MM.dt, dY1MH.dt, dY2FL.dt,
> dY2FM.dt, dY2FH.dt, dY2ML.dt, dY2MM.dt, dY2MH.dt, dZFL.dt, dZFM.dt,
> dZFH.dt,
> dZML.dt, dZMM.dt, dZMH.dt, dVFL.dt, dVFM.dt, dVFH.dt, dVML.dt, dVMM.dt,
> dVMH.dt, dW1FL.dt, dW1FM.dt, dW1FH.dt, dW1ML.dt, dW1MM.dt, dW1MH.dt,
> dW2FL.dt, dW2FM.dt, dW2FH.dt, dW2ML.dt, dW2MM.dt, dW2MH.dt)));
> 	})
> }
> 
> #giving the parameters
> 
> mew = 1/15 																													#proportion of individuals
> entering
> or exiting the sexually active group at a time
> total = 60020																												#total population of sexually
> active
> phi = 0.9 																													#Proportion of individuals who are
> successfully vaccinated
> sigma = 1/10																												#loss of vaccination status
> gamma = matrix(data=c(0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66),
> ncol=2, nrow=4)																#Duration of infectiousness
> omega = matrix(data=c(0.82, 0.15, 0.03))
> #proportion
> of those in each sexual activity level
> population = matrix(data=c(omega[1,1]*0.5*total, omega[2,1]*0.5*total,
> omega[3,1]*0.5*total, omega[1,1]*0.5*total, omega[2,1]*0.5*total,
> omega[3,1]*0.5*total), ncol=2, nrow=3)	#population in each sexual
> activity
> level and gender group
> partner = matrix(data=c(1.4, 3, 9))																									#average
> number
> of partners per year by risk group
> beta = matrix(data=c(0.8, 0.7))																									#Chance of
> infection
> from partner given 1 sexual encounter
> rho = matrix(data=c(1, 1, 1, 1, 1, 1, 1, 1, 1), ncol=3, nrow=3)
> #preference for selecting sexual partner by activity group
> tau = matrix(data=c(1, 1, 1, 1), ncol=2, nrow=2)
> delta = matrix(data=c(1, 1, 1, 1), ncol=2, nrow=2)
> #reduction of infection from a vaccinated infected individual
> 
> XFL0 = 1850						#Initial number of females in the low risk group
> unvaccinated susceptibles
> XFM0 = 340						#Initial number of susceptible unvaccinated females
> medium
> risk
> XFH0 = 70						#Initial number of susceptible unvaccinated females high
> risk
> XML0 = 1850						#Initial number of susceptible unvaccinated males low
> risk
> XMM0 = 340						#Initial number of susceptible unvaccinated males medium
> risk
> XMH0 = 70						#Initial number of susceptible unvaccinated males high
> risk
> Y1FL0 = 590						#Initial number of infected unvaccinated females low
> risk
> Y1FM0 = 100						#Initial number of infected unvaccinated females medium
> risk
> Y1FH0 = 20						#Initial number of infected unvaccinated females high
> risk
> Y1ML0 = 590						#Initial number of infected unvaccinated males low risk
> Y1MM0 = 100						#Initial number of infected unvaccinated males medium
> risk
> Y1MH0 = 20						#Initial number of infected unvaccinated males high risk
> Y2FL0 = 590						#Initial number of infected unvaccinated females low
> risk
> Y2FM0 = 100						#Initial number of infected unvaccinated females medium
> risk
> Y2FH0 = 20						#Initial number of infected unvaccinated females high
> risk
> Y2ML0 = 590						#Initial number of infected unvaccinated males low risk
> Y2MM0 = 100						#Initial number of infected unvaccinated males medium
> risk
> Y2MH0 = 20						#Initial number of infected unvaccinated males high risk
> ZFL0 = 0						#Initial number of immune females low risk
> ZFM0 = 0	 					#Initial number of immune females medium risk
> ZFH0 = 0 						#Initial number of immune females high risk
> ZML0 = 0 						#Initial number of immune males low risk
> ZMM0 = 0 						#Initial number of immune males medium risk
> ZMH0 = 0 						#Initial number of immune males high risk
> VFL0 = 21070					#Initial number of susceptible vaccinated females low
> risk
> VFM0 = 3850						#Initial number of susceptible vaccinated females medium
> risk
> VFH0 = 770						#Initial number of susceptible vaccinated females high
> risk
> VML0 = 21070					#Initial number of susceptible vaccinated males low risk
> VMM0 = 3850						#Initial number of susceptible vaccinated males medium
> risk
> VMH0 = 770						#Initial number of susceptible vaccinated males high risk
> W1FL0 = 1110					#Initial number of infected vaccinated females low risk
> W1FM0 = 200						#Initial number of infected vaccinated females medium
> risk
> W1FH0 = 40						#Initial number of infected vaccinated females high risk
> W1ML0 = 1110					#Initial number of infected vaccinated males low risk
> W1MM0 = 200						#Initial number of infected vaccinated males medium risk
> W1MH0 = 40						#Initial number of infected vaccinated males high risk
> W2FL0 = 1110					#Initial number of infected vaccinated females low risk
> W2FM0 = 200						#Initial number of infected vaccinated females medium
> risk
> W2FH0 = 40						#Initial number of infected vaccinated females high risk
> W2ML0 = 1110					#Initial number of infected vaccinated males low risk
> W2MM0 = 200						#Initial number of infected vaccinated males medium risk
> W2MH0 = 40						#Initial number of infected vaccinated males high risk
> 
> p = list(mew=mew, total=total, phi=phi, sigma=sigma, gamma=gamma,
> omega=omega, population=population, partner=partner, beta=beta, rho=rho,
> tau=tau, delta=delta)
> 
> y0 = c(XFL0, XFM0, XFH0, XML0, XMM0, XMH0, Y1FL0, Y1FM0, Y1FH0, Y1ML0,
> Y1MM0, Y1MH0, Y2FL0, Y2FM0, Y2FH0, Y2ML0, Y2MM0, Y2MH0, ZFL0, ZFM0, ZFH0,
> ZML0, ZMM0, ZMH0, VFL0, VFM0, VFH0, VML0, VMM0, VMH0, W1FL0, W1FM0,
> W1FH0,
> W1ML0, W1MM0, W1MH0, W2FL0, W2FM0, W2FH0, W2ML0, W2MM0, W2MH0)
> 
> #Running the ode integrator
> 
> steps= 10;
> t = seq(from=0, to=100, by=1);
> 
> Is anyone able to help?
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/DeSolver-giving-NA-as-output-but-running-fully-tp4706497.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From joshuamichaeldixon at gmail.com  Tue Apr 28 00:35:13 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Mon, 27 Apr 2015 23:35:13 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <F0739AC4AF7.00000E24jrkrideau@inbox.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<CAOkeKBJMP8hRs8TpfXvZxTsEVRwav_JMJn7HnGb3n18=4JjQgA@mail.gmail.com>
	<F0739AC4AF7.00000E24jrkrideau@inbox.com>
Message-ID: <CAOkeKB+7SYL7+VLZQak-Mf4JAimRTJK=u7tsz1juFwK23eY6og@mail.gmail.com>

Thanks John!

This ok?

> dput(head(data, 100))
structure(list(Id = c(7451L, 148L, 10393L, 10200L, 1961L, 10428L,
10541L, 10012L, 9895L, 10626L, 1151L, 8775L, 10083L, 6217L, 90L,
10168L, 10291L, 8549L, 3451L, 10003L, 5907L, 10136L, 6182L, 6315L,
10015L, 9956L, 2040L, 4710L, 10747L, 6787L, 1222L, 10757L, 2892L,
117L, 10328L, 10503L, 768L, 2979L, 1961L, 10520L, 10498L, 3018L,
10335L, 2448L, 9027L, 362L, 8499L, 10603L, 9489L, 2124L, 707L,
8501L, 4908L, 9905L, 3000L, 2819L, 9973L, 10550L, 9921L, 10639L,
8771L, 10121L, 32L, 9935L, 9299L, 3246L, 682L, 10325L, 6741L,
3295L, 5270L, 727L, 8500L, 50L, 4705L, 3018L, 787L, 2953L, 1391L,
3682L, 7974L, 5023L, 652L, 727L, 679L, 10212L, 9488L, 9987L,
10039L, 5025L, 250L, 2539L, 787L, 3000L, 1151L, 8946L, 6177L,
3296L, 250L, 498L), Level = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
c("CHAMPIONSHIP",
"CONFERENCE", "LEAGUE_ONE", "LEAGUE_TWO", "PREMIER_LEAGUE"), class =
"factor"),
    AgeGr = c(14L, 16L, 10L, 10L, 13L, 10L, 10L, 10L, 10L, 10L,
    14L, 10L, 10L, 10L, 12L, 10L, 10L, 12L, 10L, 10L, 10L, 10L,
    12L, 10L, 10L, 10L, 10L, 10L, 10L, 15L, 10L, 10L, 10L, 12L,
    10L, 10L, 13L, 10L, 13L, 11L, 11L, 13L, 12L, 11L, 12L, 14L,
    13L, 13L, 13L, 13L, 12L, 11L, 15L, 11L, 14L, 13L, 11L, 11L,
    11L, 12L, 14L, 12L, 13L, 11L, 13L, 15L, 11L, 13L, 13L, 13L,
    14L, 13L, 13L, 12L, 13L, 13L, 13L, 14L, 12L, 14L, 13L, 13L,
    13L, 13L, 13L, 12L, 13L, 14L, 13L, 14L, 13L, 14L, 13L, 14L,
    14L, 13L, 14L, 13L, 13L, 13L), Position = structure(c(4L,
    1L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 4L, 3L, 2L, 3L,
    4L, 3L, 4L, 2L, 4L, 2L, 3L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 4L,
    2L, 1L, 4L, 1L, 1L, 2L, 4L, 3L, 1L, 4L, 1L, 2L, 3L, 3L, 1L,
    1L, 3L, 1L, 3L, 4L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 3L, 1L,
    2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 4L, 1L, 1L, 1L,
    2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 1L, 3L, 4L, 4L, 4L, 4L, 2L,
    2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 2L), .Label = c("D", "F",
    "GK", "M"), class = "factor"), Height = c(NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 151L, NA,
    154L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L, NA,
    147L, NA, NA, NA, NA, NA, 138L, 172L, NA, NA, 150L, NA, NA,
    NA, NA, NA, NA, NA, 140L, 153L, NA, NA, NA, NA, NA, NA, NA,
    158L, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L), Weight = c(63,
    64, 36, 46, 67, 40, 25, 30, 36, 33, 61, 31, 29, 34, 47, 38,
    32, 44, 32, 32, 30, 34, 51, 34, 28, 27, 33, 31, 28, 44, 37,
    46, 26, 42, 32, 32, 43, 31, 72, 27, 30, 55, 53, 50, 51, 55,
    48.6, 49, 48, 64, 35, 32, 55, 32, 50, 61, 42, 33, 37, 45,
    45, 50, 36, 33, 49, 59, 42, 43, 35.1, 66.9, 52, 47, 40, 38,
    45, 53, 44, 54, 39, 62, 33, 53.8, 42, 46, 39, 48, 39, 54,
    40, 42.4, 50, 48, 46, 52, 58, 40, 46, 51, 54, 42), BMI = c(NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    21.2, NA, 20.24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, 18.49, NA, 16.66, NA, NA, NA, NA, NA, 18.57, 22.61, NA,
    NA, 17.77, NA, NA, NA, NA, NA, NA, NA, 16.84, 22.86, NA,
    NA, NA, NA, NA, NA, NA, 16.9, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, 17.26), YoYo = c(80L, 80L, 160L, 160L, 160L, 160L,
    160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
    160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
    160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
    160L, 160L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
    200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
    200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
    200L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
    240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
    240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
    240L, 240L, 240L, 240L)), .Names = c("Id", "Level", "AgeGr",
"Position", "Height", "Weight", "BMI", "YoYo"), row.names = c(NA,
100L), class = "data.frame")

On Mon, Apr 27, 2015 at 10:43 PM, John Kane <jrkrideau at inbox.com> wrote:

>
> Hi Josh,
>
> Just a sample  is usually  fine. As long as it cover a representative
> (must be time for dinner---I was going to type reprehensibe) sample of the
> data then something like dput(head(mydata, 100) ) works well.
>
> Kingston ON Canada
>
> -----Original Message-----
> From: joshuamichaeldixon at gmail.com
> Sent: Mon, 27 Apr 2015 21:30:39 +0100
> To: lists at dewey.myzen.co.uk
> Subject: Re: [R] Help Interpreting Linear Mixed Model
>
> Apologies for my ignorance!
>
> Thierry - thank you for the reading.  I'll look into those ASAP!
>
> John - The data set I have is quite large, when using the dput() command
> I'm unsure if it actually fits the whole output into the console.  I can't
> scroll up far enough to see the actual command.  I can paste what is there
> if that may help?  The bottom line:
>
> Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI",
> "YoYo"), class = "data.frame", row.names = c(NA, -9689L))
>
> Michael - Essentially, I'm looking for differences between "YoYo" outcome
> for "Positions", "Levels" and accounting for repeated measures using "Id"
> as a random factor.  So I was able to figure out points 2 and 3.
>
> I've searched for definitions of "Scaled residuals", "Random
> effects", "Fixed effects", "Correlation of Fixed Effects".  However, I'm
> confused at the different interpretations I've found.  Or quite possibly,
> I'm just confused...  What should I be looking out for in these variables?
>
> I've tried to take my analysis smaller, and just look at specifics, to
> make it simpler.  Such as, comparing YoYo (outcome score) for a
> Premier_League (Level), 22 (AgeGr) F (Position) with a Premier_League
> (Level), 22 (AgeGr) M (Position).  How do I convert these into a factors
> for analysis?
>
> Simple question maybe, but it's not when you can't find the answer!
>
> Thank you,
>
> Josh
>
> On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>
>         Dear Joshua
>
>  It would also help if you told us what your scientific question was. At
> the moment we know what R commands you used and have seen the head of your
> dataset but not why you are doing it.
>
>  I would summarise what you have given us as
>
>  1 - most ID only occur once
>  2 - goal keepers do worse than outfield players
>  3 - older people (presumably in fact age is in years as a continuous
> variable) do better
>
>  On 27/04/2015 12:42, John Kane wrote:
>
>  John Kane
>  Kingston ON Canada
>
>          -----Original Message-----
>  From: joshuamichaeldixon at gmail.com
>  Sent: Mon, 27 Apr 2015 08:54:51 +0100
>  To: thierry.onkelinx at inbo.be
>  Subject: Re: [R] Help Interpreting Linear Mixed Model
>
>  Hello Thierry,
>
>  No, this isn't homework. Not that young unfortunately.
>
>  A few years ago a friend of mine and her daughter were neck-in-neck on
> who got their Ph.D first. What's this "not that young" business?
>
>  BTW, a better way to supply sample data is to use the dput() command.
>
>  Do a dput(mydata), copy the results into the email and you have supplied
> us with an exact copy of your data.
>
>  It is possible for many reasons that I will not read in your data, as you
> supplied it, in the format you have it in.  This can lead to real confusion.
>
>          Josh
>
>          On 27 Apr 2015, at 08:06, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
>  wrote:
>
>  Dear Josh,
>
>  Is this homework? Because the list has a no homework policy.
>
>  Best regards,
>
>  ir. Thierry Onkelinx
>  Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>  and Forest
>  team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>  Kliniekstraat 25
>  1070 Anderlecht
>  Belgium
>
>  To call in the statistician after the experiment is done may be no more
>  than asking him to perform a post-mortem examination: he may be able to
>  say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>  The plural of anecdote is not data. ~ Roger Brinner
>  The combination of some data and an aching desire for an answer does not
>  ensure that a reasonable answer can be extracted from a given body of
>  data. ~ John Tukey
>
>  2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>
>          Hello!
>
>  Very new to R (10 days), and I've run the linear mixed model, below.
>  Attempting to interpret what it means...  What do I need to look for?
>  Residuals, correlations of fixed effects?!
>
>  How would I look at very specific interactions, such as PREMIER_LEAGUE
>  (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>  GK?
>
>  For reference my data set looks like this:
>
>  Id Level AgeGr   Position Height Weight BMI YoYo
>  7451 CHAMPIONSHIP 14 M NA 63 NA 80
>  148 PREMIER_LEAGUE 16 D NA 64 NA 80
>  10393 CONFERENCE 10 D NA 36 NA 160
>  10200 CHAMPIONSHIP 10 F NA 46 NA 160
>  1961 LEAGUE_TWO 13 GK NA 67 NA 160
>  10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>  10541 LEAGUE_ONE 10 F NA 25 NA 160
>  10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>  9895 CHAMPIONSHIP 10 D NA 36 NA 160
>
>  Many thanks in advance for time and help.  Really appreciate it.
>
>  Josh
>
>          summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>
>  Linear mixed model fit by REML ['lmerMod']
>  Formula: YoYo ~ AgeGr + Position + (1 | Id)
>
>  REML criterion at convergence: 125712.2
>
>  Scaled residuals:
>       Min      1Q  Median      3Q     Max
>  -3.4407 -0.5288 -0.0874  0.4531  4.8242
>
>  Random effects:
>    Groups   Name        Variance Std.Dev.
>    Id       (Intercept) 15300    123.7
>    Residual             16530    128.6
>  Number of obs: 9609, groups:  Id, 6071
>
>  Fixed effects:
>                Estimate Std. Error t value
>  (Intercept) -521.6985    16.8392  -30.98
>  AgeGr         62.6786     0.9783   64.07
>  PositionD    139.4682     7.8568   17.75
>  PositionM    141.2227     7.7072   18.32
>  PositionF    135.1241     8.1911   16.50
>
>  Correlation of Fixed Effects:
>             (Intr) AgeGr  PostnD PostnM
>  AgeGr     -0.910
>  PositionD -0.359 -0.009
>  PositionM -0.375  0.001  0.810
>  PositionF -0.349 -0.003  0.756  0.782
>
>          model=lmer(YoYo~AgeGr+Position+(1|Id))
>  summary(glht(model,linfct=mcp(Position="Tukey")))
>
>    Simultaneous Tests for General Linear Hypotheses
>
>  Multiple Comparisons of Means: Tukey Contrasts
>
>  Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>
>  Linear Hypotheses:
>               Estimate Std. Error z value Pr(>|z|)
>  D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>  M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>  F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>  M - D == 0     1.754      4.799   0.366    0.983
>  F - D == 0    -4.344      5.616  -0.774    0.862
>  F - M == 0    -6.099      5.267  -1.158    0.645
>  ---
>  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>  (Adjusted p values reported -- single-step method)
>
>           [[alternative HTML version deleted]]
>
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]
>  PLEASE do read the posting guide
>  http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]
>  and provide commented, minimal, self-contained, reproducible code.
>
>          [[alternative HTML version deleted]]
>
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]
>  PLEASE do read the posting guide
>  http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]
>  and provide commented, minimal, self-contained, reproducible code.
>
>  ____________________________________________________________
>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
>  Visit http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing] to find out more!
>
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]
>  PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]
>  and provide commented, minimal, self-contained, reproducible code.
>
>  --
>  Michael
>  http://www.dewey.myzen.co.uk/home.html [
> http://www.dewey.myzen.co.uk/home.html]
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 00:45:52 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Apr 2015 18:45:52 -0400
Subject: [R] select portion of text file using R
In-Reply-To: <CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>	<5534E05C.2010407@gmail.com>
	<CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
Message-ID: <553EBC20.9070608@gmail.com>

On 27/04/2015 5:20 PM, Luigi Marongiu wrote:
> Dear Duncan,
> thank you for your reply,
> I tried to read the file using skip and nrows but it did not work.

What does that mean?  We might be able to be more help if you tell us
what happened when you tried the code below.

> Here i am pasting the code I wrote and the head of the file i need to
> read. Probably the error is due to the fact that the column "well" has
> duplication, but how can i add a row column with unique row names? How
> can I overcome this error?
> Best regards
> Luigi
> 
> CODE
> raw.data<-read.table(
>       mydata,
>       header=TRUE,
>       row.names=31,

That's a strange entry, in conflict with the entry below...

>       dec=".",
>       sep="\t",
>       skip = 30,
>       nrows = 17281,
>       row.names = 1:17281

... i.e. here.  If you don't have row names in the file, there's no need
to specify them numerically:  that would be the default.  So I'd drop
*both* cases where you give the row.names argument.

Also, I may have counted wrong, but it looks to me that the line with
the column headings is line 32, so you should have skip = 31.

Duncan Murdoch


>     )
> 
> 
> HEAD OF MYDATA
> * Block Type = Array Card Block
> * Calibration Background is expired = No
> * Calibration Background performed on = 2014-12-02 11:27:49 AM PST
> * Calibration FAM is expired = No
> * Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
> * Calibration ROI is expired = No
> * Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
> * Calibration ROX is expired = No
> * Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
> * Calibration Uniformity is expired = No
> * Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
> * Calibration VIC is expired = No
> * Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
> * Chemistry = TAQMAN
> * Experiment Barcode =
> * Experiment Comments =
> * Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
> * Experiment Name = 2015-04-13 171216
> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> * Experiment Type = Comparative C? (??C?)
> * Experiment User Name =
> * Instrument Name = 278882033
> * Instrument Serial Number = 278882033
> * Instrument Type = ViiA 7
> * Passive Reference = ROX
> * Quantification Cycle Method = Ct
> * Signal Smoothing On = false
> * Stage/ Cycle where Analysis is performed = Stage 3, Step 2
> 
> [Amplification Data]
> 
> Well \tCycle \tTarget \tName \tRn
> \t1 \t1 \tAdeno 1 \t0.82
> \t1 \t2 \tAdeno 1\ \t0.93
> ...
> \t2 \t1 \tAdeno 2 \t0.78
> ...
> 
> On Mon, Apr 20, 2015 at 12:17 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
>>> Dear all,
>>> I have a flat file (tab delimited) derived from an excel file which is
>>> subdivided in different parts: a first part is reporting metadata,
>>> then there is a first spreadsheet indicated by [ ], then the actual
>>> data and the second spreadsheet with the same format [ ] and then the
>>> data.
>>> How can I import such file using for instance read.table()?
>>
>> read.table() by itself can't recognize where the data starts, but it has
>> arguments "skip" and "nrows" to control how much gets read.  If you
>> don't know the values for those arguments, you can use readLines() to
>> read the entire file, then use grep() to recognize your table data, and
>> either re-read the file, or just extract those lines and read from them
>> as a textConnection.
>>
>> Duncan Murdoch
>>
>>> Many thanks
>>> regards
>>> Luigi
>>>
>>> Here is a sample of the file:
>>> * Experiment Barcode =
>>> * Experiment Comments =
>>> * Experiment File Name = F:\array 59
>>> * Experiment Name = 2015-04-13 171216
>>> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
>>> ...
>>> [Amplification Data]
>>> Well    Cycle    Target Name    Rn    Delta Rn
>>> 1    1    Adeno 1-Adeno 1    0.820    -0.051
>>> 1    2    Adeno 1-Adeno 1    0.827    -0.042
>>> 1    3    Adeno 1-Adeno 1    0.843    -0.025
>>> 1    4    Adeno 1-Adeno 1    0.852    -0.015
>>> 1    5    Adeno 1-Adeno 1    0.858    -0.008
>>> 1    6    Adeno 1-Adeno 1    0.862    -0.002
>>> ...
>>> [Results]
>>> Well    Well Position    Omit    Sample Name    Target Name    Task
>>> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
>>> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
>>> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
>>> Baseline Start    Baseline End    Efficiency    Comments    Custom1
>>> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
>>> EXPFAIL
>>> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
>>> NFQ-MGB                Undetermined                            false
>>>  0.200    true    3    44    1.000    N/A                            N
>>>    Y
>>> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
>>> NFQ-MGB                Undetermined
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From jholtman at gmail.com  Tue Apr 28 02:30:27 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 27 Apr 2015 20:30:27 -0400
Subject: [R] select portion of text file using R
In-Reply-To: <CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>
	<5534E05C.2010407@gmail.com>
	<CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
Message-ID: <CAAxdm-6DkobB7ANt368oRYq8d4t9ZLD9UeH4Vjh41UnRJO9gNA@mail.gmail.com>

try this.  It read in all the data and discards the lines not required.

> # read in the data and delete lines not required
> data_in <- readLines(textConnection("HEAD OF MYDATA
+  * Block Type = Array Card Block
+  * Calibration Background is expired = No
+  * Calibration Background performed on = 2014-12-02 11:27:49 AM PST
+  * Calibration FAM is expired = No
+  * Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
+  * Calibration ROI is expired = No
+  * Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
+  * Calibration ROX is expired = No
+  * Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
+  * Calibration Uniformity is expired = No
+  * Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
+  * Calibration VIC is expired = No
+  * Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
+  * Chemistry = TAQMAN
+  * Experiment Barcode =
+  * Experiment Comments =
+  * Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate
3.eds
+  * Experiment Name = 2015-04-13 171216
+  * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
+  * Experiment Type = Comparative
+  * Experiment User Name =
+  * Instrument Name = 278882033
+  * Instrument Serial Number = 278882033
+  * Instrument Type = ViiA 7
+  * Passive Reference = ROX
+  * Quantification Cycle Method = Ct
+  * Signal Smoothing On = false
+  * Stage/ Cycle where Analysis is performed = Stage 3, Step 2
+
+  [Amplification Data]
+
+  Well \tCycle \tTarget \tName \tRn
+  \t1 \t1 \tAdeno 1 \t0.82
+  \t1 \t2 \tAdeno 1\ \t0.93
+  \t2 \t1 \tAdeno 2 \t0.78"))
>
>  indx <- grep("Amplification Data", data_in) + 1
>  data_in <- tail(data_in, -indx)  # delete lines
>  read.table(text = data_in, header = TRUE, sep = '\t')
  Well Cycle Target     Name   Rn
1   NA     1      1 Adeno 1  0.82
2   NA     1      2 Adeno 1  0.93
3   NA     2      1 Adeno 2  0.78
>
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Apr 27, 2015 at 5:20 PM, Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Dear Duncan,
> thank you for your reply,
> I tried to read the file using skip and nrows but it did not work.
> Here i am pasting the code I wrote and the head of the file i need to
> read. Probably the error is due to the fact that the column "well" has
> duplication, but how can i add a row column with unique row names? How
> can I overcome this error?
> Best regards
> Luigi
>
> CODE
> raw.data<-read.table(
>       mydata,
>       header=TRUE,
>       row.names=31,
>       dec=".",
>       sep="\t",
>       skip = 30,
>       nrows = 17281,
>       row.names = 1:17281
>     )
>
>
> HEAD OF MYDATA
> * Block Type = Array Card Block
> * Calibration Background is expired = No
> * Calibration Background performed on = 2014-12-02 11:27:49 AM PST
> * Calibration FAM is expired = No
> * Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
> * Calibration ROI is expired = No
> * Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
> * Calibration ROX is expired = No
> * Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
> * Calibration Uniformity is expired = No
> * Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
> * Calibration VIC is expired = No
> * Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
> * Chemistry = TAQMAN
> * Experiment Barcode =
> * Experiment Comments =
> * Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
> * Experiment Name = 2015-04-13 171216
> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> * Experiment Type = Comparative C? (??C?)
> * Experiment User Name =
> * Instrument Name = 278882033
> * Instrument Serial Number = 278882033
> * Instrument Type = ViiA 7
> * Passive Reference = ROX
> * Quantification Cycle Method = Ct
> * Signal Smoothing On = false
> * Stage/ Cycle where Analysis is performed = Stage 3, Step 2
>
> [Amplification Data]
>
> Well \tCycle \tTarget \tName \tRn
> \t1 \t1 \tAdeno 1 \t0.82
> \t1 \t2 \tAdeno 1\ \t0.93
> ...
> \t2 \t1 \tAdeno 2 \t0.78
> ...
>
> On Mon, Apr 20, 2015 at 12:17 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
> >> Dear all,
> >> I have a flat file (tab delimited) derived from an excel file which is
> >> subdivided in different parts: a first part is reporting metadata,
> >> then there is a first spreadsheet indicated by [ ], then the actual
> >> data and the second spreadsheet with the same format [ ] and then the
> >> data.
> >> How can I import such file using for instance read.table()?
> >
> > read.table() by itself can't recognize where the data starts, but it has
> > arguments "skip" and "nrows" to control how much gets read.  If you
> > don't know the values for those arguments, you can use readLines() to
> > read the entire file, then use grep() to recognize your table data, and
> > either re-read the file, or just extract those lines and read from them
> > as a textConnection.
> >
> > Duncan Murdoch
> >
> >> Many thanks
> >> regards
> >> Luigi
> >>
> >> Here is a sample of the file:
> >> * Experiment Barcode =
> >> * Experiment Comments =
> >> * Experiment File Name = F:\array 59
> >> * Experiment Name = 2015-04-13 171216
> >> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> >> ...
> >> [Amplification Data]
> >> Well    Cycle    Target Name    Rn    Delta Rn
> >> 1    1    Adeno 1-Adeno 1    0.820    -0.051
> >> 1    2    Adeno 1-Adeno 1    0.827    -0.042
> >> 1    3    Adeno 1-Adeno 1    0.843    -0.025
> >> 1    4    Adeno 1-Adeno 1    0.852    -0.015
> >> 1    5    Adeno 1-Adeno 1    0.858    -0.008
> >> 1    6    Adeno 1-Adeno 1    0.862    -0.002
> >> ...
> >> [Results]
> >> Well    Well Position    Omit    Sample Name    Target Name    Task
> >> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
> >> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
> >> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
> >> Baseline Start    Baseline End    Efficiency    Comments    Custom1
> >> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
> >> EXPFAIL
> >> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
> >> NFQ-MGB                Undetermined                            false
> >>  0.200    true    3    44    1.000    N/A                            N
> >>    Y
> >> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
> >> NFQ-MGB                Undetermined
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Tue Apr 28 03:30:00 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 28 Apr 2015 11:30:00 +1000
Subject: [R] select portion of text file using R
In-Reply-To: <CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>	<5534E05C.2010407@gmail.com>
	<CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>
Message-ID: <000401d08152$d8983720$89c8a560$@bigpond.com>

Hi Luigi

I think there may be problems with \t being equivalent to tab chr(9)

Therefore try

xlines <-
readLines(textConnection("* Block Type = Array Card Block
* Calibration Background is expired = No
* Calibration Background performed on = 2014-12-02 11:27:49 AM PST
* Calibration FAM is expired = No
* Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
* Calibration ROI is expired = No
* Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
* Calibration ROX is expired = No
* Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
* Calibration Uniformity is expired = No
* Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
* Calibration VIC is expired = No
* Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
* Chemistry = TAQMAN
* Experiment Barcode =
* Experiment Comments =
* Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
* Experiment Name = 2015-04-13 171216
* Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
* Experiment Type = Comparative C? (??C?)
* Experiment User Name =
* Instrument Name = 278882033
* Instrument Serial Number = 278882033
* Instrument Type = ViiA 7
* Passive Reference = ROX
* Quantification Cycle Method = Ct
* Signal Smoothing On = false
* Stage/ Cycle where Analysis is performed = Stage 3, Step 2
Well  Cycle   Target  Name  Rn
  1   1   Adeno 1   0.82
  1   2   Adeno 1   0.93
  2   1   Adeno 2   0.78") )
xlines = sub("^\\*.*$","", xlines)
xlines = xlines[nchar(xlines)>0]
xlines = sub("^[[:space:]]+","", xlines)
xlines = xlines[-1]
datc = data.frame(do.call(rbind, lapply(xlines, function(x) unlist(strsplit(x, "[[:space:]]+")))))
names(datc) = c("Well","Cycle","Target","Name","Rn")
dat = datc
for (j in c(1,2,4,5)) dat[,j] = as.numeric(dat[,j])

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi Marongiu
Sent: Tuesday, 28 April 2015 07:20
To: Duncan Murdoch; r-help
Subject: Re: [R] select portion of text file using R

Dear Duncan,
thank you for your reply,
I tried to read the file using skip and nrows but it did not work.
Here i am pasting the code I wrote and the head of the file i need to
read. Probably the error is due to the fact that the column "well" has
duplication, but how can i add a row column with unique row names? How
can I overcome this error?
Best regards
Luigi

CODE
raw.data<-read.table(
      mydata,
      header=TRUE,
      row.names=31,
      dec=".",
      sep="\t",
      skip = 30,
      nrows = 17281,
      row.names = 1:17281
    )


HEAD OF MYDATA
* Block Type = Array Card Block
* Calibration Background is expired = No
* Calibration Background performed on = 2014-12-02 11:27:49 AM PST
* Calibration FAM is expired = No
* Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
* Calibration ROI is expired = No
* Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
* Calibration ROX is expired = No
* Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
* Calibration Uniformity is expired = No
* Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
* Calibration VIC is expired = No
* Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
* Chemistry = TAQMAN
* Experiment Barcode =
* Experiment Comments =
* Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
* Experiment Name = 2015-04-13 171216
* Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
* Experiment Type = Comparative C? (??C?)
* Experiment User Name =
* Instrument Name = 278882033
* Instrument Serial Number = 278882033
* Instrument Type = ViiA 7
* Passive Reference = ROX
* Quantification Cycle Method = Ct
* Signal Smoothing On = false
* Stage/ Cycle where Analysis is performed = Stage 3, Step 2

[Amplification Data]

Well \tCycle \tTarget \tName \tRn
\t1 \t1 \tAdeno 1 \t0.82
\t1 \t2 \tAdeno 1\ \t0.93
...
\t2 \t1 \tAdeno 2 \t0.78
...

On Mon, Apr 20, 2015 at 12:17 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
>> Dear all,
>> I have a flat file (tab delimited) derived from an excel file which is
>> subdivided in different parts: a first part is reporting metadata,
>> then there is a first spreadsheet indicated by [ ], then the actual
>> data and the second spreadsheet with the same format [ ] and then the
>> data.
>> How can I import such file using for instance read.table()?
>
> read.table() by itself can't recognize where the data starts, but it has
> arguments "skip" and "nrows" to control how much gets read.  If you
> don't know the values for those arguments, you can use readLines() to
> read the entire file, then use grep() to recognize your table data, and
> either re-read the file, or just extract those lines and read from them
> as a textConnection.
>
> Duncan Murdoch
>
>> Many thanks
>> regards
>> Luigi
>>
>> Here is a sample of the file:
>> * Experiment Barcode =
>> * Experiment Comments =
>> * Experiment File Name = F:\array 59
>> * Experiment Name = 2015-04-13 171216
>> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
>> ...
>> [Amplification Data]
>> Well    Cycle    Target Name    Rn    Delta Rn
>> 1    1    Adeno 1-Adeno 1    0.820    -0.051
>> 1    2    Adeno 1-Adeno 1    0.827    -0.042
>> 1    3    Adeno 1-Adeno 1    0.843    -0.025
>> 1    4    Adeno 1-Adeno 1    0.852    -0.015
>> 1    5    Adeno 1-Adeno 1    0.858    -0.008
>> 1    6    Adeno 1-Adeno 1    0.862    -0.002
>> ...
>> [Results]
>> Well    Well Position    Omit    Sample Name    Target Name    Task
>> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
>> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
>> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
>> Baseline Start    Baseline End    Efficiency    Comments    Custom1
>> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
>> EXPFAIL
>> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
>> NFQ-MGB                Undetermined                            false
>>  0.200    true    3    44    1.000    N/A                            N
>>    Y
>> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
>> NFQ-MGB                Undetermined
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Tue Apr 28 03:39:57 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 27 Apr 2015 17:39:57 -0800
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAOkeKB+7SYL7+VLZQak-Mf4JAimRTJK=u7tsz1juFwK23eY6og@mail.gmail.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<caokekbjmp8hrs8tpfxvzxtsevrwav_jmjn7hngb3n18=4jjqga@mail.gmail.com>
	<f0739ac4af7.00000e24jrkrideau@inbox.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
Message-ID: <F28501AEC71.0000113Ejrkrideau@inbox.com>


Looks great.  How come so many NA's in Height and BMI? Just no data available?

 str(dat1)
'data.frame':	100 obs. of  8 variables:
 $ Id      : int  7451 148 10393 10200 1961 10428 10541 10012 9895 10626 ...
 $ Level   : Factor w/ 5 levels "CHAMPIONSHIP",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ AgeGr   : int  14 16 10 10 13 10 10 10 10 10 ...
 $ Position: Factor w/ 4 levels "D","F","GK","M": 4 1 1 2 3 3 2 3 1 1 ...
 $ Height  : int  NA NA NA NA NA NA NA NA NA NA ...
 $ Weight  : num  63 64 36 46 67 40 25 30 36 33 ...
 $ BMI     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ YoYo    : int  80 80 160 160 160 160 160 160 160 160 ...

John Kane
Kingston ON Canada

-----Original Message-----
From: joshuamichaeldixon at gmail.com
Sent: Mon, 27 Apr 2015 23:35:13 +0100
To: jrkrideau at inbox.com
Subject: Re: [R] Help Interpreting Linear Mixed Model

Thanks John!

This ok?

> dput(head(data, 100))

structure(list(Id = c(7451L, 148L, 10393L, 10200L, 1961L, 10428L,?

10541L, 10012L, 9895L, 10626L, 1151L, 8775L, 10083L, 6217L, 90L,?

10168L, 10291L, 8549L, 3451L, 10003L, 5907L, 10136L, 6182L, 6315L,?

10015L, 9956L, 2040L, 4710L, 10747L, 6787L, 1222L, 10757L, 2892L,?

117L, 10328L, 10503L, 768L, 2979L, 1961L, 10520L, 10498L, 3018L,?

10335L, 2448L, 9027L, 362L, 8499L, 10603L, 9489L, 2124L, 707L,?

8501L, 4908L, 9905L, 3000L, 2819L, 9973L, 10550L, 9921L, 10639L,?

8771L, 10121L, 32L, 9935L, 9299L, 3246L, 682L, 10325L, 6741L,?

3295L, 5270L, 727L, 8500L, 50L, 4705L, 3018L, 787L, 2953L, 1391L,?

3682L, 7974L, 5023L, 652L, 727L, 679L, 10212L, 9488L, 9987L,?

10039L, 5025L, 250L, 2539L, 787L, 3000L, 1151L, 8946L, 6177L,?

3296L, 250L, 498L), Level = structure(c(1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("CHAMPIONSHIP",?

"CONFERENCE", "LEAGUE_ONE", "LEAGUE_TWO", "PREMIER_LEAGUE"), class = "factor"),?

? ? AgeGr = c(14L, 16L, 10L, 10L, 13L, 10L, 10L, 10L, 10L, 10L,?

? ? 14L, 10L, 10L, 10L, 12L, 10L, 10L, 12L, 10L, 10L, 10L, 10L,?

? ? 12L, 10L, 10L, 10L, 10L, 10L, 10L, 15L, 10L, 10L, 10L, 12L,?

? ? 10L, 10L, 13L, 10L, 13L, 11L, 11L, 13L, 12L, 11L, 12L, 14L,?

? ? 13L, 13L, 13L, 13L, 12L, 11L, 15L, 11L, 14L, 13L, 11L, 11L,?

? ? 11L, 12L, 14L, 12L, 13L, 11L, 13L, 15L, 11L, 13L, 13L, 13L,?

? ? 14L, 13L, 13L, 12L, 13L, 13L, 13L, 14L, 12L, 14L, 13L, 13L,?

? ? 13L, 13L, 13L, 12L, 13L, 14L, 13L, 14L, 13L, 14L, 13L, 14L,?

? ? 14L, 13L, 14L, 13L, 13L, 13L), Position = structure(c(4L,?

? ? 1L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 4L, 3L, 2L, 3L,?

? ? 4L, 3L, 4L, 2L, 4L, 2L, 3L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 4L,?

? ? 2L, 1L, 4L, 1L, 1L, 2L, 4L, 3L, 1L, 4L, 1L, 2L, 3L, 3L, 1L,?

? ? 1L, 3L, 1L, 3L, 4L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 3L, 1L,?

? ? 2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 4L, 1L, 1L, 1L,?

? ? 2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 1L, 3L, 4L, 4L, 4L, 4L, 2L,?

? ? 2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 2L), .Label = c("D", "F",?

? ? "GK", "M"), class = "factor"), Height = c(NA, NA, NA, NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 151L, NA,?

? ? 154L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L, NA,?

? ? 147L, NA, NA, NA, NA, NA, 138L, 172L, NA, NA, 150L, NA, NA,?

? ? NA, NA, NA, NA, NA, 140L, 153L, NA, NA, NA, NA, NA, NA, NA,?

? ? 158L, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L), Weight = c(63,?

? ? 64, 36, 46, 67, 40, 25, 30, 36, 33, 61, 31, 29, 34, 47, 38,?

? ? 32, 44, 32, 32, 30, 34, 51, 34, 28, 27, 33, 31, 28, 44, 37,?

? ? 46, 26, 42, 32, 32, 43, 31, 72, 27, 30, 55, 53, 50, 51, 55,?

? ? 48.6, 49, 48, 64, 35, 32, 55, 32, 50, 61, 42, 33, 37, 45,?

? ? 45, 50, 36, 33, 49, 59, 42, 43, 35.1, 66.9, 52, 47, 40, 38,?

? ? 45, 53, 44, 54, 39, 62, 33, 53.8, 42, 46, 39, 48, 39, 54,?

? ? 40, 42.4, 50, 48, 46, 52, 58, 40, 46, 51, 54, 42), BMI = c(NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? 21.2, NA, 20.24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, 18.49, NA, 16.66, NA, NA, NA, NA, NA, 18.57, 22.61, NA,?

? ? NA, 17.77, NA, NA, NA, NA, NA, NA, NA, 16.84, 22.86, NA,?

? ? NA, NA, NA, NA, NA, NA, 16.9, NA, NA, NA, NA, NA, NA, NA,?

? ? NA, NA, 17.26), YoYo = c(80L, 80L, 160L, 160L, 160L, 160L,?

? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

? ? 160L, 160L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

? ? 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

? ? 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

? ? 200L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

? ? 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

? ? 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

? ? 240L, 240L, 240L, 240L)), .Names = c("Id", "Level", "AgeGr",?

"Position", "Height", "Weight", "BMI", "YoYo"), row.names = c(NA,?

100L), class = "data.frame")

On Mon, Apr 27, 2015 at 10:43 PM, John Kane <jrkrideau at inbox.com> wrote:

 Hi Josh,

 Just a sample? is usually? fine. As long as it cover a representative (must be time for dinner---I was going to type reprehensibe) sample of the data then something like dput(head(mydata, 100) ) works well.

 Kingston ON Canada

 -----Original Message-----
 From: joshuamichaeldixon at gmail.com

Sent: Mon, 27 Apr 2015 21:30:39 +0100
 To: lists at dewey.myzen.co.uk
 Subject: Re: [R] Help Interpreting Linear Mixed Model

 Apologies for my ignorance!

 Thierry - thank you for the reading.? I'll look into those ASAP!

 John - The data set I have is quite large, when using the dput() command I'm unsure if it actually fits the whole output into the console.? I can't scroll up far enough to see the actual command.? I can paste what is there if that may help?? The bottom line:?

 Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI", "YoYo"), class = "data.frame", row.names = c(NA, -9689L))

 Michael - Essentially, I'm looking for differences between "YoYo" outcome for "Positions", "Levels" and accounting for repeated measures using "Id" as a random factor.? So I was able to figure out points 2 and 3.

 I've searched for definitions of "Scaled residuals",?"Random effects",?"Fixed effects",?"Correlation of Fixed Effects".? However, I'm confused at the different interpretations I've found.? Or quite possibly, I'm just confused...? What should I be?looking?out for in these variables?

 I've tried to take my analysis smaller, and just look at specifics, to make it simpler.? Such as, comparing YoYo (outcome score) for a Premier_League (Level), 22 (AgeGr) F (Position) with a?Premier_League (Level), 22 (AgeGr) M (Position).? How do I convert these into a factors for analysis?

 Simple question maybe, but it's not when you can't find the answer!

 Thank you,

 Josh

 On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

 ? ? ? ? Dear Joshua

 ?It would also help if you told us what your scientific question was. At the moment we know what R commands you used and have seen the head of your dataset but not why you are doing it.

 ?I would summarise what you have given us as

 ?1 - most ID only occur once
 ?2 - goal keepers do worse than outfield players
 ?3 - older people (presumably in fact age is in years as a continuous variable) do better

 ?On 27/04/2015 12:42, John Kane wrote:

 ?John Kane
 ?Kingston ON Canada

 ? ? ? ? ?-----Original Message-----
 ?From: joshuamichaeldixon at gmail.com
 ?Sent: Mon, 27 Apr 2015 08:54:51 +0100
 ?To: thierry.onkelinx at inbo.be
 ?Subject: Re: [R] Help Interpreting Linear Mixed Model

 ?Hello Thierry,

 ?No, this isn't homework. Not that young unfortunately.

 ?A few years ago a friend of mine and her daughter were neck-in-neck on who got their Ph.D first. What's this "not that young" business?

 ?BTW, a better way to supply sample data is to use the dput() command.

 ?Do a dput(mydata), copy the results into the email and you have supplied us with an exact copy of your data.

 ?It is possible for many reasons that I will not read in your data, as you supplied it, in the format you have it in.? This can lead to real confusion.

 ? ? ? ? ?Josh

 ? ? ? ? ?On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
 ?wrote:

 ?Dear Josh,

 ?Is this homework? Because the list has a no homework policy.

 ?Best regards,

 ?ir. Thierry Onkelinx
 ?Instituut voor natuur- en bosonderzoek / Research Institute for Nature
 ?and Forest
 ?team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
 ?Kliniekstraat 25
 ?1070 Anderlecht
 ?Belgium

 ?To call in the statistician after the experiment is done may be no more
 ?than asking him to perform a post-mortem examination: he may be able to
 ?say what the experiment died of. ~ Sir Ronald Aylmer Fisher
 ?The plural of anecdote is not data. ~ Roger Brinner
 ?The combination of some data and an aching desire for an answer does not
 ?ensure that a reasonable answer can be extracted from a given body of
 ?data. ~ John Tukey

 ?2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:

 ? ? ? ? ?Hello!

 ?Very new to R (10 days), and I've run the linear mixed model, below.
 ?Attempting to interpret what it means...? What do I need to look for?
 ?Residuals, correlations of fixed effects?!

 ?How would I look at very specific interactions, such as PREMIER_LEAGUE
 ?(Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
 ?GK?

 ?For reference my data set looks like this:

 ?Id Level AgeGr? ?Position Height Weight BMI YoYo
 ?7451 CHAMPIONSHIP 14 M NA 63 NA 80
 ?148 PREMIER_LEAGUE 16 D NA 64 NA 80
 ?10393 CONFERENCE 10 D NA 36 NA 160
 ?10200 CHAMPIONSHIP 10 F NA 46 NA 160
 ?1961 LEAGUE_TWO 13 GK NA 67 NA 160
 ?10428 CHAMPIONSHIP 10 GK NA 40 NA 160
 ?10541 LEAGUE_ONE 10 F NA 25 NA 160
 ?10012 CHAMPIONSHIP 10 GK NA 30 NA 160
 ?9895 CHAMPIONSHIP 10 D NA 36 NA 160

 ?Many thanks in advance for time and help.? Really appreciate it.

 ?Josh

 ? ? ? ? ?summary(lmer(YoYo~AgeGr+Position+(1|Id)))

 ?Linear mixed model fit by REML ['lmerMod']
 ?Formula: YoYo ~ AgeGr + Position + (1 | Id)

 ?REML criterion at convergence: 125712.2

 ?Scaled residuals:
 ?? ? ?Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
 ?-3.4407 -0.5288 -0.0874? 0.4531? 4.8242

 ?Random effects:
 ?? Groups? ?Name? ? ? ? Variance Std.Dev.
 ?? Id? ? ? ?(Intercept) 15300? ? 123.7
 ?? Residual? ? ? ? ? ? ?16530? ? 128.6
 ?Number of obs: 9609, groups:? Id, 6071

 ?Fixed effects:
 ?? ? ? ? ? ? ? Estimate Std. Error t value
 ?(Intercept) -521.6985? ? 16.8392? -30.98
 ?AgeGr? ? ? ? ?62.6786? ? ?0.9783? ?64.07
 ?PositionD? ? 139.4682? ? ?7.8568? ?17.75
 ?PositionM? ? 141.2227? ? ?7.7072? ?18.32
 ?PositionF? ? 135.1241? ? ?8.1911? ?16.50

 ?Correlation of Fixed Effects:
 ?? ? ? ? ? ?(Intr) AgeGr? PostnD PostnM
 ?AgeGr? ? ?-0.910
 ?PositionD -0.359 -0.009
 ?PositionM -0.375? 0.001? 0.810
 ?PositionF -0.349 -0.003? 0.756? 0.782

 ? ? ? ? ?model=lmer(YoYo~AgeGr+Position+(1|Id))
 ?summary(glht(model,linfct=mcp(Position="Tukey")))

 ?? Simultaneous Tests for General Linear Hypotheses

 ?Multiple Comparisons of Means: Tukey Contrasts

 ?Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))

 ?Linear Hypotheses:
 ?? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
 ?D - GK == 0? 139.468? ? ? 7.857? 17.751? ?<1e-04 ***
 ?M - GK == 0? 141.223? ? ? 7.707? 18.323? ?<1e-04 ***
 ?F - GK == 0? 135.124? ? ? 8.191? 16.496? ?<1e-04 ***
 ?M - D == 0? ? ?1.754? ? ? 4.799? ?0.366? ? 0.983
 ?F - D == 0? ? -4.344? ? ? 5.616? -0.774? ? 0.862
 ?F - M == 0? ? -6.099? ? ? 5.267? -1.158? ? 0.645
 ?---
 ?Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 ?(Adjusted p values reported -- single-step method)

 ?? ? ? ? ?[[alternative HTML version deleted]]

 ?______________________________________________
 ?R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

?https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]
 ?PLEASE do read the posting guide
 ?http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]
 ?and provide commented, minimal, self-contained, reproducible code.

 ?? ? ? ? [[alternative HTML version deleted]]

 ?______________________________________________
 ?R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ?https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]
 ?PLEASE do read the posting guide
 ?http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]
 ?and provide commented, minimal, self-contained, reproducible code.

 ?____________________________________________________________
 ?FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 ?Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]] to find out more!

 ?______________________________________________
 ?R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ?https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]
 ?PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]
 ?and provide commented, minimal, self-contained, reproducible code.

 ?--
 ?Michael
 ?http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html] [http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html]]

 ____________________________________________________________
 Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.
 Check it out at http://mysecurelogon.com/manager [http://mysecurelogon.com/manager]

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From drjimlemon at gmail.com  Tue Apr 28 07:25:01 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 28 Apr 2015 15:25:01 +1000
Subject: [R] Distribution to use to calculate p values
In-Reply-To: <8E14F040-4167-4006-ABF9-E24CA4A19507@comcast.net>
References: <CAMeJHHBtAsBv8M+hzMbum7pF+nA5jvf1BSnfeB7buHVir+MEuw@mail.gmail.com>
	<CAMeJHHBgA=eXioH6K6KaNL8zwNt2sFRdS9RAzhtDdPj=twdJ4Q@mail.gmail.com>
	<8E14F040-4167-4006-ABF9-E24CA4A19507@comcast.net>
Message-ID: <CA+8X3fWTYbFQHKBHFdQ52ZkxTwSQyRr1g_O_06fLNUtJyB9fsQ@mail.gmail.com>

Hi Lalitha,
If you want to find a reasonable model distribution for your data, try
plotting the histogram of the variable you want to predict and compare
this to the density curves of the distributions that you think will
fit. So for example:

# plot a histogram of a uniform distribution
hist(seq(1,10,length.out=100))
# overlay a normal density function with the same mean
lines(seq(1,10,length.out=91),dnorm(seq(1,10,by=0.1),mean=5.5)*30)

Not a very good fit, but:

hist(rnorm(100,5.5))
lines(seq(1,10,length.out=91),dnorm(seq(1,10,by=0.1),mean=5.5)*90)

Much better. You can then perform a "goodness of fit" test if you need
it to justify your choice of distribution. In most cases, you will
have to find a "family" (link function) to use in a generalized linear
modeling (glm) test.

Another approach is to use a non-parametric test if one gives an
appropriate answer to your question.

Jim


On Tue, Apr 28, 2015 at 5:07 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Apr 27, 2015, at 10:50 AM, Lalitha Viswanathan wrote:
>
>> Hi
>> I have a dataset as below
>> Price Country Reliability Mileage Type Weight Disp. HP
>>
>>
>> 8895 USA 4 33 Small 2560 97 113
>> (Hundreds of rows)
>>
>> I am trying to find the best possible distribution to use, to find p-values
>> and compute which factors most influence efficiency.
>
> "Finding p-values" is a task that requires research questions. You obviously have some sort of meaning attached to the word "efficiency" but have not stated what it is. This appears to be a request for a statistical tutorial an a topic that has not been described. (And if this is course homework, then it is off-topic for r-help.)
>
>>
>> Any starting points for the functions I could use, or similar examples I
>> could follow, would be a start.
>> I am a relative novice at R having used it many years ago and am now
>> getting back to it.
>> So looking for pointers
>>
>> Thanks
>>
>>       [[alternative HTML version deleted]]
>
> The Posting Guide suggests that you create a small example in R code and describe your question more clearly (if it's not homework.)
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kevin511511 at gmail.com  Tue Apr 28 08:43:31 2015
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Tue, 28 Apr 2015 02:43:31 -0400
Subject: [R] invalid function value in 'nlm' optimizer
Message-ID: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>

Hi, R users,


I am using nlm function to get the MLE of parameter alpha and lambda from a
 parametric survival model (Weibull distribution). However, this message
always came out: ' invalid function value in 'nlm' optimizer'. Could anyone
help me? Code is

project<-read.table(file="C://data.txt", header=T, as.is=T)
names(project)
attach(project)

x<-time
delta<-ind


# -log likelihood
#alpha<-theta[1]
#lambda<-theta[2]
ln<-function(theta)
  {

 -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
}

#MLE
nlm(ln,theta<-c(1,1),hessian=TRUE)


Thanks!

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Apr 28 09:19:33 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 28 Apr 2015 00:19:33 -0700
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
Message-ID: <CACk-te1Amjwi-c2YMbK44u=kaOYiMSYZUhBZ3kRVWTXpgTmPdQ@mail.gmail.com>

Why are you doing this instead of using the survival package?

Bert

On Tuesday, April 28, 2015, Hanze Zhang <kevin511511 at gmail.com> wrote:

> Hi, R users,
>
>
> I am using nlm function to get the MLE of parameter alpha and lambda from a
>  parametric survival model (Weibull distribution). However, this message
> always came out: ' invalid function value in 'nlm' optimizer'. Could anyone
> help me? Code is
>
> project<-read.table(file="C://data.txt", header=T, as.is=T)
> names(project)
> attach(project)
>
> x<-time
> delta<-ind
>
>
> # -log likelihood
> #alpha<-theta[1]
> #lambda<-theta[2]
> ln<-function(theta)
>   {
>
>
>  -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
> }
>
> #MLE
> nlm(ln,theta<-c(1,1),hessian=TRUE)
>
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Apr 28 09:21:38 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 28 Apr 2015 00:21:38 -0700
Subject: [R] Fwd: Distribution to use to calculate p values
In-Reply-To: <CA+8X3fWTYbFQHKBHFdQ52ZkxTwSQyRr1g_O_06fLNUtJyB9fsQ@mail.gmail.com>
References: <CAMeJHHBtAsBv8M+hzMbum7pF+nA5jvf1BSnfeB7buHVir+MEuw@mail.gmail.com>
	<CAMeJHHBgA=eXioH6K6KaNL8zwNt2sFRdS9RAzhtDdPj=twdJ4Q@mail.gmail.com>
	<8E14F040-4167-4006-ABF9-E24CA4A19507@comcast.net>
	<CA+8X3fWTYbFQHKBHFdQ52ZkxTwSQyRr1g_O_06fLNUtJyB9fsQ@mail.gmail.com>
Message-ID: <CACk-te3qMGdymmdYNwZ-B8fpLqEY=8U=V_sCWvGg+w90nTr47g@mail.gmail.com>

... Realizing, of course, that after such data dredging, any subsequent
inference is highly biased.

Cheers,
Bert

On Tuesday, April 28, 2015, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Lalitha,
> If you want to find a reasonable model distribution for your data, try
> plotting the histogram of the variable you want to predict and compare
> this to the density curves of the distributions that you think will
> fit. So for example:
>
> # plot a histogram of a uniform distribution
> hist(seq(1,10,length.out=100))
> # overlay a normal density function with the same mean
> lines(seq(1,10,length.out=91),dnorm(seq(1,10,by=0.1),mean=5.5)*30)
>
> Not a very good fit, but:
>
> hist(rnorm(100,5.5))
> lines(seq(1,10,length.out=91),dnorm(seq(1,10,by=0.1),mean=5.5)*90)
>
> Much better. You can then perform a "goodness of fit" test if you need
> it to justify your choice of distribution. In most cases, you will
> have to find a "family" (link function) to use in a generalized linear
> modeling (glm) test.
>
> Another approach is to use a non-parametric test if one gives an
> appropriate answer to your question.
>
> Jim
>
>
> On Tue, Apr 28, 2015 at 5:07 AM, David Winsemius <dwinsemius at comcast.net
> <javascript:;>> wrote:
> >
> > On Apr 27, 2015, at 10:50 AM, Lalitha Viswanathan wrote:
> >
> >> Hi
> >> I have a dataset as below
> >> Price Country Reliability Mileage Type Weight Disp. HP
> >>
> >>
> >> 8895 USA 4 33 Small 2560 97 113
> >> (Hundreds of rows)
> >>
> >> I am trying to find the best possible distribution to use, to find
> p-values
> >> and compute which factors most influence efficiency.
> >
> > "Finding p-values" is a task that requires research questions. You
> obviously have some sort of meaning attached to the word "efficiency" but
> have not stated what it is. This appears to be a request for a statistical
> tutorial an a topic that has not been described. (And if this is course
> homework, then it is off-topic for r-help.)
> >
> >>
> >> Any starting points for the functions I could use, or similar examples I
> >> could follow, would be a start.
> >> I am a relative novice at R having used it many years ago and am now
> >> getting back to it.
> >> So looking for pointers
> >>
> >> Thanks
> >>
> >>       [[alternative HTML version deleted]]
> >
> > The Posting Guide suggests that you create a small example in R code and
> describe your question more clearly (if it's not homework.)
> >
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Tue Apr 28 09:40:45 2015
From: johnwasige at gmail.com (John Wasige)
Date: Tue, 28 Apr 2015 09:40:45 +0200
Subject: [R] Heatmap
Message-ID: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>

Dear all,

I need to make a heapmap of SPI results for a monthly timeseies of 30
years. Does anybody know to do it?

Thanks for your help

John

	[[alternative HTML version deleted]]


From aasdelat at aim.com  Tue Apr 28 10:35:56 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Tue, 28 Apr 2015 04:35:56 -0400
Subject: [R] Interactive maps
In-Reply-To: <1FBF7FEA-EF16-408E-9A53-CD443BD064EC@bigelow.org>
Message-ID: <14cff2b18e1-7c74-2b6b0@webprd-m10.mail.aol.com>

Thank you, Ben. I've just subscribed to R-sig-geo as you recommend. I'll post this staff there.
 

 

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Ben Tupper <btupper at bigelow.org>
To: Antonio Serrano <aasdelat at aim.com>
Cc: r-help <r-help at r-project.org>
Sent: Mon, Apr 27, 2015 7:59 pm
Subject: Re: [R] Interactive maps


Hi,

You may want to redirect your question to the R-sig-Geo mailing list:


https://stat.ethz.ch/mailman/listinfo/r-sig-geo

In the meantime, you
might consider writing to the 'rasterfile' format.  The 'rasterfile' format is
very well documented and is to read/write from R; I suspect it would easy for
you to write to this format from Fortran.  See the details
here:

http://cran.r-project.org/web/packages/raster/vignettes/rasterfile.pdf

Cheers,
Ben

On
Apr 27, 2015, at 11:55 AM, Antonio Serrano via R-help <r-help at r-project.org>
wrote:

> 
> 
> Ok.
> 
> 
> The point now is that I have the sources (in
Fortran) of the program that produces the graph with the map. And have to attach
the information about the xrange and yrange to this graph in order for them to
be read from R. Id est, I have to write: first longitude, first latitude, last
longitude, last latitude, and also, the "figure" coordinates of the bounding box
of the map in the figure.
> 
> If I produce the map in eps, I can open it as a
text file from the same fortran rogram, and modify the contents of the eps file
in order to put the coordinates information into it.
> 
> Then, once the
fortran program has ended, I convert the eps to png using ImageMagic, because
the EBImage library doesn't read eps, but png.
> 
> In order for the png to
contain the same properties as the eps, these have to be correctly defined in
the eps.
> 
> So, the question now is: how can I properly define properties in
a eps, so that these are preserved in the convertion to png?.
> 
> Perhaps
this is not for this forum, but I haven't found information about it in the
internet.
> 
> 
> 
> 
> 
> Antonio Serrano   
> aasdelat at aim.com   
>   
?   
> 
> 
> 
> 
> 
> 
> 
> 
> -----Original Message-----   
> From:
Jim Lemon <drjimlemon at gmail.com>   
> To: Antonio Serrano <aasdelat at aim.com>  

> Sent: Sun, Apr 26, 2015 1:03 am   
> Subject: Re: [R] Interactive maps  

> 
> 
> 
> Hi Antonio,
> If you mean the normalized figure coordinates
(i.e. from 0 to 1)
> then
> you want something like
> this:
> 
>
loc_convert<-function(n=1,xrange=c(0,1),yrange=c(0,1)) {
> 
>
plot_loc<-locator(n=n)
> plot_loc$x<-plot_loc$x/diff(xrange)+xrange[1]
> 
>
plot_loc$y<-plot_loc$y/diff(yrange)+yrange[1]
> return(plot$loc)
> }
> 
>
where
> xrange and yrange are the longitudes and latitudes respectively.
> 
>
Jim
> 
> 
> On
> Sun, Apr 26, 2015 at 1:09 AM, Antonio Serrano
<aasdelat at aim.com> wrote:
>> Thank
> you, Jim:
>> 
>>   I have tried your
suggestion and I get the following
> error:
>> 
>>  Error en
rasterImage(image = "map.eps",  :
>>   invalid color
> name 'map.eps'
>> 
>>
I have tried with three formats of the same image: svg,
> gif and eps, with
>>
the same result.
>> 
>> But I have found a possible better
> way to
accomplish this objective in the
>> following thread:
>> 
>
http://r.789695.n4.nabble.com/Loading-an-image-picture-png-jpeg-to-screen-td2244923.html
>>

>> 
> In short:
>> 
>> library(gridExtra)
>> library(EBImage)
>>
library(RGraphics)
>> 
> x <-
readImage("http://www.google.com/logos/teachersday09.gif")
>> g1 <-
>
ebimageGrob(x)
>> dev.new(width=g1$width/72, height=g1$height/72)
>> 
>
plot.new()
>> grid.draw(g1)
>> c=locator(n=1, type="n")
>> 
>> Then, when I
click
> on the map, I get the "figure" coordinates where I
>> clicked, and
still have to
> translate these to longitude-latitude.
>> 
>> And here comes
another question:
> How can I attach the first longitude, last
>> longitude,
fisrt latitude, last
> latitude, to a JPEG, PNG or TIFF graphic?.
>> These are
the formats supported by
> the EBImage package.
>> 
>> 
>> 
>> Antonio
Serrano
>> aasdelat at aim.com
>> 
> ?
>> 
>> 
>> -----Original
Message-----
>> From: Jim Lemon
> <drjimlemon at gmail.com>
>> To: Antonio
Serrano <aasdelat at aim.com>
>> Sent: Sat,
> Apr 25, 2015 8:36 am
>> Subject:
Re: [R] Interactive maps
>> 
>> Hi Antonio,
>> 
> Try the rasterImage
function.
>> 
>> Jim
>> 
>> 
>> On Sat, Apr 25, 2015 at
>> 4:19
> PM,
Antonio Serrano <aasdelat at aim.com> wrote:
>>> Thank you, Jim.
>>> 
>>> I
>>

> didn't know the existence of the locator() function. But I can see now
>>>
that
> I
>> don't know how to read a graphic image into R to work with
it.
>>> How can
> I read
>> a pre-exisiting image into R?.
>>> 
>>> Thanks
again
>>> 
>>> 
>>> 
> Antonio Serrano
>>> 
>> aasdelat at aim.com
>>>
?
>>> 
>>> 
>>> -----Original
> Message-----
>>> From: Jim Lemon
>>
<drjimlemon at gmail.com>
>>> To: Antonio
> Serrano <aasdelat at aim.com>
>>> Cc:
r-help
>> mailing list
> <r-help at r-project.org>
>>> Sent: Sat, Apr 25, 2015
5:47 am
>>> 
>> Subject: Re:
> [R] Interactive maps
>>> 
>>> Hi
Antonio,
>>> If you do create the map
>> in R,
> you can use
>>>
locator().
>>> 
>>> Jim
>>> 
>>> 
>>> On Sat, Apr 25, 2015 at
> 8:37
>>
AM, Antonio Serrano via
>>> R-help
>>> <r-help at r-project.org>
> wrote:
>>>>

>>>> 
>> Hello, all:
>>>> 
>>>>   I am new here,
>>> and have a
>
challenge to present some
>> graphical data to the user in a
>>>
convenient
>>> 
> way.
>>>> 
>>>>   The challenge
>> is to present a map to
the user which is
> coloured
>>> with the value of a
>> variable. Say for
example, temperature. This
> is a
>>> preexisting graph that I
>> can
generate in any format, including svg.
> I don't
>>> have
>>> to produce
it
>> using R.
>>>> 
>>>>   When the user clicks
> anywhere in the map,
the
>>> coordinates
>> (longitude and latitude) have to be
> passed to R so
that this, R,
>>> can
>>> look
>> for the values of other
> variables in
that location and make another
>>> graph
>>> 
>> with
> them.
>>>> 
>>>>  
Does anyubody know how could I accomplish
>> 
> this?.
>>>> 
>>>> 
>>>
Thanks in advance.
>>>> 
>>>> 
>>>> 
>>>> Antonio
> Serrano
>>>> 
>>
aasdelat at aim.com
>>>> ?
>>>> 
>>>> 
>>>> 
>>> [[alternative HTML
>
version
>> deleted]]
>>>> 
>>>> 
>>> 
>
______________________________________________
>>>> 
>>
R-help at r-project.org
> mailing
>>> list -- To UNSUBSCRIBE and more, see
>>>>

>>> 
>> 
> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read
the posting
>> 
> guide
>>> http://www.R-project.org/posting-guide.html
>>>>
and provide
> commented,
>> minimal,
>>> self-contained, reproducible
code.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
>
______________________________________________
> R-help at r-project.org mailing
list -- To UNSUBSCRIBE and more, see
>
https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal,
self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean
Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine
04544
http://www.bigelow.org











	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Tue Apr 28 11:18:00 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 28 Apr 2015 05:18:00 -0400
Subject: [R] Heatmap
In-Reply-To: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>
References: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>
Message-ID: <553F180F020000CB0012ADCA@smtp.medicine.umaryland.edu>

Look at the heatmap function 

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Apr 28, 2015, at 3:41 AM, John Wasige <johnwasige at gmail.com> wrote:
> 
> Dear all,
> 
> I need to make a heapmap of SPI results for a monthly timeseies of 30
> years. Does anybody know to do it?
> 
> Thanks for your help
> 
> John
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From murdoch.duncan at gmail.com  Tue Apr 28 12:40:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 06:40:10 -0400
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
Message-ID: <553F638A.8040005@gmail.com>

On 28/04/2015 2:43 AM, Hanze Zhang wrote:
> Hi, R users,
> 
> 
> I am using nlm function to get the MLE of parameter alpha and lambda from a
>  parametric survival model (Weibull distribution). However, this message
> always came out: ' invalid function value in 'nlm' optimizer'. Could anyone
> help me? Code is
> 
> project<-read.table(file="C://data.txt", header=T, as.is=T)
> names(project)
> attach(project)
> 
> x<-time
> delta<-ind
> 
> 
> # -log likelihood
> #alpha<-theta[1]
> #lambda<-theta[2]
> ln<-function(theta)
>   {
> 
>  -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
> }
> 
> #MLE
> nlm(ln,theta<-c(1,1),hessian=TRUE)

You are taking logs of parameters.  Probably the optimizer is setting
the parameters to negative values, and so the log returns NaN.

You can avoid this by testing your parameters on input, and always
returning a valid number.  There are lots of ways to do this: One
strategy is to return +Inf for invalid values; another is to move the
parameter to the nearest boundary, and apply a penalty according to how
far you moved it.  Or just take the absolute value of the parameter.  Or
reparametrize so that illegal values aren't possible.

Duncan Murdoch


From joseclaudio.faria at gmail.com  Tue Apr 28 13:04:55 2015
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Tue, 28 Apr 2015 08:04:55 -0300
Subject: [R] R 3.2.0 for Windows: error installing local zip packages using
	repos=NULL
Message-ID: <CAN+Emd-LdrQV+N3UXojpxZ3p=9R-5o5o2sATEQ2ax3x3cSXpoQ@mail.gmail.com>

Hello list,

I update from R 3.1.3 to R 3.2.0patched today.

For all packages I'm getting error message below

> install.packages('bpca_1.2-2.zip', repos=NULL)
Error in install.packages("bpca_1.2-2.zip", repos = NULL) :
  type == "both" cannot be used with 'repos = NULL'

Is it a bug?

Regards,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9966.9100 - VIVO
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 13:11:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 07:11:10 -0400
Subject: [R] R 3.2.0 for Windows: error installing local zip packages
 using repos=NULL
In-Reply-To: <CAN+Emd-LdrQV+N3UXojpxZ3p=9R-5o5o2sATEQ2ax3x3cSXpoQ@mail.gmail.com>
References: <CAN+Emd-LdrQV+N3UXojpxZ3p=9R-5o5o2sATEQ2ax3x3cSXpoQ@mail.gmail.com>
Message-ID: <553F6ACE.3040203@gmail.com>

On 28/04/2015 7:04 AM, Jose Claudio Faria wrote:
> Hello list,
> 
> I update from R 3.1.3 to R 3.2.0patched today.
> 
> For all packages I'm getting error message below
> 
>> install.packages('bpca_1.2-2.zip', repos=NULL)
> Error in install.packages("bpca_1.2-2.zip", repos = NULL) :
>   type == "both" cannot be used with 'repos = NULL'
> 
> Is it a bug?

The default for "type" has changed to "both", but it doesn't work with
repos=NULL.  You need to specify type="binary".

It would make sense for the repos=NULL case to guess the type based on
the filename.  I'll make that change.

Duncan Murdoch


From justinushize at aims.ac.za  Tue Apr 28 08:52:24 2015
From: justinushize at aims.ac.za (Justin USHIZE RUTIKANGA)
Date: Tue, 28 Apr 2015 08:52:24 +0200
Subject: [R] Limiting state probability for Markov chain
Message-ID: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>

Dear All,

I am trying to determine  the liming state probability  .
my_fun<-function(A,b){
for (j in 1:3){
x<-A;
while ((sum(x[j,]) ==1) )
{
  x <- x%*%x;
  print (x);
  if ( b%*%x==b)
  {
    break;
  }}}
}
A<-rbind(c(.5,.3,.2), c(.3,.3,.4),c(.1,.5,.4))
b <- matrix(data=c(1,0,0), nrow=1, ncol=3, byrow=FALSE)
my_fun(A,b)

I got the  following warning
1: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
2: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
3: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
4: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
5: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
6: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
7: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
8: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
9: In if (b %*% x == b) { :
  the condition has length > 1 and only the first element will be used
your help will be appreciate

Best Regard
Ushize Rutikanga Justin
Student at African Institute for Mathematical Sciences (AIMS) South Africa
E-mail:justinushize at aims.ac.za
Tel:+27717029144

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 14:30:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 08:30:47 -0400
Subject: [R] Limiting state probability for Markov chain
In-Reply-To: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>
References: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>
Message-ID: <553F7D77.4020105@gmail.com>

On 28/04/2015 2:52 AM, Justin USHIZE RUTIKANGA wrote:
> Dear All,
> 
> I am trying to determine  the liming state probability  .
> my_fun<-function(A,b){
> for (j in 1:3){
> x<-A;
> while ((sum(x[j,]) ==1) )
> {
>   x <- x%*%x;
>   print (x);
>   if ( b%*%x==b)
>   {
>     break;
>   }}}
> }
> A<-rbind(c(.5,.3,.2), c(.3,.3,.4),c(.1,.5,.4))
> b <- matrix(data=c(1,0,0), nrow=1, ncol=3, byrow=FALSE)
> my_fun(A,b)
> 
> I got the  following warning
> 1: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used

b has 3 elements; the if() statement wants just a single test.  You can use

if (all( b %*% x == b )) { ...

to avoid this problem, but it's always problematic to compare floating
point values for equality:  even if your Markov chain is exactly at the
limit, rounding may mean those two vectors are not equal.  You can do an
approximate test using the all.equal() function; see the help page
?all.equal for how to use it in an if() statement.

Duncan Murdoch

> 2: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 3: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 4: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 5: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 6: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 7: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 8: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 9: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> your help will be appreciate
> 
> Best Regard
> Ushize Rutikanga Justin
> Student at African Institute for Mathematical Sciences (AIMS) South Africa
> E-mail:justinushize at aims.ac.za
> Tel:+27717029144
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Tue Apr 28 14:31:56 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 28 Apr 2015 12:31:56 +0000
Subject: [R] Limiting state probability for Markov chain
In-Reply-To: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>
References: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2BD1C@SRVEXCHMBX.precheza.cz>

Hi

> x<-A%*%A
> b%*%x
     [,1] [,2] [,3]
[1,] 0.36 0.34  0.3
> b%*%x==b
      [,1]  [,2]  [,3]
[1,] FALSE FALSE FALSE

if function expects scalar as input

From help page:

cond = A length-one logical vector that is not NA. Conditions of length greater than one are accepted with a warning, but only the first element is used. Other types are coerced to logical if possible, ignoring any class.

So before asking a question it is always advisable to consult respective help page together results of actual commands

BTW your code resembles C+. If you wanted that R behaves as C+ you'd better to use C+ directly.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Justin
> USHIZE RUTIKANGA
> Sent: Tuesday, April 28, 2015 8:52 AM
> To: r-help at r-project.org
> Subject: [R] Limiting state probability for Markov chain
>
> Dear All,
>
> I am trying to determine  the liming state probability  .
> my_fun<-function(A,b){
> for (j in 1:3){
> x<-A;
> while ((sum(x[j,]) ==1) )
> {
>   x <- x%*%x;
>   print (x);
>   if ( b%*%x==b)
>   {
>     break;
>   }}}
> }
> A<-rbind(c(.5,.3,.2), c(.3,.3,.4),c(.1,.5,.4))
> b <- matrix(data=c(1,0,0), nrow=1, ncol=3, byrow=FALSE)
> my_fun(A,b)
>
> I got the  following warning
> 1: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 2: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 3: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 4: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 5: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 6: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 7: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 8: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> 9: In if (b %*% x == b) { :
>   the condition has length > 1 and only the first element will be used
> your help will be appreciate
>
> Best Regard
> Ushize Rutikanga Justin
> Student at African Institute for Mathematical Sciences (AIMS) South
> Africa
> E-mail:justinushize at aims.ac.za
> Tel:+27717029144
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Pradip.Muhuri at samhsa.hhs.gov  Tue Apr 28 15:48:33 2015
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Tue, 28 Apr 2015 13:48:33 +0000
Subject: [R] =?windows-1252?q?R_Error=3A_wrong_result_size_=28=2E=2E=2E=29?=
	=?windows-1252?q?=2C_expected_=2E=2E=2E_or_1=94?=
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C439116BB@PL-EMSMB20.ees.hhs.gov>

Hello,

I have written a user-defined function (myFunc below) with ten arguments. When calling the function, I get the following message: ?Error: wrong result size (816841), expected 52939 or 1?.
myFunc involves a data frame (named xanloid_set), which has 816841 rows.  R is correct to say that I was expecting only 52939 rows because of the filter() function.

These results are from the following code outside myFunc:
addmargins(table(xanloid_set$cohort_type))

NMPR_Cohort  OID_Cohort      Others         Sum
      52939      158192      605710      816841


How would I resolve the issue: error message from the muFunc?  Any hints would be appreciated.

Thanks,

Pradip Muhuri






#count_nmpr_oid_nmproid_by_year.R
setwd ("H:/R/cis_data")
library(dplyr)
library(knitr)
rm(list = ls())


myFunc <- function (newdata,
                    oridata,
                    cohort,
                    value,
                    xdate_to_int_time,
                    xflag,
                    idate,
                    xdate,
                    xdate_to_int_time_cat,
                    year) {

                    newdata  <-    filter (oridata, cohort== value ) %>%
                                   mutate(xdate_to_int_time = ifelse(xflag==1, (idate-xdate)/365.25, NA),
                                   xdate_to_int_time_cat = cut(xdate_to_int_time, breaks=c(0,1,2,3,4,5,6,7),
                                                                 include.lowest=TRUE, stringsAsFactors = FALSE) )
                    addmargins(with(newdata, table(year, xdate_to_int_time_cat)))
                                            }

load("xanloid_set.rdata")
myFunc (  newdata=nmpr_nmproid,
        oridata=xanloid_set,
        cohort=xanloid_set$cohort_type,
        value= "NMPR_Cohort",
        xdate_to_int_time=anl_to_int_time,
        xflag=xanloid_set$anlflag,
        idate=xanloid_set$intdate,
        xdate=xanloid_set$anldate,
        xdate_to_int_time_cat=xanloid_set$anl_to_int_time_cat,
        year=xanloid_set$xyear
        )

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Tue Apr 28 16:05:10 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 14:05:10 +0000 (UTC)
Subject: [R] package.skeleton warning
In-Reply-To: <1913600354.1884289.1427786439228.JavaMail.yahoo@mail.yahoo.com>
References: <1014342616.1870285.1427785920470.JavaMail.yahoo@mail.yahoo.com>
	<1913600354.1884289.1427786439228.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1675503641.5998716.1430229911011.JavaMail.yahoo@mail.yahoo.com>

 Hi,Why do I get this warning when I run package.skeleton() and how to solve this problem?
Warning messages:
1: In package.skeleton(name = "myPackage", code_files = "~/Desktop/myPkg/R/") :
? Invalid file name(s) for R code in ./myPackage/R:
? 'R'
?are now renamed to 'z<name>.R'
2: In file.rename(from = file.path(code_dir, wrong), to = file.path(code_dir,? :
? cannot rename file './myPackage/R/R' to './myPackage/R/zR.R', reason 'No such file or directory'
Thanks 
Carol

  

  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 16:48:36 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 10:48:36 -0400
Subject: [R] package.skeleton warning
In-Reply-To: <1675503641.5998716.1430229911011.JavaMail.yahoo@mail.yahoo.com>
References: <1014342616.1870285.1427785920470.JavaMail.yahoo@mail.yahoo.com>	<1913600354.1884289.1427786439228.JavaMail.yahoo@mail.yahoo.com>
	<1675503641.5998716.1430229911011.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553F9DC4.70307@gmail.com>

On 28/04/2015 10:05 AM, carol white via R-help wrote:
>   Hi,Why do I get this warning when I run package.skeleton() and how to solve this problem?
> Warning messages:
> 1: In package.skeleton(name = "myPackage", code_files = "~/Desktop/myPkg/R/") :
>    Invalid file name(s) for R code in ./myPackage/R:
>    'R'
>   are now renamed to 'z<name>.R'
> 2: In file.rename(from = file.path(code_dir, wrong), to = file.path(code_dir,  :
>    cannot rename file './myPackage/R/R' to './myPackage/R/zR.R', reason 'No such file or directory'
>

You are saying that your code is in a file called

"~/Desktop/myPkg/R/"

but you have no such file.  If you really do have your code already in some files, list them in the code_files argument, otherwise leave it blank.

Duncan Murdoch


From wht_crl at yahoo.com  Tue Apr 28 14:54:16 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 12:54:16 +0000 (UTC)
Subject: [R] reverse dep of a package
Message-ID: <992430600.5985746.1430225656532.JavaMail.yahoo@mail.yahoo.com>

Hi,How to cite reverse dependancies in the NAMESPACE file in building a package?
Regards,
Carol


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 17:02:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 11:02:33 -0400
Subject: [R] reverse dep of a package
In-Reply-To: <992430600.5985746.1430225656532.JavaMail.yahoo@mail.yahoo.com>
References: <992430600.5985746.1430225656532.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FA109.7010706@gmail.com>

On 28/04/2015 8:54 AM, carol white via R-help wrote:
> Hi,How to cite reverse dependancies in the NAMESPACE file in building a package?

That doesn't make sense.  How could you predict which packages will 
depend on yours?

Perhaps you mean something different by "reverse dependency".  The 
standard definition is that if B depends on A, then A is a dependency of 
B, and B is a reverse dependency of A.

Duncan Murdoch


From wht_crl at yahoo.com  Tue Apr 28 17:21:04 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 15:21:04 +0000 (UTC)
Subject: [R] package.skeleton warning
In-Reply-To: <553F9DC4.70307@gmail.com>
References: <553F9DC4.70307@gmail.com>
Message-ID: <1165466691.6077637.1430234464061.JavaMail.yahoo@mail.yahoo.com>

I have many code files so listing them will be long. When leave it empty, I get
package.skeleton(name = "myPackage", code_files = "")
Error in sys.source(cf, envir = environment) : '' is not an existing file
 
There should be an automatic way to source all code files instead of listing them. Even if I upload and have them as R objects, I shouldn't have to list them in the list arg.
Thanks 


     On Tuesday, April 28, 2015 4:48 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 10:05 AM, carol white via R-help wrote:
>? Hi,Why do I get this warning when I run package.skeleton() and how to solve this problem?
> Warning messages:
> 1: In package.skeleton(name = "myPackage", code_files = "~/Desktop/myPkg/R/") :
>? ? Invalid file name(s) for R code in ./myPackage/R:
>? ? 'R'
>? are now renamed to 'z<name>.R'
> 2: In file.rename(from = file.path(code_dir, wrong), to = file.path(code_dir,? :
>? ? cannot rename file './myPackage/R/R' to './myPackage/R/zR.R', reason 'No such file or directory'
>

You are saying that your code is in a file called

"~/Desktop/myPkg/R/"

but you have no such file.? If you really do have your code already in some files, list them in the code_files argument, otherwise leave it blank.

Duncan Murdoch



  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Apr 28 18:37:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 28 Apr 2015 09:37:43 -0700
Subject: [R] package.skeleton warning
In-Reply-To: <1165466691.6077637.1430234464061.JavaMail.yahoo@mail.yahoo.com>
References: <553F9DC4.70307@gmail.com>
	<1165466691.6077637.1430234464061.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1ABCE1BF-3BDA-45D9-9967-2D5E0AD54C6C@dcn.davis.CA.us>

You don't have to do it by hand. Use the list.files function to create the list of file names.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 28, 2015 8:21:04 AM PDT, carol white via R-help <r-help at r-project.org> wrote:
>I have many code files so listing them will be long. When leave it
>empty, I get
>package.skeleton(name = "myPackage", code_files = "")
>Error in sys.source(cf, envir = environment) : '' is not an existing
>file
> 
>There should be an automatic way to source all code files instead of
>listing them. Even if I upload and have them as R objects, I shouldn't
>have to list them in the list arg.
>Thanks 
>
>
>On Tuesday, April 28, 2015 4:48 PM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>   
>
> On 28/04/2015 10:05 AM, carol white via R-help wrote:
>>? Hi,Why do I get this warning when I run package.skeleton() and how
>to solve this problem?
>> Warning messages:
>> 1: In package.skeleton(name = "myPackage", code_files =
>"~/Desktop/myPkg/R/") :
>>? ? Invalid file name(s) for R code in ./myPackage/R:
>>? ? 'R'
>>? are now renamed to 'z<name>.R'
>> 2: In file.rename(from = file.path(code_dir, wrong), to =
>file.path(code_dir,? :
>>? ? cannot rename file './myPackage/R/R' to './myPackage/R/zR.R',
>reason 'No such file or directory'
>>
>
>You are saying that your code is in a file called
>
>"~/Desktop/myPkg/R/"
>
>but you have no such file.? If you really do have your code already in
>some files, list them in the code_files argument, otherwise leave it
>blank.
>
>Duncan Murdoch
>
>
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wht_crl at yahoo.com  Tue Apr 28 19:00:50 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 17:00:50 +0000 (UTC)
Subject: [R] cite publications in the package help file
Message-ID: <1885741710.6122078.1430240450450.JavaMail.yahoo@mail.yahoo.com>

To cite related publications, it seems that they can't be mentioned in? DESCRIPTION. Where to mention so that it appears on the 1st page of? the pdf help file and the package main web page? I'm not talking about what is specified in? inst/citation.

?Thanks,
Carol


	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Tue Apr 28 19:04:58 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 17:04:58 +0000 (UTC)
Subject: [R] reverse dep of a package
In-Reply-To: <553FA109.7010706@gmail.com>
References: <553FA109.7010706@gmail.com>
Message-ID: <51318866.6162021.1430240698017.JavaMail.yahoo@mail.yahoo.com>

yes, reverse dependency. All the reverse dependancies on the main web page of the packages are generated by CRAN?
Thanks
 


     On Tuesday, April 28, 2015 5:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 8:54 AM, carol white via R-help wrote:
> Hi,How to cite reverse dependancies in the NAMESPACE file in building a package?

That doesn't make sense.? How could you predict which packages will 
depend on yours?

Perhaps you mean something different by "reverse dependency".? The 
standard definition is that if B depends on A, then A is a dependency of 
B, and B is a reverse dependency of A.

Duncan Murdoch


  
	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Apr 28 19:34:26 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 28 Apr 2015 19:34:26 +0200
Subject: [R] reverse dep of a package
In-Reply-To: <51318866.6162021.1430240698017.JavaMail.yahoo@mail.yahoo.com>
References: <553FA109.7010706@gmail.com>
	<51318866.6162021.1430240698017.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FC4A2.3010004@statistik.tu-dortmund.de>



On 28.04.2015 19:04, carol white via R-help wrote:
> yes, reverse dependency. All the reverse dependancies on the main web page of the packages are generated by CRAN?

Yes, and updated once a new package depends on the one in question.

Best,
Uwe Ligges


> Thanks
>
>
>
>       On Tuesday, April 28, 2015 5:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>
>   On 28/04/2015 8:54 AM, carol white via R-help wrote:
>> Hi,How to cite reverse dependancies in the NAMESPACE file in building a package?
>
> That doesn't make sense.  How could you predict which packages will
> depend on yours?
>
> Perhaps you mean something different by "reverse dependency".  The
> standard definition is that if B depends on A, then A is a dependency of
> B, and B is a reverse dependency of A.
>
> Duncan Murdoch
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Tue Apr 28 19:37:57 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 13:37:57 -0400
Subject: [R] cite publications in the package help file
In-Reply-To: <1885741710.6122078.1430240450450.JavaMail.yahoo@mail.yahoo.com>
References: <1885741710.6122078.1430240450450.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FC575.4080706@gmail.com>

On 28/04/2015 1:00 PM, carol white via R-help wrote:
> To cite related publications, it seems that they can't be mentioned in  DESCRIPTION. Where to mention so that it appears on the 1st page of  the pdf help file and the package main web page? I'm not talking about what is specified in  inst/citation.

The package help file (e.g. foo-package.Rd for package "foo") will be
displayed first in the PDF, and is the first entry linked in the help
page index for the package.

I don't know what page you mean as the "package main web page".

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Apr 28 19:38:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 13:38:19 -0400
Subject: [R] reverse dep of a package
In-Reply-To: <51318866.6162021.1430240698017.JavaMail.yahoo@mail.yahoo.com>
References: <553FA109.7010706@gmail.com>
	<51318866.6162021.1430240698017.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FC58B.3070406@gmail.com>

On 28/04/2015 1:04 PM, carol white wrote:
> yes, reverse dependency. All the reverse dependancies on the main web
> page of the packages are generated by CRAN?

Yes.

Duncan Murdoch

> 
> Thanks
> 
> 
> 
> On Tuesday, April 28, 2015 5:02 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 28/04/2015 8:54 AM, carol white via R-help wrote:
> 
>> Hi,How to cite reverse dependancies in the NAMESPACE file in building
> a package?
> 
> 
> That doesn't make sense.  How could you predict which packages will
> depend on yours?
> 
> Perhaps you mean something different by "reverse dependency".  The
> standard definition is that if B depends on A, then A is a dependency of
> B, and B is a reverse dependency of A.
> 
> Duncan Murdoch
> 
> 
>


From philippe.janssen at irstea.fr  Tue Apr 28 17:04:17 2015
From: philippe.janssen at irstea.fr (Janssen Philippe)
Date: Tue, 28 Apr 2015 17:04:17 +0200
Subject: [R] Inconsistent results between CAP (capscale) and RDA
Message-ID: <3CB901080554B04881D30F111F62D93004ED976D@nadia.grenoble.cemagref.fr>

Hello everyone,

 

I have inconsistent results using vegan's capscale() and rda() on a hellinger distance matrix, based on presence/absence data matrix of 192 plants species (columns) x 70 sites (rows). 

HellingerFloreDist <-dist(decostand(flore[12:204], method="hellinger"))

 

I first wanted to perform a Canonical Analysis of Principal coordinates (CAP) using capscale() function. However, based on Jari Oksanen comment, i.e. "Constrained Analysis of Principal Coordinates (CAP) is an ordination method similar to Redundancy Analysis (rda)... If called with Euclidean distance, the results are identical to rda, but capscale will be much more inefficient.", I decided to perform RDA using rda().

 

###CAP analysis

CAP<-capscale(HellingerFloreDist~ancien+mature+interact, data=data)

anova(CAP) #Test of the significance of the analysis

anova(CAP, by="axis", perm.max=999) #test axes for significance 

anova(CAP, by="terms", permu=999) #test environment variables for significance 

RsquareAdj(CAP)

summary(CAP)

 

###RDA analysis

RDA<-rda(flore.hellinger~ancien+mature+interact, data=data)

plot(RDA)

anova(RDA) #Test of the significance of the analysis

anova(RDA, by="axis", perm.max=999) #test axes for significance 

anova(RDA, by="terms", permu=999) #test environment variables for significance 

RsquareAdj(RDA)

summary(RDA)

 

However, I was quite surprised by the results, i.e. the difference between the total inertia of CAP and RDA. 

 

Results from CAP (capscale) :

Partitioning of squared Euclidean distance:
              Inertia Proportion
Total          35.957    1.00000
Constrained     2.052    0.05706
Unconstrained  33.905    0.94294

 

Results from RDA :

Partitioning of variance:
              Inertia Proportion
Total          1.5384    1.00000
Constrained    0.1096    0.07124
Unconstrained  1.4289    0.92876

 

Searching all day long for an explanation, I still don't understand those results.

 

Any explanation would be greatly appreciated.

 

Thanks in advance.

 

Philippe JANSSEN

Doctorant - UR Ecosyst?mes Montagnards 

Irstea - Centre de Grenoble 

+33 (0)4 76 76 28 79

Philippe.janssen @irstea.fr

www.irstea.fr <http://www.irstea.fr/> 

 

 

 


	[[alternative HTML version deleted]]


From m.kofler at aew.eu  Tue Apr 28 17:11:02 2015
From: m.kofler at aew.eu (randomness)
Date: Tue, 28 Apr 2015 08:11:02 -0700 (PDT)
Subject: [R] Forecasting prices
Message-ID: <1430233862520-4706535.post@n4.nabble.com>

Hi,
apologies in advance for the generic question but I would highly appreciate
if someone pointed me in the right direction.
My challenge: I need to forecast Prices (Gas & Electricity Spot). Both gas
and electricity Show Autocorrelative and seasonal (hourly, daily, monthly)
behaviour. And there are explaining variables, of which I have forecasts out
of Reuters (temp, production etc). 

I have looked at dynamic linear Regression and neural Networks so far. It
would be great if someone can provide any Input, which model they would
suggest using. I got several conflicting opinions so far, which is of course
suboptimal as I would love to Focus on one subject. Of course if you can
suggest any literature or even have some code I would be very grateful.

Many thanks!

Markus



--
View this message in context: http://r.789695.n4.nabble.com/Forecasting-prices-tp4706535.html
Sent from the R help mailing list archive at Nabble.com.


From ghada.f.mm at gmail.com  Tue Apr 28 19:39:23 2015
From: ghada.f.mm at gmail.com (Ghada Almousa)
Date: Tue, 28 Apr 2015 20:39:23 +0300
Subject: [R] please help me in r
Message-ID: <CADG8gkuQdtMBws3WLRReHqOyAmhNnJ4H21=R8uNr9gUr3pJ7NA@mail.gmail.com>

Hello dears

I using (R tool) in my project
and I want to compare the results betwen k-mean cluster ,Hierarchical
cluster and EM cluster
  I use cluster.stats() it's work on k-mean cluster and hrarichal cluster
but not work in EM

Hello Dears
 I Use R tool in my project
I want to do comparison of the results between the k-mean cluster
,Hierarchical cluster and EM cluster
   I use cluster.stats () function that it is working on a the k-mean
cluster ,Hierarchical cluster  But do not work in EM
mydata<-(data)
my <-data.matrix(mydata)
d<-dist(as.matrix(my
 library(mclust)
m <- Mclust(d, G =2)
cluster.stats(d, m
Error in max(clustering) : invalid 'type' (list) of argument

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Tue Apr 28 20:28:21 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 18:28:21 +0000 (UTC)
Subject: [R] cite publications in the package help file
In-Reply-To: <553FC575.4080706@gmail.com>
References: <553FC575.4080706@gmail.com>
Message-ID: <1326055155.6195920.1430245701528.JavaMail.yahoo@mail.yahoo.com>

the main web page is meant the page when a package is accessed on CRAN. So is it possible on this page that the content of DESCRIPTION is displayed to display the related publications and also put the related publications so that they appear on the help pdf file?
 


     On Tuesday, April 28, 2015 7:37 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 1:00 PM, carol white via R-help wrote:
> To cite related publications, it seems that they can't be mentioned in? DESCRIPTION. Where to mention so that it appears on the 1st page of? the pdf help file and the package main web page? I'm not talking about what is specified in? inst/citation.

The package help file (e.g. foo-package.Rd for package "foo") will be
displayed first in the PDF, and is the first entry linked in the help
page index for the package.

I don't know what page you mean as the "package main web page".

Duncan Murdoch


  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Apr 28 20:34:16 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 28 Apr 2015 11:34:16 -0700
Subject: [R] Forecasting prices
In-Reply-To: <1430233862520-4706535.post@n4.nabble.com>
References: <1430233862520-4706535.post@n4.nabble.com>
Message-ID: <0D6B3C13-084C-460E-9D3E-23A2263066CE@dcn.davis.CA.us>

This is off topic here. You might try stats.stack exchange.com.

Be warned that if someone tells you to study only one method they are probably misleading you (perhaps unintentionally) because every method has the potential to be wrong in some way.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 28, 2015 8:11:02 AM PDT, randomness <m.kofler at aew.eu> wrote:
>Hi,
>apologies in advance for the generic question but I would highly
>appreciate
>if someone pointed me in the right direction.
>My challenge: I need to forecast Prices (Gas & Electricity Spot). Both
>gas
>and electricity Show Autocorrelative and seasonal (hourly, daily,
>monthly)
>behaviour. And there are explaining variables, of which I have
>forecasts out
>of Reuters (temp, production etc). 
>
>I have looked at dynamic linear Regression and neural Networks so far.
>It
>would be great if someone can provide any Input, which model they would
>suggest using. I got several conflicting opinions so far, which is of
>course
>suboptimal as I would love to Focus on one subject. Of course if you
>can
>suggest any literature or even have some code I would be very grateful.
>
>Many thanks!
>
>Markus
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Forecasting-prices-tp4706535.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wht_crl at yahoo.com  Tue Apr 28 20:52:22 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 28 Apr 2015 18:52:22 +0000 (UTC)
Subject: [R] cite publications in the package help file
In-Reply-To: <553FC575.4080706@gmail.com>
References: <553FC575.4080706@gmail.com>
Message-ID: <262905476.6217141.1430247142227.JavaMail.yahoo@mail.yahoo.com>

an example of a package main web page on CRANhttp://cran.r-project.org/web/packages/A3/index.html
and the help pdf filehttp://cran.r-project.org/web/packages/A3/A3.pdf
Regards, 



     On Tuesday, April 28, 2015 7:37 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 1:00 PM, carol white via R-help wrote:
> To cite related publications, it seems that they can't be mentioned in? DESCRIPTION. Where to mention so that it appears on the 1st page of? the pdf help file and the package main web page? I'm not talking about what is specified in? inst/citation.

The package help file (e.g. foo-package.Rd for package "foo") will be
displayed first in the PDF, and is the first entry linked in the help
page index for the package.

I don't know what page you mean as the "package main web page".

Duncan Murdoch


  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 28 20:59:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Apr 2015 14:59:19 -0400
Subject: [R] cite publications in the package help file
In-Reply-To: <1326055155.6195920.1430245701528.JavaMail.yahoo@mail.yahoo.com>
References: <553FC575.4080706@gmail.com>
	<1326055155.6195920.1430245701528.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FD887.60207@gmail.com>

On 28/04/2015 2:28 PM, carol white wrote:
> the main web page is meant the page when a package is accessed on CRAN.
> So is it possible on this page that the content of DESCRIPTION is
> displayed to display the related publications and also put the related
> publications so that they appear on the help pdf file?

That page is produced by CRAN.  The text at the top is the
"Description:" field from your DESCRIPTION file, so you could put text
about other publications there, but it needs to be just one paragraph,
so a reference list wouldn't be appropriate.  Adding a sentence like
"See the 'foo' vignette for related references." seems reasonable.
(Or you  could refer to the reference manual, or a help page, etc.)

Duncan Murdoch

> 
> 
> 
> On Tuesday, April 28, 2015 7:37 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 28/04/2015 1:00 PM, carol white via R-help wrote:
> 
>> To cite related publications, it seems that they can't be mentioned
> in  DESCRIPTION. Where to mention so that it appears on the 1st page of 
> the pdf help file and the package main web page? I'm not talking about
> what is specified in  inst/citation.
> 
> 
> The package help file (e.g. foo-package.Rd for package "foo") will be
> displayed first in the PDF, and is the first entry linked in the help
> page index for the package.
> 
> I don't know what page you mean as the "package main web page".
> 
> Duncan Murdoch
> 
> 
>


From wzhang01 at gmail.com  Tue Apr 28 21:20:23 2015
From: wzhang01 at gmail.com (W Z)
Date: Tue, 28 Apr 2015 14:20:23 -0500
Subject: [R] Subsetting from pareto distribution
Message-ID: <CAAVHDWgTcV=PEmPk-Ttstnin6qHeM0euNsy4=6xZA3p3Vm+dNw@mail.gmail.com>

I have a dataset of 20k records heavily right skewed as pareto
distribution, I'd like to pull 1k subset of it with same distribution, any
R package would do that?

Thanks.

	[[alternative HTML version deleted]]


From dafemlions at yahoo.co.uk  Tue Apr 28 21:32:30 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Tue, 28 Apr 2015 19:32:30 +0000 (UTC)
Subject: [R] error in running optimx
Message-ID: <876084663.9404451.1430249550970.JavaMail.yahoo@mail.yahoo.com>

Hello,I tried installing optimx and got a confirmation that it was installed. However, anytime I call for it, I received the following error message
> library("optimx", lib.loc="~/R/win-library/3.1")Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :?? there is no package called ?quadprog?In addition: Warning message:package ?optimx? was built under R version 3.1.3?Error: package or namespace load failed for ?optimx?
When I go ahead to run my code, I have the following error message:
Error: could not find function "optimx"

How do I go about solving this issue.
Thanks.Olufemi
?

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Apr 28 21:43:55 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 28 Apr 2015 20:43:55 +0100
Subject: [R] error in running optimx
In-Reply-To: <876084663.9404451.1430249550970.JavaMail.yahoo@mail.yahoo.com>
References: <876084663.9404451.1430249550970.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <553FE2FB.5070706@sapo.pt>

Hello,

The error message is quite clear, you must also install package 'quadprog'.

Hope this helps,

Rui Barradas

Em 28-04-2015 20:32, Olufemi Bolarinwa escreveu:
> Hello,I tried installing optimx and got a confirmation that it was installed. However, anytime I call for it, I received the following error message
>> library("optimx", lib.loc="~/R/win-library/3.1")Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :   there is no package called ?quadprog?In addition: Warning message:package ?optimx? was built under R version 3.1.3 Error: package or namespace load failed for ?optimx?
> When I go ahead to run my code, I have the following error message:
> Error: could not find function "optimx"
>
> How do I go about solving this issue.
> Thanks.Olufemi
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Tue Apr 28 21:49:48 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Apr 2015 12:49:48 -0700
Subject: [R] Subsetting from pareto distribution
In-Reply-To: <CAAVHDWgTcV=PEmPk-Ttstnin6qHeM0euNsy4=6xZA3p3Vm+dNw@mail.gmail.com>
References: <CAAVHDWgTcV=PEmPk-Ttstnin6qHeM0euNsy4=6xZA3p3Vm+dNw@mail.gmail.com>
Message-ID: <B62DDA17-8A98-44CA-8385-4F3A7710A924@comcast.net>


On Apr 28, 2015, at 12:20 PM, W Z wrote:

> I have a dataset of 20k records heavily right skewed as pareto
> distribution, I'd like to pull 1k subset of it with same distribution, any
> R package would do that?

Why not just:

 subdat <- dat[sample( nrow(dat), 1000), ] # if "dataset" is a dataframe

Or:

subdat <- dat[sample( length(dat), 1000) ] # if "dataset" is a vector


> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]

Do read the posting guide and the documentation for your mail client and learn how to post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Apr 28 22:15:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Apr 2015 13:15:33 -0700
Subject: [R] error in running optimx
In-Reply-To: <553FE2FB.5070706@sapo.pt>
References: <876084663.9404451.1430249550970.JavaMail.yahoo@mail.yahoo.com>
	<553FE2FB.5070706@sapo.pt>
Message-ID: <AA230DAD-AE3B-4AA2-96B8-9B9BD1B614F7@comcast.net>


On Apr 28, 2015, at 12:43 PM, Rui Barradas wrote:

> Hello,
> 
> The error message is quite clear, you must also install package 'quadprog'.

The 'quadprog' pkg is not listed as a dependency or even as 'suggested' and there is no mention of 'quadprog' in the NEWS file, nor does a search of the 'demos' code for a call to load "quadprog" produce a hit, and there is no mention of quadprog in the NAMESPACE file,  so the message while "clear" can still be considered "quite unexpected".

-- 
David.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 28-04-2015 20:32, Olufemi Bolarinwa escreveu:
>> Hello,I tried installing optimx and got a confirmation that it was installed. However, anytime I call for it, I received the following error message
>>> library("optimx", lib.loc="~/R/win-library/3.1")Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :   there is no package called ?quadprog?In addition: Warning message:package ?optimx? was built under R version 3.1.3 Error: package or namespace load failed for ?optimx?
>> When I go ahead to run my code, I have the following error message:
>> Error: could not find function "optimx"
>> 
>> How do I go about solving this issue.
>> Thanks.Olufemi
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From joshuamichaeldixon at gmail.com  Tue Apr 28 22:25:15 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Tue, 28 Apr 2015 21:25:15 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <F28501AEC71.0000113Ejrkrideau@inbox.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<caokekbjmp8hrs8tpfxvzxtsevrwav_jmjn7hngb3n18=4jjqga@mail.gmail.com>
	<f0739ac4af7.00000e24jrkrideau@inbox.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<CAOkeKB+7SYL7+VLZQak-Mf4JAimRTJK=u7tsz1juFwK23eY6og@mail.gmail.com>
	<F28501AEC71.0000113Ejrkrideau@inbox.com>
Message-ID: <CAOkeKB+-VQbrapCiS0isTUZxXhZwY5XFtFBgpzqFj0oSMp=x-Q@mail.gmail.com>

*John* -  Lot's of missing data for height unfortunately.  Which is needed
for BMI calculation.

How would I look compare very specific parts of the data, i.e. comparing
YoYo outcomes between "F" and "M" position that are both in the
PREMIER_LEAGUE Level?

Still can't figure it out!

Josh

On Tue, Apr 28, 2015 at 2:39 AM, John Kane <jrkrideau at inbox.com> wrote:

>
> Looks great.  How come so many NA's in Height and BMI? Just no data
> available?
>
>  str(dat1)
> 'data.frame':   100 obs. of  8 variables:
>  $ Id      : int  7451 148 10393 10200 1961 10428 10541 10012 9895 10626
> ...
>  $ Level   : Factor w/ 5 levels "CHAMPIONSHIP",..: 1 1 1 1 1 1 1 1 1 1 ...
>  $ AgeGr   : int  14 16 10 10 13 10 10 10 10 10 ...
>  $ Position: Factor w/ 4 levels "D","F","GK","M": 4 1 1 2 3 3 2 3 1 1 ...
>  $ Height  : int  NA NA NA NA NA NA NA NA NA NA ...
>  $ Weight  : num  63 64 36 46 67 40 25 30 36 33 ...
>  $ BMI     : num  NA NA NA NA NA NA NA NA NA NA ...
>  $ YoYo    : int  80 80 160 160 160 160 160 160 160 160 ...
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: joshuamichaeldixon at gmail.com
> Sent: Mon, 27 Apr 2015 23:35:13 +0100
> To: jrkrideau at inbox.com
> Subject: Re: [R] Help Interpreting Linear Mixed Model
>
> Thanks John!
>
> This ok?
>
> > dput(head(data, 100))
>
> structure(list(Id = c(7451L, 148L, 10393L, 10200L, 1961L, 10428L,
>
> 10541L, 10012L, 9895L, 10626L, 1151L, 8775L, 10083L, 6217L, 90L,
>
> 10168L, 10291L, 8549L, 3451L, 10003L, 5907L, 10136L, 6182L, 6315L,
>
> 10015L, 9956L, 2040L, 4710L, 10747L, 6787L, 1222L, 10757L, 2892L,
>
> 117L, 10328L, 10503L, 768L, 2979L, 1961L, 10520L, 10498L, 3018L,
>
> 10335L, 2448L, 9027L, 362L, 8499L, 10603L, 9489L, 2124L, 707L,
>
> 8501L, 4908L, 9905L, 3000L, 2819L, 9973L, 10550L, 9921L, 10639L,
>
> 8771L, 10121L, 32L, 9935L, 9299L, 3246L, 682L, 10325L, 6741L,
>
> 3295L, 5270L, 727L, 8500L, 50L, 4705L, 3018L, 787L, 2953L, 1391L,
>
> 3682L, 7974L, 5023L, 652L, 727L, 679L, 10212L, 9488L, 9987L,
>
> 10039L, 5025L, 250L, 2539L, 787L, 3000L, 1151L, 8946L, 6177L,
>
> 3296L, 250L, 498L), Level = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
> c("CHAMPIONSHIP",
>
> "CONFERENCE", "LEAGUE_ONE", "LEAGUE_TWO", "PREMIER_LEAGUE"), class =
> "factor"),
>
>     AgeGr = c(14L, 16L, 10L, 10L, 13L, 10L, 10L, 10L, 10L, 10L,
>
>     14L, 10L, 10L, 10L, 12L, 10L, 10L, 12L, 10L, 10L, 10L, 10L,
>
>     12L, 10L, 10L, 10L, 10L, 10L, 10L, 15L, 10L, 10L, 10L, 12L,
>
>     10L, 10L, 13L, 10L, 13L, 11L, 11L, 13L, 12L, 11L, 12L, 14L,
>
>     13L, 13L, 13L, 13L, 12L, 11L, 15L, 11L, 14L, 13L, 11L, 11L,
>
>     11L, 12L, 14L, 12L, 13L, 11L, 13L, 15L, 11L, 13L, 13L, 13L,
>
>     14L, 13L, 13L, 12L, 13L, 13L, 13L, 14L, 12L, 14L, 13L, 13L,
>
>     13L, 13L, 13L, 12L, 13L, 14L, 13L, 14L, 13L, 14L, 13L, 14L,
>
>     14L, 13L, 14L, 13L, 13L, 13L), Position = structure(c(4L,
>
>     1L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 4L, 3L, 2L, 3L,
>
>     4L, 3L, 4L, 2L, 4L, 2L, 3L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 4L,
>
>     2L, 1L, 4L, 1L, 1L, 2L, 4L, 3L, 1L, 4L, 1L, 2L, 3L, 3L, 1L,
>
>     1L, 3L, 1L, 3L, 4L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 3L, 1L,
>
>     2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 4L, 1L, 1L, 1L,
>
>     2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 1L, 3L, 4L, 4L, 4L, 4L, 2L,
>
>     2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 2L), .Label = c("D", "F",
>
>     "GK", "M"), class = "factor"), Height = c(NA, NA, NA, NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 151L, NA,
>
>     154L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L, NA,
>
>     147L, NA, NA, NA, NA, NA, 138L, 172L, NA, NA, 150L, NA, NA,
>
>     NA, NA, NA, NA, NA, 140L, 153L, NA, NA, NA, NA, NA, NA, NA,
>
>     158L, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L), Weight = c(63,
>
>     64, 36, 46, 67, 40, 25, 30, 36, 33, 61, 31, 29, 34, 47, 38,
>
>     32, 44, 32, 32, 30, 34, 51, 34, 28, 27, 33, 31, 28, 44, 37,
>
>     46, 26, 42, 32, 32, 43, 31, 72, 27, 30, 55, 53, 50, 51, 55,
>
>     48.6, 49, 48, 64, 35, 32, 55, 32, 50, 61, 42, 33, 37, 45,
>
>     45, 50, 36, 33, 49, 59, 42, 43, 35.1, 66.9, 52, 47, 40, 38,
>
>     45, 53, 44, 54, 39, 62, 33, 53.8, 42, 46, 39, 48, 39, 54,
>
>     40, 42.4, 50, 48, 46, 52, 58, 40, 46, 51, 54, 42), BMI = c(NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     21.2, NA, 20.24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, 18.49, NA, 16.66, NA, NA, NA, NA, NA, 18.57, 22.61, NA,
>
>     NA, 17.77, NA, NA, NA, NA, NA, NA, NA, 16.84, 22.86, NA,
>
>     NA, NA, NA, NA, NA, NA, 16.9, NA, NA, NA, NA, NA, NA, NA,
>
>     NA, NA, 17.26), YoYo = c(80L, 80L, 160L, 160L, 160L, 160L,
>
>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>
>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>
>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>
>     160L, 160L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>
>     200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>
>     200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>
>     200L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>
>     240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>
>     240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>
>     240L, 240L, 240L, 240L)), .Names = c("Id", "Level", "AgeGr",
>
> "Position", "Height", "Weight", "BMI", "YoYo"), row.names = c(NA,
>
> 100L), class = "data.frame")
>
> On Mon, Apr 27, 2015 at 10:43 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>  Hi Josh,
>
>  Just a sample  is usually  fine. As long as it cover a representative
> (must be time for dinner---I was going to type reprehensibe) sample of the
> data then something like dput(head(mydata, 100) ) works well.
>
>  Kingston ON Canada
>
>  -----Original Message-----
>  From: joshuamichaeldixon at gmail.com
>
> Sent: Mon, 27 Apr 2015 21:30:39 +0100
>  To: lists at dewey.myzen.co.uk
>  Subject: Re: [R] Help Interpreting Linear Mixed Model
>
>  Apologies for my ignorance!
>
>  Thierry - thank you for the reading.  I'll look into those ASAP!
>
>  John - The data set I have is quite large, when using the dput() command
> I'm unsure if it actually fits the whole output into the console.  I can't
> scroll up far enough to see the actual command.  I can paste what is there
> if that may help?  The bottom line:
>
>  Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI",
> "YoYo"), class = "data.frame", row.names = c(NA, -9689L))
>
>  Michael - Essentially, I'm looking for differences between "YoYo" outcome
> for "Positions", "Levels" and accounting for repeated measures using "Id"
> as a random factor.  So I was able to figure out points 2 and 3.
>
>  I've searched for definitions of "Scaled residuals", "Random
> effects", "Fixed effects", "Correlation of Fixed Effects".  However, I'm
> confused at the different interpretations I've found.  Or quite possibly,
> I'm just confused...  What should I be looking out for in these variables?
>
>  I've tried to take my analysis smaller, and just look at specifics, to
> make it simpler.  Such as, comparing YoYo (outcome score) for a
> Premier_League (Level), 22 (AgeGr) F (Position) with a Premier_League
> (Level), 22 (AgeGr) M (Position).  How do I convert these into a factors
> for analysis?
>
>  Simple question maybe, but it's not when you can't find the answer!
>
>  Thank you,
>
>  Josh
>
>  On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>
>          Dear Joshua
>
>   It would also help if you told us what your scientific question was. At
> the moment we know what R commands you used and have seen the head of your
> dataset but not why you are doing it.
>
>   I would summarise what you have given us as
>
>   1 - most ID only occur once
>   2 - goal keepers do worse than outfield players
>   3 - older people (presumably in fact age is in years as a continuous
> variable) do better
>
>   On 27/04/2015 12:42, John Kane wrote:
>
>   John Kane
>   Kingston ON Canada
>
>           -----Original Message-----
>   From: joshuamichaeldixon at gmail.com
>   Sent: Mon, 27 Apr 2015 08:54:51 +0100
>   To: thierry.onkelinx at inbo.be
>   Subject: Re: [R] Help Interpreting Linear Mixed Model
>
>   Hello Thierry,
>
>   No, this isn't homework. Not that young unfortunately.
>
>   A few years ago a friend of mine and her daughter were neck-in-neck on
> who got their Ph.D first. What's this "not that young" business?
>
>   BTW, a better way to supply sample data is to use the dput() command.
>
>   Do a dput(mydata), copy the results into the email and you have supplied
> us with an exact copy of your data.
>
>   It is possible for many reasons that I will not read in your data, as
> you supplied it, in the format you have it in.  This can lead to real
> confusion.
>
>           Josh
>
>           On 27 Apr 2015, at 08:06, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
>   wrote:
>
>   Dear Josh,
>
>   Is this homework? Because the list has a no homework policy.
>
>   Best regards,
>
>   ir. Thierry Onkelinx
>   Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>   and Forest
>   team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>   Kliniekstraat 25
>   1070 Anderlecht
>   Belgium
>
>   To call in the statistician after the experiment is done may be no more
>   than asking him to perform a post-mortem examination: he may be able to
>   say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>   The plural of anecdote is not data. ~ Roger Brinner
>   The combination of some data and an aching desire for an answer does not
>   ensure that a reasonable answer can be extracted from a given body of
>   data. ~ John Tukey
>
>   2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>
>           Hello!
>
>   Very new to R (10 days), and I've run the linear mixed model, below.
>   Attempting to interpret what it means...  What do I need to look for?
>   Residuals, correlations of fixed effects?!
>
>   How would I look at very specific interactions, such as PREMIER_LEAGUE
>   (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>   GK?
>
>   For reference my data set looks like this:
>
>   Id Level AgeGr   Position Height Weight BMI YoYo
>   7451 CHAMPIONSHIP 14 M NA 63 NA 80
>   148 PREMIER_LEAGUE 16 D NA 64 NA 80
>   10393 CONFERENCE 10 D NA 36 NA 160
>   10200 CHAMPIONSHIP 10 F NA 46 NA 160
>   1961 LEAGUE_TWO 13 GK NA 67 NA 160
>   10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>   10541 LEAGUE_ONE 10 F NA 25 NA 160
>   10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>   9895 CHAMPIONSHIP 10 D NA 36 NA 160
>
>   Many thanks in advance for time and help.  Really appreciate it.
>
>   Josh
>
>           summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>
>   Linear mixed model fit by REML ['lmerMod']
>   Formula: YoYo ~ AgeGr + Position + (1 | Id)
>
>   REML criterion at convergence: 125712.2
>
>   Scaled residuals:
>        Min      1Q  Median      3Q     Max
>   -3.4407 -0.5288 -0.0874  0.4531  4.8242
>
>   Random effects:
>     Groups   Name        Variance Std.Dev.
>     Id       (Intercept) 15300    123.7
>     Residual             16530    128.6
>   Number of obs: 9609, groups:  Id, 6071
>
>   Fixed effects:
>                 Estimate Std. Error t value
>   (Intercept) -521.6985    16.8392  -30.98
>   AgeGr         62.6786     0.9783   64.07
>   PositionD    139.4682     7.8568   17.75
>   PositionM    141.2227     7.7072   18.32
>   PositionF    135.1241     8.1911   16.50
>
>   Correlation of Fixed Effects:
>              (Intr) AgeGr  PostnD PostnM
>   AgeGr     -0.910
>   PositionD -0.359 -0.009
>   PositionM -0.375  0.001  0.810
>   PositionF -0.349 -0.003  0.756  0.782
>
>           model=lmer(YoYo~AgeGr+Position+(1|Id))
>   summary(glht(model,linfct=mcp(Position="Tukey")))
>
>     Simultaneous Tests for General Linear Hypotheses
>
>   Multiple Comparisons of Means: Tukey Contrasts
>
>   Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>
>   Linear Hypotheses:
>                Estimate Std. Error z value Pr(>|z|)
>   D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>   M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>   F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>   M - D == 0     1.754      4.799   0.366    0.983
>   F - D == 0    -4.344      5.616  -0.774    0.862
>   F - M == 0    -6.099      5.267  -1.158    0.645
>   ---
>   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>   (Adjusted p values reported -- single-step method)
>
>            [[alternative HTML version deleted]]
>
>   ______________________________________________
>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
>  https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]
>   PLEASE do read the posting guide
>   http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]
>   and provide commented, minimal, self-contained, reproducible code.
>
>           [[alternative HTML version deleted]]
>
>   ______________________________________________
>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>   https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]
>   PLEASE do read the posting guide
>   http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]
>   and provide commented, minimal, self-contained, reproducible code.
>
>   ____________________________________________________________
>   FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> and family!
>   Visit http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing]] to find out more!
>
>   ______________________________________________
>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>   https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]
>   PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]
>   and provide commented, minimal, self-contained, reproducible code.
>
>   --
>   Michael
>   http://www.dewey.myzen.co.uk/home.html [
> http://www.dewey.myzen.co.uk/home.html] [
> http://www.dewey.myzen.co.uk/home.html [
> http://www.dewey.myzen.co.uk/home.html]]
>
>  ____________________________________________________________
>  Can't remember your password? Do you need a strong and secure password?
>  Use Password manager! It stores your passwords & protects your account.
>  Check it out at http://mysecurelogon.com/manager [
> http://mysecurelogon.com/manager]
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]


From joshuamichaeldixon at gmail.com  Tue Apr 28 22:26:31 2015
From: joshuamichaeldixon at gmail.com (Joshua Dixon)
Date: Tue, 28 Apr 2015 21:26:31 +0100
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAOkeKB+-VQbrapCiS0isTUZxXhZwY5XFtFBgpzqFj0oSMp=x-Q@mail.gmail.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<caokekbjmp8hrs8tpfxvzxtsevrwav_jmjn7hngb3n18=4jjqga@mail.gmail.com>
	<f0739ac4af7.00000e24jrkrideau@inbox.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<CAOkeKB+7SYL7+VLZQak-Mf4JAimRTJK=u7tsz1juFwK23eY6og@mail.gmail.com>
	<F28501AEC71.0000113Ejrkrideau@inbox.com>
	<CAOkeKB+-VQbrapCiS0isTUZxXhZwY5XFtFBgpzqFj0oSMp=x-Q@mail.gmail.com>
Message-ID: <CAOkeKBLzG784LzGAKm_o2ANR6Fk0EmK-0HN6BZUhxfX2a6Y8vA@mail.gmail.com>

*Edit*

Where "F" position are in the same AgeGr as well.

Thanks,

Josh

On Tue, Apr 28, 2015 at 9:25 PM, Joshua Dixon <joshuamichaeldixon at gmail.com>
wrote:

> *John* -  Lot's of missing data for height unfortunately.  Which is
> needed for BMI calculation.
>
> How would I look compare very specific parts of the data, i.e. comparing
> YoYo outcomes between "F" and "M" position that are both in the
> PREMIER_LEAGUE Level?
>
> Still can't figure it out!
>
> Josh
>
> On Tue, Apr 28, 2015 at 2:39 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>>
>> Looks great.  How come so many NA's in Height and BMI? Just no data
>> available?
>>
>>  str(dat1)
>> 'data.frame':   100 obs. of  8 variables:
>>  $ Id      : int  7451 148 10393 10200 1961 10428 10541 10012 9895 10626
>> ...
>>  $ Level   : Factor w/ 5 levels "CHAMPIONSHIP",..: 1 1 1 1 1 1 1 1 1 1 ...
>>  $ AgeGr   : int  14 16 10 10 13 10 10 10 10 10 ...
>>  $ Position: Factor w/ 4 levels "D","F","GK","M": 4 1 1 2 3 3 2 3 1 1 ...
>>  $ Height  : int  NA NA NA NA NA NA NA NA NA NA ...
>>  $ Weight  : num  63 64 36 46 67 40 25 30 36 33 ...
>>  $ BMI     : num  NA NA NA NA NA NA NA NA NA NA ...
>>  $ YoYo    : int  80 80 160 160 160 160 160 160 160 160 ...
>>
>> John Kane
>> Kingston ON Canada
>>
>> -----Original Message-----
>> From: joshuamichaeldixon at gmail.com
>> Sent: Mon, 27 Apr 2015 23:35:13 +0100
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] Help Interpreting Linear Mixed Model
>>
>> Thanks John!
>>
>> This ok?
>>
>> > dput(head(data, 100))
>>
>> structure(list(Id = c(7451L, 148L, 10393L, 10200L, 1961L, 10428L,
>>
>> 10541L, 10012L, 9895L, 10626L, 1151L, 8775L, 10083L, 6217L, 90L,
>>
>> 10168L, 10291L, 8549L, 3451L, 10003L, 5907L, 10136L, 6182L, 6315L,
>>
>> 10015L, 9956L, 2040L, 4710L, 10747L, 6787L, 1222L, 10757L, 2892L,
>>
>> 117L, 10328L, 10503L, 768L, 2979L, 1961L, 10520L, 10498L, 3018L,
>>
>> 10335L, 2448L, 9027L, 362L, 8499L, 10603L, 9489L, 2124L, 707L,
>>
>> 8501L, 4908L, 9905L, 3000L, 2819L, 9973L, 10550L, 9921L, 10639L,
>>
>> 8771L, 10121L, 32L, 9935L, 9299L, 3246L, 682L, 10325L, 6741L,
>>
>> 3295L, 5270L, 727L, 8500L, 50L, 4705L, 3018L, 787L, 2953L, 1391L,
>>
>> 3682L, 7974L, 5023L, 652L, 727L, 679L, 10212L, 9488L, 9987L,
>>
>> 10039L, 5025L, 250L, 2539L, 787L, 3000L, 1151L, 8946L, 6177L,
>>
>> 3296L, 250L, 498L), Level = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
>> c("CHAMPIONSHIP",
>>
>> "CONFERENCE", "LEAGUE_ONE", "LEAGUE_TWO", "PREMIER_LEAGUE"), class =
>> "factor"),
>>
>>     AgeGr = c(14L, 16L, 10L, 10L, 13L, 10L, 10L, 10L, 10L, 10L,
>>
>>     14L, 10L, 10L, 10L, 12L, 10L, 10L, 12L, 10L, 10L, 10L, 10L,
>>
>>     12L, 10L, 10L, 10L, 10L, 10L, 10L, 15L, 10L, 10L, 10L, 12L,
>>
>>     10L, 10L, 13L, 10L, 13L, 11L, 11L, 13L, 12L, 11L, 12L, 14L,
>>
>>     13L, 13L, 13L, 13L, 12L, 11L, 15L, 11L, 14L, 13L, 11L, 11L,
>>
>>     11L, 12L, 14L, 12L, 13L, 11L, 13L, 15L, 11L, 13L, 13L, 13L,
>>
>>     14L, 13L, 13L, 12L, 13L, 13L, 13L, 14L, 12L, 14L, 13L, 13L,
>>
>>     13L, 13L, 13L, 12L, 13L, 14L, 13L, 14L, 13L, 14L, 13L, 14L,
>>
>>     14L, 13L, 14L, 13L, 13L, 13L), Position = structure(c(4L,
>>
>>     1L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 4L, 3L, 2L, 3L,
>>
>>     4L, 3L, 4L, 2L, 4L, 2L, 3L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 4L,
>>
>>     2L, 1L, 4L, 1L, 1L, 2L, 4L, 3L, 1L, 4L, 1L, 2L, 3L, 3L, 1L,
>>
>>     1L, 3L, 1L, 3L, 4L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 3L, 1L,
>>
>>     2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 4L, 1L, 1L, 1L,
>>
>>     2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 1L, 3L, 4L, 4L, 4L, 4L, 2L,
>>
>>     2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 2L), .Label = c("D", "F",
>>
>>     "GK", "M"), class = "factor"), Height = c(NA, NA, NA, NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 151L, NA,
>>
>>     154L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L, NA,
>>
>>     147L, NA, NA, NA, NA, NA, 138L, 172L, NA, NA, 150L, NA, NA,
>>
>>     NA, NA, NA, NA, NA, 140L, 153L, NA, NA, NA, NA, NA, NA, NA,
>>
>>     158L, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L), Weight = c(63,
>>
>>     64, 36, 46, 67, 40, 25, 30, 36, 33, 61, 31, 29, 34, 47, 38,
>>
>>     32, 44, 32, 32, 30, 34, 51, 34, 28, 27, 33, 31, 28, 44, 37,
>>
>>     46, 26, 42, 32, 32, 43, 31, 72, 27, 30, 55, 53, 50, 51, 55,
>>
>>     48.6, 49, 48, 64, 35, 32, 55, 32, 50, 61, 42, 33, 37, 45,
>>
>>     45, 50, 36, 33, 49, 59, 42, 43, 35.1, 66.9, 52, 47, 40, 38,
>>
>>     45, 53, 44, 54, 39, 62, 33, 53.8, 42, 46, 39, 48, 39, 54,
>>
>>     40, 42.4, 50, 48, 46, 52, 58, 40, 46, 51, 54, 42), BMI = c(NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     21.2, NA, 20.24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, 18.49, NA, 16.66, NA, NA, NA, NA, NA, 18.57, 22.61, NA,
>>
>>     NA, 17.77, NA, NA, NA, NA, NA, NA, NA, 16.84, 22.86, NA,
>>
>>     NA, NA, NA, NA, NA, NA, 16.9, NA, NA, NA, NA, NA, NA, NA,
>>
>>     NA, NA, 17.26), YoYo = c(80L, 80L, 160L, 160L, 160L, 160L,
>>
>>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>>
>>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>>
>>     160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,
>>
>>     160L, 160L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>>
>>     200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>>
>>     200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,
>>
>>     200L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>>
>>     240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>>
>>     240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,
>>
>>     240L, 240L, 240L, 240L)), .Names = c("Id", "Level", "AgeGr",
>>
>> "Position", "Height", "Weight", "BMI", "YoYo"), row.names = c(NA,
>>
>> 100L), class = "data.frame")
>>
>> On Mon, Apr 27, 2015 at 10:43 PM, John Kane <jrkrideau at inbox.com> wrote:
>>
>>  Hi Josh,
>>
>>  Just a sample  is usually  fine. As long as it cover a representative
>> (must be time for dinner---I was going to type reprehensibe) sample of the
>> data then something like dput(head(mydata, 100) ) works well.
>>
>>  Kingston ON Canada
>>
>>  -----Original Message-----
>>  From: joshuamichaeldixon at gmail.com
>>
>> Sent: Mon, 27 Apr 2015 21:30:39 +0100
>>  To: lists at dewey.myzen.co.uk
>>  Subject: Re: [R] Help Interpreting Linear Mixed Model
>>
>>  Apologies for my ignorance!
>>
>>  Thierry - thank you for the reading.  I'll look into those ASAP!
>>
>>  John - The data set I have is quite large, when using the dput() command
>> I'm unsure if it actually fits the whole output into the console.  I can't
>> scroll up far enough to see the actual command.  I can paste what is there
>> if that may help?  The bottom line:
>>
>>  Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI",
>> "YoYo"), class = "data.frame", row.names = c(NA, -9689L))
>>
>>  Michael - Essentially, I'm looking for differences between "YoYo"
>> outcome for "Positions", "Levels" and accounting for repeated measures
>> using "Id" as a random factor.  So I was able to figure out points 2 and 3.
>>
>>  I've searched for definitions of "Scaled residuals", "Random
>> effects", "Fixed effects", "Correlation of Fixed Effects".  However, I'm
>> confused at the different interpretations I've found.  Or quite possibly,
>> I'm just confused...  What should I be looking out for in these variables?
>>
>>  I've tried to take my analysis smaller, and just look at specifics, to
>> make it simpler.  Such as, comparing YoYo (outcome score) for a
>> Premier_League (Level), 22 (AgeGr) F (Position) with a Premier_League
>> (Level), 22 (AgeGr) M (Position).  How do I convert these into a factors
>> for analysis?
>>
>>  Simple question maybe, but it's not when you can't find the answer!
>>
>>  Thank you,
>>
>>  Josh
>>
>>  On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk>
>> wrote:
>>
>>          Dear Joshua
>>
>>   It would also help if you told us what your scientific question was. At
>> the moment we know what R commands you used and have seen the head of your
>> dataset but not why you are doing it.
>>
>>   I would summarise what you have given us as
>>
>>   1 - most ID only occur once
>>   2 - goal keepers do worse than outfield players
>>   3 - older people (presumably in fact age is in years as a continuous
>> variable) do better
>>
>>   On 27/04/2015 12:42, John Kane wrote:
>>
>>   John Kane
>>   Kingston ON Canada
>>
>>           -----Original Message-----
>>   From: joshuamichaeldixon at gmail.com
>>   Sent: Mon, 27 Apr 2015 08:54:51 +0100
>>   To: thierry.onkelinx at inbo.be
>>   Subject: Re: [R] Help Interpreting Linear Mixed Model
>>
>>   Hello Thierry,
>>
>>   No, this isn't homework. Not that young unfortunately.
>>
>>   A few years ago a friend of mine and her daughter were neck-in-neck on
>> who got their Ph.D first. What's this "not that young" business?
>>
>>   BTW, a better way to supply sample data is to use the dput() command.
>>
>>   Do a dput(mydata), copy the results into the email and you have
>> supplied us with an exact copy of your data.
>>
>>   It is possible for many reasons that I will not read in your data, as
>> you supplied it, in the format you have it in.  This can lead to real
>> confusion.
>>
>>           Josh
>>
>>           On 27 Apr 2015, at 08:06, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>>   wrote:
>>
>>   Dear Josh,
>>
>>   Is this homework? Because the list has a no homework policy.
>>
>>   Best regards,
>>
>>   ir. Thierry Onkelinx
>>   Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>   and Forest
>>   team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>   Kliniekstraat 25
>>   1070 Anderlecht
>>   Belgium
>>
>>   To call in the statistician after the experiment is done may be no more
>>   than asking him to perform a post-mortem examination: he may be able to
>>   say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>   The plural of anecdote is not data. ~ Roger Brinner
>>   The combination of some data and an aching desire for an answer does not
>>   ensure that a reasonable answer can be extracted from a given body of
>>   data. ~ John Tukey
>>
>>   2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:
>>
>>           Hello!
>>
>>   Very new to R (10 days), and I've run the linear mixed model, below.
>>   Attempting to interpret what it means...  What do I need to look for?
>>   Residuals, correlations of fixed effects?!
>>
>>   How would I look at very specific interactions, such as PREMIER_LEAGUE
>>   (Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
>>   GK?
>>
>>   For reference my data set looks like this:
>>
>>   Id Level AgeGr   Position Height Weight BMI YoYo
>>   7451 CHAMPIONSHIP 14 M NA 63 NA 80
>>   148 PREMIER_LEAGUE 16 D NA 64 NA 80
>>   10393 CONFERENCE 10 D NA 36 NA 160
>>   10200 CHAMPIONSHIP 10 F NA 46 NA 160
>>   1961 LEAGUE_TWO 13 GK NA 67 NA 160
>>   10428 CHAMPIONSHIP 10 GK NA 40 NA 160
>>   10541 LEAGUE_ONE 10 F NA 25 NA 160
>>   10012 CHAMPIONSHIP 10 GK NA 30 NA 160
>>   9895 CHAMPIONSHIP 10 D NA 36 NA 160
>>
>>   Many thanks in advance for time and help.  Really appreciate it.
>>
>>   Josh
>>
>>           summary(lmer(YoYo~AgeGr+Position+(1|Id)))
>>
>>   Linear mixed model fit by REML ['lmerMod']
>>   Formula: YoYo ~ AgeGr + Position + (1 | Id)
>>
>>   REML criterion at convergence: 125712.2
>>
>>   Scaled residuals:
>>        Min      1Q  Median      3Q     Max
>>   -3.4407 -0.5288 -0.0874  0.4531  4.8242
>>
>>   Random effects:
>>     Groups   Name        Variance Std.Dev.
>>     Id       (Intercept) 15300    123.7
>>     Residual             16530    128.6
>>   Number of obs: 9609, groups:  Id, 6071
>>
>>   Fixed effects:
>>                 Estimate Std. Error t value
>>   (Intercept) -521.6985    16.8392  -30.98
>>   AgeGr         62.6786     0.9783   64.07
>>   PositionD    139.4682     7.8568   17.75
>>   PositionM    141.2227     7.7072   18.32
>>   PositionF    135.1241     8.1911   16.50
>>
>>   Correlation of Fixed Effects:
>>              (Intr) AgeGr  PostnD PostnM
>>   AgeGr     -0.910
>>   PositionD -0.359 -0.009
>>   PositionM -0.375  0.001  0.810
>>   PositionF -0.349 -0.003  0.756  0.782
>>
>>           model=lmer(YoYo~AgeGr+Position+(1|Id))
>>   summary(glht(model,linfct=mcp(Position="Tukey")))
>>
>>     Simultaneous Tests for General Linear Hypotheses
>>
>>   Multiple Comparisons of Means: Tukey Contrasts
>>
>>   Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))
>>
>>   Linear Hypotheses:
>>                Estimate Std. Error z value Pr(>|z|)
>>   D - GK == 0  139.468      7.857  17.751   <1e-04 ***
>>   M - GK == 0  141.223      7.707  18.323   <1e-04 ***
>>   F - GK == 0  135.124      8.191  16.496   <1e-04 ***
>>   M - D == 0     1.754      4.799   0.366    0.983
>>   F - D == 0    -4.344      5.616  -0.774    0.862
>>   F - M == 0    -6.099      5.267  -1.158    0.645
>>   ---
>>   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>   (Adjusted p values reported -- single-step method)
>>
>>            [[alternative HTML version deleted]]
>>
>>   ______________________________________________
>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>>  https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help] [
>> https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help]]
>>   PLEASE do read the posting guide
>>   http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html] [
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html]]
>>   and provide commented, minimal, self-contained, reproducible code.
>>
>>           [[alternative HTML version deleted]]
>>
>>   ______________________________________________
>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>   https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help] [
>> https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help]]
>>   PLEASE do read the posting guide
>>   http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html] [
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html]]
>>   and provide commented, minimal, self-contained, reproducible code.
>>
>>   ____________________________________________________________
>>   FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>>   Visit http://www.inbox.com/photosharing [
>> http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [
>> http://www.inbox.com/photosharing]] to find out more!
>>
>>   ______________________________________________
>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>   https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help] [
>> https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help]]
>>   PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html] [
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html]]
>>   and provide commented, minimal, self-contained, reproducible code.
>>
>>   --
>>   Michael
>>   http://www.dewey.myzen.co.uk/home.html [
>> http://www.dewey.myzen.co.uk/home.html] [
>> http://www.dewey.myzen.co.uk/home.html [
>> http://www.dewey.myzen.co.uk/home.html]]
>>
>>  ____________________________________________________________
>>  Can't remember your password? Do you need a strong and secure password?
>>  Use Password manager! It stores your passwords & protects your account.
>>  Check it out at http://mysecurelogon.com/manager [
>> http://mysecurelogon.com/manager]
>>
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> Check it out at http://www.inbox.com/earth
>>
>>
>>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Apr 28 22:28:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Apr 2015 13:28:32 -0700
Subject: [R] error in running optimx
In-Reply-To: <AA230DAD-AE3B-4AA2-96B8-9B9BD1B614F7@comcast.net>
References: <876084663.9404451.1430249550970.JavaMail.yahoo@mail.yahoo.com>
	<553FE2FB.5070706@sapo.pt>
	<AA230DAD-AE3B-4AA2-96B8-9B9BD1B614F7@comcast.net>
Message-ID: <1390DA08-4AB1-4930-9E6D-A27B8DA442FD@comcast.net>


On Apr 28, 2015, at 1:15 PM, David Winsemius wrote:

> 
> On Apr 28, 2015, at 12:43 PM, Rui Barradas wrote:
> 
>> Hello,
>> 
>> The error message is quite clear, you must also install package 'quadprog'.
> 
> The 'quadprog' pkg is not listed as a dependency or even as 'suggested' and there is no mention of 'quadprog' in the NEWS file, nor does a search of the 'demos' code for a call to load "quadprog" produce a hit, and there is no mention of quadprog in the NAMESPACE file,  so the message while "clear" can still be considered "quite unexpected".

The "BB" package is imported by "optimx" and "BB" in turn imports "quadprog.

> 
> -- 
> David.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 28-04-2015 20:32, Olufemi Bolarinwa escreveu:
>>> Hello,I tried installing optimx and got a confirmation that it was installed. However, anytime I call for it, I received the following error message
>>>> library("optimx", lib.loc="~/R/win-library/3.1")Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :   there is no package called ?quadprog?In addition: Warning message:package ?optimx? was built under R version 3.1.3 Error: package or namespace load failed for ?optimx?
>>> When I go ahead to run my code, I have the following error message:
>>> Error: could not find function "optimx"
>>> 
>>> How do I go about solving this issue.
>>> Thanks.Olufemi
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dafemlions at yahoo.co.uk  Tue Apr 28 22:51:14 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Tue, 28 Apr 2015 20:51:14 +0000 (UTC)
Subject: [R] optimx: Cannot evaluate function at initial parameters
Message-ID: <1996084605.9475931.1430254274908.JavaMail.yahoo@mail.yahoo.com>

Hello,I am estimating a system of nonlinear GMM. the following are my objective function, the gradient function and the optimx code for the optimization. ?I actually worked out the gradient and hessian by hand before inputing the code into r. However, I did get the following error message in my optimx routine
objective functionobj = function(initial.values,z) {? e1 = y1-(a1*x1 + a2*x2 +a3*x3 + a4*x4 + a5*x5 + a22*(exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16)/(1+exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16))))?? e2 = y2-(b1*x1 + b2*x2 +b3*x3 + b4*x4 + b5*x5 + b22*(exp(b6*x6 + b7*x7 + b8*x9 + b9*x10 + b10*x11 + b11*x12 + b14*x16)/(1+exp(b6*x6 + b7*x7 + b8*x9 + b9*x10 + b10*x11 + b11*x12 + b14*x16))))? e3 = y3-(exp(c1*x1 + c2*x18 + c3*x19 + c4*x20 + c5*x21 + c6*x14 + c7*x8)/(1 + exp(c1*x1 + c2*x18 + c3*x19 + c4*x20 + c5*x21 + c6*x14 + c7*x8)))? e = rbind(e1,e2,e3)? q = t(e)%x%z%x%w%x%t(z)%x%e? return(q)}

gradientgradient = function(initial.values,z) {? df = 2*(t(d)%x%z%x%w%x%t(z)%x%e)? return(df)}

hessian = function(initial.values,z) {? h = 2*(t(d)%x%z%x%w%x%t(z)%x%d)? return(h)}

nlgmm = optimx(par=initial.values, dat= dta, fn=obj, gr=gradient,hess=hessian, method = c("BFGS","nlmind","nlm"), itnmax=c(500,500,500), control=list(maximize=TRUE))Maximizing -- use negfn and neggrError in optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower, ?:?? Cannot evaluate function at initial parameters
A way forward will be greatly appreciated.
ThanksOlufemi?

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Apr 28 23:30:06 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 28 Apr 2015 13:30:06 -0800
Subject: [R] Help Interpreting Linear Mixed Model
In-Reply-To: <CAOkeKBLzG784LzGAKm_o2ANR6Fk0EmK-0HN6BZUhxfX2a6Y8vA@mail.gmail.com>
References: <eb356122a2c.0000029djrkrideau@inbox.com>
	<cajucy5zm6meb=dmno6tcqpgpqux2021t3mj7wpkifea6zc8zna@mail.gmail.com>
	<caokekbjt-wvwtt1nemyxhskz1cnwk36q+_neg2yky_4pm2rgqw@mail.gmail.com>
	<f0739ac4af7.00000e24jrkrideau@inbox.com>
	<f28501aec71.0000113ejrkrideau@inbox.com>
	<caokekbjmp8hrs8tpfxvzxtsevrwav_jmjn7hngb3n18=4jjqga@mail.gmail.com>
	<caokekb+7syl7+vlzqak-mf4jaimrtjk=u7tsz1jufwk23ey6og@mail.gmail.com>
	<caokekb+-vqbrapcis0istuzxxhzwy5xftfbgpzqfj0osmp=x-q@mail.gmail.com>
	<553e5157.10206@dewey.myzen.co.uk>
Message-ID: <FCE9346BB06.000008E0jrkrideau@inbox.com>

You are posting in HTML and the R-help list is a plain text one. Would you reset to plain in your e-mail editor before posting, please?

 For security reasons R-help strips the HTML version and, we on the list,  receive the resulting plain text.  This, often,  mangles code to the point that it is almost indecipherable.   

Re your question, if I understood it. Something like this should do it
 fm  <-  subset(dat1, Level =="PREMIER_LEAGUE" &  (Position ==  "F" | Position == "m"))

This now gives you a data.frame with only those rows that match your criteria.  
Untested since all 100 rows are CHAMPIONSHIP.  No fPREMIER_LEAGUE in your first 100 rows of data.  I should have warned you about this but it was late and I didn't think through your statement about "The data set I have is quite large".  

Here is an example of how to do some random sampling of your data.frame, which I should have mentioned yesterday

http://stackoverflow.com/questions/8273313/random-rows-in-dataframe-in-r

But in any case the idea is just to subset the data and go from there.  Just type ?subset for help.

##   "Where "F" position are in the same AgeGr as well."

You should be able to add a AgeGr = 99 in the subset statement.

fm  <-  subset(dat1, Level =="PREMIER_LEAGUE" & AgeGr = 10 & (Position ==  "F" | Position == "m"))

should work. Untested and again it's almost dinner time so no guarantees.

I think that there are faster and better ways to do this but this is fairly basic and "relatively' self-documenting.

After that, it depends on what you want to do with the data.

I hope this helps


John Kane
Kingston ON Canada

-----Original Message-----
From: joshuamichaeldixon at gmail.com
Sent: Tue, 28 Apr 2015 21:26:31 +0100
To: jrkrideau at inbox.com
Subject: Re: [R] Help Interpreting Linear Mixed Model

*Edit*?

Where "F" position are in the same AgeGr as well.

Thanks,

Josh

On Tue, Apr 28, 2015 at 9:25 PM, Joshua Dixon <joshuamichaeldixon at gmail.com> wrote:

John - ?Lot's of missing data for height unfortunately.? Which is needed for BMI calculation. ?

How would I look compare very specific parts of the data, i.e. comparing YoYo outcomes between "F" and "M" position that are both in the PREMIER_LEAGUE Level?

Still can't figure it out!

Josh

On Tue, Apr 28, 2015 at 2:39 AM, John Kane <jrkrideau at inbox.com> wrote:

 Looks great.? How come so many NA's in Height and BMI? Just no data available?

 ?str(dat1)
 'data.frame':? ?100 obs. of? 8 variables:
 ?$ Id? ? ? : int? 7451 148 10393 10200 1961 10428 10541 10012 9895 10626 ...
 ?$ Level? ?: Factor w/ 5 levels "CHAMPIONSHIP",..: 1 1 1 1 1 1 1 1 1 1 ...
 ?$ AgeGr? ?: int? 14 16 10 10 13 10 10 10 10 10 ...
 ?$ Position: Factor w/ 4 levels "D","F","GK","M": 4 1 1 2 3 3 2 3 1 1 ...
 ?$ Height? : int? NA NA NA NA NA NA NA NA NA NA ...
 ?$ Weight? : num? 63 64 36 46 67 40 25 30 36 33 ...
 ?$ BMI? ? ?: num? NA NA NA NA NA NA NA NA NA NA ...
 ?$ YoYo? ? : int? 80 80 160 160 160 160 160 160 160 160 ...

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: joshuamichaeldixon at gmail.com

Sent: Mon, 27 Apr 2015 23:35:13 +0100
 To: jrkrideau at inbox.com
 Subject: Re: [R] Help Interpreting Linear Mixed Model

 Thanks John!

 This ok?

 > dput(head(data, 100))

 structure(list(Id = c(7451L, 148L, 10393L, 10200L, 1961L, 10428L,?

 10541L, 10012L, 9895L, 10626L, 1151L, 8775L, 10083L, 6217L, 90L,?

 10168L, 10291L, 8549L, 3451L, 10003L, 5907L, 10136L, 6182L, 6315L,?

 10015L, 9956L, 2040L, 4710L, 10747L, 6787L, 1222L, 10757L, 2892L,?

 117L, 10328L, 10503L, 768L, 2979L, 1961L, 10520L, 10498L, 3018L,?

 10335L, 2448L, 9027L, 362L, 8499L, 10603L, 9489L, 2124L, 707L,?

 8501L, 4908L, 9905L, 3000L, 2819L, 9973L, 10550L, 9921L, 10639L,?

 8771L, 10121L, 32L, 9935L, 9299L, 3246L, 682L, 10325L, 6741L,?

 3295L, 5270L, 727L, 8500L, 50L, 4705L, 3018L, 787L, 2953L, 1391L,?

 3682L, 7974L, 5023L, 652L, 727L, 679L, 10212L, 9488L, 9987L,?

 10039L, 5025L, 250L, 2539L, 787L, 3000L, 1151L, 8946L, 6177L,?

 3296L, 250L, 498L), Level = structure(c(1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("CHAMPIONSHIP",?

 "CONFERENCE", "LEAGUE_ONE", "LEAGUE_TWO", "PREMIER_LEAGUE"), class = "factor"),?

 ? ? AgeGr = c(14L, 16L, 10L, 10L, 13L, 10L, 10L, 10L, 10L, 10L,?

 ? ? 14L, 10L, 10L, 10L, 12L, 10L, 10L, 12L, 10L, 10L, 10L, 10L,?

 ? ? 12L, 10L, 10L, 10L, 10L, 10L, 10L, 15L, 10L, 10L, 10L, 12L,?

 ? ? 10L, 10L, 13L, 10L, 13L, 11L, 11L, 13L, 12L, 11L, 12L, 14L,?

 ? ? 13L, 13L, 13L, 13L, 12L, 11L, 15L, 11L, 14L, 13L, 11L, 11L,?

 ? ? 11L, 12L, 14L, 12L, 13L, 11L, 13L, 15L, 11L, 13L, 13L, 13L,?

 ? ? 14L, 13L, 13L, 12L, 13L, 13L, 13L, 14L, 12L, 14L, 13L, 13L,?

 ? ? 13L, 13L, 13L, 12L, 13L, 14L, 13L, 14L, 13L, 14L, 13L, 14L,?

 ? ? 14L, 13L, 14L, 13L, 13L, 13L), Position = structure(c(4L,?

 ? ? 1L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 1L, 1L, 2L, 4L, 3L, 2L, 3L,?

 ? ? 4L, 3L, 4L, 2L, 4L, 2L, 3L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 4L,?

 ? ? 2L, 1L, 4L, 1L, 1L, 2L, 4L, 3L, 1L, 4L, 1L, 2L, 3L, 3L, 1L,?

 ? ? 1L, 3L, 1L, 3L, 4L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 3L, 1L,?

 ? ? 2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 3L, 4L, 4L, 1L, 1L, 1L,?

 ? ? 2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 1L, 3L, 4L, 4L, 4L, 4L, 2L,?

 ? ? 2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 2L), .Label = c("D", "F",?

 ? ? "GK", "M"), class = "factor"), Height = c(NA, NA, NA, NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 151L, NA,?

 ? ? 154L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L, NA,?

 ? ? 147L, NA, NA, NA, NA, NA, 138L, 172L, NA, NA, 150L, NA, NA,?

 ? ? NA, NA, NA, NA, NA, 140L, 153L, NA, NA, NA, NA, NA, NA, NA,?

 ? ? 158L, NA, NA, NA, NA, NA, NA, NA, NA, NA, 156L), Weight = c(63,?

 ? ? 64, 36, 46, 67, 40, 25, 30, 36, 33, 61, 31, 29, 34, 47, 38,?

 ? ? 32, 44, 32, 32, 30, 34, 51, 34, 28, 27, 33, 31, 28, 44, 37,?

 ? ? 46, 26, 42, 32, 32, 43, 31, 72, 27, 30, 55, 53, 50, 51, 55,?

 ? ? 48.6, 49, 48, 64, 35, 32, 55, 32, 50, 61, 42, 33, 37, 45,?

 ? ? 45, 50, 36, 33, 49, 59, 42, 43, 35.1, 66.9, 52, 47, 40, 38,?

 ? ? 45, 53, 44, 54, 39, 62, 33, 53.8, 42, 46, 39, 48, 39, 54,?

 ? ? 40, 42.4, 50, 48, 46, 52, 58, 40, 46, 51, 54, 42), BMI = c(NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? 21.2, NA, 20.24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, 18.49, NA, 16.66, NA, NA, NA, NA, NA, 18.57, 22.61, NA,?

 ? ? NA, 17.77, NA, NA, NA, NA, NA, NA, NA, 16.84, 22.86, NA,?

 ? ? NA, NA, NA, NA, NA, NA, 16.9, NA, NA, NA, NA, NA, NA, NA,?

 ? ? NA, NA, 17.26), YoYo = c(80L, 80L, 160L, 160L, 160L, 160L,?

 ? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

 ? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

 ? ? 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L, 160L,?

 ? ? 160L, 160L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

 ? ? 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

 ? ? 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L, 200L,?

 ? ? 200L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

 ? ? 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

 ? ? 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L, 240L,?

 ? ? 240L, 240L, 240L, 240L)), .Names = c("Id", "Level", "AgeGr",?

 "Position", "Height", "Weight", "BMI", "YoYo"), row.names = c(NA,?

 100L), class = "data.frame")

 On Mon, Apr 27, 2015 at 10:43 PM, John Kane <jrkrideau at inbox.com> wrote:

 ?Hi Josh,

 ?Just a sample? is usually? fine. As long as it cover a representative (must be time for dinner---I was going to type reprehensibe) sample of the data then something like dput(head(mydata, 100) ) works well.

 ?Kingston ON Canada

 ?-----Original Message-----
 ?From: joshuamichaeldixon at gmail.com

 Sent: Mon, 27 Apr 2015 21:30:39 +0100
 ?To: lists at dewey.myzen.co.uk
 ?Subject: Re: [R] Help Interpreting Linear Mixed Model

 ?Apologies for my ignorance!

 ?Thierry - thank you for the reading.? I'll look into those ASAP!

 ?John - The data set I have is quite large, when using the dput() command I'm unsure if it actually fits the whole output into the console.? I can't scroll up far enough to see the actual command.? I can paste what is there if that may help?? The bottom line:?

 ?Names = c("Id", "Level", "AgeGr", "Position", "Height", "Weight", "BMI", "YoYo"), class = "data.frame", row.names = c(NA, -9689L))

 ?Michael - Essentially, I'm looking for differences between "YoYo" outcome for "Positions", "Levels" and accounting for repeated measures using "Id" as a random factor.? So I was able to figure out points 2 and 3.

 ?I've searched for definitions of "Scaled residuals",?"Random effects",?"Fixed effects",?"Correlation of Fixed Effects".? However, I'm confused at the different interpretations I've found.? Or quite possibly, I'm just confused...? What should I be?looking?out for in these variables?

 ?I've tried to take my analysis smaller, and just look at specifics, to make it simpler.? Such as, comparing YoYo (outcome score) for a Premier_League (Level), 22 (AgeGr) F (Position) with a?Premier_League (Level), 22 (AgeGr) M (Position).? How do I convert these into a factors for analysis?

 ?Simple question maybe, but it's not when you can't find the answer!

 ?Thank you,

 ?Josh

 ?On Mon, Apr 27, 2015 at 4:10 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

 ?? ? ? ? Dear Joshua

 ??It would also help if you told us what your scientific question was. At the moment we know what R commands you used and have seen the head of your dataset but not why you are doing it.

 ??I would summarise what you have given us as

 ??1 - most ID only occur once
 ??2 - goal keepers do worse than outfield players
 ??3 - older people (presumably in fact age is in years as a continuous variable) do better

 ??On 27/04/2015 12:42, John Kane wrote:

 ??John Kane
 ??Kingston ON Canada

 ?? ? ? ? ?-----Original Message-----
 ??From: joshuamichaeldixon at gmail.com
 ??Sent: Mon, 27 Apr 2015 08:54:51 +0100
 ??To: thierry.onkelinx at inbo.be
 ??Subject: Re: [R] Help Interpreting Linear Mixed Model

 ??Hello Thierry,

 ??No, this isn't homework. Not that young unfortunately.

 ??A few years ago a friend of mine and her daughter were neck-in-neck on who got their Ph.D first. What's this "not that young" business?

 ??BTW, a better way to supply sample data is to use the dput() command.

 ??Do a dput(mydata), copy the results into the email and you have supplied us with an exact copy of your data.

 ??It is possible for many reasons that I will not read in your data, as you supplied it, in the format you have it in.? This can lead to real confusion.

 ?? ? ? ? ?Josh

 ?? ? ? ? ?On 27 Apr 2015, at 08:06, Thierry Onkelinx <thierry.onkelinx at inbo.be>
 ??wrote:

 ??Dear Josh,

 ??Is this homework? Because the list has a no homework policy.

 ??Best regards,

 ??ir. Thierry Onkelinx
 ??Instituut voor natuur- en bosonderzoek / Research Institute for Nature
 ??and Forest
 ??team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
 ??Kliniekstraat 25
 ??1070 Anderlecht
 ??Belgium

 ??To call in the statistician after the experiment is done may be no more
 ??than asking him to perform a post-mortem examination: he may be able to
 ??say what the experiment died of. ~ Sir Ronald Aylmer Fisher
 ??The plural of anecdote is not data. ~ Roger Brinner
 ??The combination of some data and an aching desire for an answer does not
 ??ensure that a reasonable answer can be extracted from a given body of
 ??data. ~ John Tukey

 ??2015-04-27 2:26 GMT+02:00 Joshua Dixon <joshuamichaeldixon at gmail.com>:

 ?? ? ? ? ?Hello!

 ??Very new to R (10 days), and I've run the linear mixed model, below.
 ??Attempting to interpret what it means...? What do I need to look for?
 ??Residuals, correlations of fixed effects?!

 ??How would I look at very specific interactions, such as PREMIER_LEAGUE
 ??(Level) 18 (AgeGr) GK (Position) mean difference to CHAMPIONSHIP 18
 ??GK?

 ??For reference my data set looks like this:

 ??Id Level AgeGr? ?Position Height Weight BMI YoYo
 ??7451 CHAMPIONSHIP 14 M NA 63 NA 80
 ??148 PREMIER_LEAGUE 16 D NA 64 NA 80
 ??10393 CONFERENCE 10 D NA 36 NA 160
 ??10200 CHAMPIONSHIP 10 F NA 46 NA 160
 ??1961 LEAGUE_TWO 13 GK NA 67 NA 160
 ??10428 CHAMPIONSHIP 10 GK NA 40 NA 160
 ??10541 LEAGUE_ONE 10 F NA 25 NA 160
 ??10012 CHAMPIONSHIP 10 GK NA 30 NA 160
 ??9895 CHAMPIONSHIP 10 D NA 36 NA 160

 ??Many thanks in advance for time and help.? Really appreciate it.

 ??Josh

 ?? ? ? ? ?summary(lmer(YoYo~AgeGr+Position+(1|Id)))

 ??Linear mixed model fit by REML ['lmerMod']
 ??Formula: YoYo ~ AgeGr + Position + (1 | Id)

 ??REML criterion at convergence: 125712.2

 ??Scaled residuals:
 ??? ? ?Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
 ??-3.4407 -0.5288 -0.0874? 0.4531? 4.8242

 ??Random effects:
 ??? Groups? ?Name? ? ? ? Variance Std.Dev.
 ??? Id? ? ? ?(Intercept) 15300? ? 123.7
 ??? Residual? ? ? ? ? ? ?16530? ? 128.6
 ??Number of obs: 9609, groups:? Id, 6071

 ??Fixed effects:
 ??? ? ? ? ? ? ? Estimate Std. Error t value
 ??(Intercept) -521.6985? ? 16.8392? -30.98
 ??AgeGr? ? ? ? ?62.6786? ? ?0.9783? ?64.07
 ??PositionD? ? 139.4682? ? ?7.8568? ?17.75
 ??PositionM? ? 141.2227? ? ?7.7072? ?18.32
 ??PositionF? ? 135.1241? ? ?8.1911? ?16.50

 ??Correlation of Fixed Effects:
 ??? ? ? ? ? ?(Intr) AgeGr? PostnD PostnM
 ??AgeGr? ? ?-0.910
 ??PositionD -0.359 -0.009
 ??PositionM -0.375? 0.001? 0.810
 ??PositionF -0.349 -0.003? 0.756? 0.782

 ?? ? ? ? ?model=lmer(YoYo~AgeGr+Position+(1|Id))
 ??summary(glht(model,linfct=mcp(Position="Tukey")))

 ??? Simultaneous Tests for General Linear Hypotheses

 ??Multiple Comparisons of Means: Tukey Contrasts

 ??Fit: lmer(formula = YoYo ~ AgeGr + Position + (1 | Id))

 ??Linear Hypotheses:
 ??? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
 ??D - GK == 0? 139.468? ? ? 7.857? 17.751? ?<1e-04 ***
 ??M - GK == 0? 141.223? ? ? 7.707? 18.323? ?<1e-04 ***
 ??F - GK == 0? 135.124? ? ? 8.191? 16.496? ?<1e-04 ***
 ??M - D == 0? ? ?1.754? ? ? 4.799? ?0.366? ? 0.983
 ??F - D == 0? ? -4.344? ? ? 5.616? -0.774? ? 0.862
 ??F - M == 0? ? -6.099? ? ? 5.267? -1.158? ? 0.645
 ??---
 ??Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 ??(Adjusted p values reported -- single-step method)

 ??? ? ? ? ?[[alternative HTML version deleted]]

 ??______________________________________________
 ??R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

?https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]]
 ??PLEASE do read the posting guide
 ??http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]]
 ??and provide commented, minimal, self-contained, reproducible code.

 ??? ? ? ? [[alternative HTML version deleted]]

 ??______________________________________________
 ??R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ??https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]]
 ??PLEASE do read the posting guide
 ??http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]]
 ??and provide commented, minimal, self-contained, reproducible code.

 ??____________________________________________________________
 ??FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 ??Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]]] to find out more!

 ??______________________________________________
 ??R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ??https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]]
 ??PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]]
 ??and provide commented, minimal, self-contained, reproducible code.

 ??--
 ??Michael
 ??http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html] [http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html]] [http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html] [http://www.dewey.myzen.co.uk/home.html [http://www.dewey.myzen.co.uk/home.html]]]

 ?____________________________________________________________
 ?Can't remember your password? Do you need a strong and secure password?
 ?Use Password manager! It stores your passwords & protects your account.
 ?Check it out at http://mysecurelogon.com/manager [http://mysecurelogon.com/manager] [http://mysecurelogon.com/manager [http://mysecurelogon.com/manager]]

 ____________________________________________________________
 FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From dcarlson at tamu.edu  Tue Apr 28 23:31:08 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 28 Apr 2015 21:31:08 +0000
Subject: [R] cite publications in the package help file
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D687845@mb02.ads.tamu.edu>

Reproducible examples help. For package MASS do you mean?

http://cran.r-project.org/web/packages/MASS/index.html

Which provides information about the package and a link to the Reference manual:

http://cran.r-project.org/web/packages/MASS/MASS.pdf

In that manual data sets and functions contain a Source entry and/or References for that function or data set. For a large package such as MASS with over 150 functions/data sets, it would be unwieldy to put them all on the web page.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of carol white via R-help
Sent: Tuesday, April 28, 2015 1:28 PM
To: Duncan Murdoch; R-help Help
Subject: Re: [R] cite publications in the package help file

the main web page is meant the page when a package is accessed on CRAN. So is it possible on this page that the content of DESCRIPTION is displayed to display the related publications and also put the related publications so that they appear on the help pdf file?
 


     On Tuesday, April 28, 2015 7:37 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 1:00 PM, carol white via R-help wrote:
> To cite related publications, it seems that they can't be mentioned in? DESCRIPTION. Where to mention so that it appears on the 1st page of? the pdf help file and the package main web page? I'm not talking about what is specified in? inst/citation.

The package help file (e.g. foo-package.Rd for package "foo") will be
displayed first in the PDF, and is the first entry linked in the help
page index for the package.

I don't know what page you mean as the "package main web page".

Duncan Murdoch


  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From drjimlemon at gmail.com  Wed Apr 29 03:00:19 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 29 Apr 2015 11:00:19 +1000
Subject: [R] please help me in r
In-Reply-To: <CADG8gkuQdtMBws3WLRReHqOyAmhNnJ4H21=R8uNr9gUr3pJ7NA@mail.gmail.com>
References: <CADG8gkuQdtMBws3WLRReHqOyAmhNnJ4H21=R8uNr9gUr3pJ7NA@mail.gmail.com>
Message-ID: <CA+8X3fWX5Tc4fVV8yzKm2r1KbhoYRKcozbe2hVdXTvou36qJMg@mail.gmail.com>

Hi Ghada,
The value returned by Mclust ("m" in your example) has different
components from say the hierarchical clustering. The second argument
for "cluster.stats" is the cluster IDs of the objects in the initial
set. Perhaps if you call it like this:

cluster.stats(d,m$classification)

I don't have the mclust package, so this is a guess.

Jim


On Wed, Apr 29, 2015 at 3:39 AM, Ghada Almousa <ghada.f.mm at gmail.com> wrote:
> Hello dears
>
> I using (R tool) in my project
> and I want to compare the results betwen k-mean cluster ,Hierarchical
> cluster and EM cluster
>   I use cluster.stats() it's work on k-mean cluster and hrarichal cluster
> but not work in EM
>
> Hello Dears
>  I Use R tool in my project
> I want to do comparison of the results between the k-mean cluster
> ,Hierarchical cluster and EM cluster
>    I use cluster.stats () function that it is working on a the k-mean
> cluster ,Hierarchical cluster  But do not work in EM
> mydata<-(data)
> my <-data.matrix(mydata)
> d<-dist(as.matrix(my
>  library(mclust)
> m <- Mclust(d, G =2)
> cluster.stats(d, m
> Error in max(clustering) : invalid 'type' (list) of argument
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Apr 29 03:14:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 29 Apr 2015 11:14:43 +1000
Subject: [R] Limiting state probability for Markov chain
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2BD1C@SRVEXCHMBX.precheza.cz>
References: <CAGNVZpq0S0UwXFvaaKqgsbSwg-+tszoRYh98nucKS+TQpv4mng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2BD1C@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+8X3fV=uSvvtMBefWda3aewSWKaqNcX3kA7dASqGc4vDfGh6A@mail.gmail.com>

Hi Justin,
As already noted, you want to compare two values in your "if"
statement. I think you may want to do it like this:

my_fun<-function(A,b) {
 for(j in 1:3) {
  x<-A;
  while((sum(x[j,])==1)) {
   x<-x%*%x;
   print(x);
   if(b%*%x[,j]==b[j]) break;
  }
 }
}

Jim

Justin USHIZE RUTIKANGA wrote:
>> Dear All,
>>
>> I am trying to determine  the liming state probability  .
>> my_fun<-function(A,b){
>> for (j in 1:3){
>> x<-A;
>> while ((sum(x[j,]) ==1) )
>> {
>>   x <- x%*%x;
>>   print (x);
>>   if ( b%*%x==b)
>>   {
>>     break;
>>   }}}
>> }
>> A<-rbind(c(.5,.3,.2), c(.3,.3,.4),c(.1,.5,.4))
>> b <- matrix(data=c(1,0,0), nrow=1, ncol=3, byrow=FALSE)
>> my_fun(A,b)
>>
>> I got the  following warning
>> 1: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 2: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 3: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 4: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 5: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 6: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 7: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 8: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> 9: In if (b %*% x == b) { :
>>   the condition has length > 1 and only the first element will be used
>> your help will be appreciate
>>


From kevin511511 at gmail.com  Wed Apr 29 03:40:18 2015
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Tue, 28 Apr 2015 21:40:18 -0400
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <553F638A.8040005@gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
	<553F638A.8040005@gmail.com>
Message-ID: <CAB4W2n7Y6qBt1mL0YY2TGqC3Wskc==xA8MEG=qaCQfJj3KiPGw@mail.gmail.com>

I still cannot solve the problem:  'invalid function value in 'nlm'
optimizer'

I want to get the MLE for theta[1] and theta[2], my code is below:


x <- c(2,5,3,7,3,2,4)
delta <- c(1, 0, 1, 1, 1, 0, 1)

# -log likelihood
#alpha<-theta[1]
#lamda<-theta[2]
ln<-function(theta,x1,x2  )
  {

 -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
}


#MLE
nlm(ln,theta<-c(1,1),x1=x, x2=delta, hessian=TRUE)


On Tue, Apr 28, 2015 at 6:40 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 28/04/2015 2:43 AM, Hanze Zhang wrote:
> > Hi, R users,
> >
> >
> > I am using nlm function to get the MLE of parameter alpha and lambda
> from a
> >  parametric survival model (Weibull distribution). However, this message
> > always came out: ' invalid function value in 'nlm' optimizer'. Could
> anyone
> > help me? Code is
> >
> > project<-read.table(file="C://data.txt", header=T, as.is=T)
> > names(project)
> > attach(project)
> >
> > x<-time
> > delta<-ind
> >
> >
> > # -log likelihood
> > #alpha<-theta[1]
> > #lambda<-theta[2]
> > ln<-function(theta)
> >   {
> >
> >
> -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
> > }
> >
> > #MLE
> > nlm(ln,theta<-c(1,1),hessian=TRUE)
>
> You are taking logs of parameters.  Probably the optimizer is setting
> the parameters to negative values, and so the log returns NaN.
>
> You can avoid this by testing your parameters on input, and always
> returning a valid number.  There are lots of ways to do this: One
> strategy is to return +Inf for invalid values; another is to move the
> parameter to the nearest boundary, and apply a penalty according to how
> far you moved it.  Or just take the absolute value of the parameter.  Or
> reparametrize so that illegal values aren't possible.
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Wed Apr 29 04:09:40 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 29 Apr 2015 12:09:40 +1000
Subject: [R] select portion of text file using R
In-Reply-To: <CAMk+s2RaP901wzThr9a7_o+-OPS+LYvKtSwK=HgQUxVxAwz1nw@mail.gmail.com>
References: <CAMk+s2SGu5iZox-kxi3wOcEiwaYkCLWpEw-AJs9RhH83zr_V6w@mail.gmail.com>	<5534E05C.2010407@gmail.com>	<CAMk+s2TA-oumPnkW1UXvaNmyHEMe7Kw32ii7K8bFUHE9-4cQSA@mail.gmail.com>	<000401d08152$d8983720$89c8a560$@bigpond.com>
	<CAMk+s2RaP901wzThr9a7_o+-OPS+LYvKtSwK=HgQUxVxAwz1nw@mail.gmail.com>
Message-ID: <000001d08221$8d3c8630$a7b59290$@bigpond.com>

Hi Luigi

If it is an excel sheet can you split the excel sheet into sections and import them that way
There are several ways to import excel
If you only have a text file:

# The good news is that the file is tab delimited although multiple for some columns
xlines <- readLines("G:/1/plate 2.txt")
# similar to prev post
xlines = sub("^[\\[\\*]+.*$","", xlines)
xlines = xlines[nchar(xlines)>0]
# get non numeric row ? col headers
grep('^[^0-9]', xlines)
# ? second group
xlines[386]
# first group
x1 <- xlines[2:385]
head(x1)
tail(x1)
strsplit(x1[1],"\t+")
dat1 = data.frame(do.call(rbind, lapply(x1, function(x) unlist(strsplit(x, "\t+")))))
dat1
# remove " "
dat1[,10] = sub(" ","", dat1[,10])
# split colours
data.frame(do.call(rbind, lapply(dat1[,4],function(x) unlist(strsplit(gsub("[RGB\\(\\)]+","", x),",")))))

If you have not got a good text editor then get one; there are plenty of free ones not to mention shareware; very handy to view the separators 

You will have to split it into sections based on grepping the non numeric lines
The method will be similar to above for the different sections
I suggest you read up on regular expressions - I use them every day in various ways.
? sub 
and follow the prompts as well as the page

Duncan

-----Original Message-----
From: Luigi Marongiu [mailto:marongiu.luigi at gmail.com] 
Sent: Wednesday, 29 April 2015 08:06
To: Duncan Mackay
Subject: Re: [R] select portion of text file using R

Dear Duncan,
thank you for your reply. Please find attached the file I need to read
for further reference. I can't paste the content of the file because,
as you cans see, the content is huge; I need to send the path to the
file to a function that can screen the content of the file and select
the good part of it. The file is a flatfile version of an excel
spreadsheet and thus divided in different sections, each with a entry
part with comments that shall be removed.
The actual script I have is:
raw.data<-read.table(
      plate,
      header=TRUE,
      row.names=1,
      dec=".",
      sep="\t",
      skip = 30,
      nrows = 17281,
      row.names = 1:17281
    )
where plate is the path to the file (my count of the entry section is
30, coming from the calc spreadsheet version of the file).
The error I am getting is:
>Error in read.table(plate, header = TRUE, row.names = 31, dec = ".", sep = "\t",  :
  formal argument "row.names" matched by multiple actual arguments
and when removing the row.names argument the error becomes:
>Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 17283 did not have 5 elements
so I reduced nrows to 17280 but the the error became:
>Error in data[[rlabp]] : subscript out of bounds
How can I overcome these issues?
Best regards
Luigi


On Tue, Apr 28, 2015 at 2:30 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> I think there may be problems with \t being equivalent to tab chr(9)
>
> Therefore try
>
> xlines <-
> readLines(textConnection("* Block Type = Array Card Block
> * Calibration Background is expired = No
> * Calibration Background performed on = 2014-12-02 11:27:49 AM PST
> * Calibration FAM is expired = No
> * Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
> * Calibration ROI is expired = No
> * Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
> * Calibration ROX is expired = No
> * Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
> * Calibration Uniformity is expired = No
> * Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
> * Calibration VIC is expired = No
> * Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
> * Chemistry = TAQMAN
> * Experiment Barcode =
> * Experiment Comments =
> * Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
> * Experiment Name = 2015-04-13 171216
> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> * Experiment Type = Comparative C? (??C?)
> * Experiment User Name =
> * Instrument Name = 278882033
> * Instrument Serial Number = 278882033
> * Instrument Type = ViiA 7
> * Passive Reference = ROX
> * Quantification Cycle Method = Ct
> * Signal Smoothing On = false
> * Stage/ Cycle where Analysis is performed = Stage 3, Step 2
> Well  Cycle   Target  Name  Rn
>   1   1   Adeno 1   0.82
>   1   2   Adeno 1   0.93
>   2   1   Adeno 2   0.78") )
> xlines = sub("^\\*.*$","", xlines)
> xlines = xlines[nchar(xlines)>0]
> xlines = sub("^[[:space:]]+","", xlines)
> xlines = xlines[-1]
> datc = data.frame(do.call(rbind, lapply(xlines, function(x) unlist(strsplit(x, "[[:space:]]+")))))
> names(datc) = c("Well","Cycle","Target","Name","Rn")
> dat = datc
> for (j in c(1,2,4,5)) dat[,j] = as.numeric(dat[,j])
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi Marongiu
> Sent: Tuesday, 28 April 2015 07:20
> To: Duncan Murdoch; r-help
> Subject: Re: [R] select portion of text file using R
>
> Dear Duncan,
> thank you for your reply,
> I tried to read the file using skip and nrows but it did not work.
> Here i am pasting the code I wrote and the head of the file i need to
> read. Probably the error is due to the fact that the column "well" has
> duplication, but how can i add a row column with unique row names? How
> can I overcome this error?
> Best regards
> Luigi
>
> CODE
> raw.data<-read.table(
>       mydata,
>       header=TRUE,
>       row.names=31,
>       dec=".",
>       sep="\t",
>       skip = 30,
>       nrows = 17281,
>       row.names = 1:17281
>     )
>
>
> HEAD OF MYDATA
> * Block Type = Array Card Block
> * Calibration Background is expired = No
> * Calibration Background performed on = 2014-12-02 11:27:49 AM PST
> * Calibration FAM is expired = No
> * Calibration FAM performed on = 2014-12-02 12:00:20 PM PST
> * Calibration ROI is expired = No
> * Calibration ROI performed on = 2014-12-02 11:20:40 AM PST
> * Calibration ROX is expired = No
> * Calibration ROX performed on = 2014-12-02 12:11:21 PM PST
> * Calibration Uniformity is expired = No
> * Calibration Uniformity performed on = 2014-12-02 11:43:43 AM PST
> * Calibration VIC is expired = No
> * Calibration VIC performed on = 2014-12-02 11:51:59 AM PST
> * Chemistry = TAQMAN
> * Experiment Barcode =
> * Experiment Comments =
> * Experiment File Name = F:\2015-04-13 Gastro array 59 Luigi - plate 3.eds
> * Experiment Name = 2015-04-13 171216
> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
> * Experiment Type = Comparative C? (??C?)
> * Experiment User Name =
> * Instrument Name = 278882033
> * Instrument Serial Number = 278882033
> * Instrument Type = ViiA 7
> * Passive Reference = ROX
> * Quantification Cycle Method = Ct
> * Signal Smoothing On = false
> * Stage/ Cycle where Analysis is performed = Stage 3, Step 2
>
> [Amplification Data]
>
> Well \tCycle \tTarget \tName \tRn
> \t1 \t1 \tAdeno 1 \t0.82
> \t1 \t2 \tAdeno 1\ \t0.93
> ...
> \t2 \t1 \tAdeno 2 \t0.78
> ...
>
> On Mon, Apr 20, 2015 at 12:17 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 20/04/2015 3:28 AM, Luigi Marongiu wrote:
>>> Dear all,
>>> I have a flat file (tab delimited) derived from an excel file which is
>>> subdivided in different parts: a first part is reporting metadata,
>>> then there is a first spreadsheet indicated by [ ], then the actual
>>> data and the second spreadsheet with the same format [ ] and then the
>>> data.
>>> How can I import such file using for instance read.table()?
>>
>> read.table() by itself can't recognize where the data starts, but it has
>> arguments "skip" and "nrows" to control how much gets read.  If you
>> don't know the values for those arguments, you can use readLines() to
>> read the entire file, then use grep() to recognize your table data, and
>> either re-read the file, or just extract those lines and read from them
>> as a textConnection.
>>
>> Duncan Murdoch
>>
>>> Many thanks
>>> regards
>>> Luigi
>>>
>>> Here is a sample of the file:
>>> * Experiment Barcode =
>>> * Experiment Comments =
>>> * Experiment File Name = F:\array 59
>>> * Experiment Name = 2015-04-13 171216
>>> * Experiment Run End Time = 2015-04-13 18:07:57 PM PDT
>>> ...
>>> [Amplification Data]
>>> Well    Cycle    Target Name    Rn    Delta Rn
>>> 1    1    Adeno 1-Adeno 1    0.820    -0.051
>>> 1    2    Adeno 1-Adeno 1    0.827    -0.042
>>> 1    3    Adeno 1-Adeno 1    0.843    -0.025
>>> 1    4    Adeno 1-Adeno 1    0.852    -0.015
>>> 1    5    Adeno 1-Adeno 1    0.858    -0.008
>>> 1    6    Adeno 1-Adeno 1    0.862    -0.002
>>> ...
>>> [Results]
>>> Well    Well Position    Omit    Sample Name    Target Name    Task
>>> Reporter    Quencher    RQ    RQ Min    RQ Max    CT    Ct Mean    Ct
>>> SD    Quantity    Delta Ct Mean    Delta Ct SD    Delta Delta Ct
>>> Automatic Ct Threshold    Ct Threshold    Automatic Baseline
>>> Baseline Start    Baseline End    Efficiency    Comments    Custom1
>>> Custom2    Custom3    Custom4    Custom5    Custom6    NOAMP
>>> EXPFAIL
>>> 1    A1    false    P17    Adeno 1-Adeno 1    UNKNOWN    FAM
>>> NFQ-MGB                Undetermined                            false
>>>  0.200    true    3    44    1.000    N/A                            N
>>>    Y
>>> 2    A2    false    P17    Adeno 40/41 EH-AIQJCT3    UNKNOWN    FAM
>>> NFQ-MGB                Undetermined
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Wed Apr 29 05:06:45 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 28 Apr 2015 20:06:45 -0700
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <CAB4W2n7Y6qBt1mL0YY2TGqC3Wskc==xA8MEG=qaCQfJj3KiPGw@mail.gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
	<553F638A.8040005@gmail.com>
	<CAB4W2n7Y6qBt1mL0YY2TGqC3Wskc==xA8MEG=qaCQfJj3KiPGw@mail.gmail.com>
Message-ID: <CAF8bMcanYy8RiZZGDqb5g5G-nROHoHsnN9ex4GTWp3UrtMQhug@mail.gmail.com>

Your function ln() does not return a scalar.
   > ln(theta=c(1,2))
   [1] 48.5342640972 48.5342640972 48.5342640972 48.5342640972 48.5342640972


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 28, 2015 at 6:40 PM, Hanze Zhang <kevin511511 at gmail.com> wrote:

> I still cannot solve the problem:  'invalid function value in 'nlm'
> optimizer'
>
> I want to get the MLE for theta[1] and theta[2], my code is below:
>
>
> x <- c(2,5,3,7,3,2,4)
> delta <- c(1, 0, 1, 1, 1, 0, 1)
>
> # -log likelihood
> #alpha<-theta[1]
> #lamda<-theta[2]
> ln<-function(theta,x1,x2  )
>   {
>
>
>  -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
> }
>
>
> #MLE
> nlm(ln,theta<-c(1,1),x1=x, x2=delta, hessian=TRUE)
>
>
> On Tue, Apr 28, 2015 at 6:40 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 28/04/2015 2:43 AM, Hanze Zhang wrote:
> > > Hi, R users,
> > >
> > >
> > > I am using nlm function to get the MLE of parameter alpha and lambda
> > from a
> > >  parametric survival model (Weibull distribution). However, this
> message
> > > always came out: ' invalid function value in 'nlm' optimizer'. Could
> > anyone
> > > help me? Code is
> > >
> > > project<-read.table(file="C://data.txt", header=T, as.is=T)
> > > names(project)
> > > attach(project)
> > >
> > > x<-time
> > > delta<-ind
> > >
> > >
> > > # -log likelihood
> > > #alpha<-theta[1]
> > > #lambda<-theta[2]
> > > ln<-function(theta)
> > >   {
> > >
> > >
> >
> -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
> > > }
> > >
> > > #MLE
> > > nlm(ln,theta<-c(1,1),hessian=TRUE)
> >
> > You are taking logs of parameters.  Probably the optimizer is setting
> > the parameters to negative values, and so the log returns NaN.
> >
> > You can avoid this by testing your parameters on input, and always
> > returning a valid number.  There are lots of ways to do this: One
> > strategy is to return +Inf for invalid values; another is to move the
> > parameter to the nearest boundary, and apply a penalty according to how
> > far you moved it.  Or just take the absolute value of the parameter.  Or
> > reparametrize so that illegal values aren't possible.
> >
> > Duncan Murdoch
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Wed Apr 29 09:49:49 2015
From: wht_crl at yahoo.com (carol white)
Date: Wed, 29 Apr 2015 07:49:49 +0000 (UTC)
Subject: [R] package.skeleton warning
In-Reply-To: <553FA5B4.9050303@gmail.com>
References: <553FA5B4.9050303@gmail.com>
Message-ID: <1066081590.276047.1430293789840.JavaMail.yahoo@mail.yahoo.com>

So I finally used 
filenames <- list.files("~/Desktop/myPkg/R/", full.names = TRUE)
package.skeleton(name = "myPackage", code_files = filenames) 
and still despite the warnings mentioned before, the man and R folders seem to have been created correctly. I had put the vignettes folder and inst in the source folder (~/Desktop/myPkg) at the same level as R folder. inst contains citation. but after invoking package.skeleton, nothing happened to copy the vignettes nor inst folders in the myPackage folder. Should package.skeleton have taken care of them or I should process separately?
Thanks
?


     On Tuesday, April 28, 2015 5:22 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 28/04/2015 11:09 AM, carol white wrote:
> I have many code files so listing them will be long. When leave it
> empty, I get
> 
> package.skeleton(name = "myPackage", code_files = "")
> Error in sys.source(cf, envir = environment) : '' is not an existing file

Sorry, I meant "leave it out", i.e. just use
package.skeleton(name="myPackage").? This will look at the objects that
are currently defined in your workspace and base your package on those.

But if you have your code already in a bunch of files in
~/Desktop/myPkg/R/, you could use

filenames <- list.files("~/Desktop/myPkg/R/", full.names = TRUE)

to get all the names in one vector, and use that as the code_files
argument, i.e.

package.skeleton(name = "myPackage", code_files = filenames)

You may need to leave out some files if they aren't all *.R files.

Duncan Murdoch

> 
> Thanks
> 
> On Tuesday, April 28, 2015 4:48 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 28/04/2015 10:05 AM, carol white via R-help wrote:
>>? Hi,Why do I get this warning when I run package.skeleton() and how to
> solve this problem?
>> Warning messages:
>> 1: In package.skeleton(name = "myPackage", code_files =
> "~/Desktop/myPkg/R/") :
>>? ? Invalid file name(s) for R code in ./myPackage/R:
>>? ? 'R'
>>? are now renamed to 'z<name>.R'
>> 2: In file.rename(from = file.path(code_dir, wrong), to =
> file.path(code_dir,? :
>>? ? cannot rename file './myPackage/R/R' to './myPackage/R/zR.R',
> reason 'No such file or directory'
>>
> 
> You are saying that your code is in a file called
> 
> 
> "~/Desktop/myPkg/R/"
> 
> 
> but you have no such file.? If you really do have your code already in
> some files, list them in the code_files argument, otherwise leave it blank.
> 
> Duncan Murdoch
> 
> 
> 
> 



  
	[[alternative HTML version deleted]]


From naresh_gurbuxani at hotmail.com  Wed Apr 29 13:09:19 2015
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Wed, 29 Apr 2015 07:09:19 -0400
Subject: [R] Help with lattice panel function
Message-ID: <SNT150-W6476F94F252DBEB8213C5CFAD70@phx.gbl>

I want to plot multiple variables in xyplot, but plot loess trend for only one of these variables.  My problem is that the last command below does not give the desired result. 
Any help will be gratefully received.
Thanks,Naresh
my.df <- data.frame(date = as.numeric(as.Date("2015-01-01")) + 0:49, x = rnorm(50))
my.df$date <- as.Date(my.df$date, origin = as.Date("1970-01-01"))


library(zoo)
x <- zoo(my.df[,"x"], my.df[,"date"])
max.x <- rollapply(x, 10, max, align = "right")
x <- merge(x, max.x)
my.newdf <- data.frame(x)
my.newdf$date <- as.Date(row.names(my.newdf))


library(lattice)# This works as expected
xyplot(x + max.x ~ date, data = my.newdf, type = "l", 
   auto.key = list(columns = 2, points = FALSE, lines = TRUE), ylab = "x")
   # This does not work
xyplot(x ~ date, data = my.newdf, y2 = max.x, ylab = "x",
   panel = function(x, y, x2, ...){
   	panel.xyplot(x, y, type = "l")
   	panel.loess(x, y, lty = 2)
   	panel.xyplot(x, y2, type = "l")
   })      		 	   		  
	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Wed Apr 29 13:27:55 2015
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Wed, 29 Apr 2015 13:27:55 +0200
Subject: [R] Help with lattice panel function
In-Reply-To: <SNT150-W6476F94F252DBEB8213C5CFAD70@phx.gbl>
References: <SNT150-W6476F94F252DBEB8213C5CFAD70@phx.gbl>
Message-ID: <CAALi0vL=JtobHOU9O=q+wAvUTg5EUvfiArm_VGe1zqU=UjCMCA@mail.gmail.com>

This worked for me. It is btw. quite confusing to name your y-variable x.
I think part of the problem arised from the date format.

xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
       panel = function(x, y, x2, ...){
         panel.xyplot(x, y, type = "l")
         panel.loess(as.numeric(my.newdf$date), my.newdf$max.x, lty = 2)
         #panel.xyplot(x, y2, type = "l")
       })


2015-04-29 13:09 GMT+02:00 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>:

> I want to plot multiple variables in xyplot, but plot loess trend for only
> one of these variables.  My problem is that the last command below does not
> give the desired result.
> Any help will be gratefully received.
> Thanks,Naresh
> my.df <- data.frame(date = as.numeric(as.Date("2015-01-01")) + 0:49, x =
> rnorm(50))
> my.df$date <- as.Date(my.df$date, origin = as.Date("1970-01-01"))
>
>
> library(zoo)
> x <- zoo(my.df[,"x"], my.df[,"date"])
> max.x <- rollapply(x, 10, max, align = "right")
> x <- merge(x, max.x)
> my.newdf <- data.frame(x)
> my.newdf$date <- as.Date(row.names(my.newdf))
>
>
> library(lattice)# This works as expected
> xyplot(x + max.x ~ date, data = my.newdf, type = "l",
>    auto.key = list(columns = 2, points = FALSE, lines = TRUE), ylab = "x")
>    # This does not work
> xyplot(x ~ date, data = my.newdf, y2 = max.x, ylab = "x",
>    panel = function(x, y, x2, ...){
>         panel.xyplot(x, y, type = "l")
>         panel.loess(x, y, lty = 2)
>         panel.xyplot(x, y2, type = "l")
>    })
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr 29 14:00:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Apr 2015 08:00:45 -0400
Subject: [R] package.skeleton warning
In-Reply-To: <1066081590.276047.1430293789840.JavaMail.yahoo@mail.yahoo.com>
References: <553FA5B4.9050303@gmail.com>
	<1066081590.276047.1430293789840.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5540C7ED.1060302@gmail.com>

On 29/04/2015 3:49 AM, carol white wrote:
> So I finally used
> filenames <- list.files("~/Desktop/myPkg/R/", full.names = TRUE)
> package.skeleton(name = "myPackage", code_files = filenames)
> 
> and still despite the warnings mentioned before, the man and R folders
> seem to have been created correctly. I had put the vignettes folder and
> inst in the source folder (~/Desktop/myPkg) at the same level as R
> folder. inst contains citation. but after invoking package.skeleton,
> nothing happened to copy the vignettes nor inst folders in the myPackage
> folder. Should package.skeleton have taken care of them or I should
> process separately?
> 

It sounds as though myPkg is already a complete package, so you probably
shouldn't be using package.skeleton at all.  It's for starting out, not
for modifying an existing package.

So in answer to your question:  package.skeleton won't do anything with
your inst or vignette directories.  You'll need to copy those into the
new package yourself.

Duncan Murdoch


From naresh_gurbuxani at hotmail.com  Wed Apr 29 14:16:24 2015
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Wed, 29 Apr 2015 08:16:24 -0400
Subject: [R] Help with lattice panel function
In-Reply-To: <CAALi0vL=JtobHOU9O=q+wAvUTg5EUvfiArm_VGe1zqU=UjCMCA@mail.gmail.com>
References: <SNT150-W6476F94F252DBEB8213C5CFAD70@phx.gbl>
	<CAALi0vL=JtobHOU9O=q+wAvUTg5EUvfiArm_VGe1zqU=UjCMCA@mail.gmail.com>
Message-ID: <SNT405-EAS251FE7BBDB6EF829F83EBB3FAD70@phx.gbl>

Thanks for your lightening fast response.  This solution works.

Sent from my iPhone

> On Apr 29, 2015, at 7:27 AM, Brandst?tter Christian <bran.chri at gmail.com> wrote:
> 
> This worked for me. It is btw. quite confusing to name your y-variable x. 
> I think part of the problem arised from the date format. 
> 
> xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
>        panel = function(x, y, x2, ...){
>          panel.xyplot(x, y, type = "l")
>          panel.loess(as.numeric(my.newdf$date), my.newdf$max.x, lty = 2)
>          #panel.xyplot(x, y2, type = "l")
>        })
> 
> 
> 2015-04-29 13:09 GMT+02:00 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>:
>> I want to plot multiple variables in xyplot, but plot loess trend for only one of these variables.  My problem is that the last command below does not give the desired result.
>> Any help will be gratefully received.
>> Thanks,Naresh
>> my.df <- data.frame(date = as.numeric(as.Date("2015-01-01")) + 0:49, x = rnorm(50))
>> my.df$date <- as.Date(my.df$date, origin = as.Date("1970-01-01"))
>> 
>> 
>> library(zoo)
>> x <- zoo(my.df[,"x"], my.df[,"date"])
>> max.x <- rollapply(x, 10, max, align = "right")
>> x <- merge(x, max.x)
>> my.newdf <- data.frame(x)
>> my.newdf$date <- as.Date(row.names(my.newdf))
>> 
>> 
>> library(lattice)# This works as expected
>> xyplot(x + max.x ~ date, data = my.newdf, type = "l",
>>    auto.key = list(columns = 2, points = FALSE, lines = TRUE), ylab = "x")
>>    # This does not work
>> xyplot(x ~ date, data = my.newdf, y2 = max.x, ylab = "x",
>>    panel = function(x, y, x2, ...){
>>         panel.xyplot(x, y, type = "l")
>>         panel.loess(x, y, lty = 2)
>>         panel.xyplot(x, y2, type = "l")
>>    })
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From kevin511511 at gmail.com  Wed Apr 29 15:49:05 2015
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Wed, 29 Apr 2015 09:49:05 -0400
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <CAF8bMcanYy8RiZZGDqb5g5G-nROHoHsnN9ex4GTWp3UrtMQhug@mail.gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>
	<553F638A.8040005@gmail.com>
	<CAB4W2n7Y6qBt1mL0YY2TGqC3Wskc==xA8MEG=qaCQfJj3KiPGw@mail.gmail.com>
	<CAF8bMcanYy8RiZZGDqb5g5G-nROHoHsnN9ex4GTWp3UrtMQhug@mail.gmail.com>
Message-ID: <CAB4W2n66r4_V7b0YPcjSU06mCU8rvD1ffp9sC-pSAVCV0043FQ@mail.gmail.com>

How should I do? The issue happened on log likelihood function?

On Tue, Apr 28, 2015 at 11:06 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Your function ln() does not return a scalar.
>    > ln(theta=c(1,2))
>    [1] 48.5342640972 48.5342640972 48.5342640972 48.5342640972 48.
> 5342640972
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 28, 2015 at 6:40 PM, Hanze Zhang <kevin511511 at gmail.com>
> wrote:
>
>> I still cannot solve the problem:  'invalid function value in 'nlm'
>> optimizer'
>>
>> I want to get the MLE for theta[1] and theta[2], my code is below:
>>
>>
>> x <- c(2,5,3,7,3,2,4)
>> delta <- c(1, 0, 1, 1, 1, 0, 1)
>>
>> # -log likelihood
>> #alpha<-theta[1]
>> #lamda<-theta[2]
>> ln<-function(theta,x1,x2  )
>>   {
>>
>>
>>  -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
>> }
>>
>>
>> #MLE
>> nlm(ln,theta<-c(1,1),x1=x, x2=delta, hessian=TRUE)
>>
>>
>> On Tue, Apr 28, 2015 at 6:40 AM, Duncan Murdoch <murdoch.duncan at gmail.com
>> >
>> wrote:
>>
>> > On 28/04/2015 2:43 AM, Hanze Zhang wrote:
>> > > Hi, R users,
>> > >
>> > >
>> > > I am using nlm function to get the MLE of parameter alpha and lambda
>> > from a
>> > >  parametric survival model (Weibull distribution). However, this
>> message
>> > > always came out: ' invalid function value in 'nlm' optimizer'. Could
>> > anyone
>> > > help me? Code is
>> > >
>> > > project<-read.table(file="C://data.txt", header=T, as.is=T)
>> > > names(project)
>> > > attach(project)
>> > >
>> > > x<-time
>> > > delta<-ind
>> > >
>> > >
>> > > # -log likelihood
>> > > #alpha<-theta[1]
>> > > #lambda<-theta[2]
>> > > ln<-function(theta)
>> > >   {
>> > >
>> > >
>> >
>> -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
>> > > }
>> > >
>> > > #MLE
>> > > nlm(ln,theta<-c(1,1),hessian=TRUE)
>> >
>> > You are taking logs of parameters.  Probably the optimizer is setting
>> > the parameters to negative values, and so the log returns NaN.
>> >
>> > You can avoid this by testing your parameters on input, and always
>> > returning a valid number.  There are lots of ways to do this: One
>> > strategy is to return +Inf for invalid values; another is to move the
>> > parameter to the nearest boundary, and apply a penalty according to how
>> > far you moved it.  Or just take the absolute value of the parameter.  Or
>> > reparametrize so that illegal values aren't possible.
>> >
>> > Duncan Murdoch
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr 29 15:54:05 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Apr 2015 09:54:05 -0400
Subject: [R] invalid function value in 'nlm' optimizer
In-Reply-To: <CAB4W2n66r4_V7b0YPcjSU06mCU8rvD1ffp9sC-pSAVCV0043FQ@mail.gmail.com>
References: <CAB4W2n7KfjOkGuz8izGEzWkYjivP8_HYtbYQ5veW-Q7+z6Koyg@mail.gmail.com>	<553F638A.8040005@gmail.com>	<CAB4W2n7Y6qBt1mL0YY2TGqC3Wskc==xA8MEG=qaCQfJj3KiPGw@mail.gmail.com>	<CAF8bMcanYy8RiZZGDqb5g5G-nROHoHsnN9ex4GTWp3UrtMQhug@mail.gmail.com>
	<CAB4W2n66r4_V7b0YPcjSU06mCU8rvD1ffp9sC-pSAVCV0043FQ@mail.gmail.com>
Message-ID: <5540E27D.4090902@gmail.com>

On 29/04/2015 9:49 AM, Hanze Zhang wrote:
> How should I do? The issue happened on log likelihood function?

I imagine it's the log(x[delta==1]) term that is turning the result into 
a vector.

Duncan Murdoch
>
> On Tue, Apr 28, 2015 at 11:06 PM, William Dunlap <wdunlap at tibco.com 
> <mailto:wdunlap at tibco.com>> wrote:
>
>     Your function ln() does not return a scalar.
>        > ln(theta=c(1,2))
>        [1] 48.5342640972 48.5342640972 48.5342640972 48.5342640972
>     48.5342640972 <tel:5342640972>
>
>
>     Bill Dunlap
>     TIBCO Software
>     wdunlap tibco.com <http://tibco.com>
>
>     On Tue, Apr 28, 2015 at 6:40 PM, Hanze Zhang
>     <kevin511511 at gmail.com <mailto:kevin511511 at gmail.com>> wrote:
>
>         I still cannot solve the problem: 'invalid function value in 'nlm'
>         optimizer'
>
>         I want to get the MLE for theta[1] and theta[2], my code is below:
>
>
>         x <- c(2,5,3,7,3,2,4)
>         delta <- c(1, 0, 1, 1, 1, 0, 1)
>
>         # -log likelihood
>         #alpha<-theta[1]
>         #lamda<-theta[2]
>         ln<-function(theta,x1,x2  )
>           {
>
>          -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
>         }
>
>
>         #MLE
>         nlm(ln,theta<-c(1,1),x1=x, x2=delta, hessian=TRUE)
>
>
>         On Tue, Apr 28, 2015 at 6:40 AM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>
>         wrote:
>
>         > On 28/04/2015 2:43 AM, Hanze Zhang wrote:
>         > > Hi, R users,
>         > >
>         > >
>         > > I am using nlm function to get the MLE of parameter alpha
>         and lambda
>         > from a
>         > >  parametric survival model (Weibull distribution).
>         However, this message
>         > > always came out: ' invalid function value in 'nlm'
>         optimizer'. Could
>         > anyone
>         > > help me? Code is
>         > >
>         > > project<-read.table(file="C://data.txt", header=T, as.is
>         <http://as.is>=T)
>         > > names(project)
>         > > attach(project)
>         > >
>         > > x<-time
>         > > delta<-ind
>         > >
>         > >
>         > > # -log likelihood
>         > > #alpha<-theta[1]
>         > > #lambda<-theta[2]
>         > > ln<-function(theta)
>         > >   {
>         > >
>         > >
>         >
>         -sum(delta)*log(theta[1]*theta[2])-sum(delta)*(theta[1]-1)*log(x[delta==1])+theta[2]*sum(x^theta[1])
>         > > }
>         > >
>         > > #MLE
>         > > nlm(ln,theta<-c(1,1),hessian=TRUE)
>         >
>         > You are taking logs of parameters.  Probably the optimizer
>         is setting
>         > the parameters to negative values, and so the log returns NaN.
>         >
>         > You can avoid this by testing your parameters on input, and
>         always
>         > returning a valid number.  There are lots of ways to do
>         this: One
>         > strategy is to return +Inf for invalid values; another is to
>         move the
>         > parameter to the nearest boundary, and apply a penalty
>         according to how
>         > far you moved it.  Or just take the absolute value of the
>         parameter.  Or
>         > reparametrize so that illegal values aren't possible.
>         >
>         > Duncan Murdoch
>         >
>         >
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From dulcalma at bigpond.com  Wed Apr 29 15:56:45 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 29 Apr 2015 23:56:45 +1000
Subject: [R] Help with lattice panel function
In-Reply-To: <SNT405-EAS251FE7BBDB6EF829F83EBB3FAD70@phx.gbl>
References: <SNT150-W6476F94F252DBEB8213C5CFAD70@phx.gbl>	<CAALi0vL=JtobHOU9O=q+wAvUTg5EUvfiArm_VGe1zqU=UjCMCA@mail.gmail.com>
	<SNT405-EAS251FE7BBDB6EF829F83EBB3FAD70@phx.gbl>
Message-ID: <000001d08284$54f91b90$feeb52b0$@bigpond.com>

Did you want both "groups" to have loess?

xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
       panel = function(x, y, x2, ...){
         panel.xyplot(x, y, type = "l")
         panel.loess(as.numeric(my.newdf$date), my.newdf$max.x, lty = 2)
         #panel.xyplot(x, y2, type = "l")
       })

xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
    panel = function(x, y, ...){
   	panel.xyplot(x, y, type = "l")
   	panel.loess(x, y, lty = 2)
   })
# equivalent to above
xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
    outer = F,
    panel = function(x, y, ...){
   	panel.xyplot(x, y, type = "l")
   	panel.loess(x, y, lty = 2)
   })

# both groups with loess
xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
       outer = F,
       panel = panel.superpose,
    panel.groups = function(x, y, ...){
   	panel.xyplot(x, y, type = "l")
   	panel.loess(x, y, lty = 2)
   })

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naresh Gurbuxani
Sent: Wednesday, 29 April 2015 22:16
To: Brandst?tter Christian
Cc: r-help at R-project.org
Subject: Re: [R] Help with lattice panel function

Thanks for your lightening fast response.  This solution works.

Sent from my iPhone

> On Apr 29, 2015, at 7:27 AM, Brandst?tter Christian <bran.chri at gmail.com> wrote:
> 
> This worked for me. It is btw. quite confusing to name your y-variable x. 
> I think part of the problem arised from the date format. 
> 
> xyplot(x + max.x ~ date, data = my.newdf, ylab = "x",
>        panel = function(x, y, x2, ...){
>          panel.xyplot(x, y, type = "l")
>          panel.loess(as.numeric(my.newdf$date), my.newdf$max.x, lty = 2)
>          #panel.xyplot(x, y2, type = "l")
>        })
> 
> 
> 2015-04-29 13:09 GMT+02:00 Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>:
>> I want to plot multiple variables in xyplot, but plot loess trend for only one of these variables.  My problem is that the last command below does not give the desired result.
>> Any help will be gratefully received.
>> Thanks,Naresh
>> my.df <- data.frame(date = as.numeric(as.Date("2015-01-01")) + 0:49, x = rnorm(50))
>> my.df$date <- as.Date(my.df$date, origin = as.Date("1970-01-01"))
>> 
>> 
>> library(zoo)
>> x <- zoo(my.df[,"x"], my.df[,"date"])
>> max.x <- rollapply(x, 10, max, align = "right")
>> x <- merge(x, max.x)
>> my.newdf <- data.frame(x)
>> my.newdf$date <- as.Date(row.names(my.newdf))
>> 
>> 
>> library(lattice)# This works as expected
>> xyplot(x + max.x ~ date, data = my.newdf, type = "l",
>>    auto.key = list(columns = 2, points = FALSE, lines = TRUE), ylab = "x")
>>    # This does not work
>> xyplot(x ~ date, data = my.newdf, y2 = max.x, ylab = "x",
>>    panel = function(x, y, x2, ...){
>>         panel.xyplot(x, y, type = "l")
>>         panel.loess(x, y, lty = 2)
>>         panel.xyplot(x, y2, type = "l")
>>    })
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Martin.Spindler at gmx.de  Wed Apr 29 16:21:16 2015
From: Martin.Spindler at gmx.de (Martin Spindler)
Date: Wed, 29 Apr 2015 16:21:16 +0200
Subject: [R] Problem with predict.lm()
Message-ID: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>

Dear all,
?
the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
?
y <- rnorm(100)
X <- matrix(rnorm(100*10), ncol=10)
lm <- lm(y~X)
Xnew <- matrix(rnorm(100*20), ncol=10)
ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
?
How can I foce predict.lm to use use the new data?
?
Thank you very much for your efforts in advance!
?
Best,
?
Martin


From dcarlson at tamu.edu  Wed Apr 29 16:50:11 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 29 Apr 2015 14:50:11 +0000
Subject: [R] Problem with predict.lm()
In-Reply-To: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
References: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D687A29@mb02.ads.tamu.edu>

Since you passed a matrix to lm() and then a data.frame to predict(), predict can't match up what variables to use for the prediction so it falls back on the original data. This seems to work:

> set.seed(42)
> y <- rnorm(100)
> X <- matrix(rnorm(100*10), ncol=10)
> Xd <- data.frame(X)
> lm <- lm(y~., Xd)
> Xnew <- matrix(rnorm(100*20), ncol=10)
> Xnewd <- data.frame(Xnew)
> ynew <- predict(lm, newdata=Xnewd)
> head(ynew)
          1           2           3           4           5           6 
 0.35404067  0.14073495 -0.45442499  0.31065562 -0.02091366  0.25358175 
> head(predict(lm))
          1           2           3           4           5           6 
 0.75474817  0.06024122 -0.27221466 -0.20344713  0.20218135 -0.24045859 
>

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Spindler
Sent: Wednesday, April 29, 2015 9:21 AM
To: r-help at r-project.org
Subject: [R] Problem with predict.lm()

Dear all,
?
the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
?
y <- rnorm(100)
X <- matrix(rnorm(100*10), ncol=10)
lm <- lm(y~X)
Xnew <- matrix(rnorm(100*20), ncol=10)
ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
?
How can I foce predict.lm to use use the new data?
?
Thank you very much for your efforts in advance!
?
Best,
?
Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From Martin.Spindler at gmx.de  Wed Apr 29 16:56:26 2015
From: Martin.Spindler at gmx.de (Martin Spindler)
Date: Wed, 29 Apr 2015 16:56:26 +0200
Subject: [R] Problem with predict.lm()
Message-ID: <trinity-4f941022-6497-44cd-9bbd-935bddb12b92-1430319386658@3capp-gmx-bs28>

Dear Arnab,
?
Thank you very much for your reply. It does not give an error message.
The problem is that predict does "work and predict" on the old data and does not make the predictions with the provided new data.
?
Best,
?
Martin
?
?

Gesendet:?Mittwoch, 29. April 2015 um 16:51 Uhr
Von:?"ARNAB KR MAITY" <arnab_stat at yahoo.com>
An:?"Martin Spindler" <Martin.Spindler at gmx.de>, "r-help at r-project.org" <r-help at r-project.org>
Betreff:?Re: [R] Problem with predict.lm()

Hi,
?
It seems to be working in my R. Although it is throwing the warning message
?
Warning message:
?
'newdata' had 200 rows but variables found have 100 rows?
?
?y
? [1] -1.071307580 ?0.102414204 -0.965046207 ?1.386057875 ?0.726835339
? [6] -0.186549950 -0.777144258 ?1.137210314 -1.069446945 -0.696084338
?[11] -0.467686285 ?0.997316781 ?0.776265490 -1.385720997 -0.007438381
?[16] ?0.302821728 ?0.024075173 -0.590401970 ?0.877104292 ?0.652724314
?[21] ?2.142135078 ?2.023051454 -0.547221960 ?0.342600702 ?0.080848203
?[26] ?0.074609232 ?0.255946197 -0.191242759 ?1.036445108 ?0.895068954
?[31] ?0.589477883 ?0.123230750 ?1.467210735 -1.636657283 -0.131504288
?[36] -0.665000122 ?0.390977868 ?0.546802014 ?0.445498091 ?1.063872749
?[41] ?1.406788635 -0.037147550 -1.047190960 -0.189105987 ?0.069617165
?[46] -0.049760285 -1.454279226 ?0.358351554 ?0.246587937 -0.060735329
?[51] ?1.664530111 -0.475931484 ?0.405480604 ?1.560446941 -0.030537155
?[56] -1.060319583 -1.828624216 -0.429391165 ?0.301697744 -0.029593593
?[61] -1.696307754 ?0.342678986 -0.433965195 -0.947338037 ?0.318186677
?[66] ?0.539630789 -1.354555193 ?0.086168702 ?0.002950100 ?1.783486665
?[71] -1.182419158 -0.930524123 ?0.376579158 -1.085035387 ?1.186125702
?[76] ?0.719738391 -0.486692820 -2.105396602 ?0.531238276 ?1.302812739
?[81] ?0.347851244 ?0.016452693 ?0.417535566 ?0.277705766 ?2.286275977
?[86] ?1.610183518 ?2.032037030 ?1.319074179 ?1.129375593 ?0.176684807
?[91] -0.630517144 ?1.302785450 ?0.994275267 -0.060116993 -0.655966924
?[96] ?1.628197169 ?1.935532651 -1.635783346 -1.172511179 ?1.238336597
> ynew
? ? ? ? ? ?1 ? ? ? ? ? ?2 ? ? ? ? ? ?3 ? ? ? ? ? ?4 ? ? ? ? ? ?5 ? ? ? ? ? ?6?
-0.270916637 ?0.169149841 ?0.191348061 -0.009541999 ?0.112027155 ?0.016242323?
? ? ? ? ? ?7 ? ? ? ? ? ?8 ? ? ? ? ? ?9 ? ? ? ? ? 10 ? ? ? ? ? 11 ? ? ? ? ? 12?
-0.062178365 ?0.275322344 ?0.397030485 ?0.565078468 ?0.301230303 ?0.305405674?
? ? ? ? ? 13 ? ? ? ? ? 14 ? ? ? ? ? 15 ? ? ? ? ? 16 ? ? ? ? ? 17 ? ? ? ? ? 18?
?0.552136794 -0.151275710 ?0.470280882 ?0.349631748 ?0.022005869 ?0.181384646?
? ? ? ? ? 19 ? ? ? ? ? 20 ? ? ? ? ? 21 ? ? ? ? ? 22 ? ? ? ? ? 23 ? ? ? ? ? 24?
?0.143719339 ?0.478791323 ?0.518731127 ?0.229860133 -0.199433324 ?0.310576455?
? ? ? ? ? 25 ? ? ? ? ? 26 ? ? ? ? ? 27 ? ? ? ? ? 28 ? ? ? ? ? 29 ? ? ? ? ? 30?
?0.127612633 -0.157347145 ?0.413807523 ?0.007961485 -0.288867750 ?0.208759771?
? ? ? ? ? 31 ? ? ? ? ? 32 ? ? ? ? ? 33 ? ? ? ? ? 34 ? ? ? ? ? 35 ? ? ? ? ? 36?
?0.286165027 ?0.299492579 ?0.197312294 ?0.135601904 ?0.452828662 ?0.187191405?
? ? ? ? ? 37 ? ? ? ? ? 38 ? ? ? ? ? 39 ? ? ? ? ? 40 ? ? ? ? ? 41 ? ? ? ? ? 42?
?0.335596502 -0.109960231 -0.303770506 -0.276385255 ?0.429700474 ?0.003930969?
? ? ? ? ? 43 ? ? ? ? ? 44 ? ? ? ? ? 45 ? ? ? ? ? 46 ? ? ? ? ? 47 ? ? ? ? ? 48?
?0.184186301 ?0.140858190 ?0.479882236 ?0.182523553 -0.133845870 ?0.443940376?
? ? ? ? ? 49 ? ? ? ? ? 50 ? ? ? ? ? 51 ? ? ? ? ? 52 ? ? ? ? ? 53 ? ? ? ? ? 54?
?0.070571673 -0.383780163 ?0.362153269 ?0.202527841 ?0.164299813 ?0.327998904?
? ? ? ? ? 55 ? ? ? ? ? 56 ? ? ? ? ? 57 ? ? ? ? ? 58 ? ? ? ? ? 59 ? ? ? ? ? 60?
?0.047612361 -0.032167295 ?0.060976285 ?0.231929803 -0.449532973 ?0.109925656?
? ? ? ? ? 61 ? ? ? ? ? 62 ? ? ? ? ? 63 ? ? ? ? ? 64 ? ? ? ? ? 65 ? ? ? ? ? 66?
?0.468842330 ?0.108507841 ?0.158697337 -0.125813680 ?0.501159861 ?0.101646132?
? ? ? ? ? 67 ? ? ? ? ? 68 ? ? ? ? ? 69 ? ? ? ? ? 70 ? ? ? ? ? 71 ? ? ? ? ? 72?
?0.194383106 -0.006185569 ?0.354467348 ?0.340013811 ?0.088757961 ?0.439984356?
? ? ? ? ? 73 ? ? ? ? ? 74 ? ? ? ? ? 75 ? ? ? ? ? 76 ? ? ? ? ? 77 ? ? ? ? ? 78?
?0.330976669 ?0.449337326 ?0.081841142 -0.190123754 ?0.337794560 -0.111895039?
? ? ? ? ? 79 ? ? ? ? ? 80 ? ? ? ? ? 81 ? ? ? ? ? 82 ? ? ? ? ? 83 ? ? ? ? ? 84?
?0.598231564 ?0.444399789 ?0.388313945 ?0.244270482 ?0.200026237 ?0.009025077?
? ? ? ? ? 85 ? ? ? ? ? 86 ? ? ? ? ? 87 ? ? ? ? ? 88 ? ? ? ? ? 89 ? ? ? ? ? 90?
?0.341093767 -0.164196034 ?0.825849472 ?0.325975911 ?0.494473323 ?0.270037159?
? ? ? ? ? 91 ? ? ? ? ? 92 ? ? ? ? ? 93 ? ? ? ? ? 94 ? ? ? ? ? 95 ? ? ? ? ? 96?
?0.369787280 ?0.247455471 ?0.282701738 -0.541688411 -0.145796547 ?0.073172268?
? ? ? ? ? 97 ? ? ? ? ? 98 ? ? ? ? ? 99 ? ? ? ? ?100?
?0.685833173 -0.079174316 -0.193161949 -0.137517175?
?
?
?

Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb,
Illinois 60115
U.S.A?

------------------------------------------------------------
From: Martin Spindler <Martin.Spindler at gmx.de>
To: r-help at r-project.org
Sent: Wednesday, April 29, 2015 9:21 AM
Subject: [R] Problem with predict.lm()
Dear all,
?
the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
?
y <- rnorm(100)
X <- matrix(rnorm(100*10), ncol=10)
lm <- lm(y~X)
Xnew <- matrix(rnorm(100*20), ncol=10)
ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
?
How can I foce predict.lm to use use the new data?
?
Thank you very much for your efforts in advance!
?
Best,
?
Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.r-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.
?


From dwinsemius at comcast.net  Wed Apr 29 16:56:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 29 Apr 2015 07:56:43 -0700
Subject: [R] Problem with predict.lm()
In-Reply-To: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
References: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
Message-ID: <5B952773-479A-40AC-B9EB-CDBA1F60F7D6@comcast.net>


On Apr 29, 2015, at 7:21 AM, Martin Spindler wrote:

> Dear all,
>  
> the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
>  
> y <- rnorm(100)
> X <- matrix(rnorm(100*10), ncol=10)
> lm <- lm(y~X)
> Xnew <- matrix(rnorm(100*20), ncol=10)
> ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
>  
> How can I foce predict.lm to use use the new data?

If you look at what you are passing to `predict`, it should be apparent why it does not find a proper 'newdata' argument:

str( as.data.frame(Xnew) )
'data.frame':	200 obs. of  10 variables:
 $ V1 : num  1.2 -0.319 -0.175 -1.009 0.197 ...
 $ V2 : num  1.529 -0.107 -1.013 -0.869 1.166 ...
 $ V3 : num  -0.417 -0.34 -0.101 -0.018 -2.237 ...
 $ V4 : num  -2.2274 -1.15 0.0252 1.014 1.9455 ...
 $ V5 : num  -0.207 1.628 -0.24 -0.194 -0.722 ...
 $ V6 : num  -1.176 0.935 -0.862 -1.152 0.815 ...
 $ V7 : num  0.967 -1.464 -1.554 0.065 0.205 ...
 $ V8 : num  -0.282 1.699 -0.267 -0.8 -0.643 ...
 $ V9 : num  -0.34833 -0.24907 -0.84185 -0.0518 -0.00216 ...
 $ V10: num  -0.37 -0.227 -2.949 0.899 -0.586 ...

You need the newdata argument to be named exactly as lm would have coerced into being when given a single X predictor that was a matrix.

Try instead:

ynew <- predict(lm, newdata=list(X=Xnew) )

-- 
David Winsemius
Alameda, CA, USA


From Martin.Spindler at gmx.de  Wed Apr 29 16:59:09 2015
From: Martin.Spindler at gmx.de (Martin Spindler)
Date: Wed, 29 Apr 2015 16:59:09 +0200
Subject: [R] Problem with predict.lm()
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D687A29@mb02.ads.tamu.edu>
References: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D687A29@mb02.ads.tamu.edu>
Message-ID: <trinity-3c89e22e-04f3-4772-95bd-a8e491f285fa-1430319549465@3capp-gmx-bs28>

Thank you! I think I now understand where the problem was.

Best,

Martin
?
?

Gesendet:?Mittwoch, 29. April 2015 um 16:50 Uhr
Von:?"David L Carlson" <dcarlson at tamu.edu>
An:?"Martin Spindler" <Martin.Spindler at gmx.de>, "r-help at r-project.org" <r-help at r-project.org>
Betreff:?RE: [R] Problem with predict.lm()
Since you passed a matrix to lm() and then a data.frame to predict(), predict can't match up what variables to use for the prediction so it falls back on the original data. This seems to work:

> set.seed(42)
> y <- rnorm(100)
> X <- matrix(rnorm(100*10), ncol=10)
> Xd <- data.frame(X)
> lm <- lm(y~., Xd)
> Xnew <- matrix(rnorm(100*20), ncol=10)
> Xnewd <- data.frame(Xnew)
> ynew <- predict(lm, newdata=Xnewd)
> head(ynew)
1 2 3 4 5 6
0.35404067 0.14073495 -0.45442499 0.31065562 -0.02091366 0.25358175
> head(predict(lm))
1 2 3 4 5 6
0.75474817 0.06024122 -0.27221466 -0.20344713 0.20218135 -0.24045859
>

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Spindler
Sent: Wednesday, April 29, 2015 9:21 AM
To: r-help at r-project.org
Subject: [R] Problem with predict.lm()

Dear all,
?
the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
?
y <- rnorm(100)
X <- matrix(rnorm(100*10), ncol=10)
lm <- lm(y~X)
Xnew <- matrix(rnorm(100*20), ncol=10)
ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
?
How can I foce predict.lm to use use the new data?
?
Thank you very much for your efforts in advance!
?
Best,
?
Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From catherine.h.peters at googlemail.com  Wed Apr 29 01:02:18 2015
From: catherine.h.peters at googlemail.com (catherine peters)
Date: Wed, 29 Apr 2015 11:02:18 +1200
Subject: [R] How to solve: error in file(file,
 "rt") : invalid 'description' argument
Message-ID: <etPan.5540117a.643c9869.2d6@catherines-MacBook-Pro.local>

Hi thank you in advance for your assistance.?

I am using the following section of script:?

DirPath_folder?
<-Sys.glob(file.path("/Users/catpeters/Documents/R_working_directory/1_Data_MC_Sorted"))?

for (folder in 1: length(DirPath_folder)) {?

# ## EVERY Control and Impact #?
DirPath_Matrix <-Sys.glob(file.path(DirPath_folder[folder],?
"*Markov_Matrix_Month.txt"))?

data <- read.table(DirPath_Matrix, header = TRUE, sep = ";")?

if (folder ==1) { DATA_ALL1 <- data } else { DATA_ALL1 <- rbind(DATA_ALL1,?
data) }?

if (folder == length(DirPath_folder)) {?
setwd("/Users/catpeters/Documents/R_working_directory/1_Data_MC_Sorted")?
write.table(DATA_ALL1 ,"Matrix_Markov_ALL_MONTH_RB.txt" , col.names=TRUE,?
row.names=FALSE, sep=";") write.table(DATA_ALL1?
,"Matrix_Markov_ALL_MONTH_RB.csv" , col.names=TRUE, row.names=FALSE,?
sep=";") } }?

There seems to be a problem with: data <- read.table(DirPath_Matrix, header?
= TRUE, sep = ";"). When run it returns the Error in file(file, "rt") :?
invalid 'description' argument. This has worked previously and I'm not sure?
where the error is.?

Thanks again?
	[[alternative HTML version deleted]]


From lvest09 at student.sdu.dk  Wed Apr 29 12:26:28 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Wed, 29 Apr 2015 10:26:28 +0000
Subject: [R] LM() and time in R
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>


Hello,

I need some help with a project that I?m working one.

Im trying to make a l regression model (lm) in r with time as independant variable and gas prices as the depended.
But It seems like everything im trying to run it, R freeze, I think that I need to tell R somehow that my time is time but how ?



Hope that you can help me :)
Livia

From arnab_stat at yahoo.com  Wed Apr 29 16:51:22 2015
From: arnab_stat at yahoo.com (ARNAB KR MAITY)
Date: Wed, 29 Apr 2015 14:51:22 +0000 (UTC)
Subject: [R] Problem with predict.lm()
In-Reply-To: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
References: <trinity-02d022b1-e2ef-411e-986f-8b5b76faf555-1430317276183@3capp-gmx-bs14>
Message-ID: <544142796.584570.1430319082498.JavaMail.yahoo@mail.yahoo.com>

Hi,
It seems to be working in my R. Although it is throwing the warning message
Warning message:'newdata' had 200 rows but variables found have 100 rows?
?y? [1] -1.071307580 ?0.102414204 -0.965046207 ?1.386057875 ?0.726835339? [6] -0.186549950 -0.777144258 ?1.137210314 -1.069446945 -0.696084338?[11] -0.467686285 ?0.997316781 ?0.776265490 -1.385720997 -0.007438381?[16] ?0.302821728 ?0.024075173 -0.590401970 ?0.877104292 ?0.652724314?[21] ?2.142135078 ?2.023051454 -0.547221960 ?0.342600702 ?0.080848203?[26] ?0.074609232 ?0.255946197 -0.191242759 ?1.036445108 ?0.895068954?[31] ?0.589477883 ?0.123230750 ?1.467210735 -1.636657283 -0.131504288?[36] -0.665000122 ?0.390977868 ?0.546802014 ?0.445498091 ?1.063872749?[41] ?1.406788635 -0.037147550 -1.047190960 -0.189105987 ?0.069617165?[46] -0.049760285 -1.454279226 ?0.358351554 ?0.246587937 -0.060735329?[51] ?1.664530111 -0.475931484 ?0.405480604 ?1.560446941 -0.030537155?[56] -1.060319583 -1.828624216 -0.429391165 ?0.301697744 -0.029593593?[61] -1.696307754 ?0.342678986 -0.433965195 -0.947338037 ?0.318186677?[66] ?0.539630789 -1.354555193 ?0.086168702 ?0.002950100 ?1.783486665?[71] -1.182419158 -0.930524123 ?0.376579158 -1.085035387 ?1.186125702?[76] ?0.719738391 -0.486692820 -2.105396602 ?0.531238276 ?1.302812739?[81] ?0.347851244 ?0.016452693 ?0.417535566 ?0.277705766 ?2.286275977?[86] ?1.610183518 ?2.032037030 ?1.319074179 ?1.129375593 ?0.176684807?[91] -0.630517144 ?1.302785450 ?0.994275267 -0.060116993 -0.655966924?[96] ?1.628197169 ?1.935532651 -1.635783346 -1.172511179 ?1.238336597> ynew? ? ? ? ? ?1 ? ? ? ? ? ?2 ? ? ? ? ? ?3 ? ? ? ? ? ?4 ? ? ? ? ? ?5 ? ? ? ? ? ?6?-0.270916637 ?0.169149841 ?0.191348061 -0.009541999 ?0.112027155 ?0.016242323?? ? ? ? ? ?7 ? ? ? ? ? ?8 ? ? ? ? ? ?9 ? ? ? ? ? 10 ? ? ? ? ? 11 ? ? ? ? ? 12?-0.062178365 ?0.275322344 ?0.397030485 ?0.565078468 ?0.301230303 ?0.305405674?? ? ? ? ? 13 ? ? ? ? ? 14 ? ? ? ? ? 15 ? ? ? ? ? 16 ? ? ? ? ? 17 ? ? ? ? ? 18??0.552136794 -0.151275710 ?0.470280882 ?0.349631748 ?0.022005869 ?0.181384646?? ? ? ? ? 19 ? ? ? ? ? 20 ? ? ? ? ? 21 ? ? ? ? ? 22 ? ? ? ? ? 23 ? ? ? ? ? 24??0.143719339 ?0.478791323 ?0.518731127 ?0.229860133 -0.199433324 ?0.310576455?? ? ? ? ? 25 ? ? ? ? ? 26 ? ? ? ? ? 27 ? ? ? ? ? 28 ? ? ? ? ? 29 ? ? ? ? ? 30??0.127612633 -0.157347145 ?0.413807523 ?0.007961485 -0.288867750 ?0.208759771?? ? ? ? ? 31 ? ? ? ? ? 32 ? ? ? ? ? 33 ? ? ? ? ? 34 ? ? ? ? ? 35 ? ? ? ? ? 36??0.286165027 ?0.299492579 ?0.197312294 ?0.135601904 ?0.452828662 ?0.187191405?? ? ? ? ? 37 ? ? ? ? ? 38 ? ? ? ? ? 39 ? ? ? ? ? 40 ? ? ? ? ? 41 ? ? ? ? ? 42??0.335596502 -0.109960231 -0.303770506 -0.276385255 ?0.429700474 ?0.003930969?? ? ? ? ? 43 ? ? ? ? ? 44 ? ? ? ? ? 45 ? ? ? ? ? 46 ? ? ? ? ? 47 ? ? ? ? ? 48??0.184186301 ?0.140858190 ?0.479882236 ?0.182523553 -0.133845870 ?0.443940376?? ? ? ? ? 49 ? ? ? ? ? 50 ? ? ? ? ? 51 ? ? ? ? ? 52 ? ? ? ? ? 53 ? ? ? ? ? 54??0.070571673 -0.383780163 ?0.362153269 ?0.202527841 ?0.164299813 ?0.327998904?? ? ? ? ? 55 ? ? ? ? ? 56 ? ? ? ? ? 57 ? ? ? ? ? 58 ? ? ? ? ? 59 ? ? ? ? ? 60??0.047612361 -0.032167295 ?0.060976285 ?0.231929803 -0.449532973 ?0.109925656?? ? ? ? ? 61 ? ? ? ? ? 62 ? ? ? ? ? 63 ? ? ? ? ? 64 ? ? ? ? ? 65 ? ? ? ? ? 66??0.468842330 ?0.108507841 ?0.158697337 -0.125813680 ?0.501159861 ?0.101646132?? ? ? ? ? 67 ? ? ? ? ? 68 ? ? ? ? ? 69 ? ? ? ? ? 70 ? ? ? ? ? 71 ? ? ? ? ? 72??0.194383106 -0.006185569 ?0.354467348 ?0.340013811 ?0.088757961 ?0.439984356?? ? ? ? ? 73 ? ? ? ? ? 74 ? ? ? ? ? 75 ? ? ? ? ? 76 ? ? ? ? ? 77 ? ? ? ? ? 78??0.330976669 ?0.449337326 ?0.081841142 -0.190123754 ?0.337794560 -0.111895039?? ? ? ? ? 79 ? ? ? ? ? 80 ? ? ? ? ? 81 ? ? ? ? ? 82 ? ? ? ? ? 83 ? ? ? ? ? 84??0.598231564 ?0.444399789 ?0.388313945 ?0.244270482 ?0.200026237 ?0.009025077?? ? ? ? ? 85 ? ? ? ? ? 86 ? ? ? ? ? 87 ? ? ? ? ? 88 ? ? ? ? ? 89 ? ? ? ? ? 90??0.341093767 -0.164196034 ?0.825849472 ?0.325975911 ?0.494473323 ?0.270037159?? ? ? ? ? 91 ? ? ? ? ? 92 ? ? ? ? ? 93 ? ? ? ? ? 94 ? ? ? ? ? 95 ? ? ? ? ? 96??0.369787280 ?0.247455471 ?0.282701738 -0.541688411 -0.145796547 ?0.073172268?? ? ? ? ? 97 ? ? ? ? ? 98 ? ? ? ? ? 99 ? ? ? ? ?100??0.685833173 -0.079174316 -0.193161949 -0.137517175?
?Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb,
Illinois 60115
U.S.A
      From: Martin Spindler <Martin.Spindler at gmx.de>
 To: r-help at r-project.org 
 Sent: Wednesday, April 29, 2015 9:21 AM
 Subject: [R] Problem with predict.lm()
   
Dear all,
?
the following example somehow uses the "old data" (X) to make the predictions, but not the new data Xnew as intended.
?
y <- rnorm(100)
X <- matrix(rnorm(100*10), ncol=10)
lm <- lm(y~X)
Xnew <- matrix(rnorm(100*20), ncol=10)
ynew <- predict(lm, newdata=as.data.frame(Xnew)) #prediction in not made for Xnew
?
How can I foce predict.lm to use use the new data?
?
Thank you very much for your efforts in advance!
?
Best,
?
Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From dawoodmalik at hotmail.com  Wed Apr 29 16:47:39 2015
From: dawoodmalik at hotmail.com (dawood ahmad)
Date: Wed, 29 Apr 2015 14:47:39 +0000
Subject: [R] Need Help!
Message-ID: <COL127-W3915E8E1DF7670F4AFA2FBBBD70@phx.gbl>

Dear Sir/Madam,
 
I hope you will be fine. Recently, I have started to use R language. I am new in programming. 
I have to fit my data with mathematical equation which I am pasting below. The problem is that one of the
parameter named "ep" which is x-axis required a loop so that I could a range of data. Please see below the code,
 
 
pi<-3.14159; c<-0.5; xc<-2; s<-6; Hc2<-30; H<-1; ep<-0.01; 
f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) -  trigamma(((c + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H))); 
integrate(f,-pi/s,pi/s)$value
I have typed in bold the x-axis. If I execute this model, it works well. But, I want to make a loop for this parameter inorder to enter a range of values.For instance, from 0.01 to 1 with specific interval (increment interval 0.005). I will be really grateful if you help me in this matter.  With best Regards, Dawood 		 	   		  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Apr 29 20:25:46 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 29 Apr 2015 14:25:46 -0400
Subject: [R] LM() and time in R
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>

Have a look at the help page for the function ts() 
(type ?ts  at the R prompt).  Other than that, you haven't provided nearly enough information for us to diagnose your issue.

Please see here for some hints on how to ask questions productively:
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
Cheers

B.

On Apr 29, 2015, at 6:26 AM, Livia Maria Vestergaard <lvest09 at student.sdu.dk> wrote:

> 
> Hello,
> 
> I need some help with a project that I?m working one.
> 
> Im trying to make a l regression model (lm) in r with time as independant variable and gas prices as the depended.
> But It seems like everything im trying to run it, R freeze, I think that I need to tell R somehow that my time is time but how ?
> 
> 
> 
> Hope that you can help me :)
> Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Wed Apr 29 20:26:49 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 29 Apr 2015 14:26:49 -0400
Subject: [R] Forecasting prices
Message-ID: <20150429142649.26792@web001.roc2.bluetie.com>

Prof. Hydman's book is a good place to start :

https://www.otexts.org/fpp


-----Original Message-----
From: "randomness" [m.kofler at aew.eu]
Date: 04/28/2015 01:52 PM
To: r-help at r-project.org
Subject: [R] Forecasting prices

Hi,
apologies in advance for the generic question but I would highly appreciate
if someone pointed me in the right direction.
My challenge: I need to forecast Prices (Gas & Electricity Spot). Both gas
and electricity Show Autocorrelative and seasonal (hourly, daily, monthly)
behaviour. And there are explaining variables, of which I have forecasts out
of Reuters (temp, production etc). 

I have looked at dynamic linear Regression and neural Networks so far. It
would be great if someone can provide any Input, which model they would
suggest using. I got several conflicting opinions so far, which is of course
suboptimal as I would love to Focus on one subject. Of course if you can
suggest any literature or even have some code I would be very grateful.

Many thanks!

Markus



--
View this message in context: http://r.789695.n4.nabble.com/Forecasting-prices-tp4706535.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nickdoban at gmail.com  Wed Apr 29 19:52:55 2015
From: nickdoban at gmail.com (Nicolae Doban)
Date: Wed, 29 Apr 2015 19:52:55 +0200
Subject: [R] Cross-Validate a Multivariate Polynomial Regression with K-folds
Message-ID: <CADPWiKhJ=3CU9C+NKMjA34-bONKVEyGH2Pbf=dtBHP-syeJVnA@mail.gmail.com>

Hi,

could you tell me please which is the fastest and most accurate
way/algorithm/code of cross-validating a Multivariate Polynomial Regression
with K-folds? I have a dataframe of 5 input variables and I want to predict
one output variable. Every variable features a different power for which
the error is the smallest.

I was replicating the steps from this video:
https://www.youtube.com/watch?v=6dSXlqHAoMk

Ideally, I would want to use also GAM and ANN to see which method behaves
faster and more accurately. Could you also suggest me other non-linear
models?

Thank you in advance,
Nick

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Apr 29 21:02:16 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 29 Apr 2015 15:02:16 -0400
Subject: [R] How to solve: error in file(file,
	"rt") : invalid 'description' argument
In-Reply-To: <etPan.5540117a.643c9869.2d6@catherines-MacBook-Pro.local>
References: <etPan.5540117a.643c9869.2d6@catherines-MacBook-Pro.local>
Message-ID: <5C66D26B-FA38-479E-B66D-1343ECEDE370@utoronto.ca>

If you google for "invalid 'description' argument" it should be pretty clear what's going on - most likely your DirPath_Matrix is not a single item.

B.


On Apr 28, 2015, at 7:02 PM, catherine peters <catherine.h.peters at googlemail.com> wrote:

> Hi thank you in advance for your assistance. 
> 
> I am using the following section of script: 
> 
> DirPath_folder 
> <-Sys.glob(file.path("/Users/catpeters/Documents/R_working_directory/1_Data_MC_Sorted")) 
> 
> for (folder in 1: length(DirPath_folder)) { 
> 
> # ## EVERY Control and Impact # 
> DirPath_Matrix <-Sys.glob(file.path(DirPath_folder[folder], 
> "*Markov_Matrix_Month.txt")) 
> 
> data <- read.table(DirPath_Matrix, header = TRUE, sep = ";") 
> 
> if (folder ==1) { DATA_ALL1 <- data } else { DATA_ALL1 <- rbind(DATA_ALL1, 
> data) } 
> 
> if (folder == length(DirPath_folder)) { 
> setwd("/Users/catpeters/Documents/R_working_directory/1_Data_MC_Sorted") 
> write.table(DATA_ALL1 ,"Matrix_Markov_ALL_MONTH_RB.txt" , col.names=TRUE, 
> row.names=FALSE, sep=";") write.table(DATA_ALL1 
> ,"Matrix_Markov_ALL_MONTH_RB.csv" , col.names=TRUE, row.names=FALSE, 
> sep=";") } } 
> 
> There seems to be a problem with: data <- read.table(DirPath_Matrix, header 
> = TRUE, sep = ";"). When run it returns the Error in file(file, "rt") : 
> invalid 'description' argument. This has worked previously and I'm not sure 
> where the error is. 
> 
> Thanks again 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Apr 29 21:59:59 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 29 Apr 2015 15:59:59 -0400
Subject: [R] Need Help!
In-Reply-To: <COL127-W3915E8E1DF7670F4AFA2FBBBD70@phx.gbl>
References: <COL127-W3915E8E1DF7670F4AFA2FBBBD70@phx.gbl>
Message-ID: <A4CBEE89-D01E-4E56-AD54-0A8347A7D4AE@utoronto.ca>

A: Look at the function seq() e.g. seq(0.01, 1, by=0.005)

B: Don't post in HTML. Seriously. Do not.

C: You need to invest more time getting the basics down. Google for R introduction.

D: Ow. pi is a predefined constant. Your re-defintion loses accuracy. (See C:)

Please see here for some hints on how to ask questions productively:
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


B.




On Apr 29, 2015, at 10:47 AM, dawood ahmad <dawoodmalik at hotmail.com> wrote:

> Dear Sir/Madam,
> 
> I hope you will be fine. Recently, I have started to use R language. I am new in programming. 
> I have to fit my data with mathematical equation which I am pasting below. The problem is that one of the
> parameter named "ep" which is x-axis required a loop so that I could a range of data. Please see below the code,
> 
> 
> pi<-3.14159; c<-0.5; xc<-2; s<-6; Hc2<-30; H<-1; ep<-0.01; 
> f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) -  trigamma(((c + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H))); 
> integrate(f,-pi/s,pi/s)$value
> I have typed in bold the x-axis. If I execute this model, it works well. But, I want to make a loop for this parameter inorder to enter a range of values.For instance, from 0.01 to 1 with specific interval (increment interval 0.005). I will be really grateful if you help me in this matter.  With best Regards, Dawood 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From walke554 at umn.edu  Wed Apr 29 23:27:06 2015
From: walke554 at umn.edu (walke554)
Date: Wed, 29 Apr 2015 14:27:06 -0700 (PDT)
Subject: [R] DeSolver giving "NA" as output, but running fully.
In-Reply-To: <F07BCBA2037.00000E31jrkrideau@inbox.com>
References: <1430166894068-4706497.post@n4.nabble.com>
	<F07BCBA2037.00000E31jrkrideau@inbox.com>
Message-ID: <1430342826590-4706620.post@n4.nabble.com>

All of the data you need to run the ODE integrator is there.  all the
parameters and starting populations and values are given under the:

"#giving the parameters"

section of the code.



--
View this message in context: http://r.789695.n4.nabble.com/DeSolver-giving-NA-as-output-but-running-fully-tp4706497p4706620.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Thu Apr 30 00:59:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Apr 2015 08:59:32 +1000
Subject: [R] LM() and time in R
In-Reply-To: <C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>
	<C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>
Message-ID: <CA+8X3fXGQMEhK+WzuRW0bPX-67C_a4pk16BU=h8SCVErEEBjxQ@mail.gmail.com>

Hi Livia,
>From your description, it sounds like the "time" variable is actually
a vector of date strings like "30/04/2015". These will usually be
input as "factors" in R, meaning that you probably had a very large
number of categorical values instead of numeric. To find out, do this:

is.factor(time_variable)

where "time_variable" is something like mydata$Time. If the answer is
TRUE, convert that variable to a vector of dates with as.Date and try
your analysis again.

Jim


On Thu, Apr 30, 2015 at 4:25 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Have a look at the help page for the function ts()
> (type ?ts  at the R prompt).  Other than that, you haven't provided nearly enough information for us to diagnose your issue.
>
> Please see here for some hints on how to ask questions productively:
> http://adv-r.had.co.nz/Reproducibility.html
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> Cheers
>
> B.
>
> On Apr 29, 2015, at 6:26 AM, Livia Maria Vestergaard <lvest09 at student.sdu.dk> wrote:
>
>>
>> Hello,
>>
>> I need some help with a project that I?m working one.
>>
>> Im trying to make a l regression model (lm) in r with time as independant variable and gas prices as the depended.
>> But It seems like everything im trying to run it, R freeze, I think that I need to tell R somehow that my time is time but how ?
>>
>>
>>
>> Hope that you can help me :)
>> Livia
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dafemlions at yahoo.co.uk  Thu Apr 30 03:56:46 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Thu, 30 Apr 2015 01:56:46 +0000 (UTC)
Subject: [R] Stacking of vectors to form a column vector
Message-ID: <511855918.1280496.1430359006066.JavaMail.yahoo@mail.yahoo.com>

Hello,I am estimating a system of nonlinear equation where I need to stack my vector of y. I have data of about 6000units. I tried using the rbind but instead of having a vector of 1 by 18000, it is giving me a 3 by 6000 so that my matrix multiplication is non-conformable. The stack command requires an identifier but in this case, I do not have a unique identifier.
I would like to stack the the first 6000 units of y1 on the 2nd 6000 units of y2 and 6000 units of y3.
Any help will be greatly appreciated.
ThanksOlufemi

?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Apr 30 04:31:49 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 29 Apr 2015 19:31:49 -0700
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <511855918.1280496.1430359006066.JavaMail.yahoo@mail.yahoo.com>
References: <511855918.1280496.1430359006066.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>

Vectors are not "columns" or "rows". Use the c() function to concatenate vectors.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>Hello,I am estimating a system of nonlinear equation where I need to
>stack my vector of y. I have data of about 6000units. I tried using the
>rbind but instead of having a vector of 1 by 18000, it is giving me a 3
>by 6000 so that my matrix multiplication is non-conformable. The stack
>command requires an identifier but in this case, I do not have a unique
>identifier.
>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>units of y2 and 6000 units of y3.
>Any help will be greatly appreciated.
>ThanksOlufemi
>
>?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dafemlions at yahoo.co.uk  Thu Apr 30 04:48:24 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Thu, 30 Apr 2015 02:48:24 +0000 (UTC)
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
Message-ID: <1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>

Thank you Jeff for your response.
My y1, y2, y3 are actually 3 columns in the data so I cannot use the c() function to concatenate them. I am confusing the "columns" with vectors. I actually meant columns.
Any help will be much appreciated
Olufemi?
 


     On Wednesday, 29 April 2015, 22:31, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
   

 Vectors are not "columns" or "rows". Use the c() function to concatenate vectors.
---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.


> wrote:
>Hello,I am estimating a system of nonlinear equation where I need to
>stack my vector of y. I have data of about 6000units. I tried using the
>rbind but instead of having a vector of 1 by 18000, it is giving me a 3
>by 6000 so that my matrix multiplication is non-conformable. The stack
>command requires an identifier but in this case, I do not have a unique
>identifier.
>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>units of y2 and 6000 units of y3.
>Any help will be greatly appreciated.
>ThanksOlufemi
>
>?
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Apr 30 05:20:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 29 Apr 2015 20:20:25 -0700
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
	<1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>

I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>Thank you Jeff for your response.
>My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>c() function to concatenate them. I am confusing the "columns" with
>vectors. I actually meant columns.
>Any help will be much appreciated
>Olufemi?
> 
>
>
>On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
><jdnewmil at dcn.davis.CA.us> wrote:
>   
>
>Vectors are not "columns" or "rows". Use the c() function to
>concatenate vectors.
>---------------------------------------------------------------------------
>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>Go...
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.?
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
><dafemlions at yahoo.co.uk> wrote:
>>Hello,I am estimating a system of nonlinear equation where I need to
>>stack my vector of y. I have data of about 6000units. I tried using
>the
>>rbind but instead of having a vector of 1 by 18000, it is giving me a
>3
>>by 6000 so that my matrix multiplication is non-conformable. The stack
>>command requires an identifier but in this case, I do not have a
>unique
>>identifier.
>>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>units of y2 and 6000 units of y3.
>>Any help will be greatly appreciated.
>>ThanksOlufemi
>>
>>?
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From toby at huksu.com  Thu Apr 30 00:05:03 2015
From: toby at huksu.com (thuksu)
Date: Wed, 29 Apr 2015 15:05:03 -0700 (PDT)
Subject: [R] GLM: What is a good way for dealing with new factor levels in
 the test set?
Message-ID: <1430345103451-4706621.post@n4.nabble.com>

My training set and my test set have some factor levels that are
different....  It's rare, but it occurs.

What is a good way for dealing with this?

I don't want to throw away the entire row from the data frame, because there
is some valuable information in there.

Is there some way to say something like "use the weighted average
coefficient level for this factor"?



--
View this message in context: http://r.789695.n4.nabble.com/GLM-What-is-a-good-way-for-dealing-with-new-factor-levels-in-the-test-set-tp4706621.html
Sent from the R help mailing list archive at Nabble.com.


From lutipilotto at yahoo.com.br  Thu Apr 30 03:45:26 2015
From: lutipilotto at yahoo.com.br (Luciane Maria Pilotto)
Date: Wed, 29 Apr 2015 18:45:26 -0700
Subject: [R] help - hoslem.test
Message-ID: <1430358326.99757.YahooMailBasic@web120206.mail.ne1.yahoo.com>

Hello,

I'm working with ordinal logistic regression model (polr) and would like to test the proportional odds assumption. For this, I ran the binary logistic regressions with varying cutpoints on the dependent variable, as described in the following commands. When running the test of Hosmer and Lemeshow (hoslem.test) for residuals gives error.

Thanks,
Luciane 


From drjimlemon at gmail.com  Thu Apr 30 08:51:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Apr 2015 16:51:32 +1000
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
	<1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
	<B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>
Message-ID: <CA+8X3fVYS6cjU=XGKi_SuxE=D5M=ng80E4C6HQ++-YLRiQ=55Q@mail.gmail.com>

Hi Olufemi,
I sounds like you have a data frame (let's call it "mydata") with at
least three elements (columns). You may be trying to use c() in this
way:

y1to3<-c(y1,y2,y3)

in which case it won't work. However:

y1to3<-c(mydata$y1,mydata$y2,mydata$y3)

might do what you want, substituting whatever the name of your data
frame is for "mydata".

Jim


On Thu, Apr 30, 2015 at 1:20 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>>Thank you Jeff for your response.
>>My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>>c() function to concatenate them. I am confusing the "columns" with
>>vectors. I actually meant columns.
>>Any help will be much appreciated
>>Olufemi
>>
>>
>>
>>On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
>><jdnewmil at dcn.davis.CA.us> wrote:
>>
>>
>>Vectors are not "columns" or "rows". Use the c() function to
>>concatenate vectors.
>>---------------------------------------------------------------------------
>>Jeff Newmiller                        The    .....      .....  Go
>>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.      ##.#.  Live
>>Go...
>>                                      Live:  OO#.. Dead: OO#..  Playing
>>Research Engineer (Solar/Batteries            O.O#.      #.O#.  with
>>/Software/Embedded Controllers)              .OO#.      .OO#.
>>rocks...1k
>>---------------------------------------------------------------------------
>>
>>Sent from my phone. Please excuse my brevity.
>>
>>On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
>><dafemlions at yahoo.co.uk> wrote:
>>>Hello,I am estimating a system of nonlinear equation where I need to
>>>stack my vector of y. I have data of about 6000units. I tried using
>>the
>>>rbind but instead of having a vector of 1 by 18000, it is giving me a
>>3
>>>by 6000 so that my matrix multiplication is non-conformable. The stack
>>>command requires an identifier but in this case, I do not have a
>>unique
>>>identifier.
>>>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>>units of y2 and 6000 units of y3.
>>>Any help will be greatly appreciated.
>>>ThanksOlufemi
>>>
>>>
>>>
>>>    [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Apr 30 08:54:34 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Apr 2015 16:54:34 +1000
Subject: [R] GLM: What is a good way for dealing with new factor levels
 in the test set?
In-Reply-To: <1430345103451-4706621.post@n4.nabble.com>
References: <1430345103451-4706621.post@n4.nabble.com>
Message-ID: <CA+8X3fVpesBYY9bXbyHwYQUXrrrTh1qA_7USuAh3hvg0oaGmNg@mail.gmail.com>

Hi thuksu,
Would defining the factor in your training set with all the levels
that occur in the test set solve the problem? That is, there would be
at least one factor level in the training set even though there were
no instances of that factor.

Jim


On Thu, Apr 30, 2015 at 8:05 AM, thuksu <toby at huksu.com> wrote:
> My training set and my test set have some factor levels that are
> different....  It's rare, but it occurs.
>
> What is a good way for dealing with this?
>
> I don't want to throw away the entire row from the data frame, because there
> is some valuable information in there.
>
> Is there some way to say something like "use the weighted average
> coefficient level for this factor"?
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/GLM-What-is-a-good-way-for-dealing-with-new-factor-levels-in-the-test-set-tp4706621.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tsjerkw at gmail.com  Thu Apr 30 09:01:07 2015
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Thu, 30 Apr 2015 09:01:07 +0200
Subject: [R] DeSolver giving "NA" as output, but running fully.
In-Reply-To: <1430166894068-4706497.post@n4.nabble.com>
References: <1430166894068-4706497.post@n4.nabble.com>
Message-ID: <CABzE1SiEFpOJzc16QwftUGzLEgPADMFn+mmE=bNtMZKfJZjvuw@mail.gmail.com>

Hey :)


        W2MH = y[43]; #number of infected vaccinated males high risk
> infected with
> non-vaccine strain
>

> length(y0)

[1] 42


As a sidenote, would you mind sharing the flow diagram with me, so I can
show it to my students doing a practical with DeSolve, as example of a
contemporary model?

Cheers,

Tsjerk

-- 
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 30 10:33:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Apr 2015 18:33:47 +1000
Subject: [R] LM() and time in R
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42646@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>
	<C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>
	<2DFEDD9D3576FB419C7BF7511E983C964AE42646@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <CA+8X3fU-ciOtjEWnBEdmx5Qc0Awc1-+0wwBbGNRC0rJbNYqVSQ@mail.gmail.com>

Hi Livia,
You can convert the time of day fields using strptime like this:

strptime(sapply(strsplit("time: 08:14:22"," "),"[",2),"%H:%M:%S")

This will give you the times as seconds in the current day. If you
then wish to divide the day into morning, afternoon and night, you
could create three time cutpoints, say:

strptime("06:00:00","%H:%M:%S")
strptime("12:00:00","%H:%M:%S")
strptime("20:00:00","%H:%M:%S")

such that any time less than the first or more than the third would be
night, and so on. I think it might be a good idea to factor the daily
price of crude oil (get this from the date) into the regression just
to see how much variance that explains compared to time of day
variations.

Jim

On Thu, Apr 30, 2015 at 6:06 PM, Livia Maria Vestergaard
<lvest09 at student.sdu.dk> wrote:
> Hello guys,
> thanks for your quick reply
> I will try and specific my problem
>
> I have over 300.000 observations for different petrol pumps in all of Denmark fra 1. november 2014 - 31 january 2015
> for example I have:
>
> petrol pump number:  "1111" /  date: 1. november 2014 / time: 08:14:22 / price: 10.55 /day /   zipcode: 2000
> petrol pump number:  "1111" /  date: 1. november 2014 / time: 08:29:00 / price: 10.52 / day / zipcode: 2000
> petrol pump number: "3456" / date: 1. november 2014 / time: 08:19:21 / price: 10.88 / day/  zipcode: 2100
>
>
> And then put the zip codes into dummy categories like X1: zipcode (1000-2000)=1 all others 0 and so on.
>
> My regression model then look like
>
> lm(price, x1 + x2 + x3 ...  ) but the "Multiple R-squared" is really low, 0.01217
>
> So instead I would like to check if the time "hh:mm:ss" have an effect on the price. I know how to tell R about the date by as.Date() , but not with the time, how can I do that?
>
>
> Or do you guys maybe a third idea about what should make a regression about to improve the model?
>
> Cheers
> Livia :)
>
> ________________________________________
> Fra: Boris Steipe [boris.steipe at utoronto.ca]
> Sendt: 29. april 2015 20:25
> Til: Livia Maria Vestergaard
> Cc: r-help mailing list
> Emne: Re: [R] LM() and time in R
>
> Have a look at the help page for the function ts()
> (type ?ts  at the R prompt).  Other than that, you haven't provided nearly enough information for us to diagnose your issue.
>
> Please see here for some hints on how to ask questions productively:
> http://adv-r.had.co.nz/Reproducibility.html
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> Cheers
>
> B.
>
> On Apr 29, 2015, at 6:26 AM, Livia Maria Vestergaard <lvest09 at student.sdu.dk> wrote:
>
>>
>> Hello,
>>
>> I need some help with a project that I?m working one.
>>
>> Im trying to make a l regression model (lm) in r with time as independant variable and gas prices as the depended.
>> But It seems like everything im trying to run it, R freeze, I think that I need to tell R somehow that my time is time but how ?
>>
>>
>>
>> Hope that you can help me :)
>> Livia
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Thu Apr 30 12:52:15 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 30 Apr 2015 02:52:15 -0800
Subject: [R] help - hoslem.test
In-Reply-To: <1430358326.99757.YahooMailBasic@web120206.mail.ne1.yahoo.com>
Message-ID: <107CCFECB29.00000B79jrkrideau@inbox.com>

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lutipilotto at yahoo.com.br
> Sent: Wed, 29 Apr 2015 18:45:26 -0700
> To: r-help at r-project.org
> Subject: [R] help - hoslem.test
> 
> Hello,
> 
> I'm working with ordinal logistic regression model (polr) and would like
> to test the proportional odds assumption. For this, I ran the binary
> logistic regressions with varying cutpoints on the dependent variable, as
> described in the following commands. When running the test of Hosmer and
> Lemeshow (hoslem.test) for residuals gives error.
> 
> Thanks,
> Luciane
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Thu Apr 30 14:21:37 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 30 Apr 2015 04:21:37 -0800
Subject: [R] help - hoslem.test
In-Reply-To: <1430393072.47712.YahooMailBasic@web120204.mail.ne1.yahoo.com>
References: <107ccfecb29.00000b79jrkrideau@inbox.com>
Message-ID: <1144898E265.00000CA2jrkrideau@inbox.com>


> -----Original Message-----
> From: lutipilotto at yahoo.com.br
> Sent: Thu, 30 Apr 2015 04:24:32 -0700
> To: r-help at r-project.org, jrkrideau at inbox.com
> Subject: RE: [R] help - hoslem.test
> 
> load("id3.rda")
And what is this?  

We do not have access to your office or computer hard disc.

Please read http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example, see ?dput for sending data?

It is very unlikely anyone here can help if we have no data.


> attach(id3)
> 
> #transformando q13 em bin?ria
> q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
> ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
> id3<-cbind(id3,q131)
> id3$q131 <- as.factor(id3$q131)
> 
> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
> binomial(link = "logit"), data=id3)
> tp1
> 
> library(ResourceSelection)
> hoslem.test(tp1$q131, fitted(tp1), g=10)
> 
> dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
> 
> 
> __________________________________________________
> Luciane Maria Pilotto
> Mestre e?Doutoranda em Sa?de Bucal Coletiva - FO/UFRGS
> NDE Odontologia - UNIVATES
> Telefone: (51) 84512344
> 
> --------------------------------------------
> Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:
> 
>  Assunto: RE: [R] help - hoslem.test
>  Para: "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
> r-help at r-project.org
>  Data: Quinta-feira, 30 de Abril de 2015, 7:52
> 
>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
>  John Kane
>  Kingston ON Canada
> 
> 
>  > -----Original Message-----
>  > From: lutipilotto at yahoo.com.br
>  > Sent: Wed, 29 Apr 2015 18:45:26 -0700
>  > To: r-help at r-project.org
>  > Subject: [R] help - hoslem.test
>  >
>  > Hello,
>  >
>  > I'm working with
>  ordinal logistic regression model (polr) and would like
>  > to test the proportional odds assumption.
>  For this, I ran the binary
>  > logistic
>  regressions with varying cutpoints on the dependent
>  variable, as
>  > described in the following
>  commands. When running the test of Hosmer and
>  > Lemeshow (hoslem.test) for residuals gives
>  error.
>  >
>  > Thanks,
>  > Luciane
>  >
>  >
>  ______________________________________________
>  > R-help at r-project.org
>  mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
>  > http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal,
>  self-contained, reproducible code.
> 
>  ____________________________________________________________
>  FREE ONLINE PHOTOSHARING - Share your photos
>  online with your friends and family!
>  Visit
>  http://www.inbox.com/photosharing to
>  find out more!

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From petr.pikal at precheza.cz  Thu Apr 30 16:25:23 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 30 Apr 2015 14:25:23 +0000
Subject: [R] help - hoslem.test
In-Reply-To: <1144898E265.00000CA2jrkrideau@inbox.com>
References: <107ccfecb29.00000b79jrkrideau@inbox.com>
	<1144898E265.00000CA2jrkrideau@inbox.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C280@SRVEXCHMBX.precheza.cz>

Hi

I agree with John

Just small refinements in lines

> -----Original Message-----
> > -----Original Message-----
> > From: lutipilotto at yahoo.com.br
> > Sent: Thu, 30 Apr 2015 04:24:32 -0700
> > To: r-help at r-project.org, jrkrideau at inbox.com
> > Subject: RE: [R] help - hoslem.test
> >
> > load("id3.rda")
> And what is this?
>
> We do not have access to your office or computer hard disc.
>
> Please read http://stackoverflow.com/questions/5963269/how-to-make-a-
> great-r-reproducible-example, see ?dput for sending data?
>
> It is very unlikely anyone here can help if we have no data.
>
>
> > attach(id3)

Do not use attach. It prevents from modifiyng id3.

> >
> > #transformando q13 em bin?ria
> > q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
> > ifelse(q13==4,2,ifelse(q13==5,2,NA)))))

q131 <- as.numeric(cut(q13, c(0,1.5,5)))

> x<-1:7
> x
[1] 1 2 3 4 5 6 7
> as.numeric(cut(x, c(0,1.5,5)))
[1]  1  2  2  2  2 NA NA

> > id3<-cbind(id3,q131)

rather dangerous in case id3 is not data.frame but matrix

> > id3$q131 <- as.factor(id3$q131)
> >
> > tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
> > binomial(link = "logit"), data=id3)
> > tp1
> >
> > library(ResourceSelection)
> > hoslem.test(tp1$q131, fitted(tp1), g=10)

hoslem.test expects x to be a numeric vector of observations, binary (0/1).
If I understand correctly tp1$q131 have values 1, 2 or NA.

Cheers
Petr

> >
> > dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
> >
> >
> > __________________________________________________
> > Luciane Maria Pilotto
> > Mestre e Doutoranda em Sa?de Bucal Coletiva - FO/UFRGS
> > NDE Odontologia - UNIVATES
> > Telefone: (51) 84512344
> >
> > --------------------------------------------
> > Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:
> >
> >  Assunto: RE: [R] help - hoslem.test
> >  Para: "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
> > r-help at r-project.org
> >  Data: Quinta-feira, 30 de Abril de 2015, 7:52
> >
> >  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example
> >
> >  John Kane
> >  Kingston ON Canada
> >
> >
> >  > -----Original Message-----
> >  > From: lutipilotto at yahoo.com.br
> >  > Sent: Wed, 29 Apr 2015 18:45:26 -0700
> >  > To: r-help at r-project.org
> >  > Subject: [R] help - hoslem.test
> >  >
> >  > Hello,
> >  >
> >  > I'm working with
> >  ordinal logistic regression model (polr) and would like
> >  > to test the proportional odds assumption.
> >  For this, I ran the binary
> >  > logistic
> >  regressions with varying cutpoints on the dependent
> >  variable, as
> >  > described in the following
> >  commands. When running the test of Hosmer and
> >  > Lemeshow (hoslem.test) for residuals gives
> >  error.
> >  >
> >  > Thanks,
> >  > Luciane
> >  >
> >  >
> >  ______________________________________________
> >  > R-help at r-project.org
> >  mailing list -- To UNSUBSCRIBE and more, see
> >  > https://stat.ethz.ch/mailman/listinfo/r-help
> >  > PLEASE do read the posting guide
> >  > http://www.R-project.org/posting-guide.html
> >  > and provide commented, minimal,
> >  self-contained, reproducible code.
> >
> >  ____________________________________________________________
> >  FREE ONLINE PHOTOSHARING - Share your photos
> >  online with your friends and family!
> >  Visit
> >  http://www.inbox.com/photosharing to
> >  find out more!
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Apr 30 16:42:36 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 30 Apr 2015 14:42:36 +0000
Subject: [R] help - hoslem.test
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C280@SRVEXCHMBX.precheza.cz>
References: <107ccfecb29.00000b79jrkrideau@inbox.com>
	<1144898E265.00000CA2jrkrideau@inbox.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C280@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C2A5@SRVEXCHMBX.precheza.cz>

I must correct myself,

attach does not prevent from modifying the object but can be confusing see ?attach example

> x<-1:5
> y<-NA
> xx<-data.frame(x,y)
> attach(xx)
The following objects are masked _by_ .GlobalEnv:

    x, y

> rm(x,y)
> x
[1] 1 2 3 4 5
> yy<-x>3
> xx<-cbind(xx,yy)
> xx
  x  y    yy
1 1 NA FALSE
2 2 NA FALSE
3 3 NA FALSE
4 4 NA  TRUE
5 5 NA  TRUE
> x
[1] 1 2 3 4 5
> x<-x*rnorm(5)
> x
[1] -0.1621579 -0.0142278 -0.6453297 -4.4597072 -1.9681243
> xx
  x  y    yy
1 1 NA FALSE
2 2 NA FALSE
3 3 NA FALSE
4 4 NA  TRUE
5 5 NA  TRUE
>
so new x variable is created and the x variable in xx data frame stays the same.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> Petr
> Sent: Thursday, April 30, 2015 4:25 PM
> To: Luciane Maria Pilotto; r-help at r-project.org
> Subject: Re: [R] help - hoslem.test
>
> Hi
>
> I agree with John
>
> Just small refinements in lines
>
> > -----Original Message-----
> > > -----Original Message-----
> > > From: lutipilotto at yahoo.com.br
> > > Sent: Thu, 30 Apr 2015 04:24:32 -0700
> > > To: r-help at r-project.org, jrkrideau at inbox.com
> > > Subject: RE: [R] help - hoslem.test
> > >
> > > load("id3.rda")
> > And what is this?
> >
> > We do not have access to your office or computer hard disc.
> >
> > Please read http://stackoverflow.com/questions/5963269/how-to-make-a-
> > great-r-reproducible-example, see ?dput for sending data?
> >
> > It is very unlikely anyone here can help if we have no data.
> >
> >
> > > attach(id3)
>
> Do not use attach. It prevents from modifiyng id3.
>
> > >
> > > #transformando q13 em bin?ria
> > > q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
> > > ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
>
> q131 <- as.numeric(cut(q13, c(0,1.5,5)))
>
> > x<-1:7
> > x
> [1] 1 2 3 4 5 6 7
> > as.numeric(cut(x, c(0,1.5,5)))
> [1]  1  2  2  2  2 NA NA
>
> > > id3<-cbind(id3,q131)
>
> rather dangerous in case id3 is not data.frame but matrix
>
> > > id3$q131 <- as.factor(id3$q131)
> > >
> > > tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
> > > binomial(link = "logit"), data=id3)
> > > tp1
> > >
> > > library(ResourceSelection)
> > > hoslem.test(tp1$q131, fitted(tp1), g=10)
>
> hoslem.test expects x to be a numeric vector of observations, binary
> (0/1).
> If I understand correctly tp1$q131 have values 1, 2 or NA.
>
> Cheers
> Petr
>
> > >
> > > dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
> > >
> > >
> > > __________________________________________________
> > > Luciane Maria Pilotto
> > > Mestre e Doutoranda em Sa?de Bucal Coletiva - FO/UFRGS NDE
> > > Odontologia - UNIVATES
> > > Telefone: (51) 84512344
> > >
> > > --------------------------------------------
> > > Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:
> > >
> > >  Assunto: RE: [R] help - hoslem.test
> > >  Para: "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
> > > r-help at r-project.org
> > >  Data: Quinta-feira, 30 de Abril de 2015, 7:52
> > >
> > >  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> > reproducible-example
> > >
> > >  John Kane
> > >  Kingston ON Canada
> > >
> > >
> > >  > -----Original Message-----
> > >  > From: lutipilotto at yahoo.com.br
> > >  > Sent: Wed, 29 Apr 2015 18:45:26 -0700  > To: r-help at r-
> project.org
> > > > Subject: [R] help - hoslem.test  >  > Hello,  >  > I'm working
> > > with  ordinal logistic regression model (polr) and would like  > to
> > > test the proportional odds assumption.
> > >  For this, I ran the binary
> > >  > logistic
> > >  regressions with varying cutpoints on the dependent  variable, as
> > > > described in the following  commands. When running the test of
> > > Hosmer and  > Lemeshow (hoslem.test) for residuals gives  error.
> > >  >
> > >  > Thanks,
> > >  > Luciane
> > >  >
> > >  >
> > >  ______________________________________________
> > >  > R-help at r-project.org
> > >  mailing list -- To UNSUBSCRIBE and more, see  >
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > >  > PLEASE do read the posting guide
> > >  > http://www.R-project.org/posting-guide.html
> > >  > and provide commented, minimal,
> > >  self-contained, reproducible code.
> > >
> > >  ____________________________________________________________
> > >  FREE ONLINE PHOTOSHARING - Share your photos  online with your
> > > friends and family!
> > >  Visit
> > >  http://www.inbox.com/photosharing to  find out more!
> >
> > ____________________________________________________________
> > FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> > and family!
> > Visit http://www.inbox.com/photosharing to find out more!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any
> reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jrkrideau at inbox.com  Thu Apr 30 16:51:07 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 30 Apr 2015 06:51:07 -0800
Subject: [R] help - hoslem.test
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C280@SRVEXCHMBX.precheza.cz>
References: <107ccfecb29.00000b79jrkrideau@inbox.com>
	<1144898e265.00000ca2jrkrideau@inbox.com>
Message-ID: <1292B391472.00000ED8jrkrideau@inbox.com>

Kevin Thorpe pointed out to me that there is a dropbox link at the very bottom of the post that I missed. :(

I just downloaded it, read it in and it looks fine.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: petr.pikal at precheza.cz
> Sent: Thu, 30 Apr 2015 14:25:23 +0000
> To: lutipilotto at yahoo.com.br, r-help at r-project.org
> Subject: Re: [R] help - hoslem.test
> 
> Hi
> 
> I agree with John
> 
> Just small refinements in lines
> 
>> -----Original Message-----
>>> -----Original Message-----
>>> From: lutipilotto at yahoo.com.br
>>> Sent: Thu, 30 Apr 2015 04:24:32 -0700
>>> To: r-help at r-project.org, jrkrideau at inbox.com
>>> Subject: RE: [R] help - hoslem.test
>>> 
>>> load("id3.rda")
>> And what is this?
>> 
>> We do not have access to your office or computer hard disc.
>> 
>> Please read http://stackoverflow.com/questions/5963269/how-to-make-a-
>> great-r-reproducible-example, see ?dput for sending data?
>> 
>> It is very unlikely anyone here can help if we have no data.
>> 
>> 
>>> attach(id3)
> 
> Do not use attach. It prevents from modifiyng id3.
> 
>>> 
>>> #transformando q13 em bin?ria
>>> q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
>>> ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
> 
> q131 <- as.numeric(cut(q13, c(0,1.5,5)))
> 
>> x<-1:7
>> x
> [1] 1 2 3 4 5 6 7
>> as.numeric(cut(x, c(0,1.5,5)))
> [1]  1  2  2  2  2 NA NA
> 
>>> id3<-cbind(id3,q131)
> 
> rather dangerous in case id3 is not data.frame but matrix
> 
>>> id3$q131 <- as.factor(id3$q131)
>>> 
>>> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
>>> binomial(link = "logit"), data=id3)
>>> tp1
>>> 
>>> library(ResourceSelection)
>>> hoslem.test(tp1$q131, fitted(tp1), g=10)
> 
> hoslem.test expects x to be a numeric vector of observations, binary
> (0/1).
> If I understand correctly tp1$q131 have values 1, 2 or NA.
> 
> Cheers
> Petr
> 
>>> 
>>> dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
>>> 
>>> 
>>> __________________________________________________
>>> Luciane Maria Pilotto
>>> Mestre e Doutoranda em Sa?de Bucal Coletiva - FO/UFRGS
>>> NDE Odontologia - UNIVATES
>>> Telefone: (51) 84512344
>>> 
>>> --------------------------------------------
>>> Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:
>>> 
>>>  Assunto: RE: [R] help - hoslem.test
>>>  Para: "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
>>> r-help at r-project.org
>>>  Data: Quinta-feira, 30 de Abril de 2015, 7:52
>>> 
>>>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
>> reproducible-example
>>> 
>>>  John Kane
>>>  Kingston ON Canada
>>> 
>>> 
>>>  > -----Original Message-----
>>>  > From: lutipilotto at yahoo.com.br
>>>  > Sent: Wed, 29 Apr 2015 18:45:26 -0700
>>>  > To: r-help at r-project.org
>>>  > Subject: [R] help - hoslem.test
>>>  >
>>>  > Hello,
>>>  >
>>>  > I'm working with
>>>  ordinal logistic regression model (polr) and would like
>>>  > to test the proportional odds assumption.
>>>  For this, I ran the binary
>>>  > logistic
>>>  regressions with varying cutpoints on the dependent
>>>  variable, as
>>>  > described in the following
>>>  commands. When running the test of Hosmer and
>>>  > Lemeshow (hoslem.test) for residuals gives
>>>  error.
>>>  >
>>>  > Thanks,
>>>  > Luciane
>>>  >
>>>  >
>>>  ______________________________________________
>>>  > R-help at r-project.org
>>>  mailing list -- To UNSUBSCRIBE and more, see
>>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>>  > PLEASE do read the posting guide
>>>  > http://www.R-project.org/posting-guide.html
>>>  > and provide commented, minimal,
>>>  self-contained, reproducible code.
>>> 
>>>  ____________________________________________________________
>>>  FREE ONLINE PHOTOSHARING - Share your photos
>>>  online with your friends and family!
>>>  Visit
>>>  http://www.inbox.com/photosharing to
>>>  find out more!
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by the
> recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From macqueen1 at llnl.gov  Thu Apr 30 17:14:55 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 30 Apr 2015 15:14:55 +0000
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <511855918.1280496.1430359006066.JavaMail.yahoo@mail.yahoo.com>
References: <511855918.1280496.1430359006066.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D167944A.1273A5%macqueen1@llnl.gov>

Here are two correct uses of the "stack command", if by that you mean the
stack() function.

> stack( data.frame(a=1:3, b=4:6, c=7:9) )
  values ind
1      1   a
2      2   a
3      3   a
4      4   b
5      5   b
6      6   b
7      7   c
8      8   c
9      9   c

> stack( list(a=1:3, b=4:6, c=7:9) )
  values ind
1      1   a
2      2   a
3      3   a
4      4   b
5      5   b
6      6   b
7      7   c
8      8   c
9      9   c

I would say that the "values" column of the output fits your description
of what you want to do. (though I used names a, b, c instead of y1, y2,
y3).

But without a reproducible example, one can't say for sure.



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/29/15, 6:56 PM, "Olufemi Bolarinwa" <dafemlions at yahoo.co.uk> wrote:

>Hello,I am estimating a system of nonlinear equation where I need to
>stack my vector of y. I have data of about 6000units. I tried using the
>rbind but instead of having a vector of 1 by 18000, it is giving me a 3
>by 6000 so that my matrix multiplication is non-conformable. The stack
>command requires an identifier but in this case, I do not have a unique
>identifier.
>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>units of y2 and 6000 units of y3.
>Any help will be greatly appreciated.
>ThanksOlufemi
>
> 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Apr 30 17:52:14 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 30 Apr 2015 08:52:14 -0700
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <CA+8X3fVYS6cjU=XGKi_SuxE=D5M=ng80E4C6HQ++-YLRiQ=55Q@mail.gmail.com>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
	<1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
	<B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>
	<CA+8X3fVYS6cjU=XGKi_SuxE=D5M=ng80E4C6HQ++-YLRiQ=55Q@mail.gmail.com>
Message-ID: <CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>

... and if this is what is wanted, somewhat cleaner and more
generalizable for programming would be:

do.call(c, mydata[,1:3])

## where the column indices might have to be adjusted to get the
desired columns.

Cheers,

Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Apr 29, 2015 at 11:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Olufemi,
> I sounds like you have a data frame (let's call it "mydata") with at
> least three elements (columns). You may be trying to use c() in this
> way:
>
> y1to3<-c(y1,y2,y3)
>
> in which case it won't work. However:
>
> y1to3<-c(mydata$y1,mydata$y2,mydata$y3)
>
> might do what you want, substituting whatever the name of your data
> frame is for "mydata".
>
> Jim
>
>
> On Thu, Apr 30, 2015 at 1:20 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.
>>
>> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>>>Thank you Jeff for your response.
>>>My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>>>c() function to concatenate them. I am confusing the "columns" with
>>>vectors. I actually meant columns.
>>>Any help will be much appreciated
>>>Olufemi
>>>
>>>
>>>
>>>On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
>>><jdnewmil at dcn.davis.CA.us> wrote:
>>>
>>>
>>>Vectors are not "columns" or "rows". Use the c() function to
>>>concatenate vectors.
>>>---------------------------------------------------------------------------
>>>Jeff Newmiller                        The    .....      .....  Go
>>>Live...
>>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.      ##.#.  Live
>>>Go...
>>>                                      Live:  OO#.. Dead: OO#..  Playing
>>>Research Engineer (Solar/Batteries            O.O#.      #.O#.  with
>>>/Software/Embedded Controllers)              .OO#.      .OO#.
>>>rocks...1k
>>>---------------------------------------------------------------------------
>>>
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
>>><dafemlions at yahoo.co.uk> wrote:
>>>>Hello,I am estimating a system of nonlinear equation where I need to
>>>>stack my vector of y. I have data of about 6000units. I tried using
>>>the
>>>>rbind but instead of having a vector of 1 by 18000, it is giving me a
>>>3
>>>>by 6000 so that my matrix multiplication is non-conformable. The stack
>>>>command requires an identifier but in this case, I do not have a
>>>unique
>>>>identifier.
>>>>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>>>units of y2 and 6000 units of y3.
>>>>Any help will be greatly appreciated.
>>>>ThanksOlufemi
>>>>
>>>>
>>>>
>>>>    [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Apr 30 18:32:50 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 30 Apr 2015 11:32:50 -0500
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
	<1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
	<B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>
	<CA+8X3fVYS6cjU=XGKi_SuxE=D5M=ng80E4C6HQ++-YLRiQ=55Q@mail.gmail.com>
	<CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>
Message-ID: <F3FB0552-AB11-47F7-9057-C2B082270571@me.com>

Hi,

Given that a data frame is a list:

  unlist(mydata[, 1:3])

For example:

> all(unlist(iris[, 1:3]) == do.call(c, iris[, 1:3]))
[1] TRUE


Also, note that the returned result in both cases above retains names:

> unlist(iris[, 1:3])
  Sepal.Length1   Sepal.Length2   Sepal.Length3   Sepal.Length4 
            5.1             4.9             4.7             4.6 
  Sepal.Length5   Sepal.Length6   Sepal.Length7   Sepal.Length8 
            5.0             5.4             4.6             5.0 
  Sepal.Length9  Sepal.Length10  Sepal.Length11  Sepal.Length12 
            4.4             4.9             5.4             4.8 
...

You can just get the plain vector by using:

> unlist(iris[, 1:3], use.names = FALSE)
  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7
 [17] 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4
 [33] 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6
 [49] 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1
...


As Bert notes, the indices would need to be adjusted for the actual data frame in question.

Regards,

Marc



> On Apr 30, 2015, at 10:52 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> ... and if this is what is wanted, somewhat cleaner and more
> generalizable for programming would be:
> 
> do.call(c, mydata[,1:3])
> 
> ## where the column indices might have to be adjusted to get the
> desired columns.
> 
> Cheers,
> 
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Wed, Apr 29, 2015 at 11:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Olufemi,
>> I sounds like you have a data frame (let's call it "mydata") with at
>> least three elements (columns). You may be trying to use c() in this
>> way:
>> 
>> y1to3<-c(y1,y2,y3)
>> 
>> in which case it won't work. However:
>> 
>> y1to3<-c(mydata$y1,mydata$y2,mydata$y3)
>> 
>> might do what you want, substituting whatever the name of your data
>> frame is for "mydata".
>> 
>> Jim
>> 
>> 
>> On Thu, Apr 30, 2015 at 1:20 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.
>>> 
>>> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>>>> Thank you Jeff for your response.
>>>> My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>>>> c() function to concatenate them. I am confusing the "columns" with
>>>> vectors. I actually meant columns.
>>>> Any help will be much appreciated
>>>> Olufemi
>>>> 
>>>> 
>>>> 
>>>> On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.CA.us> wrote:
>>>> 
>>>> 
>>>> Vectors are not "columns" or "rows". Use the c() function to
>>>> concatenate vectors.
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The    .....      .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.      ##.#.  Live
>>>> Go...
>>>>                                     Live:  OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.      #.O#.  with
>>>> /Software/Embedded Controllers)              .OO#.      .OO#.
>>>> rocks...1k
>>>> ---------------------------------------------------------------------------
>>>> 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
>>>> <dafemlions at yahoo.co.uk> wrote:
>>>>> Hello,I am estimating a system of nonlinear equation where I need to
>>>>> stack my vector of y. I have data of about 6000units. I tried using
>>>> the
>>>>> rbind but instead of having a vector of 1 by 18000, it is giving me a
>>>> 3
>>>>> by 6000 so that my matrix multiplication is non-conformable. The stack
>>>>> command requires an identifier but in this case, I do not have a
>>>> unique
>>>>> identifier.
>>>>> I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>>>> units of y2 and 6000 units of y3.
>>>>> Any help will be greatly appreciated.
>>>>> ThanksOlufemi


From dafemlions at yahoo.co.uk  Thu Apr 30 18:33:34 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Thu, 30 Apr 2015 16:33:34 +0000 (UTC)
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>
References: <CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>
Message-ID: <854286386.2091421.1430411614136.JavaMail.yahoo@mail.yahoo.com>

Thank you. your suggestions all worked.
Best Regards?
 


     On Thursday, 30 April 2015, 11:52, Bert Gunter <gunter.berton at gene.com> wrote:
   

 ... and if this is what is wanted, somewhat cleaner and more
generalizable for programming would be:

do.call(c, mydata[,1:3])

## where the column indices might have to be adjusted to get the
desired columns.

Cheers,

Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Apr 29, 2015 at 11:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Olufemi,
> I sounds like you have a data frame (let's call it "mydata") with at
> least three elements (columns). You may be trying to use c() in this
> way:
>
> y1to3<-c(y1,y2,y3)
>
> in which case it won't work. However:
>
> y1to3<-c(mydata$y1,mydata$y2,mydata$y3)
>
> might do what you want, substituting whatever the name of your data
> frame is for "mydata".
>
> Jim
>
>
> On Thu, Apr 30, 2015 at 1:20 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.
>>
>> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ---------------------------------------------------------------------------
>> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>> /Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>>>Thank you Jeff for your response.
>>>My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>>>c() function to concatenate them. I am confusing the "columns" with
>>>vectors. I actually meant columns.
>>>Any help will be much appreciated
>>>Olufemi
>>>
>>>
>>>
>>>On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
>>><jdnewmil at dcn.davis.CA.us> wrote:
>>>
>>>
>>>Vectors are not "columns" or "rows". Use the c() function to
>>>concatenate vectors.
>>>---------------------------------------------------------------------------
>>>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>>>Live...
>>>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>>>Go...
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>>>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>>>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.
>>>rocks...1k
>>>---------------------------------------------------------------------------
>>>
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
>>><dafemlions at yahoo.co.uk> wrote:
>>>>Hello,I am estimating a system of nonlinear equation where I need to
>>>>stack my vector of y. I have data of about 6000units. I tried using
>>>the
>>>>rbind but instead of having a vector of 1 by 18000, it is giving me a
>>>3
>>>>by 6000 so that my matrix multiplication is non-conformable. The stack
>>>>command requires an identifier but in this case, I do not have a
>>>unique
>>>>identifier.
>>>>I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>>>units of y2 and 6000 units of y3.
>>>>Any help will be greatly appreciated.
>>>>ThanksOlufemi
>>>>
>>>>
>>>>
>>>>? ? [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Thu Apr 30 18:51:05 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 30 Apr 2015 09:51:05 -0700
Subject: [R] Stacking of vectors to form a column vector
In-Reply-To: <F3FB0552-AB11-47F7-9057-C2B082270571@me.com>
References: <B1C0422A-5E4A-499B-AE29-0A122EBCD52C@dcn.davis.CA.us>
	<1150031295.1291430.1430362105001.JavaMail.yahoo@mail.yahoo.com>
	<B0CF9C13-2DF8-4D33-8A33-EEAF7F0BBF1B@dcn.davis.CA.us>
	<CA+8X3fVYS6cjU=XGKi_SuxE=D5M=ng80E4C6HQ++-YLRiQ=55Q@mail.gmail.com>
	<CACk-te30ZXtLNqwMgMixZWTehrU33UVZ0e7JK=nVRwz-OZJVKA@mail.gmail.com>
	<F3FB0552-AB11-47F7-9057-C2B082270571@me.com>
Message-ID: <CACk-te30HWc1c+8DnDtQ+SxfaxiubS+2irgkWPZeKqWMp3U4Bg@mail.gmail.com>

Yes, I think unlist() is still better.

One caution (for all): make sure the columns are all of the same
type/class/mode or you may be in for nasty surprises.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Apr 30, 2015 at 9:32 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Hi,
>
> Given that a data frame is a list:
>
>   unlist(mydata[, 1:3])
>
> For example:
>
>> all(unlist(iris[, 1:3]) == do.call(c, iris[, 1:3]))
> [1] TRUE
>
>
> Also, note that the returned result in both cases above retains names:
>
>> unlist(iris[, 1:3])
>   Sepal.Length1   Sepal.Length2   Sepal.Length3   Sepal.Length4
>             5.1             4.9             4.7             4.6
>   Sepal.Length5   Sepal.Length6   Sepal.Length7   Sepal.Length8
>             5.0             5.4             4.6             5.0
>   Sepal.Length9  Sepal.Length10  Sepal.Length11  Sepal.Length12
>             4.4             4.9             5.4             4.8
> ...
>
> You can just get the plain vector by using:
>
>> unlist(iris[, 1:3], use.names = FALSE)
>   [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7
>  [17] 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4
>  [33] 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6
>  [49] 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1
> ...
>
>
> As Bert notes, the indices would need to be adjusted for the actual data frame in question.
>
> Regards,
>
> Marc
>
>
>
>> On Apr 30, 2015, at 10:52 AM, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> ... and if this is what is wanted, somewhat cleaner and more
>> generalizable for programming would be:
>>
>> do.call(c, mydata[,1:3])
>>
>> ## where the column indices might have to be adjusted to get the
>> desired columns.
>>
>> Cheers,
>>
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Wed, Apr 29, 2015 at 11:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Olufemi,
>>> I sounds like you have a data frame (let's call it "mydata") with at
>>> least three elements (columns). You may be trying to use c() in this
>>> way:
>>>
>>> y1to3<-c(y1,y2,y3)
>>>
>>> in which case it won't work. However:
>>>
>>> y1to3<-c(mydata$y1,mydata$y2,mydata$y3)
>>>
>>> might do what you want, substituting whatever the name of your data
>>> frame is for "mydata".
>>>
>>> Jim
>>>
>>>
>>> On Thu, Apr 30, 2015 at 1:20 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>> I am sure you can use c() because columns may be vectors even though vectors are not columns, but you really need to follow the posting guide and provide a reproducible example for us to show you how. You might find [1] helpful, in particular as it describes the use of the dput function to give us a few rows of your data.
>>>>
>>>> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On April 29, 2015 7:48:24 PM PDT, Olufemi Bolarinwa <dafemlions at yahoo.co.uk> wrote:
>>>>> Thank you Jeff for your response.
>>>>> My y1, y2, y3 are actually 3 columns in the data so I cannot use the
>>>>> c() function to concatenate them. I am confusing the "columns" with
>>>>> vectors. I actually meant columns.
>>>>> Any help will be much appreciated
>>>>> Olufemi
>>>>>
>>>>>
>>>>>
>>>>> On Wednesday, 29 April 2015, 22:31, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.CA.us> wrote:
>>>>>
>>>>>
>>>>> Vectors are not "columns" or "rows". Use the c() function to
>>>>> concatenate vectors.
>>>>> ---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The    .....      .....  Go
>>>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.      ##.#.  Live
>>>>> Go...
>>>>>                                     Live:  OO#.. Dead: OO#..  Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.      #.O#.  with
>>>>> /Software/Embedded Controllers)              .OO#.      .OO#.
>>>>> rocks...1k
>>>>> ---------------------------------------------------------------------------
>>>>>
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On April 29, 2015 6:56:46 PM PDT, Olufemi Bolarinwa
>>>>> <dafemlions at yahoo.co.uk> wrote:
>>>>>> Hello,I am estimating a system of nonlinear equation where I need to
>>>>>> stack my vector of y. I have data of about 6000units. I tried using
>>>>> the
>>>>>> rbind but instead of having a vector of 1 by 18000, it is giving me a
>>>>> 3
>>>>>> by 6000 so that my matrix multiplication is non-conformable. The stack
>>>>>> command requires an identifier but in this case, I do not have a
>>>>> unique
>>>>>> identifier.
>>>>>> I would like to stack the the first 6000 units of y1 on the 2nd 6000
>>>>>> units of y2 and 6000 units of y3.
>>>>>> Any help will be greatly appreciated.
>>>>>> ThanksOlufemi
>


From ishaqbaba at yahoo.com  Thu Apr 30 09:03:45 2015
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Thu, 30 Apr 2015 07:03:45 +0000 (UTC)
Subject: [R] Editable plot
Message-ID: <2032167268.1280045.1430377425843.JavaMail.yahoo@mail.yahoo.com>


Hello,Kindly assist me on how to make the plot from the following programm to be editable?

x<-c(0.84,1.03,0.96)y<-c(1.30,1.46,1.48)z<-c(1.32,1.47,1.5)w<-c(0.07,0.07,0.07)r<-c(500,1000,2000)
# Graph cars using a y axis that ranges from 0 to 12plot(r,x, type="o", col="blue", ylim=c(0,1.5),lwd= 2, xlab = " Number of iteration",ylab=" Bias" )
# Graph trucks with red dashed line and square pointslines(r,y, type="o", pch=22, lty=2, col="red",lwd=2)lines(r,z, type="o", pch=22, lty=3, col="green",lwd=2)lines(r,w, type="o", pch=22, lty=4, col="forestgreen",lwd=2)
# Create a title with a red, bold/italic font#title(main="Estimated Bias for the optimal response ", col.main="red", font.main=4)
#legend("center", lty = 1:4, col = 1:4,?? ? ? #legend = c("x","y", "z","w"))
text(1000, 0.15, "PM")text(1000, 1.10, "VM")text(1000, 1.52, "WMSE")text(1000, 1.40, "LT")

Thank youIshaq

	[[alternative HTML version deleted]]


From lvest09 at student.sdu.dk  Thu Apr 30 10:06:08 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Thu, 30 Apr 2015 08:06:08 +0000
Subject: [R] LM() and time in R
In-Reply-To: <C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42526@ADM-EXMBX10D.adm.c.sdu.dk>,
	<C29AD083-E0DC-429D-8EEC-1D0A896D16DD@utoronto.ca>
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE42646@ADM-EXMBX10D.adm.c.sdu.dk>

Hello guys, 
thanks for your quick reply 
I will try and specific my problem 

I have over 300.000 observations for different petrol pumps in all of Denmark fra 1. november 2014 - 31 january 2015
for example I have: 

petrol pump number:  "1111" /  date: 1. november 2014 / time: 08:14:22 / price: 10.55 /day /   zipcode: 2000
petrol pump number:  "1111" /  date: 1. november 2014 / time: 08:29:00 / price: 10.52 / day / zipcode: 2000
petrol pump number: "3456" / date: 1. november 2014 / time: 08:19:21 / price: 10.88 / day/  zipcode: 2100


And then put the zip codes into dummy categories like X1: zipcode (1000-2000)=1 all others 0 and so on.

My regression model then look like 

lm(price, x1 + x2 + x3 ...  ) but the "Multiple R-squared" is really low, 0.01217 

So instead I would like to check if the time "hh:mm:ss" have an effect on the price. I know how to tell R about the date by as.Date() , but not with the time, how can I do that? 


Or do you guys maybe a third idea about what should make a regression about to improve the model?

Cheers 
Livia :) 

________________________________________
Fra: Boris Steipe [boris.steipe at utoronto.ca]
Sendt: 29. april 2015 20:25
Til: Livia Maria Vestergaard
Cc: r-help mailing list
Emne: Re: [R] LM() and time in R

Have a look at the help page for the function ts()
(type ?ts  at the R prompt).  Other than that, you haven't provided nearly enough information for us to diagnose your issue.

Please see here for some hints on how to ask questions productively:
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
Cheers

B.

On Apr 29, 2015, at 6:26 AM, Livia Maria Vestergaard <lvest09 at student.sdu.dk> wrote:

>
> Hello,
>
> I need some help with a project that I?m working one.
>
> Im trying to make a l regression model (lm) in r with time as independant variable and gas prices as the depended.
> But It seems like everything im trying to run it, R freeze, I think that I need to tell R somehow that my time is time but how ?
>
>
>
> Hope that you can help me :)
> Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pbailey at air.org  Tue Apr 28 21:43:15 2015
From: pbailey at air.org (Bailey, Paul)
Date: Tue, 28 Apr 2015 19:43:15 +0000
Subject: [R] [R-pkgs] New package: lfactors (0.4-0)
Message-ID: <02C0B4336BD2BC4A8FC51CDF98D2F494ABF00C15@DC1VEX10MB001.air.org>

Dear R users,

The "lfactors" package is now available from CRAN. It provides a class "lfactor" that is similar to the class "factor" but can be referred to by level or label.

This package is best explained with an example

flips <- lfactor(c(0,1,1,0,0,1), levels=0:1, labels=c("Tails", "Heads"))
# Tails can now be referred to as, "Tails" or 0
# These two lines return the same result
flips == "Tails"
flips == 0

Other functions, such as %in% and != also work with lfactors.

This package is helpful for data that was labeled with long labels, making references to the label cumbersome. This happens to me when I'm sharing data with users of other statistical software that uses the same convention as lfactors--that is, allowing a factor level to be referred to by its numeric or character value.

Comments, contributions, and suggests are welcome.

Best,
Paul
---
Paul D. Bailey, Ph.D.
Economist, Education
American Institutes for Research
202.403.5694

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ghada.f.mm at gmail.com  Thu Apr 30 11:27:24 2015
From: ghada.f.mm at gmail.com (Ghada Almousa)
Date: Thu, 30 Apr 2015 12:27:24 +0300
Subject: [R] Problem in r help me
Message-ID: <CADG8gktu_zJ8Ex0Sx1yo=wYd6dV=f_ZTXrQ8BWcF+OediaYf-g@mail.gmail.com>

hello dears

I have Search to compare the results between the three types of cluster
k-maen ,Em and  Hierarchal clusters
How i figured the number of iterations , the time required to build each
Cluster ,accuracy  and sum square error SSE for each cluster in the R
programming

	[[alternative HTML version deleted]]


From jeremyclarkbio at gmail.com  Thu Apr 30 14:05:55 2015
From: jeremyclarkbio at gmail.com (Jeremy Clark)
Date: Thu, 30 Apr 2015 14:05:55 +0200
Subject: [R] Graphs for scientific publication ?
Message-ID: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>

Dear All,

First of all, many thanks to all R contributors for a fantastic
program, and especially to Hadley Wickham for creating ggplot2. The
following is intended to be a warning that, if the apparently
superficial problems described are not sorted out, R could well find
itself being superceded. The reason is that a new user wants to draw a
graph, and perhaps publish in a scientific journal a graph created
using R, well before wanting to do a complex regression (and the
latter is relatively easy). So here goes:

1) The saga of the straight line. I implemented a geom_abline - it
looked superb. Unfortunately I had to disable clip to allow text - now
my abline looked ridiculous. My search found plotrix: ablineclip -
fantastic I thought - but it applies to plot and not geom_plot. I
switched to geom_segment - the rendering looked trash. I switched to
geom_smooth - should work but as I don't know the x values beforehand
I'll have to clip a new dataframe - it that a hassle ? - Yes it is !

            So my general question is - why isn't ggplot2 already part
of R base - or at least if someone is to create useful packages for
plot - perhaps a subtle hint could be made that they should also apply
to ggplot2 (and perhaps to lattice ?? - also personally I would scrap
qplot as an unnecessary distraction which is not easier to implement
than ggplot). In general duplication of packages for plot and ggplot
doesn't seem like a good idea.


2) The saga of the italic letter. I found, to my dismay, that to
insert an italic letter into my plot I had to learn a whole new
language called plotmath - which wouldn't accept normal R coding, and
didn't even have normal control functions such as /n for a new line.
This is ridiculous (and I'm not sure how plotmath managed to get into
R base).

            So my question is, when is plotmath going to have a
complete overhaul to allow eg. "," instead of, or as well as, ~,~, and
normal control functions such as \n ?

3) A related question to (2) is: where is geom_textbox ?

4) Where are examples with scientific graph defaults ?  (meaning a
two-axis graph which is publishable - I will post my own after this is
published in a years time, but as suggested above, while the graph
looks good the implementation of this is not pretty).

Having said that - good luck with implementation - and many thanks for
all your hard work !

Yours sincerely,

Abiologist


From toby at huksu.com  Thu Apr 30 17:02:26 2015
From: toby at huksu.com (thuksu)
Date: Thu, 30 Apr 2015 08:02:26 -0700 (PDT)
Subject: [R] GLM: What is a good way for dealing with new factor levels
 in the test set?
In-Reply-To: <CA+8X3fVpesBYY9bXbyHwYQUXrrrTh1qA_7USuAh3hvg0oaGmNg@mail.gmail.com>
References: <1430345103451-4706621.post@n4.nabble.com>
	<CA+8X3fVpesBYY9bXbyHwYQUXrrrTh1qA_7USuAh3hvg0oaGmNg@mail.gmail.com>
Message-ID: <1430406146519-4706644.post@n4.nabble.com>

Hi, Thanks for the reply!

I did try this...

# res is a data frame
levels(res$mytypeid.f) <- c(levels(res$mytypeid.f),"mynewlevel")
logreg <- glm(yesno ~ mytypeid.f + amount, data=res, family="binomial")
exp(coef(logreg)) 
# this result shows that the new level is not included in the regression. 
it's probably automatically removed.


I think what I want to do is identify new levels that are not in the
training set, and prune those from the test set.  Then I would be using the
dummy variable by default, which I think is the "average", from reading
this:
http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm

Problem is, I'm not sure how to do that...



--
View this message in context: http://r.789695.n4.nabble.com/GLM-What-is-a-good-way-for-dealing-with-new-factor-levels-in-the-test-set-tp4706621p4706644.html
Sent from the R help mailing list archive at Nabble.com.


From anirudhj at igidr.ac.in  Thu Apr 30 20:12:43 2015
From: anirudhj at igidr.ac.in (Anirudh Jayaraman)
Date: Thu, 30 Apr 2015 23:42:43 +0530
Subject: [R] 'Installation of package <package> had non-zero exit status' on
 R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
Message-ID: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>

I recently upgraded to *R-3.2.0* from *R-2.14.1* on *Ubuntu 12.04 LTS.*

I have been *trying to install some add-on packages* (that weren't
installed in the earlier version of R) to R-3.2.0. *but to no avail*,
getting repeated error messages. For example, *I tried installing swirl*.
Here's my output. The problem areas are highlighted in yellow. Any solution?


*> install.packages("swirl")*

Installing package into ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2?
(as ?lib? is unspecified)
also installing the dependencies ?testthat?, ?httr?, ?yaml?, ?RCurl?

trying URL 'http://cran.rstudio.com/src/contrib/testthat_0.9.1.tar.gz'
Content type 'application/x-gzip' length 49533 bytes (48 KB)
==================================================
downloaded 48 KB

trying URL 'http://cran.rstudio.com/src/contrib/httr_0.6.1.tar.gz'
Content type 'application/x-gzip' length 247531 bytes (241 KB)
==================================================
downloaded 241 KB

trying URL 'http://cran.rstudio.com/src/contrib/yaml_2.1.13.tar.gz'
Content type 'application/x-gzip' length 81045 bytes (79 KB)
==================================================
downloaded 79 KB

trying URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.6.tar.gz'
Content type 'application/x-gzip' length 878616 bytes (858 KB)
==================================================
downloaded 858 KB

trying URL 'http://cran.rstudio.com/src/contrib/swirl_2.2.21.tar.gz'
Content type 'application/x-gzip' length 51037 bytes (49 KB)
==================================================
downloaded 49 KB

* installing *source* package ?testthat? ...
** package ?testthat? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reassign.c -o reassign.o
gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o testthat.so reassign.o -L/usr/lib/R/lib -lR
installing to /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/testthat/libs
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (testthat)
* installing *source* package ?yaml? ...
** package ?yaml? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c api.c -o api.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c dumper.c -o dumper.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c emitter.c -o emitter.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c implicit.c -o implicit.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c loader.c -o loader.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c parser.c -o parser.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c r-ext.c -o r-ext.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reader.c -o reader.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c scanner.c -o scanner.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c writer.c -o writer.o
gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o yaml.so api.o dumper.o emitter.o implicit.o loader.o
parser.o r-ext.o reader.o scanner.o writer.o -L/usr/lib/R/lib -lR
installing to /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/yaml/libs
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (yaml)
* installing *source* package ?RCurl? ...
** package ?RCurl? successfully unpacked and MD5 sums checked
checking for curl-config... no
Cannot find curl-config
ERROR: configuration failed for package ?RCurl?
* removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/RCurl?
Warning in install.packages :
  installation of package ?RCurl? had non-zero exit status
ERROR: dependency ?RCurl? is not available for package ?httr?
* removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/httr?
Warning in install.packages :
  installation of package ?httr? had non-zero exit status
ERROR: dependencies ?httr?, ?RCurl? are not available for package ?swirl?
* removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/swirl?
Warning in install.packages :
  installation of package ?swirl? had non-zero exit status

The downloaded source packages are in
    ?/tmp/RtmpmKycFY/downloaded_packages?
*________________________________________________________*
*Anirudh Jayaraman*
M.Sc Economics (2014-16)
Indira Gandhi Institute of Development Research (IGIDR), Mumbai
Ph No: +91 9560476729

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Thu Apr 30 13:22:41 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 30 Apr 2015 04:22:41 -0700 (PDT)
Subject: [R] Inference Syntax
Message-ID: <1430392961881-4706637.post@n4.nabble.com>

Hi All,

This is my first post in the community.
I am currently working on finding some inferences from my sample data and
the code I have used is:
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0,
method = "theoretical"). While researching more on the code as I have just
started using R, online I found alternative also as a keyword for the syntax
which has option as either less, greater or two sided. I am unsure what it
is referring to. 
If someone would please explain the alterative keyword. Thank you. 



--
View this message in context: http://r.789695.n4.nabble.com/Inference-Syntax-tp4706637.html
Sent from the R help mailing list archive at Nabble.com.


From lutipilotto at yahoo.com.br  Thu Apr 30 13:24:32 2015
From: lutipilotto at yahoo.com.br (Luciane Maria Pilotto)
Date: Thu, 30 Apr 2015 04:24:32 -0700
Subject: [R] help - hoslem.test
In-Reply-To: <107CCFECB29.00000B79jrkrideau@inbox.com>
Message-ID: <1430393072.47712.YahooMailBasic@web120204.mail.ne1.yahoo.com>

load("id3.rda")
attach(id3)

#transformando q13 em bin?ria
q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2, ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
id3<-cbind(id3,q131)
id3$q131 <- as.factor(id3$q131)

tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family = binomial(link = "logit"), data=id3) 
tp1

library(ResourceSelection)
hoslem.test(tp1$q131, fitted(tp1), g=10)

dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0


__________________________________________________
Luciane Maria Pilotto
Mestre e?Doutoranda em Sa?de Bucal Coletiva - FO/UFRGS?
NDE Odontologia - UNIVATES
Telefone: (51) 84512344

--------------------------------------------
Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:

 Assunto: RE: [R] help - hoslem.test

.org
 Data: Quinta-feira, 30 de Abril de 2015, 7:52

 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

 John Kane
 Kingston ON Canada


 > -----Original Message-----

 > Sent: Wed, 29 Apr 2015 18:45:26 -0700
 > To: r-help at r-project.org
 > Subject: [R] help - hoslem.test
 > 
 > Hello,
 > 
 > I'm working with
 ordinal logistic regression model (polr) and would like
 > to test the proportional odds assumption.
 For this, I ran the binary
 > logistic
 regressions with varying cutpoints on the dependent
 variable, as
 > described in the following
 commands. When running the test of Hosmer and
 > Lemeshow (hoslem.test) for residuals gives
 error.
 > 
 > Thanks,
 > Luciane
 > 
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.

 ____________________________________________________________
 FREE ONLINE PHOTOSHARING - Share your photos
[[elided Yahoo spam]]
 Visit
 http://www.inbox.com/photosharing to
 find out more!


From murdoch.duncan at gmail.com  Thu Apr 30 20:38:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Apr 2015 14:38:16 -0400
Subject: [R] 'Installation of package <package> had non-zero exit
 status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
In-Reply-To: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>
References: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>
Message-ID: <55427698.1080309@gmail.com>

On 30/04/2015 2:12 PM, Anirudh Jayaraman wrote:
> I recently upgraded to *R-3.2.0* from *R-2.14.1* on *Ubuntu 12.04 LTS.*
>
> I have been *trying to install some add-on packages* (that weren't
> installed in the earlier version of R) to R-3.2.0. *but to no avail*,
> getting repeated error messages. For example, *I tried installing swirl*.
> Here's my output. The problem areas are highlighted in yellow. Any solution?

The error message looks pretty clear:  the installer couldn't find 
curl-config.  Just install whatever package is necessary to get libcurl, 
and make sure curl-config is on your path, and you should get past that 
error, and on to the next one.

Duncan Murdoch

>
>
> *> install.packages("swirl")*
>
> Installing package into ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2?
> (as ?lib? is unspecified)
> also installing the dependencies ?testthat?, ?httr?, ?yaml?, ?RCurl?
>
> trying URL 'http://cran.rstudio.com/src/contrib/testthat_0.9.1.tar.gz'
> Content type 'application/x-gzip' length 49533 bytes (48 KB)
> ==================================================
> downloaded 48 KB
>
> trying URL 'http://cran.rstudio.com/src/contrib/httr_0.6.1.tar.gz'
> Content type 'application/x-gzip' length 247531 bytes (241 KB)
> ==================================================
> downloaded 241 KB
>
> trying URL 'http://cran.rstudio.com/src/contrib/yaml_2.1.13.tar.gz'
> Content type 'application/x-gzip' length 81045 bytes (79 KB)
> ==================================================
> downloaded 79 KB
>
> trying URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.6.tar.gz'
> Content type 'application/x-gzip' length 878616 bytes (858 KB)
> ==================================================
> downloaded 858 KB
>
> trying URL 'http://cran.rstudio.com/src/contrib/swirl_2.2.21.tar.gz'
> Content type 'application/x-gzip' length 51037 bytes (49 KB)
> ==================================================
> downloaded 49 KB
>
> * installing *source* package ?testthat? ...
> ** package ?testthat? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reassign.c -o reassign.o
> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o testthat.so reassign.o -L/usr/lib/R/lib -lR
> installing to /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/testthat/libs
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (testthat)
> * installing *source* package ?yaml? ...
> ** package ?yaml? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c api.c -o api.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c dumper.c -o dumper.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c emitter.c -o emitter.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c implicit.c -o implicit.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c loader.c -o loader.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c parser.c -o parser.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c r-ext.c -o r-ext.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reader.c -o reader.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c scanner.c -o scanner.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c writer.c -o writer.o
> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o yaml.so api.o dumper.o emitter.o implicit.o loader.o
> parser.o r-ext.o reader.o scanner.o writer.o -L/usr/lib/R/lib -lR
> installing to /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/yaml/libs
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (yaml)
> * installing *source* package ?RCurl? ...
> ** package ?RCurl? successfully unpacked and MD5 sums checked
> checking for curl-config... no
> Cannot find curl-config
> ERROR: configuration failed for package ?RCurl?
> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/RCurl?
> Warning in install.packages :
>    installation of package ?RCurl? had non-zero exit status
> ERROR: dependency ?RCurl? is not available for package ?httr?
> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/httr?
> Warning in install.packages :
>    installation of package ?httr? had non-zero exit status
> ERROR: dependencies ?httr?, ?RCurl? are not available for package ?swirl?
> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/swirl?
> Warning in install.packages :
>    installation of package ?swirl? had non-zero exit status
>
> The downloaded source packages are in
>      ?/tmp/RtmpmKycFY/downloaded_packages?
> *________________________________________________________*
> *Anirudh Jayaraman*
> M.Sc Economics (2014-16)
> Indira Gandhi Institute of Development Research (IGIDR), Mumbai
> Ph No: +91 9560476729
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Apr 30 20:41:17 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 30 Apr 2015 11:41:17 -0700
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>
References: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>
Message-ID: <CACk-te2vEXidgQOz-o3si9x4XRgF1BEChXzKYjb+5FLF7haafQ@mail.gmail.com>

Jeremy:

I suggest you have a look at the latest edition of Paul Murrell's
book, "R Graphics", as you seem to be unaware that ggplot2 (as well as
a 3rd graphics paradigm, the lattice package) and base graphics are
built on 2 different and incompatible graphics engines.

Obviously, you are entitled to your opinions and graphical
predilections vary, but I do not think R-Help is a good venue for
these sorts of discussions. The R-devel list might be a better place
to discuss such matters.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Apr 30, 2015 at 5:05 AM, Jeremy Clark <jeremyclarkbio at gmail.com> wrote:
> Dear All,
>
> First of all, many thanks to all R contributors for a fantastic
> program, and especially to Hadley Wickham for creating ggplot2. The
> following is intended to be a warning that, if the apparently
> superficial problems described are not sorted out, R could well find
> itself being superceded. The reason is that a new user wants to draw a
> graph, and perhaps publish in a scientific journal a graph created
> using R, well before wanting to do a complex regression (and the
> latter is relatively easy). So here goes:
>
> 1) The saga of the straight line. I implemented a geom_abline - it
> looked superb. Unfortunately I had to disable clip to allow text - now
> my abline looked ridiculous. My search found plotrix: ablineclip -
> fantastic I thought - but it applies to plot and not geom_plot. I
> switched to geom_segment - the rendering looked trash. I switched to
> geom_smooth - should work but as I don't know the x values beforehand
> I'll have to clip a new dataframe - it that a hassle ? - Yes it is !
>
>             So my general question is - why isn't ggplot2 already part
> of R base - or at least if someone is to create useful packages for
> plot - perhaps a subtle hint could be made that they should also apply
> to ggplot2 (and perhaps to lattice ?? - also personally I would scrap
> qplot as an unnecessary distraction which is not easier to implement
> than ggplot). In general duplication of packages for plot and ggplot
> doesn't seem like a good idea.
>
>
> 2) The saga of the italic letter. I found, to my dismay, that to
> insert an italic letter into my plot I had to learn a whole new
> language called plotmath - which wouldn't accept normal R coding, and
> didn't even have normal control functions such as /n for a new line.
> This is ridiculous (and I'm not sure how plotmath managed to get into
> R base).
>
>             So my question is, when is plotmath going to have a
> complete overhaul to allow eg. "," instead of, or as well as, ~,~, and
> normal control functions such as \n ?
>
> 3) A related question to (2) is: where is geom_textbox ?
>
> 4) Where are examples with scientific graph defaults ?  (meaning a
> two-axis graph which is publishable - I will post my own after this is
> published in a years time, but as suggested above, while the graph
> looks good the implementation of this is not pretty).
>
> Having said that - good luck with implementation - and many thanks for
> all your hard work !
>
> Yours sincerely,
>
> Abiologist
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Apr 30 21:22:51 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 30 Apr 2015 19:22:51 +0000
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACk-te2vEXidgQOz-o3si9x4XRgF1BEChXzKYjb+5FLF7haafQ@mail.gmail.com>
References: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>
	<CACk-te2vEXidgQOz-o3si9x4XRgF1BEChXzKYjb+5FLF7haafQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68805E@mb02.ads.tamu.edu>

More useful to the r-help list would be a reproducible example of the data you are using and a clear statement of what you are trying to accomplish. It is likely that all of your requirements can be easily met, but you spent most of your message talking about what you have tried without telling us where you want to end up. People on the list are familiar with base graphics, lattice graphics, and ggplot2. If you list your requirements clearly, you might end up with three solutions.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, April 30, 2015 1:41 PM
To: Jeremy Clark
Cc: r-help at r-project.org
Subject: Re: [R] Graphs for scientific publication ?

Jeremy:

I suggest you have a look at the latest edition of Paul Murrell's
book, "R Graphics", as you seem to be unaware that ggplot2 (as well as
a 3rd graphics paradigm, the lattice package) and base graphics are
built on 2 different and incompatible graphics engines.

Obviously, you are entitled to your opinions and graphical
predilections vary, but I do not think R-Help is a good venue for
these sorts of discussions. The R-devel list might be a better place
to discuss such matters.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Apr 30, 2015 at 5:05 AM, Jeremy Clark <jeremyclarkbio at gmail.com> wrote:
> Dear All,
>
> First of all, many thanks to all R contributors for a fantastic
> program, and especially to Hadley Wickham for creating ggplot2. The
> following is intended to be a warning that, if the apparently
> superficial problems described are not sorted out, R could well find
> itself being superceded. The reason is that a new user wants to draw a
> graph, and perhaps publish in a scientific journal a graph created
> using R, well before wanting to do a complex regression (and the
> latter is relatively easy). So here goes:
>
> 1) The saga of the straight line. I implemented a geom_abline - it
> looked superb. Unfortunately I had to disable clip to allow text - now
> my abline looked ridiculous. My search found plotrix: ablineclip -
> fantastic I thought - but it applies to plot and not geom_plot. I
> switched to geom_segment - the rendering looked trash. I switched to
> geom_smooth - should work but as I don't know the x values beforehand
> I'll have to clip a new dataframe - it that a hassle ? - Yes it is !
>
>             So my general question is - why isn't ggplot2 already part
> of R base - or at least if someone is to create useful packages for
> plot - perhaps a subtle hint could be made that they should also apply
> to ggplot2 (and perhaps to lattice ?? - also personally I would scrap
> qplot as an unnecessary distraction which is not easier to implement
> than ggplot). In general duplication of packages for plot and ggplot
> doesn't seem like a good idea.
>
>
> 2) The saga of the italic letter. I found, to my dismay, that to
> insert an italic letter into my plot I had to learn a whole new
> language called plotmath - which wouldn't accept normal R coding, and
> didn't even have normal control functions such as /n for a new line.
> This is ridiculous (and I'm not sure how plotmath managed to get into
> R base).
>
>             So my question is, when is plotmath going to have a
> complete overhaul to allow eg. "," instead of, or as well as, ~,~, and
> normal control functions such as \n ?
>
> 3) A related question to (2) is: where is geom_textbox ?
>
> 4) Where are examples with scientific graph defaults ?  (meaning a
> two-axis graph which is publishable - I will post my own after this is
> published in a years time, but as suggested above, while the graph
> looks good the implementation of this is not pretty).
>
> Having said that - good luck with implementation - and many thanks for
> all your hard work !
>
> Yours sincerely,
>
> Abiologist
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Apr 30 21:25:25 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 30 Apr 2015 19:25:25 +0000
Subject: [R] Editable plot
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68809C@mb02.ads.tamu.edu>

Do not post in html. You need to change your email software so that it sends messages in plain text only. Look below to see why.

Your plot is edited by modifying the code you gave us to change the graph. Save the code in a script file, change it in any way you want and then run the code again to get a changed plot. You cannot edit the plot by selecting an element on the plot and changing its properties in some way. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of IZHAK shabsogh via R-help
Sent: Thursday, April 30, 2015 2:04 AM
To: R.
Subject: [R] Editable plot


Hello,Kindly assist me on how to make the plot from the following programm to be editable?

x<-c(0.84,1.03,0.96)y<-c(1.30,1.46,1.48)z<-c(1.32,1.47,1.5)w<-c(0.07,0.07,0.07)r<-c(500,1000,2000)
# Graph cars using a y axis that ranges from 0 to 12plot(r,x, type="o", col="blue", ylim=c(0,1.5),lwd= 2, xlab = " Number of iteration",ylab=" Bias" )
# Graph trucks with red dashed line and square pointslines(r,y, type="o", pch=22, lty=2, col="red",lwd=2)lines(r,z, type="o", pch=22, lty=3, col="green",lwd=2)lines(r,w, type="o", pch=22, lty=4, col="forestgreen",lwd=2)
# Create a title with a red, bold/italic font#title(main="Estimated Bias for the optimal response ", col.main="red", font.main=4)
#legend("center", lty = 1:4, col = 1:4,?? ? ? #legend = c("x","y", "z","w"))
text(1000, 0.15, "PM")text(1000, 1.10, "VM")text(1000, 1.52, "WMSE")text(1000, 1.40, "LT")

Thank youIshaq

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From murdoch.duncan at gmail.com  Thu Apr 30 22:32:53 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Apr 2015 16:32:53 -0400
Subject: [R] 'Installation of package <package> had non-zero exit
 status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
In-Reply-To: <CAD4HhLwRUW4jy2XerC4-zvYBDjA8RiPP=82t2k45++mr8jmfpA@mail.gmail.com>
References: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>	<55427698.1080309@gmail.com>
	<CAD4HhLwRUW4jy2XerC4-zvYBDjA8RiPP=82t2k45++mr8jmfpA@mail.gmail.com>
Message-ID: <55429175.8000504@gmail.com>

On 30/04/2015 3:20 PM, Anirudh Jayaraman wrote:
> In that case, it seems that *libcurl* is not available for R-3.2.0 as I
> get a message for
> 
> *>* *install.packages("libcurl")*

It's not an R package, it's a library that you'll need on your system.

> 
>   package ?libcurl? is not available (for R version 3.2.0)
> 
> Or if on Terminal I run
> 
> *sudo apt-get install libcurl4-openssl-dev*
> 
> Package libcurl4-openssl-dev is not available, but is referred to by
> another package.
> This may mean that the package is missing, has been obsoleted, or
> is only available from another source

That sounds like a problem you'll need to ask about on an Ubuntu forum,
not R-help.  Once you get the library installed so that the curl-config
command works for you (outside of R), you should be able to install the
RCurl package in R.

Duncan Murdoch

> 
> 
> *________________________________________________________*
> *Anirudh Jayaraman*
> M.Sc Economics (2014-16)
> Indira Gandhi Institute of Development Research (IGIDR), Mumbai
> Ph No: +91 9560476729
> 
> 
> 
> 
> On Fri, May 1, 2015 at 12:08 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 30/04/2015 2:12 PM, Anirudh Jayaraman wrote:
> 
>         I recently upgraded to *R-3.2.0* from *R-2.14.1* on *Ubuntu
>         12.04 LTS.*
> 
>         I have been *trying to install some add-on packages* (that weren't
>         installed in the earlier version of R) to R-3.2.0. *but to no
>         avail*,
>         getting repeated error messages. For example, *I tried
>         installing swirl*.
>         Here's my output. The problem areas are highlighted in yellow.
>         Any solution?
> 
> 
>     The error message looks pretty clear:  the installer couldn't find
>     curl-config.  Just install whatever package is necessary to get
>     libcurl, and make sure curl-config is on your path, and you should
>     get past that error, and on to the next one.
> 
>     Duncan Murdoch
> 
> 
> 
>         *> install.packages("swirl")*
> 
> 
>         Installing package into
>         ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2?
>         (as ?lib? is unspecified)
>         also installing the dependencies ?testthat?, ?httr?, ?yaml?, ?RCurl?
> 
>         trying URL
>         'http://cran.rstudio.com/src/contrib/testthat_0.9.1.tar.gz'
>         Content type 'application/x-gzip' length 49533 bytes (48 KB)
>         ==================================================
>         downloaded 48 KB
> 
>         trying URL 'http://cran.rstudio.com/src/contrib/httr_0.6.1.tar.gz'
>         Content type 'application/x-gzip' length 247531 bytes (241 KB)
>         ==================================================
>         downloaded 241 KB
> 
>         trying URL 'http://cran.rstudio.com/src/contrib/yaml_2.1.13.tar.gz'
>         Content type 'application/x-gzip' length 81045 bytes (79 KB)
>         ==================================================
>         downloaded 79 KB
> 
>         trying URL
>         'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.6.tar.gz'
>         Content type 'application/x-gzip' length 878616 bytes (858 KB)
>         ==================================================
>         downloaded 858 KB
> 
>         trying URL 'http://cran.rstudio.com/src/contrib/swirl_2.2.21.tar.gz'
>         Content type 'application/x-gzip' length 51037 bytes (49 KB)
>         ==================================================
>         downloaded 49 KB
> 
>         * installing *source* package ?testthat? ...
>         ** package ?testthat? successfully unpacked and MD5 sums checked
>         ** libs
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>         -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reassign.c -o
>         reassign.o
>         gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>         -Wl,-z,relro -o testthat.so reassign.o -L/usr/lib/R/lib -lR
>         installing to
>         /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/testthat/libs
>         ** R
>         ** inst
>         ** preparing package for lazy loading
>         ** help
>         *** installing help indices
>         ** building package indices
>         ** testing if installed package can be loaded
>         * DONE (testthat)
>         * installing *source* package ?yaml? ...
>         ** package ?yaml? successfully unpacked and MD5 sums checked
>         ** libs
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c api.c -o api.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c dumper.c -o
>         dumper.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c emitter.c -o
>         emitter.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c implicit.c -o
>         implicit.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c loader.c -o
>         loader.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c parser.c -o
>         parser.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c r-ext.c -o
>         r-ext.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reader.c -o
>         reader.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c scanner.c -o
>         scanner.o
>         gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG   
>          -fpic  -g
>         -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>         -Wformat-security
>         -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c writer.c -o
>         writer.o
>         gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>         -Wl,-z,relro -o yaml.so api.o dumper.o emitter.o implicit.o loader.o
>         parser.o r-ext.o reader.o scanner.o writer.o -L/usr/lib/R/lib -lR
>         installing to
>         /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/yaml/libs
>         ** R
>         ** inst
>         ** preparing package for lazy loading
>         ** help
>         *** installing help indices
>         ** building package indices
>         ** testing if installed package can be loaded
>         * DONE (yaml)
>         * installing *source* package ?RCurl? ...
>         ** package ?RCurl? successfully unpacked and MD5 sums checked
>         checking for curl-config... no
>         Cannot find curl-config
>         ERROR: configuration failed for package ?RCurl?
>         * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/RCurl?
>         Warning in install.packages :
>            installation of package ?RCurl? had non-zero exit status
>         ERROR: dependency ?RCurl? is not available for package ?httr?
>         * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/httr?
>         Warning in install.packages :
>            installation of package ?httr? had non-zero exit status
>         ERROR: dependencies ?httr?, ?RCurl? are not available for
>         package ?swirl?
>         * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/swirl?
>         Warning in install.packages :
>            installation of package ?swirl? had non-zero exit status
> 
>         The downloaded source packages are in
>              ?/tmp/RtmpmKycFY/downloaded_packages?
>         *________________________________________________________*
>         *Anirudh Jayaraman*
>         M.Sc Economics (2014-16)
>         Indira Gandhi Institute of Development Research (IGIDR), Mumbai
>         Ph No: +91 9560476729
> 
>                 [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From rshepard at appl-ecosys.com  Thu Apr 30 22:56:47 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 30 Apr 2015 13:56:47 -0700 (PDT)
Subject: [R] Results Differ in Ternary Plot Matrix of Compositional Response
 Variables
Message-ID: <alpine.LNX.2.11.1504301355470.15872@localhost>

   After hours of looking for the reason why one data set plots correctly and
another one does not I am still not seeing the reason. The only differences
I see between the two data sets is the number of discrete variables (one has
6 years, the other 7 years) and one contains zeros. I wonder if the number
of discrete variables is the issue.

   I'm sure that more experienced eyes will see the reason for the different
results and will point it out to me.

   The following data and code produce a matrix of ternary plots with the
other continuous variables represented by a dot above the top point of the
triangle:

<filename = snow-regression.dat>
"Year","NO3","SO4","pH","Fi","Ga","Gr","Pr","Sh"
"2005",0.60,816,7.87,0.0556,0.5370,0.1667,0.1667,0.0741
"2006",0.40,224,7.59,0.0435,0.6739,0.0870,0.1522,0.0435
"2010",0.10,571,7.81,0.0735,0.4706,0.1029,0.1912,0.1618
"2011",0.52,130,7.42,0.0462,0.5692,0.0769,0.2462,0.0615
"2012",0.42,363,7.79,0.0548,0.5205,0.0548,0.2466,0.1233
"2013",0.42,363,7.79,0.0484,0.5323,0.1129,0.2419,0.0645

<snow-ternary-plot.R>
# Create matrix of ternary plots of FFGs as dependent variables.
# Follows 'Analyzing Compositional Data with R' sec. 5.3; pp 122 ff
# Change stream name as necessary.
# load package from library
require(compositions)
# read in raw data
SnowRegr <- read.csv('snow-regression.dat', header=T)
# extract response variables
SnowY <- acomp(SnowRegr[,5:9])
# column headings; variables
names(SnowRegr)
# continuous explanatory co-variables
SnowCovars <- SnowRegr[,c("Year","NO3","SO4","pH")]
# first continuous co-variable
SnowX1 <- SnowCovars$NO3
# second continuous co-variable
SnowX2 <- SnowCovars$SO4
# third continuous co-variable
SnowX3 <- SnowCovars$pH
# discrete co-variable
SnowX4 <- 
factor(SnowCovars$Year,c("2005","2006","2010","2011","2012","2013"),ordered=T)
# for the discrete co-var, ANOVA not specified in unique way so contrasts must 
be specified; use the
#   treatment contrasts.
contrasts(SnowX4) <- "contr.treatment"
# save figure parameters
opar <- par(xpd=NA,no.readonly=T)
# ternary plot matrix
plot(SnowY, pch=as.numeric(SnowX4), col=c("red","dark green","dark blue","dark 
goldenrod","dark orange","dark grey")[SnowX4])
# add legend
legend(x=0.83, y=-0.165, abbreviate(levels(SnowX4), 
minlength=1),pch=as.numeric(SnowX4), col=c("red","dark green","dark blue","dark 
goldenrod","dark orange","dark grey"), ncol=2, xpd=T, bty="n", yjust=0)
# reset plot parameters
par(opar)
# unload the package
detach('package:compositions')

   This data set with eqivalent code produces plots with the other continuous
variables as bars with colors on the top points of the triangles:

<filename = jerritt-regression.dat>
"Year","NO3","SO4","pH","Fi","Ga","Gr","Pr","Sh"
"2004",1.70,2200,8.70,0.0444,0.6889,0.0222,0.2222,0.0222
"2005",2.50,5000,8.43,0.0182,0.5636,0.0909,0.3091,0.0182
"2006",1.80,6670,8.57,0.0370,0.6173,0.0741,0.2469,0.0247
"2010",0.54,4000,8.00,0.0870,0.6087,0.0870,0.2174,0.0000
"2011",2.70,4300,8.47,0.0449,0.5256,0.0897,0.2949,0.0449
"2012",0.76,595,8.21,0.0000,0.4231,0.0769,0.5000,0.0000
"2013",0.76,595,8.21,0.0000,0.4545,0.0455,0.4545,0.0455

<jerritt-ternary-plot.R>
# Create matrix of ternary plots of FFGs as dependent variables.
# Follows 'Analyzing Compositional Data with R' sec. 5.3; pp 122 ff
# Change stream name as necessary.
# load package from library
require(compositions)
# read in raw data
JerrittRegr <- read.csv('jerritt-regression.dat', header=T)
# extract response variables
JerrittY <- acomp(JerrittRegr[,5:9])
# column headings; variables
names(JerrittRegr)
# continuous explanatory co-variables
JerrittCovars <- JerrittRegr[,c("Year","NO3","SO4","pH")]
# first continuous co-variable
JerrittX1 <- JerrittCovars$NO3
# second continuous co-variable
JerrittX2 <- JerrittCovars$SO4
# third continuous co-variable
JerrittX3 <- JerrittCovars$pH
# discrete co-variable
JerrittX4 <- 
factor(JerrittCovars$Year,c("2004","2005","2006","2010","2011","2012","2013"),ordered=T)
# for the discrete co-var, ANOVA not specified in unique way so contrasts must 
be specified; use the
#   treatment contrasts.
contrasts(JerrittX4) <- "contr.treatment"
# save figure parameters
opar <- par(xpd=NA,no.readonly=T)
# ternary plot matrix
plot(JerrittY, pch=as.numeric(JerrittX4), col=c("black","red","dark 
green","dark blue","dark goldenrod","dark orange","dark grey")[JerrittX4])
# add legend
legend(x=0.83, y=-0.165, abbreviate(levels(JerrittX4), 
minlength=1),pch=as.numeric(JerrittX4), col=c("black","red","dark green","dark 
blue","dark goldenrod","dark orange","dark grey"), ncol=2, xpd=T, bty="n", 
yjust=0)
# reset plot parameters
par(opar)
# unload the package
detach('package:compositions')

Thanks in advance,

Rich


From r.turner at auckland.ac.nz  Thu Apr 30 23:46:22 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 01 May 2015 09:46:22 +1200
Subject: [R] Inference Syntax
In-Reply-To: <1430392961881-4706637.post@n4.nabble.com>
References: <1430392961881-4706637.post@n4.nabble.com>
Message-ID: <5542A2AE.1020306@auckland.ac.nz>

On 30/04/15 23:22, Shivi82 wrote:
> Hi All,
>
> This is my first post in the community.
> I am currently working on finding some inferences from my sample data and
> the code I have used is:
> inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0,
> method = "theoretical"). While researching more on the code as I have just
> started using R, online I found alternative also as a keyword for the syntax
> which has option as either less, greater or two sided. I am unsure what it
> is referring to.
> If someone would please explain the alterative keyword. Thank you.

The word "alternative" refers to the alternative hypothesis in the test 
that you are carrying out.

Where does the function inference() come from?  I can find no trace of 
it in a standard R installation, and the term is too broad to search for 
effectively.  Please do not expect the R-help list to be telepathic.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From NordlDJ at dshs.wa.gov  Thu Apr 30 23:31:11 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 30 Apr 2015 21:31:11 +0000
Subject: [R] 'Installation of package <package> had non-zero exit
 status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
In-Reply-To: <55429175.8000504@gmail.com>
References: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>
	<55427698.1080309@gmail.com>
	<CAD4HhLwRUW4jy2XerC4-zvYBDjA8RiPP=82t2k45++mr8jmfpA@mail.gmail.com>
	<55429175.8000504@gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED29708@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
> Murdoch
> Sent: Thursday, April 30, 2015 1:33 PM
> To: Anirudh Jayaraman
> Cc: r-help at r-project.org
> Subject: Re: [R] 'Installation of package <package> had non-zero exit
> status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
> 
> On 30/04/2015 3:20 PM, Anirudh Jayaraman wrote:
> > In that case, it seems that *libcurl* is not available for R-3.2.0 as
> I
> > get a message for
> >
> > *>* *install.packages("libcurl")*
> 
> It's not an R package, it's a library that you'll need on your system.
> 
> >
> >   package ?libcurl? is not available (for R version 3.2.0)
> >
> > Or if on Terminal I run
> >
> > *sudo apt-get install libcurl4-openssl-dev*
> >
> > Package libcurl4-openssl-dev is not available, but is referred to by
> > another package.
> > This may mean that the package is missing, has been obsoleted, or
> > is only available from another source
> 
> That sounds like a problem you'll need to ask about on an Ubuntu forum,
> not R-help.  Once you get the library installed so that the curl-config
> command works for you (outside of R), you should be able to install the
> RCurl package in R.
> 
> Duncan Murdoch
> 
<<<snip>>>

Or maybe even better, the r-sig-debian list.  They are very helpful with R and Ubuntu issues.

https://stat.ethz.ch/mailman/listinfo/r-sig-debian


Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


From anirudhj at igidr.ac.in  Thu Apr 30 21:20:38 2015
From: anirudhj at igidr.ac.in (Anirudh Jayaraman)
Date: Fri, 1 May 2015 00:50:38 +0530
Subject: [R] 'Installation of package <package> had non-zero exit
 status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
In-Reply-To: <55427698.1080309@gmail.com>
References: <CAD4HhLxw4ZFT+qjos3vF5wo7=mkBuXujLDg_ahX9H9pqbiFcBw@mail.gmail.com>
	<55427698.1080309@gmail.com>
Message-ID: <CAD4HhLwRUW4jy2XerC4-zvYBDjA8RiPP=82t2k45++mr8jmfpA@mail.gmail.com>

In that case, it seems that *libcurl* is not available for R-3.2.0 as I get
a message for

*>* *install.packages("libcurl")*

  package ?libcurl? is not available (for R version 3.2.0)

Or if on Terminal I run

*sudo apt-get install libcurl4-openssl-dev*

Package libcurl4-openssl-dev is not available, but is referred to by
another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source


*________________________________________________________*
*Anirudh Jayaraman*
M.Sc Economics (2014-16)
Indira Gandhi Institute of Development Research (IGIDR), Mumbai
Ph No: +91 9560476729




On Fri, May 1, 2015 at 12:08 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/04/2015 2:12 PM, Anirudh Jayaraman wrote:
>
>> I recently upgraded to *R-3.2.0* from *R-2.14.1* on *Ubuntu 12.04 LTS.*
>>
>> I have been *trying to install some add-on packages* (that weren't
>> installed in the earlier version of R) to R-3.2.0. *but to no avail*,
>> getting repeated error messages. For example, *I tried installing swirl*.
>> Here's my output. The problem areas are highlighted in yellow. Any
>> solution?
>>
>
> The error message looks pretty clear:  the installer couldn't find
> curl-config.  Just install whatever package is necessary to get libcurl,
> and make sure curl-config is on your path, and you should get past that
> error, and on to the next one.
>
> Duncan Murdoch
>
>
>>
>> *> install.packages("swirl")*
>>
>>
>> Installing package into ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2?
>> (as ?lib? is unspecified)
>> also installing the dependencies ?testthat?, ?httr?, ?yaml?, ?RCurl?
>>
>> trying URL 'http://cran.rstudio.com/src/contrib/testthat_0.9.1.tar.gz'
>> Content type 'application/x-gzip' length 49533 bytes (48 KB)
>> ==================================================
>> downloaded 48 KB
>>
>> trying URL 'http://cran.rstudio.com/src/contrib/httr_0.6.1.tar.gz'
>> Content type 'application/x-gzip' length 247531 bytes (241 KB)
>> ==================================================
>> downloaded 241 KB
>>
>> trying URL 'http://cran.rstudio.com/src/contrib/yaml_2.1.13.tar.gz'
>> Content type 'application/x-gzip' length 81045 bytes (79 KB)
>> ==================================================
>> downloaded 79 KB
>>
>> trying URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.6.tar.gz'
>> Content type 'application/x-gzip' length 878616 bytes (858 KB)
>> ==================================================
>> downloaded 858 KB
>>
>> trying URL 'http://cran.rstudio.com/src/contrib/swirl_2.2.21.tar.gz'
>> Content type 'application/x-gzip' length 51037 bytes (49 KB)
>> ==================================================
>> downloaded 49 KB
>>
>> * installing *source* package ?testthat? ...
>> ** package ?testthat? successfully unpacked and MD5 sums checked
>> ** libs
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reassign.c -o
>> reassign.o
>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>> -Wl,-z,relro -o testthat.so reassign.o -L/usr/lib/R/lib -lR
>> installing to
>> /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/testthat/libs
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (testthat)
>> * installing *source* package ?yaml? ...
>> ** package ?yaml? successfully unpacked and MD5 sums checked
>> ** libs
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c api.c -o api.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c dumper.c -o dumper.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c emitter.c -o emitter.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c implicit.c -o
>> implicit.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c loader.c -o loader.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c parser.c -o parser.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c r-ext.c -o r-ext.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c reader.c -o reader.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c scanner.c -o scanner.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I. -DNDEBUG     -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c writer.c -o writer.o
>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>> -Wl,-z,relro -o yaml.so api.o dumper.o emitter.o implicit.o loader.o
>> parser.o r-ext.o reader.o scanner.o writer.o -L/usr/lib/R/lib -lR
>> installing to /home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/yaml/libs
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (yaml)
>> * installing *source* package ?RCurl? ...
>> ** package ?RCurl? successfully unpacked and MD5 sums checked
>> checking for curl-config... no
>> Cannot find curl-config
>> ERROR: configuration failed for package ?RCurl?
>> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/RCurl?
>> Warning in install.packages :
>>    installation of package ?RCurl? had non-zero exit status
>> ERROR: dependency ?RCurl? is not available for package ?httr?
>> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/httr?
>> Warning in install.packages :
>>    installation of package ?httr? had non-zero exit status
>> ERROR: dependencies ?httr?, ?RCurl? are not available for package ?swirl?
>> * removing ?/home/anirudh/R/x86_64-pc-linux-gnu-library/3.2/swirl?
>> Warning in install.packages :
>>    installation of package ?swirl? had non-zero exit status
>>
>> The downloaded source packages are in
>>      ?/tmp/RtmpmKycFY/downloaded_packages?
>> *________________________________________________________*
>> *Anirudh Jayaraman*
>> M.Sc Economics (2014-16)
>> Indira Gandhi Institute of Development Research (IGIDR), Mumbai
>> Ph No: +91 9560476729
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From aaronwright1 at hotmail.com  Thu Apr 30 22:19:47 2015
From: aaronwright1 at hotmail.com (Aaron)
Date: Thu, 30 Apr 2015 13:19:47 -0700 (PDT)
Subject: [R] New User Having Trouble Loading R Commander on Mac OS Yosemite
Message-ID: <BLU182-W3011AC773EECFA8697AD5E9AD60@phx.gbl>

I keep getting the same error message when trying to install R Commander.
My operating system is Mac OS Yosemite 10.10
I have installed R 3.2, Rstudio, XQuartz (X11), and tcltk-8.x.x-x11.dmg.
But I keep getting the following error:Loading required package: splinesLoading required package: RcmdrMiscLoading required package: carError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :   there is no package called ?SparseM?Error: package ?car? could not be loaded 		 	   		  



--
View this message in context: http://r.789695.n4.nabble.com/New-User-Having-Trouble-Loading-R-Commander-on-Mac-OS-Yosemite-tp4706666.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


