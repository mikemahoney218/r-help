From r.turner at auckland.ac.nz  Tue Jul  1 00:29:57 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 01 Jul 2014 10:29:57 +1200
Subject: [R] Delaunay triangles with LONG/LAT + biomass
In-Reply-To: <CAJhyqVj1EC+eE3ES4RDiLomJ+peA9VfKf689hq0gbxzCz5dLkA@mail.gmail.com>
References: <CAJhyqVj1EC+eE3ES4RDiLomJ+peA9VfKf689hq0gbxzCz5dLkA@mail.gmail.com>
Message-ID: <53B1E4E5.5060607@auckland.ac.nz>

On 01/07/14 04:31, Trevor Davies wrote:
> Hello,
>
> I was hoping someone could point me in the direction towards a package
> where I can use delaunay triangulation to create a polygon set where the
> inside of the triangles are tagged with an estimate of a mean value of the
> points making up the points of the triangle.  This is fisheries trawl data
> if that helps add context.
>
> For those familiar with the system, it's to make plots similar to those
> made by the Dept of Fisheries and Oceans Canada in ACON (which has now
> stopped being maintained).  Although freely available, I'm on a mac and it
> would be nice to just get it sorted out in R going forward.
>
> Ref here:
> http://www2.mar.dfo-mpo.gc.ca/science/acon/Examples/ShadedContours.html

The deldir package has the capacity to tag points with values, and the 
triang.list() function creates a list of data frames corresponding to 
each triangle, the last column of these data frames (named "z") being 
the "values" associated with the corners of the triangles.

The means of these values can be calculated using sapply().

E.g.:

set.seed(42)
x <- runif(20)
y <- runif(20)
z <- sample(1:5,20,TRUE)
dxy <- deldir(x,y,z=z)
txy <- triang.list(dxy)
mxy <- sapply(txy,function(u){mean(u[["z"]])})

You could "tag" the triangles with these mean values by assigning the 
values as attributes of the components of txy, using lapply(), possibly.

Note that deldir() treats coordinates as ***Euclidean*** coordinates. 
This is only an approximation to a triangulation on a sphere.  Whether 
the approximation is good enough is up to you, I guess.

cheers,

Rolf Turner


From jim at bitwrit.com.au  Tue Jul  1 01:48:41 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 01 Jul 2014 09:48:41 +1000
Subject: [R] yet another regular expression
In-Reply-To: <2310760.RmipCVWQby@localhost.localdomain>
References: <2310760.RmipCVWQby@localhost.localdomain>
Message-ID: <11901088.FbOoqmIQAC@localhost.localdomain>

On Mon, 30 Jun 2014 11:13:18 PM Jim Lemon wrote:
> Hi all,
> I have managed, with the help of glob2rx() to get two parts of a text
> manipulation working. I have successfully gotten rid of the first and
> second bits, but I have hit the wall trying to get rid of the last bit.
> Here's an example:
> 
> initString<-
>  "\"Delete this\":value1,\"Delete this too\":value2},Delete last bit"
> sub("\"Delete this too\":","",
>  sub(glob2rx("*this\":*"),"",initString),fixed=TRUE)
> 
> This gives me:
> 
> [1] "value1,value2},Delete last bit"
> 
> and glob2rx("},*") just won't get rid of the last bit. I throw myself upon
> the mercy of the regular expression gurus.
> 
Hi again,
Sorry, but my "minimal reproducible example" was apparently 
misleading. "value1" and "value2" are not fixed strings, but varying 
numbers. After a night's sleep I solved the problem using strsplit(), which 
gave me a big list of strings that I could process without wearing out the 
"\" key. Thanks for the suggestions.

Jim


From NordlDJ at dshs.wa.gov  Tue Jul  1 02:03:31 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 1 Jul 2014 00:03:31 +0000
Subject: [R] Getting data from Table in RStudio
In-Reply-To: <1404161875.45790.YahooMailNeo@web141403.mail.bf1.yahoo.com>
References: <1404161875.45790.YahooMailNeo@web141403.mail.bf1.yahoo.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623A399D9@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shanae Clarke
> Sent: Monday, June 30, 2014 1:58 PM
> To: r-help at r-project.org
> Subject: [R] Getting data from Table in RStudio
> 
> Hello,
> 
> I am new to R progaming and have just started using this program since
> last week. What i want to achieve is to use R to determine patterns in
> sales/ customer complaint etc. information located in a mysql database.
> I am not sure how to approach this or which technique i should use to
> do so. However, i had proceeded to add a dataset to RStudio using the
> following code:
> library(RODBC)
> dsn.name <- "MySQLlocal"
> user.name <- "orange"
> pwd <- ""
> ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> res <- sqlFetch(ch, "<my_table_name>")
> odbcQuery(ch, "Select * from?<my_table_name>")
> odbcClose(ch)
> 
> When the code is run all that is returned is
> > library (RODBC)
> > dsn.name <- "MySQLlocal"
> ?> user.name <- "orange"
> > pwd <- ""
> > ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> >?res <- sqlFetch(ch, "<my_table_name>")
> >?odbcQuery(ch, "Select * from?<my_table_name>")
> ?[1] 1
> > odbcClose(ch)
> 
> No other results.
> I was expecting to see the table values or some other data. Not that.
> Maybe I am misunderstanding the whole concept of how R works.
> If so could someone please help me to clarify what the problem is and
> perhaps point me to a tutorial or somewhere i can get a information and
> get a better understanding.
> 
> Thank you. Your Help will be greatly appreciated.
> 
> Gayon Clarke
> 	[[alternative HTML version deleted]]

1. For future reference, you should read the posting guide linked at the bottom of each email, and post only in plain text (no HTML).  

2. You should read the help files for each of the functions you are trying use.

3. Did you try to look at the object, res, that you created?  That should have contained the table that you fetched from the MySQL database.  You could have typed res and the table would have printed out.  You also could have used head(res) to look at the first few records, or used str(res) to examine the structure of res.

There is also an R-sig-DB list where you can get more specific help with database connectivity questions.
     https://stat.ethz.ch/mailman/listinfo/r-sig-db


Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From jorgeivanvelez at gmail.com  Tue Jul  1 04:08:06 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 1 Jul 2014 12:08:06 +1000
Subject: [R] From long to wide format
In-Reply-To: <1404118260.82792.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAKL8G3HAtkLu0FJFTkYqLn_49EwfgErw_F9ErOGy=82HPjZj0Q@mail.gmail.com>
	<1404118260.82792.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAKL8G3GzDH+kger80OS6S7dMDZ+yNxn45CB2xmmoem8i7xg0Xg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/6695d455/attachment.pl>

From chiefmurphy at gmail.com  Tue Jul  1 04:47:49 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 30 Jun 2014 19:47:49 -0700
Subject: [R] Must array methods be defined for user defined classes?
Message-ID: <CAHgH9_G7SOVuF0kipHURVjOyYzzCwhiqA6EtsrmjdpddtzT4GQ@mail.gmail.com>

Here's a simple example:

setClass("foo", contains="numeric")
x <- new("foo", 4)

# Division by scalar works
> x / 2
An object of class "foo"
[1] 2

# Division by array blows up
y <- array(2, c(2, 2))
> x / y
Error in getDataPart(c(2, 2, 2, 2)) : node stack overflow

# Not sure I understand the error message, but in any case, based on
the success of ...
> x / as.numeric(y)
[1] 2 2 2 2

# ... wrote a division method for arrays, which worked.
> setMethod("/", signature = c("foo", "array"), function(e1, e2) e1 / as.numeric(e2))
[1] "/"
> x / y
[1] 2 2 2 2

Is it always necessary to define "array" methods for arithmetic on
user defined classes? Maybe the answer has to do with the error
message I did not understand.

Thanks,
Dan Murphy

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                      LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.0
>


From johnson.cheryl625 at gmail.com  Tue Jul  1 02:36:19 2014
From: johnson.cheryl625 at gmail.com (Cheryl Johnson)
Date: Mon, 30 Jun 2014 20:36:19 -0400
Subject: [R] R Console Output
In-Reply-To: <CAAxdm-4XcOr-6OYghOhCu0ibQ=_ac6ZAzN2-kXLLgbyW-rNySQ@mail.gmail.com>
References: <CAJJ9dtt-AZkRyHh_2yKOFkcUODCD9OOVsZ6H4OTEc_c-ApuyRg@mail.gmail.com>
	<CAAxdm-4XcOr-6OYghOhCu0ibQ=_ac6ZAzN2-kXLLgbyW-rNySQ@mail.gmail.com>
Message-ID: <CAJJ9dtsBGo63au3mN3avsLxSYv=HMfcwRym9w93DrS-RN4cC2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140630/74c173b5/attachment.pl>

From mhaartman at alteryx.com  Tue Jul  1 03:55:03 2014
From: mhaartman at alteryx.com (meg)
Date: Mon, 30 Jun 2014 18:55:03 -0700 (PDT)
Subject: [R] What are the other Options for hiddenActFunc in the RSNNS r
 package?
Message-ID: <1404179703661-4693313.post@n4.nabble.com>

I am trying to figure out the options for hiddenActFunc..any help would be
great!!



--
View this message in context: http://r.789695.n4.nabble.com/What-are-the-other-Options-for-hiddenActFunc-in-the-RSNNS-r-package-tp4693313.html
Sent from the R help mailing list archive at Nabble.com.


From mark.doubell at sa.gov.au  Tue Jul  1 04:35:21 2014
From: mark.doubell at sa.gov.au (Doobs)
Date: Mon, 30 Jun 2014 19:35:21 -0700 (PDT)
Subject: [R] 1-dinemsional point process
Message-ID: <1404182121229-4693315.post@n4.nabble.com>

Hi,
As a new user, is it possible to look at clustering/dispersion processes of
a 1D point process (i.e. points along a transect)?
My limited  understanding is that spatstat is for 2&3D point patterns.

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/1-dinemsional-point-process-tp4693315.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Jul  1 05:08:27 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Jun 2014 20:08:27 -0700
Subject: [R] matrix
In-Reply-To: <CAN5YmCGWimAzPCzbvZWj6QUxKwR_Re6NVt1Ydwj+2VMcwQYgqg@mail.gmail.com>
References: <1404142058.68911.YahooMailNeo@web142506.mail.bf1.yahoo.com>
	<CAN5YmCGWimAzPCzbvZWj6QUxKwR_Re6NVt1Ydwj+2VMcwQYgqg@mail.gmail.com>
Message-ID: <1404184107.61352.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Izhak,
If the position of the elements to be replaced follow the pattern below:
seq(1,length(t), by=7)
#[1]? 1? 8 15

t[seq(1,length(t), by=7)] <- c(50,90,100)
A.K.






On Monday, June 30, 2014 4:19 PM, "Adams, Jean" <jvadams at usgs.gov> wrote:
t[1, 1] <- 50
t[3, 2] <- 90
t[5, 3] <- 100

Jean


On Mon, Jun 30, 2014 at 10:27 AM, IZHAK shabsogh <ishaqbaba at yahoo.com>
wrote:

>
>
> kindly guide me on how i can delete and replace an element from a matrix t
> below
>
> for example delete first element in column one and replace it with 50,
> third element in column 2 by 90 and fifth element in column 3 by 100
>
>
> t1<-c(1,2,3,4,5)
> t2<-c(6,7,8,9,10)
> t3<-c(11,12,13,14,15)
> t<-cbind(t1,t2,t3)
>
>
> thanks
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul  1 05:33:23 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Jun 2014 20:33:23 -0700
Subject: [R] From long to wide format
In-Reply-To: <CAKL8G3GzDH+kger80OS6S7dMDZ+yNxn45CB2xmmoem8i7xg0Xg@mail.gmail.com>
References: <CAKL8G3HAtkLu0FJFTkYqLn_49EwfgErw_F9ErOGy=82HPjZj0Q@mail.gmail.com>
	<1404118260.82792.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAKL8G3GzDH+kger80OS6S7dMDZ+yNxn45CB2xmmoem8i7xg0Xg@mail.gmail.com>
Message-ID: <1404185603.80078.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI Jorge,

I was able to reproduce the error.? The link below provides a way to adjust the stack. I didn't test it.? 


http://stackoverflow.com/questions/14719349/error-c-stack-usage-is-too-close-to-the-limit
Also check this link

http://stackoverflow.com/questions/13245019/how-to-change-the-stack-size-using-ulimit-or-per-process-on-mac-os-x-for-a-c-or


A.K.

On Monday, June 30, 2014 10:08 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:



Hi Arun,

Thank you very much for your suggestion. ??

While running some tests, I came across the following:

# sample data
n <- 2000
p <- 1000
x2 <- data.frame(variable = rep(paste0('x', 1:p), each = n), id = rep(paste0('p', 1:p), n), outcome = sample(0:2, n*p, TRUE), rate = runif(n*p, 0.5, 1))
str(x2)

library(dplyr)
library(tidyr)

# Arun's suggestion
system.time({wide1 <- x2%>%
? ? ? ? select(-rate) %>%
? ? ? ? mutate(variable=factor(variable, levels=unique(variable)),id=factor(id, levels=unique(id))) %>% ? ? ? ? ? ? ? ??
? ? ? ? ? ? spread(variable,outcome)
colnames(wide1)[-1] <- paste("outcome",colnames(wide1)[-1],sep=".")
})

# Error: C stack usage ?18920219 is too close to the limit
# Timing stopped at: 13.833 0.251 14.085


Do you happen to know what can be done to avoid this?

Thank you.

Best,
Jorge.-



On Mon, Jun 30, 2014 at 6:51 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi Jorge,
>
>You may try:
>library(dplyr)
>library(tidyr)
>
>#Looks like this is faster than the other methods.
>system.time({wide1 <- x2%>%
>??? ??? select(-rate) %>%
>??? ??? mutate(variable=factor(variable, levels=unique(variable)),id=factor(id, levels=unique(id))) %>%?????????????????
>??????????? spread(variable,outcome)
>colnames(wide1)[-1] <- paste("outcome",colnames(wide1)[-1],sep=".")
>})
>
>?#user? system elapsed
>?#? 0.006??? 0.00??? 0.006
>
>
>
>system.time(wide <- reshape(x2[, -4], v.names = "outcome", idvar = "id",
>?????????????? timevar = "variable", direction = "wide"))
>?#user? system elapsed
>?# 0.169?? 0.000?? 0.169
>
>
>
>system.time({
>sel <- unique(x2$variable)
>id <- unique(x2$id)
>
>X <- matrix(NA, ncol = length(sel) + 1, nrow = length(id))
>X[, 1] <- id
>colnames(X) <- c('id', sel)
>r <- mclapply(seq_along(sel), function(i){
>??????????????????????? out <- x2[x2$variable == sel[i], ][, 3]
>??????????????????????? }, mc.cores = 4)
>X[, -1] <- do.call(rbind, r)
>X
>})
>
># user? system elapsed
>#? 0.125?? 0.011?? 0.074
>
>
>?wide2 <- wide1
>wide2$id <- as.character(wide2$id)
>?wide$id <- as.character(wide$id)
>all.equal(wide, wide2, check.attributes=F)
>#[1] TRUE
>
>A.K.
>
>
>
>
>On Sunday, June 29, 2014 11:48 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
>Dear R-help,
>
>I am working with some data stored as "filename.txt.gz" in my working
>directory.
>After reading the data in using read.table(), I can see that each of them
>has four columns (variable, id, outcome, and rate) and the following
>structure:
>
># sample data
>x2 <- data.frame(variable = rep(paste0('x', 1:100), each = 100), id =
>rep(paste0('p', 1:100), 100), outcome = sample(0:2, 10000, TRUE), rate =
>runif(10000, 0.5, 1))
>str(x2)
>
>Each variable, i.e., x1, x2,..., x100 is repeated as many times as the
>number of unique IDs (100 in this example).? What I would like to do is to
>transform the data above
>in a long format.? I can do this by using
>
># reshape
>wide <- reshape(x2[, -4], v.names = "outcome", idvar = "id",
>? ? ? ? ? ? ? ? timevar = "variable", direction = "wide")
>str(wide)
>
># or a "hack" with mclapply:
>
>require(parallel)
>sel <- as.character(unique(x2$variable))
>id <- as.character(unique(x2$id))
>X <- matrix(NA, ncol = length(sel) + 1, nrow = length(id))
>X[, 1] <- id
>colnames(X) <- c('id', sel)
>r <- mclapply(seq_along(sel), function(i){
>? ? ? ? ? ? ? ? ? ? ? ? out <- x2[x2$variable == sel[i], ][, 3]
>? ? ? ? ? ? ? ? ? ? ? ? }, mc.cores = 4)
>X[, -1] <- do.call(rbind, r)
>X
>
>However, I was wondering if it is possible to come up with another solution
>, hopefully faster than these
>.? Unfortunately, either one of these takes a very long time to process,
>specially when the number of variables is very large
>(> 250,000) and the number of ids is ~2000.
>
>I would very much appreciate your suggestions.? ?At the end of this message
>is my sessionInfo().
>
>Thank you very much in advance.
>
>Best regards,
>Jorge Velez.-
>
>
>R>? sessionInfo()
>
>R version 3.0.2 Patched (2013-12-11 r64449)
>Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
>locale:
>[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>
>attached base packages:
>[1] graphics? grDevices utils? ? ?datasets? parallel? compiler? stats
>[8] methods? ?base
>
>other attached packages:
>[1] knitr_1.6.3? ? ? ? ? ? ggplot2_1.0.0? ? ? ? ? slidifyLibraries_0.3.1
>[4] slidify_0.3.52
>
>loaded via a namespace (and not attached):
>[1] colorspace_1.2-4 digest_0.6.4? ? ?evaluate_0.5.5? ?formatR_0.10
>[5] grid_3.0.2? ? ? ?gtable_0.1.2? ? ?markdown_0.7.1? ?MASS_7.3-33
>[9] munsell_0.4.2? ? plyr_1.8.1? ? ? ?proto_0.3-10? ? ?Rcpp_0.11.2
>[13] reshape2_1.4? ? ?scales_0.2.4? ? ?stringr_0.6.2? ? tools_3.0.2
>[17] whisker_0.4? ? ? yaml_2.1.13
>
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From irasharenow100 at yahoo.com  Tue Jul  1 06:12:42 2014
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Mon, 30 Jun 2014 21:12:42 -0700
Subject: [R] Change database in SQL Server using RODBC
In-Reply-To: <8mvdhga0jryarb1s4x8lyhi4.1404141433891@email.android.com>
References: <8mvdhga0jryarb1s4x8lyhi4.1404141433891@email.android.com>
Message-ID: <53B2353A.1030404@yahoo.com>

Thanks for everyone?s help.

I followed the instruction given on a variety of web pages in order to 
set up the connection. The problem is trying to use the first connection 
for a second database and doing so from within R.

It seems to me that an easy workaround is to simply set up another 
connection and use a second database as the default.

In Windows 7 the basic strategy is do the following:

Control Panel

Administrative Tools

Data Sources (ODBC)

In the ODBC Data Source Administrator pop up select SQL 2012 and then 
click on Add.

Since I do not have to work with a large number of databases, I consider 
this to be a satisfactory work around.

On 6/30/2014 8:17 AM, Frede Aakmann T?gersen wrote:
> Hi
>
> I can see that you do have troubles understanding how all this works 
> using the RODBC package. Peter wasn't really being helpful to you.
>
> This is something that is quite difficult to help with not sitting 
> beside you. Do you not having some local help from e.g. the IT department?
>
> However for a start please let me know how you managed to get
>
> con = odbcConnect("SQLServer2012")
>
> to work.
>
> It seems like that some DSN was set up.
>
> From there we can probably find a solution.
>
> Br. Frede
>
>
> Sendt fra Samsung mobil
>
>
> -------- Oprindelig meddelelse --------
> Fra: Ira Sharenow
> Dato:30/06/2014 16.42 (GMT+01:00)
> Til: Peter Crowther ,R list
> Emne: Re: [R] Change database in SQL Server using RODBC
>
> Thanks for everyone?s feedback.
>
> library(RODBC)
>
> con = odbcConnect("SQLServer2012")
>
> orders1 = sqlFetch(con,"dbo.orders")
>
> odbcClose(con)
>
> Allowed me to close the connection properly. Thanks.
>
> However, I still cannot figure out how to connect to the second database
> and table.
>
> library(RODBC)
>
> >con2 = odbcConnect("[sportsDB].dbo.sports")
>
> Warning messages:
>
> 1: In odbcDriverConnect("DSN=[sportsDB].dbo.sports") :
>
>    [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver 
> Manager] Data source name not found and no default driver specified
>
> 2: In odbcDriverConnect("DSN=[sportsDB].dbo.sports") :
>
>    ODBC connection failed
>
> >con2 = odbcConnect("[sportsDB].[dbo].sports")
>
> Warning messages:
>
> 1: In odbcDriverConnect("DSN=[sportsDB].[dbo].sports") :
>
>    [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver 
> Manager] Data source name not found and no default driver specified
>
> 2: In odbcDriverConnect("DSN=[sportsDB].[dbo].sports") :
>
>    ODBC connection failed
>
> >con2 = odbcConnect("[sportsDB].[dbo].[sports]")
>
> Warning messages:
>
> 1: In odbcDriverConnect("DSN=[sportsDB].[dbo].[sports]") :
>
>    [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver 
> Manager] Data source name not found and no default driver specified
>
> 2: In odbcDriverConnect("DSN=[sportsDB].[dbo].[sports]") :
>
>    ODBC connection failed
>
> >con3 = odbcConnect("SQLServer2012")
>
> >orders3 =   sqlFetch(con3, "sportsDB.dbo.sports")
>
> Error in odbcTableExists(channel, sqtable) :
>
>    ?sportsDB.dbo.sports?: table not found on channel
>
> On 6/30/2014 1:34 AM, Peter Crowther wrote:
> > On 30 June 2014 02:44, Ira Sharenow <irasharenow100 at yahoo.com> wrote:
> >> I wish to query tables that are NOT in the default SQL Server 2012 
> database.
> >> Now for the problem. I also want to read in the table dbo.sports. That
> >> table is in the database sportsDB. I did not see any way to do so from
> >> within R.
> > Can you not use sportsDB.dbo.sports to reference the table?
> >
> > In general, table reference syntax is [ [ [ serverName '.' ]
> > databaseName '.' ] [schema ] '.' ] tableName, where the names need
> > only be surrounded by [...] if they are not valid SQL Server
> > identifiers.  Many people may suggest you reference
> > [sportsDB].[dbo].[sports]; this is unnecessary verbiage.
> >
> > Cheers,
> >
> > - Peter
> >
>
>
>         [[alternative HTML version deleted]]
>


From nickeubank at gmail.com  Tue Jul  1 08:37:29 2014
From: nickeubank at gmail.com (Nick Eubank)
Date: Mon, 30 Jun 2014 23:37:29 -0700
Subject: [R] Using external SQLite installation for RSQLite in Windows?
Message-ID: <CAFWQgOkZGL69F=aYdYg=3wvi2kHThjM0oa7ieko1ciAc79vg_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140630/f5cf8ac1/attachment.pl>

From aguitatierra at hotmail.com  Tue Jul  1 12:59:31 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Tue, 1 Jul 2014 12:59:31 +0200
Subject: [R] How to plot individual pdf files for each wrapped plot with
 ggplot2?
In-Reply-To: <CAJhyqVjG2Vq-D42rLUNm5EbXkRzmCdS5QKUqGSks=Sni4EBmdQ@mail.gmail.com>
References: <BLU436-SMTP121608CDBA28619BD233D71D9040@phx.gbl>
	<CAJhyqVjG2Vq-D42rLUNm5EbXkRzmCdS5QKUqGSks=Sni4EBmdQ@mail.gmail.com>
Message-ID: <BLU436-SMTP49D59D334E021FAD22DC58D9070@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/be8546dd/attachment.pl>

From aguitatierra at hotmail.com  Tue Jul  1 13:02:59 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Tue, 1 Jul 2014 13:02:59 +0200
Subject: [R] How to plot individual pdf files for each wrapped plot with
 ggplot2?
In-Reply-To: <53B29493.7080906@hotmail.com>
References: <BLU436-SMTP121608CDBA28619BD233D71D9040@phx.gbl>
	<CAJhyqVjG2Vq-D42rLUNm5EbXkRzmCdS5QKUqGSks=Sni4EBmdQ@mail.gmail.com>
	<53B29493.7080906@hotmail.com>
Message-ID: <BLU436-SMTP640BD0880C1BA5BD517898D9070@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/940d44e0/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Jul  1 13:50:15 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 01 Jul 2014 13:50:15 +0200
Subject: [R] Dead link in the help page of as.Date()
In-Reply-To: <CA+dpOJmYR+uP-Gd69s8sdYhNzgo8vF-gRKR6EU4Snz-h7abb8g@mail.gmail.com>
References: <CA+dpOJmYR+uP-Gd69s8sdYhNzgo8vF-gRKR6EU4Snz-h7abb8g@mail.gmail.com>
Message-ID: <53B2A077.7040104@statistik.tu-dortmund.de>



On 23.06.2014 21:41, Christofer Bogaso wrote:
> Hi,
>
> I was reading the help page for as.Date() function for some reason,
> and noticed a Matlab link:
>
> http://www.mathworks.com/help/techdoc/matlab_prog/bspgcx2-1.html

Thanks, updated now.

Best,
Uwe Ligges



> It looks like this link is dead. So may be it would be better to put a
> correct link or remove this altogether.
>
> Thanks and regards,
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Jul  1 13:54:57 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 01 Jul 2014 13:54:57 +0200
Subject: [R] c() with POSIXlt objects and their timezone is lost
In-Reply-To: <53A8A187.9060103@yahoo.fr>
References: <53A8A187.9060103@yahoo.fr>
Message-ID: <53B2A191.9030905@statistik.tu-dortmund.de>



On 23.06.2014 23:52, Marc Girondot wrote:
> When two POSIXlt objects are combine with c(), they lost their tzone
> attribute, even if they are the same.
> I don't know if it is a feature, but I don't like it !
>
> Marc
>
>  > es <- strptime("2010-02-03 10:20:30", format="%Y-%m-%d %H:%M:%S",
> tz="UTC")
>  > es
> [1] "2010-02-03 10:20:30 UTC"
>  > attributes(es)
> $names
> [1] "sec"   "min"   "hour"  "mday"  "mon"   "year"  "wday"  "yday" "isdst"
>
> $class
> [1] "POSIXlt" "POSIXt"
>
> $tzone
> [1] "UTC"
>
>  > c(es, es)
> [1] "2010-02-03 11:20:30 CET" "2010-02-03 11:20:30 CET"
>  > attributes(c(es, es))
> $names
>   [1] "sec"    "min"    "hour"   "mday"   "mon"    "year"   "wday"
> "yday"   "isdst"  "zone"   "gmtoff"
>
> $class
> [1] "POSIXlt" "POSIXt"
>
> $tzone
> [1] ""     "CET"  "CEST"




 From ?c:

"c is sometimes used for its side effect of removing attributes [...]"

and from ?c.POSIXlt:


"Using c on "POSIXlt" objects converts them to the current time zone, [...]"

Best,
Uwe Ligges



> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmersman at smail.uni-koeln.de  Tue Jul  1 16:21:51 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Tue, 1 Jul 2014 16:21:51 +0200
Subject: [R] (PLM- package) Residual-Plotting and missing Values
Message-ID: <001a01cf9537$ccfbfd00$66f3f700$@uni-koeln.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/cf8ba990/attachment.pl>

From agostinodiciaula at tiscali.it  Tue Jul  1 09:02:29 2014
From: agostinodiciaula at tiscali.it (adc)
Date: Tue, 1 Jul 2014 00:02:29 -0700 (PDT)
Subject: [R] plot in generalized additive model (GAM)
Message-ID: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/c680441e/attachment.pl>

From humtumiit at gmail.com  Tue Jul  1 14:37:23 2014
From: humtumiit at gmail.com (Param Jeet)
Date: Tue, 1 Jul 2014 18:07:23 +0530
Subject: [R] Socket Connection in R
Message-ID: <CAOwGQ9AX3AwRVSFUiK6DwRZ1ei-gJFjpYFTe-LkSZNF2c0t7wA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/92723c55/attachment.pl>

From jeethghambole at gmail.com  Tue Jul  1 14:08:44 2014
From: jeethghambole at gmail.com (jeeth ghambole)
Date: Tue, 1 Jul 2014 17:38:44 +0530
Subject: [R] Order Book details in R Interactive Brokers Package
Message-ID: <CAFp0RzWKOwb0K0wce+nDY=DFxPvJVEd-=42HL2-v4OPb2bqvpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/dbb8535a/attachment.pl>

From john.archie.mckown at gmail.com  Tue Jul  1 14:06:42 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 1 Jul 2014 07:06:42 -0500
Subject: [R] combining data from multiple read.delim() invocations.
Message-ID: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/4ff3ddbd/attachment.pl>

From suzon.sepp at gmail.com  Tue Jul  1 16:24:15 2014
From: suzon.sepp at gmail.com (Suzon Sepp)
Date: Tue, 1 Jul 2014 16:24:15 +0200
Subject: [R] logistic regression for data with repeated measures
Message-ID: <CAJb6Km_ndhkW=7c__1a6CX4U2WBuVjhRQNjemvs6Y_hMQfe22g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/21c5ada8/attachment.pl>

From mmalten at gmail.com  Tue Jul  1 17:13:53 2014
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Tue, 1 Jul 2014 11:13:53 -0400
Subject: [R] logistic regression for data with repeated measures
In-Reply-To: <CAJb6Km_ndhkW=7c__1a6CX4U2WBuVjhRQNjemvs6Y_hMQfe22g@mail.gmail.com>
References: <CAJb6Km_ndhkW=7c__1a6CX4U2WBuVjhRQNjemvs6Y_hMQfe22g@mail.gmail.com>
Message-ID: <CANOgrHaQGFKWbKp=zkARYpfaZYHWTFbDOyA0rHvypMMV3=xKeA@mail.gmail.com>

http://stats.stackexchange.com/questions/62225/conditional-logistic-regression-vs-glmm-in-r
might be a good start
____________________________
Ersatzistician and Chutzpahthologist
I can answer any question.  "I don't know" is an answer. "I don't know
yet" is a better answer.


On Tue, Jul 1, 2014 at 10:24 AM, Suzon Sepp <suzon.sepp at gmail.com> wrote:
> Hi,
>
> It seems that I'm quite lost in this wide and powerful R's universe, so I
> permit myself to ask your help about issues with which I'm struggling.
> Thank you,
>
> I would like to know if the answer?s accuracy (correct = 1; incorrect = 0)
> varies depending on 2 categorical variables which are the group (A and B)
> and the condition (a, b and c) knowing that I?ve got n subjects and 12
> trials by conditions for each subject (i.e. 12 repetitions).
>
> To do that, I?m focusing on logistic regression analysis. I?ve got no
> problem with this kind of analysis until now (logistic regression with
> numeric predictor variables and/or categorical predictor with 2 levels
> only) but, in this new context, I think I have to focus more specifically
> on logistic regression including *nested (or random?) factors* in a*repeated
> measures design* (because of the variables ?Subject? and ?Trial?) with a
> categorical predictor variable with *more than 2 levels* (the variable
> ?Condition?) and I never did such a thing?yet.
>
> mydata =
> mydata$Subject: Factor w/38 levels: "i01", "i02", "i03", "i04"
> mydata$Group: Factor w/2 levels: "A", "B"
> mydata$Condition: Factor w/3 levels: "a", "b", "c"
> mydata$Trial: Factor w/12 levels: "t01", "t02", ..."t12"
> mydata$Accuracy: Factor w/2 levels: "0", "1"
>
> Subject      Group      Trial      Condition      Accuracy
>    i01              A           t01             a                   0
>    i01              A           t02             a                   1
> ...
>    i01              A           t12             a                   1
>    i01              A           t01             b                   1
>    i01              A           t02             b                   1
> ...
>    i01              A           t12             b                   0
>    i01              A           t01             c                   0
>    i01              A           t02             c                   1
> ...
>    i01              A           t12             c                   1
>    i02              B           t01             a                   1
> ...
>
> First, I?m wondering if I have to calculate a % of accuracy for each
> subject and each condition and thus ?remove? the variable ?Trial? but
> ?lose? data (power?) in the same time? or to take into account this
> variable in the analysis and in this case, how to do that?
>
> Second, I don?t know which function I?ve to choose (lmer, glm, glmer?)?
>
> Third, I?m not sure I proceed correctly to specify in this analysis that
> the responses all come from the same subject: within-subject design =
> ?+(1|Subject) as I can do for a repeated measures ANOVA to analyze the
> effect of my different variables on a numeric one such as the response
> time: test=aov(Int~Group*Condition+*Error(Subject/(Group*Condition)*),data=mydata)
> and here again how can I add the variable "Trial" if I don't work on an
> average reaction time for each subject in the different conditions?
>
> Below, examples of models I can write with glmer(),
>
> fit.1=glmer(Accuracy~Group* Condition
> +(1|Subject),data=mydata,family=binomial)
>
> fit.2=glmer(Accuracy~Group* Condition
> +(1|Subject)-1,data=mydata,family=binomial)   (?without intercept?)
>
> fit.3=glmer(Accuracy~Group* Condition +(1|Subject)+(1|Trial)...??
>
>
> I believed the analysis I've to conduct will be in the range of my
> qualifications then I realize it could be more complicated than that of
> course (ex GLMMs), I can hear "do it as we do usually" (=repeated measures
> ANOVA on a percentage of correct answers for each subject ??) as if there's
> only one way to follow but I think there's a lot, which one's revelant for
> my data, that's I want to find.
>
> Hope you can put me on the track,
>
> Best
>
> Suzon
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Jul  1 18:31:44 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 1 Jul 2014 16:31:44 +0000
Subject: [R] combining data from multiple read.delim() invocations.
In-Reply-To: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>

There is a better way. First we need some data. This creates three files in your home directory, each with five rows:

write.table(data.frame(rep("A", 5), Sys.time(), Sys.time()),
	"A.tab", sep="\t", row.names=FALSE, col.names=FALSE)
write.table(data.frame(rep("B", 5), Sys.time(), Sys.time()),
	 "B.tab", sep="\t", row.names=FALSE, col.names=FALSE)
write.table(data.frame(rep("C", 5), Sys.time(), Sys.time()),
	"C.tab", sep="\t", row.names=FALSE, col.names=FALSE)

Now to read and combine them into a single data.frame:

fls <- c("A.tab", "B.tab", "C.tab")
df.list <- lapply(fls, read.delim, header=FALSE, col.names=c("lpar","started","ended"),
           as.is=TRUE, na.strings='\\N', colClasses=c("character","POSIXct","POSIXct"))
df.all <- do.call(rbind, df.list)
> str(df.all)
'data.frame':   15 obs. of  3 variables:
 $ lpar   : chr  "A" "A" "A" "A" ...
 $ started: POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...
 $ ended  : POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
Sent: Tuesday, July 1, 2014 7:07 AM
To: r-help at r-project.org
Subject: [R] combining data from multiple read.delim() invocations.

Is there a better way to do the following? I have data in a number of tab
delimited files. I am using read.delim() to read them, in a loop. I am
invoking my code on Linux Fedora 20, from the BASH command line, using
Rscript. The code I'm using looks like:

arguments <- commandArgs(trailingOnly=TRUE);
# initialize the capped_data data.frame
capped_data <- data.frame(lpar="NULL",
                       started=Sys.time(),
                       ended=Sys.time(),
                       stringsAsFactors=FALSE);
# and empty it.
capped_data <- capped_data[-1,];
#
# Read in the data from the files listed
for (file in arguments) {
    data <- read.delim(file,
                    header=FALSE,
                    col.names=c("lpar","started","ended"),
                    as.is=TRUE,
                    na.strings='\\N',
                    colClasses=c("character","POSIXct","POSIXct"));
    capped_data <- rbind(capped_data,data)
}
#

I.e. is there an easier way than doing a read.delim/rbind in a loop?


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Jul  1 19:33:00 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 1 Jul 2014 10:33:00 -0700
Subject: [R] combining data from multiple read.delim() invocations.
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
Message-ID: <CACk-te2zZwZhZQfFL3qsz-BCNNuz2wHGUWpFqFBdvSez5nD7=A@mail.gmail.com>

Maybe, David, but this isn't really it.

Your code just basically reproduces the explicit for() loop with the
lapply. Maybe there might be some advantage in rbinding the list over
incrementally adding rows to the data frame, but I would be surprised
if it made much of a difference either way.  Of course, someone with
actual data might prove me wrong...

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 1, 2014 at 9:31 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> There is a better way. First we need some data. This creates three files in your home directory, each with five rows:
>
> write.table(data.frame(rep("A", 5), Sys.time(), Sys.time()),
>         "A.tab", sep="\t", row.names=FALSE, col.names=FALSE)
> write.table(data.frame(rep("B", 5), Sys.time(), Sys.time()),
>          "B.tab", sep="\t", row.names=FALSE, col.names=FALSE)
> write.table(data.frame(rep("C", 5), Sys.time(), Sys.time()),
>         "C.tab", sep="\t", row.names=FALSE, col.names=FALSE)
>
> Now to read and combine them into a single data.frame:
>
> fls <- c("A.tab", "B.tab", "C.tab")
> df.list <- lapply(fls, read.delim, header=FALSE, col.names=c("lpar","started","ended"),
>            as.is=TRUE, na.strings='\\N', colClasses=c("character","POSIXct","POSIXct"))
> df.all <- do.call(rbind, df.list)
>> str(df.all)
> 'data.frame':   15 obs. of  3 variables:
>  $ lpar   : chr  "A" "A" "A" "A" ...
>  $ started: POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...
>  $ ended  : POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
> Sent: Tuesday, July 1, 2014 7:07 AM
> To: r-help at r-project.org
> Subject: [R] combining data from multiple read.delim() invocations.
>
> Is there a better way to do the following? I have data in a number of tab
> delimited files. I am using read.delim() to read them, in a loop. I am
> invoking my code on Linux Fedora 20, from the BASH command line, using
> Rscript. The code I'm using looks like:
>
> arguments <- commandArgs(trailingOnly=TRUE);
> # initialize the capped_data data.frame
> capped_data <- data.frame(lpar="NULL",
>                        started=Sys.time(),
>                        ended=Sys.time(),
>                        stringsAsFactors=FALSE);
> # and empty it.
> capped_data <- capped_data[-1,];
> #
> # Read in the data from the files listed
> for (file in arguments) {
>     data <- read.delim(file,
>                     header=FALSE,
>                     col.names=c("lpar","started","ended"),
>                     as.is=TRUE,
>                     na.strings='\\N',
>                     colClasses=c("character","POSIXct","POSIXct"));
>     capped_data <- rbind(capped_data,data)
> }
> #
>
> I.e. is there an easier way than doing a read.delim/rbind in a loop?
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vincentdeanboyce at gmail.com  Tue Jul  1 20:21:20 2014
From: vincentdeanboyce at gmail.com (VINCENT DEAN BOYCE)
Date: Tue, 1 Jul 2014 14:21:20 -0400
Subject: [R] Stringr / Regular Expressions advice
In-Reply-To: <CAM_vjuk8N3R1qxQKZtYT+SAVeE-Ac121PnzWhcJmumF6TqssYA@mail.gmail.com>
References: <CAMDKLUxmKLtpGVDBO8oSEeZH121kjJPbAFROKNKdoqo6dZptPA@mail.gmail.com>
	<CAM_vjun5wxdt8S_KLhFoYkiW-NE3dNcJCAQ_UYu+EOtBiODyCg@mail.gmail.com>
	<CAMDKLUxMCZoxo7iahndSaoHEsHk=RkRt5MEdahjFbss9N8HZrw@mail.gmail.com>
	<CAM_vjuk8N3R1qxQKZtYT+SAVeE-Ac121PnzWhcJmumF6TqssYA@mail.gmail.com>
Message-ID: <CAMDKLUxu+Z+JqpGozbxUWG_BVsCMMm2B5m6OY6y6gnK+RcQHNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/d9f0e301/attachment.pl>

From dcarlson at tamu.edu  Tue Jul  1 20:22:31 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 1 Jul 2014 18:22:31 +0000
Subject: [R] combining data from multiple read.delim() invocations.
In-Reply-To: <CACk-te2zZwZhZQfFL3qsz-BCNNuz2wHGUWpFqFBdvSez5nD7=A@mail.gmail.com>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
	<CACk-te2zZwZhZQfFL3qsz-BCNNuz2wHGUWpFqFBdvSez5nD7=A@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F7B29D@mb02.ads.tamu.edu>

I agree it is not necessarily faster, but the code is more compact since we don't have to initialize the variable or explicitly refer to the index. For big data it has the disadvantage of storing the data twice. 

For speed, this is faster and does not store the data twice, but is system dependent. For Windows:

shell("copy ?.tab Combined.tab")
df.all <- read.delim("Combined.tab", header=FALSE, col.names=c("lpar","started","ended"),
           as.is=TRUE, na.strings='\\N', colClasses=c("character","POSIXct","POSIXct"))

David C

-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Tuesday, July 1, 2014 12:33 PM
To: David L Carlson
Cc: John McKown; r-help at r-project.org
Subject: Re: [R] combining data from multiple read.delim() invocations.

Maybe, David, but this isn't really it.

Your code just basically reproduces the explicit for() loop with the
lapply. Maybe there might be some advantage in rbinding the list over
incrementally adding rows to the data frame, but I would be surprised
if it made much of a difference either way.  Of course, someone with
actual data might prove me wrong...

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 1, 2014 at 9:31 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> There is a better way. First we need some data. This creates three files in your home directory, each with five rows:
>
> write.table(data.frame(rep("A", 5), Sys.time(), Sys.time()),
>         "A.tab", sep="\t", row.names=FALSE, col.names=FALSE)
> write.table(data.frame(rep("B", 5), Sys.time(), Sys.time()),
>          "B.tab", sep="\t", row.names=FALSE, col.names=FALSE)
> write.table(data.frame(rep("C", 5), Sys.time(), Sys.time()),
>         "C.tab", sep="\t", row.names=FALSE, col.names=FALSE)
>
> Now to read and combine them into a single data.frame:
>
> fls <- c("A.tab", "B.tab", "C.tab")
> df.list <- lapply(fls, read.delim, header=FALSE, col.names=c("lpar","started","ended"),
>            as.is=TRUE, na.strings='\\N', colClasses=c("character","POSIXct","POSIXct"))
> df.all <- do.call(rbind, df.list)
>> str(df.all)
> 'data.frame':   15 obs. of  3 variables:
>  $ lpar   : chr  "A" "A" "A" "A" ...
>  $ started: POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...
>  $ ended  : POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05" ...
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
> Sent: Tuesday, July 1, 2014 7:07 AM
> To: r-help at r-project.org
> Subject: [R] combining data from multiple read.delim() invocations.
>
> Is there a better way to do the following? I have data in a number of tab
> delimited files. I am using read.delim() to read them, in a loop. I am
> invoking my code on Linux Fedora 20, from the BASH command line, using
> Rscript. The code I'm using looks like:
>
> arguments <- commandArgs(trailingOnly=TRUE);
> # initialize the capped_data data.frame
> capped_data <- data.frame(lpar="NULL",
>                        started=Sys.time(),
>                        ended=Sys.time(),
>                        stringsAsFactors=FALSE);
> # and empty it.
> capped_data <- capped_data[-1,];
> #
> # Read in the data from the files listed
> for (file in arguments) {
>     data <- read.delim(file,
>                     header=FALSE,
>                     col.names=c("lpar","started","ended"),
>                     as.is=TRUE,
>                     na.strings='\\N',
>                     colClasses=c("character","POSIXct","POSIXct"));
>     capped_data <- rbind(capped_data,data)
> }
> #
>
> I.e. is there an easier way than doing a read.delim/rbind in a loop?
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From andrewee at buffalo.edu  Tue Jul  1 17:18:28 2014
From: andrewee at buffalo.edu (Andre Weeks)
Date: Tue, 1 Jul 2014 11:18:28 -0400
Subject: [R] R help
Message-ID: <CAEAZOpX29a-+rqrQFCqeAOjf+4+eP6J_3OgcriWVF5JWm_aHoQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/65ae4429/attachment.pl>

From dstrick1 at vt.edu  Tue Jul  1 17:44:38 2014
From: dstrick1 at vt.edu (dstrick1)
Date: Tue, 1 Jul 2014 08:44:38 -0700 (PDT)
Subject: [R] Using CSS package to extract text from html
Message-ID: <1404229477971-4693347.post@n4.nabble.com>

This being my first post, I'm sure I'll do something discordant with
convention, so forgive me in advance.

Basically, I am trying to extract text from an html file using the CSS
package in R. However, I am unable to do so because it seems that the text
itself is not identified with any class and thus targeting it via the CSS
function `cssApply` is difficult. 

I'll provide some detailed information so that you may be able to spot
something I've missed. Let's say I want to extract the latitude/longitude
info from the following html:
http://va.water.usgs.gov/duration_plots/htm_7/dp02059500.htm 

Here's what the initial portion of my code would look like:

install.packages('CSS')

library(CSS)

doc<-"http://va.water.usgs.gov/duration_plots/htm_7/dp02059500.htm"

doc<-htmlParse(doc)


Now, considering that the text I want to extract is under the following
Xpath (c&p from Chrome DevTool):
/html/body/table[1]/tbody/tr/td/table/tbody/tr[2]/td[2]/font/text()[1]

Would the next move be to call the text from that path? If you need to see
for yourself how the site's html is configured follow the link and use your
respective browser's inspect element tool. 

Any help would be appreciated. Thanks.





--
View this message in context: http://r.789695.n4.nabble.com/Using-CSS-package-to-extract-text-from-html-tp4693347.html
Sent from the R help mailing list archive at Nabble.com.


From michael88millar at hotmail.co.uk  Tue Jul  1 19:41:52 2014
From: michael88millar at hotmail.co.uk (Michael Millar)
Date: Tue, 1 Jul 2014 18:41:52 +0100
Subject: [R] x axis labelling
Message-ID: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/81f9fe78/attachment.pl>

From dwinsemius at comcast.net  Tue Jul  1 20:44:53 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Jul 2014 11:44:53 -0700
Subject: [R] 1-dinemsional point process
In-Reply-To: <1404182121229-4693315.post@n4.nabble.com>
References: <1404182121229-4693315.post@n4.nabble.com>
Message-ID: <7411E40D-1168-41AB-BF34-254168E0CEC0@comcast.net>

It's unclear why density estimates are not being mentioned. Also suggest you search:

install.packages("sos")
require(sos)
findFn("scan statistic")


On Jun 30, 2014, at 7:35 PM, Doobs wrote:

> Hi,
> As a new user, is it possible to look at clustering/dispersion processes of
> a 1D point process (i.e. points along a transect)?
> My limited  understanding is that spatstat is for 2&3D point patterns.
> 
> Thanks
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/1-dinemsional-point-process-tp4693315.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From michael.gang.peng at gmail.com  Tue Jul  1 20:58:51 2014
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Tue, 1 Jul 2014 13:58:51 -0500
Subject: [R] x axis labelling
In-Reply-To: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
References: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
Message-ID: <CAMjJGR1mOH4DF0Ak0-D0Xca4GGwTgLaBzBorjJ0fmLgDcoxThw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/290b3c4c/attachment.pl>

From dwinsemius at comcast.net  Tue Jul  1 21:18:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Jul 2014 12:18:02 -0700
Subject: [R] Generating Patient Data
In-Reply-To: <C2ACB9D4-2D54-4DC8-BA00-2DDBE740F8D5@comcast.net>
References: <CANtKHPW5WgiQkZa8ERWOAN2+dsF1EX-Je+G3AsLKyB0PtUwPXw@mail.gmail.com>
	<00D35C5F-981E-4B9C-9012-114B14D97F7E@comcast.net>
	<CANtKHPU3Oty9=tKUz6n2-rqYVS6wv9OV1KnRuVg=PKwwwByGJA@mail.gmail.com>
	<C2ACB9D4-2D54-4DC8-BA00-2DDBE740F8D5@comcast.net>
Message-ID: <62DDB442-189F-40D2-9F8D-944BE16D7674@comcast.net>


On Jun 25, 2014, at 1:49 PM, David Winsemius wrote:

> 
> On Jun 24, 2014, at 11:18 PM, Abhinaba Roy wrote:
> 
>> Hi David,
>> 
>> I was thinking something like this:
>> 
>> ID   Disease
>> 1     A
>> 2     B
>> 3     A
>> 1    C
>> 2    D
>> 5    A
>> 4    B
>> 3    D
>> 2    A
>> ..    ..
>> 
>> How can this be done?
> 
> do.call(rbind,  lapply( 1:20, function(pt) { 
>        data.frame( patient=pt, 
>                    disease= sample( c('A','B','C','D','E','F'), pmin(2+rpois(1, 2), 6))  )}) )

If you were doing this repeatedly I suppose you might get time efficiency by  the rpois vector as a single item of the same length as your PatientID's 
> 
> -- 
> David.
>> 
>> 
>> On Wed, Jun 25, 2014 at 11:34 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Jun 24, 2014, at 10:14 PM, Abhinaba Roy wrote:
>> 
>>> Dear R helpers,
>>> 
>>> I want to generate data for say 1000 patients (i.e., 1000 unique IDs)
>>> having suffered from various diseases in the past (say diseases
>>> A,B,C,D,E,F). The only condition imposed is that each patient should've
>>> suffered from *atleast* two diseases. So my data frame will have two
>>> columns 'ID' and 'Disease'.
>>> 
>>> I want to do a basket analysis with this data, where ID will be the
>>> identifier and we will establish rules based on the 'Disease' column.
>>> 
>>> How can I generate this type of data in R?
>>> 
>> 
>> Perhaps something along these lines for 20 cases:
>> 
>>> data.frame(patient=1:20, disease = sapply(pmin(2+rpois(20, 2), 6), function(n) paste0( sample( c('A','B','C','D','E','F'), n), collapse="+" ) )
>> + )
>>   patient     disease
>> 1        1         F+D
>> 2        2     F+A+D+E
>> 3        3     F+D+C+E
>> 4        4     B+D+C+A
>> 5        5     D+A+F+C
>> 6        6       E+A+D
>> 7        7 E+F+B+C+A+D
>> 8        8   A+B+C+D+E
>> 9        9     B+E+C+F
>> 10      10         C+A
>> 11      11 B+A+D+E+C+F
>> 12      12         B+C
>> 13      13     A+D+B+E
>> 14      14 D+C+E+F+B+A
>> 15      15   C+F+D+E+A
>> 16      16       A+C+B
>> 17      17     C+D+B+E
>> 18      18         A+B
>> 19      19   C+B+D+E+F
>> 20      20       D+C+F
>> 
>>> --
>>> Regards
>>> Abhinaba Roy
>>> 
>>>      [[alternative HTML version deleted]]
>> 
>> You should read the Posting Guide and learn to post in HTML.
>>> 
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> --
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
>> 
>> 
>> -- 
>> Regards
>> Abhinaba Roy
>> Statistician
>> Radix Analytics Pvt. Ltd
>> Ahmedabad
>> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From john.archie.mckown at gmail.com  Tue Jul  1 21:03:46 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 1 Jul 2014 14:03:46 -0500
Subject: [R] Fwd:  combining data from multiple read.delim() invocations.
In-Reply-To: <CAAJSdjhC-H-ZUrTBu9aa+NNytmTMHzLMz1y6QsrquuW_AazuLA@mail.gmail.com>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
	<CAAJSdjhC-H-ZUrTBu9aa+NNytmTMHzLMz1y6QsrquuW_AazuLA@mail.gmail.com>
Message-ID: <CAAJSdjiU8yByVOZybunpvTTrUxmWcuhcUQ4p22J9o60P+cARrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/29fa5cb7/attachment.pl>

From erinm.hodgess at gmail.com  Tue Jul  1 22:27:55 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 1 Jul 2014 16:27:55 -0400
Subject: [R] an incredibly trivial question about nls
Message-ID: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/3df09095/attachment.pl>

From gunter.berton at gene.com  Tue Jul  1 22:30:52 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 1 Jul 2014 13:30:52 -0700
Subject: [R] Fwd: combining data from multiple read.delim() invocations.
In-Reply-To: <CAAJSdjiU8yByVOZybunpvTTrUxmWcuhcUQ4p22J9o60P+cARrw@mail.gmail.com>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
	<CAAJSdjhC-H-ZUrTBu9aa+NNytmTMHzLMz1y6QsrquuW_AazuLA@mail.gmail.com>
	<CAAJSdjiU8yByVOZybunpvTTrUxmWcuhcUQ4p22J9o60P+cARrw@mail.gmail.com>
Message-ID: <CACk-te0ekbq1vJ69H-c8eOULKsJ=EUnfpmFCP=4urrLrokza+w@mail.gmail.com>

On Tue, Jul 1, 2014 at 12:03 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Tue, Jul 1, 2014 at 11:31 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>> There is a better way. First we need some data. This creates three files
>> in your home directory, each with five rows:
>>
>> write.table(data.frame(rep("A", 5), Sys.time(), Sys.time()),
>>         "A.tab", sep="\t", row.names=FALSE, col.names=FALSE)
>> write.table(data.frame(rep("B", 5), Sys.time(), Sys.time()),
>>          "B.tab", sep="\t", row.names=FALSE, col.names=FALSE)
>> write.table(data.frame(rep("C", 5), Sys.time(), Sys.time()),
>>         "C.tab", sep="\t", row.names=FALSE, col.names=FALSE)
>>
>> Now to read and combine them into a single data.frame:
>>
>> fls <- c("A.tab", "B.tab", "C.tab")
>> df.list <- lapply(fls, read.delim, header=FALSE,
>> col.names=c("lpar","started","ended"),
>>            as.is=TRUE, na.strings='\\N',
>> colClasses=c("character","POSIXct","POSIXct"))
>> df.all <- do.call(rbind, df.list)
>> > str(df.all)
>> 'data.frame':   15 obs. of  3 variables:
>>  $ lpar   : chr  "A" "A" "A" "A" ...
>>  $ started: POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05"
>> ...
>>  $ ended  : POSIXct, format: "2014-07-01 11:25:05" "2014-07-01 11:25:05"
>> ...
>>
>> -------------------------------------
>> David L Carlson
>>
>
> I do like that better than my version. Mainly because it is fewer
> statements. I'm rather new with R and the *apply series of functions is
> "bleeding edge" for me. And I haven't the the "do.call" before either. I'm
> still reading. But the way that I learn best is to try projects as I am
> learning. So I get ahead of myself.

If you have not already done so, please read "An Introduction to R" or
online tutorial of your choice before posting further. I do not
consider it proper to post queries concerning basics that you can
easily learn about yourself.  I DO consider it proper to post queries
about such topics if you have made the effort but are still confused.
That is what this list is for. You can decide -- and chastise me if
you like -- into which category you fit.

Cheers,
Bert



>
> According to the Linux "time" command, your method for a single input file,
> resulting in 144 output elements in the data.frame, took:
> real    0m0.525s
> user    0m0.441s
> sys     0m0.063s
>
> Mine:
> real    0m0.523s
> user    0m0.446s
> sys     0m0.060s
>
> Basically, a "wash". For a stress, I took in all 136 of my files in a
> single execution. Output was 22,823 elements in the data.frame.
> Yours:
> real    3m32.651s
> user    3m26.837s
> sys     0m2.292s
>
> Mine:
> real    3m24.603s
> user    3m20.225s
> sys     0m0.969s
>
> Still a wash. Of course, since I run this only once a week, on a Sunday,
> the time is not too important. I actually think that your solution is a bit
> more readable than mine. So long as I document what is going on.
>
> ===
>
> I had considered combining all the files together using the R "pipe"
> command to run the UNIX "cat" command, something like:
>
> command <- paste("cat ",arguments,collapse=" ");
> read.delim(pipe(command), ...
>
> but I was trying to be "pure R" since I am a Linux bigot surrounded by
> Windows weenies <grin/>.
>
> ===
>
> Hook'em horns!
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Jul  1 22:40:39 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 1 Jul 2014 13:40:39 -0700
Subject: [R] an incredibly trivial question about nls
In-Reply-To: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
References: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
Message-ID: <CACk-te1n9oPNehymTMB_9srVzuoYrNHCMXqp6qBED9q9bvh3Uw@mail.gmail.com>

1. Why? What do you think it tells you? (The number of parameters in a
NONlinear model is probably not what you think it is).

2. ?deviance

3. You've been posting all this time and still didn't try
stats:::print.nls  ?? -- which is where you would find the answer.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 1, 2014 at 1:27 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello R People:
>
> I'm having a forest/trees location problem with the output of nls.
>
> If I save the output to an object, and print the object, it shows, amongst
> other things, the residual sum of squares.  I would like to get that.
>
> However, when I look at names or str of the object, I can't find the
> residual sum of squares.
>
> Any help would be much appreciated.
> thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Tue Jul  1 22:48:49 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 1 Jul 2014 13:48:49 -0700
Subject: [R] an incredibly trivial question about nls
In-Reply-To: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
References: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
Message-ID: <CA+hbrhUAxnJ2D=0fpyta7eUYWV38Q_HL+3ZA6bUwbKnHym6crg@mail.gmail.com>

On Tue, Jul 1, 2014 at 1:27 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello R People:
>
> I'm having a forest/trees location problem with the output of nls.
>
> If I save the output to an object, and print the object, it shows, amongst
> other things, the residual sum of squares.  I would like to get that.
>
> However, when I look at names or str of the object, I can't find the
> residual sum of squares.

I think you want to look at summary(object), which contains (see
help("summary.nls"))

   sigma: the square root of the estimated variance of the random error

                          sigma^2 = 1/(n-p) Sum(R[i]^2),

          where R[i] is the i-th weighted residual.

In other words, you probably want summary(object)$sigma^2*(n-p),
perhaps a square root of it, or maybe just the sigma.

HTH,

Peter


From r.turner at auckland.ac.nz  Tue Jul  1 23:29:55 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 2 Jul 2014 09:29:55 +1200
Subject: [R] an incredibly trivial question about nls
In-Reply-To: <CACk-te1n9oPNehymTMB_9srVzuoYrNHCMXqp6qBED9q9bvh3Uw@mail.gmail.com>
References: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
	<CACk-te1n9oPNehymTMB_9srVzuoYrNHCMXqp6qBED9q9bvh3Uw@mail.gmail.com>
Message-ID: <53B32853.9000103@auckland.ac.nz>



In direct contrast to what Bert says, I think this is a very reasonable 
(and non-trivial) question.

The problem results from Gurus structuring the functions that they write 
in such a way that they are totally opaque to anyone but the 
ultra-cognoscenti.  What is gained by not having things set up in a 
straightforward manner that is accessible to normal human beings is 
mysterious to me.

If you do look at stats:::print.nls (and you have to start with that 
"stats:::"; things just *have* to be hidden away so that normal human 
beings can't see them!) you are likely to be no more enlightened than 
you were previously, until you engage in a good long struggle.

It turns out that what happens is that, in order to print the residual 
sum of squares, print.nls() calls the function x$m$deviance (where "x" 
is the object returned by nls()).  This function simply returns the 
object "dev" which is stored in its environment.  Could one get more 
convoluted and obscure if one tried?

So, to get the residual sum of squares you could do:

	rss <- x$m$deviance()
or
	rss <- get("dev",envir=environment(x$m$deviance))

The actual residuals are hidden away as "resid" in the environment of 
the function x$m$resid, so you could also get the residual sum of 
squares via:

	rss <- sum(get("resid",envir=environment(x$m$resid))^2)
or
	rss <- sum(x$m$resid()^2)
or
	rss <- sum(resid(x)^2)

the last of which applies the (hidden) nls method for the residuals() 
function.  Happily, they all seem to give the same answer. :-)

On 02/07/14 08:40, Bert Gunter wrote:
> 1. Why? What do you think it tells you?

	That's *her* business.

(The number of parameters in a
> NONlinear model is probably not what you think it is).
>
> 2. ?deviance

	Not at all useful.
>
> 3. You've been posting all this time and still didn't try
> stats:::print.nls  ?? -- which is where you would find the answer.

	Chastising people for failing to see the invisible is not
	helpful.  And even when they manage to see the invisible, the
	result is still very obscure.

cheers,

Rolf

>
> Cheers,
> Bert
>
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Jul 1, 2014 at 1:27 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>> Hello R People:
>>
>> I'm having a forest/trees location problem with the output of nls.
>>
>> If I save the output to an object, and print the object, it shows, amongst
>> other things, the residual sum of squares.  I would like to get that.
>>
>> However, when I look at names or str of the object, I can't find the
>> residual sum of squares.
>>
>> Any help would be much appreciated.
>> thanks,
>> Erin


From erinm.hodgess at gmail.com  Wed Jul  2 00:17:50 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 1 Jul 2014 18:17:50 -0400
Subject: [R] an incredibly trivial question about nls
In-Reply-To: <CACk-te2JHb-Dr4MQ+Sv3n6Bn20GMVOJZ-q3ZDXR+84ij11uFew@mail.gmail.com>
References: <CACxE24muB3dLZj9RkuVA_pZhxu+vzDeEgw_J7hw7N8OYP-4Tkg@mail.gmail.com>
	<CACk-te1n9oPNehymTMB_9srVzuoYrNHCMXqp6qBED9q9bvh3Uw@mail.gmail.com>
	<53B32853.9000103@auckland.ac.nz>
	<CACk-te2JHb-Dr4MQ+Sv3n6Bn20GMVOJZ-q3ZDXR+84ij11uFew@mail.gmail.com>
Message-ID: <CACxE24nRiDC3v244f20z7h0CsHBF7bjy808oAu+ebQFLESg65w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/8a6dc153/attachment.pl>

From jim at bitwrit.com.au  Wed Jul  2 00:30:34 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 02 Jul 2014 08:30:34 +1000
Subject: [R] x axis labelling
In-Reply-To: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
References: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
Message-ID: <2601779.Ra5ovTfCeX@localhost.localdomain>

On Tue, 1 Jul 2014 06:41:52 PM Michael Millar wrote:
> Hi,
> 
> I am new to R and am trying to create a graph with Time(24hr) along 
the x
> axis. Rather than start at 01.00, I wanted to start at 14.00.
> 
> I tried to use the axis(side=1, at=c(  )) function but it continues to put
> then in numeric order. Is there another way I can add labels to the x 
axis?
> 
Hi Michael,
Perhaps this will get you out of trouble.

mmdat<-data.frame(time=paste(c(14:23,0:13),"00",sep=":"),
 wind_speed=sample(0:30,24))
plot(mmdat$wind_speed,type="b",xaxt="n",xlab="Time")
axis(1,at=1:24,labels=mmdat$time)

If you want to get more tick labels on the time axis, look at staxlab 
(plotrix).

Jim


From jan.graffelman at upc.edu  Wed Jul  2 00:12:57 2014
From: jan.graffelman at upc.edu (Jan Graffelman)
Date: Wed, 02 Jul 2014 00:12:57 +0200
Subject: [R] Using RCMD INSTALL under Spanish version of windows.
Message-ID: <53B33269.4030401@upc.edu>

Using RCMD INSTALL with R-version 3.1.0 under a Spanish Windows 7 gives 
the following error message:

rcmd INSTALL MyPackages
Mensajes de aviso perdidos
In normalizePath(path.expand(path), winslash, mustWork) :
   path[1]="c:/ARCHIV~1/R/R-31~1.0/library": Acceso denegado
Mensajes de aviso perdidos
package "methods" in options("defaultPackages") was not found
Durante la inicializaci?n - Mensajes de aviso perdidos
1: package 'datasets' in options("defaultPackages") was not found
2: package 'utils' in options("defaultPackages") was not found
3: package 'grDevices' in options("defaultPackages") was not found
4: package 'graphics' in options("defaultPackages") was not found
5: package 'stats' in options("defaultPackages") was not found
6: package 'methods' in options("defaultPackages") was not found
Error en normalizePath(path.expand(path), winslash, mustWork) :
   path[1]="c:/ARCHIV~1/R/R-31~1.0/library/tools": Acceso denegado
Calls: ::: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
Ejecuci?n interrumpida

The user running this command has all permissions to modify the
directory C:\Program Files\R\R-3.1.0\library, as is also clear from the
fact that installing a package by install.packages() works.

Any suggestions are welcome.

Jan.

-- 
Jan Graffelman
Dpt. of Statistics and Operations Research
Universitat Polit?cnica de Catalunya
Av. Diagonal 647, 6th floor
08028 Barcelona, Spain
email: jan.graffelman at upc.edu
web: http://www-eio.upc.es/~jan
tel: +34-93-4011739
fax: +34-93-4016575


From sjsjsj2009 at gmail.com  Wed Jul  2 00:46:34 2014
From: sjsjsj2009 at gmail.com (Supriya Jain)
Date: Tue, 1 Jul 2014 17:46:34 -0500
Subject: [R] Data visualization: overlay columns of train/test/validation
	datasets
Message-ID: <CAPc8pCJ-Ae=0t5Qzpd6x8N2SV5Q9zoRUs+pip5hz=JoZ4Cdzsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140701/51b0f3fb/attachment.pl>

From dwinsemius at comcast.net  Wed Jul  2 01:42:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Jul 2014 16:42:57 -0700
Subject: [R] Data visualization: overlay columns of
	train/test/validation datasets
In-Reply-To: <CAPc8pCJ-Ae=0t5Qzpd6x8N2SV5Q9zoRUs+pip5hz=JoZ4Cdzsw@mail.gmail.com>
References: <CAPc8pCJ-Ae=0t5Qzpd6x8N2SV5Q9zoRUs+pip5hz=JoZ4Cdzsw@mail.gmail.com>
Message-ID: <DB38A235-F278-443C-9253-56BCDDCCABA4@comcast.net>


On Jul 1, 2014, at 3:46 PM, Supriya Jain wrote:

> Hello,
> 
> Given two different datasets (having the same number and type of columns,
> but different observations, as commonly encountered in data-mining as
> train/test/validation datasets), is it possible to overlay plots
> (histograms) and compare the different attributes from the separate
> datasets, in order to check how similar the different datasets are?
> 
> Is there a package available for such plotting together of similar columns
> from different datasets?

Possible. Assuming you just want frequency histograms (or ones using counts for that matter) it can be done in any of the three major plotting paradigms supported in R. No extra packages needed if using just base graphics.


> 
> Thanks,
> SJ
> 
> 	[[alternative HTML version deleted]]

Oh, you must have missed the parts of the Posign Guide where plain text was requyested. See below.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

And you missed that section, as well.

> and provide commented, minimal, self-contained, reproducible code.



-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Jul  2 01:50:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Jul 2014 16:50:13 -0700
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
Message-ID: <5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>


On Jul 1, 2014, at 12:02 AM, adc wrote:

>  I performed the following GAM by the MGCV package: 

I think it's actually spelled in all lower case.

> gam(mortality ~
> (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) 
> 
> How
> can I obtain a plot of Log-relative risk of mortality vs. PM10 ? 
> thanks

Shouldn't we need to know more details about the experimental setup to answer that question? And what sort of comparisons you are requesting? And about what parts of  ?mgcv::plot.gam you need further explanations to answer the question?

> agostino   
> 
snipped
> --
snipped
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
snipped
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Wed Jul  2 02:46:57 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 2 Jul 2014 10:46:57 +1000
Subject: [R] x axis labelling
In-Reply-To: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
References: <SNT146-W85C25DA381754CDBE5E157E2070@phx.gbl>
Message-ID: <001a01cf958f$2180e0f0$6482a2d0$@bigpond.com>

Hi Michael
Dates and times are always a problem as they are irregular not 1,2,3 ...,
100
If you want more fancy formatting of the x axis try this

First convert your time to a datetime class
# Use a dummy date for datetime as it is easier  
mmdat$time <- seq(strptime("20140702 14", "%Y%m%d %H"), by = "hours",
length= 24)
 # only gives numerical sequence on xlab
 plot(mmdat$wind_speed,type="b",xlab="Time")

However

 library(lattice)
 ?xyplot
# by starting at 15:00 hours get sequence and use formatting of dates 
xyplot(wind_speed ~time, data = mmdat,
        type = "b",
        xlab="Time",
        scales = list(x = list(at = seq(mmdat[2,1], by = "3 hours", length =
8),
                               labels = format(seq(mmdat[2,1], by = "3
hours", length = 8),"%H:%M")))
        )

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Michael Millar
Sent: Wednesday, 2 July 2014 03:42
To: r-help at R-project.org
Subject: [R] x axis labelling

Hi,

I am new to R and am trying to create a graph with Time(24hr) along the x
axis. Rather than start at 01.00, I wanted to start at 14.00.

I tried to use the axis(side=1, at=c(  )) function but it continues to put
then in numeric order. Is there another way I can add labels to the x axis?

Thank You.

Michael
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul  2 05:00:00 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 1 Jul 2014 20:00:00 -0700
Subject: [R] Stringr / Regular Expressions advice
In-Reply-To: <1404269806.45313.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAMDKLUxmKLtpGVDBO8oSEeZH121kjJPbAFROKNKdoqo6dZptPA@mail.gmail.com>	<CAM_vjun5wxdt8S_KLhFoYkiW-NE3dNcJCAQ_UYu+EOtBiODyCg@mail.gmail.com>	<CAMDKLUxMCZoxo7iahndSaoHEsHk=RkRt5MEdahjFbss9N8HZrw@mail.gmail.com>	<CAM_vjuk8N3R1qxQKZtYT+SAVeE-Ac121PnzWhcJmumF6TqssYA@mail.gmail.com>
	<CAMDKLUxu+Z+JqpGozbxUWG_BVsCMMm2B5m6OY6y6gnK+RcQHNg@mail.gmail.com>
	<1404269806.45313.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1404270000.12006.YahooMailNeo@web142602.mail.bf1.yahoo.com>

#or 

res <- mapply(`%in%`, accel_data, v.to.match)

res1 <- sapply(seq_len(ncol(accel_data)),function(i) accel_data[i]<=tail(v.to.match[[i]],1) & accel_data[i] >=v.to.match[[i]][1])

all.equal(res, res1,check.attributes=F)
#[1] TRUE

A.K.

On Tuesday, July 1, 2014 10:56 PM, arun <smartpink111 at yahoo.com> wrote:
Hi Vincent,

You could try:
v.to.match <- list(438:445, 454:460,459:470)

sapply(seq_len(ncol(accel_data)),function(i) accel_data[i]<=tail(v.to.match[[i]],1) & accel_data[i] >=v.to.match[[i]][1])

#or use ?cut or ?findInterval

A.K.







On Tuesday, July 1, 2014 2:23 PM, VINCENT DEAN BOYCE <vincentdeanboyce at gmail.com> wrote:
Sara,

Yes, I modified the code that you provided and it worked quite well. Here
is the revised code:

.....

accel_data <- data
*# pattern to be identified*
v.to.match <- c(438, 454, 459)
# call the below function anytime the "v.to.match" criteria changes to
ensure match is updated
v.matches <- apply(fakedata, 1, function(x)all(x == v.to.match))
which(v.matches)
[1] 405
sum(v.matches)
[1] 1

......

Again, here is the dataset:

> dput(head(accel_data, 20))

structure(list(x_reading = c(455L, 451L, 458L, 463L, 462L, 460L,
448L, 449L, 450L, 451L, 445L, 440L, 439L, 445L, 448L, 447L, 440L,
439L, 440L, 434L), y_reading = c(502L, 503L, 502L, 502L, 495L,
505L, 480L, 483L, 489L, 488L, 489L, 456L, 497L, 476L, 470L, 474L,
469L, 482L, 484L, 477L), z_reading = c(454L, 454L, 452L, 452L,
446L, 459L, 456L, 451L, 451L, 455L, 438L, 462L, 437L, 455L, 470L,
455L, 460L, 463L, 458L, 458L)), .Names = c("x_reading", "y_reading",
"z_reading"), row.names = c(NA, 20L), class = "data.frame")

My next goal is to extend the range for each column. For instance:

v.to.match <- c(438:445, 454:460, 459:470)

Your thoughts?

Many thanks,

Vincent








On Fri, Jun 27, 2014 at 5:51 AM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> It's a good idea to copy back to the list, not just to mo, to keep the
> discussion all in one place.
>
>
> On Thursday, June 26, 2014, VINCENT DEAN BOYCE <vincentdeanboyce at gmail.com>
> wrote:
>
>> Sarah,
>>
>> Great feedback and direction. Here is the data I am working with*:
>>
>> > dput(head(data_log, 20))
>>
>> structure(list(x_reading = c(455L, 451L, 458L, 463L, 462L, 460L,
>> 448L, 449L, 450L, 451L, 445L, 440L, 439L, 445L, 448L, 447L, 440L,
>> 439L, 440L, 434L), y_reading = c(502L, 503L, 502L, 502L, 495L,
>> 505L, 480L, 483L, 489L, 488L, 489L, 456L, 497L, 476L, 470L, 474L,
>> 469L, 482L, 484L, 477L), z_reading = c(454L, 454L, 452L, 452L,
>> 446L, 459L, 456L, 451L, 451L, 455L, 438L, 462L, 437L, 455L, 470L,
>> 455L, 460L, 463L, 458L, 458L)), .Names = c("x_reading", "y_reading",
>> "z_reading"), row.names = c(NA, 20L), class = "data.frame")
>>
>> *however, I am unsure why the letter "L" has been appended to each
>> numerical string.
>>
>
> It denotes values stored as integers, and is nothing you need to worry
> about.
>
>
>> In any event, as you can see there are three columns of data named
>> x_reading, y_reading and z_reading. I would like to detect patterns among
>> them.
>>
>> For instance, let's say the pattern I wish to detect is 455, 502, 454
>> across the three columns respectively. As you can see in the data, this is
>> found in the first row.This particular string reoccurs numerous times
>> within the dataset is what I wish to quantify - how many times the string
>> 455, 502, 454 appears.
>>
>> Your thoughts?
>>
>
> Did you try the code I provided? It does what I think you're looking for.
>
> Sarah
>
>
>> Many thanks,
>>
>> Vincent
>>
>>
>> On Thu, Jun 26, 2014 at 4:46 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> On Thu, Jun 26, 2014 at 12:17 PM, VINCENT DEAN BOYCE
>>> <vincentdeanboyce at gmail.com> wrote:
>>> > Hello,
>>> >
>>> > Using R,? I've loaded a .cvs file comprised of several hundred rows
>>> and 3
>>> > columns of data. The data within maps the output of a triaxial
>>> > accelerometer, a sensor which measures an object's acceleration along
>>> the
>>> > x,y and z axes. The data for each respective column sequentially
>>> > oscillates, and ranges numerically from 100 to 500.
>>>
>>> If your data are numeric, why are you using stringr?
>>>
>>> It would be easier to provide you with an answer if we knew what your
>>> data looked like.
>>>
>>> dput(head(yourdata, 20))
>>>
>>> and paste that into your non-HTML email.
>>>
>>> > I want create a function that parses the data and detects patterns
>>> across
>>> > the three columns.
>>> >
>>> > For instance, I would like to detect instances when the values for the
>>> x,y
>>> > and z columns equal 150, 200, 300 respectively. Additionally, when a
>>> match
>>> > is detected, I would like to know how many times the pattern appears.
>>>
>>> That's easy enough:
>>>
>>> fakedata <- data.frame(matrix(c(
>>> 100, 100, 200,
>>> 150, 200, 300,
>>> 100, 350, 100,
>>> 400, 200, 300,
>>> 200, 500, 200,
>>> 150, 200, 300,
>>> 150, 200, 300),
>>> ncol=3, byrow=TRUE))
>>>
>>> v.to.match <- c(150, 200, 300)
>>>
>>> v.matches <- apply(fakedata, 1, function(x)all(x == v.to.match))
>>>
>>> # which rows match
>>> which(v.matches)
>>>
>>> # how many rows match
>>> sum(v.matches)
>>>
>>> > I have been successful using str_detect to provide a Boolean, however
>>> it
>>> > seems to only work on a single vector, i.e, "400" , not a range of
>>> values
>>> > i.e "400 - 450". See below:
>>>
>>> This is where I get confused, and where we need sample data. Are your
>>> data numeric, as you state above, or some other format?
>>>
>>> If your data are character, and like "400 - 450", you can still match
>>> them with the code I suggested above.
>>>
>>> > # this works
>>> >> vals <- str_detect (string = data_log$x_reading, pattern = "400")
>>> >
>>> > # this also works, but doesn't detect the particular range, rather the
>>> > existence of the numbers
>>> >> vals <- str_detect (string = data_log$x_reading, pattern =
>>> "[400-450]")
>>>
>>> Are you trying to match any numeric value in the range 400-450? Again,
>>> actual data.
>>>
>>> > Also, it appears that I can only apply it to a single column, not to
>>> all
>>> > three columns. However I may be mistaken.
>>>
>>> You answer your own question unwittingly - apply().
>>>
>>> Sarah
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>
>>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul  2 08:42:41 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Jul 2014 23:42:41 -0700
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
Message-ID: <BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>


On Jul 1, 2014, at 11:33 PM, agostinodiciaula at tiscali.it wrote:

> Dear David, many thanks for your reply.
> The aim was to evaluate the relationship between daily mortality (variable "mortality") and mean daily values of PM10 levels (variable "PM10") in a specific geographic area, considering the effect of meteorological confounders (temperature, umidity).
> I used the following model (mgcv package):
> gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson)
> 
> the question is: how can I obtain a plot of log-relative risk of daily mortality vs. PM10 levels?
> regards

Still rather unclear what the problem is. I see no error message in your question. Are you asking how to assign a model to a name and then call the plot method?

mdl <- gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson)
plot(mdl)

-- 
david.
> 
> Agostino
> Il 02.07.2014 01:50 David Winsemius ha scritto:
> 
>> On Jul 1, 2014, at 12:02 AM, adc wrote:
>>> I performed the following GAM by the MGCV package:
>> I think it's actually spelled in all lower case.
>>> gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) How can I obtain a plot of Log-relative risk of mortality vs. PM10 ? thanks
>> Shouldn't we need to know more details about the experimental setup to answer that question? And what sort of comparisons you are requesting? And about what parts of  ?mgcv::plot.gam you need further explanations to answer the question?
>>> agostino
>> snipped
>>> --
>> snipped
>>> Sent from the R help mailing list archive at Nabble.com. [[alternative HTML version deleted]]
>> snipped
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> 
>> R-help at r-project.org
>>  mailing list
>> 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> 
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> 
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> Scopri istella, il nuovo motore per il web italiano.
> Istella garantisce risultati di qualit? e la possibilit? di condividere, in modo semplice e veloce, documenti, immagini, audio e video.
> Usa istella, vai su http://www.istella.it?wtk=amc138614816829636
> 

David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Wed Jul  2 09:17:08 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 02 Jul 2014 08:17:08 +0100
Subject: [R] Socket Connection in R
In-Reply-To: <CAOwGQ9AX3AwRVSFUiK6DwRZ1ei-gJFjpYFTe-LkSZNF2c0t7wA@mail.gmail.com>
References: <CAOwGQ9AX3AwRVSFUiK6DwRZ1ei-gJFjpYFTe-LkSZNF2c0t7wA@mail.gmail.com>
Message-ID: <53B3B1F4.8060505@stats.ox.ac.uk>

On 01/07/2014 13:37, Param Jeet wrote:
> I am trying to create socket connection in R.

That is not a 'socket connection'.  I suggest you use one instead: see 
?socketConnection.

>
>      socket <- make.socket("localhost",2099,T,T)
>      msg2<-'function=subscribe|item=MI.EQCON.1|schema=last_price;ask;bid'
>      write.socket(socket,msg2)
>      read.socket(socket,252,FALSE)
>
> When I run the read.socket line, I get error:
>
>      Error in read.socket(socket, 252, FALSE) :
>      embedded nul in string:
> '????-\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\001\0\004\0CTCL\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0'
>
> I am Unable to solve this problem. Please advice how to get rid of this
> issue.

The help says

      ?read.socket? reads a string from the specified socket,

'Strings' do not have embedded nulls: you need something which can do 
binary reads.  For that you need to use connections.

>
>
> Regards,
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Jul  2 11:23:48 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 2 Jul 2014 11:23:48 +0200
Subject: [R] combining data from multiple read.delim() invocations.
In-Reply-To: <CAAJSdjiU8yByVOZybunpvTTrUxmWcuhcUQ4p22J9o60P+cARrw@mail.gmail.com>
References: <CAAJSdji0g0X1HzoHs_-5NjFY6iA-52rvAR73wtkt6GzFCphjuA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7B213@mb02.ads.tamu.edu>
	<CAAJSdjhC-H-ZUrTBu9aa+NNytmTMHzLMz1y6QsrquuW_AazuLA@mail.gmail.com>
	<CAAJSdjiU8yByVOZybunpvTTrUxmWcuhcUQ4p22J9o60P+cARrw@mail.gmail.com>
Message-ID: <CBAC3661-B337-4622-919B-61584D78AB06@gmail.com>


On 01 Jul 2014, at 21:03 , John McKown <john.archie.mckown at gmail.com> wrote:

> Basically, a "wash". For a stress, I took in all 136 of my files in a
> single execution. Output was 22,823 elements in the data.frame.
> Yours:
> real    3m32.651s
> user    3m26.837s
> sys     0m2.292s
> 
> Mine:
> real    3m24.603s
> user    3m20.225s
> sys     0m0.969s
> 
> Still a wash. Of course, since I run this only once a week, on a Sunday,
> the time is not too important. I actually think that your solution is a bit
> more readable than mine. So long as I document what is going on.

One rbind() should actually be faster than using 136 rbind() calls while expanding the data frame on each iteration. Presumably, most of the time is spent elsewhere, but 8s in the opposite direction is a little surprising. You might want to check the timing  of just the

df.all <- do.call(rbind, df.list)

bit.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gayonclarke at yahoo.com  Wed Jul  2 16:04:40 2014
From: gayonclarke at yahoo.com (Shanae Clarke)
Date: Wed, 2 Jul 2014 07:04:40 -0700
Subject: [R] Getting data from Table in RStudio
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276623A399D9@WAXMXOLYMB025.WAX.wa.lcl>
References: <1404161875.45790.YahooMailNeo@web141403.mail.bf1.yahoo.com>
	<F7E6D18CC2877149AB5296CE54EA276623A399D9@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <1404309880.18129.YahooMailNeo@web141401.mail.bf1.yahoo.com>

This was very helpful. I think my problem is actually knowing which function to use when and where.?
This was a big help. Thank you again Dan.

By the way, if I am not asking too much could you recommend a technique that could be use to analyze a patterns, do a frequency count on recurring text or phrases. Basically Content Analysis. I was reading up on?
The help would be really appreciated.?






On Monday, June 30, 2014 7:06 PM, "Nordlund, Dan (DSHS/RDA)" <NordlDJ at dshs.wa.gov> wrote:



> -----Original Message-----

> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shanae Clarke
> Sent: Monday, June 30, 2014 1:58 PM
> To: r-help at r-project.org
> Subject: [R] Getting data from Table in RStudio
> 
> Hello,
> 
> I am new to R progaming and have just started using this program since
> last week. What i want to achieve is to use R to determine patterns in
> sales/ customer complaint etc. information located in a mysql database.
> I am not sure how to approach this or which technique i should use to
> do so. However, i had proceeded to add a dataset to RStudio using the
> following code:
> library(RODBC)
> dsn.name <- "MySQLlocal"
> user.name <- "orange"
> pwd <- ""
> ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> res <- sqlFetch(ch, "<my_table_name>")
> odbcQuery(ch, "Select * from?<my_table_name>")
> odbcClose(ch)
> 
> When the code is run all that is returned is
> > library (RODBC)
> > dsn.name <- "MySQLlocal"
> ?> user.name <- "orange"
> > pwd <- ""
> > ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> >?res <- sqlFetch(ch, "<my_table_name>")
> >?odbcQuery(ch, "Select * from?<my_table_name>")
> ?[1] 1
> > odbcClose(ch)
> 
> No other results.
> I was expecting to see the table values or some other data. Not that.
> Maybe I am misunderstanding the whole concept of how R works.
> If so could someone please help me to clarify what the problem is and
> perhaps point me to a tutorial or somewhere i can get a information and
> get a better understanding.
> 
> Thank you. Your Help will be greatly appreciated.
> 
> Gayon Clarke
> ??? [[alternative HTML version deleted]]

1. For future reference, you should read the posting guide linked at the bottom of each email, and post only in plain text (no HTML).? 

2. You should read the help files for each of the functions you are trying use.

3. Did you try to look at the object, res, that you created?? That should have contained the table that you fetched from the MySQL database.? You could have typed res and the table would have printed out.? You also could have used head(res) to look at the first few records, or used str(res) to examine the structure of res.

There is also an R-sig-DB list where you can get more specific help with database connectivity questions.
? ? https://stat.ethz.ch/mailman/listinfo/r-sig-db


Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul  2 16:41:21 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Jul 2014 07:41:21 -0700
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
	<fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
Message-ID: <2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>


On Jul 2, 2014, at 1:25 AM, agostinodiciaula at tiscali.it wrote:

> Sorry for my unclear request and description
> I performed:
> 
> x.gam <- gam(mortality ~ s(PM10) + (Tmax) + (umidity), data = data, family = quasipoisson)
> plot(x.gam, page =1)
> 
> the plot showed on the left axis "sPM10,3.07".
> How can I have "Log relative risk" ?

You just want to change the axis label? Then add this to the plot call:

ylab="Log Relative Hazard"

Again, you have not told us anything about the data, so we remain unable to say whether the results corresponds to that label change, but with a quasipoisson link one might expect a logged estimate of <something>.

-- 
David

> thanks again for your kind help
> agostino
> 
> Il 02.07.2014 08:42 David Winsemius ha scritto:
> 
>> On Jul 1, 2014, at 11:33 PM, agostinodiciaula at tiscali.itwrote:
>>> Dear David, many thanks for your reply. The aim was to evaluate the relationship between daily mortality (variable "mortality") and mean daily values of PM10 levels (variable "PM10") in a specific geographic area, considering the effect of meteorological confounders (temperature, umidity). I used the following model (mgcv package): gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) the question is: how can I obtain a plot of log-relative risk of daily mortality vs. PM10 levels? regards
>> Still rather unclear what the problem is. I see no error message in your question. Are you asking how to assign a model to a name and then call the plot method?
>> 
>> mdlAgostino
>> Il 02.07.2014 01:50 David Winsemius ha scritto:
>> 
>>> On Jul 1, 2014, at 12:02 AM, adc wrote:
>>>> I performed the following GAM by the MGCV package:
>>> I think it's actually spelled in all lower case.
>>>> gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) How can I obtain a plot of Log-relative risk of mortality vs. PM10 ? thanks
>>> Shouldn't we need to know more details about the experimental setup to answer that question? And what sort of comparisons you are requesting? And about what parts of ?mgcv::plot.gam you need further explanations to answer the question?
>>>> agostino
>>> snipped
>>>> --
>>> snipped
>>>> Sent from the R help mailing list archive at Nabble.com. [[alternative HTML version deleted]]
>>> snipped
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>>> David Winsemius Alameda, CA, USA ______________________________________________ R-help at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>> 
>> Scopri istella, il nuovo motore per il web italiano.
>> Istella garantisce risultati di qualit? e la possibilit? di condividere, in modo semplice e veloce, documenti, immagini, audio e video.
>> Usa istella, vai su 
>> http://www.istella.it?wtk=amc138614816829636
>> 
>> 
>> 
> David Winsemius Alameda, CA, USA
> 
> 
> 
> Scopri istella, il nuovo motore per il web italiano.
> Istella garantisce risultati di qualit? e la possibilit? di condividere, in modo semplice e veloce, documenti, immagini, audio e video.
> Usa istella, vai su http://www.istella.it?wtk=amc138614816829636
> 

David Winsemius
Alameda, CA, USA


From NordlDJ at dshs.wa.gov  Wed Jul  2 18:08:51 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 2 Jul 2014 16:08:51 +0000
Subject: [R] Getting data from Table in RStudio
In-Reply-To: <1404309880.18129.YahooMailNeo@web141401.mail.bf1.yahoo.com>
References: <1404161875.45790.YahooMailNeo@web141403.mail.bf1.yahoo.com>
	<F7E6D18CC2877149AB5296CE54EA276623A399D9@WAXMXOLYMB025.WAX.wa.lcl>
	<1404309880.18129.YahooMailNeo@web141401.mail.bf1.yahoo.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623A3AE4D@WAXMXOLYMB025.WAX.wa.lcl>

I haven't done much in this area, but you might take a look at the Task Views at

http://cran.r-project.org/

In particular, look at the Natural Language Processing task view.  It lists a number of packages that are useful for text mining using frequency counts and content analysis.  You might also google "sentiment analysis".

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: Shanae Clarke [mailto:gayonclarke at yahoo.com]
> Sent: Wednesday, July 02, 2014 7:05 AM
> To: Nordlund, Dan (DSHS/RDA); R. Mailing List
> Subject: Re: [R] Getting data from Table in RStudio
> 
> This was very helpful. I think my problem is actually knowing which
> function to use when and where.
> This was a big help. Thank you again Dan.
> 
> By the way, if I am not asking too much could you recommend a technique
> that could be use to analyze a patterns, do a frequency count on
> recurring text or phrases. Basically Content Analysis. I was reading up
> on
> The help would be really appreciated.
> 
> 
> 
> 
> 
> 
> On Monday, June 30, 2014 7:06 PM, "Nordlund, Dan (DSHS/RDA)"
> <NordlDJ at dshs.wa.gov> wrote:
> 
> 
> 
> > -----Original Message-----
> 
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Shanae Clarke
> > Sent: Monday, June 30, 2014 1:58 PM
> > To: r-help at r-project.org
> > Subject: [R] Getting data from Table in RStudio
> >
> > Hello,
> >
> > I am new to R progaming and have just started using this program
> since
> > last week. What i want to achieve is to use R to determine patterns
> in
> > sales/ customer complaint etc. information located in a mysql
> database.
> > I am not sure how to approach this or which technique i should use to
> > do so. However, i had proceeded to add a dataset to RStudio using the
> > following code:
> > library(RODBC)
> > dsn.name <- "MySQLlocal"
> > user.name <- "orange"
> > pwd <- ""
> > ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> > res <- sqlFetch(ch, "<my_table_name>")
> > odbcQuery(ch, "Select * from?<my_table_name>")
> > odbcClose(ch)
> >
> > When the code is run all that is returned is
> > > library (RODBC)
> > > dsn.name <- "MySQLlocal"
> > ?> user.name <- "orange"
> > > pwd <- ""
> > > ch <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd)
> > >?res <- sqlFetch(ch, "<my_table_name>")
> > >?odbcQuery(ch, "Select * from?<my_table_name>")
> > ?[1] 1
> > > odbcClose(ch)
> >
> > No other results.
> > I was expecting to see the table values or some other data. Not that.
> > Maybe I am misunderstanding the whole concept of how R works.
> > If so could someone please help me to clarify what the problem is and
> > perhaps point me to a tutorial or somewhere i can get a information
> and
> > get a better understanding.
> >
> > Thank you. Your Help will be greatly appreciated.
> >
> > Gayon Clarke
> > ??? [[alternative HTML version deleted]]
> 
> 1. For future reference, you should read the posting guide linked at
> the bottom of each email, and post only in plain text (no HTML).
> 
> 2. You should read the help files for each of the functions you are
> trying use.
> 
> 3. Did you try to look at the object, res, that you created?? That
> should have contained the table that you fetched from the MySQL
> database.? You could have typed res and the table would have printed
> out.? You also could have used head(res) to look at the first few
> records, or used str(res) to examine the structure of res.
> 
> There is also an R-sig-DB list where you can get more specific help
> with database connectivity questions.
> ? ? https://stat.ethz.ch/mailman/listinfo/r-sig-db
> 
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel J. Nordlund
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Wed Jul  2 19:59:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Jul 2014 10:59:56 -0700
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <0CC400D6-76A6-4501-90D4-A75CA00264C9@tiscali.it>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
	<fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
	<2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>
	<0CC400D6-76A6-4501-90D4-A75CA00264C9@tiscali.it>
Message-ID: <32F2D064-A4A2-4775-8160-8772C0FCC878@comcast.net>


On Jul 2, 2014, at 8:37 AM, Agostino Di Ciaula wrote:

> My aim was to perform a a generalized additive model with penalized splines to analyze the relationship between daily mortality and PM10 levels, and to control for the non-linear confounding effects of weather (temperature = ?Tmax?; humidity = ?umidit??).
> 
> this is my complete analysis: 
> > x.gam <- gam(mortality ~ s(PM10) + (Tmax) + (umidit?), data = sab, family = quasipoisson)
> > summary (x.gam)
> 
> Family: quasipoisson 
> Link function: log 
> 
> Formula:
> mortality ~ s(PM10) + (Tmax) + (umidit?)
> 
> Parametric coefficients:
>             Estimate Std. Error t value Pr(>|t|)  
> (Intercept)  1.50456    0.83802   1.795   0.0784 .
> Tmax         0.02060    0.01760   1.170   0.2472  
> umidit?      0.01256    0.00826   1.520   0.1345  
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Approximate significance of smooth terms:
>           edf Ref.df     F p-value   
> s(PM10) 3.067  3.857 4.862 0.00235 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> R-sq.(adj) =  0.269   Deviance explained = 34.2%
> GCV score = 6.6782  Scale est. = 5.9797    n = 58
> 
> Can I assume that the y axis of the plot (which is labeled "sPM10,3.07)
> plot(x.gam, page =1)
> is the log relative risk ?

You have repeatedly ignored my suggestions that you describe the data. Without knowing what was measured or counted in the column of data named "mortality", I doubt that anyone (and certainly not I)  can offer reassurances or advice about what to assume.

-- 
David.
> 
> thanks again
> agostino
> 
> Il giorno 02/lug/2014, alle ore 16:41, David Winsemius <dwinsemius at comcast.net> ha scritto:
> 
>> 
>> On Jul 2, 2014, at 1:25 AM, agostinodiciaula at tiscali.it wrote:
>> 
>>> Sorry for my unclear request and description
>>> I performed:
>>> 
>>> x.gam <- gam(mortality ~ s(PM10) + (Tmax) + (umidity), data = data, family = quasipoisson)
>>> plot(x.gam, page =1)
>>> 
>>> the plot showed on the left axis "sPM10,3.07".
>>> How can I have "Log relative risk" ?
>> 
>> You just want to change the axis label? Then add this to the plot call:
>> 
>> ylab="Log Relative Hazard"
>> 
>> Again, you have not told us anything about the data, so we remain unable to say whether the results corresponds to that label change, but with a quasipoisson link one might expect a logged estimate of <something>.
>> 
>> -- 
>> David
>> 
>>> thanks again for your kind help
>>> agostino
>>> 
>>> Il 02.07.2014 08:42 David Winsemius ha scritto:
>>> 
>>>> On Jul 1, 2014, at 11:33 PM, agostinodiciaula at tiscali.itwrote:
>>>>> Dear David, many thanks for your reply. The aim was to evaluate the relationship between daily mortality (variable "mortality") and mean daily values of PM10 levels (variable "PM10") in a specific geographic area, considering the effect of meteorological confounders (temperature, umidity). I used the following model (mgcv package): gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) the question is: how can I obtain a plot of log-relative risk of daily mortality vs. PM10 levels? regards
>>>> Still rather unclear what the problem is. I see no error message in your question. Are you asking how to assign a model to a name and then call the plot method?
>>>> 
>>>> mdlAgostino
>>>> Il 02.07.2014 01:50 David Winsemius ha scritto:
>>>> 
>>>>> On Jul 1, 2014, at 12:02 AM, adc wrote:
>>>>>> I performed the following GAM by the MGCV package:
>>>>> I think it's actually spelled in all lower case.
>>>>>> gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) How can I obtain a plot of Log-relative risk of mortality vs. PM10 ? thanks
>>>>> Shouldn't we need to know more details about the experimental setup to answer that question? And what sort of comparisons you are requesting? And about what parts of ?mgcv::plot.gam you need further explanations to answer the question?
>>>>>> agostino
>>>>> snipped
>>>>>> --
>>>>> snipped
>>>>>> Sent from the R help mailing list archive at Nabble.com. [[alternative HTML version deleted]]
>>>>> snipped
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.

snipped



David Winsemius
Alameda, CA, USA


From cryan at binghamton.edu  Wed Jul  2 20:17:51 2014
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Wed, 2 Jul 2014 14:17:51 -0400
Subject: [R] empty density plot for point pattern in spatstat
In-Reply-To: <CAL7Mys=Bj0j04+gRaoM_hda93A0NMYAKpW6Y5GSnZuMrp9ozDg@mail.gmail.com>
References: <CAM+rpYnjg_SGnyGrVcwuakX1xmXd7ysy1gZntdn7m2zD=kqong@mail.gmail.com>
	<CAM+rpYmz8zWkZvpNX6--a+F6vu6p2JkjzzTeoWta+PZ1oKh6jA@mail.gmail.com>
	<53A0B1C5.2080008@auckland.ac.nz>
	<CAL7MysnyrphaRcxHUhNT1nuy7By2fHzdHrXyTY7EQ1UxG22kKg@mail.gmail.com>
	<CF5661163F77A44781208D9AC4FDEA725D6726061A@IS-WIN-376.staffad.uwa.edu.au>
	<CAL7MyskMQwcTrePrb7Baa3-b0oRZO=_B946UNF7r1hEA4QXgTA@mail.gmail.com>
	<CF5661163F77A44781208D9AC4FDEA725D67260626@IS-WIN-376.staffad.uwa.edu.au>
	<CAM+rpYktZg28NjBRNnx4xbO2xE1vUGv5Aq6jgRROp3z_sFJjZg@mail.gmail.com>
	<CAL7Mys=Bj0j04+gRaoM_hda93A0NMYAKpW6Y5GSnZuMrp9ozDg@mail.gmail.com>
Message-ID: <CAM+rpY=CbxFNfWcVPZh2vgUaSmTgXNvGBmvXajZ3nAhFKYQiXw@mail.gmail.com>

Thanks, this solves my problem.

On R 3.1.0 on Windows XP:

library(spatstat)  # version 1.37.0
data(redwood)
dens <- density(redwood)
plot(dens, useRaster=FALSE, ribargs=list(useRaster=FALSE))

# produces the proper plot

--Chris Ryan

On Fri, Jun 20, 2014 at 5:24 PM, Pablo Ram?n <paramon at utpl.edu.ec> wrote:
> Hi Chris,
>
> Try the form: plot(dens, useRaster=FALSE, ribargs=list(useRaster=FALSE))
>
>
>
> Pablo
>
>
> 2014-06-20 15:58 GMT-05:00 Christopher W Ryan <cryan at binghamton.edu>:
>
>> I'm back in the office with the machine that was giving me trouble.
>>
>> # fresh start-up of R 3.1.0, installed on the my machine's hard drive,
>> #under Windows XP Service Pack 3.
>> # spatstat version 1.37-0
>>
>> library(spatstat)
>> data(redwood)
>> dens <- density(redwood)
>> str(dens) # everything looks to be in order
>> plot(dens)  # empty plot with empty ribbon on right side
>> dev.cur() # yields " null device
>>           #                    1"
>>                   # I think I closed the plot window
>>                   # before issuing this command
>>
>> plot(dens, col=grey(seq(0,1,length=32)))
>> # yields an empty density plot with empty ribbon
>>
>> plot(dens, useRaster=FALSE)
>> # yields a proper density plot in blue/green/yellow,
>> # with an empty ribbon
>>
>> plot(dens, useRaster=FALSE, ribargs=list(useRaster=TRUE))
>> # yields a proper density plot in blue/green/yellow,
>> # with an empty ribbon
>>
>> dev.cur()
>> # yields "windows
>> #               2 "
>>
>> example(plot.im)
>> # yields a series of 8 plot.
>> #All but one of them is empty--both plot area and ribbon
>> # the second one has a color ramp in the ribbon
>> # along the bottom, but again no plot
>>
>> with(bei.extra,plot(elev))
>> # yields an empty plot with empty ribbon
>>
>> with(bei.extra,plot(elev, useRaster=FALSE))
>> with(bei.extra,plot(elev, useRaster=FALSE,  ribargs=list(useRaster=TRUE)))
>> # these both yield the same result:
>> # a colored density plot with an empty ribbon
>>
>> Thanks
>>
>> --Chris Ryan
>>
>> On Thu, Jun 19, 2014 at 8:31 PM, Adrian Baddeley
>> <adrian.baddeley at uwa.edu.au> wrote:
>> > Dear Pablo,
>> >
>> >> Yes, effectively utilizando useRaster = FALSE, the plot is printed.
>> >
>> > Muy bien!
>> >
>> >> Only the ribbon appears without color.
>> >
>> > Try setting ribargs=list(useRaster=TRUE).
>> >
>> >> I'm using R version 3.0.2, Windows 7 system, and spatstat 1.33-0
>> >> package version.
>> >
>> > Things may improve if you upgrade to the current versions, R 3.1.0 and
>> > spatstat 1.37-0.
>> >
>> > A
>> >
>> > Prof Adrian Baddeley FAA
>> > University of Western Australia
>
>
>
>
> --
> Mat. Pablo Ram?n
> Secci?n de Ecolog?a
> Departamento de Ciencias Naturales
> Universidad T?cnica Particular de Loja (http://www.utpl.edu.ec/)
> Telf. 593 7 2570275 Ext. 2505, 2258


From agostinodiciaula at tiscali.it  Wed Jul  2 08:33:17 2014
From: agostinodiciaula at tiscali.it (agostinodiciaula at tiscali.it)
Date: Wed, 02 Jul 2014 08:33:17 +0200
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
Message-ID: <474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/3fdf1555/attachment.pl>

From agostinodiciaula at tiscali.it  Wed Jul  2 10:25:35 2014
From: agostinodiciaula at tiscali.it (agostinodiciaula at tiscali.it)
Date: Wed, 02 Jul 2014 10:25:35 +0200
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
Message-ID: <fb23a603d5feae865acf55b118c1ad6c@tiscali.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/0ddac450/attachment.pl>

From agostinodiciaula at tiscali.it  Wed Jul  2 17:37:49 2014
From: agostinodiciaula at tiscali.it (Agostino Di Ciaula)
Date: Wed, 2 Jul 2014 17:37:49 +0200
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
	<fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
	<2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>
Message-ID: <0CC400D6-76A6-4501-90D4-A75CA00264C9@tiscali.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/302af477/attachment.pl>

From b.h.willis at bham.ac.uk  Wed Jul  2 13:33:10 2014
From: b.h.willis at bham.ac.uk (Brian Willis)
Date: Wed, 2 Jul 2014 04:33:10 -0700 (PDT)
Subject: [R] Dataframes and text identifier columns
In-Reply-To: <1404046004960-4693184.post@n4.nabble.com>
References: <1404046004960-4693184.post@n4.nabble.com>
Message-ID: <1404300790321-4693389.post@n4.nabble.com>

Apologies I was trying to simplify the programme and missed out four input
files. The files on Andrew, Burt, Charlie  and Dave have the same format of
one factor and 13 numeric variables with repeated measurements eg.
Study	v1	v2	v3 	v4	v5	v6	v7	v8	v9	v10	v11	v12	v13
A	153	4.0	2.00	2.00	145.00	0.67	0.01	49.00	0.34	0.04	0.96	-3.24	0.04
B	96	33	3.0	13.0	47.0	0.9	0.2	4.2	0.1	0.5	0.5	-0.7	-0.7

Inp_dat is 
Case	r	p	SE	n
Andrew	0.03	0.01	0.0004	500
Burt	0.08	0.111	0.04	50
Charlie	0.04	0.022	0.0005	200
Dave	0.2	0.028	0.006	85

out_put starts as empty data frame and rows are added incrementally one for
Andrew, one for Burt etc.
If the code is
Andrew<-read.csv("/File /Andrew.csv")
Burt<-read.csv("/File /Burt.csv")
Charlie<-read.csv("/File /Charlie.csv")
Dave<-read.csv("/File /Dave.csv")

Inp_dat<- read.csv("/File/Input data.csv")


out_put<-data.frame(Case=character(), StdL=numeric(), StdPP=numeric(),
StdSE=numeric(), L=numeric(), MRPP=numeric(), MRSE=numeric(),
stringsAsFactors=FALSE)

for(i in 1:4)
{
if (i==1) b<-Andrew
if (i==2) b<-Burt
if (i==3) b<-Charlie
if (i==4) b<-Dave

pr <- Inp_dat$p[i]
SE_pr <- Inp_dat$SE[i]
r<- Inp_dat$r[i]
n<- Inp_dat$n[i]
Case<- Inp_dat$Case[i]
?

out_put[i,]<-data.frame(Case, stdL, stdPP, stdSE, L, PP, PP_SE)

}
out_put

  Case     StdL          StdPP           StdSE           L               
MRPP            MRSE
1    1  19.466823   0.16432300   0.03137456   26.002294   0.2080145  
0.03804692
2    2   2.334130    0.22566939   0.08962662    5.095703    0.3888451  
0.08399101
3    3   2.588678    0.05502765   0.00454159   42.058326   0.4861511  
0.02128030
4    4   7.857898    0.18457822   0.04372297    4.705487    0.1193687  
0.01921609



The Cases are labelled as integers 1 corresponding to Andrew, 2
corresponding to Burt etc. instead of the intended text labels Andrew, Burt,
Charlie and Dave. 

Note all other columns are correct. Furthermore

str(Case) 
Factor w/ 4 levels "Andrew","Burt",..: 4

str(out_put)

'data.frame':   4 obs. of  7 variables:
 $ Case  : chr  "1" "2" "3" "4"
 $ StdL : num  19.47 2.33 2.59 7.86
etc


I have tried changing the line

Case<- Inp_dat$Case[i]
 to

Case<- levels(Inp_dat$Case)[i]

and this gives the following output

  Case     StdL          StdPP           StdSE           L               
MRPP            MRSE
1    1  19.466823   0.16432300   0.03137456   26.002294   0.2080145  
0.03804692
2    1   2.334130    0.22566939   0.08962662    5.095703    0.3888451  
0.08399101
3    1   2.588678    0.05502765   0.00454159   42.058326   0.4861511  
0.02128030
4    1   7.857898    0.18457822   0.04372297    4.705487    0.1193687  
0.01921609

str(Case) 

chr "Dave"

and 

str(out_put)

'data.frame':   4 obs. of  7 variables:
 $ Case  : chr  "1" "1" "1" "1"
 $ StdL : num  19.47 2.33 2.59 7.86
etc


I?ve also tried adding, as suggested the stringsAsFactors=FALSE to the
Inp_dat<- read.csv("/File/Input data.csv", stringsAsFactors=FALSE)

This gives the same as the 2nd output above.




--
View this message in context: http://r.789695.n4.nabble.com/Dataframes-and-text-identifier-columns-tp4693184p4693389.html
Sent from the R help mailing list archive at Nabble.com.


From biannone at purdue.edu  Wed Jul  2 18:04:15 2014
From: biannone at purdue.edu (Basil Iannone)
Date: Wed, 2 Jul 2014 12:04:15 -0400
Subject: [R] correlation structures in gls
Message-ID: <CANukVfp1D92yVeqX5nHrmH=xEZcdSfbG+ao31C0RcrYJS2dOLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/81373f7c/attachment.pl>

From c.devlin at analyticsengines.com  Wed Jul  2 17:41:55 2014
From: c.devlin at analyticsengines.com (cdevlin48)
Date: Wed, 2 Jul 2014 08:41:55 -0700 (PDT)
Subject: [R] How do I call a C++ function (for k-means) within R?
Message-ID: <1404315715806-4693393.post@n4.nabble.com>

I am trying to call a C++ k-means function within R and I am struggling. I
know that the below code is used to call a C++ function for gbm but how do I
do it for k-means?

gbm.obj <- .Call("gbm",
                    Y=as.double(y),
                    Offset=as.double(offset),
                    X=as.double(x),
                    X.order=as.integer(x.order),
                    weights=as.double(w),
                    Misc=as.double(Misc),
                    cRows=as.integer(cRows),
                    cCols=as.integer(cCols),
                    var.type=as.integer(var.type),
                    var.monotone=as.integer(var.monotone),
                    distribution=as.character(distribution.call.name),
                    n.trees=as.integer(n.trees),
                    interaction.depth=as.integer(interaction.depth),
                    n.minobsinnode=as.integer(n.minobsinnode),
                    n.classes = as.integer(nClass),
                    shrinkage=as.double(shrinkage),
                    bag.fraction=as.double(bag.fraction),
                    nTrain=as.integer(nTrain),
                    fit.old=as.double(NA),
                    n.cat.splits.old=as.integer(0),
                    n.trees.old=as.integer(0),
                    verbose=as.integer(verbose),
                    PACKAGE = "gbm")

   names(gbm.obj) <- c("initF","fit","train.error","valid.error",
                       "oobag.improve","trees","c.splits")

   gbm.obj$bag.fraction <- bag.fraction
   gbm.obj$distribution <- distribution
   gbm.obj$interaction.depth <- interaction.depth
   gbm.obj$n.minobsinnode <- n.minobsinnode
   gbm.obj$num.classes <- nClass
   gbm.obj$n.trees <- length(gbm.obj$trees) / nClass
   gbm.obj$nTrain <- nTrain
   gbm.obj$train.fraction <- train.fraction
   gbm.obj$response.name <- response.name
   gbm.obj$shrinkage <- shrinkage
   gbm.obj$var.levels <- var.levels
   gbm.obj$var.monotone <- var.monotone
   gbm.obj$var.names <- var.names
   gbm.obj$var.type <- var.type
   gbm.obj$verbose <- verbose
   gbm.obj$Terms <- NULL




--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-call-a-C-function-for-k-means-within-R-tp4693393.html
Sent from the R help mailing list archive at Nabble.com.


From desolator88 at 163.com  Wed Jul  2 09:21:21 2014
From: desolator88 at 163.com (super)
Date: Wed, 2 Jul 2014 15:21:21 +0800 (CST)
Subject: [R]  What is the group generic mean?
Message-ID: <4a7260f4.1a73a.146f5f2ff94.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/f2beba58/attachment.pl>

From feuerwald at gmx.de  Wed Jul  2 18:19:42 2014
From: feuerwald at gmx.de (Marc Jekel)
Date: Wed, 2 Jul 2014 18:19:42 +0200
Subject: [R] robust standard errors in maximum likelihood estimation;
 sandwich estimator for mle/mle2
References: <trinity-72c3fba9-6b91-48df-818b-573ff56fa4bf-1404202073131@3capp-gmx-bs37>
Message-ID: <trinity-9a51a2cf-2ab4-4994-8c17-b3c76cfbf5b6-1404317981985@3capp-gmx-bs56>


   Dear list,

   After more reading, I can specify my rather broad question I asked yesterday
   and therefore ask a better question: I have specified a function that gives
   me log likelihood values. In the function, I have several free parameters
   (the  function  itself  is not linear). I use mle2 to find the maximum
   likelihood estimators for all free parameters. When I use summary() on the
   object created by mle2 I get the maximum likelihhod estimators, standard
   errors, corresponding z-values and Pr(z).

   My problem: The data I fit the function to consists of repeated choices by
   multiple participants. This means I have to correct standard errors that are
   shown by summary() since these standard errors are calculated under the
   assumption that each choice is independent. From what I read is that I need
   the  sandwich  estimator (i.e., Huber) to estimate robust errors. This
   estimator is implemented in the R-library "sandwich". But, as far as I found
   out, the library needs an object of the (e.g.) type lm. An object resulting
   from mle2 cannot be used with the commands of the  package. In STATA maximum
   likelihood estimation with robust standard errors is easily implemented with
   he command "cluster(id)". Is there something similar in R?

   Thank you for any advice,

   Marc

   Gesendet: Dienstag, 01. Juli 2014 um 10:07 Uhr
   Von: "Marc Jekel" <feuerwald at gmx.de>
   An: r-help at r-project.org
   Betreff: maximum likelihood estimation with clustered data
   Dear list,

   I am currently trying to fit free parameters of a model from economics
   (cumulative prospect theory) using maximum likelihood estimation. I know how
   to do maximum likelihood estimation using mle or mle2 in R, the problem to
   which I could not find a solution to is that my data is correlated (i.e.,
   multiple participants with multiple responses) which needs to be accounted
   for when doing mle. In STATA, mle can be done with clustered data (with the
   command "ml model ..., cluster(id)") but I could not find an equivalent
   command in R.

   More  detail  (in  case someone tried to do the same before): I try to
   implement an approach proposed  by Glenn Harrison who shows in STATA how to
   implement user-written maximum likelihood estimates for utility functions
   with clustered
   data ([1]http://faculty.cbpp.uaa.alaska.edu/jalevy/protected/HarrisonSTATML.
   pdf).

   Thank you for any hint,

   Marc

References

   1. http://faculty.cbpp.uaa.alaska.edu/jalevy/protected/HarrisonSTATML.pdf

From humtumiit at gmail.com  Wed Jul  2 09:51:50 2014
From: humtumiit at gmail.com (Param Jeet)
Date: Wed, 2 Jul 2014 13:21:50 +0530
Subject: [R] Socket Connection in R
In-Reply-To: <53B3B1F4.8060505@stats.ox.ac.uk>
References: <CAOwGQ9AX3AwRVSFUiK6DwRZ1ei-gJFjpYFTe-LkSZNF2c0t7wA@mail.gmail.com>
	<53B3B1F4.8060505@stats.ox.ac.uk>
Message-ID: <CAOwGQ9AhstH6tu6AJz-ju8JG1EnBGTYXMZNZ6591zcQSPuevDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/4293c44c/attachment.pl>

From martavaldes85 at gmail.com  Wed Jul  2 16:42:31 2014
From: martavaldes85 at gmail.com (Marta valdes lopez)
Date: Wed, 2 Jul 2014 14:42:31 +0000
Subject: [R] error:max not meaningful for factors
Message-ID: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/b09c9ba3/attachment.pl>

From sjsjsj2009 at gmail.com  Wed Jul  2 20:42:28 2014
From: sjsjsj2009 at gmail.com (Supriya Jain)
Date: Wed, 2 Jul 2014 13:42:28 -0500
Subject: [R] Data visualization: overlay columns of
	train/test/validation datasets
In-Reply-To: <DB38A235-F278-443C-9253-56BCDDCCABA4@comcast.net>
References: <CAPc8pCJ-Ae=0t5Qzpd6x8N2SV5Q9zoRUs+pip5hz=JoZ4Cdzsw@mail.gmail.com>
	<DB38A235-F278-443C-9253-56BCDDCCABA4@comcast.net>
Message-ID: <CAPc8pCLaAY=TvGcYVHHcB4N0X+dS78KuHt779zTXm-Lb0ATYMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/bd86c3e2/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul  2 15:31:36 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Jul 2014 06:31:36 -0700
Subject: [R] Sorting data.frame datewise in a descending order and
	geting datewise subtotl
In-Reply-To: <CAP0TLd_EuLBDrQ+Z5vX7m6A5fC5uLcifsAGQ+WfE8-UXnE=wrw@mail.gmail.com>
References: <CAP0TLd_EuLBDrQ+Z5vX7m6A5fC5uLcifsAGQ+WfE8-UXnE=wrw@mail.gmail.com>
Message-ID: <1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>


Hi veepsirtt,


If `dat` is the dataset

library(dplyr)
?dat %>% 

group_by(DATE) %>% 

summarize(PROFIT=sum(PROFIT)) %>%
?arrange(desc(as.Date(DATE,format="%d/%m/%Y")))
Source: local data frame [4 x 2]

??????? DATE PROFIT
1 02/07/2014? -1350
2 01/07/2014?? 9400
3 30/06/2014? 11325
4 27/06/2014?? 6850


If you just wanted to have a new variable subTotalPROFIT and not summarize the dataset


?dat %>% 

?group_by(DATE) %>% 

?mutate(subTotalPROFIT=sum(PROFIT)) %>% 

arrange(desc(as.Date(DATE,format="%d/%m/%Y")))

A.K.



On Wednesday, July 2, 2014 4:03 AM, Velappan Periasamy <veepsirtt at gmail.com> wrote:



Hi A.K,
How to Sort the ?given data.frame date wise in a descending order
?and getting date wise subtotal

SLNO. ? ? ? ?DATE ? ? ? ?SCRIP ? ? ? ?PROFIT?
6006302/07/2014Aluminium ? ? ? -1000
6005702/07/2014Copper ?900
6005602/07/2014LEAD ? ? ? -1250
6002901/07/2014Crude Oil6400
6003401/07/2014LEAD ? ? ? ?1500
6002501/07/2014Nickel ? ? ? ?1500
5998030/06/2014Nickel ? ? ? ? ?475
5998430/06/2014Natural Gas3000
5997230/06/2014Crude Oil2600
5997130/06/2014Copper3750
5997030/06/2014Natural Gas1500
5992427/06/2014Aluminium ? ?500
5992227/06/2014LEAD ? ? ? ?2250
5992027/06/2014Copper1100
5991827/06/2014Natural Gas3000

Thanks
veepsirtt


From agostinodiciaula at tiscali.it  Wed Jul  2 22:28:20 2014
From: agostinodiciaula at tiscali.it (Agostino Di Ciaula)
Date: Wed, 2 Jul 2014 22:28:20 +0200
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <32F2D064-A4A2-4775-8160-8772C0FCC878@comcast.net>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
	<fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
	<2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>
	<0CC400D6-76A6-4501-90D4-A75CA00264C9@tiscali.it>
	<32F2D064-A4A2-4775-8160-8772C0FCC878@comcast.net>
Message-ID: <52E9926B-27A6-437F-9557-1C077FE874BC@tiscali.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/5c7e5a9e/attachment.pl>

From dwinsemius at comcast.net  Wed Jul  2 23:47:01 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Jul 2014 14:47:01 -0700
Subject: [R] Data visualization: overlay columns of
	train/test/validation datasets
In-Reply-To: <CAPc8pCLaAY=TvGcYVHHcB4N0X+dS78KuHt779zTXm-Lb0ATYMw@mail.gmail.com>
References: <CAPc8pCJ-Ae=0t5Qzpd6x8N2SV5Q9zoRUs+pip5hz=JoZ4Cdzsw@mail.gmail.com>
	<DB38A235-F278-443C-9253-56BCDDCCABA4@comcast.net>
	<CAPc8pCLaAY=TvGcYVHHcB4N0X+dS78KuHt779zTXm-Lb0ATYMw@mail.gmail.com>
Message-ID: <B2287BA0-4B1F-420B-990E-62C9E62F29BE@comcast.net>


On Jul 2, 2014, at 11:42 AM, Supriya Jain wrote:

> Hi David,
>  
> Thanks for your mail. 
>  
> Here are the details of what I would like to do. 
> Given a dataset, I make two sets from it (for training and testing my model, respectively). But before the modeling, I would like to check the distributions of all columns in my dataset in order to make sure that my splitted tables represent the same distributions. 
>  
> With the code below (using the "attenu" dataset), I can overlay histograms normalized to unit area from the two splitted datasets, for columns that are of type numeric. 
> ---------------------
>  
> head(attenu, 10)
> nrow(attenu)
> indices <- sample(1:182, 50)
> t1 <- attenu[indices, ]
> t2 <- attenu[-indices, ]
>  
> # overlay column "event" from t1 and t2:
>  
> hist(t2$event, col = "red", density = 0, freq = FALSE, breaks = seq(1, 25, 2), xlab = "event", ylim = c(0, 0.2))
> par(new=TRUE) 
> hist(t1$event, col = "blue", density = 0, freq = FALSE, breaks = seq(1, 25, 2), xlab = "event", ylim = c(0, 0.2))
>  
> #-------------
>  
> However, for columns of type factor, although I can get the frequency of the different levels using the "summary" method for the columns separately, how do I plot their frequency distribution, after normalizing the frequencies by the total count, and overlay these distributions? 
>  
> summary(t1$station)
>  
> #--------output--------------
>  
>    135     111     113     117    1027    1028    1052    1093    1095    1102     112    1219 
>       3       2       2       2       1       1       1       1       1       1       1       1 
>     126     127    1291    1293     130    1308    1383    1408    1409     141    1410    1418 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>     266     270     272     411     412    5042    5043    5054    5060    5066    5069    5160 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    5165     952    c168    c266    1008    1011    1013    1014    1015    1016    1030    1032 
>       1       1       1       1       0       0       0       0       0       0       0       0 
>    1051    1083    1096     110    1117     116     125    1250    1251     128    1292    1298 
>       0       0       0       0       0       0       0       0       0       0       0       0 
>    1299    1376    1377    1411    1413    1422    1438    1445    1456    1492    2001    2316 
>       0       0       0       0       0       0       0       0       0       0       0       0 
>     262     269    2708    2714    2715    2728    2734     280     283     286     290    3501 
>       0       0       0       0       0       0       0       0       0       0       0       0 
>     475    5028    5044    5045    5047    5049    5050    5051    5052    5053    5055    5056 
>       0       0       0       0       0       0       0       0       0       0       0       0 
>    5057    5058 (Other)    NA's 
>       0       0       0       5 
>  
> #----------------------------
>  
> summary(t2$station)
>  
> #--------output--------------
>  
>    1028     117     475    1030    1083     112     113     116    1299    1377     269     283 
>       3       3       3       2       2       2       2       2       2       2       2       2 
>     290    5028    5053    5055    5056    5057    5058    5115     942     955     958    1008 
>       2       2       2       2       2       2       2       2       2       2       2       1 
>    1011    1013    1014    1015    1016    1032    1051    1093    1095    1096     110    1117 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    1219     125    1250    1251     128    1292    1298     130    1308    1376    1383    1411 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    1413    1418    1422    1438    1445    1456    1492    2001    2316     262     266    2708 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    2714    2715     272    2728    2734     280     286    3501     412    5044    5045    5047 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    5049    5050    5051    5052    5054    5059    5060    5061    5062    5067    5068    5070 
>       1       1       1       1       1       1       1       1       1       1       1       1 
>    5072    5073    5165     655     724     885     931     952    c118    c203    c204    1027 
>       1       1       1       1       1       1       1       1       1       1       1       0 
>    1052    1102 (Other)    NA's 
>       0       0       0      11 
>  
> #---------------------------
>  

It appears there may be a natural order to those categories but that the alpha ordering of the factor representation is making a hash of that fact. It also appears that the factor levels are different in the two datasets. Seems unlikely that you will get satisfactory plots for comparison using barplot.

-- 
David.
>  
> Thanks in advance for any help with this,
> Supriya
>  
> 
> 
> 
> 
> On Tue, Jul 1, 2014 at 6:42 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Jul 1, 2014, at 3:46 PM, Supriya Jain wrote:
> 
> > Hello,
> >
> > Given two different datasets (having the same number and type of columns,
> > but different observations, as commonly encountered in data-mining as
> > train/test/validation datasets), is it possible to overlay plots
> > (histograms) and compare the different attributes from the separate
> > datasets, in order to check how similar the different datasets are?
> >
> > Is there a package available for such plotting together of similar columns
> > from different datasets?
> 
> Possible. Assuming you just want frequency histograms (or ones using counts for that matter) it can be done in any of the three major plotting paradigms supported in R. No extra packages needed if using just base graphics.
> 
> 
> >
> > Thanks,
> > SJ
> >
> >       [[alternative HTML version deleted]]
> 
> Oh, you must have missed the parts of the Posign Guide where plain text was requyested. See below.
> 
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> 
> And you missed that section, as well.
> 
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From jabbba at gmail.com  Wed Jul  2 23:54:40 2014
From: jabbba at gmail.com (=?UTF-8?Q?Marco_Barb=C3=A0ra?=)
Date: Wed, 2 Jul 2014 23:54:40 +0200
Subject: [R] survplot invert number at risk labels
Message-ID: <CABL+AMfh2O4QHC3ftV39XCeQKb9iLR56DcOgvKxBfFAmGU73mQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/bf3f270e/attachment.pl>

From f.harrell at Vanderbilt.Edu  Thu Jul  3 00:17:15 2014
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 2 Jul 2014 22:12:15 -0005
Subject: [R] survplot invert number at risk labels
Message-ID: <1404339435.9598.0@smtpauth.vanderbilt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/db63f555/attachment.pl>

From thomas.worthington at okstate.edu  Thu Jul  3 00:26:54 2014
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Wed, 2 Jul 2014 22:26:54 +0000
Subject: [R] Checking whether a time series is stationary with irregular
 spaced data
Message-ID: <C1A5238848713043B7C18ED38FFEF1F812B83275@STWMB01.ad.okstate.edu>

I attempting to model the relationship between water temperature and air temperature. The seasonal component of the temperature time series has been modeled using a sinusoidal function, leaving the air and water temperature residuals. I want to model the relationship with 

M5<- gls(Water ~ Air +Air1 +Air2, correlation = corCAR1(form =~ Date))

Where Water is the water temperature residual, Air is the air temperature residuals at 1 and 2 day lags. I have included an autocorrelation structure that takes into account the fact that the water temperature were taken at irregular spaced intervals. 

I would like to test whether the time series is stationary, I found a blog post that used the following graphical methods and tests (Cent_Water is the water temperature centered by subtracting the mean value)

Acf(Cent_Water)
Pacf(Cent_Water)
Box.test(Cent_Water, lag=20, type="Ljung-Box")
adf.test(Cent_Water, alternative="stationary")
kpss.test(Cent_Water)

Are these methods useable with irregular spaced data as I believe it is not possible to use Acf?

Any suggestions would be greatly appreciated

Best wishes
Tom   


From dwinsemius at comcast.net  Thu Jul  3 00:28:58 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Jul 2014 15:28:58 -0700
Subject: [R] plot in generalized additive model (GAM)
In-Reply-To: <52E9926B-27A6-437F-9557-1C077FE874BC@tiscali.it>
References: <60af61f27470fdc9caf8212545b9ebc0@tiscali.it>
	<5E5E8767-2EAF-4B08-9A8C-4E9DA4A0A6B2@comcast.net>
	<474c0b0ca9555c3dcfda6a62135d423c@tiscali.it>
	<BDDA0DA4-1BE4-4221-8E1C-3D8A157D99DD@comcast.net>
	<fb23a603d5feae865acf55b118c1ad6c@tiscali.it>
	<2AAD6BB4-F12A-4FE5-A98E-A2672DC52F60@comcast.net>
	<0CC400D6-76A6-4501-90D4-A75CA00264C9@tiscali.it>
	<32F2D064-A4A2-4775-8160-8772C0FCC878@comcast.net>
	<52E9926B-27A6-437F-9557-1C077FE874BC@tiscali.it>
Message-ID: <261DDA3C-7327-49EA-BAE9-3C5BDB936E16@comcast.net>


On Jul 2, 2014, at 1:28 PM, Agostino Di Ciaula wrote:

> "mortality" is the daily number of deaths.
> many thanks again for your patience and for your help.
> agostino

A risk estimate requires specification of a risk set, which I do not see in the data description. Usually one would add an offset of the log(risk_count). It is possible to estimate relative risks without defining an explicit risk set under certain conditions, but it is not yet clear whether those conditions would be met for whatever data collection method or design was used.

-- 
David.


> 
> 
> Il giorno 02/lug/2014, alle ore 19:59, David Winsemius <dwinsemius at comcast.net> ha scritto:
> 
>> 
>> On Jul 2, 2014, at 8:37 AM, Agostino Di Ciaula wrote:
>> 
>>> My aim was to perform a a generalized additive model with penalized splines to analyze the relationship between daily mortality and PM10 levels, and to control for the non-linear confounding effects of weather (temperature = ?Tmax?; humidity = ?umidit??).
>>> 
>>> this is my complete analysis: 
>>>> x.gam <- gam(mortality ~ s(PM10) + (Tmax) + (umidit?), data = sab, family = quasipoisson)
>>>> summary (x.gam)
>>> 
>>> Family: quasipoisson 
>>> Link function: log 
>>> 
>>> Formula:
>>> mortality ~ s(PM10) + (Tmax) + (umidit?)
>>> 
>>> Parametric coefficients:
>>>            Estimate Std. Error t value Pr(>|t|)  
>>> (Intercept)  1.50456    0.83802   1.795   0.0784 .
>>> Tmax         0.02060    0.01760   1.170   0.2472  
>>> umidit?      0.01256    0.00826   1.520   0.1345  
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Approximate significance of smooth terms:
>>>          edf Ref.df     F p-value   
>>> s(PM10) 3.067  3.857 4.862 0.00235 **
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> R-sq.(adj) =  0.269   Deviance explained = 34.2%
>>> GCV score = 6.6782  Scale est. = 5.9797    n = 58
>>> 
>>> Can I assume that the y axis of the plot (which is labeled "sPM10,3.07)
>>> plot(x.gam, page =1)
>>> is the log relative risk ?
>> 
>> You have repeatedly ignored my suggestions that you describe the data. Without knowing what was measured or counted in the column of data named "mortality", I doubt that anyone (and certainly not I)  can offer reassurances or advice about what to assume.
>> 
>> -- 
>> David.
>>> 
>>> thanks again
>>> agostino
>>> 
>>> Il giorno 02/lug/2014, alle ore 16:41, David Winsemius <dwinsemius at comcast.net> ha scritto:
>>> 
>>>> 
>>>> On Jul 2, 2014, at 1:25 AM, agostinodiciaula at tiscali.it wrote:
>>>> 
>>>>> Sorry for my unclear request and description
>>>>> I performed:
>>>>> 
>>>>> x.gam <- gam(mortality ~ s(PM10) + (Tmax) + (umidity), data = data, family = quasipoisson)
>>>>> plot(x.gam, page =1)
>>>>> 
>>>>> the plot showed on the left axis "sPM10,3.07".
>>>>> How can I have "Log relative risk" ?
>>>> 
>>>> You just want to change the axis label? Then add this to the plot call:
>>>> 
>>>> ylab="Log Relative Hazard"
>>>> 
>>>> Again, you have not told us anything about the data, so we remain unable to say whether the results corresponds to that label change, but with a quasipoisson link one might expect a logged estimate of <something>.
>>>> 
>>>> -- 
>>>> David
>>>> 
>>>>> thanks again for your kind help
>>>>> agostino
>>>>> 
>>>>> Il 02.07.2014 08:42 David Winsemius ha scritto:
>>>>> 
>>>>>> On Jul 1, 2014, at 11:33 PM, agostinodiciaula at tiscali.itwrote:
>>>>>>> Dear David, many thanks for your reply. The aim was to evaluate the relationship between daily mortality (variable "mortality") and mean daily values of PM10 levels (variable "PM10") in a specific geographic area, considering the effect of meteorological confounders (temperature, umidity). I used the following model (mgcv package): gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) the question is: how can I obtain a plot of log-relative risk of daily mortality vs. PM10 levels? regards
>>>>>> Still rather unclear what the problem is. I see no error message in your question. Are you asking how to assign a model to a name and then call the plot method?
>>>>>> 
>>>>>> mdlAgostino
>>>>>> Il 02.07.2014 01:50 David Winsemius ha scritto:
>>>>>> 
>>>>>>> On Jul 1, 2014, at 12:02 AM, adc wrote:
>>>>>>>> I performed the following GAM by the MGCV package:
>>>>>>> I think it's actually spelled in all lower case.
>>>>>>>> gam(mortality ~ (PM10) + (Tmax) + (umidity), data = data, family = quasipoisson) How can I obtain a plot of Log-relative risk of mortality vs. PM10 ? thanks
>>>>>>> Shouldn't we need to know more details about the experimental setup to answer that question? And what sort of comparisons you are requesting? And about what parts of ?mgcv::plot.gam you need further explanations to answer the question?
>>>>>>>> agostino
>>>>>>> snipped
>>>>>>>> --
>>>>>>> snipped
>>>>>>>> Sent from the R help mailing list archive at Nabble.com. [[alternative HTML version deleted]]
>>>>>>> snipped
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>> 
>> snipped
>> 
>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Thu Jul  3 01:17:48 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 03 Jul 2014 09:17:48 +1000
Subject: [R] error:max not meaningful for factors
In-Reply-To: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>
References: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>
Message-ID: <3602301.tNus6OuQrx@localhost.localdomain>

On Wed, 2 Jul 2014 02:42:31 PM Marta valdes lopez wrote:
> Hello,
> 
> I run this script , because i would like to do the mean of x and y base 
on
> alpha as factor.
> 
> 
> library(xlsx)
> library(ROCR
> filename<-"amanhecer roc.csv"
> rocdata<- read.table(filename, sep=";",header=TRUE,dec=",")
> 
> rocdata$alpha.15_12 <- as.factor(rocdata$alpha.15_12)
> 
> TPaverage <- tapply(rocdata$y.15_12, rocdata$alpha.15_12, mean)
> FPaverage <- tapply(rocdata$x.15_12, rocdata$alpha.15_12, mean)
> 
> ###And them with the new data i want to create a plot, kind of ROC 
plot.
> 
>  Anthias<-rocdata
>  str(Anthias)
> data(ROCR.simple)
> pred <- prediction( ROCR.simple$predictions, ROCR.simple$labels )
> perf <- performance( pred, "tpr", "fpr" )
> windows(width = 9.5, height = 10.50)
> par(mfrow = c(1,1))
> 
> cc<-Anthias[1]
> ee<-Anthias[2]
> aa<-Anthias[3]
> perf at x.name<-"FP"
> perf at y.name<-"TP"
> perf at alpha.name<-"Speed"
> bb<-data.frame(aa)
> perf at x.values<-bb
> dd<-data.frame(cc)
> perf at y.values<-dd
> ff<-data.frame(ee)
> perf at alpha.values<-ff
> 
> plot(perf, main="Teste", colorize=TRUE, 
coloraxis.at=c(0,2,4,6,8,10),
>  coloraxis.cex.axis=0.8, colorize.palette=(rainbow(256,start=0, 
end=0.7)),
> lwd=7, colorkey.relwidth=0.4, yaxis.las=1)
> 
> But after run the whole script i got the error:max not meaningful for
> factors, anyone can help me?  I am a beginner in R ,so sorry if this is
> wasting anyone's time*.*
> 
Hi Marta,
The error message is straightforward. Somewhere in one of the 
functions you have called, the "max" function is applied to your factor 
variable. The definition of factor variables is that the the actual values 
are of nominal class, in which there is no meaningful ordering of 
values, therefore the maximum value is undefined. You could try 
as.numeric(alpha), but that is dangerous as it depends on whether the 
sorting of values (default alphabetic) is what you want. If we knew what 
"alpha" was, it would help.

Jim


From abhinabaroy09 at gmail.com  Thu Jul  3 08:29:50 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Thu, 3 Jul 2014 11:59:50 +0530
Subject: [R] Problem in compiling a function
Message-ID: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/864c4283/attachment.pl>

From kridox at ymail.com  Thu Jul  3 08:42:41 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 3 Jul 2014 15:42:41 +0900
Subject: [R] Problem in compiling a function
In-Reply-To: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>
References: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>
Message-ID: <CAAcyNCwyt3WmEZgewxhSmM4+ZWhbLe_1kqWN9jr6DFkRdLVOtw@mail.gmail.com>

Hi,

At the 3rd line, a bracket is missing, to close the "if" statement.

HTH
Pascal

On Thu, Jul 3, 2014 at 3:29 PM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi R-helpers,
>
> Can someone help me with this function
>
> prepArr <- function(CA) {
>   if(CA$CD_ACCRUAL_FLAG == 'AY' ){
>     if(!is.na(CA_AMT_PAYBACK ){
>             CA$IND_COLLECTION[(CA$TOT_PAID>=CA$TOT_ARREAR_BEG|
>                                     CA$TOT_PAID>=CA_AMT_PAYBACK)] <- 1L
>             CA$IND_COLLECTION[CA$TOT_PAID<CA_AMT_PAYBACK] <- 2L
>             CA$IND_COLLECTION[CA$TOT_PAID==0] <- 5L}
>     else{
>              CA$IND_COLLECTION[(CA$TOT_PAID>=CA$TOT_ARREAR_BEG|
>                                     CA$TOT_PAID>=CA$ARR_SAT)] <- 1L
>             CA$IND_COLLECTION[CA$TOT_PAID<CA$ARR_SAT] <- 4L
>             CA$IND_COLLECTION[CA$TOT_PAID==0] <- 5L
>         }
>
> }
>   if(CA$ACC_PREV == 'AY'){
>     if(!is.na(CA_PAYBACK_PREV)){
>         CA$IND_PREV[(CA$PAID_PREV>=ARR_PREV|
>                 CA$PAID_PREV>=CA_PAYBACK_PREV)] <- 1L
>             CA$IND_PREV[CA$PAID_PREV<CA_PAYBACK_PREV] <- 2L
>             CA$IND_PREV[CA$PAID_PREV==0] <- 5L}
>     else{
>         CA$IND_PREV[(CA$PAID_PREV>=ARR_PREV|
>                                     CA$PAID_PREV>=CA$ARR_SAT_PREV)] <- 1L
>             CA$IND_PREV[CA$PAID_PREV<CA$ARR_SAT_PREV] <- 4L
>             CA$IND_PREV[CA$PAID_PREV==0] <- 5L
>         }
>
> }
>
>     return(CA)
> }
>
> When I run this function in R, it throws me a lot of errors.
>
> --
> Regards,
> Abhinaba Roy
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From abhinabaroy09 at gmail.com  Thu Jul  3 09:03:19 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Thu, 3 Jul 2014 12:33:19 +0530
Subject: [R] Problem in compiling a function
In-Reply-To: <CAAcyNCwyt3WmEZgewxhSmM4+ZWhbLe_1kqWN9jr6DFkRdLVOtw@mail.gmail.com>
References: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>
	<CAAcyNCwyt3WmEZgewxhSmM4+ZWhbLe_1kqWN9jr6DFkRdLVOtw@mail.gmail.com>
Message-ID: <CANtKHPUtU+6xVv3EEM6ok5rdOxYn_q3zH17GuLdMQzOzPTwX4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/be97d07d/attachment.pl>

From Dylan.Tevlin at kochind.com  Wed Jul  2 23:49:18 2014
From: Dylan.Tevlin at kochind.com (Tevlin, Dylan)
Date: Wed, 2 Jul 2014 16:49:18 -0500
Subject: [R] parLapply on sqlQuery (from package RODBC)
Message-ID: <9D606AC27145D74F845B5AA9F37F9D9DEDB41BD88D@MSGICTB.kochind.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/e0a3ece2/attachment.pl>

From barrylambert at gmail.com  Thu Jul  3 04:33:12 2014
From: barrylambert at gmail.com (Barry Lambert)
Date: Wed, 2 Jul 2014 21:33:12 -0500
Subject: [R] Help with tables in R
Message-ID: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>

I am a new convert to R (from SAS).  I am a research scientist and most of
my
use of SAS was in data analysis.  Recently, I have been wanting to use R to
create a simple, reliable way to summarize a dataset of student demographics
for a university.
The spreadsheet has a row for every student registered at the university for
each term since fall 2010 with the following information about each student
in columns:
Columns are the following: Term, College, Program, Campus, Gender,
Ethnicity, Age.

I have created summary tables in Excel using if/then type formulas to select
data and count the number of female students in program A at location 3,
etc.

I have written some R code to create some figures that generally meet my
needs.
I would like to find a way to have R populate some tables with this type of
information.

An example of my excel sheets are attached.


Any suggestions will be appreciated.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example table.pdf
Type: application/pdf
Size: 37441 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/fd5597cb/attachment.pdf>

From veepsirtt at gmail.com  Thu Jul  3 06:45:00 2014
From: veepsirtt at gmail.com (veepsirtt)
Date: Wed, 2 Jul 2014 21:45:00 -0700 (PDT)
Subject: [R] Sorting data.frame datewise in a descending order and
 geting datewise subtotl
In-Reply-To: <1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1404288403378-4693384.post@n4.nabble.com>
	<1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAP0TLd8oHrUVrvaDxkWPsNKS3e=WJDy=UiEORMXr2RJ-sygmGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/ff51aa4d/attachment.pl>

From pjsleuth at gmail.com  Thu Jul  3 07:45:40 2014
From: pjsleuth at gmail.com (Pat Jackson)
Date: Wed, 02 Jul 2014 22:45:40 -0700
Subject: [R] Data frame with unequal lines per case
In-Reply-To: <f003978b-b24b-4c7d-94b8-43c3c7ff3e0d@email.android.com>
References: <f003978b-b24b-4c7d-94b8-43c3c7ff3e0d@email.android.com>
Message-ID: <542e2b12-209e-4f16-b32d-6864cd78377c@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140702/cdea6943/attachment.pl>

From jbscheuber at gmail.com  Thu Jul  3 09:04:59 2014
From: jbscheuber at gmail.com (Javier)
Date: Thu, 3 Jul 2014 01:04:59 -0600
Subject: [R] Compilation fails for package 'BayesTree' on R 3.0.1 for Windows
Message-ID: <CAN1kyLFNANOgKo8O5TeTK0iA1LVvL-w6AZoV1xGXO1HWwvGScA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/143800cd/attachment.pl>

From kridox at ymail.com  Thu Jul  3 09:14:52 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 3 Jul 2014 16:14:52 +0900
Subject: [R] Problem in compiling a function
In-Reply-To: <CANtKHPUtU+6xVv3EEM6ok5rdOxYn_q3zH17GuLdMQzOzPTwX4A@mail.gmail.com>
References: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>
	<CAAcyNCwyt3WmEZgewxhSmM4+ZWhbLe_1kqWN9jr6DFkRdLVOtw@mail.gmail.com>
	<CANtKHPUtU+6xVv3EEM6ok5rdOxYn_q3zH17GuLdMQzOzPTwX4A@mail.gmail.com>
Message-ID: <CAAcyNCyuR+N3eitN1FzP3av1_Yi1ih2WumvG5z-9iH+1X12L5A@mail.gmail.com>

3rd line:

if(!is.na(CA_AMT_PAYBACK ){
 ^        ^                              ^

Two brackets opened, only one closed. You must close the second one.

HTH
Pascal


On Thu, Jul 3, 2014 at 4:03 PM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi,
>
> The 'if' statement closes
> CA$IND_COLLECTION[CA$TOT_PAID=
> =0] <- 5L}
>
>
>
> On Thu, Jul 3, 2014 at 12:12 PM, Pascal Oettli <kridox at ymail.com> wrote:
>>
>> Hi,
>>
>> At the 3rd line, a bracket is missing, to close the "if" statement.
>>
>> HTH
>> Pascal
>>
>> On Thu, Jul 3, 2014 at 3:29 PM, Abhinaba Roy <abhinabaroy09 at gmail.com>
>> wrote:
>> > Hi R-helpers,
>> >
>> > Can someone help me with this function
>> >
>> > prepArr <- function(CA) {
>> >   if(CA$CD_ACCRUAL_FLAG == 'AY' ){
>> >     if(!is.na(CA_AMT_PAYBACK ){
>> >             CA$IND_COLLECTION[(CA$TOT_PAID>=CA$TOT_ARREAR_BEG|
>> >                                     CA$TOT_PAID>=CA_AMT_PAYBACK)] <- 1L
>> >             CA$IND_COLLECTION[CA$TOT_PAID<CA_AMT_PAYBACK] <- 2L
>> >             CA$IND_COLLECTION[CA$TOT_PAID==0] <- 5L}
>> >     else{
>> >              CA$IND_COLLECTION[(CA$TOT_PAID>=CA$TOT_ARREAR_BEG|
>> >                                     CA$TOT_PAID>=CA$ARR_SAT)] <- 1L
>> >             CA$IND_COLLECTION[CA$TOT_PAID<CA$ARR_SAT] <- 4L
>> >             CA$IND_COLLECTION[CA$TOT_PAID==0] <- 5L
>> >         }
>> >
>> > }
>> >   if(CA$ACC_PREV == 'AY'){
>> >     if(!is.na(CA_PAYBACK_PREV)){
>> >         CA$IND_PREV[(CA$PAID_PREV>=ARR_PREV|
>> >                 CA$PAID_PREV>=CA_PAYBACK_PREV)] <- 1L
>> >             CA$IND_PREV[CA$PAID_PREV<CA_PAYBACK_PREV] <- 2L
>> >             CA$IND_PREV[CA$PAID_PREV==0] <- 5L}
>> >     else{
>> >         CA$IND_PREV[(CA$PAID_PREV>=ARR_PREV|
>> >                                     CA$PAID_PREV>=CA$ARR_SAT_PREV)] <-
>> > 1L
>> >             CA$IND_PREV[CA$PAID_PREV<CA$ARR_SAT_PREV] <- 4L
>> >             CA$IND_PREV[CA$PAID_PREV==0] <- 5L
>> >         }
>> >
>> > }
>> >
>> >     return(CA)
>> > }
>> >
>> > When I run this function in R, it throws me a lot of errors.
>> >
>> > --
>> > Regards,
>> > Abhinaba Roy
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Pascal Oettli
>> Project Scientist
>> JAMSTEC
>> Yokohama, Japan
>
>
>
>
> --
> Regards,
> Abhinaba Roy
>
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From abhinabaroy09 at gmail.com  Thu Jul  3 09:19:40 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Thu, 3 Jul 2014 12:49:40 +0530
Subject: [R] Problem in compiling a function
In-Reply-To: <CAAcyNCyuR+N3eitN1FzP3av1_Yi1ih2WumvG5z-9iH+1X12L5A@mail.gmail.com>
References: <CANtKHPXF3u7h6zh=Pvw93cqiY4xmxJN+fX2VRap6fkOT2+nHEw@mail.gmail.com>
	<CAAcyNCwyt3WmEZgewxhSmM4+ZWhbLe_1kqWN9jr6DFkRdLVOtw@mail.gmail.com>
	<CANtKHPUtU+6xVv3EEM6ok5rdOxYn_q3zH17GuLdMQzOzPTwX4A@mail.gmail.com>
	<CAAcyNCyuR+N3eitN1FzP3av1_Yi1ih2WumvG5z-9iH+1X12L5A@mail.gmail.com>
Message-ID: <CANtKHPUNCDc+7u-XxMKDevGmk4m1az+u+sFHbJ+hg4-mxdgAzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/b2a6fc56/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul  3 09:21:03 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 07:21:03 +0000
Subject: [R] Data frame with unequal lines per case
In-Reply-To: <542e2b12-209e-4f16-b32d-6864cd78377c@email.android.com>
References: <f003978b-b24b-4c7d-94b8-43c3c7ff3e0d@email.android.com>
	<542e2b12-209e-4f16-b32d-6864cd78377c@email.android.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA20A@SRVEXCHMBX.precheza.cz>

Hi

You shall consult
?aggregate
to get summaries for groups.

And you shall also consult R-intro manual to learn some basic facts about objects structure and manipulation with them.

And finally you shal also have a look into Posting guide how to construct questions

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Pat Jackson
> Sent: Thursday, July 03, 2014 7:46 AM
> To: r-help at r-project.org
> Subject: [R] Data frame with unequal lines per case
>
> Dear R Help list,
>      I have data in a comma delimited format with an unequal number of
> lines per case,  ranging from 1 to 5. Each line contains that
> individual's rating of a televised conference they observed. I'm
> interested in the influence of group size on ratings.
>       My questions: how can I create a data frame that will a) treat
> the group as the unit of analysis and b) permit me to calculate group
> results,  e.g., average ratings per group among those with data (which
> will vary)?
>        The data are formatted like those below (but with commas), which
> contains 3 groups (my unit of analysis). The header is the first row.
> Groupname is alpha (which I'll convert later) and the rest are numeric.
> Number is the number of the individual rater in the group, ranging from
> 1-5.  Rate1 and Rate2 range from 0-7 but my example has a more limited
> range. Male,  female,  white and nonwhite are 1 yes or 0 no.
>
> So I have a maximum of 5 raters in 3 groups.
>
> Is it necessary to create a rectangular data frame with empty lines for
> groups with fewer than 5 raters? How should I do that? Or is there a
> better way? ( I have a lot more cases than provided below. )
>
> Thank you for a referral to apps or a suggested strategy to deal with
> this.
>
> Pat J.
>
> Header:
> Groupname number rate1 rate2 males females white nonwhite
>
> Data:
> Blue 1 3 1 1 0 0 1
> Blue 2 2 3 1 0 1 0
> Orange 1 4 4 0 1 1 0
> Yellow 1 3 2 1 0 1 0
> Yellow 2 5 2 0 1 0 1
> Yellow 3 4 3 1 0 0 1
> Yellow 4 4 2 1 0 1 0
> Yellow 5 2 2 0 1 0 1
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Jul  3 09:37:16 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 07:37:16 +0000
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA226@SRVEXCHMBX.precheza.cz>

Hi

Hm. Cooperation of R with excel can be probably done by Rexcel package.

Without more detailed information how do you want to use R in connection with Excel you probably do not get more precise answer.

For summaries use
?aggregate or maybe ?sapply

For counting item occurance
?table, ?xtabs or sum(something == "something")

can be used.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Barry Lambert
> Sent: Thursday, July 03, 2014 4:33 AM
> To: r-help at r-project.org
> Subject: [R] Help with tables in R
>
> I am a new convert to R (from SAS).  I am a research scientist and most
> of my use of SAS was in data analysis.  Recently, I have been wanting
> to use R to create a simple, reliable way to summarize a dataset of
> student demographics for a university.
> The spreadsheet has a row for every student registered at the
> university for each term since fall 2010 with the following information
> about each student in columns:
> Columns are the following: Term, College, Program, Campus, Gender,
> Ethnicity, Age.
>
> I have created summary tables in Excel using if/then type formulas to
> select data and count the number of female students in program A at
> location 3, etc.
>
> I have written some R code to create some figures that generally meet
> my needs.
> I would like to find a way to have R populate some tables with this
> type of information.
>
> An example of my excel sheets are attached.
>
>
> Any suggestions will be appreciated.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Jul  3 09:48:43 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 07:48:43 +0000
Subject: [R] Dataframes and text identifier columns
In-Reply-To: <1404300790321-4693389.post@n4.nabble.com>
References: <1404046004960-4693184.post@n4.nabble.com>
	<1404300790321-4693389.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA289@SRVEXCHMBX.precheza.cz>

Hi

What is the problem?

some comments in line

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Brian Willis
> Sent: Wednesday, July 02, 2014 1:33 PM
> To: r-help at r-project.org
> Subject: Re: [R] Dataframes and text identifier columns
>
> Apologies I was trying to simplify the programme and missed out four
> input files. The files on Andrew, Burt, Charlie  and Dave have the same
> format of one factor and 13 numeric variables with repeated
> measurements eg.
> Study v1      v2      v3      v4      v5      v6      v7      v8      v9      v10     v11
>       v12     v13
> A     153     4.0     2.00    2.00    145.00  0.67    0.01    49.00   0.34    0.04
>       0.96    -3.24   0.04
> B     96      33      3.0     13.0    47.0    0.9     0.2     4.2     0.1     0.5     0.5
>       -0.7    -0.7
>
> Inp_dat is
> Case  r       p       SE      n
> Andrew        0.03    0.01    0.0004  500
> Burt  0.08    0.111   0.04    50
> Charlie       0.04    0.022   0.0005  200
> Dave  0.2     0.028   0.006   85
>
> out_put starts as empty data frame and rows are added incrementally one
> for Andrew, one for Burt etc.
> If the code is
> Andrew<-read.csv("/File /Andrew.csv")
> Burt<-read.csv("/File /Burt.csv")
> Charlie<-read.csv("/File /Charlie.csv")
> Dave<-read.csv("/File /Dave.csv")
>
> Inp_dat<- read.csv("/File/Input data.csv")
>
>
> out_put<-data.frame(Case=character(), StdL=numeric(), StdPP=numeric(),
> StdSE=numeric(), L=numeric(), MRPP=numeric(), MRSE=numeric(),
> stringsAsFactors=FALSE)
>
> for(i in 1:4)
> {
> if (i==1) b<-Andrew
> if (i==2) b<-Burt
> if (i==3) b<-Charlie
> if (i==4) b<-Dave
^^^^^^^^^^^^^^^^^
you do not use b in your further code so this is not necessary

>
> pr <- Inp_dat$p[i]
> SE_pr <- Inp_dat$SE[i]
> r<- Inp_dat$r[i]
> n<- Inp_dat$n[i]
> Case<- Inp_dat$Case[i]
> ?
>
> out_put[i,]<-data.frame(Case, stdL, stdPP, stdSE, L, PP, PP_SE)
>
> }
> out_put
>
>   Case     StdL          StdPP           StdSE           L
> MRPP            MRSE
> 1    1  19.466823   0.16432300   0.03137456   26.002294   0.2080145
> 0.03804692
> 2    2   2.334130    0.22566939   0.08962662    5.095703    0.3888451
> 0.08399101
> 3    3   2.588678    0.05502765   0.00454159   42.058326   0.4861511
> 0.02128030
> 4    4   7.857898    0.18457822   0.04372297    4.705487    0.1193687
> 0.01921609
>
>
>
> The Cases are labelled as integers 1 corresponding to Andrew, 2
> corresponding to Burt etc. instead of the intended text labels Andrew,
> Burt, Charlie and Dave.

If you want to change Case to labels just use

out_put$Case <- factor(out_put$Case), labels(Inp_dat$Case))

Regards
Petr

>
> Note all other columns are correct. Furthermore
>
> str(Case)
> Factor w/ 4 levels "Andrew","Burt",..: 4
>
> str(out_put)
>
> 'data.frame':   4 obs. of  7 variables:
>  $ Case  : chr  "1" "2" "3" "4"
>  $ StdL : num  19.47 2.33 2.59 7.86
> etc
>
>
> I have tried changing the line
>
> Case<- Inp_dat$Case[i]
>  to
>
> Case<- levels(Inp_dat$Case)[i]
>
> and this gives the following output
>
>   Case     StdL          StdPP           StdSE           L
> MRPP            MRSE
> 1    1  19.466823   0.16432300   0.03137456   26.002294   0.2080145
> 0.03804692
> 2    1   2.334130    0.22566939   0.08962662    5.095703    0.3888451
> 0.08399101
> 3    1   2.588678    0.05502765   0.00454159   42.058326   0.4861511
> 0.02128030
> 4    1   7.857898    0.18457822   0.04372297    4.705487    0.1193687
> 0.01921609
>
> str(Case)
>
> chr "Dave"
>
> and
>
> str(out_put)
>
> 'data.frame':   4 obs. of  7 variables:
>  $ Case  : chr  "1" "1" "1" "1"
>  $ StdL : num  19.47 2.33 2.59 7.86
> etc
>
>
> I?ve also tried adding, as suggested the stringsAsFactors=FALSE to the
> Inp_dat<- read.csv("/File/Input data.csv", stringsAsFactors=FALSE)
>
> This gives the same as the 2nd output above.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Dataframes-
> and-text-identifier-columns-tp4693184p4693389.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From frtog at vestas.com  Thu Jul  3 09:51:06 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 3 Jul 2014 09:51:06 +0200
Subject: [R] parLapply on sqlQuery (from package RODBC)
In-Reply-To: <9D606AC27145D74F845B5AA9F37F9D9DEDB41BD88D@MSGICTB.kochind.com>
References: <9D606AC27145D74F845B5AA9F37F9D9DEDB41BD88D@MSGICTB.kochind.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C67C0DF5@DKRDSEXC016.vestas.net>

Hi

Why are you doing duplicate queries to the database (two As and Cs in your names vector)?

Why do 5 simultaneously connection to the database server? Woukld you do 500 connections?

Why not do one query and let the database server do the job for you?

Try this:

> options(useFancyQuotes = FALSE)
> 
> query0 <- "select id from table where name in (%s)" 
> 
> names <- paste(sQuote(LETTERS[1:5]), collapse = ",")
> names
[1] "'A','B','C','D','E'"
> 
> query <- sprintf(query0, names)
> query
[1] "select id from table where name in ('A','B','C','D','E')"
> 
> dataFromDB <- sqlQuery(dbConn, query)

This should work for MS SQL and MySQL servers.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Tevlin, Dylan
> Sent: 2. juli 2014 23:49
> To: r-help at r-project.org
> Subject: [R] parLapply on sqlQuery (from package RODBC)
> 
> R Version : 2.14.1 x64
> Running on Windows 7
> 
> Connecting to a database on a remote Microsoft SQL Server 2012
> 
> The short form of my problem is the following.
> 
> I have an unordered vectors of names, say:
> 
> names<-c("A", "B", "A", "C","C")
> 
> each of which have an id in a table in my db.  I need to convert the names to
> their corresponding ids.
> 
> I currently have the following code to do it.
> ###
> names<-c("A", "B", "A", "C","C")
> dbConn<-odbcDriverConnect(connection="connection string") #successfully
> connects
> 
> nameToID<-function(name, dbConn){
>                 #dbConn : active db connection formed via odbcDriverConnect
>                 #name     : a char string
> 
>                 sqlQuery(dbConn, paste("select id from table where name='", name,
> "'", sep=""))
> }
> sapply(names, nameToID, dbConn=dbConn)
> ###
> 
> Barring better ways to do this, which could involve loading the table into R
> then working with the problem there (which is possible), I understand why
> the following doesn't work, but I cannot seem to find a solution.  Attempting
> to use parallelization via the package 'parallel' :
> 
> ###
> names<-c("A", "B", "A", "C","C")
> dbConn<-odbcDriverConnect(connection="connection string") #successfully
> connects
> 
> nameToID<-function(name, dbConn){
>                 #dbConn : active db connection formed via odbcDriverConnect
>                 #name     : a char string
> 
>                 sqlQuery(dbConn, paste("select id from table where name='", name,
> "'", sep=""))
> }
> 
> mc<-detectCores()
> cl<-makeCluster(mc)
> clusterExport(cl, c("sqlQuery", "dbConn"))
> parSapply(cl, names, nameToID, dbConn=dbConn)    #incorrect passing of
> nameToID's second argument
> ###
> 
> As in the comment, this is not the correct way to assign the second argument
> to nameToID.
> 
> I have also tried the following:
> 
> parSapply(cl, names, function(x) nameToID(x, dbConn))
> 
> in place of the previous parSapply call, but that also does not work, with the
> error being thrown saying "the first parameter is not an open RODBC
> connection", presumably referring to the first parameter of the sqlQuery()
> 
> The following code does work with parallization.
> 
> ###
> names<-c("A", "B", "A", "C","C")
> dbConn<-odbcDriverConnect(connection="connection string") #successfully
> connects
> nameToID<-function(name){
>                 #name     : a char string
>                 dbConn<-odbcDriverConnect(connection="string")
>                 result<-sqlQuery(dbConn, paste("select id from table where
> name='", name, "'", sep=""))
>                 odbcClose(dbConn)
>                 result
> }
> 
> mc<-detectCores()
> cl<-makeCluster(mc)
> clusterExport(cl, c("sqlQuery", "odbcDriverConnect", "odbcClose", "dbConn",
> "nameToID"))      #throwing everything in
> parSapply(cl, names, nameToID)
> ###
> 
> But the constant opening and closing a ton of the gains from parallelization,
> and seems just a bit silly.
> 
> So the overall question would be how to pass the second parameter (the
> open db connection) to the function within parSapply, in much the same way
> as it is done in the regular apply?  In general, how does one pass a second,
> third, nth parameter to a function within a parallel routine?
> 
> Thanks and if you need any more information let me know.
> 
> -DT
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Jul  3 10:05:18 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 03 Jul 2014 01:05:18 -0700
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
Message-ID: <7d62367b-4e06-4bd7-a9ce-d2ce19439f32@email.android.com>

Your question is vague. You say you have code that does what you want it to, yet do not share an example of it as a starting point, or explain what you have not been able to do. It is the nature of the Internet that you have to be precise in describing your problems and desired solutions.

When I read "populate tables" I think of input processing, yet you say you already have code, suggesting that you have successfully read in your data to R.

Since you attempted to attach Excel files to a posting, I assume you have not yet read the Posting Guide mentioned at the bottom of this (or any other email from this mailing list) since that document warns against attaching non-text files. Please read it. Also, we tend to "speak" in R on this list rather than translating from other programming dialects, especially proprietary ones... that is your responsibility. Sort of like foreign language immersion. :-)

A word to the wise... it is significantly easier to read in CSV data than XLS or XLSX data in R. For getting started in R I highly recommend exporting your XLSX data to CSV.

You may find [1] helpful in formulating a reproducible example to get the ball rolling more effectively.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 2, 2014 7:33:12 PM PDT, Barry Lambert <barrylambert at gmail.com> wrote:
>I am a new convert to R (from SAS).  I am a research scientist and most
>of
>my
>use of SAS was in data analysis.  Recently, I have been wanting to use
>R to
>create a simple, reliable way to summarize a dataset of student
>demographics
>for a university.
>The spreadsheet has a row for every student registered at the
>university for
>each term since fall 2010 with the following information about each
>student
>in columns:
>Columns are the following: Term, College, Program, Campus, Gender,
>Ethnicity, Age.
>
>I have created summary tables in Excel using if/then type formulas to
>select
>data and count the number of female students in program A at location
>3,
>etc.
>
>I have written some R code to create some figures that generally meet
>my
>needs.
>I would like to find a way to have R populate some tables with this
>type of
>information.
>
>An example of my excel sheets are attached.
>
>
>Any suggestions will be appreciated.
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hansen_marte at hotmail.com  Thu Jul  3 10:32:44 2014
From: hansen_marte at hotmail.com (Marte Hansen)
Date: Thu, 3 Jul 2014 10:32:44 +0200
Subject: [R] Comparing two times with different format
Message-ID: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/df5782a0/attachment.pl>

From veepsirtt at gmail.com  Thu Jul  3 09:19:15 2014
From: veepsirtt at gmail.com (veepsirtt)
Date: Thu, 3 Jul 2014 00:19:15 -0700 (PDT)
Subject: [R] Sorting data.frame datewise in a descending order and
 geting datewise subtotl
In-Reply-To: <1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1404288403378-4693384.post@n4.nabble.com>
	<1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAP0TLd-9rFO9+7ddcDk828VpCWHHozo1LFGfvt0QLxGeYDp9Bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/d47790d4/attachment.pl>

From veepsirtt at gmail.com  Thu Jul  3 09:28:34 2014
From: veepsirtt at gmail.com (veepsirtt)
Date: Thu, 3 Jul 2014 00:28:34 -0700 (PDT)
Subject: [R] Sorting data.frame datewise in a descending order and
 geting datewise subtotl
In-Reply-To: <1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1404288403378-4693384.post@n4.nabble.com>
	<1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAP0TLd9AYBQcvHe2+gnn_9bHpsTKyZq6LwrQwLQGb5wihGS4Hw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/6a6ff68e/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul  3 11:19:07 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 09:19:07 +0000
Subject: [R] Comparing two times with different format
In-Reply-To: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>
References: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA2F5@SRVEXCHMBX.precheza.cz>

Hi

Are you sure that In Excel your times have same formating? There can be many sources of quirks from Excel itself through automatic csv conversion performed by Pearl to reading this csv to R. I presume that the timestamp is not actually in POSIX format (check with str) so if it is consistent in each data.frame you can do the conversion by

?strptime

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Marte Hansen
> Sent: Thursday, July 03, 2014 10:33 AM
> To: r-help at r-project.org
> Subject: [R] Comparing two times with different format
>
>
> I want to compare two tables, but the format on the time stamps are
> different. Both had the same format in Excel, but when I read those
> into R,
> the times have changed in the following way:
> 00:00 = 0:00, that is, the smallest dataset has the original time
> stamp, the
> largest has a new format. The two dataset are pretty big, about 65 000
> rows
> on the smallest and 350 000 rows in the largest... So changing them
> manually
> is not an option.
>
> They are read in the same, so I don't understand how one of them
> changes the
> format on one column.
>
> Hist <- read.xls(HistFil, perl = perl, header = FALSE, colClasses = c(
> rep("character", 7)))
> Ra <- read.xls(RaFil, perl = perl, header = TRUE, colClasses =
> c(rep("character", 6)))
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jim at bitwrit.com.au  Thu Jul  3 12:16:54 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 03 Jul 2014 20:16:54 +1000
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
Message-ID: <2132503.P6MiPbcVsQ@localhost.localdomain>

On Wed, 2 Jul 2014 09:33:12 PM Barry Lambert wrote:
> I am a new convert to R (from SAS).  I am a research scientist and 
most of
> my
> use of SAS was in data analysis.  Recently, I have been wanting to 
use R to
> create a simple, reliable way to summarize a dataset of student 
demographics
> for a university.
> The spreadsheet has a row for every student registered at the 
university for
> each term since fall 2010 with the following information about each 
student
> in columns:
> Columns are the following: Term, College, Program, Campus, 
Gender,
> Ethnicity, Age.
> 
> I have created summary tables in Excel using if/then type formulas 
to select
> data and count the number of female students in program A at 
location 3,
> etc.
> 
> I have written some R code to create some figures that generally 
meet my
> needs.
> I would like to find a way to have R populate some tables with this 
type of
> information.
> 
> An example of my excel sheets are attached.
> 
> 
> Any suggestions will be appreciated.

Hi Barry,
If I understand the above properly, you are calculating counts of 
female students in different programs and locations. I would do this 
using the "by" function with "length" as the function called for each 
group defined by program and location. This will produce an array of 
counts, and your problem is then to add a table of values to the plot. 
Here is an example:

bldat<-data.frame(sex=sample(c("M","F"),1000,TRUE),
 year=rep(2010:2013,each=250),
 program=sample(c("Arts","Math","Science"),1000,TRUE),
 location=sample(c("New York","London","Paris"),1000,TRUE))
females<-bldat$sex=="F"
femsumm<-by(bldat$sex,bldat[,c("program","location")],
 FUN=length)
rownames(femsumm)<-c("Arts","Math","Science") 
barplot(femsumm,beside=TRUE,ylim=c(0,150))
library(plotrix)
addtable2plot(4,120,femsumm,display.rownames=TRUE)

Jim


From murdoch.duncan at gmail.com  Thu Jul  3 12:23:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Jul 2014 06:23:10 -0400
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
Message-ID: <53B52F0E.9000304@gmail.com>

On 02/07/2014, 10:33 PM, Barry Lambert wrote:
> I am a new convert to R (from SAS).  I am a research scientist and most of
> my
> use of SAS was in data analysis.  Recently, I have been wanting to use R to
> create a simple, reliable way to summarize a dataset of student demographics
> for a university.
> The spreadsheet has a row for every student registered at the university for
> each term since fall 2010 with the following information about each student
> in columns:
> Columns are the following: Term, College, Program, Campus, Gender,
> Ethnicity, Age.
> 
> I have created summary tables in Excel using if/then type formulas to select
> data and count the number of female students in program A at location 3,
> etc.
> 
> I have written some R code to create some figures that generally meet my
> needs.
> I would like to find a way to have R populate some tables with this type of
> information.
> 
> An example of my excel sheets are attached.
> 

The "tables" package has formulas that are like PROC TABULATE formulas
(except better :-).

Your samples would be something like

tabular( term ~ campus * college )
tabular( college * program ~ campus * term )

The second one will need some extra work to remove all the empty cells
(e.g. College 1 Program 3 will show up, even though it doesn't really
exist).  See the vignette for a couple of approaches to handling this.

The package is mainly aimed at LaTeX output, but it can produce HTML, or
just put the numbers in a CSV file for pasting into some spreadsheet for
manual formatting.

Duncan


From dulcalma at bigpond.com  Thu Jul  3 13:00:51 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 3 Jul 2014 21:00:51 +1000
Subject: [R] Comparing two times with different format
In-Reply-To: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>
References: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>
Message-ID: <003301cf96ae$0e373a10$2aa5ae30$@bigpond.com>

Hi

If you have problems with dates in Excel copy and paste the date column into
a text editor and see if there are any peculiarities.

Remember what is shown on the screen may be totally different from what is
stored.

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Marte Hansen
Sent: Thursday, 3 July 2014 18:33
To: r-help at r-project.org
Subject: [R] Comparing two times with different format


I want to compare two tables, but the format on the time stamps are
different. Both had the same format in Excel, but when I read those into R,
the times have changed in the following way: 
00:00 = 0:00, that is, the smallest dataset has the original time stamp, the
largest has a new format. The two dataset are pretty big, about 65 000 rows
on the smallest and 350 000 rows in the largest... So changing them manually
is not an option. 

They are read in the same, so I don't understand how one of them changes the
format on one column.

Hist <- read.xls(HistFil, perl = perl, header = FALSE, colClasses = c(
rep("character", 7)))
Ra <- read.xls(RaFil, perl = perl, header = TRUE, colClasses =
c(rep("character", 6)))


 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Jul  3 14:28:56 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 12:28:56 +0000
Subject: [R] Help with tables in R
In-Reply-To: <2132503.P6MiPbcVsQ@localhost.localdomain>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
	<2132503.P6MiPbcVsQ@localhost.localdomain>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA388@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jim Lemon
> Sent: Thursday, July 03, 2014 12:17 PM
> To: r-help at r-project.org
> Cc: Barry Lambert
> Subject: Re: [R] Help with tables in R
>

<snip>

>
> Hi Barry,
> If I understand the above properly, you are calculating counts of
> female students in different programs and locations. I would do this
> using the "by" function with "length" as the function called for each
> group defined by program and location. This will produce an array of
> counts, and your problem is then to add a table of values to the plot.
> Here is an example:
>
> bldat<-data.frame(sex=sample(c("M","F"),1000,TRUE),
>  year=rep(2010:2013,each=250),
>  program=sample(c("Arts","Math","Science"),1000,TRUE),
>  location=sample(c("New York","London","Paris"),1000,TRUE))
> females<-bldat$sex=="F"
> femsumm<-by(bldat$sex,bldat[,c("program","location")],
>  FUN=length)

You computed occurence for all not only female.

> temp<-with(bldat, xtabs(~program+location+sex))
> temp
, , sex = F

         location
program   London New York Paris
  Arts        48       52    52
  Math        57       46    55
  Science     43       54    50

, , sex = M

         location
program   London New York Paris
  Arts        73       68    65
  Math        58       39    65
  Science     60       60    55

> temp[,,1]+temp[,,2]
         location
program   London New York Paris
  Arts       121      120   117
  Math       115       85   120
  Science    103      114   105

> head(femsumm)
[1] 121 115 103 120  85 114

Regards
Petr



> rownames(femsumm)<-c("Arts","Math","Science")
> barplot(femsumm,beside=TRUE,ylim=c(0,150))
> library(plotrix)
> addtable2plot(4,120,femsumm,display.rownames=TRUE)
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From barrylambert at gmail.com  Thu Jul  3 14:29:03 2014
From: barrylambert at gmail.com (Barry Lambert)
Date: Thu, 3 Jul 2014 07:29:03 -0500
Subject: [R] Help with tables in R
In-Reply-To: <7d62367b-4e06-4bd7-a9ce-d2ce19439f32@email.android.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
	<7d62367b-4e06-4bd7-a9ce-d2ce19439f32@email.android.com>
Message-ID: <CACqsi-BR2J=2nXxsFoCg8vsOt2oyiak55b_EP5xj2DvPTG+6SA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/89502b4d/attachment.pl>

From thomas.worthington at okstate.edu  Thu Jul  3 15:01:49 2014
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Thu, 3 Jul 2014 13:01:49 +0000
Subject: [R] Checking whether a time series is stationary with irregular
 spaced data
In-Reply-To: <CAHz+bWbcqDquju5GNJfjss4ppimNM-GXAVveNGLE_+dT5bd0cA@mail.gmail.com>
References: <C1A5238848713043B7C18ED38FFEF1F812B83275@STWMB01.ad.okstate.edu>
	<CAHz+bWbcqDquju5GNJfjss4ppimNM-GXAVveNGLE_+dT5bd0cA@mail.gmail.com>
Message-ID: <C1A5238848713043B7C18ED38FFEF1F812B83675@STWMB01.ad.okstate.edu>

Hi Mark 

Thank you for the response. The problem is biologically I can?t really avoid using the irregular time step (daily samples taken at irregular intervals)

I guess generally I?m not really doing time series analysis (my model  is a multiple regression), I just wanted to use time series techniques to test for stationarity. 

Therefore would it be feasible to aggregate the data to say a weekly time step which is regularly spaced, use one of the methods to check were the data is stationary, then use the irregular daily time step data in the multiple regression model?

Thanks again

Tom      

    

From: Mark Leeds [mailto:markleeds2 at gmail.com] 
Sent: Thursday, July 03, 2014 12:09 AM
To: Worthington, Thomas A
Subject: Re: [R] Checking whether a time series is stationary with irregular spaced data

hi thomas: I don't deal with irregularly spaced data but the standard time series techniques
don't apply there. there may be other ways but one workaround is to interpolate so
that it's regularly spaced and then use that regularly spaced series.

On Wed, Jul 2, 2014 at 6:26 PM, Worthington, Thomas A <thomas.worthington at okstate.edu> wrote:
I attempting to model the relationship between water temperature and air temperature. The seasonal component of the temperature time series has been modeled using a sinusoidal function, leaving the air and water temperature residuals. I want to model the relationship with

M5<- gls(Water ~ Air +Air1 +Air2, correlation = corCAR1(form =~ Date))

Where Water is the water temperature residual, Air is the air temperature residuals at 1 and 2 day lags. I have included an autocorrelation structure that takes into account the fact that the water temperature were taken at irregular spaced intervals.

I would like to test whether the time series is stationary, I found a blog post that used the following graphical methods and tests (Cent_Water is the water temperature centered by subtracting the mean value)

Acf(Cent_Water)
Pacf(Cent_Water)
Box.test(Cent_Water, lag=20, type="Ljung-Box")
adf.test(Cent_Water, alternative="stationary")
kpss.test(Cent_Water)

Are these methods useable with irregular spaced data as I believe it is not possible to use Acf?

Any suggestions would be greatly appreciated

Best wishes
Tom

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Jul  3 15:10:02 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 3 Jul 2014 23:10:02 +1000
Subject: [R] Comparing two times with different format
In-Reply-To: <DUB129-W91F87FD810827BE3C38C2FE0010@phx.gbl>
References: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>,
	<003301cf96ae$0e373a10$2aa5ae30$@bigpond.com>
	<DUB129-W91F87FD810827BE3C38C2FE0010@phx.gbl>
Message-ID: <000301cf96c0$1a0c1380$4e243a80$@bigpond.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/2dce7a77/attachment.pl>

From info at aghmed.fsnet.co.uk  Thu Jul  3 15:39:41 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 03 Jul 2014 14:39:41 +0100
Subject: [R] Compilation fails for package 'BayesTree' on R 3.0.1 for
 Windows
In-Reply-To: <CAN1kyLFNANOgKo8O5TeTK0iA1LVvL-w6AZoV1xGXO1HWwvGScA@mail.g
	mail.com>
References: <CAN1kyLFNANOgKo8O5TeTK0iA1LVvL-w6AZoV1xGXO1HWwvGScA@mail.gmail.com>
Message-ID: <Zen-1X2hEm-0001xt-AJ@smarthost01a.mail.zen.net.uk>

At 08:04 03/07/2014, Javier wrote:
>Hello, I am trying to install package BayesTree on R 3.0.1 for Windows, but
>I am getting a compilation error: "compilation failed for package
>'BayesTree'".
>
>Here is what I am doing:
>
>I installed Rstudio for windows from binary file.
>On Rstudio, I go to Tools->Install Packages.
>I select 'Install from Package archive file: BayesTree_0.3-1.tar.gz
>(previously I had downloaded the archived package file
>BayesTree_0.3-1.tar.gz from
>http://cran.r-project.org/src/contrib/Archive/BayesTree/ archive.)

That is the source.
Have you installed the tools you need to compile it? The Installation 
and Admin manual tells you about it.



>Why am I trying to install archived BayesTree package on old R 3.0.1?
>
>I was asked to take over a project using BayesTree package. The project
>used to work fine, until R 3.1.0 recently came out. Apparently BayesTree
>package was removed in R 3.1.0 from the CRAN repository, because "memory
>access errors were not corrected".(
>http://cran.r-project.org/web/packages/BayesTree/index.html). My
>understanding is that I need to install BayesTree package, because it is
>used by the project. So, I made a clean install of R 3.0.1 and tried to
>install BayesTree from the archive file.
>
>I would appreciate very much any help or advice on how I may be able get to
>work again this R project requiring BayesTree package. I am new to R and
>the error message I am getting does not provide much insight on how to
>solve the problem, so I have no clue what to do.
>
>Thank you in advance for any help,
>
>Javier
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From petr.pikal at precheza.cz  Thu Jul  3 15:41:50 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 13:41:50 +0000
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-BR2J=2nXxsFoCg8vsOt2oyiak55b_EP5xj2DvPTG+6SA@mail.gmail.com>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
	<7d62367b-4e06-4bd7-a9ce-d2ce19439f32@email.android.com>
	<CACqsi-BR2J=2nXxsFoCg8vsOt2oyiak55b_EP5xj2DvPTG+6SA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA3E0@SRVEXCHMBX.precheza.cz>

Hi

Maybe you can find something in Hmisc package from Frank Harrel. Especially summary.formula first example is probably close to what you want.

And also this seems to be quite convenient.

http://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Barry Lambert
> Sent: Thursday, July 03, 2014 2:29 PM
> To: Jeff Newmiller
> Cc: r-help at r-project.org
> Subject: Re: [R] Help with tables in R
>
> Thanks for the suggestions Jeff.  I have added some text below that
> will
> hopefully clarify my question and more closely follow the guidelines.
> Barry
> --
>
> Sorry for the confusing first post. I have edited for clarity and
> included
> some sample data.
>
> Clarified summary of problem: I have an excel spreadsheet has a row for
> every student registered at the university for each term since fall
> 2010
> with the following information about each student in columns: Term,
> Campus,
> College, Major, Gender, Ethnicity, Age.
>
> My goal is to be able to generate a print ready report out of R that
> will
> build some output quality tables for printing. I don't care if they are
> PDF, HTML, etc., as long as I can print them and they are somewhat
> attractive. So far, I have imported the spreadsheet into R as a CSV I
> have
> been attempting to do this with the "GridExtra" library with some
> success.
>
> I have 3 problems thus far: 1. If the count for a cell in the table is
> zero, it does not appear in the table; 2. I am unable to understand how
> to
> create more complex tables: for example a table that; 3. I am not able
> to
> create a column and row total.
>
> An example table is shown below:
>
>        ------Campus S-------|---------Campus M-----|-----Campus O------
>        2010    2011    2012   2010    2011    2012  2010    2011
> 2012   Total column
>
> COE
>
>     A
>     B
>     C
>
> COBA
>
>     A
>     B
>     C
>
> Totals -->
>
> Thus far my efforts have been something like this (small sample
> dataset):
>
> Term <- c("Fall 2010", "Fall 2010", "Fall 2011", "Fall 2011", "Fall
> 2011", "Fall 2011", "Fall 2010",
>           "Fall 2010", "Fall 2011", "Fall 2011", "Fall 2011", "Fall
> 2011")
> Campus <- c("S", "M", "O", "O", "S", "S", "O", "S", "S", "O", "S", "S")
> College <- c("COE", "COBA", "COBA", "COLFA", "COE", "COBA", "COBA",
> "COBA", "COBA", "COBA", "COBA", "COLFA")
> Major <- c("A", "B", "C", "A", "C", "C", "A", "C", "C", "A", "C", "C")
> Gender <- c("M", "F", "F", "F", "F", "M", "F", "F", "M", "F", "F", "M")
> Ethnicity <- c("B", "W", "W", "B", "B", "W", "B", "W", "W", "B", "W",
> "W")
> Age <- c(25, 27, 44, 62, 23, 36, 42, 44, 55, 65, 33, 20)
> mydata <- data.frame(Term, Campus, College, Major, Gender, Ethnicity,
> Age)
> mydata
>
> termxcamp.table <- table(mydata$Term, mydata$Campus)
> termxcoll.table <- table(mydata$Term, mydata$College)
>
> library(gridExtra)
> plot.new()
> grid.table(termxcamp.table)
> plot.new()
> grid.table(termxcoll.table)
>
>
>
> On Thu, Jul 3, 2014 at 3:05 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > Your question is vague. You say you have code that does what you want
> it
> > to, yet do not share an example of it as a starting point, or explain
> what
> > you have not been able to do. It is the nature of the Internet that
> you
> > have to be precise in describing your problems and desired solutions.
> >
> > When I read "populate tables" I think of input processing, yet you
> say you
> > already have code, suggesting that you have successfully read in your
> data
> > to R.
> >
> > Since you attempted to attach Excel files to a posting, I assume you
> have
> > not yet read the Posting Guide mentioned at the bottom of this (or
> any
> > other email from this mailing list) since that document warns against
> > attaching non-text files. Please read it. Also, we tend to "speak" in
> R on
> > this list rather than translating from other programming dialects,
> > especially proprietary ones... that is your responsibility. Sort of
> like
> > foreign language immersion. :-)
> >
> > A word to the wise... it is significantly easier to read in CSV data
> than
> > XLS or XLSX data in R. For getting started in R I highly recommend
> > exporting your XLSX data to CSV.
> >
> > You may find [1] helpful in formulating a reproducible example to get
> the
> > ball rolling more effectively.
> >
> > [1]
> > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example
> >
> > ---------------------------------------------------------------------
> ------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..
> Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> > ---------------------------------------------------------------------
> ------
> > Sent from my phone. Please excuse my brevity.
> >
> > On July 2, 2014 7:33:12 PM PDT, Barry Lambert
> <barrylambert at gmail.com>
> > wrote:
> > >I am a new convert to R (from SAS).  I am a research scientist and
> most
> > >of
> > >my
> > >use of SAS was in data analysis.  Recently, I have been wanting to
> use
> > >R to
> > >create a simple, reliable way to summarize a dataset of student
> > >demographics
> > >for a university.
> > >The spreadsheet has a row for every student registered at the
> > >university for
> > >each term since fall 2010 with the following information about each
> > >student
> > >in columns:
> > >Columns are the following: Term, College, Program, Campus, Gender,
> > >Ethnicity, Age.
> > >
> > >I have created summary tables in Excel using if/then type formulas
> to
> > >select
> > >data and count the number of female students in program A at
> location
> > >3,
> > >etc.
> > >
> > >I have written some R code to create some figures that generally
> meet
> > >my
> > >needs.
> > >I would like to find a way to have R populate some tables with this
> > >type of
> > >information.
> > >
> > >An example of my excel sheets are attached.
> > >
> > >
> > >Any suggestions will be appreciated.
> > >
> > >
> > >--------------------------------------------------------------------
> ----
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> --
> Barry Lambert
> Mobile/Text: 254-485-5328
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kmersman at smail.uni-koeln.de  Thu Jul  3 16:18:49 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Thu, 3 Jul 2014 16:18:49 +0200
Subject: [R] Residual-Plotting and na.exclude
Message-ID: <000001cf96c9$b58ad040$20a070c0$@uni-koeln.de>



-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im
Auftrag von Katharina Mersmann
Gesendet: Dienstag, 1. Juli 2014 16:22
An: r-help at r-project.org
Betreff: [R] (PLM- package) Residual-Plotting and missing Values

Dear R-Community,

I tried plotting the residuals of an FE-model estimated via plm .

And detected that there are no residuals in the plot for the last two
countries.

I guess this happens because for some countries values are missing and R
gives me the following for 
> fixed.reg1.new$resid[1]

         5 

-0.4051985

Because the first 4 elements are missing. So there are residuals different
from zero for the last two countries, but because of NA there4s a shift
because the residuals are not padded to the correct length.
I  read  in https://stat.ethz.ch/pipermail/r-help/2008-June/166312.html
and the manual that na.action=na.exclude is useful in lm-case to avoid this:
(when na.exclude is used the residuals and predictions are padded to the
correct length by inserting NAs for cases omitted by na.exclude)
and tried it for my plm regression, but it does not work.
 
To make it easier explaining the way of proceeding, a reproducible example
could be:

> # add NA4s for firm 6
> data("Grunfeld", package = "plm")
> Grunfeld$inv2= ifelse(Grunfeld$firm==6,NA, Grunfeld$inv)
> data<- pdata.frame(Grunfeld,index=c("firm","year"))
> fixed.reg1.1 <- plm(value~inv2+capital,
+                data = data,na.action=na.exclude 
+ ,index=c("firm","year"),
model="within")
> #resid(fixed.reg1.1)
> # no values for firm 6, no residuals displayed from 101-120
> fixed.reg1.1$resid[105]
     125 
9.371963

> require(lattice)
> xyplot(resid(fixed.reg1.1) ~ firm, data=data)
# As you can see because of  the NA4s of firm 6 ,there is a shift because
the residuals are not padded to the correct length,
and looking at the plot suggests there are no residuals for firm 10 but for
firm 6, which is not true.

 

Perhaps you have an Idea how to get residuals into the correct length? Or
another way to deal with it? 
Thanks in advance for your help!

Have a nice day Katie

 


From lanczos at fns.uniba.sk  Thu Jul  3 16:49:05 2014
From: lanczos at fns.uniba.sk (Tomas Lanczos)
Date: Thu, 03 Jul 2014 16:49:05 +0200
Subject: [R] RPostgreSQL, RS-DBI error
Message-ID: <1404398945.4733.22.camel@localhost.localdomain>

Hello all,



I have a problem with the connection to a Postgresql database in R.
At first, some system information:
Fedora 2.0, 
R 3.1.0 compiled from source, 
Postgresql 9.2

I installed the RPostgreSQL package in R with all the dependencies
also. 

When I'm trying to connect to the database using the following commands:

library(DBI)
library(RPostgreSQL)
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv,
dbname="Litava",host="localhost",port=1234,user="postgres",password="****")

I'm getting an error message:
ERROR:
RS-DBI driver

with no other error specification. Do have somebody an idea could be
wrong with this?

Thank You in advance for any advice

Tomas




-- 
Tom?? L?nczos, PhD
Dept. Gechemistry 
Commenius University
Mlynsk? dolina G-235
842 15
Bratislava


From biannone at purdue.edu  Thu Jul  3 16:53:18 2014
From: biannone at purdue.edu (Basil Iannone)
Date: Thu, 3 Jul 2014 10:53:18 -0400
Subject: [R] correlation structures in gls models
Message-ID: <CANukVfqPc_6eYe8KB_2JqLx3cj1RgxtQa67vCNEYDpsU0TcRQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/e165bb14/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul  3 17:01:40 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Jul 2014 15:01:40 +0000
Subject: [R] Residual-Plotting and na.exclude
In-Reply-To: <000001cf96c9$b58ad040$20a070c0$@uni-koeln.de>
References: <000001cf96c9$b58ad040$20a070c0$@uni-koeln.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA497@SRVEXCHMBX.precheza.cz>

Hi

I tried plm and it seems that na.exclude does not work. Try to connect maintainer directly.

> maintainer("plm")
[1] "Yves Croissant <yves.croissant at univ-reunion.fr>"
>

The only workaround I can think about is to give NAs to proper places in residual vector. In your example it is simple

nas<-lapply(data, function(x) which(is.na(x)))$inv2
fit <- plm(value~inv2+capital, data = data,na.action=na.exclude ,index=c("firm","year"))
res<-resid(fit)
xyplot(c(res[1:100], rep(NA, length(nas)), res[101:180]) ~ firm, data=data)

another option would be to use
?complete.cases

to find rows without NAs and select only those without missing values.

However in real situations this can be tricky.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Katharina Mersmann
> Sent: Thursday, July 03, 2014 4:19 PM
> To: r-help at r-project.org
> Subject: [R] Residual-Plotting and na.exclude
>
>
>
> -----Urspr?ngliche Nachricht-----
> Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> Im
> Auftrag von Katharina Mersmann
> Gesendet: Dienstag, 1. Juli 2014 16:22
> An: r-help at r-project.org
> Betreff: [R] (PLM- package) Residual-Plotting and missing Values
>
> Dear R-Community,
>
> I tried plotting the residuals of an FE-model estimated via plm .
>
> And detected that there are no residuals in the plot for the last two
> countries.
>
> I guess this happens because for some countries values are missing and
> R
> gives me the following for
> > fixed.reg1.new$resid[1]
>
>          5
>
> -0.4051985
>
> Because the first 4 elements are missing. So there are residuals
> different
> from zero for the last two countries, but because of NA there4s a shift
> because the residuals are not padded to the correct length.
> I  read  in https://stat.ethz.ch/pipermail/r-help/2008-June/166312.html
> and the manual that na.action=na.exclude is useful in lm-case to avoid
> this:
> (when na.exclude is used the residuals and predictions are padded to
> the
> correct length by inserting NAs for cases omitted by na.exclude)
> and tried it for my plm regression, but it does not work.
>
> To make it easier explaining the way of proceeding, a reproducible
> example
> could be:
>
> > # add NA4s for firm 6
> > data("Grunfeld", package = "plm")
> > Grunfeld$inv2= ifelse(Grunfeld$firm==6,NA, Grunfeld$inv)
> > data<- pdata.frame(Grunfeld,index=c("firm","year"))
> > fixed.reg1.1 <- plm(value~inv2+capital,
> +                data = data,na.action=na.exclude
> + ,index=c("firm","year"),
> model="within")
> > #resid(fixed.reg1.1)
> > # no values for firm 6, no residuals displayed from 101-120
> > fixed.reg1.1$resid[105]
>      125
> 9.371963
>
> > require(lattice)
> > xyplot(resid(fixed.reg1.1) ~ firm, data=data)
> # As you can see because of  the NA4s of firm 6 ,there is a shift
> because
> the residuals are not padded to the correct length,
> and looking at the plot suggests there are no residuals for firm 10 but
> for
> firm 6, which is not true.
>
>
>
> Perhaps you have an Idea how to get residuals into the correct length?
> Or
> another way to deal with it?
> Thanks in advance for your help!
>
> Have a nice day Katie
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From dcarlson at tamu.edu  Thu Jul  3 17:03:37 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 3 Jul 2014 15:03:37 +0000
Subject: [R] Help with tables in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA3E0@SRVEXCHMBX.precheza.cz>
References: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
	<7d62367b-4e06-4bd7-a9ce-d2ce19439f32@email.android.com>
	<CACqsi-BR2J=2nXxsFoCg8vsOt2oyiak55b_EP5xj2DvPTG+6SA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA3E0@SRVEXCHMBX.precheza.cz>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F7BB9A@mb02.ads.tamu.edu>

Generating tables from your sample data like the ones you attached is simple using the ftable() function:

> (CCxT <- ftable(College+Campus~Term, mydata))
          College COBA     COE     COLFA    
          Campus     M O S   M O S     M O S
Term                                        
Fall 2010            1 1 1   0 0 1     0 0 0
Fall 2011            0 2 3   0 0 1     0 1 1
> (TCxCM <- ftable(Term+Campus~College+Major, mydata))
              Term   Fall 2010     Fall 2011    
              Campus         M O S         M O S
College Major                                   
COBA    A                    0 1 0         0 1 0
        B                    1 0 0         0 0 0
        C                    0 0 1         0 1 3
COE     A                    0 0 1         0 0 0
        B                    0 0 0         0 0 0
        C                    0 0 0         0 0 1
COLFA   A                    0 0 0         0 1 0
        B                    0 0 0         0 0 0
        C                    0 0 0         0 0 1

Getting the formatting you want is more difficult. Both ways that I can think of involve using Excel. One approach is to use write.ftable():

> write.ftable(TCxCM, file="TCxCM.txt", quote=FALSE)

Then open the text file in Excel. The default settings in Excel should give you the complete table although you will have to add lines, shading, other formatting.

The second approach is to use package xtable to format the table with html. 

> library(xtable)
> print(xtable(as.matrix(TCxCM)), file="TCxCM.html", type="html")

Then open this file in Excel or an html editor. Word is also a possibility, but usually opening it in Excel and then copying to Word gives better results. The table will have the row/column labels concatenated so that the table appears to be a flat (2 way) table. That happens when converting the ftable object to a matrix since xtable handles a number of different object types, but not ftable.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Thursday, July 3, 2014 8:42 AM
To: Barry Lambert
Cc: r-help at r-project.org
Subject: Re: [R] Help with tables in R

Hi

Maybe you can find something in Hmisc package from Frank Harrel. Especially summary.formula first example is probably close to what you want.

And also this seems to be quite convenient.

http://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Barry Lambert
> Sent: Thursday, July 03, 2014 2:29 PM
> To: Jeff Newmiller
> Cc: r-help at r-project.org
> Subject: Re: [R] Help with tables in R
>
> Thanks for the suggestions Jeff.  I have added some text below that
> will
> hopefully clarify my question and more closely follow the guidelines.
> Barry
> --
>
> Sorry for the confusing first post. I have edited for clarity and
> included
> some sample data.
>
> Clarified summary of problem: I have an excel spreadsheet has a row for
> every student registered at the university for each term since fall
> 2010
> with the following information about each student in columns: Term,
> Campus,
> College, Major, Gender, Ethnicity, Age.
>
> My goal is to be able to generate a print ready report out of R that
> will
> build some output quality tables for printing. I don't care if they are
> PDF, HTML, etc., as long as I can print them and they are somewhat
> attractive. So far, I have imported the spreadsheet into R as a CSV I
> have
> been attempting to do this with the "GridExtra" library with some
> success.
>
> I have 3 problems thus far: 1. If the count for a cell in the table is
> zero, it does not appear in the table; 2. I am unable to understand how
> to
> create more complex tables: for example a table that; 3. I am not able
> to
> create a column and row total.
>
> An example table is shown below:
>
>        ------Campus S-------|---------Campus M-----|-----Campus O------
>        2010    2011    2012   2010    2011    2012  2010    2011
> 2012   Total column
>
> COE
>
>     A
>     B
>     C
>
> COBA
>
>     A
>     B
>     C
>
> Totals -->
>
> Thus far my efforts have been something like this (small sample
> dataset):
>
> Term <- c("Fall 2010", "Fall 2010", "Fall 2011", "Fall 2011", "Fall
> 2011", "Fall 2011", "Fall 2010",
>           "Fall 2010", "Fall 2011", "Fall 2011", "Fall 2011", "Fall
> 2011")
> Campus <- c("S", "M", "O", "O", "S", "S", "O", "S", "S", "O", "S", "S")
> College <- c("COE", "COBA", "COBA", "COLFA", "COE", "COBA", "COBA",
> "COBA", "COBA", "COBA", "COBA", "COLFA")
> Major <- c("A", "B", "C", "A", "C", "C", "A", "C", "C", "A", "C", "C")
> Gender <- c("M", "F", "F", "F", "F", "M", "F", "F", "M", "F", "F", "M")
> Ethnicity <- c("B", "W", "W", "B", "B", "W", "B", "W", "W", "B", "W",
> "W")
> Age <- c(25, 27, 44, 62, 23, 36, 42, 44, 55, 65, 33, 20)
> mydata <- data.frame(Term, Campus, College, Major, Gender, Ethnicity,
> Age)
> mydata
>
> termxcamp.table <- table(mydata$Term, mydata$Campus)
> termxcoll.table <- table(mydata$Term, mydata$College)
>
> library(gridExtra)
> plot.new()
> grid.table(termxcamp.table)
> plot.new()
> grid.table(termxcoll.table)
>
>
>
> On Thu, Jul 3, 2014 at 3:05 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > Your question is vague. You say you have code that does what you want
> it
> > to, yet do not share an example of it as a starting point, or explain
> what
> > you have not been able to do. It is the nature of the Internet that
> you
> > have to be precise in describing your problems and desired solutions.
> >
> > When I read "populate tables" I think of input processing, yet you
> say you
> > already have code, suggesting that you have successfully read in your
> data
> > to R.
> >
> > Since you attempted to attach Excel files to a posting, I assume you
> have
> > not yet read the Posting Guide mentioned at the bottom of this (or
> any
> > other email from this mailing list) since that document warns against
> > attaching non-text files. Please read it. Also, we tend to "speak" in
> R on
> > this list rather than translating from other programming dialects,
> > especially proprietary ones... that is your responsibility. Sort of
> like
> > foreign language immersion. :-)
> >
> > A word to the wise... it is significantly easier to read in CSV data
> than
> > XLS or XLSX data in R. For getting started in R I highly recommend
> > exporting your XLSX data to CSV.
> >
> > You may find [1] helpful in formulating a reproducible example to get
> the
> > ball rolling more effectively.
> >
> > [1]
> > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example
> >
> > ---------------------------------------------------------------------
> ------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..
> Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> > ---------------------------------------------------------------------
> ------
> > Sent from my phone. Please excuse my brevity.
> >
> > On July 2, 2014 7:33:12 PM PDT, Barry Lambert
> <barrylambert at gmail.com>
> > wrote:
> > >I am a new convert to R (from SAS).  I am a research scientist and
> most
> > >of
> > >my
> > >use of SAS was in data analysis.  Recently, I have been wanting to
> use
> > >R to
> > >create a simple, reliable way to summarize a dataset of student
> > >demographics
> > >for a university.
> > >The spreadsheet has a row for every student registered at the
> > >university for
> > >each term since fall 2010 with the following information about each
> > >student
> > >in columns:
> > >Columns are the following: Term, College, Program, Campus, Gender,
> > >Ethnicity, Age.
> > >
> > >I have created summary tables in Excel using if/then type formulas
> to
> > >select
> > >data and count the number of female students in program A at
> location
> > >3,
> > >etc.
> > >
> > >I have written some R code to create some figures that generally
> meet
> > >my
> > >needs.
> > >I would like to find a way to have R populate some tables with this
> > >type of
> > >information.
> > >
> > >An example of my excel sheets are attached.
> > >
> > >
> > >Any suggestions will be appreciated.
> > >
> > >
> > >--------------------------------------------------------------------
> ----
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> --
> Barry Lambert
> Mobile/Text: 254-485-5328
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From moleps2 at gmail.com  Thu Jul  3 17:09:15 2014
From: moleps2 at gmail.com (moleps islon)
Date: Thu, 3 Jul 2014 17:09:15 +0200
Subject: [R] Using R to analyze multiple MRI studies
Message-ID: <CACxze+ZcSJe5iWXf72vTV_6AoOX74y30CyZ8Jr2u+y6QA0OVXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/ef0e9569/attachment.pl>

From zadig_1 at excite.com  Thu Jul  3 17:31:45 2014
From: zadig_1 at excite.com (ce)
Date: Thu, 03 Jul 2014 11:31:45 -0400
Subject: [R] Order Book details in R Interactive Brokers Package
Message-ID: <20140703113145.26995@web007.roc2.bluetie.com>


There is a very good example system in 

http://censix.com/download/ 

-----Original Message-----
From: "jeeth ghambole" [jeethghambole at gmail.com]
Date: 07/01/2014 10:59 AM
To: r-help at r-project.org
Subject: [R] Order Book details in R Interactive Brokers Package

Hello All,

I am working on project of Automated trade execution using R and
Interactive Brokers Package.

I have successfully implemented and tested the connection of R with
Interactive Brokers API. Implementing orders, placing orders too are
working fine. The only problem is that while executing order i wanted to
check whether there are any pending orders in the order book. I search a
lot but didn't found anything to retrieve the order books details.

Can anyone provide me the logic to retrieve the order books details using R
Interactive Brokers Package.

Any help regarding this would be very appreciable.

Thank you.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From b.h.willis at bham.ac.uk  Thu Jul  3 12:06:44 2014
From: b.h.willis at bham.ac.uk (Brian Willis)
Date: Thu, 3 Jul 2014 03:06:44 -0700 (PDT)
Subject: [R] Dataframes and text identifier columns
In-Reply-To: <1404300790321-4693389.post@n4.nabble.com>
References: <1404046004960-4693184.post@n4.nabble.com>
	<1404300790321-4693389.post@n4.nabble.com>
Message-ID: <1404382004622-4693443.post@n4.nabble.com>

Thank you for the suggestion

What seems to work is assigning           out_put$Case <-  Inp_dat$Case         
that is

for(i in 1:4)
{
...
Case<- Inp_dat$Case[i]
?

out_put[i,]<-data.frame(Case, stdL, stdPP, stdSE, L, PP, PP_SE)

}

out_put$Case <-  Inp_dat$Case

out_put

What I don't understand is why I need to do this, and why  adding rows to
out_put[i,] within the loop the Case column has an integer label assigned
and not the text label.

Further it seems I cannot correct this within the loop?





--
View this message in context: http://r.789695.n4.nabble.com/Dataframes-and-text-identifier-columns-tp4693184p4693443.html
Sent from the R help mailing list archive at Nabble.com.


From lanczos at fns.uniba.sk  Thu Jul  3 18:58:14 2014
From: lanczos at fns.uniba.sk (Tomas Lanczos)
Date: Thu, 03 Jul 2014 18:58:14 +0200
Subject: [R] RPostgreSQL, RS-DBI error
In-Reply-To: <CAAJSdjj-3L7wD=ez5y4PBtMHC_9ceq+KgHR=2YTZ8GnksX-mdA@mail.gmail.com>
References: <1404398945.4733.22.camel@localhost.localdomain>
	<CAAJSdjj-3L7wD=ez5y4PBtMHC_9ceq+KgHR=2YTZ8GnksX-mdA@mail.gmail.com>
Message-ID: <1404406694.4733.25.camel@localhost.localdomain>




On Thu, 2014-07-03 at 11:09 -0500, John McKown wrote:
> On Thu, Jul 3, 2014 at 9:49 AM, Tomas Lanczos <lanczos at fns.uniba.sk> wrote:
> >
> > Hello all,
> >
> > I have a problem with the connection to a Postgresql database in R.
> > At first, some system information:
> > Fedora 2.0,
> > R 3.1.0 compiled from source,
> > Postgresql 9.2
> >
> > I installed the RPostgreSQL package in R with all the dependencies
> > also.
> >
> > When I'm trying to connect to the database using the following commands:
> >
> > library(DBI)
> > library(RPostgreSQL)
> > drv <- dbDriver("PostgreSQL")
> > con <- dbConnect(drv,
> > dbname="Litava",host="localhost",port=1234,user="postgres",password="****")
> >
> > I'm getting an error message:
> > ERROR:
> > RS-DBI driver
> >
> > with no other error specification. Do have somebody an idea could be
> > wrong with this?
> >
> > Thank You in advance for any advice
> >
> > Tomas
> >
> > --
> > Tom?? L?nczos, PhD
> 
> I also use PostgreSQL on Fedora 20. I don't have any problems. What
> you might want to try is removing the host= and port= arguments from
> your dbConnect
> 
> con <- dbConnect(drv,dbname="Litava",user="postgres",password="****");
> 
> I let the host= and port= default. Also, at least in my version, the
> port is not "1234", but is "5432". So that may be the problem.
> 

OMG, I'm so stupid, the port is "5432" also in my version! Thank You
very much, it works now :).

Have a nice day and sorry for bothering :)

Tomas


From dstrick1 at vt.edu  Thu Jul  3 18:17:55 2014
From: dstrick1 at vt.edu (dstrick1)
Date: Thu, 3 Jul 2014 09:17:55 -0700 (PDT)
Subject: [R] How to hide the vector number output in write.table function?
Message-ID: <1404404275426-4693469.post@n4.nabble.com>

What I'm trying to do should be simple enough, but I've been having some
trouble - hence this post.

I am attempting to output a tsv file directly from R but for some reason the
write.table function is outputting the vector number for each set of values
and thus offsetting all of my tab delimitations. I'll provide a visual:
<http://r.789695.n4.nabble.com/file/n4693469/Screen_Shot_2014-07-03_at_12.png> 

At the moment, my write.table function looks like the following:
write.table(results, file="name_of_file.csv",
append="FALSE",col.names=c('gageID','sitename','lat','long'),sep="\t"). All
I'd like to do is delete the first column (keeping the header), thus
shifting each column to the left. 

Any ideas?



Thanks,

David



--
View this message in context: http://r.789695.n4.nabble.com/How-to-hide-the-vector-number-output-in-write-table-function-tp4693469.html
Sent from the R help mailing list archive at Nabble.com.


From Guillaume.Tahon at UGent.be  Thu Jul  3 13:40:18 2014
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Thu, 3 Jul 2014 04:40:18 -0700 (PDT)
Subject: [R] How to install Vennerable
Message-ID: <1404387618529-4693449.post@n4.nabble.com>

Hi,

I'm new to using R and would like to use Vennerable to process my data and
make Venn diagrams. However I cannot seem to install the package. If I enter
the command 
install.packages("Vennerable", repos="http://R-Forge.R-project.org")
I get the following message:
package ?Vennerable? is available as a source package but not as a binary
Warning Message:
package ?Vennerable? is not available (for R version 3.1.0)

How could I install the package? I managed to download a .zip file from the
R-Forge location, but do not know how to continue.

Many thanks in advance,


Guillaume



--
View this message in context: http://r.789695.n4.nabble.com/How-to-install-Vennerable-tp4693449.html
Sent from the R help mailing list archive at Nabble.com.


From hansen_marte at hotmail.com  Thu Jul  3 14:06:02 2014
From: hansen_marte at hotmail.com (Marte Hansen)
Date: Thu, 3 Jul 2014 14:06:02 +0200
Subject: [R] Comparing two times with different format
In-Reply-To: <003301cf96ae$0e373a10$2aa5ae30$@bigpond.com>
References: <DUB129-W39DBABC55C4067D08E8BD2E0010@phx.gbl>,
	<003301cf96ae$0e373a10$2aa5ae30$@bigpond.com>
Message-ID: <DUB129-W91F87FD810827BE3C38C2FE0010@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/ff4b7076/attachment.pl>

From martavaldes85 at gmail.com  Thu Jul  3 12:34:42 2014
From: martavaldes85 at gmail.com (Marta valdes lopez)
Date: Thu, 3 Jul 2014 12:34:42 +0200
Subject: [R] error:max not meaningful for factors
In-Reply-To: <3602301.tNus6OuQrx@localhost.localdomain>
References: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>
	<3602301.tNus6OuQrx@localhost.localdomain>
Message-ID: <CAE0cxbE3sCKFydYnSOj300D6uRrM9OxsAgcLmH06yN+BjN4zKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/4d6bb9e0/attachment.pl>

From frtog at vestas.com  Thu Jul  3 19:13:42 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 3 Jul 2014 19:13:42 +0200
Subject: [R] How to hide the vector number output in write.table
 function?
Message-ID: <6vuuyy1v1o5jqeh0cqdvwwyf.1404407618870@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/c115344a/attachment.pl>

From schmidt.dietlinde at web.de  Thu Jul  3 15:07:48 2014
From: schmidt.dietlinde at web.de (Dietlinde Schmidt)
Date: Thu, 03 Jul 2014 15:07:48 +0200
Subject: [R] metafor package: changing decimal in forest plot to midline
	decimal
Message-ID: <53B555A4.8070708@web.de>

Dear R-Community,

I need to change the punctuation of the reported weights, effect sizes 
and confidence intervals in a forest plot created with the 
forest()-function in the metafor-package.

Midline decimal means that it looks like this (23?6) rather than that 
(23.6).

Do I need to change the forest()-function and if yes which part exactly?
Or is there an otherway how I can do it maybe by changing the 
rma()-function, of which the forest()-function is then applied to?

Thanks for any hints and tipps!

Cheers, Linde


From smartpink111 at yahoo.com  Thu Jul  3 12:15:05 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Jul 2014 03:15:05 -0700
Subject: [R] Sorting data.frame datewise in a descending order and
	geting datewise subtotl
In-Reply-To: <CAP0TLd9AYBQcvHe2+gnn_9bHpsTKyZq6LwrQwLQGb5wihGS4Hw@mail.gmail.com>
References: <1404288403378-4693384.post@n4.nabble.com>	<1404307896.18766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAP0TLd9AYBQcvHe2+gnn_9bHpsTKyZq6LwrQwLQGb5wihGS4Hw@mail.gmail.com>
Message-ID: <1404382505.39038.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
Try:

res1 <- aggregate(PROFIT~DATE, data=dat, FUN=sum)
res1[rev(order(as.Date(res1$DATE, format="%d/%m/%Y"))),]
#??????? DATE PROFIT
#2 02/07/2014? -1350
#1 01/07/2014?? 9400
#4 30/06/2014? 11325
#3 27/06/2014?? 6850

#if you don't wanted another column in the original dataset with `sum`
?res2 <- transform(dat, sumPROFIT=ave(PROFIT, DATE, FUN=sum))
res2[rev(order(as.Date(res2$DATE,format="%d/%m/%Y"))),]
A.K.



On Thursday, July 3, 2014 4:43 AM, veepsirtt <veepsirtt at gmail.com> wrote:
Warning in install.packages :
? package ?dplyr? is not available (for R version 2.15.3)

Is there any alternate way to sorting data.frame datewise in a

descending order?.(not using dplyr)




On Thu, Jul 3, 2014 at 12:48 PM, Velappan Periasamy <veepsirtt at gmail.com>
wrote:

> Hi A.K
> I modified and got the results
> thanks A.K
>
> library(XML)
> URL <-? "
> http://money.securebank.in/index.php?option=com_dashboard&view=history&Itemid=56&startdate=01/01/2014&enddate=02/07/2014&exchange=MCX&sid=1
> "
>
> doc <- htmlParse(URL)
> tableNodes <- getNodeSet(doc, "//table")
> l=length(tableNodes)
> dat1 <- readHTMLTable(tableNodes[[l]], colClasses=c("numeric","character",
> "character", "numeric", "character", "numeric", "numeric", "character",
> "numeric"),stringsAsFactors=FALSE)
>
> dat1$DATE <- as.Date(dat1$DATE, "%d-%m-%Y")
> str(dat1)
>
>
> On Thu, Jul 3, 2014 at 10:14 AM, Velappan Periasamy <veepsirtt at gmail.com>
> wrote:
>
>> Hi A.K
>>
>> -----------------------------
>> library(XML)
>> URL <-? "
>> http://money.securebank.in/index.php?option=com_dashboard&view=history&Itemid=56&startdate=01/01/2013&enddate=6/9/2014&exchange=MCX&sid=1"
>>
>> doc <- htmlParse(URL)
>> tableNodes <- getNodeSet(doc, "//table")
>> dat1 <- readHTMLTable(tableNodes[[4]],
>> colClasses=c("numeric","character", "character", "numeric", "character",
>> "numeric", "numeric", "character", "numeric"),stringsAsFactors=FALSE)
>> dat1$DATE <- as.Date(dat1$DATE, "%d-%m-%Y")
>> str(dat1)
>> ------------------------------
>>
>>
>> I got this error,while running the above code under RStudio.,
>> how to correct it?.
>>
>> > dat1 <- readHTMLTable(tableNodes[[4]],
>> colClasses=c("numeric","character", "character", "numeric", "character",
>> "numeric", "numeric", "character", " ..." ... [TRUNCATED]
>> Error in readHTMLTable(tableNodes[[4]], colClasses = c("numeric",
>> "character",? :
>>?  error in evaluating the argument 'doc' in selecting a method for
>> function 'readHTMLTable': Error in tableNodes[[4]] : subscript out of
>> bounds
>>
>>
>> On Thu, Jul 3, 2014 at 12:42 AM, arun kirshna [via R] <
>> ml-node+s789695n4693407h97 at n4.nabble.com> wrote:
>>
>>>
>>> Hi veepsirtt,
>>>
>>>
>>> If `dat` is the dataset
>>>
>>> library(dplyr)
>>>? dat %>%
>>>
>>> group_by(DATE) %>%
>>>
>>> summarize(PROFIT=sum(PROFIT)) %>%
>>>? arrange(desc(as.Date(DATE,format="%d/%m/%Y")))
>>> Source: local data frame [4 x 2]
>>>
>>>? ? ? ?  DATE PROFIT
>>> 1 02/07/2014? -1350
>>> 2 01/07/2014?  9400
>>> 3 30/06/2014? 11325
>>> 4 27/06/2014?  6850
>>>
>>>
>>> If you just wanted to have a new variable subTotalPROFIT and not
>>> summarize the dataset
>>>
>>>
>>>? dat %>%
>>>
>>>? group_by(DATE) %>%
>>>
>>>? mutate(subTotalPROFIT=sum(PROFIT)) %>%
>>>
>>> arrange(desc(as.Date(DATE,format="%d/%m/%Y")))
>>>
>>> A.K.
>>>
>>>
>>>
>>> On Wednesday, July 2, 2014 4:03 AM, Velappan Periasamy <[hidden email]
>>> <http://user/SendEmail.jtp?type=node&node=4693407&i=0>> wrote:



>>>
>>>
>>>
>>> Hi A.K,
>>> How to Sort the? given data.frame date wise in a descending order
>>>? and getting date wise subtotal
>>>
>>> SLNO.? ? ? ? DATE? ? ? ? SCRIP? ? ? ? PROFIT
>>> 6006302/07/2014Aluminium? ? ?  -1000
>>> 6005702/07/2014Copper? 900
>>> 6005602/07/2014LEAD? ? ?  -1250
>>> 6002901/07/2014Crude Oil6400
>>> 6003401/07/2014LEAD? ? ? ? 1500
>>> 6002501/07/2014Nickel? ? ? ? 1500
>>> 5998030/06/2014Nickel? ? ? ? ? 475
>>> 5998430/06/2014Natural Gas3000
>>> 5997230/06/2014Crude Oil2600
>>> 5997130/06/2014Copper3750
>>> 5997030/06/2014Natural Gas1500
>>> 5992427/06/2014Aluminium? ? 500
>>> 5992227/06/2014LEAD? ? ? ? 2250
>>> 5992027/06/2014Copper1100
>>> 5991827/06/2014Natural Gas3000
>>>
>>> Thanks
>>> veepsirtt
>>>
>>> ______________________________________________
>>> [hidden email] <http://user/SendEmail.jtp?type=node&node=4693407&i=1>
>>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ------------------------------
>>>? If you reply to this email, your message will be added to the
>>> discussion below:
>>>
>>> http://r.789695.n4.nabble.com/Sorting-data-frame-datewise-in-a-descending-order-and-geting-datewise-subtotl-tp4693384p4693407.html
>>>? To unsubscribe from Sorting data.frame datewise in a descending order
>>> and geting datewise subtotl, click here
>>> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4693384&code=dmVlcHNpcnR0QGdtYWlsLmNvbXw0NjkzMzg0fDY5NzkzMTE3Nw==>
>>> .
>>> NAML
>>> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>>>
>>
>>
>




--
View this message in context: http://r.789695.n4.nabble.com/Sorting-data-frame-datewise-in-a-descending-order-and-geting-datewise-subtotl-tp4693384p4693434.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dstrick1 at vt.edu  Thu Jul  3 19:27:42 2014
From: dstrick1 at vt.edu (dstrick1)
Date: Thu, 3 Jul 2014 10:27:42 -0700 (PDT)
Subject: [R] How to hide the vector number output in write.table
	function?
In-Reply-To: <6vuuyy1v1o5jqeh0cqdvwwyf.1404407618870@email.android.com>
References: <1404404275426-4693469.post@n4.nabble.com>
	<6vuuyy1v1o5jqeh0cqdvwwyf.1404407618870@email.android.com>
Message-ID: <1404408462946-4693478.post@n4.nabble.com>

Can't believe I missed that. Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/How-to-hide-the-vector-number-output-in-write-table-function-tp4693469p4693478.html
Sent from the R help mailing list archive at Nabble.com.


From jvadams at usgs.gov  Thu Jul  3 20:03:03 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 3 Jul 2014 13:03:03 -0500
Subject: [R] How to install Vennerable
In-Reply-To: <1404387618529-4693449.post@n4.nabble.com>
References: <1404387618529-4693449.post@n4.nabble.com>
Message-ID: <CAN5YmCFxERUav6OwmLUNTGr++k9_C8gca6OdE0cjEu+EziuwCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/726ec973/attachment.pl>

From mckellercran at gmail.com  Thu Jul  3 20:28:20 2014
From: mckellercran at gmail.com (Matthew Keller)
Date: Thu, 3 Jul 2014 12:28:20 -0600
Subject: [R] odd behavior of seq()
Message-ID: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/1d46e31a/attachment.pl>

From marc_schwartz at me.com  Thu Jul  3 20:37:06 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 03 Jul 2014 13:37:06 -0500
Subject: [R] odd behavior of seq()
In-Reply-To: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>
References: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>
Message-ID: <CEA2D5D6-8C90-41B1-AD57-3F15C76FB68B@me.com>

On Jul 3, 2014, at 1:28 PM, Matthew Keller <mckellercran at gmail.com> wrote:

> Hi all,
> 
> A bit stumped here.
> 
> z <- seq(.05,.85,by=.1)
> z==.05     #good
> [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
> z==.15  #huh????
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
> More generally:
>> sum(z==.25)
> [1] 1
>> sum(z==.35)
> [1] 0
>> sum(z==.45)
> [1] 1
>> sum(z==.55)
> [1] 1
>> sum(z==.65)
> [1] 0
>> sum(z==.75)
> [1] 0
>> sum(z==.85)
> [1] 1
> 
> Does anyone have any ideas what is going on here?


See the MFAQ[1]:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Regards,

Marc Schwartz

[1] Most Frequently Asked Question


From jholtman at gmail.com  Thu Jul  3 20:38:30 2014
From: jholtman at gmail.com (Jim Holtman)
Date: Thu, 03 Jul 2014 11:38:30 -0700
Subject: [R] odd behavior of seq()
Message-ID: <jx2oc460gj94liufgx4iqajx.1404412710016@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/7580e6bd/attachment.pl>

From peter.langfelder at gmail.com  Thu Jul  3 20:38:42 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 3 Jul 2014 11:38:42 -0700
Subject: [R] odd behavior of seq()
In-Reply-To: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>
References: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>
Message-ID: <CA+hbrhU-r574zLLaWT89o-es3o6YtJmwNcMoy4T5C93fPt0WSA@mail.gmail.com>

Precision, precision, precision...

> z[2]-0.15
[1] 2.775558e-17

My solution:

> z <- signif(seq(.05,.85,by=.1), 5)
> z[2] - 0.15
[1] 0
> z[2]==0.15
[1] TRUE

Peter

On Thu, Jul 3, 2014 at 11:28 AM, Matthew Keller <mckellercran at gmail.com> wrote:
> Hi all,
>
> A bit stumped here.
>
> z <- seq(.05,.85,by=.1)
> z==.05     #good
> [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>
> z==.15  #huh????
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>
> More generally:
>> sum(z==.25)
> [1] 1
>> sum(z==.35)
> [1] 0
>> sum(z==.45)
> [1] 1
>> sum(z==.55)
> [1] 1
>> sum(z==.65)
> [1] 0
>> sum(z==.75)
> [1] 0
>> sum(z==.85)
> [1] 1
>
> Does anyone have any ideas what is going on here?
>
>> R.Version()
> $platform
> [1] "x86_64-apple-darwin9.8.0"
>
> $arch
> [1] "x86_64"
>
> $os
> [1] "darwin9.8.0"
>
> $system
> [1] "x86_64, darwin9.8.0"
>
> $status
> [1] ""
>
> $major
> [1] "2"
>
> $minor
> [1] "13.1"
>
> $year
> [1] "2011"
>
> $month
> [1] "07"
>
> $day
> [1] "08"
>
> $`svn rev`
> [1] "56322"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 2.13.1 (2011-07-08)"
>
> --
> Matthew C Keller
> Asst. Professor of Psychology
> University of Colorado at Boulder
> www.matthewckeller.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mckellercran at gmail.com  Thu Jul  3 20:39:47 2014
From: mckellercran at gmail.com (Matthew Keller)
Date: Thu, 3 Jul 2014 12:39:47 -0600
Subject: [R] odd behavior of seq()
In-Reply-To: <CA+hbrhU-r574zLLaWT89o-es3o6YtJmwNcMoy4T5C93fPt0WSA@mail.gmail.com>
References: <CAB7vCMQtSqVLpUd3F+srMY6R7RrMXyPi8t3cOXB4wLho=kbyNQ@mail.gmail.com>
	<CA+hbrhU-r574zLLaWT89o-es3o6YtJmwNcMoy4T5C93fPt0WSA@mail.gmail.com>
Message-ID: <CAB7vCMQ+=mgrr3eBwF-8bTZdOcq=mR177VjvSnMD+j9OVLUTzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/173da975/attachment.pl>

From spencer.graves at structuremonitoring.com  Thu Jul  3 20:55:18 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 03 Jul 2014 11:55:18 -0700
Subject: [R] intermittent errors in [.data.frame
Message-ID: <53B5A716.1070109@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/bb41ff53/attachment.pl>

From jrkrideau at inbox.com  Thu Jul  3 21:13:50 2014
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 3 Jul 2014 11:13:50 -0800
Subject: [R] Help with tables in R
In-Reply-To: <CACqsi-DrybQ6Swo6W6VmXww6Dox6qCUgGz34K9QYaou82R-s3w@mail.gmail.com>
Message-ID: <4C7003F34B4.00000226jrkrideau@inbox.com>

I see that others have answered the question much better than I could. 
However assumng you are getting the data in the layout you want you may also want to look at the xtable package in R as a very handy alternative to stargazer if you want to produce some good-loking tables in some flavour of LaTeX.  

Odfweave seems to produce good tables in OpenOffice/LibreOffice.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: barrylambert at gmail.com
> Sent: Wed, 2 Jul 2014 21:33:12 -0500
> To: r-help at r-project.org
> Subject: [R] Help with tables in R
> 
> I am a new convert to R (from SAS).  I am a research scientist and most
> of
> my
> use of SAS was in data analysis.  Recently, I have been wanting to use R
> to
> create a simple, reliable way to summarize a dataset of student
> demographics
> for a university.
> The spreadsheet has a row for every student registered at the university
> for
> each term since fall 2010 with the following information about each
> student
> in columns:
> Columns are the following: Term, College, Program, Campus, Gender,
> Ethnicity, Age.
> 
> I have created summary tables in Excel using if/then type formulas to
> select
> data and count the number of female students in program A at location 3,
> etc.
> 
> I have written some R code to create some figures that generally meet my
> needs.
> I would like to find a way to have R populate some tables with this type
> of
> information.
> 
> An example of my excel sheets are attached.
> 
> 
> Any suggestions will be appreciated.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From murdoch.duncan at gmail.com  Thu Jul  3 21:25:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Jul 2014 15:25:00 -0400
Subject: [R] intermittent errors in [.data.frame
In-Reply-To: <53B5A716.1070109@structuremonitoring.com>
References: <53B5A716.1070109@structuremonitoring.com>
Message-ID: <53B5AE0C.6010600@gmail.com>

On 03/07/2014 2:55 PM, Spencer Graves wrote:
>         I get inconsistent results from "[.data.frame".  I've so far been
> unable to create a simple, replicable example nor a workaround.  With
> debug, I traced the problem to "rows <- rows[i]", line 131 in
> "[.data.frame":  In this example, rows = 1:45, and rows[1:3] = 1:3, as
> we expect.  However with i = 1:3, rows[i] = c(1, 2, 2):
>
>
> Browse[4]> rows[1:3]
> [1] 1 2 3
> Browse[4]>i
> [1] 1 2 3
> Browse[4]>rows[i]
> [1] 1 2 2
>
>
>
>         Absent better suggestions, I currently plan to try to simplify my
> example as much as I can while retaining the error. Unfortunately, the
> search path includes 19 packages (see below), so I expect this not to be
> easy.  Other suggestions would be welcomed.

Are you computing i using floating point values?  You may have 2.9999999 
instead of 3; as an index, it is equivalent to 2, though it will print as 3.

Duncan Murdoch


From wht_crl at yahoo.com  Thu Jul  3 21:35:19 2014
From: wht_crl at yahoo.com (carol white)
Date: Thu, 3 Jul 2014 12:35:19 -0700
Subject: [R] access an element of a list without looping
Message-ID: <1404416119.42714.YahooMailNeo@web121502.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/addacf12/attachment.pl>

From spencer.graves at structuremonitoring.com  Thu Jul  3 21:52:00 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 03 Jul 2014 12:52:00 -0700
Subject: [R] intermittent errors in [.data.frame
In-Reply-To: <53B5AE0C.6010600@gmail.com>
References: <53B5A716.1070109@structuremonitoring.com>
	<53B5AE0C.6010600@gmail.com>
Message-ID: <53B5B460.4020107@structuremonitoring.com>

Hi, Duncan:


On 7/3/2014 12:25 PM, Duncan Murdoch wrote:
> On 03/07/2014 2:55 PM, Spencer Graves wrote:
>>         I get inconsistent results from "[.data.frame".  I've so far 
>> been
>> unable to create a simple, replicable example nor a workaround. With
>> debug, I traced the problem to "rows <- rows[i]", line 131 in
>> "[.data.frame":  In this example, rows = 1:45, and rows[1:3] = 1:3, as
>> we expect.  However with i = 1:3, rows[i] = c(1, 2, 2):
>>
>>
>> Browse[4]> rows[1:3]
>> [1] 1 2 3
>> Browse[4]>i
>> [1] 1 2 3
>> Browse[4]>rows[i]
>> [1] 1 2 2
>>
>>
>>
>>         Absent better suggestions, I currently plan to try to 
>> simplify my
>> example as much as I can while retaining the error. Unfortunately, the
>> search path includes 19 packages (see below), so I expect this not to be
>> easy.  Other suggestions would be welcomed.
>
> Are you computing i using floating point values?  You may have 
> 2.9999999 instead of 3; as an index, it is equivalent to 2, though it 
> will print as 3.
>


       You identified it:


  str(i)
  num [1:3] 1 2 3
Browse[4]> as.integer(i)
[1] 1 2 2


       Thanks so much.
       Spencer

>
> Duncan Murdoch


From 538280 at gmail.com  Thu Jul  3 21:54:46 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 3 Jul 2014 13:54:46 -0600
Subject: [R] access an element of a list without looping
In-Reply-To: <1404416119.42714.YahooMailNeo@web121502.mail.ne1.yahoo.com>
References: <1404416119.42714.YahooMailNeo@web121502.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdyd8LZTxe9oeOvAdXKXpb3je5vuK6QFrUqdB2aX2bG_Mg@mail.gmail.com>

You could use

which( sapply(l, length) == 2 )

but that still uses a loop internally.

On Thu, Jul 3, 2014 at 1:35 PM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> Is there any way to access an element of a list without looping over the list nor using unlist? Just to avoid parsing a very long list.
>
>
> For ex, how to find a vector of a length 2 in a list without using a loop?
>
> l = list (c(1), c(2,3), c(1,2,3))
> for (i in 1:length(l))
>     if(length(l[[i]]==2){
>         print (i)
>         break
>     }
>
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From gangchen6 at gmail.com  Thu Jul  3 21:56:07 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 3 Jul 2014 15:56:07 -0400
Subject: [R] Display a dataframe
Message-ID: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>

I have a matrix 'dd' defined as below:

dd <- t(matrix(c(153.0216306,  1, 7.578366e-35,
13.3696538,  1, 5.114571e-04,
0.8476713,  1, 7.144239e-01,
1.2196050,  1, 5.388764e-01,
2.6349405,  1, 2.090719e-01,
6.0507714,  1, 2.780045e-02), nrow=3, ncol=6))
dimnames(dd)[[2]] <- c('# Chisq', 'DF', 'Pr(>Chisq)')
dimnames(dd)[[1]] <- c('# Sex', '# Volume', '# Weight', '# Intensity',
'# ISO', '# SEC')

'dd' displays as the following:

                # Chisq DF   Pr(>Chisq)
# Sex       153.0216306  1 7.578366e-35
# Volume     13.3696538  1 5.114571e-04
# Weight      0.8476713  1 7.144239e-01
# Intensity   1.2196050  1 5.388764e-01
# ISO         2.6349405  1 2.090719e-01
# SEC         6.0507714  1 2.780045e-02

I would like to display it as:

# Chisq               DF   Pr(>Chisq)                        term
153.0216306  1 7.578366e-35                            # Sex
13.3696538  1 5.114571e-04                              # Volume
0.8476713  1 7.144239e-01                                # Weight
1.2196050  1 5.388764e-01                                # Intensity
2.6349405  1 2.090719e-01                                # ISO
6.0507714  1 2.780045e-02                                # SEC

This is what I came up with

(cc <- data.frame(data.frame(dd), term=dimnames(dd)[[1]]))

               X..Chisq DF   Pr..Chisq.        term
# Sex       153.0216306  1 7.578366e-35       # Sex
# Volume     13.3696538  1 5.114571e-04    # Volume
# Weight      0.8476713  1 7.144239e-01    # Weight
# Intensity   1.2196050  1 5.388764e-01 # Intensity
# ISO         2.6349405  1 2.090719e-01       # ISO
# SEC         6.0507714  1 2.780045e-02       # SEC

But I'm not happy with the following two issues:

1) How to get rid of the row names?
2) The special characters of #, (, >,) in the column names are not
displayed correctly.

Any suggestions?

Thanks,
Gang


From marc_schwartz at me.com  Thu Jul  3 21:58:14 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 03 Jul 2014 14:58:14 -0500
Subject: [R] access an element of a list without looping
In-Reply-To: <1404416119.42714.YahooMailNeo@web121502.mail.ne1.yahoo.com>
References: <1404416119.42714.YahooMailNeo@web121502.mail.ne1.yahoo.com>
Message-ID: <B0486713-11BD-443C-94F0-05E043283022@me.com>

On Jul 3, 2014, at 2:35 PM, carol white <wht_crl at yahoo.com> wrote:

> Hi,
> Is there any way to access an element of a list without looping over the list nor using unlist? Just to avoid parsing a very long list.
> 
> 
> For ex, how to find a vector of a length 2 in a list without using a loop?
> 
> l = list (c(1), c(2,3), c(1,2,3))
> for (i in 1:length(l))
>     if(length(l[[i]]==2){
>         print (i)
>         break
>     }
> 
> Thanks
> 
> Carol


You can use one of the *apply() functions, albeit, it is still effectively looping through the list. It may or may not be faster in some cases than an explicit for() loop, but it can be easier to read, depending upon the complexity of the function being utilized within the call.

For example:

> which(sapply(l, function(x) length(x) == 2))
[1] 2

This presumes that you only have a single level of list elements to scan. If you have "sub-levels" within the list, you might want to look at ?rapply, which is a recursive version.

Regards,

Marc Schwartz


From dcarlson at tamu.edu  Thu Jul  3 23:10:02 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 3 Jul 2014 21:10:02 +0000
Subject: [R] Display a dataframe
In-Reply-To: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F7BECF@mb02.ads.tamu.edu>

Not elegant, but it works:

> term <- dimnames(dd)[[1]]
> dd1 <- dd
> dimnames(dd1)[[1]] <- rep("", 6)
> dd2 <- capture.output(dd1)
> cat(paste(dd2, "   ", c("Term", term)), fill=48)
     # Chisq DF   Pr(>Chisq)     Term 
 153.0216306  1 7.578366e-35     # Sex 
  13.3696538  1 5.114571e-04     # Volume 
   0.8476713  1 7.144239e-01     # Weight 
   1.2196050  1 5.388764e-01     # Intensity 
   2.6349405  1 2.090719e-01     # ISO 
   6.0507714  1 2.780045e-02     # SEC


David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Gang Chen
Sent: Thursday, July 3, 2014 2:56 PM
To: r-help
Subject: [R] Display a dataframe

I have a matrix 'dd' defined as below:

dd <- t(matrix(c(153.0216306,  1, 7.578366e-35,
13.3696538,  1, 5.114571e-04,
0.8476713,  1, 7.144239e-01,
1.2196050,  1, 5.388764e-01,
2.6349405,  1, 2.090719e-01,
6.0507714,  1, 2.780045e-02), nrow=3, ncol=6))
dimnames(dd)[[2]] <- c('# Chisq', 'DF', 'Pr(>Chisq)')
dimnames(dd)[[1]] <- c('# Sex', '# Volume', '# Weight', '# Intensity',
'# ISO', '# SEC')

'dd' displays as the following:

                # Chisq DF   Pr(>Chisq)
# Sex       153.0216306  1 7.578366e-35
# Volume     13.3696538  1 5.114571e-04
# Weight      0.8476713  1 7.144239e-01
# Intensity   1.2196050  1 5.388764e-01
# ISO         2.6349405  1 2.090719e-01
# SEC         6.0507714  1 2.780045e-02

I would like to display it as:

# Chisq               DF   Pr(>Chisq)                        term
153.0216306  1 7.578366e-35                            # Sex
13.3696538  1 5.114571e-04                              # Volume
0.8476713  1 7.144239e-01                                # Weight
1.2196050  1 5.388764e-01                                # Intensity
2.6349405  1 2.090719e-01                                # ISO
6.0507714  1 2.780045e-02                                # SEC

This is what I came up with

(cc <- data.frame(data.frame(dd), term=dimnames(dd)[[1]]))

               X..Chisq DF   Pr..Chisq.        term
# Sex       153.0216306  1 7.578366e-35       # Sex
# Volume     13.3696538  1 5.114571e-04    # Volume
# Weight      0.8476713  1 7.144239e-01    # Weight
# Intensity   1.2196050  1 5.388764e-01 # Intensity
# ISO         2.6349405  1 2.090719e-01       # ISO
# SEC         6.0507714  1 2.780045e-02       # SEC

But I'm not happy with the following two issues:

1) How to get rid of the row names?
2) The special characters of #, (, >,) in the column names are not
displayed correctly.

Any suggestions?

Thanks,
Gang

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From cory.champagn at gmail.com  Thu Jul  3 21:45:51 2014
From: cory.champagn at gmail.com (Cory Champagne)
Date: Thu, 03 Jul 2014 12:45:51 -0700
Subject: [R] Using subplot (from Hmisc) along with par(mfrow)
Message-ID: <53B5B2EF.4040907@gmail.com>


   Hello all,
   I think this should be a relatively easy solution involving par but I can't
   figure it out, involving subplot:
   I'm  making  a  three-figure plot, each with a subplot.  Here's simple
   reproducible code below.  But each plot seems to call the original par
   setting and redraws the new plot in the first position, rather than adding
   subsequent plots in a single plot window.
   Can someone tell me how to fix this so the result is three figures, each
   containing a subplot, all within a single plot window?
   Thanks,
   -Cory
   library(Hmisc)    # subplot from the Hmisc package
   par(mfrow=c(3,1) )    # set mfrow for 3 rows and 1 column.
   plot(1:10, 1:10, main = "Plot 1")
       subplot(plot(10,10, xlab="", ylab=""), x=2, y=8, size = c(0.5, 0.5) )
   plot(11:20, 11:20, main = "Plot 2")
       subplot(plot(10,10, xlab="", ylab=""), x=12, y=18, size = c(0.5, 0.5)
   )
   plot(21:30, 21:30, main = "Plot 3")
       subplot(plot(10,10, xlab="", ylab=""), x=22, y=28, size = c(0.5, 0.5)
   )

From bgoelv at gmail.com  Thu Jul  3 19:32:00 2014
From: bgoelv at gmail.com (Vijay goel)
Date: Thu, 3 Jul 2014 23:02:00 +0530
Subject: [R] Fisher Scoring v/s Coordinate Descent for MLE in R
Message-ID: <CAAai-LimRGRMzoj-bA_6-tz6j6bQETiO4E_7qq66x6JwrRn8qA@mail.gmail.com>

R base function glm() uses Fishers Scoring for MLE, while the glmnet uses the
coordinate descent method to solve the same equation ? Coordinate descent is
more time efficient than Fisher Scoring as fisher scoring calculates the
second order derivative matrix and some other matrix operation which makes
it space and time expensive, while coordinate descent can do the same task
in O(np) time.

Why R base function uses Fisher Scoring or this method has advantage over
other optimization methods? What will be comparison between coordinate
descent and Fisher Scoring ? I am relatively new to do this field so any
help or resource will be helpful

Regards
Vij


From icromwell at bccrc.ca  Thu Jul  3 20:53:39 2014
From: icromwell at bccrc.ca (Ian Cromwell)
Date: Thu, 3 Jul 2014 11:53:39 -0700 (PDT)
Subject: [R] Analysis of censored cost data
In-Reply-To: <alpine.LNX.2.11.1404231120510.12012@localhost>
References: <1398274531.77891.YahooMailNeo@web160905.mail.bf1.yahoo.com>
	<alpine.LNX.2.11.1404231120510.12012@localhost>
Message-ID: <1404413619387-4693485.post@n4.nabble.com>

Paul, I happen to be working on the exact same problem. If you found a
solution somewhere, please let me know. I will do the same if I stumble onto
a solution first.

Rich - cost information can be collected prospectively but be censored due
to incomplete follow-up or some other similar reason. This is common when
analyzing costs from administrative data sets, where records are collected
over time but not everyone has had the outcome of interest (death,
remission, whatever). The paper that Paul is referring to is here:
http://www.ncbi.nlm.nih.gov/pubmed/12229999



--
View this message in context: http://r.789695.n4.nabble.com/Analysis-of-censored-cost-data-tp4689336p4693485.html
Sent from the R help mailing list archive at Nabble.com.


From steve.bellan at gmail.com  Fri Jul  4 00:53:19 2014
From: steve.bellan at gmail.com (Steve Bellan)
Date: Thu, 3 Jul 2014 17:53:19 -0500
Subject: [R] applying operations within() a matrix's environment
Message-ID: <B0D6B9F8-0AF6-492E-9EDA-EB7848F306E9@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140703/268386a8/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  4 03:37:22 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Jul 2014 18:37:22 -0700
Subject: [R] How to install Vennerable
In-Reply-To: <1404387618529-4693449.post@n4.nabble.com>
References: <1404387618529-4693449.post@n4.nabble.com>
Message-ID: <D7A37839-6891-43E3-BB77-3BC4EB04FCB8@comcast.net>


On Jul 3, 2014, at 4:40 AM, gktahon wrote:

> Hi,
> 
> I'm new to using R and would like to use Vennerable to process my data and
> make Venn diagrams. However I cannot seem to install the package. If I enter
> the command 
> install.packages("Vennerable", repos="http://R-Forge.R-project.org")
> I get the following message:
> package ?Vennerable? is available as a source package but not as a binary
> Warning Message:
> package ?Vennerable? is not available (for R version 3.1.0)
> 
> How could I install the package? I managed to download a .zip file from the
> R-Forge location, but do not know how to continue.

You would need to tell us your OS setup. Try reading the Details section of ?install.packages. You will need to set repos to NULL and use the proper type for a binary install ... if you are using R 3.1.x

> 
> Many thanks in advance,
> 
> 
> Guillaume
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-install-Vennerable-tp4693449.html
> Sent from the R help mailing list archive at Nabble.com.

Better to post directly to the list.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Jul  4 03:51:26 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Jul 2014 18:51:26 -0700
Subject: [R] Using subplot (from Hmisc) along with par(mfrow)
In-Reply-To: <53B5B2EF.4040907@gmail.com>
References: <53B5B2EF.4040907@gmail.com>
Message-ID: <CE7320D5-0D11-47D7-8434-91B3583637D3@comcast.net>


On Jul 3, 2014, at 12:45 PM, Cory Champagne wrote:

> 
>   Hello all,
>   I think this should be a relatively easy solution involving par but I can't
>   figure it out, involving subplot:
>   I'm  making  a  three-figure plot, each with a subplot.  Here's simple
>   reproducible code below.  But each plot seems to call the original par
>   setting and redraws the new plot in the first position, rather than adding
>   subsequent plots in a single plot window.
>   Can someone tell me how to fix this so the result is three figures, each
>   containing a subplot, all within a single plot window?
>   Thanks,
>   -Cory
>   library(Hmisc)    # subplot from the Hmisc package
>   par(mfrow=c(3,1) )    # set mfrow for 3 rows and 1 column.
>   plot(1:10, 1:10, main = "Plot 1")
>       subplot(plot(10,10, xlab="", ylab=""), x=2, y=8, size = c(0.5, 0.5) )
>   plot(11:20, 11:20, main = "Plot 2")
>       subplot(plot(10,10, xlab="", ylab=""), x=12, y=18, size = c(0.5, 0.5)
>   )
>   plot(21:30, 21:30, main = "Plot 3")
>       subplot(plot(10,10, xlab="", ylab=""), x=22, y=28, size = c(0.5, 0.5)
>   )

Need to read a bit further down below the 'mfrow' and 'mfcol' arguments in par, specifically until you get to 'mfg':

library(Hmisc)    
  par(mfrow=c(3,1) )    
  plot(1:10, 1:10, main = "Plot 1")
      subplot(plot(10,10, xlab="", ylab=""), x=2, y=8, size = c(0.5, 0.5) )
  par(mfg=c(2,1) ); plot(11:20, 11:20, main = "Plot 2")
      subplot(plot(10,10, xlab="", ylab=""), x=12, y=18, size = c(0.5, 0.5)
  )
  par(mfg=c(3,1)); plot(21:30, 21:30, main = "Plot 3")
      subplot(plot(10,10, xlab="", ylab=""), x=22, y=28, size = c(0.5, 0.5)
  )

I suspect that the subplot manipulations of par settings are the cause of the problem. It is restoring the mfg pointer.

-- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Fri Jul  4 03:57:00 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Jul 2014 18:57:00 -0700
Subject: [R] Display a dataframe
In-Reply-To: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
Message-ID: <1404439020.26963.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:
nC <- max(nchar(row.names(dd)))
?term <- formatC(row.names(dd), width=-nC)
#or
?term <- sprintf("%-11s", row.names(dd))

? dd1 <- setNames(data.frame(unname(dd), term,stringsAsFactors=F), c(colnames(dd), formatC("term",width=-nC)))
dd1
#????? # Chisq DF?? Pr(>Chisq) term?????? 
#1 153.0216306? 1 7.578366e-35 # Sex????? 
#2? 13.3696538? 1 5.114571e-04 # Volume?? 
#3?? 0.8476713? 1 7.144239e-01 # Weight?? 
#4?? 1.2196050? 1 5.388764e-01 # Intensity
#5?? 2.6349405? 1 2.090719e-01 # ISO????? 
#6?? 6.0507714? 1 2.780045e-02 # SEC????? 

A.K.





On Thursday, July 3, 2014 3:57 PM, Gang Chen <gangchen6 at gmail.com> wrote:
I have a matrix 'dd' defined as below:

dd <- t(matrix(c(153.0216306,? 1, 7.578366e-35,
13.3696538,? 1, 5.114571e-04,
0.8476713,? 1, 7.144239e-01,
1.2196050,? 1, 5.388764e-01,
2.6349405,? 1, 2.090719e-01,
6.0507714,? 1, 2.780045e-02), nrow=3, ncol=6))
dimnames(dd)[[2]] <- c('# Chisq', 'DF', 'Pr(>Chisq)')
dimnames(dd)[[1]] <- c('# Sex', '# Volume', '# Weight', '# Intensity',
'# ISO', '# SEC')

'dd' displays as the following:

? ? ? ? ? ? ? ? # Chisq DF?  Pr(>Chisq)
# Sex? ? ?  153.0216306? 1 7.578366e-35
# Volume? ?  13.3696538? 1 5.114571e-04
# Weight? ? ? 0.8476713? 1 7.144239e-01
# Intensity?  1.2196050? 1 5.388764e-01
# ISO? ? ? ?  2.6349405? 1 2.090719e-01
# SEC? ? ? ?  6.0507714? 1 2.780045e-02

I would like to display it as:

# Chisq? ? ? ? ? ? ?  DF?  Pr(>Chisq)? ? ? ? ? ? ? ? ? ? ? ? term
153.0216306? 1 7.578366e-35? ? ? ? ? ? ? ? ? ? ? ? ? ? # Sex
13.3696538? 1 5.114571e-04? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # Volume
0.8476713? 1 7.144239e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # Weight
1.2196050? 1 5.388764e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # Intensity
2.6349405? 1 2.090719e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # ISO
6.0507714? 1 2.780045e-02? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # SEC

This is what I came up with

(cc <- data.frame(data.frame(dd), term=dimnames(dd)[[1]]))

? ? ? ? ? ? ?  X..Chisq DF?  Pr..Chisq.? ? ? ? term
# Sex? ? ?  153.0216306? 1 7.578366e-35? ? ?  # Sex
# Volume? ?  13.3696538? 1 5.114571e-04? ? # Volume
# Weight? ? ? 0.8476713? 1 7.144239e-01? ? # Weight
# Intensity?  1.2196050? 1 5.388764e-01 # Intensity
# ISO? ? ? ?  2.6349405? 1 2.090719e-01? ? ?  # ISO
# SEC? ? ? ?  6.0507714? 1 2.780045e-02? ? ?  # SEC

But I'm not happy with the following two issues:

1) How to get rid of the row names?
2) The special characters of #, (, >,) in the column names are not
displayed correctly.

Any suggestions?

Thanks,
Gang

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From guetlein at informatik.uni-freiburg.de  Fri Jul  4 09:12:42 2014
From: guetlein at informatik.uni-freiburg.de (Martin Guetlein)
Date: Fri, 4 Jul 2014 09:12:42 +0200
Subject: [R] sammon fails with duplicates error,
	but no duplicates there (MASS package)
Message-ID: <CANjGdQLGiVRLzuAY2OAVBU9zoOnv-LFSAZmokZey6EzvmKtf0w@mail.gmail.com>

Hi all,

the sammon mapping fails with message "initial configuration has
duplicates". But there are no duplicates in my data (see example
below).
Apparently, the problem is that row 9 and 10 have an equal distance to
all other rows (but they are not equal, see last two columns).

Any help to get sammon working would be great,
Kind regards,
Martin


library("MASS")
c1 <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c2 <- c(0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c3 <- c(1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c4 <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c5 <- c(1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c6 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,
1, 1, 1, 0, 0)
c7 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
0, 0, 0, 0, 0)
c8 <- c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0)
c9 <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 1, 0)
c10<- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 1)
# working
data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9)
sammon(dist(data))
# not working:
data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9,c10)
sammon(dist(data))


From petr.pikal at precheza.cz  Fri Jul  4 09:51:14 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 4 Jul 2014 07:51:14 +0000
Subject: [R] applying operations within() a matrix's environment
In-Reply-To: <B0D6B9F8-0AF6-492E-9EDA-EB7848F306E9@gmail.com>
References: <B0D6B9F8-0AF6-492E-9EDA-EB7848F306E9@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA5A8@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/ebe9ca1f/attachment.pl>

From frtog at vestas.com  Fri Jul  4 10:02:30 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 4 Jul 2014 10:02:30 +0200
Subject: [R] sammon fails with duplicates error,
 but no duplicates there (MASS package)
In-Reply-To: <CANjGdQLGiVRLzuAY2OAVBU9zoOnv-LFSAZmokZey6EzvmKtf0w@mail.gmail.com>
References: <CANjGdQLGiVRLzuAY2OAVBU9zoOnv-LFSAZmokZey6EzvmKtf0w@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C67C12A2@DKRDSEXC016.vestas.net>

Hi

It seems to be related to the way that the default start values (y argument of sammon) are calculated.

Here the last two rows are the same:

> cmdscale(dist(data), 2)
           [,1]       [,2]
c1   2.04910556 -0.3627887
c2  -0.01889892 -0.1822057
c3   0.40767629  0.2599026
c4   0.81569304 -0.4165993
c5   0.70362596 -0.3573003
c6  -1.69673266 -1.7209956
c7  -0.65997449 -0.2888096
c8  -0.24449262  0.4502489
c9  -0.67800108  1.3092739
c10 -0.67800108  1.3092739

Try to perturb the start values using jitter(). Like this

> sammon(dist(data), y = jitter(cmdscale(dist(data), 2)))
Initial stress        : 0.18304
stress after  10 iters: 0.07867, magic = 0.092
stress after  20 iters: 0.05149, magic = 0.500
stress after  30 iters: 0.05101, magic = 0.500
stress after  40 iters: 0.05096, magic = 0.500
$points
           [,1]       [,2]
c1   2.12900041 -1.7255589
c2   0.32144017 -0.4397770
c3   1.09694083  1.2989299
c4   1.90228818  0.3198121
c5   0.09479179 -1.7229204
c6  -2.35619505 -1.2913663
c7  -0.95749355 -0.2635698
c8  -0.08310984  0.6903391
c9  -1.48236001  1.2443252
c10 -0.66530292  1.8897858

$stress
[1] 0.0509611

$call
sammon(d = dist(data), y = jitter(cmdscale(dist(data), 2)))

> 

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Martin Guetlein
> Sent: 4. juli 2014 09:13
> To: r-help at r-project.org
> Subject: [R] sammon fails with duplicates error, but no duplicates there
> (MASS package)
> 
> Hi all,
> 
> the sammon mapping fails with message "initial configuration has
> duplicates". But there are no duplicates in my data (see example
> below).
> Apparently, the problem is that row 9 and 10 have an equal distance to
> all other rows (but they are not equal, see last two columns).
> 
> Any help to get sammon working would be great,
> Kind regards,
> Martin
> 
> 
> library("MASS")
> c1 <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c2 <- c(0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c3 <- c(1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c4 <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c5 <- c(1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c6 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,
> 1, 1, 1, 0, 0)
> c7 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
> 0, 0, 0, 0, 0)
> c8 <- c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0)
> c9 <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 1, 0)
> c10<- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 1)
> # working
> data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9)
> sammon(dist(data))
> # not working:
> data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9,c10)
> sammon(dist(data))
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Jul  4 10:42:26 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 4 Jul 2014 08:42:26 +0000
Subject: [R] Dataframes and text identifier columns
In-Reply-To: <1404382004622-4693443.post@n4.nabble.com>
References: <1404046004960-4693184.post@n4.nabble.com>
	<1404300790321-4693389.post@n4.nabble.com>
	<1404382004622-4693443.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA605@SRVEXCHMBX.precheza.cz>

Hi.

Well, Case is probably factor, which is basically numeric vector with labels. It is useful for some operations but it can have some features which lead to this behaviour. I do not have available your exact code but I presume you use c or cbind somewhere.

> Case<-factor(letters[1:4])
> Case
[1] a b c d
Levels: a b c d
> c(Case, 1)
[1] 1 2 3 4 1
> cbind(Case, rep(1,4))
     Case
[1,]    1 1
[2,]    2 1
[3,]    3 1
[4,]    4 1

You can try to change Case to character by as.character(Case) before cycle.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Brian Willis
> Sent: Thursday, July 03, 2014 12:07 PM
> To: r-help at r-project.org
> Subject: Re: [R] Dataframes and text identifier columns
>
> Thank you for the suggestion
>
> What seems to work is assigning           out_put$Case <-  Inp_dat$Case
> that is
>
> for(i in 1:4)
> {
> ...
> Case<- Inp_dat$Case[i]
> ?
>
> out_put[i,]<-data.frame(Case, stdL, stdPP, stdSE, L, PP, PP_SE)
>
> }
>
> out_put$Case <-  Inp_dat$Case
>
> out_put
>
> What I don't understand is why I need to do this, and why  adding rows
> to out_put[i,] within the loop the Case column has an integer label
> assigned and not the text label.
>
> Further it seems I cannot correct this within the loop?
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Dataframes-
> and-text-identifier-columns-tp4693184p4693443.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Jul  4 10:59:47 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 4 Jul 2014 08:59:47 +0000
Subject: [R] error:max not meaningful for factors
In-Reply-To: <CAE0cxbE3sCKFydYnSOj300D6uRrM9OxsAgcLmH06yN+BjN4zKA@mail.gmail.com>
References: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>
	<3602301.tNus6OuQrx@localhost.localdomain>
	<CAE0cxbE3sCKFydYnSOj300D6uRrM9OxsAgcLmH06yN+BjN4zKA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA61D@SRVEXCHMBX.precheza.cz>

Hi

Not much helpful. Now we know what you ***think*** alpha is but not what it really is.

You shall post at least result of

str(your.objects)

I also wonder why do you populate slots in perf manually and with data.frames instead of lists which are required according to documentation.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Marta valdes lopez
> Sent: Thursday, July 03, 2014 12:35 PM
> To: r-help at r-project.org
> Subject: Re: [R] error:max not meaningful for factors
>
> Thank you Jim for your answer.Ok alpha( it is the speed of the boat) is
> a range of number from 0.5 to 10 like 0.5,1,1.5,2...., I would like to
> have the mean of x and y base on each value of alpha, because I have
> like ten numbers of x for each value of speed, thats why I want the
> mean of that and them i could create the roc plot with the new values.
> I would say that alpha values are ordered already?
>
> Thanks , Marta
>
>
>
> 2014-07-03 1:17 GMT+02:00 Jim Lemon <jim at bitwrit.com.au>:
>
> > On Wed, 2 Jul 2014 02:42:31 PM Marta valdes lopez wrote:
> > > Hello,
> > >
> > > I run this script , because i would like to do the mean of x and y
> > > base
> > on
> > > alpha as factor.
> > >
> > >
> > > library(xlsx)
> > > library(ROCR
> > > filename<-"amanhecer roc.csv"
> > > rocdata<- read.table(filename, sep=";",header=TRUE,dec=",")
> > >
> > > rocdata$alpha.15_12 <- as.factor(rocdata$alpha.15_12)
> > >
> > > TPaverage <- tapply(rocdata$y.15_12, rocdata$alpha.15_12, mean)
> > > FPaverage <- tapply(rocdata$x.15_12, rocdata$alpha.15_12, mean)
> > >
> > > ###And them with the new data i want to create a plot, kind of ROC
> > plot.
> > >
> > >  Anthias<-rocdata
> > >  str(Anthias)
> > > data(ROCR.simple)
> > > pred <- prediction( ROCR.simple$predictions, ROCR.simple$labels )
> > > perf <- performance( pred, "tpr", "fpr" ) windows(width = 9.5,
> > > height = 10.50) par(mfrow = c(1,1))
> > >
> > > cc<-Anthias[1]
> > > ee<-Anthias[2]
> > > aa<-Anthias[3]
> > > perf at x.name<-"FP"
> > > perf at y.name<-"TP"
> > > perf at alpha.name<-"Speed"
> > > bb<-data.frame(aa)
> > > perf at x.values<-bb
> > > dd<-data.frame(cc)
> > > perf at y.values<-dd
> > > ff<-data.frame(ee)
> > > perf at alpha.values<-ff
> > >
> > > plot(perf, main="Teste", colorize=TRUE,
> > coloraxis.at=c(0,2,4,6,8,10),
> > >  coloraxis.cex.axis=0.8, colorize.palette=(rainbow(256,start=0,
> > end=0.7)),
> > > lwd=7, colorkey.relwidth=0.4, yaxis.las=1)
> > >
> > > But after run the whole script i got the error:max not meaningful
> > > for factors, anyone can help me?  I am a beginner in R ,so sorry if
> > > this is wasting anyone's time*.*
> > >
> > Hi Marta,
> > The error message is straightforward. Somewhere in one of the
> > functions you have called, the "max" function is applied to your
> > factor variable. The definition of factor variables is that the the
> > actual values are of nominal class, in which there is no meaningful
> > ordering of values, therefore the maximum value is undefined. You
> > could try as.numeric(alpha), but that is dangerous as it depends on
> > whether the sorting of values (default alphabetic) is what you want.
> > If we knew what "alpha" was, it would help.
> >
> > Jim
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Fri Jul  4 11:04:13 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Jul 2014 11:04:13 +0200
Subject: [R] Fisher Scoring v/s Coordinate Descent for MLE in R
In-Reply-To: <CAAai-LimRGRMzoj-bA_6-tz6j6bQETiO4E_7qq66x6JwrRn8qA@mail.gmail.com>
References: <CAAai-LimRGRMzoj-bA_6-tz6j6bQETiO4E_7qq66x6JwrRn8qA@mail.gmail.com>
Message-ID: <EDC5A835-CF36-44B2-87EC-3984A7E866C3@gmail.com>

There are books on this, can't repeat them here...

Roughly speaking, Fisher Scoring is quadratically convergent, hence requires much fewer iterations than gradient descent methods which are generally only linear, and sometimes very slowly so (in highly collinear cases, usually). I.e., it is a matter of extra work per iterations against more iterations. Besides, glm() wants the information matrix for the variance-covariance matrix of estimates anyway.

-pd

On 03 Jul 2014, at 19:32 , Vijay goel <bgoelv at gmail.com> wrote:

> R base function glm() uses Fishers Scoring for MLE, while the glmnet uses the
> coordinate descent method to solve the same equation ? Coordinate descent is
> more time efficient than Fisher Scoring as fisher scoring calculates the
> second order derivative matrix and some other matrix operation which makes
> it space and time expensive, while coordinate descent can do the same task
> in O(np) time.
> 
> Why R base function uses Fisher Scoring or this method has advantage over
> other optimization methods? What will be comparison between coordinate
> descent and Fisher Scoring ? I am relatively new to do this field so any
> help or resource will be helpful
> 
> Regards
> Vij
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From guetlein at informatik.uni-freiburg.de  Fri Jul  4 11:06:50 2014
From: guetlein at informatik.uni-freiburg.de (Martin Guetlein)
Date: Fri, 4 Jul 2014 11:06:50 +0200
Subject: [R] sammon fails with duplicates error,
 but no duplicates there (MASS package)
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C67C12A2@DKRDSEXC016.vestas.net>
References: <CANjGdQLGiVRLzuAY2OAVBU9zoOnv-LFSAZmokZey6EzvmKtf0w@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C67C12A2@DKRDSEXC016.vestas.net>
Message-ID: <CANjGdQJ4xXLiUhH81XEWN0dYCwAcgz4qPvkPCQsE3KV6WAQVHA@mail.gmail.com>

Hi Frede,

awesome, thanks a lot. Helped me to understand how sammon is working as well.

Martin

On 4 July 2014 10:02, Frede Aakmann T?gersen <frtog at vestas.com> wrote:
> Hi
>
> It seems to be related to the way that the default start values (y argument of sammon) are calculated.
>
> Here the last two rows are the same:
>
>> cmdscale(dist(data), 2)
>            [,1]       [,2]
> c1   2.04910556 -0.3627887
> c2  -0.01889892 -0.1822057
> c3   0.40767629  0.2599026
> c4   0.81569304 -0.4165993
> c5   0.70362596 -0.3573003
> c6  -1.69673266 -1.7209956
> c7  -0.65997449 -0.2888096
> c8  -0.24449262  0.4502489
> c9  -0.67800108  1.3092739
> c10 -0.67800108  1.3092739
>
> Try to perturb the start values using jitter(). Like this
>
>> sammon(dist(data), y = jitter(cmdscale(dist(data), 2)))
> Initial stress        : 0.18304
> stress after  10 iters: 0.07867, magic = 0.092
> stress after  20 iters: 0.05149, magic = 0.500
> stress after  30 iters: 0.05101, magic = 0.500
> stress after  40 iters: 0.05096, magic = 0.500
> $points
>            [,1]       [,2]
> c1   2.12900041 -1.7255589
> c2   0.32144017 -0.4397770
> c3   1.09694083  1.2989299
> c4   1.90228818  0.3198121
> c5   0.09479179 -1.7229204
> c6  -2.35619505 -1.2913663
> c7  -0.95749355 -0.2635698
> c8  -0.08310984  0.6903391
> c9  -1.48236001  1.2443252
> c10 -0.66530292  1.8897858
>
> $stress
> [1] 0.0509611
>
> $call
> sammon(d = dist(data), y = jitter(cmdscale(dist(data), 2)))
>
>>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Martin Guetlein
>> Sent: 4. juli 2014 09:13
>> To: r-help at r-project.org
>> Subject: [R] sammon fails with duplicates error, but no duplicates there
>> (MASS package)
>>
>> Hi all,
>>
>> the sammon mapping fails with message "initial configuration has
>> duplicates". But there are no duplicates in my data (see example
>> below).
>> Apparently, the problem is that row 9 and 10 have an equal distance to
>> all other rows (but they are not equal, see last two columns).
>>
>> Any help to get sammon working would be great,
>> Kind regards,
>> Martin
>>
>>
>> library("MASS")
>> c1 <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c2 <- c(0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c3 <- c(1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c4 <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c5 <- c(1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c6 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,
>> 1, 1, 1, 0, 0)
>> c7 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
>> 0, 0, 0, 0, 0)
>> c8 <- c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0)
>> c9 <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 1, 0)
>> c10<- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 1)
>> # working
>> data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9)
>> sammon(dist(data))
>> # not working:
>> data <- rbind(c1,c2,c3,c4,c5,c6,c7,c8,c9,c10)
>> sammon(dist(data))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Dipl-Inf. Martin G?tlein
Phone:
+49 (0)761 203 8442 (office)
+49 (0)177 623 9499 (mobile)
Email:
guetlein at informatik.uni-freiburg.de


From jim at bitwrit.com.au  Fri Jul  4 11:20:50 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 04 Jul 2014 19:20:50 +1000
Subject: [R] error:max not meaningful for factors
In-Reply-To: <CAE0cxbE3sCKFydYnSOj300D6uRrM9OxsAgcLmH06yN+BjN4zKA@mail.gmail.com>
References: <CAE0cxbEurjoV88JcFA0NidU6mOCwqYMQ=N1KCfT=xeNfWhRzCQ@mail.gmail.com>
	<3602301.tNus6OuQrx@localhost.localdomain>
	<CAE0cxbE3sCKFydYnSOj300D6uRrM9OxsAgcLmH06yN+BjN4zKA@mail.gmail.com>
Message-ID: <2945682.WOI3ZjS2dQ@localhost.localdomain>

On Thu, 3 Jul 2014 12:34:42 PM Marta valdes lopez wrote:
> Thank you Jim for your answer.Ok alpha( it is the speed of the boat) is 
a
> range of number from 0.5 to 10 like 0.5,1,1.5,2...., I would like to have
> the mean of x and y base on each value of alpha, because I have like 
ten
> numbers of x for each value of speed, thats why I want the mean of 
that and
> them i could create the roc plot with the new values.
> I would say that alpha values are ordered already?
> 
> Thanks , Marta
> 
Hi Marta,
The variable "alpha" should be numeric and shouldn't cause the error 
you described. If you get this result:

is.numeric(alpha)
FALSE

then "alpha" has been converted to a factor somehow. This usually 
happens when one or more values of alpha can't be read as a number in 
the read.csv step. It doesn't seem like your dataset is very large, so 
perhaps you could print alpha:

alpha

and see if anything doesn't look like a number. You may be able to track 
this back to the CSV file and correct a typo or something.

Jim


From Guillaume.Tahon at UGent.be  Fri Jul  4 13:25:36 2014
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Fri, 4 Jul 2014 04:25:36 -0700 (PDT)
Subject: [R] How to apply data sets in Vennerable?
Message-ID: <1404473136699-4693516.post@n4.nabble.com>

Hi all,

I finally managed to get Vennerable working with the help I got on the
forum. However, I'm faced with my next challange now.
The easy way to work with Vennerable works just fine, that is, if I enter
code like this:
Vdemo2 <- Venn(SetNames = c("foo", "bar"), Weight = c(`01`= 7, '11' = 8,
'10' = 12))

What I would like to do is the following:
I have sequence data that I need to compare between 3 or 4 samples.
For example sequence 1 is found in samples 1 and 2, sequence 2 is only found
in sample 3, ...
This gives me a list of sequences present in each sample.
I would like to have these lists read in R as input for Vennerable, giving
me a Venn Diagram as output, preferably with weight and colors.
I believe I'd have to do something like this:
Set1 <- c(1,2,3,4,5,6,7,8,9,10)
Set2 <- c(1,2,5,6,11,12,13,14)
Set3 <- c(2,6,11,12,15,16,17)

And afterwards, based on these sets, the matrix has to be generated so I get
a nice plot of my data.

Hopefully anyone can help with this? Your help would be greatly appreciated!


Kind regards,
Guillaume



--
View this message in context: http://r.789695.n4.nabble.com/How-to-apply-data-sets-in-Vennerable-tp4693516.html
Sent from the R help mailing list archive at Nabble.com.


From jhernandezcabrera at gmail.com  Fri Jul  4 14:47:30 2014
From: jhernandezcabrera at gmail.com (Juan Andres Hernandez)
Date: Fri, 4 Jul 2014 13:47:30 +0100
Subject: [R] How to extract convergence code from lmer object?
Message-ID: <CAL79i+T4hjPVWLLR7f196L7N1O76-OGHjpYoZ_E9rJrL04fiUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/263f832e/attachment.pl>

From petr.pikal at precheza.cz  Fri Jul  4 15:32:10 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 4 Jul 2014 13:32:10 +0000
Subject: [R] applying operations within() a matrix's environment
In-Reply-To: <41F61303-C50A-4C0B-9623-4F4156215A42@gmail.com>
References: <B0D6B9F8-0AF6-492E-9EDA-EB7848F306E9@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA5A8@SRVEXCHMBX.precheza.cz>
	<41F61303-C50A-4C0B-9623-4F4156215A42@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA6B2@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/d66efd4b/attachment.pl>

From schubert.seb at gmail.com  Fri Jul  4 13:04:29 2014
From: schubert.seb at gmail.com (Sebastian Schubert)
Date: Fri, 04 Jul 2014 13:04:29 +0200
Subject: [R] Best practice: to factor or not to factor for float variables
Message-ID: <53B68A3D.1050804@gmail.com>

Hi,

I would like to ask for best practice advice on the design of data
structure and the connected analysis techniques.

In my particular case, I have measurements of several variables at
several, sometimes equal, heights. Following the tidy data approach of
Hadley Wickham, I want to put all data in one data frame. In principle,
the height variable is something like a category. For example, I want to
average over time for every height. Using dplyr this works very well
when my height variable is a factor. However, if it is not a factor the
grouping sometimes will not work probably due to numerical issues:

http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-vs-no-factor
https://github.com/hadley/dplyr/issues/482

Even if the behaviour described in the links above is a bug, on can
easily create other numerical issues in R:
> (0.1+0.2) == 0.3
[1] FALSE

Thus, it seems one should avoid grouping by float values and, in my
case, use factors. However, from time to time, I need the numerical
character of the heights: compare heights, find the maximum height, etc.
Here, the ordered factor approach might help. However, I have to combine
(via rbind or merge) different data sets quite often so keeping the
order of the different ordered factor heights also seem to be difficult.

Is there any general approach which reduces the work or do I have to
switch between approaches as needed?

Thanks a lot for any input,
Sebastian


From steve.bellan at gmail.com  Fri Jul  4 13:06:08 2014
From: steve.bellan at gmail.com (Steve Bellan)
Date: Fri, 4 Jul 2014 06:06:08 -0500
Subject: [R] applying operations within() a matrix's environment
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA5A8@SRVEXCHMBX.precheza.cz>
References: <B0D6B9F8-0AF6-492E-9EDA-EB7848F306E9@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA5A8@SRVEXCHMBX.precheza.cz>
Message-ID: <41F61303-C50A-4C0B-9623-4F4156215A42@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/cd5b1f02/attachment.pl>

From joao.patricio at gmx.pt  Fri Jul  4 14:50:53 2014
From: joao.patricio at gmx.pt (=?ISO-8859-1?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Fri, 04 Jul 2014 13:50:53 +0100
Subject: [R] Transform a data.frame with ";
 " sep column and another one in a a new one with the same two
 column but with repetitions
Message-ID: <53B6A32D.4000506@gmx.pt>

Hi,

I've been trying to solve this issue but with no success.

I have some data like this:

1 > TC	WC
2 > 0	Instruments & Instrumentation; Nuclear Science & Technology; 
Physics, Particles & Fields; Spectroscopy
3 > 0	Nanoscience & Nanotechnology; Materials Science, 
Multidisciplinary; Physics, Applied
4 > 2	Physics, Nuclear; Physics, Particles & Fields
5 > 0	Chemistry, Inorganic & Nuclear
6 > 2	Chemistry, Physical; Materials Science, Multidisciplinary; 
Metallurgy & Metallurgical Engineering

And I need to have this:

1 > TC	WC
2 > 0	Instruments & Instrumentation
2 > 0	Nuclear Science & Technology
2 > 0	Physics, Particles & Fields
2 > 0	Spectroscopy
3 > 0	Nanoscience & Nanotechnology
3 > 0	Materials Science, Multidisciplinary
3 > 0	Physics, Applied
4 > 2	Physics, Nuclear
4 > 2	Physics, Particles & Fields
5 > 0	Chemistry, Inorganic & Nuclear
6 > 2	Chemistry, Physical
6 > 2	Materials Science, Multidisciplinary
6 > 2	Metallurgy & Metallurgical Engineering

This means repeat the row for each element in WC and keeping the same 
value in TC. The goal is to check how many TC (sum) there are by WC, 
when WC is multiple.

i've tried to separate the column using strsplt but then I cannot keep 
the track of TC.

thanks in advance.
-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From gangchen6 at gmail.com  Fri Jul  4 16:17:25 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 04 Jul 2014 10:17:25 -0400
Subject: [R] Display a dataframe
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F7BECF@mb02.ads.tamu.edu>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F7BECF@mb02.ads.tamu.edu>
Message-ID: <165e1679-ac75-47b9-80d4-0daaf3077ce6@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/4da1e924/attachment.pl>

From petr.pikal at precheza.cz  Fri Jul  4 16:26:07 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 4 Jul 2014 14:26:07 +0000
Subject: [R] Best practice: to factor or not to factor for float
 variables
In-Reply-To: <53B68A3D.1050804@gmail.com>
References: <53B68A3D.1050804@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDA6FD@SRVEXCHMBX.precheza.cz>

Hi

I would keep height as numeric and created height.f as factor, maybe ordered.

> hh<-runif(50)
> hh
 [1] 0.116060220 0.447546370 0.433749570 0.006548963 0.425710667 0.328972894
 [7] 0.091274539 0.271797166 0.007669982 0.208922146 0.168174196 0.227466231
...
hh.f<-cut(hh, seq(0,1,.1))
> hh.f
 [1] (0.1,0.2] (0.4,0.5] (0.4,0.5] (0,0.1]   (0.4,0.5] (0.3,0.4] (0,0.1]
 [8] (0.2,0.3] (0,0.1]   (0.2,0.3] (0.1,0.2] (0.2,0.3] (0.8,0.9] (0.2,0.3]
...
10 Levels: (0,0.1] (0.1,0.2] (0.2,0.3] (0.3,0.4] (0.4,0.5] ... (0.9,1]
> boxplot(split(hh, hh.f))
> aggregate(hh, list(hh.f), mean)
     Group.1          x
1    (0,0.1] 0.04679132
2  (0.1,0.2] 0.14659980
3  (0.2,0.3] 0.24458350
4  (0.3,0.4] 0.34881489
5  (0.4,0.5] 0.45444531
6  (0.5,0.6] 0.50291886
7  (0.6,0.7] 0.66860900
8  (0.7,0.8] 0.76984008
9  (0.8,0.9] 0.85753777
10   (0.9,1] 0.95682747
>

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Sebastian Schubert
> Sent: Friday, July 04, 2014 1:04 PM
> To: r-help at r-project.org
> Subject: [R] Best practice: to factor or not to factor for float
> variables
>
> Hi,
>
> I would like to ask for best practice advice on the design of data
> structure and the connected analysis techniques.
>
> In my particular case, I have measurements of several variables at
> several, sometimes equal, heights. Following the tidy data approach of
> Hadley Wickham, I want to put all data in one data frame. In principle,
> the height variable is something like a category. For example, I want
> to average over time for every height. Using dplyr this works very well
> when my height variable is a factor. However, if it is not a factor the
> grouping sometimes will not work probably due to numerical issues:
>
> http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-
> vs-no-factor
> https://github.com/hadley/dplyr/issues/482
>
> Even if the behaviour described in the links above is a bug, on can
> easily create other numerical issues in R:
> > (0.1+0.2) == 0.3
> [1] FALSE
>
> Thus, it seems one should avoid grouping by float values and, in my
> case, use factors. However, from time to time, I need the numerical
> character of the heights: compare heights, find the maximum height,
> etc.
> Here, the ordered factor approach might help. However, I have to
> combine (via rbind or merge) different data sets quite often so keeping
> the order of the different ordered factor heights also seem to be
> difficult.
>
> Is there any general approach which reduces the work or do I have to
> switch between approaches as needed?
>
> Thanks a lot for any input,
> Sebastian
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From gangchen6 at gmail.com  Fri Jul  4 16:27:37 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 04 Jul 2014 10:27:37 -0400
Subject: [R] Display a dataframe
In-Reply-To: <1404439020.26963.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
	<1404439020.26963.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <201005aa-8dae-4cf4-b9e6-808aa40fa97c@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/30c9fd84/attachment.pl>

From h.wickham at gmail.com  Fri Jul  4 17:33:34 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 4 Jul 2014 08:33:34 -0700
Subject: [R] Best practice: to factor or not to factor for float
	variables
In-Reply-To: <53B68A3D.1050804@gmail.com>
References: <53B68A3D.1050804@gmail.com>
Message-ID: <CABdHhvHB4imJ0JMyG0eu1aHfV129KO4EwsbaQLHaDTP7ySrPwg@mail.gmail.com>

Why not just round the floating point numbers to ensure they're equal
with zapsmall, round or signif?

Hadley

On Fri, Jul 4, 2014 at 4:04 AM, Sebastian Schubert
<schubert.seb at gmail.com> wrote:
> Hi,
>
> I would like to ask for best practice advice on the design of data
> structure and the connected analysis techniques.
>
> In my particular case, I have measurements of several variables at
> several, sometimes equal, heights. Following the tidy data approach of
> Hadley Wickham, I want to put all data in one data frame. In principle,
> the height variable is something like a category. For example, I want to
> average over time for every height. Using dplyr this works very well
> when my height variable is a factor. However, if it is not a factor the
> grouping sometimes will not work probably due to numerical issues:
>
> http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-vs-no-factor
> https://github.com/hadley/dplyr/issues/482
>
> Even if the behaviour described in the links above is a bug, on can
> easily create other numerical issues in R:
>> (0.1+0.2) == 0.3
> [1] FALSE
>
> Thus, it seems one should avoid grouping by float values and, in my
> case, use factors. However, from time to time, I need the numerical
> character of the heights: compare heights, find the maximum height, etc.
> Here, the ordered factor approach might help. However, I have to combine
> (via rbind or merge) different data sets quite often so keeping the
> order of the different ordered factor heights also seem to be difficult.
>
> Is there any general approach which reduces the work or do I have to
> switch between approaches as needed?
>
> Thanks a lot for any input,
> Sebastian
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From dwinsemius at comcast.net  Fri Jul  4 19:18:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 4 Jul 2014 10:18:48 -0700
Subject: [R] Best practice: to factor or not to factor for float
	variables
In-Reply-To: <CABdHhvHB4imJ0JMyG0eu1aHfV129KO4EwsbaQLHaDTP7ySrPwg@mail.gmail.com>
References: <53B68A3D.1050804@gmail.com>
	<CABdHhvHB4imJ0JMyG0eu1aHfV129KO4EwsbaQLHaDTP7ySrPwg@mail.gmail.com>
Message-ID: <0A40A894-9188-445F-A462-AC777D8F04C4@comcast.net>

Keep as numeric and group with cut(), Hmisc::cut2, or findInterval. The beauty of the functional language design is that you do not need to create a new factor variable.

-- 
David

Sent from my iPhone

> On Jul 4, 2014, at 8:33 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> Why not just round the floating point numbers to ensure they're equal
> with zapsmall, round or signif?
> 
> Hadley
> 
> On Fri, Jul 4, 2014 at 4:04 AM, Sebastian Schubert
> <schubert.seb at gmail.com> wrote:
>> Hi,
>> 
>> I would like to ask for best practice advice on the design of data
>> structure and the connected analysis techniques.
>> 
>> In my particular case, I have measurements of several variables at
>> several, sometimes equal, heights. Following the tidy data approach of
>> Hadley Wickham, I want to put all data in one data frame. In principle,
>> the height variable is something like a category. For example, I want to
>> average over time for every height. Using dplyr this works very well
>> when my height variable is a factor. However, if it is not a factor the
>> grouping sometimes will not work probably due to numerical issues:
>> 
>> http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-vs-no-factor
>> https://github.com/hadley/dplyr/issues/482
>> 
>> Even if the behaviour described in the links above is a bug, on can
>> easily create other numerical issues in R:
>>> (0.1+0.2) == 0.3
>> [1] FALSE
>> 
>> Thus, it seems one should avoid grouping by float values and, in my
>> case, use factors. However, from time to time, I need the numerical
>> character of the heights: compare heights, find the maximum height, etc.
>> Here, the ordered factor approach might help. However, I have to combine
>> (via rbind or merge) different data sets quite often so keeping the
>> order of the different ordered factor heights also seem to be difficult.
>> 
>> Is there any general approach which reduces the work or do I have to
>> switch between approaches as needed?
>> 
>> Thanks a lot for any input,
>> Sebastian
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> http://had.co.nz/
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgoelv at gmail.com  Fri Jul  4 20:55:27 2014
From: bgoelv at gmail.com (Vijay goel)
Date: Sat, 5 Jul 2014 00:25:27 +0530
Subject: [R] Training and testing on Unbalanced Data Set
Message-ID: <CAAai-LhA1zB0wTpvmOZUoZZENe6PrDLU4ib-KPa+AHm8R9R+8w@mail.gmail.com>

I used SMOTE algorithm in R for class balancing. My data size has
13000 rows, I had 7% minority class in my sample now I used SMOTE(
Synthetic Minority Oversampling Technique) for class balancing such
that I raised the ration of minority class to 42 % and number of rows
in data sample becomes 12655, Now I need to fit a logistic regression
on my data set for that I need to divide the sample for cross
validation and testing. I tried two approach :

a.) train my data on sample obtained after SMOTE and tested on the
original sample having 13000 rows.

b.) divide the sample obtained after SMOTE into train and test and do
the fitting and testing on this data set only

In first approach my results might get skewed so which approach should
I take and Why ?
-- 
Vijay Goel
*+91-7501378852*


From wewolski at gmail.com  Fri Jul  4 23:44:34 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Fri, 4 Jul 2014 23:44:34 +0200
Subject: [R] data.table merge question...
Message-ID: <CAAjnpdiwoQjjVjwGnWXONFjd9jUrVJOKLsyExK_RyrFyuNxVtg@mail.gmail.com>

Actually the question is regarding differences in behaviour on windows in linux.
The 2 lines of code produce on linux all TRUE ....
on windows this looks "heterogenous"...

Using merge.data.frame produces on all platforms TRUE ...


> msexp$pepinfo = data.frame(merge(tt,msexp$pepinfo,by="transition_group_id"),stringsAsFactors=FALSE)
> tt$transition_group_id == msexp$pepinfo$transition_group_id

  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
 [23]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
 [45]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
 [67] FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
 [89] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[111] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE ...


-- 
Witold Eryk Wolski


From wewolski at gmail.com  Sat Jul  5 00:35:00 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sat, 5 Jul 2014 00:35:00 +0200
Subject: [R] how does a valid subscript can produce an "subscript out of
	bounds" error?
Message-ID: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>

how does a valid subscript (see first 2 lines) can produce an
"subscript out of bounds" error (see line 4)?


1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
[1] 0
2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
[1] 0
3> class(msexp$rt)
[1] "matrix"
4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
  subscript out of bounds
>

-- 
Witold Eryk Wolski


From murdoch.duncan at gmail.com  Sat Jul  5 01:50:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Jul 2014 19:50:51 -0400
Subject: [R] how does a valid subscript can produce an "subscript out of
 bounds" error?
In-Reply-To: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
References: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
Message-ID: <53B73DDB.6090204@gmail.com>

On 04/07/2014, 6:35 PM, Witold E Wolski wrote:
> how does a valid subscript (see first 2 lines) can produce an
> "subscript out of bounds" error (see line 4)?
> 
> 
> 1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
> [1] 0
> 2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
> [1] 0
> 3> class(msexp$rt)
> [1] "matrix"
> 4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
> Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
>   subscript out of bounds
>>
> 

How are we supposed to know, since you didn't show us

msexp$pepinfo$transition_group_id

or the thing it was indexing,

msexp$rt

?  Please post reproducible examples.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Jul  5 02:18:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Jul 2014 20:18:08 -0400
Subject: [R] how does a valid subscript can produce an "subscript out of
 bounds" error?
In-Reply-To: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
References: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
Message-ID: <53B74440.5000708@gmail.com>

On 04/07/2014, 6:35 PM, Witold E Wolski wrote:
> how does a valid subscript (see first 2 lines) can produce an
> "subscript out of bounds" error (see line 4)?
> 
> 
> 1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
> [1] 0
> 2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
> [1] 0
> 3> class(msexp$rt)
> [1] "matrix"
> 4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
> Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
>   subscript out of bounds
>>
> 

> x <- matrix(1,1,1)
> rownames(x) <- colnames(x) <- "23"
> 23 %in% rownames(x)
[1] TRUE
> x[23,]
Error in x[23, ] : subscript out of bounds


From dwinsemius at comcast.net  Sat Jul  5 03:42:15 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 4 Jul 2014 18:42:15 -0700
Subject: [R] Display a dataframe
In-Reply-To: <201005aa-8dae-4cf4-b9e6-808aa40fa97c@email.android.com>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
	<1404439020.26963.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<201005aa-8dae-4cf4-b9e6-808aa40fa97c@email.android.com>
Message-ID: <BDCE22A4-5003-4314-89B1-EF6BBAC08D8B@comcast.net>


On Jul 4, 2014, at 7:27 AM, Gang Chen wrote:

> I really your kind help! This is exactly what I was looking for  
> except that I need to get rid of the numbered row names.
>

Look at the documentation:

?print.data.frame

You cannot "get rid of" rownames in dataframes (at least as far as I  
know) but you _can_ print them without rownames.


-- 
David

> On July 3, 2014 9:57:00 PM EDT, arun <smartpink111 at yahoo.com> wrote:
>> Hi,
>> May be this helps:
>> nC <- max(nchar(row.names(dd)))
>>  term <- formatC(row.names(dd), width=-nC)
>> #or
>>  term <- sprintf("%-11s", row.names(dd))
>>
>>   dd1 <- setNames(data.frame(unname(dd), term,stringsAsFactors=F),
>> c(colnames(dd), formatC("term",width=-nC)))
>> dd1
>> #      # Chisq DF   Pr(>Chisq) term
>> #1 153.0216306  1 7.578366e-35 # Sex
>> #2  13.3696538  1 5.114571e-04 # Volume
>> #3   0.8476713  1 7.144239e-01 # Weight
>> #4   1.2196050  1 5.388764e-01 # Intensity
>> #5   2.6349405  1 2.090719e-01 # ISO
>> #6   6.0507714  1 2.780045e-02 # SEC
>>
>> A.K.
>>
>>
>>
>>
>>
>> On Thursday, July 3, 2014 3:57 PM, Gang Chen <gangchen6 at gmail.com>
>> wrote:
>> I have a matrix 'dd' defined as below:
>>
>> dd <- t(matrix(c(153.0216306,  1, 7.578366e-35,
>> 13.3696538,  1, 5.114571e-04,
>> 0.8476713,  1, 7.144239e-01,
>> 1.2196050,  1, 5.388764e-01,
>> 2.6349405,  1, 2.090719e-01,
>> 6.0507714,  1, 2.780045e-02), nrow=3, ncol=6))
>> dimnames(dd)[[2]] <- c('# Chisq', 'DF', 'Pr(>Chisq)')
>> dimnames(dd)[[1]] <- c('# Sex', '# Volume', '# Weight', '#  
>> Intensity',
>> '# ISO', '# SEC')
>>
>> 'dd' displays as the following:
>>
>>                 # Chisq DF   Pr(>Chisq)
>> # Sex       153.0216306  1 7.578366e-35
>> # Volume     13.3696538  1 5.114571e-04
>> # Weight      0.8476713  1 7.144239e-01
>> # Intensity   1.2196050  1 5.388764e-01
>> # ISO         2.6349405  1 2.090719e-01
>> # SEC         6.0507714  1 2.780045e-02
>>
>> I would like to display it as:
>>
>> # Chisq               DF   Pr(>Chisq)                        term
>> 153.0216306  1 7.578366e-35                            # Sex
>> 13.3696538  1 5.114571e-04                              # Volume
>> 0.8476713  1 7.144239e-01                                # Weight
>> 1.2196050  1 5.388764e-01                                # Intensity
>> 2.6349405  1 2.090719e-01                                # ISO
>> 6.0507714  1 2.780045e-02                                # SEC
>>
>> This is what I came up with
>>
>> (cc <- data.frame(data.frame(dd), term=dimnames(dd)[[1]]))
>>
>>                X..Chisq DF   Pr..Chisq.        term
>> # Sex       153.0216306  1 7.578366e-35       # Sex
>> # Volume     13.3696538  1 5.114571e-04    # Volume
>> # Weight      0.8476713  1 7.144239e-01    # Weight
>> # Intensity   1.2196050  1 5.388764e-01 # Intensity
>> # ISO         2.6349405  1 2.090719e-01       # ISO
>> # SEC         6.0507714  1 2.780045e-02       # SEC
>>
>> But I'm not happy with the following two issues:
>>
>> 1) How to get rid of the row names?
>> 2) The special characters of #, (, >,) in the column names are not
>> displayed correctly.
>>
>> Any suggestions?
>>
>> Thanks,
>> Gang


David Winsemius, MD
Alameda, CA, USA


From ambiz27 at hotmail.com  Fri Jul  4 17:12:41 2014
From: ambiz27 at hotmail.com (Anne-Marie B.)
Date: Fri, 4 Jul 2014 15:12:41 +0000
Subject: [R] Rugarch package: arfimaspec and arfimafit
Message-ID: <BLU184-W528FFAE7BBE28911A234A6B7000@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/0fbdc404/attachment.pl>

From smartpink111 at yahoo.com  Fri Jul  4 16:15:49 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Jul 2014 07:15:49 -0700
Subject: [R] Transform a data.frame with ";
	" sep column and another one in a a new one with the same two
	column but with repetitions
In-Reply-To: <53B6A32D.4000506@gmx.pt>
References: <53B6A32D.4000506@gmx.pt>
Message-ID: <1404483349.44950.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
Try:
dat1 <- read.table(text="'1 > TC' 'WC'
'2 > 0'? 'Instruments & Instrumentation; Nuclear Science & Technology;Physics, Particles & Fields; Spectroscopy'
'3 > 0' 'Nanoscience & Nanotechnology; Materials Science,Multidisciplinary; Physics, Applied'
'4 > 2'??? 'Physics, Nuclear; Physics, Particles & Fields'
'5 > 0'??? 'Chemistry, Inorganic & Nuclear'
'6 > 2'??? 'Chemistry, Physical; Materials Science, Multidisciplinary;Metallurgy & Metallurgical Engineering'",sep="",header=F, stringsAsFactors=F)

library(data.table)
Using `cSplit()` from
https://gist.github.com/mrdwab/11380733

cSplit(dat1, "V2", ";", "long")
??????? V1???????????????????????????????????? V2
?1: 1 > TC???????????????????????????????????? WC
?2:? 2 > 0????????? Instruments & Instrumentation
?3:? 2 > 0?????????? Nuclear Science & Technology
?4:? 2 > 0??????????? Physics, Particles & Fields
?5:? 2 > 0?????????????????????????? Spectroscopy
?6:? 3 > 0?????????? Nanoscience & Nanotechnology
?7:? 3 > 0??? Materials Science,Multidisciplinary
?8:? 3 > 0?????????????????????? Physics, Applied
?9:? 4 > 2?????????????????????? Physics, Nuclear
10:? 4 > 2??????????? Physics, Particles & Fields
11:? 5 > 0???????? Chemistry, Inorganic & Nuclear
12:? 6 > 2??????????????????? Chemistry, Physical
13:? 6 > 2?? Materials Science, Multidisciplinary
14:? 6 > 2 Metallurgy & Metallurgical Engineering



A.K.


On Friday, July 4, 2014 9:53 AM, Jo?o Azevedo Patr?cio <joao.patricio at gmx.pt> wrote:
Hi,

I've been trying to solve this issue but with no success.

I have some data like this:

1 > TC??? WC
2 > 0??? Instruments & Instrumentation; Nuclear Science & Technology; 
Physics, Particles & Fields; Spectroscopy
3 > 0??? Nanoscience & Nanotechnology; Materials Science, 
Multidisciplinary; Physics, Applied
4 > 2??? Physics, Nuclear; Physics, Particles & Fields
5 > 0??? Chemistry, Inorganic & Nuclear
6 > 2??? Chemistry, Physical; Materials Science, Multidisciplinary; 
Metallurgy & Metallurgical Engineering

And I need to have this:

1 > TC??? WC
2 > 0??? Instruments & Instrumentation
2 > 0??? Nuclear Science & Technology
2 > 0??? Physics, Particles & Fields
2 > 0??? Spectroscopy
3 > 0??? Nanoscience & Nanotechnology
3 > 0??? Materials Science, Multidisciplinary
3 > 0??? Physics, Applied
4 > 2??? Physics, Nuclear
4 > 2??? Physics, Particles & Fields
5 > 0??? Chemistry, Inorganic & Nuclear
6 > 2??? Chemistry, Physical
6 > 2??? Materials Science, Multidisciplinary
6 > 2??? Metallurgy & Metallurgical Engineering

This means repeat the row for each element in WC and keeping the same 
value in TC. The goal is to check how many TC (sum) there are by WC, 
when WC is multiple.

i've tried to separate the column using strsplt but then I cannot keep 
the track of TC.

thanks in advance.
-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From schubert.seb at gmail.com  Fri Jul  4 21:38:59 2014
From: schubert.seb at gmail.com (Sebastian Schubert)
Date: Fri, 04 Jul 2014 21:38:59 +0200
Subject: [R] Best practice: to factor or not to factor for float
	variables
In-Reply-To: <CABdHhvHB4imJ0JMyG0eu1aHfV129KO4EwsbaQLHaDTP7ySrPwg@mail.gmail.com>
References: <53B68A3D.1050804@gmail.com>
	<CABdHhvHB4imJ0JMyG0eu1aHfV129KO4EwsbaQLHaDTP7ySrPwg@mail.gmail.com>
Message-ID: <53B702D3.5070200@gmail.com>

Hi Hadley,

actually, I started with floating point numbers, ensured that the
respective numbers are equal in R but I still got strange behaviour with
dplyr's group_by:

https://github.com/hadley/dplyr/issues/482

If I had to guess, I would suppose the source of this error somewhere in
the C++ part of dplyr. This happened only on one machine I have
available. Whether this is a bug in dplyr, or in the older machine's
libraries, or not a bug at all, I cannot say. Nonetheless, this
confirmed my feelings about avoiding floating point numbers in this
context and lead me to ask for advice here...

Sebastian

Am 04.07.2014 17:33, schrieb Hadley Wickham:
> Why not just round the floating point numbers to ensure they're equal
> with zapsmall, round or signif?
> 
> Hadley
> 
> On Fri, Jul 4, 2014 at 4:04 AM, Sebastian Schubert
> <schubert.seb at gmail.com> wrote:
>> Hi,
>>
>> I would like to ask for best practice advice on the design of data
>> structure and the connected analysis techniques.
>>
>> In my particular case, I have measurements of several variables at
>> several, sometimes equal, heights. Following the tidy data approach of
>> Hadley Wickham, I want to put all data in one data frame. In principle,
>> the height variable is something like a category. For example, I want to
>> average over time for every height. Using dplyr this works very well
>> when my height variable is a factor. However, if it is not a factor the
>> grouping sometimes will not work probably due to numerical issues:
>>
>> http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-vs-no-factor
>> https://github.com/hadley/dplyr/issues/482
>>
>> Even if the behaviour described in the links above is a bug, on can
>> easily create other numerical issues in R:
>>> (0.1+0.2) == 0.3
>> [1] FALSE
>>
>> Thus, it seems one should avoid grouping by float values and, in my
>> case, use factors. However, from time to time, I need the numerical
>> character of the heights: compare heights, find the maximum height, etc.
>> Here, the ordered factor approach might help. However, I have to combine
>> (via rbind or merge) different data sets quite often so keeping the
>> order of the different ordered factor heights also seem to be difficult.
>>
>> Is there any general approach which reduces the work or do I have to
>> switch between approaches as needed?
>>
>> Thanks a lot for any input,
>> Sebastian
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From joao.patricio at gmx.pt  Fri Jul  4 17:00:44 2014
From: joao.patricio at gmx.pt (=?ISO-8859-1?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Fri, 04 Jul 2014 16:00:44 +0100
Subject: [R] Transform a data.frame with ";
 " sep column and another one in a a new one with the same two
 column but with repetitions
In-Reply-To: <1404483349.44950.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <53B6A32D.4000506@gmx.pt>
	<1404483349.44950.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <53B6C19C.6080706@gmx.pt>

Em 04-07-2014 15:15, arun escreveu:
>
> Hi,
> Try:
> dat1 <- read.table(text="'1 > TC' 'WC'
> '2 > 0'  'Instruments & Instrumentation; Nuclear Science & Technology;Physics, Particles & Fields; Spectroscopy'
> '3 > 0' 'Nanoscience & Nanotechnology; Materials Science,Multidisciplinary; Physics, Applied'
> '4 > 2'    'Physics, Nuclear; Physics, Particles & Fields'
> '5 > 0'    'Chemistry, Inorganic & Nuclear'
> '6 > 2'    'Chemistry, Physical; Materials Science, Multidisciplinary;Metallurgy & Metallurgical Engineering'",sep="",header=F, stringsAsFactors=F)
>
> library(data.table)
> Using `cSplit()` from
> https://gist.github.com/mrdwab/11380733
>
> cSplit(dat1, "V2", ";", "long")
>          V1                                     V2
>   1: 1 > TC                                     WC
>   2:  2 > 0          Instruments & Instrumentation
>   3:  2 > 0           Nuclear Science & Technology
>   4:  2 > 0            Physics, Particles & Fields
>   5:  2 > 0                           Spectroscopy
>   6:  3 > 0           Nanoscience & Nanotechnology
>   7:  3 > 0    Materials Science,Multidisciplinary
>   8:  3 > 0                       Physics, Applied
>   9:  4 > 2                       Physics, Nuclear
> 10:  4 > 2            Physics, Particles & Fields
> 11:  5 > 0         Chemistry, Inorganic & Nuclear
> 12:  6 > 2                    Chemistry, Physical
> 13:  6 > 2   Materials Science, Multidisciplinary
> 14:  6 > 2 Metallurgy & Metallurgical Engineering
>
>
>
> A.K.
>
>
> On Friday, July 4, 2014 9:53 AM, Jo?o Azevedo Patr?cio <joao.patricio at gmx.pt> wrote:
> Hi,
>
> I've been trying to solve this issue but with no success.
>
> I have some data like this:
>
> 1 > TC    WC
> 2 > 0    Instruments & Instrumentation; Nuclear Science & Technology;
> Physics, Particles & Fields; Spectroscopy
> 3 > 0    Nanoscience & Nanotechnology; Materials Science,
> Multidisciplinary; Physics, Applied
> 4 > 2    Physics, Nuclear; Physics, Particles & Fields
> 5 > 0    Chemistry, Inorganic & Nuclear
> 6 > 2    Chemistry, Physical; Materials Science, Multidisciplinary;
> Metallurgy & Metallurgical Engineering
>
> And I need to have this:
>
> 1 > TC    WC
> 2 > 0    Instruments & Instrumentation
> 2 > 0    Nuclear Science & Technology
> 2 > 0    Physics, Particles & Fields
> 2 > 0    Spectroscopy
> 3 > 0    Nanoscience & Nanotechnology
> 3 > 0    Materials Science, Multidisciplinary
> 3 > 0    Physics, Applied
> 4 > 2    Physics, Nuclear
> 4 > 2    Physics, Particles & Fields
> 5 > 0    Chemistry, Inorganic & Nuclear
> 6 > 2    Chemistry, Physical
> 6 > 2    Materials Science, Multidisciplinary
> 6 > 2    Metallurgy & Metallurgical Engineering
>
> This means repeat the row for each element in WC and keeping the same
> value in TC. The goal is to check how many TC (sum) there are by WC,
> when WC is multiple.
>
> i've tried to separate the column using strsplt but then I cannot keep
> the track of TC.
>
> thanks in advance.
Thanks is simply fantastic!
After that I just have to do an aggregate by WC and it gives me the n of 
TC by WC.

thanks!

my code looks like this:

isi <- read.table("filename", header = TRUE, sep=";") ##get citations 
and web of science categories file
cSplit(isi, "WC", ";", "long") ## split by WC
isisplit <- cSplit(isi, "WC", ";", "long") ## create file with split WC info
wccitations <- aggregate (isisplit$TC, by=list(Category=isisplit$WC), 
FUN = sum) ## creates a table with the list of WCategories and the 
specific citations sum for  each
wcproduction <- table(isisplit$WC) ## creates a table with the number of 
pubs by WCategories

-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From johnson.cheryl625 at gmail.com  Fri Jul  4 19:00:17 2014
From: johnson.cheryl625 at gmail.com (Cheryl Johnson)
Date: Fri, 4 Jul 2014 13:00:17 -0400
Subject: [R] Calling Matrices from a Function
Message-ID: <CAJJ9dtuYuxpPLwVfoew6fQ8wMb4ETykPyo+FtfMHeTO-f-Nx6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140704/2159bf35/attachment.pl>

From smartpink111 at yahoo.com  Fri Jul  4 20:18:25 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Jul 2014 11:18:25 -0700
Subject: [R] Display a dataframe
In-Reply-To: <201005aa-8dae-4cf4-b9e6-808aa40fa97c@email.android.com>
References: <CAHmzXO5Yfy2QVmudk+=yj0=9T9C7SGvqamok2JO-U-B=1PasxQ@mail.gmail.com>
	<1404439020.26963.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<201005aa-8dae-4cf4-b9e6-808aa40fa97c@email.android.com>
Message-ID: <1404497905.97532.YahooMailNeo@web142602.mail.bf1.yahoo.com>

You can use:
print(dd1, row.names=F)
??? # Chisq DF?? Pr(>Chisq) term?????? 
?153.0216306? 1 7.578366e-35 # Sex????? 
? 13.3696538? 1 5.114571e-04 # Volume?? 
?? 0.8476713? 1 7.144239e-01 # Weight?? 
?? 1.2196050? 1 5.388764e-01 # Intensity
?? 2.6349405? 1 2.090719e-01 # ISO????? 
?? 6.0507714? 1 2.780045e-02 # SEC????? 

A.K.





On Friday, July 4, 2014 10:27 AM, Gang Chen <gangchen6 at gmail.com> wrote:



I really your kind help! This is exactly what I was looking for except that I need to get rid of the numbered row names.


On July 3, 2014 9:57:00 PM EDT, arun <smartpink111 at yahoo.com> wrote:
Hi,
>May be this helps:
>nC <- max(nchar(row.names(dd)))
>?term <- formatC(row.names(dd), width=-nC)
>#or
>?term <- sprintf("%-11s", row.names(dd))
>
>? dd1 <- setNames(data.frame(unname(dd), term,stringsAsFactors=F), c(colnames(dd), formatC("term",width=-nC)))
>dd1
>#????? # Chisq DF?? Pr(>Chisq) term?????? 
>#1 153.0216306? 1 7.578366e-35 # Sex????? 
>#2? 13.3696538? 1 5.114571e-04 # Volume?? 
>#3?? 0.8476713? 1 7.144239e-01 # Weight?? 
>#4?? 1.2196050? 1 5.388764e-01 # Intensity
>#5?? 2.6349405? 1 2.090719e-01 # ISO????? 
>#6?? 6.0507714? 1 2.780045e-02 # SEC????? 
>
>A.K.
>
>
>
>
>
>On Thursday, July 3, 2014 3:57 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>I have a matrix 'dd' defined as below:
>
>dd <- t(matrix(c(153.0216306,? 1, 7.578366e-35,
>13.3696538,? 1, 5.114571e-04,
>0.8476713,? 1, 7.144239e-01,
>1.2196050,? 1, 5.388764e-01,
>2.6349405,? 1, 2.090719e-01,
>6.0507714,? 1, 2.780045e-02), nrow=3, ncol=6))
>dimnames(dd)[[2]] <- c('# Chisq', 'DF', 'Pr(>Chisq)')
>dimnames(dd)[[1]] <- c('# Sex', '# Volume', '# Weight', '# Intensity',
>'# ISO', '# SEC')
>
>'dd' displays as the following:
>
>? ? ? ? ? ? ? ? # Chisq DF???Pr(>Chisq)
># Sex? ? ???153.0216306? 1 7.578366e-35
># Volume? ???13.3696538? 1 5.114571e-04
># Weight? ? ? 0.8476713? 1 7.144239e-01
># Intensity???1.2196050? 1 5.388764e-01
># ISO? ? ? ???2.6349405? 1 2.090719e-01
># SEC? ? ? ???6.0507714? 1 2.780045e-02
>
>I would like to display it as:
>
># Chisq? ? ? ? ? ? ???DF???Pr(>Chisq)? ? ? ? ? ? ? ? ? ? ? ? term
>153.0216306? 1 7.578366e-35? ? ? ? ? ? ? ? ? ? ? ? ? ? # Sex
>13.3696538? 1 5.114571e-04? ? ? ? ? ? ?
? ? ? ? ? ? ? ? # Volume
>0.8476713? 1 7.144239e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # Weight
>1.2196050? 1 5.388764e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # Intensity
>2.6349405? 1 2.090719e-01? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # ISO
>6.0507714? 1 2.780045e-02? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # SEC
>
>This is what I came up with
>
>(cc <- data.frame(data.frame(dd), term=dimnames(dd)[[1]]))
>
>? ? ? ? ? ? ???X..Chisq DF???Pr..Chisq.? ? ? ? term
># Sex? ? ???153.0216306? 1 7.578366e-35? ? ???# Sex
># Volume? ???13.3696538? 1 5.114571e-04? ? # Volume
># Weight? ? ? 0.8476713? 1 7.144239e-01? ? # Weight
># Intensity???1.2196050? 1 5.388764e-01 # Intensity
># ISO? ? ? ???2.6349405? 1 2.090719e-01? ? ???# ISO
># SEC? ? ? ???6.0507714? 1 2.780045e-02? ? ???# SEC
>
>But I'm not happy with the following
two issues:
>
>1) How to get rid of the row names?
>2) The special characters of #, (, >,) in the column names are not
>displayed correctly.
>
>Any suggestions?
>
>Thanks,
>Gang
>
>
>________________________________
>
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From john.archie.mckown at gmail.com  Sat Jul  5 04:35:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 4 Jul 2014 21:35:58 -0500
Subject: [R] Transform a data.frame with ";
 " sep column and another one in a a new one with the same two
 column but with repetitions
In-Reply-To: <53B6A32D.4000506@gmx.pt>
References: <53B6A32D.4000506@gmx.pt>
Message-ID: <CAAJSdjg7NpjPmm6uDoNAteBBwL-=sVW=XoQmuiSuN+r-2aN7Zw@mail.gmail.com>

On Fri, Jul 4, 2014 at 7:50 AM, Jo?o Azevedo Patr?cio
<joao.patricio at gmx.pt> wrote:
> Hi,
>
> I've been trying to solve this issue but with no success.
>
> I have some data like this:
>
> 1 > TC  WC
> 2 > 0   Instruments & Instrumentation; Nuclear Science & Technology;
> Physics, Particles & Fields; Spectroscopy
> 3 > 0   Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
> Physics, Applied
> 4 > 2   Physics, Nuclear; Physics, Particles & Fields
> 5 > 0   Chemistry, Inorganic & Nuclear
> 6 > 2   Chemistry, Physical; Materials Science, Multidisciplinary;
> Metallurgy & Metallurgical Engineering
>
> And I need to have this:
>
> 1 > TC  WC
> 2 > 0   Instruments & Instrumentation
> 2 > 0   Nuclear Science & Technology
> 2 > 0   Physics, Particles & Fields
> 2 > 0   Spectroscopy
> 3 > 0   Nanoscience & Nanotechnology
> 3 > 0   Materials Science, Multidisciplinary
> 3 > 0   Physics, Applied
> 4 > 2   Physics, Nuclear
> 4 > 2   Physics, Particles & Fields
> 5 > 0   Chemistry, Inorganic & Nuclear
> 6 > 2   Chemistry, Physical
> 6 > 2   Materials Science, Multidisciplinary
> 6 > 2   Metallurgy & Metallurgical Engineering
>
> This means repeat the row for each element in WC and keeping the same value
> in TC. The goal is to check how many TC (sum) there are by WC, when WC is
> multiple.
>
> i've tried to separate the column using strsplt but then I cannot keep the
> track of TC.
>
> thanks in advance.
> --
> Jo?o Azevedo Patr?cio

Best that I've come up with, which seems to give the result desired
from the example data given.

splitAtSemiColon <- function(input) {
    z <- strsplit(input$WC,';');
    result <- data.table(TC=rep(input$TC,sapply(z,length)), WC=unlist(z));
    return(result);
}

flatted.data <- splitAtSemiColon(original.data);

<transcript>
> print(original.data,right=FALSE)
  TC
1 0
2 0
3 2
4 0
5 2
  WC
1 Instruments & Instrumentation; Nuclear Science & Technology;
Physics, Particles & Fields; Spectroscopy
2 Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
Physics, Applied
3 Physics, Nuclear; Physics, Particles & Fields
4 Chemistry, Inorganic & Nuclear
5 Chemistry, Physical; Materials Science, Multidisciplinary;
Metallurgy & Metallurgical Engineering
>
>> print(splitAtSemiColon,right=FALSE);
function(x) {
    z=strsplit(x$WC,';');
    result3=data.frame(TC=rep(x$TC,sapply(z,length)),WC=unlist(z));
    return(result3);
}
> print(splitAtSemiColon(original.data),right=FALSE);
   TC WC
1  0  Instruments & Instrumentation
2  0   Nuclear Science & Technology
3  0   Physics, Particles & Fields
4  0   Spectroscopy
5  0  Nanoscience & Nanotechnology
6  0   Materials Science, Multidisciplinary
7  0   Physics, Applied
8  2  Physics, Nuclear
9  2   Physics, Particles & Fields
10 0  Chemistry, Inorganic & Nuclear
11 2  Chemistry, Physical
12 2   Materials Science, Multidisciplinary
13 2   Metallurgy & Metallurgical Engineering

Note that I still have a problem in that the WC data can have leading
and/or trailing blanks due to the say that strsplit works. The easiest
way to fix this is to use the strtrim() function from the stringr
package.


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From sarah.goslee at gmail.com  Sat Jul  5 10:36:48 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 5 Jul 2014 04:36:48 -0400
Subject: [R] Calling Matrices from a Function
In-Reply-To: <CAJJ9dtuYuxpPLwVfoew6fQ8wMb4ETykPyo+FtfMHeTO-f-Nx6A@mail.gmail.com>
References: <CAJJ9dtuYuxpPLwVfoew6fQ8wMb4ETykPyo+FtfMHeTO-f-Nx6A@mail.gmail.com>
Message-ID: <CAM_vju=yNEakRc334eAbto0PrsASUdYjX6EVLaXL=qUB-fHMpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140705/c6eb51d0/attachment.pl>

From axel.urbiz at gmail.com  Sat Jul  5 14:28:48 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 5 Jul 2014 08:28:48 -0400
Subject: [R] Predictions from "coxph" or "cph" objects
Message-ID: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140705/553c6e9f/attachment.pl>

From wewolski at gmail.com  Sat Jul  5 16:19:11 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sat, 5 Jul 2014 16:19:11 +0200
Subject: [R] how does a valid subscript can produce an "subscript out of
 bounds" error?
In-Reply-To: <53B74440.5000708@gmail.com>
References: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
	<53B74440.5000708@gmail.com>
Message-ID: <CAAjnpdhuGngtYQg08tc85tpvtpz9prRh=cRLShVaor22zae_8A@mail.gmail.com>

Thank you. You example helped to FIX IT.

The problem is I guess somehow related to:
> class(msexp$pepinfo$transition_group_id)
[1] "factor"

and the whole R type conversion , riddle.

For subscripts my intuition is:  either require integer or do the
"cast" to the rowname type (character).
However, it seems that R somehow prefers to cast factors to integers...

it seems that %in% "casts" both vectors to the same type. But to which one?

Oh, I guess all this is neatly explained in the R standard ... but
websearching for it just returns:
standard deviation


a frustrated R user.

On 5 July 2014 02:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/07/2014, 6:35 PM, Witold E Wolski wrote:
>> how does a valid subscript (see first 2 lines) can produce an
>> "subscript out of bounds" error (see line 4)?
>>
>>
>> 1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
>> [1] 0
>> 2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
>> [1] 0
>> 3> class(msexp$rt)
>> [1] "matrix"
>> 4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
>> Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
>>   subscript out of bounds
>>>
>>
>
>> x <- matrix(1,1,1)
>> rownames(x) <- colnames(x) <- "23"
>> 23 %in% rownames(x)
> [1] TRUE
>> x[23,]
> Error in x[23, ] : subscript out of bounds
>



-- 
Witold Eryk Wolski


From pdalgd at gmail.com  Sat Jul  5 16:49:39 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 5 Jul 2014 16:49:39 +0200
Subject: [R] how does a valid subscript can produce an "subscript out of
	bounds" error?
In-Reply-To: <CAAjnpdhuGngtYQg08tc85tpvtpz9prRh=cRLShVaor22zae_8A@mail.gmail.com>
References: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>
	<53B74440.5000708@gmail.com>
	<CAAjnpdhuGngtYQg08tc85tpvtpz9prRh=cRLShVaor22zae_8A@mail.gmail.com>
Message-ID: <D742207F-2C4E-404E-AE1C-AA69AE5BC5A4@gmail.com>


On 05 Jul 2014, at 16:19 , Witold E Wolski <wewolski at gmail.com> wrote:

> Thank you. You example helped to FIX IT.
> 
> The problem is I guess somehow related to:
>> class(msexp$pepinfo$transition_group_id)
> [1] "factor"
> 
> and the whole R type conversion , riddle.
> 
> For subscripts my intuition is:  either require integer or do the
> "cast" to the rowname type (character).
> However, it seems that R somehow prefers to cast factors to integers...
> 
> it seems that %in% "casts" both vectors to the same type. But to which one?
> 
> Oh, I guess all this is neatly explained in the R standard ... but
> websearching for it just returns:
> standard deviation
> 

From help("[")

     The index object ?i? can be numeric, logical, character or empty.
     Indexing by factors is allowed and is equivalent to indexing by
     the numeric codes (see ?factor?) and not by the character values
     which are printed (for which use ?[as.character(i)]?).

One reason for hanging on to this convention is that it allows you to do

plot(x, y, col=c("red","blue")[sex])

Another reason is that it is the broader definition: It works for indexing vectors that do not have names.

> 
> a frustrated R user.
> 
> On 5 July 2014 02:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 04/07/2014, 6:35 PM, Witold E Wolski wrote:
>>> how does a valid subscript (see first 2 lines) can produce an
>>> "subscript out of bounds" error (see line 4)?
>>> 
>>> 
>>> 1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
>>> [1] 0
>>> 2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
>>> [1] 0
>>> 3> class(msexp$rt)
>>> [1] "matrix"
>>> 4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
>>> Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
>>>  subscript out of bounds
>>>> 
>>> 
>> 
>>> x <- matrix(1,1,1)
>>> rownames(x) <- colnames(x) <- "23"
>>> 23 %in% rownames(x)
>> [1] TRUE
>>> x[23,]
>> Error in x[23, ] : subscript out of bounds
>> 
> 
> 
> 
> -- 
> Witold Eryk Wolski
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pburns at pburns.seanet.com  Sat Jul  5 17:54:26 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 05 Jul 2014 16:54:26 +0100
Subject: [R] how does a valid subscript can produce an "subscript out of
 bounds" error?
In-Reply-To: <CAAjnpdhuGngtYQg08tc85tpvtpz9prRh=cRLShVaor22zae_8A@mail.gmail.com>
References: <CAAjnpdhnitu8CQ4Kr4qE8Am-G=UbEw5Rpy01FWBpZYkaAs3SYw@mail.gmail.com>	<53B74440.5000708@gmail.com>
	<CAAjnpdhuGngtYQg08tc85tpvtpz9prRh=cRLShVaor22zae_8A@mail.gmail.com>
Message-ID: <53B81FB2.3030406@pburns.seanet.com>

I think you are somewhere between
Circle 8.2.6 of 'The R Inferno'

http://www.burns-stat.com/documents/books/the-r-inferno/

and the basics of subscripting

http://www.burns-stat.com/documents/tutorials/impatient-r/more-r-subscript/

Pat

On 05/07/2014 15:19, Witold E Wolski wrote:
> Thank you. You example helped to FIX IT.
>
> The problem is I guess somehow related to:
>> class(msexp$pepinfo$transition_group_id)
> [1] "factor"
>
> and the whole R type conversion , riddle.
>
> For subscripts my intuition is:  either require integer or do the
> "cast" to the rowname type (character).
> However, it seems that R somehow prefers to cast factors to integers...
>
> it seems that %in% "casts" both vectors to the same type. But to which one?
>
> Oh, I guess all this is neatly explained in the R standard ... but
> websearching for it just returns:
> standard deviation
>
>
> a frustrated R user.
>
> On 5 July 2014 02:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 04/07/2014, 6:35 PM, Witold E Wolski wrote:
>>> how does a valid subscript (see first 2 lines) can produce an
>>> "subscript out of bounds" error (see line 4)?
>>>
>>>
>>> 1> sum(!rownames(msexp$rt) %in% msexp$pepinfo$transition_group_id)
>>> [1] 0
>>> 2> sum(!msexp$pepinfo$transition_group_id %in% rownames(msexp$rt))
>>> [1] 0
>>> 3> class(msexp$rt)
>>> [1] "matrix"
>>> 4> msexp$rt = as.matrix(msexp$rt[msexp$pepinfo$transition_group_id,])
>>> Error in msexp$rt[msexp$pepinfo$transition_group_id, ] :
>>>    subscript out of bounds
>>>>
>>>
>>
>>> x <- matrix(1,1,1)
>>> rownames(x) <- colnames(x) <- "23"
>>> 23 %in% rownames(x)
>> [1] TRUE
>>> x[23,]
>> Error in x[23, ] : subscript out of bounds
>>
>
>
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Jul  5 19:06:18 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sat, 5 Jul 2014 19:06:18 +0200
Subject: [R] metafor package: changing decimal in forest plot to
	midline	decimal
In-Reply-To: <53B555A4.8070708@web.de>
References: <53B555A4.8070708@web.de>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>

I found this:

https://stat.ethz.ch/pipermail/r-help/2012-August/321057.html

So, use this before drawing the forest plot:

options(OutDec="\xB7")

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 | http://www.wvbauer.com
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of Dietlinde Schmidt [schmidt.dietlinde at web.de]
Sent: Thursday, July 03, 2014 3:07 PM
To: r-help at r-project.org
Subject: [R] metafor package: changing decimal in forest plot to midline        decimal

Dear R-Community,

I need to change the punctuation of the reported weights, effect sizes
and confidence intervals in a forest plot created with the
forest()-function in the metafor-package.

Midline decimal means that it looks like this (23?6) rather than that
(23.6).

Do I need to change the forest()-function and if yes which part exactly?
Or is there an otherway how I can do it maybe by changing the
rma()-function, of which the forest()-function is then applied to?

Thanks for any hints and tipps!

Cheers, Linde

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From 538280 at gmail.com  Sat Jul  5 19:10:33 2014
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 5 Jul 2014 11:10:33 -0600
Subject: [R] Using subplot (from Hmisc) along with par(mfrow)
In-Reply-To: <53B5B2EF.4040907@gmail.com>
References: <53B5B2EF.4040907@gmail.com>
Message-ID: <CAFEqCdxNHoO51+-KrBjQ4t9JQV4G6Td1k_d-d4Nk-pzeFTy+kw@mail.gmail.com>

The subplot function in the TeachingDemos package is more up to date
than the version in Hmisc (the Hmisc version is a copy of an earlier
version of the one in TeachingDemos).  If you replace library(Hmisc)
with library(TeachingDemos) (with a recent version of TeachingDemos
installed) then the code works as you expect.

On Thu, Jul 3, 2014 at 1:45 PM, Cory Champagne <cory.champagn at gmail.com> wrote:
>
>    Hello all,
>    I think this should be a relatively easy solution involving par but I can't
>    figure it out, involving subplot:
>    I'm  making  a  three-figure plot, each with a subplot.  Here's simple
>    reproducible code below.  But each plot seems to call the original par
>    setting and redraws the new plot in the first position, rather than adding
>    subsequent plots in a single plot window.
>    Can someone tell me how to fix this so the result is three figures, each
>    containing a subplot, all within a single plot window?
>    Thanks,
>    -Cory
>    library(Hmisc)    # subplot from the Hmisc package
>    par(mfrow=c(3,1) )    # set mfrow for 3 rows and 1 column.
>    plot(1:10, 1:10, main = "Plot 1")
>        subplot(plot(10,10, xlab="", ylab=""), x=2, y=8, size = c(0.5, 0.5) )
>    plot(11:20, 11:20, main = "Plot 2")
>        subplot(plot(10,10, xlab="", ylab=""), x=12, y=18, size = c(0.5, 0.5)
>    )
>    plot(21:30, 21:30, main = "Plot 3")
>        subplot(plot(10,10, xlab="", ylab=""), x=22, y=28, size = c(0.5, 0.5)
>    )
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From msuzen at gmail.com  Sat Jul  5 19:16:23 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sat, 5 Jul 2014 19:16:23 +0200
Subject: [R] Using R to analyze multiple MRI studies
In-Reply-To: <CACxze+ZcSJe5iWXf72vTV_6AoOX74y30CyZ8Jr2u+y6QA0OVXA@mail.gmail.com>
References: <CACxze+ZcSJe5iWXf72vTV_6AoOX74y30CyZ8Jr2u+y6QA0OVXA@mail.gmail.com>
Message-ID: <CAPtbhHwF5kyANp6R+k+wmPs5jnFjyYWiDQyTmjjvsitUKOz82g@mail.gmail.com>

Did you inspect the CRAN view for Medical imaging?
http://cran.r-project.org/web/views/MedicalImaging.html

On 3 July 2014 17:09, moleps islon <moleps2 at gmail.com> wrote:
> I need to analyze multiple T1 contrast enhanced MRI studies from different
> patients. They are all in DICOM format. I see that there are different
> packages for loading individual studies in DICOM format, however I have had
> limited luck so far researching how the different studies can be tranformed
> into MNI or Talairach space. Is there an R-implementation of this?
>
> Best,
>
> M
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jul  5 19:54:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Jul 2014 10:54:14 -0700
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
Message-ID: <D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>


On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:

> Dear R users,
>
> My apologies for the simple question, as I'm starting to learn the  
> concepts
> behind the Cox PH model. I was just experimenting with the survival  
> and rms
> packages for this.
>
> I'm simply trying to obtain the expected survival time (as opposed  
> to the
> probability of survival at a given time t).

What does "expected survival time" actually mean? Do you want the  
median survival time?

> I can't seem to find an option
> from the "type" argument in the predict methods from coxph{survival}  
> or
> cph{rms} that will give me expected survival times.
>
> library(rms)
> options(na.action=na.exclude) # retain NA in predictions
> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
> head(predict(fit,type="lp"))
> head(predict(fit2,type="lp"))

`predict` will return the results of the regression, i.e. the log- 
hazard ratios for each term in the RHS of the formula. What you want  
(as described in the Index for the survival package) is either  
`survfit` or `survexp`.

require(survival)
help(pack=survival)
?survfit
?survexp
?summary.survfit
?quantile.survfit   # to get the median
?print.summary.survfit

require(rms)
help(pack=rms)

The rms-package also adds a `survfit.cph` function but I have found  
the `survest` function also provides useful added features, beyond  
those offered by survfit

>
>
> Thank you.
>
> Regards,
> Axel.
>
> 	[[alternative HTML version deleted]]

This is a plain text mailing list.

-- 

David Winsemius, MD
Alameda, CA, USA


From macqueen1 at llnl.gov  Sat Jul  5 21:22:45 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sat, 5 Jul 2014 19:22:45 +0000
Subject: [R] Best practice: to factor or not to factor for float
 variables
In-Reply-To: <53B68A3D.1050804@gmail.com>
References: <53B68A3D.1050804@gmail.com>
Message-ID: <CFDD9D26.100EBB%macqueen1@llnl.gov>

However,

> format((0.1+0.2)) == format(0.3)
[1] TRUE

Which suggests that if you want to treat measured variables as categories,
one way to do it is to format them first.

Of course, one may have to control the format more carefully than above
(if necessary, see for example ?formatC).

merge() on carefully formatted float values may be more reliable than
merging on the floats themselves.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/4/14 4:04 AM, "Sebastian Schubert" <schubert.seb at gmail.com> wrote:

>Hi,
>
>I would like to ask for best practice advice on the design of data
>structure and the connected analysis techniques.
>
>In my particular case, I have measurements of several variables at
>several, sometimes equal, heights. Following the tidy data approach of
>Hadley Wickham, I want to put all data in one data frame. In principle,
>the height variable is something like a category. For example, I want to
>average over time for every height. Using dplyr this works very well
>when my height variable is a factor. However, if it is not a factor the
>grouping sometimes will not work probably due to numerical issues:
>
>http://stackoverflow.com/questions/24555010/dplyr-and-group-by-factor-vs-n
>o-factor
>https://github.com/hadley/dplyr/issues/482
>
>Even if the behaviour described in the links above is a bug, on can
>easily create other numerical issues in R:
>> (0.1+0.2) == 0.3
>[1] FALSE
>
>Thus, it seems one should avoid grouping by float values and, in my
>case, use factors. However, from time to time, I need the numerical
>character of the heights: compare heights, find the maximum height, etc.
>Here, the ordered factor approach might help. However, I have to combine
>(via rbind or merge) different data sets quite often so keeping the
>order of the different ordered factor heights also seem to be difficult.
>
>Is there any general approach which reduces the work or do I have to
>switch between approaches as needed?
>
>Thanks a lot for any input,
>Sebastian
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Sat Jul  5 21:43:26 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 5 Jul 2014 15:43:26 -0400
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>
Message-ID: <CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140705/68414e26/attachment.pl>

From dwinsemius at comcast.net  Sun Jul  6 06:12:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Jul 2014 21:12:48 -0700
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>
	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>
Message-ID: <697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>


On Jul 5, 2014, at 12:43 PM, Axel Urbiz wrote:

> Thank you David. It is my understanding that using survfirsurvit  
> below I get the median predicted survival. I actually was looking  
> for the mean. I can't seem to find in the documentation how to get  
> that.
>
> options(na.action=na.exclude) # retain NA in predictions
> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
> pred <- survfit(fit, newdata=lung)
> head(pred)
>
There might be a way. I don't know it if so, so I would probably just  
use the definition of the mean:

sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$time)

(I continue to take effort to keep my postings in plain text despite  
my mail-clients's efforts to match your formatted postings. It adds to  
the work of responders when you post formatted questions and responses.)


> Thanks again,
> Axel.
>
>
>
> On Sat, Jul 5, 2014 at 1:54 PM, David Winsemius <dwinsemius at comcast.net 
> > wrote:
>
> On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:
>
> Dear R users,
>
> My apologies for the simple question, as I'm starting to learn the  
> concepts
> behind the Cox PH model. I was just experimenting with the survival  
> and rms
> packages for this.
>
> I'm simply trying to obtain the expected survival time (as opposed  
> to the
> probability of survival at a given time t).
>
> What does "expected survival time" actually mean? Do you want the  
> median survival time?
>
>
> I can't seem to find an option
> from the "type" argument in the predict methods from coxph{survival}  
> or
> cph{rms} that will give me expected survival times.
>
> library(rms)
> options(na.action=na.exclude) # retain NA in predictions
> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
> head(predict(fit,type="lp"))
> head(predict(fit2,type="lp"))
>
> `predict` will return the results of the regression, i.e. the log- 
> hazard ratios for each term in the RHS of the formula. What you want  
> (as described in the Index for the survival package) is either  
> `survfit` or `survexp`.
>
> require(survival)
> help(pack=survival)
> ?survfit
> ?survexp
> ?summary.survfit
> ?quantile.survfit   # to get the median
> ?print.summary.survfit
>
> require(rms)
> help(pack=rms)
>
> The rms-package also adds a `survfit.cph` function but I have found  
> the `survest` function also provides useful added features, beyond  
> those offered by survfit
>
>
>
> Thank you.
>
> Regards,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> This is a plain text mailing list.
>
> -- 
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Jul  6 06:17:00 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Jul 2014 21:17:00 -0700
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>
	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>
	<697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>
Message-ID: <CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>


On Jul 5, 2014, at 9:12 PM, David Winsemius wrote:

>
> On Jul 5, 2014, at 12:43 PM, Axel Urbiz wrote:
>
>> Thank you David. It is my understanding that using survfirsurvit  
>> below I get the median predicted survival. I actually was looking  
>> for the mean. I can't seem to find in the documentation how to get  
>> that.
>>
>> options(na.action=na.exclude) # retain NA in predictions
>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>> pred <- survfit(fit, newdata=lung)
>> head(pred)
>>
> There might be a way. I don't know it if so, so I would probably  
> just use the definition of the mean:
>
> sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$time)
>

Er, I think I meant to type:

fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
pred <- survfit(fit)

  sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$surv)
[1] 211.0943


> (I continue to take effort to keep my postings in plain text despite  
> my mail-clients's efforts to match your formatted postings. It adds  
> to the work of responders when you post formatted questions and  
> responses.)
>
>
>> Thanks again,
>> Axel.
>>
>>
>>
>> On Sat, Jul 5, 2014 at 1:54 PM, David Winsemius <dwinsemius at comcast.net 
>> > wrote:
>>
>> On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:
>>
>> Dear R users,
>>
>> My apologies for the simple question, as I'm starting to learn the  
>> concepts
>> behind the Cox PH model. I was just experimenting with the survival  
>> and rms
>> packages for this.
>>
>> I'm simply trying to obtain the expected survival time (as opposed  
>> to the
>> probability of survival at a given time t).
>>
>> What does "expected survival time" actually mean? Do you want the  
>> median survival time?
>>
>>
>> I can't seem to find an option
>> from the "type" argument in the predict methods from  
>> coxph{survival} or
>> cph{rms} that will give me expected survival times.
>>
>> library(rms)
>> options(na.action=na.exclude) # retain NA in predictions
>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
>> head(predict(fit,type="lp"))
>> head(predict(fit2,type="lp"))
>>
>> `predict` will return the results of the regression, i.e. the log- 
>> hazard ratios for each term in the RHS of the formula. What you  
>> want (as described in the Index for the survival package) is either  
>> `survfit` or `survexp`.
>>
>> require(survival)
>> help(pack=survival)
>> ?survfit
>> ?survexp
>> ?summary.survfit
>> ?quantile.survfit   # to get the median
>> ?print.summary.survfit
>>
>> require(rms)
>> help(pack=rms)
>>
>> The rms-package also adds a `survfit.cph` function but I have found  
>> the `survest` function also provides useful added features, beyond  
>> those offered by survfit
>>
>>
>>
>> Thank you.
>>
>> Regards,
>> Axel.
>>
>>        [[alternative HTML version deleted]]
>>
>> This is a plain text mailing list.
>>
>> -- 
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>>
>
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From bbolker at gmail.com  Sun Jul  6 08:40:25 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 6 Jul 2014 06:40:25 +0000
Subject: [R] How to extract convergence code from lmer object?
References: <CAL79i+T4hjPVWLLR7f196L7N1O76-OGHjpYoZ_E9rJrL04fiUw@mail.gmail.com>
Message-ID: <loom.20140706T083925-611@post.gmane.org>

Juan Andres Hernandez <jhernandezcabrera <at> gmail.com> writes:

> 
> Does anyone know how to extract the convergence code of an lmer object. I
> am working in a monte carlo simulation with mixed model and I need to know
> if a model has or not convergence. With unclass(mymodel) the following
> information attr(,"optinfo")$conv$lme4 can be seen. How can I get this
> important information in an automatic way?

 I don't know what you mean by "automatic".

mymodel at optinfo$conv$lme4

is the way that I usually extract it.  Yes, there should be a better
accessor method.

  Follow-ups to r-sig-mixed-models at r-project.org, please ...


From goran.brostrom at umu.se  Sun Jul  6 10:48:16 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 6 Jul 2014 10:48:16 +0200
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>	<697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>
	<CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>
Message-ID: <53B90D50.4060107@umu.se>

David and Axel,

I have two comments to your discussion:

(i) The area under the survival curve is equal to the mean of the 
distribution, so the estimate of the mean should be the sum of the areas 
of the rectangles defined by the estimated survival curve and the 
successive distances between observed event times.

Thus,

 > surv <- pred$surv
 > time <- pred$time
 > sum(surv * diff(time))

should give you the (estimated) mean). (Note that time[1] == 0, and 
length(time) == length(surv) + 1)

(I do not think that David's suggestion gives the same answer, but I may 
be wrong.)

(ii) With censored data, this may be a bad idea. For instance, when the 
largest observation is a censoring time, you may badly underestimate the 
mean. Your best hope is to be able to estimate a conditional mean of the 
type E(T | T < x).

This is essentially a non-parametric situation, and therefore it is 
better to stick to medians and quantiles.

G?ran Brostr?m

On 2014-07-06 06:17, David Winsemius wrote:
>
> On Jul 5, 2014, at 9:12 PM, David Winsemius wrote:
>
>>
>> On Jul 5, 2014, at 12:43 PM, Axel Urbiz wrote:
>>
>>> Thank you David. It is my understanding that using survfirsurvit
>>> below I get the median predicted survival. I actually was looking
>>> for the mean. I can't seem to find in the documentation how to get
>>> that.
>>>
>>> options(na.action=na.exclude) # retain NA in predictions
>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>> pred <- survfit(fit, newdata=lung)
>>> head(pred)
>>>
>> There might be a way. I don't know it if so, so I would probably
>> just use the definition of the mean:
>>
>> sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$time)
>>
>
> Er, I think I meant to type:
>
> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
> pred <- survfit(fit)
>
>    sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$surv)
> [1] 211.0943
>
>
>> (I continue to take effort to keep my postings in plain text despite
>> my mail-clients's efforts to match your formatted postings. It adds
>> to the work of responders when you post formatted questions and
>> responses.)
>>
>>
>>> Thanks again,
>>> Axel.
>>>
>>>
>>>
>>> On Sat, Jul 5, 2014 at 1:54 PM, David Winsemius <dwinsemius at comcast.net
>>>> wrote:
>>>
>>> On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:
>>>
>>> Dear R users,
>>>
>>> My apologies for the simple question, as I'm starting to learn the
>>> concepts
>>> behind the Cox PH model. I was just experimenting with the survival
>>> and rms
>>> packages for this.
>>>
>>> I'm simply trying to obtain the expected survival time (as opposed
>>> to the
>>> probability of survival at a given time t).
>>>
>>> What does "expected survival time" actually mean? Do you want the
>>> median survival time?
>>>
>>>
>>> I can't seem to find an option
>>> from the "type" argument in the predict methods from
>>> coxph{survival} or
>>> cph{rms} that will give me expected survival times.
>>>
>>> library(rms)
>>> options(na.action=na.exclude) # retain NA in predictions
>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
>>> head(predict(fit,type="lp"))
>>> head(predict(fit2,type="lp"))
>>>
>>> `predict` will return the results of the regression, i.e. the log-
>>> hazard ratios for each term in the RHS of the formula. What you
>>> want (as described in the Index for the survival package) is either
>>> `survfit` or `survexp`.
>>>
>>> require(survival)
>>> help(pack=survival)
>>> ?survfit
>>> ?survexp
>>> ?summary.survfit
>>> ?quantile.survfit   # to get the median
>>> ?print.summary.survfit
>>>
>>> require(rms)
>>> help(pack=rms)
>>>
>>> The rms-package also adds a `survfit.cph` function but I have found
>>> the `survest` function also provides useful added features, beyond
>>> those offered by survfit
>>>
>>>
>>>
>>> Thank you.
>>>
>>> Regards,
>>> Axel.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> This is a plain text mailing list.
>>>
>>> --
>>>
>>> David Winsemius, MD
>>> Alameda, CA, USA
>>>
>>>
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From goran.brostrom at umu.se  Sun Jul  6 11:17:10 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 6 Jul 2014 11:17:10 +0200
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <53B90D50.4060107@umu.se>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>	<697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>
	<CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>
	<53B90D50.4060107@umu.se>
Message-ID: <53B91416.2030305@umu.se>

On 2014-07-06 10:48, G?ran Brostr?m wrote:
> David and Axel,
>
> I have two comments to your discussion:
>
> (i) The area under the survival curve is equal to the mean of the
> distribution, so the estimate of the mean should be the sum of the areas
> of the rectangles defined by the estimated survival curve and the
> successive distances between observed event times.
>
> Thus,
>
>  > surv <- pred$surv
>  > time <- pred$time
>  > sum(surv * diff(time))
>
> should give you the (estimated) mean). (Note that time[1] == 0, and
> length(time) == length(surv) + 1)

Well, this is not quite true; on the first interval the survival curve 
is one, so you need to

 > surv <- c(1, surv)

first. But then the lengths of the surv and time vectors do not match so 
you need to add a (large) time at the end of time. If the largest 
observation is an event, 'no problem' (surv is zero), but otherwise ...

Btw, I tried

 > exit <- rexp(10)
 > event <- rep(1, 10)
 > fit <- coxph(Surv(exit, event) ~ 1)

 > survfit(fit)$surv
  [1] 0.90483742 0.80968410 0.71454371 0.61942215 0.52432953 0.42928471
  [7] 0.33432727 0.23955596 0.14529803 0.05345216

 > survfit(Surv(exit, event) ~ 1)$surv
[1] 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0

so be careful ...

G?ran

>
> (I do not think that David's suggestion gives the same answer, but I may
> be wrong.)
>
> (ii) With censored data, this may be a bad idea. For instance, when the
> largest observation is a censoring time, you may badly underestimate the
> mean. Your best hope is to be able to estimate a conditional mean of the
> type E(T | T < x).
>
> This is essentially a non-parametric situation, and therefore it is
> better to stick to medians and quantiles.
>
> G?ran Brostr?m
>
> On 2014-07-06 06:17, David Winsemius wrote:
>>
>> On Jul 5, 2014, at 9:12 PM, David Winsemius wrote:
>>
>>>
>>> On Jul 5, 2014, at 12:43 PM, Axel Urbiz wrote:
>>>
>>>> Thank you David. It is my understanding that using survfirsurvit
>>>> below I get the median predicted survival. I actually was looking
>>>> for the mean. I can't seem to find in the documentation how to get
>>>> that.
>>>>
>>>> options(na.action=na.exclude) # retain NA in predictions
>>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>>> pred <- survfit(fit, newdata=lung)
>>>> head(pred)
>>>>
>>> There might be a way. I don't know it if so, so I would probably
>>> just use the definition of the mean:
>>>
>>> sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$time)
>>>
>>
>> Er, I think I meant to type:
>>
>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>> pred <- survfit(fit)
>>
>>    sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$surv)
>> [1] 211.0943
>>
>>
>>> (I continue to take effort to keep my postings in plain text despite
>>> my mail-clients's efforts to match your formatted postings. It adds
>>> to the work of responders when you post formatted questions and
>>> responses.)
>>>
>>>
>>>> Thanks again,
>>>> Axel.
>>>>
>>>>
>>>>
>>>> On Sat, Jul 5, 2014 at 1:54 PM, David Winsemius <dwinsemius at comcast.net
>>>>> wrote:
>>>>
>>>> On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:
>>>>
>>>> Dear R users,
>>>>
>>>> My apologies for the simple question, as I'm starting to learn the
>>>> concepts
>>>> behind the Cox PH model. I was just experimenting with the survival
>>>> and rms
>>>> packages for this.
>>>>
>>>> I'm simply trying to obtain the expected survival time (as opposed
>>>> to the
>>>> probability of survival at a given time t).
>>>>
>>>> What does "expected survival time" actually mean? Do you want the
>>>> median survival time?
>>>>
>>>>
>>>> I can't seem to find an option
>>>> from the "type" argument in the predict methods from
>>>> coxph{survival} or
>>>> cph{rms} that will give me expected survival times.
>>>>
>>>> library(rms)
>>>> options(na.action=na.exclude) # retain NA in predictions
>>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>>> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
>>>> head(predict(fit,type="lp"))
>>>> head(predict(fit2,type="lp"))
>>>>
>>>> `predict` will return the results of the regression, i.e. the log-
>>>> hazard ratios for each term in the RHS of the formula. What you
>>>> want (as described in the Index for the survival package) is either
>>>> `survfit` or `survexp`.
>>>>
>>>> require(survival)
>>>> help(pack=survival)
>>>> ?survfit
>>>> ?survexp
>>>> ?summary.survfit
>>>> ?quantile.survfit   # to get the median
>>>> ?print.summary.survfit
>>>>
>>>> require(rms)
>>>> help(pack=rms)
>>>>
>>>> The rms-package also adds a `survfit.cph` function but I have found
>>>> the `survest` function also provides useful added features, beyond
>>>> those offered by survfit
>>>>
>>>>
>>>>
>>>> Thank you.
>>>>
>>>> Regards,
>>>> Axel.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> This is a plain text mailing list.
>>>>
>>>> --
>>>>
>>>> David Winsemius, MD
>>>> Alameda, CA, USA
>>>>
>>>>
>>>
>>> David Winsemius, MD
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From wewolski at gmail.com  Sun Jul  6 12:30:53 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sun, 6 Jul 2014 12:30:53 +0200
Subject: [R] sort order of a character sequence is different on windose and
 linux (linux result)
Message-ID: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>

This is the result of sorting a character sequence on a linux box
(with R . 3.10)

> bla = read.table("xx.txt",stringsAsFactors=F)
> bla = bla[,1]
> bla[1:10]
 [1] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1000_DGFVALSK_2_run0"
 [6] "1000_DGFVALSK_2_run0"   "1001_DGGAWGTEQR_2_run0"
"1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
"1001_DGGAWGTEQR_2_run0"
> sort(bla)[1:10]
 [1] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1000_DGFVALSK_2_run0"
 [6] "1000_DGFVALSK_2_run0"   "1001_DGGAWGTEQR_2_run0"
"1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
"1001_DGGAWGTEQR_2_run0"
>

I will send the result of sorting the content of xx.txt on windows
from the windows box in a moment.

the file xx.txt can be found at:
https://github.com/wolski/imsbInfer/blob/master/xx.txt



-- 
Witold Eryk Wolski


From wewolski at gmail.com  Sun Jul  6 12:32:19 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sun, 6 Jul 2014 12:32:19 +0200
Subject: [R] sort order of a character sequence is different on windose and
 linux (windows result)
Message-ID: <CAAjnpdgwEyRj1F_8CkAxOv-HgwetUgwqNg-fWY3QPiK1N8TUvA@mail.gmail.com>

And here is the result when sorting the same sequence on a windows box:


> bla = read.table("xx.txt",stringsAsFactors=F)
> bla = bla[,1]
> bla[1:10]
 [1] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
 [5] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
"1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
 [9] "1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
> sort(bla)[1:10]
 [1] "1_AAAAAAALQAK_2_run0"  "1_AAAAAAALQAK_2_run0"
"1_AAAAAAALQAK_2_run0"  "1_AAAAAAALQAK_2_run0"
 [5] "1_AAAAAAALQAK_2_run0"  "1_AAAAAAALQAK_2_run0"
"10_AAATAEEPDPK_2_run0" "10_AAATAEEPDPK_2_run0"
 [9] "10_AAATAEEPDPK_2_run0" "10_AAATAEEPDPK_2_run0"


-- 
Witold Eryk Wolski


From murdoch.duncan at gmail.com  Sun Jul  6 13:06:47 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 Jul 2014 07:06:47 -0400
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>
Message-ID: <53B92DC7.9090009@gmail.com>

On 06/07/2014, 6:30 AM, Witold E Wolski wrote:
> This is the result of sorting a character sequence on a linux box
> (with R . 3.10)

See ?sort.  The sort order depends on your locale.  Set it to "C" for
consistent ordering if that is important to you.  For example, on my system:

> "B" < "a"
[1] FALSE
> Sys.setlocale("LC_COLLATE", "C")
[1] "C"
> "B" < "a"
[1] TRUE

(but see the warning in the example in ?locales).

Duncan Murdoch

> 
>> bla = read.table("xx.txt",stringsAsFactors=F)
>> bla = bla[,1]
>> bla[1:10]
>  [1] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
> "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
> "1000_DGFVALSK_2_run0"
>  [6] "1000_DGFVALSK_2_run0"   "1001_DGGAWGTEQR_2_run0"
> "1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
> "1001_DGGAWGTEQR_2_run0"
>> sort(bla)[1:10]
>  [1] "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
> "1000_DGFVALSK_2_run0"   "1000_DGFVALSK_2_run0"
> "1000_DGFVALSK_2_run0"
>  [6] "1000_DGFVALSK_2_run0"   "1001_DGGAWGTEQR_2_run0"
> "1001_DGGAWGTEQR_2_run0" "1001_DGGAWGTEQR_2_run0"
> "1001_DGGAWGTEQR_2_run0"
>>
> 
> I will send the result of sorting the content of xx.txt on windows
> from the windows box in a moment.
> 
> the file xx.txt can be found at:
> https://github.com/wolski/imsbInfer/blob/master/xx.txt
> 
> 
>


From wewolski at gmail.com  Sun Jul  6 13:19:09 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sun, 6 Jul 2014 13:19:09 +0200
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <53B92DC7.9090009@gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>
	<53B92DC7.9090009@gmail.com>
Message-ID: <CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>

It seems that the package I am developing depends on the locale "C"
because of interactions with other packages (data.table).

So I would like to set the locale to "C" as soon as the package is loaded.
Where can I do it .. I could of course set it in every function in my
package but...


From murdoch.duncan at gmail.com  Sun Jul  6 13:33:24 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 Jul 2014 07:33:24 -0400
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>	<53B92DC7.9090009@gmail.com>
	<CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>
Message-ID: <53B93404.7030402@gmail.com>

On 06/07/2014, 7:19 AM, Witold E Wolski wrote:
> It seems that the package I am developing depends on the locale "C"
> because of interactions with other packages (data.table).
> 
> So I would like to set the locale to "C" as soon as the package is loaded.
> Where can I do it .. I could of course set it in every function in my
> package but...
> 

As the help page says, you can't do it reliably on all platforms, and
you really shouldn't even try:  that will affect other things that the
user does.

You will need to find another solution to your problem.

Duncan Murdoch


From wewolski at gmail.com  Sun Jul  6 13:56:23 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Sun, 6 Jul 2014 13:56:23 +0200
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <53B93404.7030402@gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>
	<53B92DC7.9090009@gmail.com>
	<CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>
	<53B93404.7030402@gmail.com>
Message-ID: <CAAjnpdjDkcFKjskBdkYXWo_vPWrrVSaSXLmBNFzj4yVzYitU9Q@mail.gmail.com>

This is the info I got from the data.table developers... Seems that
they did have tried to find a more elegant solution solution.:


data.table used to support this until 1.8.6. But since Scollate became
not a part of authorised R-API (IIUC) anymore at some point,
data.table only supports sort/order under the C-locale.

data.table's ordering/sorting is over 10-20x faster than base's and
the only way right now (IIUC) to sort by locale is to use base's
sort/order.

This post may give some more insight.
http://r.789695.n4.nabble.com/internal-string-comparison-Scollate-td4687584.html

In summary, we support only C-locale.


On 6 July 2014 13:33, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 06/07/2014, 7:19 AM, Witold E Wolski wrote:
>> It seems that the package I am developing depends on the locale "C"
>> because of interactions with other packages (data.table).
>>
>> So I would like to set the locale to "C" as soon as the package is loaded.
>> Where can I do it .. I could of course set it in every function in my
>> package but...
>>
>
> As the help page says, you can't do it reliably on all platforms, and
> you really shouldn't even try:  that will affect other things that the
> user does.
>
> You will need to find another solution to your problem.
>
> Duncan Murdoch



-- 
Witold Eryk Wolski


From murdoch.duncan at gmail.com  Sun Jul  6 14:15:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 Jul 2014 08:15:12 -0400
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <CAAjnpdjDkcFKjskBdkYXWo_vPWrrVSaSXLmBNFzj4yVzYitU9Q@mail.gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>	<53B92DC7.9090009@gmail.com>	<CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>	<53B93404.7030402@gmail.com>
	<CAAjnpdjDkcFKjskBdkYXWo_vPWrrVSaSXLmBNFzj4yVzYitU9Q@mail.gmail.com>
Message-ID: <53B93DD0.2060200@gmail.com>

On 06/07/2014, 7:56 AM, Witold E Wolski wrote:
> This is the info I got from the data.table developers... Seems that
> they did have tried to find a more elegant solution solution.:

>From my reading of the response below, data.table doesn't use R's sort()
function to do their sorting.  You should use whatever sort function
they use if you want to match their sort order.

Duncan Murdoch

> 
> 
> data.table used to support this until 1.8.6. But since Scollate became
> not a part of authorised R-API (IIUC) anymore at some point,
> data.table only supports sort/order under the C-locale.
> 
> data.table's ordering/sorting is over 10-20x faster than base's and
> the only way right now (IIUC) to sort by locale is to use base's
> sort/order.
> 
> This post may give some more insight.
> http://r.789695.n4.nabble.com/internal-string-comparison-Scollate-td4687584.html
> 
> In summary, we support only C-locale.
> 
> 
> On 6 July 2014 13:33, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 06/07/2014, 7:19 AM, Witold E Wolski wrote:
>>> It seems that the package I am developing depends on the locale "C"
>>> because of interactions with other packages (data.table).
>>>
>>> So I would like to set the locale to "C" as soon as the package is loaded.
>>> Where can I do it .. I could of course set it in every function in my
>>> package but...
>>>
>>
>> As the help page says, you can't do it reliably on all platforms, and
>> you really shouldn't even try:  that will affect other things that the
>> user does.
>>
>> You will need to find another solution to your problem.
>>
>> Duncan Murdoch
> 
> 
>


From axel.urbiz at gmail.com  Sun Jul  6 14:01:29 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sun, 6 Jul 2014 08:01:29 -0400
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <53B91416.2030305@umu.se>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>
	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>
	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>
	<697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>
	<CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>
	<53B90D50.4060107@umu.se> <53B91416.2030305@umu.se>
Message-ID: <CAAyVsXJQiKZztdjLoYB9_GdNg=A1SgU3VcmXW3eJqT0LkfE5=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/b84a6129/attachment.pl>

From hunzikp at gmail.com  Sun Jul  6 14:36:55 2014
From: hunzikp at gmail.com (Philipp Hunziker)
Date: Sun, 6 Jul 2014 14:36:55 +0200
Subject: [R] spatstat package: Simulating from fitted Matern cluster process
	model fails
Message-ID: <CABm=VRcndDf+tdAiZ5Lo2ZB3UjmA6gOqhif=gHn71ro1OZr2Yw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/82243550/attachment.pl>

From moleps2 at gmail.com  Sun Jul  6 17:09:44 2014
From: moleps2 at gmail.com (moleps)
Date: Sun, 6 Jul 2014 17:09:44 +0200
Subject: [R] Using R to analyze multiple MRI studies
Message-ID: <44AC45C1-CD4E-49D9-8505-C111C4738D02@gmail.com>

Yes-I did look through the CRAN view and could not find any package that featured a function whereby an MRI set was transformed into Talairach or MNI space. 

From clivelists at googlemail.com  Sun Jul  6 17:38:16 2014
From: clivelists at googlemail.com (Clive Nicholas)
Date: Sun, 6 Jul 2014 16:38:16 +0100
Subject: [R] Expanding dataset on the values of one of its variables
Message-ID: <CAHs5aThmkVvZy6EK_oKLLXuD-RLYdJbWLLSN2pi0EHaAH5oa-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/7f499da1/attachment.pl>

From f.harrell at Vanderbilt.Edu  Sun Jul  6 17:48:41 2014
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 6 Jul 2014 10:48:41 -0500
Subject: [R] Predictions from "coxph" or "cph" objects
Message-ID: <op.xik17fybn6oykk@hp27home>

When using cph in the rms package there is a function Mean that operates  
on cph objects to produce an R function for computing the mean or  
restricted mean life time.

Frank


From smartpink111 at yahoo.com  Sun Jul  6 18:14:22 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Jul 2014 09:14:22 -0700
Subject: [R] Expanding dataset on the values of one of its variables
In-Reply-To: <CAHs5aThmkVvZy6EK_oKLLXuD-RLYdJbWLLSN2pi0EHaAH5oa-g@mail.gmail.com>
References: <CAHs5aThmkVvZy6EK_oKLLXuD-RLYdJbWLLSN2pi0EHaAH5oa-g@mail.gmail.com>
Message-ID: <1404663262.30666.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

Not sure about the expected output.

If `dat` is the dataset:
res <- dat[rep(1:nrow(dat), dat$score),]
head(res,7)
??? team year time score out top goals host format formed culture wcups cholder
1??? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
1.1? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
1.2? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
1.3? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
1.4? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
1.5? ARG 1986??? 1???? 6?? 0?? 1???? 4??? 0????? 0?? 1893????? 93???? 8?????? 0
2??? ARG 1990??? 2???? 5?? 1?? 0???? 1??? 0????? 0?? 1893????? 97???? 9?????? 0
??? times cards????? gdp
1?????? 6??? 12 6146.155
1.1???? 6??? 12 6146.155
1.2???? 6??? 12 6146.155
1.3???? 6??? 12 6146.155
1.4???? 6??? 12 6146.155
1.5???? 6??? 12 6146.155
2?????? 6??? 25 5800.057


A.K.


On Sunday, July 6, 2014 11:38 AM, Clive Nicholas <clivelists at googlemail.com> wrote:
Hello!

I have a dataset which is perhaps rather topical at about this time:

> wc=read.delim("/home/openclive/Documents/worldcup.csv",header=T,sep="\t",fill=T)> head(wc,n=20)?  team year time score out top goals host format formed culture wcups cholder times
1?  ARG 1986? ? 1? ?  6?  0?  1? ?  4? ? 0? ? ? 0?  1893? ? ? 93? ?  8
? ? ? 0? ?  6
2?  ARG 1990? ? 2? ?  5?  1?  0? ?  1? ? 0? ? ? 0?  1893? ? ? 97? ?  9
? ? ? 0? ?  6
3?  ARG 1994? ? 3? ?  1?  1?  0? ?  3? ? 0? ? ? 0?  1893? ?  101? ? 10
? ? ? 1? ?  6
4?  ARG 1998? ? 4? ?  2?  1?  1? ?  7? ? 0? ? ? 1?  1893? ?  105? ? 11
? ? ? 0? ?  6
5?  ARG 2006? ? 6? ?  2?  1?  1? ?  7? ? 0? ? ? 1?  1893? ?  113? ? 13
? ? ? 0? ?  6
6?  ARG 2010? ? 7? ?  2?  1?  1? ?  6? ? 0? ? ? 1?  1893? ?  117? ? 14
? ? ? 0? ?  6
7?  AUS 2006? ? 6? ?  1?  1?  0? ?  0? ? 0? ? ? 1?  1961? ? ? 45? ?  1
? ? ? 1? ?  1
8?  BEL 1986? ? 1? ?  3?  1?  0? ?  0? ? 0? ? ? 0?  1895? ? ? 91? ?  6
? ? ? 0? ?  4
9?  BEL 1990? ? 2? ?  1?  1?  0? ?  3? ? 0? ? ? 0?  1895? ? ? 95? ?  7
? ? ? 0? ?  4
10? BEL 1994? ? 3? ?  1?  1?  0? ?  1? ? 0? ? ? 0?  1895? ? ? 99? ?  8
? ? ? 0? ?  4
11? BEL 2002? ? 5? ?  1?  1?  0? ?  1? ? 0? ? ? 1?  1895? ?  107? ?  9
? ? ? 0? ?  4
12? BRA 1986? ? 1? ?  2?  1?  1? ?  5? ? 0? ? ? 0?  1914? ? ? 72? ? 12
? ? ? 0? ?  7
13? BRA 1990? ? 2? ?  1?  1?  1? ?  3? ? 0? ? ? 0?  1914? ? ? 76? ? 13
? ? ? 1? ?  7
14? BRA 1994? ? 3? ?  6?  0?  1? ?  5? ? 0? ? ? 0?  1914? ? ? 80? ? 14
? ? ? 0? ?  7
15? BRA 1998? ? 4? ?  5?  1?  1? ?  3? ? 0? ? ? 1?  1914? ? ? 84? ? 15
? ? ? 1? ?  7
16? BRA 2002? ? 5? ?  6?  0?  1? ?  8? ? 0? ? ? 1?  1914? ? ? 88? ? 16
? ? ? 0? ?  7
17? BRA 2006? ? 6? ?  2?  1?  1? ?  6? ? 0? ? ? 1?  1914? ? ? 92? ? 17
? ? ? 1? ?  7
18? BRA 2010? ? 7? ?  2?  1?  1? ?  3? ? 0? ? ? 1?  1914? ? ? 96? ? 18
? ? ? 0? ?  7
19? BUL 1986? ? 1? ?  1?  1?  0? ? -2? ? 0? ? ? 0?  1923? ? ? 63? ?  4
? ? ? 0? ?  2
20? BUL 1994? ? 3? ?  3?  1?  0? ?  3? ? 0? ? ? 0?  1923? ? ? 71? ?  5
? ? ? 0? ?  2
?  cards? ? ?  gdp
1? ?  12? 6146.155
2? ?  25? 5800.057
3? ? ? 9? 7162.093
4? ?  14? 7994.116
5? ?  15? 8107.975
6? ? ? 7? 9933.229
7? ?  12? 9933.229
8? ? ? 8 16273.539
9? ? ? 3 18222.221
10? ?  6 18964.370
11? ?  6 22801.777
12? ?  3? 3334.000
13? ?  7? 3564.636
14? ? 11? 3380.128
15? ? 12? 3693.276
16? ? 10? 3692.840
17? ? 11? 3976.619
18? ? 13? 4424.759
19? ?  3? 1508.592
20? ? 25? 1438.153


Don't worry about they all denote; I merely show it to you for the purposes
of demonstration. Basically, I want to expand the dataset on the value of
the -score- variable in order to prepare the data for survival analysis.
Thus, where Argentina achieved a score of 6 in 1986, I want R to create
five additional records. Where Bulgaria achieved a score of 3 in 1994, I
want it to create two additional records. Rows containing scores of 1
shouldn't create any extra records at all.

Doing this should be straightforward, but the -expand- command in the
-reshape- package doesn't appear to do this ... unless I've missed
something or there is another command from another package that does what I
need.

I'd be most grateful if anybody has a solution to this.

-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From clivelists at googlemail.com  Sun Jul  6 18:28:54 2014
From: clivelists at googlemail.com (Clive Nicholas)
Date: Sun, 6 Jul 2014 17:28:54 +0100
Subject: [R] Expanding dataset on the values of one of its variables
In-Reply-To: <1404663262.30666.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAHs5aThmkVvZy6EK_oKLLXuD-RLYdJbWLLSN2pi0EHaAH5oa-g@mail.gmail.com>
	<1404663262.30666.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAHs5aTjqjjDOyHuK7yiSdq9_9NgSuZgKwTpWJM7F5ECtO59Vxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/c3432f0c/attachment.pl>

From f.harrell at Vanderbilt.Edu  Sun Jul  6 20:40:57 2014
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 6 Jul 2014 13:40:57 -0500
Subject: [R] Using subplot (from Hmisc) along with par(mfrow)
Message-ID: <op.xik96j0wn6oykk@hp27home>

Greg I just re-copied the latest subplot and its help file from  
TeachingDemos to Hmisc for the next release.  Thanks for pointing this out.
Frank


From arturrataj at gmail.com  Sun Jul  6 17:31:34 2014
From: arturrataj at gmail.com (Artur Rataj)
Date: Sun, 6 Jul 2014 17:31:34 +0200
Subject: [R] A custom legend for three data frames in one plot
Message-ID: <CACO3_sBe-=qsot-1QNikBXsm+Vfo-Qkmv9E4FKYMMh16Gj_kYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/d4bea0ae/attachment.pl>

From mari_c1729 at yahoo.com  Sun Jul  6 19:34:13 2014
From: mari_c1729 at yahoo.com (Mari)
Date: Sun, 6 Jul 2014 10:34:13 -0700
Subject: [R] package: RWinEdt question
Message-ID: <1404668053.86381.YahooMailNeo@web121305.mail.ne1.yahoo.com>

I just upgraded WinEdt from 5.2 to 8.2. With the older version, invoking library(RWinEdt) started a new instance of WinEdt identified by "R-WinEdt" as the title. This way, I was able to separate R work from other editing work with two instances of WinEdt running.


However, with the newer version of WinEdt, this no longer seems to be the case. If I already have WinEdt running for editing, say tex files, typing library(RWinEdt) in R does not start a new instance of WinEdt.
I guess what I need is to figure out how to supply the argument -c="R-WinEdt" to the WinEdt.exe command when in R.


Thank you for any suggestions.

-Mari


From ligges at statistik.tu-dortmund.de  Sun Jul  6 22:35:57 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 06 Jul 2014 22:35:57 +0200
Subject: [R] package: RWinEdt question
In-Reply-To: <1404668053.86381.YahooMailNeo@web121305.mail.ne1.yahoo.com>
References: <1404668053.86381.YahooMailNeo@web121305.mail.ne1.yahoo.com>
Message-ID: <53B9B32D.7090607@statistik.tu-dortmund.de>

The RWinEdt package does not support WinEdt 8.x yet.

Versions 5.x and 6.x shoudl be supported. Not sure about 7.x.
Unfortunately, the trick to get it working changes with each version of 
WinEdt these days ... Well, I may be too bad in WinEdt macro programming...
I do notn have the new versions available, hence hard time to get the 
plugin running without a WinEdt version to test it ...

Best,
Uwe Ligges


On 06.07.2014 19:34, Mari wrote:
> I just upgraded WinEdt from 5.2 to 8.2. With the older version, invoking library(RWinEdt) started a new instance of WinEdt identified by "R-WinEdt" as the title. This way, I was able to separate R work from other editing work with two instances of WinEdt running.
>
>
> However, with the newer version of WinEdt, this no longer seems to be the case. If I already have WinEdt running for editing, say tex files, typing library(RWinEdt) in R does not start a new instance of WinEdt.
> I guess what I need is to figure out how to supply the argument -c="R-WinEdt" to the WinEdt.exe command when in R.
>
>
> Thank you for any suggestions.
>
> -Mari
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sun Jul  6 22:44:13 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 Jul 2014 16:44:13 -0400
Subject: [R] package: RWinEdt question
In-Reply-To: <53B9B32D.7090607@statistik.tu-dortmund.de>
References: <1404668053.86381.YahooMailNeo@web121305.mail.ne1.yahoo.com>
	<53B9B32D.7090607@statistik.tu-dortmund.de>
Message-ID: <53B9B51D.4080704@gmail.com>

On 06/07/2014, 4:35 PM, Uwe Ligges wrote:
> The RWinEdt package does not support WinEdt 8.x yet.
> 
> Versions 5.x and 6.x shoudl be supported. Not sure about 7.x.
> Unfortunately, the trick to get it working changes with each version of 
> WinEdt these days ... Well, I may be too bad in WinEdt macro programming...
> I do notn have the new versions available, hence hard time to get the 
> plugin running without a WinEdt version to test it ...

I gave up on trying to support WinEdt with my patchDVI package because
of these constant incompatible changes.  Nowadays I recommend that my
students use RStudio and/or TeXWorks.

Duncan Murdoch

> 
> Best,
> Uwe Ligges
> 
> 
> On 06.07.2014 19:34, Mari wrote:
>> I just upgraded WinEdt from 5.2 to 8.2. With the older version, invoking library(RWinEdt) started a new instance of WinEdt identified by "R-WinEdt" as the title. This way, I was able to separate R work from other editing work with two instances of WinEdt running.
>>
>>
>> However, with the newer version of WinEdt, this no longer seems to be the case. If I already have WinEdt running for editing, say tex files, typing library(RWinEdt) in R does not start a new instance of WinEdt.
>> I guess what I need is to figure out how to supply the argument -c="R-WinEdt" to the WinEdt.exe command when in R.
>>
>>
>> Thank you for any suggestions.
>>
>> -Mari
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mari_c1729 at yahoo.com  Sun Jul  6 23:21:09 2014
From: mari_c1729 at yahoo.com (Mari)
Date: Sun, 6 Jul 2014 14:21:09 -0700
Subject: [R] package: RWinEdt question
In-Reply-To: <53B9B51D.4080704@gmail.com>
References: <1404668053.86381.YahooMailNeo@web121305.mail.ne1.yahoo.com>
	<53B9B32D.7090607@statistik.tu-dortmund.de>
	<53B9B51D.4080704@gmail.com>
Message-ID: <1404681669.65339.YahooMailNeo@web121306.mail.ne1.yahoo.com>

Thank you for your quick reply. Except for the "instances" issue, RWinEdt seems to be
working well with WinEdt 8.2 so I'll continue to use it. (I can't customize keyboard shortcuts in
RStudio or some of the other often mentioned editors).


I looked at the code for "startWinEdt" and I can see where the difference in the versions occcur:


function (InstallRoot, ApplData, WinEdtVersion, args = NULL) 
{
??? if (WinEdtVersion < 6) {
??????? shell(paste("\"\"", InstallRoot, "\\WinEdt.exe\" -C=\"R-WinEdt\" -E=", 
??????????? shQuote(normalizePath(file.path(ApplData, "R.ini"))), 
??????????? "\"", sep = ""), wait = FALSE)
??? }
??? else {
??????? shell(paste("\"\"", InstallRoot, "\\WinEdt.exe\"\"", 
??????????? if (!is.null(args)) 
??????????????? args, sep = ""), wait = FALSE)
??? }
}


-Mari




On Sunday, July 6, 2014 3:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
On 06/07/2014, 4:35 PM, Uwe Ligges wrote:
> The RWinEdt package does not support WinEdt 8.x yet.
> 
> Versions 5.x and 6.x shoudl be supported. Not sure about 7.x.
> Unfortunately, the trick to get it working changes with each version of 
> WinEdt these days ... Well, I may be too bad in WinEdt macro programming...
> I do notn have the new versions available, hence hard time to get the 
> plugin running without a WinEdt version to test it ...

I gave up on trying to support WinEdt with my patchDVI package because
of these constant incompatible changes.? Nowadays I recommend that my
students use RStudio and/or TeXWorks.

Duncan Murdoch

> 
> Best,
> Uwe Ligges
> 
> 
> On 06.07.2014 19:34, Mari wrote:
>> I just upgraded WinEdt from 5.2 to 8.2. With the older version, invoking library(RWinEdt) started a new instance of WinEdt identified by "R-WinEdt" as the title. This way, I was able to separate R work from other editing work with two instances of WinEdt running.
>>
>>
>> However, with the newer version of WinEdt, this no longer seems to be the case. If I already have WinEdt running for editing, say tex files, typing library(RWinEdt) in R does not start a new instance of WinEdt.
>> I guess what I need is to figure out how to supply the argument -c="R-WinEdt" to the WinEdt.exe command when in R.
>>
>>
>> Thank you for any suggestions.
>>
>> -Mari
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Sun Jul  6 23:56:49 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 07 Jul 2014 09:56:49 +1200
Subject: [R] spatstat package: Simulating from fitted Matern cluster
 process model fails
In-Reply-To: <CABm=VRcndDf+tdAiZ5Lo2ZB3UjmA6gOqhif=gHn71ro1OZr2Yw@mail.gmail.com>
References: <CABm=VRcndDf+tdAiZ5Lo2ZB3UjmA6gOqhif=gHn71ro1OZr2Yw@mail.gmail.com>
Message-ID: <53B9C621.8020100@auckland.ac.nz>



There appears to be a small bug in the code.  What is happening is that 
occasionally there are simulated points that lie inside your triangular 
window but do not lie inside any pixel of the image created from your 
"distorigin()" function.

This will be fixed in a future release of spatstat.  In the meantime I 
think you can work around the problem by using finer pixellations. For 
your example,

     spatstat.options(npixel=256)

seems to work.  For a real life example you might need to go with a 
larger value of npixel, e.g. 512.  (Powers of 2 are recommended although 
not required.)

cheers,

Rolf Turner

On 07/07/14 00:36, Philipp Hunziker wrote:
> Dear R-help list,
>
> I'm using the excellent spatstat package to fit an inhomogeneous Matern
> cluster point process model, but unfortunately I'm unable to simulate new
> data points from the fitted object.
>
> Specifically, I get the following error message:
>
>
> Error in rthin(result, P) :
>    some points of X lie outside the domain of image P
>
> I've toyed around a bit, and apparently the error only occurs if the window
> enclosing the analyzed point pattern is derived from a polygon, and the
> fitted model is inhomogeneous (includes covariates). Moreover, whether the
> error occurs appears to be dependent on some idiosyncrasies in the analyzed
> point patterns, i.e., in the example provided below changing the random
> seed will sometimes make the simulation work.
>
> I'm using spatstat 1.37-0 with R 3.1.0 on a x86_64-w64-mingw32/x64 (64-bit)
> machine.
>
> Here's some reproducible code:
>
>> require(spatstat)> set.seed(0)> > # Create an irregular window> poly.mat <- matrix(c(1,0,0.5,1,0,0), 3, 2, byrow=TRUE)> poly.owin <- owin(poly=poly.mat)> > # Generate Matern points> matern.ppp <- rMatClust(50, 0.05, 5, win=poly.owin)> > # Some distance function as a covariate> distorigin <- function(x, y) {+   sqrt(x^2 + y^2)+ }> > # No covariates: works fine> homogeneous.fit <- kppm(matern.ppp, ~ 1, clusters="MatClust") > matern.sim <- simulate(homogeneous.fit, retry=0)> > # Covariates: Simulation fails> inhomogeneous.fit <- kppm(matern.ppp, ~ distorigin, clusters="MatClust") > matern.sim <- simulate(inhomogeneous.fit, retry=0)Error in rthin(result, P) :
>    some points of X lie outside the domain of image PWarning message:In
> simulate.kppm(inhomogeneous.fit, retry = 0) :
>    1 simulation was unsuccessful: returned as NULL
>
>
> I'm fairly new to working with spatstat, so I might be missing something
> very basic. Any ideas on what I'm doing wrong? Many thanks for your help.


From jim at bitwrit.com.au  Mon Jul  7 03:28:54 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 07 Jul 2014 11:28:54 +1000
Subject: [R] A custom legend for three data frames in one plot
In-Reply-To: <CACO3_sBe-=qsot-1QNikBXsm+Vfo-Qkmv9E4FKYMMh16Gj_kYQ@mail.gmail.com>
References: <CACO3_sBe-=qsot-1QNikBXsm+Vfo-Qkmv9E4FKYMMh16Gj_kYQ@mail.gmail.com>
Message-ID: <2677115.7rnp4KF62m@localhost.localdomain>

On Sun, 6 Jul 2014 05:31:34 PM Artur Rataj wrote:
> Hello. I have three data frames, and made a single plot out of them. 
Here
> is a workable example:
> 
> cloud2 <- data.frame(x = c(0, 1, 2), y = c(0.3, 0.4, 0.5))
> sandwich3 <- data.frame(x = c(1, 2, 3), y = c(0.4, 0.5, 0.6), p =
> c(0.1, 0.6, 0.3))
> sandwich4 <- data.frame(x = c(3, 4, 5), y = c(0.6, 0.3, 0.5), p =
> c(0.1, 0.7, 0.2))
> ggplot(cloud2, aes(x=x, y=y)) + 
geom_line(size=0.1,colour="gray70") +
>   aes(x=x, y=y, size=sqrt(p)) +
>   geom_point(data=sandwich3,colour="gray40",shape=15) +
> scale_size(range=c(0,2)) +
>   geom_point(data=sandwich4,colour="black",shape=16) +
>   theme(legend.position=c(0.905, 0.14), 
legend.title=element_blank(),
>   axis.ticks = element_line(colour = "black"), axis.text =
> element_text(colour = "black")) +
>   scale_x_continuous(limits = c(-5, 5), breaks=c(-2, 0, 2)) +
>   scale_y_continuous(limits = c(-1.1, 1.2))
> 
> The problem is, that the default legend ignores two of the data 
frames, and
> needlessly draws size levels for the third data frame. I would want a
> legend like that instead:
> 
> [light gray line] graph 1
> [black circle of size=1] graph 2
> [gray rectangle of size=1] graph 3
> 
> I tried scale_colour_manual, guide=legend, etc., but it changes 
nothing.
> How could it be done?
> Cheers,
> Artur
> 
Hi Artur,
Here is one way.

plot(cloud2,type="l",col="lightgray",xlim=c(0,5),ylim=c(0.3,0.6))
points(sandwich3)
points(sandwich4,pch=5,col="gray") 
legend(3,0.5,c("cloud2","sandwich3","sandwich4"),
 lty=c(1,NA,NA),pch=c(NA,1,5),col=c("lightgray","black","gray"))

Jim


From research.baba at gmail.com  Mon Jul  7 01:35:28 2014
From: research.baba at gmail.com (Sunny Srivastava)
Date: Sun, 6 Jul 2014 19:35:28 -0400
Subject: [R] Question regarding lattice::levelplot and distribution of colors
Message-ID: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140706/e0026d83/attachment.pl>

From ravi.varadhan at jhu.edu  Mon Jul  7 03:33:56 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 7 Jul 2014 01:33:56 +0000
Subject: [R] Box-cox transformation
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C31242F111@DOM-MTW-MAIL2.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/464770fa/attachment.pl>

From jwiley.psych at gmail.com  Mon Jul  7 05:33:44 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 7 Jul 2014 13:33:44 +1000
Subject: [R] Box-cox transformation
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C31242F111@DOM-MTW-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C31242F111@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <CANz9Z_JDzGNA7qRR_8aOsoXdPMTRE-Fs+=HeNuV6041F9VOKgQ@mail.gmail.com>

Hi Ravi,

Deviance is the SS in this case, but you need a normalizing constant
adjusted by the lambda to put them on the same scale.  I modified your
example below to simplify slightly and use the normalization (see the
LL line).

Cheers,

Josh

######################################

require(MASS)

myp <- function(y, lambda) (y^lambda-1)/lambda


lambda <- seq(-0.05, 0.45, len = 20)
N <- nrow(quine)
res <- matrix(numeric(0), nrow = length(lambda), 2, dimnames =
list(NULL, c("Lambda", "LL")))

# scaling contant
C <- exp(mean(log(quine$Days+1)))

for(i in seq_along(lambda)) {
  r <- resid(lm(myp(Days + 1, lambda[i]) ~ Eth*Sex*Age*Lrn, data = quine))
  LL <- (- (N/2) * log(sum((r/(C^lambda[i]))^2)))
  res[i, ] <- c(lambda[i], LL)
}

# box cox
boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine, lambda = lambda)
# add our points on top to verify match
points(res[, 1], res[,2], pch = 16)

######################################



On Mon, Jul 7, 2014 at 11:33 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> Hi,
>
> I am trying to do Box-Cox transformation, but I am not sure how to do it correctly.  Here is an example showing what I am trying:
>
>
>
> # example from MASS
>
> require(MASS)
> boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
>        lambda = seq(-0.05, 0.45, len = 20))
>
> # Here is My attempt at getting the profile likelihood for the Box-Cox parameter
> lam <- seq(-0.05, 0.45, len = 20)
> dev <- rep(NA, length=20)
>
> for (i in 1:20) {
> a <- lam[i]
> ans <- glm(((Days+1)^a-1)/a ~ Eth*Sex*Age*Lrn, family=gaussian, data = quine)
> dev[i] <- ans$deviance
> }
>
> plot(lam, dev, type="b", xlab="lambda", ylab="deviance")
>
> I am trying to create the profile likelihood for the Box-Cox parameter, but obviously I am not getting it right.  I am not sure that ans$deviance is the right thing to do.
>
> I would appreciate any guidance.
>
> Thanks & Best,
> Ravi
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518


From dwinsemius at comcast.net  Mon Jul  7 05:59:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Jul 2014 20:59:46 -0700
Subject: [R] Question regarding lattice::levelplot and distribution of
	colors
In-Reply-To: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
References: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
Message-ID: <C91B50C9-D917-4599-BB36-69E2F344C424@comcast.net>


On Jul 6, 2014, at 4:35 PM, Sunny Srivastava wrote:

> Hello R-helpers:
> 
> I think there is some problem with my code, but I would like to seek you
> help because I can't spot it.
> 
> I have a data.frame defined as follows:
> 
> testdf <- structure(list(yy = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("R", "L"), class = c("ordered",
> "factor")),
>                         xx = c(8L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 32L,
> 33L, 34L, 37L, 38L, 44L, 47L, 48L),
>                         zz = c(-0.0509470162236187, -0.127284016213917,
> -0.148955671035087, -0.142907338502986, -0.160948815798959,
> -0.173350477727937, -0.161083124553469,
>                             -0.14273409035068, -0.0214438692797626,
> -0.0628618704957434, -0.0877747107755074, -0.0948371137126557,
> -0.0659475583478307, -0.0601482978919971,
>                             -0.0339547824620206, -0.0433516197870341)),
>                    .Names = c("yy", "xx", "zz"),
>                    row.names = c("25", "26", "27", "28", "29", "210",
> "211", "212", "213", "214", "215", "216", "217", "218", "219", "220"),
> class = "data.frame")
> 
> I would like to see a 'levelplot'  of yy vs xx, but the value of xx creates
> problem in the distribution of colors.  I am guessing it is due to the
> value of xx = 8.  The levelplot below seems to be fine.

I think the fundamental problem is that you are trying to use levelplot with a categorical variable on the RHS of the formula. That is NOT what is expected. You are the one who expanded the X range to c(0,50) and the color range to seq(-0.3, 0.3, length = 20).

-- 
David.
> 
> library(latticeExtra)
> 
> 
> ## ok; note the subset argument!
> levelplot(zz ~ xx + yy, testdf, par.settings = custom.theme.2(), subset =
> xx != 8,
>          scales = list(x = list(cex = 0.5, rot=90), y = list(cex = 0.5),
> alternating = FALSE),
>          xlim = c(0, 50),
>          at = seq(-0.3, 0.3, length = 20),
>          panel = function(x, y, z, ...) {
>              panel.levelplot(x, y, z,...)
>          },
>          colorkey=list(labels = list(cex = 1.5))
>          )
> 
> If I remove the subsetting of xx != 8, then the distribution of colors is
> wrong.  Specifically, it ranges from xx =1 to 20 for y = R, which is
> incorrect.  What am I missing here?  Note that using the default color
> scheme has no effect.
> 
> ## seems to be a bug ? see xx = 1 to 20; note that the subset argument is
> removed
> levelplot(zz ~ xx + yy, testdf, par.settings = custom.theme.2(),
>          scales = list(x = list(cex = 0.5, rot=90), y = list(cex = 0.5),
> alternating = FALSE),
>          xlim = c(0, 50),
>          at = seq(-0.3, 0.3, length = 20),
>          panel = function(x, y, z, ...) {
>              panel.levelplot(x, y, z,...)
>          },
>          colorkey=list(labels = list(cex = 1.5))
>          )
> 
> 
> Thanks,
> S.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Mon Jul  7 06:42:20 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 7 Jul 2014 14:42:20 +1000
Subject: [R] Question regarding lattice::levelplot and distribution of
	colors
In-Reply-To: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
References: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
Message-ID: <000901cf999d$d73f2a70$85bd7f50$@bigpond.com>

Your y values are not of the type required by levelplot
? levelplot 

I prefer not to use themes as they do not suit my data here is a way to get
what you want - colours are a bit garish but they are some easily to hand
breaks/cuts are just what came in a reasonable sequence - yours to change 

testdf$y <- ifelse(testdf$yy == "L",1,0)

levelplot(zz ~ xx + y, testdf, par.settings = custom.theme.2(),
          scales = list(x = list(cex = 0.5, rot=90), y = list(cex = 0.5),
                         alternating = FALSE),
          xlim = c(0, 50),
          at = seq(-0.3, 0.3, length = 20),
          panel = function(x, y, z, ...) {
              panel.levelplot(x, y, z,...)
          },
          colorkey=list(labels = list(cex = 1.5))
          )

  testcol <- c("#FF0000","#00FF00","#0000FF","#FFA54F",
             "#00FFFF","#FF00FF","#C00000","#00B414")

  levelplot(zz~ xx+y, testdf,#subset(testdf, xx > 0),
            at =  seq(-0.2,0, 0.025),
            cuts = 8,
            col.regions = testcol,
            scales = list(x = list(cex = 0.5,
                                   rot = 90),
                          y = list(cex = 0.5),
                          alternating = FALSE),
             xlim = c(0, 50),
             colorkey = list(labels = paste(seq(-0.2,0, 0.025)),
                             at =  seq(-0.2,0, 0.025),
                             cex = 1.5)
            )

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sunny Srivastava
Sent: Monday, 7 July 2014 09:35
To: R mailing list
Subject: [R] Question regarding lattice::levelplot and distribution of
colors

Hello R-helpers:

I think there is some problem with my code, but I would like to seek you
help because I can't spot it.

I have a data.frame defined as follows:

testdf <- structure(list(yy = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("R", "L"), class = c("ordered",
"factor")),
                         xx = c(8L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 32L,
33L, 34L, 37L, 38L, 44L, 47L, 48L),
                         zz = c(-0.0509470162236187, -0.127284016213917,
-0.148955671035087, -0.142907338502986, -0.160948815798959,
-0.173350477727937, -0.161083124553469,
                             -0.14273409035068, -0.0214438692797626,
-0.0628618704957434, -0.0877747107755074, -0.0948371137126557,
-0.0659475583478307, -0.0601482978919971,
                             -0.0339547824620206, -0.0433516197870341)),
                    .Names = c("yy", "xx", "zz"),
                    row.names = c("25", "26", "27", "28", "29", "210",
"211", "212", "213", "214", "215", "216", "217", "218", "219", "220"),
class = "data.frame")

I would like to see a 'levelplot'  of yy vs xx, but the value of xx creates
problem in the distribution of colors.  I am guessing it is due to the
value of xx = 8.  The levelplot below seems to be fine.

library(latticeExtra)


## ok; note the subset argument!
levelplot(zz ~ xx + yy, testdf, par.settings = custom.theme.2(), subset =
xx != 8,
          scales = list(x = list(cex = 0.5, rot=90), y = list(cex = 0.5),
alternating = FALSE),
          xlim = c(0, 50),
          at = seq(-0.3, 0.3, length = 20),
          panel = function(x, y, z, ...) {
              panel.levelplot(x, y, z,...)
          },
          colorkey=list(labels = list(cex = 1.5))
          )

If I remove the subsetting of xx != 8, then the distribution of colors is
wrong.  Specifically, it ranges from xx =1 to 20 for y = R, which is
incorrect.  What am I missing here?  Note that using the default color
scheme has no effect.

## seems to be a bug ? see xx = 1 to 20; note that the subset argument is
removed
levelplot(zz ~ xx + yy, testdf, par.settings = custom.theme.2(),
          scales = list(x = list(cex = 0.5, rot=90), y = list(cex = 0.5),
alternating = FALSE),
          xlim = c(0, 50),
          at = seq(-0.3, 0.3, length = 20),
          panel = function(x, y, z, ...) {
              panel.levelplot(x, y, z,...)
          },
          colorkey=list(labels = list(cex = 1.5))
          )


Thanks,
S.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From research.baba at gmail.com  Mon Jul  7 06:22:27 2014
From: research.baba at gmail.com (Sunny Srivastava)
Date: Mon, 7 Jul 2014 00:22:27 -0400
Subject: [R] Question regarding lattice::levelplot and distribution of
	colors
In-Reply-To: <C91B50C9-D917-4599-BB36-69E2F344C424@comcast.net>
References: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
	<C91B50C9-D917-4599-BB36-69E2F344C424@comcast.net>
Message-ID: <CAJ-bWQAm1+GBAHtuGDT2Rn+Vr9rP1Gg6jdJtV2bowShweoU8bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/6664ab1f/attachment.ksh>

From wht_crl at yahoo.com  Mon Jul  7 10:05:48 2014
From: wht_crl at yahoo.com (carol white)
Date: Mon, 7 Jul 2014 01:05:48 -0700
Subject: [R] writing matrices of different rows in a file
Message-ID: <1404720348.95680.YahooMailNeo@web121502.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/8c1c4789/attachment.ksh>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Jul  7 11:21:23 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 7 Jul 2014 11:21:23 +0200
Subject: [R] metafor package: changing decimal in forest plot to midline
 decimal
In-Reply-To: <53BA5585.7010206@web.de>
References: <53B555A4.8070708@web.de>
	<077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>
	<53BA5585.7010206@web.de>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DC69201C8@UM-MAIL4112.unimaas.nl>

I tried this:

library(metafor)
data(dat.bcg)
res <- rma(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, slab=paste(author, year, sep=", "))
options(OutDec="\xB7")
forest(res)

No warning, no scrambling, and all decimals shown in midline (also on the x-axis). But this is on Windows.

My guess it's a font issue. There may be others that can give more useful advice.

Best,
Wolfgang

> -----Original Message-----
> From: Dietlinde Schmidt [mailto:schmidt.dietlinde at web.de]
> Sent: Monday, July 07, 2014 10:09
> To: Viechtbauer Wolfgang (STAT); r-help at r-project.org
> Subject: Re: [R] metafor package: changing decimal in forest plot to
> midline decimal
> 
> Thanks for that link, Wolfgang. Unfortunately, there comes the Warning
> with it:
> "(process:3634): Pango-WARNING **: Invalid UTF-8 string passed to
> pango_layout_set_text()"
> and decimal being "scrambled" in forest plot and not displaying the
> midline decimal.
> 
> I think it has to do with the fact, that only 1-byte-codes are allowed
> for options(OutDec="\xB7").
> Or does it have to do with me using Ubuntu?
> 
> Apart from that the options-command does not seem to change the decimal
> of values on the "true" x-axis under the plot.
> 
> Still searching for a solution.
> 
> Cheers,
> Linde
> 
> Am 05.07.2014 19:06, schrieb Viechtbauer Wolfgang (STAT):
> > I found this:
> >
> > https://stat.ethz.ch/pipermail/r-help/2012-August/321057.html
> >
> > So, use this before drawing the forest plot:
> >
> > options(OutDec="\xB7")
> >
> > Best,
> > Wolfgang
> >
> > --
> > Wolfgang Viechtbauer, Ph.D., Statistician
> > Department of Psychiatry and Psychology
> > School for Mental Health and Neuroscience
> > Faculty of Health, Medicine, and Life Sciences
> > Maastricht University, P.O. Box 616 (VIJV1)
> > 6200 MD Maastricht, The Netherlands
> > +31 (43) 388-4170 | http://www.wvbauer.com
> > ________________________________________
> > From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On
> Behalf Of Dietlinde Schmidt [schmidt.dietlinde at web.de]
> > Sent: Thursday, July 03, 2014 3:07 PM
> > To: r-help at r-project.org
> > Subject: [R] metafor package: changing decimal in forest plot to
> midline        decimal
> >
> > Dear R-Community,
> >
> > I need to change the punctuation of the reported weights, effect sizes
> > and confidence intervals in a forest plot created with the
> > forest()-function in the metafor-package.
> >
> > Midline decimal means that it looks like this (23*6) rather than that
> > (23.6).
> >
> > Do I need to change the forest()-function and if yes which part
> exactly?
> > Or is there an otherway how I can do it maybe by changing the
> > rma()-function, of which the forest()-function is then applied to?
> >
> > Thanks for any hints and tipps!
> >
> > Cheers, Linde
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From joao.patricio at gmx.pt  Mon Jul  7 11:49:46 2014
From: joao.patricio at gmx.pt (=?ISO-8859-1?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Mon, 07 Jul 2014 10:49:46 +0100
Subject: [R] Transform a data.frame with ";
 " sep column and another one in a a new one with the same two
 column but with repetitions
In-Reply-To: <CAAJSdjg7NpjPmm6uDoNAteBBwL-=sVW=XoQmuiSuN+r-2aN7Zw@mail.gmail.com>
References: <53B6A32D.4000506@gmx.pt>
	<CAAJSdjg7NpjPmm6uDoNAteBBwL-=sVW=XoQmuiSuN+r-2aN7Zw@mail.gmail.com>
Message-ID: <53BA6D3A.2090604@gmx.pt>

Em 05-07-2014 03:35, John McKown escreveu:
> On Fri, Jul 4, 2014 at 7:50 AM, Jo?o Azevedo Patr?cio
> <joao.patricio at gmx.pt> wrote:
>> Hi,
>>
>> I've been trying to solve this issue but with no success.
>>
>> I have some data like this:
>>
>> 1 > TC  WC
>> 2 > 0   Instruments & Instrumentation; Nuclear Science & Technology;
>> Physics, Particles & Fields; Spectroscopy
>> 3 > 0   Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
>> Physics, Applied
>> 4 > 2   Physics, Nuclear; Physics, Particles & Fields
>> 5 > 0   Chemistry, Inorganic & Nuclear
>> 6 > 2   Chemistry, Physical; Materials Science, Multidisciplinary;
>> Metallurgy & Metallurgical Engineering
>>
>> And I need to have this:
>>
>> 1 > TC  WC
>> 2 > 0   Instruments & Instrumentation
>> 2 > 0   Nuclear Science & Technology
>> 2 > 0   Physics, Particles & Fields
>> 2 > 0   Spectroscopy
>> 3 > 0   Nanoscience & Nanotechnology
>> 3 > 0   Materials Science, Multidisciplinary
>> 3 > 0   Physics, Applied
>> 4 > 2   Physics, Nuclear
>> 4 > 2   Physics, Particles & Fields
>> 5 > 0   Chemistry, Inorganic & Nuclear
>> 6 > 2   Chemistry, Physical
>> 6 > 2   Materials Science, Multidisciplinary
>> 6 > 2   Metallurgy & Metallurgical Engineering
>>
>> This means repeat the row for each element in WC and keeping the same value
>> in TC. The goal is to check how many TC (sum) there are by WC, when WC is
>> multiple.
>>
>> i've tried to separate the column using strsplt but then I cannot keep the
>> track of TC.
>>
>> thanks in advance.
>> --
>> Jo?o Azevedo Patr?cio
> Best that I've come up with, which seems to give the result desired
> from the example data given.
>
> splitAtSemiColon <- function(input) {
>      z <- strsplit(input$WC,';');
>      result <- data.table(TC=rep(input$TC,sapply(z,length)), WC=unlist(z));
>      return(result);
> }
>
> flatted.data <- splitAtSemiColon(original.data);
>
> <transcript>
>> print(original.data,right=FALSE)
>    TC
> 1 0
> 2 0
> 3 2
> 4 0
> 5 2
>    WC
> 1 Instruments & Instrumentation; Nuclear Science & Technology;
> Physics, Particles & Fields; Spectroscopy
> 2 Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
> Physics, Applied
> 3 Physics, Nuclear; Physics, Particles & Fields
> 4 Chemistry, Inorganic & Nuclear
> 5 Chemistry, Physical; Materials Science, Multidisciplinary;
> Metallurgy & Metallurgical Engineering
>>> print(splitAtSemiColon,right=FALSE);
> function(x) {
>      z=strsplit(x$WC,';');
>      result3=data.frame(TC=rep(x$TC,sapply(z,length)),WC=unlist(z));
>      return(result3);
> }
>> print(splitAtSemiColon(original.data),right=FALSE);
>     TC WC
> 1  0  Instruments & Instrumentation
> 2  0   Nuclear Science & Technology
> 3  0   Physics, Particles & Fields
> 4  0   Spectroscopy
> 5  0  Nanoscience & Nanotechnology
> 6  0   Materials Science, Multidisciplinary
> 7  0   Physics, Applied
> 8  2  Physics, Nuclear
> 9  2   Physics, Particles & Fields
> 10 0  Chemistry, Inorganic & Nuclear
> 11 2  Chemistry, Physical
> 12 2   Materials Science, Multidisciplinary
> 13 2   Metallurgy & Metallurgical Engineering
>
> Note that I still have a problem in that the WC data can have leading
> and/or trailing blanks due to the say that strsplit works. The easiest
> way to fix this is to use the strtrim() function from the stringr
> package.
>
>
Yes also have that problem. Tried to work it ou using "sub" but didn't 
work at all.

-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From evapcastro at yahoo.es  Mon Jul  7 10:21:49 2014
From: evapcastro at yahoo.es (Eva Prieto Castro)
Date: Mon, 7 Jul 2014 09:21:49 +0100
Subject: [R] =?iso-8859-1?q?Consulta_paquetizaci=F3n_con_versi=F3n_R_3=2E1?=
	=?iso-8859-1?q?=2E0?=
Message-ID: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/e9c4c82f/attachment.pl>

From research.baba at gmail.com  Mon Jul  7 10:56:34 2014
From: research.baba at gmail.com (Sunny Srivastava)
Date: Mon, 7 Jul 2014 04:56:34 -0400
Subject: [R] Question regarding lattice::levelplot and distribution of
	colors
In-Reply-To: <000901cf999d$d73f2a70$85bd7f50$@bigpond.com>
References: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>
	<000901cf999d$d73f2a70$85bd7f50$@bigpond.com>
Message-ID: <CAJ-bWQCkcLvUr7dQ1JE+UiG+nue9CEFm2=581p0BC69facDy_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/5c0a51ec/attachment.pl>

From schmidt.dietlinde at web.de  Mon Jul  7 10:08:37 2014
From: schmidt.dietlinde at web.de (Dietlinde Schmidt)
Date: Mon, 07 Jul 2014 10:08:37 +0200
Subject: [R] metafor package: changing decimal in forest plot to midline
 decimal
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>
References: <53B555A4.8070708@web.de>
	<077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>
Message-ID: <53BA5585.7010206@web.de>

Thanks for that link, Wolfgang. Unfortunately, there comes the Warning 
with it:
"(process:3634): Pango-WARNING **: Invalid UTF-8 string passed to 
pango_layout_set_text()"
and decimal being "scrambled" in forest plot and not displaying the 
midline decimal.

I think it has to do with the fact, that only 1-byte-codes are allowed 
for options(OutDec="\xB7").
Or does it have to do with me using Ubuntu?

Apart from that the options-command does not seem to change the decimal 
of values on the "true" x-axis under the plot.

Still searching for a solution.

Cheers,
Linde

Am 05.07.2014 19:06, schrieb Viechtbauer Wolfgang (STAT):
> I found this:
>
> https://stat.ethz.ch/pipermail/r-help/2012-August/321057.html
>
> So, use this before drawing the forest plot:
>
> options(OutDec="\xB7")
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of Dietlinde Schmidt [schmidt.dietlinde at web.de]
> Sent: Thursday, July 03, 2014 3:07 PM
> To: r-help at r-project.org
> Subject: [R] metafor package: changing decimal in forest plot to midline        decimal
>
> Dear R-Community,
>
> I need to change the punctuation of the reported weights, effect sizes
> and confidence intervals in a forest plot created with the
> forest()-function in the metafor-package.
>
> Midline decimal means that it looks like this (23?6) rather than that
> (23.6).
>
> Do I need to change the forest()-function and if yes which part exactly?
> Or is there an otherway how I can do it maybe by changing the
> rma()-function, of which the forest()-function is then applied to?
>
> Thanks for any hints and tipps!
>
> Cheers, Linde
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wagner.fab at gmx.de  Mon Jul  7 10:01:54 2014
From: wagner.fab at gmx.de (Wagner)
Date: Mon, 7 Jul 2014 01:01:54 -0700 (PDT)
Subject: [R] Principal component analysis with EQUAMAX rotation
In-Reply-To: <FE0C2577-1B19-4E34-86BB-671E67DE9E6D@revelle.net>
References: <1403161657006-4692337.post@n4.nabble.com>
	<FE0C2577-1B19-4E34-86BB-671E67DE9E6D@revelle.net>
Message-ID: <1404720114897-4693612.post@n4.nabble.com>

That's what I was looking for, thank you very much!



--
View this message in context: http://r.789695.n4.nabble.com/Principal-component-analysis-with-EQUAMAX-rotation-tp4692337p4693612.html
Sent from the R help mailing list archive at Nabble.com.


From jeremy.miles at gmail.com  Mon Jul  7 12:49:20 2014
From: jeremy.miles at gmail.com (Jeremy Miles)
Date: Mon, 7 Jul 2014 11:49:20 +0100
Subject: [R] metafor package: changing decimal in forest plot to midline
	decimal
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DC69201C8@UM-MAIL4112.unimaas.nl>
References: <53B555A4.8070708@web.de>
	<077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>
	<53BA5585.7010206@web.de>
	<077E31A57DA26E46AB0D493C9966AC730DC69201C8@UM-MAIL4112.unimaas.nl>
Message-ID: <CAMtGSxnaq=uMxycH++Up2TkXBxM6a9t-PVP61tpfWPGxKS9koA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/c8792794/attachment.pl>

From info at aghmed.fsnet.co.uk  Mon Jul  7 13:02:23 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 07 Jul 2014 12:02:23 +0100
Subject: [R] metafor package: changing decimal in forest plot to midline
 decimal
In-Reply-To: <53BA5585.7010206@web.de>
References: <53B555A4.8070708@web.de>
	<077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>
	<53BA5585.7010206@web.de>
Message-ID: <Zen-1X46gn-0003AX-Gu@smarthost01b.mail.zen.net.uk>

At 09:08 07/07/2014, Dietlinde Schmidt wrote:
>Thanks for that link, Wolfgang. Unfortunately, 
>there comes the Warning with it:
>"(process:3634): Pango-WARNING **: Invalid UTF-8 
>string passed to pango_layout_set_text()"
>and decimal being "scrambled" in forest plot and 
>not displaying the midline decimal.
>
>I think it has to do with the fact, that only 
>1-byte-codes are allowed for options(OutDec="\xB7").
>Or does it have to do with me using Ubuntu?

I am not an expert on encodings but I think that 
in Unicode it is indeed two bytes but for some 
reason in the encoding used in Windows it is a 
single byte. It may be that some expert in 
encodings can tell you how to temporarily reset 
your locale in Ubuntu but I am not that expert.


>Apart from that the options-command does not 
>seem to change the decimal of values on the "true" x-axis under the plot.
>
>Still searching for a solution.
>
>Cheers,
>Linde
>
>Am 05.07.2014 19:06, schrieb Viechtbauer Wolfgang (STAT):
>>I found this:
>>
>>https://stat.ethz.ch/pipermail/r-help/2012-August/321057.html
>>
>>So, use this before drawing the forest plot:
>>
>>options(OutDec="\xB7")
>>
>>Best,
>>Wolfgang
>>
>>--
>>Wolfgang Viechtbauer, Ph.D., Statistician
>>Department of Psychiatry and Psychology
>>School for Mental Health and Neuroscience
>>Faculty of Health, Medicine, and Life Sciences
>>Maastricht University, P.O. Box 616 (VIJV1)
>>6200 MD Maastricht, The Netherlands
>>+31 (43) 388-4170 | http://www.wvbauer.com
>>________________________________________
>>From: r-help-bounces at r-project.org 
>>[r-help-bounces at r-project.org] On Behalf Of 
>>Dietlinde Schmidt [schmidt.dietlinde at web.de]
>>Sent: Thursday, July 03, 2014 3:07 PM
>>To: r-help at r-project.org
>>Subject: [R] metafor package: changing decimal 
>>in forest plot to midline        decimal
>>
>>Dear R-Community,
>>
>>I need to change the punctuation of the reported weights, effect sizes
>>and confidence intervals in a forest plot created with the
>>forest()-function in the metafor-package.
>>
>>Midline decimal means that it looks like this (23?6) rather than that
>>(23.6).
>>
>>Do I need to change the forest()-function and if yes which part exactly?
>>Or is there an otherway how I can do it maybe by changing the
>>rma()-function, of which the forest()-function is then applied to?
>>
>>Thanks for any hints and tipps!
>>
>>Cheers, Linde
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From thanoon.younis80 at gmail.com  Mon Jul  7 13:03:14 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Mon, 7 Jul 2014 14:03:14 +0300
Subject: [R] RMS equation
Message-ID: <CABLo8nGj593v_J256GqN7DSTAzCJ-kKm8MbhQwA7bApBY_o0=w@mail.gmail.com>

dear R-users
i am new on R-program so i need your help to solve the root mean square
equation  in R. i have a problem in summation (r=1:100)how can i write it
in R . i tried to write the code as below but the problem is the result
must be vector not constant number as code below.

i appreciate any help

thanks alot for all

p<-23
r<-100
x<-c(1.098,0.995, 1.078, 1.098, 1.034, 1.009, 1.070, 0.996, 1.070, 0.827,
0.651, 1.032, 0.841, 0.769, 0.860, 0.717, 0.847, 1.008, 0.833, 0.806,
0.273, 0.934, 0.321)
y<-c(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
1.0,0.7,0.7,0.8,0.8,0.7,0.7,0.6,0.6,0.8,0.8,1.0,0.3,1.0,0.3)
w<-x-y
A<-(w)^2
q<-sum(A)
z<-1/100*q
t<-sqrt(z)
t

From john.archie.mckown at gmail.com  Mon Jul  7 14:56:19 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 7 Jul 2014 07:56:19 -0500
Subject: [R] interesting article
Message-ID: <CAAJSdjhsV6L868+BFZZKfnSW9MXQN8hhUZdwgaEYq+PkpxZUSg@mail.gmail.com>

http://opensource.com/business/14/7/interview-david-smith-revolution-analytics


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From dulcalma at bigpond.com  Mon Jul  7 15:24:25 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 7 Jul 2014 23:24:25 +1000
Subject: [R] Question regarding lattice::levelplot and distribution of
	colors
In-Reply-To: <CAJ-bWQCkcLvUr7dQ1JE+UiG+nue9CEFm2=581p0BC69facDy_A@mail.gmail.com>
References: <CAJ-bWQDp+zAbAe00EOF31=LVv-6_-HmPpfrj5-AQN0jZB2AUSA@mail.gmail.com>	<000901cf999d$d73f2a70$85bd7f50$@bigpond.com>
	<CAJ-bWQCkcLvUr7dQ1JE+UiG+nue9CEFm2=581p0BC69facDy_A@mail.gmail.com>
Message-ID: <002501cf99e6$c6b17480$54145d80$@bigpond.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/95636e5e/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Jul  7 15:29:31 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 07 Jul 2014 14:29:31 +0100
Subject: [R] metafor package: changing decimal in forest plot to midline
 decimal
In-Reply-To: <Zen-1X46gn-0003AX-Gu@smarthost01b.mail.zen.net.uk>
References: <53B555A4.8070708@web.de>	<077E31A57DA26E46AB0D493C9966AC730DC64F7A73@UM-MAIL4112.unimaas.nl>	<53BA5585.7010206@web.de>
	<Zen-1X46gn-0003AX-Gu@smarthost01b.mail.zen.net.uk>
Message-ID: <53BAA0BB.7090207@stats.ox.ac.uk>

On 07/07/2014 12:02, Michael Dewey wrote:
> At 09:08 07/07/2014, Dietlinde Schmidt wrote:
>> Thanks for that link, Wolfgang. Unfortunately, there comes the Warning
>> with it:
>> "(process:3634): Pango-WARNING **: Invalid UTF-8 string passed to
>> pango_layout_set_text()"
>> and decimal being "scrambled" in forest plot and not displaying the
>> midline decimal.
>>
>> I think it has to do with the fact, that only 1-byte-codes are allowed
>> for options(OutDec="\xB7").
>> Or does it have to do with me using Ubuntu?
>
> I am not an expert on encodings but I think that in Unicode it is indeed
> two bytes but for some reason in the encoding used in Windows it is a
> single byte. It may be that some expert in encodings can tell you how to
> temporarily reset your locale in Ubuntu but I am not that expert.

All non-ASCII chars are two or more bytes in UTF-8: this one is c2 b7 in 
hex.

Ubuntu is based on Debian which micro-packages its encoding support.  On 
a standard Linux system you can just use (e.g.) LC_CTYPE=de_DE which is 
encoded in Latin-1.   That might not be installed on Debian/Ubuntu, in 
which case you need to install it.

OutDec is designed for outputting numbers in an internationalized way: 
no known locale uses a centred dot.  (If one did, you could most likely 
set LC_NUMERIC to such a locale instead.)

>
>
>> Apart from that the options-command does not seem to change the
>> decimal of values on the "true" x-axis under the plot.
>>
>> Still searching for a solution.
>>
>> Cheers,
>> Linde
>>
>> Am 05.07.2014 19:06, schrieb Viechtbauer Wolfgang (STAT):
>>> I found this:
>>>
>>> https://stat.ethz.ch/pipermail/r-help/2012-August/321057.html
>>>
>>> So, use this before drawing the forest plot:
>>>
>>> options(OutDec="\xB7")
>>>
>>> Best,
>>> Wolfgang
>>>
>>> --
>>> Wolfgang Viechtbauer, Ph.D., Statistician
>>> Department of Psychiatry and Psychology
>>> School for Mental Health and Neuroscience
>>> Faculty of Health, Medicine, and Life Sciences
>>> Maastricht University, P.O. Box 616 (VIJV1)
>>> 6200 MD Maastricht, The Netherlands
>>> +31 (43) 388-4170 | http://www.wvbauer.com
>>> ________________________________________
>>> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On
>>> Behalf Of Dietlinde Schmidt [schmidt.dietlinde at web.de]
>>> Sent: Thursday, July 03, 2014 3:07 PM
>>> To: r-help at r-project.org
>>> Subject: [R] metafor package: changing decimal in forest plot to
>>> midline        decimal
>>>
>>> Dear R-Community,
>>>
>>> I need to change the punctuation of the reported weights, effect sizes
>>> and confidence intervals in a forest plot created with the
>>> forest()-function in the metafor-package.
>>>
>>> Midline decimal means that it looks like this (23?6) rather than that
>>> (23.6).
>>>
>>> Do I need to change the forest()-function and if yes which part exactly?
>>> Or is there an otherway how I can do it maybe by changing the
>>> rma()-function, of which the forest()-function is then applied to?
>>>
>>> Thanks for any hints and tipps!
>>>
>>> Cheers, Linde
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jan.graffelman at upc.edu  Mon Jul  7 12:22:11 2014
From: jan.graffelman at upc.edu (Jan Graffelman)
Date: Mon, 07 Jul 2014 12:22:11 +0200
Subject: [R] Using RCMD INSTALL under Spanish version of windows.
In-Reply-To: <53B33269.4030401@upc.edu>
References: <53B33269.4030401@upc.edu>
Message-ID: <53BA74D3.3050706@upc.edu>

Here is a solution for the posted problem.

Under the Spanish version of Windows 7, inside Windows Explorer, the 
directory where R is installed appears as

C:\Archivos de programa\R\R-3.1.0\bin\x64

If you wish to compile a personal libary, this suggests you should 
extend the search path by changing the environmental
variable PATH to Path=C:\Archivos de 
programa\R\R-3.1.0\bin\x64;C:\windows;C:etc......

However, the real name of the directory is not "Archivos de programa" 
but "Program files", this will become evident if
you open a DOS window on C:\

So if you change the environmental variable PATH to Path=C:\Program 
files\R\R-3.1.0\bin\x64;C:\windows;C:etc......

then the problem is over and RCMD INSTALL MyPackages installs MyPackages 
without the error message

In normalizePath(path.expand(path), winslash, mustWork) :
   path[1]="c:/ARCHIV~1/R/R-31~1.0/library": Acceso denegado

Jan.

On 02/07/2014 0:12, Jan Graffelman wrote:
> Using RCMD INSTALL with R-version 3.1.0 under a Spanish Windows 7 
> gives the following error message:
>
> rcmd INSTALL MyPackages
> Mensajes de aviso perdidos
> In normalizePath(path.expand(path), winslash, mustWork) :
>   path[1]="c:/ARCHIV~1/R/R-31~1.0/library": Acceso denegado C
> Mensajes de aviso perdidos
> package "methods" in options("defaultPackages") was not found
> Durante la inicializaci?n - Mensajes de aviso perdidos
> 1: package 'datasets' in options("defaultPackages") was not found
> 2: package 'utils' in options("defaultPackages") was not found
> 3: package 'grDevices' in options("defaultPackages") was not found
> 4: package 'graphics' in options("defaultPackages") was not found
> 5: package 'stats' in options("defaultPackages") was not found
> 6: package 'methods' in options("defaultPackages") was not found
> Error en normalizePath(path.expand(path), winslash, mustWork) :
>   path[1]="c:/ARCHIV~1/R/R-31~1.0/library/tools": Acceso denegado
> Calls: ::: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
> Ejecuci?n interrumpida
>
> The user running this command has all permissions to modify the
> directory C:\Program Files\R\R-3.1.0\library, as is also clear from the
> fact that installing a package by install.packages() works.
>
> Any suggestions are welcome.
>
> Jan.
>


-- 
Jan Graffelman
Dpt. of Statistics and Operations Research
Universitat Polit?cnica de Catalunya
Av. Diagonal 647, 6th floor
08028 Barcelona, Spain
email: jan.graffelman at upc.edu
web: http://www-eio.upc.es/~jan
tel: +34-93-4011739
fax: +34-93-4016575


From therneau at mayo.edu  Mon Jul  7 15:49:00 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 07 Jul 2014 08:49:00 -0500
Subject: [R] Predictions from "coxph" or "cph" objects
Message-ID: <27747b$8tjdko@ironport10.mayo.edu>

I've been off on vacation for a few days and so am arriving late to this discussion.

  Try ?print.survfit, and look at the print.rmean option and the discussion thereof in the 
"Details" section of the page.  It will answer your question, in more detail than you 
asked.  The option applies to survival curves from coxph fits as well.

Short summary
1. For any positive random variable X, mean(x) = integral from 0 to inf of the survival 
curve.  For some reason I found this particular homework problem impossible, back when I 
was a new grad student, consequently I remember it well.

2. When there is censoring the survival curve never drops to zero, which makes the full 
integral not evaluable.  There are well known responses to this problem, but the mean 
survival is used by so few that these "well known" approaches are only known by a small 
few. Enough people got confused by the resulting truncated mean that I set the default 
option for print.rmean to "don't print it".  The downside is that the few who do want a 
mean (like you) often have trouble discovering how to obtain it.

A reference manual (with index) for the survival package is sorely needed.  Someday...

Terry Therneau





Dear R users,

My apologies for the simple question, as I'm starting to learn the concepts
behind the Cox PH model. I was just experimenting with the survival and rms
packages for this.

I'm simply trying to obtain the expected survival time (as opposed to the
probability of survival at a given time t). I can't seem to find an option
from the "type" argument in the predict methods from coxph{survival} or
cph{rms} that will give me expected survival times.


From arpitrb at gmail.com  Mon Jul  7 15:50:13 2014
From: arpitrb at gmail.com (Arpit Jain)
Date: Mon, 7 Jul 2014 15:50:13 +0200
Subject: [R] nls - Error in qr.qty(QR,
 resid) : NA/NaN/Inf in foreign function call (arg 1)
Message-ID: <CAEG6eiKfOYF+Eta24T_d1h_9k=jg_inT6ahj3Hv91Ax0ESADDQ@mail.gmail.com>

Dear All,

I have made a script in R (r_nonlinear_leastsquare.R) to fit an exponential
decay curve to my data using nls module:

-----------------------------------------------------------------------------------------------------------------
args <- commandArgs(trailingOnly = TRUE)

#"/project/dmp-work/alex/workspace/test/test_data"
path = args[1]
 y <- scan(path)
x = seq(0.1, length(y)*0.1, 0.1)
y=1-y
 myfunc = function(t, params){
(1*params[1]*exp(params[2]*t))/(1+params[1]*(exp(params[2]*t)-1)) }
 fitModel = nls(y~(1*N*exp(r*x))/(1+N*(exp(r*x)-1)), start=list(N=0.01,
r=0.6), control = list(maxiter = 500), alg="plinear", trace = TRUE)
par = coef(fitModel)
y2 = myfunc(x, par)
 jpeg(paste(path, ".jpg", sep=""))
plot(x, 1-y2, type="l", ylab="fraction of detection", xlab="distance")
points(x, 1-y)
dev.off()
 write(par[1], file=paste(path, "_parameter", sep=""), append = FALSE)
write(par[2], file=paste(path, "_parameter", sep=""), append = TRUE)

residual_sumofsquares = sum(resid(fitModel)^2);
write(residual_sumofsquares, file=paste(path, "_residualsumofsquares",
sep=""), append = FALSE)

q()
--------------------------------------------------------------------------------------------------------------------

The script is called using the following command:

R --vanilla --file=r_nonlinear_leastsquare.R --args copy_decay_YEAST04876

The 'copy_decay_YEAST04876' has been enclosed in this email.

*On execution, this throws an error:*
Error in qr.solve(QR.B, cc) : singular matrix 'a' in solve
Calls: nls -> <Anonymous> -> qr.solve

Kindly help me in solving this issue.

Regards,
-- 
*Arpit Jain*
PhD student at Goethe Universit?t, Frankfurt, Germany
CALIPSO, Marie-Curie ITN,
Ph :- +49 157 50913290

From mhaartman at alteryx.com  Mon Jul  7 17:13:40 2014
From: mhaartman at alteryx.com (meg)
Date: Mon, 7 Jul 2014 08:13:40 -0700 (PDT)
Subject: [R] How to build and importance chart with mlp function from RSNNS
 package in R?
Message-ID: <1404746020070-4693635.post@n4.nabble.com>

I would like to build a bar plot with the importance of the independent
variables ranked by largest value. I am using the mlp function for the model
and don't believe I am using the correct output. model is what comes out of
the mlp function

data(iris)

#shuffle the vector
iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]

irisValues <- iris[,1:4]
irisTargets <- decodeClassLabels(iris[,5])
#irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)

iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)
iris <- normTrainingAndTestSet(iris)

model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5,
learnFuncParams=c(0.1),
             maxit=50, inputsTest=iris$inputsTest,
targetsTest=iris$targetsTest)    
ex<-extractNetInfo(model)
    k<-ex$unitDefinitions
    w <- which(k[,5]=="UNIT_INPUT")

    dat<-subset(k, select=c("unitName","unitAct"))[w,]
    dat$unitAct=dat$unitAct/max(dat$unitAct)
    dat["new"]<-colnames(the.data$inputsTrain)


    dat <- dat[order(dat$unitAct),] 
    par(las=2) # make label text perpendicular to 
    par(mar=c(5,8,4,2)) # increase y-axis margin.
    barplot(dat$unitAct, main="Importance of Independent Variables",
horiz=TRUE, names.arg=dat$new, cex.names=0.8)



--
View this message in context: http://r.789695.n4.nabble.com/How-to-build-and-importance-chart-with-mlp-function-from-RSNNS-package-in-R-tp4693635.html
Sent from the R help mailing list archive at Nabble.com.


From Guillaume.Tahon at UGent.be  Mon Jul  7 17:42:45 2014
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Mon, 7 Jul 2014 08:42:45 -0700 (PDT)
Subject: [R] Plot does not show in R
Message-ID: <1404747765990-4693637.post@n4.nabble.com>

I'm trying to get my figure to open with R, but it does not come up.
Here is my standard code:

venn.diagram(		
	x = list(	
		KP2 = c(2, 62, 22, 33, 11, 36, 26, 27, 28, 64, 5, 66, 10, 18, 68, 61, 6,
29, 19, 65, 30, 35, 32, 20, 69, 8, 31, 13, 21, 7),
		KP15 = c(2, 22, 39, 1, 14, 65, 67, 68, 1, 12, 23, 37, 4, 24, 25, 64, 52,
34, 9, 15, 13, 8, 16, 63, 3, 17),
		KP43 = c(39, 2, 49, 43, 51, 38, 56, 58, 60, 44, 54, 40, 50, 45, 57, 59,
46, 41, 47, 48, 42, 55, 53)
		),
	filename = "location\\nifH_AA_alles.jpg" ,	
	col = "transparent",	
	fill = c("red", "blue", "green"),	
	alpha = 0.5,	
	label.col = c("darkred", "white", "darkblue", "white", "white", "white",
"darkgreen"),	
	cex = 2.5,	
	fontfamily = "serif",	
	fontface = "bold",	
	cat.default.pos = "text",	
	cat.col = c("darkred", "darkblue", "darkgreen"),	
	cat.cex = 2.5,	
	cat.fontfamily = "serif",	
	cat.dist = c(0.3, 0.4, 0.27),	
	cat.pos = 0	
	);	

This code saves the file to the desired location. However, I want the plot
to open in the R interface, so I changed that line of the code to
"filename=NULL". When I run the script afterwards, the plot does not open,
instead, I get the following outputline:

(polygon[GRID.polygon.1], polygon[GRID.polygon.2], polygon[GRID.polygon.3],
polygon[GRID.polygon.4], polygon[GRID.polygon.5], polygon[GRID.polygon.6],
text[GRID.text.7], text[GRID.text.8], text[GRID.text.9], text[GRID.text.10],
text[GRID.text.11], text[GRID.text.12], text[GRID.text.13],
text[GRID.text.14])


Could anyone help me adapt the code so I get the plot opened in R?

Many thanks in advance,
Guillaume



--
View this message in context: http://r.789695.n4.nabble.com/Plot-does-not-show-in-R-tp4693637.html
Sent from the R help mailing list archive at Nabble.com.


From john.archie.mckown at gmail.com  Mon Jul  7 17:54:23 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 7 Jul 2014 10:54:23 -0500
Subject: [R] getting numeric [0..6] day of week from POSIXct?
Message-ID: <CAAJSdjisDw6_SaKAabbXQjLJcr=O4vOPaXf-HEHTXsHuAzVn5Q@mail.gmail.com>

I have a column, dt, in a data.frame. It is a list of POSIXct objects.
I could use strftime(frame$dt,"%a") to get the day of week as
[sun..sat]. But I need the numeric value in the range of [0..6]. I
can't see a function to do this. I can get it by converting the
POSIXct objects to POSIXlt objects, then extracting the $wday. I don't
know why, but that just doesn't "feel" right to me. What I am actually
trying to do is group my data by Gregorian week (Sunday..Saturday). To
group the data, I am getting the ISO 8601 year and week number using
strftime(dt) with the format of "%G-%V" . But the ISO year&week number
start on Monday, not Sunday. So what I do is:

dt <- as.POSIXlt(frame$dt);
dt <- dt - dt$wday*86400; # 86400 is seconds in a day
frame$groupByWeekNumber <- strftime(dt,"%G-%V");

is there a better way? I have tried my best to find a simpler way.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From sarah.goslee at gmail.com  Mon Jul  7 18:07:43 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 7 Jul 2014 12:07:43 -0400
Subject: [R] Plot does not show in R
In-Reply-To: <1404747765990-4693637.post@n4.nabble.com>
References: <1404747765990-4693637.post@n4.nabble.com>
Message-ID: <CAM_vjumg5WuhVdMex8biPpso8wuEFaUDGE=NTOr7UFNi3Htyig@mail.gmail.com>

Hi,

Are you using the vennDiagram package? It's very important to specify.

If so, setting the argument filename=NULL then returns a grid object
(as stated in the help file), which you can then plot or do whatever
you wish with. A grid object is an R object that describes a plot, not
the plot itself.

http://stat.ethz.ch/R-manual/R-devel/library/grid/html/grid.grob.html
http://stat.ethz.ch/R-manual/R-devel/library/grid/html/grid.draw.html

Sarah

On Mon, Jul 7, 2014 at 11:42 AM, gktahon <Guillaume.Tahon at ugent.be> wrote:
> I'm trying to get my figure to open with R, but it does not come up.
> Here is my standard code:
>
> venn.diagram(
>         x = list(
>                 KP2 = c(2, 62, 22, 33, 11, 36, 26, 27, 28, 64, 5, 66, 10, 18, 68, 61, 6,
> 29, 19, 65, 30, 35, 32, 20, 69, 8, 31, 13, 21, 7),
>                 KP15 = c(2, 22, 39, 1, 14, 65, 67, 68, 1, 12, 23, 37, 4, 24, 25, 64, 52,
> 34, 9, 15, 13, 8, 16, 63, 3, 17),
>                 KP43 = c(39, 2, 49, 43, 51, 38, 56, 58, 60, 44, 54, 40, 50, 45, 57, 59,
> 46, 41, 47, 48, 42, 55, 53)
>                 ),
>         filename = "location\\nifH_AA_alles.jpg" ,
>         col = "transparent",
>         fill = c("red", "blue", "green"),
>         alpha = 0.5,
>         label.col = c("darkred", "white", "darkblue", "white", "white", "white",
> "darkgreen"),
>         cex = 2.5,
>         fontfamily = "serif",
>         fontface = "bold",
>         cat.default.pos = "text",
>         cat.col = c("darkred", "darkblue", "darkgreen"),
>         cat.cex = 2.5,
>         cat.fontfamily = "serif",
>         cat.dist = c(0.3, 0.4, 0.27),
>         cat.pos = 0
>         );
>
> This code saves the file to the desired location. However, I want the plot
> to open in the R interface, so I changed that line of the code to
> "filename=NULL". When I run the script afterwards, the plot does not open,
> instead, I get the following outputline:
>
> (polygon[GRID.polygon.1], polygon[GRID.polygon.2], polygon[GRID.polygon.3],
> polygon[GRID.polygon.4], polygon[GRID.polygon.5], polygon[GRID.polygon.6],
> text[GRID.text.7], text[GRID.text.8], text[GRID.text.9], text[GRID.text.10],
> text[GRID.text.11], text[GRID.text.12], text[GRID.text.13],
> text[GRID.text.14])
>
>
> Could anyone help me adapt the code so I get the plot opened in R?
>
> Many thanks in advance,
> Guillaume
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Mon Jul  7 18:08:51 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 7 Jul 2014 16:08:51 +0000
Subject: [R] getting numeric [0..6] day of week from POSIXct?
In-Reply-To: <CAAJSdjisDw6_SaKAabbXQjLJcr=O4vOPaXf-HEHTXsHuAzVn5Q@mail.gmail.com>
References: <CAAJSdjisDw6_SaKAabbXQjLJcr=O4vOPaXf-HEHTXsHuAzVn5Q@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F7CBEE@mb02.ads.tamu.edu>

?format.POSIXct

Particularly %w

> x <- Sys.time()
> as.numeric(format(x, "%w"))
[1] 1

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
Sent: Monday, July 7, 2014 10:54 AM
To: r-help
Subject: [R] getting numeric [0..6] day of week from POSIXct?

I have a column, dt, in a data.frame. It is a list of POSIXct objects.
I could use strftime(frame$dt,"%a") to get the day of week as
[sun..sat]. But I need the numeric value in the range of [0..6]. I
can't see a function to do this. I can get it by converting the
POSIXct objects to POSIXlt objects, then extracting the $wday. I don't
know why, but that just doesn't "feel" right to me. What I am actually
trying to do is group my data by Gregorian week (Sunday..Saturday). To
group the data, I am getting the ISO 8601 year and week number using
strftime(dt) with the format of "%G-%V" . But the ISO year&week number
start on Monday, not Sunday. So what I do is:

dt <- as.POSIXlt(frame$dt);
dt <- dt - dt$wday*86400; # 86400 is seconds in a day
frame$groupByWeekNumber <- strftime(dt,"%G-%V");

is there a better way? I have tried my best to find a simpler way.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jabbba at gmail.com  Mon Jul  7 18:12:47 2014
From: jabbba at gmail.com (=?UTF-8?Q?Marco_Barb=C3=A0ra?=)
Date: Mon, 7 Jul 2014 18:12:47 +0200
Subject: [R] survplot invert number at risk labels
In-Reply-To: <1404339435.9598.0@smtpauth.vanderbilt.edu>
References: <1404339435.9598.0@smtpauth.vanderbilt.edu>
Message-ID: <CABL+AMc=ZiT8yso_aJEvTMoQQHyQnROEUgjRZ8GnAa9adhuyag@mail.gmail.com>

Hi all,

and thank you for your interested answers. The problem could be
already solved. It is present on my old R 2.15.1
(x86_64-pc-linux-gnu), but after reproducing the error I got the
expected result on a R 3.0.2 through a web interface. However, since I
spent a considerable amount of time to understand what was happening,
I nevertheless decided to submit to your attention what i found.

The following code reproduces the problem on my system (and probably
on every Debian 7 "Wheezy" system with no cran repositories added)

library(survival)
library(rms)
Hazards <- rep(c(1/3, 1/10), each=50)
FupTimes <- rexp(100, rate=Hazards)
CensTimes <- rexp(100, rate=Hazards) # just for fun, we don't need
censoring here
Status <- ifelse(FupTimes <= CensTimes, 1, 0)
FupTimes <- ifelse(Status==1, FupTimes, CensTimes)
SurvObj <- Surv(FupTimes, Status)

# let's manually order the levels:
Covariate <- factor(rep(c("A","B"), each=50), labels=c("B", "A"))
SurvfitObj <- survfit(SurvObj ~ Covariate)
survplot(SurvfitObj, conf="none", n.risk=TRUE, levels.only=TRUE, time.inc=1)

(Resulting plot has nrisk labels inverted)

The error was much simpler than I initially thought, and it is
actually unrelated to survfit. I think that
survplot relies (on my R) on the factor's levels being alphabetically
ordered with the underlying numerical code appropriately arranged
(which I believe is the default behavior of factor() ). There is no
problem if the covariate is a character vector, since in that case the
survfit$strata names have the expected order.

Incidentally, debugging this little problem, I also found that if the
internal nrisk vector has length 1 the survplot function gives error
(line 244 in my version), and this is why I put time.inc=1 in the
previous call (This other issue is still present in 3.0.2)

I'm going to upgrade my R and check that this little error is actually gone.

Thank you
Marco

2014-07-03 0:17 GMT+02:00 Frank Harrell <f.harrell at vanderbilt.edu>:
> Please try hard to create a simple reproducible example, then I'll work
> on it.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Jul  7 19:29:04 2014
From: jholtman at gmail.com (jim holtman)
Date: Mon, 7 Jul 2014 13:29:04 -0400
Subject: [R] RMS equation
In-Reply-To: <CABLo8nGj593v_J256GqN7DSTAzCJ-kKm8MbhQwA7bApBY_o0=w@mail.gmail.com>
References: <CABLo8nGj593v_J256GqN7DSTAzCJ-kKm8MbhQwA7bApBY_o0=w@mail.gmail.com>
Message-ID: <CAAxdm-6Vi-5K6sHXkOSDXAUXpCNnji5xbjBgeXY2dVZez17hsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/f6097f54/attachment.pl>

From briofons at gmail.com  Mon Jul  7 18:05:38 2014
From: briofons at gmail.com (=?UTF-8?Q?Alfonso_de_U=C3=B1a?=)
Date: Mon, 7 Jul 2014 18:05:38 +0200
Subject: [R] Plot does not show in R
In-Reply-To: <1404747765990-4693637.post@n4.nabble.com>
References: <1404747765990-4693637.post@n4.nabble.com>
Message-ID: <CALEA=OJkyAduVisP28b_PDe5-51xPB1cW7Gx5KXY6F+LPeujPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/ca0d2416/attachment.pl>

From jwiley.psych at gmail.com  Mon Jul  7 22:15:11 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 8 Jul 2014 06:15:11 +1000
Subject: [R] Box-cox transformation
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3124301FF@DOM-MTW-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C31242F111@DOM-MTW-MAIL2.win.ad.jhu.edu>
	<CANz9Z_JDzGNA7qRR_8aOsoXdPMTRE-Fs+=HeNuV6041F9VOKgQ@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3124301FF@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <CANz9Z_JjEPQ7HOvGnNqSrfzpjs36AQa99Fg+YXWBHZovgn8dbQ@mail.gmail.com>

Dear Ravi,

In my previous example, I used the residuals, so:

sum [ (r_i / scaling)^2 ]

If you want to use the deviance from glm, that gives you:

sum [ r_i^2 ]

and since the scaling factor is just a constant for any given lambda,
then the modification would be:

sum [ r_i^2 ] / ( scaling^2 )

and is given in the modified code below (posted back to R-help in case
any else has this question).

Hope this helps,

Josh


##########################################
require(MASS)

myp <- function(y, lambda) (y^lambda-1)/lambda


lambda <- seq(-0.05, 0.45, len = 20)
N <- nrow(quine)
res <- matrix(numeric(0), nrow = length(lambda), 2, dimnames =
list(NULL, c("Lambda", "LL")))

# scaling contant
C <- exp(mean(log(quine$Days+1)))

for(i in seq_along(lambda)) {
  SS <- deviance(glm(myp(Days + 1, lambda[i]) ~ Eth*Sex*Age*Lrn, data = quine))
  LL <- (- (N/2) * log(SS/((C^lambda[i])^2)))
  res[i, ] <- c(lambda[i], LL)
}

# box cox
boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine, lambda = lambda)
# add our points on top to verify match
points(res[, 1], res[,2], pch = 16)

##########################################

On Mon, Jul 7, 2014 at 11:57 PM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> Dear Josh,
> Thank you very much.  I knew that the scaling had to be adjusted, but was not sure on how to do this.
>
> Can you please show me how to do this scaling with `glm'? In other words, how would I scale the deviance from glm?
>
> Thanks,
> Ravi
>
> -----Original Message-----
> From: Joshua Wiley [mailto:jwiley.psych at gmail.com]
> Sent: Sunday, July 06, 2014 11:34 PM
> To: Ravi Varadhan
> Cc: r-help at r-project.org
> Subject: Re: [R] Box-cox transformation
>
> Hi Ravi,
>
> Deviance is the SS in this case, but you need a normalizing constant adjusted by the lambda to put them on the same scale.  I modified your example below to simplify slightly and use the normalization (see the LL line).
>
> Cheers,
>
> Josh
>
> ######################################
>
> require(MASS)
>
> myp <- function(y, lambda) (y^lambda-1)/lambda
>
>
> lambda <- seq(-0.05, 0.45, len = 20)
> N <- nrow(quine)
> res <- matrix(numeric(0), nrow = length(lambda), 2, dimnames = list(NULL, c("Lambda", "LL")))
>
> # scaling contant
> C <- exp(mean(log(quine$Days+1)))
>
> for(i in seq_along(lambda)) {
>   r <- resid(lm(myp(Days + 1, lambda[i]) ~ Eth*Sex*Age*Lrn, data = quine))
>   LL <- (- (N/2) * log(sum((r/(C^lambda[i]))^2)))
>   res[i, ] <- c(lambda[i], LL)
> }
>
> # box cox
> boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine, lambda = lambda) # add our points on top to verify match points(res[, 1], res[,2], pch = 16)
>
> ######################################
>
>
>
> On Mon, Jul 7, 2014 at 11:33 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>> Hi,
>>
>> I am trying to do Box-Cox transformation, but I am not sure how to do it correctly.  Here is an example showing what I am trying:
>>
>>
>>
>> # example from MASS
>>
>> require(MASS)
>> boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
>>        lambda = seq(-0.05, 0.45, len = 20))
>>
>> # Here is My attempt at getting the profile likelihood for the Box-Cox
>> parameter lam <- seq(-0.05, 0.45, len = 20) dev <- rep(NA, length=20)
>>
>> for (i in 1:20) {
>> a <- lam[i]
>> ans <- glm(((Days+1)^a-1)/a ~ Eth*Sex*Age*Lrn, family=gaussian, data =
>> quine) dev[i] <- ans$deviance }
>>
>> plot(lam, dev, type="b", xlab="lambda", ylab="deviance")
>>
>> I am trying to create the profile likelihood for the Box-Cox parameter, but obviously I am not getting it right.  I am not sure that ans$deviance is the right thing to do.
>>
>> I would appreciate any guidance.
>>
>> Thanks & Best,
>> Ravi
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology http://joshuawiley.com/ Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518


From alvaroflores at derco.cl  Mon Jul  7 21:27:38 2014
From: alvaroflores at derco.cl (Alvaro Flores)
Date: Mon, 7 Jul 2014 15:27:38 -0400
Subject: [R] eclat help
Message-ID: <05A3A1E4B6BBE740AF1389A88C77583A04624B5D91@DCQLC02EXC02.derco.cl>

An embedded and charset-unspecified text was scrubbed...
Name: demo_basket.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/afb52cd8/attachment-0001.txt>

From eva.pcastro.lind at gmail.com  Mon Jul  7 20:02:12 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Mon, 7 Jul 2014 20:02:12 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
Message-ID: <CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/2e84ee89/attachment.pl>

From murdoch.duncan at gmail.com  Mon Jul  7 22:49:07 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Jul 2014 16:49:07 -0400
Subject: [R]
 =?iso-8859-1?q?=5BR-es=5D_Consulta_paquetizaci=F3n_con_versi?=
 =?iso-8859-1?q?=F3n_R_3=2E1=2E0?=
In-Reply-To: <CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
Message-ID: <53BB07C3.1040207@gmail.com>

On 07/07/2014, 2:02 PM, Eva Prieto Castro wrote:
> Hi eveybody,
> 
> I think the problem is with the package.skeleton function, because of the
> changes made in version 3.0.2. Since that version the management of
> environment parameter is different and I think it can justify the fact of
> package.skeleton is not considering my environment. I have not tested it
> yet.

The package.skeleton() function is intended to be used once as a quick
setup of a new package; you shouldn't be using it routinely.  After the
first quick setup, you should edit the source of the package to get what
you want.

A few more comments inline...

> 
> Regards.
> 
> Eva
> 
> 
> 2014-07-07 10:21 GMT+02:00 Eva Prieto Castro <evapcastro at yahoo.es>:
> 
>> Hi everybody
>>
>> I have a very big problem:
>>
>> With R 3.0.2 I could construct the package for this code:
>>
>>
>> if (exists('.ChrL.env') == TRUE) {
>>   rm(.ChrL.env)
>> }

The code above doesn't make sense in a package:  either you created the
environment, or you didn't.  That code will look through attached
packages, and if one of them has a variable of that name, will try to
remove it (but will likely fail to do so).

>>
>> .ChrL.env <- new.env()
>> .ChrL.env$lGlo <- list()
>> .ChrL.env$bStarted <- FALSE
>>
>> CheckGloCreated <- function() {
>>   if (.ChrL.env$bStarted == TRUE) {
>>     stop("Data structures were already initialized.", call.=FALSE)
>>   }
>> }
>> ChrL.Start <- function() {
>>   CheckGloCreated()
>>
>>   cat("Libraries have been loaded and data structure has been
>> initialized.\n")
>> }
>>
>>
>>
>> As you can do, I used an own environment (.ChrL.env).
>>
>>
>> Now, with R 3.1.0, I construct the package and I load it but it seems
>> .ChrL.env does not exists.
>>
>>
>> The method I use is the following:
>>
>>
>> rm(list=ls())
>>
>> setwd("D:/probando")
>>
>> source("probando.r", encoding="utf-8")
>>
>> package.skeleton(name="ChrL", path="D:/probando")

This says that you read the file d:/probando/probando.r, then created a
package in the same directory.  Don't do that.  Create the package
somewhere else, and copy the source to your functions into the R
subdirectory that gets created.

>>
>>
>> My Namespace:
>>
>> export(ChrL.Start)
>>
>>
>> My ChrL-internal.R:
>>
>> .ChrL.env <- new.env()

As far as I can see, you never added this to the package, so the
environment wouldn't be created.

Duncan Murdoch

>>
>>
>> Could you help me, please?. It is very urgent...
>>
>>
>> My project is more complex that the example I put, but I have tested with
>> this simple example and the problem is the same.
>>
>>
>> Thank you in advance.
>>
>>
>> Regards,
>>
>> Eva
>>         [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-help-es mailing list
>> R-help-es at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-help-es
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alvaroflores at derco.cl  Mon Jul  7 22:56:02 2014
From: alvaroflores at derco.cl (Alvaro Flores)
Date: Mon, 7 Jul 2014 16:56:02 -0400
Subject: [R] eclat problem
Message-ID: <05A3A1E4B6BBE740AF1389A88C77583A04624EF7D3@DCQLC02EXC02.derco.cl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/5722a75b/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jul  8 00:55:09 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Jul 2014 18:55:09 -0400
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
 =?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
Message-ID: <53BB254D.1020004@gmail.com>

On 07/07/2014, 6:39 PM, Eva Prieto Castro wrote:
> Hi again, Duncan
> 
> I think I must tell you all the details of the method I use, in order to
> make possible you notice my error. 

Your error is in calling package.skeleton.  As I said before, you should
have done this once, when you first thought of creating the ChrL
package, and *you should never call it again* for that package.

The normal workflow after the single call to that function is to edit
the files in the ChrL directory.  Don't call package.skeleton again.

If you want to describe the problems you are having, you should be
describing the contents of the ChrL directory, not how they were
created.  That is normally irrelevant, except that in your case, I think
that is the source of the problem.

Duncan Murdoch

However, you must know that this
> method run on 3.0.1 version (not in 3.0.2 and not in 3.1.0; this is the
> problem!).
> 
> 1) This is my code in "D:/probando.r" :
> 
> 
> .ChrL.env <- new.env()
> .ChrL.env$lGlo <- list()
> .ChrL.env$bStarted <- FALSE
> 
> CheckGloCreated <- function() {
>   if (.ChrL.env$bStarted == TRUE) {
>     stop("Data structures were already initialized.", call.=FALSE) 
>   }
> }
> ChrL.Start <- function() { 
>   CheckGloCreated()
>   cat("Tested.\n")
> }
> 
> 2) I open RGUI and run the following:
> 
> setwd("D:/")
> source("probando.r", encoding="utf-8")
> package.skeleton(name="ChrL", path="D:/")
> 
> 3) At this point, ChrL folder has been created in D:/, so I adjust
> Description and Namespace files. In R folder, ChrL-internal.r file is as
> I indicate below...
> 
>>>
>>>
>>> My Namespace:
>>>
>>> export(ChrL.Start)
>>>
>>>
>>> My ChrL-internal.R:
>>>
>>> .ChrL.env <- new.env()
> 
> 3) I go to bin folder (C:/Program Files/R/R-3.1.0/bin) and run the
> following:
> 
> R CMD INSTALL D:/ChrL
> 
> R CMD check D:/ChrL
> 
> R CMD build D:/ChrL
> 
> R CMD INSTALL --build D:/ChrL
> 
> Consequently, zip is generated, and I load it in RGUI. Then I do
> "library(ChrL)", but I see .ChrL.env does not exists. ?In 3.0.1 version
> it run ok!. What is the reason why in 3.1.0 version It does not exists?.
> 
> 
> Thanks again.
> 
> Eva
> 
> 
> 2014-07-07 22:49 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 07/07/2014, 2:02 PM, Eva Prieto Castro wrote:
>     > Hi eveybody,
>     >
>     > I think the problem is with the package.skeleton function, because
>     of the
>     > changes made in version 3.0.2. Since that version the management of
>     > environment parameter is different and I think it can justify the
>     fact of
>     > package.skeleton is not considering my environment. I have not
>     tested it
>     > yet.
> 
>     The package.skeleton() function is intended to be used once as a quick
>     setup of a new package; you shouldn't be using it routinely.  After the
>     first quick setup, you should edit the source of the package to get what
>     you want.
> 
>     A few more comments inline...
> 
>     >
>     > Regards.
>     >
>     > Eva
>     >
>     >
>     > 2014-07-07 10:21 GMT+02:00 Eva Prieto Castro <evapcastro at yahoo.es
>     <mailto:evapcastro at yahoo.es>>:
>     >
>     >> Hi everybody
>     >>
>     >> I have a very big problem:
>     >>
>     >> With R 3.0.2 I could construct the package for this code:
>     >>
>     >>
>     >> if (exists('.ChrL.env') == TRUE) {
>     >>   rm(.ChrL.env)
>     >> }
> 
>     The code above doesn't make sense in a package:  either you created the
>     environment, or you didn't.  That code will look through attached
>     packages, and if one of them has a variable of that name, will try to
>     remove it (but will likely fail to do so).
> 
>     >>
>     >> .ChrL.env <- new.env()
>     >> .ChrL.env$lGlo <- list()
>     >> .ChrL.env$bStarted <- FALSE
>     >>
>     >> CheckGloCreated <- function() {
>     >>   if (.ChrL.env$bStarted == TRUE) {
>     >>     stop("Data structures were already initialized.", call.=FALSE)
>     >>   }
>     >> }
>     >> ChrL.Start <- function() {
>     >>   CheckGloCreated()
>     >>
>     >>   cat("Libraries have been loaded and data structure has been
>     >> initialized.\n")
>     >> }
>     >>
>     >>
>     >>
>     >> As you can do, I used an own environment (.ChrL.env).
>     >>
>     >>
>     >> Now, with R 3.1.0, I construct the package and I load it but it seems
>     >> .ChrL.env does not exists.
>     >>
>     >>
>     >> The method I use is the following:
>     >>
>     >>
>     >> rm(list=ls())
>     >>
>     >> setwd("D:/probando")
>     >>
>     >> source("probando.r", encoding="utf-8")
>     >>
>     >> package.skeleton(name="ChrL", path="D:/probando")
> 
>     This says that you read the file d:/probando/probando.r, then created a
>     package in the same directory.  Don't do that.  Create the package
>     somewhere else, and copy the source to your functions into the R
>     subdirectory that gets created.
> 
>     >>
>     >>
>     >> My Namespace:
>     >>
>     >> export(ChrL.Start)
>     >>
>     >>
>     >> My ChrL-internal.R:
>     >>
>     >> .ChrL.env <- new.env()
> 
>     As far as I can see, you never added this to the package, so the
>     environment wouldn't be created.
> 
>     Duncan Murdoch
> 
>     >>
>     >>
>     >> Could you help me, please?. It is very urgent...
>     >>
>     >>
>     >> My project is more complex that the example I put, but I have
>     tested with
>     >> this simple example and the problem is the same.
>     >>
>     >>
>     >> Thank you in advance.
>     >>
>     >>
>     >> Regards,
>     >>
>     >> Eva
>     >>         [[alternative HTML version deleted]]
>     >>
>     >>
>     >> _______________________________________________
>     >> R-help-es mailing list
>     >> R-help-es at r-project.org <mailto:R-help-es at r-project.org>
>     >> https://stat.ethz.ch/mailman/listinfo/r-help-es
>     >>
>     >>
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
> 
>


From jjonphl at gmail.com  Tue Jul  8 01:38:59 2014
From: jjonphl at gmail.com (Miguel Manese)
Date: Tue, 8 Jul 2014 07:38:59 +0800
Subject: [R] getting numeric [0..6] day of week from POSIXct?
In-Reply-To: <CAAJSdjisDw6_SaKAabbXQjLJcr=O4vOPaXf-HEHTXsHuAzVn5Q@mail.gmail.com>
References: <CAAJSdjisDw6_SaKAabbXQjLJcr=O4vOPaXf-HEHTXsHuAzVn5Q@mail.gmail.com>
Message-ID: <CAK2ScDjQxBXb6taXUai0gV=br9kZrNCZX0s_LBA4VxXbLkgKrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/d76b4f0e/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jul  8 01:56:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Jul 2014 19:56:10 -0400
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
 =?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>	<53BB07C3.1040207@gmail.com>	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
Message-ID: <53BB339A.8030301@gmail.com>

On 07/07/2014, 7:13 PM, Eva Prieto Castro wrote:
> Duncan,
> 
> The ChrL folder has the following components:
> 
> * Description file
> * Namespace file
> * R folder, including 3 files: CheckGloCreated.r, ChrL.Start.r and
> ChrL-internal.r
> 

And does ChrL-internal.r contain just one line as you said before, i.e.

.ChrL.env <- new.env()

?

If so, how have you determined that .ChrL.env does not exist?  Names
that start with a "." don't show up in ls() listings by default. You
can't use exists() to test for .ChrL.env in either of the other files,
because they are probably sourced before it is (depending on the
collation order).  It won't exist when you run them, but it will exist
in the package namespace when you load the package.

Duncan Murdoch

> Obs.: Sometimes I remove man folder and another I adjust the rd files.
> In all cases the result is the same:.ChrL.env does not exist!.
> 
> Description file:
> 
> Package: ChrL
> Type: Package
> Title: What the package does (short line)
> Version: 1.0
> Date: 2014-07-08
> Author: Eva Prieto Castro
> Maintainer: Eva Prieto Castro <yourfault at somewhere.net
> <mailto:yourfault at somewhere.net>>
> Description: Test Pkg
> License: Unlimited
> 
> Namespace file:
> exportPattern("^[[:alpha:]]+")
> 
> I also test with this namespace file:
> export(ChrL.Start)
> 
> Thank you very much, again.
> 
> Eva
> 
> 
> 2014-07-08 0:55 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 07/07/2014, 6:39 PM, Eva Prieto Castro wrote:
>     > Hi again, Duncan
>     >
>     > I think I must tell you all the details of the method I use, in
>     order to
>     > make possible you notice my error.
> 
>     Your error is in calling package.skeleton.  As I said before, you should
>     have done this once, when you first thought of creating the ChrL
>     package, and *you should never call it again* for that package.
> 
>     The normal workflow after the single call to that function is to edit
>     the files in the ChrL directory.  Don't call package.skeleton again.
> 
>     If you want to describe the problems you are having, you should be
>     describing the contents of the ChrL directory, not how they were
>     created.  That is normally irrelevant, except that in your case, I think
>     that is the source of the problem.
> 
>     Duncan Murdoch
> 
>     However, you must know that this
>     > method run on 3.0.1 version (not in 3.0.2 and not in 3.1.0; this
>     is the
>     > problem!).
>     >
>     > 1) This is my code in "D:/probando.r" :
>     >
>     >
>     > .ChrL.env <- new.env()
>     > .ChrL.env$lGlo <- list()
>     > .ChrL.env$bStarted <- FALSE
>     >
>     > CheckGloCreated <- function() {
>     >   if (.ChrL.env$bStarted == TRUE) {
>     >     stop("Data structures were already initialized.", call.=FALSE)
>     >   }
>     > }
>     > ChrL.Start <- function() {
>     >   CheckGloCreated()
>     >   cat("Tested.\n")
>     > }
>     >
>     > 2) I open RGUI and run the following:
>     >
>     > setwd("D:/")
>     > source("probando.r", encoding="utf-8")
>     > package.skeleton(name="ChrL", path="D:/")
>     >
>     > 3) At this point, ChrL folder has been created in D:/, so I adjust
>     > Description and Namespace files. In R folder, ChrL-internal.r file
>     is as
>     > I indicate below...
>     >
>     >>>
>     >>>
>     >>> My Namespace:
>     >>>
>     >>> export(ChrL.Start)
>     >>>
>     >>>
>     >>> My ChrL-internal.R:
>     >>>
>     >>> .ChrL.env <- new.env()
>     >
>     > 3) I go to bin folder (C:/Program Files/R/R-3.1.0/bin) and run the
>     > following:
>     >
>     > R CMD INSTALL D:/ChrL
>     >
>     > R CMD check D:/ChrL
>     >
>     > R CMD build D:/ChrL
>     >
>     > R CMD INSTALL --build D:/ChrL
>     >
>     > Consequently, zip is generated, and I load it in RGUI. Then I do
>     > "library(ChrL)", but I see .ChrL.env does not exists. ?In 3.0.1
>     version
>     > it run ok!. What is the reason why in 3.1.0 version It does not
>     exists?.
>     >
>     >
>     > Thanks again.
>     >
>     > Eva
>     >
>     >
>     > 2014-07-07 22:49 GMT+02:00 Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>     > <mailto:murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>>:
>     >
>     >     On 07/07/2014, 2:02 PM, Eva Prieto Castro wrote:
>     >     > Hi eveybody,
>     >     >
>     >     > I think the problem is with the package.skeleton function,
>     because
>     >     of the
>     >     > changes made in version 3.0.2. Since that version the
>     management of
>     >     > environment parameter is different and I think it can
>     justify the
>     >     fact of
>     >     > package.skeleton is not considering my environment. I have not
>     >     tested it
>     >     > yet.
>     >
>     >     The package.skeleton() function is intended to be used once as
>     a quick
>     >     setup of a new package; you shouldn't be using it routinely.
>      After the
>     >     first quick setup, you should edit the source of the package
>     to get what
>     >     you want.
>     >
>     >     A few more comments inline...
>     >
>     >     >
>     >     > Regards.
>     >     >
>     >     > Eva
>     >     >
>     >     >
>     >     > 2014-07-07 10:21 GMT+02:00 Eva Prieto Castro
>     <evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>
>     >     <mailto:evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>>>:
>     >     >
>     >     >> Hi everybody
>     >     >>
>     >     >> I have a very big problem:
>     >     >>
>     >     >> With R 3.0.2 I could construct the package for this code:
>     >     >>
>     >     >>
>     >     >> if (exists('.ChrL.env') == TRUE) {
>     >     >>   rm(.ChrL.env)
>     >     >> }
>     >
>     >     The code above doesn't make sense in a package:  either you
>     created the
>     >     environment, or you didn't.  That code will look through attached
>     >     packages, and if one of them has a variable of that name, will
>     try to
>     >     remove it (but will likely fail to do so).
>     >
>     >     >>
>     >     >> .ChrL.env <- new.env()
>     >     >> .ChrL.env$lGlo <- list()
>     >     >> .ChrL.env$bStarted <- FALSE
>     >     >>
>     >     >> CheckGloCreated <- function() {
>     >     >>   if (.ChrL.env$bStarted == TRUE) {
>     >     >>     stop("Data structures were already initialized.",
>     call.=FALSE)
>     >     >>   }
>     >     >> }
>     >     >> ChrL.Start <- function() {
>     >     >>   CheckGloCreated()
>     >     >>
>     >     >>   cat("Libraries have been loaded and data structure has been
>     >     >> initialized.\n")
>     >     >> }
>     >     >>
>     >     >>
>     >     >>
>     >     >> As you can do, I used an own environment (.ChrL.env).
>     >     >>
>     >     >>
>     >     >> Now, with R 3.1.0, I construct the package and I load it
>     but it seems
>     >     >> .ChrL.env does not exists.
>     >     >>
>     >     >>
>     >     >> The method I use is the following:
>     >     >>
>     >     >>
>     >     >> rm(list=ls())
>     >     >>
>     >     >> setwd("D:/probando")
>     >     >>
>     >     >> source("probando.r", encoding="utf-8")
>     >     >>
>     >     >> package.skeleton(name="ChrL", path="D:/probando")
>     >
>     >     This says that you read the file d:/probando/probando.r, then
>     created a
>     >     package in the same directory.  Don't do that.  Create the package
>     >     somewhere else, and copy the source to your functions into the R
>     >     subdirectory that gets created.
>     >
>     >     >>
>     >     >>
>     >     >> My Namespace:
>     >     >>
>     >     >> export(ChrL.Start)
>     >     >>
>     >     >>
>     >     >> My ChrL-internal.R:
>     >     >>
>     >     >> .ChrL.env <- new.env()
>     >
>     >     As far as I can see, you never added this to the package, so the
>     >     environment wouldn't be created.
>     >
>     >     Duncan Murdoch
>     >
>     >     >>
>     >     >>
>     >     >> Could you help me, please?. It is very urgent...
>     >     >>
>     >     >>
>     >     >> My project is more complex that the example I put, but I have
>     >     tested with
>     >     >> this simple example and the problem is the same.
>     >     >>
>     >     >>
>     >     >> Thank you in advance.
>     >     >>
>     >     >>
>     >     >> Regards,
>     >     >>
>     >     >> Eva
>     >     >>         [[alternative HTML version deleted]]
>     >     >>
>     >     >>
>     >     >> _______________________________________________
>     >     >> R-help-es mailing list
>     >     >> R-help-es at r-project.org <mailto:R-help-es at r-project.org>
>     <mailto:R-help-es at r-project.org <mailto:R-help-es at r-project.org>>
>     >     >> https://stat.ethz.ch/mailman/listinfo/r-help-es
>     >     >>
>     >     >>
>     >     >
>     >     >       [[alternative HTML version deleted]]
>     >     >
>     >     > ______________________________________________
>     >     > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-help
>     >     > PLEASE do read the posting guide
>     >     http://www.R-project.org/posting-guide.html
>     >     > and provide commented, minimal, self-contained, reproducible
>     code.
>     >     >
>     >
>     >
> 
>


From ravi.varadhan at jhu.edu  Mon Jul  7 22:50:21 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 7 Jul 2014 20:50:21 +0000
Subject: [R] Box-cox transformation
In-Reply-To: <CANz9Z_JjEPQ7HOvGnNqSrfzpjs36AQa99Fg+YXWBHZovgn8dbQ@mail.gmail.com>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C31242F111@DOM-MTW-MAIL2.win.ad.jhu.edu>
	<CANz9Z_JDzGNA7qRR_8aOsoXdPMTRE-Fs+=HeNuV6041F9VOKgQ@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3124301FF@DOM-MTW-MAIL2.win.ad.jhu.edu>
	<CANz9Z_JjEPQ7HOvGnNqSrfzpjs36AQa99Fg+YXWBHZovgn8dbQ@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C312430474@DOM-MTW-MAIL2.win.ad.jhu.edu>

Thank you.  It is very helpful.

Ravi

-----Original Message-----
From: Joshua Wiley [mailto:jwiley.psych at gmail.com] 
Sent: Monday, July 07, 2014 4:15 PM
To: Ravi Varadhan
Cc: r-help at r-project.org
Subject: Re: [R] Box-cox transformation

Dear Ravi,

In my previous example, I used the residuals, so:

sum [ (r_i / scaling)^2 ]

If you want to use the deviance from glm, that gives you:

sum [ r_i^2 ]

and since the scaling factor is just a constant for any given lambda, then the modification would be:

sum [ r_i^2 ] / ( scaling^2 )

and is given in the modified code below (posted back to R-help in case any else has this question).

Hope this helps,

Josh


##########################################
require(MASS)

myp <- function(y, lambda) (y^lambda-1)/lambda


lambda <- seq(-0.05, 0.45, len = 20)
N <- nrow(quine)
res <- matrix(numeric(0), nrow = length(lambda), 2, dimnames = list(NULL, c("Lambda", "LL")))

# scaling contant
C <- exp(mean(log(quine$Days+1)))

for(i in seq_along(lambda)) {
  SS <- deviance(glm(myp(Days + 1, lambda[i]) ~ Eth*Sex*Age*Lrn, data = quine))
  LL <- (- (N/2) * log(SS/((C^lambda[i])^2)))
  res[i, ] <- c(lambda[i], LL)
}

# box cox
boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine, lambda = lambda) # add our points on top to verify match points(res[, 1], res[,2], pch = 16)

##########################################

On Mon, Jul 7, 2014 at 11:57 PM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> Dear Josh,
> Thank you very much.  I knew that the scaling had to be adjusted, but was not sure on how to do this.
>
> Can you please show me how to do this scaling with `glm'? In other words, how would I scale the deviance from glm?
>
> Thanks,
> Ravi
>
> -----Original Message-----
> From: Joshua Wiley [mailto:jwiley.psych at gmail.com]
> Sent: Sunday, July 06, 2014 11:34 PM
> To: Ravi Varadhan
> Cc: r-help at r-project.org
> Subject: Re: [R] Box-cox transformation
>
> Hi Ravi,
>
> Deviance is the SS in this case, but you need a normalizing constant adjusted by the lambda to put them on the same scale.  I modified your example below to simplify slightly and use the normalization (see the LL line).
>
> Cheers,
>
> Josh
>
> ######################################
>
> require(MASS)
>
> myp <- function(y, lambda) (y^lambda-1)/lambda
>
>
> lambda <- seq(-0.05, 0.45, len = 20)
> N <- nrow(quine)
> res <- matrix(numeric(0), nrow = length(lambda), 2, dimnames = 
> list(NULL, c("Lambda", "LL")))
>
> # scaling contant
> C <- exp(mean(log(quine$Days+1)))
>
> for(i in seq_along(lambda)) {
>   r <- resid(lm(myp(Days + 1, lambda[i]) ~ Eth*Sex*Age*Lrn, data = quine))
>   LL <- (- (N/2) * log(sum((r/(C^lambda[i]))^2)))
>   res[i, ] <- c(lambda[i], LL)
> }
>
> # box cox
> boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine, lambda = lambda) # add 
> our points on top to verify match points(res[, 1], res[,2], pch = 16)
>
> ######################################
>
>
>
> On Mon, Jul 7, 2014 at 11:33 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>> Hi,
>>
>> I am trying to do Box-Cox transformation, but I am not sure how to do it correctly.  Here is an example showing what I am trying:
>>
>>
>>
>> # example from MASS
>>
>> require(MASS)
>> boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
>>        lambda = seq(-0.05, 0.45, len = 20))
>>
>> # Here is My attempt at getting the profile likelihood for the 
>> Box-Cox parameter lam <- seq(-0.05, 0.45, len = 20) dev <- rep(NA, 
>> length=20)
>>
>> for (i in 1:20) {
>> a <- lam[i]
>> ans <- glm(((Days+1)^a-1)/a ~ Eth*Sex*Age*Lrn, family=gaussian, data 
>> =
>> quine) dev[i] <- ans$deviance }
>>
>> plot(lam, dev, type="b", xlab="lambda", ylab="deviance")
>>
>> I am trying to create the profile likelihood for the Box-Cox parameter, but obviously I am not getting it right.  I am not sure that ans$deviance is the right thing to do.
>>
>> I would appreciate any guidance.
>>
>> Thanks & Best,
>> Ravi
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology http://joshuawiley.com/ Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518



--
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology http://joshuawiley.com/ Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

From eva.pcastro.lind at gmail.com  Mon Jul  7 23:41:49 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Mon, 7 Jul 2014 23:41:49 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BB07C3.1040207@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
Message-ID: <CA+g8WVqB8=O2bP+GE-S7W53DccSFjYgFSnOHemSf5i5HpSSi8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140707/1750d0e4/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 00:39:12 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 00:39:12 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BB07C3.1040207@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
Message-ID: <CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/b4c8d964/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 01:13:20 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 01:13:20 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BB254D.1020004@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
Message-ID: <CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/36493bd5/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 01:18:16 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 01:18:16 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BB254D.1020004@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
Message-ID: <CA+g8WVr-WUHJLCpaYBvw3_1+buEBykejgk27bvvoTMdMYMAKZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/4b631a08/attachment.pl>

From frtog at vestas.com  Tue Jul  8 07:14:48 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Jul 2014 07:14:48 +0200
Subject: [R] parLapply on sqlQuery (from package RODBC)
In-Reply-To: <9D606AC27145D74F845B5AA9F37F9D9DEDB41BDB3F@MSGICTB.kochind.com>
References: <9D606AC27145D74F845B5AA9F37F9D9DEDB41BD88D@MSGICTB.kochind.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C67C0DF5@DKRDSEXC016.vestas.net>
	<9D606AC27145D74F845B5AA9F37F9D9DEDB41BDB3F@MSGICTB.kochind.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C6854E33@DKRDSEXC016.vestas.net>

Hi Dylan

Please remember to post to the list. You'll have a greater chance to get answers to your questions by doing so.

Also my name is Frede and not Med. The greetings "Med venlig hilsen" is the Danish translation of "Yours sincerely". Vestas is a global company so even the corporate language is English our signature in our emails is honoring the regional greetings from the country that we work in.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: Tevlin, Dylan [mailto:Dylan.Tevlin at kochind.com]
> Sent: 7. juli 2014 16:13
> To: Frede Aakmann T?gersen
> Subject: RE: parLapply on sqlQuery (from package RODBC)
> 
> Hi Med, thanks for the reply.
> 
> Maybe I should clarify, if I have a list of names as follows
> 
> names<-c("A", "B", "A", "C","C")
> 
> and a table in the database as follows
> 
> clientid	clientname
> 1	A
> 2	B
> 3	C
> 4	D
> 5	E
> 
> I need to convert the names list to the following ids list
> 
> ids<-c(1,2,1,3,3)
> 
> There are two ways I can see doing this.
> One would be to read my table into R (or more efficiently read in only the
> needed entries by your method), and then make an apply routine over the
> list of names to get the ids, which is straightforward.
> 
> Another would be to skip the intermediary step of reading the table in and
> apply over sql queries on names to get ids.  A further improvement on this
> would be to parallelize this apply routine.
> 
> I think the efficiency comparison between these two methods would be
> dependent on the size of the table, network connection, distance between
> server and client, so it is probably the case that your method combined with
> a bit more functionality would be the quickest way to accomplish my task.
> 
> Just from a learning standpoint, though, I wanted to understand how to pass
> a database connection into parLapply, and more generally how to pass a
> second parameter into parLapply.  It turns out I needed to use clusterEvalQ
> to set the environment of each of my "thread" nodes, since the global
> environment isn't preserved when a new node is created.
> 
> -----Original Message-----
> From: Frede Aakmann T?gersen [mailto:frtog at vestas.com]
> Sent: Thursday, July 03, 2014 12:51 AM
> To: Tevlin, Dylan; r-help at r-project.org
> Subject: RE: parLapply on sqlQuery (from package RODBC)
> 
> Hi
> 
> Why are you doing duplicate queries to the database (two As and Cs in your
> names vector)?
> 
> Why do 5 simultaneously connection to the database server? Woukld you do
> 500 connections?
> 
> Why not do one query and let the database server do the job for you?
> 
> Try this:
> 
> > options(useFancyQuotes = FALSE)
> >
> > query0 <- "select id from table where name in (%s)"
> >
> > names <- paste(sQuote(LETTERS[1:5]), collapse = ",") names
> [1] "'A','B','C','D','E'"
> >
> > query <- sprintf(query0, names)
> > query
> [1] "select id from table where name in ('A','B','C','D','E')"
> >
> > dataFromDB <- sqlQuery(dbConn, query)
> 
> This should work for MS SQL and MySQL servers.
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S This e-mail is subject to our e-
> mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice If you have received this e-mail
> in error please contact the sender.
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org]
> > On Behalf Of Tevlin, Dylan
> > Sent: 2. juli 2014 23:49
> > To: r-help at r-project.org
> > Subject: [R] parLapply on sqlQuery (from package RODBC)
> >
> > R Version : 2.14.1 x64
> > Running on Windows 7
> >
> > Connecting to a database on a remote Microsoft SQL Server 2012
> >
> > The short form of my problem is the following.
> >
> > I have an unordered vectors of names, say:
> >
> > names<-c("A", "B", "A", "C","C")
> >
> > each of which have an id in a table in my db.  I need to convert the
> > names to their corresponding ids.
> >
> > I currently have the following code to do it.
> > ###
> > names<-c("A", "B", "A", "C","C")
> > dbConn<-odbcDriverConnect(connection="connection string")
> > #successfully connects
> >
> > nameToID<-function(name, dbConn){
> >                 #dbConn : active db connection formed via odbcDriverConnect
> >                 #name     : a char string
> >
> >                 sqlQuery(dbConn, paste("select id from table where
> > name='", name, "'", sep="")) } sapply(names, nameToID, dbConn=dbConn)
> > ###
> >
> > Barring better ways to do this, which could involve loading the table
> > into R then working with the problem there (which is possible), I
> > understand why the following doesn't work, but I cannot seem to find a
> > solution.  Attempting to use parallelization via the package 'parallel' :
> >
> > ###
> > names<-c("A", "B", "A", "C","C")
> > dbConn<-odbcDriverConnect(connection="connection string")
> > #successfully connects
> >
> > nameToID<-function(name, dbConn){
> >                 #dbConn : active db connection formed via odbcDriverConnect
> >                 #name     : a char string
> >
> >                 sqlQuery(dbConn, paste("select id from table where
> > name='", name, "'", sep="")) }
> >
> > mc<-detectCores()
> > cl<-makeCluster(mc)
> > clusterExport(cl, c("sqlQuery", "dbConn"))
> > parSapply(cl, names, nameToID, dbConn=dbConn)    #incorrect passing of
> > nameToID's second argument
> > ###
> >
> > As in the comment, this is not the correct way to assign the second
> > argument to nameToID.
> >
> > I have also tried the following:
> >
> > parSapply(cl, names, function(x) nameToID(x, dbConn))
> >
> > in place of the previous parSapply call, but that also does not work,
> > with the error being thrown saying "the first parameter is not an open
> > RODBC connection", presumably referring to the first parameter of the
> > sqlQuery()
> >
> > The following code does work with parallization.
> >
> > ###
> > names<-c("A", "B", "A", "C","C")
> > dbConn<-odbcDriverConnect(connection="connection string")
> > #successfully connects nameToID<-function(name){
> >                 #name     : a char string
> >                 dbConn<-odbcDriverConnect(connection="string")
> >                 result<-sqlQuery(dbConn, paste("select id from table
> > where name='", name, "'", sep=""))
> >                 odbcClose(dbConn)
> >                 result
> > }
> >
> > mc<-detectCores()
> > cl<-makeCluster(mc)
> > clusterExport(cl, c("sqlQuery", "odbcDriverConnect", "odbcClose",
> "dbConn",
> > "nameToID"))      #throwing everything in
> > parSapply(cl, names, nameToID)
> > ###
> >
> > But the constant opening and closing a ton of the gains from
> > parallelization, and seems just a bit silly.
> >
> > So the overall question would be how to pass the second parameter (the
> > open db connection) to the function within parSapply, in much the same
> > way as it is done in the regular apply?  In general, how does one pass
> > a second, third, nth parameter to a function within a parallel routine?
> >
> > Thanks and if you need any more information let me know.
> >
> > -DT
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.


From eva.pcastro.lind at gmail.com  Tue Jul  8 06:56:39 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 06:56:39 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BB339A.8030301@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
Message-ID: <CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/78b313f2/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 07:00:09 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 07:00:09 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
Message-ID: <CA+g8WVporZa+Ez8ifpvNpkLFzbt0n=QFt9Wagn9tNpjT5k-_JA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/94a58f0a/attachment.pl>

From Guillaume.Tahon at UGent.be  Tue Jul  8 09:48:50 2014
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Tue, 8 Jul 2014 00:48:50 -0700 (PDT)
Subject: [R] Plot does not show in R
In-Reply-To: <CALEA=OJkyAduVisP28b_PDe5-51xPB1cW7Gx5KXY6F+LPeujPA@mail.gmail.com>
References: <1404747765990-4693637.post@n4.nabble.com>
	<CALEA=OJkyAduVisP28b_PDe5-51xPB1cW7Gx5KXY6F+LPeujPA@mail.gmail.com>
Message-ID: <003001cf9a80$f3cbb9e0$db632da0$@UGent.be>

Een ingesloten tekst met niet-gespecificeerde tekenset is gescrubt ...
Naam: niet beschikbaar
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/41112947/attachment.pl>

From arturrataj at gmail.com  Tue Jul  8 10:19:50 2014
From: arturrataj at gmail.com (Artur Rataj)
Date: Tue, 8 Jul 2014 10:19:50 +0200
Subject: [R] A custom legend for three data frames in one plot
In-Reply-To: <2677115.7rnp4KF62m@localhost.localdomain>
References: <CACO3_sBe-=qsot-1QNikBXsm+Vfo-Qkmv9E4FKYMMh16Gj_kYQ@mail.gmail.com>
	<2677115.7rnp4KF62m@localhost.localdomain>
Message-ID: <CACO3_sC+aTtgcS2ALGLAyVFoaFPwUsqiMTk8CBg7dnizw6J08Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/dcde576f/attachment.pl>

From arturrataj at gmail.com  Tue Jul  8 10:30:30 2014
From: arturrataj at gmail.com (Artur Rataj)
Date: Tue, 8 Jul 2014 10:30:30 +0200
Subject: [R] A custom legend for three data frames in one plot
In-Reply-To: <CACO3_sC+aTtgcS2ALGLAyVFoaFPwUsqiMTk8CBg7dnizw6J08Q@mail.gmail.com>
References: <CACO3_sBe-=qsot-1QNikBXsm+Vfo-Qkmv9E4FKYMMh16Gj_kYQ@mail.gmail.com>
	<2677115.7rnp4KF62m@localhost.localdomain>
	<CACO3_sC+aTtgcS2ALGLAyVFoaFPwUsqiMTk8CBg7dnizw6J08Q@mail.gmail.com>
Message-ID: <CACO3_sDJqzG6rWdykS0W1_V=mw-qxpYbQK-s7YWqxomC4Li_VA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/1fab330e/attachment.pl>

From vd4mmind at gmail.com  Tue Jul  8 10:30:59 2014
From: vd4mmind at gmail.com (Vivek Das)
Date: Tue, 8 Jul 2014 10:30:59 +0200
Subject: [R] Fwd: Need some assistance in plotting distributions
In-Reply-To: <CAFkF=gGUXJwzS-9jAyaP9YKfY7RrL3NXu+8ej901XytT4eEQxw@mail.gmail.com>
References: <CAFkF=gGUXJwzS-9jAyaP9YKfY7RrL3NXu+8ej901XytT4eEQxw@mail.gmail.com>
Message-ID: <CAFkF=gFe788tZEQfoJ7M9Xjg=dAkcWNLzHesnMf9DT4aQJE4Ow@mail.gmail.com>

Dear Users,

I need some assistance in plotting some distribution enrichments, like I
have files with some frequency values, now I want to plot plot the
distribution of those frequencies for one sample and then on the same plot
I want to plot the next samples where the frequency comes from another
file. Can you tell me which command to use? I would like to see the
distribution both in curve and histrogram format. Even if the frequency are
not normally distributed I would like to see to what extent they are
distributed and how much they are deviated from the normal distribution.
However I would expect a Gaussian curve but due to the low frequency in
LG_freq it would be not evident. Can you share some snippets for that? Am
attaching the two files, can you please guide me how to do it, I tried with
the plot function but I was unable to do, I read somewhere it was possible
to do with plot function with type 'L' but am unable to do that. I would
need some assistance in this. Thanks



----------------------------------------------------------

Das
-------------- next part --------------
Position	frequency
chr19_11942254	75
chr3_195511403	62.5
chr3_195508084	50
chr12_76424940	48.94
chr2_97268035	47.06
chr3_195507251	45.45
chr13_19751134	44.83
chr3_195511412	42.86
chr1_10689608	41.77
chr3_195515338	41.18
chr11_57958767	40.05
chr6_43308106	38.97
chr15_74427183	38.79
chr14_104643970	38.01
chr22_33670601	37.89
chr3_140277621	37.69
chr11_106680777	37.61
chrX_57146798	37.5
chrX_47086421	34.68
chr3_195511369	33.33
chr4_1087326	32.29
chr12_53069243	30.22
chr3_195511431	30
chr4_1087324	28.79
chr21_46012181	28.57
chr1_201179704	27.27
chr14_23371268	25.54
chr12_11506533	25
chr12_11506591	25
chr17_15457041	25
chr17_15457087	25
chr21_46012182	25
chr3_195511364	23.08
chr17_39305773	22.92
chr3_195507049	22.22
chr17_25973584	22.22
chr22_37964392	21.21
chr3_53263444	21.05
chr11_116719841	21.05
chr3_195507144	20
chr5_60628560	20
chr5_94991794	20
chr12_131359191	20
chr16_447262	20
chr17_39305774	20
chr17_39305769	19.64
chrX_44386604	19.05
chr13_48542810	18.18
chr21_46057625	17.81
chr2_61147615	17.65
chr12_7045912	17.56
chr17_39305760	17.54
chr17_39305761	16.95
chr1_17263165	16.67
chr5_146030285	16.67
chr6_31323226	16.67
chr11_637322	16.67
chrX_48675859	16.67
chr7_75028240	16.28
chr7_75028241	16.28
chr19_54973990	16.28
chr2_119604507	15.38
chr2_119604516	15.38
chr7_5352611	15.38
chr17_26089997	15.38
chr17_39305785	15.09
chr1_94495000	14.29
chr3_195512302	14.29
chr8_24811065	14.29
chr13_45008854	14.29
chrX_150349560	13.78
chr3_195509180	13.64
chr3_184039775	13.41
chr1_68960347	13.33
chr14_73978819	13.33
chr16_2228973	13.33
chr19_39401543	13.33
chr20_61460326	13.33
chr22_41721847	13.33
chr12_31250875	12.9
chr12_7045906	12.83
chr1_152082400	12.5
chr5_176886214	12.5
chr6_52664095	12.5
chr11_71276876	12.5
chr12_7045918	12.5
chr12_112037063	12.5
chr17_36666805	12.5
chr19_47249635	12.5
chr19_51919865	12.5
chr6_3751542	12.24
chr1_55167775	12.12
chr3_108829608	11.94
chr4_154506754	11.9
chr4_15690513	11.76
chr5_121515260	11.76
chr6_30711937	11.76
chr6_137365780	11.76
chr19_7927910	11.76
chr22_37964391	11.63
chr1_120479954	11.54
chrX_38145683	11.54
chr11_6411941	11.22
chr3_197880219	11.11
chr9_21367597	11.11
chr9_135947040	11.11
chr12_9083164	11.11
chr12_56666904	11.11
chr14_102550787	11.11
chr15_29418469	11.11
chr19_53770754	11.11
chrX_152967477	11.11
chr3_122284773	11.02
chr7_43679191	10.94
chr19_23159168	10.81
chr4_2263479	10.71
chr22_39358173	10.71
chr1_896173	10.53
chr1_152681679	10.53
chr1_196794685	10.53
chr1_206858647	10.53
chr2_119604501	10.53
chr4_1940235	10.53
chr4_110772956	10.53
chr6_44218787	10.53
chr11_18424472	10.53
chr14_64586208	10.53
chr19_16940257	10.53
chr1_152681695	10.48
chr21_46057634	10.47
chr6_151219997	10.34
chr6_107955970	10.08
chr1_248224586	10
chr1_248224587	10
chr2_119604688	10
chr9_135947042	10
chr19_40374025	10
chr20_3208503	10
chrX_150840056	10
chr22_37964389	9.78
chr6_112397545	9.76
chr19_40374023	9.76
chr17_73749982	9.68
chr12_53069229	9.66
chr19_36278848	9.62
chr1_3541668	9.52
chr2_241375390	9.52
chr8_38273487	9.52
chr11_73516094	9.52
chr16_1032172	9.52
chr16_28619615	9.52
chr17_80039228	9.52
chr22_38051445	9.52
chr22_37964408	9.45
chr3_197880204	9.38
chr9_124538672	9.38
chr18_32470282	9.3
chr13_19753704	9.23
chr1_203186947	9.09
chr4_13629164	9.09
chr4_17841298	9.09
chr4_101401073	9.09
chr4_170037774	9.09
chr5_76332530	9.09
chr9_32986009	9.09
chr14_55615321	9.09
chr16_30991325	9.09
chr17_78968823	9.09
chr19_14272414	9.09
chr1_152187437	9
chr6_166743049	8.93
chr1_91182180	8.89
chr9_130489354	8.82
chr17_47036073	8.82
chr17_6606350	8.75
chr8_133175742	8.74
chr4_57248712	8.7
chr6_34385300	8.7
chr7_2259002	8.7
chr8_145621579	8.7
chr9_131812242	8.7
chr10_50227779	8.7
chr10_118031512	8.7
chr10_135081469	8.7
chr15_42436820	8.7
chr17_16097870	8.7
chr17_37821636	8.7
chr19_34945172	8.7
chr19_55317437	8.7
chr22_37964387	8.7
chr12_130841616	8.57
chr19_20002820	8.51
chr11_1018382	8.45
chr19_17346702	8.42
chr1_152681696	8.33
chr8_134251333	8.33
chr9_7103690	8.33
chr10_51579199	8.33
chr17_4793831	8.33
chr17_4862841	8.33
chr19_18991121	8.33
chrX_152771461	8.22
chr1_152276598	8.16
chr8_142458157	8.16
chr1_28920394	8.11
chr3_195515460	8.11
chr4_17635330	8.11
chr19_39138514	8.11
chr12_76424952	8.02
chr1_12853629	8
chr3_195509606	8
chr5_174156448	8
chr6_13711629	8
chr9_13123252	8
chr10_15290649	8
chr10_23481993	8
chr15_56969830	8
chr19_4236994	8
chr19_33487128	8
chr22_38302504	8
chr7_1785413	7.97
chr12_7045900	7.95
chr5_78610466	7.89
chr5_137503717	7.89
chr17_36584794	7.89
chr12_6664485	7.87
chr7_149487483	7.84
chr16_31277200	7.84
chr17_27382098	7.81
chr7_138266466	7.79
chr1_25696990	7.69
chr1_156851274	7.69
chr1_185062192	7.69
chr1_208272311	7.69
chr3_113099810	7.69
chr3_140167368	7.69
chr3_187446275	7.69
chr7_151078680	7.69
chr7_151078686	7.69
chr8_42914267	7.69
chr9_115600852	7.69
chr14_23897864	7.69
chr16_57609382	7.69
chr16_84793023	7.69
chr17_7758397	7.69
chrX_47092601	7.69
chr4_1087328	7.63
chr15_65983337	7.56
chr6_39284209	7.55
chr11_562704	7.55
chr11_64567598	7.55
chr3_184039770	7.52
chr1_32193188	7.5
chr1_145295505	7.5
chr8_22436475	7.5
chr1_17295836	7.41
chr1_93300371	7.41
chr1_229677983	7.41
chr4_437494	7.41
chr4_3076749	7.41
chr5_133509682	7.41
chr8_95835780	7.41
chr12_112893769	7.41
chr14_97304131	7.41
chr19_46394391	7.41
chr19_58899571	7.41
chr20_62680268	7.41
chr21_48071719	7.41
chr22_39413947	7.41
chr5_43388474	7.32
chr11_55594723	7.32
chr11_123909529	7.32
chr13_21381681	7.32
chr15_44811380	7.32
chr17_3181890	7.32
chr4_79301135	7.27
chr13_53617369	7.27
chr11_120175847	7.25
chr19_613326	7.25
chr8_124350007	7.21
chr2_62066566	7.14
chr2_95942773	7.14
chr4_186064577	7.14
chr5_64956709	7.14
chr5_65310522	7.14
chr5_140051296	7.14
chr11_64121595	7.14
chr13_49794503	7.14
chr15_27193372	7.14
chr17_10248525	7.14
chr17_62496058	7.14
chr17_79097109	7.14
chr19_10654843	7.14
chr19_11918067	7.14
chr22_39136415	7.14
chrX_50085227	7.14
chr1_26671594	7.09
chr3_184039769	7.09
chr1_90048336	7.07
chr11_68478386	7.06
chr1_28271760	6.98
chr6_152527450	6.98
chr11_108332229	6.98
chr11_119187797	6.94
chr12_130185137	6.93
chr1_26671595	6.9
chr5_68665289	6.9
chr7_11630263	6.9
chr11_9025445	6.9
chr14_25100386	6.9
chr16_67763188	6.9
chr17_59534024	6.9
chr19_1074825	6.9
chr20_5987158	6.9
chr20_62190644	6.9
chr22_20749699	6.87
chr2_110372521	6.82
chr12_49691358	6.82
chr15_69347823	6.82
chr19_16640508	6.82
chr3_142840665	6.78
chr7_147600793	6.78
chr16_2147187	6.78
chr17_67286178	6.78
chr7_128865145	6.72
chr12_7045897	6.7
chr18_56204392	6.7
chr3_101576028	6.69
chr1_26662626	6.67
chr2_116510776	6.67
chr2_127811565	6.67
chr2_202402201	6.67
chr6_51918860	6.67
chr9_112811093	6.67
chr9_133951336	6.67
chr9_139934234	6.67
chr10_93784516	6.67
chr11_1643303	6.67
chr11_59382984	6.67
chr15_60748966	6.67
chr15_72492085	6.67
chr16_2141537	6.67
chr21_45711053	6.67
chrX_112022627	6.58
chr1_103381212	6.56
chr5_133702153	6.56
chr16_69221456	6.56
chr19_13888904	6.56
chr1_202880182	6.52
chr6_5771579	6.52
chr9_6604595	6.52
chr12_133351735	6.52
chr14_69558515	6.52
chr14_93408012	6.52
chr4_140811129	6.49
chr1_103461452	6.45
chr1_211477424	6.45
chr1_224371122	6.45
chr3_107799182	6.45
chr3_133302886	6.45
chr4_16513603	6.45
chr5_235351	6.45
chr5_59895072	6.45
chr5_132150036	6.45
chr5_137893653	6.45
chr6_46726496	6.45
chr6_111329263	6.45
chr9_114147617	6.45
chr10_17087182	6.45
chr10_88476505	6.45
chr11_1606381	6.45
chr12_80211203	6.45
chr12_124857020	6.45
chr14_93118237	6.45
chr17_26092624	6.45
chr17_40273220	6.45
chr18_63477195	6.45
chr21_46913427	6.45
chrX_118603929	6.45
chr8_52287292	6.38
chr12_121125264	6.38
chr11_6411936	6.37
chr3_14536359	6.35
chr7_102978252	6.35
chr9_79829247	6.35
chr12_25242704	6.35
chr15_44889041	6.35
chr22_19381969	6.35
chr19_4511395	6.33
chr14_69992716	6.32
chr18_56204393	6.32
chr6_111901465	6.31
chr1_15599019	6.25
chr1_115229393	6.25
chr1_162769606	6.25
chr2_167330356	6.25
chr6_33382887	6.25
chr9_136529136	6.25
chr9_139740797	6.25
chr12_123756143	6.25
chr13_33232422	6.25
chr14_74417145	6.25
chr14_76173360	6.25
chr16_1306815	6.25
chr19_4791966	6.25
chr19_43375937	6.25
chr19_51918849	6.25
chr7_56148932	6.15
chr12_124419938	6.15
chr22_37964413	6.14
chr3_100387829	6.12
chr11_1606372	6.12
chr17_34866734	6.12
chr22_45683265	6.12
chr17_3658411	6.09
chr1_153314241	6.06
chr1_197482049	6.06
chr1_205890902	6.06
chr2_38604295	6.06
chr3_62739264	6.06
chr7_56087369	6.06
chr7_63537819	6.06
chr8_101014589	6.06
chr9_2039768	6.06
chr9_137713953	6.06
chr11_1606367	6.06
chr11_60199927	6.06
chr11_119061117	6.06
chr12_71033058	6.06
chr12_113873162	6.06
chr14_39760248	6.06
chr15_42135978	6.06
chr15_78764102	6.06
chr16_69221462	6.06
chr19_23836509	6.06
chr19_51526465	6.06
chr19_53014735	6.06
chr20_2842771	6.06
chr11_12348765	6
chr11_62482776	6
chr17_9532094	6
chr11_94583391	5.97
chr1_186276430	5.88
chr1_231906731	5.88
chr2_32402654	5.88
chr2_233404481	5.88
chr7_44179454	5.88
chr8_120079656	5.88
chr11_65721195	5.88
chr12_117476983	5.88
chr14_69799888	5.88
chr14_94405461	5.88
chr15_62243173	5.88
chr16_3108202	5.88
chr16_50373917	5.88
chr22_39239850	5.88
chrX_89177334	5.88
chrX_133948845	5.88
chr9_19335017	5.83
chr5_138651825	5.8
chr7_44096378	5.8
chr15_40257979	5.8
chr1_40980776	5.78
chr4_44688714	5.77
chr11_133795834	5.77
chr16_2147451	5.77
chr18_43666168	5.77
chr11_6411966	5.75
chr16_19612993	5.75
chr1_202163137	5.71
chr1_226027561	5.71
chr2_152483650	5.71
chr2_220313949	5.71
chr2_232576108	5.71
chr3_48605318	5.71
chr3_186838994	5.71
chr4_96222790	5.71
chr5_74893761	5.71
chr6_149795442	5.71
chr7_100856141	5.71
chr8_126443178	5.71
chr11_47281470	5.71
chr11_113283602	5.71
chr17_7916479	5.71
chr17_36886629	5.71
chr17_48601139	5.71
chr17_67178330	5.71
chr19_18391886	5.71
chr19_24310449	5.71
chr19_50826473	5.71
chr21_46011569	5.71
chrX_99931136	5.71
chr17_38512376	5.68
chr1_145581206	5.66
chr12_21370118	5.66
chr18_2729382	5.66
chr1_186276166	5.63
chr2_43871858	5.63
chr16_57201044	5.63
chr1_52302059	5.56
chr1_204423810	5.56
chr3_27418337	5.56
chr3_195515459	5.56
chr6_27791948	5.56
chr6_31239775	5.56
chr7_135285679	5.56
chr10_27313443	5.56
chr10_69644686	5.56
chr10_124920070	5.56
chr12_111744725	5.56
chr12_111895062	5.56
chr13_78477730	5.56
chr15_76866550	5.56
chr16_18861275	5.56
chr17_49052156	5.56
chr19_19330123	5.56
chrX_70823544	5.56
chr22_37964419	5.51
chr2_210642074	5.48
chr3_113499918	5.48
chr17_10397704	5.48
chr5_137906749	5.45
chr6_50805773	5.45
chr15_58001174	5.45
chr15_63446256	5.45
chr15_68510953	5.45
chr19_15354117	5.45
chr4_5810032	5.44
chr1_16901184	5.41
chr1_31896614	5.41
chr1_156810866	5.41
chr1_228511297	5.41
chr2_8891632	5.41
chr2_103281630	5.41
chr4_55976929	5.41
chr5_179382669	5.41
chr9_95147922	5.41
chr9_117130733	5.41
chr9_136504999	5.41
chr10_52751393	5.41
chr15_91500394	5.41
chr15_101933617	5.41
chr18_43490485	5.41
chr18_77171450	5.41
chr19_290950	5.41
chr19_1754228	5.41
chr19_1979561	5.41
chr22_39710773	5.41
chr22_42033620	5.41
chrX_11779645	5.41
chrX_48689818	5.41
chr2_101185442	5.36
chr7_72754656	5.36
chrX_48837635	5.36
chr17_27380580	5.33
chrX_16870193	5.33
chr1_39945654	5.26
chr1_118426248	5.26
chr2_239186358	5.26
chr3_33260219	5.26
chr3_48573701	5.26
chr3_123166941	5.26
chr4_17838823	5.26
chr7_139229088	5.26
chr8_144451176	5.26
chr8_144671187	5.26
chr10_117824053	5.26
chr12_88479818	5.26
chr14_75386577	5.26
chr14_92403511	5.26
chr16_847744	5.26
chr16_70819662	5.26
chr19_16536056	5.26
chr19_45849009	5.26
chr20_6022716	5.26
chr20_45905096	5.26
chr22_45681947	5.26
chrX_23929956	5.26
chr7_28844114	5.23
chr1_45266265	5.19
chr2_31152327	5.19
chr2_179576710	5.19
chr4_88537258	5.19
chr5_1878736	5.19
chr8_87519310	5.19
chr3_8675389	5.17
chr5_118814536	5.17
chr7_140706308	5.17
chr15_28459327	5.17
chr15_71302292	5.17
chr16_85691005	5.17
chr19_54783206	5.17
chrX_24948634	5.17
chr9_95237069	5.16
chr4_88537322	5.15
chr11_1606369	5.15
chr1_15541927	5.13
chr1_152277262	5.13
chr1_176905484	5.13
chr4_68449410	5.13
chr4_81123829	5.13
chr4_124177180	5.13
chr5_148712421	5.13
chr6_84372085	5.13
chr7_76916888	5.13
chr7_103294652	5.13
chr8_82615287	5.13
chr8_126443492	5.13
chr9_133364742	5.13
chr11_3742047	5.13
chr18_19076652	5.13
chr19_36333036	5.13
chr19_47546115	5.13
chr22_21335314	5.13
chr22_45281390	5.13
chr1_236714227	5.1
chr19_45556358	5.1
chr21_46893880	5.1
chr2_74787291	5.08
chr11_16760337	5.08
chr13_42245084	5.08
chr17_65862662	5.08
chr1_201293671	5.06
chr2_61450409	5.06
chr5_177419761	5.06
chr11_47380524	5.06
chr16_417782	5.06
chr17_37374277	5.06
chrX_54496718	5.06
chrX_117119238	5.06
chrX_122830580	5.06
chr2_198621248	5.04
chr17_72863001	5.04
chr4_40337969	5.03
chr19_12878712	5.03
chr1_1231956	5
chr1_17265595	5
chr1_74506896	5
chr1_178861386	5
chr2_70162493	5
chr2_170463635	5
chr2_181925403	5
chr3_8607273	5
chr3_176752111	5
chr5_9379982	5
chr6_576786	5
chr6_43268964	5
chr6_127771491	5
chr8_109468115	5
chr9_842093	5
chr9_104375731	5
chr10_133946950	5
chr11_119185958	5
chr12_25362839	5
chr14_23816109	5
chr14_64489561	5
chr14_77229379	5
chr16_18861296	5
chr16_67692044	5
chr17_1546848	5
chr17_5042838	5
chr17_41477690	5
chr17_78765266	5
chr19_20727834	5
chr19_22271274	5
chr19_36359540	5
chr19_50104917	5
chr20_56227582	5
chr21_42752048	5
-------------- next part --------------
Position	frequency
chr1_12907316	35.71
chr1_12907400	28
chr1_12907905	37.50
chr1_16918411	36.36
chr1_26608883	20.69
chr1_40323027	25
chr1_62675667	31.16
chr1_62675673	22.82
chr1_62675674	26.56
chr1_154294464	23.53
chr1_198663246	22.22
chr1_215820884	20
chr1_233463785	57.14
chr2_110342744	36.36
chr3_100105773	54.76
chr3_100170628	20.91
chr3_195511283	50
chr3_195511911	21.74
chr3_195511937	35.90
chr3_195511983	46.15
chr4_88536899	37.01
chr4_88536901	33.08
chr4_122732809	31.58
chr4_125591724	51.77
chr5_68830537	22.22
chr5_140235716	28.57
chr5_140502742	46.88
chr6_24302200	47.89
chr6_132031159	25
chr6_136590640	27.94
chr7_40118360	22.22
chr7_100677285	22.09
chr7_156802567	28.57
chr8_7218752	77.78
chr8_48736460	20.69
chr8_98788165	24.10
chr9_33799026	20.48
chr9_79843064	20
chr9_96438989	20
chr9_96438992	21.15
chr9_96438998	30.36
chr9_96439007	56.60
chr9_96439019	29.82
chr9_136597579	45.45
chr9_139368543	44.44
chr10_51768625	22.22
chr11_1017789	22.47
chr11_1018385	30.51
chr11_1606138	27.27
chr11_68133065	24
chr11_117789327	37.50
chr11_122928540	62.50
chr12_10588418	28.57
chr12_53298675	44.44
chr12_76424940	62.79
chr12_109017680	24.34
chr12_112036779	55.56
chr13_100623505	20
chr14_105416257	53.33
chr15_22743235	33.33
chr15_41482321	48.36
chr15_65412291	25
chr17_21319860	49.56
chr17_38788488	25
chr17_38975149	42.37
chr17_38975151	43.86
chr17_39262036	56.52
chr17_39262037	62.50
chr17_39305760	25
chr17_39305761	25
chr17_39305769	31.03
chr17_39305773	32.14
chr17_39305774	32.14
chr17_39305785	55.17
chr19_501695	20
chr19_2248179	25.37
chr19_4511598	23.04
chr19_4511599	23.39
chr19_12543963	28.57
chr19_13875711	22.22
chr19_18260134	25
chr19_22363689	43.75
chr19_34945216	20
chr19_47918022	54.05
chr19_53303182	26.09
chr19_56273293	52.94
chr21_36042478	41.67
chr21_45959447	28.12
chr22_30761993	57.45
chr22_46760432	58.75
chrX_69639610	41.88
chrX_118603742	29.17
chrX_118603747	31.03
chrX_118603773	37.50

From jholtman at gmail.com  Tue Jul  8 12:19:36 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 8 Jul 2014 06:19:36 -0400
Subject: [R] Fwd: Need some assistance in plotting distributions
In-Reply-To: <CAFkF=gFe788tZEQfoJ7M9Xjg=dAkcWNLzHesnMf9DT4aQJE4Ow@mail.gmail.com>
References: <CAFkF=gGUXJwzS-9jAyaP9YKfY7RrL3NXu+8ej901XytT4eEQxw@mail.gmail.com>
	<CAFkF=gFe788tZEQfoJ7M9Xjg=dAkcWNLzHesnMf9DT4aQJE4Ow@mail.gmail.com>
Message-ID: <CAAxdm-4xOgvro_rbHY8MJim-pi3z4zknonw+L14PVbrn0yVhYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/9dbc2b1b/attachment.pl>

From vd4mmind at gmail.com  Tue Jul  8 12:37:30 2014
From: vd4mmind at gmail.com (Vivek Das)
Date: Tue, 8 Jul 2014 12:37:30 +0200
Subject: [R] Fwd: Need some assistance in plotting distributions
In-Reply-To: <CAAxdm-4xOgvro_rbHY8MJim-pi3z4zknonw+L14PVbrn0yVhYw@mail.gmail.com>
References: <CAFkF=gGUXJwzS-9jAyaP9YKfY7RrL3NXu+8ej901XytT4eEQxw@mail.gmail.com>
	<CAFkF=gFe788tZEQfoJ7M9Xjg=dAkcWNLzHesnMf9DT4aQJE4Ow@mail.gmail.com>
	<CAAxdm-4xOgvro_rbHY8MJim-pi3z4zknonw+L14PVbrn0yVhYw@mail.gmail.com>
Message-ID: <CAFkF=gGOwcfwsB0Xc2LvkgSQuFrqzi0Oa-vQcPhyFOdmysLEdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/8bdeb307/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jul  8 12:49:06 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Jul 2014 06:49:06 -0400
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
 =?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>	<53BB07C3.1040207@gmail.com>	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>	<53BB254D.1020004@gmail.com>	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
Message-ID: <53BBCCA2.9070802@gmail.com>

On 08/07/2014, 12:56 AM, Eva Prieto Castro wrote:
> Duncan,
> 
> Yes, it has exactly that line.
> 
> I know it does not exists because of this:
> 
>> library("ChrL")
>> .ChrL.env
> Error: objeto '.ChrL.env' no encontrado

That says that you did not export it.  It is only visible from code
within the package.

Duncan Murdoch

> 
> 
> 
> However, it should be as follows:
> 
>> library("ChrL")
>> .ChrL.env
> <environment: 0x00000000091eb898>
> 
> 
> I'm desperate; I have to solve this urgently and I don't find the solution.
> 
> Thanks again.
> 
> Eva
> 
> 
> 2014-07-08 1:56 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 07/07/2014, 7:13 PM, Eva Prieto Castro wrote:
>     > Duncan,
>     >
>     > The ChrL folder has the following components:
>     >
>     > * Description file
>     > * Namespace file
>     > * R folder, including 3 files: CheckGloCreated.r, ChrL.Start.r and
>     > ChrL-internal.r
>     >
> 
>     And does ChrL-internal.r contain just one line as you said before, i.e.
> 
>     .ChrL.env <- new.env()
> 
>     ?
> 
>     If so, how have you determined that .ChrL.env does not exist?  Names
>     that start with a "." don't show up in ls() listings by default. You
>     can't use exists() to test for .ChrL.env in either of the other files,
>     because they are probably sourced before it is (depending on the
>     collation order).  It won't exist when you run them, but it will exist
>     in the package namespace when you load the package.
> 
>     Duncan Murdoch
> 
>     > Obs.: Sometimes I remove man folder and another I adjust the rd files.
>     > In all cases the result is the same:.ChrL.env does not exist!.
>     >
>     > Description file:
>     >
>     > Package: ChrL
>     > Type: Package
>     > Title: What the package does (short line)
>     > Version: 1.0
>     > Date: 2014-07-08
>     > Author: Eva Prieto Castro
>     > Maintainer: Eva Prieto Castro <yourfault at somewhere.net
>     <mailto:yourfault at somewhere.net>
>     > <mailto:yourfault at somewhere.net <mailto:yourfault at somewhere.net>>>
>     > Description: Test Pkg
>     > License: Unlimited
>     >
>     > Namespace file:
>     > exportPattern("^[[:alpha:]]+")
>     >
>     > I also test with this namespace file:
>     > export(ChrL.Start)
>     >
>     > Thank you very much, again.
>     >
>     > Eva
>     >
>     >
>     > 2014-07-08 0:55 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
>     <mailto:murdoch.duncan at gmail.com>
>     > <mailto:murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>>:
>     >
>     >     On 07/07/2014, 6:39 PM, Eva Prieto Castro wrote:
>     >     > Hi again, Duncan
>     >     >
>     >     > I think I must tell you all the details of the method I use, in
>     >     order to
>     >     > make possible you notice my error.
>     >
>     >     Your error is in calling package.skeleton.  As I said before,
>     you should
>     >     have done this once, when you first thought of creating the ChrL
>     >     package, and *you should never call it again* for that package.
>     >
>     >     The normal workflow after the single call to that function is
>     to edit
>     >     the files in the ChrL directory.  Don't call package.skeleton
>     again.
>     >
>     >     If you want to describe the problems you are having, you should be
>     >     describing the contents of the ChrL directory, not how they were
>     >     created.  That is normally irrelevant, except that in your
>     case, I think
>     >     that is the source of the problem.
>     >
>     >     Duncan Murdoch
>     >
>     >     However, you must know that this
>     >     > method run on 3.0.1 version (not in 3.0.2 and not in 3.1.0; this
>     >     is the
>     >     > problem!).
>     >     >
>     >     > 1) This is my code in "D:/probando.r" :
>     >     >
>     >     >
>     >     > .ChrL.env <- new.env()
>     >     > .ChrL.env$lGlo <- list()
>     >     > .ChrL.env$bStarted <- FALSE
>     >     >
>     >     > CheckGloCreated <- function() {
>     >     >   if (.ChrL.env$bStarted == TRUE) {
>     >     >     stop("Data structures were already initialized.",
>     call.=FALSE)
>     >     >   }
>     >     > }
>     >     > ChrL.Start <- function() {
>     >     >   CheckGloCreated()
>     >     >   cat("Tested.\n")
>     >     > }
>     >     >
>     >     > 2) I open RGUI and run the following:
>     >     >
>     >     > setwd("D:/")
>     >     > source("probando.r", encoding="utf-8")
>     >     > package.skeleton(name="ChrL", path="D:/")
>     >     >
>     >     > 3) At this point, ChrL folder has been created in D:/, so I
>     adjust
>     >     > Description and Namespace files. In R folder,
>     ChrL-internal.r file
>     >     is as
>     >     > I indicate below...
>     >     >
>     >     >>>
>     >     >>>
>     >     >>> My Namespace:
>     >     >>>
>     >     >>> export(ChrL.Start)
>     >     >>>
>     >     >>>
>     >     >>> My ChrL-internal.R:
>     >     >>>
>     >     >>> .ChrL.env <- new.env()
>     >     >
>     >     > 3) I go to bin folder (C:/Program Files/R/R-3.1.0/bin) and
>     run the
>     >     > following:
>     >     >
>     >     > R CMD INSTALL D:/ChrL
>     >     >
>     >     > R CMD check D:/ChrL
>     >     >
>     >     > R CMD build D:/ChrL
>     >     >
>     >     > R CMD INSTALL --build D:/ChrL
>     >     >
>     >     > Consequently, zip is generated, and I load it in RGUI. Then I do
>     >     > "library(ChrL)", but I see .ChrL.env does not exists. ?In 3.0.1
>     >     version
>     >     > it run ok!. What is the reason why in 3.1.0 version It does not
>     >     exists?.
>     >     >
>     >     >
>     >     > Thanks again.
>     >     >
>     >     > Eva
>     >     >
>     >     >
>     >     > 2014-07-07 22:49 GMT+02:00 Duncan Murdoch
>     >     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>     <mailto:murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>
>     >     > <mailto:murdoch.duncan at gmail.com
>     <mailto:murdoch.duncan at gmail.com> <mailto:murdoch.duncan at gmail.com
>     <mailto:murdoch.duncan at gmail.com>>>>:
>     >     >
>     >     >     On 07/07/2014, 2:02 PM, Eva Prieto Castro wrote:
>     >     >     > Hi eveybody,
>     >     >     >
>     >     >     > I think the problem is with the package.skeleton function,
>     >     because
>     >     >     of the
>     >     >     > changes made in version 3.0.2. Since that version the
>     >     management of
>     >     >     > environment parameter is different and I think it can
>     >     justify the
>     >     >     fact of
>     >     >     > package.skeleton is not considering my environment. I
>     have not
>     >     >     tested it
>     >     >     > yet.
>     >     >
>     >     >     The package.skeleton() function is intended to be used
>     once as
>     >     a quick
>     >     >     setup of a new package; you shouldn't be using it routinely.
>     >      After the
>     >     >     first quick setup, you should edit the source of the package
>     >     to get what
>     >     >     you want.
>     >     >
>     >     >     A few more comments inline...
>     >     >
>     >     >     >
>     >     >     > Regards.
>     >     >     >
>     >     >     > Eva
>     >     >     >
>     >     >     >
>     >     >     > 2014-07-07 10:21 GMT+02:00 Eva Prieto Castro
>     >     <evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>
>     <mailto:evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>>
>     >     >     <mailto:evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>
>     <mailto:evapcastro at yahoo.es <mailto:evapcastro at yahoo.es>>>>:
>     >     >     >
>     >     >     >> Hi everybody
>     >     >     >>
>     >     >     >> I have a very big problem:
>     >     >     >>
>     >     >     >> With R 3.0.2 I could construct the package for this code:
>     >     >     >>
>     >     >     >>
>     >     >     >> if (exists('.ChrL.env') == TRUE) {
>     >     >     >>   rm(.ChrL.env)
>     >     >     >> }
>     >     >
>     >     >     The code above doesn't make sense in a package:  either you
>     >     created the
>     >     >     environment, or you didn't.  That code will look through
>     attached
>     >     >     packages, and if one of them has a variable of that
>     name, will
>     >     try to
>     >     >     remove it (but will likely fail to do so).
>     >     >
>     >     >     >>
>     >     >     >> .ChrL.env <- new.env()
>     >     >     >> .ChrL.env$lGlo <- list()
>     >     >     >> .ChrL.env$bStarted <- FALSE
>     >     >     >>
>     >     >     >> CheckGloCreated <- function() {
>     >     >     >>   if (.ChrL.env$bStarted == TRUE) {
>     >     >     >>     stop("Data structures were already initialized.",
>     >     call.=FALSE)
>     >     >     >>   }
>     >     >     >> }
>     >     >     >> ChrL.Start <- function() {
>     >     >     >>   CheckGloCreated()
>     >     >     >>
>     >     >     >>   cat("Libraries have been loaded and data structure
>     has been
>     >     >     >> initialized.\n")
>     >     >     >> }
>     >     >     >>
>     >     >     >>
>     >     >     >>
>     >     >     >> As you can do, I used an own environment (.ChrL.env).
>     >     >     >>
>     >     >     >>
>     >     >     >> Now, with R 3.1.0, I construct the package and I load it
>     >     but it seems
>     >     >     >> .ChrL.env does not exists.
>     >     >     >>
>     >     >     >>
>     >     >     >> The method I use is the following:
>     >     >     >>
>     >     >     >>
>     >     >     >> rm(list=ls())
>     >     >     >>
>     >     >     >> setwd("D:/probando")
>     >     >     >>
>     >     >     >> source("probando.r", encoding="utf-8")
>     >     >     >>
>     >     >     >> package.skeleton(name="ChrL", path="D:/probando")
>     >     >
>     >     >     This says that you read the file d:/probando/probando.r,
>     then
>     >     created a
>     >     >     package in the same directory.  Don't do that.  Create
>     the package
>     >     >     somewhere else, and copy the source to your functions
>     into the R
>     >     >     subdirectory that gets created.
>     >     >
>     >     >     >>
>     >     >     >>
>     >     >     >> My Namespace:
>     >     >     >>
>     >     >     >> export(ChrL.Start)
>     >     >     >>
>     >     >     >>
>     >     >     >> My ChrL-internal.R:
>     >     >     >>
>     >     >     >> .ChrL.env <- new.env()
>     >     >
>     >     >     As far as I can see, you never added this to the
>     package, so the
>     >     >     environment wouldn't be created.
>     >     >
>     >     >     Duncan Murdoch
>     >     >
>     >     >     >>
>     >     >     >>
>     >     >     >> Could you help me, please?. It is very urgent...
>     >     >     >>
>     >     >     >>
>     >     >     >> My project is more complex that the example I put,
>     but I have
>     >     >     tested with
>     >     >     >> this simple example and the problem is the same.
>     >     >     >>
>     >     >     >>
>     >     >     >> Thank you in advance.
>     >     >     >>
>     >     >     >>
>     >     >     >> Regards,
>     >     >     >>
>     >     >     >> Eva
>     >     >     >>         [[alternative HTML version deleted]]
>     >     >     >>
>     >     >     >>
>     >     >     >> _______________________________________________
>     >     >     >> R-help-es mailing list
>     >     >     >> R-help-es at r-project.org
>     <mailto:R-help-es at r-project.org> <mailto:R-help-es at r-project.org
>     <mailto:R-help-es at r-project.org>>
>     >     <mailto:R-help-es at r-project.org
>     <mailto:R-help-es at r-project.org> <mailto:R-help-es at r-project.org
>     <mailto:R-help-es at r-project.org>>>
>     >     >     >> https://stat.ethz.ch/mailman/listinfo/r-help-es
>     >     >     >>
>     >     >     >>
>     >     >     >
>     >     >     >       [[alternative HTML version deleted]]
>     >     >     >
>     >     >     > ______________________________________________
>     >     >     > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>     >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>> mailing
>     list
>     >     >     > https://stat.ethz.ch/mailman/listinfo/r-help
>     >     >     > PLEASE do read the posting guide
>     >     >     http://www.R-project.org/posting-guide.html
>     >     >     > and provide commented, minimal, self-contained,
>     reproducible
>     >     code.
>     >     >     >
>     >     >
>     >     >
>     >
>     >
> 
>


From frtog at vestas.com  Tue Jul  8 12:56:02 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Jul 2014 12:56:02 +0200
Subject: [R] Fwd: Need some assistance in plotting distributions
In-Reply-To: <CAFkF=gGOwcfwsB0Xc2LvkgSQuFrqzi0Oa-vQcPhyFOdmysLEdQ@mail.gmail.com>
References: <CAFkF=gGUXJwzS-9jAyaP9YKfY7RrL3NXu+8ej901XytT4eEQxw@mail.gmail.com>
	<CAFkF=gFe788tZEQfoJ7M9Xjg=dAkcWNLzHesnMf9DT4aQJE4Ow@mail.gmail.com>
	<CAAxdm-4xOgvro_rbHY8MJim-pi3z4zknonw+L14PVbrn0yVhYw@mail.gmail.com>
	<CAFkF=gGOwcfwsB0Xc2LvkgSQuFrqzi0Oa-vQcPhyFOdmysLEdQ@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C685501D@DKRDSEXC016.vestas.net>

Well

plot(density(a$frequency), col = "blue")

lines(density(b$frequency), col = "green")

Where a is as Jim defined it and b similar from the other data file.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Vivek Das
> Sent: 8. juli 2014 12:38
> To: jim holtman
> Cc: R help
> Subject: Re: [R] Fwd: Need some assistance in plotting distributions
> 
> Dear Jim,
> 
> Thank you for replying to my query. Both the files contains tumor
> mutational frequencies. The LG_freq contains the entire mutational
> landscape and the HIPS2_freq contains mutational frequency of one clone. I
> want to see how both the frequency curve are behaving in one plot. Is that
> possible to see in one plot with different colors to distinguish the
> frequency distribution of both files in one image where I can see both the
> plots. I have tried density plot but could not figure out how to add the
> next frequency distribution file to the same plot and see the difference in
> both the plots in one image with different colors. Can this be done?
> 
> ----------------------------------------------------------
> 
> Vivek Das
> 
> 
> 
> On Tue, Jul 8, 2014 at 12:19 PM, jim holtman <jholtman at gmail.com> wrote:
> 
> > Have you tried the density function:
> >
> > > a <- read.table('/users/jim/downloads/LG_freq.txt',header = TRUE)
> > > str(a)
> > 'data.frame':   669 obs. of  2 variables:
> >  $ Position : Factor w/ 669 levels "chr1_103381212",..: 308 463 458 160
> > 393 457 165 464 3 467 ...
> >  $ frequency: num  75 62.5 50 48.9 47.1 ...
> > > plot(density(a$frequency))
> > >
> >
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> >
> > On Tue, Jul 8, 2014 at 4:30 AM, Vivek Das <vd4mmind at gmail.com> wrote:
> >
> >> Dear Users,
> >>
> >> I need some assistance in plotting some distribution enrichments, like I
> >> have files with some frequency values, now I want to plot plot the
> >> distribution of those frequencies for one sample and then on the same
> plot
> >> I want to plot the next samples where the frequency comes from another
> >> file. Can you tell me which command to use? I would like to see the
> >> distribution both in curve and histrogram format. Even if the frequency
> >> are
> >> not normally distributed I would like to see to what extent they are
> >> distributed and how much they are deviated from the normal distribution.
> >> However I would expect a Gaussian curve but due to the low frequency in
> >> LG_freq it would be not evident. Can you share some snippets for that?
> Am
> >> attaching the two files, can you please guide me how to do it, I tried
> >> with
> >> the plot function but I was unable to do, I read somewhere it was possible
> >> to do with plot function with type 'L' but am unable to do that. I would
> >> need some assistance in this. Thanks
> >>
> >>
> >>
> >> ----------------------------------------------------------
> >>
> >> Das
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Tue Jul  8 14:14:48 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 8 Jul 2014 14:14:48 +0200
Subject: [R] sort order of a character sequence is different on windose
 and linux (linux result)
In-Reply-To: <53B93DD0.2060200@gmail.com>
References: <CAAjnpdjeK1ZwK80XZ_Din-D8=M-Ocx46mbubmJNSbcAhH--Tyg@mail.gmail.com>
	<53B92DC7.9090009@gmail.com>
	<CAAjnpdi-G8PA9hpa93cHOpkUziCH5b1q1dBRUGBWumMNXqorTw@mail.gmail.com>
	<53B93404.7030402@gmail.com>
	<CAAjnpdjDkcFKjskBdkYXWo_vPWrrVSaSXLmBNFzj4yVzYitU9Q@mail.gmail.com>
	<53B93DD0.2060200@gmail.com>
Message-ID: <CAAjnpdidUAvMFUq=GsHBiFFhV_2K+mOpkxmfEnw4qstqhoC08A@mail.gmail.com>

>From my reading of
http://r.789695.n4.nabble.com/internal-string-comparison-Scollate-td4687584.html
they have good arguments to ask for Scollate whatever it is in the R public API.


And from my point of view R would benefit from a tight integration of
data.table.
Without data.table R is very impractical to use, with data which is
avaiable today.

On 6 July 2014 14:15, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 06/07/2014, 7:56 AM, Witold E Wolski wrote:
>> This is the info I got from the data.table developers... Seems that
>> they did have tried to find a more elegant solution solution.:
>
> From my reading of the response below, data.table doesn't use R's sort()
> function to do their sorting.  You should use whatever sort function
> they use if you want to match their sort order.
>
> Duncan Murdoch
>
>>
>>
>> data.table used to support this until 1.8.6. But since Scollate became
>> not a part of authorised R-API (IIUC) anymore at some point,
>> data.table only supports sort/order under the C-locale.
>>
>> data.table's ordering/sorting is over 10-20x faster than base's and
>> the only way right now (IIUC) to sort by locale is to use base's
>> sort/order.
>>
>> This post may give some more insight.
>> http://r.789695.n4.nabble.com/internal-string-comparison-Scollate-td4687584.html
>>
>> In summary, we support only C-locale.
>>
>>
>> On 6 July 2014 13:33, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 06/07/2014, 7:19 AM, Witold E Wolski wrote:
>>>> It seems that the package I am developing depends on the locale "C"
>>>> because of interactions with other packages (data.table).
>>>>
>>>> So I would like to set the locale to "C" as soon as the package is loaded.
>>>> Where can I do it .. I could of course set it in every function in my
>>>> package but...
>>>>
>>>
>>> As the help page says, you can't do it reliably on all platforms, and
>>> you really shouldn't even try:  that will affect other things that the
>>> user does.
>>>
>>> You will need to find another solution to your problem.
>>>
>>> Duncan Murdoch
>>
>>
>>
>



-- 
Witold Eryk Wolski


From ligges at statistik.tu-dortmund.de  Tue Jul  8 14:23:11 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Jul 2014 14:23:11 +0200
Subject: [R] R help
In-Reply-To: <CAEAZOpX29a-+rqrQFCqeAOjf+4+eP6J_3OgcriWVF5JWm_aHoQ@mail.gmail.com>
References: <CAEAZOpX29a-+rqrQFCqeAOjf+4+eP6J_3OgcriWVF5JWm_aHoQ@mail.gmail.com>
Message-ID: <53BBE2AF.4050202@statistik.tu-dortmund.de>



On 01.07.2014 17:18, Andre Weeks wrote:
> To whom it may concern:
>
> I installed R 3.1 and I get this.
>
> In normalizePath(path.expand(path), winslash, mustWork) :
>    path[1]="\\network\users\aweeks\My Documents/R/win-library/3.1": Access
> is denied
>
> Is there any way to change this path? I have looked it up on the internet
> but cannot seem to find the right option.
>
> If you could help me out, that would be fantastic.

See

?.libPaths

and find that you can set an environmetn variable R_LIBS_USER to change 
that path.

Best,
Uwe Ligges



>
> Thanks in advance and have a wonderful day!
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Jul  8 14:25:10 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Jul 2014 14:25:10 +0200
Subject: [R] (PLM- package) Residual-Plotting and missing Values
In-Reply-To: <001a01cf9537$ccfbfd00$66f3f700$@uni-koeln.de>
References: <001a01cf9537$ccfbfd00$66f3f700$@uni-koeln.de>
Message-ID: <53BBE326.2060803@statistik.tu-dortmund.de>

If you havn't got a response yet, ask the package authors.

Best,
Uwe Ligges



On 01.07.2014 16:21, Katharina Mersmann wrote:
> Dear R-Community,
>
> I tried plotting the residuals of an FE-model estimated via plm .
>
> And detected that there are no residuals in the plot for the last two
> countries.
>
> I guess this happens because for some countries values are missing and R
> gives me the following for
>
>
>
>> fixed.reg1.new$resid[1]
>
>           5
>
> -0.4051985
>
>
>
> Because the first 4 elements are missing. So there are residuals different
> from zero for the last two countries, but because of NA there?s a shift
> because the residuals are not padded to the correct length.
>
>
>
> I?ve  read  in https://stat.ethz.ch/pipermail/r-help/2008-June/166312.html
> and the manual
>
> that na.action=na.exclude is useful in lm-case to avoid this:  ?when
> na.exclude is used the residuals and predictions are padded to the correct
> length by inserting NAs for cases omitted by na.exclude?
>
>
>
> and tried it for my plm regression, but it does not work.
>
>
>
> Perhaps you have an Idea how to get residuals into the correct length? Or
> another way to deal with it?
>
>
>
>
>
>
>
>
>
> To make it easier explaining the way of proceeding, a reproducible example
> could be:
>
>
>
>> # add NA?s for firm 6
>
>>
>
>> data("Grunfeld", package = "plm")
>
>> Grunfeld$inv2= ifelse(Grunfeld$firm==6,NA, Grunfeld$inv)
>
>> data<- pdata.frame(Grunfeld,index=c("firm","year"))
>
>> fixed.reg1.1 <- plm(value~inv2+capital,
>
> +                data = data,na.action=na.exclude ,index=c("firm","year"),
> model="within")
>
>> #resid(fixed.reg1.1)
>
>> # no values for firm 6, no residuals displayed from 101-120
>
>> fixed.reg1.1$resid[105]
>
>       125
>
> 9.371963
>
>> require(lattice)
>
>> xyplot(resid(fixed.reg1.1) ~ firm, data=data)
>
> # As you can see because of  the NA?s of firm 6 ,there?s a shift because the
> residuals are not padded to the correct length,
>
> #  and looking at the plot suggests there are no residuals for firm 10,
> which is not true.
>
>
>
>
>
>
>
> Thanks in advance for your help!
>
> Have a nice day Katie
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From goran.brostrom at umu.se  Tue Jul  8 14:25:32 2014
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 8 Jul 2014 14:25:32 +0200
Subject: [R] Predictions from "coxph" or "cph" objects
In-Reply-To: <53B91416.2030305@umu.se>
References: <CAAyVsXKo8Q4VV=JSrnF7Q4=-Nvnog2Q4TJ14T7v_-3GDsyyQtw@mail.gmail.com>	<D8993113-4963-49D4-88AE-73BD768A304F@comcast.net>	<CAAyVsXJEy774BdogjrPE_vPoOVeKKN_2HA8=qgeBBypVEKjT0w@mail.gmail.com>	<697F8018-87A0-4751-88DD-6ED8BEF32848@comcast.net>	<CF151F08-95F2-4F74-A8B8-41397FDE6130@comcast.net>	<53B90D50.4060107@umu.se>
	<53B91416.2030305@umu.se>
Message-ID: <53BBE33C.6050705@umu.se>

On 2014-07-06 11:17, G?ran Brostr?m wrote:
> On 2014-07-06 10:48, G?ran Brostr?m wrote:
>> David and Axel,
>>
>> I have two comments to your discussion:
>>
>> (i) The area under the survival curve is equal to the mean of the
>> distribution, so the estimate of the mean should be the sum of the areas
>> of the rectangles defined by the estimated survival curve and the
>> successive distances between observed event times.
>>
>> Thus,
>>
>>   > surv <- pred$surv
>>   > time <- pred$time
>>   > sum(surv * diff(time))
>>
>> should give you the (estimated) mean). (Note that time[1] == 0, and
>> length(time) == length(surv) + 1)
>
> Well, this is not quite true; on the first interval the survival curve
> is one, so you need to
>
>   > surv <- c(1, surv)
>
> first. But then the lengths of the surv and time vectors do not match so
> you need to add a (large) time at the end of time. If the largest
> observation is an event, 'no problem' (surv is zero), but otherwise ...
>
> Btw, I tried
>
>   > exit <- rexp(10)
>   > event <- rep(1, 10)
>   > fit <- coxph(Surv(exit, event) ~ 1)
>
>   > survfit(fit)$surv
>    [1] 0.90483742 0.80968410 0.71454371 0.61942215 0.52432953 0.42928471
>    [7] 0.33432727 0.23955596 0.14529803 0.05345216
>
>   > survfit(Surv(exit, event) ~ 1)$surv
> [1] 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
>
> so be careful ...

Addendum: Note the argument 'type':

 > survfit(fit, type = "kalbfleisch-prentice")$surv
  [1] 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0

This gives, I think (at least if no ties), the nonparametric maximum 
likelihood estimator (NPMLE) of the baseline survivor function in the PH 
model, and thus coincides with the Kaplan-Meier estimator in the case of 
no covariates. It drops down to zero if the largest observation is a 
failure. See Kalbfleisch & Prentice (1980), pp. 84-86.

I suppose that the default type ( = "efron") simply uses the formula 
S(t) = exp(-H(t)) (on an estimator of H(t)), which never drops down to 
zero, censorings or no censorings. This relation does not hold for 
discrete-time distributions, and even if our underlying model is 
continuous, the resulting non-parametric estimator of H(t) define a 
discrete-time distribution, which causes a small dilemma for the purist. 
(Should 'type = "kalbfleisch-prentice"' be the default in survfit?)

However, in practice this is of no importance at all. If you stick to 
the median and quantiles.

G?ran

>
> G?ran
>
>>
>> (I do not think that David's suggestion gives the same answer, but I may
>> be wrong.)
>>
>> (ii) With censored data, this may be a bad idea. For instance, when the
>> largest observation is a censoring time, you may badly underestimate the
>> mean. Your best hope is to be able to estimate a conditional mean of the
>> type E(T | T < x).
>>
>> This is essentially a non-parametric situation, and therefore it is
>> better to stick to medians and quantiles.
>>
>> G?ran Brostr?m
>>
>> On 2014-07-06 06:17, David Winsemius wrote:
>>>
>>> On Jul 5, 2014, at 9:12 PM, David Winsemius wrote:
>>>
>>>>
>>>> On Jul 5, 2014, at 12:43 PM, Axel Urbiz wrote:
>>>>
>>>>> Thank you David. It is my understanding that using survfirsurvit
>>>>> below I get the median predicted survival. I actually was looking
>>>>> for the mean. I can't seem to find in the documentation how to get
>>>>> that.
>>>>>
>>>>> options(na.action=na.exclude) # retain NA in predictions
>>>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>>>> pred <- survfit(fit, newdata=lung)
>>>>> head(pred)
>>>>>
>>>> There might be a way. I don't know it if so, so I would probably
>>>> just use the definition of the mean:
>>>>
>>>> sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$time)
>>>>
>>>
>>> Er, I think I meant to type:
>>>
>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>> pred <- survfit(fit)
>>>
>>>     sum(summary(pred)$surv* summary(pred)$time)/sum(  summary(pred)$surv)
>>> [1] 211.0943
>>>
>>>
>>>> (I continue to take effort to keep my postings in plain text despite
>>>> my mail-clients's efforts to match your formatted postings. It adds
>>>> to the work of responders when you post formatted questions and
>>>> responses.)
>>>>
>>>>
>>>>> Thanks again,
>>>>> Axel.
>>>>>
>>>>>
>>>>>
>>>>> On Sat, Jul 5, 2014 at 1:54 PM, David Winsemius <dwinsemius at comcast.net
>>>>>> wrote:
>>>>>
>>>>> On Jul 5, 2014, at 5:28 AM, Axel Urbiz wrote:
>>>>>
>>>>> Dear R users,
>>>>>
>>>>> My apologies for the simple question, as I'm starting to learn the
>>>>> concepts
>>>>> behind the Cox PH model. I was just experimenting with the survival
>>>>> and rms
>>>>> packages for this.
>>>>>
>>>>> I'm simply trying to obtain the expected survival time (as opposed
>>>>> to the
>>>>> probability of survival at a given time t).
>>>>>
>>>>> What does "expected survival time" actually mean? Do you want the
>>>>> median survival time?
>>>>>
>>>>>
>>>>> I can't seem to find an option
>>>>> from the "type" argument in the predict methods from
>>>>> coxph{survival} or
>>>>> cph{rms} that will give me expected survival times.
>>>>>
>>>>> library(rms)
>>>>> options(na.action=na.exclude) # retain NA in predictions
>>>>> fit <- coxph(Surv(time, status) ~ age + ph.ecog, lung)
>>>>> fit2 <-  cph(Surv(time, status) ~ age + ph.ecog, lung)
>>>>> head(predict(fit,type="lp"))
>>>>> head(predict(fit2,type="lp"))
>>>>>
>>>>> `predict` will return the results of the regression, i.e. the log-
>>>>> hazard ratios for each term in the RHS of the formula. What you
>>>>> want (as described in the Index for the survival package) is either
>>>>> `survfit` or `survexp`.
>>>>>
>>>>> require(survival)
>>>>> help(pack=survival)
>>>>> ?survfit
>>>>> ?survexp
>>>>> ?summary.survfit
>>>>> ?quantile.survfit   # to get the median
>>>>> ?print.summary.survfit
>>>>>
>>>>> require(rms)
>>>>> help(pack=rms)
>>>>>
>>>>> The rms-package also adds a `survfit.cph` function but I have found
>>>>> the `survest` function also provides useful added features, beyond
>>>>> those offered by survfit
>>>>>
>>>>>
>>>>>
>>>>> Thank you.
>>>>>
>>>>> Regards,
>>>>> Axel.
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> This is a plain text mailing list.
>>>>>
>>>>> --
>>>>>
>>>>> David Winsemius, MD
>>>>> Alameda, CA, USA
>>>>>
>>>>>
>>>>
>>>> David Winsemius, MD
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius, MD
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Jul  8 14:27:55 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Jul 2014 14:27:55 +0200
Subject: [R] writing matrices of different rows in a file
In-Reply-To: <1404720348.95680.YahooMailNeo@web121502.mail.ne1.yahoo.com>
References: <1404720348.95680.YahooMailNeo@web121502.mail.ne1.yahoo.com>
Message-ID: <53BBE3CB.8000708@statistik.tu-dortmund.de>



On 07.07.2014 10:05, carol white wrote:
> Hi,
> What is the best way of writing of matrices of different rows in a file? Should the matrices with the same number of rows be written first and then, empty columns for the matrices with a smaller number of rows followed by the matrices with a larger number of rows? Not a good solution (see below).
>
> Can't they be written with 1 script?
>
> m = rbind(c(1,2),c(2,44))
> n = rbind(c(1,3),c(2,4),c(5,8))
>
> write.csv(cbind(m,n),...)
> Error in .Method(..., deparse.level = deparse.level) :
>    number of rows of matrices must match (see arg 2)
>
>
> write.csv(cbind(m,n[1.2,]),...)
>   write.csv(cbind(cbind(rep(" ",1), rep(" ",1)),n[3,]),...)
>
> Warning message:
> In write.csv(cbind(cbind(rep(" ", 1), rep(" ", 1)), n[3,  :
>    attempt to set 'append' ignored


First combine them into one matrix, e.g. with missing values, then write...


Best,
Uwe Ligges


>
> Thanks
>
> Carol
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Jul  8 14:28:33 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Jul 2014 14:28:33 +0200
Subject: [R] eclat problem
In-Reply-To: <05A3A1E4B6BBE740AF1389A88C77583A04624EF7D3@DCQLC02EXC02.derco.cl>
References: <05A3A1E4B6BBE740AF1389A88C77583A04624EF7D3@DCQLC02EXC02.derco.cl>
Message-ID: <53BBE3F1.9050508@statistik.tu-dortmund.de>

This is something for the authors of that package...

Best,
Uwe Ligges




On 07.07.2014 22:56, Alvaro Flores wrote:
>
>
> I'm working with arule packages and I'm constantly trying to mine frequent itemsets in different datasets. But recently R kept returning the same error message :
>
>
>
> Error in eclat(txn, parameter = list(supp = 0.001)) :
>
>    internal error in trio library
>
>
>
> Is just this particular dataset that gives me problems.
>
>
>
> Anyone has ever passed and fixed this error?
>
>
>
> Here are an example of the transaction data set:
>
>     items
>
> 1  {001200-3,
>
>      004100-3,
>
>      004200-5,
>
>      004500-9,
>
>      004600-5}
>
> 2  {001524-K,
>
>      002100-2}
>
> 3  {00179,
>
>      03807,
>
>      08019,
>
>      09314,
>
>      12432}
>
> 4  {002000}
>
> 5  {002600-4,
>
>      002700-0}
>
> 6  {004115-F,
>
>      02/100073A,
>
>      02/630935A,
>
>      044.1567.0,
>
>      044.1567.0/I,
>
>      1010301FA,
>
>      1012015-400-0000,
>
>      1117285,
>
>      1118100-201-4020,
>
>      1118105-051-0000M,
>
>      173171,
>
>      1903628,
>
>      1903628/I,
>
>      1903629,
>
>      1903629/I,
>
>      1907566,
>
>      1907567,
>
>      1907570,
>
>      1907571,
>
>      1931018,
>
>      2.4419.340.0,
>
>      215420/N,
>
>      2654408-N,
>
>      2992242,
>
>      2992544,
>
>      2996416,
>
>      2VC-115561,
>
>      320/04133A,
>
>      4102AZL.14.100N00,
>
>      4110Z.14.30,
>
>      4625547,
>
>      477556,
>
>      477556/O,
>
>      478736,
>
>      478736/O,
>
>      500054655,
>
>      581/18096,
>
>      61000070005,
>
>      957E-6731 A,
>
>      BF8T-6731 BA,
>
>      BG2X-6731 CA,
>
>      DBPN-6731 A,
>
>      F2NN-6714 AB,
>
>      LF16015,
>
>      LF3000,
>
>      LF3345,
>
>      LF3346,
>
>      LF3349,
>
>      LF3806,
>
>      LF4054,
>
>      LF9009,
>
>      RE504836,
>
>      RE59754,
>
>      T19044/I,
>
>      TAE-115561,
>
>      W-950/7,
>
>      ZP520}
>
> 7  {005226,
>
>      012.0348.0,
>
>      012.0349.0,
>
>      02/910150A,
>
>      1105010E834N00,
>
>      1105020D354,
>
>      1117011-630-0000W,
>
>      1117025-621-0000,
>
>      1372444,
>
>      1393640,
>
>      1457434310001,
>
>      1521219,
>
>      1873018,
>
>      1901605,
>
>      1902134,
>
>      1902138,
>
>      1902138/I,
>
>      1907640,
>
>      1907640/I,
>
>      1908547,
>
>      1908547/I,
>
>      1930010,
>
>      19BG920-30001,
>
>      20430751,
>
>      20514654,
>
>      20976003/O,
>
>      20998367,
>
>      215460,
>
>      26560143,
>
>      26560201,
>
>      26560201/I,
>
>      2710806,
>
>      2992241,
>
>      2992241/I,
>
>      2992300,
>
>      2992662,
>
>      2992662/I,
>
>      2995711,
>
>      2997376,
>
>      2R0-127177,
>
>      2R0-127177 A,
>
>      2RD-127491,
>
>      32/401102,
>
>      32/912001A,
>
>      32/925423,
>
>      32/925760,
>
>      32/925869,
>
>      32/925915,
>
>      320/07155,
>
>      343144,
>
>      4102H.15.110,
>
>      4102H.15.110N00,
>
>      4102H.15.20,
>
>      500315480,
>
>      500315480/I,
>
>      500316868,
>
>      550228,
>
>      550228/N,
>
>      582042,
>
>      612630080011N00,
>
>      612630080087,
>
>      7146717,
>
>      8159975/O,
>
>      81BASE9200001,
>
>      98439681,
>
>      AR50041,
>
>      BC11320000N01,
>
>      BF0X-9155 AA,
>
>      BF5T-9155 AB,
>
>      BF8T-9155 DA,
>
>      DDN-99162 B,
>
>      DONN-9N074 BG,
>
>      E5HT-9155 CA,
>
>      E7HN-9155 AA,
>
>      FF42000,
>
>      FF5421,
>
>      FF5458,
>
>      FF5488,
>
>      FS1000,
>
>      FS1015,
>
>      FS1241,
>
>      FS1242,
>
>      FS1280,
>
>      PSD460/1,
>
>      PSD970/1,
>
>      R28-30M,
>
>      RC45MB,
>
>      RE62418,
>
>      RK120MBQ2,
>
>      T22VA,
>
>      WK-723}
>
> 8  {005227,
>
>      2641311,
>
>      2641371,
>
>      2641406,
>
>      2641725,
>
>      2641729,
>
>      2641808,
>
>      376518,
>
>      4757883,
>
>      72013,
>
>      72061,
>
>      8190393,
>
>      9986316,
>
>      D8NN-9350 AA,
>
>      DDN-9350,
>
>      RE42211}
>
> 9  {0055,
>
>      0087,
>
>      0482,
>
>      0484,
>
>      0531,
>
>      11329,
>
>      8311}
>
> 10 {007.0762.0/40,
>
>      014.0428.0,
>
>      1114036,
>
>      1118369,
>
>      1118375,
>
>      1118376,
>
>      1118377,
>
>      1118379,
>
>      1305546,
>
>      1312934,
>
>      1677591,
>
>      1677592,
>
>      1677593,
>
>      2.1539.130.0,
>
>      2.1539.259.0,
>
>      20515059/C,
>
>      275092/C,
>
>      275636/C,
>
>      2RD-107124,
>
>      31358393-G,
>
>      3135X031,
>
>      3135X063,
>
>      4622074,
>
>      4622074/G,
>
>      4742199,
>
>      4742202,
>
>      4770623,
>
>      4803030/G,
>
>      500337911,
>
>      61316752,
>
>      61316793,
>
>      7114756,
>
>      8815939,
>
>      99435938,
>
>      99448192,
>
>      99467115,
>
>      BF0X-6055 AA,
>
>      BF0X-6055 AA/C,
>
>      BF0X-6055 AA/CM,
>
>      BF0X-6055 AA/M,
>
>      BF8T-6055 AA,
>
>      TAE-107125,
>
>      TAF-107127,
>
>      TE3-107125}
>
> 11 {008.4748.4,
>
>      026566T3,
>
>      1370794,
>
>      1393185,
>
>      1868005,
>
>      2UH-141025,
>
>      353430,
>
>      5016033/034,
>
>      5196807,
>
>      9959900,
>
>      9962518,
>
>      E6NN-7563 AA,
>
>      EONN-7563 BA,
>
>      XC45-7563 BA/C/P,
>
>      XC45-7563 CA}
>
> 12 {009.4749.3,
>
>      1865836,
>
>      2RD-141031,
>
>      3191991,
>
>      3610274,
>
>      42102093,
>
>      4999812/R,
>
>      525587/D,
>
>      887889,
>
>      96HU-7550 AA,
>
>      96HU-7550 AA/C,
>
>      97HU-7550 AA/C,
>
>      AL33315,
>
>      C7NN-7550 V,
>
>      D1NN-7550 A,
>
>      D5NN-7550 A,
>
>      E6NN-7550 ABL}
>
> 13 {0118,
>
>      VLF-3200,
>
>      VLF-3202,
>
>      VLF-3205}
>
> 14 {014.5259.0/10,
>
>      014.5260.0/10,
>
>      014.5261.0/10,
>
>      065.1450.0/30,
>
>      069.1450.0/30,
>
>      087.0050.0,
>
>      087.0050.6/10,
>
>      1367028/CL,
>
>      136750,
>
>      143810,
>
>      149300,
>
>      149340,
>
>      1725112,
>
>      1905560/KP,
>
>      1905961/62,
>
>      1905968/G,
>
>      1908819,
>
>      1930248,
>
>      2500617/K,
>
>      270789,
>
>      2830919,
>
>      2852012,
>
>      2852743,
>
>      2992642,
>
>      2R0-109287,
>
>      2R0-198015 C,
>
>      2TA-109289/4,
>
>      3092642,
>
>      3228362R1,
>
>      36811122,
>
>      36812349,
>
>      3681E006,
>
>      3681E037,
>
>      3681E046,
>
>      4690375,
>
>      500308780,
>
>      551528,
>
>      99477119,
>
>      BF0X-6008 AA,
>
>      BF5X-6008 D,
>
>      BF5X-6008 D/4,
>
>      BF5X-6020 C,
>
>      BF5X-6L621 A,
>
>      BG5X-6008 AA,
>
>      BG5X-6008 BA,
>
>      C7NN-6584 B,
>
>      C7NN-6584 C,
>
>      CFPN-6008 FKI,
>
>      D4NN-6008 BG,
>
>      D4NN-6008 BGI,
>
>      D4NN-6710 A,
>
>      DDN-6008 AM,
>
>      DDN-6051 CG,
>
>      EONN-6051 AA,
>
>      EONN-6051 FA,
>
>      EONN-6051 FAGG,
>
>      R80241,
>
>      R92425,
>
>      RE38857,
>
>      RE50978,
>
>      TE6H-6008 B,
>
>      TJG-109289,
>
>      TJG-115441,
>
>      U5LB1164,
>
>      U5LT0065/016,
>
>      U5LT0178}
>
> 15 {014.7994.4,
>
>      1448659,
>
>      1887506,
>
>      20709848,
>
>      20824906,
>
>      2VC-115105,
>
>      4705827,
>
>      479317,
>
>      4802609,
>
>      8193737,
>
>      BF5T-6600 A,
>
>      BF5X-6600 B,
>
>      BG1X-6600 AA,
>
>      C7NN-6A605 A,
>
>      D3NN-6A820 F,
>
>      D5NN-6600 DI,
>
>      F1NN-9278 AA,
>
>      R78202,
>
>      TJG-117021}
>
>
>
> Thanks in advance.
>
>
> Alvaro.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alvaroflores at derco.cl  Tue Jul  8 14:38:41 2014
From: alvaroflores at derco.cl (Alvaro Flores)
Date: Tue, 8 Jul 2014 08:38:41 -0400
Subject: [R] eclat problem
In-Reply-To: <53BBE3F1.9050508@statistik.tu-dortmund.de>
References: <05A3A1E4B6BBE740AF1389A88C77583A04624EF7D3@DCQLC02EXC02.derco.cl>
	<53BBE3F1.9050508@statistik.tu-dortmund.de>
Message-ID: <05A3A1E4B6BBE740AF1389A88C77583A0463555C63@DCQLC02EXC02.derco.cl>

Thanks Uwe, i'll try to contact with them. I was expecting someone with the same problem here!

Kind regards.


Alvaro.




-----Mensaje original-----
De: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de] 
Enviado el: martes, 08 de julio de 2014 8:29
Para: Alvaro Flores; r-help at r-project.org
Asunto: Re: [R] eclat problem

This is something for the authors of that package...

Best,
Uwe Ligges




On 07.07.2014 22:56, Alvaro Flores wrote:
>
>
> I'm working with arule packages and I'm constantly trying to mine frequent itemsets in different datasets. But recently R kept returning the same error message :
>
>
>
> Error in eclat(txn, parameter = list(supp = 0.001)) :
>
>    internal error in trio library
>
>
>
> Is just this particular dataset that gives me problems.
>
>
>
> Anyone has ever passed and fixed this error?
>
>
>
> Here are an example of the transaction data set:
>
>     items
>
> 1  {001200-3,
>
>      004100-3,
>
>      004200-5,
>
>      004500-9,
>
>      004600-5}
>
> 2  {001524-K,
>
>      002100-2}
>
> 3  {00179,
>
>      03807,
>
>      08019,
>
>      09314,
>
>      12432}
>
> 4  {002000}
>
> 5  {002600-4,
>
>      002700-0}
>
> 6  {004115-F,
>
>      02/100073A,
>
>      02/630935A,
>
>      044.1567.0,
>
>      044.1567.0/I,
>
>      1010301FA,
>
>      1012015-400-0000,
>
>      1117285,
>
>      1118100-201-4020,
>
>      1118105-051-0000M,
>
>      173171,
>
>      1903628,
>
>      1903628/I,
>
>      1903629,
>
>      1903629/I,
>
>      1907566,
>
>      1907567,
>
>      1907570,
>
>      1907571,
>
>      1931018,
>
>      2.4419.340.0,
>
>      215420/N,
>
>      2654408-N,
>
>      2992242,
>
>      2992544,
>
>      2996416,
>
>      2VC-115561,
>
>      320/04133A,
>
>      4102AZL.14.100N00,
>
>      4110Z.14.30,
>
>      4625547,
>
>      477556,
>
>      477556/O,
>
>      478736,
>
>      478736/O,
>
>      500054655,
>
>      581/18096,
>
>      61000070005,
>
>      957E-6731 A,
>
>      BF8T-6731 BA,
>
>      BG2X-6731 CA,
>
>      DBPN-6731 A,
>
>      F2NN-6714 AB,
>
>      LF16015,
>
>      LF3000,
>
>      LF3345,
>
>      LF3346,
>
>      LF3349,
>
>      LF3806,
>
>      LF4054,
>
>      LF9009,
>
>      RE504836,
>
>      RE59754,
>
>      T19044/I,
>
>      TAE-115561,
>
>      W-950/7,
>
>      ZP520}
>
> 7  {005226,
>
>      012.0348.0,
>
>      012.0349.0,
>
>      02/910150A,
>
>      1105010E834N00,
>
>      1105020D354,
>
>      1117011-630-0000W,
>
>      1117025-621-0000,
>
>      1372444,
>
>      1393640,
>
>      1457434310001,
>
>      1521219,
>
>      1873018,
>
>      1901605,
>
>      1902134,
>
>      1902138,
>
>      1902138/I,
>
>      1907640,
>
>      1907640/I,
>
>      1908547,
>
>      1908547/I,
>
>      1930010,
>
>      19BG920-30001,
>
>      20430751,
>
>      20514654,
>
>      20976003/O,
>
>      20998367,
>
>      215460,
>
>      26560143,
>
>      26560201,
>
>      26560201/I,
>
>      2710806,
>
>      2992241,
>
>      2992241/I,
>
>      2992300,
>
>      2992662,
>
>      2992662/I,
>
>      2995711,
>
>      2997376,
>
>      2R0-127177,
>
>      2R0-127177 A,
>
>      2RD-127491,
>
>      32/401102,
>
>      32/912001A,
>
>      32/925423,
>
>      32/925760,
>
>      32/925869,
>
>      32/925915,
>
>      320/07155,
>
>      343144,
>
>      4102H.15.110,
>
>      4102H.15.110N00,
>
>      4102H.15.20,
>
>      500315480,
>
>      500315480/I,
>
>      500316868,
>
>      550228,
>
>      550228/N,
>
>      582042,
>
>      612630080011N00,
>
>      612630080087,
>
>      7146717,
>
>      8159975/O,
>
>      81BASE9200001,
>
>      98439681,
>
>      AR50041,
>
>      BC11320000N01,
>
>      BF0X-9155 AA,
>
>      BF5T-9155 AB,
>
>      BF8T-9155 DA,
>
>      DDN-99162 B,
>
>      DONN-9N074 BG,
>
>      E5HT-9155 CA,
>
>      E7HN-9155 AA,
>
>      FF42000,
>
>      FF5421,
>
>      FF5458,
>
>      FF5488,
>
>      FS1000,
>
>      FS1015,
>
>      FS1241,
>
>      FS1242,
>
>      FS1280,
>
>      PSD460/1,
>
>      PSD970/1,
>
>      R28-30M,
>
>      RC45MB,
>
>      RE62418,
>
>      RK120MBQ2,
>
>      T22VA,
>
>      WK-723}
>
> 8  {005227,
>
>      2641311,
>
>      2641371,
>
>      2641406,
>
>      2641725,
>
>      2641729,
>
>      2641808,
>
>      376518,
>
>      4757883,
>
>      72013,
>
>      72061,
>
>      8190393,
>
>      9986316,
>
>      D8NN-9350 AA,
>
>      DDN-9350,
>
>      RE42211}
>
> 9  {0055,
>
>      0087,
>
>      0482,
>
>      0484,
>
>      0531,
>
>      11329,
>
>      8311}
>
> 10 {007.0762.0/40,
>
>      014.0428.0,
>
>      1114036,
>
>      1118369,
>
>      1118375,
>
>      1118376,
>
>      1118377,
>
>      1118379,
>
>      1305546,
>
>      1312934,
>
>      1677591,
>
>      1677592,
>
>      1677593,
>
>      2.1539.130.0,
>
>      2.1539.259.0,
>
>      20515059/C,
>
>      275092/C,
>
>      275636/C,
>
>      2RD-107124,
>
>      31358393-G,
>
>      3135X031,
>
>      3135X063,
>
>      4622074,
>
>      4622074/G,
>
>      4742199,
>
>      4742202,
>
>      4770623,
>
>      4803030/G,
>
>      500337911,
>
>      61316752,
>
>      61316793,
>
>      7114756,
>
>      8815939,
>
>      99435938,
>
>      99448192,
>
>      99467115,
>
>      BF0X-6055 AA,
>
>      BF0X-6055 AA/C,
>
>      BF0X-6055 AA/CM,
>
>      BF0X-6055 AA/M,
>
>      BF8T-6055 AA,
>
>      TAE-107125,
>
>      TAF-107127,
>
>      TE3-107125}
>
> 11 {008.4748.4,
>
>      026566T3,
>
>      1370794,
>
>      1393185,
>
>      1868005,
>
>      2UH-141025,
>
>      353430,
>
>      5016033/034,
>
>      5196807,
>
>      9959900,
>
>      9962518,
>
>      E6NN-7563 AA,
>
>      EONN-7563 BA,
>
>      XC45-7563 BA/C/P,
>
>      XC45-7563 CA}
>
> 12 {009.4749.3,
>
>      1865836,
>
>      2RD-141031,
>
>      3191991,
>
>      3610274,
>
>      42102093,
>
>      4999812/R,
>
>      525587/D,
>
>      887889,
>
>      96HU-7550 AA,
>
>      96HU-7550 AA/C,
>
>      97HU-7550 AA/C,
>
>      AL33315,
>
>      C7NN-7550 V,
>
>      D1NN-7550 A,
>
>      D5NN-7550 A,
>
>      E6NN-7550 ABL}
>
> 13 {0118,
>
>      VLF-3200,
>
>      VLF-3202,
>
>      VLF-3205}
>
> 14 {014.5259.0/10,
>
>      014.5260.0/10,
>
>      014.5261.0/10,
>
>      065.1450.0/30,
>
>      069.1450.0/30,
>
>      087.0050.0,
>
>      087.0050.6/10,
>
>      1367028/CL,
>
>      136750,
>
>      143810,
>
>      149300,
>
>      149340,
>
>      1725112,
>
>      1905560/KP,
>
>      1905961/62,
>
>      1905968/G,
>
>      1908819,
>
>      1930248,
>
>      2500617/K,
>
>      270789,
>
>      2830919,
>
>      2852012,
>
>      2852743,
>
>      2992642,
>
>      2R0-109287,
>
>      2R0-198015 C,
>
>      2TA-109289/4,
>
>      3092642,
>
>      3228362R1,
>
>      36811122,
>
>      36812349,
>
>      3681E006,
>
>      3681E037,
>
>      3681E046,
>
>      4690375,
>
>      500308780,
>
>      551528,
>
>      99477119,
>
>      BF0X-6008 AA,
>
>      BF5X-6008 D,
>
>      BF5X-6008 D/4,
>
>      BF5X-6020 C,
>
>      BF5X-6L621 A,
>
>      BG5X-6008 AA,
>
>      BG5X-6008 BA,
>
>      C7NN-6584 B,
>
>      C7NN-6584 C,
>
>      CFPN-6008 FKI,
>
>      D4NN-6008 BG,
>
>      D4NN-6008 BGI,
>
>      D4NN-6710 A,
>
>      DDN-6008 AM,
>
>      DDN-6051 CG,
>
>      EONN-6051 AA,
>
>      EONN-6051 FA,
>
>      EONN-6051 FAGG,
>
>      R80241,
>
>      R92425,
>
>      RE38857,
>
>      RE50978,
>
>      TE6H-6008 B,
>
>      TJG-109289,
>
>      TJG-115441,
>
>      U5LB1164,
>
>      U5LT0065/016,
>
>      U5LT0178}
>
> 15 {014.7994.4,
>
>      1448659,
>
>      1887506,
>
>      20709848,
>
>      20824906,
>
>      2VC-115105,
>
>      4705827,
>
>      479317,
>
>      4802609,
>
>      8193737,
>
>      BF5T-6600 A,
>
>      BF5X-6600 B,
>
>      BG1X-6600 AA,
>
>      C7NN-6A605 A,
>
>      D3NN-6A820 F,
>
>      D5NN-6600 DI,
>
>      F1NN-9278 AA,
>
>      R78202,
>
>      TJG-117021}
>
>
>
> Thanks in advance.
>
>
> Alvaro.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Guillaume.Tahon at UGent.be  Tue Jul  8 16:07:57 2014
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Tue, 8 Jul 2014 07:07:57 -0700 (PDT)
Subject: [R] Extrapolation of rarefaction curve
Message-ID: <1404828477427-4693693.post@n4.nabble.com>

Hi all,

I used R (vegan package) to make rarefaction curves and I calculated the
Chao index for each curve. However, the plateau is far from reached.
What I want to do now is the following:
Based on the Chao index, I want to extrapolate the curve so I get an x-value
which gives me an estimation of the total number of clones I'd have to pick
up and sequence in order to have a full coverage of the species diversity in
my sample. 
Is there anyone who knows how to do this? Using vegan or any other package?
Or is there any other way to calculate this x-value?

Thanks in advance!


Guillaume



--
View this message in context: http://r.789695.n4.nabble.com/Extrapolation-of-rarefaction-curve-tp4693693.html
Sent from the R help mailing list archive at Nabble.com.


From pjmiller_57 at yahoo.com  Tue Jul  8 18:00:29 2014
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Tue, 8 Jul 2014 09:00:29 -0700
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <mailman.88.1404764530.4543.r-help@r-project.org>
Message-ID: <1404835229.95312.YahooMailBasic@web140204.mail.bf1.yahoo.com>

Hello All,

I'm trying to figure out how to perform a survival analysis with an historical control. I've spent some time looking online and in my boooks but haven't found much showing how to do this. Was wondering if there is a R package that can do it, or if there are resources somewhere that show the actual steps one takes, or if some knowledgeable person might be willing to share some code. 

Here is a statement that describes the sort of analyis I'm being asked to do.

A one-sample parametric test assuming an exponential form of survival was used to test the hypothesis that the treatment produces a median PFS no greater than the historical control PFS of 16 weeks.  A sample median PFS greater than 20.57 weeks would fall beyond the critical value associated with the null hypothesis, and would be considered statistically significant at alpha = .05, 1 tailed.  

My understanding is that the cutoff of 20.57 weeks was obtained using an online calculator that can be found at:

http://www.swogstat.org/stat/public/one_survival.htm

Thus far, I've been unable to determine what values were plugged into the calculator to get the cutoff.

There's another calculator for a nonparamertric test that can be found at:

http://www.swogstat.org/stat/public/one_nonparametric_survival.htm

It would be nice to try doing this using both a parameteric and a non-parametric model.

So my first question would be whether the approach outlined above is valid or if the analysis should be done some other way. If the basic idea is correct, is it relatively easy (for a Terry Therneau type genius) to implement the whole thing using R? The calculator is a great tool, but, if reasonable, it would be nice to be able to look at some code to see how the numbers actually get produced.

Below are some sample survival data and code in case this proves helpful.

Thanks,

Paul

###################################
#### Example Data: GD2 Vaccine ####
###################################

connection <- textConnection("
GD2  1   8 12  GD2  3 -12 10  GD2  6 -52  7
GD2  7  28 10  GD2  8  44  6  GD2 10  14  8
GD2 12   3  8  GD2 14 -52  9  GD2 15  35 11
GD2 18   6 13  GD2 20  12  7  GD2 23  -7 13
GD2 24 -52  9  GD2 26 -52 12  GD2 28  36 13
GD2 31 -52  8  GD2 33   9 10  GD2 34 -11 16
GD2 36 -52  6  GD2 39  15 14  GD2 40  13 13
GD2 42  21 13  GD2 44 -24 16  GD2 46 -52 13
GD2 48  28  9  GD2  2  15  9  GD2  4 -44 10
GD2  5  -2 12  GD2  9   8  7  GD2 11  12  7
GD2 13 -52  7  GD2 16  21  7  GD2 17  19 11
GD2 19   6 16  GD2 21  10 16  GD2 22 -15  6
GD2 25   4 15  GD2 27  -9  9  GD2 29  27 10
GD2 30   1 17  GD2 32  12  8  GD2 35  20  8
GD2 37 -32  8  GD2 38  15  8  GD2 41   5 14
GD2 43  35 13  GD2 45  28  9  GD2 47   6 15
")

hsv <- data.frame(scan(connection, list(VAC="", PAT=0, WKS=0, X=0)))
hsv <- transform(hsv, CENS=ifelse(WKS < 1, 1, 0), WKS=abs(WKS))
head(hsv)

require("survival")

survObj <- Surv(hsv$WKS, hsv$CENS==0) ~ 1

km <- survfit(survObj, type=c("kaplan-meier"))
print(km)

paraExp <- survreg(survObj, dist="exponential")
print(paraExp)


From jim.silverton at gmail.com  Tue Jul  8 18:29:32 2014
From: jim.silverton at gmail.com (Jim Silverton)
Date: Tue, 8 Jul 2014 12:29:32 -0400
Subject: [R] PCA with a lot of zeros
Message-ID: <CAGPwjHwpvU=_e5N-XiJsa6kadSZzA0udfmGgAVuWdT-SrcD8pQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/8c538aa4/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 10:30:50 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 10:30:50 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVporZa+Ez8ifpvNpkLFzbt0n=QFt9Wagn9tNpjT5k-_JA@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
	<CA+g8WVporZa+Ez8ifpvNpkLFzbt0n=QFt9Wagn9tNpjT5k-_JA@mail.gmail.com>
Message-ID: <CA+g8WVrfTwdL8MX+A4f1-mCRAEY36cGeX0-RJvpp_enCWg37vQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/3ca3f628/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 12:55:25 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 12:55:25 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <53BBCCA2.9070802@gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
	<53BBCCA2.9070802@gmail.com>
Message-ID: <CA+g8WVrq-oPhsv-MwUkREW9QWdY4tCJOvrFQqGjm7ee_wkPgJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/96aa900d/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 13:02:17 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 13:02:17 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVrq-oPhsv-MwUkREW9QWdY4tCJOvrFQqGjm7ee_wkPgJA@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
	<53BBCCA2.9070802@gmail.com>
	<CA+g8WVrq-oPhsv-MwUkREW9QWdY4tCJOvrFQqGjm7ee_wkPgJA@mail.gmail.com>
Message-ID: <CA+g8WVrc5ZBkr4qwvuMn6SpNecQ8AUckc5o-B-PRRgzUjGK1yA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/9da94b26/attachment.pl>

From eva.pcastro.lind at gmail.com  Tue Jul  8 13:43:14 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 13:43:14 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <CA+g8WVrc5ZBkr4qwvuMn6SpNecQ8AUckc5o-B-PRRgzUjGK1yA@mail.gmail.com>
References: <1404721309.9386.YahooMailNeo@web171505.mail.ir2.yahoo.com>
	<CA+g8WVqnDYHcmDTa_DzBnZmkkbhQZhu=uMGyPC-y0gM1vLgeNw@mail.gmail.com>
	<53BB07C3.1040207@gmail.com>
	<CA+g8WVoRhJuE6ph52gYwOEvuKR1Po2ewWcAKTApX00P+-bofKw@mail.gmail.com>
	<53BB254D.1020004@gmail.com>
	<CA+g8WVrWo-6WqywmMEFKux-3YEvso42eCwgwUnd1g1YNvDEDQQ@mail.gmail.com>
	<53BB339A.8030301@gmail.com>
	<CA+g8WVqe7Zi4NZV_d_ecKY6Jg6arvZ_kgPFR4ZKS8K8V0Stx-A@mail.gmail.com>
	<53BBCCA2.9070802@gmail.com>
	<CA+g8WVrq-oPhsv-MwUkREW9QWdY4tCJOvrFQqGjm7ee_wkPgJA@mail.gmail.com>
	<CA+g8WVrc5ZBkr4qwvuMn6SpNecQ8AUckc5o-B-PRRgzUjGK1yA@mail.gmail.com>
Message-ID: <CA+g8WVoHFpFqmz4p0edmmvrsO0Q+2n5-+nVU=5Q2f0CTpQBF+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/319f5c67/attachment.pl>

From soeren.groettrup at gmail.com  Tue Jul  8 11:56:05 2014
From: soeren.groettrup at gmail.com (Soeren Groettrup)
Date: Tue, 08 Jul 2014 11:56:05 +0200
Subject: [R] Formating cell with xlsx package
Message-ID: <53BBC035.7010505@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/2c197cc2/attachment.pl>

From martyn.byng at nag.co.uk  Tue Jul  8 18:37:41 2014
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Tue, 8 Jul 2014 16:37:41 +0000
Subject: [R] PCA with a lot of zeros
In-Reply-To: <CAGPwjHwpvU=_e5N-XiJsa6kadSZzA0udfmGgAVuWdT-SrcD8pQ@mail.gmail.com>
References: <CAGPwjHwpvU=_e5N-XiJsa6kadSZzA0udfmGgAVuWdT-SrcD8pQ@mail.gmail.com>
Message-ID: <663c48ef837f41d4a9ad511c1c21ddd9@AM3PR05MB545.eurprd05.prod.outlook.com>

Hi,

Not sure if these are relevant as they have been on my "must look at" list for some time and I've not managed to get around to it ...

http://www.cmap.polytechnique.fr/~aspremon/PDF/SPCAhandbookSV.pdf
http://www2.imm.dtu.dk/projects/manifold/Papers/sparsepc.pdf

Martyn

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Silverton
Sent: 08 July 2014 17:30
To: r-help at r-project.org
Subject: Re: [R] PCA with a lot of zeros

Hello all,
I was wondering if R has some routine that can handle PCA with a lot of zeros. I have fourteen variables - these variables represent angles...so there are some negative and some positive angles. Histograms appear sparse
- in the sense that there are gaps. Any ideas or papers would be greatly appreciated.


--
Thanks,
Jim.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From alfios17 at hotmail.com  Tue Jul  8 18:39:17 2014
From: alfios17 at hotmail.com (Lorenzo Alfieri)
Date: Tue, 8 Jul 2014 18:39:17 +0200
Subject: [R] reorder a list
Message-ID: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/0e1b5a70/attachment.pl>

From jholtman at gmail.com  Tue Jul  8 19:10:53 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 8 Jul 2014 13:10:53 -0400
Subject: [R] reorder a list
In-Reply-To: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
Message-ID: <CAAxdm-4xpA03+XYBq=DzFE9p4uRKXuPtDU19ieCTLGzvMYcSYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/80b357c5/attachment.pl>

From 538280 at gmail.com  Tue Jul  8 19:11:05 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Jul 2014 11:11:05 -0600
Subject: [R] reorder a list
In-Reply-To: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
Message-ID: <CAFEqCdwiE_wzmiWx3TtHkRHX89pHU_Zh50nSP9dq4LOEf3zQ2A@mail.gmail.com>

Here is one approach that gives almost the same answer as your example:

> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>
> A2 <- sort(unique(unlist(A1)))
> names(A2) <- A2
> sapply(A2, function(x) which( sapply(A1, function(y) x %in% y) ),
+ simplify=FALSE, USE.NAMES=TRUE )
$`1`
[1] 1

$`2`
[1] 1 2

$`3`
[1] 1

$`4`
[1] 1 2 4

$`5`
[1] 2 4

$`13`
[1] 4

$`23`
[1] 3

If you want the `23` to be in the 23rd element of the list (with empty
values before it) then just change A2 to be a vector from 1 to the
largest value

On Tue, Jul 8, 2014 at 10:39 AM, Lorenzo Alfieri <alfios17 at hotmail.com> wrote:
> Hi,
> I'm trying to find a way to reorder the elements of a list.
> Let's say I have a list like this:
> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>
>> A1
> [[1]]
> [1] 1 2 3 4
>
> [[2]]
> [1] 2 4 5
>
> [[3]]
> [1] 23
>
> [[4]]
> [1]  4  5 13
>
> All the elements included in it are values, while each sublist is a time index
> Now, I'd like to reorder the list (without looping) so to obtain one sublist for each value, which include all the time indices where each value appears.
> In other words, the result should look like this:
>>A2
> [[1]]
> [1] 1
>
> [[2]]
> [1] 1 2    #because value "2" appears in the time index [[1]] and [[2]] of A1
>
> [[3]]
> [1] 1
>
> [[4]]
> [1] 1 2 4
>
> [[5]]
> [1] 2 4
>
> [[13]]
> [1] 4
>
> [[23]]
> [1] 3
>
> Any suggestion?
> Thanks
> Alfio
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From frtog at vestas.com  Tue Jul  8 19:12:24 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 8 Jul 2014 19:12:24 +0200
Subject: [R]
 =?iso-8859-1?q?=5BR-es=5D_Consulta_paquetizaci=F3n_con_versi?=
 =?iso-8859-1?q?=F3n_R_3=2E1=2E0?=
Message-ID: <tq7cjjcuxiaboirnxlg6twf8.1404838680625@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/a974f49c/attachment.pl>

From 538280 at gmail.com  Tue Jul  8 19:24:15 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Jul 2014 11:24:15 -0600
Subject: [R] reorder a list
In-Reply-To: <CAFEqCdwiE_wzmiWx3TtHkRHX89pHU_Zh50nSP9dq4LOEf3zQ2A@mail.gmail.com>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
	<CAFEqCdwiE_wzmiWx3TtHkRHX89pHU_Zh50nSP9dq4LOEf3zQ2A@mail.gmail.com>
Message-ID: <CAFEqCdy3G78+DGr+rn6__YEhOFNU_0Rc5yq9eAsnXg2NG4_=uQ@mail.gmail.com>

And here is another approach:

> out <- vector('list',length(unique(unlist(A1))))
> names(out) <- sort(unique(unlist(A1)))
> for( i in seq_along(A1) ) {
+ for( j in as.character(A1[[i]]) ) {
+ out[[j]] <- c(out[[j]], i)
+ }
+ }
>
> out
$`1`
[1] 1

$`2`
[1] 1 2

$`3`
[1] 1

$`4`
[1] 1 2 4

$`5`
[1] 2 4

$`13`
[1] 4

$`23`
[1] 3

Which approach is faster/more efficient could depend on what your real
data looks like, how big the list is, how large/variable the vectors
within the list are.  Both methods could probably also be improved,
but unless the list is big enough that either takes quite a bit of
time then it is probably not worth the time to optimize them.

On Tue, Jul 8, 2014 at 11:11 AM, Greg Snow <538280 at gmail.com> wrote:
> Here is one approach that gives almost the same answer as your example:
>
>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>
>> A2 <- sort(unique(unlist(A1)))
>> names(A2) <- A2
>> sapply(A2, function(x) which( sapply(A1, function(y) x %in% y) ),
> + simplify=FALSE, USE.NAMES=TRUE )
> $`1`
> [1] 1
>
> $`2`
> [1] 1 2
>
> $`3`
> [1] 1
>
> $`4`
> [1] 1 2 4
>
> $`5`
> [1] 2 4
>
> $`13`
> [1] 4
>
> $`23`
> [1] 3
>
> If you want the `23` to be in the 23rd element of the list (with empty
> values before it) then just change A2 to be a vector from 1 to the
> largest value
>
> On Tue, Jul 8, 2014 at 10:39 AM, Lorenzo Alfieri <alfios17 at hotmail.com> wrote:
>> Hi,
>> I'm trying to find a way to reorder the elements of a list.
>> Let's say I have a list like this:
>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>
>>> A1
>> [[1]]
>> [1] 1 2 3 4
>>
>> [[2]]
>> [1] 2 4 5
>>
>> [[3]]
>> [1] 23
>>
>> [[4]]
>> [1]  4  5 13
>>
>> All the elements included in it are values, while each sublist is a time index
>> Now, I'd like to reorder the list (without looping) so to obtain one sublist for each value, which include all the time indices where each value appears.
>> In other words, the result should look like this:
>>>A2
>> [[1]]
>> [1] 1
>>
>> [[2]]
>> [1] 1 2    #because value "2" appears in the time index [[1]] and [[2]] of A1
>>
>> [[3]]
>> [1] 1
>>
>> [[4]]
>> [1] 1 2 4
>>
>> [[5]]
>> [1] 2 4
>>
>> [[13]]
>> [1] 4
>>
>> [[23]]
>> [1] 3
>>
>> Any suggestion?
>> Thanks
>> Alfio
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 at gmail.com  Tue Jul  8 19:41:18 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Jul 2014 11:41:18 -0600
Subject: [R] reorder a list
In-Reply-To: <CAAxdm-4xpA03+XYBq=DzFE9p4uRKXuPtDU19ieCTLGzvMYcSYw@mail.gmail.com>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
	<CAAxdm-4xpA03+XYBq=DzFE9p4uRKXuPtDU19ieCTLGzvMYcSYw@mail.gmail.com>
Message-ID: <CAFEqCdzqDmO6CGdb_g2yAgBd8C5LuW3-DHbr-3ro1_kZWv-ADQ@mail.gmail.com>

Here is another approach inspired by Jim's answer:

> names(A1) <- paste0(seq_along(A1),'.')
> tmp <- unlist(A1)
> split( rep( seq_along(A1), sapply(A1,length) ), as.numeric(sub('\\..+$','',tmp)) )
$`1`
[1] 1

$`2`
[1] 1 2

$`3`
[1] 1

$`4`
[1] 1 2 4

$`5`
[1] 2 4

$`13`
[1] 4

$`23`
[1] 3

On Tue, Jul 8, 2014 at 11:10 AM, jim holtman <jholtman at gmail.com> wrote:
> Try this:
>
>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>
>> # unlist with the list number
>> result <- do.call(rbind, sapply(seq(length(A1)), function(.indx){
> +     cbind(value = A1[[.indx]], index = .indx)
> + }))
>>
>> ans <- split(result[, 2], result[, 1])
>> ans
> $`1`
> [1] 1
>
> $`2`
> [1] 1 2
>
> $`3`
> [1] 1
>
> $`4`
> [1] 1 2 4
>
> $`5`
> [1] 2 4
>
> $`13`
> [1] 4
>
> $`23`
> [1] 3
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Tue, Jul 8, 2014 at 12:39 PM, Lorenzo Alfieri <alfios17 at hotmail.com>
> wrote:
>
>> Hi,
>> I'm trying to find a way to reorder the elements of a list.
>> Let's say I have a list like this:
>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>
>> > A1
>> [[1]]
>> [1] 1 2 3 4
>>
>> [[2]]
>> [1] 2 4 5
>>
>> [[3]]
>> [1] 23
>>
>> [[4]]
>> [1]  4  5 13
>>
>> All the elements included in it are values, while each sublist is a time
>> index
>> Now, I'd like to reorder the list (without looping) so to obtain one
>> sublist for each value, which include all the time indices where each value
>> appears.
>> In other words, the result should look like this:
>> >A2
>> [[1]]
>> [1] 1
>>
>> [[2]]
>> [1] 1 2    #because value "2" appears in the time index [[1]] and [[2]] of
>> A1
>>
>> [[3]]
>> [1] 1
>>
>> [[4]]
>> [1] 1 2 4
>>
>> [[5]]
>> [1] 2 4
>>
>> [[13]]
>> [1] 4
>>
>> [[23]]
>> [1] 3
>>
>> Any suggestion?
>> Thanks
>> Alfio
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 at gmail.com  Tue Jul  8 19:47:01 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Jul 2014 11:47:01 -0600
Subject: [R] reorder a list
In-Reply-To: <CAFEqCdzqDmO6CGdb_g2yAgBd8C5LuW3-DHbr-3ro1_kZWv-ADQ@mail.gmail.com>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
	<CAAxdm-4xpA03+XYBq=DzFE9p4uRKXuPtDU19ieCTLGzvMYcSYw@mail.gmail.com>
	<CAFEqCdzqDmO6CGdb_g2yAgBd8C5LuW3-DHbr-3ro1_kZWv-ADQ@mail.gmail.com>
Message-ID: <CAFEqCdxP1yMDGOwSMTYvFQy3DMndAEjHYiccDtApdK9fZn-h8A@mail.gmail.com>

Oops, I combined 2 ideas (by chance it still worked), the last line
should have been one of the following:

split( rep( seq_along(A1), sapply(A1,length) ), tmp )

split( as.numeric(sub('\\..*$','',names(tmp))), tmp )

On Tue, Jul 8, 2014 at 11:41 AM, Greg Snow <538280 at gmail.com> wrote:
> Here is another approach inspired by Jim's answer:
>
>> names(A1) <- paste0(seq_along(A1),'.')
>> tmp <- unlist(A1)
>> split( rep( seq_along(A1), sapply(A1,length) ), as.numeric(sub('\\..+$','',tmp)) )
> $`1`
> [1] 1
>
> $`2`
> [1] 1 2
>
> $`3`
> [1] 1
>
> $`4`
> [1] 1 2 4
>
> $`5`
> [1] 2 4
>
> $`13`
> [1] 4
>
> $`23`
> [1] 3
>
> On Tue, Jul 8, 2014 at 11:10 AM, jim holtman <jholtman at gmail.com> wrote:
>> Try this:
>>
>>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>>
>>> # unlist with the list number
>>> result <- do.call(rbind, sapply(seq(length(A1)), function(.indx){
>> +     cbind(value = A1[[.indx]], index = .indx)
>> + }))
>>>
>>> ans <- split(result[, 2], result[, 1])
>>> ans
>> $`1`
>> [1] 1
>>
>> $`2`
>> [1] 1 2
>>
>> $`3`
>> [1] 1
>>
>> $`4`
>> [1] 1 2 4
>>
>> $`5`
>> [1] 2 4
>>
>> $`13`
>> [1] 4
>>
>> $`23`
>> [1] 3
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Tue, Jul 8, 2014 at 12:39 PM, Lorenzo Alfieri <alfios17 at hotmail.com>
>> wrote:
>>
>>> Hi,
>>> I'm trying to find a way to reorder the elements of a list.
>>> Let's say I have a list like this:
>>> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>>>
>>> > A1
>>> [[1]]
>>> [1] 1 2 3 4
>>>
>>> [[2]]
>>> [1] 2 4 5
>>>
>>> [[3]]
>>> [1] 23
>>>
>>> [[4]]
>>> [1]  4  5 13
>>>
>>> All the elements included in it are values, while each sublist is a time
>>> index
>>> Now, I'd like to reorder the list (without looping) so to obtain one
>>> sublist for each value, which include all the time indices where each value
>>> appears.
>>> In other words, the result should look like this:
>>> >A2
>>> [[1]]
>>> [1] 1
>>>
>>> [[2]]
>>> [1] 1 2    #because value "2" appears in the time index [[1]] and [[2]] of
>>> A1
>>>
>>> [[3]]
>>> [1] 1
>>>
>>> [[4]]
>>> [1] 1 2 4
>>>
>>> [[5]]
>>> [1] 2 4
>>>
>>> [[13]]
>>> [1] 4
>>>
>>> [[23]]
>>> [1] 3
>>>
>>> Any suggestion?
>>> Thanks
>>> Alfio
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Tue Jul  8 21:11:09 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 8 Jul 2014 12:11:09 -0700
Subject: [R] reorder a list
In-Reply-To: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
Message-ID: <CAF8bMcZ1iFZhtq4RzgTCBoLjhYnApV4y8SGaOjJ9Kxv+zr+1iw@mail.gmail.com>

f <- function (x) {
    lengths <- vapply(x, FUN = length, FUN.VALUE = 0L)
    split(rep(seq_along(x), lengths), unlist(x, use.names = FALSE))
}
f(A1) # gives about what you want (has, e.g., name 23, not position
23, in output)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jul 8, 2014 at 9:39 AM, Lorenzo Alfieri <alfios17 at hotmail.com> wrote:
> Hi,
> I'm trying to find a way to reorder the elements of a list.
> Let's say I have a list like this:
> A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))
>
>> A1
> [[1]]
> [1] 1 2 3 4
>
> [[2]]
> [1] 2 4 5
>
> [[3]]
> [1] 23
>
> [[4]]
> [1]  4  5 13
>
> All the elements included in it are values, while each sublist is a time index
> Now, I'd like to reorder the list (without looping) so to obtain one sublist for each value, which include all the time indices where each value appears.
> In other words, the result should look like this:
>>A2
> [[1]]
> [1] 1
>
> [[2]]
> [1] 1 2    #because value "2" appears in the time index [[1]] and [[2]] of A1
>
> [[3]]
> [1] 1
>
> [[4]]
> [1] 1 2 4
>
> [[5]]
> [1] 2 4
>
> [[13]]
> [1] 4
>
> [[23]]
> [1] 3
>
> Any suggestion?
> Thanks
> Alfio
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eva.pcastro.lind at gmail.com  Tue Jul  8 21:20:51 2014
From: eva.pcastro.lind at gmail.com (Eva Prieto Castro)
Date: Tue, 8 Jul 2014 21:20:51 +0200
Subject: [R] =?utf-8?q?=5BR-es=5D_Consulta_paquetizaci=C3=B3n_con_versi?=
	=?utf-8?b?w7NuIFIgMy4xLjA=?=
In-Reply-To: <tq7cjjcuxiaboirnxlg6twf8.1404838680625@email.android.com>
References: <tq7cjjcuxiaboirnxlg6twf8.1404838680625@email.android.com>
Message-ID: <CA+g8WVoEnYRTs55ofccBW-uRpVxjNx1rJx7RWSWpeHHowFcVBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/91c2b7e6/attachment.pl>

From farnoosh_81 at yahoo.com  Tue Jul  8 21:11:37 2014
From: farnoosh_81 at yahoo.com (farnoosh sheikhi)
Date: Tue, 8 Jul 2014 12:11:37 -0700
Subject: [R] Seprate last name and first name into two columns
In-Reply-To: <1404784060.96552.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1404439393.78071.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1404455964.50778.YahooMailAndroidMobile@web141706.mail.bf1.yahoo.com>
	<1404464323.18851.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1404751486.87705.YahooMailNeo@web141703.mail.bf1.yahoo.com>
	<1404753219.19017.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1404753660.43218.YahooMailNeo@web141701.mail.bf1.yahoo.com>
	<1404753973.2453.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1404754492.57251.YahooMailNeo@web141706.mail.bf1.yahoo.com>
	<1404754707.21840.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1404761893.50009.YahooMailNeo@web141701.mail.bf1.yahoo.com>
	<1404784060.96552.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1404846697.14043.YahooMailNeo@web141702.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/93f8e82a/attachment.pl>

From harish1805 at gmail.com  Tue Jul  8 21:11:10 2014
From: harish1805 at gmail.com (Harish Nair)
Date: Wed, 9 Jul 2014 00:41:10 +0530
Subject: [R] unable to install rJava in centos R
Message-ID: <CAJJ+LeJWDxyjKZNTe7H6TXjuDdSQARvm7eno8or_QDXKr4=3yw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/9685a28d/attachment.pl>

From johnson.cheryl625 at gmail.com  Tue Jul  8 23:28:04 2014
From: johnson.cheryl625 at gmail.com (Cheryl Johnson)
Date: Tue, 8 Jul 2014 17:28:04 -0400
Subject: [R] Error in file.exists(swf.file) : invalid 'file' argument
Message-ID: <CAJJ9dtvySzhKS--92o3NMyVjpOJyb4xLY9Q5+GrOFZS5Sn345w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/b4684191/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Jul  9 02:49:04 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 08 Jul 2014 17:49:04 -0700
Subject: [R] Error in file.exists(swf.file) : invalid 'file' argument
In-Reply-To: <CAJJ9dtvySzhKS--92o3NMyVjpOJyb4xLY9Q5+GrOFZS5Sn345w@mail.gmail.com>
References: <CAJJ9dtvySzhKS--92o3NMyVjpOJyb4xLY9Q5+GrOFZS5Sn345w@mail.gmail.com>
Message-ID: <d48aafc1-88f3-47e8-a1b7-e3f8cb081a71@email.android.com>

Code is corrupted. Please post in plain text as the Posting Guide indicates is expected of you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 8, 2014 2:28:04 PM PDT, Cheryl Johnson <johnson.cheryl625 at gmail.com> wrote:
>*I am receiving the error message ???*Error in file.exists(swf.file) :
>invalid 'file' argument*??? from my swf2html command. In addition,
>there is a
>command that says the Flash file was created: ???*Flash has been
>created at:
>C:\Users\CHERYL\AppData\Local\Temp\Rtmp6n6FXw\file2.swf*???*
>
>*Below is the R code. Thanks in advance for any guidance.*
>
>
>
>*g<-c(0.1,0.2,0.3)*
>
>*#This function produces the swf file.*
>
>*myanimation<-function(v){*
>
>*output1=saveSWF({*
>
>*<code>*
>
>*}, img.name <http://img.name/> = "file",swf.name <http://swf.name/> =
>"file2.swf" , single.opts = "'utf8': false", autoplay = FALSE , *
>
>*interval = 0.1, imgdir = "directory", htmlfile = "random.html",
>ani.height
>= 500, *
>
>*ani.width = 500, title = "groups", *
>
>*description = c("group1", "group2"))*
>
>*return(output1)*
>
>}
>
>#These commands create the html page.
>
>dir.create(file.path(tempdir(),"R2HTML"))
>
>target <-
>HTMLInitFile(file.path(tempdir(),"R2HTML"),filename="sample2",
>BackGroundColor="#BBBBEE")
>
>HTMLInsertGraph("<br>Title",file=target)
>
>#This for loop calls the animation function with each value of g.
>
>for(v in g){
>
>  output2=myanimation(v)
>
>  HTML(swf2html(output2),file=target)
>
>}
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul  9 04:19:15 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Jul 2014 19:19:15 -0700
Subject: [R] reorder a list
In-Reply-To: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
Message-ID: <1404872355.28319.YahooMailNeo@web142601.mail.bf1.yahoo.com>

You may also try:
library(reshape2)
?A2 <- melt(A1)

split(A2[,2],A2[,1])
A.K.




On Tuesday, July 8, 2014 12:57 PM, Lorenzo Alfieri <alfios17 at hotmail.com> wrote:
Hi,
I'm trying to find a way to reorder the elements of a list.
Let's say I have a list like this:
A1<-list(c(1:4),c(2,4,5),23,c(4,5,13))

> A1
[[1]]
[1] 1 2 3 4

[[2]]
[1] 2 4 5

[[3]]
[1] 23

[[4]]
[1]? 4? 5 13

All the elements included in it are values, while each sublist is a time index
Now, I'd like to reorder the list (without looping) so to obtain one sublist for each value, which include all the time indices where each value appears.
In other words, the result should look like this:
>A2
[[1]]
[1] 1

[[2]]
[1] 1 2? ? #because value "2" appears in the time index [[1]] and [[2]] of A1

[[3]]
[1] 1

[[4]]
[1] 1 2 4

[[5]]
[1] 2 4

[[13]]
[1] 4

[[23]]
[1] 3

Any suggestion?
Thanks
Alfio

??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Wed Jul  9 05:07:00 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Jul 2014 20:07:00 -0700
Subject: [R] Error in file.exists(swf.file) : invalid 'file' argument
In-Reply-To: <d48aafc1-88f3-47e8-a1b7-e3f8cb081a71@email.android.com>
References: <CAJJ9dtvySzhKS--92o3NMyVjpOJyb4xLY9Q5+GrOFZS5Sn345w@mail.gmail.com>
	<d48aafc1-88f3-47e8-a1b7-e3f8cb081a71@email.android.com>
Message-ID: <7EF80808-88C8-4B4E-A901-183EA8D6EFA2@comcast.net>


On Jul 8, 2014, at 5:49 PM, Jeff Newmiller wrote:

> Code is corrupted. Please post in plain text as the Posting Guide indicates is expected of you.

To explain a bit further.... Making text BOLD in formatted email adds extraneous asterisks in what some of us see in a plain text mail client. We could conceivably do some sort of global replacement of the '*'  ... but why should we? You are expected to post in plain text.  

Furthermore I'm guessing that saveSWF is a function from some non-base package. I do not see a library(,) or require(.) call that loads the package.

-- 
David,
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On July 8, 2014 2:28:04 PM PDT, Cheryl Johnson <johnson.cheryl625 at gmail.com> wrote:
>> *I am receiving the error message ???*Error in file.exists(swf.file) :
>> invalid 'file' argument*??? from my swf2html command. In addition,
>> there is a
>> command that says the Flash file was created: ???*Flash has been
>> created at:
>> C:\Users\CHERYL\AppData\Local\Temp\Rtmp6n6FXw\file2.swf*???*
>> 
>> *Below is the R code. Thanks in advance for any guidance.*
>> 
>> 
>> 
>> *g<-c(0.1,0.2,0.3)*
>> 
>> *#This function produces the swf file.*
>> 
>> *myanimation<-function(v){*
>> 
>> *output1=saveSWF({*
>> 
>> *<code>*
>> 
>> *}, img.name <http://img.name/> = "file",swf.name <http://swf.name/> =
>> "file2.swf" , single.opts = "'utf8': false", autoplay = FALSE , *
>> 
>> *interval = 0.1, imgdir = "directory", htmlfile = "random.html",
>> ani.height
>> = 500, *
>> 
>> *ani.width = 500, title = "groups", *
>> 
>> *description = c("group1", "group2"))*
>> 
>> *return(output1)*
>> 
>> }
>> 
>> #These commands create the html page.
>> 
>> dir.create(file.path(tempdir(),"R2HTML"))
>> 
>> target <-
>> HTMLInitFile(file.path(tempdir(),"R2HTML"),filename="sample2",
>> BackGroundColor="#BBBBEE")
>> 
>> HTMLInsertGraph("<br>Title",file=target)
>> 
>> #This for loop calls the animation function with each value of g.
>> 
>> for(v in g){
>> 
>> output2=myanimation(v)
>> 
>> HTML(swf2html(output2),file=target)
>> 
>> }
>> 
>> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From taquito2007 at gmail.com  Wed Jul  9 09:17:07 2014
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Wed, 9 Jul 2014 16:17:07 +0900
Subject: [R] How to process each element in 3 minute interval using a for
	loop in R?
Message-ID: <CADL0PchPvyWP_7n80YdQOZfGU-jyzXyxLE7wED96Xg0nVNxg5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/e2e6bc93/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Jul  9 09:31:40 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 09 Jul 2014 08:31:40 +0100
Subject: [R] How to process each element in 3 minute interval using a
 for loop in R?
In-Reply-To: <CADL0PchPvyWP_7n80YdQOZfGU-jyzXyxLE7wED96Xg0nVNxg5w@mail.gmail.com>
References: <CADL0PchPvyWP_7n80YdQOZfGU-jyzXyxLE7wED96Xg0nVNxg5w@mail.gmail.com>
Message-ID: <53BCEFDC.1090007@stats.ox.ac.uk>

On 09/07/2014 08:17, Takatsugu Kobayashi wrote:
> Hi R-users,
>
> This should be a simple question: How can I delay each loop process in some
> minutes? The reason for this is I need to avoid too much traffic to get
> longitudes and latitudes of 2000 addresses using google API.
>
> I am searching for solutions with keywords like interval, minutes, delay,
> but no directly relevant clues have come up yet.

See ?Sys.sleep

>
> Many thanks in advance.
>
> Best,
>
> Taka


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From alfios17 at hotmail.com  Wed Jul  9 11:04:21 2014
From: alfios17 at hotmail.com (Lorenzo Alfieri)
Date: Wed, 9 Jul 2014 11:04:21 +0200
Subject: [R] reorder a list
In-Reply-To: <CAF8bMcZ1iFZhtq4RzgTCBoLjhYnApV4y8SGaOjJ9Kxv+zr+1iw@mail.gmail.com>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>,
	<CAF8bMcZ1iFZhtq4RzgTCBoLjhYnApV4y8SGaOjJ9Kxv+zr+1iw@mail.gmail.com>
Message-ID: <DUB115-W129203369B27F7C705ED89ED70F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/8fed3382/attachment.pl>

From carlo-giovanni.camarda at ined.fr  Wed Jul  9 12:14:26 2014
From: carlo-giovanni.camarda at ined.fr (Carlo Giovanni Camarda)
Date: Wed, 09 Jul 2014 12:14:26 +0200
Subject: [R] matrix built by diagonal matrices with a given structure (2nd
 trial)
In-Reply-To: <246332922.78671.1403613515220.JavaMail.root@ined.fr>
References: <246332922.78671.1403613515220.JavaMail.root@ined.fr>
Message-ID: <53BD1602.6040808@ined.fr>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/daf9f06e/attachment.pl>

From mdsumner at gmail.com  Wed Jul  9 13:08:05 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 9 Jul 2014 21:08:05 +1000
Subject: [R] How to process each element in 3 minute interval using a
 for loop in R?
In-Reply-To: <CADL0PchPvyWP_7n80YdQOZfGU-jyzXyxLE7wED96Xg0nVNxg5w@mail.gmail.com>
References: <CADL0PchPvyWP_7n80YdQOZfGU-jyzXyxLE7wED96Xg0nVNxg5w@mail.gmail.com>
Message-ID: <CAAcGz9_yJpFebL8kRfO8cVbQcNk_HKuja30RqoJ2FRrgzSObPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/975e9f48/attachment.pl>

From joao.patricio at gmx.pt  Wed Jul  9 13:49:44 2014
From: joao.patricio at gmx.pt (=?ISO-8859-1?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Wed, 09 Jul 2014 12:49:44 +0100
Subject: [R] Transform a data.frame with ";
 " sep column and another one in a a new one with the same two
 column but with repetitions
In-Reply-To: <CAAJSdjgUgfPfqP-Z5Yz8n-g1b1nA1Osmrpc27mFX5XVpFSoncA@mail.gmail.com>
References: <53B6A32D.4000506@gmx.pt>
	<CAAJSdjgUgfPfqP-Z5Yz8n-g1b1nA1Osmrpc27mFX5XVpFSoncA@mail.gmail.com>
Message-ID: <53BD2C58.2020802@gmx.pt>

Em 05-07-2014 00:43, John McKown escreveu:
> I messed up my original response by not including r-help in the
> distribution. And now I won't look as bad because, after a short nap,
> I have new, much shorted (but more difficult, for me, to understand)
> answer.
>
> #
> # The original data is in the variable "x".
> z=data.frame(TC=x$TC,
> WC=I(mapply(strsplit,x$WC,MoreArgs=list(';'),USE.NAMES=FALSE)));
> result=data.frame(TC=rep(x$TC,sapply(z$WC,length)),WC=unlist(z$WC));
> #
>
> There may be a way to eliminate the temporary variable "z". Maybe I
> need another nap!
>
> The heart of this is the mapply, which results in a list where each
> entry in the list is another list. And the entries in embedded list
> are the list of results from the output of strsplit() on the WC
> information.
>
> If this needs to be a function, then
>
> splitUp <- function(x) {
>      z=data.frame(TC=x$TC,
> WC=I(mapply(strsplit,x$WC,MoreArgs=list(';'),USE.NAMES=FALSE)));
>      result=data.frame(TC=rep(x$TC,sapply(z$WC,length)),WC=unlist(z$WC));
>      return(result);
> }
>
> Then invoke it with:
>
> flattened.result <- splitUp(original.data.frame);
>
> On Fri, Jul 4, 2014 at 7:50 AM, Jo?o Azevedo Patr?cio
> <joao.patricio at gmx.pt> wrote:
>> Hi,
>>
>> I've been trying to solve this issue but with no success.
>>
>> I have some data like this:
>>
>> 1 > TC  WC
>> 2 > 0   Instruments & Instrumentation; Nuclear Science & Technology;
>> Physics, Particles & Fields; Spectroscopy
>> 3 > 0   Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
>> Physics, Applied
>> 4 > 2   Physics, Nuclear; Physics, Particles & Fields
>> 5 > 0   Chemistry, Inorganic & Nuclear
>> 6 > 2   Chemistry, Physical; Materials Science, Multidisciplinary;
>> Metallurgy & Metallurgical Engineering
>>
>> And I need to have this:
>>
>> 1 > TC  WC
>> 2 > 0   Instruments & Instrumentation
>> 2 > 0   Nuclear Science & Technology
>> 2 > 0   Physics, Particles & Fields
>> 2 > 0   Spectroscopy
>> 3 > 0   Nanoscience & Nanotechnology
>> 3 > 0   Materials Science, Multidisciplinary
>> 3 > 0   Physics, Applied
>> 4 > 2   Physics, Nuclear
>> 4 > 2   Physics, Particles & Fields
>> 5 > 0   Chemistry, Inorganic & Nuclear
>> 6 > 2   Chemistry, Physical
>> 6 > 2   Materials Science, Multidisciplinary
>> 6 > 2   Metallurgy & Metallurgical Engineering
>>
>> This means repeat the row for each element in WC and keeping the same value
>> in TC. The goal is to check how many TC (sum) there are by WC, when WC is
>> multiple.
>>
>> i've tried to separate the column using strsplt but then I cannot keep the
>> track of TC.
>>
>> thanks in advance.
>> --
>> Jo?o Azevedo Patr?cio
I've been testing it and the results is coming nicely.

It grabs a CSV taken from ISI Web Of science, works it out and produces 
a table organized by WC (web of science category) with number of papers 
per area, citations and impact factor.

my code is like this right now:

 > isi <- read.table("file.csv", header = TRUE, sep=";") ##get citations 
and web of science categories file
 > isisplit=data.frame(TC=isi$TC,
+ WC=I(mapply(strsplit,isi$WC,MoreArgs=list(';'),USE.NAMES=FALSE)));
 > 
result=data.frame(TC=rep(isi$TC,sapply(isisplit$WC,length)),WC=unlist(isisplit$WC));
 > isisplit$WC <- str_trim(isisplit$WC)
 > wccitations <- aggregate (isisplit$TC, by=list(Category=isisplit$WC), 
FUN = sum) ## creates a table with the list of WCategories and the 
specific + citations
 > colnames(wccitations) <- c("WC", "TC")
 > wcproduction <- table(isisplit$WC) ## creates a table with the number 
of pubs by WCategories
 > wcproduction <- as.data.table(wcproduction)
 > colnames(wcproduction) <- c("WC", "PUB")
 >wc <- data.frame(WC = wccitations$WC, PUB = wcproduction$PUB, TC = 
wccitations$TC, IMP = round((wcproduction$PUB/wccitations$TC), digits = 
+ 2))
 > wc[wc == Inf] = 0 ## removes inf in impact by impact 0
 > write.table(wc, file = "file.csv", sep = ";", dec = ",")


-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From johannesradinger at gmail.com  Wed Jul  9 14:06:46 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Wed, 9 Jul 2014 14:06:46 +0200
Subject: [R] Cutting hierarchical cluster tree at specific height fails
Message-ID: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/0a7c11a8/attachment.pl>

From jack at jackwasey.com  Wed Jul  9 10:27:24 2014
From: jack at jackwasey.com (Jack Wasey)
Date: Wed, 09 Jul 2014 08:27:24 -0000
Subject: [R] [R-pkgs] icd9 - a new R package
Message-ID: <CA+zP7HEU9Ny4_t4kDS=CFwPM5KhQ3nyMUOGMDCZ8HM3miFDgWg@mail.gmail.com>

Dear R people,

The new packge 'icd9' provides a range of tools for working with ICD-9-CM codes.

http://cran.r-project.org/web/packages/icd9/index.html
https://github.com/jackwasey/icd9

ICD-9 (clinical modification) is primarily used for categorizing
diseases in the USA for hospital administration, whereas ICD-10 is
used by the rest of the world for disease surveillance. This package
is currently restricted to ICD-9-CM codes.

I've seen other R code which manipulates ICD-9 codes, but the mistake
is often made of thinking they are numeric. This is not the case, e.g.
100.0 is different from 100 and 100.00 . This package takes care of
validating these codes, explaining them (converting code to plain
English), comparing them, and attributing codes to groups of codes to
assign co-morbidities to patients. ICD-9 codes are often provided in a
shortened format without a decimal place, and these have distinct
validation rules. Functions to convert between decimal and short forms
are provided. All key parts use vectorized code, and comorbidities for
a million patient visits can be assigned in a few seconds on a modest
workstation.

SAS code is published by AHRQ to allow assignment of ICD-9 codes to
comorbidities. This package contains some SAS source to R code
translation, so that the canonical ICD-9-CM to comorbidity mapping
provided by AHRQ can be derived directly without the cumbersome and
error-prone manual task of re-encoding the relationships in R. I
believe a SAS to R converter was an April Fools' joke some time ago,
but this is indeed a very limited answer to that problem.
http://www.biostatistics.dk/sas2r/index.html

A short vignette covers the major use-cases.
http://cran.r-project.org/web/packages/icd9/vignettes/icd9.pdf

The code is supported by a fairly thorough test suite, and is well
documented in the hope that it will be easier for users of the package
to understand it, and to get involved. I chose only to export key
functions where I had thought carefully about the external API, but
all internal functions are documented and contain potentially useful
nuggets for power users.

Comments and contributions are most welcome. In particular, I'd love
to see unit tests corresponding to any failures you may encounter
working with your own ICD-9 data.

Hope you find this useful.
Jack

--
Jack Wasey
Resident Physician, Anesthesiology and Critical Care Medicine
Johns Hopkins Hospital
Baltimore, MD, USA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From scdavis6 at gmail.com  Wed Jul  9 01:21:52 2014
From: scdavis6 at gmail.com (Scott Davis)
Date: Tue, 8 Jul 2014 16:21:52 -0700
Subject: [R] Error evaluating partitioning around medoids clustering method
 R clValid package
Message-ID: <CACjGKHJBpJSifBjOn29Nh2qUfzK48Prc-kDaVEMYMTViayd+CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140708/0f621aac/attachment.pl>

From Troung.Phan at team.telstra.com  Wed Jul  9 04:34:16 2014
From: Troung.Phan at team.telstra.com (Phan, Truong Q)
Date: Wed, 9 Jul 2014 12:34:16 +1000
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
Message-ID: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/d7254840/attachment.pl>

From _ at thomaslevine.com  Wed Jul  9 15:10:14 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Wed, 9 Jul 2014 13:10:14 +0000
Subject: [R] HPGL or PCL plotting device? Or otherwise plotting plots
Message-ID: <20140709131014.GB32129@d1stkfactory>

Hi,

I want to print plots on a Roland DXY-1100 plotter.
How can I do this from R? I think the easiest thing
would be a graphics device for Printer Command
Language or Hewlett-Packard Graphics Language, but
I haven't managed to find any of those.

Thanks

Tom


From _ at thomaslevine.com  Wed Jul  9 15:32:44 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Wed, 9 Jul 2014 13:32:44 +0000
Subject: [R] HPGL or PCL plotting device? Or otherwise plotting plots
In-Reply-To: <20140709131014.GB32129@d1stkfactory>
References: <20140709131014.GB32129@d1stkfactory>
Message-ID: <20140709133244.GA32313@d1stkfactory>

Oh it was easier than I thought.

  postscript('project-contracts.ps')
  hist(log(projects$n.contracts))
  dev.off()

Then run this from the shell.

  pstoedit -f plot-hpgl project-contracts.ps project-contracts.hpgl

And send it to the plotter.

On 09 Jul 13:10, Thomas Levine wrote:
> Hi,
> 
> I want to print plots on a Roland DXY-1100 plotter.
> How can I do this from R? I think the easiest thing
> would be a graphics device for Printer Command
> Language or Hewlett-Packard Graphics Language, but
> I haven't managed to find any of those.
> 
> Thanks
> 
> Tom


From gunter.berton at gene.com  Wed Jul  9 16:10:00 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 9 Jul 2014 07:10:00 -0700
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
In-Reply-To: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
References: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
Message-ID: <CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>

RStudio is a separate product with its own support. Post there, not here.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 8, 2014 at 7:34 PM, Phan, Truong Q
<Troung.Phan at team.telstra.com> wrote:
> Hi R'er,
>
> I have a dataset which has a matrix of 7502 x 1426 (rows x columns).
> The data is in a CSV format which has a size around 68Mb. This dataset is less than 10% of our dataset.
> I have been adopting the Anomaly detection method as described by http://www.mattpeeples.net/kmeans.html .
> It has been running more than 24hrs and still haven't completed the calculation.
> I did manage to run it with a smaller dataset (ie, 2100 rows x 1426 columns). It took around 12hrs to run.
>
> I have a few questions and need your expertise guidance.
>
> 1)      Is there any better Open source tools to use to do in one tool (eg, R Studio): prepare data, build models, validate models, test models and present data. I am looking a tool which will allow me to do the same as per the above link (Matt Peeples' blog).
>
> 2)      Is there an Open source tools to perform the above which will allow me to run on top of Hadoop eco-system?
>
> 3)      Can we use R Studio for windows as a client to run on top of Hadoop eco-system? If yes, please point me to the site where they have a use cases or samples.
>
> Thanks and Regards,
> Truong Phan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alvaroflores at derco.cl  Wed Jul  9 16:34:07 2014
From: alvaroflores at derco.cl (Alvaro Flores)
Date: Wed, 9 Jul 2014 10:34:07 -0400
Subject: [R] eclat problem
In-Reply-To: <53BD4B57.5090405@lyle.smu.edu>
References: <mailman.27.1404900009.27769.r-help@r-project.org>
	<53BD4B57.5090405@lyle.smu.edu>
Message-ID: <05A3A1E4B6BBE740AF1389A88C77583A0464597E15@DCQLC02EXC02.derco.cl>

Thanks Michael, everything going perfect right now! I didn't expect such an extensive list of itemsets given the insights on the data that I have. And the error message didn't gave me the right clue. Now is working fine! Thanks for your time! 

Best Regards.


Alvaro.




-----Mensaje original-----
De: Michael Hahsler [mailto:mhahsler at lyle.smu.edu] 
Enviado el: mi?rcoles, 09 de julio de 2014 10:02
Para: r-help at r-project.org; Alvaro Flores
Asunto: Re: [R] eclat problem

Hi Alvaro,

this was a tricky problem. Under Windows R uses the trio library (different from the package Trio which creates very similar error
messages) for printf support. arules currently contains a bug that results in an invalid format string for printf when an error message is created. For your problem below the error message should read "out of memory," but since creating the error message produces an invalid printf format string you see under Windows the internal error instead. This problem will be fixed in the next release of arules (version 1.1-4).

Note however that your code still runs out of memory and you need to increase support and/or restrict the number of items in the itemsets (both with the list for parameter; see also class? ECparameter).

-Michael

On 07.07.2014 22:56, Alvaro Flores wrote:
 >
 >
 > I'm working with arule packages and I'm constantly trying to mine frequent itemsets in different datasets. But recently R kept returning the same error message :
 >
 >
 >
 > Error in eclat(txn, parameter = list(supp = 0.001)) :
 >
 >    internal error in trio library
 >
 >
 >
 > Is just this particular dataset that gives me problems.
 >
 >
 >
 > Anyone has ever passed and fixed this error?
 >
 >
 >
 > Here are an example of the transaction data set:
 >
 >     items
 >
 > 1  {001200-3,
 >
 >      004100-3,
 >
 >      004200-5,
 >
 >      004500-9,
 >
 >      004600-5}
 >
 > 2  {001524-K,
 >
 >      002100-2}
 >
 > 3  {00179,
 >
 >      03807,
 >
 >      08019,
 >
 >      09314,
 >
 >      12432}
 >
 > 4  {002000}
 >
 > 5  {002600-4,
 >
 >      002700-0}
 >
 > 6  {004115-F,
 >
 >      02/100073A,
 >
 >      02/630935A,
 >
 >      044.1567.0,
 >
 >      044.1567.0/I,
 >
 >      1010301FA,
 >
 >      1012015-400-0000,
 >
 >      1117285,
 >
 >      1118100-201-4020,
 >
 >      1118105-051-0000M,
 >
 >      173171,
 >
 >      1903628,
 >
 >      1903628/I,
 >
 >      1903629,
 >
 >      1903629/I,
 >
 >      1907566,
 >
 >      1907567,
 >
 >      1907570,
 >
 >      1907571,
 >
 >      1931018,
 >
 >      2.4419.340.0,
 >
 >      215420/N,
 >
 >      2654408-N,
 >
 >      2992242,
 >
 >      2992544,
 >
 >      2996416,
 >
 >      2VC-115561,
 >
 >      320/04133A,
 >
 >      4102AZL.14.100N00,
 >
 >      4110Z.14.30,
 >
 >      4625547,
 >
 >      477556,
 >
 >      477556/O,
 >
 >      478736,
 >
 >      478736/O,
 >
 >      500054655,
 >
 >      581/18096,
 >
 >      61000070005,
 >
 >      957E-6731 A,
 >
 >      BF8T-6731 BA,
 >
 >      BG2X-6731 CA,
 >
 >      DBPN-6731 A,
 >
 >      F2NN-6714 AB,
 >
 >      LF16015,
 >
 >      LF3000,
 >
 >      LF3345,
 >
 >      LF3346,
 >
 >      LF3349,
 >
 >      LF3806,
 >
 >      LF4054,
 >
 >      LF9009,
 >
 >      RE504836,
 >
 >      RE59754,
 >
 >      T19044/I,
 >
 >      TAE-115561,
 >
 >      W-950/7,
 >
 >      ZP520}
 >
 > 7  {005226,
 >
 >      012.0348.0,
 >
 >      012.0349.0,
 >
 >      02/910150A,
 >
 >      1105010E834N00,
 >
 >      1105020D354,
 >
 >      1117011-630-0000W,
 >
 >      1117025-621-0000,
 >
 >      1372444,
 >
 >      1393640,
 >
 >      1457434310001,
 >
 >      1521219,
 >
 >      1873018,
 >
 >      1901605,
 >
 >      1902134,
 >
 >      1902138,
 >
 >      1902138/I,
 >
 >      1907640,
 >
 >      1907640/I,
 >
 >      1908547,
 >
 >      1908547/I,
 >
 >      1930010,
 >
 >      19BG920-30001,
 >
 >      20430751,
 >
 >      20514654,
 >
 >      20976003/O,
 >
 >      20998367,
 >
 >      215460,
 >
 >      26560143,
 >
 >      26560201,
 >
 >      26560201/I,
 >
 >      2710806,
 >
 >      2992241,
 >
 >      2992241/I,
 >
 >      2992300,
 >
 >      2992662,
 >
 >      2992662/I,
 >
 >      2995711,
 >
 >      2997376,
 >
 >      2R0-127177,
 >
 >      2R0-127177 A,
 >
 >      2RD-127491,
 >
 >      32/401102,
 >
 >      32/912001A,
 >
 >      32/925423,
 >
 >      32/925760,
 >
 >      32/925869,
 >
 >      32/925915,
 >
 >      320/07155,
 >
 >      343144,
 >
 >      4102H.15.110,
 >
 >      4102H.15.110N00,
 >
 >      4102H.15.20,
 >
 >      500315480,
 >
 >      500315480/I,
 >
 >      500316868,
 >
 >      550228,
 >
 >      550228/N,
 >
 >      582042,
 >
 >      612630080011N00,
 >
 >      612630080087,
 >
 >      7146717,
 >
 >      8159975/O,
 >
 >      81BASE9200001,
 >
 >      98439681,
 >
 >      AR50041,
 >
 >      BC11320000N01,
 >
 >      BF0X-9155 AA,
 >
 >      BF5T-9155 AB,
 >
 >      BF8T-9155 DA,
 >
 >      DDN-99162 B,
 >
 >      DONN-9N074 BG,
 >
 >      E5HT-9155 CA,
 >
 >      E7HN-9155 AA,
 >
 >      FF42000,
 >
 >      FF5421,
 >
 >      FF5458,
 >
 >      FF5488,
 >
 >      FS1000,
 >
 >      FS1015,
 >
 >      FS1241,
 >
 >      FS1242,
 >
 >      FS1280,
 >
 >      PSD460/1,
 >
 >      PSD970/1,
 >
 >      R28-30M,
 >
 >      RC45MB,
 >
 >      RE62418,
 >
 >      RK120MBQ2,
 >
 >      T22VA,
 >
 >      WK-723}
 >
 > 8  {005227,
 >
 >      2641311,
 >
 >      2641371,
 >
 >      2641406,
 >
 >      2641725,
 >
 >      2641729,
 >
 >      2641808,
 >
 >      376518,
 >
 >      4757883,
 >
 >      72013,
 >
 >      72061,
 >
 >      8190393,
 >
 >      9986316,
 >
 >      D8NN-9350 AA,
 >
 >      DDN-9350,
 >
 >      RE42211}
 >
 > 9  {0055,
 >
 >      0087,
 >
 >      0482,
 >
 >      0484,
 >
 >      0531,
 >
 >      11329,
 >
 >      8311}
 >
 > 10 {007.0762.0/40,
 >
 >      014.0428.0,
 >
 >      1114036,
 >
 >      1118369,
 >
 >      1118375,
 >
 >      1118376,
 >
 >      1118377,
 >
 >      1118379,
 >
 >      1305546,
 >
 >      1312934,
 >
 >      1677591,
 >
 >      1677592,
 >
 >      1677593,
 >
 >      2.1539.130.0,
 >
 >      2.1539.259.0,
 >
 >      20515059/C,
 >
 >      275092/C,
 >
 >      275636/C,
 >
 >      2RD-107124,
 >
 >      31358393-G,
 >
 >      3135X031,
 >
 >      3135X063,
 >
 >      4622074,
 >
 >      4622074/G,
 >
 >      4742199,
 >
 >      4742202,
 >
 >      4770623,
 >
 >      4803030/G,
 >
 >      500337911,
 >
 >      61316752,
 >
 >      61316793,
 >
 >      7114756,
 >
 >      8815939,
 >
 >      99435938,
 >
 >      99448192,
 >
 >      99467115,
 >
 >      BF0X-6055 AA,
 >
 >      BF0X-6055 AA/C,
 >
 >      BF0X-6055 AA/CM,
 >
 >      BF0X-6055 AA/M,
 >
 >      BF8T-6055 AA,
 >
 >      TAE-107125,
 >
 >      TAF-107127,
 >
 >      TE3-107125}
 >
 > 11 {008.4748.4,
 >
 >      026566T3,
 >
 >      1370794,
 >
 >      1393185,
 >
 >      1868005,
 >
 >      2UH-141025,
 >
 >      353430,
 >
 >      5016033/034,
 >
 >      5196807,
 >
 >      9959900,
 >
 >      9962518,
 >
 >      E6NN-7563 AA,
 >
 >      EONN-7563 BA,
 >
 >      XC45-7563 BA/C/P,
 >
 >      XC45-7563 CA}
 >
 > 12 {009.4749.3,
 >
 >      1865836,
 >
 >      2RD-141031,
 >
 >      3191991,
 >
 >      3610274,
 >
 >      42102093,
 >
 >      4999812/R,
 >
 >      525587/D,
 >
 >      887889,
 >
 >      96HU-7550 AA,
 >
 >      96HU-7550 AA/C,
 >
 >      97HU-7550 AA/C,
 >
 >      AL33315,
 >
 >      C7NN-7550 V,
 >
 >      D1NN-7550 A,
 >
 >      D5NN-7550 A,
 >
 >      E6NN-7550 ABL}
 >
 > 13 {0118,
 >
 >      VLF-3200,
 >
 >      VLF-3202,
 >
 >      VLF-3205}
 >
 > 14 {014.5259.0/10,
 >
 >      014.5260.0/10,
 >
 >      014.5261.0/10,
 >
 >      065.1450.0/30,
 >
 >      069.1450.0/30,
 >
 >      087.0050.0,
 >
 >      087.0050.6/10,
 >
 >      1367028/CL,
 >
 >      136750,
 >
 >      143810,
 >
 >      149300,
 >
 >      149340,
 >
 >      1725112,
 >
 >      1905560/KP,
 >
 >      1905961/62,
 >
 >      1905968/G,
 >
 >      1908819,
 >
 >      1930248,
 >
 >      2500617/K,
 >
 >      270789,
 >
 >      2830919,
 >
 >      2852012,
 >
 >      2852743,
 >
 >      2992642,
 >
 >      2R0-109287,
 >
 >      2R0-198015 C,
 >
 >      2TA-109289/4,
 >
 >      3092642,
 >
 >      3228362R1,
 >
 >      36811122,
 >
 >      36812349,
 >
 >      3681E006,
 >
 >      3681E037,
 >
 >      3681E046,
 >
 >      4690375,
 >
 >      500308780,
 >
 >      551528,
 >
 >      99477119,
 >
 >      BF0X-6008 AA,
 >
 >      BF5X-6008 D,
 >
 >      BF5X-6008 D/4,
 >
 >      BF5X-6020 C,
 >
 >      BF5X-6L621 A,
 >
 >      BG5X-6008 AA,
 >
 >      BG5X-6008 BA,
 >
 >      C7NN-6584 B,
 >
 >      C7NN-6584 C,
 >
 >      CFPN-6008 FKI,
 >
 >      D4NN-6008 BG,
 >
 >      D4NN-6008 BGI,
 >
 >      D4NN-6710 A,
 >
 >      DDN-6008 AM,
 >
 >      DDN-6051 CG,
 >
 >      EONN-6051 AA,
 >
 >      EONN-6051 FA,
 >
 >      EONN-6051 FAGG,
 >
 >      R80241,
 >
 >      R92425,
 >
 >      RE38857,
 >
 >      RE50978,
 >
 >      TE6H-6008 B,
 >
 >      TJG-109289,
 >
 >      TJG-115441,
 >
 >      U5LB1164,
 >
 >      U5LT0065/016,
 >
 >      U5LT0178}
 >
 > 15 {014.7994.4,
 >
 >      1448659,
 >
 >      1887506,
 >
 >      20709848,
 >
 >      20824906,
 >
 >      2VC-115105,
 >
 >      4705827,
 >
 >      479317,
 >
 >      4802609,
 >
 >      8193737,
 >
 >      BF5T-6600 A,
 >
 >      BF5X-6600 B,
 >
 >      BG1X-6600 AA,
 >
 >      C7NN-6A605 A,
 >
 >      D3NN-6A820 F,
 >
 >      D5NN-6600 DI,
 >
 >      F1NN-9278 AA,
 >
 >      R78202,
 >
 >      TJG-117021}
 >
 >
 >
 > Thanks in advance.
 >
 >
 > Alvaro.
 >


-- 
   Michael Hahsler, Assistant Professor
   Department of Engineering Management, Information, and Systems
   Department of Computer Science and Engineering
   Bobby B. Lyle School of Engineering
   Southern Methodist University, Dallas, Texas

   office: Caruth Hall, suite 337, room 311
   email:  mhahsler at lyle.smu.edu
   web:    http://lyle.smu.edu/~mhahsler


From david at revolutionanalytics.com  Wed Jul  9 16:52:25 2014
From: david at revolutionanalytics.com (David Smith)
Date: Wed, 9 Jul 2014 09:52:25 -0500
Subject: [R] Revolutions blog: June 2014 Roundup
Message-ID: <CABgvEC-y3p-rLrHCA9-9hkQ0DvCpVNhK7KcGq9w97xRcU=4Rww@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of June:

The useR! 2014 conference in Los Angeles opened with 16 tutorials:
http://bit.ly/1rSoqeh

DataInformed published my article on how various companies use R:
http://bit.ly/1rSos5L

Joe Rickert reviews the new book "Applied Predictive Modeling" by Max
Kuhn and Kjell Johnson, which is rich with examples in R and the
"caret" package: http://bit.ly/1rSopam

Hadley Wickham's new ggvis package features a new syntax to create
interactive ggplot2-style graphics: http://bit.ly/1rSoqei

Guest poster Wayne Smith reviews the R and Statistics presentations at
the Intel International Science and Engineering Fair:
http://bit.ly/1rSos5K

Bank of America uses R to make "mundane tables stand out", as reported
in a recent FastCoLabs article: http://bit.ly/1rSoqen

DataCamp created an infographic comparing SAS, R and SPSS: http://bit.ly/1rSos5M

Prizes on offer for the best R graphic mapping the locations of R user
groups: http://bit.ly/1rSoqeo

Guy Abel used the circlize package to visualize the players in the
World Cup and the location of their home teams: http://bit.ly/1rSos5N

How to create a clean financial data set for backtesting using data
from Quandl: http://bit.ly/1rSoqep

R's popularity continues to surge, with high rankings in the latest
KDNuggets poll and Redmonk language rankings: http://bit.ly/1rSos5O

Analysis of movie palettes using Python and R reveals that Hollywood
cinematographers prefer orange and blue: http://bit.ly/1rSoqeq

There are now 141 R user groups worldwide, with recent additions in
Chennai (India), Exeter (UK), Miami (FL), Durham (NH), Albany (NY) and
Charlotte (NC): http://bit.ly/1rSos5Q

Two more companies share how they use R: the ride-sharing company
Uber, and CultureAmp (a "people intelligence platform"):
http://bit.ly/1rSoquF

Tutorial on constructing a term structure of interest rates with R:
http://bit.ly/1rSos5R

R is featured in a Dataversity article on the relevance of open source
analytics for businesses: http://bit.ly/1rSoqer

The China R Users Conference attracted more than 1000 attendees:
http://bit.ly/1rSoquE

A look at the state of the art in Deep Learning research, including
the darch and deepnet packages: http://bit.ly/1rSos5U

One million students have enrolled in Coursera courses based on R:
http://bit.ly/1rSoquG

An updated function for reading data into R from Google Spreadsheets
that works with Google's current security model: http://bit.ly/1rSos5W

General interest stories (not related to R) in the past month
included: the illusory colors of Benham's Top (http://bit.ly/1rSos5V),
an airport performance of "All by Myself" (http://bit.ly/1rSoquH), and
beer bottle harmonies (http://bit.ly/1rSos5X).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
Try Enterprise R Now!  
<https://aws.amazon.com/marketplace/seller-profile/ref=_ptnr_emailfooter?ie=UTF8&id=3c6536d3-8115-4bc0-a713-be58e257a7be>
Get a 14 Day Free Trial of Revolution R Enterprise on AWS Marketplace


From aguitatierra at hotmail.com  Wed Jul  9 17:24:02 2014
From: aguitatierra at hotmail.com (Bea GD)
Date: Wed, 9 Jul 2014 17:24:02 +0200
Subject: [R] How to include factor levels into plot title?
Message-ID: <BLU436-SMTP1632B86CBDFDD90ED35541D90F0@phx.gbl>

Hi all,

I'd like to include the levels of one of my variables in the title of a 
plot. I'd like these factor levels to be concatenated. E.g. 'These are 
the levels: setosa, versicolor, virginica'.

I've been working with this code but I don't get the desired results. 
Any suggestions would be a great help. Thanks!

dd <- iris

plot(dd$Sepal.Length, dd$Petal.Length,
      main=sprintf("These are the levels: %s", levels(dd$Species)))


From dcarlson at tamu.edu  Wed Jul  9 17:31:23 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 9 Jul 2014 15:31:23 +0000
Subject: [R] Cutting hierarchical cluster tree at specific height fails
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F85A5E@mb02.ads.tamu.edu>

To cut the tree, the clustering algorithm must produce consistently increasing height values with no reversals. You used one of the two options in hclust that does not do this. Note the following from the hclust manual page:

"Note however, that methods "median" and "centroid" are not leading to a monotone distance measure, or equivalently the resulting dendrograms can have so called inversions (which are hard to interpret)."

The cutree manual page:

"Cutting trees at a given height is only possible for ultrametric trees (with monotone clustering heights)."

Use a different method (but not median).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Johannes Radinger
Sent: Wednesday, July 9, 2014 7:07 AM
To: R help
Subject: [R] Cutting hierarchical cluster tree at specific height fails

Hi,

I'd like to cut a hierachical cluster tree calculated with hclust at a
specific height.
However ever get following error message:
"Error in cutree(hc, h = 60) :
  the 'height' component of 'tree' is not sorted (increasingly)"


Here is a working example to show that when specifing a height in  cutree()
the code fails. In contrast, specifying the number of clusters in cutree()
works.
What is the exact problem and how can I solve it?

x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
df <- data.frame(x,y)
plot(df)

hc <- hclust(dist(df,method = "euclidean"), method="centroid")
plot(hc)

df$memb <- cutree(hc, h = 60) # this does not work
df$memb <- cutree(hc, k = 3) # this works!

plot(df$x,df$y,col=df$memb)


Thank you for your hints!

Best regards,
Johannes

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Wed Jul  9 17:46:48 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Jul 2014 11:46:48 -0400
Subject: [R] How to include factor levels into plot title?
In-Reply-To: <BLU436-SMTP1632B86CBDFDD90ED35541D90F0@phx.gbl>
References: <BLU436-SMTP1632B86CBDFDD90ED35541D90F0@phx.gbl>
Message-ID: <CAM_vjum7Fp3CZE-bvNP5T4vGoU5EnhvuNe8sKk_pu3Q=OwHKiA@mail.gmail.com>

How about:


plot(dd$Sepal.Length, dd$Petal.Length, main=paste("These are the
levels:", paste(levels(dd$Species), collapse=", ")))


Thanks for the actual reproducible example!

Sarah

On Wed, Jul 9, 2014 at 11:24 AM, Bea GD <aguitatierra at hotmail.com> wrote:
> Hi all,
>
> I'd like to include the levels of one of my variables in the title of a
> plot. I'd like these factor levels to be concatenated. E.g. 'These are the
> levels: setosa, versicolor, virginica'.
>
> I've been working with this code but I don't get the desired results. Any
> suggestions would be a great help. Thanks!
>
> dd <- iris
>
> plot(dd$Sepal.Length, dd$Petal.Length,
>      main=sprintf("These are the levels: %s", levels(dd$Species)))
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From mhahsler at lyle.smu.edu  Wed Jul  9 16:01:59 2014
From: mhahsler at lyle.smu.edu (Michael Hahsler)
Date: Wed, 9 Jul 2014 16:01:59 +0200
Subject: [R] eclat problem
In-Reply-To: <mailman.27.1404900009.27769.r-help@r-project.org>
References: <mailman.27.1404900009.27769.r-help@r-project.org>
Message-ID: <53BD4B57.5090405@lyle.smu.edu>

Hi Alvaro,

this was a tricky problem. Under Windows R uses the trio library 
(different from the package Trio which creates very similar error 
messages) for printf support. arules currently contains a bug that 
results in an invalid format string for printf when an error message is 
created. For your problem below the error message should read "out of 
memory," but since creating the error message produces an invalid printf 
format string you see under Windows the internal error instead. This 
problem will be fixed in the next release of arules (version 1.1-4).

Note however that your code still runs out of memory and you need to 
increase support and/or restrict the number of items in the itemsets 
(both with the list for parameter; see also class? ECparameter).

-Michael

On 07.07.2014 22:56, Alvaro Flores wrote:
 >
 >
 > I'm working with arule packages and I'm constantly trying to mine 
frequent itemsets in different datasets. But recently R kept returning 
the same error message :
 >
 >
 >
 > Error in eclat(txn, parameter = list(supp = 0.001)) :
 >
 >    internal error in trio library
 >
 >
 >
 > Is just this particular dataset that gives me problems.
 >
 >
 >
 > Anyone has ever passed and fixed this error?
 >
 >
 >
 > Here are an example of the transaction data set:
 >
 >     items
 >
 > 1  {001200-3,
 >
 >      004100-3,
 >
 >      004200-5,
 >
 >      004500-9,
 >
 >      004600-5}
 >
 > 2  {001524-K,
 >
 >      002100-2}
 >
 > 3  {00179,
 >
 >      03807,
 >
 >      08019,
 >
 >      09314,
 >
 >      12432}
 >
 > 4  {002000}
 >
 > 5  {002600-4,
 >
 >      002700-0}
 >
 > 6  {004115-F,
 >
 >      02/100073A,
 >
 >      02/630935A,
 >
 >      044.1567.0,
 >
 >      044.1567.0/I,
 >
 >      1010301FA,
 >
 >      1012015-400-0000,
 >
 >      1117285,
 >
 >      1118100-201-4020,
 >
 >      1118105-051-0000M,
 >
 >      173171,
 >
 >      1903628,
 >
 >      1903628/I,
 >
 >      1903629,
 >
 >      1903629/I,
 >
 >      1907566,
 >
 >      1907567,
 >
 >      1907570,
 >
 >      1907571,
 >
 >      1931018,
 >
 >      2.4419.340.0,
 >
 >      215420/N,
 >
 >      2654408-N,
 >
 >      2992242,
 >
 >      2992544,
 >
 >      2996416,
 >
 >      2VC-115561,
 >
 >      320/04133A,
 >
 >      4102AZL.14.100N00,
 >
 >      4110Z.14.30,
 >
 >      4625547,
 >
 >      477556,
 >
 >      477556/O,
 >
 >      478736,
 >
 >      478736/O,
 >
 >      500054655,
 >
 >      581/18096,
 >
 >      61000070005,
 >
 >      957E-6731 A,
 >
 >      BF8T-6731 BA,
 >
 >      BG2X-6731 CA,
 >
 >      DBPN-6731 A,
 >
 >      F2NN-6714 AB,
 >
 >      LF16015,
 >
 >      LF3000,
 >
 >      LF3345,
 >
 >      LF3346,
 >
 >      LF3349,
 >
 >      LF3806,
 >
 >      LF4054,
 >
 >      LF9009,
 >
 >      RE504836,
 >
 >      RE59754,
 >
 >      T19044/I,
 >
 >      TAE-115561,
 >
 >      W-950/7,
 >
 >      ZP520}
 >
 > 7  {005226,
 >
 >      012.0348.0,
 >
 >      012.0349.0,
 >
 >      02/910150A,
 >
 >      1105010E834N00,
 >
 >      1105020D354,
 >
 >      1117011-630-0000W,
 >
 >      1117025-621-0000,
 >
 >      1372444,
 >
 >      1393640,
 >
 >      1457434310001,
 >
 >      1521219,
 >
 >      1873018,
 >
 >      1901605,
 >
 >      1902134,
 >
 >      1902138,
 >
 >      1902138/I,
 >
 >      1907640,
 >
 >      1907640/I,
 >
 >      1908547,
 >
 >      1908547/I,
 >
 >      1930010,
 >
 >      19BG920-30001,
 >
 >      20430751,
 >
 >      20514654,
 >
 >      20976003/O,
 >
 >      20998367,
 >
 >      215460,
 >
 >      26560143,
 >
 >      26560201,
 >
 >      26560201/I,
 >
 >      2710806,
 >
 >      2992241,
 >
 >      2992241/I,
 >
 >      2992300,
 >
 >      2992662,
 >
 >      2992662/I,
 >
 >      2995711,
 >
 >      2997376,
 >
 >      2R0-127177,
 >
 >      2R0-127177 A,
 >
 >      2RD-127491,
 >
 >      32/401102,
 >
 >      32/912001A,
 >
 >      32/925423,
 >
 >      32/925760,
 >
 >      32/925869,
 >
 >      32/925915,
 >
 >      320/07155,
 >
 >      343144,
 >
 >      4102H.15.110,
 >
 >      4102H.15.110N00,
 >
 >      4102H.15.20,
 >
 >      500315480,
 >
 >      500315480/I,
 >
 >      500316868,
 >
 >      550228,
 >
 >      550228/N,
 >
 >      582042,
 >
 >      612630080011N00,
 >
 >      612630080087,
 >
 >      7146717,
 >
 >      8159975/O,
 >
 >      81BASE9200001,
 >
 >      98439681,
 >
 >      AR50041,
 >
 >      BC11320000N01,
 >
 >      BF0X-9155 AA,
 >
 >      BF5T-9155 AB,
 >
 >      BF8T-9155 DA,
 >
 >      DDN-99162 B,
 >
 >      DONN-9N074 BG,
 >
 >      E5HT-9155 CA,
 >
 >      E7HN-9155 AA,
 >
 >      FF42000,
 >
 >      FF5421,
 >
 >      FF5458,
 >
 >      FF5488,
 >
 >      FS1000,
 >
 >      FS1015,
 >
 >      FS1241,
 >
 >      FS1242,
 >
 >      FS1280,
 >
 >      PSD460/1,
 >
 >      PSD970/1,
 >
 >      R28-30M,
 >
 >      RC45MB,
 >
 >      RE62418,
 >
 >      RK120MBQ2,
 >
 >      T22VA,
 >
 >      WK-723}
 >
 > 8  {005227,
 >
 >      2641311,
 >
 >      2641371,
 >
 >      2641406,
 >
 >      2641725,
 >
 >      2641729,
 >
 >      2641808,
 >
 >      376518,
 >
 >      4757883,
 >
 >      72013,
 >
 >      72061,
 >
 >      8190393,
 >
 >      9986316,
 >
 >      D8NN-9350 AA,
 >
 >      DDN-9350,
 >
 >      RE42211}
 >
 > 9  {0055,
 >
 >      0087,
 >
 >      0482,
 >
 >      0484,
 >
 >      0531,
 >
 >      11329,
 >
 >      8311}
 >
 > 10 {007.0762.0/40,
 >
 >      014.0428.0,
 >
 >      1114036,
 >
 >      1118369,
 >
 >      1118375,
 >
 >      1118376,
 >
 >      1118377,
 >
 >      1118379,
 >
 >      1305546,
 >
 >      1312934,
 >
 >      1677591,
 >
 >      1677592,
 >
 >      1677593,
 >
 >      2.1539.130.0,
 >
 >      2.1539.259.0,
 >
 >      20515059/C,
 >
 >      275092/C,
 >
 >      275636/C,
 >
 >      2RD-107124,
 >
 >      31358393-G,
 >
 >      3135X031,
 >
 >      3135X063,
 >
 >      4622074,
 >
 >      4622074/G,
 >
 >      4742199,
 >
 >      4742202,
 >
 >      4770623,
 >
 >      4803030/G,
 >
 >      500337911,
 >
 >      61316752,
 >
 >      61316793,
 >
 >      7114756,
 >
 >      8815939,
 >
 >      99435938,
 >
 >      99448192,
 >
 >      99467115,
 >
 >      BF0X-6055 AA,
 >
 >      BF0X-6055 AA/C,
 >
 >      BF0X-6055 AA/CM,
 >
 >      BF0X-6055 AA/M,
 >
 >      BF8T-6055 AA,
 >
 >      TAE-107125,
 >
 >      TAF-107127,
 >
 >      TE3-107125}
 >
 > 11 {008.4748.4,
 >
 >      026566T3,
 >
 >      1370794,
 >
 >      1393185,
 >
 >      1868005,
 >
 >      2UH-141025,
 >
 >      353430,
 >
 >      5016033/034,
 >
 >      5196807,
 >
 >      9959900,
 >
 >      9962518,
 >
 >      E6NN-7563 AA,
 >
 >      EONN-7563 BA,
 >
 >      XC45-7563 BA/C/P,
 >
 >      XC45-7563 CA}
 >
 > 12 {009.4749.3,
 >
 >      1865836,
 >
 >      2RD-141031,
 >
 >      3191991,
 >
 >      3610274,
 >
 >      42102093,
 >
 >      4999812/R,
 >
 >      525587/D,
 >
 >      887889,
 >
 >      96HU-7550 AA,
 >
 >      96HU-7550 AA/C,
 >
 >      97HU-7550 AA/C,
 >
 >      AL33315,
 >
 >      C7NN-7550 V,
 >
 >      D1NN-7550 A,
 >
 >      D5NN-7550 A,
 >
 >      E6NN-7550 ABL}
 >
 > 13 {0118,
 >
 >      VLF-3200,
 >
 >      VLF-3202,
 >
 >      VLF-3205}
 >
 > 14 {014.5259.0/10,
 >
 >      014.5260.0/10,
 >
 >      014.5261.0/10,
 >
 >      065.1450.0/30,
 >
 >      069.1450.0/30,
 >
 >      087.0050.0,
 >
 >      087.0050.6/10,
 >
 >      1367028/CL,
 >
 >      136750,
 >
 >      143810,
 >
 >      149300,
 >
 >      149340,
 >
 >      1725112,
 >
 >      1905560/KP,
 >
 >      1905961/62,
 >
 >      1905968/G,
 >
 >      1908819,
 >
 >      1930248,
 >
 >      2500617/K,
 >
 >      270789,
 >
 >      2830919,
 >
 >      2852012,
 >
 >      2852743,
 >
 >      2992642,
 >
 >      2R0-109287,
 >
 >      2R0-198015 C,
 >
 >      2TA-109289/4,
 >
 >      3092642,
 >
 >      3228362R1,
 >
 >      36811122,
 >
 >      36812349,
 >
 >      3681E006,
 >
 >      3681E037,
 >
 >      3681E046,
 >
 >      4690375,
 >
 >      500308780,
 >
 >      551528,
 >
 >      99477119,
 >
 >      BF0X-6008 AA,
 >
 >      BF5X-6008 D,
 >
 >      BF5X-6008 D/4,
 >
 >      BF5X-6020 C,
 >
 >      BF5X-6L621 A,
 >
 >      BG5X-6008 AA,
 >
 >      BG5X-6008 BA,
 >
 >      C7NN-6584 B,
 >
 >      C7NN-6584 C,
 >
 >      CFPN-6008 FKI,
 >
 >      D4NN-6008 BG,
 >
 >      D4NN-6008 BGI,
 >
 >      D4NN-6710 A,
 >
 >      DDN-6008 AM,
 >
 >      DDN-6051 CG,
 >
 >      EONN-6051 AA,
 >
 >      EONN-6051 FA,
 >
 >      EONN-6051 FAGG,
 >
 >      R80241,
 >
 >      R92425,
 >
 >      RE38857,
 >
 >      RE50978,
 >
 >      TE6H-6008 B,
 >
 >      TJG-109289,
 >
 >      TJG-115441,
 >
 >      U5LB1164,
 >
 >      U5LT0065/016,
 >
 >      U5LT0178}
 >
 > 15 {014.7994.4,
 >
 >      1448659,
 >
 >      1887506,
 >
 >      20709848,
 >
 >      20824906,
 >
 >      2VC-115105,
 >
 >      4705827,
 >
 >      479317,
 >
 >      4802609,
 >
 >      8193737,
 >
 >      BF5T-6600 A,
 >
 >      BF5X-6600 B,
 >
 >      BG1X-6600 AA,
 >
 >      C7NN-6A605 A,
 >
 >      D3NN-6A820 F,
 >
 >      D5NN-6600 DI,
 >
 >      F1NN-9278 AA,
 >
 >      R78202,
 >
 >      TJG-117021}
 >
 >
 >
 > Thanks in advance.
 >
 >
 > Alvaro.
 >


-- 
   Michael Hahsler, Assistant Professor
   Department of Engineering Management, Information, and Systems
   Department of Computer Science and Engineering
   Bobby B. Lyle School of Engineering
   Southern Methodist University, Dallas, Texas

   office: Caruth Hall, suite 337, room 311
   email:  mhahsler at lyle.smu.edu
   web:    http://lyle.smu.edu/~mhahsler


From jdnewmil at dcn.davis.CA.us  Wed Jul  9 18:24:14 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 09 Jul 2014 09:24:14 -0700
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
In-Reply-To: <CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>
References: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
	<CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>
Message-ID: <4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>

Grumpy today, Bert?

While it is a fact that RStudio is a separate tool from R, it is clear from the question that the OP is interested in capabilities that R is providing and he simply cannot tell the difference.

OP:

1) "Better" is a word that leads to pointless arguments. You will have to be the judge of what works for you. I caution you that Open Source tools almost always achieve success by interoperating with other OS tools, and much of the success you have already obtained is the result of many contributions, of which R and its contributed packages deserve the lion's share of credit. RStudio is a very convenient editor that makes using R and LaTeX and Markdown and version control easier, but it is unlikely that either the blame for your dissatisfaction or the credit for your success should be attributed to RStudio.

I have successfully used all sorts of plain text editors and command line interfaces with R, and if you plan to scale up your projects then you will likely want to be very clear on this distinction between editors and computing tools so you can distribute your work on multiple parallel servers (where editors may not necessarily even be helpful) even if you choose to use RStudio as your controlling environment for launching such tasks.

2) and 3) I know that R has contributed packages that can manage Hadoop data processing, but I have no personal experience with them. Google is your friend... especially if you keep in mind that these tools are not all found in one monolithic package.

For future reference: this is a plain text mailing list, so please adjust your mail client appropriately when sending to this list. Also, there are considerable resources mentioned in the Posting Guide that you should be aware of... see the link below.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 9, 2014 7:10:00 AM PDT, Bert Gunter <gunter.berton at gene.com> wrote:
>RStudio is a separate product with its own support. Post there, not
>here.
>
>-- Bert
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>(650) 467-7374
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>Clifford Stoll
>
>
>
>
>On Tue, Jul 8, 2014 at 7:34 PM, Phan, Truong Q
><Troung.Phan at team.telstra.com> wrote:
>> Hi R'er,
>>
>> I have a dataset which has a matrix of 7502 x 1426 (rows x columns).
>> The data is in a CSV format which has a size around 68Mb. This
>dataset is less than 10% of our dataset.
>> I have been adopting the Anomaly detection method as described by
>http://www.mattpeeples.net/kmeans.html .
>> It has been running more than 24hrs and still haven't completed the
>calculation.
>> I did manage to run it with a smaller dataset (ie, 2100 rows x 1426
>columns). It took around 12hrs to run.
>>
>> I have a few questions and need your expertise guidance.
>>
>> 1)      Is there any better Open source tools to use to do in one
>tool (eg, R Studio): prepare data, build models, validate models, test
>models and present data. I am looking a tool which will allow me to do
>the same as per the above link (Matt Peeples' blog).
>>
>> 2)      Is there an Open source tools to perform the above which will
>allow me to run on top of Hadoop eco-system?
>>
>> 3)      Can we use R Studio for windows as a client to run on top of
>Hadoop eco-system? If yes, please point me to the site where they have
>a use cases or samples.
>>
>> Thanks and Regards,
>> Truong Phan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Jul  9 18:26:14 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 9 Jul 2014 09:26:14 -0700
Subject: [R] reorder a list
In-Reply-To: <DUB115-W129203369B27F7C705ED89ED70F0@phx.gbl>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
	<CAF8bMcZ1iFZhtq4RzgTCBoLjhYnApV4y8SGaOjJ9Kxv+zr+1iw@mail.gmail.com>
	<DUB115-W129203369B27F7C705ED89ED70F0@phx.gbl>
Message-ID: <CAF8bMcYvipQQ8_ObzFBLm83T9L1DBWbiXi9m625_c148k9j6MA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/ad565148/attachment.pl>

From chrisaa at med.umich.edu  Wed Jul  9 18:26:34 2014
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Wed, 9 Jul 2014 16:26:34 +0000
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <1404835229.95312.YahooMailBasic@web140204.mail.bf1.yahoo.com>
References: <mailman.88.1404764530.4543.r-help@r-project.org>
	<1404835229.95312.YahooMailBasic@web140204.mail.bf1.yahoo.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C2D7190@UHEXMBSPR03.umhs.med.umich.edu>

The code is actually available at the websites you provide.  Try "View page source" in your browser.  The most cryptic code isn't needed because the math functions (e.g, incomplete gamma function) are available in R.


-----Original Message-----
From: Paul Miller [mailto:pjmiller_57 at yahoo.com] 
Sent: Tuesday, July 08, 2014 12:00 PM
To: r-help at r-project.org
Subject: [R] Survival Analysis with an Historical Control

Hello All,

I'm trying to figure out how to perform a survival analysis with an historical control. I've spent some time looking online and in my boooks but haven't found much showing how to do this. Was wondering if there is a R package that can do it, or if there are resources somewhere that show the actual steps one takes, or if some knowledgeable person might be willing to share some code. 

Here is a statement that describes the sort of analyis I'm being asked to do.

A one-sample parametric test assuming an exponential form of survival was used to test the hypothesis that the treatment produces a median PFS no greater than the historical control PFS of 16 weeks.  A sample median PFS greater than 20.57 weeks would fall beyond the critical value associated with the null hypothesis, and would be considered statistically significant at alpha = .05, 1 tailed.  

My understanding is that the cutoff of 20.57 weeks was obtained using an online calculator that can be found at:

http://www.swogstat.org/stat/public/one_survival.htm

Thus far, I've been unable to determine what values were plugged into the calculator to get the cutoff.

There's another calculator for a nonparamertric test that can be found at:

http://www.swogstat.org/stat/public/one_nonparametric_survival.htm

It would be nice to try doing this using both a parameteric and a non-parametric model.

So my first question would be whether the approach outlined above is valid or if the analysis should be done some other way. If the basic idea is correct, is it relatively easy (for a Terry Therneau type genius) to implement the whole thing using R? The calculator is a great tool, but, if reasonable, it would be nice to be able to look at some code to see how the numbers actually get produced.

Below are some sample survival data and code in case this proves helpful.

Thanks,

Paul

###################################
#### Example Data: GD2 Vaccine ####
###################################

connection <- textConnection("
GD2  1   8 12  GD2  3 -12 10  GD2  6 -52  7
GD2  7  28 10  GD2  8  44  6  GD2 10  14  8
GD2 12   3  8  GD2 14 -52  9  GD2 15  35 11
GD2 18   6 13  GD2 20  12  7  GD2 23  -7 13
GD2 24 -52  9  GD2 26 -52 12  GD2 28  36 13
GD2 31 -52  8  GD2 33   9 10  GD2 34 -11 16
GD2 36 -52  6  GD2 39  15 14  GD2 40  13 13
GD2 42  21 13  GD2 44 -24 16  GD2 46 -52 13
GD2 48  28  9  GD2  2  15  9  GD2  4 -44 10
GD2  5  -2 12  GD2  9   8  7  GD2 11  12  7
GD2 13 -52  7  GD2 16  21  7  GD2 17  19 11
GD2 19   6 16  GD2 21  10 16  GD2 22 -15  6
GD2 25   4 15  GD2 27  -9  9  GD2 29  27 10
GD2 30   1 17  GD2 32  12  8  GD2 35  20  8
GD2 37 -32  8  GD2 38  15  8  GD2 41   5 14
GD2 43  35 13  GD2 45  28  9  GD2 47   6 15
")

hsv <- data.frame(scan(connection, list(VAC="", PAT=0, WKS=0, X=0)))
hsv <- transform(hsv, CENS=ifelse(WKS < 1, 1, 0), WKS=abs(WKS))
head(hsv)

require("survival")

survObj <- Surv(hsv$WKS, hsv$CENS==0) ~ 1

km <- survfit(survObj, type=c("kaplan-meier"))
print(km)

paraExp <- survreg(survObj, dist="exponential")
print(paraExp)


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From alfios17 at hotmail.com  Wed Jul  9 18:37:35 2014
From: alfios17 at hotmail.com (Lorenzo Alfieri)
Date: Wed, 9 Jul 2014 18:37:35 +0200
Subject: [R] reorder a list
In-Reply-To: <CAF8bMcYvipQQ8_ObzFBLm83T9L1DBWbiXi9m625_c148k9j6MA@mail.gmail.com>
References: <DUB115-W73FA64A7B692E6A65E24D6D70C0@phx.gbl>
	<CAF8bMcZ1iFZhtq4RzgTCBoLjhYnApV4y8SGaOjJ9Kxv+zr+1iw@mail.gmail.com>,
	<DUB115-W129203369B27F7C705ED89ED70F0@phx.gbl>,
	<CAF8bMcYvipQQ8_ObzFBLm83T9L1DBWbiXi9m625_c148k9j6MA@mail.gmail.com>
Message-ID: <DUB115-W8167C508C6768A278B7CA0D70F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/ad3b2d07/attachment.pl>

From tonightsthenight at gmail.com  Wed Jul  9 19:19:42 2014
From: tonightsthenight at gmail.com (Sam Albers)
Date: Wed, 9 Jul 2014 10:19:42 -0700
Subject: [R] < symbols in a data frame
Message-ID: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/b02a5e21/attachment.pl>

From sarah.goslee at gmail.com  Wed Jul  9 19:26:54 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Jul 2014 13:26:54 -0400
Subject: [R] < symbols in a data frame
In-Reply-To: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
Message-ID: <CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>

Hi Sam,

I'd take the similar tack of removing the < instead. Note that if you
import the data frame using the stringsAsFactors=FALSE argument, you
don't need the first step.

metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)

R> str(metals)
'data.frame':    19 obs. of  2 variables:
 $ Parameter  : Factor w/ 20 levels "Antimony","Arsenic",..: 1 2 3 4 6
7 8 9 10 11 ...
 $ Cedar.Creek: num  100 100 500 100 10 1000 100 516 550 10 ...

Sarah


On Wed, Jul 9, 2014 at 1:19 PM, Sam Albers <tonightsthenight at gmail.com> wrote:
> Hello,
>
> I have recently received a dataset from a metal analysis company. The
> dataset is filled with less than symbols. What I am looking for is a
> efficient way to subset for any whole numbers from the dataset. The column
> is automatically formatted as a factor because of the "<" symbols making it
> difficult to deal with the numbers is a useful way.
>
> So in sum any ideas on how I could subset the example below for only whole
> numbers?
>
> Thanks in advance!
>
> Sam
>
> #code
>
> metals <-
>
>
> structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
> 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
> = c("Antimony",
> "Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
> "Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
> "Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
> "Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek = structure(c(3L,
> 3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
> 4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
> "<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
> "1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
> "22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
> "516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
> "77", "89", "951"), class = "factor")), .Names = c("Parameter",
> "Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Wed Jul  9 19:29:42 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 09 Jul 2014 12:29:42 -0500
Subject: [R] < symbols in a data frame
In-Reply-To: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
Message-ID: <7A2206CB-C755-4154-8086-52EED7BFAF1E@me.com>

On Jul 9, 2014, at 12:19 PM, Sam Albers <tonightsthenight at gmail.com> wrote:

> Hello,
> 
> I have recently received a dataset from a metal analysis company. The
> dataset is filled with less than symbols. What I am looking for is a
> efficient way to subset for any whole numbers from the dataset. The column
> is automatically formatted as a factor because of the "<" symbols making it
> difficult to deal with the numbers is a useful way.
> 
> So in sum any ideas on how I could subset the example below for only whole
> numbers?
> 
> Thanks in advance!
> 
> Sam
> 
> #code
> 
> metals <-
> 
> 
> structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
> 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
> = c("Antimony",
> "Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
> "Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
> "Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
> "Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek = structure(c(3L,
> 3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
> 4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
> "<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
> "1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
> "22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
> "516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
> "77", "89", "951"), class = "factor")), .Names = c("Parameter",
> "Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")


Sam,

You can use ?gsub to remove the '<' characters from the column and then use ?subset to select the records you wish.

Note that gsub() returns a character vector, so you want to coerce to numeric.

> as.numeric(gsub("<", "", metals$Cedar.Creek))
 [1]  100  100  500  100   10 1000  100  516  550   10  200  500  100
[14]  500  100  951 1000 1000  100


For example:

> subset(metals, as.numeric(gsub("<", "", Cedar.Creek)) == 100)
   Parameter Cedar.Creek
1   Antimony        <100
2    Arsenic        <100
4  Beryllium        <100
7     Cobalt        <100
13  Selenium        <100
15  Thallium        <100
19  Antimony        <100


> subset(metals, as.numeric(gsub("<", "", Cedar.Creek)) <= 500)
    Parameter Cedar.Creek
1    Antimony        <100
2     Arsenic        <100
3      Barium        <500
4   Beryllium        <100
5     Cadmium         <10
7      Cobalt        <100
10    Mercury         <10
11 Molybdenum        <200
12     Nickel        <500
13   Selenium        <100
14     Silver        <500
15   Thallium        <100
19   Antimony        <100


You can also just create a new column that is numeric and go from there:

metals$CC.Num <- as.numeric(gsub("<", "", metals$Cedar.Creek))

> str(metals)
'data.frame':	19 obs. of  3 variables:
 $ Parameter  : Factor w/ 20 levels "Antimony","Arsenic",..: 1 2 3 4 6 7 8 9 10 11 ...
 $ Cedar.Creek: Factor w/ 45 levels "<1","<10","<100",..: 3 3 7 3 2 4 3 34 36 2 ...
 $ CC.Num     : num  100 100 500 100 10 1000 100 516 550 10 ...


> metals
    Parameter Cedar.Creek CC.Num
1    Antimony        <100    100
2     Arsenic        <100    100
3      Barium        <500    500
4   Beryllium        <100    100
5     Cadmium         <10     10
6    Chromium       <1000   1000
7      Cobalt        <100    100
8      Copper         516    516
9        Lead         550    550
10    Mercury         <10     10
11 Molybdenum        <200    200
12     Nickel        <500    500
13   Selenium        <100    100
14     Silver        <500    500
15   Thallium        <100    100
16        Tin         951    951
17   Vanadium       <1000   1000
18       Zinc       <1000   1000
19   Antimony        <100    100



Regards,

Marc Schwartz


From gunter.berton at gene.com  Wed Jul  9 19:41:07 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 9 Jul 2014 10:41:07 -0700
Subject: [R] < symbols in a data frame
In-Reply-To: <CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
	<CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>
Message-ID: <CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>

Well, ?grep and ?regex are clearly apropos here -- dealing with
character data is an essential skill for handling input from diverse
sources with various formatting conventions. I suggest you go through
one of the many regular expression tutorials on the web to learn more.

But this may not be the important issue here at all. If "<k" means the
value is left censored at k -- i.e. we know it's less than k but not
how much less -- than Sarah's proposal is not what you want to do.
Exactly what you do want to do depends on context, and as it concerns
statistical methodology, is not something that should be discussed
here. Consult a local statistician if this is a correct guess.
Otherwise ignore.

... and please post in plain text in future (as requested) as HTML can
get garbled.

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Jul 9, 2014 at 10:26 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi Sam,
>
> I'd take the similar tack of removing the < instead. Note that if you
> import the data frame using the stringsAsFactors=FALSE argument, you
> don't need the first step.
>
> metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
> metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
> metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)
>
> R> str(metals)
> 'data.frame':    19 obs. of  2 variables:
>  $ Parameter  : Factor w/ 20 levels "Antimony","Arsenic",..: 1 2 3 4 6
> 7 8 9 10 11 ...
>  $ Cedar.Creek: num  100 100 500 100 10 1000 100 516 550 10 ...
>
> Sarah
>
>
> On Wed, Jul 9, 2014 at 1:19 PM, Sam Albers <tonightsthenight at gmail.com> wrote:
>> Hello,
>>
>> I have recently received a dataset from a metal analysis company. The
>> dataset is filled with less than symbols. What I am looking for is a
>> efficient way to subset for any whole numbers from the dataset. The column
>> is automatically formatted as a factor because of the "<" symbols making it
>> difficult to deal with the numbers is a useful way.
>>
>> So in sum any ideas on how I could subset the example below for only whole
>> numbers?
>>
>> Thanks in advance!
>>
>> Sam
>>
>> #code
>>
>> metals <-
>>
>>
>> structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
>> 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
>> = c("Antimony",
>> "Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
>> "Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
>> "Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
>> "Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek = structure(c(3L,
>> 3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
>> 4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
>> "<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
>> "1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
>> "22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
>> "516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
>> "77", "89", "951"), class = "factor")), .Names = c("Parameter",
>> "Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aguitatierra at hotmail.com  Wed Jul  9 19:47:46 2014
From: aguitatierra at hotmail.com (Beatriz)
Date: Wed, 9 Jul 2014 19:47:46 +0200
Subject: [R] How to include factor levels into plot title?
In-Reply-To: <CAM_vjum7Fp3CZE-bvNP5T4vGoU5EnhvuNe8sKk_pu3Q=OwHKiA@mail.gmail.com>
References: <BLU436-SMTP1632B86CBDFDD90ED35541D90F0@phx.gbl>
	<CAM_vjum7Fp3CZE-bvNP5T4vGoU5EnhvuNe8sKk_pu3Q=OwHKiA@mail.gmail.com>
Message-ID: <BLU436-SMTP171A4636C9FDEE6A9472D46D90F0@phx.gbl>

@ Sarah
Thanks a lot, paste does the job perfectly!


On 09/07/2014 17:46, Sarah Goslee wrote:
> How about:
>
>
> plot(dd$Sepal.Length, dd$Petal.Length, main=paste("These are the
> levels:", paste(levels(dd$Species), collapse=", ")))
>
>
> Thanks for the actual reproducible example!
>
> Sarah
>
> On Wed, Jul 9, 2014 at 11:24 AM, Bea GD <aguitatierra at hotmail.com> wrote:
>> Hi all,
>>
>> I'd like to include the levels of one of my variables in the title of a
>> plot. I'd like these factor levels to be concatenated. E.g. 'These are the
>> levels: setosa, versicolor, virginica'.
>>
>> I've been working with this code but I don't get the desired results. Any
>> suggestions would be a great help. Thanks!
>>
>> dd <- iris
>>
>> plot(dd$Sepal.Length, dd$Petal.Length,
>>       main=sprintf("These are the levels: %s", levels(dd$Species)))
>>


From tonightsthenight at gmail.com  Wed Jul  9 20:02:59 2014
From: tonightsthenight at gmail.com (Sam Albers)
Date: Wed, 9 Jul 2014 11:02:59 -0700
Subject: [R] < symbols in a data frame
In-Reply-To: <CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
	<CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>
	<CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>
Message-ID: <CADkXsV2dLgvgsDnKoswSyp=W6EWZZo8v=Wxzwsd2ai=J6K_pZg@mail.gmail.com>

Thanks for all the responses. It sometimes difficult to outline
exactly what you need. These response were helpful to get there.
Speaking to Bert's point a bit, I needed a column to identify where
the < symbol was used. If I knew more about R I think I might be
embarrassed to post my solution to that problem but here is how I used
Sarah's solution but still kept the info about detection limits. I'm
sure there is a more elegant way:

metals <-
structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
= c("Antimony",
"Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
"Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
"Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
"Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek = structure(c(3L,
3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
"<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
"1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
"22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
"516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
"77", "89", "951"), class = "factor")), .Names = c("Parameter",
"Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")



metals$temp1<-metals$Cedar.Creek
metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)

metals$temp2<-metals$temp1==metals$Cedar.Creek
metals$Detection<-factor(ifelse(metals$temp2=="TRUE","Measured","Limit"))
metals[,c(1,2,5)]


Thanks again!

Sam

On Wed, Jul 9, 2014 at 10:41 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Well, ?grep and ?regex are clearly apropos here -- dealing with
> character data is an essential skill for handling input from diverse
> sources with various formatting conventions. I suggest you go through
> one of the many regular expression tutorials on the web to learn more.
>
> But this may not be the important issue here at all. If "<k" means the
> value is left censored at k -- i.e. we know it's less than k but not
> how much less -- than Sarah's proposal is not what you want to do.
> Exactly what you do want to do depends on context, and as it concerns
> statistical methodology, is not something that should be discussed
> here. Consult a local statistician if this is a correct guess.
> Otherwise ignore.
>
> ... and please post in plain text in future (as requested) as HTML can
> get garbled.
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Wed, Jul 9, 2014 at 10:26 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> Hi Sam,
>>
>> I'd take the similar tack of removing the < instead. Note that if you
>> import the data frame using the stringsAsFactors=FALSE argument, you
>> don't need the first step.
>>
>> metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
>> metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
>> metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)
>>
>> R> str(metals)
>> 'data.frame':    19 obs. of  2 variables:
>>  $ Parameter  : Factor w/ 20 levels "Antimony","Arsenic",..: 1 2 3 4 6
>> 7 8 9 10 11 ...
>>  $ Cedar.Creek: num  100 100 500 100 10 1000 100 516 550 10 ...
>>
>> Sarah
>>
>>
>> On Wed, Jul 9, 2014 at 1:19 PM, Sam Albers <tonightsthenight at gmail.com> wrote:
>>> Hello,
>>>
>>> I have recently received a dataset from a metal analysis company. The
>>> dataset is filled with less than symbols. What I am looking for is a
>>> efficient way to subset for any whole numbers from the dataset. The column
>>> is automatically formatted as a factor because of the "<" symbols making it
>>> difficult to deal with the numbers is a useful way.
>>>
>>> So in sum any ideas on how I could subset the example below for only whole
>>> numbers?
>>>
>>> Thanks in advance!
>>>
>>> Sam
>>>
>>> #code
>>>
>>> metals <-
>>>
>>>
>>> structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
>>> 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
>>> = c("Antimony",
>>> "Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
>>> "Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
>>> "Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
>>> "Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek = structure(c(3L,
>>> 3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
>>> 4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
>>> "<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
>>> "1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
>>> "22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
>>> "516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
>>> "77", "89", "951"), class = "factor")), .Names = c("Parameter",
>>> "Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From _ at thomaslevine.com  Wed Jul  9 20:11:13 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Wed, 9 Jul 2014 18:11:13 +0000
Subject: [R] HPGL or PCL plotting device? Or otherwise plotting plots
In-Reply-To: <20140709133244.GA32313@d1stkfactory>
References: <20140709131014.GB32129@d1stkfactory>
	<20140709133244.GA32313@d1stkfactory>
Message-ID: <20140709181113.GA944@d1stkfactory>

Actually, this doesn't _quite_ do what I want;
I want different R colors (1, 2, 3, &c.) to select
different pens in HPGL ("SP1", "SP2", "SP3", &c.),
but the HPGL file I get selects only pen 1.

A hacky way to do this would be to generate
a few different postscript files for the different
colors on the plot, create the corresponding HPGL
files, edit the SP command in each of them, and
concatenate them. But maybe there's a better way?

On 09 Jul 13:32, Thomas Levine wrote:
> Oh it was easier than I thought.
> 
>   postscript('project-contracts.ps')
>   hist(log(projects$n.contracts))
>   dev.off()
> 
> Then run this from the shell.
> 
>   pstoedit -f plot-hpgl project-contracts.ps project-contracts.hpgl
> 
> And send it to the plotter.
> 
> On 09 Jul 13:10, Thomas Levine wrote:
> > Hi,
> > 
> > I want to print plots on a Roland DXY-1100 plotter.
> > How can I do this from R? I think the easiest thing
> > would be a graphics device for Printer Command
> > Language or Hewlett-Packard Graphics Language, but
> > I haven't managed to find any of those.
> > 
> > Thanks
> > 
> > Tom


From juditycarmona at gmail.com  Wed Jul  9 18:36:35 2014
From: juditycarmona at gmail.com (Maria Judith Carmona H)
Date: Wed, 9 Jul 2014 11:36:35 -0500
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
Message-ID: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/ac6654de/attachment.pl>

From Michael.Folkes at dfo-mpo.gc.ca  Wed Jul  9 21:58:23 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 9 Jul 2014 12:58:23 -0700
Subject: [R] using match to obtain non-sorted index values from non-sorted
	vector
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/25963329/attachment.pl>

From dcarlson at tamu.edu  Wed Jul  9 22:10:53 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 9 Jul 2014 20:10:53 +0000
Subject: [R] using match to obtain non-sorted index values from
	non-sorted	vector
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F85C84@mb02.ads.tamu.edu>

There may be a faster way, but 

> sapply(Tset, function(x) which(pop.df$pop==x))
[1] 5 4 2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Folkes, Michael
Sent: Wednesday, July 9, 2014 2:58 PM
To: r-help at r-project.org
Subject: [R] using match to obtain non-sorted index values from non-sorted vector

Hello all,

I've been struggling with the best way to find index values from a large
vector with elements that will match elements of a subset vector [the
table argument in match()]. 

BUT the index values can't come out sorted (as we'd get in  which(X %in%
Y) ).

My 'population' vector can't be sorted. 

pop.df <- data.frame(pop=c(1,6,4,3,10)) 

The subset:  Tset = c(10,3,6)



So I'd like to get these index values (from pop.df) , in this order:
5,4,2



If it could be sorted I could use:

which(sort(pop.df$pop) %in% sort(Tset))



But sorting will cause more grief later, so best not mess with it.

Here is my hopefully adequate MWE of a solution. I'm keen to see if
anybody has a better suggestion. 

Thanks!

_____________________

###BEGIN R

#pop is the full set of values, it has no info on their ranking

# I don't want to sort these data. They need to remain in this order.

pop.df <- data.frame(pop=c(1,6,4,3,10))



#rank.df is my dataframe that tells me the top three rankings (derived
elsewhere)

rank.df <- data.frame(rank=1:3, Tset = c(10,3,6))   # Target set



#match.df will be my source of row index based on rank

match.df <- data.frame(match.vec= match(pop.df$pop, table=rank.df$Tset),
index.vec=1:nrow(pop.df))



#rank.df will now include the index location in the pop.df where I can
find the top three ranks.

rank.df  <- merge(rank.df, match.df, by.x='rank', by.y='match.vec')

rank.df



####END



_______________________________________________________

Michael Folkes

Salmon Stock Assessment

Canadian Dept. of Fisheries & Oceans     

Pacific Biological Station

3190 Hammond Bay Rd.

Nanaimo, B.C., Canada

V9T-6N7

Ph (250) 756-7264 Fax (250) 756-7053  Michael.Folkes at dfo-mpo.gc.ca
<mailto:Michael.Folkes at dfo-mpo.gc.ca> 




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Michael.Folkes at dfo-mpo.gc.ca  Wed Jul  9 22:13:20 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 9 Jul 2014 13:13:20 -0700
Subject: [R] using match to obtain non-sorted index values from
	non-sortedvector
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F85C84@mb02.ads.tamu.edu>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F85C84@mb02.ads.tamu.edu>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00F58293C@pacpbsex01.pac.dfo-mpo.ca>

So nice! 
Apply wins again.
Thanks David.
Michael

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: July-09-14 1:11 PM
To: Folkes, Michael; r-help at r-project.org
Subject: RE: using match to obtain non-sorted index values from
non-sortedvector

There may be a faster way, but 

> sapply(Tset, function(x) which(pop.df$pop==x))
[1] 5 4 2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Folkes, Michael
Sent: Wednesday, July 9, 2014 2:58 PM
To: r-help at r-project.org
Subject: [R] using match to obtain non-sorted index values from
non-sorted vector

Hello all,

I've been struggling with the best way to find index values from a large
vector with elements that will match elements of a subset vector [the
table argument in match()]. 

BUT the index values can't come out sorted (as we'd get in  which(X %in%
Y) ).

My 'population' vector can't be sorted. 

pop.df <- data.frame(pop=c(1,6,4,3,10)) 

The subset:  Tset = c(10,3,6)



So I'd like to get these index values (from pop.df) , in this order:
5,4,2



If it could be sorted I could use:

which(sort(pop.df$pop) %in% sort(Tset))



But sorting will cause more grief later, so best not mess with it.

Here is my hopefully adequate MWE of a solution. I'm keen to see if
anybody has a better suggestion. 

Thanks!

_____________________

###BEGIN R

#pop is the full set of values, it has no info on their ranking

# I don't want to sort these data. They need to remain in this order.

pop.df <- data.frame(pop=c(1,6,4,3,10))



#rank.df is my dataframe that tells me the top three rankings (derived
elsewhere)

rank.df <- data.frame(rank=1:3, Tset = c(10,3,6))   # Target set



#match.df will be my source of row index based on rank

match.df <- data.frame(match.vec= match(pop.df$pop, table=rank.df$Tset),
index.vec=1:nrow(pop.df))



#rank.df will now include the index location in the pop.df where I can
find the top three ranks.

rank.df  <- merge(rank.df, match.df, by.x='rank', by.y='match.vec')

rank.df



####END



_______________________________________________________

Michael Folkes

Salmon Stock Assessment

Canadian Dept. of Fisheries & Oceans     

Pacific Biological Station

3190 Hammond Bay Rd.

Nanaimo, B.C., Canada

V9T-6N7

Ph (250) 756-7264 Fax (250) 756-7053  Michael.Folkes at dfo-mpo.gc.ca
<mailto:Michael.Folkes at dfo-mpo.gc.ca> 




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From claudia.beleites at ipht-jena.de  Wed Jul  9 22:49:58 2014
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Wed, 9 Jul 2014 22:49:58 +0200
Subject: [R] < symbols in a data frame
In-Reply-To: <CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
	<CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>
	<CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>
Message-ID: <20140709224958.2c7ea1e7@cbdesktop>

Hi Sam,

> But this may not be the important issue here at all. If "<k" means the
> value is left censored at k -- i.e. we know it's less than k but not
> how much less -- than Sarah's proposal is not what you want to do.
> Exactly what you do want to do depends on context, and as it concerns
> statistical methodology, is not something that should be discussed
> here. Consult a local statistician if this is a correct guess.
I'd like to chime in with Bert's advise here. Unless the < LOQs are
very few*, they have the potential to seriously mess up any further data
analysis. 

Actually, I'd recommend you go one step back and ask the analysis lab
whether they can supply you with the uncensored data, specifying the
LOQ separately. 

A while ago I posted some illustrations about such censoring
at LOQ situations on cross validated, which may help you in forming a
decision how to go on:
http://stats.stackexchange.com/a/30739/4598

Claudia (Analytical Chemist & Chemometrician)


*or you know that they'll not matter for the particular data analysis
you want to do




-- 
Claudia Beleites, Chemist
Spectroscopy/Imaging
Leibniz Institute of Photonic Technology 
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From dwinsemius at comcast.net  Wed Jul  9 23:01:29 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Jul 2014 14:01:29 -0700
Subject: [R] using match to obtain non-sorted index values from
	non-sortedvector
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB00F58293C@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F85C84@mb02.ads.tamu.edu>
	<63F107BCC37AEA49A75FD94AA3E07CB00F58293C@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <26B13FB4-0CB6-484F-B45A-16DA1720D45E@comcast.net>


On Jul 9, 2014, at 1:13 PM, Folkes, Michael wrote:

> So nice! 
> Apply wins again.

I doubt that `sapply( ..., which(,) )` would win a foot race with `match`:

> match(Tset, pop.df$pop)
[1] 5 4 2

-- 
David.
> Thanks David.
> Michael
> 
> -----Original Message-----
> From: David L Carlson [mailto:dcarlson at tamu.edu] 
> Sent: July-09-14 1:11 PM
> To: Folkes, Michael; r-help at r-project.org
> Subject: RE: using match to obtain non-sorted index values from
> non-sortedvector
> 
> There may be a faster way, but 
> 
>> sapply(Tset, function(x) which(pop.df$pop==x))
> [1] 5 4 2
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Folkes, Michael
> Sent: Wednesday, July 9, 2014 2:58 PM
> To: r-help at r-project.org
> Subject: [R] using match to obtain non-sorted index values from
> non-sorted vector
> 
> Hello all,
> 
> I've been struggling with the best way to find index values from a large
> vector with elements that will match elements of a subset vector [the
> table argument in match()]. 
> 
> BUT the index values can't come out sorted (as we'd get in  which(X %in%
> Y) ).
> 
> My 'population' vector can't be sorted. 
> 
> pop.df <- data.frame(pop=c(1,6,4,3,10)) 
> 
> The subset:  Tset = c(10,3,6)
> 
> 
> 
> So I'd like to get these index values (from pop.df) , in this order:
> 5,4,2
> 
> 
> 
> If it could be sorted I could use:
> 
> which(sort(pop.df$pop) %in% sort(Tset))
> 
> 
> 
> But sorting will cause more grief later, so best not mess with it.
> 
> Here is my hopefully adequate MWE of a solution. I'm keen to see if
> anybody has a better suggestion. 
> 
> Thanks!
> 
> _____________________
> 
> ###BEGIN R
> 
> #pop is the full set of values, it has no info on their ranking
> 
> # I don't want to sort these data. They need to remain in this order.
> 
> pop.df <- data.frame(pop=c(1,6,4,3,10))
> 
> 
> 
> #rank.df is my dataframe that tells me the top three rankings (derived
> elsewhere)
> 
> rank.df <- data.frame(rank=1:3, Tset = c(10,3,6))   # Target set
> 
> 
> 
> #match.df will be my source of row index based on rank
> 
> match.df <- data.frame(match.vec= match(pop.df$pop, table=rank.df$Tset),
> index.vec=1:nrow(pop.df))
> 
> 
> #rank.df will now include the index location in the pop.df where I can
> find the top three ranks.
> 
> rank.df  <- merge(rank.df, match.df, by.x='rank', by.y='match.vec')
> 
> rank.df
> 
> 
> ####END
> 
> 
> 
> _______________________________________________________
> 
> Michael Folkes
> 
> Salmon Stock Assessment
> 


David Winsemius
Alameda, CA, USA


From Michael.Folkes at dfo-mpo.gc.ca  Thu Jul 10 00:04:14 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 9 Jul 2014 15:04:14 -0700
Subject: [R] using match to obtain non-sorted index values from
	non-sortedvector
In-Reply-To: <26B13FB4-0CB6-484F-B45A-16DA1720D45E@comcast.net>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F58291A@pacpbsex01.pac.dfo-mpo.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F85C84@mb02.ads.tamu.edu>
	<63F107BCC37AEA49A75FD94AA3E07CB00F58293C@pacpbsex01.pac.dfo-mpo.ca>
	<26B13FB4-0CB6-484F-B45A-16DA1720D45E@comcast.net>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00F5D5832@pacpbsex01.pac.dfo-mpo.ca>

Oh dear,
I seem to have suffered a case of reversed arguments. 
This explains my surprise why R didn't have this in a function already -
as it does!
I was following the pattern of  search.vector %in% pattern, but match()
arguments are opposite this.

Thanks to both Davids.
Michael

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: July-09-14 2:01 PM
To: Folkes, Michael
Cc: David L Carlson; r-help at r-project.org
Subject: Re: [R] using match to obtain non-sorted index values from
non-sortedvector


On Jul 9, 2014, at 1:13 PM, Folkes, Michael wrote:

> So nice! 
> Apply wins again.

I doubt that `sapply( ..., which(,) )` would win a foot race with
`match`:

> match(Tset, pop.df$pop)
[1] 5 4 2

--
David.
> Thanks David.
> Michael
> 
> -----Original Message-----
> From: David L Carlson [mailto:dcarlson at tamu.edu]
> Sent: July-09-14 1:11 PM
> To: Folkes, Michael; r-help at r-project.org
> Subject: RE: using match to obtain non-sorted index values from 
> non-sortedvector
> 
> There may be a faster way, but
> 
>> sapply(Tset, function(x) which(pop.df$pop==x))
> [1] 5 4 2
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org]
> On Behalf Of Folkes, Michael
> Sent: Wednesday, July 9, 2014 2:58 PM
> To: r-help at r-project.org
> Subject: [R] using match to obtain non-sorted index values from 
> non-sorted vector
> 
> Hello all,
> 
> I've been struggling with the best way to find index values from a 
> large vector with elements that will match elements of a subset vector

> [the table argument in match()].
> 
> BUT the index values can't come out sorted (as we'd get in  which(X 
> %in%
> Y) ).
> 
> My 'population' vector can't be sorted. 
> 
> pop.df <- data.frame(pop=c(1,6,4,3,10))
> 
> The subset:  Tset = c(10,3,6)
> 
> 
> 
> So I'd like to get these index values (from pop.df) , in this order:
> 5,4,2
> 
> 
> 
> If it could be sorted I could use:
> 
> which(sort(pop.df$pop) %in% sort(Tset))
> 
> 
> 
> But sorting will cause more grief later, so best not mess with it.
> 
> Here is my hopefully adequate MWE of a solution. I'm keen to see if 
> anybody has a better suggestion.
> 
> Thanks!
> 
> _____________________
> 
> ###BEGIN R
> 
> #pop is the full set of values, it has no info on their ranking
> 
> # I don't want to sort these data. They need to remain in this order.
> 
> pop.df <- data.frame(pop=c(1,6,4,3,10))
> 
> 
> 
> #rank.df is my dataframe that tells me the top three rankings (derived
> elsewhere)
> 
> rank.df <- data.frame(rank=1:3, Tset = c(10,3,6))   # Target set
> 
> 
> 
> #match.df will be my source of row index based on rank
> 
> match.df <- data.frame(match.vec= match(pop.df$pop, 
> table=rank.df$Tset),
> index.vec=1:nrow(pop.df))
> 
> 
> #rank.df will now include the index location in the pop.df where I can

> find the top three ranks.
> 
> rank.df  <- merge(rank.df, match.df, by.x='rank', by.y='match.vec')
> 
> rank.df
> 
> 
> ####END
> 
> 
> 
> _______________________________________________________
> 
> Michael Folkes
> 
> Salmon Stock Assessment
> 


David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Jul 10 00:13:05 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 10 Jul 2014 10:13:05 +1200
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
In-Reply-To: <4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>
References: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
	<CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>
	<4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>
Message-ID: <53BDBE71.8050701@auckland.ac.nz>


On 10/07/14 04:24, Jeff Newmiller wrote:

> Grumpy today, Bert?

<SNIP>

Bert is ***always*** grumpy! :-)  If he weren't, I'd get worried.

But then someone else, not more than a million miles from this email, 
has a strong tendency to be grumpy (acerbic?) as well.

Of course ***I*** am ***never*** grumpy! :-)

cheers,

Rolf


From jfox at mcmaster.ca  Thu Jul 10 00:30:34 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Jul 2014 18:30:34 -0400
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
Message-ID: <web-518038008@cgpsrv2.cis.mcmaster.ca>

Dear Maria Judith Carmona Higuita,

Since you didn't include enough information (such as your access to your data) to reproduce the error, one can only guess. My guess: you have fewer observations in your data set than response variables on the LHS of the multivariate linear model.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

On Wed, 9 Jul 2014 11:36:35 -0500
 Maria Judith Carmona H <juditycarmona at gmail.com> wrote:
> Hi,
> 
> I have a problem using the function Candisc from Candisc Package.
> 
> bosques1<-read.csv("bosques1.csv",header=TRUE,encoding="latin1")
> bosques1<-na.exclude(bosques1)
> attach(bosques1)
> 
> #Modelo de regresi??n
> mod <-
> lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
>                 Acanthaceae, Apocinaceae, Araceae, Araliaceae, Arecaceae,
> Aspleniaceae, Begoniaceae,
>                 Blechnaceae, Bromeliaceae, Clusiaceae, Cyclanthaceae,
> Davalliaceae, Denstaedtiaceae,
>                 Dryopteridaceae, Ericaceae, Gesneriaceae, Hymenophyllaceae,
> indet., Lauraceae, Lomariopsidaceae, Lycopodiaceae, Melastomataceae,
> Moraceae, Myrsinaceae, Ophioglossaceae,
>                 Orchidaceae, Peperomia, Piperaceae, Poaceae, Polypodiaceae,
> Primulaceae, Pteridaceae,
>                 Pteridophyta.taxa, Rubiaceae, Vittariaceae) ~ sitio,
> data=bosques1)
> summary(mod)
> 
> #Gr??fico 1
> can <- candisc(mod, term="sitio",data=bosques1,ndim=1,eig=T)
> ### The error happens here, so I can not run the plot.
> plot(can,titles.1d = c("Puntuaci??n can??nica", "Estructura"))
> summary(can, means = FALSE, scores = TRUE, coef = c("std"), digits = 2)
> 
> The error is:
> Error in eigen(eHe, symmetric = TRUE) : infinite or missing values in 'x'
> In addition: Warning message:
> In sqrt(wmd) : NaNs produced
> 
> Please help!
> 
> -- 
> Maria Judith Carmona Higuita.
> Estudiante de Biolog??a - Universidad de Antioquia
> Medell??n - Colombia
> 
> "La felicidad ocurre cuando encajas en tu vida, cuando encajas
> tan arm??nicamente que cualquier cosa que hagas es una alegr??a para ti. De
> repente lo sabr??s y la meditaci??n te seguir??. Si amas el trabajo que haces,
> si amas la manera como vives, entonces ya est??s meditando y nada puede
> distraerte." Osho
> 
> 	[[alternative HTML version deleted]]
>


From macqueen1 at llnl.gov  Thu Jul 10 01:17:56 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 9 Jul 2014 23:17:56 +0000
Subject: [R] < symbols in a data frame
In-Reply-To: <CADkXsV2dLgvgsDnKoswSyp=W6EWZZo8v=Wxzwsd2ai=J6K_pZg@mail.gmail.com>
References: <CADkXsV3xqMbrH7NjaOKSe5FP41STjCrm_hYbw7npzk8zibHoTw@mail.gmail.com>
	<CAM_vjunN7yiOJ8rq8+a7mRAGuSdAH1n4G80DX3edvBai6u_4XA@mail.gmail.com>
	<CACk-te1iSEaRHuGmP1WGyzP9iiKE3cEfCsycd9y_bzjaHaR5ZA@mail.gmail.com>
	<CADkXsV2dLgvgsDnKoswSyp=W6EWZZo8v=Wxzwsd2ai=J6K_pZg@mail.gmail.com>
Message-ID: <CFE31AF1.101C5E%macqueen1@llnl.gov>

After reading the metals data frame, I would do this:

metals$result <- as.numeric(gsub('<','',metals$Cedar.Creek))
metals$flag <- ifelse(grepl('<',metals$Cedar.Creek),'<','h')

Also, assuming you got your data into R using read.table(),
read.csv(), or similar, I would include
   stringsAsFactors=TRUE

as another argument to the function call. You don't need factors at this
point.

-Don
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/9/14 11:02 AM, "Sam Albers" <tonightsthenight at gmail.com> wrote:

>Thanks for all the responses. It sometimes difficult to outline
>exactly what you need. These response were helpful to get there.
>Speaking to Bert's point a bit, I needed a column to identify where
>the < symbol was used. If I knew more about R I think I might be
>embarrassed to post my solution to that problem but here is how I used
>Sarah's solution but still kept the info about detection limits. I'm
>sure there is a more elegant way:
>
>metals <-
>structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
>8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
>= c("Antimony",
>"Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
>"Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
>"Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
>"Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek =
>structure(c(3L,
>3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
>4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
>"<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
>"1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
>"22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
>"516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
>"77", "89", "951"), class = "factor")), .Names = c("Parameter",
>"Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")
>
>
>
>metals$temp1<-metals$Cedar.Creek
>metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
>metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
>metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)
>
>metals$temp2<-metals$temp1==metals$Cedar.Creek
>metals$Detection<-factor(ifelse(metals$temp2=="TRUE","Measured","Limit"))
>metals[,c(1,2,5)]
>
>
>Thanks again!
>
>Sam
>
>On Wed, Jul 9, 2014 at 10:41 AM, Bert Gunter <gunter.berton at gene.com>
>wrote:
>> Well, ?grep and ?regex are clearly apropos here -- dealing with
>> character data is an essential skill for handling input from diverse
>> sources with various formatting conventions. I suggest you go through
>> one of the many regular expression tutorials on the web to learn more.
>>
>> But this may not be the important issue here at all. If "<k" means the
>> value is left censored at k -- i.e. we know it's less than k but not
>> how much less -- than Sarah's proposal is not what you want to do.
>> Exactly what you do want to do depends on context, and as it concerns
>> statistical methodology, is not something that should be discussed
>> here. Consult a local statistician if this is a correct guess.
>> Otherwise ignore.
>>
>> ... and please post in plain text in future (as requested) as HTML can
>> get garbled.
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Wed, Jul 9, 2014 at 10:26 AM, Sarah Goslee <sarah.goslee at gmail.com>
>>wrote:
>>> Hi Sam,
>>>
>>> I'd take the similar tack of removing the < instead. Note that if you
>>> import the data frame using the stringsAsFactors=FALSE argument, you
>>> don't need the first step.
>>>
>>> metals$Cedar.Creek <- as.character(metals$Cedar.Creek)
>>> metals$Cedar.Creek <- gsub("<", "", metals$Cedar.Creek)
>>> metals$Cedar.Creek <- as.numeric(metals$Cedar.Creek)
>>>
>>> R> str(metals)
>>> 'data.frame':    19 obs. of  2 variables:
>>>  $ Parameter  : Factor w/ 20 levels "Antimony","Arsenic",..: 1 2 3 4 6
>>> 7 8 9 10 11 ...
>>>  $ Cedar.Creek: num  100 100 500 100 10 1000 100 516 550 10 ...
>>>
>>> Sarah
>>>
>>>
>>> On Wed, Jul 9, 2014 at 1:19 PM, Sam Albers
>>><tonightsthenight at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I have recently received a dataset from a metal analysis company. The
>>>> dataset is filled with less than symbols. What I am looking for is a
>>>> efficient way to subset for any whole numbers from the dataset. The
>>>>column
>>>> is automatically formatted as a factor because of the "<" symbols
>>>>making it
>>>> difficult to deal with the numbers is a useful way.
>>>>
>>>> So in sum any ideas on how I could subset the example below for only
>>>>whole
>>>> numbers?
>>>>
>>>> Thanks in advance!
>>>>
>>>> Sam
>>>>
>>>> #code
>>>>
>>>> metals <-
>>>>
>>>>
>>>> structure(list(Parameter = structure(c(1L, 2L, 3L, 4L, 6L, 7L,
>>>> 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 1L), .Label
>>>> = c("Antimony",
>>>> "Arsenic", "Barium", "Beryllium", "Boron (Hot Water Soluble)",
>>>> "Cadmium", "Chromium", "Cobalt", "Copper", "Lead", "Mercury",
>>>> "Molybdenum", "Nickel", "pH 1:2", "Selenium", "Silver", "Thallium",
>>>> "Tin", "Vanadium", "Zinc"), class = "factor"), Cedar.Creek =
>>>>structure(c(3L,
>>>> 3L, 7L, 3L, 2L, 4L, 3L, 34L, 36L, 2L, 5L, 7L, 3L, 7L, 3L, 45L,
>>>> 4L, 4L, 3L), .Label = c("<1", "<10", "<100", "<1000", "<200",
>>>> "<5", "<500", "0.1", "0.13", "0.5", "0.8", "1.07", "1.1", "1.4",
>>>> "1.5", "137", "154", "163", "165", "169", "178", "2.3", "2.4",
>>>> "22", "24", "244", "27.2", "274", "3", "3.1", "40.2", "43", "50",
>>>> "516", "53.3", "550", "569", "65", "66.1", "68", "7.6", "72",
>>>> "77", "89", "951"), class = "factor")), .Names = c("Parameter",
>>>> "Cedar.Creek"), row.names = c(NA, 19L), class = "data.frame")
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jsc.eco at gmail.com  Thu Jul 10 01:47:39 2014
From: jsc.eco at gmail.com (Janet Choate)
Date: Wed, 9 Jul 2014 16:47:39 -0700
Subject: [R] function completing properly
Message-ID: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/104c36e1/attachment.pl>

From pdalgd at gmail.com  Thu Jul 10 02:07:49 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Jul 2014 02:07:49 +0200
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
In-Reply-To: <4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>
References: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
	<CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>
	<4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>
Message-ID: <66EDAA5B-0B6F-46F7-A429-FE170FCF7233@gmail.com>

Grumpy today, Jeff?

For the concrete issue, I'd conjecture that the base problem is that there are way too many columns in the data and that the nature of the method is not properly understood. It is not obvious that k-means clustering based on Euclidean distance makes sense in 1426-dimensional space. It is quite possible that the data set not even consists of columns measured in the same units. Even if it does fit the problem, it is a quite computationally intensive. Some sort of feature extraction or data reduction technique is likely to be required.

So basically, further study of the methodology, or contact with a machine learning expert (which I am not) seems advisable.

-pd  


On 09 Jul 2014, at 18:24 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Grumpy today, Bert?
> 
> While it is a fact that RStudio is a separate tool from R, it is clear from the question that the OP is interested in capabilities that R is providing and he simply cannot tell the difference.
> 
> OP:
> 
> 1) "Better" is a word that leads to pointless arguments. You will have to be the judge of what works for you. I caution you that Open Source tools almost always achieve success by interoperating with other OS tools, and much of the success you have already obtained is the result of many contributions, of which R and its contributed packages deserve the lion's share of credit. RStudio is a very convenient editor that makes using R and LaTeX and Markdown and version control easier, but it is unlikely that either the blame for your dissatisfaction or the credit for your success should be attributed to RStudio.
> 
> I have successfully used all sorts of plain text editors and command line interfaces with R, and if you plan to scale up your projects then you will likely want to be very clear on this distinction between editors and computing tools so you can distribute your work on multiple parallel servers (where editors may not necessarily even be helpful) even if you choose to use RStudio as your controlling environment for launching such tasks.
> 
> 2) and 3) I know that R has contributed packages that can manage Hadoop data processing, but I have no personal experience with them. Google is your friend... especially if you keep in mind that these tools are not all found in one monolithic package.
> 
> For future reference: this is a plain text mailing list, so please adjust your mail client appropriately when sending to this list. Also, there are considerable resources mentioned in the Posting Guide that you should be aware of... see the link below.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On July 9, 2014 7:10:00 AM PDT, Bert Gunter <gunter.berton at gene.com> wrote:
>> RStudio is a separate product with its own support. Post there, not
>> here.
>> 
>> -- Bert
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>> 
>> 
>> 
>> 
>> On Tue, Jul 8, 2014 at 7:34 PM, Phan, Truong Q
>> <Troung.Phan at team.telstra.com> wrote:
>>> Hi R'er,
>>> 
>>> I have a dataset which has a matrix of 7502 x 1426 (rows x columns).
>>> The data is in a CSV format which has a size around 68Mb. This
>> dataset is less than 10% of our dataset.
>>> I have been adopting the Anomaly detection method as described by
>> http://www.mattpeeples.net/kmeans.html .
>>> It has been running more than 24hrs and still haven't completed the
>> calculation.
>>> I did manage to run it with a smaller dataset (ie, 2100 rows x 1426
>> columns). It took around 12hrs to run.
>>> 
>>> I have a few questions and need your expertise guidance.
>>> 
>>> 1)      Is there any better Open source tools to use to do in one
>> tool (eg, R Studio): prepare data, build models, validate models, test
>> models and present data. I am looking a tool which will allow me to do
>> the same as per the above link (Matt Peeples' blog).
>>> 
>>> 2)      Is there an Open source tools to perform the above which will
>> allow me to run on top of Hadoop eco-system?
>>> 
>>> 3)      Can we use R Studio for windows as a client to run on top of
>> Hadoop eco-system? If yes, please point me to the site where they have
>> a use cases or samples.
>>> 
>>> Thanks and Regards,
>>> Truong Phan
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Thu Jul 10 02:27:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 09 Jul 2014 17:27:16 -0700
Subject: [R] function completing properly
In-Reply-To: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
References: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
Message-ID: <334e55a9-eab5-4e69-a660-20c9b9a7d2b0@email.android.com>

I think you are mistaken. Please provide an example of how you used this function in any version of R that behaved as you describe.
Also, please post in plain text to avoid the what-you-see-is-not-what-we-see feature that HTML email provides.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 9, 2014 4:47:39 PM PDT, Janet Choate <jsc.eco at gmail.com> wrote:
>Hi R community,
>i created a function (mkdate) as follows:
>
>mkdate = function(x) {
>x$date = as.Date(paste(x$year, x$month, x$day, sep="-"))
>x$wy = ifelse(x$month >=10, x$year+1, x$year)
>x$yd = as.integer(format(as.Date(x$date), format="%j"))
>x$wyd = cal.wyd(x)
>x
>}
>
>the function results in adding the new columns date, wy, yd, and wyd to
>the
>table i apply it to.
>this has always worked in R version 2.14.2.
>however, in R version 3.1.0 - instead of my mkdate function adding
>those
>columns to my existing table, it just overwrites my table and leaves me
>with just a list of the last variable created by my mkdate function. so
>i
>end up with just a list of numbers representing wyd, and lose all the
>data
>in my original table.
>
>does anyone know what would now be causing this to occur, and what i
>need
>to do to make my function work properly again?
>
>thank you for any assistance,
>Janet
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Thu Jul 10 03:12:45 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Jul 2014 21:12:45 -0400
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
Message-ID: <web-518047580@cgpsrv2.cis.mcmaster.ca>

Dear Judith,

I take it from your reply that you have *more* observations than there are response variables in the multivariate linear model, but since you still haven't provided access to the data, it's still impossible to tell what the problem is. 

I don't follow your application, possibly because I'm ignorant of the area in which you work, but also possibly because there's insufficient information about that too. When you say that there are 0 abundances, I assume that this doesn't mean that some abundance values are 0 for *all* observations. If that's the case, then that would I believe produce a computational error, though not I think the one you observed. As an aside, if there are many 0 abundances then using the multivariate normal distribution for the responses likely isn't reasonable, which is what you're doing, but this in itself won't produce a computational error in candisc().

So, to reiterate, without the data, there's not much more that I can say. Because I'm out of town and will be traveling tomorrow, I'm unlikely to be able to respond again for several days.

 Best,
 John

On Wed, 9 Jul 2014 17:54:56 -0500
 Maria Judith Carmona H <juditycarmona at gmail.com> wrote:
> Dear John,
> 
> I am including abundance values ??in my data set so obviously I have zero
> abundances.
> The problem is that if plot only the factors (biomasa, altdosel, altsoto,
> cobertura, riqarb, elevacion, temperatura, precipitacion) I get the
> graphic, the same happen when I included only the families, but I want to
> see the effect of all these factors+families on this plot . In fact I
> included only certain families:
> 
> prueba4 <-
> lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
> 
> Araceae,Begoniaceae,Bromeliaceae,Clusiaceae,Cyclanthaceae,Ericaceae,Gesneriaceae,
>                     Melastomataceae,Orchidaceae,Piperaceae,Pteridophyta) ~
> sitio, data=bosques.p)
> canprueba2 <- candisc(prueba2, term="sitio", data=bosques.p, ndim=1)
> Error in eigen (EHD, symmetric = TRUE): infinite or missing values ??in 'x'
> In addition: Warning message:
> In sqrt (wmd): NaNs produced
> 
> You see I get the same error.
> 
> Best regards,
> Judith
> 
> 
> On Wed, Jul 9, 2014 at 5:30 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> > Dear Maria Judith Carmona Higuita,
> >
> > Since you didn't include enough information (such as your access to your
> > data) to reproduce the error, one can only guess. My guess: you have fewer
> > observations in your data set than response variables on the LHS of the
> > multivariate linear model.
> >
> > I hope this helps,
> >  John
> >
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> > On Wed, 9 Jul 2014 11:36:35 -0500
> >  Maria Judith Carmona H <juditycarmona at gmail.com> wrote:
> > > Hi,
> > >
> > > I have a problem using the function Candisc from Candisc Package.
> > >
> > > bosques1<-read.csv("bosques1.csv",header=TRUE,encoding="latin1")
> > > bosques1<-na.exclude(bosques1)
> > > attach(bosques1)
> > >
> > > #Modelo de regresi?n
> > > mod <-
> > >
> > lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
> > >                 Acanthaceae, Apocinaceae, Araceae, Araliaceae, Arecaceae,
> > > Aspleniaceae, Begoniaceae,
> > >                 Blechnaceae, Bromeliaceae, Clusiaceae, Cyclanthaceae,
> > > Davalliaceae, Denstaedtiaceae,
> > >                 Dryopteridaceae, Ericaceae, Gesneriaceae,
> > Hymenophyllaceae,
> > > indet., Lauraceae, Lomariopsidaceae, Lycopodiaceae, Melastomataceae,
> > > Moraceae, Myrsinaceae, Ophioglossaceae,
> > >                 Orchidaceae, Peperomia, Piperaceae, Poaceae,
> > Polypodiaceae,
> > > Primulaceae, Pteridaceae,
> > >                 Pteridophyta.taxa, Rubiaceae, Vittariaceae) ~ sitio,
> > > data=bosques1)
> > > summary(mod)
> > >
> > > #Gr?fico 1
> > > can <- candisc(mod, term="sitio",data=bosques1,ndim=1,eig=T)
> > > ### The error happens here, so I can not run the plot.
> > > plot(can,titles.1d = c("Puntuaci?n can?nica", "Estructura"))
> > > summary(can, means = FALSE, scores = TRUE, coef = c("std"), digits = 2)
> > >
> > > The error is:
> > > Error in eigen(eHe, symmetric = TRUE) : infinite or missing values in 'x'
> > > In addition: Warning message:
> > > In sqrt(wmd) : NaNs produced
> > >
> > > Please help!
> > >
> > > --
> > > Maria Judith Carmona Higuita.
> > > Estudiante de Biolog?a - Universidad de Antioquia
> > > Medell?n - Colombia
> > >
> > > "La felicidad ocurre cuando encajas en tu vida, cuando encajas
> > > tan arm?nicamente que cualquier cosa que hagas es una alegr?a para ti. De
> > > repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo que
> > haces,
> > > si amas la manera como vives, entonces ya est?s meditando y nada puede
> > > distraerte." Osho
> > >
> > >       [[alternative HTML version deleted]]
> > >
> >
> >
> >
> >
> >
> 
> 
> -- 
> Maria Judith Carmona Higuita.
> Estudiante de Biolog?a - Universidad de Antioquia
> Medell?n - Colombia
> 
> "La felicidad ocurre cuando encajas en tu vida, cuando encajas
> tan arm?nicamente que cualquier cosa que hagas es una alegr?a para ti. De
> repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo que haces,
> si amas la manera como vives, entonces ya est?s meditando y nada puede
> distraerte." Osho

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From arz at berkeley.edu  Thu Jul 10 00:08:48 2014
From: arz at berkeley.edu (Adam Zeilinger)
Date: Wed, 09 Jul 2014 15:08:48 -0700
Subject: [R] Installing rgdal and rjags packages on a linux cluster
Message-ID: <53BDBD70.7020403@berkeley.edu>

Dear R Help,

I'm trying to install the rjags and rgdal packages on a linux cluster 
running R 3.0.3.  However, I'm having problems installing them 
successfully.  Both packages require external programs (JAGS and GDAL, 
respectively), which have been successfully installed.

For rjags, the error message reads:
"configure: error: "Location of JAGS headers not defined.  Use configure 
arg '--with-jags-include' or environment variable 'JAGS_INCLUDE'""

I tried the following:
 > install.packages("rjags", configure.args = list("--with-jags-include"))
This returns a different error:
"configure: error: "Problem with header file yes/Console.h""

 From my readings of various help pages, it seems that I need to 
download the developer version of the rjags package, in order to supply 
the header files.  Is this correct?  If so, where do I find developer 
packages and how do I install them?  R package development is new to me.

For rgdal, the error message reads:
"Error: gdal-config not found
The gdal-config script distributed with GDAL could not be found."

Here, it's my understanding that I need to install PROJ.4 libraries and 
the developer versions of the rgdal and proj4 packages.  Is this correct?

Are the problems with installing rjags and rgdal basically the same?  
Could the problems be caused by running an older version of R?

Any help would be greatly appreciated.
Adam Zeilinger

-- 
Adam Zeilinger
Postdoctoral scholar
Berkeley Initiative for Global Change Biology
University of California Berkeley
http://www.linkedin.com/in/adamzeilinger/


From juditycarmona at gmail.com  Thu Jul 10 00:54:56 2014
From: juditycarmona at gmail.com (Maria Judith Carmona H)
Date: Wed, 9 Jul 2014 17:54:56 -0500
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <web-518038008@cgpsrv2.cis.mcmaster.ca>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/c641491c/attachment.pl>

From juditycarmona at gmail.com  Thu Jul 10 03:47:21 2014
From: juditycarmona at gmail.com (Maria Judith Carmona H)
Date: Wed, 9 Jul 2014 20:47:21 -0500
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <web-518047580@cgpsrv2.cis.mcmaster.ca>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
	<web-518047580@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAAweS99FEhf_i+4bkM=boz3xva_EHnSf7pAhvtRK-4oyKvSb9A@mail.gmail.com>

Dear John

There is my data set.

Thanks.


On Wed, Jul 9, 2014 at 8:12 PM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Judith,
>
> I take it from your reply that you have *more* observations than there are
> response variables in the multivariate linear model, but since you still
> haven't provided access to the data, it's still impossible to tell what the
> problem is.
>
> I don't follow your application, possibly because I'm ignorant of the area
> in which you work, but also possibly because there's insufficient
> information about that too. When you say that there are 0 abundances, I
> assume that this doesn't mean that some abundance values are 0 for *all*
> observations. If that's the case, then that would I believe produce a
> computational error, though not I think the one you observed. As an aside,
> if there are many 0 abundances then using the multivariate normal
> distribution for the responses likely isn't reasonable, which is what
> you're doing, but this in itself won't produce a computational error in
> candisc().
>
> So, to reiterate, without the data, there's not much more that I can say.
> Because I'm out of town and will be traveling tomorrow, I'm unlikely to be
> able to respond again for several days.
>
>  Best,
>  John
>
> On Wed, 9 Jul 2014 17:54:56 -0500
>  Maria Judith Carmona H <juditycarmona at gmail.com> wrote:
> > Dear John,
> >
> > I am including abundance values ??in my data set so obviously I have zero
> > abundances.
> > The problem is that if plot only the factors (biomasa, altdosel, altsoto,
> > cobertura, riqarb, elevacion, temperatura, precipitacion) I get the
> > graphic, the same happen when I included only the families, but I want to
> > see the effect of all these factors+families on this plot . In fact I
> > included only certain families:
> >
> > prueba4 <-
> >
> lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
> >
> >
> Araceae,Begoniaceae,Bromeliaceae,Clusiaceae,Cyclanthaceae,Ericaceae,Gesneriaceae,
> >                     Melastomataceae,Orchidaceae,Piperaceae,Pteridophyta)
> ~
> > sitio, data=bosques.p)
> > canprueba2 <- candisc(prueba2, term="sitio", data=bosques.p, ndim=1)
> > Error in eigen (EHD, symmetric = TRUE): infinite or missing values ??in
> 'x'
> > In addition: Warning message:
> > In sqrt (wmd): NaNs produced
> >
> > You see I get the same error.
> >
> > Best regards,
> > Judith
> >
> >
> > On Wed, Jul 9, 2014 at 5:30 PM, John Fox <jfox at mcmaster.ca> wrote:
> >
> > > Dear Maria Judith Carmona Higuita,
> > >
> > > Since you didn't include enough information (such as your access to
> your
> > > data) to reproduce the error, one can only guess. My guess: you have
> fewer
> > > observations in your data set than response variables on the LHS of the
> > > multivariate linear model.
> > >
> > > I hope this helps,
> > >  John
> > >
> > > ------------------------------------------------
> > > John Fox, Professor
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > http://socserv.mcmaster.ca/jfox/
> > >
> > > On Wed, 9 Jul 2014 11:36:35 -0500
> > >  Maria Judith Carmona H <juditycarmona at gmail.com> wrote:
> > > > Hi,
> > > >
> > > > I have a problem using the function Candisc from Candisc Package.
> > > >
> > > > bosques1<-read.csv("bosques1.csv",header=TRUE,encoding="latin1")
> > > > bosques1<-na.exclude(bosques1)
> > > > attach(bosques1)
> > > >
> > > > #Modelo de regresi?n
> > > > mod <-
> > > >
> > >
> lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
> > > >                 Acanthaceae, Apocinaceae, Araceae, Araliaceae,
> Arecaceae,
> > > > Aspleniaceae, Begoniaceae,
> > > >                 Blechnaceae, Bromeliaceae, Clusiaceae, Cyclanthaceae,
> > > > Davalliaceae, Denstaedtiaceae,
> > > >                 Dryopteridaceae, Ericaceae, Gesneriaceae,
> > > Hymenophyllaceae,
> > > > indet., Lauraceae, Lomariopsidaceae, Lycopodiaceae, Melastomataceae,
> > > > Moraceae, Myrsinaceae, Ophioglossaceae,
> > > >                 Orchidaceae, Peperomia, Piperaceae, Poaceae,
> > > Polypodiaceae,
> > > > Primulaceae, Pteridaceae,
> > > >                 Pteridophyta.taxa, Rubiaceae, Vittariaceae) ~ sitio,
> > > > data=bosques1)
> > > > summary(mod)
> > > >
> > > > #Gr?fico 1
> > > > can <- candisc(mod, term="sitio",data=bosques1,ndim=1,eig=T)
> > > > ### The error happens here, so I can not run the plot.
> > > > plot(can,titles.1d = c("Puntuaci?n can?nica", "Estructura"))
> > > > summary(can, means = FALSE, scores = TRUE, coef = c("std"), digits =
> 2)
> > > >
> > > > The error is:
> > > > Error in eigen(eHe, symmetric = TRUE) : infinite or missing values
> in 'x'
> > > > In addition: Warning message:
> > > > In sqrt(wmd) : NaNs produced
> > > >
> > > > Please help!
> > > >
> > > > --
> > > > Maria Judith Carmona Higuita.
> > > > Estudiante de Biolog?a - Universidad de Antioquia
> > > > Medell?n - Colombia
> > > >
> > > > "La felicidad ocurre cuando encajas en tu vida, cuando encajas
> > > > tan arm?nicamente que cualquier cosa que hagas es una alegr?a para
> ti. De
> > > > repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo que
> > > haces,
> > > > si amas la manera como vives, entonces ya est?s meditando y nada
> puede
> > > > distraerte." Osho
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > >
> > >
> > >
> > >
> > >
> >
> >
> > --
> > Maria Judith Carmona Higuita.
> > Estudiante de Biolog?a - Universidad de Antioquia
> > Medell?n - Colombia
> >
> > "La felicidad ocurre cuando encajas en tu vida, cuando encajas
> > tan arm?nicamente que cualquier cosa que hagas es una alegr?a para ti. De
> > repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo que
> haces,
> > si amas la manera como vives, entonces ya est?s meditando y nada puede
> > distraerte." Osho
>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
>
>
>


-- 
Maria Judith Carmona Higuita.
Biologist - University of Antioquia
Medell?n - Colombia

"Happiness happens when you fit with your life, when you fit so
harmoniously that whatsoever you are doing is your joy. Then suddenly you
will come to know: meditation follows you. If you love the work that you
are doing, if you love the way you are living, then you are meditative".
Osho

From pomchip at free.fr  Thu Jul 10 04:47:21 2014
From: pomchip at free.fr (=?UTF-8?Q?S=C3=A9bastien_Bihorel?=)
Date: Wed, 9 Jul 2014 22:47:21 -0400
Subject: [R] Information about font
Message-ID: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140709/291debd9/attachment.pl>

From dwinsemius at comcast.net  Thu Jul 10 06:21:59 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Jul 2014 21:21:59 -0700
Subject: [R] Information about font
In-Reply-To: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>
References: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>
Message-ID: <71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>


On Jul 9, 2014, at 7:47 PM, S?bastien Bihorel wrote:

> Hi,
> 
> I have this set of R scripts which are ran on a linux box and create plots
> with the lattice package. I do not specify any custom font family, so I
> believe that whatever is the default font on my system is used in the plot.
> 1- how can I know which is the default font used in my plots?
> 2- is this font specific to R or can it be used by external tools?
> 3- if this font can be used by external tools, how can I know the location
> of this font on my system?

Fonts are specific to the graphical device being used. You have not specified what device you are using.

?Devices

The fonts are provided by your OS setup. 

?pdfFonts
?Type1Font
?grid::gpar

> 
> Thank you in advance for your help
> 
> Sebastien
> 
> 	[[alternative HTML version deleted]]


Still having trouble understanding your mail client?

-- 
David Winsemius
Alameda, CA, USA


From abhinabaroy09 at gmail.com  Thu Jul 10 07:34:59 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Thu, 10 Jul 2014 11:04:59 +0530
Subject: [R] Decision Tree
Message-ID: <CANtKHPWVRwyVaT5AMCoT=q8jynV8rYX_79jdkTGpAxqAT8o7DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/8c4b6ad3/attachment.pl>

From william.lian.fang at gmail.com  Thu Jul 10 05:59:32 2014
From: william.lian.fang at gmail.com (William)
Date: Thu, 10 Jul 2014 11:59:32 +0800
Subject: [R] quantmod: How could I change the name in chartSeries
Message-ID: <53BE0FA4.2080507@gmail.com>

hi, guys,

I am just a beginner to the excellent R package, quantmod. I quite don't 
know how to change the y-axis name in the chartSeries function. 
Actually, I want to write some sort of the following function, by which 
I could use just one code  sentence  to complete the financial analysis.

The following function is designed to provide some aspects of the 
S&P500. And now I want to change the "stock.name" on the y-axis as 
"S&P500". Is there anyway to realize this?

THX

         William


#################################################################
stock.price <- function(stock.name, stock.code){
   #### Loading......
   library(zoo)
   library(xts)
   library(TTR)
   library(Defaults)
   library(quantmod)
#------------------------------------------------------------------------------------------------------------------------------------------
   ## Theme: white
   theme.white <- chartTheme("white")
   names(theme.white)
   theme.white$bg.col <- "white"
   theme.white$up.col <- "red"
   theme.white$dn.col <- "green"
#------------------------------------------------------------------------------------------------------------------------------------------
   #### main function
   stock.name <- getSymbols(stock.code, from = "2010-01-01",
                                                 to = Sys.Date(), src = 
"yahoo", auto.assign=FALSE)
   chartSeries(stock.name, theme = theme.white,
               # subset = 'last 12 months',
               TA = "addVo(); addSMA(); addEnvelope();
                   addMACD(); addMomentum(); addROC();
                   addBBands()")
   addLines(v = which(stock.name[,4] == max(stock.name[,4])),
            col = "gray")
}
#################################################################
stock.price(S&P500, "^GSPC")


From friendly at yorku.ca  Thu Jul 10 10:22:07 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 10 Jul 2014 10:22:07 +0200
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
Message-ID: <53BE4D2F.40408@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/a2f7f60b/attachment.pl>

From pd.mes at cbs.dk  Thu Jul 10 10:51:52 2014
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 10 Jul 2014 10:51:52 +0200
Subject: [R]   R 3.1.1 is released
Message-ID: <737AC669-98EA-41D4-9C83-ABB6F09C6724@cbs.dk>

The build system rolled up R-3.1.1.tar.gz (codename "Sock it to Me") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.1.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course. Perhaps with some delays due to vacations. In particular, the Mac OS X maintainer is traveling and may be without Internet access for some days yet.

For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = cbf6da8f886ccd8d0dda0cc7ffd1b8ec
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 19b98552686c3f3c95a6028596c533e9
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = bf2c79e7fd7e2dff621a3a8410c89bb4
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = e840d32b7ef7a7603455d30d6d54fda7
MD5 (NEWS.html) = 206dc0c4dc31004f245813b403ec6d6a
MD5 (R-latest.tar.gz) = 2598f5bbbedb00e463e0c1385e6fe999
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = c7cb32499ebbf85deb064aab282f93a4
MD5 (THANKS) = d4b45e302b7cad0fc4bb50d2cfe69649
MD5 (R-3/R-3.1.1.tar.gz) = 2598f5bbbedb00e463e0c1385e6fe999


This is the relevant part of the NEWS file


  NEW FEATURES:

    * When attach() reports conflicts, it does so compatibly with
      library() by using message().

    * R CMD Sweave no longer cleans any files by default, compatibly
      with versions of R prior to 3.1.0.  There are new options
      --clean, --clean=default and --clean=keepOuts.

    * tools::buildVignette() and tools::buildVignettes() with clean =
      FALSE no longer remove any created files.  buildvignette() gains
      a keep argument for more cleaning customization.

    * The Bioconductor 'version' used by setRepositories() can now be
      set by environment variable R_BIOC_VERSION at runtime, not just
      when R is installed.  (It has been stated that Bioconductor will
      switch from 'version' 2.14 to 'version' 3.0 during the lifetime
      of the R 3.1 series.)

    * Error messages from bugs in embedded Sexpr code in Sweave
      documents now report the source location.

    * type.convert(), read.table() and similar read.*() functions get a
      new numerals argument, specifying how numeric input is converted
      when its conversion to double precision loses accuracy.  The
      default value, "allow.loss" allows accuracy loss, as in R
      versions before 3.1.0.

    * For some compilers, integer addition could overflow without a
      warning.  R's internal code for both integer addition and
      subtraction is more robust now.  (PR#15774)

    * The function determining the default number of knots for
      smooth.spline() is now exported, as .nknots.smspl().

    * dbeta(, a,b), pbeta(), qbeta() and rbeta() are now defined also
      for a = 0, b = 0, or infinite a and b (where they typically
      returned NaN before).

    * Many package authors report that the RStudio graphics device does
      not work correctly with their package's use of dev.new().  The
      new option dev.new(noRStudioGD = TRUE) replaces the RStudio
      override by the default device as selected by R itself, still
      respecting environment variables R_INTERACTIVE_DEVICE and
      R_DEFAULT_DEVICE.

    * readRDS() now returns visibly.

    * Modifying internal logical scalar constants now results in an
      error instead of a warning.

    * install.packages(repos = NULL) now accepts http:// or ftp:// URLs
      of package archives as well as file paths, and will download as
      required.  In most cases repos = NULL can be deduced from the
      extension of the URL.

    * The warning when using partial matching with the $ operator on
      data frames is now only given when
      options("warnPartialMatchDollar") is TRUE.

    * Package help requests like package?foo now try the package foo
      whether loaded or not.

    * General help requests now default to trying all loaded packages,
      not just those on the search path.

    * Added a new function promptImport(), to generate a help page for
      a function that was imported from another package (and presumably
      re-exported, or help would not be needed).

  INSTALLATION and INCLUDED SOFTWARE:

    * configure option --with-internal-tzcode can now be used with
      variable rsharedir.

    * The included version of PCRE has been updated to 8.35.

    * There is a new target make uninstall-libR to remove an installed
      shared/static libR.

      make install-libR now works if a sub-architecture is used,
      although the user will need to specify libdir differently for
      different sub-architectures.

    * There is more extensive advice on which LaTeX packages are
      required to install R or to make package manuals (as done by R
      CMD check) in the 'Writing R Extensions' manual.

    * Compilers/linkers were handling the visibility controls in
      src/extra/xz inconsistently (and apparently in some cases
      incorrectly), so it has been simplified.  (PR#15327)

    * (Windows) There is updated support for the use of ICU for
      collation: see the 'R Installation and Administration Manual'.

  BUG FIXES:

    * dbinom(x, n), pbinom(), dpois(), etc, are slightly less
      restrictive in checking if n is integer-valued.  (Wish of
      PR#15734.)

    * pchisq(x, df, ncp, log.p = TRUE) is more accurate and no longer
      underflows for small x and ncp < 80, e.g, for pchisq(1e-5, df =
      100, ncp = 1, log = TRUE).  (Based on PR#15635 and a suggestion
      by Roby Joehanes.)

    * The s ("step into") command in the debugger would cause R to step
      into expressions evaluated there, not just into functions being
      debugged.  (PR#15770)

    * The C code used by strptime() rejected time-zone offsets of more
      than +1200 (+1245, +1300 and +1400 can occur).  (PR#15768)

    * (Windows only.)  png(type = "cairo", antialias = "gray") was not
      accepted.  (PR#15760)

    * Use of save(..., envir=) with named objects could fail.
      (PR#15758)

    * Sweave() mis-parsed Sexpr expressions that contained backslashes.
      (PR#15779)

    * The return value from options(foo = NULL) was not the previous
      value of the option.  (PR#15781)

    * enc2utf8() and enc2native() did not always mark the encoding of
      the return values when it was known.

    * dnbinom(x, size = <large>, mu, log = TRUE) no longer underflows
      to -Inf for large mu, thanks to a suggestion from Alessandro
      Mammana (MPI MolGen, Berlin).

    * pbeta(x, a, b, log = TRUE) no longer behaves discontinuously (in
      a small x-region) because of denormalized numbers.  Also,
      pbeta(1-1e-12, 1e30, 1.001, log=TRUE) now terminates "in real
      time".

    * The "CRAN" filter (see available.packages()) no longer removes
      duplicates other than of packages on CRAN, and does not fail if
      there is no CRAN repository in getOption("repos").

    * The device listing from dev2bitmap() and bitmap() was truncated
      to 1000 characters: modern versions of GhostScript on most
      platforms have many more devices.

    * (Windows.)  Commands such as Sys.which() and pipe() which needed
      to find the full path to a command could segfault if the 'long'
      path name was much longer than the 'short' path name (which
      Sys.which() returns), as the behaviour of the Windows API call
      had changed.

    * R CMD build will fail with an error if one of the packages
      specified in the VignetteBuilder field is not installed.
      (Without loading those packages it cannot be ascertained which
      files are intended to be vignettes. This means that the
      VignetteBuilder packages have to be installed for package
      checking too.)  (Wish of PR#15775.)

    * Misguided attempts to use chull() with non-finite points now give
      an error (related to PR#15777).

    * For a formula with exactly 32 variables the 32nd variable was
      aliased to the intercept in some C-level computations of terms,
      so that for example attempting to remove it would remove the
      intercept instead (and leave a corrupt internal structure).
      (PR#15735)

    * anyDuplicated() silently returned wrong values when the first
      duplicate was at an index which was too large to be stored in an
      integer vector (although a lot of RAM and patience would have
      been needed to encounter this).

    * tools::Rd2ex(commentDontrun = FALSE) failed if the block had only
      one line.

    * Hexadecimal constants such as 0x110p-5L which were incorrectly
      qualified by L were parsed incorrectly since R 3.0.0, with a
      slightly garbled warning. (PR#15753)

    * system() returned success on some platforms even if the system
      was unable to launch a process. (PR#15796)

    * (Windows Rgui console.)  Unbuffered output was sometimes not
      output immediately if the prompt was not on the last line of the
      console.

    * The built-in help server did not declare the encoding for the
      DESCRIPTION or other text files to be the package encoding, so
      non-ASCII characters could be displayed incorrectly.

    * R is now trying harder to not cleanup child processes that were
      not spawned by mcparallel() on platforms that provide information
      about the source process of the SIGCHLD signal. This allows 3rd
      party libraries to manage the exit status of children that they
      spawn without R interfering.

    * mcmapply() was only parallelizing if the number of jobs was
      bigger than the number of cores. It now parallelizes if the
      number of jobs is more than one.

    * Auto-printing would re-evaluate its argument when trying to
      dispatch to a print method.  This is now avoided when possible.

    * Unserializing (including load() and readRDS()) could silently
      return incorrect numeric values from ASCII saves if there was a
      read error.

    * getParseData() could return incorrect values for the parents of
      some elements. (Reported by Andrew Redd.)

    * Attempting to use data frames of 2^31 or more rows with merge()
      or to create a merged data frame of that size now gives a clearer
      error message.

    * parse() did not check its file argument was a connection if it
      was not a character string, so e.g. parse(FALSE) attempted to
      read from stdin.

      Nor did dump() and dput().

    * The "help.try.all.packages" option was ignored when the shortcut
      syntax for help was used, e.g. ?foo.

    * A potential segfault in string allocation has been fixed.  (Found
      by Radford Neal.)

    * Potential memory protection errors in sort() and D() have been
      fixed. (Found by Radford Neal.)

    * Fixed a lack of error checking in graphics event functions.
      (Found by Radford Neal; a different patch used here than the one
      in pqR.)

    * numericDeriv() sometimes miscalculated the gradient.  (PR#15849,
      reported originally by Radford Neal)



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From kmersman at smail.uni-koeln.de  Thu Jul 10 12:04:46 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Thu, 10 Jul 2014 12:04:46 +0200
Subject: [R] linearHypothesis() ERROR-Message
Message-ID: <000001cf9c26$60ffc960$22ff5c20$@uni-koeln.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/ded85f91/attachment.pl>

From lars52r at gmail.com  Thu Jul 10 12:23:13 2014
From: lars52r at gmail.com (Lars Bishop)
Date: Thu, 10 Jul 2014 06:23:13 -0400
Subject: [R] Median expected survival
Message-ID: <CAO7OmOi_OA6teVQybyZATzxtOksqQZa6p+Q4oSWKu42+8+drSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/fcc6366a/attachment.pl>

From jabbba at gmail.com  Thu Jul 10 13:15:49 2014
From: jabbba at gmail.com (=?UTF-8?Q?Marco_Barb=C3=A0ra?=)
Date: Thu, 10 Jul 2014 13:15:49 +0200
Subject: [R] Median expected survival
In-Reply-To: <CAO7OmOi_OA6teVQybyZATzxtOksqQZa6p+Q4oSWKu42+8+drSA@mail.gmail.com>
References: <CAO7OmOi_OA6teVQybyZATzxtOksqQZa6p+Q4oSWKu42+8+drSA@mail.gmail.com>
Message-ID: <CABL+AMdFhTiYah950naP0R6YQHM93S0EL_-UZtMXU4nkjQQYqg@mail.gmail.com>

Hi, Lars.

I don't understand well your question. why don't you simply type

 pred_leuk

Call: survfit(formula = leuk.cox, newdata = leuk_new)

   records n.max n.start events median 0.95LCL 0.95UCL
1       42    42      42     30      1       1      23
2       42    42      42     30      7       5      NA
3       42    42      42     30     15      10      NA
4       42    42      42     30     NA      NA      NA
5       42    42      42     30      8       5      NA
6       42    42      42     30     23      22      NA
7       42    42      42     30      8       6      NA
8       42    42      42     30     NA      22      NA
9       42    42      42     30      6       4      NA
10      42    42      42     30     23      17      NA

Yes, the quantile method returns the correct medians. The NAs usually
appear when the unit belongs to a category for which median survival
time has not yet been reached, so there is no way for the model to
estimate the median time. You can see the expected survival curve with
plot(predl_leuk)


From jim at bitwrit.com.au  Thu Jul 10 13:50:19 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 10 Jul 2014 21:50:19 +1000
Subject: [R] function completing properly
In-Reply-To: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
References: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
Message-ID: <1700231.7mFF8UFI5I@localhost.localdomain>

On Wed, 9 Jul 2014 04:47:39 PM Janet Choate wrote:
> Hi R community,
> i created a function (mkdate) as follows:
> 
> mkdate = function(x) {
> x$date = as.Date(paste(x$year, x$month, x$day, sep="-"))
> x$wy = ifelse(x$month >=10, x$year+1, x$year)
> x$yd = as.integer(format(as.Date(x$date), format="%j"))
> x$wyd = cal.wyd(x)
> x
> }
> 
> the function results in adding the new columns date, wy, yd, and 
wyd to the
> table i apply it to.
> this has always worked in R version 2.14.2.
> however, in R version 3.1.0 - instead of my mkdate function adding 
those
> columns to my existing table, it just overwrites my table and leaves 
me
> with just a list of the last variable created by my mkdate function. so 
i
> end up with just a list of numbers representing wyd, and lose all the 
data
> in my original table.
> 
> does anyone know what would now be causing this to occur, and 
what i need
> to do to make my function work properly again?
> 
> thank you for any assistance,
> Janet
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible 
code.
Hi Janet,
It looks to me as though x should be at least a three column list 
containing a year, month and day in numeric format. You then add 
four other fields to it and return the resulting (at least) seven column 
list. What you may have been doing was to pass your entire data 
frame (?) to the function with one or more incomplete rows, 
whereupon the function would calculate the four fields for all the rows 
and fill in the incomplete rows. This is not a very efficient way to do this 
and you should probably consider just passing the new values and 
appending the object returned to your data frame.

Jim


From lebatsnok at gmail.com  Thu Jul 10 14:18:52 2014
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Thu, 10 Jul 2014 15:18:52 +0300
Subject: [R] R on Windows crashes when source'ing UTF-8 file
Message-ID: <CAH7sKSPVJuJXm4ksJYn3XZVmz=6L68w=T-s0Li+En2Co9pm4Tg@mail.gmail.com>

Dear all,

I found an unexpected behaviour when trying to `source` an utf-8 file
on windows 7:

source("http://psych.ut.ee/~nek/R/test-utf8.txt")

# Rgui.exe reacts:
# R for windows GUI has stopped working. A problem caused the program
to stop working correctly.
# Windows will close the program and notify you if a solution is available.

The same will happen with R.exe ("terminal") and R running wihin
Rstudio. (Session and locale info below).

However, a non-utf version of this little script can be `source`d
without problems.

source("http://psych.ut.ee/~nek/R/test.txt")

Adding the `encoding` argument to `source` helps a little:

source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="utf-8")
#  unsure about the spelling of utf-8 so I also tried UTF8, utf8, and UTF-8
# ... with the same result in all cases

R doesn't crash any more but gives the following error:

# Error in source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding
= "utf-8") :
#   http://psych.ut.ee/~nek/R/test-utf8.txt:2:0: unexpected end of input
# 1: ?
#    ^
# In addition: Warning message:
# In readLines(file, warn = FALSE) :
#  invalid input found on input connection
'http://psych.ut.ee/~nek/R/test-utf8.txt'

I thought maybe that's because what notepad told me is UTF-8 is
actually something else ... so I did two more experiments.

source("http://psych.ut.ee/~nek/R/test2.R")
# this was created on a linux machine with leafpad, and saved as utf-8 text
# it can be source?d on windows

source("http://psych.ut.ee/~nek/R/test3.R")
# the same as previous but o's in file were replaced by ?'s
# can be source'd on windows but the "?" character is shown as ??
# except if you add encoding="utf-8" - then, as expected, it works as expected

So in sum, I can create "plain text" (saved with utf-8 encoding) files
on windows that cannot be sourced to R on windows, or will crash R
(depending on how you source them). The same files can be sourced on
linux without problems. Part of the problem is obviously in windows
but maybe R shouldn't at least crash.

Session info:

 R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Estonian_Estonia.1257  LC_CTYPE=Estonian_Estonia.1257
[3] LC_MONETARY=Estonian_Estonia.1257 LC_NUMERIC=C
[5] LC_TIME=Estonian_Estonia.1257

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.2


OS: Windows 7

Linux Mint Debian Edition and R 3.0.2 on the other machine (where
everything worked).

Context:

I was trying to find out how to make files that could be source'd on
both windows and linux. This is partly solved so I have no specific
question other than "is this a bug in windows version?" but any
comments on the general topic would be appreciated too.

Best regards,

Kenn


Kenn Konstabel
Research fellow
Department of chronic diseases
National Institute of Health Development
Hiiu 42
Tallinn
Estonia


From pomchip at free.fr  Thu Jul 10 14:54:43 2014
From: pomchip at free.fr (=?UTF-8?Q?S=C3=A9bastien_Bihorel?=)
Date: Thu, 10 Jul 2014 08:54:43 -0400
Subject: [R] Information about font
In-Reply-To: <71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>
References: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>
	<71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>
Message-ID: <CABR8Zvpd8rWPw2cirosqwLEGC5CZ1J_Vg0t8z5hzdejjBdEhEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/bc0cc957/attachment.pl>

From pomchip at free.fr  Thu Jul 10 15:40:52 2014
From: pomchip at free.fr (=?UTF-8?Q?S=C3=A9bastien_Bihorel?=)
Date: Thu, 10 Jul 2014 09:40:52 -0400
Subject: [R] Information about font
In-Reply-To: <CABR8Zvpd8rWPw2cirosqwLEGC5CZ1J_Vg0t8z5hzdejjBdEhEA@mail.gmail.com>
References: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>
	<71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>
	<CABR8Zvpd8rWPw2cirosqwLEGC5CZ1J_Vg0t8z5hzdejjBdEhEA@mail.gmail.com>
Message-ID: <CABR8ZvomNReHJtjN7sw8OjzFSD=CZd1bF4NLbccVccpmrw1tEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/201abd7e/attachment.pl>

From madhvi.gupta at orkash.com  Thu Jul 10 13:40:40 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Thu, 10 Jul 2014 17:10:40 +0530
Subject: [R] Error in installing package raccumulo for R version 3.1.0
Message-ID: <53BE7BB8.8020805@orkash.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/307ea710/attachment.pl>

From marcus.schwemmle at gmail.com  Thu Jul 10 14:08:16 2014
From: marcus.schwemmle at gmail.com (Marcus Schwemmle)
Date: Thu, 10 Jul 2014 05:08:16 -0700 (PDT)
Subject: [R] Preserving topology when simplifying Spatial Polygons
In-Reply-To: <CAJg3qJh8KdnOAW=OCZENBk=-hqQ_qQQh8T6TJzs2Y42LPqgy4g@mail.gmail.com>
References: <CAJg3qJh8KdnOAW=OCZENBk=-hqQ_qQQh8T6TJzs2Y42LPqgy4g@mail.gmail.com>
Message-ID: <43fffc39-6355-4150-80a2-d024a5eec973@googlegroups.com>

Have you got any further with this? I have the same problem...



On Wednesday, 4 June 2014 22:17:20 UTC+2, Will Leahy wrote:
>
> I'm trying to simplify a group of adjacent polygons without gaps and line 
> overlaps forming between them. Ideally I'd like results similar to what 
> mapshaper produces. I've tried using gSimplify() (from rGEOS), 
> thinnedSpatialPoly() (from maptools), and dp() (from shapefiles) but 
> haven't been able to get good results. The first two have a 
> "topologyPreserve" argument but it only applies to single polygons. Are 
> there any other tools / methods for line simplification that I might try? 
> Thanks 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From geoffrey_klein at etu.u-bourgogne.fr  Thu Jul 10 14:34:22 2014
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Thu, 10 Jul 2014 05:34:22 -0700 (PDT)
Subject: [R] find & remove sequences of at least N values for a specific
	value
Message-ID: <1404995662430-4693810.post@n4.nabble.com>

Hi everybody,

I have a small problem in a function, about removing short sequences of
identical numeric values.

For the example, we can consider this data, containing only some "0" and
"1":

test <- data.frame(x=c(0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1))

The aim of my purpose here is simply to remove each sequence of "1" with a
length shorter than 5, and to keep sequences of "1" which are bigger than 5.
So my final data should look like this:

final <- data.frame(x=c(0,0,NA,NA,NA,0,0,0,0,1,1,1,1,1,1,1,1))

For the moment, I have this function:

    foo <- function(X,N){
      tab <- table(X[X==1])
      under.n <- as.numeric(names(tab)[tab<N]) 
      ind <- X %in% under.n
      Ind.sup <- which(ind)
      X <- ifelse(ind,NA,X)
    }

test$x <- apply(as.data.frame(test$x),2,function(x) foo(x,5))

The problem is that the function doesn't consider each sequence separately,
but only one sequence. I think that adding rle() instead of table() in my
function should to the trick, but it doesn't work yet. 
Does someone have an idea about fixing this problem?





--
View this message in context: http://r.789695.n4.nabble.com/find-remove-sequences-of-at-least-N-values-for-a-specific-value-tp4693810.html
Sent from the R help mailing list archive at Nabble.com.


From therneau at mayo.edu  Thu Jul 10 15:52:18 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 10 Jul 2014 08:52:18 -0500
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <mailman.23.1404986407.26997.r-help@r-project.org>
References: <mailman.23.1404986407.26997.r-help@r-project.org>
Message-ID: <d46aec$hoe7h2@ironport9.mayo.edu>

You are asking for a one sample test.  Using your own data:

connection <- textConnection("
GD2  1   8 12  GD2  3 -12 10  GD2  6 -52  7
GD2  7  28 10  GD2  8  44  6  GD2 10  14  8
GD2 12   3  8  GD2 14 -52  9  GD2 15  35 11
GD2 18   6 13  GD2 20  12  7  GD2 23  -7 13
GD2 24 -52  9  GD2 26 -52 12  GD2 28  36 13
GD2 31 -52  8  GD2 33   9 10  GD2 34 -11 16
GD2 36 -52  6  GD2 39  15 14  GD2 40  13 13
GD2 42  21 13  GD2 44 -24 16  GD2 46 -52 13
GD2 48  28  9  GD2  2  15  9  GD2  4 -44 10
GD2  5  -2 12  GD2  9   8  7  GD2 11  12  7
GD2 13 -52  7  GD2 16  21  7  GD2 17  19 11
GD2 19   6 16  GD2 21  10 16  GD2 22 -15  6
GD2 25   4 15  GD2 27  -9  9  GD2 29  27 10
GD2 30   1 17  GD2 32  12  8  GD2 35  20  8
GD2 37 -32  8  GD2 38  15  8  GD2 41   5 14
GD2 43  35 13  GD2 45  28  9  GD2 47   6 15
")

hsv <- data.frame(scan(connection, list(vac="", pat=0, wks=0, x=0)))
hsv <- transform(hsv, status= (wks >0), wks = abs(wks))

fit1 <- survreg(Surv(wks, status) ~ 1, data=hsv, dist='exponential')
temp <- predict(fit1, type='quantile', p=.5, se=TRUE)

c(median= temp$fit[1], std= temp$se[1])
   median    std
24.32723  4.36930

--
The predict function gives the predicted median survival and standard deviation for each 
observation in the data set.  Since this was a mean only model all n of them are the same 
and I printed only the first.
For prediction they make the assumption that the std error for my future study will be the 
same as the std from this one, you want the future 95% CI to not include the value of 16, 
so the future mean will need to be at least 16 + 1.96* 4.369.

A nonparmetric version of the argument would be

> fit2 <- survfit(Surv(wks, status) ~ 1, data=hsv)
> print(fit2)
records   n.max n.start  events  median 0.95LCL 0.95UCL
      48      48      48      31      21      15      35

Then make the argument that in our future study, the 95% CI will stretch 6 units to the 
left of the median, just like it did here.  This argument is a bit more tenuous though. 
The exponential CI width depends on the total number of events and total follow-up time, 
and we can guess that the new study will be similar.  The Kaplan-Meier CI also depends on 
the spacing of the deaths, which is less likely to replicate.

Notes:
  1. Use summary(fit2)$table to extract the CI values.  In R the print functions don't 
allow you to "grab" what was printed, summary normally does.
  2. For the exponential we could work out the formula in closed form -- a good homework 
exercise for grad students perhaps but not an exciting way to spend my own afternoon.  An 
advantage of the above approach is that we can easily use a more realistic model like the 
weibull.
  3. I've never liked extracting out the "Surv(t,s)" part of a formula as a separate 
statement on another line.  If I ever need to read this code again, or even just the 
printout from the run, keeping it all together gives much better documentation.
  4. Future calculations for survival data, of any form, are always tenuous since they 
depend critically on the total number of events that will be in the future study.  We can 
legislate the total enrollment and follow-up time for that future study, but the number of 
events is never better than a guess.  Paraphrasing a motto found on the door of a well 
respected investigator I worked with 30 years ago (because I don't remember it exaclty):

   "The incidence of the condition under consideration and its subsequent death rate will 
both drop by 1/2 at the commencement of a study, and will not return to their former 
values until the study finishes or the PI retires."


Terry T.

---------------------------------------------------------------------------

On 07/10/2014 05:00 AM, r-help-request at r-project.org wrote:
> Hello All,
>
> I'm trying to figure out how to perform a survival analysis with an historical control. I've spent some time looking online and in my boooks but haven't found much showing how to do this. Was wondering if there is a R package that can do it, or if there are resources somewhere that show the actual steps one takes, or if some knowledgeable person might be willing to share some code.
>
> Here is a statement that describes the sort of analyis I'm being asked to do.
>
> A one-sample parametric test assuming an exponential form of survival was used to test the hypothesis that the treatment produces a median PFS no greater than the historical control PFS of 16 weeks.  A sample median PFS greater than 20.57 weeks would fall beyond the critical value associated with the null hypothesis, and would be considered statistically significant at alpha = .05, 1 tailed.
>
> My understanding is that the cutoff of 20.57 weeks was obtained using an online calculator that can be found at:
>
> http://www.swogstat.org/stat/public/one_survival.htm
>
> Thus far, I've been unable to determine what values were plugged into the calculator to get the cutoff.
>
> There's another calculator for a nonparamertric test that can be found at:
>
> http://www.swogstat.org/stat/public/one_nonparametric_survival.htm
>
> It would be nice to try doing this using both a parameteric and a non-parametric model.
>
> So my first question would be whether the approach outlined above is valid or if the analysis should be done some other way. If the basic idea is correct, is it relatively easy (for a Terry Therneau type genius) to implement the whole thing using R? The calculator is a great tool, but, if reasonable, it would be nice to be able to look at some code to see how the numbers actually get produced.


From lebatsnok at gmail.com  Thu Jul 10 15:53:54 2014
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Thu, 10 Jul 2014 16:53:54 +0300
Subject: [R] R on Windows crashes when source'ing UTF-8 file
In-Reply-To: <CAAJSdjiUFcnq+sfFzUJXUYBHnWbSrdbLXGDLGiTgHNrydG_F2A@mail.gmail.com>
References: <CAH7sKSPVJuJXm4ksJYn3XZVmz=6L68w=T-s0Li+En2Co9pm4Tg@mail.gmail.com>
	<CAAJSdjiUFcnq+sfFzUJXUYBHnWbSrdbLXGDLGiTgHNrydG_F2A@mail.gmail.com>
Message-ID: <CAH7sKSNaOoHnyYMJ8Wtg1K59OVYQHuFDH2Q=+fBfYLYC2YvrHg@mail.gmail.com>

Wow. Thanks a lot!

source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="UTF-8-BOM")
# works correctly on my Windows 7 machine
# (and without encoding argument it still crashes R)

Kenn

On Thu, Jul 10, 2014 at 4:33 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Thu, Jul 10, 2014 at 7:18 AM, Kenn Konstabel <lebatsnok at gmail.com> wrote:
>> Dear all,
>>
>> I found an unexpected behaviour when trying to `source` an utf-8 file
>> on windows 7:
>>
>> source("http://psych.ut.ee/~nek/R/test-utf8.txt")
>>
>> # Rgui.exe reacts:
>> # R for windows GUI has stopped working. A problem caused the program
>> to stop working correctly.
>> # Windows will close the program and notify you if a solution is available.
>>
>> The same will happen with R.exe ("terminal") and R running wihin
>> Rstudio. (Session and locale info below).
>>
>> However, a non-utf version of this little script can be `source`d
>> without problems.
>>
>> source("http://psych.ut.ee/~nek/R/test.txt")
>>
>> Adding the `encoding` argument to `source` helps a little:
>>
>> source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="utf-8")
>> #  unsure about the spelling of utf-8 so I also tried UTF8, utf8, and UTF-8
>> # ... with the same result in all cases
>>
>> R doesn't crash any more but gives the following error:
>>
>> # Error in source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding
>> = "utf-8") :
>> #   http://psych.ut.ee/~nek/R/test-utf8.txt:2:0: unexpected end of input
>> # 1: ?
>> #    ^
>> # In addition: Warning message:
>> # In readLines(file, warn = FALSE) :
>> #  invalid input found on input connection
>> 'http://psych.ut.ee/~nek/R/test-utf8.txt'
>
> I just tried that. On Windows XP/Pro,  R 3.1.0 didn't fail, but did
> get the error you mention later. I used "wget" to actually download
> the file mentioned (on Linux). I think that the problem _may_ be that
> the file starts with a BOM (Byte Order Mark), which is 0xef, 0xbb,
> 0xef . This is supposed to tell us that this is UTF-8.
>
> BOM: http://en.wikipedia.org/wiki/Byte_order_mark
>
> I get an identical error with R 3.1.0 on both Windows XP/Pro and Linux
> Fedora 20. The problem is that the R readLines() apparently does not
> like the leading BOM. It reads it as data. Most other Linux and
> Windows applications _do_ understand the BOM and so, when you use
> them, they work properly. And, normally, when you then save the file,
> the software does not write the BOM at the start. So it works on the
> saved version of the file.
>
> Being the curious sort, I decided to look at the source to R. In
> particular in ~/R/src/main/connections.c I saw where it did support
> the reading of BOMs. But there is a special way to do it! Which I
> cannot find in the documentation.
>
> source("http://psych.ut.ee/~nek/R/test-utf8.txt",encoding="UTF-8-BOM");
>
> I tried the above AND IT WORKED properly!
>
> I simply adore having source code.
>
>
>>
>> I thought maybe that's because what notepad told me is UTF-8 is
>> actually something else ... so I did two more experiments.
>>
>> source("http://psych.ut.ee/~nek/R/test2.R")
>> # this was created on a linux machine with leafpad, and saved as utf-8 text
>> # it can be source?d on windows
>>
>> source("http://psych.ut.ee/~nek/R/test3.R")
>> # the same as previous but o's in file were replaced by ?'s
>> # can be source'd on windows but the "?" character is shown as ??
>> # except if you add encoding="utf-8" - then, as expected, it works as expected
>>
>> So in sum, I can create "plain text" (saved with utf-8 encoding) files
>> on windows that cannot be sourced to R on windows, or will crash R
>> (depending on how you source them). The same files can be sourced on
>> linux without problems. Part of the problem is obviously in windows
>> but maybe R shouldn't at least crash.
>>
>> Session info:
>>
>>  R version 3.0.2 (2013-09-25)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=Estonian_Estonia.1257  LC_CTYPE=Estonian_Estonia.1257
>> [3] LC_MONETARY=Estonian_Estonia.1257 LC_NUMERIC=C
>> [5] LC_TIME=Estonian_Estonia.1257
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.2
>>
>>
>> OS: Windows 7
>>
>> Linux Mint Debian Edition and R 3.0.2 on the other machine (where
>> everything worked).
>>
>> Context:
>>
>> I was trying to find out how to make files that could be source'd on
>> both windows and linux. This is partly solved so I have no specific
>> question other than "is this a bug in windows version?" but any
>> comments on the general topic would be appreciated too.
>>
>> Best regards,
>>
>> Kenn
>>
>>
>> Kenn Konstabel
>> Research fellow
>> Department of chronic diseases
>> National Institute of Health Development
>> Hiiu 42
>> Tallinn
>> Estonia
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


From dcarlson at tamu.edu  Thu Jul 10 16:04:58 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 10 Jul 2014 14:04:58 +0000
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <53BE4D2F.40408@yorku.ca>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
	<53BE4D2F.40408@yorku.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F86F27@mb02.ads.tamu.edu>

In particular, look at the vegan Vignette, "Introduction to Ordination in vegan", particularly section 4 on constrained ordination which describes three approaches that seem relevant to your problem.

http://cran.r-project.org/web/packages/vegan/vignettes/intro-vegan.pdf

David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Friendly
Sent: Thursday, July 10, 2014 3:22 AM
To: Maria Judith Carmona H
Cc: r-help at r-project.org; John Fox
Subject: Re: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)

Maria

The variables 
Araceae,Begoniaceae,Bromeliaceae,Clusiaceae,Cyclanthaceae,Ericaceae,Gesneriaceae, 
Melastomataceae,Orchidaceae,Piperaceae,Pteridophyta
are frequencies (abundances?) of which most are 0 and this is not 
appropriate
as multivariate normal data.

There is probably a version of canonical analysis that takes such 
variables into account,
but I don't know specifically.  Have you looked at the vegan package and 
its references?

HTH
-Michael



On 10/07/2014 12:54 AM, Maria Judith Carmona H wrote:
> Dear John,
>
> I am including abundance values ??in my data set so obviously I have 
> zero abundances.
> The problem is that if plot only the factors (biomasa, altdosel, 
> altsoto, cobertura, riqarb, elevacion, temperatura, precipitacion) I 
> get the graphic, the same happen when I included only the families, 
> but I want to see the effect of all these factors+families on this 
> plot . In fact I included only certain families:
>
> prueba4 <- 
> lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
> Araceae,Begoniaceae,Bromeliaceae,Clusiaceae,Cyclanthaceae,Ericaceae,Gesneriaceae,
> Melastomataceae,Orchidaceae,Piperaceae,Pteridophyta) ~ sitio, 
> data=bosques.p)
> canprueba2 <- candisc(prueba2, term="sitio", data=bosques.p, ndim=1)
> Error in eigen (EHD, symmetric = TRUE): infinite or missing values ?? 
> in 'x'
> In addition: Warning message:
> In sqrt (wmd): NaNs produced
>
> You see I get the same error.
>
> Best regards,
> Judith
>
>
> On Wed, Jul 9, 2014 at 5:30 PM, John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>> wrote:
>
>     Dear Maria Judith Carmona Higuita,
>
>     Since you didn't include enough information (such as your access
>     to your data) to reproduce the error, one can only guess. My
>     guess: you have fewer observations in your data set than response
>     variables on the LHS of the multivariate linear model.
>
>     I hope this helps,
>      John
>
>     ------------------------------------------------
>     John Fox, Professor
>     McMaster University
>     Hamilton, Ontario, Canada
>     http://socserv.mcmaster.ca/jfox/
>
>     On Wed, 9 Jul 2014 11:36:35 -0500
>      Maria Judith Carmona H <juditycarmona at gmail.com
>     <mailto:juditycarmona at gmail.com>> wrote:
>     > Hi,
>     >
>     > I have a problem using the function Candisc from Candisc Package.
>     >
>     > bosques1<-read.csv("bosques1.csv",header=TRUE,encoding="latin1")
>     > bosques1<-na.exclude(bosques1)
>     > attach(bosques1)
>     >
>     > #Modelo de regresi?n
>     > mod <-
>     >
>     lm(cbind(biomasa,altdosel,altsoto,cobertura,riqarb,elevacion,temperatura,precipitacion,
>     >                 Acanthaceae, Apocinaceae, Araceae, Araliaceae,
>     Arecaceae,
>     > Aspleniaceae, Begoniaceae,
>     >                 Blechnaceae, Bromeliaceae, Clusiaceae,
>     Cyclanthaceae,
>     > Davalliaceae, Denstaedtiaceae,
>     >                 Dryopteridaceae, Ericaceae, Gesneriaceae,
>     Hymenophyllaceae,
>     > indet., Lauraceae, Lomariopsidaceae, Lycopodiaceae, Melastomataceae,
>     > Moraceae, Myrsinaceae, Ophioglossaceae,
>     >                 Orchidaceae, Peperomia, Piperaceae, Poaceae,
>     Polypodiaceae,
>     > Primulaceae, Pteridaceae,
>     >                 Pteridophyta.taxa, Rubiaceae, Vittariaceae) ~ sitio,
>     > data=bosques1)
>     > summary(mod)
>     >
>     > #Gr?fico 1
>     > can <- candisc(mod, term="sitio",data=bosques1,ndim=1,eig=T)
>     > ### The error happens here, so I can not run the plot.
>     > plot(can,titles.1d = c("Puntuaci?n can?nica", "Estructura"))
>     > summary(can, means = FALSE, scores = TRUE, coef = c("std"),
>     digits = 2)
>     >
>     > The error is:
>     > Error in eigen(eHe, symmetric = TRUE) : infinite or missing
>     values in 'x'
>     > In addition: Warning message:
>     > In sqrt(wmd) : NaNs produced
>     >
>     > Please help!
>     >
>     > --
>     > Maria Judith Carmona Higuita.
>     > Estudiante de Biolog?a - Universidad de Antioquia
>     > Medell?n - Colombia
>     >
>     > "La felicidad ocurre cuando encajas en tu vida, cuando encajas
>     > tan arm?nicamente que cualquier cosa que hagas es una alegr?a
>     para ti. De
>     > repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo
>     que haces,
>     > si amas la manera como vives, entonces ya est?s meditando y nada
>     puede
>     > distraerte." Osho
>     >
>     >       [[alternative HTML version deleted]]
>     >
>
>
>
>
>
>
>
> -- 
> Maria Judith Carmona Higuita.
> Estudiante de Biolog?a - Universidad de Antioquia
> Medell?n - Colombia
>
> "La felicidad ocurre cuando encajas en tu vida, cuando encajas 
> tan arm?nicamente que cualquier cosa que hagas es una alegr?a para ti. 
> De repente lo sabr?s y la meditaci?n te seguir?. Si amas el trabajo 
> que haces, si amas la manera como vives, entonces ya est?s meditando y 
> nada puede distraerte." Osho
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jul 10 16:18:04 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 10 Jul 2014 14:18:04 +0000
Subject: [R] function completing properly
In-Reply-To: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
References: <CAEqw1VyQ3yK0PdafV1RTy2dGqNnmmGuxCnf__8PrB3=V8oqTwg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDAF79@SRVEXCHMBX.precheza.cz>

Hi

Works for me after I commented uknown function cal.wyd

> version
               _
platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         Under development (unstable)
major          3
minor          1.0
year           2013
month          12
day            19
svn rev        64488
language       R
version.string R Under development (unstable) (2013-12-19 r64488)
nickname       Unsuffered Consequences


> mkdate = function(x) {
+ x$date = as.Date(paste(x$year, x$month, x$day, sep="-"))
+ x$wy = ifelse(x$month >=10, x$year+1, x$year)
+ x$yd = as.integer(format(as.Date(x$date), format="%j"))
+ #x$wyd = cal.wyd(x)
+ x
+ }
>
> test<-data.frame(year=2000, month=10, day=5)
> test
  year month day
1 2000    10   5
> mkdate(test)
  year month day       date   wy  yd
1 2000    10   5 2000-10-05 2001 279
> test<-mkdate(test)
> test
  year month day       date   wy  yd
1 2000    10   5 2000-10-05 2001 279
>

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Janet Choate
> Sent: Thursday, July 10, 2014 1:48 AM
> To: r-help at r-project.org
> Subject: [R] function completing properly
>
> Hi R community,
> i created a function (mkdate) as follows:
>
> mkdate = function(x) {
> x$date = as.Date(paste(x$year, x$month, x$day, sep="-"))
> x$wy = ifelse(x$month >=10, x$year+1, x$year)
> x$yd = as.integer(format(as.Date(x$date), format="%j"))
> x$wyd = cal.wyd(x)
> x
> }
>
> the function results in adding the new columns date, wy, yd, and wyd to
> the
> table i apply it to.
> this has always worked in R version 2.14.2.
> however, in R version 3.1.0 - instead of my mkdate function adding
> those
> columns to my existing table, it just overwrites my table and leaves me
> with just a list of the last variable created by my mkdate function. so
> i
> end up with just a list of numbers representing wyd, and lose all the
> data
> in my original table.
>
> does anyone know what would now be causing this to occur, and what i
> need
> to do to make my function work properly again?
>
> thank you for any assistance,
> Janet
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jvadams at usgs.gov  Thu Jul 10 16:31:50 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 10 Jul 2014 09:31:50 -0500
Subject: [R] Decision Tree
In-Reply-To: <CANtKHPWVRwyVaT5AMCoT=q8jynV8rYX_79jdkTGpAxqAT8o7DA@mail.gmail.com>
References: <CANtKHPWVRwyVaT5AMCoT=q8jynV8rYX_79jdkTGpAxqAT8o7DA@mail.gmail.com>
Message-ID: <CAN5YmCEPeg5A0XOsn8MQz2Ma2D5aW-Qvsk5a8YC7e6AomgPCOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/1eff6177/attachment.pl>

From john.archie.mckown at gmail.com  Thu Jul 10 16:50:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 10 Jul 2014 09:50:58 -0500
Subject: [R] list of valid R encodings.in source(...,encoding=)
Message-ID: <CAAJSdjhOoE1Kg6ivOwdbJ77KzmwGWNY6F+5nrFmbPjcHSgtb5Q@mail.gmail.com>

This question was spawned by another thread entitled "R on Windows
crashes when source'ing UTF-8 file".

The solution to that problem was to use the _proper_ encoding=
parameter of the source() function. But where are they documented? Or
how do I find them in R itself? I ask because the proper encoding to
solve the problem was "UTF-8-BOM". I got this by reading the source
code to main/connnections.c . Not where I expect most people to go.

I found iconvlist(). But it does not list UTF-8-BOM, only UTF8 and
UTF-8. I got no useful response to ??BOM from the R prompt.

My normal locale is "C" on Linux. If I use encoding="UTF-8" in the
source() line, it fails because the BOM at the start is intepreted as
data to be processed. If I use UTF-8-BOM instead, it succeeds. It also
succeeds if I do Sys.setlocale("LC_ALL","en_US.utf8").

I admit that I don't understand all (or even much) of the ins-and-outs
of i10n, or code pages. But the UTF-8-BOM is just "weird" to me; and
confusing since it is not documented anywhere I can find.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From murdoch.duncan at gmail.com  Thu Jul 10 16:50:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Jul 2014 10:50:58 -0400
Subject: [R] R on Windows crashes when source'ing UTF-8 file
In-Reply-To: <CAH7sKSNaOoHnyYMJ8Wtg1K59OVYQHuFDH2Q=+fBfYLYC2YvrHg@mail.gmail.com>
References: <CAH7sKSPVJuJXm4ksJYn3XZVmz=6L68w=T-s0Li+En2Co9pm4Tg@mail.gmail.com>	<CAAJSdjiUFcnq+sfFzUJXUYBHnWbSrdbLXGDLGiTgHNrydG_F2A@mail.gmail.com>
	<CAH7sKSNaOoHnyYMJ8Wtg1K59OVYQHuFDH2Q=+fBfYLYC2YvrHg@mail.gmail.com>
Message-ID: <53BEA852.80002@gmail.com>

On 10/07/2014 9:53 AM, Kenn Konstabel wrote:
> Wow. Thanks a lot!
>
> source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="UTF-8-BOM")
> # works correctly on my Windows 7 machine
> # (and without encoding argument it still crashes R)
>
> Kenn
>
> On Thu, Jul 10, 2014 at 4:33 PM, John McKown
> <john.archie.mckown at gmail.com> wrote:
> > On Thu, Jul 10, 2014 at 7:18 AM, Kenn Konstabel <lebatsnok at gmail.com> wrote:
> >> Dear all,
> >>
> >> I found an unexpected behaviour when trying to `source` an utf-8 file
> >> on windows 7:
> >>
> >> source("http://psych.ut.ee/~nek/R/test-utf8.txt")
> >>
> >> # Rgui.exe reacts:
> >> # R for windows GUI has stopped working. A problem caused the program
> >> to stop working correctly.
> >> # Windows will close the program and notify you if a solution is available.
> >>
> >> The same will happen with R.exe ("terminal") and R running wihin
> >> Rstudio. (Session and locale info below).
> >>
> >> However, a non-utf version of this little script can be `source`d
> >> without problems.
> >>
> >> source("http://psych.ut.ee/~nek/R/test.txt")
> >>
> >> Adding the `encoding` argument to `source` helps a little:
> >>
> >> source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="utf-8")
> >> #  unsure about the spelling of utf-8 so I also tried UTF8, utf8, and UTF-8
> >> # ... with the same result in all cases
> >>
> >> R doesn't crash any more but gives the following error:
> >>
> >> # Error in source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding
> >> = "utf-8") :
> >> #   http://psych.ut.ee/~nek/R/test-utf8.txt:2:0: unexpected end of input
> >> # 1: ?
> >> #    ^
> >> # In addition: Warning message:
> >> # In readLines(file, warn = FALSE) :
> >> #  invalid input found on input connection
> >> 'http://psych.ut.ee/~nek/R/test-utf8.txt'
> >
> > I just tried that. On Windows XP/Pro,  R 3.1.0 didn't fail, but did
> > get the error you mention later. I used "wget" to actually download
> > the file mentioned (on Linux). I think that the problem _may_ be that
> > the file starts with a BOM (Byte Order Mark), which is 0xef, 0xbb,
> > 0xef . This is supposed to tell us that this is UTF-8.
> >
> > BOM: http://en.wikipedia.org/wiki/Byte_order_mark
> >
> > I get an identical error with R 3.1.0 on both Windows XP/Pro and Linux
> > Fedora 20. The problem is that the R readLines() apparently does not
> > like the leading BOM. It reads it as data. Most other Linux and
> > Windows applications _do_ understand the BOM and so, when you use
> > them, they work properly. And, normally, when you then save the file,
> > the software does not write the BOM at the start. So it works on the
> > saved version of the file.
> >
> > Being the curious sort, I decided to look at the source to R. In
> > particular in ~/R/src/main/connections.c I saw where it did support
> > the reading of BOMs. But there is a special way to do it! Which I
> > cannot find in the documentation.
> >
> > source("http://psych.ut.ee/~nek/R/test-utf8.txt",encoding="UTF-8-BOM");
> >
> > I tried the above AND IT WORKED properly!
> >
> > I simply adore having source code.

Searching the source for the string "UTF-8-BOM" finds it mentioned in 
the docs in 3 places:  in the NEWS file,
in the R Data Import/Export manual, and in the ?connections help page.

Duncan Murdoch

> >
> >
> >>
> >> I thought maybe that's because what notepad told me is UTF-8 is
> >> actually something else ... so I did two more experiments.
> >>
> >> source("http://psych.ut.ee/~nek/R/test2.R")
> >> # this was created on a linux machine with leafpad, and saved as utf-8 text
> >> # it can be source?d on windows
> >>
> >> source("http://psych.ut.ee/~nek/R/test3.R")
> >> # the same as previous but o's in file were replaced by ?'s
> >> # can be source'd on windows but the "?" character is shown as ??
> >> # except if you add encoding="utf-8" - then, as expected, it works as expected
> >>
> >> So in sum, I can create "plain text" (saved with utf-8 encoding) files
> >> on windows that cannot be sourced to R on windows, or will crash R
> >> (depending on how you source them). The same files can be sourced on
> >> linux without problems. Part of the problem is obviously in windows
> >> but maybe R shouldn't at least crash.
> >>
> >> Session info:
> >>
> >>  R version 3.0.2 (2013-09-25)
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=Estonian_Estonia.1257  LC_CTYPE=Estonian_Estonia.1257
> >> [3] LC_MONETARY=Estonian_Estonia.1257 LC_NUMERIC=C
> >> [5] LC_TIME=Estonian_Estonia.1257
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >> loaded via a namespace (and not attached):
> >> [1] tools_3.0.2
> >>
> >>
> >> OS: Windows 7
> >>
> >> Linux Mint Debian Edition and R 3.0.2 on the other machine (where
> >> everything worked).
> >>
> >> Context:
> >>
> >> I was trying to find out how to make files that could be source'd on
> >> both windows and linux. This is partly solved so I have no specific
> >> question other than "is this a bug in windows version?" but any
> >> comments on the general topic would be appreciated too.
> >>
> >> Best regards,
> >>
> >> Kenn
> >>
> >>
> >> Kenn Konstabel
> >> Research fellow
> >> Department of chronic diseases
> >> National Institute of Health Development
> >> Hiiu 42
> >> Tallinn
> >> Estonia
> >
> > --
> > There is nothing more pleasant than traveling and meeting new people!
> > Genghis Khan
> >
> > Maranatha! <><
> > John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From juditycarmona at gmail.com  Thu Jul 10 17:10:24 2014
From: juditycarmona at gmail.com (Maria Judith Carmona H)
Date: Thu, 10 Jul 2014 10:10:24 -0500
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F86F27@mb02.ads.tamu.edu>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>
	<web-518038008@cgpsrv2.cis.mcmaster.ca>
	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>
	<53BE4D2F.40408@yorku.ca>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F86F27@mb02.ads.tamu.edu>
Message-ID: <CAAweS98OXE8i8-_Lx5x4gThd=2f2ESu1KmTitZ0YrHs31KMsHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/694d2693/attachment.pl>

From wdunlap at tibco.com  Thu Jul 10 17:23:52 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 10 Jul 2014 08:23:52 -0700
Subject: [R] find & remove sequences of at least N values for a specific
	value
In-Reply-To: <1404995662430-4693810.post@n4.nabble.com>
References: <1404995662430-4693810.post@n4.nabble.com>
Message-ID: <CAF8bMcYg84j8OgtpiJdPrATEwE0k3fv5PrnnSzz1QSHe0kMEjw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/2e01af57/attachment.pl>

From pjmiller_57 at yahoo.com  Thu Jul 10 18:11:40 2014
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Thu, 10 Jul 2014 09:11:40 -0700
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <27747b$8u1e0k@ironport10.mayo.edu>
Message-ID: <1405008700.27847.YahooMailBasic@web140205.mail.bf1.yahoo.com>

Hi Dr. Therneau,

Thanks for your response. This is very helpful.

My historical control value is 16 weeks. I've been having some trouble though determining how this value was obtained. Are you able to indicate how people normally go about determining a value for the historical control? Or do you have an view on how it ought to be done? 

It does seem like selecting an appropriate value is extremely important. Otherwise the results obtained from the analysis are likely to be nonsense. 

Thanks,

Paul

--------------------------------------------
On Thu, 7/10/14, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:

 Subject: Re: Survival Analysis with an Historical Control
 To: r-help at r-project.org, "Andrews, Chris" <chrisaa at med.umich.edu>, pjmill
 Received: Thursday, July 10, 2014, 8:52 AM

 You are asking for a one sample
 test.? Using your own data:

 connection <- textConnection("
 GD2? 1???8 12? GD2? 3 -12
 10? GD2? 6 -52? 7
 GD2? 7? 28 10? GD2? 8? 44?
 6? GD2 10? 14? 8
 GD2 12???3? 8? GD2 14 -52?
 9? GD2 15? 35 11
 GD2 18???6 13? GD2 20? 12?
 7? GD2 23? -7 13
 GD2 24 -52? 9? GD2 26 -52 12? GD2 28? 36
 13
 GD2 31 -52? 8? GD2 33???9 10?
 GD2 34 -11 16
 GD2 36 -52? 6? GD2 39? 15 14? GD2
 40? 13 13
 GD2 42? 21 13? GD2 44 -24 16? GD2 46 -52 13
 GD2 48? 28? 9? GD2? 2? 15?
 9? GD2? 4 -44 10
 GD2? 5? -2 12? GD2?
 9???8? 7? GD2 11? 12? 7
 GD2 13 -52? 7? GD2 16? 21? 7? GD2
 17? 19 11
 GD2 19???6 16? GD2 21? 10 16?
 GD2 22 -15? 6
 GD2 25???4 15? GD2 27? -9?
 9? GD2 29? 27 10
 GD2 30???1 17? GD2 32? 12?
 8? GD2 35? 20? 8
 GD2 37 -32? 8? GD2 38? 15? 8? GD2
 41???5 14
 GD2 43? 35 13? GD2 45? 28? 9? GD2
 47???6 15
 ")

 hsv <- data.frame(scan(connection, list(vac="", pat=0,
 wks=0, x=0)))
 hsv <- transform(hsv, status= (wks >0), wks =
 abs(wks))

 fit1 <- survreg(Surv(wks, status) ~ 1, data=hsv,
 dist='exponential')
 temp <- predict(fit1, type='quantile', p=.5, se=TRUE)

 c(median= temp$fit[1], std= temp$se[1])
 ???median? ? std
 24.32723? 4.36930

 --
 The predict function gives the predicted median survival and
 standard deviation for each 
 observation in the data set.? Since this was a mean
 only model all n of them are the same 
 and I printed only the first.
 For prediction they make the assumption that the std error
 for my future study will be the 
 same as the std from this one, you want the future 95% CI to
 not include the value of 16, 
 so the future mean will need to be at least 16 + 1.96*
 4.369.

 A nonparmetric version of the argument would be

 > fit2 <- survfit(Surv(wks, status) ~ 1, data=hsv)
 > print(fit2)
 records???n.max n.start? events?
 median 0.95LCL 0.95UCL
 ? ? ? 48? ? ? 48? ?
 ? 48? ? ? 31? ? ?
 21? ? ? 15? ? ? 35

 Then make the argument that in our future study, the 95% CI
 will stretch 6 units to the 
 left of the median, just like it did here.? This
 argument is a bit more tenuous though. 
 The exponential CI width depends on the total number of
 events and total follow-up time, 
 and we can guess that the new study will be similar.?
 The Kaplan-Meier CI also depends on 
 the spacing of the deaths, which is less likely to
 replicate.

 Notes:
 ? 1. Use summary(fit2)$table to extract the CI
 values.? In R the print functions don't 
 allow you to "grab" what was printed, summary normally
 does.
 ? 2. For the exponential we could work out the formula
 in closed form -- a good homework 
 exercise for grad students perhaps but not an exciting way
 to spend my own afternoon.? An 
 advantage of the above approach is that we can easily use a
 more realistic model like the 
 weibull.
 ? 3. I've never liked extracting out the "Surv(t,s)"
 part of a formula as a separate 
 statement on another line.? If I ever need to read this
 code again, or even just the 
 printout from the run, keeping it all together gives much
 better documentation.
 ? 4. Future calculations for survival data, of any
 form, are always tenuous since they 
 depend critically on the total number of events that will be
 in the future study.? We can 
 legislate the total enrollment and follow-up time for that
 future study, but the number of 
 events is never better than a guess.? Paraphrasing a
 motto found on the door of a well 
 respected investigator I worked with 30 years ago (because I
 don't remember it exaclty):

 ???"The incidence of the condition under
 consideration and its subsequent death rate will 
 both drop by 1/2 at the commencement of a study, and will
 not return to their former 
 values until the study finishes or the PI retires."


 Terry T.

 ---------------------------------------------------------------------------

 On 07/10/2014 05:00 AM, r-help-request at r-project.org
 wrote:
 > Hello All,
 >
 > I'm trying to figure out how to perform a survival
 analysis with an historical control. I've spent some time
 looking online and in my boooks but haven't found much
 showing how to do this. Was wondering if there is a R
 package that can do it, or if there are resources somewhere
 that show the actual steps one takes, or if some
 knowledgeable person might be willing to share some code.
 >
 > Here is a statement that describes the sort of analyis
 I'm being asked to do.
 >
 > A one-sample parametric test assuming an exponential
 form of survival was used to test the hypothesis that the
 treatment produces a median PFS no greater than the
 historical control PFS of 16 weeks.? A sample median
 PFS greater than 20.57 weeks would fall beyond the critical
 value associated with the null hypothesis, and would be
 considered statistically significant at alpha = .05, 1
 tailed.
 >
 > My understanding is that the cutoff of 20.57 weeks was
 obtained using an online calculator that can be found at:
 >
 > http://www.swogstat.org/stat/public/one_survival.htm
 >
 > Thus far, I've been unable to determine what values
 were plugged into the calculator to get the cutoff.
 >
 > There's another calculator for a nonparamertric test
 that can be found at:
 >
 > http://www.swogstat.org/stat/public/one_nonparametric_survival.htm
 >
 > It would be nice to try doing this using both a
 parameteric and a non-parametric model.
 >
 > So my first question would be whether the approach
 outlined above is valid or if the analysis should be done
 some other way. If the basic idea is correct, is it
 relatively easy (for a Terry Therneau type genius) to
 implement the whole thing using R? The calculator is a great
 tool, but, if reasonable, it would be nice to be able to
 look at some code to see how the numbers actually get
 produced.


From jgrn at illinois.edu  Thu Jul 10 19:03:30 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 10 Jul 2014 12:03:30 -0500
Subject: [R] table over a matrix dimension...
Message-ID: <CABG0rfuP6YDHzD=f1mfaJtkM0HvBdkqf7apcvSDXTuOJ7GEkVw@mail.gmail.com>

R-helpers:

I'm trying to determine the frequency of characters for a matrix
applied to a single dimension, and generate a matrix as an output.
I've come up with a solution, but it appears inelegant -- I was
wondering if there is an easier way to accomplish this task:

# Create a matrix of "factors" (characters):
random_characters=matrix(sample(letters[1:4],1000,replace=TRUE),100,10)

# Applying with the table() function doesn't work properly, because not all rows
# have ALL of the factors, so I get a list output:
apply(random_characters,1,table)

# Hacked solution:
unique_values = letters[1:4]

countsmatrix <- t(apply(random_characters,1,function(x,unique_values)
{
counts=vector(length=length(unique_values))
for(i in seq(unique_values))
{
counts[i] = sum(x==unique_values[i])
}
return(counts)
},
unique_values=unique_values
))

# Gets me the output I want but requires two nested loops (apply and
for() ), so
# not efficient for very large datasets.

###

Is there a more elegant solution to this?

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From marc_schwartz at me.com  Thu Jul 10 19:50:13 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 10 Jul 2014 12:50:13 -0500
Subject: [R] table over a matrix dimension...
In-Reply-To: <CABG0rfuP6YDHzD=f1mfaJtkM0HvBdkqf7apcvSDXTuOJ7GEkVw@mail.gmail.com>
References: <CABG0rfuP6YDHzD=f1mfaJtkM0HvBdkqf7apcvSDXTuOJ7GEkVw@mail.gmail.com>
Message-ID: <C11C23DB-1B6C-4768-8B64-69311393BB87@me.com>


On Jul 10, 2014, at 12:03 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:

> R-helpers:
> 
> I'm trying to determine the frequency of characters for a matrix
> applied to a single dimension, and generate a matrix as an output.
> I've come up with a solution, but it appears inelegant -- I was
> wondering if there is an easier way to accomplish this task:
> 
> # Create a matrix of "factors" (characters):
> random_characters=matrix(sample(letters[1:4],1000,replace=TRUE),100,10)
> 
> # Applying with the table() function doesn't work properly, because not all rows
> # have ALL of the factors, so I get a list output:
> apply(random_characters,1,table)
> 
> # Hacked solution:
> unique_values = letters[1:4]
> 
> countsmatrix <- t(apply(random_characters,1,function(x,unique_values)
> {
> counts=vector(length=length(unique_values))
> for(i in seq(unique_values))
> {
> counts[i] = sum(x==unique_values[i])
> }
> return(counts)
> },
> unique_values=unique_values
> ))
> 
> # Gets me the output I want but requires two nested loops (apply and
> for() ), so
> # not efficient for very large datasets.
> 
> ###
> 
> Is there a more elegant solution to this?
> 
> --j
> 


If I am correctly understanding your issue, you simply need to coerce the input to table() to a factor with a common set of levels, since the matrix will be 'character' by default:


set.seed(1)
random_characters <- matrix(sample(factor(letters[1:4]), 1000, replace = TRUE), 100, 10)

> random_characters 
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
  [1,] "b"  "c"  "b"  "c"  "c"  "c"  "d"  "d"  "d"  "d"  
  [2,] "b"  "b"  "a"  "a"  "a"  "c"  "d"  "d"  "a"  "d"  
  [3,] "c"  "b"  "c"  "b"  "d"  "c"  "a"  "d"  "d"  "b"  
  [4,] "d"  "d"  "b"  "b"  "d"  "c"  "c"  "c"  "c"  "a"  
  [5,] "a"  "c"  "a"  "b"  "d"  "b"  "d"  "c"  "b"  "a"  
  [6,] "d"  "a"  "c"  "d"  "c"  "d"  "d"  "a"  "c"  "a"  
  [7,] "d"  "a"  "c"  "a"  "b"  "b"  "b"  "b"  "b"  "a"  
  [8,] "c"  "b"  "a"  "d"  "d"  "d"  "b"  "c"  "d"  "a"  
  [9,] "c"  "d"  "b"  "a"  "a"  "d"  "d"  "d"  "b"  "a"  
 [10,] "a"  "c"  "c"  "b"  "d"  "c"  "a"  "c"  "a"  "a"  
 [11,] "a"  "d"  "d"  "a"  "d"  "d"  "d"  "c"  "b"  "c"  
 [12,] "a"  "c"  "a"  "a"  "b"  "b"  "b"  "b"  "b"  "d"  
 [13,] "c"  "b"  "d"  "d"  "c"  "a"  "c"  "a"  "b"  "c"  
 [14,] "b"  "b"  "d"  "c"  "d"  "c"  "c"  "d"  "d"  "a"  
 [15,] "d"  "a"  "d"  "b"  "c"  "c"  "c"  "b"  "b"  "a"  
 [16,] "b"  "a"  "b"  "b"  "b"  "a"  "b"  "b"  "c"  "b"  
 [17,] "c"  "c"  "c"  "a"  "b"  "c"  "a"  "a"  "d"  "a"  
 [18,] "d"  "a"  "d"  "b"  "b"  "c"  "b"  "a"  "d"  "c" 
 ...


RES <- t(apply(random_characters, 1, 
               function(x) table(factor(x, levels = letters[1:4]))))

> RES
       a b c d
  [1,] 0 2 4 4
  [2,] 4 2 1 3
  [3,] 1 3 3 3
  [4,] 1 2 4 3
  [5,] 3 3 2 2
  [6,] 3 0 3 4
  [7,] 3 5 1 1
  [8,] 2 2 2 4
  [9,] 3 2 1 4
 [10,] 4 1 4 1
 [11,] 2 1 2 5
 [12,] 3 5 1 1
 [13,] 2 2 4 2
 [14,] 1 2 3 4
 [15,] 2 3 3 2
 [16,] 2 7 1 0
 [17,] 4 1 4 1
 [18,] 2 3 2 3
 ...



Regards,

Marc Schwartz


From wdunlap at tibco.com  Thu Jul 10 20:09:04 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 10 Jul 2014 11:09:04 -0700
Subject: [R] table over a matrix dimension...
In-Reply-To: <CABG0rfuP6YDHzD=f1mfaJtkM0HvBdkqf7apcvSDXTuOJ7GEkVw@mail.gmail.com>
References: <CABG0rfuP6YDHzD=f1mfaJtkM0HvBdkqf7apcvSDXTuOJ7GEkVw@mail.gmail.com>
Message-ID: <CAF8bMcYs8pqW6mXTXVEVKV7Qut4xnuFw4Q54EbT3vJBgdwigew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140710/947fe02b/attachment.pl>

From atramon at ncsu.edu  Thu Jul 10 15:49:21 2014
From: atramon at ncsu.edu (atramon)
Date: Thu, 10 Jul 2014 06:49:21 -0700 (PDT)
Subject: [R] nScree
Message-ID: <1405000161722-4693815.post@n4.nabble.com>

I'm trying to determine the number of factors to extract for a factor
analysis, but am having trouble with the nS/nScree function.  I did this
successfully earlier today but with the wrong matrix/dataframe, and for some
reason it won't work with the corrected one even though I've entered the
same call.

attmott is the matrix:

attmott<-read.table(file.choose(), header=F, sep=",",)
> attmott<-as.matrix(attmott)
> dim(attmott)
[1] 18 41
> ev<-eigen(cor(attmott))
> ap<-parallel(subject=ncol(attmott), var=nrow(attmott), rep=100, cent=.05)
> nS<-nScree(x=ev$values, aparallel=ap$eigen$qevpea)
Error in while ((cond1 == TRUE) && (cond2 == TRUE) && (i < nk)) { : 
  missing value where TRUE/FALSE needed


I'm not sure what this error message means...  I tried entering
nS<-nScree(x=ev$values, cor=TRUE, aparallel=ap$eigen$qevpea) but that did
not help, nor did replacing all the 0's with NA.


Any help would be greatly appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/nScree-tp4693815.html
Sent from the R help mailing list archive at Nabble.com.


From pjmiller_57 at yahoo.com  Thu Jul 10 14:58:32 2014
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Thu, 10 Jul 2014 05:58:32 -0700
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <30411786F64EEF46856EFBA2CD9177992C2D7190@UHEXMBSPR03.umhs.med.umich.edu>
Message-ID: <1404997112.53151.YahooMailBasic@web140202.mail.bf1.yahoo.com>


Hi Chris,

Thanks for pointing out the use of "View page source". Very helpful to know.

Do you happen to know anything about how to perform the analysis itself? I haven't been able to find anything confirming that the approach described in my original email (below) is correct. 

Thanks,

Paul

--------------------------------------------
On Wed, 7/9/14, Andrews, Chris <chrisaa at med.umich.edu> wrote:

 Subject: RE: [R] Survival Analysis with an Historical Control

r-project.org>
 Received: Wednesday, July 9, 2014, 11:26 AM

 The code is actually
 available at the websites you provide.? Try "View page
 source" in your browser.? The most cryptic code
 isn't needed because the math functions (e.g, incomplete
 gamma function) are available in R.


 -----Original Message-----


 Sent: Tuesday, July 08, 2014 12:00 PM
 To: r-help at r-project.org
 Subject: [R] Survival Analysis with an
 Historical Control

 Hello
 All,

 I'm trying to
 figure out how to perform a survival analysis with an
 historical control. I've spent some time looking online
 and in my boooks but haven't found much showing how to
 do this. Was wondering if there is a R package that can do
 it, or if there are resources somewhere that show the actual
 steps one takes, or if some knowledgeable person might be
 willing to share some code. 

 Here is a statement that describes the sort of
 analyis I'm being asked to do.

 A one-sample parametric test assuming an
 exponential form of survival was used to test the hypothesis
 that the treatment produces a median PFS no greater than the
 historical control PFS of 16 weeks.? A sample median PFS
 greater than 20.57 weeks would fall beyond the critical
 value associated with the null hypothesis, and would be
 considered statistically significant at alpha = .05, 1
 tailed.? 

 My understanding
 is that the cutoff of 20.57 weeks was obtained using an
 online calculator that can be found at:

 http://www.swogstat.org/stat/public/one_survival.htm

 Thus far, I've been unable
 to determine what values were plugged into the calculator to
 get the cutoff.

 There's
 another calculator for a nonparamertric test that can be
 found at:

 http://www.swogstat.org/stat/public/one_nonparametric_survival.htm

 It would be nice to try doing
 this using both a parameteric and a non-parametric model.

 So my first question would be
 whether the approach outlined above is valid or if the
 analysis should be done some other way. If the basic idea is
 correct, is it relatively easy (for a Terry Therneau type
 genius) to implement the whole thing using R? The calculator
 is a great tool, but, if reasonable, it would be nice to be
 able to look at some code to see how the numbers actually
 get produced.

 Below are
 some sample survival data and code in case this proves
 helpful.

 Thanks,

 Paul

 ###################################
 #### Example Data: GD2 Vaccine ####
 ###################################

 connection <-
 textConnection("
 GD2? 1???8
 12? GD2? 3 -12 10? GD2? 6 -52? 7
 GD2?
 7? 28 10? GD2? 8? 44? 6? GD2 10? 14? 8
 GD2 12???3? 8? GD2 14 -52? 9?
 GD2 15? 35 11
 GD2 18???6 13?
 GD2 20? 12? 7? GD2 23? -7 13
 GD2 24
 -52? 9? GD2 26 -52 12? GD2 28? 36 13
 GD2
 31 -52? 8? GD2 33???9 10? GD2 34 -11 16
 GD2 36 -52? 6? GD2 39? 15 14? GD2 40? 13
 13
 GD2 42? 21 13? GD2 44 -24 16? GD2 46
 -52 13
 GD2 48? 28? 9? GD2? 2? 15? 9?
 GD2? 4 -44 10
 GD2? 5? -2 12? GD2?
 9???8? 7? GD2 11? 12? 7
 GD2
 13 -52? 7? GD2 16? 21? 7? GD2 17? 19 11
 GD2 19???6 16? GD2 21? 10 16? GD2
 22 -15? 6
 GD2 25???4 15? GD2
 27? -9? 9? GD2 29? 27 10
 GD2
 30???1 17? GD2 32? 12? 8? GD2 35? 20? 8
 GD2 37 -32? 8? GD2 38? 15? 8? GD2
 41???5 14
 GD2 43? 35 13? GD2
 45? 28? 9? GD2 47???6 15
 ")

 hsv
 <- data.frame(scan(connection, list(VAC="",
 PAT=0, WKS=0, X=0)))
 hsv <-
 transform(hsv, CENS=ifelse(WKS < 1, 1, 0),
 WKS=abs(WKS))
 head(hsv)

 require("survival")

 survObj <- Surv(hsv$WKS,
 hsv$CENS==0) ~ 1

 km <-
 survfit(survObj, type=c("kaplan-meier"))
 print(km)

 paraExp <- survreg(survObj,
 dist="exponential")
 print(paraExp)


 **********************************************************
 Electronic Mail is not secure, may not be read
 every day, and should not be used for urgent or sensitive
 issues 


From santec at riseup.net  Thu Jul 10 21:34:10 2014
From: santec at riseup.net (Federico Razzoli)
Date: Thu, 10 Jul 2014 21:34:10 +0200
Subject: [R] Installing RMySQL on Debian
Message-ID: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>

Hello. I am trying to install RMySQL. My Os is Debian and I have MariaDB
installed from the tar package (not deb). After downloading RMySQL, I ran
the following commands, and I see DONE. Hoewever, I don't think that the
package is installed, because the dbConnect() function cannot be found.
Probably I'm not passing R the correct paths, but then what paths should I
pass?


root at this:/tmp# export PKG_CPPFLAGS="-I/usr/local/mysql/include/mysql"
root at this:/tmp# export PKG_LIBS="-L/usr/local/mysql/lib -lmysqlclient"
root at this:/tmp# R CMD INSTALL /tmp/RMySQL_0.9-3.tar.gz
* installing to library ?/usr/local/lib/R/site-library?
* installing *source* package ?RMySQL? ...
** package ?RMySQL? successfully unpacked and MD5 sums checked
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... no
checking for egrep... grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking mysql.h usability... no
checking mysql.h presence... no
checking for mysql.h... no
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG
-I/usr/local/mysql/include/mysql     -fpic  -O2 -pipe -g  -c RS-DBI.c -o
RS-DBI.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG
-I/usr/local/mysql/include/mysql     -fpic  -O2 -pipe -g  -c RS-MySQL.c -o
RS-MySQL.o
gcc -std=gnu99 -shared -o RMySQL.so RS-DBI.o RS-MySQL.o
-L/usr/local/mysql/lib -lmysqlclient -lz -L/usr/lib/R/lib -lR
installing to /usr/local/lib/R/site-library/RMySQL/libs
** R
** inst
** preparing package for lazy loading
Creating a generic function for ?format? from package ?base? in package
?RMySQL?
Creating a generic function for ?print? from package ?base? in package
?RMySQL?
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded

* DONE (RMySQL)


Thank you in advance
Federico


From sarah.goslee at gmail.com  Thu Jul 10 21:58:38 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 10 Jul 2014 15:58:38 -0400
Subject: [R] Installing RMySQL on Debian
In-Reply-To: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>
References: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>
Message-ID: <CAM_vjum==pVz8enH9BupESrDkhz3ZJcQKJM4r2_X5u+n6mTAQA@mail.gmail.com>

Hi,

On Thu, Jul 10, 2014 at 3:34 PM, Federico Razzoli <santec at riseup.net> wrote:
> Hello. I am trying to install RMySQL. My Os is Debian and I have MariaDB
> installed from the tar package (not deb). After downloading RMySQL, I ran
> the following commands, and I see DONE. Hoewever, I don't think that the
> package is installed, because the dbConnect() function cannot be found.
> Probably I'm not passing R the correct paths, but then what paths should I
> pass?

Just to check, are you loading the package using

library(RMySQL)

before trying to use it?

If so, is it giving you any errors?

Sarah

>
>
> root at this:/tmp# export PKG_CPPFLAGS="-I/usr/local/mysql/include/mysql"
> root at this:/tmp# export PKG_LIBS="-L/usr/local/mysql/lib -lmysqlclient"
> root at this:/tmp# R CMD INSTALL /tmp/RMySQL_0.9-3.tar.gz
> * installing to library ?/usr/local/lib/R/site-library?
> * installing *source* package ?RMySQL? ...
> ** package ?RMySQL? successfully unpacked and MD5 sums checked
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... no
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mysql.h usability... no
> checking mysql.h presence... no
> checking for mysql.h... no
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG
> -I/usr/local/mysql/include/mysql     -fpic  -O2 -pipe -g  -c RS-DBI.c -o
> RS-DBI.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG
> -I/usr/local/mysql/include/mysql     -fpic  -O2 -pipe -g  -c RS-MySQL.c -o
> RS-MySQL.o
> gcc -std=gnu99 -shared -o RMySQL.so RS-DBI.o RS-MySQL.o
> -L/usr/local/mysql/lib -lmysqlclient -lz -L/usr/lib/R/lib -lR
> installing to /usr/local/lib/R/site-library/RMySQL/libs
> ** R
> ** inst
> ** preparing package for lazy loading
> Creating a generic function for ?format? from package ?base? in package
> ?RMySQL?
> Creating a generic function for ?print? from package ?base? in package
> ?RMySQL?
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
>
> * DONE (RMySQL)
>
>
> Thank you in advance
> Federico
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From santec at riseup.net  Thu Jul 10 22:07:23 2014
From: santec at riseup.net (Federico Razzoli)
Date: Thu, 10 Jul 2014 22:07:23 +0200
Subject: [R] Installing RMySQL on Debian
In-Reply-To: <CAM_vjum==pVz8enH9BupESrDkhz3ZJcQKJM4r2_X5u+n6mTAQA@mail.gmail.com>
References: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>
	<CAM_vjum==pVz8enH9BupESrDkhz3ZJcQKJM4r2_X5u+n6mTAQA@mail.gmail.com>
Message-ID: <d0ce50a1920c2d179c51e6f769f360cf.squirrel@fruiteater.riseup.net>

> Just to check, are you loading the package using
>
> library(RMySQL)
>
> before trying to use it?
>
> If so, is it giving you any errors?

Hi,
It was my first attempt, but since it didn't work I tried the other
suggested method. By the way, here is what I get:


> install.packages("RMySQL")
Installing package(s) into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
provo con l'URL
'http://cran.mirror.garr.it/mirrors/CRAN/src/contrib/RMySQL_0.9-3.tar.gz'
Content type 'text/plain' length 165363 bytes (161 Kb)
URL aperto
==================================================
downloaded 161 Kb

* installing *source* package ?RMySQL? ...
** package ?RMySQL? successfully unpacked and MD5 sums checked
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... no
checking for egrep... grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking mysql.h usability... no
checking mysql.h presence... no
checking for mysql.h... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking /usr/local/include/mysql/mysql.h usability... no
checking /usr/local/include/mysql/mysql.h presence... no
checking for /usr/local/include/mysql/mysql.h... no
checking /usr/include/mysql/mysql.h usability... no
checking /usr/include/mysql/mysql.h presence... no
checking for /usr/include/mysql/mysql.h... no
checking /usr/local/mysql/include/mysql/mysql.h usability... yes
checking /usr/local/mysql/include/mysql/mysql.h presence... yes
checking for /usr/local/mysql/include/mysql/mysql.h... yes

Configuration error:
  could not find the MySQL installation include and/or library
  directories.  Manually specify the location of the MySQL
  libraries and the header files and re-run R CMD INSTALL.

INSTRUCTIONS:

1. Define and export the 2 shell variables PKG_CPPFLAGS and
   PKG_LIBS to include the directory for header files (*.h)
   and libraries, for example (using Bourne shell syntax):

      export PKG_CPPFLAGS="-I<MySQL-include-dir>"
      export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"

   Re-run the R INSTALL command:

      R CMD INSTALL RMySQL_<version>.tar.gz

2. Alternatively, you may pass the configure arguments
      --with-mysql-dir=<base-dir> (distribution directory)
   or
      --with-mysql-inc=<base-inc> (where MySQL header files reside)
      --with-mysql-lib=<base-lib> (where MySQL libraries reside)
   in the call to R INSTALL --configure-args='...'

   R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
RMySQL_<version>.tar.gz

ERROR: configuration failed for package ?RMySQL?
* removing ?/usr/local/lib/R/site-library/RMySQL?
* restoring previous ?/usr/local/lib/R/site-library/RMySQL?

The downloaded source packages are in
	?/tmp/RtmpaJ2WeK/downloaded_packages?
Warning message:
In install.packages("RMySQL") :
  installation of package ?RMySQL? had non-zero exit status


Federico


From lebatsnok at gmail.com  Fri Jul 11 00:00:00 2014
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Fri, 11 Jul 2014 01:00:00 +0300
Subject: [R] R on Windows crashes when source'ing UTF-8 file
In-Reply-To: <53BEA852.80002@gmail.com>
References: <CAH7sKSPVJuJXm4ksJYn3XZVmz=6L68w=T-s0Li+En2Co9pm4Tg@mail.gmail.com>
	<CAAJSdjiUFcnq+sfFzUJXUYBHnWbSrdbLXGDLGiTgHNrydG_F2A@mail.gmail.com>
	<CAH7sKSNaOoHnyYMJ8Wtg1K59OVYQHuFDH2Q=+fBfYLYC2YvrHg@mail.gmail.com>
	<53BEA852.80002@gmail.com>
Message-ID: <CAH7sKSNDGcfLS2avKM9MF96C0CwCgveYPfdBPnwexx3=TEA9Kg@mail.gmail.com>

I confirm that the original problem doesn't happen in R 3.1.1. in
Windows (XP, this time). That is,

source("http://psych.ut.ee/~R/test-utf8.txt")

.. no longer crashes R but gives a sensible (i.e., understandable,
after this discussion) error.
... and adding encoding="UTF-8-BOM" reads in the file correctly.



On Thu, Jul 10, 2014 at 5:50 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 10/07/2014 9:53 AM, Kenn Konstabel wrote:
>>
>> Wow. Thanks a lot!
>>
>> source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="UTF-8-BOM")
>> # works correctly on my Windows 7 machine
>> # (and without encoding argument it still crashes R)
>>
>> Kenn
>>
>> On Thu, Jul 10, 2014 at 4:33 PM, John McKown
>> <john.archie.mckown at gmail.com> wrote:
>> > On Thu, Jul 10, 2014 at 7:18 AM, Kenn Konstabel <lebatsnok at gmail.com>
>> > wrote:
>> >> Dear all,
>> >>
>> >> I found an unexpected behaviour when trying to `source` an utf-8 file
>> >> on windows 7:
>> >>
>> >> source("http://psych.ut.ee/~nek/R/test-utf8.txt")
>> >>
>> >> # Rgui.exe reacts:
>> >> # R for windows GUI has stopped working. A problem caused the program
>> >> to stop working correctly.
>> >> # Windows will close the program and notify you if a solution is
>> >> available.
>> >>
>> >> The same will happen with R.exe ("terminal") and R running wihin
>> >> Rstudio. (Session and locale info below).
>> >>
>> >> However, a non-utf version of this little script can be `source`d
>> >> without problems.
>> >>
>> >> source("http://psych.ut.ee/~nek/R/test.txt")
>> >>
>> >> Adding the `encoding` argument to `source` helps a little:
>> >>
>> >> source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding="utf-8")
>> >> #  unsure about the spelling of utf-8 so I also tried UTF8, utf8, and
>> >> UTF-8
>> >> # ... with the same result in all cases
>> >>
>> >> R doesn't crash any more but gives the following error:
>> >>
>> >> # Error in source("http://psych.ut.ee/~nek/R/test-utf8.txt", encoding
>> >> = "utf-8") :
>> >> #   http://psych.ut.ee/~nek/R/test-utf8.txt:2:0: unexpected end of
>> >> input
>> >> # 1: ?
>> >> #    ^
>> >> # In addition: Warning message:
>> >> # In readLines(file, warn = FALSE) :
>> >> #  invalid input found on input connection
>> >> 'http://psych.ut.ee/~nek/R/test-utf8.txt'
>> >
>> > I just tried that. On Windows XP/Pro,  R 3.1.0 didn't fail, but did
>> > get the error you mention later. I used "wget" to actually download
>> > the file mentioned (on Linux). I think that the problem _may_ be that
>> > the file starts with a BOM (Byte Order Mark), which is 0xef, 0xbb,
>> > 0xef . This is supposed to tell us that this is UTF-8.
>> >
>> > BOM: http://en.wikipedia.org/wiki/Byte_order_mark
>> >
>> > I get an identical error with R 3.1.0 on both Windows XP/Pro and Linux
>> > Fedora 20. The problem is that the R readLines() apparently does not
>> > like the leading BOM. It reads it as data. Most other Linux and
>> > Windows applications _do_ understand the BOM and so, when you use
>> > them, they work properly. And, normally, when you then save the file,
>> > the software does not write the BOM at the start. So it works on the
>> > saved version of the file.
>> >
>> > Being the curious sort, I decided to look at the source to R. In
>> > particular in ~/R/src/main/connections.c I saw where it did support
>> > the reading of BOMs. But there is a special way to do it! Which I
>> > cannot find in the documentation.
>> >
>> > source("http://psych.ut.ee/~nek/R/test-utf8.txt",encoding="UTF-8-BOM");
>> >
>> > I tried the above AND IT WORKED properly!
>> >
>> > I simply adore having source code.
>
>
> Searching the source for the string "UTF-8-BOM" finds it mentioned in the
> docs in 3 places:  in the NEWS file,
> in the R Data Import/Export manual, and in the ?connections help page.
>
> Duncan Murdoch
>
>> >
>> >
>> >>
>> >> I thought maybe that's because what notepad told me is UTF-8 is
>> >> actually something else ... so I did two more experiments.
>> >>
>> >> source("http://psych.ut.ee/~nek/R/test2.R")
>> >> # this was created on a linux machine with leafpad, and saved as utf-8
>> >> text
>> >> # it can be source?d on windows
>> >>
>> >> source("http://psych.ut.ee/~nek/R/test3.R")
>> >> # the same as previous but o's in file were replaced by ?'s
>> >> # can be source'd on windows but the "?" character is shown as ??
>> >> # except if you add encoding="utf-8" - then, as expected, it works as
>> >> expected
>> >>
>> >> So in sum, I can create "plain text" (saved with utf-8 encoding) files
>> >> on windows that cannot be sourced to R on windows, or will crash R
>> >> (depending on how you source them). The same files can be sourced on
>> >> linux without problems. Part of the problem is obviously in windows
>> >> but maybe R shouldn't at least crash.
>> >>
>> >> Session info:
>> >>
>> >>  R version 3.0.2 (2013-09-25)
>> >> Platform: i386-w64-mingw32/i386 (32-bit)
>> >>
>> >> locale:
>> >> [1] LC_COLLATE=Estonian_Estonia.1257  LC_CTYPE=Estonian_Estonia.1257
>> >> [3] LC_MONETARY=Estonian_Estonia.1257 LC_NUMERIC=C
>> >> [5] LC_TIME=Estonian_Estonia.1257
>> >>
>> >> attached base packages:
>> >> [1] stats     graphics  grDevices utils     datasets  methods   base
>> >>
>> >> loaded via a namespace (and not attached):
>> >> [1] tools_3.0.2
>> >>
>> >>
>> >> OS: Windows 7
>> >>
>> >> Linux Mint Debian Edition and R 3.0.2 on the other machine (where
>> >> everything worked).
>> >>
>> >> Context:
>> >>
>> >> I was trying to find out how to make files that could be source'd on
>> >> both windows and linux. This is partly solved so I have no specific
>> >> question other than "is this a bug in windows version?" but any
>> >> comments on the general topic would be appreciated too.
>> >>
>> >> Best regards,
>> >>
>> >> Kenn
>> >>
>> >>
>> >> Kenn Konstabel
>> >> Research fellow
>> >> Department of chronic diseases
>> >> National Institute of Health Development
>> >> Hiiu 42
>> >> Tallinn
>> >> Estonia
>> >
>> > --
>> > There is nothing more pleasant than traveling and meeting new people!
>> > Genghis Khan
>> >
>> > Maranatha! <><
>> > John McKown
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From Troung.Phan at team.telstra.com  Fri Jul 11 03:46:43 2014
From: Troung.Phan at team.telstra.com (Phan, Truong Q)
Date: Fri, 11 Jul 2014 11:46:43 +1000
Subject: [R] R Studio v3.0.3 for Windows 32bits is too slow
In-Reply-To: <66EDAA5B-0B6F-46F7-A429-FE170FCF7233@gmail.com>
References: <5336C307A4580E42BE60BE607FBA023D0843C6C40F@WSMSG3105V.srv.dir.telstra.com>
	<CACk-te3PWyYonTCx6fFujCyB=0SM5yvhZCGDbHXMXDNOA1xsHQ@mail.gmail.com>
	<4a7fe9c0-48c3-4900-a76a-d7702420d6bb@email.android.com>
	<66EDAA5B-0B6F-46F7-A429-FE170FCF7233@gmail.com>
Message-ID: <5336C307A4580E42BE60BE607FBA023D0843D9B415@WSMSG3105V.srv.dir.telstra.com>

Hi All,

Thanks for all comments/suggestions.
I would like to clarify a few things for some of your questions/doubts.

1) Matt Peeples' K-Clusters R scripts has covered some of pre-requisite steps for the K-Clusters algorithm. 
   I would recommend for those who has not done K-Clusters to read it.
	a) Convert count data to percent
	b) Allow to use Z-score standardize data when variables differ greatly in range or standard deviation or are not directly comparable measures

2) K-Clusters algorithm can handle well for the dataset which has less than 5000 features.

3) Our original dataset has more than 9000 parameters which I have been using Hadoop MapReduce streaming via Python to reduce them down to around 2000 parameter and then I use R to further cleansing data down to 1426 parameters.

4) I have been trying to use Mahout and Cloudera's Oryx tools but the integration of different tools perform tasks: Prepare data, Build models, Cross Validating models, Test models and Present data product are far too complicate for this small POC.

Thanks and Regards,
Truong Phan


P? ? + 61 2 8576 5771
M?? + 61 4 1463 7424
E? ? troung.phan at team.telstra.com
W? www.telstra.com


-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Thursday, 10 July 2014 10:08 AM
To: Jeff Newmiller
Cc: Bert Gunter; Phan, Truong Q; r-help at r-project.org
Subject: Re: [R] R Studio v3.0.3 for Windows 32bits is too slow

Grumpy today, Jeff?

For the concrete issue, I'd conjecture that the base problem is that there are way too many columns in the data and that the nature of the method is not properly understood. It is not obvious that k-means clustering based on Euclidean distance makes sense in 1426-dimensional space. It is quite possible that the data set not even consists of columns measured in the same units. Even if it does fit the problem, it is a quite computationally intensive. Some sort of feature extraction or data reduction technique is likely to be required.

So basically, further study of the methodology, or contact with a machine learning expert (which I am not) seems advisable.

-pd  


On 09 Jul 2014, at 18:24 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Grumpy today, Bert?
> 
> While it is a fact that RStudio is a separate tool from R, it is clear from the question that the OP is interested in capabilities that R is providing and he simply cannot tell the difference.
> 
> OP:
> 
> 1) "Better" is a word that leads to pointless arguments. You will have to be the judge of what works for you. I caution you that Open Source tools almost always achieve success by interoperating with other OS tools, and much of the success you have already obtained is the result of many contributions, of which R and its contributed packages deserve the lion's share of credit. RStudio is a very convenient editor that makes using R and LaTeX and Markdown and version control easier, but it is unlikely that either the blame for your dissatisfaction or the credit for your success should be attributed to RStudio.
> 
> I have successfully used all sorts of plain text editors and command line interfaces with R, and if you plan to scale up your projects then you will likely want to be very clear on this distinction between editors and computing tools so you can distribute your work on multiple parallel servers (where editors may not necessarily even be helpful) even if you choose to use RStudio as your controlling environment for launching such tasks.
> 
> 2) and 3) I know that R has contributed packages that can manage Hadoop data processing, but I have no personal experience with them. Google is your friend... especially if you keep in mind that these tools are not all found in one monolithic package.
> 
> For future reference: this is a plain text mailing list, so please adjust your mail client appropriately when sending to this list. Also, there are considerable resources mentioned in the Posting Guide that you should be aware of... see the link below.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> ----- Sent from my phone. Please excuse my brevity.
> 
> On July 9, 2014 7:10:00 AM PDT, Bert Gunter <gunter.berton at gene.com> wrote:
>> RStudio is a separate product with its own support. Post there, not 
>> here.
>> 
>> -- Bert
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge 
>> is certainly not wisdom."
>> Clifford Stoll
>> 
>> 
>> 
>> 
>> On Tue, Jul 8, 2014 at 7:34 PM, Phan, Truong Q 
>> <Troung.Phan at team.telstra.com> wrote:
>>> Hi R'er,
>>> 
>>> I have a dataset which has a matrix of 7502 x 1426 (rows x columns).
>>> The data is in a CSV format which has a size around 68Mb. This
>> dataset is less than 10% of our dataset.
>>> I have been adopting the Anomaly detection method as described by
>> http://www.mattpeeples.net/kmeans.html .
>>> It has been running more than 24hrs and still haven't completed the
>> calculation.
>>> I did manage to run it with a smaller dataset (ie, 2100 rows x 1426
>> columns). It took around 12hrs to run.
>>> 
>>> I have a few questions and need your expertise guidance.
>>> 
>>> 1)      Is there any better Open source tools to use to do in one
>> tool (eg, R Studio): prepare data, build models, validate models, 
>> test models and present data. I am looking a tool which will allow me 
>> to do the same as per the above link (Matt Peeples' blog).
>>> 
>>> 2)      Is there an Open source tools to perform the above which will
>> allow me to run on top of Hadoop eco-system?
>>> 
>>> 3)      Can we use R Studio for windows as a client to run on top of
>> Hadoop eco-system? If yes, please point me to the site where they 
>> have a use cases or samples.
>>> 
>>> Thanks and Regards,
>>> Truong Phan
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dulcalma at bigpond.com  Fri Jul 11 03:49:59 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 11 Jul 2014 11:49:59 +1000
Subject: [R] quantmod: How could I change the name in chartSeries
In-Reply-To: <53BE0FA4.2080507@gmail.com>
References: <53BE0FA4.2080507@gmail.com>
Message-ID: <000901cf9caa$6d4f7150$47ee53f0$@bigpond.com>

Hi

I have not used quantmod before  so I got the

stock.name <- getSymbols(stock.code, from = "2010-01-01",
                                                 to = Sys.Date(), src = 
"yahoo", auto.assign=FALSE)
   chartSeries(stock.name, theme = theme.white,
               # subset = 'last 12 months',
               TA = "addVo(); addSMA(); addEnvelope();
                   addMACD(); addMomentum(); addROC();
                   addBBands()")
and 
str(stock.name)

on it to see its structure

If you require  the "^" before the stock.code insert

name = sub("\\..*$","",attributes(stock.name)$dimnames[[2]][1]),
otherwise 
name = stock.code

eg

chartSeries(stock.name,
               theme = theme.white,
               name =
sub("\\..*$","",attributes(stock.name)$dimnames[[2]][1]),
               # subset = 'last 12 months',
               TA = "addVo(); addSMA(); addEnvelope(); addMACD();
addMomentum(); addROC(); addBBands()")
               addLines(v = which(stock.name[,4] == max(stock.name[,4])),
               col = "gray")

If this is not what you want it will be somewhere in the stock.name and
?chartSeries

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of William
Sent: Thursday, 10 July 2014 14:00
To: r-help at r-project.org
Subject: [R] quantmod: How could I change the name in chartSeries

hi, guys,

I am just a beginner to the excellent R package, quantmod. I quite don't 
know how to change the y-axis name in the chartSeries function. 
Actually, I want to write some sort of the following function, by which 
I could use just one code  sentence  to complete the financial analysis.

The following function is designed to provide some aspects of the 
S&P500. And now I want to change the "stock.name" on the y-axis as 
"S&P500". Is there anyway to realize this?

THX

         William


#################################################################
stock.price <- function(stock.name, stock.code){
   #### Loading......
   library(zoo)
   library(xts)
   library(TTR)
   library(Defaults)
   library(quantmod)
#---------------------------------------------------------------------------
---------------------------------------------------------------
   ## Theme: white
   theme.white <- chartTheme("white")
   names(theme.white)
   theme.white$bg.col <- "white"
   theme.white$up.col <- "red"
   theme.white$dn.col <- "green"
#---------------------------------------------------------------------------
---------------------------------------------------------------
   #### main function
   stock.name <- getSymbols(stock.code, from = "2010-01-01",
                                                 to = Sys.Date(), src = 
"yahoo", auto.assign=FALSE)
   chartSeries(stock.name, theme = theme.white,
               # subset = 'last 12 months',
               TA = "addVo(); addSMA(); addEnvelope();
                   addMACD(); addMomentum(); addROC();
                   addBBands()")
   addLines(v = which(stock.name[,4] == max(stock.name[,4])),
            col = "gray")
}
#################################################################
stock.price(S&P500, "^GSPC")

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri Jul 11 03:54:08 2014
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 10 Jul 2014 21:54:08 -0400
Subject: [R] linearHypothesis() ERROR-Message
In-Reply-To: <000001cf9c26$60ffc960$22ff5c20$@uni-koeln.de>
References: <000001cf9c26$60ffc960$22ff5c20$@uni-koeln.de>
Message-ID: <web-518216588@cgpsrv2.cis.mcmaster.ca>

Dear Katharina,

There's no specific method for linearHypothesis() for objects produced by plm(), but as you say, the default method seems to work. For example, following example(plm):

---------- snip -----------

> linearHypothesis(zz, names(coef(zz)), test="F")
Linear hypothesis test

Hypothesis:
log(pcap) = 0
log(pc) = 0
log(emp) = 0
unemp = 0

Model 1: restricted model
Model 2: log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp

  Res.Df Df      F    Pr(>F)    
1    768                        
2    764  4 3064.8 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

--------------- snip -------------

The error message seems reasonably self-explanatory, and given the hypothesis that you're testing -- that all coefficients are 0 -- it suggests that the covariance matrix of the coefficients is numerically singular. You can check that, e.g., by examining the eigenstructure of vcov(fixed.interest3). 

I agree that's curious given that plm() doesn't complain. Are you able to get coefficient standard errors in summary(fixed.interest3)?

Without your data, it's not possible to say more, and you could make the problem reproducible by supplying the data. In any event, I've just returned from several weeks out of town and wouldn't be able to look at your data for a few days.

I hope this helps,
 John

On Thu, 10 Jul 2014 12:04:46 +0200
 "Katharina Mersmann" <kmersman at smail.uni-koeln.de> wrote:
> Dear Community,
> 
> unfortunately I can?t give you an reproducable example, because I really do
> not understand why this messages pops up.
> 
> I estimate an Fixed Effects Modell, controlling for HAC, because F-statistic
> changes, I want to compute it, for the other model-specifications it works,
> 
> But for this special one I get the following error: 
> 
>  
> 
> > fixed.interest3<-plm(CSmean~ numfull_FCRlong_adj+exp(numfull_FCRlong_adj),
> 
> +                      data=data.plm,index = c("countrynr","quartal"),
> model="within")
> 
> > ###F-Test
> 
> > coefs <- names(coef(fixed.interest3))
> 
> > linearHypothesis(fixed.interest3,coefs,test="F", vcov=function(x)
> vcovHC(x, method = "arellano")) 
> 
> Fehler in solve.default(L %*% V %*% t(L)) : 
> 
>   System ist f?r den Rechner singul?r: reziproke Konditionszahl =
> 1.37842e-19  ?system is computationally singular reciprocal condition
> number?
> 
> > drop(coefs)
> 
> [1] "numfull_FCRlong_adj"         "exp(numfull_FCRlong_adj)"
> 
> > 
> 
>  
> 
> Is something wrong in the code. Or is it because of the model?
> 
>  
> 
>  
> 
> Thanks in advance and a really nice day
> 
> Katie
> 
> 
> 	[[alternative HTML version deleted]]
> 

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From feigsc at gmail.com  Fri Jul 11 01:59:54 2014
From: feigsc at gmail.com (Chris Feigl)
Date: Fri, 11 Jul 2014 09:59:54 +1000
Subject: [R] Installing RStudio for ARM architecture
Message-ID: <CABvWtXxQov2dsKnEVxt6+h-oN8io+F7ZP32_K1gYgyUeWxH6Cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/daa0ae13/attachment.pl>

From feigsc at gmail.com  Fri Jul 11 02:35:53 2014
From: feigsc at gmail.com (Chris Feigl)
Date: Fri, 11 Jul 2014 10:35:53 +1000
Subject: [R] Porting GHC neccessary to install RStudio on ARM/Linux?
Message-ID: <CABvWtXzydSLr2xQaQW74Jnn7SUHEfJctOcCiJSKu_T60qWgY7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/f151eb02/attachment.pl>

From feigsc at gmail.com  Fri Jul 11 05:38:14 2014
From: feigsc at gmail.com (Chris Feigl)
Date: Fri, 11 Jul 2014 13:38:14 +1000
Subject: [R] Build and install of Rstudio on ARMv7/Linux freezes
Message-ID: <CABvWtXxp4=tBgSqB71wKGWz=tdLibMvTCvmaCb-gcKNiuV1GmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/f2ef5daf/attachment.pl>

From abhinabaroy09 at gmail.com  Fri Jul 11 06:52:29 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Fri, 11 Jul 2014 10:22:29 +0530
Subject: [R] Decision Tree
In-Reply-To: <CAN5YmCEPeg5A0XOsn8MQz2Ma2D5aW-Qvsk5a8YC7e6AomgPCOw@mail.gmail.com>
References: <CANtKHPWVRwyVaT5AMCoT=q8jynV8rYX_79jdkTGpAxqAT8o7DA@mail.gmail.com>
	<CAN5YmCEPeg5A0XOsn8MQz2Ma2D5aW-Qvsk5a8YC7e6AomgPCOw@mail.gmail.com>
Message-ID: <CANtKHPU8wcbaHWr7Egdz6v6h8bEx0NTKb2JN_7pP3tFYY7rCsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/6cd2d354/attachment.pl>

From katherine_gobin at yahoo.com  Fri Jul 11 08:17:23 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 11 Jul 2014 14:17:23 +0800
Subject: [R] Paper on Analytics using R
Message-ID: <1405059443.45150.YahooMailNeo@web193301.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/d5029627/attachment.pl>

From dwinsemius at comcast.net  Fri Jul 11 08:50:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Jul 2014 23:50:33 -0700
Subject: [R] Installing RMySQL on Debian
In-Reply-To: <d0ce50a1920c2d179c51e6f769f360cf.squirrel@fruiteater.riseup.net>
References: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>
	<CAM_vjum==pVz8enH9BupESrDkhz3ZJcQKJM4r2_X5u+n6mTAQA@mail.gmail.com>
	<d0ce50a1920c2d179c51e6f769f360cf.squirrel@fruiteater.riseup.net>
Message-ID: <2B37F0CD-4256-48B0-AE0F-83744AAE29BF@comcast.net>


On Jul 10, 2014, at 1:07 PM, Federico Razzoli wrote:

>> Just to check, are you loading the package using
>> 
>> library(RMySQL)
>> 
>> before trying to use it?
>> 
>> If so, is it giving you any errors?
> 
> Hi,
> It was my first attempt, but since it didn't work I tried the other
> suggested method. By the way, here is what I get:

> What did you think when you read this:
========
Configuration error:
 could not find the MySQL installation include and/or library
 directories.  Manually specify the location of the MySQL
 libraries and the header files and re-run R CMD INSTALL.
========
?????

I'm wondering if you understand the RMySQL is only an interface to the MySQL package, and it needs to be installed separately for your OS.

-- 
David


>> install.packages("RMySQL")
> Installing package(s) into ?/usr/local/lib/R/site-library?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> provo con l'URL
> 'http://cran.mirror.garr.it/mirrors/CRAN/src/contrib/RMySQL_0.9-3.tar.gz'
> Content type 'text/plain' length 165363 bytes (161 Kb)
> URL aperto
> ==================================================
> downloaded 161 Kb
> 
> * installing *source* package ?RMySQL? ...
> ** package ?RMySQL? successfully unpacked and MD5 sums checked
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... no
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mysql.h usability... no
> checking mysql.h presence... no
> checking for mysql.h... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking /usr/local/include/mysql/mysql.h usability... no
> checking /usr/local/include/mysql/mysql.h presence... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking /usr/include/mysql/mysql.h usability... no
> checking /usr/include/mysql/mysql.h presence... no
> checking for /usr/include/mysql/mysql.h... no
> checking /usr/local/mysql/include/mysql/mysql.h usability... yes
> checking /usr/local/mysql/include/mysql/mysql.h presence... yes
> checking for /usr/local/mysql/include/mysql/mysql.h... yes
> 
> Configuration error:
>  could not find the MySQL installation include and/or library
>  directories.  Manually specify the location of the MySQL
>  libraries and the header files and re-run R CMD INSTALL.
> 
> INSTRUCTIONS:
> 
> 1. Define and export the 2 shell variables PKG_CPPFLAGS and
>   PKG_LIBS to include the directory for header files (*.h)
>   and libraries, for example (using Bourne shell syntax):
> 
>      export PKG_CPPFLAGS="-I<MySQL-include-dir>"
>      export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"
> 
>   Re-run the R INSTALL command:
> 
>      R CMD INSTALL RMySQL_<version>.tar.gz
> 
> 2. Alternatively, you may pass the configure arguments
>      --with-mysql-dir=<base-dir> (distribution directory)
>   or
>      --with-mysql-inc=<base-inc> (where MySQL header files reside)
>      --with-mysql-lib=<base-lib> (where MySQL libraries reside)
>   in the call to R INSTALL --configure-args='...'
> 
>   R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
> RMySQL_<version>.tar.gz
> 
> ERROR: configuration failed for package ?RMySQL?
> * removing ?/usr/local/lib/R/site-library/RMySQL?
> * restoring previous ?/usr/local/lib/R/site-library/RMySQL?
> 
> The downloaded source packages are in
> 	?/tmp/RtmpaJ2WeK/downloaded_packages?
> Warning message:
> In install.packages("RMySQL") :
>  installation of package ?RMySQL? had non-zero exit status
> 
> 
> Federico
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jwd at surewest.net  Fri Jul 11 08:46:11 2014
From: jwd at surewest.net (jwd)
Date: Thu, 10 Jul 2014 23:46:11 -0700
Subject: [R] Paper on Analytics using R
In-Reply-To: <1405059443.45150.YahooMailNeo@web193301.mail.sg3.yahoo.com>
References: <1405059443.45150.YahooMailNeo@web193301.mail.sg3.yahoo.com>
Message-ID: <20140710234611.055b54cb@draco>

On Fri, 11 Jul 2014 14:17:23 +0800
Katherine Gobin <katherine_gobin at yahoo.com> wrote:

> Dear R Forum,
> 
> I am looking for some write-up or paper on Use of R for Analytics or
> why R should be preferred over others for Analytics purpose. Tried
> google but got some info about some commercial vendors using R for
> analytics. I am looking for some paper where no commercial flavor is
> given, I mean it deals with R strictly and doesn't talk about some
> product using R for analytics.
> 
> Kindly share if you are aware of some writeups or paper.
> 
> Regards
> 
> Katherine
>
Try researching here.

http://www.jstatsoft.org/

JWDougherty


From h.wickham at gmail.com  Fri Jul 11 09:06:18 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 11 Jul 2014 17:06:18 +1000
Subject: [R] list of valid R encodings.in source(...,encoding=)
In-Reply-To: <CAAJSdjhOoE1Kg6ivOwdbJ77KzmwGWNY6F+5nrFmbPjcHSgtb5Q@mail.gmail.com>
References: <CAAJSdjhOoE1Kg6ivOwdbJ77KzmwGWNY6F+5nrFmbPjcHSgtb5Q@mail.gmail.com>
Message-ID: <CABdHhvGtT0pBjgmPzMMPF+=i9uxCwn=sC0QN+3HB7FNzx94Lpw@mail.gmail.com>

It's documented in the Encodings section of ?file:

"As from R 3.0.0 the encoding "UTF-8-BOM" is accepted for reading and
will remove a Byte Order Mark if present (which it often is for files
and webpages generated by Microsoft applications). If it is required
(it is not recommended) when writing it should be written explicitly,
e.g. by writeChar("\ufeff", con, eos = NULL) or
writeBin(as.raw(c(0xef, 0xbb, 0xff)), binary_con)"

Hadley

On Fri, Jul 11, 2014 at 12:50 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> This question was spawned by another thread entitled "R on Windows
> crashes when source'ing UTF-8 file".
>
> The solution to that problem was to use the _proper_ encoding=
> parameter of the source() function. But where are they documented? Or
> how do I find them in R itself? I ask because the proper encoding to
> solve the problem was "UTF-8-BOM". I got this by reading the source
> code to main/connnections.c . Not where I expect most people to go.
>
> I found iconvlist(). But it does not list UTF-8-BOM, only UTF8 and
> UTF-8. I got no useful response to ??BOM from the R prompt.
>
> My normal locale is "C" on Linux. If I use encoding="UTF-8" in the
> source() line, it fails because the BOM at the start is intepreted as
> data to be processed. If I use UTF-8-BOM instead, it succeeds. It also
> succeeds if I do Sys.setlocale("LC_ALL","en_US.utf8").
>
> I admit that I don't understand all (or even much) of the ins-and-outs
> of i10n, or code pages. But the UTF-8-BOM is just "weird" to me; and
> confusing since it is not documented anywhere I can find.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From johannesradinger at gmail.com  Fri Jul 11 10:24:15 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Fri, 11 Jul 2014 10:24:15 +0200
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
Message-ID: <CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/8c0d6dfc/attachment.pl>

From santec at riseup.net  Fri Jul 11 12:23:39 2014
From: santec at riseup.net (Federico Razzoli)
Date: Fri, 11 Jul 2014 12:23:39 +0200
Subject: [R] Installing RMySQL on Debian
In-Reply-To: <2B37F0CD-4256-48B0-AE0F-83744AAE29BF@comcast.net>
References: <634542b373858e73be7b3befe32d72ad.squirrel@fruiteater.riseup.net>
	<CAM_vjum==pVz8enH9BupESrDkhz3ZJcQKJM4r2_X5u+n6mTAQA@mail.gmail.com>
	<d0ce50a1920c2d179c51e6f769f360cf.squirrel@fruiteater.riseup.net>
	<2B37F0CD-4256-48B0-AE0F-83744AAE29BF@comcast.net>
Message-ID: <b8f15eae5164b39dd43a56c6a2f4cc29.squirrel@fruiteater.riseup.net>

> I'm wondering if you understand the RMySQL is only an interface to the
> MySQL package, and it needs to be installed separately for your OS.
>
> --
> David

Hi David.

As I wrote in my first mail, MySQL (MariaDB) is installed from the tar
file. Please, if you want to help me, re-read my first mail: you will see
how I specified paths and which errors I got.

Federico


From tim at mlhim.org  Fri Jul 11 12:59:15 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Fri, 11 Jul 2014 07:59:15 -0300
Subject: [R] Paper on Analytics using R
In-Reply-To: <1405059443.45150.YahooMailNeo@web193301.mail.sg3.yahoo.com>
References: <1405059443.45150.YahooMailNeo@web193301.mail.sg3.yahoo.com>
Message-ID: <CA+=OU3UpreZ4e2Q8Rg_CDKWH=2kShwHNdj9-AMet--Znh=KO2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/c611247d/attachment.pl>

From chrisaa at med.umich.edu  Fri Jul 11 13:46:41 2014
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Fri, 11 Jul 2014 11:46:41 +0000
Subject: [R] Median expected survival
In-Reply-To: <CAO7OmOi_OA6teVQybyZATzxtOksqQZa6p+Q4oSWKu42+8+drSA@mail.gmail.com>
References: <CAO7OmOi_OA6teVQybyZATzxtOksqQZa6p+Q4oSWKu42+8+drSA@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C2D742C@UHEXMBSPR03.umhs.med.umich.edu>

Hi Lars,

Graph it:

plot(pred_leuk)

will show that some of the survival curves do not reach 0.5 before you run out of data.  Thus the median is not estimated and you get NA.

Chris

-----Original Message-----
From: Lars Bishop [mailto:lars52r at gmail.com] 
Sent: Thursday, July 10, 2014 6:23 AM
To: r-help at r-project.org
Subject: [R] Median expected survival

Hi All,

Apologies for the simple question, but I could not find a straightforward
answer based on my limited knowledge of survival analysis.

I?m trying to obtain the predicted median survival time for each subject on
a new dataset from a fitted coxph{survival} or cph{rms} object. Would the
quantile.survfit function (as used below) return the expected median
survival? Why this function returns NAs in this case, when all predictors
have non-missing values?

As an alternative, I?ve tried to use the Quntile{rms} function as in my
second chunk of code, but in this case I get an error message (most likely
due to my lack of understanding as well).

library(MASS)

library(survival)

library(rms)

data(gehan)

leuk.cox <-coxph(Surv(time, cens) ~ treat + factor(pair), data = gehan)

leuk_new <- gehan[1:10, ] # take first 10 patients

pred_leuk <- survfit(leuk.cox, newdata=leuk_new)

quantile(pred_leuk, 0.5)$quantile



### alternative using rms

leuk.cox.rms <-cph(Surv(time, cens) ~ treat + factor(pair), data = gehan,
surv = T)

med <- Quantile(leuk.cox.rms)

Predict(leuk.cox.rms, data = leuk_new, fun=function(x)med(lp=x))

>Error in Predict(leuk.cox.rms, data = leuk_new, fun = function(x) med(lp =
x)) :

  predictors(s) not in model: data


Thank you for your help.

Best,

Lars.

	[[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From anupam.contact at gmail.com  Fri Jul 11 08:38:20 2014
From: anupam.contact at gmail.com (anupam sinha)
Date: Fri, 11 Jul 2014 12:08:20 +0530
Subject: [R] Grouped Boxplot
Message-ID: <CAPPk2Ah4ZFCBCLmzmy=hof5Tse6kqZE4xhiztK8iLYYMc6CBbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/6061722b/attachment.pl>

From jorgeivanvelez at gmail.com  Fri Jul 11 14:56:21 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Fri, 11 Jul 2014 22:56:21 +1000
Subject: [R] Grouped Boxplot
In-Reply-To: <CAPPk2Ah4ZFCBCLmzmy=hof5Tse6kqZE4xhiztK8iLYYMc6CBbA@mail.gmail.com>
References: <CAPPk2Ah4ZFCBCLmzmy=hof5Tse6kqZE4xhiztK8iLYYMc6CBbA@mail.gmail.com>
Message-ID: <CAKL8G3GaDUd+T6JfJMGWRcdk8L0FQeRzM8fN7kwUvJeBaTuKzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/84fccd89/attachment.pl>

From dcarlson at tamu.edu  Fri Jul 11 16:19:00 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 11 Jul 2014 14:19:00 +0000
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
	<CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/9e6b335f/attachment.pl>

From jfox at mcmaster.ca  Fri Jul 11 17:09:31 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 11 Jul 2014 11:09:31 -0400
Subject: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
In-Reply-To: <CAAweS98OXE8i8-_Lx5x4gThd=2f2ESu1KmTitZ0YrHs31KMsHA@mail.gmail.com>
References: <CAAweS9_DjD4ZfyzC+2cN9tWjVbq7AMNuc-fmyxqu+cZdKD0KFg@mail.gmail.com>	<web-518038008@cgpsrv2.cis.mcmaster.ca>	<CAAweS9-esAijA=XzzpJbD_2pGmQoZw6EtqM2+OwMwdwxjbRssg@mail.gmail.com>	<53BE4D2F.40408@yorku.ca>	<53BF8FB63FAF2E4A9455EF1EE94DA726F86F27@mb02.ads.tamu.edu>
	<CAAweS98OXE8i8-_Lx5x4gThd=2f2ESu1KmTitZ0YrHs31KMsHA@mail.gmail.com>
Message-ID: <001601cf9d1a$1f3521c0$5d9f6540$@mcmaster.ca>

Dear Judith,

Michael and David's suggestion (and my earlier suggestion) that you use a
method appropriate to the distribution of your data is no doubt good advice,
but it remains to be explained why candisc() produced an error.

If you do the following, you'll see that many of your variables are
invariant within levels of sitio:

-------- snip ----------

Data <- read.csv("c:/temp/bosques1.csv", header=TRUE)
vars <- scan(what="")
biomasa altdosel altsoto cobertura riqarb elevacion temperatura 
precipitacion  Araceae Begoniaceae Bromeliaceae Clusiaceae Cyclanthaceae
Ericaceae 
Gesneriaceae Melastomataceae Orchidaceae Piperaceae Pteridophyta.taxa

by(Data[, vars], Data$sitio, function(D) apply(D, 2, sd))

-------- snip ----------

I believe that you would have discovered this had you looked at the data --
always a good idea -- prior to using candisc().

BTW, in the original script that you posted, you apparently misspelled two
of the variable names as "Cyclanthace" and "Pteridophyta", which suggests to
me that the version of the data set that you sent is different from the
version that you used.

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Maria Judith Carmona H
> Sent: Thursday, July 10, 2014 11:10 AM
> To: David L Carlson
> Cc: r-help at r-project.org; John Fox; Michael Friendly
> Subject: Re: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
> 
> Hello John, Michael and David,
> 
> I will review Vegan Package. I am very thankful with your help.
> 
> Best,
> Judith
> 
> 
> On Thu, Jul 10, 2014 at 9:04 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> 
> > In particular, look at the vegan Vignette, "Introduction to
> Ordination in
> > vegan", particularly section 4 on constrained ordination which
> describes
> > three approaches that seem relevant to your problem.
> >
> > http://cran.r-project.org/web/packages/vegan/vignettes/intro-
> vegan.pdf
> >
> > David Carlson
> >
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org]
> > On Behalf Of Michael Friendly
> > Sent: Thursday, July 10, 2014 3:22 AM
> > To: Maria Judith Carmona H
> > Cc: r-help at r-project.org; John Fox
> > Subject: Re: [R] Cansisc: Error in eigen(eHe, symmetric = TRUE)
> >
> > Maria
> >
> > The variables
> >
> >
> Araceae,Begoniaceae,Bromeliaceae,Clusiaceae,Cyclanthaceae,Ericaceae,Ges
> neriaceae,
> > Melastomataceae,Orchidaceae,Piperaceae,Pteridophyta
> > are frequencies (abundances?) of which most are 0 and this is not
> > appropriate
> > as multivariate normal data.
> >
> > There is probably a version of canonical analysis that takes such
> > variables into account,
> > but I don't know specifically.  Have you looked at the vegan package
> and
> > its references?
> >
> > HTH
> > -Michael
> >
> >
> >
> > On 10/07/2014 12:54 AM, Maria Judith Carmona H wrote:
> > > Dear John,
> > >
> > > I am including abundance values b


From ryan.devera.03 at gmail.com  Fri Jul 11 18:19:39 2014
From: ryan.devera.03 at gmail.com (Ryan de Vera)
Date: Fri, 11 Jul 2014 12:19:39 -0400
Subject: [R] Merge rows
Message-ID: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/70b25202/attachment.pl>

From sarah.goslee at gmail.com  Fri Jul 11 18:27:55 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 11 Jul 2014 12:27:55 -0400
Subject: [R] Merge rows
In-Reply-To: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
References: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
Message-ID: <CAM_vjukHVOj-kLJkjxg4Fq3HMjB8Nc=jWjDdZwGXxv77ua69EQ@mail.gmail.com>

Hi Ryan,

We can't tell from your example what structure your original data are
in, nor what your output is intended to look like, or for that matter
how you got from one to the other. Please don't post in HTML because
it gets mangled!

Using dput() to provide your example data is the best thing, because
that preserves R structures. And an R-format example of your desired
output would also be helpful.

Sarah

On Fri, Jul 11, 2014 at 12:19 PM, Ryan de Vera <ryan.devera.03 at gmail.com> wrote:
> Hello all,
>
> I have a data frame filled with senders and recipients. Some of the senders
> have multiple rows with different recipients and I want to merge those
> rows. For example I have
>
> a at email.com     b at email.com
> a at email.com     c at email.com     d at email.com
> r at email.com      f at email.com
> r at email.com      h at email.com
>
> I want this to become
>
> a at email.com     b at email.com     c at email.com     d at email.com
> r at email.com      f at email.com      h at email.com
>
> How would I go about doing this?
>
>         [[alternative HTML version deleted]]

^^^ That is part of the problem!

-- 
Sarah Goslee
http://www.functionaldiversity.org


From pomchip at free.fr  Fri Jul 11 19:52:21 2014
From: pomchip at free.fr (=?UTF-8?Q?S=C3=A9bastien_Bihorel?=)
Date: Fri, 11 Jul 2014 13:52:21 -0400
Subject: [R] Information about font
In-Reply-To: <71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>
References: <CABR8ZvpaSrB3X1JGVK4RBmTN=DsR5tYeK2Unb8rgai8KxvDL0w@mail.gmail.com>
	<71DA7266-5F2A-4860-A2BD-C0578BDA4E4E@comcast.net>
Message-ID: <CABR8ZvpSMyHgNAEGDfoz5su5du+d0i5=s-yAmOrgQrfRkDhqGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/70570eca/attachment.pl>

From robert.b.lynch at gmail.com  Fri Jul 11 20:43:16 2014
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Fri, 11 Jul 2014 11:43:16 -0700
Subject: [R] CI for nlme predictions
Message-ID: <CACYeG1jjz0wm2V2YB0NYKQ_eFGoPUsSZcC6v_Ww9bgtnODkNcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/64f6827d/attachment.pl>

From giovanni.millo at generali.com  Fri Jul 11 15:11:13 2014
From: giovanni.millo at generali.com (Millo Giovanni)
Date: Fri, 11 Jul 2014 13:11:13 +0000
Subject: [R] (no subject)
Message-ID: <DB36B6DC36CFD746A374F62BE5B5C5BD04AF73E7@D3MBXSRVPD1.corp.generali.net>

Dear Katie,

the code looks all right. On a standard example, everything works fine, e.g.:

# example(plm)
# coefs<-names(coef(zz))
# lht(zz, coefs)
# lht(zz, coefs, vcov=vcovHC) # "arellano" is the default HC method anyway

As the error message says, your case is somehow ill-conditioned and the vcov matrix turns out numerically singular. In this sense, it may be "the model's fault".

I've never seen this happen before and cannot say anything more useful, at least not w/o a reproducible example.

LG,
Giovanni

Giovanni Millo, PhD
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 3,
34132 Trieste (Italy)
tel. +39 040 671184
fax  +39 040 671160


-------------------------- original message -----------------------------

Message: 1
Date: Thu, 10 Jul 2014 12:04:46 +0200
From: "Katharina Mersmann" <kmersman at smail.uni-koeln.de>
To: <r-help at r-project.org>
Subject: [R] linearHypothesis() ERROR-Message
Message-ID: <000001cf9c26$60ffc960$22ff5c20$@uni-koeln.de>
Content-Type: text/plain

Dear Community,

unfortunately I can?t give you an reproducable example, because I really do
not understand why this messages pops up.

I estimate an Fixed Effects Modell, controlling for HAC, because F-statistic
changes, I want to compute it, for the other model-specifications it works,

But for this special one I get the following error:



> fixed.interest3<-plm(CSmean~ numfull_FCRlong_adj+exp(numfull_FCRlong_adj),

+                      data=data.plm,index = c("countrynr","quartal"),
model="within")

> ###F-Test

> coefs <- names(coef(fixed.interest3))

> linearHypothesis(fixed.interest3,coefs,test="F", vcov=function(x)
vcovHC(x, method = "arellano"))

Fehler in solve.default(L %*% V %*% t(L)) :

  System ist f?r den Rechner singul?r: reziproke Konditionszahl =
1.37842e-19  ?system is computationally singular reciprocal condition
number?

> drop(coefs)

[1] "numfull_FCRlong_adj"         "exp(numfull_FCRlong_adj)"

>



Is something wrong in the code. Or is it because of the model?





Thanks in advance and a really nice day

Katie


        [[alternative HTML version deleted]]



---------------- end original message --------------

Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From trichter at uni-bremen.de  Fri Jul 11 16:15:44 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Fri, 11 Jul 2014 16:15:44 +0200
Subject: [R] Problems with read.table and data structure
Message-ID: <53BFF190.2030801@uni-bremen.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/93127782/attachment.pl>

From marc_schwartz at me.com  Fri Jul 11 21:36:52 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 11 Jul 2014 14:36:52 -0500
Subject: [R] Problems with read.table and data structure
In-Reply-To: <53BFF190.2030801@uni-bremen.de>
References: <53BFF190.2030801@uni-bremen.de>
Message-ID: <46FD9C76-0930-43E8-B722-2365A4425668@me.com>


On Jul 11, 2014, at 9:15 AM, Tim Richter-Heitmann <trichter at uni-bremen.de> wrote:

> Hi there!
> 
> I have huge datafile of 600 columns 360 samples:
> 
> data <- read.table("small.txt", header = TRUE, sep = "\t", dec = ".", 
> row.names=1)
> 
> The txt.file (compiled with excel) is showing me only numbers, however R 
> gives me the structure of ANY column as "factor".
> 
> When i try "stringsAsFactors=FALSE" in the read command, the structure 
> of the dataset becomes "character."
> 
> When i try as.numeric(data), i get
> 
> Error: (list) object cannot be coerced to type 'double'
> 
> 
> even, if i try to subset columns with [].
> 
> 
> When i try as.numeric on single columns with $, i am successful, but the numbers dont make any sense at all, as the factors are not converted by their levels:
> 
> 
> Factor w/ 358 levels "0,123111694",..: 11 14 50 12 38 44 13 76 31 30
> 
> 
> becomes
> 
> 
> num  11 14 50 12 38 44 13 76 31 30
> 
> 
> whereas i would need the levels, though!
> 
> 
> I suspect excel to mess up the "save as tab-delimited text", but the text file seems fine with me on surface (i dont know how the numbers are stored  internally). I just see correct numbers, also the View command
> yields the correct content.
> 
> 
> 
> Anyone knows help? Its pretty annoying.
> 
> 
> 
> Thank you!


Hi,

See:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-convert-factors-to-numeric_003f

Regards,

Marc Schwartz


From marc_schwartz at me.com  Fri Jul 11 21:42:14 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 11 Jul 2014 14:42:14 -0500
Subject: [R] Problems with read.table and data structure
In-Reply-To: <46FD9C76-0930-43E8-B722-2365A4425668@me.com>
References: <53BFF190.2030801@uni-bremen.de>
	<46FD9C76-0930-43E8-B722-2365A4425668@me.com>
Message-ID: <F8008110-0370-4B7F-BA06-8FEA70785BAA@me.com>


On Jul 11, 2014, at 2:36 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> 
> On Jul 11, 2014, at 9:15 AM, Tim Richter-Heitmann <trichter at uni-bremen.de> wrote:
> 
>> Hi there!
>> 
>> I have huge datafile of 600 columns 360 samples:
>> 
>> data <- read.table("small.txt", header = TRUE, sep = "\t", dec = ".", 
>> row.names=1)
>> 
>> The txt.file (compiled with excel) is showing me only numbers, however R 
>> gives me the structure of ANY column as "factor".
>> 
>> When i try "stringsAsFactors=FALSE" in the read command, the structure 
>> of the dataset becomes "character."
>> 
>> When i try as.numeric(data), i get
>> 
>> Error: (list) object cannot be coerced to type 'double'
>> 
>> 
>> even, if i try to subset columns with [].
>> 
>> 
>> When i try as.numeric on single columns with $, i am successful, but the numbers dont make any sense at all, as the factors are not converted by their levels:
>> 
>> 
>> Factor w/ 358 levels "0,123111694",..: 11 14 50 12 38 44 13 76 31 30
>> 
>> 
>> becomes
>> 
>> 
>> num  11 14 50 12 38 44 13 76 31 30
>> 
>> 
>> whereas i would need the levels, though!
>> 
>> 
>> I suspect excel to mess up the "save as tab-delimited text", but the text file seems fine with me on surface (i dont know how the numbers are stored  internally). I just see correct numbers, also the View command
>> yields the correct content.
>> 
>> 
>> 
>> Anyone knows help? Its pretty annoying.
>> 
>> 
>> 
>> Thank you!
> 
> 
> Hi,
> 
> See:
> 
>  http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-convert-factors-to-numeric_003f
> 
> Regards,
> 
> Marc Schwartz


Sorry, I just noted that you defined dec = "." in your call to read.table(), whereas it appears that a comma (,) is being used as a decimal separator in your source data.

Modify the dec = "." to dec = "," and that should obviate the need to convert the numeric values to factors during import. They should be converted to numerics right away.

For example:

> str(read.table(textConnection("0,1234"), dec = "."))
'data.frame':	1 obs. of  1 variable:
 $ V1: Factor w/ 1 level "0,1234": 1

> str(read.table(textConnection("0,1234"), dec = ","))
'data.frame':	1 obs. of  1 variable:
 $ V1: num 0.123


Regards,

Marc


From sarah.goslee at gmail.com  Fri Jul 11 21:44:53 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 11 Jul 2014 15:44:53 -0400
Subject: [R] Merge rows
In-Reply-To: <CAAJSdjjVu=AciFTON8cJj_WT+Sb0yxwgCC1Xucy85NaqizKreQ@mail.gmail.com>
References: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
	<CAM_vjukHVOj-kLJkjxg4Fq3HMjB8Nc=jWjDdZwGXxv77ua69EQ@mail.gmail.com>
	<CAAJSdjjVu=AciFTON8cJj_WT+Sb0yxwgCC1Xucy85NaqizKreQ@mail.gmail.com>
Message-ID: <CAM_vjunuF4h=05+pctO1ri1jAvLfdVTm75uKpPVJegA6RidaSg@mail.gmail.com>

Hi John,

I don't think your x2 is right, but who knows?

One possible approach would be:
R> lapply(split(x2$recipients,  unique(x2$sender)), paste, collapse=", ")
$`a at email.com`
[1] "b at email.com, f at email.com"

$`r at email.com`
[1] "c(\"c at email.com\", \"d at email.com\"), h at email.com"

but again, who knows exactly what the OP wants?

You sent this just to me; I've copied the R-help list back again.

Sarah

On Fri, Jul 11, 2014 at 3:19 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Fri, Jul 11, 2014 at 11:27 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> Hi Ryan,
>>
>> We can't tell from your example what structure your original data are
>> in, nor what your output is intended to look like, or for that matter
>> how you got from one to the other. Please don't post in HTML because
>> it gets mangled!
>>
>> Using dput() to provide your example data is the best thing, because
>> that preserves R structures. And an R-format example of your desired
>> output would also be helpful.
>>
>> Sarah
>
> In a, perhaps vain, attempt to be helpful, I think the following
> output from what I constructed myself will show what the OP was
> talking about:
>
>> dput(x2)
> structure(list(sender = c("a at email.com", "a at email.com", "r at email.com",
> "r at email.com"), recipients = list("b at email.com", c("c at email.com",
> "d at email.com"), "f at email.com", "h at email.com")), .Names = c("sender",
> "recipients"), row.names = c(NA, -4L), class = "data.frame")
>
> I probably should have called it "mailingList" instead of x2, no?
>
> Now, after "wasting" too much time, perhaps somebody will come up with
> a solution. I could "brute force" something (yes, you can write
> FORTRAN style code in R!). But have been "sensitized" from doing so by
> others.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


-- 
Sarah Goslee
http://www.sarahgoslee.com


From dcarlson at tamu.edu  Fri Jul 11 21:46:12 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 11 Jul 2014 19:46:12 +0000
Subject: [R] Problems with read.table and data structure
In-Reply-To: <53BFF190.2030801@uni-bremen.de>
References: <53BFF190.2030801@uni-bremen.de>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8791D@mb02.ads.tamu.edu>

It is hard to diagnose without looking at the file. For example

readLines("small.txt", n=5)

would print out the first five lines that might show problems with wrapping the lines. What does dim(data) give you? Are you getting all 360 samples and 600 columns? You could also try using the colClasses=
argument in read.table(), eg. colClasses=rep("numeric", 600). You could also have Excel save in csv format and use read.csv().

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Tim Richter-Heitmann
Sent: Friday, July 11, 2014 9:16 AM
To: R-help at r-project.org
Subject: [R] Problems with read.table and data structure

Hi there!

I have huge datafile of 600 columns 360 samples:

data <- read.table("small.txt", header = TRUE, sep = "\t", dec = ".", 
row.names=1)

The txt.file (compiled with excel) is showing me only numbers, however R 
gives me the structure of ANY column as "factor".

When i try "stringsAsFactors=FALSE" in the read command, the structure 
of the dataset becomes "character."

When i try as.numeric(data), i get

Error: (list) object cannot be coerced to type 'double'


even, if i try to subset columns with [].


When i try as.numeric on single columns with $, i am successful, but the numbers dont make any sense at all, as the factors are not converted by their levels:


Factor w/ 358 levels "0,123111694",..: 11 14 50 12 38 44 13 76 31 30


becomes


num  11 14 50 12 38 44 13 76 31 30


whereas i would need the levels, though!


I suspect excel to mess up the "save as tab-delimited text", but the text file seems fine with me on surface (i dont know how the numbers are stored  internally). I just see correct numbers, also the View command
yields the correct content.



Anyone knows help? Its pretty annoying.



Thank you!

-- 
Tim Richter-Heitmann


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Jul 11 21:49:31 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 11 Jul 2014 12:49:31 -0700
Subject: [R] Problems with read.table and data structure
In-Reply-To: <53BFF190.2030801@uni-bremen.de>
References: <53BFF190.2030801@uni-bremen.de>
Message-ID: <CAF8bMcZUM3GxiGPeUcgeEN1y+p62Pb=dvb-GsSza_tMnwhN18A@mail.gmail.com>

> data <- read.table("small.txt", header = TRUE, sep = "\t", dec = ".", row.names=1)
> ...
> Factor w/ 358 levels "0,123111694",..: 11 14 50 12 38 44 13 76 31 30

It looks like your data file used commas for the decimal point.  Is that right?
You used dec="." when reading it; does dec="," work better?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jul 11, 2014 at 7:15 AM, Tim Richter-Heitmann
<trichter at uni-bremen.de> wrote:
>
> Hi there!
>
> I have huge datafile of 600 columns 360 samples:
>
> data <- read.table("small.txt", header = TRUE, sep = "\t", dec = ".",
> row.names=1)
>
> The txt.file (compiled with excel) is showing me only numbers, however R
> gives me the structure of ANY column as "factor".
>
> When i try "stringsAsFactors=FALSE" in the read command, the structure
> of the dataset becomes "character."
>
> When i try as.numeric(data), i get
>
> Error: (list) object cannot be coerced to type 'double'
>
>
> even, if i try to subset columns with [].
>
>
> When i try as.numeric on single columns with $, i am successful, but the numbers dont make any sense at all, as the factors are not converted by their levels:
>
>
> Factor w/ 358 levels "0,123111694",..: 11 14 50 12 38 44 13 76 31 30
>
>
> becomes
>
>
> num  11 14 50 12 38 44 13 76 31 30
>
>
> whereas i would need the levels, though!
>
>
> I suspect excel to mess up the "save as tab-delimited text", but the text file seems fine with me on surface (i dont know how the numbers are stored  internally). I just see correct numbers, also the View command
> yields the correct content.
>
>
>
> Anyone knows help? Its pretty annoying.
>
>
>
> Thank you!
>
> --
> Tim Richter-Heitmann
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Jul 11 23:35:46 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 11 Jul 2014 14:35:46 -0700
Subject: [R] CI for nlme predictions
In-Reply-To: <CACYeG1jjz0wm2V2YB0NYKQ_eFGoPUsSZcC6v_Ww9bgtnODkNcg@mail.gmail.com>
References: <CACYeG1jjz0wm2V2YB0NYKQ_eFGoPUsSZcC6v_Ww9bgtnODkNcg@mail.gmail.com>
Message-ID: <CACk-te2w53ZK+sJqzVS8ZS66rvnHhw7w+xKeJVkv3sLh9kcFQA@mail.gmail.com>

Full Disclosure: I am not an expert on this and this requires an
expert's answer.

But my understanding is that inference in mixed effect models is an
entirely nontrivial matter -- i.e. exactly what you want must be
clearly defined (what variance components to include) and the
distributions of the statistics are complex, with various
approximations available depending on the assumptions one is willing
to make.

The simple situation for linear models with closed form expressions
and pivots is wholly different in nonlinear models (which even linear
mixed effects models are). Profile likelihoods and bootstrapping may
be more appropriate here, but you've got to know what you're doing. If
you do not, I suggest you get local help.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Jul 11, 2014 at 11:43 AM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
> I am running a mixed effects model with random intercepts
>
> fit.courseCross <- lme(fixed= zGrade ~ Rep  + ISE
> +P7APrior+Female+White+HSGPA+MATH+Years+Course+Course*P7APrior ,
>                   random= ~1|SID,
>                   data = Master.complete[Master.complete$Course != "P7A",])
> where all variables are factors except for HSGPA, MATH and Years
>
> I noticed that predict.lm has an option for standard error, but
> predict.nlme does not.  I understand that this might be because there is a
> difference between SE's that conditioned or not on random effects.
>
> I have looked at this stack overflow question
> <http://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit>
> (extract-prediction-band-from-lme-fit) but do not understand what is being
> done.
>
> And would like to show the predicted fit of zGrade vs Years with a
> confidence interval.
> a-la ggplot's geom_smooth.  The particular intercept does not mater ( I
> don't care what the intercept is, though given a choice I'd prefer grand
> mean centered) I would be happy with either conditional on unconditional
> CI's.
>
> Robert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mkbartl at gmail.com  Sat Jul 12 00:18:38 2014
From: mkbartl at gmail.com (Megan Bartlett)
Date: Fri, 11 Jul 2014 15:18:38 -0700
Subject: [R] Correlating multiple effect sizes within a study to study-level
 predictors: metafor package
Message-ID: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/babaa7b6/attachment.pl>

From anirudh.kondaveeti at gmail.com  Sat Jul 12 01:46:16 2014
From: anirudh.kondaveeti at gmail.com (Anirudh Kondaveeti)
Date: Fri, 11 Jul 2014 16:46:16 -0700
Subject: [R] Finding sparse cuts in a graph
Message-ID: <CAGYSssfW93+AVfs2vRPF2JKo8=UxoSNt13htbSNBg5C0bQ3OSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140711/e8e46d9e/attachment.pl>

From miles2yang at gmail.com  Sat Jul 12 06:44:43 2014
From: miles2yang at gmail.com (Miles Yang)
Date: Sat, 12 Jul 2014 14:44:43 +1000
Subject: [R] Zeta-squared transformation use R?
Message-ID: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/d527317d/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Jul 12 08:01:44 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 11 Jul 2014 23:01:44 -0700
Subject: [R] Zeta-squared transformation use R?
In-Reply-To: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>
References: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>
Message-ID: <0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>

Have you tried

RSiteSearch("zeta squared")

?

Someone may recognize this, but it never hurts to communicate where you have already looked.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 11, 2014 9:44:43 PM PDT, Miles Yang <miles2yang at gmail.com> wrote:
>Hi R-helpers,
>
>Is there any packages can do "*zeta-squared transformation*"?
>
>The Zeta-squared transformation comes from the following article:
>Standardizing Variables in Multiplicative Choice Models
>Lee G. Cooper and Masao Nakanishi
>Journal of Consumer Research, Vol. 10, No. 1 (Jun., 1983), pp. 96-108
>
>Thanks for any help in advance.
>
>miles


From jim at bitwrit.com.au  Sat Jul 12 09:07:24 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 12 Jul 2014 17:07:24 +1000
Subject: [R] Merge rows
In-Reply-To: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
References: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
Message-ID: <1969373.rnpqOJh24M@localhost.localdomain>

On Fri, 11 Jul 2014 12:19:39 PM Ryan de Vera wrote:
> Hello all,
> 
> I have a data frame filled with senders and recipients. Some of the 
senders
> have multiple rows with different recipients and I want to merge 
those
> rows. For example I have
> 
> a at email.com     b at email.com
> a at email.com     c at email.com     d at email.com
> r at email.com      f at email.com
> r at email.com      h at email.com
> 
> I want this to become
> 
> a at email.com     b at email.com     c at email.com     d at email.com
> r at email.com      f at email.com      h at email.com
> 
> How would I go about doing this?
> 
Hi Ryan,
This is a bit messy, but assuming that you do have a data frame like 
this:

rdvdf<-
data.frame(sender=rep(c("a at email.com","r at email.com"),each=2),
 recipient1=c("b at email.com","c at email.com","f at email.com","h at email.com"),
 recipient2=c(NA,"d at email.com",NA,NA))

you can try this:

newdat<-list()
senderno<-1
for(sndr in unique(rdvdf$sender)) {
 newvec<-
  as.character(unique(unlist(rdvdf[rdvdf$sender==sndr,])))
 newdat[[senderno]]<-newvec[!is.na(newvec)]
 senderno<-senderno+1
}

Jim


From miles2yang at gmail.com  Sat Jul 12 13:31:03 2014
From: miles2yang at gmail.com (Miles Yang)
Date: Sat, 12 Jul 2014 21:31:03 +1000
Subject: [R] Zeta-squared transformation use R?
In-Reply-To: <0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>
References: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>
	<0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>
Message-ID: <CAMPud13J19N7yTZhEbYzdrbPLw9U8N_cSNak=8q25ZYSFi29Sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/37911106/attachment.pl>

From zadig_1 at excite.com  Sat Jul 12 15:25:45 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 12 Jul 2014 09:25:45 -0400
Subject: [R] lapply returns NULL ?
Message-ID: <20140712092545.14291@web006.roc2.bluetie.com>



Dear all,

I have a list of arrays :

foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1)) 

> foo
$A
[1] 1 3

$B
[1] 1 2

$C
[1] 3 1

> if( foo$C[1] == 1 ) foo$C[1]

>  lapply(foo, function(x) if(x[1] == 1 )  x  )

$A
[1] 1 3

$B
[1] 1 2

$C
NULL

I don't want to list $C NULL  in the output. How I can do that ? 

From ligges at statistik.tu-dortmund.de  Sat Jul 12 15:37:44 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 12 Jul 2014 15:37:44 +0200
Subject: [R] lapply returns NULL ?
In-Reply-To: <20140712092545.14291@web006.roc2.bluetie.com>
References: <20140712092545.14291@web006.roc2.bluetie.com>
Message-ID: <53C13A28.2000002@statistik.tu-dortmund.de>



On 12.07.2014 15:25, ce wrote:
>
>
> Dear all,
>
> I have a list of arrays :
>
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>
>> foo
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> [1] 3 1
>
>> if( foo$C[1] == 1 ) foo$C[1]
>
>>   lapply(foo, function(x) if(x[1] == 1 )  x  )
>
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> NULL
>
> I don't want to list $C NULL  in the output. How I can do that ?

Either use your own print function or, if you do not want NULL elements 
in the object, remove them.

Best,
Uwe Ligges


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From david.stevens at usu.edu  Sat Jul 12 16:33:45 2014
From: david.stevens at usu.edu (David Stevens)
Date: Sat, 12 Jul 2014 08:33:45 -0600
Subject: [R] Merge rows
In-Reply-To: <1969373.rnpqOJh24M@localhost.localdomain>
References: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>
	<1969373.rnpqOJh24M@localhost.localdomain>
Message-ID: <53C14749.5020006@usu.edu>

This is a (very) slightly modified version of Jim's reply that takes the 
sender's email our of the list element and uses it as the name so it can 
be accessed as newdat$'senders email' or newdat[['senders email']]

newdat<-list()
for(sndr in unique(rdvdf$sender)) {
  newvec<-
   as.character(unique(unlist(rdvdf[rdvdf$sender==sndr,])))
  newdat[[(sndr)]]<-newvec[which(!is.na(newvec))][-1]
}

David

On 7/12/2014 1:07 AM, Jim Lemon wrote:
> On Fri, 11 Jul 2014 12:19:39 PM Ryan de Vera wrote:
>> Hello all,
>>
>> I have a data frame filled with senders and recipients. Some of the
> senders
>> have multiple rows with different recipients and I want to merge
> those
>> rows. For example I have
>>
>> a at email.com     b at email.com
>> a at email.com     c at email.com     d at email.com
>> r at email.com      f at email.com
>> r at email.com      h at email.com
>>
>> I want this to become
>>
>> a at email.com     b at email.com     c at email.com     d at email.com
>> r at email.com      f at email.com      h at email.com
>>
>> How would I go about doing this?
>>
> Hi Ryan,
> This is a bit messy, but assuming that you do have a data frame like
> this:
>
> rdvdf<-
> data.frame(sender=rep(c("a at email.com","r at email.com"),each=2),
>   recipient1=c("b at email.com","c at email.com","f at email.com","h at email.com"),
>   recipient2=c(NA,"d at email.com",NA,NA))
>
> you can try this:
>
> newdat<-list()
> senderno<-1
> for(sndr in unique(rdvdf$sender)) {
>   newvec<-
>    as.character(unique(unlist(rdvdf[rdvdf$sender==sndr,])))
>   newdat[[senderno]]<-newvec[!is.na(newvec)]
>   senderno<-senderno+1
> }
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From ruipbarradas at sapo.pt  Sat Jul 12 16:37:50 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 12 Jul 2014 15:37:50 +0100
Subject: [R] lapply returns NULL ?
In-Reply-To: <20140712092545.14291@web006.roc2.bluetie.com>
References: <20140712092545.14291@web006.roc2.bluetie.com>
Message-ID: <53C1483E.9040709@sapo.pt>

Hello,

Try the following.

res <- lapply(foo, function(x) if(x[1] == 1 )  x  )
res[!sapply(res, is.null)]

Hope this helps,

Rui Barradas

Em 12-07-2014 14:25, ce escreveu:
>
>
> Dear all,
>
> I have a list of arrays :
>
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>
>> foo
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> [1] 3 1
>
>> if( foo$C[1] == 1 ) foo$C[1]
>
>>   lapply(foo, function(x) if(x[1] == 1 )  x  )
>
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> NULL
>
> I don't want to list $C NULL  in the output. How I can do that ?
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Sat Jul 12 16:37:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 12 Jul 2014 07:37:55 -0700
Subject: [R] lapply returns NULL ?
In-Reply-To: <53C13A28.2000002@statistik.tu-dortmund.de>
References: <20140712092545.14291@web006.roc2.bluetie.com>
	<53C13A28.2000002@statistik.tu-dortmund.de>
Message-ID: <85f054fb-7af7-453e-bb58-3fa2fb3f9ef7@email.android.com>

I think that removing them is something the OP doesn't understand how to do.

The lapply function ALWAYS produces an output element for every input element. If this is not what you want then you need to choose a looping structure that is not so tightly linked to the input, such as a for loop (untested):

result <- list()
for (nm in names(foo)) {
  if ( 1 == foo[[nm]][1] ) {
    result[[ nm ]] <- foo[[ nm ]]
  }
}
result

or use vector indexing (lists are a special kind of vector) with the loop result:

foo[ sapply(foo,function(v){1==v[1]}) ]

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 12, 2014 6:37:44 AM PDT, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>On 12.07.2014 15:25, ce wrote:
>>
>>
>> Dear all,
>>
>> I have a list of arrays :
>>
>> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>>
>>> foo
>> $A
>> [1] 1 3
>>
>> $B
>> [1] 1 2
>>
>> $C
>> [1] 3 1
>>
>>> if( foo$C[1] == 1 ) foo$C[1]
>>
>>>   lapply(foo, function(x) if(x[1] == 1 )  x  )
>>
>> $A
>> [1] 1 3
>>
>> $B
>> [1] 1 2
>>
>> $C
>> NULL
>>
>> I don't want to list $C NULL  in the output. How I can do that ?
>
>Either use your own print function or, if you do not want NULL elements
>
>in the object, remove them.
>
>Best,
>Uwe Ligges
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sat Jul 12 17:11:33 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 12 Jul 2014 11:11:33 -0400
Subject: [R] lapply returns NULL ?
Message-ID: <20140712111133.22632@web007.roc2.bluetie.com>


Thanks Jeff et. all,

This is exactly what I needed.

-----Original Message-----
From: "Jeff Newmiller" [jdnewmil at dcn.davis.CA.us]
Date: 07/12/2014 10:38 AM
To: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>, "ce" <zadig_1 at excite.com>, r-help at r-project.org
Subject: Re: [R] lapply returns NULL ?

I think that removing them is something the OP doesn't understand how to do.

The lapply function ALWAYS produces an output element for every input element. If this is not what you want then you need to choose a looping structure that is not so tightly linked to the input, such as a for loop (untested):

result <- list()
for (nm in names(foo)) {
  if ( 1 == foo[[nm]][1] ) {
    result[[ nm ]] <- foo[[ nm ]]
  }
}
result

or use vector indexing (lists are a special kind of vector) with the loop result:

foo[ sapply(foo,function(v){1==v[1]}) ]

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 12, 2014 6:37:44 AM PDT, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>On 12.07.2014 15:25, ce wrote:
>>
>>
>> Dear all,
>>
>> I have a list of arrays :
>>
>> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>>
>>> foo
>> $A
>> [1] 1 3
>>
>> $B
>> [1] 1 2
>>
>> $C
>> [1] 3 1
>>
>>> if( foo$C[1] == 1 ) foo$C[1]
>>
>>>   lapply(foo, function(x) if(x[1] == 1 )  x  )
>>
>> $A
>> [1] 1 3
>>
>> $B
>> [1] 1 2
>>
>> $C
>> NULL
>>
>> I don't want to list $C NULL  in the output. How I can do that ?
>
>Either use your own print function or, if you do not want NULL elements
>
>in the object, remove them.
>
>Best,
>Uwe Ligges
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From luke-tierney at uiowa.edu  Sat Jul 12 17:49:12 2014
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sat, 12 Jul 2014 10:49:12 -0500
Subject: [R] lapply returns NULL ?
In-Reply-To: <20140712111133.22632@web007.roc2.bluetie.com>
References: <20140712111133.22632@web007.roc2.bluetie.com>
Message-ID: <alpine.DEB.2.02.1407121048520.20288@luke-Latitude>

Another option is

Filter(function(x) x[1] == 1, foo)

Best,

luke
On Sat, 12 Jul 2014, ce wrote:

>
> Thanks Jeff et. all,
>
> This is exactly what I needed.
>
> -----Original Message-----
> From: "Jeff Newmiller" [jdnewmil at dcn.davis.CA.us]
> Date: 07/12/2014 10:38 AM
> To: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>, "ce" <zadig_1 at excite.com>, r-help at r-project.org
> Subject: Re: [R] lapply returns NULL ?
>
> I think that removing them is something the OP doesn't understand how to do.
>
> The lapply function ALWAYS produces an output element for every input element. If this is not what you want then you need to choose a looping structure that is not so tightly linked to the input, such as a for loop (untested):
>
> result <- list()
> for (nm in names(foo)) {
>  if ( 1 == foo[[nm]][1] ) {
>    result[[ nm ]] <- foo[[ nm ]]
>  }
> }
> result
>
> or use vector indexing (lists are a special kind of vector) with the loop result:
>
> foo[ sapply(foo,function(v){1==v[1]}) ]
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On July 12, 2014 6:37:44 AM PDT, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>>
>>
>> On 12.07.2014 15:25, ce wrote:
>>>
>>>
>>> Dear all,
>>>
>>> I have a list of arrays :
>>>
>>> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>>>
>>>> foo
>>> $A
>>> [1] 1 3
>>>
>>> $B
>>> [1] 1 2
>>>
>>> $C
>>> [1] 3 1
>>>
>>>> if( foo$C[1] == 1 ) foo$C[1]
>>>
>>>>   lapply(foo, function(x) if(x[1] == 1 )  x  )
>>>
>>> $A
>>> [1] 1 3
>>>
>>> $B
>>> [1] 1 2
>>>
>>> $C
>>> NULL
>>>
>>> I don't want to list $C NULL  in the output. How I can do that ?
>>
>> Either use your own print function or, if you do not want NULL elements
>>
>> in the object, remove them.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From j.a.timms at newcastle.ac.uk  Sat Jul 12 16:11:46 2014
From: j.a.timms at newcastle.ac.uk (Jessica Timms)
Date: Sat, 12 Jul 2014 14:11:46 +0000
Subject: [R] lm and 450k data
Message-ID: <1405174301697.92244@newcastle.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/921d2eb1/attachment.pl>

From kevinkunzmann at gmx.net  Sat Jul 12 13:25:34 2014
From: kevinkunzmann at gmx.net (Kevin Kunzmann)
Date: Sat, 12 Jul 2014 13:25:34 +0200
Subject: [R] multiplicative error
Message-ID: <53C11B2E.4070603@gmx.net>

Hi,

I am currently trying to build a regression model for calibration of 
HPLC outputs. I decided to use a multiplicative error model:

Y_i = (a*X_i + b)*eps_i

where the eps_i ~ iid N(0, s^2). Now I am having a hard time estimating 
my parameters ;) So the idea was to apply log() to both sides:

Z_i = log(Y_i) = log(a*X_i + b) + log(eps_i)

Now the additive errors are lognormally distributed and I could 
formulate this as a GLM

Z_i = g^(-1)(a*X_i + b) + iota_i

where iota_i are lognormal and the link function g(x) is exp(x) as 
g^(-1) = log. So wouldn't the corresponding call for R have to be 
something like:

glm(z ~ x, data=data.frame(x=x, z=log(y)), family=lognormal(link='exp'))

this however is not working (there is no lognormal family and no exp 
link function ^^. How do I estimate those parameters? This seems to be a 
pretty standard problem to me...

Thanks for your comments!

Kevin


From bbukar at nda.edu.ng  Sat Jul 12 17:25:35 2014
From: bbukar at nda.edu.ng (Baba Bukar)
Date: Sat, 12 Jul 2014 16:25:35 +0100
Subject: [R] Metropolis-within Gibbs sampling
Message-ID: <CAHYO52eAwT1RATOJhSv62zeCfad=h-m07FPGbHYNWxhT1uyO9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/2c5fa501/attachment.pl>

From optionsraghu at gmail.com  Sat Jul 12 20:50:59 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sat, 12 Jul 2014 19:50:59 +0100
Subject: [R] Fwd:  lm and 450k data
In-Reply-To: <CADgEnD=NVK7OK0gMo7zhrt1XN6oTb3rXcqNcG6tHH++6oHB-DQ@mail.gmail.com>
References: <1405174301697.92244@newcastle.ac.uk>
	<CADgEnD=NVK7OK0gMo7zhrt1XN6oTb3rXcqNcG6tHH++6oHB-DQ@mail.gmail.com>
Message-ID: <CADgEnD=NHq6EwZRqBZ1v2hFH_3-kOWhor-E0Vsjet5HDKarUDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/e5569f85/attachment.pl>

From louise.stevenson at lifesci.ucsb.edu  Sat Jul 12 22:47:08 2014
From: louise.stevenson at lifesci.ucsb.edu (Louise Stevenson)
Date: Sat, 12 Jul 2014 13:47:08 -0700
Subject: [R] R GUI for undergraduate lab class?
References: <mailman.541.1405194503.4543.r-help@r-project.org>
Message-ID: <41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>

Hi,

I'm working on a new set of simple, ecological modeling exercises for our
campus' undergraduate Introductory Biology lab series. The students work
with simple population models by looking at graphs and seeing how changing
parameter values and initial population sizes changes how the populations
fluctuate through time. Does anyone know of an existing R GUI or any other
interface that would be good for an undergraduate setting? Basically I want
something that shows the students the model's output as graphs and lets them
change parameter values but the equations/coding itself is hidden such that
they can't change any of that. I want what Populus can do (a fantastic
program written for this exact purpose, info here:
http://www.cbs.umn.edu/research/resources/populus) but I want to be able to
upload data so the students can compare model outputs to real data and I
can't figure out how to get Populus to plot data. Any help would be very
much appreciated! Thank you!

Sincerely,
Louise Stevenson
Graduate Student, University of California, Santa Barbara
Department of Ecology, Evolution and Marine Biology


From roy.mendelssohn at noaa.gov  Sat Jul 12 22:56:56 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Sat, 12 Jul 2014 13:56:56 -0700
Subject: [R] R GUI for undergraduate lab class?
In-Reply-To: <41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
References: <mailman.541.1405194503.4543.r-help@r-project.org>
	<41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
Message-ID: <13EC0AEA-5CCA-4443-9BE1-DA630098C465@noaa.gov>

There are probably several solutions to what you want to do, but you might look at Shiny as one possibility:

http://shiny.rstudio.com

-Roy M.
On Jul 12, 2014, at 1:47 PM, Louise Stevenson <louise.stevenson at lifesci.ucsb.edu> wrote:

> Hi,
> 
> I'm working on a new set of simple, ecological modeling exercises for our
> campus' undergraduate Introductory Biology lab series. The students work
> with simple population models by looking at graphs and seeing how changing
> parameter values and initial population sizes changes how the populations
> fluctuate through time. Does anyone know of an existing R GUI or any other
> interface that would be good for an undergraduate setting? Basically I want
> something that shows the students the model's output as graphs and lets them
> change parameter values but the equations/coding itself is hidden such that
> they can't change any of that. I want what Populus can do (a fantastic
> program written for this exact purpose, info here:
> http://www.cbs.umn.edu/research/resources/populus) but I want to be able to
> upload data so the students can compare model outputs to real data and I
> can't figure out how to get Populus to plot data. Any help would be very
> much appreciated! Thank you!
> 
> Sincerely,
> Louise Stevenson
> Graduate Student, University of California, Santa Barbara
> Department of Ecology, Evolution and Marine Biology
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From rmh at temple.edu  Sat Jul 12 23:15:03 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 12 Jul 2014 17:15:03 -0400
Subject: [R] R GUI for undergraduate lab class?
In-Reply-To: <41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
References: <mailman.541.1405194503.4543.r-help@r-project.org>
	<41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
Message-ID: <CAGx1TMCyx2Eqw4HRmuDO0OGZeJmjayuyPJ0AwRSNsvo4yPHVWA@mail.gmail.com>

I recommend RExcel.
RExcel is an add-in for Windows Excel that gives complete access to
the entirety of R
from Windows Excel.  It is free for educational use.

The program by Erich Neuwirth is at http://rcom.univie.ac.at
Our book, designed as a supplement to any text, is at
http://www.springer.com/978-1-4419-0051-7

Rich


On Sat, Jul 12, 2014 at 4:47 PM, Louise Stevenson
<louise.stevenson at lifesci.ucsb.edu> wrote:
> Hi,
>
> I'm working on a new set of simple, ecological modeling exercises for our
> campus' undergraduate Introductory Biology lab series. The students work
> with simple population models by looking at graphs and seeing how changing
> parameter values and initial population sizes changes how the populations
> fluctuate through time. Does anyone know of an existing R GUI or any other
> interface that would be good for an undergraduate setting? Basically I want
> something that shows the students the model's output as graphs and lets them
> change parameter values but the equations/coding itself is hidden such that
> they can't change any of that. I want what Populus can do (a fantastic
> program written for this exact purpose, info here:
> http://www.cbs.umn.edu/research/resources/populus) but I want to be able to
> upload data so the students can compare model outputs to real data and I
> can't figure out how to get Populus to plot data. Any help would be very
> much appreciated! Thank you!
>
> Sincerely,
> Louise Stevenson
> Graduate Student, University of California, Santa Barbara
> Department of Ecology, Evolution and Marine Biology
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jul 13 00:00:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 12 Jul 2014 15:00:48 -0700
Subject: [R] multiplicative error
In-Reply-To: <53C11B2E.4070603@gmx.net>
References: <53C11B2E.4070603@gmx.net>
Message-ID: <5021B5CF-D6D8-495F-956C-D956E2573179@comcast.net>


On Jul 12, 2014, at 4:25 AM, Kevin Kunzmann wrote:

> Hi,
> 
> I am currently trying to build a regression model for calibration of HPLC outputs. I decided to use a multiplicative error model:
> 
> Y_i = (a*X_i + b)*eps_i
> 
> where the eps_i ~ iid N(0, s^2). Now I am having a hard time estimating my parameters ;) So the idea was to apply log() to both sides:
> 
> Z_i = log(Y_i) = log(a*X_i + b) + log(eps_i)
> 
> Now the additive errors are lognormally distributed and I could formulate this as a GLM
> 
> Z_i = g^(-1)(a*X_i + b) + iota_i
> 
> where iota_i are lognormal and the link function g(x) is exp(x) as g^(-1) = log. So wouldn't the corresponding call for R have to be something like:
> 
> glm(z ~ x, data=data.frame(x=x, z=log(y)), family=lognormal(link='exp'))
> 
> this however is not working (there is no lognormal family and no exp link function ^^. How do I estimate those parameters? This seems to be a pretty standard problem to me...

I would have imagined that this would do what was described in the beginning:

glm( y ~ x, data=data.frame(x,y), family="quasipoisson")

# family="poisson" would choke on non-integer y.

Link is `log` by default for this family and the model is multiplicative with poisson errors. It's admittedly not exactly log-normal errors, but should be sufficiently similar.

--
David Winsemius
Alameda, CA, USA


From monaly.mistry at gmail.com  Sun Jul 13 00:13:27 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Sat, 12 Jul 2014 23:13:27 +0100
Subject: [R] canonical correlation
Message-ID: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140712/b43e243c/attachment.pl>

From maitra.mbox.ignored at inbox.com  Sun Jul 13 04:12:54 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 12 Jul 2014 21:12:54 -0500
Subject: [R] R GUI for undergraduate lab class?
In-Reply-To: <41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
References: <mailman.541.1405194503.4543.r-help@r-project.org>
	<41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
Message-ID: <20140712211254.fde803cd5676c78fa01b7505@inbox.com>

Hi Louise,

I tried using Deducer (graphical frontend to R) in my introductory
class (Stat 105 at Iowa State University) for  civil and construction
engineers and this was a roaring success this year. The class itself
has a wee bit of software experience, which has previously been done
using JMP. Most instructors (graduate TAs, typically) haven't
particularly been enamoured of using JMP, so I decided to explore the
possibility of using a GUI version of R. 

I am not in general a great fan of any kind of GUI for my own
work: however, it makes sense for this kind of class and I wanted a
one-click solution for the Windoze user which would make it possible
for them to use R with minimal typing. (Windoze users are primarily
what made up the students in this this class.)

I looked at a few R packages: pmg (or Poor Man's GUI, which appeared to
not have been updated since 2009, so I am not sure how active this
project currently is) and Rcmdr (R commander). Both these packages
served my purpose for a limited amount, but were not able to do all the
aspects of regression needed in the class (in pmg's case, could not
calculate the residuals, but in the case of RCmdr's case, could not
provide a residuals plot without the entire plethora of diagnostics
also showing up) so I decided to look at other alternatives. Also,
installing Rcmdr (with its dependencies) was not particularly easy from
the student's perspective (in my view).

I found my solution in Deducer which actually has its own website:
www.deducer.org. For Windoze users, it is a one-click
installation. The beauty of this software, in my mind, is that it can do
a lot of things (including quite involved calculations)  and has its
entire suite of graphics built on the ggplot package. Being a GUI, one
has to look around for how to do particular things (which may not
always be in the place that I might thing is intuitive, but it is
there). The manual is generally decent: however, the graphics part of
the manual is perfunctory at best. And it uses Java, a resource hog I
generally abhor.

I sent the students the e-mail (below) on how to install (and come
prepared for the class last week so that we could do a demo and
examples). They did not have much issues. In fact, in class, I got
exactly one complaint: "Can't all this be done in excel?"
-- I completed this question for him: "... and also on pen and paper"
-- but other than that, most students have taken to it and turned in
their homeworks without much fuss. In fact, some have liked it and
explored with it. 

In our introductory classes, we have typically used JMP. But if some of
us prefer using an open-source option that is not encumbered by
patents and proprietary licenses but have been bothered by R's learning
curve, using it through Deducer might be a possible option.


Btw, here is the e-mail I sent my class on how to go about installing
Deducer (note that the instructions are from late January):



Dear students,

For Stat 105, we will be demonstrating Deducer which is
available at http://www.deducer.orgfor installation. Deducer is a
graphical frontend to the statistical software R.

If you are installing to Windows, please use:

http://neolab.stat.ucla.edu/cranstats/Deducer-R-2.15.0-win.exe

This will install all you need in a one-click operation.For other OS's,
please use:

http://www.deducer.org/pmwiki/index.php?n=Main.MacOSXInstallation

for MacOSX while for Linux, please use:

http://www.deducer.org/pmwiki/index.php?n=Main.LinuxInstallation

For both Mac and Linux, you will need to install R prior to instaling
Deducer and JGR. We will go through a demonstration of Chapter 4 using
Deducer in class tomorrow.

I hope that this helps!

Many thanks and best wishes,
Ranjan


On Sat, 12 Jul 2014 13:47:08 -0700 Louise Stevenson
<louise.stevenson at lifesci.ucsb.edu> wrote:

> Hi,
> 
> I'm working on a new set of simple, ecological modeling exercises for our
> campus' undergraduate Introductory Biology lab series. The students work
> with simple population models by looking at graphs and seeing how changing
> parameter values and initial population sizes changes how the populations
> fluctuate through time. Does anyone know of an existing R GUI or any other
> interface that would be good for an undergraduate setting? Basically I want
> something that shows the students the model's output as graphs and lets them
> change parameter values but the equations/coding itself is hidden such that
> they can't change any of that. I want what Populus can do (a fantastic
> program written for this exact purpose, info here:
> http://www.cbs.umn.edu/research/resources/populus) but I want to be able to
> upload data so the students can compare model outputs to real data and I
> can't figure out how to get Populus to plot data. Any help would be very
> much appreciated! Thank you!
> 
> Sincerely,
> Louise Stevenson
> Graduate Student, University of California, Santa Barbara
> Department of Ecology, Evolution and Marine Biology
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From nlange at hms.harvard.edu  Sun Jul 13 06:05:05 2014
From: nlange at hms.harvard.edu (Nicholas Lange)
Date: Sun, 13 Jul 2014 00:05:05 -0400
Subject: [R] gamm4 and lme4 error
Message-ID: <ED72C329-918E-4919-AD8C-A767AE2482EE@hms.harvard.edu>

Hello,

I'm running R.3.1.1 on Mac OS X 10.6.8 with gamm4 version 0.2-2 and lme4 version 1.1-7. I get the following error when trying to fit the simplest model I can think of:

> fit = gamm4( y ~ s(x))

Warning message:
In deviance.merMod(ret$mer) :
  deviance() is deprecated for REML fits; use REMLcrit for the REML criterion or deviance(.,REML=FALSE) for deviance calculated at the REML fit
>

Does anyone see what's wrong? Any answer would be greatly appreciated.

Nick


From optionsraghu at gmail.com  Sun Jul 13 10:00:52 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sun, 13 Jul 2014 09:00:52 +0100
Subject: [R] canonical correlation
In-Reply-To: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
Message-ID: <CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/7d596d99/attachment.pl>

From cscherb1 at gwdg.de  Sun Jul 13 12:05:05 2014
From: cscherb1 at gwdg.de (Christoph Scherber)
Date: Sun, 13 Jul 2014 12:05:05 +0200
Subject: [R] R GUI for undergraduate lab class?
Message-ID: <muq3k3frqd7gtha7uk61lgax.1405245905320@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/ff76d2c2/attachment.pl>

From Graham.Williams at togaware.com  Sun Jul 13 13:38:09 2014
From: Graham.Williams at togaware.com (Graham Williams)
Date: Sun, 13 Jul 2014 21:38:09 +1000
Subject: [R] Decision Tree
In-Reply-To: <CANtKHPU8wcbaHWr7Egdz6v6h8bEx0NTKb2JN_7pP3tFYY7rCsA@mail.gmail.com>
References: <CANtKHPWVRwyVaT5AMCoT=q8jynV8rYX_79jdkTGpAxqAT8o7DA@mail.gmail.com>
	<CAN5YmCEPeg5A0XOsn8MQz2Ma2D5aW-Qvsk5a8YC7e6AomgPCOw@mail.gmail.com>
	<CANtKHPU8wcbaHWr7Egdz6v6h8bEx0NTKb2JN_7pP3tFYY7rCsA@mail.gmail.com>
Message-ID: <CAMqPDFF-Nk-nqR042+12kPc0ski_VTFKYoRpuONvw+6tr12iPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/ec0115bd/attachment.pl>

From Graham.Williams at togaware.com  Sun Jul 13 13:40:13 2014
From: Graham.Williams at togaware.com (Graham Williams)
Date: Sun, 13 Jul 2014 21:40:13 +1000
Subject: [R] Basket Analysis in R: extract rules
In-Reply-To: <CANtKHPURe1a=RS+-4pKg2dJzmxdMY4D-8TjGGPZE853fZXQ=OQ@mail.gmail.com>
References: <CANtKHPURe1a=RS+-4pKg2dJzmxdMY4D-8TjGGPZE853fZXQ=OQ@mail.gmail.com>
Message-ID: <CAMqPDFF_je+iiiN1Nw06KGv6VFuaS+SndD9YaosHB8XBo_4DAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/36081176/attachment.pl>

From upananda.pani at gmail.com  Sun Jul 13 14:27:51 2014
From: upananda.pani at gmail.com (Upananda Pani)
Date: Sun, 13 Jul 2014 17:57:51 +0530
Subject: [R] non causality test and wavelet decompostion
Message-ID: <CAEezrQRJXE17L6ND_p+Tm8wy_cP8bZUvhWSUTkO2Np8Cg8AEtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/a8dc72c4/attachment.pl>

From jfox at mcmaster.ca  Sun Jul 13 16:14:23 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 13 Jul 2014 10:14:23 -0400
Subject: [R] canonical correlation
In-Reply-To: <CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
Message-ID: <web-518429871@cgpsrv2.cis.mcmaster.ca>

Dear Raghuraman and Monaly,

Why would one want to do canonical correlation with a single Y variable? The canonical correlation is just the R^2 from the LS regression of Y on the Xs.

Best,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
	
On Sun, 13 Jul 2014 09:00:52 +0100
 Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
> Try package CCA.
> 
> 
> On Sat, Jul 12, 2014 at 11:13 PM, Monaly Mistry <monaly.mistry at gmail.com>
> wrote:
> 
> > Hi,
> >
> > I was wondering if it's possible in R to do a canonical correlation with
> > only one dependent variable and several independent variables.
> >
> > I've tried using cc(X,Y) but I got an error message. In this case I had 1
> > dependent variable and 10 independent variables.
> >
> > Error in cor(X, use = "pairwise") :
> >   supply both 'x' and 'y' or a matrix-like 'x'
> >
> > When I use two dependent variables I don't get the error message.
> >
> > Best,
> >
> > Monaly.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sun Jul 13 16:16:42 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 13 Jul 2014 10:16:42 -0400
Subject: [R] canonical correlation
In-Reply-To: <26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
Message-ID: <web-518430017@cgpsrv2.cis.mcmaster.ca>

A small correction: I should have said "R", not "R^2".

John

On Sun, 13 Jul 2014 10:14:23 -0400
 "John Fox" <jfox at mcmaster.ca> wrote:
> Dear Raghuraman and Monaly,
> 
> Why would one want to do canonical correlation with a single Y variable? The canonical correlation is just the R^2 from the LS regression of Y on the Xs.
> 
> Best,
>  John
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 	
> 	
> On Sun, 13 Jul 2014 09:00:52 +0100
>  Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
> > Try package CCA.
> > 
> > 
> > On Sat, Jul 12, 2014 at 11:13 PM, Monaly Mistry <monaly.mistry at gmail.com>
> > wrote:
> > 
> > > Hi,
> > >
> > > I was wondering if it's possible in R to do a canonical correlation with
> > > only one dependent variable and several independent variables.
> > >
> > > I've tried using cc(X,Y) but I got an error message. In this case I had 1
> > > dependent variable and 10 independent variables.
> > >
> > > Error in cor(X, use = "pairwise") :
> > >   supply both 'x' and 'y' or a matrix-like 'x'
> > >
> > > When I use two dependent variables I don't get the error message.
> > >
> > > Best,
> > >
> > > Monaly.
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From monaly.mistry at gmail.com  Sun Jul 13 16:39:15 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Sun, 13 Jul 2014 15:39:15 +0100
Subject: [R] canonical correlation
In-Reply-To: <web-518430017@cgpsrv2.cis.mcmaster.ca>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/8e3b6d9c/attachment.pl>

From jfox at mcmaster.ca  Sun Jul 13 16:45:45 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 13 Jul 2014 10:45:45 -0400
Subject: [R] canonical correlation
In-Reply-To: <CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
Message-ID: <web-518431124@cgpsrv2.cis.mcmaster.ca>

Dear Monaly,

What you described in simply the multiple LS regression of Y on the Xs, which finds the linear combination of the Xs most correlated with Y. Canonical correlation and regression are appropriate when there is more than one Y.

Best,
 John

On Sun, 13 Jul 2014 15:39:15 +0100
 Monaly Mistry <monaly.mistry at gmail.com> wrote:
> Dear John,
> 
> In my final model I have 10 independent variables that account for the
> variation in my dependent variable, and I needed to visually demonstrate
> this relationship.  So I did a canonical correlation to get a linear
> combination of independent variables that that predicts the variation in my
> dependent variable to plot the relationship. Although I ended up using 2
> dependent variables in the canonical correlation analysis.
> 
> Best,
> 
> Monaly.
> 
> 
> On Sun, Jul 13, 2014 at 3:16 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> > A small correction: I should have said "R", not "R^2".
> >
> > John
> >
> > On Sun, 13 Jul 2014 10:14:23 -0400
> >  "John Fox" <jfox at mcmaster.ca> wrote:
> > > Dear Raghuraman and Monaly,
> > >
> > > Why would one want to do canonical correlation with a single Y variable?
> > The canonical correlation is just the R^2 from the LS regression of Y on
> > the Xs.
> > >
> > > Best,
> > >  John
> > >
> > > ------------------------------------------------
> > > John Fox, Professor
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > http://socserv.mcmaster.ca/jfox/
> > >
> > >
> > > On Sun, 13 Jul 2014 09:00:52 +0100
> > >  Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
> > > > Try package CCA.
> > > >
> > > >
> > > > On Sat, Jul 12, 2014 at 11:13 PM, Monaly Mistry <
> > monaly.mistry at gmail.com>
> > > > wrote:
> > > >
> > > > > Hi,
> > > > >
> > > > > I was wondering if it's possible in R to do a canonical correlation
> > with
> > > > > only one dependent variable and several independent variables.
> > > > >
> > > > > I've tried using cc(X,Y) but I got an error message. In this case I
> > had 1
> > > > > dependent variable and 10 independent variables.
> > > > >
> > > > > Error in cor(X, use = "pairwise") :
> > > > >   supply both 'x' and 'y' or a matrix-like 'x'
> > > > >
> > > > > When I use two dependent variables I don't get the error message.
> > > > >
> > > > > Best,
> > > > >
> > > > > Monaly.
> > > > >
> > > > >         [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > >
> > > >     [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Jul 13 17:03:37 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 13 Jul 2014 11:03:37 -0400
Subject: [R] Norton Virus program indicates that R3.1.1 is not reliable
Message-ID: <CAAxdm-66zFGFtyphJdaeowo6PPy=wgCVGEWmGm-zXGrdh0TgzQ@mail.gmail.com>

I was downloading the latest version of R from the CMU mirror and got
the following message (also tried the MTU mirror and got the same).
Has anyone else seen this?

========================
Filename: r-3.1.1-win.exe
Threat name: WS.Reputation.1
Full Path: c:\users\owner\downloads\r-3.1.1-win.exe

____________________________



Details
Unknown Community Usage,  Unknown Age,  Risk Medium





Origin
Downloaded from
 http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe





Activity
Actions performed: Actions performed: 1



____________________________



On computers as of
Not Available


Last Used
7/13/14 at 10:56:56


Startup Item
No


Launched
No


____________________________


Unknown
It is unknown how many users in the Norton Community have used this file.

Unknown
This file release is currently not known.

Medium
This file risk is medium.

Threat type: Insight Network Threat. There are many indications that
this file is untrustworthy and therefore not safe



____________________________


http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe

Downloaded File r-3.1.1-win.exe Threat name: WS.Reputation.1
 from cmu.edu

Source: External Media



____________________________

File Actions

File: c:\users\owner\downloads\ r-3.1.1-win.exe Removed
____________________________


File Thumbprint - SHA:
ce6fb76612aefc482583fb92f4f5c3cb8e8e3bf1a8dda97df7ec5caf746e53fe
File Thumbprint - MD5:
Not available


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


From jholtman at gmail.com  Sun Jul 13 17:14:25 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 13 Jul 2014 11:14:25 -0400
Subject: [R] 3.1.1-win.exe download
Message-ID: <CAAxdm-7hXAMTsBgR5rk+LTQRtJXmb+Jg-94VMK7Zqbc8fvw+Rw@mail.gmail.com>

I am also getting a message on another computer that has Symantec
Endpoint Protection that the 3.1.1-win.exe has been removed because of
"WS.Reputation.1"; here is what their website says about the error

=============

Updated:February 15, 2012 3:15:47 PMType:OtherRisk Impact:HighSystems
Affected:Windows XP, Windows Vista, Windows NT, Windows Server 2003,
Windows 2000

Behavior

WS.Reputation.1 is a detection for files that have a low reputation
score based on analyzing data from Symantec?s community of users and
therefore are likely to be security risks. Detections of this type are
based on Symantec?s reputation-based security technology. Because this
detection is based on a reputation score, it does not represent a
specific class of threat like adware or spyware, but instead applies
to all threat categories.

The reputation-based system uses "the wisdom of crowds" (Symantec?s
tens of millions of end users) connected to cloud-based intelligence
to compute a reputation score for an application, and in the process
identify malicious software in an entirely new way beyond traditional
signatures and behavior-based detection techniques.

===============

Guess I will have to wait until the 'reputation' is better based on
people downloading it.  Just wondering if anyone else saw the error.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


From jdnewmil at dcn.davis.CA.us  Sun Jul 13 17:17:00 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 13 Jul 2014 08:17:00 -0700
Subject: [R] Norton Virus program indicates that R3.1.1 is not reliable
In-Reply-To: <CAAxdm-66zFGFtyphJdaeowo6PPy=wgCVGEWmGm-zXGrdh0TgzQ@mail.gmail.com>
References: <CAAxdm-66zFGFtyphJdaeowo6PPy=wgCVGEWmGm-zXGrdh0TgzQ@mail.gmail.com>
Message-ID: <6d31b1f5-e21e-4247-bc5f-3174a18b3bba@email.android.com>

Have seen it. Had to override Norton and tell it to ignore the threat. Been awhile, don't off the top of my head remember how I did that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 13, 2014 8:03:37 AM PDT, jim holtman <jholtman at gmail.com> wrote:
>I was downloading the latest version of R from the CMU mirror and got
>the following message (also tried the MTU mirror and got the same).
>Has anyone else seen this?
>
>========================
>Filename: r-3.1.1-win.exe
>Threat name: WS.Reputation.1
>Full Path: c:\users\owner\downloads\r-3.1.1-win.exe
>
>____________________________
>
>
>
>Details
>Unknown Community Usage,  Unknown Age,  Risk Medium
>
>
>
>
>
>Origin
>Downloaded from
> http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>
>
>
>
>
>Activity
>Actions performed: Actions performed: 1
>
>
>
>____________________________
>
>
>
>On computers as of
>Not Available
>
>
>Last Used
>7/13/14 at 10:56:56
>
>
>Startup Item
>No
>
>
>Launched
>No
>
>
>____________________________
>
>
>Unknown
>It is unknown how many users in the Norton Community have used this
>file.
>
>Unknown
>This file release is currently not known.
>
>Medium
>This file risk is medium.
>
>Threat type: Insight Network Threat. There are many indications that
>this file is untrustworthy and therefore not safe
>
>
>
>____________________________
>
>
>http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>
>Downloaded File r-3.1.1-win.exe Threat name: WS.Reputation.1
> from cmu.edu
>
>Source: External Media
>
>
>
>____________________________
>
>File Actions
>
>File: c:\users\owner\downloads\ r-3.1.1-win.exe Removed
>____________________________
>
>
>File Thumbprint - SHA:
>ce6fb76612aefc482583fb92f4f5c3cb8e8e3bf1a8dda97df7ec5caf746e53fe
>File Thumbprint - MD5:
>Not available
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Jul 13 17:30:39 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 13 Jul 2014 11:30:39 -0400
Subject: [R] Norton Virus program indicates that R3.1.1 is not reliable
In-Reply-To: <6d31b1f5-e21e-4247-bc5f-3174a18b3bba@email.android.com>
References: <CAAxdm-66zFGFtyphJdaeowo6PPy=wgCVGEWmGm-zXGrdh0TgzQ@mail.gmail.com>
	<6d31b1f5-e21e-4247-bc5f-3174a18b3bba@email.android.com>
Message-ID: <CAAxdm-4Rfidy847D5JGX9HE=xjdQ+ekxBr8qAeHU=TVeHOmV=w@mail.gmail.com>

Glad to see that I am not the only one seeing the error.  I was
getting it on my other (company) computer that has Symantec and it
will not allow me to override and do the install.  Guess I will check
again in a couple of days and see it it clears up.  Will also check to
see if I can contact Norton and Symantec about the problem.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Jul 13, 2014 at 11:17 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Have seen it. Had to override Norton and tell it to ignore the threat. Been awhile, don't off the top of my head remember how I did that.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On July 13, 2014 8:03:37 AM PDT, jim holtman <jholtman at gmail.com> wrote:
>>I was downloading the latest version of R from the CMU mirror and got
>>the following message (also tried the MTU mirror and got the same).
>>Has anyone else seen this?
>>
>>========================
>>Filename: r-3.1.1-win.exe
>>Threat name: WS.Reputation.1
>>Full Path: c:\users\owner\downloads\r-3.1.1-win.exe
>>
>>____________________________
>>
>>
>>
>>Details
>>Unknown Community Usage,  Unknown Age,  Risk Medium
>>
>>
>>
>>
>>
>>Origin
>>Downloaded from
>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>>
>>
>>
>>
>>
>>Activity
>>Actions performed: Actions performed: 1
>>
>>
>>
>>____________________________
>>
>>
>>
>>On computers as of
>>Not Available
>>
>>
>>Last Used
>>7/13/14 at 10:56:56
>>
>>
>>Startup Item
>>No
>>
>>
>>Launched
>>No
>>
>>
>>____________________________
>>
>>
>>Unknown
>>It is unknown how many users in the Norton Community have used this
>>file.
>>
>>Unknown
>>This file release is currently not known.
>>
>>Medium
>>This file risk is medium.
>>
>>Threat type: Insight Network Threat. There are many indications that
>>this file is untrustworthy and therefore not safe
>>
>>
>>
>>____________________________
>>
>>
>>http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>>
>>Downloaded File r-3.1.1-win.exe Threat name: WS.Reputation.1
>> from cmu.edu
>>
>>Source: External Media
>>
>>
>>
>>____________________________
>>
>>File Actions
>>
>>File: c:\users\owner\downloads\ r-3.1.1-win.exe Removed
>>____________________________
>>
>>
>>File Thumbprint - SHA:
>>ce6fb76612aefc482583fb92f4f5c3cb8e8e3bf1a8dda97df7ec5caf746e53fe
>>File Thumbprint - MD5:
>>Not available
>>
>>
>>Jim Holtman
>>Data Munger Guru
>>
>>What is the problem that you are trying to solve?
>>Tell me what you want to do, not how you want to do it.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Sun Jul 13 17:47:16 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sun, 13 Jul 2014 10:47:16 -0500
Subject: [R] Norton Virus program indicates that R3.1.1 is not reliable
In-Reply-To: <CAAxdm-4Rfidy847D5JGX9HE=xjdQ+ekxBr8qAeHU=TVeHOmV=w@mail.gmail.com>
References: <CAAxdm-66zFGFtyphJdaeowo6PPy=wgCVGEWmGm-zXGrdh0TgzQ@mail.gmail.com>
	<6d31b1f5-e21e-4247-bc5f-3174a18b3bba@email.android.com>
	<CAAxdm-4Rfidy847D5JGX9HE=xjdQ+ekxBr8qAeHU=TVeHOmV=w@mail.gmail.com>
Message-ID: <27F02192-6780-42AE-B8D5-84FAE6F9C6E4@me.com>

Jim,

You can file a Type I error on the file here:

  https://submit.symantec.com/false_positive/

rather than waiting.

I had seen similar reports, not on R, but elsewhere with this particular Symantec community based detection. I am not a user, but since it appears to be a community based system for this detection, it will take the Symantec user community to file reports and get it removed from detection.

Regards,

Marc Schwartz

On Jul 13, 2014, at 10:30 AM, jim holtman <jholtman at gmail.com> wrote:

> Glad to see that I am not the only one seeing the error.  I was
> getting it on my other (company) computer that has Symantec and it
> will not allow me to override and do the install.  Guess I will check
> again in a couple of days and see it it clears up.  Will also check to
> see if I can contact Norton and Symantec about the problem.
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Sun, Jul 13, 2014 at 11:17 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Have seen it. Had to override Norton and tell it to ignore the threat. Been awhile, don't off the top of my head remember how I did that.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On July 13, 2014 8:03:37 AM PDT, jim holtman <jholtman at gmail.com> wrote:
>>> I was downloading the latest version of R from the CMU mirror and got
>>> the following message (also tried the MTU mirror and got the same).
>>> Has anyone else seen this?
>>> 
>>> ========================
>>> Filename: r-3.1.1-win.exe
>>> Threat name: WS.Reputation.1
>>> Full Path: c:\users\owner\downloads\r-3.1.1-win.exe
>>> 
>>> ____________________________
>>> 
>>> 
>>> 
>>> Details
>>> Unknown Community Usage,  Unknown Age,  Risk Medium
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Origin
>>> Downloaded from
>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Activity
>>> Actions performed: Actions performed: 1
>>> 
>>> 
>>> 
>>> ____________________________
>>> 
>>> 
>>> 
>>> On computers as of
>>> Not Available
>>> 
>>> 
>>> Last Used
>>> 7/13/14 at 10:56:56
>>> 
>>> 
>>> Startup Item
>>> No
>>> 
>>> 
>>> Launched
>>> No
>>> 
>>> 
>>> ____________________________
>>> 
>>> 
>>> Unknown
>>> It is unknown how many users in the Norton Community have used this
>>> file.
>>> 
>>> Unknown
>>> This file release is currently not known.
>>> 
>>> Medium
>>> This file risk is medium.
>>> 
>>> Threat type: Insight Network Threat. There are many indications that
>>> this file is untrustworthy and therefore not safe
>>> 
>>> 
>>> 
>>> ____________________________
>>> 
>>> 
>>> http://lib.stat.cmu.edu/R/CRAN/bin/windows/base/R-3.1.1-win.exe
>>> 
>>> Downloaded File r-3.1.1-win.exe Threat name: WS.Reputation.1
>>> from cmu.edu
>>> 
>>> Source: External Media
>>> 
>>> 
>>> 
>>> ____________________________
>>> 
>>> File Actions
>>> 
>>> File: c:\users\owner\downloads\ r-3.1.1-win.exe Removed
>>> ____________________________
>>> 
>>> 
>>> File Thumbprint - SHA:
>>> ce6fb76612aefc482583fb92f4f5c3cb8e8e3bf1a8dda97df7ec5caf746e53fe
>>> File Thumbprint - MD5:
>>> Not available
>>> 
>>> 
>>> Jim Holtman
>>> Data Munger Guru
>>> 
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.


From monaly.mistry at gmail.com  Sun Jul 13 18:09:17 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Sun, 13 Jul 2014 17:09:17 +0100
Subject: [R] canonical correlation
In-Reply-To: <web-518431124@cgpsrv2.cis.mcmaster.ca>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
	<web-518431124@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CANpv+649ghM7VhLZVbNuzz7jb9hS69baJ2kKURZsChZqcpE0Zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/cba81e0d/attachment.pl>

From optionsraghu at gmail.com  Sun Jul 13 19:10:36 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sun, 13 Jul 2014 18:10:36 +0100
Subject: [R] canonical correlation
In-Reply-To: <CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
Message-ID: <CADgEnDmwQBbSLHHkSvHd1fq3+g1S-0NH4ZATWQm23YOB6z0H+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/257c5d42/attachment.pl>

From jlh.membership at gmail.com  Sun Jul 13 19:14:53 2014
From: jlh.membership at gmail.com (jlh.membership)
Date: Sun, 13 Jul 2014 13:14:53 -0400
Subject: [R] Zeta-squared transformation use R?
In-Reply-To: <CAMPud13J19N7yTZhEbYzdrbPLw9U8N_cSNak=8q25ZYSFi29Sw@mail.gmail.com>
References: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>	<0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>
	<CAMPud13J19N7yTZhEbYzdrbPLw9U8N_cSNak=8q25ZYSFi29Sw@mail.gmail.com>
Message-ID: <000c01cf9ebd$fa8fa840$efaef8c0$@gmail.com>

Hi Miles,

If I read the paper correctly, zeta-squared is simply: (1+z^2) for z>=0, and 1/(1+z^2) for z<=0, where z is the z-score (Eqn. 11 in the paper). Z-scores can be calculated in R using the scale(...) function. So this should produce a zeta-squared transformation.

zeta.sq <- function(data) {
  z.sq    <- scale(data)^2
  zeta.sq <- ifelse(z.sq>0,1+z.sq,1/(1+z.sq))
}

Simple example: 100 respondents, 3 questions. First question scored on (1,7), second question scored on (-10,10), third question scored on (0,100) in 0.01 increments.

set.seed(1)    # for reproducible example
df <- data.frame(Q1=sample(1:7,100,replace=T),
                 Q2=sample(-10:10,100,replace=T),
                 Q3=sample(seq(0,1,len=101),100,replace=T))
# transform the data...
result <- zeta.sq(df)

Regards,

John Howard
Prism Marketing Group
http://www.prismmg.com


-----Original Message-----
From: Miles Yang [mailto:miles2yang at gmail.com] 
Sent: Saturday, July 12, 2014 7:31 AM
To: Jeff Newmiller
Cc: r-help at r-project.org
Subject: Re: [R] Zeta-squared transformation use R?

Hi Jeff,

Yes, I searched that but it comes out "zeta-squared coefficient" instead of transformation method.

I hope if there is someone have the experience in applying "zeta-squared transformation" in R?

Appreciate any help on this.

Regards,
miles


On Sat, Jul 12, 2014 at 4:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Have you tried
>
> RSiteSearch("zeta squared")
>
> ?
>
> Someone may recognize this, but it never hurts to communicate where 
> you have already looked.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> ----- Sent from my phone. Please excuse my brevity.
>
> On July 11, 2014 9:44:43 PM PDT, Miles Yang <miles2yang at gmail.com> wrote:
> >Hi R-helpers,
> >
> >Is there any packages can do "*zeta-squared transformation*"?
> >
> >The Zeta-squared transformation comes from the following article:
> >Standardizing Variables in Multiplicative Choice Models Lee G. Cooper 
> >and Masao Nakanishi Journal of Consumer Research, Vol. 10, No. 1 
> >(Jun., 1983), pp. 96-108
> >
> >Thanks for any help in advance.
> >
> >miles
>
>


--
??????????????????????????????????????????????????????
Miles Yang
Mobile???+61-411-985-538
E-mail???miles2yang at gmail.com
Web: Miles Yang Website <https://sites.google.com/site/miles2yang/>
??????????????????????????????????????????????????????

	[[alternative HTML version deleted]]


From babakbsn at gmail.com  Sun Jul 13 20:30:35 2014
From: babakbsn at gmail.com (Babak Bastan)
Date: Sun, 13 Jul 2014 11:30:35 -0700
Subject: [R] Scatterplot3D in r
Message-ID: <CAF-JZQtiNM26+1H0iK_QcFvunP8Re+bHOTGyKmqyEKq=uByGyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140713/087f82b2/attachment.pl>

From S.Ellison at LGCGroup.com  Mon Jul 14 11:18:54 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 14 Jul 2014 10:18:54 +0100
Subject: [R] Grouped Boxplot
In-Reply-To: <CAPPk2Ah4ZFCBCLmzmy=hof5Tse6kqZE4xhiztK8iLYYMc6CBbA@mail.gmail.com>
References: <CAPPk2Ah4ZFCBCLmzmy=hof5Tse6kqZE4xhiztK8iLYYMc6CBbA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E9DED4E96@GOLD.corp.lgc-group.com>

> I want to plot "boxplots" in such a way that DISO is on y-axis and the
> NODE_CAT is grouped according to POS. If I were to plot the above
> mentioned case I should get three groups of boxplots A, B, and C. Also each
> of the POS A, B and C should have two boxplots (one for Hubs and one for
> Nonhubs).

You could try
library(lattice)
bwplot(DISO~NODE_CAT|POS, data=your_data_frame)

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From info at aghmed.fsnet.co.uk  Mon Jul 14 12:56:43 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 14 Jul 2014 11:56:43 +0100
Subject: [R] Zeta-squared transformation use R?
In-Reply-To: <000c01cf9ebd$fa8fa840$efaef8c0$@gmail.com>
References: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>
	<0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>
	<CAMPud13J19N7yTZhEbYzdrbPLw9U8N_cSNak=8q25ZYSFi29Sw@mail.gmail.com>
	<000c01cf9ebd$fa8fa840$efaef8c0$@gmail.com>
Message-ID: <Zen-1X6dwB-000BL3-7k@smarthost01c.mail.zen.net.uk>

At 18:14 13/07/2014, jlh.membership wrote:
>Hi Miles,
>
>If I read the paper correctly, zeta-squared is 
>simply: (1+z^2) for z>=0, and 1/(1+z^2) for 
>z<=0, where z is the z-score (Eqn. 11 in the 
>paper). Z-scores can be calculated in R using 
>the scale(...) function. So this should produce a zeta-squared transformation.
>
>zeta.sq <- function(data) {
>   z.sq    <- scale(data)^2
>   zeta.sq <- ifelse(z.sq>0,1+z.sq,1/(1+z.sq))
>}

I would have thought the test needed to be on z 
to be consistent with the description above, not z^2?


>Simple example: 100 respondents, 3 questions. 
>First question scored on (1,7), second question 
>scored on (-10,10), third question scored on (0,100) in 0.01 increments.
>
>set.seed(1)    # for reproducible example
>df <- data.frame(Q1=sample(1:7,100,replace=T),
>                  Q2=sample(-10:10,100,replace=T),
>                  Q3=sample(seq(0,1,len=101),100,replace=T))
># transform the data...
>result <- zeta.sq(df)
>
>Regards,
>
>John Howard
>Prism Marketing Group
>http://www.prismmg.com
>
>
>-----Original Message-----
>From: Miles Yang [mailto:miles2yang at gmail.com]
>Sent: Saturday, July 12, 2014 7:31 AM
>To: Jeff Newmiller
>Cc: r-help at r-project.org
>Subject: Re: [R] Zeta-squared transformation use R?
>
>Hi Jeff,
>
>Yes, I searched that but it comes out 
>"zeta-squared coefficient" instead of transformation method.
>
>I hope if there is someone have the experience 
>in applying "zeta-squared transformation" in R?
>
>Appreciate any help on this.
>
>Regards,
>miles
>
>
>On Sat, Jul 12, 2014 at 4:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
> > Have you tried
> >
> > RSiteSearch("zeta squared")
> >
> > ?
> >
> > Someone may recognize this, but it never hurts to communicate where
> > you have already looked.
> >
> > ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> > ----------------------------------------------------------------------
> > ----- Sent from my phone. Please excuse my brevity.
> >
> > On July 11, 2014 9:44:43 PM PDT, Miles Yang <miles2yang at gmail.com> wrote:
> > >Hi R-helpers,
> > >
> > >Is there any packages can do "*zeta-squared transformation*"?
> > >
> > >The Zeta-squared transformation comes from the following article:
> > >Standardizing Variables in Multiplicative Choice Models Lee G. Cooper
> > >and Masao Nakanishi Journal of Consumer Research, Vol. 10, No. 1
> > >(Jun., 1983), pp. 96-108
> > >
> > >Thanks for any help in advance.
> > >
> > >miles
> >
> >
>
>
>--
>????????????????????????????????????????????????????????????????????????????????????????????????????????????
>Miles Yang
>Mobile?????+61-411-985-538
>E-mail?????miles2yang at gmail.com
>Web: Miles Yang Website <https://sites.google.com/site/miles2yang/>
>????????????????????????????????????????????????????????????????????????????????????????????????????????????
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From johannesradinger at gmail.com  Mon Jul 14 13:42:59 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Mon, 14 Jul 2014 13:42:59 +0200
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
	<CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>
Message-ID: <CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/82f7c390/attachment.pl>

From ligges at statistik.tu-dortmund.de  Mon Jul 14 13:57:11 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 14 Jul 2014 13:57:11 +0200
Subject: [R] Scatterplot3D in r
In-Reply-To: <CAF-JZQtiNM26+1H0iK_QcFvunP8Re+bHOTGyKmqyEKq=uByGyg@mail.gmail.com>
References: <CAF-JZQtiNM26+1H0iK_QcFvunP8Re+bHOTGyKmqyEKq=uByGyg@mail.gmail.com>
Message-ID: <53C3C597.3040608@statistik.tu-dortmund.de>



On 13.07.2014 20:30, Babak Bastan wrote:
> I would like to visualize my data in a scatterplot3d
>
> On my X and Y axis, I would like the same labels. Something like this:
>
> x<-c("A", "B", "c", "D")
>
> y<-c("A", "B", "c", "D")
>
>
> on the Z axis, I would like to show the comparison between labels in X and Y
>
>
> A with A
>
> A with B
>
> A with C
>
> A with D
>
> B with B
>
> B with C
>
> B with D
>
> C with C
>
> C with D
>
> D with D
>
>
> I have such a time series for this comparison.
>
> z<-c(0.25, 0.14, 0.15, 0.32, 0.79, 0.98,1.25, 0.68, 2.02, 0.64)
>
> How can I draw such a 3d scatter plot in r?


What about:

x <- factor(unlist(mapply(rep, LETTERS[1:4], each=4:1)))
y <- factor(LETTERS[c(1:4, 2:4, 3:4, 4)])
z <- c(0.25, 0.14, 0.15, 0.32, 0.79, 0.98,1.25, 0.68, 2.02, 0.64)
library("scatterplot3d")
scatterplot3d(x, y, z, type="h", x.ticklabs=LETTERS[1:4],
     y.ticklabs=LETTERS[1:4], lab=c(4,4,4))

Best,
Uwe Ligges

>
> thank you
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From info at aghmed.fsnet.co.uk  Mon Jul 14 14:42:13 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 14 Jul 2014 13:42:13 +0100
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.g
	mail.com>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
Message-ID: <Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>

At 23:18 11/07/2014, Megan Bartlett wrote:
>Hi everyone,
>
>Since metafor doesn't have its own list, I hope this is the correct place
>for this posting- my apologies if there is a more appropriate list.

metafor questions welcome here, Megan

Wolfgang seems to be off-list so while we wait for the definitive 
answer here are some hints.


>I'm conducting a meta-analysis where I would like to determine the
>correlation between plasticity in leaf traits and climate. I'm calculating
>effect sizes as Hedge's d. My data is structured so that each study
>collected data from one forest site, so there is one set of climate
>variable values for that study, and there are one or more species in each
>study, so all the species in a study have the same values for the climate
>variables. I'm not sure how to account for this structure in modeling the
>relationship between plasticity and climate.

I think you need rma.mv for your situation and you need to specify a 
random effect for site.

Try going
?rma.mv
and looking for the section entitled Specifying random effects
  You will need to set up your dataframe with one row per species and 
an indicator variable for site and then use
random = ~ 1 | site

Not tested obviously and Wolfgang may have other suggestions

>My first thought was to calculate mean effect size and variance across
>species for every study with multiple species and correlate that    with
>the climate variable values for those study with the rma() function, but
>trying to do that returns an error message:
>
>rma(yi = EffectSize, vi = Var, data = sitestable, mod = Precip)
>returns: Error in wi * (yi - X %*% b)^2 : non-conformable arrays
>
>This leaves me with two questions: 1) Am I even accounting for the data
>structure correctly with this approach, and 2) am I fundamentally
>misunderstanding how to use metafor to do so?
>
>Thanks very much for your help!
>
>Best,
>
>Megan
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Jul 14 15:06:55 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 14 Jul 2014 15:06:55 +0200
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>

Somehow that initial post slipped under the radar for me ...

Yes, I would give the same suggestion as Michael. Besides random effects for 'site', I would also suggest to add random effects for each estimates (as in a regular random-effects model). So, if you have an 'id' variable that is unique to each observed d-value, you would use:

random = list(~ 1 | site, ~ 1 | id)

with the rma.mv() function. This is in essence the model given by equation (6) in:

Nakagawa, S., & Santos, E. S. A. (2012). Methodological issues and advances in biological meta-analysis. Evolutionary Ecology, 26(5), 1253-1274.

(at the time of publication, this model could not be fitted with metafor, but it can now). Same model is described with a bit more detail in:

Konstantopoulos, S. (2011). Fixed effects and variance components estimation in three-level meta-analysis. Research Synthesis Methods, 2(1), 61-76.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Monday, July 14, 2014 14:42
> To: Megan Bartlett; r-help at r-project.org
> Subject: Re: [R] Correlating multiple effect sizes within a study to
> study-level predictors: metafor package
> 
> At 23:18 11/07/2014, Megan Bartlett wrote:
> >Hi everyone,
> >
> >Since metafor doesn't have its own list, I hope this is the correct
> place
> >for this posting- my apologies if there is a more appropriate list.
> 
> metafor questions welcome here, Megan
> 
> Wolfgang seems to be off-list so while we wait for the definitive
> answer here are some hints.
> 
> 
> >I'm conducting a meta-analysis where I would like to determine the
> >correlation between plasticity in leaf traits and climate. I'm
> calculating
> >effect sizes as Hedge's d. My data is structured so that each study
> >collected data from one forest site, so there is one set of climate
> >variable values for that study, and there are one or more species in
> each
> >study, so all the species in a study have the same values for the
> climate
> >variables. I'm not sure how to account for this structure in modeling
> the
> >relationship between plasticity and climate.
> 
> I think you need rma.mv for your situation and you need to specify a
> random effect for site.
> 
> Try going
> ?rma.mv
> and looking for the section entitled Specifying random effects
>   You will need to set up your dataframe with one row per species and
> an indicator variable for site and then use
> random = ~ 1 | site
> 
> Not tested obviously and Wolfgang may have other suggestions
> 
> >My first thought was to calculate mean effect size and variance across
> >species for every study with multiple species and correlate that    with
> >the climate variable values for those study with the rma() function, but
> >trying to do that returns an error message:
> >
> >rma(yi = EffectSize, vi = Var, data = sitestable, mod = Precip)
> >returns: Error in wi * (yi - X %*% b)^2 : non-conformable arrays
> >
> >This leaves me with two questions: 1) Am I even accounting for the data
> >structure correctly with this approach, and 2) am I fundamentally
> >misunderstanding how to use metafor to do so?
> >
> >Thanks very much for your help!
> >
> >Best,
> >
> >Megan


From abhinabaroy09 at gmail.com  Mon Jul 14 12:43:03 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Mon, 14 Jul 2014 16:13:03 +0530
Subject: [R] Multiple Correspondence Analysis
Message-ID: <CANtKHPX8ZVJWuJ86WLxxRDM_YFC92QpdNFdW7DGHEhX9c=4Tfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/0ec55dd1/attachment.pl>

From juandaniel.gv at gmail.com  Mon Jul 14 13:52:18 2014
From: juandaniel.gv at gmail.com (=?UTF-8?Q?Juan_Daniel_Garc=C3=ADa?=)
Date: Mon, 14 Jul 2014 13:52:18 +0200
Subject: [R] sqldf problems
Message-ID: <CAFPHo=gBPD8qq-cyB+=hTm8NyT-qJ=rRmXQTKb2X-aM6QNB8jQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/575ffdd1/attachment.pl>

From tommac at nova.edu  Mon Jul 14 15:42:10 2014
From: tommac at nova.edu (Dr. Thomas W. MacFarland)
Date: Mon, 14 Jul 2014 13:42:10 +0000
Subject: [R] R] R GUI for undergraduate lab class?
Message-ID: <0A977721602DFC40B5D7608CD47E987E34913BB4@DESTRILLION.oit.nova.edu>

Hi Louise:

Pasted below is a section from a syllabus where I list a set of Tegrity-based URLs that demonstrate the R Commander Graphical User Interface, for R-based analyses and graphics.

The videos are all about 1 hour in length but there is a slider at the bottom so it is fairly easy to move past course specific sections or other portions that you may not need to review.

Comment:  Students in this class have no prior experience with R and minimal, if any, experience with syntax.  I try to start them out with R Commander since it is a fairly easy to use R GUI.  In time I move them over to R Studio and near the end of the term they use an ASCII editor to construct their own syntax, bypassing R Commander and R Studio.  Some students take to this easily and others prefer the GUI approach.

Comment:  The Tegrity videos then to show best using IE and Chrome.

Best wishes.

Tom MacFarland


\begin{longtable}{ l || p{0.10in} p{4.75in} }
\multicolumn{3}{ c }{
\textbf{Weekly Instruction}}           \\
              & &                      \\
\hline
              & &                      \\
{\bf Week 00} & & Module 00 -- Video Overview of Biostatistics (DEP 5001), \url{https://tegr.it/y/1bv3i} 1:14:26 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 01} & & Module 01 -- Overview of Biostatistics (DEP 5001), \url{https://tegr.it/y/1bv3z} 1:26:50 Hrs\\
              & &                      \\[-0.10in]
              & & Review the syllabus  \\
              & &                      \\[-0.10in]
              & & Use of the Blackboard Course Management System (CMS) \\
              & &                      \\[-0.10in]
              & & Alternates for communication and instruction (e.g., online equivalent of a fire drill) \\
              & &                      \\[-0.10in]
{\bf Week 02} & & Module 02 -- Introduction:  Biostatistics and R, \url{https://tegr.it/y/1bvmt} 0:57:37 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 03} & & Module 03 -- Data in the Large, \url{https://tegr.it/y/1bvmq} 0:47:31 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 04} & & Module 04 -- Population, Normal Distribution, and Sampling, \url{https://tegr.it/y/1bvmn} 0:52:14 Hrs and \url{https://tegr.it/y/1c1tj} 1:02:24 Hrs \\
              & &                      \\[-0.10in]
{\bf Week 05} & & Module 05 -- R Graphical User Interface (R Commander, R-GUI) and R Command Line Interface (R Syntax, R-CLI), \url{https://tegr.it/y/1bvmk} 0:46:54 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 06} & & Module 06 -- Data Exploration, Descriptive Statistics, and Measures of Central Tendency, \url{https://tegr.it/y/1bvmh} 0:55:37 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 07} & & Module 07 -- Student's t-Test for Independent Samples, \url{https://tegr.it/y/1bvme} 1:09:43 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 08} & & Module 08 -- Student's t-Test for Matched Pairs, \url{https://tegr.it/y/1bvmb} 0:36:05 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 09} & & Module 09 -- Analyses and Graphics for a Large Dataset With No Missing Data, \url{https://tegr.it/y/1bvm8} 0:19:36 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 10} & & Module 10 -- Analyses and Graphics for a Large Dataset With Missing Data, \url{https://tegr.it/y/1bvm5} 0:45:51 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 11} & & Module 11 -- Oneway Analysis of Variance (ANOVA), \url{https://tegr.it/y/1bvm2} 1:00:34 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 12} & & Module 12 -- Twoway Analysis of Variance (ANOVA), \url{https://tegr.it/y/1btlg} 1:05:55 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 13} & & Module 13 -- Correlation and Linear Regression, \url{https://tegr.it/y/1bvly} 0:56:30 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 14} & & Module 14 -- Future Actions and Next Steps, \url{https://tegr.it/y/1bvlv} 0:33:38 Hrs\\
              & &                      \\[-0.10in]
{\bf Week 15} & & Review and Completion of All Assignments \\
              & &                      \\[-0.10in]
{\bf Week 16} & & Review and Completion of All Assignments \\
              & &                      \\[-0.10in]
              & & Conclusions          \\
              & &                      \\[-0.10in]
\hline
& & \\[-0.10in]
\end{longtable}

  



Date: Sat, 12 Jul 2014 13:47:08 -0700
From: Louise Stevenson <louise.stevenson at lifesci.ucsb.edu>
To: r-help at r-project.org
Subject: [R] R GUI for undergraduate lab class?
Message-ID: <41A24965-D53D-4BEF-916B-431E18086CD2 at lifesci.ucsb.edu>
Content-Type: text/plain; CHARSET=US-ASCII

Hi,

I'm working on a new set of simple, ecological modeling exercises for our
campus' undergraduate Introductory Biology lab series. The students work
with simple population models by looking at graphs and seeing how changing
parameter values and initial population sizes changes how the populations
fluctuate through time. Does anyone know of an existing R GUI or any other
interface that would be good for an undergraduate setting? Basically I want
something that shows the students the model's output as graphs and lets them
change parameter values but the equations/coding itself is hidden such that
they can't change any of that. I want what Populus can do (a fantastic
program written for this exact purpose, info here:
http://www.cbs.umn.edu/research/resources/populus) but I want to be able to
upload data so the students can compare model outputs to real data and I
can't figure out how to get Populus to plot data. Any help would be very
much appreciated! Thank you!

Sincerely,
Louise Stevenson
Graduate Student, University of California, Santa Barbara
Department of Ecology, Evolution and Marine Biology


R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

End of R-help Digest, Vol 137, Issue 14
***************************************

----------
Thomas W. MacFarland, Ed.D.
Senior Research Associate; Institutional Effectiveness and Associate Professor
Nova Southeastern University
Voice 954-262-5395 tommac at nova.edu



From ggrothendieck at gmail.com  Mon Jul 14 16:05:24 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 14 Jul 2014 10:05:24 -0400
Subject: [R] sqldf problems
In-Reply-To: <CAFPHo=gBPD8qq-cyB+=hTm8NyT-qJ=rRmXQTKb2X-aM6QNB8jQ@mail.gmail.com>
References: <CAFPHo=gBPD8qq-cyB+=hTm8NyT-qJ=rRmXQTKb2X-aM6QNB8jQ@mail.gmail.com>
Message-ID: <CAP01uR=s8xUc96KoAYdZZ-Wfw8WXSRiJo5=M-PzmRce+_9hnDA@mail.gmail.com>

2014-07-14 7:52 GMT-04:00 Juan Daniel Garc?a <juandaniel.gv at gmail.com>:
> Hello:
> I'm trying to run this code
>
> data2 <- sqldf (" SELECT plot, age,  avg(N) as N FROM data1 GROUP BY plot,
> t")
>
> The problem is that when calling sqldf with
>>require(sqldf)
>
> appears this message
>
> Warning message:
> In sqliteCloseConnection(conn, ...) :
>   RS-DBI driver warning: (closing pending result sets before closing this
> connection)
>
> If try again
>
>>require(sqldf)
>
> the message does not appear, but when trying the code afterwards, I get a
> new message
>
> Error in sqliteFetch(rs, n = -1, ...) :
>   RSQLite driver: (RS_SQLite_fetch: failed: Domain error)
>
> I have a new Windows 8.1
>
> Do I need any other installations o packages or something else?
> The code was working in older Windows XP and Linux
>

See the Troubleshooting section of the sqldf home page.
http://sqldf.googlecode.com


From jdnewmil at dcn.davis.CA.us  Mon Jul 14 16:38:53 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Jul 2014 07:38:53 -0700
Subject: [R] sqldf problems
In-Reply-To: <CAFPHo=gBPD8qq-cyB+=hTm8NyT-qJ=rRmXQTKb2X-aM6QNB8jQ@mail.gmail.com>
References: <CAFPHo=gBPD8qq-cyB+=hTm8NyT-qJ=rRmXQTKb2X-aM6QNB8jQ@mail.gmail.com>
Message-ID: <fecbbc88-078b-407c-b2bb-5664e3ba6cf7@email.android.com>

One doesn't "call" a package... so your description is unclear. One doesn't load (using the require or library functions) the relevant package AFTER calling functions in the package. Since it appears you have left out some steps or described them out of order, please supply a reproducible example [1] (including a test data set) as the Posting Guide requests.

NB I don't have Windows 8 or 8.1, so if that turns out to be the problem then I won't be able to tell, but I have a feeling there is something more basic going on here.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 14, 2014 4:52:18 AM PDT, "Juan Daniel Garc?a" <juandaniel.gv at gmail.com> wrote:
>Hello:
>I'm trying to run this code
>
>data2 <- sqldf (" SELECT plot, age,  avg(N) as N FROM data1 GROUP BY
>plot,
>t")
>
>The problem is that when calling sqldf with
>>require(sqldf)
>
>appears this message
>
>Warning message:
>In sqliteCloseConnection(conn, ...) :
>RS-DBI driver warning: (closing pending result sets before closing this
>connection)
>
>If try again
>
>>require(sqldf)
>
>the message does not appear, but when trying the code afterwards, I get
>a
>new message
>
>Error in sqliteFetch(rs, n = -1, ...) :
>  RSQLite driver: (RS_SQLite_fetch: failed: Domain error)
>
>I have a new Windows 8.1
>
>Do I need any other installations o packages or something else?
>The code was working in older Windows XP and Linux
>
>Thanks


From jverzani at gmail.com  Mon Jul 14 17:47:09 2014
From: jverzani at gmail.com (john verzani)
Date: Mon, 14 Jul 2014 15:47:09 +0000
Subject: [R] R GUI for undergraduate lab class?
References: <mailman.541.1405194503.4543.r-help@r-project.org>
	<41A24965-D53D-4BEF-916B-431E18086CD2@lifesci.ucsb.edu>
	<20140712211254.fde803cd5676c78fa01b7505@inbox.com>
Message-ID: <loom.20140714T174454-499@post.gmane.org>



Ranjan Maitra <maitra.mbox.ignored <at> inbox.com> writes:

> 
> Hi Louise,



The INZight GUI might give students something to work with.
https://www.stat.auckland.ac.nz/~wild/iNZight/


From david.stevens at usu.edu  Mon Jul 14 17:48:54 2014
From: david.stevens at usu.edu (David Stevens)
Date: Mon, 14 Jul 2014 09:48:54 -0600
Subject: [R] Merge rows
In-Reply-To: <53C14749.5020006@usu.edu>
References: <CAKcMNB+vXPVfV5x_S_tBz+XfYzziF5RaLD2oLU5NSEfoPH2arw@mail.gmail.com>	<1969373.rnpqOJh24M@localhost.localdomain>
	<53C14749.5020006@usu.edu>
Message-ID: <53C3FBE6.4070804@usu.edu>

Cautionary note on the solution below. Be sure the 'sndr' is either 
factor or character because, if sndr is numeric, as the list is 
populated, R will fill in non-adjacent list items with NULLs, leaving a 
list with many empty entries. So, the modified line is

       newdat[[as.character(vnam)]]<-newvec[-1]

David

On 7/12/2014 8:33 AM, David Stevens wrote:
> This is a (very) slightly modified version of Jim's reply that takes 
> the sender's email our of the list element and uses it as the name so 
> it can be accessed as newdat$'senders email' or newdat[['senders email']]
>
> newdat<-list()
> for(sndr in unique(rdvdf$sender)) {
>  newvec<-
>   as.character(unique(unlist(rdvdf[rdvdf$sender==sndr,])))
>  newdat[[(sndr)]]<-newvec[which(!is.na(newvec))][-1]
> }
>
> David
>
> On 7/12/2014 1:07 AM, Jim Lemon wrote:
>> On Fri, 11 Jul 2014 12:19:39 PM Ryan de Vera wrote:
>>> Hello all,
>>>
>>> I have a data frame filled with senders and recipients. Some of the
>> senders
>>> have multiple rows with different recipients and I want to merge
>> those
>>> rows. For example I have
>>>
>>> a at email.com     b at email.com
>>> a at email.com     c at email.com     d at email.com
>>> r at email.com      f at email.com
>>> r at email.com      h at email.com
>>>
>>> I want this to become
>>>
>>> a at email.com     b at email.com     c at email.com     d at email.com
>>> r at email.com      f at email.com      h at email.com
>>>
>>> How would I go about doing this?
>>>
>> Hi Ryan,
>> This is a bit messy, but assuming that you do have a data frame like
>> this:
>>
>> rdvdf<-
>> data.frame(sender=rep(c("a at email.com","r at email.com"),each=2),
>> recipient1=c("b at email.com","c at email.com","f at email.com","h at email.com"),
>>   recipient2=c(NA,"d at email.com",NA,NA))
>>
>> you can try this:
>>
>> newdat<-list()
>> senderno<-1
>> for(sndr in unique(rdvdf$sender)) {
>>   newvec<-
>>    as.character(unique(unlist(rdvdf[rdvdf$sender==sndr,])))
>>   newdat[[senderno]]<-newvec[!is.na(newvec)]
>>   senderno<-senderno+1
>> }
>>
>> Jim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From Mark.Fowler at dfo-mpo.gc.ca  Mon Jul 14 18:42:54 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Mon, 14 Jul 2014 13:42:54 -0300
Subject: [R] two questions - function help and 32vs64 bit sessions
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/95475a09/attachment.pl>

From jlh.membership at gmail.com  Mon Jul 14 18:49:01 2014
From: jlh.membership at gmail.com (jlh.membership)
Date: Mon, 14 Jul 2014 12:49:01 -0400
Subject: [R] Zeta-squared transformation use R?
In-Reply-To: <Zen-1X6dwB-000BL3-7k@smarthost01c.mail.zen.net.uk>
References: <CAMPud11VRNUohRGQ5dAXSZkLSYrzR6tfZRtca1iq76TBLzEPcQ@mail.gmail.com>
	<0da085c1-8bd6-4a96-8e7d-d330a45447ca@email.android.com>
	<CAMPud13J19N7yTZhEbYzdrbPLw9U8N_cSNak=8q25ZYSFi29Sw@mail.gmail.com>
	<000c01cf9ebd$fa8fa840$efaef8c0$@gmail.com>
	<Zen-1X6dwB-000BL3-7k@smarthost01c.mail.zen.net.uk>
Message-ID: <005701cf9f83$886e35d0$994aa170$@gmail.com>

Yes, absolutely! Sorry about that:

zeta.sq <- function(data) {
  z       <- scale(data)
  zeta.sq <- ifelse(z>0,1+z^2,1/(1+z^2))
}



-----Original Message-----
From: Michael Dewey [mailto:info at aghmed.fsnet.co.uk] 
Sent: Monday, July 14, 2014 6:57 AM
To: jlh.membership; 'Miles Yang'
Cc: r-help at r-project.org
Subject: Re: [R] Zeta-squared transformation use R?

At 18:14 13/07/2014, jlh.membership wrote:
>Hi Miles,
>
>If I read the paper correctly, zeta-squared is
>simply: (1+z^2) for z>=0, and 1/(1+z^2) for z<=0, where z is the 
>z-score (Eqn. 11 in the paper). Z-scores can be calculated in R using 
>the scale(...) function. So this should produce a zeta-squared transformation.
>
>zeta.sq <- function(data) {
>   z.sq    <- scale(data)^2
>   zeta.sq <- ifelse(z.sq>0,1+z.sq,1/(1+z.sq)) }

I would have thought the test needed to be on z to be consistent with the description above, not z^2?


>Simple example: 100 respondents, 3 questions. 
>First question scored on (1,7), second question 
>scored on (-10,10), third question scored on (0,100) in 0.01 increments.
>
>set.seed(1)    # for reproducible example
>df <- data.frame(Q1=sample(1:7,100,replace=T),
>                  Q2=sample(-10:10,100,replace=T),
>                  Q3=sample(seq(0,1,len=101),100,replace=T))
># transform the data...
>result <- zeta.sq(df)
>
>Regards,
>
>John Howard
>Prism Marketing Group
>http://www.prismmg.com
>
>
>-----Original Message-----
>From: Miles Yang [mailto:miles2yang at gmail.com]
>Sent: Saturday, July 12, 2014 7:31 AM
>To: Jeff Newmiller
>Cc: r-help at r-project.org
>Subject: Re: [R] Zeta-squared transformation use R?
>
>Hi Jeff,
>
>Yes, I searched that but it comes out 
>"zeta-squared coefficient" instead of transformation method.
>
>I hope if there is someone have the experience 
>in applying "zeta-squared transformation" in R?
>
>Appreciate any help on this.
>
>Regards,
>miles
>
>
>On Sat, Jul 12, 2014 at 4:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
> > Have you tried
> >
> > RSiteSearch("zeta squared")
> >
> > ?
> >
> > Someone may recognize this, but it never hurts to communicate where
> > you have already looked.
> >
> > ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> > ----------------------------------------------------------------------
> > ----- Sent from my phone. Please excuse my brevity.
> >
> > On July 11, 2014 9:44:43 PM PDT, Miles Yang <miles2yang at gmail.com> wrote:
> > >Hi R-helpers,
> > >
> > >Is there any packages can do "*zeta-squared transformation*"?
> > >
> > >The Zeta-squared transformation comes from the following article:
> > >Standardizing Variables in Multiplicative Choice Models Lee G. Cooper
> > >and Masao Nakanishi Journal of Consumer Research, Vol. 10, No. 1
> > >(Jun., 1983), pp. 96-108
> > >
> > >Thanks for any help in advance.
> > >
> > >miles
> >
> >
>
>
>--
>????????????????????????????????????????????????????????????????????????????????????????????????????????????
>Miles Yang
>Mobile?????+61-411-985-538
>E-mail?????miles2yang at gmail.com
>Web: Miles Yang Website <https://sites.google.com/site/miles2yang/>
>????????????????????????????????????????????????????????????????????????????????????????????????????????????
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From s.wood at bath.ac.uk  Mon Jul 14 19:06:09 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 14 Jul 2014 18:06:09 +0100
Subject: [R] gamm4 and lme4 error
In-Reply-To: <ED72C329-918E-4919-AD8C-A767AE2482EE@hms.harvard.edu>
References: <ED72C329-918E-4919-AD8C-A767AE2482EE@hms.harvard.edu>
Message-ID: <53C40E01.6090509@bath.ac.uk>

Thanks - It looks like an lme4 1.1-7 change. I'll look for a work around 
(once I can get nlopt-2.4 to install). Meanwhile, I think it's still 
safe to use.
best,
Simon

On 13/07/14 05:05, Nicholas Lange wrote:
> Hello,
>
> I'm running R.3.1.1 on Mac OS X 10.6.8 with gamm4 version 0.2-2 and lme4 version 1.1-7. I get the following error when trying to fit the simplest model I can think of:
>
>> fit = gamm4( y ~ s(x))
>
> Warning message:
> In deviance.merMod(ret$mer) :
>    deviance() is deprecated for REML fits; use REMLcrit for the REML criterion or deviance(.,REML=FALSE) for deviance calculated at the REML fit
>>
>
> Does anyone see what's wrong? Any answer would be greatly appreciated.
>
> Nick
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From jdnewmil at dcn.davis.CA.us  Mon Jul 14 19:33:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Jul 2014 10:33:17 -0700
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
Message-ID: <fa39d012-57ac-4c47-aab6-e7a2e4f5dff5@email.android.com>

I don't know any definitive answer for either if your questions, but I have a comment that may explain why I have not encountered these issues.

At one time I used to use RData files the way you are, but I discovered the value of re-running my analysis scripts from scratch regularly... as in dozens of times per day. Whenever the run time gets too long to be compatible with that, I modify the script to conditionally either regenerate any mostly-verified intermediate data objects that are slow to generate and save them with saveRDS, or simply reload them using loadRDS. Then I run most of the time with a trigger variable set to simply reload the debugged data objects for subsequent analysis or output formatting. The goal here is to build reproducible analysis scripts, not mysterious RData files generated by an unknown sequence of commands.

With this approach in mind, R sessions need not stay open long, and the script can have a check (using perhaps .Machine$sizeof.pointer) at the beginning that verifies your architecture before proceeding. You might also be able to put a shortcut or batch file in your working directory for projects that require specific versions/architectures of R that point to the correct one for that project. Then you just start R using that shortcut or script.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 14, 2014 9:42:54 AM PDT, "Fowler, Mark" <Mark.Fowler at dfo-mpo.gc.ca> wrote:
>Hello,
>
> 
>
>Two unrelated questions, and neither urgent.
>
> 
>
>Windows 7, R 3.0.1. Using R Console, no fancy interface.
>
> 
>
>The function help ultimately becomes lost to a session kept running for
>extended periods (days). I.e. with a new session if you invoke the Help
>menu 'R functions (txt)...' it activates the html help and goes to the
>named function page. This will work fine for at least a day, but
>typically the next day invoking the help menu in this fashion will
>fail,
>as R looks for a temporary address it creates on your computer. This
>gets lost, possibly due to network administration activity. So then I
>save and start another session with same Rdata. Trivial enough but
>irritating. Anybody know how to restore the 'link' without ending and
>restarting the session?
>
> 
>
>I have a mix of 32-bit and 64-bit requirements, with 64 the default. I
>became used to starting R sessions directly from the appropriate Rdata
>workspaces. With the latest version I need to start from the generic
>icon and then load the workspace if I want 32-bit. Anybody know a way
>to
>make the Rdata files keep track of which bit version they work with, or
>some trick that accomplishes the same objective? The 32-bit requirement
>is usually just RODBC, and the need for it is scattered over lots of
>workspaces. Again, trivial but a nuisance. A more pragmatic motive is
>to
>not oblige users of applications to think about it. Any way to make a
>session switch 'bits' with a source file?
>
> 
>
>Mark Fowler 
>Population Ecology Division 
>Bedford Inst of Oceanography 
>Dept Fisheries & Oceans 
>Dartmouth NS Canada 
>B2Y 4A2 
>Tel. (902) 426-3529 
>Fax (902) 426-9710 
>Email Mark.Fowler at dfo-mpo.gc.ca <mailto:Mark.Fowler at dfo-mpo.gc.ca>  
>
>
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Mon Jul 14 22:05:53 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 14 Jul 2014 15:05:53 -0500
Subject: [R] New details about Cochran and Cox's chocolate cake data
Message-ID: <CAKFxdiQezFDn7zm4-pmc3MFN+7MaMzccNu=C+Pmpv6u0sGJ4-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/a1b433be/attachment.pl>

From friendly at yorku.ca  Mon Jul 14 23:43:03 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 14 Jul 2014 23:43:03 +0200
Subject: [R] canonical correlation
In-Reply-To: <CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
Message-ID: <53C44EE7.2060208@yorku.ca>

Perhaps what you are looking for is the visualization methods for 
canonical correlation provided in the candisc package.

see
?candisc::cancor
?heplot.cancor

-Michael


On 13/07/2014 4:39 PM, Monaly Mistry wrote:
> Dear John,
>
> In my final model I have 10 independent variables that account for the
> variation in my dependent variable, and I needed to visually demonstrate
> this relationship.  So I did a canonical correlation to get a linear
> combination of independent variables that that predicts the variation in my
> dependent variable to plot the relationship. Although I ended up using 2
> dependent variables in the canonical correlation analysis.
>
> Best,
>
> Monaly.
>
>
> On Sun, Jul 13, 2014 at 3:16 PM, John Fox <jfox at mcmaster.ca> wrote:
>
>> A small correction: I should have said "R", not "R^2".
>>
>> John
>>
>> On Sun, 13 Jul 2014 10:14:23 -0400
>>   "John Fox" <jfox at mcmaster.ca> wrote:
>>> Dear Raghuraman and Monaly,
>>>
>>> Why would one want to do canonical correlation with a single Y variable?
>> The canonical correlation is just the R^2 from the LS regression of Y on
>> the Xs.
>>>
>>> Best,
>>>   John
>>>
>>> ------------------------------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> http://socserv.mcmaster.ca/jfox/
>>>
>>>
>>> On Sun, 13 Jul 2014 09:00:52 +0100
>>>   Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
>>>> Try package CCA.
>>>>
>>>>
>>>> On Sat, Jul 12, 2014 at 11:13 PM, Monaly Mistry <
>> monaly.mistry at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I was wondering if it's possible in R to do a canonical correlation
>> with
>>>>> only one dependent variable and several independent variables.
>>>>>
>>>>> I've tried using cc(X,Y) but I got an error message. In this case I
>> had 1
>>>>> dependent variable and 10 independent variables.
>>>>>
>>>>> Error in cor(X, use = "pairwise") :
>>>>>    supply both 'x' and 'y' or a matrix-like 'x'
>>>>>
>>>>> When I use two dependent variables I don't get the error message.
>>>>>
>>>>> Best,
>>>>>
>>>>> Monaly.
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ------------------------------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario, Canada
>> http://socserv.mcmaster.ca/jfox/
>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>


From friendly at yorku.ca  Mon Jul 14 23:43:03 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 14 Jul 2014 23:43:03 +0200
Subject: [R] canonical correlation
In-Reply-To: <CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
Message-ID: <53C44EE7.2060208@yorku.ca>

Perhaps what you are looking for is the visualization methods for 
canonical correlation provided in the candisc package.

see
?candisc::cancor
?heplot.cancor

-Michael


On 13/07/2014 4:39 PM, Monaly Mistry wrote:
> Dear John,
>
> In my final model I have 10 independent variables that account for the
> variation in my dependent variable, and I needed to visually demonstrate
> this relationship.  So I did a canonical correlation to get a linear
> combination of independent variables that that predicts the variation in my
> dependent variable to plot the relationship. Although I ended up using 2
> dependent variables in the canonical correlation analysis.
>
> Best,
>
> Monaly.
>
>
> On Sun, Jul 13, 2014 at 3:16 PM, John Fox <jfox at mcmaster.ca> wrote:
>
>> A small correction: I should have said "R", not "R^2".
>>
>> John
>>
>> On Sun, 13 Jul 2014 10:14:23 -0400
>>   "John Fox" <jfox at mcmaster.ca> wrote:
>>> Dear Raghuraman and Monaly,
>>>
>>> Why would one want to do canonical correlation with a single Y variable?
>> The canonical correlation is just the R^2 from the LS regression of Y on
>> the Xs.
>>>
>>> Best,
>>>   John
>>>
>>> ------------------------------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> http://socserv.mcmaster.ca/jfox/
>>>
>>>
>>> On Sun, 13 Jul 2014 09:00:52 +0100
>>>   Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
>>>> Try package CCA.
>>>>
>>>>
>>>> On Sat, Jul 12, 2014 at 11:13 PM, Monaly Mistry <
>> monaly.mistry at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I was wondering if it's possible in R to do a canonical correlation
>> with
>>>>> only one dependent variable and several independent variables.
>>>>>
>>>>> I've tried using cc(X,Y) but I got an error message. In this case I
>> had 1
>>>>> dependent variable and 10 independent variables.
>>>>>
>>>>> Error in cor(X, use = "pairwise") :
>>>>>    supply both 'x' and 'y' or a matrix-like 'x'
>>>>>
>>>>> When I use two dependent variables I don't get the error message.
>>>>>
>>>>> Best,
>>>>>
>>>>> Monaly.
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ------------------------------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario, Canada
>> http://socserv.mcmaster.ca/jfox/
>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>


From mkbartl at gmail.com  Tue Jul 15 00:19:29 2014
From: mkbartl at gmail.com (Megan Bartlett)
Date: Mon, 14 Jul 2014 15:19:29 -0700
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
Message-ID: <CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/18079bdb/attachment.pl>

From jwd at surewest.net  Tue Jul 15 05:00:01 2014
From: jwd at surewest.net (jwd)
Date: Mon, 14 Jul 2014 20:00:01 -0700
Subject: [R] Update fail
Message-ID: <20140714200001.47078ac8@draco>

I've been getting of an "R-patched" update, but running the process
results in the following:

File './x86_64/R-patched-devel-3.1.1-4.1.x86_64.rpm' not found on
medium
'http://download.opensuse.org/repositories/devel:/languages:/R:/patched/openSUSE_13.1/'


The system is opensuse 13.1, Linux 3.11.10-17

R reports as version 3.1.1 which seems to be the current release.

I'm not quite sure who is most appropriate to report this too.

Thanks,
JDougherty


From jim at bitwrit.com.au  Tue Jul 15 05:17:21 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 15 Jul 2014 13:17:21 +1000
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
Message-ID: <1875188.O42FXxQtEb@localhost.localdomain>

On Mon, 14 Jul 2014 01:42:54 PM Fowler, Mark wrote:
> Hello,
> 
> 
> 
> Two unrelated questions, and neither urgent.
> 
> 
> 
> Windows 7, R 3.0.1. Using R Console, no fancy interface.
> 
> 
> 
> The function help ultimately becomes lost to a session kept running 
for
> extended periods (days). I.e. with a new session if you invoke the Help
> menu 'R functions (txt)...' it activates the html help and goes to the
> named function page. This will work fine for at least a day, but
> typically the next day invoking the help menu in this fashion will fail,
> as R looks for a temporary address it creates on your computer. This
> gets lost, possibly due to network administration activity. So then I
> save and start another session with same Rdata. Trivial enough but
> irritating. Anybody know how to restore the 'link' without ending and
> restarting the session?

Hi Mark,
I simply shut down the help browser. It will restart with a new IP address.

Jim


From rcdall at gmail.com  Tue Jul 15 03:38:53 2014
From: rcdall at gmail.com (Ryan Dallavia)
Date: Mon, 14 Jul 2014 20:38:53 -0500
Subject: [R] Mac OSX Mavericks 10.9.3 Big Problem - New User
Message-ID: <CADCHy177j1OZfuMgjcnUfJrsOpZP5D-fr8CLih9AS08LeQ12EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/aa4b1cd3/attachment.pl>

From martavaldes85 at gmail.com  Mon Jul 14 18:17:44 2014
From: martavaldes85 at gmail.com (Marta valdes lopez)
Date: Mon, 14 Jul 2014 16:17:44 +0000
Subject: [R] how to remove outliers
Message-ID: <CAE0cxbEWTZ6Ky=JHkg-z==Yu+C3=xJK7m-89wMLZK_ZNxfL=Uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/ddbbd913/attachment.pl>

From dnedelchev65 at yahoo.com  Mon Jul 14 19:54:35 2014
From: dnedelchev65 at yahoo.com (dragomir nedeltchev)
Date: Mon, 14 Jul 2014 10:54:35 -0700
Subject: [R] Dimensionality of Higher-Order Moments of rmgarch
Message-ID: <1405360475.59602.YahooMailNeo@web164802.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/b1e8dfe7/attachment.pl>

From munjalpatel85 at gmail.com  Mon Jul 14 20:35:45 2014
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Mon, 14 Jul 2014 14:35:45 -0400
Subject: [R] List of Lists in For Loop
Message-ID: <CAOWjiK8YDBDTf2JBEnzSf9+xst_c4AhOEaau-Ru9bqEdQicMUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/ce1af684/attachment.pl>

From munjalpatel85 at gmail.com  Mon Jul 14 20:45:21 2014
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Mon, 14 Jul 2014 14:45:21 -0400
Subject: [R] List of Lists by for Loop
Message-ID: <CAOWjiK_=W1UThycVwLXZC6Rrj2nQhAmcpns-XU9YA9hw0+UJJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/c8c08281/attachment.pl>

From pennytianzh at hotmail.com  Mon Jul 14 21:49:39 2014
From: pennytianzh at hotmail.com (=?gb2312?B?1cXM7Mzt?=)
Date: Mon, 14 Jul 2014 19:49:39 +0000
Subject: [R] Determine the order of Time series
Message-ID: <BAY175-W13DB1B10AAAA5E53F70704A30A0@phx.gbl>




 Dear R help team,
 
I am currently stuck on how to determine the order of a data. I have plotted the ACF and PACF of the data and it does not seem to cuts off. Is that possible to plot AIC BIC of some order(p,q) say, 0<p<6 and 0<q<10 on the same graph so that I can compare the value of AIC and BIC to determine the best model to fit? (Please see attached picture that can clear describe what I am looking for.)
 
Or, is there any other way to determine the order of the data?
 
Thank you so much for your time
 
Kind Regrads
 
Penny 

 		 	   		  

From hasan.diwan at gmail.com  Tue Jul 15 06:43:42 2014
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Mon, 14 Jul 2014 21:43:42 -0700
Subject: [R] how to remove outliers
In-Reply-To: <CAE0cxbEWTZ6Ky=JHkg-z==Yu+C3=xJK7m-89wMLZK_ZNxfL=Uw@mail.gmail.com>
References: <CAE0cxbEWTZ6Ky=JHkg-z==Yu+C3=xJK7m-89wMLZK_ZNxfL=Uw@mail.gmail.com>
Message-ID: <CAP+bYWDnEHS-93Eo2E73PJ1=awbu-8+L4j7zRwvEkR-q8kX3TA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140714/19bc8e94/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Jul 15 07:13:58 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Jul 2014 22:13:58 -0700
Subject: [R] Mac OSX Mavericks 10.9.3 Big Problem - New User
In-Reply-To: <CADCHy177j1OZfuMgjcnUfJrsOpZP5D-fr8CLih9AS08LeQ12EA@mail.gmail.com>
References: <CADCHy177j1OZfuMgjcnUfJrsOpZP5D-fr8CLih9AS08LeQ12EA@mail.gmail.com>
Message-ID: <53699cef-9483-4b50-9ad5-9cd327e85918@email.android.com>

Providing error messages without the inputs that provoked them leaves us with only half a conversation to interpret. (For instance, what is with the misspelling error?) It is also helpful when they are provided in the sequence that they happened.

I am going to make a wild guess that you loaded your previous variables, perhaps automatically from the .RData file, but you don't remember which packages to load to work with them. You only use the install.packages function to get them into the R "library" directories (typically from CRAN). You use the "library" or "require" functions to pull them into memory each time you restart R to do some analysis. Usually it is best to store the sequence of R statements that do your analysis in a .R file. You can then just run all the commands in that file later when you have forgotten how you did your analysis the first time.

The fact that loading your variables from the .RData file does not also reload the packages you need to do your analysis is a pain. I prefer to not use RData files at all since the R file can both load those needed packages and remind me how the analysis was done.

You should read about how to ask clear questions, such as at [1], and read the Posting Guide mentioned at the bottom of this email which points out that you should post in plain text or we might not see what you see.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 14, 2014 6:38:53 PM PDT, Ryan Dallavia <rcdall at gmail.com> wrote:
>Hello,
>
>I am new to this program. I initially installed both R and R Studio 3
>months ago, easily and got a d-base icon from the package I needed, and
>saw
>my tables in spreadsheet form in studio. Now, everything has
>disappeared on
>its own -seriously nothing changed.  When trying to get my package
>back, I
>get this:
>
>Error: could not find function "intall.packages"
>Installing package into ???/Users/Computer/Library/R/3.1/library???
>(as ???lib??? is unspecified)
>trying URL '
>http://ftp.ussg.iu.edu/CRAN/bin/macosx/mavericks/contrib/3.1/SoDA_1.0-6.tgz'
>Content type 'application/x-gzip' length 255365 bytes (249 Kb)
>opened URL
>==================================================
>downloaded 249 Kb
>The downloaded binary packages are in
>
>/var/folders/bd/7z7gw4w953sd0tmgsrhdqw680000gn/T//RtmpTAMQLx/downloaded_packages
>
>var is a private directory. Though I can pull individual tables from
>the
>package (Lahman), they are now unlinked. SQL and stat commands are
>rejected
>by R and Studio. I tried about 2 dozen methods of changing the
>directory,
>specifying .lib and libPaths, (at least the ones online I understood),
>and
>nothing worked, I moved the package (Lahman) to an R directory, but I
>did
>not see it, and there seems to be no way to turn it back into a working
>d-base in the working dir complete with icon suggesting it is locked
>and
>loaded. I have tried clean installs of everything, yet R-Studio seems
>to
>remember what I did last (I don't know how). I need this back the way
>it
>was: a functioning d-base from Lahman package in R-Studio and R.
>Suggestions seriously needed. It seems unfixable, and the "var' problem
>seems very rare. Thanks for reading this.
>
>Cheers,
>RCD
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rcdall at gmail.com  Tue Jul 15 07:37:33 2014
From: rcdall at gmail.com (Ryan Dallavia)
Date: Tue, 15 Jul 2014 00:37:33 -0500
Subject: [R] Mac OSX Mavericks 10.9.3 Big Problem - New User
In-Reply-To: <53699cef-9483-4b50-9ad5-9cd327e85918@email.android.com>
References: <CADCHy177j1OZfuMgjcnUfJrsOpZP5D-fr8CLih9AS08LeQ12EA@mail.gmail.com>
	<53699cef-9483-4b50-9ad5-9cd327e85918@email.android.com>
Message-ID: <CADCHy17JymKQRdTxGnMUW8X+FGcjr_Fhk6BoSJg_LPqXk5okTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/76e04967/attachment.pl>

From petr.pikal at precheza.cz  Tue Jul 15 08:05:47 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 15 Jul 2014 06:05:47 +0000
Subject: [R] List of Lists by for Loop
In-Reply-To: <CAOWjiK_=W1UThycVwLXZC6Rrj2nQhAmcpns-XU9YA9hw0+UJJQ@mail.gmail.com>
References: <CAOWjiK_=W1UThycVwLXZC6Rrj2nQhAmcpns-XU9YA9hw0+UJJQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDB664@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Munjal Patel
> Sent: Monday, July 14, 2014 8:45 PM
> To: r-help at r-project.org
> Subject: [R] List of Lists by for Loop
>
> Dear Experts,
> I have a one more doubt about making list of lists.
> Here is the simple code i have made.
> I am doing the following for only one digit=20

You can try something like that (untested)

numbers<-c(20, 30, 40, 50)
master<-vector(length(numbers), mode="list")
k <- 0
for(j in numbers)
{
k<-k+1
a=vector(j,mode="list")
b=vector(j,mode="list")

> for (i in 1:j){
>   #Do Calculation
>   a[[i]]=data.frame(####)
>   b[[i]]=data.frame(####)
}
master[[k]] <- list(a, b)
}

Regards
Petr


>
> Now i have to repeat the whole process for Digits=c(30,40,50,60)
> In short I want the Master list containing following
> List 1(#20)
>      List a
>      List b
>
> List 2(#30)
>      List a
>      List b
>
> ........so on
> Can you please guide me in this ?
> Thank you very much.
> Sincerely
>
> --
> Munjal Patel
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ripley at stats.ox.ac.uk  Tue Jul 15 08:42:46 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Jul 2014 07:42:46 +0100
Subject: [R] Update fail
In-Reply-To: <20140714200001.47078ac8@draco>
References: <20140714200001.47078ac8@draco>
Message-ID: <53C4CD66.90605@stats.ox.ac.uk>

On 15/07/2014 04:00, jwd wrote:
> I've been getting of an "R-patched" update, but running the process
> results in the following:
>
> File './x86_64/R-patched-devel-3.1.1-4.1.x86_64.rpm' not found on
> medium
> 'http://download.opensuse.org/repositories/devel:/languages:/R:/patched/openSUSE_13.1/'
>
>
> The system is opensuse 13.1, Linux 3.11.10-17
>
> R reports as version 3.1.1 which seems to be the current release.
>
> I'm not quite sure who is most appropriate to report this too.

OpenSUSE.

If 'R-patched-devel-3.1.1' really is their naming, it certainly is not 
from the R project (which uses either R-devel or R-patched, but not both 
together.  See the R FAQ.).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From johannesradinger at gmail.com  Tue Jul 15 11:20:23 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 15 Jul 2014 11:20:23 +0200
Subject: [R] Set file path in Biomod2
Message-ID: <CABsGe_yQxHyOynXLoB=WYC0MzGySwbjLVFLngKBDj=5q9hBU2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/e22dcc21/attachment.pl>

From jzmoser at gmail.com  Tue Jul 15 12:28:13 2014
From: jzmoser at gmail.com (Johannes Moser)
Date: Tue, 15 Jul 2014 12:28:13 +0200
Subject: [R] Restricted fitting of two-component mixture distribution in R
	possible?
In-Reply-To: <53615D6A.9050503@googlemail.com>
References: <53615D6A.9050503@googlemail.com>
Message-ID: <53C5023D.5050903@googlemail.com>

Dear list,

In fitting a two-component Student's t mixture distribution to some data 
(standardized GARCH residuals) one of the components has an estimated 
degree of freedom of 0.6. This means that even the first moment of the 
mixture distribution would not exist.

The gamlss.mx package in R is used for estimation. gamlss.control, 
glim.control and MX.control seem not to support this kind of option -- 
or I couldn't find out how...

Is there a way to restrict the degree of freedom parameter estimates to 
be larger than, say, 3?

Many thanks in advance,
Johannes


From gunter.berton at gene.com  Tue Jul 15 12:38:18 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 15 Jul 2014 03:38:18 -0700
Subject: [R] how to remove outliers
In-Reply-To: <CAP+bYWDnEHS-93Eo2E73PJ1=awbu-8+L4j7zRwvEkR-q8kX3TA@mail.gmail.com>
References: <CAE0cxbEWTZ6Ky=JHkg-z==Yu+C3=xJK7m-89wMLZK_ZNxfL=Uw@mail.gmail.com>
	<CAP+bYWDnEHS-93Eo2E73PJ1=awbu-8+L4j7zRwvEkR-q8kX3TA@mail.gmail.com>
Message-ID: <CACk-te07PfSpkLuE5tYSV1bH0SAfqPK98KvfYx8aD23w=HDntA@mail.gmail.com>

No! Do not do this.

First, the syntax is wrong. Second, this will fail in general due to
floating point arithmetic. Use inequality with sufficient fuzz
instead.

e.g.
time <- time[time$TimeDiff < 14478,]

Moral: Caveat Emptor. Free advice may be worth exactly that.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Jul 14, 2014 at 9:43 PM, Hasan Diwan <hasan.diwan at gmail.com> wrote:
> Marta,
> To remove a row from your data frame, use:
>
> value <- 14478.4
> time <- time[-time[$TimeDiff] == value,]
>
> I hope that helps... If not, do push back. -- H
>
>
> On 14 July 2014 09:17, Marta valdes lopez <martavaldes85 at gmail.com> wrote:
>
>> Hi!
>>
>> I did this test and I got this outlier that i would like to remove the
>> whole row in my database; anyone knows how i can remove it?
>>
>>  chisq.out.test(time$TimeDiff)
>>         chi-squared test for outlier
>> data:  time$TimeDiff
>> X-squared = 73260.07, p-value < 2.2e-16
>> alternative hypothesis: highest value 14478.4 is an outlier
>>
>> Thank you!!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Sent from my mobile device
> Envoy? de mon portable
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From monaly.mistry at gmail.com  Tue Jul 15 13:25:42 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Tue, 15 Jul 2014 12:25:42 +0100
Subject: [R] canonical correlation
In-Reply-To: <53C44EE7.2060208@yorku.ca>
References: <CANpv+66mqSaSbqu7nsy7vDdGQ2QFWtSzq-XgN1qR6u4HAiYvxQ@mail.gmail.com>
	<CADgEnDkCQpSSXoJNgTXwFjMY11uQhjc2aDa+dtVSmB36JgffwQ@mail.gmail.com>
	<26853_1405260914_s6DEFDew001243_web-518429871@cgpsrv2.cis.mcmaster.ca>
	<web-518430017@cgpsrv2.cis.mcmaster.ca>
	<CANpv+66nRvMLM0W8O1CdkC6ZSjpzO6DE_AMuqfMw6Uwm=BZUAA@mail.gmail.com>
	<53C44EE7.2060208@yorku.ca>
Message-ID: <CANpv+656D9ge_pGfiKC8b+jjpyT6E=Uj9s7rW8-c1xsv0odGGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/55f388fd/attachment.pl>

From Mark.Fowler at dfo-mpo.gc.ca  Tue Jul 15 13:59:20 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Tue, 15 Jul 2014 08:59:20 -0300
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <1875188.O42FXxQtEb@localhost.localdomain>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
	<1875188.O42FXxQtEb@localhost.localdomain>
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F80692100D@marbioexc02.mar.dfo-mpo.ca>

Hi Jim,
Thought I tried that. Just have one session running currently, started
yesterday, help still linked. I'll wait for the link to expire and
confirm.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Jim Lemon
Sent: July 15, 2014 12:17 AM
To: r-help at r-project.org
Subject: Re: [R] two questions - function help and 32vs64 bit sessions

On Mon, 14 Jul 2014 01:42:54 PM Fowler, Mark wrote:
> Hello,
> 
> 
> 
> Two unrelated questions, and neither urgent.
> 
> 
> 
> Windows 7, R 3.0.1. Using R Console, no fancy interface.
> 
> 
> 
> The function help ultimately becomes lost to a session kept running
for
> extended periods (days). I.e. with a new session if you invoke the 
> Help menu 'R functions (txt)...' it activates the html help and goes 
> to the named function page. This will work fine for at least a day, 
> but typically the next day invoking the help menu in this fashion will

> fail, as R looks for a temporary address it creates on your computer. 
> This gets lost, possibly due to network administration activity. So 
> then I save and start another session with same Rdata. Trivial enough 
> but irritating. Anybody know how to restore the 'link' without ending 
> and restarting the session?

Hi Mark,
I simply shut down the help browser. It will restart with a new IP
address.

Jim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From eesteves at ualg.pt  Tue Jul 15 15:16:24 2014
From: eesteves at ualg.pt (Eduardo Esteves)
Date: Tue, 15 Jul 2014 14:16:24 +0100
Subject: [R] Meaningfulness of applying the delta method (sensu alr3)...
Message-ID: <00f101cfa02e$fa6f4650$ef4dd2f0$@ualg.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/b2bb88fd/attachment.pl>

From john.archie.mckown at gmail.com  Tue Jul 15 16:38:49 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 15 Jul 2014 09:38:49 -0500
Subject: [R] Reading SQL data - all at once, or "as needed"?
Message-ID: <CAAJSdjhD1PPuJKVveJUyS3OAyJWjapeGxjNGUi5u2kW+PDe9Fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/2dd7c9b7/attachment.pl>

From gordic91 at gmail.com  Tue Jul 15 14:44:32 2014
From: gordic91 at gmail.com (Velimir Gordic)
Date: Tue, 15 Jul 2014 14:44:32 +0200
Subject: [R] Granger causality test using VECM in R
Message-ID: <069BED3B-7F66-43C3-811D-940FB2223B6E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/9fc226a5/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Jul 15 17:01:10 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Jul 2014 08:01:10 -0700
Subject: [R] Reading SQL data - all at once, or "as needed"?
In-Reply-To: <CAAJSdjhD1PPuJKVveJUyS3OAyJWjapeGxjNGUi5u2kW+PDe9Fw@mail.gmail.com>
References: <CAAJSdjhD1PPuJKVveJUyS3OAyJWjapeGxjNGUi5u2kW+PDe9Fw@mail.gmail.com>
Message-ID: <8468d0ff-c49c-4fdc-93d0-79774ec67138@email.android.com>

The actual answer (which way is faster) in general can go either way depending how much data you extract and how well optimized the SQL queries and indexes are. The amount of data you mention fit one or give weeks seems small for most modern computers, though (you did not mention how many columns but it would have to be a lot to change the story).

I would go for all five weeks at once, and only break it up if I had problems.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 15, 2014 7:38:49 AM PDT, John McKown <john.archie.mckown at gmail.com> wrote:
>I have some data in an SQL data base (PostgreSQL to be exact). This
>data
>base (one table in particular) has a lot of data in it. Years worth, in
>fact (2.3 million rows since 2012). That just for background.
>
>My question is: If I am going to create 5 separate graphs, one graph
>for
>each of the previous 5 weeks (in this case a week is Sunday to
>Saturday),
>is it better to read in all 5 weeks worth of data in a single
>dbGetQuery
>where the SELECT has a WHERE clause which will get the proper 5 weeks
>worth
>of data, then subset in R. Or is it better to get a single weeks worth
>of
>data in a dbGetQuery, with the proper SELECT ... WHERE. And then
>process
>each week. There seems to be anywhere from 7,500 to 9,000 entries for a
>single week. The calculations for each week are independent of any
>other
>week's data. Basically I am just creating a simple bar chart.
>
>In the first case, I do one SELECT; and then subset the data.frame data
>in
>the for() loop. In the second case, I still use a for() loop, but I do
>a
>SELECT in each iteration, but don't need to subset the data.frame.
>
>I have read the "Data Import/Export". The only advice I can find is
>based
>on:
><quote>
>The sort of statistical applications for which DBMS might be used are
>to
>extract a 10% sample of the data, to cross-tabulate data to produce a
>multi-dimensional contingency table, and to extract data group by group
>from a database for separate analysis.
></quote>
>
>The "extract data group by group ..." seems, to me, to say that I
>should
>extract and process each week's data separately, using a dbGetQuery in
>my
>loop. Am I interpreting this correctly?
>
>Thanks for your advice.


From jlh.membership at gmail.com  Tue Jul 15 17:13:55 2014
From: jlh.membership at gmail.com (jlh.membership)
Date: Tue, 15 Jul 2014 11:13:55 -0400
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>	<CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>	<53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>
	<CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>
Message-ID: <009a01cfa03f$6a1c3110$3e549330$@gmail.com>

Hi Johannes,

Looking at the code for cutree(...), if h is provided but not k, then cutree(...) calculates k from h and calls a C function with k
to cut the tree (but all this only if height is sorted). So we can short circuit the test this way:

cutree.h <- function(tree,h) {
  # this line adapted from cutree(...) code
  k <- nrow(tree$merge) + 2L - apply(outer(c(hc$height, Inf), h, ">"), 2, which.max)
  return(cutree(tree,k=k))
}
df$memb <- cutree.h(hc, h = 60) # this *does* work 
plot(df$x,df$y,col=df$memb)

This does work, at least for your example, but note that you didn't set the seed so the plot will be different from your original
question.

John Howard
Prism Marketing Group
http://www.prismmg.com


-----Original Message-----
From: Johannes Radinger [mailto:johannesradinger at gmail.com] 
Sent: Monday, July 14, 2014 7:43 AM
To: David L Carlson
Cc: R help
Subject: Re: [R] Cutting hierarchical cluster tree at specific height fails

Of course,
manually checking the number of clusters that are cut at a specific height (e.g. by abline()) is one possibility. However, this only
makes sense for single trees, but is not a feasible approach for multiple model runs when hundreds of trees are built with many
cluster branches.

Thus, I'd be nice if somebody knows a more programatic approach or another package that allows cutting "centroid"-trees.

/Johannes


On Fri, Jul 11, 2014 at 4:19 PM, David L Carlson <dcarlson at tamu.edu> wrote:

>  The easiest workaround is the one you included in your original posting.
> Specify k= and not h=. Examine the dendrogram and decide how many 
> clusters are at the level you want. You could add guidelines to the 
> dendrogram with
> abline() to make it easier to see the number of clusters at various heights.
>
>
>
> plot(hc)
>
> abline(h=c(20, 40, 60, 80, 100, 120), lty=3)
>
>
>
> David C
>
>
>
> *From:* Johannes Radinger [mailto:johannesradinger at gmail.com]
> *Sent:* Friday, July 11, 2014 3:24 AM
> *To:* David L Carlson; R help
> *Subject:* Re: [R] Cutting hierarchical cluster tree at specific 
> height fails
>
>
>
> Hi,
>
>
>
> @David: Thanks for the explanation why this does not work. This of
>
> course makes theoretically sense.
>
>
>
> However in a recent discussion
>
> (
> http://stats.stackexchange.com/questions/107448/spatial-distance-betwe
> en-cluster-means
> )
>
> it was stated that "the 'reversals problem' of  centroid method is
>
> not a serious reason to deactivate the option of 'tree cut'". Instead
>
> a warning message should be provided rather than a deactivation.
>
>
>
> So does anyone know how a tree that was created with "centroid" can 
> still
>
> be cut at a specific height? I tried the package "dynamicTreeCut", but 
> this
>
> also relies on cutree and consequently raises an error when used for 
> cutting
>
> "centroid" trees.
>
>
>
> Does anyone know a work around and can provide a minimum working example?
>
>
>
> /Johannes
>
>
>
> On Wed, Jul 9, 2014 at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
> To cut the tree, the clustering algorithm must produce consistently 
> increasing height values with no reversals. You used one of the two 
> options in hclust that does not do this. Note the following from the 
> hclust manual
> page:
>
> "Note however, that methods "median" and "centroid" are not leading to 
> a monotone distance measure, or equivalently the resulting dendrograms 
> can have so called inversions (which are hard to interpret)."
>
> The cutree manual page:
>
> "Cutting trees at a given height is only possible for ultrametric 
> trees (with monotone clustering heights)."
>
> Use a different method (but not median).
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org]
> On Behalf Of Johannes Radinger
> Sent: Wednesday, July 9, 2014 7:07 AM
> To: R help
> Subject: [R] Cutting hierarchical cluster tree at specific height 
> fails
>
> Hi,
>
> I'd like to cut a hierachical cluster tree calculated with hclust at a 
> specific height.
> However ever get following error message:
> "Error in cutree(hc, h = 60) :
>   the 'height' component of 'tree' is not sorted (increasingly)"
>
>
> Here is a working example to show that when specifing a height in  
> cutree() the code fails. In contrast, specifying the number of 
> clusters in cutree() works.
> What is the exact problem and how can I solve it?
>
> x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
> y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
> df <- data.frame(x,y)
> plot(df)
>
> hc <- hclust(dist(df,method = "euclidean"), method="centroid")
> plot(hc)
>
> df$memb <- cutree(hc, h = 60) # this does not work df$memb <- 
> cutree(hc, k = 3) # this works!
>
> plot(df$x,df$y,col=df$memb)
>
>
> Thank you for your hints!
>
> Best regards,
> Johannes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Jul 15 17:49:57 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 15 Jul 2014 11:49:57 -0400
Subject: [R] Determine the order of Time series
In-Reply-To: <BAY175-W13DB1B10AAAA5E53F70704A30A0@phx.gbl>
References: <BAY175-W13DB1B10AAAA5E53F70704A30A0@phx.gbl>
Message-ID: <CAGx1TMB0L7Fq4ZzkBxMATsU8Gj1Ptp+eicb8ryVikAScuM8Xyg@mail.gmail.com>

Yes, of course.

Please look at the tsdiagplot function in the HH package.

install.packages("HH")  ## if you don't have it yet
?tsdiagplot
The example shows  0<p<3 and 0<q<3

You can change that to 6 and 10 with

X.loop <- arma.loop(X, order=c(6,0,10))
## The example dataset gives warnings and trapped errors because these
values are too big for this dataset.
X.dal <- diag.arma.loop(X.loop, x=X)
X.diag <- rearrange.diag.arma.loop(X.dal)
X.diagplot <- tsdiagplot(armas=X.loop, ts.diag=X.diag, lwd=1)
X.diagplot

## You will need a big plotting window to see this, the screen isn't big enough
pdf("example.pdf", width=24, height=12)
X.diagplot
dev.off()

This is my first example with two-digit q, and I discovered that the
ar:p,ma:q values are sequenced
alphabetically instead of numerically.  That shows up as the
ar:0,ma:10 column appearing
between the ar:0,ma:1 and ar:0,ma:2 columns.  I will fix it in the
next release of HH (probably late August).

Please let me (and the list) know how this works for you.

Rich


On Mon, Jul 14, 2014 at 3:49 PM, ??? <pennytianzh at hotmail.com> wrote:
>
>
>
>  Dear R help team,
>
> I am currently stuck on how to determine the order of a data. I have plotted the ACF and PACF of the data and it does not seem to cuts off. Is that possible to plot AIC BIC of some order(p,q) say, 0<p<6 and 0<q<10 on the same graph so that I can compare the value of AIC and BIC to determine the best model to fit? (Please see attached picture that can clear describe what I am looking for.)
>
> Or, is there any other way to determine the order of the data?
>
> Thank you so much for your time
>
> Kind Regrads
>
> Penny
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Ellison at LGCGroup.com  Tue Jul 15 18:04:56 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 15 Jul 2014 17:04:56 +0100
Subject: [R] how to remove outliers
In-Reply-To: <CACk-te07PfSpkLuE5tYSV1bH0SAfqPK98KvfYx8aD23w=HDntA@mail.gmail.com>
References: <CAE0cxbEWTZ6Ky=JHkg-z==Yu+C3=xJK7m-89wMLZK_ZNxfL=Uw@mail.gmail.com>
	<CAP+bYWDnEHS-93Eo2E73PJ1=awbu-8+L4j7zRwvEkR-q8kX3TA@mail.gmail.com>
	<CACk-te07PfSpkLuE5tYSV1bH0SAfqPK98KvfYx8aD23w=HDntA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E9DF55D30@GOLD.corp.lgc-group.com>

The outlier is a maximum value, so which.max() is likely to be useful 

time <- time[-which.max(time$TimeDiff ),]

should work reliably.


S Ellison

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Bert Gunter
> Sent: 15 July 2014 11:38
> To: Hasan Diwan
> Cc: R Project Help
> Subject: Re: [R] how to remove outliers
> 
> No! Do not do this.
> 
> First, the syntax is wrong. Second, this will fail in general due to floating point
> arithmetic. Use inequality with sufficient fuzz instead.
> 
> e.g.
> time <- time[time$TimeDiff < 14478,]
> 
> Moral: Caveat Emptor. Free advice may be worth exactly that.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Mon, Jul 14, 2014 at 9:43 PM, Hasan Diwan <hasan.diwan at gmail.com>
> wrote:
> > Marta,
> > To remove a row from your data frame, use:
> >
> > value <- 14478.4
> > time <- time[-time[$TimeDiff] == value,]
> >
> > I hope that helps... If not, do push back. -- H
> >
> >
> > On 14 July 2014 09:17, Marta valdes lopez <martavaldes85 at gmail.com>
> wrote:
> >
> >> Hi!
> >>
> >> I did this test and I got this outlier that i would like to remove
> >> the whole row in my database; anyone knows how i can remove it?
> >>
> >>  chisq.out.test(time$TimeDiff)
> >>         chi-squared test for outlier
> >> data:  time$TimeDiff
> >> X-squared = 73260.07, p-value < 2.2e-16 alternative hypothesis:
> >> highest value 14478.4 is an outlier
> >>
> >> Thank you!!
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Sent from my mobile device
> > Envoy? de mon portable
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From Ludovic.Brossard at rennes.inra.fr  Tue Jul 15 17:35:38 2014
From: Ludovic.Brossard at rennes.inra.fr (Ludovic Brossard)
Date: Tue, 15 Jul 2014 17:35:38 +0200
Subject: [R] request of information about creating DLL from R to be used in
	other languages/programs
Message-ID: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/de646ac1/attachment.pl>

From musketeere at gmail.com  Tue Jul 15 17:24:01 2014
From: musketeere at gmail.com (Electron Musketeer)
Date: Tue, 15 Jul 2014 16:24:01 +0100
Subject: [R] Help with Download of a comma separated file in zip format
Message-ID: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/dfb36370/attachment.pl>

From dcarlson at tamu.edu  Tue Jul 15 19:11:59 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 15 Jul 2014 17:11:59 +0000
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <009a01cfa03f$6a1c3110$3e549330$@gmail.com>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
	<CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>
	<CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>
	<009a01cfa03f$6a1c3110$3e549330$@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F89EAB@mb02.ads.tamu.edu>

I believe you can accomplish this without modifying cutree by analyzing the cluster heights before calling cutree. First generate the data setting the random seed so we are all looking at the same thing:

set.seed(42)
x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
df <- data.frame(x,y)
hc <- hclust(dist(df,method = "euclidean"), method="centroid")

Now figure where to cut the tree by finding the first place that 60 is exceeded. Because of the reversals, there could be more than one solution, so we take the one with more clusters:

hval <- 60
nclust <- (nrow(df)-1):1 # Number of clusters at each step
# Find the number of clusters that first exceeds hval
k <- max(nclust[which(diff(hc$height < hval) == -1) + 1])
df$memb <- cutree(hc, k = k)

David C

-----Original Message-----
From: jlh.membership [mailto:jlh.membership at gmail.com] 
Sent: Tuesday, July 15, 2014 10:14 AM
To: 'Johannes Radinger'; David L Carlson
Cc: 'R help'
Subject: RE: [R] Cutting hierarchical cluster tree at specific height fails

Hi Johannes,

Looking at the code for cutree(...), if h is provided but not k, then cutree(...) calculates k from h and calls a C function with k
to cut the tree (but all this only if height is sorted). So we can short circuit the test this way:

cutree.h <- function(tree,h) {
  # this line adapted from cutree(...) code
  k <- nrow(tree$merge) + 2L - apply(outer(c(hc$height, Inf), h, ">"), 2, which.max)
  return(cutree(tree,k=k))
}
df$memb <- cutree.h(hc, h = 60) # this *does* work 
plot(df$x,df$y,col=df$memb)

This does work, at least for your example, but note that you didn't set the seed so the plot will be different from your original
question.

John Howard
Prism Marketing Group
http://www.prismmg.com


-----Original Message-----
From: Johannes Radinger [mailto:johannesradinger at gmail.com] 
Sent: Monday, July 14, 2014 7:43 AM
To: David L Carlson
Cc: R help
Subject: Re: [R] Cutting hierarchical cluster tree at specific height fails

Of course,
manually checking the number of clusters that are cut at a specific height (e.g. by abline()) is one possibility. However, this only
makes sense for single trees, but is not a feasible approach for multiple model runs when hundreds of trees are built with many
cluster branches.

Thus, I'd be nice if somebody knows a more programatic approach or another package that allows cutting "centroid"-trees.

/Johannes


On Fri, Jul 11, 2014 at 4:19 PM, David L Carlson <dcarlson at tamu.edu> wrote:

>  The easiest workaround is the one you included in your original posting.
> Specify k= and not h=. Examine the dendrogram and decide how many 
> clusters are at the level you want. You could add guidelines to the 
> dendrogram with
> abline() to make it easier to see the number of clusters at various heights.
>
>
>
> plot(hc)
>
> abline(h=c(20, 40, 60, 80, 100, 120), lty=3)
>
>
>
> David C
>
>
>
> *From:* Johannes Radinger [mailto:johannesradinger at gmail.com]
> *Sent:* Friday, July 11, 2014 3:24 AM
> *To:* David L Carlson; R help
> *Subject:* Re: [R] Cutting hierarchical cluster tree at specific 
> height fails
>
>
>
> Hi,
>
>
>
> @David: Thanks for the explanation why this does not work. This of
>
> course makes theoretically sense.
>
>
>
> However in a recent discussion
>
> (
> http://stats.stackexchange.com/questions/107448/spatial-distance-betwe
> en-cluster-means
> )
>
> it was stated that "the 'reversals problem' of  centroid method is
>
> not a serious reason to deactivate the option of 'tree cut'". Instead
>
> a warning message should be provided rather than a deactivation.
>
>
>
> So does anyone know how a tree that was created with "centroid" can 
> still
>
> be cut at a specific height? I tried the package "dynamicTreeCut", but 
> this
>
> also relies on cutree and consequently raises an error when used for 
> cutting
>
> "centroid" trees.
>
>
>
> Does anyone know a work around and can provide a minimum working example?
>
>
>
> /Johannes
>
>
>
> On Wed, Jul 9, 2014 at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
> To cut the tree, the clustering algorithm must produce consistently 
> increasing height values with no reversals. You used one of the two 
> options in hclust that does not do this. Note the following from the 
> hclust manual
> page:
>
> "Note however, that methods "median" and "centroid" are not leading to 
> a monotone distance measure, or equivalently the resulting dendrograms 
> can have so called inversions (which are hard to interpret)."
>
> The cutree manual page:
>
> "Cutting trees at a given height is only possible for ultrametric 
> trees (with monotone clustering heights)."
>
> Use a different method (but not median).
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org]
> On Behalf Of Johannes Radinger
> Sent: Wednesday, July 9, 2014 7:07 AM
> To: R help
> Subject: [R] Cutting hierarchical cluster tree at specific height 
> fails
>
> Hi,
>
> I'd like to cut a hierachical cluster tree calculated with hclust at a 
> specific height.
> However ever get following error message:
> "Error in cutree(hc, h = 60) :
>   the 'height' component of 'tree' is not sorted (increasingly)"
>
>
> Here is a working example to show that when specifing a height in  
> cutree() the code fails. In contrast, specifying the number of 
> clusters in cutree() works.
> What is the exact problem and how can I solve it?
>
> x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
> y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
> df <- data.frame(x,y)
> plot(df)
>
> hc <- hclust(dist(df,method = "euclidean"), method="centroid")
> plot(hc)
>
> df$memb <- cutree(hc, h = 60) # this does not work df$memb <- 
> cutree(hc, k = 3) # this works!
>
> plot(df$x,df$y,col=df$memb)
>
>
> Thank you for your hints!
>
> Best regards,
> Johannes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Tue Jul 15 19:31:42 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 15 Jul 2014 10:31:42 -0700
Subject: [R] Cutting hierarchical cluster tree at specific height fails
In-Reply-To: <CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>
References: <CABsGe_xRx48J7RH1-kG6ZU_QnOt91FnaA5+9Xx=We6_YFsBz+w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F84983@mb02.ads.tamu.edu>
	<CABsGe_xnYpDNGyCjgE796aLiAF8L_r=guck8svv+XOROLbcdbQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F876E1@mb02.ads.tamu.edu>
	<CABsGe_wX3SP4-93WAKHNCepjVbW2OyXRdD30+PLaMqsYxM-P4w@mail.gmail.com>
Message-ID: <CA+hbrhUbKJO-yfTrMx_GWz+hBV4yc4EU9S7N18wD-TNTqevS3g@mail.gmail.com>

Hi Johannes,

you mentioned dynamicTreeCut - the dynamic hybrid method works fine on
your data. Just supply the dissimilarity matrix as well: I use the
function plotDendroAndColors from WGCNA to show the results; if you
don't want to use WGCNA, just leave out the last call.

library(WGCNA)

set.seed(42)
x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
df <- data.frame(x,y)
hc <- hclust(dist(df,method = "euclidean"), method="centroid")
dm = as.matrix(dist(df,method = "euclidean"))
plot(hc)
labels = cutreeDynamic(hc, distM = dm, deepSplit = 2)
# ..cutHeight not given, setting it to 115  ===>  99% of the
(truncated) height range in #dendro.
#..done.
plotDendroAndColors(hc, labels)

As you see, the algorithm found 3 clusters that seem right based on
the dendrogram.

Please look carefully at the help file for cutreeDynamic since the
defaults may not be what you want.

If you absolutely want to cut at a given height, it can be done as
well, but the arguments will need some massaging.

Best,

Peter

On Mon, Jul 14, 2014 at 4:42 AM, Johannes Radinger
<johannesradinger at gmail.com> wrote:
> Of course,
> manually checking the number of clusters that are cut at a specific height
> (e.g. by abline())
> is one possibility. However, this only makes sense for single trees, but is
> not a feasible
> approach for multiple model runs when hundreds of trees are built with many
> cluster branches.
>
> Thus, I'd be nice if somebody knows a more programatic approach or another
> package
> that allows cutting "centroid"-trees.
>
> /Johannes
>
>
> On Fri, Jul 11, 2014 at 4:19 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>>  The easiest workaround is the one you included in your original posting.
>> Specify k= and not h=. Examine the dendrogram and decide how many clusters
>> are at the level you want. You could add guidelines to the dendrogram with
>> abline() to make it easier to see the number of clusters at various heights.
>>
>>
>>
>> plot(hc)
>>
>> abline(h=c(20, 40, 60, 80, 100, 120), lty=3)
>>
>>
>>
>> David C
>>
>>
>>
>> *From:* Johannes Radinger [mailto:johannesradinger at gmail.com]
>> *Sent:* Friday, July 11, 2014 3:24 AM
>> *To:* David L Carlson; R help
>> *Subject:* Re: [R] Cutting hierarchical cluster tree at specific height
>> fails
>>
>>
>>
>> Hi,
>>
>>
>>
>> @David: Thanks for the explanation why this does not work. This of
>>
>> course makes theoretically sense.
>>
>>
>>
>> However in a recent discussion
>>
>> (
>> http://stats.stackexchange.com/questions/107448/spatial-distance-between-cluster-means
>> )
>>
>> it was stated that "the 'reversals problem' of  centroid method is
>>
>> not a serious reason to deactivate the option of 'tree cut'". Instead
>>
>> a warning message should be provided rather than a deactivation.
>>
>>
>>
>> So does anyone know how a tree that was created with "centroid" can still
>>
>> be cut at a specific height? I tried the package "dynamicTreeCut", but this
>>
>> also relies on cutree and consequently raises an error when used for
>> cutting
>>
>> "centroid" trees.
>>
>>
>>
>> Does anyone know a work around and can provide a minimum working example?
>>
>>
>>
>> /Johannes
>>
>>
>>
>> On Wed, Jul 9, 2014 at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> To cut the tree, the clustering algorithm must produce consistently
>> increasing height values with no reversals. You used one of the two options
>> in hclust that does not do this. Note the following from the hclust manual
>> page:
>>
>> "Note however, that methods "median" and "centroid" are not leading to a
>> monotone distance measure, or equivalently the resulting dendrograms can
>> have so called inversions (which are hard to interpret)."
>>
>> The cutree manual page:
>>
>> "Cutting trees at a given height is only possible for ultrametric trees
>> (with monotone clustering heights)."
>>
>> Use a different method (but not median).
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Johannes Radinger
>> Sent: Wednesday, July 9, 2014 7:07 AM
>> To: R help
>> Subject: [R] Cutting hierarchical cluster tree at specific height fails
>>
>> Hi,
>>
>> I'd like to cut a hierachical cluster tree calculated with hclust at a
>> specific height.
>> However ever get following error message:
>> "Error in cutree(hc, h = 60) :
>>   the 'height' component of 'tree' is not sorted (increasingly)"
>>
>>
>> Here is a working example to show that when specifing a height in  cutree()
>> the code fails. In contrast, specifying the number of clusters in cutree()
>> works.
>> What is the exact problem and how can I solve it?
>>
>> x <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,80,15))
>> y <- c(rnorm(100,50,10),rnorm(100,200,25),rnorm(100,150,25))
>> df <- data.frame(x,y)
>> plot(df)
>>
>> hc <- hclust(dist(df,method = "euclidean"), method="centroid")
>> plot(hc)
>>
>> df$memb <- cutree(hc, h = 60) # this does not work
>> df$memb <- cutree(hc, k = 3) # this works!
>>
>> plot(df$x,df$y,col=df$memb)
>>
>>
>> Thank you for your hints!
>>
>> Best regards,
>> Johannes
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Jul 15 19:31:49 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Jul 2014 10:31:49 -0700
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
Message-ID: <8eab0a04-b7b7-4ec2-889f-1499a5f04fa4@email.android.com>

Circumventing content protection measures or picky server configurations such as this appears to be tends to involve HTTP protocol details that are off topic here, though someone may tackle your problem anyway and report back. Once you know what your protocol needs are (perhaps with the help of the Firebug Firefox developer tools) and have read the R documentation for the functions and packages you are using, asking for clarification on the documentation would be fair game here.

I tried setting the HTTPUserAgent string using the options function [1] but that didn't help.

Oh, and please read the Posting Guide mentioned at the bottom of all R-help posts, which points out that you should send plain text emails to this list. HTML is a what-you-see-is-not-necessarily-what-we-see format.

[1] https://stat.ethz.ch/pipermail/r-help/2007-November/145811.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 15, 2014 8:24:01 AM PDT, Electron Musketeer <musketeere at gmail.com> wrote:
>Dear Experts
>
>I am new to this forum and to R and was trying the following to access
>a
>zip file from  the webpages of the NSE. Here is my code.
>
>temp <- tempfile()
>download.file("
>http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>",temp)
>con <- unz(temp, "a1.dat")
>data <- matrix(scan(con),ncol=4,byrow=TRUE)
>unlink(temp)
>
>
>The result is:
>cannot open URL '
>http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>'
>In addition: Warning message:
>In download.file("
>http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
> :
>  cannot open: HTTP status was '403 Forbidden'
>
>
>I tried accessing this file directly from the website and it is letting
>me
>access it. My question is why is it not letting me download from R? I
>have
>gone through some websites to see if this has been resolved but the
>older
>resolutions also do not work. Can someone help please?
>
>Thx
>Balaji
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Jul 15 20:16:23 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 15 Jul 2014 14:16:23 -0400
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
Message-ID: <CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>

Not an R question, but see
https://addons.mozilla.org/en-US/firefox/addon/cliget/ for an easy way
to see what what is going on under the hood when you download using
firefox. For your example I get

wget --header='Host: www.nseindia.com' --header='User-Agent:
Mozilla/5.0 (X11; Linux x86_64; rv:30.0) Gecko/20100101 Firefox/30.0'
--header='Accept:
text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
--header='Accept-Language: en-US,en;q=0.5' --header='Connection:
keep-alive' 'http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip'
-O 'fo09JUL2014bhav.csv.zip' -c

Now you just need to translate that to R. (Or not, sometimes its
easier to just shell out (using e.g., 'system()' ) and download with
wget or curl).

Best,
Ista

On Tue, Jul 15, 2014 at 11:24 AM, Electron Musketeer
<musketeere at gmail.com> wrote:
> Dear Experts
>
> I am new to this forum and to R and was trying the following to access a
> zip file from  the webpages of the NSE. Here is my code.
>
> temp <- tempfile()
> download.file("
> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
> ",temp)
> con <- unz(temp, "a1.dat")
> data <- matrix(scan(con),ncol=4,byrow=TRUE)
> unlink(temp)
>
>
> The result is:
> cannot open URL '
> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
> '
> In addition: Warning message:
> In download.file("
> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
>  :
>   cannot open: HTTP status was '403 Forbidden'
>
>
> I tried accessing this file directly from the website and it is letting me
> access it. My question is why is it not letting me download from R? I have
> gone through some websites to see if this has been resolved but the older
> resolutions also do not work. Can someone help please?
>
> Thx
> Balaji
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Jul 15 20:17:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Jul 2014 11:17:01 -0700
Subject: [R] request of information about creating DLL from R to be used
	in	other languages/programs
In-Reply-To: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>
References: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>
Message-ID: <bcb23b30-b9a8-4421-aceb-626a110afaf7@email.android.com>

Possible, but almost certainly not worth it. R is an interpreted language, and the dll would have to encapsulate the whole shebang.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 15, 2014 8:35:38 AM PDT, Ludovic Brossard <Ludovic.Brossard at rennes.inra.fr> wrote:
>Hello
>
> 
>
>My question is the following. I have tried to find a similar subject in
>archives but not found (perhaps bad search!).
>
>One of my colleague wrote a R code combining some R functions to create
>a
>method of calculation.
>
>I would want to use this in a program coded in Delphi.
>
> 
>
>Is there possibilities to create a DLL from R code to be called in the
>Delphi program ?
>
>It would allow us to avoid rewriting code and searching correspondence
>between R functions and Delphi program (or other types of tools as
>TPMath).
>
> 
>
>I hope to be clear in my demand an I hope you will be able to give me
>some
>indications or where to find it.
>
> 
>
>Best regards
>
> 
>
>Ludovic Brossard
>
> 
>
> 
>
>Ludovic BROSSARD
>
>UMR PEGASE (Physiologie, Environnement et G?n?tique pour l?Animal et
>les
>Syst?mes d?Elevage)
>
>INRA ? Agrocampus Ouest
>
>Domaine de la Prise, 35590 Saint-Gilles, France
>
>T?l : 33 (0)2 23 48 70 57 . Fax : 33(0)2 23 48 50 80
>
> <http://www.rennes.inra.fr/pegase> www.rennes.inra.fr/pegase.  
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Jul 15 20:23:43 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 15 Jul 2014 14:23:43 -0400
Subject: [R] Determine the order of Time series
In-Reply-To: <BAY175-W10E5E64DC15F6577A637E6A3F60@phx.gbl>
References: <BAY175-W13DB1B10AAAA5E53F70704A30A0@phx.gbl>
	<CAGx1TMB0L7Fq4ZzkBxMATsU8Gj1Ptp+eicb8ryVikAScuM8Xyg@mail.gmail.com>
	<BAY175-W10E5E64DC15F6577A637E6A3F60@phx.gbl>
Message-ID: <CAGx1TMDbJRbbM6+KoVThDkzjzHqHJ6JSPyTmF7iPzk5D7TQGHw@mail.gmail.com>

I am returning this email thread to the list.

Yes, of course.

X.diagplot$resid
X.diagplot$aic
X.diagplot$acf
X.diagplot$pacf
X.diagplot$gof

On Tue, Jul 15, 2014 at 2:14 PM, ??? <pennytianzh at hotmail.com> wrote:
> Hi Rich,
>
> Thank you for your quick reply. I wonder if it is possible to view the PACF,
> ACF, P-value of gof ,aic and standardized residual separately thus I can
> have a bigger picture to look at.
>
> Thank you very much
>
> Kind Regards
>
> Penny
>
>> Date: Tue, 15 Jul 2014 11:49:57 -0400
>> Subject: Re: [R] Determine the order of Time series
>> From: rmh at temple.edu
>> To: pennytianzh at hotmail.com
>> CC: r-help at r-project.org
>
>>
>> Yes, of course.
>>
>> Please look at the tsdiagplot function in the HH package.
>>
>> install.packages("HH") ## if you don't have it yet
>> ?tsdiagplot
>> The example shows 0<p<3 and 0<q<3
>>
>> You can change that to 6 and 10 with
>>
>> X.loop <- arma.loop(X, order=c(6,0,10))
>> ## The example dataset gives warnings and trapped errors because these
>> values are too big for this dataset.
>> X.dal <- diag.arma.loop(X.loop, x=X)
>> X.diag <- rearrange.diag.arma.loop(X.dal)
>> X.diagplot <- tsdiagplot(armas=X.loop, ts.diag=X.diag, lwd=1)
>> X.diagplot
>>
>> ## You will need a big plotting window to see this, the screen isn't big
>> enough
>> pdf("example.pdf", width=24, height=12)
>> X.diagplot
>> dev.off()
>>
>> This is my first example with two-digit q, and I discovered that the
>> ar:p,ma:q values are sequenced
>> alphabetically instead of numerically. That shows up as the
>> ar:0,ma:10 column appearing
>> between the ar:0,ma:1 and ar:0,ma:2 columns. I will fix it in the
>> next release of HH (probably late August).
>>
>> Please let me (and the list) know how this works for you.
>>
>> Rich
>>
>>
>> On Mon, Jul 14, 2014 at 3:49 PM, ??? <pennytianzh at hotmail.com> wrote:
>> >
>> >
>> >
>> > Dear R help team,
>> >
>> > I am currently stuck on how to determine the order of a data. I have
>> > plotted the ACF and PACF of the data and it does not seem to cuts off. Is
>> > that possible to plot AIC BIC of some order(p,q) say, 0<p<6 and 0<q<10 on
>> > the same graph so that I can compare the value of AIC and BIC to determine
>> > the best model to fit? (Please see attached picture that can clear describe
>> > what I am looking for.)
>> >
>> > Or, is there any other way to determine the order of the data?
>> >
>> > Thank you so much for your time
>> >
>> > Kind Regrads
>> >
>> > Penny
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >


From jvadams at usgs.gov  Tue Jul 15 20:55:25 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 15 Jul 2014 13:55:25 -0500
Subject: [R] List of Lists in For Loop
In-Reply-To: <CAOWjiK8YDBDTf2JBEnzSf9+xst_c4AhOEaau-Ru9bqEdQicMUA@mail.gmail.com>
References: <CAOWjiK8YDBDTf2JBEnzSf9+xst_c4AhOEaau-Ru9bqEdQicMUA@mail.gmail.com>
Message-ID: <CAN5YmCH0DYyWBRES0C35Scanz9VdjB7KmvkSBr_LxJrFun_7Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/51cc6d4b/attachment.pl>

From ludovic.brossard at rennes.inra.fr  Tue Jul 15 22:24:25 2014
From: ludovic.brossard at rennes.inra.fr (Ludovic.Brossard)
Date: Tue, 15 Jul 2014 22:24:25 +0200
Subject: [R] request of information about creating DLL from R to be used
 in other languages/programs
In-Reply-To: <bcb23b30-b9a8-4421-aceb-626a110afaf7@email.android.com>
References: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>
	<bcb23b30-b9a8-4421-aceb-626a110afaf7@email.android.com>
Message-ID: <20140715222425.Horde.je-zxgxwBkgveOQZsoq3Yw1@webmail.rennes.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/37db0b18/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 16 01:27:28 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Jul 2014 16:27:28 -0700
Subject: [R] Error with named definition argument to match.call
Message-ID: <8C057331-4AFB-442D-B380-8E355235C193@comcast.net>

The help page says:

"Calling match.call outside a function without specifying definition  
is an error."

And yet when I send a function with a 'definition' argument it errors:

 > g
function(x, y=NULL, z=NULL) invisible(NULL)
 > match.call(definition=g)
Error in match.call(definition, call, expand.dots) :
   unused argument(s) (definition = g)

I wondered if this had something to do with primitive functions and  
their ignoring names but:

 > is.primitive(match.call)
[1] FALSE

Calling with an unnamed first argument succeeds:

 > match.call(g )
match.call(x = g)
-- 

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Jul 16 01:51:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Jul 2014 16:51:57 -0700
Subject: [R] Mac OSX Mavericks 10.9.3 Big Problem - New User
In-Reply-To: <CADCHy17JymKQRdTxGnMUW8X+FGcjr_Fhk6BoSJg_LPqXk5okTA@mail.gmail.com>
References: <CADCHy177j1OZfuMgjcnUfJrsOpZP5D-fr8CLih9AS08LeQ12EA@mail.gmail.com>
	<53699cef-9483-4b50-9ad5-9cd327e85918@email.android.com>
	<CADCHy17JymKQRdTxGnMUW8X+FGcjr_Fhk6BoSJg_LPqXk5okTA@mail.gmail.com>
Message-ID: <21AFBAEC-3A9E-4C95-B3AD-273732E486DF@comcast.net>


On Jul 14, 2014, at 10:37 PM, Ryan Dallavia wrote:

> Thanks for your reply Jeff!
>
> install.packages('Lahman') was the first command typed and generated  
> the
> error leading to the var directory. Here's everything else that I've  
> got,
> per one of the how to ask a good question post.

There are binaries for pkg:Lahman at CRAN for both the SL and  
Mavericks versions of R for MacOS.

http://cran.r-project.org/web/packages/Lahman/index.html

We don't know what your default repository is. This is what I use:

 > getOption("repos")
                        CRAN
"http://cran.stat.ucla.edu"

>
>
> dput(Lahman)

Generally that would not be informative. The package is not an object  
in the workspace.


> Error in dput(Lahman) : object 'Lahman' not found

Your original error message suggested an error in spelling:

>>> Error: could not find function "intall.packages"


>
> I also ran the following . . .
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
>
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1

So this says that pkg:Lahman is not loaded at that time.


>
>
> I had been storing R commands, but now that I can't run any  
> meaningful commands
> related to my data, nothing is being stored at the moment.

Not sure what "storing R commands" means or what "can't run any  
meaning commands related to my data might mean either". You are not  
showing either code or error messages relating to this activity.


The message you got suggests that you _did_ install a package (perhaps  
SoDA?) in your .../User/Computer/Library/R/3.1/library/ directory. You  
can use this command to get a list of installed packages:

installed.packages()

For me that list is rather long (and is therefore omitted) but I  
suspect from your difficulties that you do not have very many  
contributed packages installed yet.

>
> Let me know if I need to provide anything else. Thanks for the input!

Less vague description. More code and error messages. This may or may  
not be a MacOS problem. It sould as though it is a problem with basic  
R commands to me. If it really is a MacOS installation problem, then  
this is the wrong mailing list.

PLEASE, stop sending HTML mail. This is a plain text mailing list.

-- 
David

>
> Cheers,
> RCD
>
>
> On Tue, Jul 15, 2014 at 12:13 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
> >
> wrote:
>
>> Providing error messages without the inputs that provoked them  
>> leaves us
>> with only half a conversation to interpret. (For instance, what is  
>> with the
>> misspelling error?) It is also helpful when they are provided in the
>> sequence that they happened.
>>
>> I am going to make a wild guess that you loaded your previous  
>> variables,
>> perhaps automatically from the .RData file, but you don't remember  
>> which
>> packages to load to work with them. You only use the install.packages
>> function to get them into the R "library" directories (typically from
>> CRAN). You use the "library" or "require" functions to pull them into
>> memory each time you restart R to do some analysis. Usually it is  
>> best to
>> store the sequence of R statements that do your analysis in a .R  
>> file. You
>> can then just run all the commands in that file later when you have
>> forgotten how you did your analysis the first time.
>>
>> The fact that loading your variables from the .RData file does not  
>> also
>> reload the packages you need to do your analysis is a pain. I  
>> prefer to not
>> use RData files at all since the R file can both load those needed  
>> packages
>> and remind me how the analysis was done.
>>
>> You should read about how to ask clear questions, such as at [1],  
>> and read
>> the Posting Guide mentioned at the bottom of this email which  
>> points out
>> that you should post in plain text or we might not see what you see.
>>
>> [1]
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go  
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..   
>> Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.   
>> rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On July 14, 2014 6:38:53 PM PDT, Ryan Dallavia <rcdall at gmail.com>  
>> wrote:
>>> Hello,
>>>
>>> I am new to this program. I initially installed both R and R  
>>> Studio 3
>>> months ago, easily and got a d-base icon from the package I  
>>> needed, and
>>> saw
>>> my tables in spreadsheet form in studio. Now, everything has
>>> disappeared on
>>> its own -seriously nothing changed.  When trying to get my package
>>> back, I
>>> get this:
>>>
>>> Error: could not find function "intall.packages"
>>> Installing package into ???/Users/Computer/Library/R/3.1/ 
>>> library???
>>> (as ???lib??? is unspecified)
>>> trying URL '
>>>
>> http://ftp.ussg.iu.edu/CRAN/bin/macosx/mavericks/contrib/3.1/SoDA_1.0-6.tgz
>> '
>>> Content type 'application/x-gzip' length 255365 bytes (249 Kb)
>>> opened URL
>>> ==================================================
>>> downloaded 249 Kb
>>> The downloaded binary packages are in
>>>
>>
>>> /var/folders/bd/7z7gw4w953sd0tmgsrhdqw680000gn/T//RtmpTAMQLx/ 
>>> downloaded_packages
>>>
>>> var is a private directory. Though I can pull individual tables from
>>> the
>>> package (Lahman), they are now unlinked. SQL and stat commands are
>>> rejected
>>> by R and Studio. I tried about 2 dozen methods of changing the
>>> directory,
>>> specifying .lib and libPaths, (at least the ones online I  
>>> understood),
>>> and
>>> nothing worked, I moved the package (Lahman) to an R directory,  
>>> but I
>>> did
>>> not see it, and there seems to be no way to turn it back into a  
>>> working
>>> d-base in the working dir complete with icon suggesting it is locked
>>> and
>>> loaded. I have tried clean installs of everything, yet R-Studio  
>>> seems
>>> to
>>> remember what I did last (I don't know how). I need this back the  
>>> way
>>> it
>>> was: a functioning d-base from Lahman package in R-Studio and R.
>>> Suggestions seriously needed. It seems unfixable, and the "var'  
>>> problem
>>> seems very rare. Thanks for reading this.
>>>
>>> Cheers,
>>> RCD
>>>
>>>      [[alternative HTML version deleted]]

>>
>>
>
> 	[[alternative HTML version deleted]]
>


David Winsemius, MD
Alameda, CA, USA


From wdunlap at tibco.com  Wed Jul 16 02:04:20 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 15 Jul 2014 17:04:20 -0700
Subject: [R] Error with named definition argument to match.call
In-Reply-To: <8C057331-4AFB-442D-B380-8E355235C193@comcast.net>
References: <8C057331-4AFB-442D-B380-8E355235C193@comcast.net>
Message-ID: <CAF8bMcZ+WcX0jTcttM-VoQS76daQ0MUyx0nOW-NmTeQ9DuF_6Q@mail.gmail.com>

Does it make sense to call match.call outside of a function without
specifying both the function definition and the call to the function?
I agree that the error message is misleading.  Also, the return value
when call is not supplied does not seem useful, although it is
possible that it is correct in some technical sense.

> match.call(definition=function(FirstArg, SecondArg)NULL, quote(anyFuncName(S=2, 1)))
anyFuncName(FirstArg = 1, SecondArg = 2)
> match.call(function(FirstArg, SecondArg)NULL, quote(anyFuncName(S=2, 1)))
anyFuncName(FirstArg = 1, SecondArg = 2)
> # without supplying 'call':
> match.call(definition=function(FirstArg, SecondArg)NULL)
Error in match.call(definition, call, expand.dots) :
  unused argument (definition = function(FirstArg, SecondArg) NULL)
> match.call(function(FirstArg, SecondArg)NULL)
match.call(FirstArg = function(FirstArg, SecondArg) NULL)







Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jul 15, 2014 at 4:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> The help page says:
>
> "Calling match.call outside a function without specifying definition is an
> error."
>
> And yet when I send a function with a 'definition' argument it errors:
>
>> g
> function(x, y=NULL, z=NULL) invisible(NULL)
>> match.call(definition=g)
> Error in match.call(definition, call, expand.dots) :
>   unused argument(s) (definition = g)
>
> I wondered if this had something to do with primitive functions and their
> ignoring names but:
>
>> is.primitive(match.call)
> [1] FALSE
>
> Calling with an unnamed first argument succeeds:
>
>> match.call(g )
> match.call(x = g)
> --
>
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul 16 02:19:40 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Jul 2014 17:19:40 -0700
Subject: [R] Error with named definition argument to match.call
In-Reply-To: <CAF8bMcZ+WcX0jTcttM-VoQS76daQ0MUyx0nOW-NmTeQ9DuF_6Q@mail.gmail.com>
References: <8C057331-4AFB-442D-B380-8E355235C193@comcast.net>
	<CAF8bMcZ+WcX0jTcttM-VoQS76daQ0MUyx0nOW-NmTeQ9DuF_6Q@mail.gmail.com>
Message-ID: <7D98461C-396E-41F2-8652-D77744CF1D80@comcast.net>


On Jul 15, 2014, at 5:04 PM, William Dunlap wrote:

> Does it make sense to call match.call outside of a function without
> specifying both the function definition and the call to the function?

My puzzlement came from the different response to these two commands:

match.call(g)
match.call(definition=g)

I thought they would be the same. So you are saying to make sense this  
would need to be

 > match.call(definition=g , call=quote(g(1)) )
g(x = 1)



-- 
David.

> I agree that the error message is misleading.  Also, the return value
> when call is not supplied does not seem useful, although it is
> possible that it is correct in some technical sense.
>
>> match.call(definition=function(FirstArg, SecondArg)NULL,  
>> quote(anyFuncName(S=2, 1)))
> anyFuncName(FirstArg = 1, SecondArg = 2)
>> match.call(function(FirstArg, SecondArg)NULL,  
>> quote(anyFuncName(S=2, 1)))
> anyFuncName(FirstArg = 1, SecondArg = 2)
>> # without supplying 'call':
>> match.call(definition=function(FirstArg, SecondArg)NULL)
> Error in match.call(definition, call, expand.dots) :
>  unused argument (definition = function(FirstArg, SecondArg) NULL)
>> match.call(function(FirstArg, SecondArg)NULL)
> match.call(FirstArg = function(FirstArg, SecondArg) NULL)
>
>
>
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Jul 15, 2014 at 4:27 PM, David Winsemius <dwinsemius at comcast.net 
> > wrote:
>> The help page says:
>>
>> "Calling match.call outside a function without specifying  
>> definition is an
>> error."
>>
>> And yet when I send a function with a 'definition' argument it  
>> errors:
>>
>>> g
>> function(x, y=NULL, z=NULL) invisible(NULL)
>>> match.call(definition=g)
>> Error in match.call(definition, call, expand.dots) :
>>  unused argument(s) (definition = g)
>>
>> I wondered if this had something to do with primitive functions and  
>> their
>> ignoring names but:
>>
>>> is.primitive(match.call)
>> [1] FALSE
>>
>> Calling with an unnamed first argument succeeds:
>>
>>> match.call(g )
>> match.call(x = g)
>> --
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From wdunlap at tibco.com  Wed Jul 16 02:38:46 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 15 Jul 2014 17:38:46 -0700
Subject: [R] Error with named definition argument to match.call
In-Reply-To: <7D98461C-396E-41F2-8652-D77744CF1D80@comcast.net>
References: <8C057331-4AFB-442D-B380-8E355235C193@comcast.net>
	<CAF8bMcZ+WcX0jTcttM-VoQS76daQ0MUyx0nOW-NmTeQ9DuF_6Q@mail.gmail.com>
	<7D98461C-396E-41F2-8652-D77744CF1D80@comcast.net>
Message-ID: <CAF8bMcb00KSae1-Oo1NVR2nx_Wq2WhpJ+QWoLw--J2_-pOrcdA@mail.gmail.com>

> So you are saying to make sense this would need to be
>
> > match.call(definition=g , call=quote(g(1)) )
> g(x = 1)

Yes.  What would you expect to get from match.call() outside of a
function if you don't give it a call argument?  It uses the default value
for 'call', sys.call(sys.parent()), but sys.parent() gives 0 at the
top level, the
same as when it is called from a function called from the top level, so the
default value of call is not useful when match.call is called from the
top level.
.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jul 15, 2014 at 5:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 15, 2014, at 5:04 PM, William Dunlap wrote:
>
>> Does it make sense to call match.call outside of a function without
>> specifying both the function definition and the call to the function?
>
>
> My puzzlement came from the different response to these two commands:
>
> match.call(g)
> match.call(definition=g)
>
> I thought they would be the same. So you are saying to make sense this would
> need to be
>
>> match.call(definition=g , call=quote(g(1)) )
> g(x = 1)
>
>
>
> --
> David.
>
>
>> I agree that the error message is misleading.  Also, the return value
>> when call is not supplied does not seem useful, although it is
>> possible that it is correct in some technical sense.
>>
>>> match.call(definition=function(FirstArg, SecondArg)NULL,
>>> quote(anyFuncName(S=2, 1)))
>>
>> anyFuncName(FirstArg = 1, SecondArg = 2)
>>>
>>> match.call(function(FirstArg, SecondArg)NULL, quote(anyFuncName(S=2, 1)))
>>
>> anyFuncName(FirstArg = 1, SecondArg = 2)
>>>
>>> # without supplying 'call':
>>> match.call(definition=function(FirstArg, SecondArg)NULL)
>>
>> Error in match.call(definition, call, expand.dots) :
>>  unused argument (definition = function(FirstArg, SecondArg) NULL)
>>>
>>> match.call(function(FirstArg, SecondArg)NULL)
>>
>> match.call(FirstArg = function(FirstArg, SecondArg) NULL)
>>
>>
>>
>>
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Jul 15, 2014 at 4:27 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>>
>>> The help page says:
>>>
>>> "Calling match.call outside a function without specifying definition is
>>> an
>>> error."
>>>
>>> And yet when I send a function with a 'definition' argument it errors:
>>>
>>>> g
>>>
>>> function(x, y=NULL, z=NULL) invisible(NULL)
>>>>
>>>> match.call(definition=g)
>>>
>>> Error in match.call(definition, call, expand.dots) :
>>>  unused argument(s) (definition = g)
>>>
>>> I wondered if this had something to do with primitive functions and their
>>> ignoring names but:
>>>
>>>> is.primitive(match.call)
>>>
>>> [1] FALSE
>>>
>>> Calling with an unnamed first argument succeeds:
>>>
>>>> match.call(g )
>>>
>>> match.call(x = g)
>>> --
>>>
>>> David Winsemius, MD
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> David Winsemius, MD
> Alameda, CA, USA
>


From jdnewmil at dcn.davis.CA.us  Wed Jul 16 04:06:26 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Jul 2014 19:06:26 -0700
Subject: [R] request of information about creating DLL from R to be used
	in other languages/programs
In-Reply-To: <20140715222425.Horde.je-zxgxwBkgveOQZsoq3Yw1@webmail.rennes.inra.fr>
References: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>
	<bcb23b30-b9a8-4421-aceb-626a110afaf7@email.android.com>
	<20140715222425.Horde.je-zxgxwBkgveOQZsoq3Yw1@webmail.rennes.inra.fr>
Message-ID: <2c80d638-c4a1-4cc1-9d1d-1956b443eacf@email.android.com>

You want algorithms compiled into a dll... I am satisfied with R in its current form, so I am not a particularly good guide for you. If you wish to continue with the wrapping-R approach then you should read the Writing R Extensions document that comes with R, and study R-devel mailing list instead of this one. You should also carefully review the licensing terms for R and the contributed packages you wish to work with to avoid surprises later. (Open source software is not a free pass to get algorithm implementations to use for just anything you like... they come with some responsibilities too.)
Alternatively you could re-implement the algorithms (in the compiled language of your choice) from any original publications referenced in the R/packages documentation and proceed with your programming as you see fit.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 15, 2014 1:24:25 PM PDT, "Ludovic.Brossard" <ludovic.brossard at rennes.inra.fr> wrote:
>  Thanks for the answer.
>If it is possible, could you indicate me how to proceed? or what would
>be
>the best alternative?
>Regard
>Ludovic Brossard
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit?:
>
>> Possible, but almost certainly not worth it. R is an interpreted
>> language, and the dll would have to encapsulate the whole shebang.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? ?.....? ?
>? ?.....? Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ?##.#.?
>Live
>> Go...
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Live:? ?OO#..
>Dead: OO#..? Playing
>> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ?
>?#.O#.? with
>> /Software/Embedded Controllers)? ? ? ? ? ? ? ?.OO#.? ? ?
>?.OO#.?
>> rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On July 15, 2014 8:35:38 AM PDT, Ludovic Brossard
>> <Ludovic.Brossard at rennes.inra.fr> wrote:
>>> Hello
>>>
>>> My question is the following. I have tried to find a similar subject
>in
>>> archives but not found (perhaps bad search!).
>>>
>>> One of my colleague wrote a R code combining some R functions to
>create
>>> a
>>> method of calculation.
>>>
>>> I would want to use this in a program coded in Delphi.
>>>
>>> Is there possibilities to create a DLL from R code to be called in
>the
>>> Delphi program ?
>>>
>>> It would allow us to avoid rewriting code and searching
>correspondence
>>> between R functions and Delphi program (or other types of tools as
>>> TPMath).
>>>
>>> I hope to be clear in my demand an I hope you will be able to give
>me
>>> some
>>> indications or where to find it.
>>>
>>> Best regards
>>>
>>> Ludovic Brossard
>>>
>>> Ludovic BROSSARD
>>>
>>> UMR PEGASE (Physiologie, Environnement et G?n?tique pour l?Animal
>et
>>> les
>>> Syst?mes d?Elevage)
>>>
>>> INRA ? Agrocampus Ouest
>>>
>>> Domaine de la Prise, 35590 Saint-Gilles, France
>>>
>>> T?l : 33 (0)2 23 48 70 57 . Fax : 33(0)2 23 48 50 80
>>>
>>> <http://www.rennes.inra.fr/pegase> www.rennes.inra.fr/pegase[1].
>>>
>>> ? ? ? ? [[alternative HTML version deleted]]
>>>
>>>
>------------------------------------------------------------------------
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.htmland provide commented,
>>> minimal, self-contained, reproducible code.
>>
>> ?
>
>
>
>Liens:
>------
>[1] http://www.rennes.inra.fr/pegase
>Ludovic Brossard
>INRA - UMR PEGASE
>Domaine de la Prise
>35590 SAINT GILLES
>tel : 02 23 48 70 57
>fax : 02 23 48 50 80


From musketeere at gmail.com  Tue Jul 15 20:46:39 2014
From: musketeere at gmail.com (Electron Musketeer)
Date: Tue, 15 Jul 2014 19:46:39 +0100
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
	<CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
Message-ID: <CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140715/00c1857b/attachment.pl>

From Ludovic.Brossard at rennes.inra.fr  Wed Jul 16 08:58:35 2014
From: Ludovic.Brossard at rennes.inra.fr (Ludovic Brossard)
Date: Wed, 16 Jul 2014 08:58:35 +0200
Subject: [R] request of information about creating DLL from R to be used
	in other languages/programs
In-Reply-To: <2c80d638-c4a1-4cc1-9d1d-1956b443eacf@email.android.com>
References: <005401cfa042$6dc7a580$4956f080$@rennes.inra.fr>
	<bcb23b30-b9a8-4421-aceb-626a110afaf7@email.android.com>
	<20140715222425.Horde.je-zxgxwBkgveOQZsoq3Yw1@webmail.rennes.inra.fr>
	<2c80d638-c4a1-4cc1-9d1d-1956b443eacf@email.android.com>
Message-ID: <000301cfa0c3$5d3c6620$17b53260$@rennes.inra.fr>

Thanks for all these indications

Regards

Ludovic Brossard

-----Message d'origine-----
De : Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Envoy? : mercredi 16 juillet 2014 04:06
? : Ludovic.Brossard
Cc : Ludovic Brossard; r-help at r-project.org
Objet : Re: [R] request of information about creating DLL from R to be used in other languages/programs

You want algorithms compiled into a dll... I am satisfied with R in its current form, so I am not a particularly good guide for you. If you wish to continue with the wrapping-R approach then you should read the Writing R Extensions document that comes with R, and study R-devel mailing list instead of this one. You should also carefully review the licensing terms for R and the contributed packages you wish to work with to avoid surprises later. (Open source software is not a free pass to get algorithm implementations to use for just anything you like... they come with some responsibilities too.) Alternatively you could re-implement the algorithms (in the compiled language of your choice) from any original publications referenced in the R/packages documentation and proceed with your programming as you see fit.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On July 15, 2014 1:24:25 PM PDT, "Ludovic.Brossard" <ludovic.brossard at rennes.inra.fr> wrote:
>  Thanks for the answer.
>If it is possible, could you indicate me how to proceed? or what would 
>be the best alternative?
>Regard
>Ludovic Brossard
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit :
>
>> Possible, but almost certainly not worth it. R is an interpreted 
>> language, and the dll would have to encapsulate the whole shebang.
>>
>-----------------------------------------------------------------------
>----
>> Jeff Newmiller                        The     .....
>   .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>Live
>> Go...
>>                                      Live:   OO#..
>Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.
> #.O#.  with
>> /Software/Embedded Controllers)               .OO#.
> .OO#.
>> rocks...1k
>>
>-----------------------------------------------------------------------
>----
>> Sent from my phone. Please excuse my brevity.
>>
>> On July 15, 2014 8:35:38 AM PDT, Ludovic Brossard 
>> <Ludovic.Brossard at rennes.inra.fr> wrote:
>>> Hello
>>>
>>> My question is the following. I have tried to find a similar subject
>in
>>> archives but not found (perhaps bad search!).
>>>
>>> One of my colleague wrote a R code combining some R functions to
>create
>>> a
>>> method of calculation.
>>>
>>> I would want to use this in a program coded in Delphi.
>>>
>>> Is there possibilities to create a DLL from R code to be called in
>the
>>> Delphi program ?
>>>
>>> It would allow us to avoid rewriting code and searching
>correspondence
>>> between R functions and Delphi program (or other types of tools as 
>>> TPMath).
>>>
>>> I hope to be clear in my demand an I hope you will be able to give
>me
>>> some
>>> indications or where to find it.
>>>
>>> Best regards
>>>
>>> Ludovic Brossard
>>>
>>> Ludovic BROSSARD
>>>
>>> UMR PEGASE (Physiologie, Environnement et G n tique pour l Animal
>et
>>> les
>>> Syst mes d Elevage)
>>>
>>> INRA   Agrocampus Ouest
>>>
>>> Domaine de la Prise, 35590 Saint-Gilles, France
>>>
>>> T l : 33 (0)2 23 48 70 57 . Fax : 33(0)2 23 48 50 80
>>>
>>> <http://www.rennes.inra.fr/pegase> www.rennes.inra.fr/pegase[1].
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>-----------------------------------------------------------------------
>-
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.htmland provide commented, 
>>> minimal, self-contained, reproducible code.
>>
>>  
>
>
>
>Liens:
>------
>[1] http://www.rennes.inra.fr/pegase
>Ludovic Brossard
>INRA - UMR PEGASE
>Domaine de la Prise
>35590 SAINT GILLES
>tel : 02 23 48 70 57
>fax : 02 23 48 50 80


From info at aghmed.fsnet.co.uk  Wed Jul 16 10:53:09 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 16 Jul 2014 09:53:09 +0100
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.g
	mail.com>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
	<CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.gmail.com>
Message-ID: <Zen-1X7Kxh-000G9u-6u@smarthost01c.mail.zen.net.uk>

At 23:19 14/07/2014, Megan Bartlett wrote:
>Thanks very much, Wolfgang and Michael! I feel like I understand rma much
>more clearly.
>
>But just to make sure, is there any way to do this kind of analysis for a
>continuous predictor variable?

Yes, just put it in as a moderator.

I am not sure I fully understand the rest of your question but the 
answer may be that the weights are a property of the individual effect sizes

>For each site level, I have a value for a
>climate variable, and it would be great to see whether the average effect
>size for each site is correlated with that climate variable. But I'm not
>sure what variance would produce the appropriate weighting for each
>site-level average- would it be the variance in effect sizes across species
>within each site? Or does this analysis not really make any sense for
>effect sizes?
>
>Thanks again!
>
>Best,
>
>Megan
>
>
>On Mon, Jul 14, 2014 at 6:06 AM, Viechtbauer Wolfgang (STAT) <
>wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
> > Somehow that initial post slipped under the radar for me ...
> >
> > Yes, I would give the same suggestion as Michael. Besides random effects
> > for 'site', I would also suggest to add random effects for each estimates
> > (as in a regular random-effects model). So, if you have an 'id' variable
> > that is unique to each observed d-value, you would use:
> >
> > random = list(~ 1 | site, ~ 1 | id)
> >
> > with the rma.mv() function. This is in essence the model given by
> > equation (6) in:
> >
> > Nakagawa, S., & Santos, E. S. A. (2012). Methodological issues and
> > advances in biological meta-analysis. Evolutionary Ecology, 26(5),
> > 1253-1274.
> >
> > (at the time of publication, this model could not be fitted with metafor,
> > but it can now). Same model is described with a bit more detail in:
> >
> > Konstantopoulos, S. (2011). Fixed effects and variance components
> > estimation in three-level meta-analysis. Research Synthesis Methods, 2(1),
> > 61-76.
> >
> > Best,
> > Wolfgang
> >
> > --
> > Wolfgang Viechtbauer, Ph.D., Statistician
> > Department of Psychiatry and Psychology
> > School for Mental Health and Neuroscience
> > Faculty of Health, Medicine, and Life Sciences
> > Maastricht University, P.O. Box 616 (VIJV1)
> > 6200 MD Maastricht, The Netherlands
> > +31 (43) 388-4170 | http://www.wvbauer.com
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> > > On Behalf Of Michael Dewey
> > > Sent: Monday, July 14, 2014 14:42
> > > To: Megan Bartlett; r-help at r-project.org
> > > Subject: Re: [R] Correlating multiple effect sizes within a study to
> > > study-level predictors: metafor package
> > >
> > > At 23:18 11/07/2014, Megan Bartlett wrote:
> > > >Hi everyone,
> > > >
> > > >Since metafor doesn't have its own list, I hope this is the correct
> > > place
> > > >for this posting- my apologies if there is a more appropriate list.
> > >
> > > metafor questions welcome here, Megan
> > >
> > > Wolfgang seems to be off-list so while we wait for the definitive
> > > answer here are some hints.
> > >
> > >
> > > >I'm conducting a meta-analysis where I would like to determine the
> > > >correlation between plasticity in leaf traits and climate. I'm
> > > calculating
> > > >effect sizes as Hedge's d. My data is structured so that each study
> > > >collected data from one forest site, so there is one set of climate
> > > >variable values for that study, and there are one or more species in
> > > each
> > > >study, so all the species in a study have the same values for the
> > > climate
> > > >variables. I'm not sure how to account for this structure in modeling
> > > the
> > > >relationship between plasticity and climate.
> > >
> > > I think you need rma.mv for your situation and you need to specify a
> > > random effect for site.
> > >
> > > Try going
> > > ?rma.mv
> > > and looking for the section entitled Specifying random effects
> > >   You will need to set up your dataframe with one row per species and
> > > an indicator variable for site and then use
> > > random = ~ 1 | site
> > >
> > > Not tested obviously and Wolfgang may have other suggestions
> > >
> > > >My first thought was to calculate mean effect size and variance across
> > > >species for every study with multiple species and correlate that    with
> > > >the climate variable values for those study with the rma() function, but
> > > >trying to do that returns an error message:
> > > >
> > > >rma(yi = EffectSize, vi = Var, data = sitestable, mod = Precip)
> > > >returns: Error in wi * (yi - X %*% b)^2 : non-conformable arrays
> > > >
> > > >This leaves me with two questions: 1) Am I even accounting for the data
> > > >structure correctly with this approach, and 2) am I fundamentally
> > > >misunderstanding how to use metafor to do so?
> > > >
> > > >Thanks very much for your help!
> > > >
> > > >Best,
> > > >
> > > >Megan
> >
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From highstat at highstat.com  Wed Jul 16 12:04:16 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 16 Jul 2014 11:04:16 +0100
Subject: [R] New book: Beginner's Guide to GAMM with R
Message-ID: <53C64E20.5050200@highstat.com>


We are please to announce the following book:

Title: Beginner's Guide to GAMM with R.
Authors: Zuur, Saveliev, Ieno


Book website: http://www.highstat.com/BGGAMM.htm
Paperback, hardcover or EBook can be order (exclusively) from: 
http://www.highstat.com/bookorder.htm
Table of Contents: http://www.highstat.com/BGS/GAMM/TOC_7_12.pdf

Keywords:
In this book we take the reader on an exciting voyage into the world of 
generalised additive mixed effects models (GAMM). Keywords are GAM, 
mgcv, gamm4, random effects, Poisson and negative binomial GAMM, gamma 
GAMM, binomial GAMM, negative binomial-P models, GAMMs with generalised 
extreme value distributions, overdispersion, underdispersion, 
two-dimensional smoothers, zero-inflated GAMMs, spatial correlation, 
INLA, Markov chain Monte Carlo techniques, JAGS, and two-way nested 
GAMMs. The book includes three chapters on the analysis of zero-inflated 
data.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From Mark.Fowler at dfo-mpo.gc.ca  Wed Jul 16 13:50:45 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Wed, 16 Jul 2014 08:50:45 -0300
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <1875188.O42FXxQtEb@localhost.localdomain>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
	<1875188.O42FXxQtEb@localhost.localdomain>
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F806921166@marbioexc02.mar.dfo-mpo.ca>

Hi Jim,
Lost the address (Tuesday night is a major system scan for DFO, messes
everybody up). Tried your suggestion, no luck. Also tried shutting down
all Explorer browsers, still no luck. Maybe something related to
configuration or environment differs between our systems.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Jim Lemon
Sent: July 15, 2014 12:17 AM
To: r-help at r-project.org
Subject: Re: [R] two questions - function help and 32vs64 bit sessions

On Mon, 14 Jul 2014 01:42:54 PM Fowler, Mark wrote:
> Hello,
> 
> 
> 
> Two unrelated questions, and neither urgent.
> 
> 
> 
> Windows 7, R 3.0.1. Using R Console, no fancy interface.
> 
> 
> 
> The function help ultimately becomes lost to a session kept running
for
> extended periods (days). I.e. with a new session if you invoke the 
> Help menu 'R functions (txt)...' it activates the html help and goes 
> to the named function page. This will work fine for at least a day, 
> but typically the next day invoking the help menu in this fashion will

> fail, as R looks for a temporary address it creates on your computer. 
> This gets lost, possibly due to network administration activity. So 
> then I save and start another session with same Rdata. Trivial enough 
> but irritating. Anybody know how to restore the 'link' without ending 
> and restarting the session?

Hi Mark,
I simply shut down the help browser. It will restart with a new IP
address.

Jim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Scott.Williams at petermac.org  Wed Jul 16 15:07:44 2014
From: Scott.Williams at petermac.org (Williams Scott)
Date: Wed, 16 Jul 2014 13:07:44 +0000
Subject: [R] how to subset based on other row values and multiplicity
Message-ID: <CFECB67F.1EF38%scott.williams@petermac.org>

Hi R experts,
 
I have a dataset as sampled below. Values are only regarded as ?confirmed?
in an individual (?id?) if they occur
more than once at least 30 days apart.

 
id   date value
a    2000-01-01 x
a    2000-03-01 x
b    2000-11-11 w
c    2000-11-11 y
c    2000-10-01 y
c    2000-09-10 y
c    2000-12-12 z
c    2000-10-11 z
d    2000-11-11 w
d    2000-11-10 w

 
I wish to subset the data to retain rows where the value for the
individual is confirmed more than 30 days apart. So, after deleting all
rows with just one occurrence of id and value, the rest would be the
earliest occurrence of each value in each case id, provided 31 or more
days exist between the dates. If >1 value is present per id, each value
level needs to be assessed independently. This example would then reduce
to:

 
id   date           value
a    2000-01-01 x
c    2000-09-10 y
c    2000-10-11 z

 
 
I can do this via some crude loops and subsetting, but I am looking for as
much efficiency as possible
as the dataset has around 50 million rows to assess. Any suggestions
welcomed.

Thanks in advance
 
Scott Williams MD
Melbourne, Australia



This email (including any attachments or links) may contain 
confidential and/or legally privileged information and is 
intended only to be read or used by the addressee.  If you 
are not the intended addressee, any use, distribution, 
disclosure or copying of this email is strictly 
prohibited.  
Confidentiality and legal privilege attached to this email 
(including any attachments) are not waived or lost by 
reason of its mistaken delivery to you.
If you have received this email in error, please delete it 
and notify us immediately by telephone or email.  Peter 
MacCallum Cancer Centre provides no guarantee that this 
transmission is free of virus or that it has not been 
intercepted or altered and will not be liable for any delay 
in its receipt.

From john.archie.mckown at gmail.com  Wed Jul 16 15:25:42 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 16 Jul 2014 08:25:42 -0500
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CFECB67F.1EF38%scott.williams@petermac.org>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
Message-ID: <CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>

On Wed, Jul 16, 2014 at 8:07 AM, Williams Scott
<Scott.Williams at petermac.org> wrote:
> Hi R experts,
>
> I have a dataset as sampled below. Values are only regarded as ?confirmed?
> in an individual (?id?) if they occur
> more than once at least 30 days apart.
>
>
> id   date value
> a    2000-01-01 x
> a    2000-03-01 x
> b    2000-11-11 w
> c    2000-11-11 y
> c    2000-10-01 y
> c    2000-09-10 y
> c    2000-12-12 z
> c    2000-10-11 z
> d    2000-11-11 w
> d    2000-11-10 w
>
>
> I wish to subset the data to retain rows where the value for the
> individual is confirmed more than 30 days apart. So, after deleting all
> rows with just one occurrence of id and value, the rest would be the
> earliest occurrence of each value in each case id, provided 31 or more
> days exist between the dates. If >1 value is present per id, each value
> level needs to be assessed independently. This example would then reduce
> to:
>
>
> id   date           value
> a    2000-01-01 x
> c    2000-09-10 y
> c    2000-10-11 z

Question: the c-y id-value pair occurs 3 times. In two cases
(2000-11-11 vs. 2000-10-01 & 2000-11-11 vs 2000-09-01) the difference
is >30 days. Why isn't
c 2000-10-01 y
also part of the result? Is it because you only want a single id-value
pair in which the date is the minimal? Or you want the one in which
the date difference is maximal? Or you overlooked that particular
match? I can't figure it out from your description.

>
>
>
> I can do this via some crude loops and subsetting, but I am looking for as
> much efficiency as possible
> as the dataset has around 50 million rows to assess. Any suggestions
> welcomed.

Hum, is the source of this data in a relational database such as
Oracle, PostgreSQL, MySQL, MS-SQL, or SQLite (or "other")? I ask
because some of this processing might be easier do to in the data base
using a "self join", instead of reading the entire relational table
into a data.frame and doing it in R.

>
> Thanks in advance
>
> Scott Williams MD
> Melbourne, Australia
>

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From murdoch.duncan at gmail.com  Wed Jul 16 15:47:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Jul 2014 08:47:04 -0500
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
Message-ID: <53C68258.7050208@gmail.com>

On 14/07/2014, 11:42 AM, Fowler, Mark wrote:
> Hello,
> 
>  
> 
> Two unrelated questions, and neither urgent.
> 
>  
> 
> Windows 7, R 3.0.1. Using R Console, no fancy interface.
> 
>  
> 
> The function help ultimately becomes lost to a session kept running for
> extended periods (days). I.e. with a new session if you invoke the Help
> menu 'R functions (txt)...' it activates the html help and goes to the
> named function page. This will work fine for at least a day, but
> typically the next day invoking the help menu in this fashion will fail,
> as R looks for a temporary address it creates on your computer. This
> gets lost, possibly due to network administration activity. So then I
> save and start another session with same Rdata. Trivial enough but
> irritating. Anybody know how to restore the 'link' without ending and
> restarting the session?

I never have sessions that last that long, so I haven't tried this, but
I'd expect you could restart the help system in this way:

tools::startDynamicHelp(FALSE) # shut it down
tools::startDynamicHelp(TRUE)  # start it up

Duncan Murdoch

> 
>  
> 
> I have a mix of 32-bit and 64-bit requirements, with 64 the default. I
> became used to starting R sessions directly from the appropriate Rdata
> workspaces. With the latest version I need to start from the generic
> icon and then load the workspace if I want 32-bit. Anybody know a way to
> make the Rdata files keep track of which bit version they work with, or
> some trick that accomplishes the same objective? The 32-bit requirement
> is usually just RODBC, and the need for it is scattered over lots of
> workspaces. Again, trivial but a nuisance. A more pragmatic motive is to
> not oblige users of applications to think about it. Any way to make a
> session switch 'bits' with a source file?
> 
>  
> 
> Mark Fowler 
> Population Ecology Division 
> Bedford Inst of Oceanography 
> Dept Fisheries & Oceans 
> Dartmouth NS Canada 
> B2Y 4A2 
> Tel. (902) 426-3529 
> Fax (902) 426-9710 
> Email Mark.Fowler at dfo-mpo.gc.ca <mailto:Mark.Fowler at dfo-mpo.gc.ca>  
> 
> 
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From g.leask at aston.ac.uk  Wed Jul 16 15:51:14 2014
From: g.leask at aston.ac.uk (Leask, Graham)
Date: Wed, 16 Jul 2014 13:51:14 +0000
Subject: [R] Area Graphs
Message-ID: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>

Area graphs are a commonly used graphic in such software as Excel but I have been unable
to find any examples of their use using R.

Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
being directed to the relevant package or a code example.

Any help will be greatly appreciated

Graham

From jholtman at gmail.com  Wed Jul 16 15:51:20 2014
From: jholtman at gmail.com (jim holtman)
Date: Wed, 16 Jul 2014 09:51:20 -0400
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>
Message-ID: <CAAxdm-5CXGvPFAY8fXVxas+a1ZETT3d0oVa+iXMZ-1yd+W-YDQ@mail.gmail.com>

I can reproduce what you requested, but there was the question about
what happens with the multiple 'c-y' values.

====================

> require(data.table)
> x <- read.table(text = 'id   date value
+ a    2000-01-01 x
+ a    2000-03-01 x
+ b    2000-11-11 w
+ c    2000-11-11 y
+ c    2000-10-01 y
+ c    2000-09-10 y
+ c    2000-12-12 z
+ c    2000-10-11 z
+ d    2000-11-11 w
+ d    2000-11-10 w', as.is = TRUE, header = TRUE)
> setDT(x)
> x[, date := as.Date(date)]
> setkey(x, id, value, date)
>
> y <- x[
+     , {
+         if (.N == 1) val <- NULL  # only one -- delete
+         else {
+             dif <- difftime(tail(date, -1), head(date, -1), units = 'days')
+             # return first value if any > 31
+             if (any(dif >= 31)) val <- list(date = date[1L])
+             else val <- NULL
+         }
+         val
+       }
+     , keyby = 'id,value'
+     ]
> y
   id value       date
1:  a     x 2000-01-01
2:  c     y 2000-09-10
3:  c     z 2000-10-11

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Jul 16, 2014 at 9:25 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Wed, Jul 16, 2014 at 8:07 AM, Williams Scott
> <Scott.Williams at petermac.org> wrote:
>> Hi R experts,
>>
>> I have a dataset as sampled below. Values are only regarded as ?confirmed?
>> in an individual (?id?) if they occur
>> more than once at least 30 days apart.
>>
>>
>> id   date value
>> a    2000-01-01 x
>> a    2000-03-01 x
>> b    2000-11-11 w
>> c    2000-11-11 y
>> c    2000-10-01 y
>> c    2000-09-10 y
>> c    2000-12-12 z
>> c    2000-10-11 z
>> d    2000-11-11 w
>> d    2000-11-10 w
>>
>>
>> I wish to subset the data to retain rows where the value for the
>> individual is confirmed more than 30 days apart. So, after deleting all
>> rows with just one occurrence of id and value, the rest would be the
>> earliest occurrence of each value in each case id, provided 31 or more
>> days exist between the dates. If >1 value is present per id, each value
>> level needs to be assessed independently. This example would then reduce
>> to:
>>
>>
>> id   date           value
>> a    2000-01-01 x
>> c    2000-09-10 y
>> c    2000-10-11 z
>
> Question: the c-y id-value pair occurs 3 times. In two cases
> (2000-11-11 vs. 2000-10-01 & 2000-11-11 vs 2000-09-01) the difference
> is >30 days. Why isn't
> c 2000-10-01 y
> also part of the result? Is it because you only want a single id-value
> pair in which the date is the minimal? Or you want the one in which
> the date difference is maximal? Or you overlooked that particular
> match? I can't figure it out from your description.
>
>>
>>
>>
>> I can do this via some crude loops and subsetting, but I am looking for as
>> much efficiency as possible
>> as the dataset has around 50 million rows to assess. Any suggestions
>> welcomed.
>
> Hum, is the source of this data in a relational database such as
> Oracle, PostgreSQL, MySQL, MS-SQL, or SQLite (or "other")? I ask
> because some of this processing might be easier do to in the data base
> using a "self join", instead of reading the entire relational table
> into a data.frame and doing it in R.
>
>>
>> Thanks in advance
>>
>> Scott Williams MD
>> Melbourne, Australia
>>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Wed Jul 16 15:58:34 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 16 Jul 2014 09:58:34 -0400
Subject: [R] Area Graphs
In-Reply-To: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
Message-ID: <CAM_vjum7=QaJHjXs3WK5u8bsyfGsW8r1HAtsjhq7YukcMBndhQ@mail.gmail.com>

You mean like this?

http://stackoverflow.com/questions/10840314/stacked-area-graph-in-r
http://menugget.blogspot.com/2013/12/data-mountains-and-streams-stacked-area.html
http://stackoverflow.com/questions/22544571/create-stacked-area-graph-from-time-data

Or any of the many other results from a google search on

"area graph" r

Since you claim to be "unable to find" anything relevant, maybe you
mean something different? If so, you'll need to be clearer, and
ideally link to an example.

Sarah

On Wed, Jul 16, 2014 at 9:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
> Area graphs are a commonly used graphic in such software as Excel but I have been unable
> to find any examples of their use using R.
>
> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
> being directed to the relevant package or a code example.
>
> Any help will be greatly appreciated
>
> Graham

-- 
Sarah Goslee
http://www.functionaldiversity.org


From john.archie.mckown at gmail.com  Wed Jul 16 16:01:21 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 16 Jul 2014 09:01:21 -0500
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CFECBB4B.1EF3C%scott.williams@petermac.org>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>
	<CFECBB4B.1EF3C%scott.williams@petermac.org>
Message-ID: <CAAJSdjg0BBHMWme6vrL6WnMKyQAHYTCAvOmVsdwy2L-0AAmqEQ@mail.gmail.com>

Thanks. So you only want a single entry with a given "id" & "value",
even if there are multiple possible confirmations.

Too bad about not being in an SQL data base. I've already partially
solved the problem using PostgreSQL. Just in case you, or others,
might be interested, below is a transcript of what I have. The SQL
might suggest a possible approach in native R.

<transcript>
tsh009=# select * from datedata;
 id |    date    | value
----+------------+-------
 a  | 2000-01-01 | x
 a  | 2000-03-01 | x
 b  | 2000-11-11 | w
 c  | 2000-11-11 | y
 c  | 2000-10-01 | y
 c  | 2000-09-10 | y
 c  | 2000-12-12 | z
 c  | 2000-10-11 | z
 d  | 2000-11-11 | w
 d  | 2000-11-10 | w
(10 rows)

tsh009=# select a.id,a.date,a.value
from datedata as a
join datedata as b
on a.id = b.id and a.value=b.value
where b.date - a.date > 30;
 id |    date    | value
----+------------+-------
 a  | 2000-01-01 | x
 c  | 2000-10-01 | y
 c  | 2000-09-10 | y
 c  | 2000-10-11 | z
(4 rows)

</transcript>

the only problem is the "multiple confirmation" problem because you
only want / need a single c-y confirmation and my code produces all
possible ones.

On Wed, Jul 16, 2014 at 8:38 AM, Williams Scott
<Scott.Williams at petermac.org> wrote:
> It probably isn?t that clear John - to put it another way - each patient
> (?id?) can have multiple diagnosis codes (w -> z in this example, several
> thousand in reality) recorded at multiple times. I just need to find the
> ?confirmed? diagnosis code or codes for each patient. To be confirmed they
> have to occur at least twice and at least a month apart. So patient c has
> 2 diagnoses recorded, 1 recorded twice and one thrice; each confirmed by
> multiplicity and time.
>
> The data is delivered as a flat .txt file. I?m not proficient with any
> databases other than MS Access unfortunately, and the 120Gb of data is not
> easily managed in Access.
>
> I hope that helps
> S
>
> On 16/07/2014 11:25 pm, "John McKown" <john.archie.mckown at gmail.com> wrote:
>
>>On Wed, Jul 16, 2014 at 8:07 AM, Williams Scott
>><Scott.Williams at petermac.org> wrote:
>>> Hi R experts,
>>>
>>> I have a dataset as sampled below. Values are only regarded as
>>>?confirmed?
>>> in an individual (?id?) if they occur
>>> more than once at least 30 days apart.
>>>
>>>
>>> id   date value
>>> a    2000-01-01 x
>>> a    2000-03-01 x
>>> b    2000-11-11 w
>>> c    2000-11-11 y
>>> c    2000-10-01 y
>>> c    2000-09-10 y
>>> c    2000-12-12 z
>>> c    2000-10-11 z
>>> d    2000-11-11 w
>>> d    2000-11-10 w
>>>
>>>
>>> I wish to subset the data to retain rows where the value for the
>>> individual is confirmed more than 30 days apart. So, after deleting all
>>> rows with just one occurrence of id and value, the rest would be the
>>> earliest occurrence of each value in each case id, provided 31 or more
>>> days exist between the dates. If >1 value is present per id, each value
>>> level needs to be assessed independently. This example would then reduce
>>> to:
>>>
>>>
>>> id   date           value
>>> a    2000-01-01 x
>>> c    2000-09-10 y
>>> c    2000-10-11 z
>>
>>Question: the c-y id-value pair occurs 3 times. In two cases
>>(2000-11-11 vs. 2000-10-01 & 2000-11-11 vs 2000-09-01) the difference
>>is >30 days. Why isn't
>>c 2000-10-01 y
>>also part of the result? Is it because you only want a single id-value
>>pair in which the date is the minimal? Or you want the one in which
>>the date difference is maximal? Or you overlooked that particular
>>match? I can't figure it out from your description.
>>
>>>
>>>
>>>
>>> I can do this via some crude loops and subsetting, but I am looking for
>>>as
>>> much efficiency as possible
>>> as the dataset has around 50 million rows to assess. Any suggestions
>>> welcomed.
>>
>>Hum, is the source of this data in a relational database such as
>>Oracle, PostgreSQL, MySQL, MS-SQL, or SQLite (or "other")? I ask
>>because some of this processing might be easier do to in the data base
>>using a "self join", instead of reading the entire relational table
>>into a data.frame and doing it in R.
>>
>>>
>>> Thanks in advance
>>>
>>> Scott Williams MD
>>> Melbourne, Australia
>>>
>>
>>--
>>There is nothing more pleasant than traveling and meeting new people!
>>Genghis Khan
>>
>>Maranatha! <><
>>John McKown
>
> This email (including any attachments or links) may contain
> confidential and/or legally privileged information and is
> intended only to be read or used by the addressee.  If you
> are not the intended addressee, any use, distribution,
> disclosure or copying of this email is strictly
> prohibited.
> Confidentiality and legal privilege attached to this email
> (including any attachments) are not waived or lost by
> reason of its mistaken delivery to you.
> If you have received this email in error, please delete it
> and notify us immediately by telephone or email.  Peter
> MacCallum Cancer Centre provides no guarantee that this
> transmission is free of virus or that it has not been
> intercepted or altered and will not be liable for any delay
> in its receipt.
>



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Wed Jul 16 16:09:02 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 16 Jul 2014 09:09:02 -0500
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CAAxdm-5CXGvPFAY8fXVxas+a1ZETT3d0oVa+iXMZ-1yd+W-YDQ@mail.gmail.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>
	<CAAxdm-5CXGvPFAY8fXVxas+a1ZETT3d0oVa+iXMZ-1yd+W-YDQ@mail.gmail.com>
Message-ID: <CAAJSdjhLvbEezU1-U3i-_7qeSCi3svxRJQf3+-P7RnwNis-2qg@mail.gmail.com>

On Wed, Jul 16, 2014 at 8:51 AM, jim holtman <jholtman at gmail.com> wrote:
> I can reproduce what you requested, but there was the question about
> what happens with the multiple 'c-y' values.
>
> ====================
>
>> require(data.table)
>> x <- read.table(text = 'id   date value
> + a    2000-01-01 x
> + a    2000-03-01 x
> + b    2000-11-11 w
> + c    2000-11-11 y
> + c    2000-10-01 y
> + c    2000-09-10 y
> + c    2000-12-12 z
> + c    2000-10-11 z
> + d    2000-11-11 w
> + d    2000-11-10 w', as.is = TRUE, header = TRUE)
>> setDT(x)
>> x[, date := as.Date(date)]
>> setkey(x, id, value, date)
>>
>> y <- x[
> +     , {
> +         if (.N == 1) val <- NULL  # only one -- delete
> +         else {
> +             dif <- difftime(tail(date, -1), head(date, -1), units = 'days')
> +             # return first value if any > 31
> +             if (any(dif >= 31)) val <- list(date = date[1L])
> +             else val <- NULL
> +         }
> +         val
> +       }
> +     , keyby = 'id,value'
> +     ]
>> y
>    id value       date
> 1:  a     x 2000-01-01
> 2:  c     y 2000-09-10
> 3:  c     z 2000-10-11
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>

Wow, I picked up a couple of _nice_ techniques from that one post!
Looks like "data.table" will let me do SQL like things in R. I have a
warped brain. I think in "result sets" and "matrix operations"

Many thanks.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From Scott.Williams at petermac.org  Wed Jul 16 16:11:08 2014
From: Scott.Williams at petermac.org (Williams Scott)
Date: Wed, 16 Jul 2014 14:11:08 +0000
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CAAJSdjhLvbEezU1-U3i-_7qeSCi3svxRJQf3+-P7RnwNis-2qg@mail.gmail.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<CAAJSdjgL8NWjHMq21USxVAsJL=Z6z7qku5YWSKag80mTWoN=Eg@mail.gmail.com>
	<CAAxdm-5CXGvPFAY8fXVxas+a1ZETT3d0oVa+iXMZ-1yd+W-YDQ@mail.gmail.com>
	<CAAJSdjhLvbEezU1-U3i-_7qeSCi3svxRJQf3+-P7RnwNis-2qg@mail.gmail.com>
Message-ID: <CFECC51E.1EF7E%scott.williams@petermac.org>

Thanks guys - amazingly prompt solutions from the R community as always.

Yes, the c-y value reverts to just the first date event - the spirit of
this is that I am trying to identify and confirm a list of diagnoses that
a patient has coded in government administrative data. Once a diagnosis is
made and confirmed, I am not interested in whether it is listed again and
again later on. I just need that date at which it first became apparent.
So in the multiple c-y case, the min date is the correct one. Some cases
will have the same diagnosis listed dozens of times, hence the very
bloated dataset.

Time to churn through the data is not a big issue, so I will have a go
with Jim?s neat code he just sent on perhaps a few thousand rows and see
how I get on. 

S



On 17/07/2014 12:09 am, "John McKown" <john.archie.mckown at gmail.com> wrote:

>On Wed, Jul 16, 2014 at 8:51 AM, jim holtman <jholtman at gmail.com> wrote:
>> I can reproduce what you requested, but there was the question about
>> what happens with the multiple 'c-y' values.
>>
>> ====================
>>
>>> require(data.table)
>>> x <- read.table(text = 'id   date value
>> + a    2000-01-01 x
>> + a    2000-03-01 x
>> + b    2000-11-11 w
>> + c    2000-11-11 y
>> + c    2000-10-01 y
>> + c    2000-09-10 y
>> + c    2000-12-12 z
>> + c    2000-10-11 z
>> + d    2000-11-11 w
>> + d    2000-11-10 w', as.is = TRUE, header = TRUE)
>>> setDT(x)
>>> x[, date := as.Date(date)]
>>> setkey(x, id, value, date)
>>>
>>> y <- x[
>> +     , {
>> +         if (.N == 1) val <- NULL  # only one -- delete
>> +         else {
>> +             dif <- difftime(tail(date, -1), head(date, -1), units =
>>'days')
>> +             # return first value if any > 31
>> +             if (any(dif >= 31)) val <- list(date = date[1L])
>> +             else val <- NULL
>> +         }
>> +         val
>> +       }
>> +     , keyby = 'id,value'
>> +     ]
>>> y
>>    id value       date
>> 1:  a     x 2000-01-01
>> 2:  c     y 2000-09-10
>> 3:  c     z 2000-10-11
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>
>Wow, I picked up a couple of _nice_ techniques from that one post!
>Looks like "data.table" will let me do SQL like things in R. I have a
>warped brain. I think in "result sets" and "matrix operations"
>
>Many thanks.
>
>-- 
>There is nothing more pleasant than traveling and meeting new people!
>Genghis Khan
>
>Maranatha! <><
>John McKown


This email (including any attachments or links) may contain 
confidential and/or legally privileged information and is 
intended only to be read or used by the addressee.  If you 
are not the intended addressee, any use, distribution, 
disclosure or copying of this email is strictly 
prohibited.  
Confidentiality and legal privilege attached to this email 
(including any attachments) are not waived or lost by 
reason of its mistaken delivery to you.
If you have received this email in error, please delete it 
and notify us immediately by telephone or email.  Peter 
MacCallum Cancer Centre provides no guarantee that this 
transmission is free of virus or that it has not been 
intercepted or altered and will not be liable for any delay 
in its receipt.


From dcarlson at tamu.edu  Wed Jul 16 16:32:54 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 16 Jul 2014 14:32:54 +0000
Subject: [R] Area Graphs
In-Reply-To: <CAM_vjum7=QaJHjXs3WK5u8bsyfGsW8r1HAtsjhq7YukcMBndhQ@mail.gmail.com>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
	<CAM_vjum7=QaJHjXs3WK5u8bsyfGsW8r1HAtsjhq7YukcMBndhQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8A28D@mb02.ads.tamu.edu>

Also look at stackpoly() in the plotrix package. 

The R Graphical Manual shows the example plots here

http://rgm.ogalab.net/RGM/R_rdfile?f=plotrix/man/stackpoly.Rd&d=R_CC

David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Wednesday, July 16, 2014 8:59 AM
To: Leask, Graham
Cc: r-help at r-project.org
Subject: Re: [R] Area Graphs

You mean like this?

http://stackoverflow.com/questions/10840314/stacked-area-graph-in-r
http://menugget.blogspot.com/2013/12/data-mountains-and-streams-stacked-area.html
http://stackoverflow.com/questions/22544571/create-stacked-area-graph-from-time-data

Or any of the many other results from a google search on

"area graph" r

Since you claim to be "unable to find" anything relevant, maybe you
mean something different? If so, you'll need to be clearer, and
ideally link to an example.

Sarah

On Wed, Jul 16, 2014 at 9:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
> Area graphs are a commonly used graphic in such software as Excel but I have been unable
> to find any examples of their use using R.
>
> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
> being directed to the relevant package or a code example.
>
> Any help will be greatly appreciated
>
> Graham

-- 
Sarah Goslee
http://www.functionaldiversity.org

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From g.leask at aston.ac.uk  Wed Jul 16 16:41:11 2014
From: g.leask at aston.ac.uk (Leask, Graham)
Date: Wed, 16 Jul 2014 14:41:11 +0000
Subject: [R] Area Graphs
In-Reply-To: <CAM_vjum7=QaJHjXs3WK5u8bsyfGsW8r1HAtsjhq7YukcMBndhQ@mail.gmail.com>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
	<CAM_vjum7=QaJHjXs3WK5u8bsyfGsW8r1HAtsjhq7YukcMBndhQ@mail.gmail.com>
Message-ID: <F68BC46D-951F-4DCA-8CF5-A5DE2CD2946F@aston.ac.uk>

Hi Sarah,

Thank you. 

What I?m looking for is similar but a a more refined example. The
stack poly example looks a bit nearer what I had in mind.

Kind regards 


Graham



On 16 Jul 2014, at 14:58, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> You mean like this?
> 
> http://stackoverflow.com/questions/10840314/stacked-area-graph-in-r
> http://menugget.blogspot.com/2013/12/data-mountains-and-streams-stacked-area.html
> http://stackoverflow.com/questions/22544571/create-stacked-area-graph-from-time-data
> 
> Or any of the many other results from a google search on
> 
> "area graph" r
> 
> Since you claim to be "unable to find" anything relevant, maybe you
> mean something different? If so, you'll need to be clearer, and
> ideally link to an example.
> 
> Sarah
> 
> On Wed, Jul 16, 2014 at 9:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
>> Area graphs are a commonly used graphic in such software as Excel but I have been unable
>> to find any examples of their use using R.
>> 
>> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
>> being directed to the relevant package or a code example.
>> 
>> Any help will be greatly appreciated
>> 
>> Graham
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org


From 538280 at gmail.com  Wed Jul 16 17:30:39 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 16 Jul 2014 09:30:39 -0600
Subject: [R] Area Graphs
In-Reply-To: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
Message-ID: <CAFEqCdytGnjfSUGqCVAPuUwgHPJgfot_xE_Dc=G6qYJYoJDFAw@mail.gmail.com>

You ask: "Is there a way to produce good quality area graphs in R?"  I
would modify that question a little and ask it back as:

Is there a way to produce good quality area graphs?

Consider the following:

> library(fortunes)
> fortune(197)

If anything, there should be a Law: Thou Shalt Not Even Think Of Producing A
Graph That Looks Like Anything From A Spreadsheet.
   -- Ted Harding (in a discussion about producing graphics)
      R-help (August 2007)

>

(also possibly fortune(266))

And also the books by Tufte and Cleveland.

What information are you trying to convey/explore using area graphs?
There is probably a better tool or set of tools to use.


On Wed, Jul 16, 2014 at 7:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
> Area graphs are a commonly used graphic in such software as Excel but I have been unable
> to find any examples of their use using R.
>
> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
> being directed to the relevant package or a code example.
>
> Any help will be greatly appreciated
>
> Graham
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From S.Ellison at LGCGroup.com  Wed Jul 16 17:33:44 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 16 Jul 2014 16:33:44 +0100
Subject: [R] Area Graphs
In-Reply-To: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5E9DF5612C@GOLD.corp.lgc-group.com>


> Is there a way to produce good quality area graphs in R? If so I would greatly
> appreciate being directed to the relevant package or a code example.

Have you tried googling 'area plot in R'?

There's a geom_area feature in ggplot2 which probably meets most expectations of 'high quality'. See examples and help at http://ggplot2.org/ (follow the documentation link)

stackpoly in plotrix draws stacked area charts in base graphics, though you'll have to add legend manually.

There's also a very pretty example using a custom base graphics functon at  http://menugget.blogspot.co.uk/2013/12/data-mountains-and-streams-stacked-area.html

... and so on ...

Personally, I like ggplot2 for prettiness and simplicity once you have your head round the grammar, but it can be quite hard to get to that point and it is perhaps _too_ pretty for publication line drawings. So for single graphs I generally stick to base graphics.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From g.leask at aston.ac.uk  Wed Jul 16 17:41:28 2014
From: g.leask at aston.ac.uk (Leask, Graham)
Date: Wed, 16 Jul 2014 15:41:28 +0000
Subject: [R] Area Graphs
In-Reply-To: <CAFEqCdytGnjfSUGqCVAPuUwgHPJgfot_xE_Dc=G6qYJYoJDFAw@mail.gmail.com>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
	<CAFEqCdytGnjfSUGqCVAPuUwgHPJgfot_xE_Dc=G6qYJYoJDFAw@mail.gmail.com>
Message-ID: <87F7608A-D243-49E0-AAA9-EF3A42C23BC8@aston.ac.uk>

Greg,

I think you encapsulate my dilemma well. I could produce a graph
using Excel in 5 minutes but they look so boring and lack precision.

A key benefit of R is the ability to produce quality customised graphs.
I have the books by Tufte and Cleveland and perhaps there is a
better way to portray these data.

What I?m looking to do is to illustrate how several blocks of data change
distribution relative to one another over time but in a less boring way.


On 16 Jul 2014, at 16:30, Greg Snow <538280 at gmail.com> wrote:

> You ask: "Is there a way to produce good quality area graphs in R?"  I
> would modify that question a little and ask it back as:
> 
> Is there a way to produce good quality area graphs?
> 
> Consider the following:
> 
>> library(fortunes)
>> fortune(197)
> 
> If anything, there should be a Law: Thou Shalt Not Even Think Of Producing A
> Graph That Looks Like Anything From A Spreadsheet.
>   -- Ted Harding (in a discussion about producing graphics)
>      R-help (August 2007)
> 
>> 
> 
> (also possibly fortune(266))
> 
> And also the books by Tufte and Cleveland.
> 
> What information are you trying to convey/explore using area graphs?
> There is probably a better tool or set of tools to use.
> 
> 
> On Wed, Jul 16, 2014 at 7:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
>> Area graphs are a commonly used graphic in such software as Excel but I have been unable
>> to find any examples of their use using R.
>> 
>> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
>> being directed to the relevant package or a code example.
>> 
>> Any help will be greatly appreciated
>> 
>> Graham
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From mkbartl at gmail.com  Wed Jul 16 18:49:43 2014
From: mkbartl at gmail.com (Megan Bartlett)
Date: Wed, 16 Jul 2014 09:49:43 -0700
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <Zen-1X7Kxh-000G9u-6u@smarthost01c.mail.zen.net.uk>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
	<CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.gmail.com>
	<Zen-1X7Kxh-000G9u-6u@smarthost01c.mail.zen.net.uk>
Message-ID: <CAB2zMEGV=hqfdHOKbSL2ThGtzBS3tbVrUzVAQSExp_NVOPSGpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/85a40504/attachment.pl>

From Mark.Fowler at dfo-mpo.gc.ca  Wed Jul 16 19:04:04 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Wed, 16 Jul 2014 14:04:04 -0300
Subject: [R] long tk2listbox display offset
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F80692124E@marbioexc02.mar.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/55c2c0c2/attachment.pl>

From 538280 at gmail.com  Wed Jul 16 20:38:37 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 16 Jul 2014 12:38:37 -0600
Subject: [R] Area Graphs
In-Reply-To: <87F7608A-D243-49E0-AAA9-EF3A42C23BC8@aston.ac.uk>
References: <97B71D62-53EF-4352-BDF6-E16584AAF942@aston.ac.uk>
	<CAFEqCdytGnjfSUGqCVAPuUwgHPJgfot_xE_Dc=G6qYJYoJDFAw@mail.gmail.com>
	<87F7608A-D243-49E0-AAA9-EF3A42C23BC8@aston.ac.uk>
Message-ID: <CAFEqCdwTpxE6Hfqb0xjHQRJ2WkH0h+X9xGZ+K9caGYGY27BS=w@mail.gmail.com>

You can show the 2 distributions at a given time with a simple plot
without needing to color in the areas.  To show this change over time
you could use the animation package or faceting from the lattice or
ggplot2 packages (depending on how many time periods you have).

On Wed, Jul 16, 2014 at 9:41 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
> Greg,
>
> I think you encapsulate my dilemma well. I could produce a graph
> using Excel in 5 minutes but they look so boring and lack precision.
>
> A key benefit of R is the ability to produce quality customised graphs.
> I have the books by Tufte and Cleveland and perhaps there is a
> better way to portray these data.
>
> What I?m looking to do is to illustrate how several blocks of data change
> distribution relative to one another over time but in a less boring way.
>
>
> On 16 Jul 2014, at 16:30, Greg Snow <538280 at gmail.com> wrote:
>
>> You ask: "Is there a way to produce good quality area graphs in R?"  I
>> would modify that question a little and ask it back as:
>>
>> Is there a way to produce good quality area graphs?
>>
>> Consider the following:
>>
>>> library(fortunes)
>>> fortune(197)
>>
>> If anything, there should be a Law: Thou Shalt Not Even Think Of Producing A
>> Graph That Looks Like Anything From A Spreadsheet.
>>   -- Ted Harding (in a discussion about producing graphics)
>>      R-help (August 2007)
>>
>>>
>>
>> (also possibly fortune(266))
>>
>> And also the books by Tufte and Cleveland.
>>
>> What information are you trying to convey/explore using area graphs?
>> There is probably a better tool or set of tools to use.
>>
>>
>> On Wed, Jul 16, 2014 at 7:51 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
>>> Area graphs are a commonly used graphic in such software as Excel but I have been unable
>>> to find any examples of their use using R.
>>>
>>> Is there a way to produce good quality area graphs in R? If so I would greatly appreciate
>>> being directed to the relevant package or a code example.
>>>
>>> Any help will be greatly appreciated
>>>
>>> Graham
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From lambert_manuel at hotmail.com  Wed Jul 16 15:46:45 2014
From: lambert_manuel at hotmail.com (Manuel Lambert)
Date: Wed, 16 Jul 2014 15:46:45 +0200
Subject: [R] ANOVA for RCBD, two factors: how to plot residuals?..
Message-ID: <DUB129-W326B741AE779AE2A48D3CDEFF70@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/f26aaf48/attachment.pl>

From lambert_manuel at hotmail.com  Wed Jul 16 15:47:15 2014
From: lambert_manuel at hotmail.com (Manuel Lambert)
Date: Wed, 16 Jul 2014 15:47:15 +0200
Subject: [R] ANOVA for RCBD, two factors: how to plot residuals?..
Message-ID: <DUB129-W328036E9DFD61FD433A01BEFF70@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/6135e20e/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 16 16:49:33 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Jul 2014 07:49:33 -0700
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CFECB67F.1EF38%scott.williams@petermac.org>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
Message-ID: <1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
If `dat` is the dataset

library(dplyr)
dat%>%
group_by(id,value)%>% 

arrange(date=as.Date(date))%>%
filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))
#Source: local data frame [3 x 3]
#Groups: id, value
#
#? id?????? date value
#1? a 2000-01-01???? x
#2? c 2000-09-10???? y
#3? c 2000-10-11???? z
A.K.




On Wednesday, July 16, 2014 9:10 AM, Williams Scott <Scott.Williams at petermac.org> wrote:
Hi R experts,

I have a dataset as sampled below. Values are only regarded as ?confirmed?
in an individual (?id?) if they occur
more than once at least 30 days apart.


id?  date value
a? ? 2000-01-01 x
a? ? 2000-03-01 x
b? ? 2000-11-11 w
c? ? 2000-11-11 y
c? ? 2000-10-01 y
c? ? 2000-09-10 y
c? ? 2000-12-12 z
c? ? 2000-10-11 z
d? ? 2000-11-11 w
d? ? 2000-11-10 w


I wish to subset the data to retain rows where the value for the
individual is confirmed more than 30 days apart. So, after deleting all
rows with just one occurrence of id and value, the rest would be the
earliest occurrence of each value in each case id, provided 31 or more
days exist between the dates. If >1 value is present per id, each value
level needs to be assessed independently. This example would then reduce
to:


id?  date? ? ? ? ?  value
a? ? 2000-01-01 x
c? ? 2000-09-10 y
c? ? 2000-10-11 z



I can do this via some crude loops and subsetting, but I am looking for as
much efficiency as possible
as the dataset has around 50 million rows to assess. Any suggestions
welcomed.

Thanks in advance

Scott Williams MD
Melbourne, Australia



This email (including any attachments or links) may contain
confidential and/or legally privileged information and is
intended only to be read or used by the addressee.? If you
are not the intended addressee, any use, distribution,
disclosure or copying of this email is strictly
prohibited.
Confidentiality and legal privilege attached to this email
(including any attachments) are not waived or lost by
reason of its mistaken delivery to you.
If you have received this email in error, please delete it
and notify us immediately by telephone or email.? Peter
MacCallum Cancer Centre provides no guarantee that this
transmission is free of virus or that it has not been
intercepted or altered and will not be liable for any delay
in its receipt.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From fmagalhaes at gmail.com  Wed Jul 16 18:29:12 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Wed, 16 Jul 2014 13:29:12 -0300
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
	<CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
	<CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>
Message-ID: <CAAu8QF6efn13KukGx412=6p1L42tPSYHM1KdCNG-B42QCbPuhQ@mail.gmail.com>

I was able to download it specifying the method as "curl", like this:

> download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip", temp, method="curl")
#! F?bio


On Tue, Jul 15, 2014 at 3:46 PM, Electron Musketeer
<musketeere at gmail.com> wrote:
> Many thanks Ista. I will try other routes as well.
> Thanks Jeff and sorry for posting without abiding by the rules.
> Thanks James. I would rather automate this than download manually
> everytime. That is my intent.
>
> Best
> Balaji
>
>
> On Tue, Jul 15, 2014 at 7:16 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> Not an R question, but see
>> https://addons.mozilla.org/en-US/firefox/addon/cliget/ for an easy way
>> to see what what is going on under the hood when you download using
>> firefox. For your example I get
>>
>> wget --header='Host: www.nseindia.com' --header='User-Agent:
>> Mozilla/5.0 (X11; Linux x86_64; rv:30.0) Gecko/20100101 Firefox/30.0'
>> --header='Accept:
>> text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
>> --header='Accept-Language: en-US,en;q=0.5' --header='Connection:
>> keep-alive' '
>> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> '
>> -O 'fo09JUL2014bhav.csv.zip' -c
>>
>> Now you just need to translate that to R. (Or not, sometimes its
>> easier to just shell out (using e.g., 'system()' ) and download with
>> wget or curl).
>>
>> Best,
>> Ista
>>
>> On Tue, Jul 15, 2014 at 11:24 AM, Electron Musketeer
>> <musketeere at gmail.com> wrote:
>> > Dear Experts
>> >
>> > I am new to this forum and to R and was trying the following to access a
>> > zip file from  the webpages of the NSE. Here is my code.
>> >
>> > temp <- tempfile()
>> > download.file("
>> >
>> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> > ",temp)
>> > con <- unz(temp, "a1.dat")
>> > data <- matrix(scan(con),ncol=4,byrow=TRUE)
>> > unlink(temp)
>> >
>> >
>> > The result is:
>> > cannot open URL '
>> >
>> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> > '
>> > In addition: Warning message:
>> > In download.file("
>> >
>> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> ",
>> >  :
>> >   cannot open: HTTP status was '403 Forbidden'
>> >
>> >
>> > I tried accessing this file directly from the website and it is letting
>> me
>> > access it. My question is why is it not letting me download from R? I
>> have
>> > gone through some websites to see if this has been resolved but the older
>> > resolutions also do not work. Can someone help please?
>> >
>> > Thx
>> > Balaji
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ravi.varadhan at jhu.edu  Wed Jul 16 19:42:44 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 16 Jul 2014 17:42:44 +0000
Subject: [R] Checking modeling assumptions in a binomial GLMM
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C312434B5E@DOM-MTW-MAIL2.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/450bb29f/attachment.pl>

From davies.trevor at gmail.com  Wed Jul 16 21:25:26 2014
From: davies.trevor at gmail.com (Trevor Davies)
Date: Wed, 16 Jul 2014 12:25:26 -0700
Subject: [R] GAM model output error(?)
Message-ID: <CAJhyqVjjX=F26BaWUSoFW+hLDYBzePoW3mESncXukNDo8jo51A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/6127b30b/attachment.pl>

From rmh at temple.edu  Wed Jul 16 21:39:41 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 16 Jul 2014 15:39:41 -0400
Subject: [R] ANOVA for RCBD, two factors: how to plot residuals?..
In-Reply-To: <DUB129-W326B741AE779AE2A48D3CDEFF70@phx.gbl>
References: <DUB129-W326B741AE779AE2A48D3CDEFF70@phx.gbl>
Message-ID: <CAGx1TMCy6ud0UKCoLNztpj=yw=JrPpu-LhOAJscWr1d8GduMew@mail.gmail.com>

## Manuel,

## Please look at the maiz example in ?mmc in the HH package.

install.packages("HH")  ## if necessary
library(HH)
?mmc

## After the full maiz example, then you need one more command

maiz.proj <- proj(maiz.aov)
maiz.proj

## I think you are looking for
maiz.proj$Within[, "Residuals"]

## Rich

On Wed, Jul 16, 2014 at 9:46 AM, Manuel Lambert
<lambert_manuel at hotmail.com> wrote:
>
>
>
> Hello,
> I'm having problems to analyse results from a RCB Design Experiment.I have three blocks. For each block: four treatments (factor A), randomized. And for each factor A treatment,  I have 6 differents treatments (factor C), randomized.
> myAOV=aov(response ~ factorA*factorC + Block + Error(field), data)
> The model i use would be response = factorA + factorC + factorA:factorC + Block (fixed effect) + Field (subplot, random effect).
> I have some good results but my problem is the following: i would like to have a look at the residuals distribution and the command:
> residuals(myAOV)
> returns a NULL object. How to do then to extract the residuals? The function works if i take off "Error(field)" from my aov function but this doesn't give me relevant residuals right?
> Thanks a lot!
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From s.wood at bath.ac.uk  Wed Jul 16 21:44:56 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 16 Jul 2014 20:44:56 +0100
Subject: [R] GAM model output error(?)
In-Reply-To: <CAJhyqVjjX=F26BaWUSoFW+hLDYBzePoW3mESncXukNDo8jo51A@mail.gmail.com>
References: <CAJhyqVjjX=F26BaWUSoFW+hLDYBzePoW3mESncXukNDo8jo51A@mail.gmail.com>
Message-ID: <53C6D638.5010801@bath.ac.uk>

Trevor,

It looks like you've added a parametric COR.YEARLY.MEAN in addition to 
your s(cxe,cyn,by=COR.YEARLY.MEAN) term. Because the latter includes a 
linear effect of COR.YEARLY.MEAN, then the parametric COR.YEARLY.MEAN 
will not be identifiable, so gam has dropped it.

I guess from the scale parameter your data are, if anything, 
under-dispersed relative to Poisson, but perhaps Poisson would have been 
ok too.

Could you give a bit more detail on 'NB just wouldn't work' please? What 
actually happened? (It's new functionality, so having reports when stuff 
goes wrong is useful).

best,
Simon

On 16/07/14 20:25, Trevor Davies wrote:
> I have run a quasipoisson spatial model via GAM (NB just wouldn't work) and
> I am getting the following output of one of my parameters
> (COR.YEARLY.MEAN).  Does this suggest an error in the model fit? The model
> seems to have converged.  Apologies for the lack of reproducible example
> but it didn't really seem warranted in this case.  Thank you for the
> assistance.
> Trevor
>
> Parametric coefficients:
>                  Estimate Std. Error t value Pr(>|t|)
> (Intercept)      -3.7084     0.2185  -16.97   <2e-16 ***
> COR.YEARLY.MEAN   0.0000     0.0000      NA       NA
> ---
>
> Approximate significance of smooth terms:
>                                             edf Ref.df       F  p-value
> s(PRED_cBOTTOM_TEMPERATURE.std)          5.008  6.045  24.871  < 2e-16 ***
> s(cxe,cyn)                              28.999 29.000  13.951  < 2e-16 ***
> s(cDMAX.std)                             3.830  4.761 243.895  < 2e-16 ***
> s(cxe,cyn):male.allyear.intensity.std    8.053  9.923   4.486  2.8e-06 ***
> s(cxe,cyn):female.allyear.intensity.std  3.733  4.334   5.478 0.000149 ***
> s(cxe,cyn):COR.YEARLY.MEAN              28.979 29.886  28.502  < 2e-16 ***
> s(cxe,cyn):cFISHING_INTENSITY.std        5.592  6.464  24.330  < 2e-16 ***
> -
> Rank: 1/169
> R-sq.(adj) =  0.697   Deviance explained = 64.1%
> GCV = 0.70372  Scale est. = 0.69061   n = 4575
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From wdunlap at tibco.com  Wed Jul 16 21:48:10 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 16 Jul 2014 12:48:10 -0700
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAF8bMcafPGEi71caGANvtbGzimugf4wqKX-_rEh2x-YP-0Vagw@mail.gmail.com>

Using base R you can solve this by doing some sorting and comparing
the first and last dates in each id-value group.  Computing the last
and last dates can be vectorized.

f1 <- function(data) {
    # sort by id, break ties with value, break remaining ties with date
    sortedData <- data[with(data, order(id, value, date)), ]
    i <- seq_len(NROW(sortedData)-1)
    # a 'group' has same id and value, entries in group are sorted by date
    isBreakPoint <- with(sortedData, id[i]!=id[i+1] | value[i]!=value[i+1])
    isFirstInGroup <- c(TRUE, isBreakPoint)
    isLastInGroup <- c(isBreakPoint, TRUE)
    sortedData[isFirstInGroup,][sortedData[isLastInGroup,"date"] -
sortedData[isFirstInGroup,"date"] >= 31,]
}
dat <- read.table(colClasses=c("character", "Date", "character"),
header=TRUE, text=
"id   date value
a    2000-01-01 x
a    2000-03-01 x
b    2000-11-11 w
c    2000-11-11 y
c    2000-10-01 y
c    2000-09-10 y
c    2000-12-12 z
c    2000-10-11 z
d    2000-11-11 w
d    2000-11-10 w")

> f1(dat)
  id       date value
1  a 2000-01-01     x
6  c 2000-09-10     y
8  c 2000-10-11     z

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jul 16, 2014 at 7:49 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> If `dat` is the dataset
>
> library(dplyr)
> dat%>%
> group_by(id,value)%>%
>
> arrange(date=as.Date(date))%>%
> filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))
> #Source: local data frame [3 x 3]
> #Groups: id, value
> #
> #  id       date value
> #1  a 2000-01-01     x
> #2  c 2000-09-10     y
> #3  c 2000-10-11     z
> A.K.
>
>
>
>
> On Wednesday, July 16, 2014 9:10 AM, Williams Scott <Scott.Williams at petermac.org> wrote:
> Hi R experts,
>
> I have a dataset as sampled below. Values are only regarded as ?confirmed?
> in an individual (?id?) if they occur
> more than once at least 30 days apart.
>
>
> id   date value
> a    2000-01-01 x
> a    2000-03-01 x
> b    2000-11-11 w
> c    2000-11-11 y
> c    2000-10-01 y
> c    2000-09-10 y
> c    2000-12-12 z
> c    2000-10-11 z
> d    2000-11-11 w
> d    2000-11-10 w
>
>
> I wish to subset the data to retain rows where the value for the
> individual is confirmed more than 30 days apart. So, after deleting all
> rows with just one occurrence of id and value, the rest would be the
> earliest occurrence of each value in each case id, provided 31 or more
> days exist between the dates. If >1 value is present per id, each value
> level needs to be assessed independently. This example would then reduce
> to:
>
>
> id   date           value
> a    2000-01-01 x
> c    2000-09-10 y
> c    2000-10-11 z
>
>
>
> I can do this via some crude loops and subsetting, but I am looking for as
> much efficiency as possible
> as the dataset has around 50 million rows to assess. Any suggestions
> welcomed.
>
> Thanks in advance
>
> Scott Williams MD
> Melbourne, Australia
>
>
>
> This email (including any attachments or links) may contain
> confidential and/or legally privileged information and is
> intended only to be read or used by the addressee.  If you
> are not the intended addressee, any use, distribution,
> disclosure or copying of this email is strictly
> prohibited.
> Confidentiality and legal privilege attached to this email
> (including any attachments) are not waived or lost by
> reason of its mistaken delivery to you.
> If you have received this email in error, please delete it
> and notify us immediately by telephone or email.  Peter
> MacCallum Cancer Centre provides no guarantee that this
> transmission is free of virus or that it has not been
> intercepted or altered and will not be liable for any delay
> in its receipt.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed Jul 16 22:01:02 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Jul 2014 20:01:02 +0000
Subject: [R] Checking modeling assumptions in a binomial GLMM
References: <2F9EA67EF9AE1C48A147CB41BE2E15C312434B5E@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <loom.20140716T215359-190@post.gmane.org>

Ravi Varadhan <ravi.varadhan <at> jhu.edu> writes:

> 
> Dear All,
 
> I am fitting a model for a binary response variable measured
> repeatedly at multiple visits.  I am using the binomial GLMM using
> the glmer() function in lme4 package.  How can I evaluate the model
> assumptions (e.g., residual diagnostics, adequacy of random effects
> distribution) for a binomial GLMM?  Are there any standard checks
> that are commonly done?  Are there any pedagogical examples or data
> sets where model assumptions have been examined for binomial GLMMs?
 
> Any suggestions/guidance is appreciated.
> 
> Thank you,
> Ravi


  This might be better for r-sig-mixed-models at r-project.org.

  Roughly speaking, you want to do one set of diagnostics on
the individual-level residuals similar to those for a binomial GLM 
(which in turn are adaptations of the diagnostics for linear models)
and one on the group-level random effects.  As with GLMs, if your
binomial values are _binary_ then the individual-level diagnostics
will be a bit challenging.  Binomial GLMMs with N>1 will be a bit
easier.

  http://rpubs.com/bbolker/glmmchapter may be helpful, especially the second
("Culcita") example.

  Also http://stats.stackexchange.com/questions/70783/
   how-to-assess-the-fit-of-a-binomial-glmm-fitted-with-lme4-1-0/

(broken URL to make Gmane happy)


From davies.trevor at gmail.com  Wed Jul 16 22:16:44 2014
From: davies.trevor at gmail.com (Trevor Davies)
Date: Wed, 16 Jul 2014 13:16:44 -0700
Subject: [R] GAM model output error(?)
In-Reply-To: <53C6D638.5010801@bath.ac.uk>
References: <CAJhyqVjjX=F26BaWUSoFW+hLDYBzePoW3mESncXukNDo8jo51A@mail.gmail.com>
	<53C6D638.5010801@bath.ac.uk>
Message-ID: <CAJhyqVjr8mD_sJ3+Q1B2+u-DWEF7XVtZPjwTdQxUqnLq2h_X7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/aa7fa388/attachment.pl>

From s.wood at bath.ac.uk  Wed Jul 16 22:24:48 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 16 Jul 2014 21:24:48 +0100
Subject: [R] GAM model output error(?)
In-Reply-To: <CAJhyqVjr8mD_sJ3+Q1B2+u-DWEF7XVtZPjwTdQxUqnLq2h_X7g@mail.gmail.com>
References: <CAJhyqVjjX=F26BaWUSoFW+hLDYBzePoW3mESncXukNDo8jo51A@mail.gmail.com>
	<53C6D638.5010801@bath.ac.uk>
	<CAJhyqVjr8mD_sJ3+Q1B2+u-DWEF7XVtZPjwTdQxUqnLq2h_X7g@mail.gmail.com>
Message-ID: <53C6DF90.4020104@bath.ac.uk>

Trevor, Can I just check - were you using the new 'nb' from mgcv version 
 >= 1.8 or the old (and very slow) 'negbin' family? (Not that negative 
binomial seems needed here, but just to know) best, Simon


On 16/07/14 21:16, Trevor Davies wrote:
> Hi Simon,
>
> Thank you so much for being active on this list, it really is
> tremendously helpful.
>
> Thanks you for your insights, I was wondering whether both terms were
> necessary.
>
> As for 'NB wouldn't work' it was a convergence problem (and tremendously
> slow).  There were also issues with the models not giving lack of
> convergence warnings but then the model saying it was not converged and
> vice versa.  The QP seemed to fit the data well (and quickly) so we
> switched to that.
>
> Thanks again.
> Trevor
>
>
> On Wed, Jul 16, 2014 at 12:44 PM, Simon Wood <s.wood at bath.ac.uk
> <mailto:s.wood at bath.ac.uk>> wrote:
>
>     Trevor,
>
>     It looks like you've added a parametric COR.YEARLY.MEAN in addition
>     to your s(cxe,cyn,by=COR.YEARLY.MEAN) term. Because the latter
>     includes a linear effect of COR.YEARLY.MEAN, then the parametric
>     COR.YEARLY.MEAN will not be identifiable, so gam has dropped it.
>
>     I guess from the scale parameter your data are, if anything,
>     under-dispersed relative to Poisson, but perhaps Poisson would have
>     been ok too.
>
>     Could you give a bit more detail on 'NB just wouldn't work' please?
>     What actually happened? (It's new functionality, so having reports
>     when stuff goes wrong is useful).
>
>     best,
>     Simon
>
>
>     On 16/07/14 20:25, Trevor Davies wrote:
>
>         I have run a quasipoisson spatial model via GAM (NB just
>         wouldn't work) and
>         I am getting the following output of one of my parameters
>         (COR.YEARLY.MEAN).  Does this suggest an error in the model fit?
>         The model
>         seems to have converged.  Apologies for the lack of reproducible
>         example
>         but it didn't really seem warranted in this case.  Thank you for the
>         assistance.
>         Trevor
>
>         Parametric coefficients:
>                           Estimate Std. Error t value Pr(>|t|)
>         (Intercept)      -3.7084     0.2185  -16.97   <2e-16 ***
>         COR.YEARLY.MEAN   0.0000     0.0000      NA       NA
>         ---
>
>         Approximate significance of smooth terms:
>                                                      edf Ref.df       F
>           p-value
>         s(PRED_cBOTTOM_TEMPERATURE.__std)          5.008  6.045  24.871
>           < 2e-16 ***
>         s(cxe,cyn)                              28.999 29.000  13.951  <
>         2e-16 ***
>         s(cDMAX.std)                             3.830  4.761 243.895  <
>         2e-16 ***
>         s(cxe,cyn):male.allyear.__intensity.std    8.053  9.923   4.486
>           2.8e-06 ***
>         s(cxe,cyn):female.allyear.__intensity.std  3.733  4.334   5.478
>         0.000149 ***
>         s(cxe,cyn):COR.YEARLY.MEAN              28.979 29.886  28.502  <
>         2e-16 ***
>         s(cxe,cyn):cFISHING_INTENSITY.__std        5.592  6.464  24.330
>           < 2e-16 ***
>         -
>         Rank: 1/169
>         R-sq.(adj) =  0.697   Deviance explained = 64.1%
>         GCV = 0.70372  Scale est. = 0.69061   n = 4575
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     --
>     Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
>     +44 (0)1225 386603 <tel:%2B44%20%280%291225%20386603>
>     http://people.bath.ac.uk/sw283
>
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From wdunlap at tibco.com  Wed Jul 16 22:24:56 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 16 Jul 2014 13:24:56 -0700
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAF8bMcbFoh-12Oo_or8LevVfYrgDCvYjhGm2rFz86WqguTyP3g@mail.gmail.com>

> filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))

Note that the 'date == min(date)' will cause superfluous output rows
when there are several readings on initial date for a given id/value
pair.  E.g.,

> dat1 <- data.frame(stringsAsFactors=FALSE, id=rep("A", 4), value=rep("x", 4), date=as.Date("2000-10-1")+c(1,1,50,50))
> f2(dat1) # want 1 output row: A, x, 2000-10-2
Source: local data frame [2 x 3]
Groups: id, value

  id value       date
1  A     x 2000-10-02
2  A     x 2000-10-02

where f2 is your code wrapped up in a function (to make testing and use easier)

f2 <- function (data)
{
    library(dplyr)
    data %>% group_by(id, value) %>% arrange(date = as.Date(date)) %>%
        filter(any(c(abs(diff(as.Date(date))), NA) > 31) & date == min(date))
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jul 16, 2014 at 7:49 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> If `dat` is the dataset
>
> library(dplyr)
> dat%>%
> group_by(id,value)%>%
>
> arrange(date=as.Date(date))%>%
> filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))
> #Source: local data frame [3 x 3]
> #Groups: id, value
> #
> #  id       date value
> #1  a 2000-01-01     x
> #2  c 2000-09-10     y
> #3  c 2000-10-11     z
> A.K.
>
>
>
>
> On Wednesday, July 16, 2014 9:10 AM, Williams Scott <Scott.Williams at petermac.org> wrote:
> Hi R experts,
>
> I have a dataset as sampled below. Values are only regarded as ?confirmed?
> in an individual (?id?) if they occur
> more than once at least 30 days apart.
>
>
> id   date value
> a    2000-01-01 x
> a    2000-03-01 x
> b    2000-11-11 w
> c    2000-11-11 y
> c    2000-10-01 y
> c    2000-09-10 y
> c    2000-12-12 z
> c    2000-10-11 z
> d    2000-11-11 w
> d    2000-11-10 w
>
>
> I wish to subset the data to retain rows where the value for the
> individual is confirmed more than 30 days apart. So, after deleting all
> rows with just one occurrence of id and value, the rest would be the
> earliest occurrence of each value in each case id, provided 31 or more
> days exist between the dates. If >1 value is present per id, each value
> level needs to be assessed independently. This example would then reduce
> to:
>
>
> id   date           value
> a    2000-01-01 x
> c    2000-09-10 y
> c    2000-10-11 z
>
>
>
> I can do this via some crude loops and subsetting, but I am looking for as
> much efficiency as possible
> as the dataset has around 50 million rows to assess. Any suggestions
> welcomed.
>
> Thanks in advance
>
> Scott Williams MD
> Melbourne, Australia
>
>
>
> This email (including any attachments or links) may contain
> confidential and/or legally privileged information and is
> intended only to be read or used by the addressee.  If you
> are not the intended addressee, any use, distribution,
> disclosure or copying of this email is strictly
> prohibited.
> Confidentiality and legal privilege attached to this email
> (including any attachments) are not waived or lost by
> reason of its mistaken delivery to you.
> If you have received this email in error, please delete it
> and notify us immediately by telephone or email.  Peter
> MacCallum Cancer Centre provides no guarantee that this
> transmission is free of virus or that it has not been
> intercepted or altered and will not be liable for any delay
> in its receipt.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Wed Jul 16 23:37:24 2014
From: rsherry8 at comcast.net (Robert Sherry)
Date: Wed, 16 Jul 2014 17:37:24 -0400
Subject: [R] Correlation
Message-ID: <53C6F094.3080603@comcast.net>

Please consider the following R Script:
        x = c(1,2,3)
        y = c(1,2,9)
        cor(x,y)
These three lines will produce, as I expected, the correlation between 
the variables x and y. However, R is going to assume that the 
probability that x = 1 is the same as the probability that x = 2. 
Suppose I know the probability that x = 1 is 0.5 and the probability 
that x = 2 (or x = 3 ) is 0.25. I believe that would effect the 
correlation between the variables x and y. How do I tell R about these 
probabilities?

I thank the group in advance for their responses to this post.

Bob


From damian.ch.82 at gmail.com  Thu Jul 17 00:08:52 2014
From: damian.ch.82 at gmail.com (=?UTF-8?Q?Damian_Chor=C4=85=C5=BCkiewicz?=)
Date: Thu, 17 Jul 2014 00:08:52 +0200
Subject: [R] dplyr problem in shiny
Message-ID: <CACaD_wq+NgCz8gDiA+4DqLZgcLeK0tjOdi=xLNmEyctafJeFVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/b14f7627/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul 17 08:16:18 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 17 Jul 2014 06:16:18 +0000
Subject: [R] Correlation
In-Reply-To: <53C6F094.3080603@comcast.net>
References: <53C6F094.3080603@comcast.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDBB1F@SRVEXCHMBX.precheza.cz>

Hi

I looked in the help page which states

See Also
cor.test for confidence intervals (and tests).

cov.wt for weighted covariance computation.

Then I looked to cov.wt help page and it seems that it does what you want

cov.wt(data.frame(x,y), wt=c(.5,.25,.25), cor=T)

$cov
    x    y
x 1.1  4.1
y 4.1 17.9

$center
   x    y
1.75 3.25

$n.obs
[1] 3

$wt
[1] 0.50 0.25 0.25

$cor
          x         y
x 1.0000000 0.9239767
y 0.9239767 1.0000000

Actually you could look to help pages yourself and probably came to the same solution quicker.

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Robert Sherry
> Sent: Wednesday, July 16, 2014 11:37 PM
> To: r-help at r-project.org
> Subject: [R] Correlation
>
> Please consider the following R Script:
>         x = c(1,2,3)
>         y = c(1,2,9)
>         cor(x,y)
> These three lines will produce, as I expected, the correlation between
> the variables x and y. However, R is going to assume that the
> probability that x = 1 is the same as the probability that x = 2.
> Suppose I know the probability that x = 1 is 0.5 and the probability
> that x = 2 (or x = 3 ) is 0.25. I believe that would effect the
> correlation between the variables x and y. How do I tell R about these
> probabilities?
>
> I thank the group in advance for their responses to this post.
>
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From optionsraghu at gmail.com  Thu Jul 17 10:26:32 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Thu, 17 Jul 2014 09:26:32 +0100
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CAAu8QF6efn13KukGx412=6p1L42tPSYHM1KdCNG-B42QCbPuhQ@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
	<CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
	<CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>
	<CAAu8QF6efn13KukGx412=6p1L42tPSYHM1KdCNG-B42QCbPuhQ@mail.gmail.com>
Message-ID: <CADgEnDkaFVGRSnS386OCLjGDLjJnnh4TU5-KfK6iLOxmUeyqnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/f3a971f2/attachment.pl>

From info at aghmed.fsnet.co.uk  Thu Jul 17 12:50:50 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 17 Jul 2014 11:50:50 +0100
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <CAB2zMEGV=hqfdHOKbSL2ThGtzBS3tbVrUzVAQSExp_NVOPSGpg@mail.g
	mail.com>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
	<CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.gmail.com>
	<Zen-1X7Kxh-000G9u-6u@smarthost01c.mail.zen.net.uk>
	<CAB2zMEGV=hqfdHOKbSL2ThGtzBS3tbVrUzVAQSExp_NVOPSGpg@mail.gmail.com>
Message-ID: <Zen-1X7jH7-0004m7-TJ@smarthost01a.mail.zen.net.uk>

At 17:49 16/07/2014, Megan Bartlett wrote:
>Hi Michael,
>
>Thank you! Just to clarify, in my question, I was thinking that in this
>regression each study should be treated as one point, instead of each
>species, so that each effect size x value has a unique climate y value. Is
>that what the random= list(~1|Species, ~1|Site) argument is doing?

No.

Since the climate variable is per study (I assume) you are assuming 
that it has the same effect on each species. If that is not true you 
need to add species as another moderator and then add the interaction 
between climate and species.

The random parameter is saying that each site has its own intercept 
but you are only estimating its variance and each species also has 
its own intercept drawn from another distribution whose variance is 
being estimated.

I think you probably need to get local statistical help now from 
someone who understands the science of what you are doing and the 
statistics of mixed effects models. I am a bit concerned that without 
that knowledge we on the list may end up giving you misleading advice,


>Thanks,
>
>Megan
>
>
>On Wed, Jul 16, 2014 at 1:53 AM, Michael Dewey <info at aghmed.fsnet.co.uk>
>wrote:
>
> > At 23:19 14/07/2014, Megan Bartlett wrote:
> >
> >> Thanks very much, Wolfgang and Michael! I feel like I understand rma much
> >> more clearly.
> >>
> >> But just to make sure, is there any way to do this kind of analysis for a
> >> continuous predictor variable?
> >>
> >
> > Yes, just put it in as a moderator.
> >
> > I am not sure I fully understand the rest of your question but the answer
> > may be that the weights are a property of the individual effect sizes
> >
> >  For each site level, I have a value for a
> >> climate variable, and it would be great to see whether the average effect
> >> size for each site is correlated with that climate variable. But I'm not
> >> sure what variance would produce the appropriate weighting for each
> >> site-level average- would it be the variance in effect sizes across
> >> species
> >> within each site? Or does this analysis not really make any sense for
> >> effect sizes?
> >>
> >> Thanks again!
> >>
> >> Best,
> >>
> >> Megan
> >>
> >>
> >> On Mon, Jul 14, 2014 at 6:06 AM, Viechtbauer Wolfgang (STAT) <
> >> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>
> >> > Somehow that initial post slipped under the radar for me ...
> >> >
> >> > Yes, I would give the same suggestion as Michael. Besides random effects
> >> > for 'site', I would also suggest to add random effects for each
> >> estimates
> >> > (as in a regular random-effects model). So, if you have an 'id' variable
> >> > that is unique to each observed d-value, you would use:
> >> >
> >> > random = list(~ 1 | site, ~ 1 | id)
> >> >
> >> > with the rma.mv() function. This is in essence the model given by
> >> > equation (6) in:
> >> >
> >> > Nakagawa, S., & Santos, E. S. A. (2012). Methodological issues and
> >> > advances in biological meta-analysis. Evolutionary Ecology, 26(5),
> >> > 1253-1274.
> >> >
> >> > (at the time of publication, this model could not be fitted with
> >> metafor,
> >> > but it can now). Same model is described with a bit more detail in:
> >> >
> >> > Konstantopoulos, S. (2011). Fixed effects and variance components
> >> > estimation in three-level meta-analysis. Research Synthesis Methods,
> >> 2(1),
> >> > 61-76.
> >> >
> >> > Best,
> >> > Wolfgang
> >> >
> >> > --
> >> > Wolfgang Viechtbauer, Ph.D., Statistician
> >> > Department of Psychiatry and Psychology
> >> > School for Mental Health and Neuroscience
> >> > Faculty of Health, Medicine, and Life Sciences
> >> > Maastricht University, P.O. Box 616 (VIJV1)
> >> > 6200 MD Maastricht, The Netherlands
> >> > +31 (43) 388-4170 | http://www.wvbauer.com
> >> >
> >> >
> >> > > -----Original Message-----
> >> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org]
> >> > > On Behalf Of Michael Dewey
> >> > > Sent: Monday, July 14, 2014 14:42
> >> > > To: Megan Bartlett; r-help at r-project.org
> >> > > Subject: Re: [R] Correlating multiple effect sizes within a study to
> >> > > study-level predictors: metafor package
> >> > >
> >> > > At 23:18 11/07/2014, Megan Bartlett wrote:
> >> > > >Hi everyone,
> >> > > >
> >> > > >Since metafor doesn't have its own list, I hope this is the correct
> >> > > place
> >> > > >for this posting- my apologies if there is a more appropriate list.
> >> > >
> >> > > metafor questions welcome here, Megan
> >> > >
> >> > > Wolfgang seems to be off-list so while we wait for the definitive
> >> > > answer here are some hints.
> >> > >
> >> > >
> >> > > >I'm conducting a meta-analysis where I would like to determine the
> >> > > >correlation between plasticity in leaf traits and climate. I'm
> >> > > calculating
> >> > > >effect sizes as Hedge's d. My data is structured so that each study
> >> > > >collected data from one forest site, so there is one set of climate
> >> > > >variable values for that study, and there are one or more species in
> >> > > each
> >> > > >study, so all the species in a study have the same values for the
> >> > > climate
> >> > > >variables. I'm not sure how to account for this structure in modeling
> >> > > the
> >> > > >relationship between plasticity and climate.
> >> > >
> >> > > I think you need rma.mv for your situation and you need to specify a
> >> > > random effect for site.
> >> > >
> >> > > Try going
> >> > > ?rma.mv
> >> > > and looking for the section entitled Specifying random effects
> >> > >   You will need to set up your dataframe with one row per species and
> >> > > an indicator variable for site and then use
> >> > > random = ~ 1 | site
> >> > >
> >> > > Not tested obviously and Wolfgang may have other suggestions
> >> > >
> >> > > >My first thought was to calculate mean effect size and variance
> >> across
> >> > > >species for every study with multiple species and correlate that
> >>  with
> >> > > >the climate variable values for those study with the rma() function,
> >> but
> >> > > >trying to do that returns an error message:
> >> > > >
> >> > > >rma(yi = EffectSize, vi = Var, data = sitestable, mod = Precip)
> >> > > >returns: Error in wi * (yi - X %*% b)^2 : non-conformable arrays
> >> > > >
> >> > > >This leaves me with two questions: 1) Am I even accounting for the
> >> data
> >> > > >structure correctly with this approach, and 2) am I fundamentally
> >> > > >misunderstanding how to use metafor to do so?
> >> > > >
> >> > > >Thanks very much for your help!
> >> > > >
> >> > > >Best,
> >> > > >
> >> > > >Megan
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >
> > Michael Dewey
> > info at aghmed.fsnet.co.uk
> > http://www.aghmed.fsnet.co.uk/home.html
> >
> >
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From optionsraghu at gmail.com  Thu Jul 17 14:29:36 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Thu, 17 Jul 2014 13:29:36 +0100
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CAAu8QF6-+Bof4iW+CPJ5CL+SdySRvG7fFTrECGr0XBJnQ-qDdw@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
	<CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
	<CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>
	<CAAu8QF6efn13KukGx412=6p1L42tPSYHM1KdCNG-B42QCbPuhQ@mail.gmail.com>
	<CADgEnDkaFVGRSnS386OCLjGDLjJnnh4TU5-KfK6iLOxmUeyqnA@mail.gmail.com>
	<CAAu8QF6-+Bof4iW+CPJ5CL+SdySRvG7fFTrECGr0XBJnQ-qDdw@mail.gmail.com>
Message-ID: <CADgEnDmxVTaWL6E2Gt7QNeFO-v5dsELC8uWRRgCN16_pVd9Vmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/1d4e1622/attachment.pl>

From gangchen6 at gmail.com  Thu Jul 17 17:00:21 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 17 Jul 2014 11:00:21 -0400
Subject: [R] Mapping from one vector to another
Message-ID: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>

Suppose I have the following dataframe:

L4 <- LETTERS[1:4]
fac <- sample(L4, 10, replace = TRUE)
(d <- data.frame(x = 1, y = 1:10, fac = fac))

     x  y  fac
1  1  1   B
2  1  2   B
3  1  3   D
4  1  4   A
5  1  5   C
6  1  6   D
7  1  7   C
8  1  8   B
9  1  9   B
10 1 10   B

I'd like to add another column 'var' that is defined based on the
following mapping of column 'fac':

A -> 8
B -> 11
C -> 3
D -> 2

How can I achieve this in an elegant way (with a generic approach for
any length)?

Thanks,
Gang


From wdunlap at tibco.com  Thu Jul 17 17:13:19 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 17 Jul 2014 08:13:19 -0700
Subject: [R] Mapping from one vector to another
In-Reply-To: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
Message-ID: <CAF8bMcaS=3jqB1rxuTx=SfF60fYz7=BU9qeeJ0Cx0GtSAuhkqA@mail.gmail.com>

One way is to use a vector with names to do the mapping:
> mapVector <- c(A=8, B=11, C=3, D=2)
> mapVector[as.character(d$fac)]
 B  B  D  A  C  D  C  B  B  B
11 11  2  8  3  2  3 11 11 11
> # you may want to wrap this with unname()
> d$mappedFac <- mapVector[as.character(d$fac)]
> d
   x  y fac mappedFac
1  1  1   B        11
2  1  2   B        11
3  1  3   D         2
4  1  4   A         8
5  1  5   C         3
6  1  6   D         2
7  1  7   C         3
8  1  8   B        11
9  1  9   B        11
10 1 10   B        11

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jul 17, 2014 at 8:00 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> Suppose I have the following dataframe:
>
> L4 <- LETTERS[1:4]
> fac <- sample(L4, 10, replace = TRUE)
> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>
>      x  y  fac
> 1  1  1   B
> 2  1  2   B
> 3  1  3   D
> 4  1  4   A
> 5  1  5   C
> 6  1  6   D
> 7  1  7   C
> 8  1  8   B
> 9  1  9   B
> 10 1 10   B
>
> I'd like to add another column 'var' that is defined based on the
> following mapping of column 'fac':
>
> A -> 8
> B -> 11
> C -> 3
> D -> 2
>
> How can I achieve this in an elegant way (with a generic approach for
> any length)?
>
> Thanks,
> Gang
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu Jul 17 17:15:49 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 17 Jul 2014 11:15:49 -0400
Subject: [R] Mapping from one vector to another
In-Reply-To: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
Message-ID: <CAM_vjumE_8H936FpC1mNsDqv-yXY2s0wxyeLEC1KaUtciTvwKw@mail.gmail.com>

What about:

d$var <- c(8, 11, 3, 2)[d$fac]

Side note: it's much appreciated that you included data and a clear
problem statement. If you use
set.seed(123)
before your call to sample(), everyone who tries it will get the same
fac that you do. Otherwise we all get something different. Or just
generate your own example data and use dput() to include it in your
email.

Sarah

On Thu, Jul 17, 2014 at 11:00 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> Suppose I have the following dataframe:
>
> L4 <- LETTERS[1:4]
> fac <- sample(L4, 10, replace = TRUE)
> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>
>      x  y  fac
> 1  1  1   B
> 2  1  2   B
> 3  1  3   D
> 4  1  4   A
> 5  1  5   C
> 6  1  6   D
> 7  1  7   C
> 8  1  8   B
> 9  1  9   B
> 10 1 10   B
>
> I'd like to add another column 'var' that is defined based on the
> following mapping of column 'fac':
>
> A -> 8
> B -> 11
> C -> 3
> D -> 2
>
> How can I achieve this in an elegant way (with a generic approach for
> any length)?
>
> Thanks,
> Gang
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From petr.pikal at precheza.cz  Thu Jul 17 17:18:08 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 17 Jul 2014 15:18:08 +0000
Subject: [R] Mapping from one vector to another
In-Reply-To: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDBC71@SRVEXCHMBX.precheza.cz>

Hi

depends if you want the new column as factor or numeric.

d$fac2<-d$fac
I did not use var as it is R function.

levels(d$fac2)<-c(8,11,3,2)
d$fac2
 [1] 3  11 8  8  2  8  11 11 8  8
Levels: 8 11 3 2

You can change it to character or numeric if you wish.

as.character(d$fac2)
 [1] "3"  "11" "8"  "8"  "2"  "8"  "11" "11" "8"  "8"
as.numeric(as.character(d$fac2))
 [1]  3 11  8  8  2  8 11 11  8  8

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Gang Chen
> Sent: Thursday, July 17, 2014 5:00 PM
> To: r-help
> Subject: [R] Mapping from one vector to another
>
> Suppose I have the following dataframe:
>
> L4 <- LETTERS[1:4]
> fac <- sample(L4, 10, replace = TRUE)
> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>
>      x  y  fac
> 1  1  1   B
> 2  1  2   B
> 3  1  3   D
> 4  1  4   A
> 5  1  5   C
> 6  1  6   D
> 7  1  7   C
> 8  1  8   B
> 9  1  9   B
> 10 1 10   B
>
> I'd like to add another column 'var' that is defined based on the
> following mapping of column 'fac':
>
> A -> 8
> B -> 11
> C -> 3
> D -> 2
>
> How can I achieve this in an elegant way (with a generic approach for
> any length)?
>
> Thanks,
> Gang
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dstr7320 at uni.sydney.edu.au  Thu Jul 17 08:00:19 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Thu, 17 Jul 2014 06:00:19 +0000
Subject: [R] Vector of Numbers Not Output to Screen
Message-ID: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>

Hello,

I have a block of code that has two head calls at the end, but only the second is shown on screen. If I manually execute the statement which is not showing, it works. I thought that if statements are not functions. It is behaving as one.

> if(1 < 2)
+ {
+   x<-rnorm(100)
+   y <- rpois(10, 5)
+   head(x)
+   head(y)
+ }
[1] 4 4 5 4 8 3
> 
> head(x)
[1] -1.89083874  0.42442102  0.96114276  0.48004716  1.94358108 -0.02654324

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

From ecjbosu at aol.com  Thu Jul 17 14:43:23 2014
From: ecjbosu at aol.com (Joe W. Byers)
Date: Thu, 17 Jul 2014 07:43:23 -0500
Subject: [R] download.file: unsuppported url scheme
Message-ID: <53C7C4EB.3050509@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/700f75a9/attachment.pl>

From fmagalhaes at gmail.com  Thu Jul 17 14:29:08 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Thu, 17 Jul 2014 09:29:08 -0300
Subject: [R] Help with Download of a comma separated file in zip format
In-Reply-To: <CADgEnDkaFVGRSnS386OCLjGDLjJnnh4TU5-KfK6iLOxmUeyqnA@mail.gmail.com>
References: <CALNqgUWYimoN1Xbhx01L3sT6-FbnqSKbuR3JtiAfS+JMLCB1WQ@mail.gmail.com>
	<CA+vqiLG47vFz=ogkUJnukaFSj9WqOppMFazAiaF=yT1oqky68A@mail.gmail.com>
	<CALNqgUW1Tb_T=BEX89iFFGC7yq_mo1WSB6Gdqygf4Q7gHr+dzg@mail.gmail.com>
	<CAAu8QF6efn13KukGx412=6p1L42tPSYHM1KdCNG-B42QCbPuhQ@mail.gmail.com>
	<CADgEnDkaFVGRSnS386OCLjGDLjJnnh4TU5-KfK6iLOxmUeyqnA@mail.gmail.com>
Message-ID: <CAAu8QF6-+Bof4iW+CPJ5CL+SdySRvG7fFTrECGr0XBJnQ-qDdw@mail.gmail.com>

Hi Balaji,

Sorry, I forgot to tell that I'm running R on OSX. I don't know if
there's an easier way, but since you are running on Windows you could
try to install curl(http://curl.haxx.se/) binaries and try the curl
method again.
#! F?bio


On Thu, Jul 17, 2014 at 5:26 AM, Raghuraman Ramachandran
<optionsraghu at gmail.com> wrote:
> Hi Fabio
>
> Can you please reproduce your output? When I tried it curl are the following
> issues I get:
>
>>download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
>> temp, method="curl")
> Error in
> download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
> :
>   object 'temp' not found
>
> Then I changed the destination file and checked again:
> download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
> "c:/", method="curl")
> Warning message:
> In
> download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
> :
>   download had nonzero exit status
>
> I was still unable to get that.
>
> Thx
> Balaji
>
>
>
> On Wed, Jul 16, 2014 at 5:29 PM, F?bio Magalh?es <fmagalhaes at gmail.com>
> wrote:
>>
>> I was able to download it specifying the method as "curl", like this:
>>
>> >
>> > download.file("http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip",
>> > temp, method="curl")
>> #! F?bio
>>
>>
>> On Tue, Jul 15, 2014 at 3:46 PM, Electron Musketeer
>> <musketeere at gmail.com> wrote:
>> > Many thanks Ista. I will try other routes as well.
>> > Thanks Jeff and sorry for posting without abiding by the rules.
>> > Thanks James. I would rather automate this than download manually
>> > everytime. That is my intent.
>> >
>> > Best
>> > Balaji
>> >
>> >
>> > On Tue, Jul 15, 2014 at 7:16 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> >
>> >> Not an R question, but see
>> >> https://addons.mozilla.org/en-US/firefox/addon/cliget/ for an easy way
>> >> to see what what is going on under the hood when you download using
>> >> firefox. For your example I get
>> >>
>> >> wget --header='Host: www.nseindia.com' --header='User-Agent:
>> >> Mozilla/5.0 (X11; Linux x86_64; rv:30.0) Gecko/20100101 Firefox/30.0'
>> >> --header='Accept:
>> >> text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
>> >> --header='Accept-Language: en-US,en;q=0.5' --header='Connection:
>> >> keep-alive' '
>> >>
>> >> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> >> '
>> >> -O 'fo09JUL2014bhav.csv.zip' -c
>> >>
>> >> Now you just need to translate that to R. (Or not, sometimes its
>> >> easier to just shell out (using e.g., 'system()' ) and download with
>> >> wget or curl).
>> >>
>> >> Best,
>> >> Ista
>> >>
>> >> On Tue, Jul 15, 2014 at 11:24 AM, Electron Musketeer
>> >> <musketeere at gmail.com> wrote:
>> >> > Dear Experts
>> >> >
>> >> > I am new to this forum and to R and was trying the following to
>> >> > access a
>> >> > zip file from  the webpages of the NSE. Here is my code.
>> >> >
>> >> > temp <- tempfile()
>> >> > download.file("
>> >> >
>> >>
>> >> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> >> > ",temp)
>> >> > con <- unz(temp, "a1.dat")
>> >> > data <- matrix(scan(con),ncol=4,byrow=TRUE)
>> >> > unlink(temp)
>> >> >
>> >> >
>> >> > The result is:
>> >> > cannot open URL '
>> >> >
>> >>
>> >> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> >> > '
>> >> > In addition: Warning message:
>> >> > In download.file("
>> >> >
>> >>
>> >> http://www.nseindia.com/content/historical/DERIVATIVES/2014/JUL/fo09JUL2014bhav.csv.zip
>> >> ",
>> >> >  :
>> >> >   cannot open: HTTP status was '403 Forbidden'
>> >> >
>> >> >
>> >> > I tried accessing this file directly from the website and it is
>> >> > letting
>> >> me
>> >> > access it. My question is why is it not letting me download from R? I
>> >> have
>> >> > gone through some websites to see if this has been resolved but the
>> >> > older
>> >> > resolutions also do not work. Can someone help please?
>> >> >
>> >> > Thx
>> >> > Balaji
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From Ingrid.Charvet at rms.com  Thu Jul 17 15:09:46 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Thu, 17 Jul 2014 06:09:46 -0700
Subject: [R] Definition of the shape paramter in PERT (mc2d)
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD04E07CB1@MAILCA6.rms.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/da51bbdc/attachment.pl>

From j.a.timms at newcastle.ac.uk  Thu Jul 17 13:32:13 2014
From: j.a.timms at newcastle.ac.uk (Jessica Timms)
Date: Thu, 17 Jul 2014 11:32:13 +0000
Subject: [R] Model for lm keeps producing an error
Message-ID: <1405596732995.42109@newcastle.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/0245b5fd/attachment.pl>

From gangchen6 at gmail.com  Thu Jul 17 17:39:56 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 17 Jul 2014 11:39:56 -0400
Subject: [R] Mapping from one vector to another
In-Reply-To: <CAM_vjumE_8H936FpC1mNsDqv-yXY2s0wxyeLEC1KaUtciTvwKw@mail.gmail.com>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
	<CAM_vjumE_8H936FpC1mNsDqv-yXY2s0wxyeLEC1KaUtciTvwKw@mail.gmail.com>
Message-ID: <CAHmzXO7JNJp-sokSW0snDtHKTGi7X2Q9CFSOGyLBL44XUy22gQ@mail.gmail.com>

Thanks a lot for the quick and elegant solutions, Sarah, Bill and
Petr! I really appreciate it, including the suggestion of setting a
random seed. Have a nice day!

Gang

On Thu, Jul 17, 2014 at 11:15 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> What about:
>
> d$var <- c(8, 11, 3, 2)[d$fac]
>
> Side note: it's much appreciated that you included data and a clear
> problem statement. If you use
> set.seed(123)
> before your call to sample(), everyone who tries it will get the same
> fac that you do. Otherwise we all get something different. Or just
> generate your own example data and use dput() to include it in your
> email.
>
> Sarah
>
> On Thu, Jul 17, 2014 at 11:00 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>> Suppose I have the following dataframe:
>>
>> L4 <- LETTERS[1:4]
>> fac <- sample(L4, 10, replace = TRUE)
>> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>>
>>      x  y  fac
>> 1  1  1   B
>> 2  1  2   B
>> 3  1  3   D
>> 4  1  4   A
>> 5  1  5   C
>> 6  1  6   D
>> 7  1  7   C
>> 8  1  8   B
>> 9  1  9   B
>> 10 1 10   B
>>
>> I'd like to add another column 'var' that is defined based on the
>> following mapping of column 'fac':
>>
>> A -> 8
>> B -> 11
>> C -> 3
>> D -> 2
>>
>> How can I achieve this in an elegant way (with a generic approach for
>> any length)?
>>
>> Thanks,
>> Gang
>>
> --
> Sarah Goslee
> http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Thu Jul 17 17:53:25 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 17 Jul 2014 11:53:25 -0400
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
Message-ID: <CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>

Hi,

You can get the behaviour you want using the print() command:

if(1 < 2)
{
  x<-rnorm(100)
  y <- rpois(10, 5)
  print(head(x))
  print(head(y))
}


Sarah

On Thu, Jul 17, 2014 at 2:00 AM, Dario Strbenac
<dstr7320 at uni.sydney.edu.au> wrote:
> Hello,
>
> I have a block of code that has two head calls at the end, but only the second is shown on screen. If I manually execute the statement which is not showing, it works. I thought that if statements are not functions. It is behaving as one.
>
>> if(1 < 2)
> + {
> +   x<-rnorm(100)
> +   y <- rpois(10, 5)
> +   head(x)
> +   head(y)
> + }
> [1] 4 4 5 4 8 3
>>
>> head(x)
> [1] -1.89083874  0.42442102  0.96114276  0.48004716  1.94358108 -0.02654324
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From shashank_guptapnp at yahoo.com  Thu Jul 17 06:53:37 2014
From: shashank_guptapnp at yahoo.com (shashank guptanp)
Date: Wed, 16 Jul 2014 21:53:37 -0700
Subject: [R] information
Message-ID: <1405572817.32018.YahooMailNeo@web163303.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140716/435df932/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 17 08:00:12 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Jul 2014 23:00:12 -0700
Subject: [R] how to subset based on other row values and multiplicity
In-Reply-To: <CAF8bMcbFoh-12Oo_or8LevVfYrgDCvYjhGm2rFz86WqguTyP3g@mail.gmail.com>
References: <CFECB67F.1EF38%scott.williams@petermac.org>
	<1405522173.13727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAF8bMcbFoh-12Oo_or8LevVfYrgDCvYjhGm2rFz86WqguTyP3g@mail.gmail.com>
Message-ID: <1405576812.48880.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Bill,

Modifying `f2` seems to solve the problem.

f2 <- function (data)
{
??? library(dplyr)
??? data%>% 
??? group_by(id, value) %>%
??? mutate(date=as.Date(date))%>% 
??? arrange(date) %>% 
??? filter(indx =any(c(abs(diff(date)),NA) >31)& date==min(date)) %>% 
??? filter(row_number()==1)

}

?f2(dat)
Source: local data frame [3 x 3]
Groups: id, value

? id?????? date value
1? a 2000-01-01???? x
2? c 2000-09-10???? y
3? c 2000-10-11???? z

f2(dat1)
Source: local data frame [1 x 3]
Groups: id, value

? id value?????? date
1? A???? x 2000-10-02



A.K.


On Wednesday, July 16, 2014 4:25 PM, William Dunlap <wdunlap at tibco.com> wrote:
> filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))

Note that the 'date == min(date)' will cause superfluous output rows
when there are several readings on initial date for a given id/value
pair.? E.g.,

> dat1 <- data.frame(stringsAsFactors=FALSE, id=rep("A", 4), value=rep("x", 4), date=as.Date("2000-10-1")+c(1,1,50,50))
> f2(dat1) # want 1 output row: A, x, 2000-10-2
Source: local data frame [2 x 3]
Groups: id, value

? id value? ? ?  date
1? A? ?  x 2000-10-02
2? A? ?  x 2000-10-02

where f2 is your code wrapped up in a function (to make testing and use easier)

f2 <- function (data)
{
? ? library(dplyr)
? ? data %>% group_by(id, value) %>% arrange(date = as.Date(date)) %>%
? ? ? ? filter(any(c(abs(diff(as.Date(date))), NA) > 31) & date == min(date))
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jul 16, 2014 at 7:49 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> If `dat` is the dataset
>
> library(dplyr)
> dat%>%
> group_by(id,value)%>%
>
> arrange(date=as.Date(date))%>%
> filter(any(c(abs(diff(as.Date(date))),NA)>31)& date == min(date))
> #Source: local data frame [3 x 3]
> #Groups: id, value
> #
> #? id? ? ?  date value
> #1? a 2000-01-01? ?  x
> #2? c 2000-09-10? ?  y
> #3? c 2000-10-11? ?  z
> A.K.
>
>
>
>
> On Wednesday, July 16, 2014 9:10 AM, Williams Scott <Scott.Williams at petermac.org> wrote:
> Hi R experts,
>
> I have a dataset as sampled below. Values are only regarded as ?confirmed?
> in an individual (?id?) if they occur
> more than once at least 30 days apart.
>
>
> id?  date value
> a? ? 2000-01-01 x
> a? ? 2000-03-01 x
> b? ? 2000-11-11 w
> c? ? 2000-11-11 y
> c? ? 2000-10-01 y
> c? ? 2000-09-10 y
> c? ? 2000-12-12 z
> c? ? 2000-10-11 z
> d? ? 2000-11-11 w
> d? ? 2000-11-10 w
>
>
> I wish to subset the data to retain rows where the value for the
> individual is confirmed more than 30 days apart. So, after deleting all
> rows with just one occurrence of id and value, the rest would be the
> earliest occurrence of each value in each case id, provided 31 or more
> days exist between the dates. If >1 value is present per id, each value
> level needs to be assessed independently. This example would then reduce
> to:
>
>
> id?  date? ? ? ? ?  value
> a? ? 2000-01-01 x
> c? ? 2000-09-10 y
> c? ? 2000-10-11 z
>
>
>
> I can do this via some crude loops and subsetting, but I am looking for as
> much efficiency as possible
> as the dataset has around 50 million rows to assess. Any suggestions
> welcomed.
>
> Thanks in advance
>
> Scott Williams MD
> Melbourne, Australia
>
>
>
> This email (including any attachments or links) may contain
> confidential and/or legally privileged information and is
> intended only to be read or used by the addressee.? If you
> are not the intended addressee, any use, distribution,
> disclosure or copying of this email is strictly
> prohibited.
> Confidentiality and legal privilege attached to this email
> (including any attachments) are not waived or lost by
> reason of its mistaken delivery to you.
> If you have received this email in error, please delete it
> and notify us immediately by telephone or email.? Peter
> MacCallum Cancer Centre provides no guarantee that this
> transmission is free of virus or that it has not been
> intercepted or altered and will not be liable for any delay
> in its receipt.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jul 17 18:06:45 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 17 Jul 2014 09:06:45 -0700 (PDT)
Subject: [R] Mapping from one vector to another
In-Reply-To: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1407170854120.3826@pedal.dcn.davis.ca.us>

You ask about generic methods for introducing alternate values for 
factors, and some of the other responses address this quite efficiently.

However, a factor has meaning only within one vector at a time, since
another vector may have additional values or missing values relative to
the first vector. For example, you used the "sample" function which
is not guaranteed to select at least one of each of the four letters in 
L4. Or, what if the data has values the mapping doesn't address?

For any work in which I am dealing with categorical data in multiple
places (e.g. your "d" data frame and whatever data structure you use
to define your mapping) I prefer NOT to work with factors until all of
my categories of data are moved into one vector (typically a column
in a data frame). Rather, I work with character vectors during the
data manipulation phase and only convert to factor when I start
analyzing or displaying the data.

With this in mind, I use a general flow something like:

d <- data.frame( x = 1, y = 1:10, fac = fac, stringsAsFactors=FALSE )
mp <- data.frame( fac=LETTERS[1:4], value=c(8,11,3,2) )
d2 <- merge( d, mp, all.x=TRUE )
d2$fac <- factor( d2$fac ) # optional

If you actually are in the analysis phase and are not pulling data from 
multiple external sources, then you may have already confirmed the 
completeness and range of values you have to work with then one of the 
other more efficient methods may still be a better choice for this 
specific task.

Hadley Wickham's "tidy data" [1] principles address this concern more 
thoroughly than I have.

[1] Google this phrase... paper seems to be a work in progress.

On Thu, 17 Jul 2014, Gang Chen wrote:

> Suppose I have the following dataframe:
>
> L4 <- LETTERS[1:4]
> fac <- sample(L4, 10, replace = TRUE)
> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>
>     x  y  fac
> 1  1  1   B
> 2  1  2   B
> 3  1  3   D
> 4  1  4   A
> 5  1  5   C
> 6  1  6   D
> 7  1  7   C
> 8  1  8   B
> 9  1  9   B
> 10 1 10   B
>
> I'd like to add another column 'var' that is defined based on the
> following mapping of column 'fac':
>
> A -> 8
> B -> 11
> C -> 3
> D -> 2
>
> How can I achieve this in an elegant way (with a generic approach for
> any length)?
>
> Thanks,
> Gang
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Thu Jul 17 18:25:44 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 17 Jul 2014 09:25:44 -0700 (PDT)
Subject: [R] information
In-Reply-To: <1405572817.32018.YahooMailNeo@web163303.mail.gq1.yahoo.com>
References: <1405572817.32018.YahooMailNeo@web163303.mail.gq1.yahoo.com>
Message-ID: <alpine.BSF.2.00.1407170907420.3826@pedal.dcn.davis.ca.us>

You should read the Posting Guide for the r-help list, and the list 
control web page. One problem with your post is that the r-help-request 
address is not for asking questions. Another problem is that cross-posting 
to multiple lists would not have been polite anyway.

Your question is really too vague... you need to provide some context to 
keep the scope of answers manageable. For instance, if you don't know how 
to use R at all, then you will need to work your way through some 
introductory material on R (one such document is supplied with the 
software). If you have specific questions that include working or broken R 
code while you learn R then this would be a fine forum to ask questions 
about that. If you don't actually know the theory of what you are trying 
to do (I certainly don't), then you will need to obtain instruction in 
that somewhere else.

Have you encountered the Statistical Genetics Task View web page on CRAN? 
[1]

[1] http://cran.r-project.org/web/views/Genetics.html

On Wed, 16 Jul 2014, shashank guptanp wrote:

> Hello,
> i am working on a metagenomics, and analyzing a genome of different
> sample using QIIME tools, will you tell me how can i use R Program for
> metagenome analysis.
>
> Regards.Shashank Gupta
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ruipbarradas at sapo.pt  Thu Jul 17 18:27:56 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 17 Jul 2014 17:27:56 +0100
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
Message-ID: <53C7F98C.8030803@sapo.pt>

Hello,

Also, unlike what the op says, if statements are functions, explaining 
the behavior he got.

Hope this helps,

Rui Barradas

Em 17-07-2014 16:53, Sarah Goslee escreveu:
> Hi,
>
> You can get the behaviour you want using the print() command:
>
> if(1 < 2)
> {
>    x<-rnorm(100)
>    y <- rpois(10, 5)
>    print(head(x))
>    print(head(y))
> }
>
>
> Sarah
>
> On Thu, Jul 17, 2014 at 2:00 AM, Dario Strbenac
> <dstr7320 at uni.sydney.edu.au> wrote:
>> Hello,
>>
>> I have a block of code that has two head calls at the end, but only the second is shown on screen. If I manually execute the statement which is not showing, it works. I thought that if statements are not functions. It is behaving as one.
>>
>>> if(1 < 2)
>> + {
>> +   x<-rnorm(100)
>> +   y <- rpois(10, 5)
>> +   head(x)
>> +   head(y)
>> + }
>> [1] 4 4 5 4 8 3
>>>
>>> head(x)
>> [1] -1.89083874  0.42442102  0.96114276  0.48004716  1.94358108 -0.02654324
>>
>>> sessionInfo()
>> R version 3.1.1 (2014-07-10)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>


From jdnewmil at dcn.davis.ca.us  Thu Jul 17 18:31:21 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 17 Jul 2014 09:31:21 -0700 (PDT)
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
Message-ID: <alpine.BSF.2.00.1407170929400.3826@pedal.dcn.davis.ca.us>

This question is related to FAQ 7.16, which you should look up.

In general, whenever you just type a variable or function directly at the 
command line, R prints the result for you. Inside code blocks of any kind, 
it does not do that, so you need to use the print function yourself.

On Thu, 17 Jul 2014, Dario Strbenac wrote:

> Hello,
>
> I have a block of code that has two head calls at the end, but only the second is shown on screen. If I manually execute the statement which is not showing, it works. I thought that if statements are not functions. It is behaving as one.
>
>> if(1 < 2)
> + {
> +   x<-rnorm(100)
> +   y <- rpois(10, 5)
> +   head(x)
> +   head(y)
> + }
> [1] 4 4 5 4 8 3
>>
>> head(x)
> [1] -1.89083874  0.42442102  0.96114276  0.48004716  1.94358108 -0.02654324
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From gangchen6 at gmail.com  Thu Jul 17 18:45:27 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 17 Jul 2014 12:45:27 -0400
Subject: [R] Mapping from one vector to another
In-Reply-To: <alpine.BSF.2.00.1407170854120.3826@pedal.dcn.davis.ca.us>
References: <CAHmzXO7vMVr83APnv4xucjyFz5K3qj6JWWwvZTXKyycmVJ2DSA@mail.gmail.com>
	<alpine.BSF.2.00.1407170854120.3826@pedal.dcn.davis.ca.us>
Message-ID: <CAHmzXO57j7i3wZEhPDfZx31Vq+Ku=-XiB+1DZ=M1vvu-3x+6Pw@mail.gmail.com>

Jeff,

Even though the solutions from the previous responders are good enough
for my current situation, the principle you just raised will be
definitely beneficial to your future work. Thanks a lot for sharing
the insights!

Gang

On Thu, Jul 17, 2014 at 12:06 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You ask about generic methods for introducing alternate values for factors,
> and some of the other responses address this quite efficiently.
>
> However, a factor has meaning only within one vector at a time, since
> another vector may have additional values or missing values relative to
> the first vector. For example, you used the "sample" function which
> is not guaranteed to select at least one of each of the four letters in L4.
> Or, what if the data has values the mapping doesn't address?
>
> For any work in which I am dealing with categorical data in multiple
> places (e.g. your "d" data frame and whatever data structure you use
> to define your mapping) I prefer NOT to work with factors until all of
> my categories of data are moved into one vector (typically a column
> in a data frame). Rather, I work with character vectors during the
> data manipulation phase and only convert to factor when I start
> analyzing or displaying the data.
>
> With this in mind, I use a general flow something like:
>
> d <- data.frame( x = 1, y = 1:10, fac = fac, stringsAsFactors=FALSE )
> mp <- data.frame( fac=LETTERS[1:4], value=c(8,11,3,2) )
> d2 <- merge( d, mp, all.x=TRUE )
> d2$fac <- factor( d2$fac ) # optional
>
> If you actually are in the analysis phase and are not pulling data from
> multiple external sources, then you may have already confirmed the
> completeness and range of values you have to work with then one of the other
> more efficient methods may still be a better choice for this specific task.
>
> Hadley Wickham's "tidy data" [1] principles address this concern more
> thoroughly than I have.
>
> [1] Google this phrase... paper seems to be a work in progress.
>
>
> On Thu, 17 Jul 2014, Gang Chen wrote:
>
>> Suppose I have the following dataframe:
>>
>> L4 <- LETTERS[1:4]
>> fac <- sample(L4, 10, replace = TRUE)
>> (d <- data.frame(x = 1, y = 1:10, fac = fac))
>>
>>     x  y  fac
>> 1  1  1   B
>> 2  1  2   B
>> 3  1  3   D
>> 4  1  4   A
>> 5  1  5   C
>> 6  1  6   D
>> 7  1  7   C
>> 8  1  8   B
>> 9  1  9   B
>> 10 1 10   B
>>
>> I'd like to add another column 'var' that is defined based on the
>> following mapping of column 'fac':
>>
>> A -> 8
>> B -> 11
>> C -> 3
>> D -> 2
>>
>> How can I achieve this in an elegant way (with a generic approach for
>> any length)?
>>
>> Thanks,
>> Gang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From emmanuel.blondel1 at gmail.com  Thu Jul 17 19:21:43 2014
From: emmanuel.blondel1 at gmail.com (Emmanuel Blondel)
Date: Thu, 17 Jul 2014 19:21:43 +0200
Subject: [R] Reading SDMX Files in R
In-Reply-To: <op.w9zn7iupzqkd1e@enea>
References: <op.w9zn7iupzqkd1e@enea>
Message-ID: <53C80627.1000703@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/214461d9/attachment.pl>

From albmont at centroin.com.br  Thu Jul 17 21:19:01 2014
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Thu, 17 Jul 2014 16:19:01 -0300
Subject: [R] Equivalent of chartr to numeric
Message-ID: <CAEyj4=_A3Ze0afpPiJXjKoV3xn0UDDaus0==LQCbou+xDwPyyg@mail.gmail.com>

Is there any equivalent to chartr for numeric values?

Meaning, something like:

numerictr(c(-1, 42, 666), 1:3, numeric.stuff)

that replaces in "numeric.stuff" (a vector, matrix, etc) all instances
of -1 for 1, 42 for 2 and 666 for 3?

Alberto Monteiro


From mkbartl at gmail.com  Thu Jul 17 21:23:25 2014
From: mkbartl at gmail.com (Megan Bartlett)
Date: Thu, 17 Jul 2014 12:23:25 -0700
Subject: [R] Correlating multiple effect sizes within a study to
 study-level predictors: metafor package
In-Reply-To: <Zen-1X7jH7-0004m7-TJ@smarthost01a.mail.zen.net.uk>
References: <CAB2zMEHhPkRhbtXZ9bBRPGOxkg2TSK8TKnwbZNpfyHS=F-qNJg@mail.gmail.com>
	<Zen-1X6fa9-00014i-M2@smarthost01c.mail.zen.net.uk>
	<077E31A57DA26E46AB0D493C9966AC730DC6AF9D7E@UM-MAIL4112.unimaas.nl>
	<CAB2zMEEtQpaXby2J+D07TEwg10BOPyitRPGEAvDjS_7G9B8HhQ@mail.gmail.com>
	<Zen-1X7Kxh-000G9u-6u@smarthost01c.mail.zen.net.uk>
	<CAB2zMEGV=hqfdHOKbSL2ThGtzBS3tbVrUzVAQSExp_NVOPSGpg@mail.gmail.com>
	<Zen-1X7jH7-0004m7-TJ@smarthost01a.mail.zen.net.uk>
Message-ID: <CAB2zMEEdf_37pQ2sCXLgMMB9vksrr9DeXBjNE7q7JGkTRoErbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140717/e78ae62e/attachment.pl>

From albmont at centroin.com.br  Thu Jul 17 21:28:33 2014
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Thu, 17 Jul 2014 16:28:33 -0300
Subject: [R] Equivalent of chartr to numeric
In-Reply-To: <CAEyj4=_A3Ze0afpPiJXjKoV3xn0UDDaus0==LQCbou+xDwPyyg@mail.gmail.com>
References: <CAEyj4=_A3Ze0afpPiJXjKoV3xn0UDDaus0==LQCbou+xDwPyyg@mail.gmail.com>
Message-ID: <CAEyj4=_nnoUusjwZDX-Vo9tngkb0OUiq3cop9=6cBShGsnD4Wg@mail.gmail.com>

Replying to self:
>
> Is there any equivalent to chartr for numeric values?
>
> Meaning, something like:
>
> numerictr(c(-1, 42, 666), 1:3, numeric.stuff)
>
> that replaces in "numeric.stuff" (a vector, matrix, etc) all instances
> of -1 for 1, 42 for 2 and 666 for 3?
>
match does it. Sorry to ask.

Alberto Monteiro


From dwinsemius at comcast.net  Fri Jul 18 01:32:26 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Jul 2014 16:32:26 -0700
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <53C7F98C.8030803@sapo.pt>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
	<53C7F98C.8030803@sapo.pt>
Message-ID: <C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>


On Jul 17, 2014, at 9:27 AM, Rui Barradas wrote:

> Hello,
> 
> Also, unlike what the op says, if statements are functions, explaining the behavior he got.

I'm not sure that is correct. The help page says if() is a control-construct. I think the function is actually "{"

> {rnorm(10); rpois(10, 3)}
 [1] 5 3 5 5 7 3 4 4 0 5

See

?Paren

-- 
David.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 17-07-2014 16:53, Sarah Goslee escreveu:
>> Hi,
>> 
>> You can get the behaviour you want using the print() command:
>> 
>> if(1 < 2)
>> {
>>   x<-rnorm(100)
>>   y <- rpois(10, 5)
>>   print(head(x))
>>   print(head(y))
>> }
>> 
>> 
>> Sarah
>> 
>> On Thu, Jul 17, 2014 at 2:00 AM, Dario Strbenac
>> <dstr7320 at uni.sydney.edu.au> wrote:
>>> Hello,
>>> 
>>> I have a block of code that has two head calls at the end, but only the second is shown on screen. If I manually execute the statement which is not showing, it works. I thought that if statements are not functions. It is behaving as one.
>>> 
>>>> if(1 < 2)
>>> + {
>>> +   x<-rnorm(100)
>>> +   y <- rpois(10, 5)
>>> +   head(x)
>>> +   head(y)
>>> + }
>>> [1] 4 4 5 4 8 3
>>>> 
>>>> head(x)
>>> [1] -1.89083874  0.42442102  0.96114276  0.48004716  1.94358108 -0.02654324
>>> 
>>>> sessionInfo()
>>> R version 3.1.1 (2014-07-10)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Fri Jul 18 03:48:03 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 18 Jul 2014 13:48:03 +1200
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>	<53C7F98C.8030803@sapo.pt>
	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>
Message-ID: <53C87CD3.4020507@auckland.ac.nz>

On 18/07/14 11:32, David Winsemius wrote:
>
> On Jul 17, 2014, at 9:27 AM, Rui Barradas wrote:
>
>> Hello,
>>
>> Also, unlike what the op says, if statements are functions, explaining the behavior he got.
>
> I'm not sure that is correct. The help page says if() is a control-construct. I think the function is actually "{"
>
>> {rnorm(10); rpois(10, 3)}
>   [1] 5 3 5 5 7 3 4 4 0 5
>
> See
>
> ?Paren

It has nothing to do either with if() or Paren.  It is the ***user's*** 
function that is suppressing the output.  Consider:

foo <- function(){
x <- 17
x
y <- 42
y
}

If you type foo() you get

[1] 42

which is the *value returned by the function.  The value of the "x" 
statement inside foo() is made invisible (and would have to be enclosed 
by print() to be made visible).

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From gunter.berton at gene.com  Fri Jul 18 04:50:03 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 17 Jul 2014 19:50:03 -0700
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <53C87CD3.4020507@auckland.ac.nz>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
	<53C7F98C.8030803@sapo.pt>
	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>
	<53C87CD3.4020507@auckland.ac.nz>
Message-ID: <CACk-te3QpyXHc=OoDFwRjis5LL+KDjUBmzs-Fz11Py1+5ys3yg@mail.gmail.com>

Rolf et.al

I have not followed this thread closely and so have nothing to say
about whose or what explanation is correct.

However, the following statement is misleading, if not wrong:

---------------------------
foo <- function(){
x <- 17
x
y <- 42
y
}

If you type foo() you get

[1] 42

which is the *value returned by the function.  *****The value of the
"x" statement inside foo() is made invisible *****(and would have to
be enclosed by print() to be made visible).

-------------
The reason I consider the asterisked passage misleading is that this
is a matter of scope. "made invisible" implies some sort of
legerdemain.  The "x" defined within the function only exists within
the function environment and the binding of the symbol "x" to the
value there disappears when the function returns (as you well know).

ergo:

> x <- 1
>
> foo<- function() {
+   x <- 2
+   x
+ }
>
> foo()
[1] 2
> x
[1] 1

Also, in general, printing from within a function is a side effect and
is generally discouraged in functional style program in favor of
explicitly returning the results. However, this is honored as much in
the breach as the observance as, for example, that;s the way most of
traditional R graphics works.

Anyway, the horse is now well and truly dead, I think.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Jul 17, 2014 at 6:48 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 18/07/14 11:32, David Winsemius wrote:
>>
>>
>> On Jul 17, 2014, at 9:27 AM, Rui Barradas wrote:
>>
>>> Hello,
>>>
>>> Also, unlike what the op says, if statements are functions, explaining
>>> the behavior he got.
>>
>>
>> I'm not sure that is correct. The help page says if() is a
>> control-construct. I think the function is actually "{"
>>
>>> {rnorm(10); rpois(10, 3)}
>>
>>   [1] 5 3 5 5 7 3 4 4 0 5
>>
>> See
>>
>> ?Paren
>
>
> It has nothing to do either with if() or Paren.  It is the ***user's***
> function that is suppressing the output.  Consider:
>
> foo <- function(){
> x <- 17
> x
> y <- 42
> y
> }
>
> If you type foo() you get
>
> [1] 42
>
> which is the *value returned by the function.  The value of the "x"
> statement inside foo() is made invisible (and would have to be enclosed by
> print() to be made visible).
>
> cheers,
>
> Rolf
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dstr7320 at uni.sydney.edu.au  Fri Jul 18 05:00:09 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 18 Jul 2014 03:00:09 +0000
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <53C87CD3.4020507@auckland.ac.nz>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
	<53C7F98C.8030803@sapo.pt>
	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
Message-ID: <1405652409062.49813@uni.sydney.edu.au>

The example in the question was not inside a user function.

From stefano.sofia at regione.marche.it  Fri Jul 18 09:07:04 2014
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 18 Jul 2014 07:07:04 +0000
Subject: [R] Use of different colours in plot
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/fd607eca/attachment.pl>

From petr.pikal at precheza.cz  Fri Jul 18 09:22:25 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 18 Jul 2014 07:22:25 +0000
Subject: [R] Model for lm keeps producing an error
In-Reply-To: <1405596732995.42109@newcastle.ac.uk>
References: <1405596732995.42109@newcastle.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDBD6E@SRVEXCHMBX.precheza.cz>

Hi

No reproducible example so lust general comments.

1. Your function does not return any value
2. You do not get errors but only warnings
3. In your function you get results only for X1. Is it really your intention?
4. I do not know mclapply but from quick look into help page parameters you use for your function shall be named vector or list so something like

list(meth_matrix=cord_betas, exposure=filtered_pheno$Number3Mth, X1=covariates$k032,
X2=covariates$k021, X3=covariates$kz029, batch=pdata.B1221.cord$BCDPlate)

I would just try to use your function interactively on one item from
setNames(seq_len(ncol(cord_betas)),dimnames(cord_betas)[[2]])

Do you get result?

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jessica Timms
> Sent: Thursday, July 17, 2014 1:32 PM
> To: r-help at r-project.org
> Subject: [R] Model for lm keeps producing an error
>
> Hi,
>
>
>
> I still seem to be getting errors from trying to run my altered R
> script, any advice?
>
>
>
> Thanks
>
> Jess
>
>
>
> Model1A = function(meth_matrix,exposure, X1, X2, X3, batch) {
> +
> +   mod = lm(methcol ~ exposure+X1+X2+X3+batch, data = meth_matrix)
> +
> +
> +   res=coef(summary(mod))[2,]
> +
> +
> + }
> >
> >
> > ##Run model1A####
> >
> > system.time(indiv.results <-
> mclapply(setNames(seq_len(ncol(cord_betas)),
> dimnames(cord_betas)[[2]]), Model1A, meth_matrix=cord_betas,
> exposure=filtered_pheno$Number3Mth, X1=covariates$k032,
> X2=covariates$k021, X3=covariates$kz029,
> batch=pdata.B1221.cord$BCDPlate))
>    user  system elapsed
>   0.044   0.526   0.272
> Warning message:
> In mclapply(setNames(seq_len(ncol(cord_betas)),
> dimnames(cord_betas)[[2]]),  :
>   all scheduled cores encountered errors in user code
>
> >
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jim at bitwrit.com.au  Fri Jul 18 10:22:01 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 18 Jul 2014 18:22:01 +1000
Subject: [R] Use of different colours in plot
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>
Message-ID: <1604130.WrmbdqJx23@localhost.localdomain>

On Fri, 18 Jul 2014 07:07:04 AM Stefano Sofia wrote:
> Dear R list users,
> I have a data frame called catchment like
> 
> "year" "season" "rainfall" "colour"
> 1953 1 409.5 "black"
> 1953 2 145.3 "black"
> 1953 3 285.6 "red"
> 1953 4 275.0 "black"
> 1954 1 273.8 "black"
> 1954 2 342.8 "blue"
> 1954 3 167.6 "black"
> 1954 4 341.1 "black"
> 1955 1 182.3 "blue"
> 1955 2 211.8 "black"
> 1955 3 222.6 "black"
> 1955 4 522.1 "black"
> 1956 1 248.7 "red"
> 1956 2 244.9 "black"
> ...
> 
> and I would like to plot it with the colours specified in the column 
colour
> (at the moment the colours are three: black, red and blue. I would 
like to
> have the possibility to add oher colours to this list).
 With
> 
> plot(catchment$year, catchment$rainfall, main="River Aso", 
xlab="years",
> ylab="mm", type="p", col=catchment$colour)
 
> the colours displayed in the graph are not the ones I have chosen.
> I looked for the answer, which probably involves a transformation to 
factor,
> but I am not able to understand well the solution.
 Could somebody help me?
> 
> Thank you
> Stefano Sofia
> 
Hi Stefano,
Try this:

plot(catchment$year, catchment$rainfall,
 main="River Aso", xlab="years",
 ylab="mm", type="p",
 col=as.character(catchment$colour))

Jim


From stefano.sofia at regione.marche.it  Fri Jul 18 10:45:14 2014
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 18 Jul 2014 08:45:14 +0000
Subject: [R] Use of different colours in plot
In-Reply-To: <1604130.WrmbdqJx23@localhost.localdomain>
References: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>,
	<1604130.WrmbdqJx23@localhost.localdomain>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0E323940@ESINO.regionemarche.intra>

Thank you Jim, perfect.
________________________________________
Da: Jim Lemon [jim at bitwrit.com.au]
Inviato: venerd? 18 luglio 2014 10.22
A: r-help at r-project.org
Cc: Stefano Sofia
Oggetto: Re: [R] Use of different colours in plot

On Fri, 18 Jul 2014 07:07:04 AM Stefano Sofia wrote:
> Dear R list users,
> I have a data frame called catchment like
>
> "year" "season" "rainfall" "colour"
> 1953 1 409.5 "black"
> 1953 2 145.3 "black"
> 1953 3 285.6 "red"
> 1953 4 275.0 "black"
> 1954 1 273.8 "black"
> 1954 2 342.8 "blue"
> 1954 3 167.6 "black"
> 1954 4 341.1 "black"
> 1955 1 182.3 "blue"
> 1955 2 211.8 "black"
> 1955 3 222.6 "black"
> 1955 4 522.1 "black"
> 1956 1 248.7 "red"
> 1956 2 244.9 "black"
> ...
>
> and I would like to plot it with the colours specified in the column
colour
> (at the moment the colours are three: black, red and blue. I would
like to
> have the possibility to add oher colours to this list).
 With
>
> plot(catchment$year, catchment$rainfall, main="River Aso",
xlab="years",
> ylab="mm", type="p", col=catchment$colour)

> the colours displayed in the graph are not the ones I have chosen.
> I looked for the answer, which probably involves a transformation to
factor,
> but I am not able to understand well the solution.
 Could somebody help me?
>
> Thank you
> Stefano Sofia
>
Hi Stefano,
Try this:

plot(catchment$year, catchment$rainfall,
 main="River Aso", xlab="years",
 ylab="mm", type="p",
 col=as.character(catchment$colour))

Jim


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From joao.patricio at gmx.pt  Fri Jul 18 11:32:20 2014
From: joao.patricio at gmx.pt (=?windows-1252?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Fri, 18 Jul 2014 10:32:20 +0100
Subject: [R] Use of different colours in plot
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0E323866@ESINO.regionemarche.intra>
Message-ID: <53C8E9A4.6080508@gmx.pt>

Em 18-07-2014 08:07, Stefano Sofia escreveu:
> Dear R list users,
> I have a data frame called catchment like
>
> "year" "season" "rainfall" "colour"
> 1953 1 409.5 "black"
> 1953 2 145.3 "black"
> 1953 3 285.6 "red"
> 1953 4 275.0 "black"
> 1954 1 273.8 "black"
> 1954 2 342.8 "blue"
> 1954 3 167.6 "black"
> 1954 4 341.1 "black"
> 1955 1 182.3 "blue"
> 1955 2 211.8 "black"
> 1955 3 222.6 "black"
> 1955 4 522.1 "black"
> 1956 1 248.7 "red"
> 1956 2 244.9 "black"
> ...
>
> and I would like to plot it with the colours specified in the column colour (at the moment the colours are three: black, red and blue. I would like to have the possibility to add oher colours to this list).
> With
>
> plot(catchment$year, catchment$rainfall, main="River Aso", xlab="years", ylab="mm", type="p", col=catchment$colour)
>
> the colours displayed in the graph are not the ones I have chosen.
> I looked for the answer, which probably involves a transformation to factor, but I am not able to understand well the solution.
> Could somebody help me?
>
> Thank you
> Stefano Sofia
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
did you try the palette() function?

you can define a new like:

 > palette(c("black","red","blue"))

then you can call the colors by numbers (1,2,3)

replace the color name in the column by the respective 1,2,3 numbers ant 
give a try.

I haven't try it, but it's the "natural" way I can think of.

|

|



-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From spencer.graves at structuremonitoring.com  Fri Jul 18 12:39:48 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 18 Jul 2014 03:39:48 -0700
Subject: [R] QR code?
Message-ID: <53C8F974.8020609@structuremonitoring.com>

       Is there an R function to convert text to a QR Code?


       My search attempts yielded QR decompositions ;-)


       Thanks,
       Spencer


From r.turner at auckland.ac.nz  Fri Jul 18 13:02:11 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 18 Jul 2014 23:02:11 +1200
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <1405652409062.49813@uni.sydney.edu.au>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>	<53C7F98C.8030803@sapo.pt>	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
	<1405652409062.49813@uni.sydney.edu.au>
Message-ID: <53C8FEB3.7080602@auckland.ac.nz>

On 18/07/14 15:00, Dario Strbenac wrote:
> The example in the question was not inside a user function.

Don't be silly.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From emmanuel.blondel1 at gmail.com  Fri Jul 18 14:36:19 2014
From: emmanuel.blondel1 at gmail.com (Emmanuel Blondel)
Date: Fri, 18 Jul 2014 14:36:19 +0200
Subject: [R] Reading SDMX Files in R
In-Reply-To: <53C80627.1000703@gmail.com>
References: <53C80627.1000703@gmail.com>
Message-ID: <53C914C3.6020700@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/1c40fe62/attachment.pl>

From drnevich at illinois.edu  Fri Jul 18 16:47:15 2014
From: drnevich at illinois.edu (Zadeh, Jenny Drnevich)
Date: Fri, 18 Jul 2014 14:47:15 +0000
Subject: [R] modifications for ONLY local repository?
Message-ID: <CC8C9444924CB748B2DDD6EABA825E661D269E18@CITESMBX2.ad.uillinois.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/b49a0a95/attachment.pl>

From veroandreo at gmail.com  Fri Jul 18 15:15:35 2014
From: veroandreo at gmail.com (Veronica Andreo)
Date: Fri, 18 Jul 2014 10:15:35 -0300
Subject: [R] help with script to get starting date of blooms
Message-ID: <CAAMki4G2UPhQ=j3Dfg=eXdrudwGnzsjJCeVND7ospB4Pibzjog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/25989282/attachment.pl>

From muhammad.dogar at kaust.edu.sa  Fri Jul 18 16:39:14 2014
From: muhammad.dogar at kaust.edu.sa (Muhammad Dogar)
Date: Fri, 18 Jul 2014 17:39:14 +0300
Subject: [R] Problem with residualPlots with type "rstudent"
Message-ID: <CAFx682gqAtSfyRdVV907KRsVfV9MeVOxDzaYn2O5Eq_coa3nNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/413d3137/attachment.pl>

From john.archie.mckown at gmail.com  Fri Jul 18 18:17:30 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 18 Jul 2014 11:17:30 -0500
Subject: [R] String comparison, trailing blanks make a difference.
Message-ID: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>

Well, this was a shock to me. And I don't really see any documentation
about it, but perhaps I just can't see it.

>"abc" == "abc "
[1] FALSE

I guess that I thought of strings in R like I do is some other
languages where the shorter value is padded with blanks to the length
of the longer value, then compared. I.e. that trailing blanks didn't
matter.

The best solution that I have found is to use the str_trim() function
from the stringr to remove all the trailing blanks after I get the
data from the SQL data base. I cannot change the SQL schema to make
the column a varchar instead of a char column. It is a vendor DB. And
I don't know an ANSI SQL standard way to remove trailing blanks in the
SELECT command. PostgreSQL has a "trim(trailing ' ' from column)', but
MS-SQL upchucks on that syntax.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From wdunlap at tibco.com  Fri Jul 18 18:32:36 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Jul 2014 09:32:36 -0700
Subject: [R] String comparison, trailing blanks make a difference.
In-Reply-To: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
References: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
Message-ID: <CAF8bMcY2g6aZ76snG6V13s_oobSL6z8fjimJO3xu3qAWKmjvvw@mail.gmail.com>

>>"abc" == "abc "
> [1] FALSE

R does no interpretation of strings when doing comparisons so you do
have do your own canonicalization.  That may involve removing
trailing, leading, or all white space or punctuation, converting to
lower or upper case, mapping nicknames to official names, trimming to
a fixed number of characters, etc.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jul 18, 2014 at 9:17 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> Well, this was a shock to me. And I don't really see any documentation
> about it, but perhaps I just can't see it.
>
>>"abc" == "abc "
> [1] FALSE
>
> I guess that I thought of strings in R like I do is some other
> languages where the shorter value is padded with blanks to the length
> of the longer value, then compared. I.e. that trailing blanks didn't
> matter.
>
> The best solution that I have found is to use the str_trim() function
> from the stringr to remove all the trailing blanks after I get the
> data from the SQL data base. I cannot change the SQL schema to make
> the column a varchar instead of a char column. It is a vendor DB. And
> I don't know an ANSI SQL standard way to remove trailing blanks in the
> SELECT command. PostgreSQL has a "trim(trailing ' ' from column)', but
> MS-SQL upchucks on that syntax.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fhcrc.org  Fri Jul 18 19:56:43 2014
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 18 Jul 2014 10:56:43 -0700
Subject: [R] String comparison, trailing blanks make a difference.
In-Reply-To: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
References: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
Message-ID: <53C95FDB.90209@fhcrc.org>

Hi John,

On 07/18/2014 09:17 AM, John McKown wrote:
> Well, this was a shock to me. And I don't really see any documentation
> about it, but perhaps I just can't see it.
>
>> "abc" == "abc"
> [1] FALSE
>
> I guess that I thought of strings in R like I do is some other
> languages where the shorter value is padded with blanks to the length
> of the longer value, then compared. I.e. that trailing blanks didn't
> matter.

The shock to me is to learn that some programming languages consider
strings "abc" and "abc " to be the same. Please name them so I can stay
away from them ;-)

Thanks,
H.

>
> The best solution that I have found is to use the str_trim() function
> from the stringr to remove all the trailing blanks after I get the
> data from the SQL data base. I cannot change the SQL schema to make
> the column a varchar instead of a char column. It is a vendor DB. And
> I don't know an ANSI SQL standard way to remove trailing blanks in the
> SELECT command. PostgreSQL has a "trim(trailing ' ' from column)', but
> MS-SQL upchucks on that syntax.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From adib.mist at gmail.com  Fri Jul 18 19:00:22 2014
From: adib.mist at gmail.com (Adib Shafi)
Date: Fri, 18 Jul 2014 13:00:22 -0400
Subject: [R] understanding the parameters of 'spca' function of 'elasticnet'
	package
Message-ID: <53C952A6.5010704@gmail.com>

Hi all,

i am trying to use the 'spca' function of 'elasticnet' package. But i am
confused with the parameter 'para'.

Basically the parameter 'para' depends on the parameter 'sparse'. If
sparse="penalty", para is a vector of 1-norm penalty parameters. If
sparse="varnum",  para de?nes the number of sparse loadings to be obtained.

As my understanding, if i use sparse="penalty" i have to set the amount
of variance for each component in a vector. But how could i know the
amount of variance in this case?

If i use sparse='varnum', i have to set the number of features i want to
extract from each component in a vector. But i dont have these numbers
even because i dont know how many key features are present in each
component.

Thanks


From gunfifa12 at gmail.com  Fri Jul 18 19:12:19 2014
From: gunfifa12 at gmail.com (=?UTF-8?B?7Jik6rG07Z2s?=)
Date: Sat, 19 Jul 2014 02:12:19 +0900
Subject: [R] Problem in installing package "ggplot2"
Message-ID: <CAJbv6rCFK-MJGRC+oNMPyiDQrj4oyZvS01mGLq_FvJR2VSMP_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140719/0f9bb60a/attachment.pl>

From wdunlap at tibco.com  Fri Jul 18 22:11:58 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Jul 2014 13:11:58 -0700
Subject: [R] Problem in installing package "ggplot2"
In-Reply-To: <CAJbv6rCFK-MJGRC+oNMPyiDQrj4oyZvS01mGLq_FvJR2VSMP_A@mail.gmail.com>
References: <CAJbv6rCFK-MJGRC+oNMPyiDQrj4oyZvS01mGLq_FvJR2VSMP_A@mail.gmail.com>
Message-ID: <CAF8bMcY69Ce2NjxcZZzrx7sQmNg+v3pnuQkvVgTO2Jr+uEXJpQ@mail.gmail.com>

> install.packages("ggplot2",dependencies=T)
> However, it didn't work, either.. it's so confusing.

What does R print when you type the 2 lines
   install.packages("ggplot2", dependencies=TRUE)
   libraray(ggplot2)
?  ("didn't work" covers a lot of ground - seeing the entire
printed output may tell others what is going on.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jul 18, 2014 at 10:12 AM, ??? <gunfifa12 at gmail.com> wrote:
> Hi..
>
> After  I upgraded R from 3.1 to 3.11, I stuck with problem in installing
> 'ggplot2' package....
>
> The error message was;
>
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?Rcpp?
> Error: package or namespace load failed for ?ggplot2?
>
>
> I tried to find out resolution on the web.. and most people recommend
> following;
>
>
> install.packages("ggplot2",dependencies=T)
>
> However, it didn't work, either.. it's so confusing.
>
> I should use this package ASAP.. so, hope you guys give me a clear answer.
>
> Best for your effort,
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Fri Jul 18 22:16:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 18 Jul 2014 13:16:55 -0700
Subject: [R] Problem in installing package "ggplot2"
In-Reply-To: <CAJbv6rCFK-MJGRC+oNMPyiDQrj4oyZvS01mGLq_FvJR2VSMP_A@mail.gmail.com>
References: <CAJbv6rCFK-MJGRC+oNMPyiDQrj4oyZvS01mGLq_FvJR2VSMP_A@mail.gmail.com>
Message-ID: <3a1c55db-f3b9-4f67-bab5-4dc523b0e3bb@email.android.com>

The obvious workaround (to me) is to go back and use 3.1 until you figure out how to setup 3.1.1.

Re the latter... you have omitted some key information that strongly suggests that you have not read the Posting Guide. You might find reading [1] helpful as well.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 18, 2014 10:12:19 AM PDT, "???" <gunfifa12 at gmail.com> wrote:
>Hi..
>
>After  I upgraded R from 3.1 to 3.11, I stuck with problem in
>installing
>'ggplot2' package....
>
>The error message was;
>
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>versionCheck
>= vI[[j]]) :
>  there is no package called ???Rcpp???
>Error: package or namespace load failed for ???ggplot2???
>
>
>I tried to find out resolution on the web.. and most people recommend
>following;
>
>
>install.packages("ggplot2",dependencies=T)
>
>However, it didn't work, either.. it's so confusing.
>
>I should use this package ASAP.. so, hope you guys give me a clear
>answer.
>
>Best for your effort,
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ahmedatia80 at gmail.com  Fri Jul 18 22:41:46 2014
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Fri, 18 Jul 2014 15:41:46 -0500
Subject: [R] Fwd: Plot the means with simultaneous horizontal and vertical
	error bars
In-Reply-To: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
Message-ID: <CAG6S0OnjPioRu=g18a=iCHU-ASoiCJrHR=6=+gnCqTKPaOc7uA@mail.gmail.com>

Dear R users,

I would appreciate your help in plotting the means with simultaneous
horizontal and vertical error bars. I use the lineplot.CI but it creates
the vertical bars only.


The attached file has the dataset that I want to graph. The (X) is the
x-axis values and (y Lint) is the response in y-axis. Therefore, values in
the x-axis would be 150, 350, 550, .....etc.

At each value of the x-axis would be the average response point (y Lint)
with vertical and horizontal error bars.

Each value of the x-axis (X) represents a range of values that in x Water.
The x Water column should be used to draw the horizontal lines.

Thank you so much.

AA




Ahmed M. Attia


Research Assistant
Dept. of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215
FAX: 001-308-455-4024

From sarah.goslee at gmail.com  Fri Jul 18 23:00:56 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 17:00:56 -0400
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0OnjPioRu=g18a=iCHU-ASoiCJrHR=6=+gnCqTKPaOc7uA@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnjPioRu=g18a=iCHU-ASoiCJrHR=6=+gnCqTKPaOc7uA@mail.gmail.com>
Message-ID: <CAM_vjum_Jeein4hOt5adMq3pvsTK22FNBGmEupFEF5PD24RRJA@mail.gmail.com>

You could try plotCI from the plotrix package.

Note that most attachments are stripped; dput() is the preferred way
to include data.

Sarah

On Fri, Jul 18, 2014 at 4:41 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Dear R users,
>
> I would appreciate your help in plotting the means with simultaneous
> horizontal and vertical error bars. I use the lineplot.CI but it creates
> the vertical bars only.
>
>
> The attached file has the dataset that I want to graph. The (X) is the
> x-axis values and (y Lint) is the response in y-axis. Therefore, values in
> the x-axis would be 150, 350, 550, .....etc.
>
> At each value of the x-axis would be the average response point (y Lint)
> with vertical and horizontal error bars.
>
> Each value of the x-axis (X) represents a range of values that in x Water.
> The x Water column should be used to draw the horizontal lines.
>
> Thank you so much.
>
> AA
>
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dimitri.liakhovitski at gmail.com  Fri Jul 18 23:04:07 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 18 Jul 2014 17:04:07 -0400
Subject: [R] setting axis limits and breaks in ggplot2
Message-ID: <CAN2xGJbwsspwCWFeObS5h9ScePNUiJae185AmEMOYrPUYRJW=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/7ea5c78d/attachment.pl>

From sarah.goslee at gmail.com  Fri Jul 18 23:18:10 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 17:18:10 -0400
Subject: [R] setting axis limits and breaks in ggplot2
In-Reply-To: <CAN2xGJbwsspwCWFeObS5h9ScePNUiJae185AmEMOYrPUYRJW=Q@mail.gmail.com>
References: <CAN2xGJbwsspwCWFeObS5h9ScePNUiJae185AmEMOYrPUYRJW=Q@mail.gmail.com>
Message-ID: <CAM_vjumyYSi6dksESoYSx-ikMA8RErXLp4L-h2KqaY7bRktxVg@mail.gmail.com>

You need to explicitly specify the limits; see

http://docs.ggplot2.org/current/scale_continuous.html


  library(ggplot2)
  test<-data.frame(a=1:4,b=c(0.12,0.5,0.6,0.4))

  ggplot(test, aes(x=a, y=b))+geom_line()+
    scale_x_continuous(breaks=1:4)+
    scale_y_continuous(breaks=seq(0,1,by=0.1), limits=c(0,1))



Sarah

On Fri, Jul 18, 2014 at 5:04 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> I want my y axis in this plot to range from 0 to 1 and use as break points
> 0, 0.1, 0.2 up to 1.
> Why is my code below not working?
>
> Thank you!
>
>   library(ggplot2)
>   test<-data.frame(a=1:4,b=c(0.12,0.5,0.6,0.4))
>
>   ggplot(test, aes(x=a, y=b))+geom_line()+
>     scale_x_continuous(breaks=1:4)+
>     scale_y_continuous(breaks=seq(0,1,by=0.1))
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dimitri.liakhovitski at gmail.com  Fri Jul 18 23:27:06 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 18 Jul 2014 17:27:06 -0400
Subject: [R] setting axis limits and breaks in ggplot2
In-Reply-To: <CAM_vjumyYSi6dksESoYSx-ikMA8RErXLp4L-h2KqaY7bRktxVg@mail.gmail.com>
References: <CAN2xGJbwsspwCWFeObS5h9ScePNUiJae185AmEMOYrPUYRJW=Q@mail.gmail.com>
	<CAM_vjumyYSi6dksESoYSx-ikMA8RErXLp4L-h2KqaY7bRktxVg@mail.gmail.com>
Message-ID: <CAN2xGJZbWhO0SzHTERSr-CorZt7hzV14A4etwKfZdqpd6OJnDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/e57f3495/attachment.pl>

From sarah.goslee at gmail.com  Fri Jul 18 23:29:02 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 17:29:02 -0400
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0OkdU3LUbBHLY9VdzyoD6dt5sf=FgS48KPmUOrYTQu3x9g@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnjPioRu=g18a=iCHU-ASoiCJrHR=6=+gnCqTKPaOc7uA@mail.gmail.com>
	<CAM_vjum_Jeein4hOt5adMq3pvsTK22FNBGmEupFEF5PD24RRJA@mail.gmail.com>
	<CAG6S0OkdU3LUbBHLY9VdzyoD6dt5sf=FgS48KPmUOrYTQu3x9g@mail.gmail.com>
Message-ID: <CAM_vjukKTcBzLZLw4O6aqBvU600zohz0FZWyUCPOonCBxSXJYQ@mail.gmail.com>

Did you read the help?

     err: The direction of error bars: "x" for horizontal, "y" for
          vertical ("xy" would be nice but is not implemented yet;
          don't know quite how everything would be specified.  See
          examples for composing a plot with simultaneous horizontal
          and vertical error bars)

Sarah

On Fri, Jul 18, 2014 at 5:22 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Sarah,
>
> PlotCI provides the vertical CI bars only. Do you have any idea?
>
> plotCI(x=means, uiw=ciw)
>
>   # prettier
>   plotCI(x=means, uiw=ciw, col="black", barcol="blue", lwd=1)
>
>
> AA
>
> Ahmed M. Attia
>
>
> Research Assistant
> Dept. of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
> FAX: 001-308-455-4024
>
>
>
> On Fri, Jul 18, 2014 at 4:00 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> You could try plotCI from the plotrix package.
>>
>> Note that most attachments are stripped; dput() is the preferred way
>> to include data.
>>
>> Sarah
>>
>> On Fri, Jul 18, 2014 at 4:41 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>> Dear R users,
>>>
>>> I would appreciate your help in plotting the means with simultaneous
>>> horizontal and vertical error bars. I use the lineplot.CI but it creates
>>> the vertical bars only.
>>>
>>>
>>> The attached file has the dataset that I want to graph. The (X) is the
>>> x-axis values and (y Lint) is the response in y-axis. Therefore, values in
>>> the x-axis would be 150, 350, 550, .....etc.
>>>
>>> At each value of the x-axis would be the average response point (y Lint)
>>> with vertical and horizontal error bars.
>>>
>>> Each value of the x-axis (X) represents a range of values that in x Water.
>>> The x Water column should be used to draw the horizontal lines.
>>>
>>> Thank you so much.
>>>
>>> AA
>>>
>>>
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Jul 18 23:42:33 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 17:42:33 -0400
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0OnnMDHndzErer7jMGZiveuqc7mEM85xFVSSjF4RdQzHjg@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnjPioRu=g18a=iCHU-ASoiCJrHR=6=+gnCqTKPaOc7uA@mail.gmail.com>
	<CAM_vjum_Jeein4hOt5adMq3pvsTK22FNBGmEupFEF5PD24RRJA@mail.gmail.com>
	<CAG6S0OkdU3LUbBHLY9VdzyoD6dt5sf=FgS48KPmUOrYTQu3x9g@mail.gmail.com>
	<CAM_vjukKTcBzLZLw4O6aqBvU600zohz0FZWyUCPOonCBxSXJYQ@mail.gmail.com>
	<CAG6S0OnnMDHndzErer7jMGZiveuqc7mEM85xFVSSjF4RdQzHjg@mail.gmail.com>
Message-ID: <CAM_vju=o4p+sE13ftx53dLF8SOAK-JE0YksbkAnBWhFjKUv4vA@mail.gmail.com>

On Fri, Jul 18, 2014 at 5:38 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Yes, I saw this but I can't translate it to a code.
>
> http://svitsrv25.epfl.ch/R-doc/library/Hmisc/html/errbar.html

Why are you reading the help for Hmisc::errbar when I suggested (and
copied and pasted for you!) the function plotCI from the plotrix
package?

The examples in ?plotCI demonstrate having horizontal and vertical
error bars, as cited in the bit I copied and pasted for you.

Please also reply all so your message returns to the R-help list, and
not just to me, so others can participate and benefit.

Sarah

>
> I looked at this but it produces the vertical bars only.
>
> AA
>
> Ahmed M. Attia
>
>
> Research Assistant
> Dept. of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
> FAX: 001-308-455-4024
>
>
>
> On Fri, Jul 18, 2014 at 4:29 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> Did you read the help?
>>
>>      err: The direction of error bars: "x" for horizontal, "y" for
>>           vertical ("xy" would be nice but is not implemented yet;
>>           don't know quite how everything would be specified.  See
>>           examples for composing a plot with simultaneous horizontal
>>           and vertical error bars)
>>
>> Sarah
>>
>> On Fri, Jul 18, 2014 at 5:22 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>> Sarah,
>>>
>>> PlotCI provides the vertical CI bars only. Do you have any idea?
>>>
>>> plotCI(x=means, uiw=ciw)
>>>
>>>   # prettier
>>>   plotCI(x=means, uiw=ciw, col="black", barcol="blue", lwd=1)
>>>
>>>
>>> AA
>>>
>>> Ahmed M. Attia
>>>
>>>
>>> Research Assistant
>>> Dept. of Soil&Crop Sciences
>>> Texas A&M University
>>> ahmed.attia at ag.tamu.edu
>>> Cell phone: 001-979-248-5215
>>> FAX: 001-308-455-4024
>>>
>>>
>>>
>>> On Fri, Jul 18, 2014 at 4:00 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>> You could try plotCI from the plotrix package.
>>>>
>>>> Note that most attachments are stripped; dput() is the preferred way
>>>> to include data.
>>>>
>>>> Sarah
>>>>
>>>> On Fri, Jul 18, 2014 at 4:41 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>>>> Dear R users,
>>>>>
>>>>> I would appreciate your help in plotting the means with simultaneous
>>>>> horizontal and vertical error bars. I use the lineplot.CI but it creates
>>>>> the vertical bars only.
>>>>>
>>>>>
>>>>> The attached file has the dataset that I want to graph. The (X) is the
>>>>> x-axis values and (y Lint) is the response in y-axis. Therefore, values in
>>>>> the x-axis would be 150, 350, 550, .....etc.
>>>>>
>>>>> At each value of the x-axis would be the average response point (y Lint)
>>>>> with vertical and horizontal error bars.
>>>>>
>>>>> Each value of the x-axis (X) represents a range of values that in x Water.
>>>>> The x Water column should be used to draw the horizontal lines.
>>>>>
>>>>> Thank you so much.
>>>>>
>>>>> AA
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Sarah Goslee
>>>> http://www.functionaldiversity.org


From ahmedatia80 at gmail.com  Sat Jul 19 00:06:38 2014
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Fri, 18 Jul 2014 17:06:38 -0500
Subject: [R] Fwd: Plot the means with simultaneous horizontal and vertical
	error bars
In-Reply-To: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
Message-ID: <CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>

Hi all,

I have been also trying the plotCI but it did not work out

plotCI(x, y = NULL, uiw, liw = uiw, ui, li, err='y', ylim=NULL,
       xlim=NULL, type="p",  col=par("col"), barcol=col,
       pt.bg = par("bg"),  sfrac = 0.01, gap=1, lwd=par("lwd"),
       lty=par("lty"), labels=FALSE, add=FALSE, xlab, ylab,  minbar,
       maxbar, ... )


I searched and looked at the previous plotCI posts below;



http://www.talkstats.com/showthread.php/51908-Vertical-and-horizontal-error-bars-PlotCI-errbar


Dear R users,

I would appreciate your help in plotting the means with simultaneous
horizontal and vertical error bars. I use the lineplot.CI but it creates
the vertical bars only.


The attached file has the dataset that I want to graph. The (X) is the
x-axis values and (y Lint) is the response in y-axis. Therefore, values in
the x-axis would be 150, 350, 550, .....etc.

At each value of the x-axis would be the average response point (y Lint)
with vertical and horizontal error bars.

Each value of the x-axis (X) represents a range of values that in x Water.
The x Water column should be used to draw the horizontal lines.

Thank you so much.

AA




Ahmed M. Attia


Research Assistant
Dept. of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215
FAX: 001-308-455-4024

From sarah.goslee at gmail.com  Sat Jul 19 00:15:18 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 18:15:18 -0400
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>
Message-ID: <CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>

The example given in ?plotCI works just fine for me. You'll need to be
more specific about what isn't working, and ideally provide some data
with dput().
Notice the add=TRUE argument in the second call to plotCI().


      y<-runif(10)
      err.x<-runif(10)
      err.y<-runif(10)
      plotCI(1:10,y,err.y,pt.bg=par("bg"),pch=21,xlim=c(0,11),
main="plotCI with extra space on the x axis")
      plotCI(1:10,y,err.x,pt.bg=par("bg"),pch=21,err="x",add=TRUE)

Sarah

On Fri, Jul 18, 2014 at 6:06 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> Hi all,
>
> I have been also trying the plotCI but it did not work out
>
> plotCI(x, y = NULL, uiw, liw = uiw, ui, li, err='y', ylim=NULL,
>        xlim=NULL, type="p",  col=par("col"), barcol=col,
>        pt.bg = par("bg"),  sfrac = 0.01, gap=1, lwd=par("lwd"),
>        lty=par("lty"), labels=FALSE, add=FALSE, xlab, ylab,  minbar,
>        maxbar, ... )
>
>
> I searched and looked at the previous plotCI posts below;
>
>
>
> http://www.talkstats.com/showthread.php/51908-Vertical-and-horizontal-error-bars-PlotCI-errbar
>
>
> Dear R users,
>
> I would appreciate your help in plotting the means with simultaneous
> horizontal and vertical error bars. I use the lineplot.CI but it creates
> the vertical bars only.
>
>
> The attached file has the dataset that I want to graph. The (X) is the
> x-axis values and (y Lint) is the response in y-axis. Therefore, values in
> the x-axis would be 150, 350, 550, .....etc.
>
> At each value of the x-axis would be the average response point (y Lint)
> with vertical and horizontal error bars.
>
> Each value of the x-axis (X) represents a range of values that in x Water.
> The x Water column should be used to draw the horizontal lines.
>
> Thank you so much.
>
> AA
>
>
>
>
> Ahmed M. Attia
>
>


From wdunlap at tibco.com  Sat Jul 19 00:30:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Jul 2014 15:30:23 -0700
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>
	<CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>
Message-ID: <CAF8bMcaAnrP4tcCqLV_vP7V4dEPYw3zYDkeZAtanESWPTGhefA@mail.gmail.com>

Is the original poster having trouble translating the synopsis at the
top of the help file to actual code?  He should look at the examples
at the bottom of the help file, or better, run them with
   example(plotCI)
and see if any of the plots looks close to what he wants.



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jul 18, 2014 at 3:15 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> The example given in ?plotCI works just fine for me. You'll need to be
> more specific about what isn't working, and ideally provide some data
> with dput().
> Notice the add=TRUE argument in the second call to plotCI().
>
>
>       y<-runif(10)
>       err.x<-runif(10)
>       err.y<-runif(10)
>       plotCI(1:10,y,err.y,pt.bg=par("bg"),pch=21,xlim=c(0,11),
> main="plotCI with extra space on the x axis")
>       plotCI(1:10,y,err.x,pt.bg=par("bg"),pch=21,err="x",add=TRUE)
>
> Sarah
>
> On Fri, Jul 18, 2014 at 6:06 PM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>> Hi all,
>>
>> I have been also trying the plotCI but it did not work out
>>
>> plotCI(x, y = NULL, uiw, liw = uiw, ui, li, err='y', ylim=NULL,
>>        xlim=NULL, type="p",  col=par("col"), barcol=col,
>>        pt.bg = par("bg"),  sfrac = 0.01, gap=1, lwd=par("lwd"),
>>        lty=par("lty"), labels=FALSE, add=FALSE, xlab, ylab,  minbar,
>>        maxbar, ... )
>>
>>
>> I searched and looked at the previous plotCI posts below;
>>
>>
>>
>> http://www.talkstats.com/showthread.php/51908-Vertical-and-horizontal-error-bars-PlotCI-errbar
>>
>>
>> Dear R users,
>>
>> I would appreciate your help in plotting the means with simultaneous
>> horizontal and vertical error bars. I use the lineplot.CI but it creates
>> the vertical bars only.
>>
>>
>> The attached file has the dataset that I want to graph. The (X) is the
>> x-axis values and (y Lint) is the response in y-axis. Therefore, values in
>> the x-axis would be 150, 350, 550, .....etc.
>>
>> At each value of the x-axis would be the average response point (y Lint)
>> with vertical and horizontal error bars.
>>
>> Each value of the x-axis (X) represents a range of values that in x Water.
>> The x Water column should be used to draw the horizontal lines.
>>
>> Thank you so much.
>>
>> AA
>>
>>
>>
>>
>> Ahmed M. Attia
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Sat Jul 19 00:42:14 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 18 Jul 2014 18:42:14 -0400
Subject: [R] Weird but interesting behavior of ggplot2 in a loop
Message-ID: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/c839c028/attachment.pl>

From sarah.goslee at gmail.com  Sat Jul 19 00:53:18 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 18 Jul 2014 18:53:18 -0400
Subject: [R] Weird but interesting behavior of ggplot2 in a loop
In-Reply-To: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
References: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
Message-ID: <CAM_vjukunGJ9c_uV1bWp_d0BX27dVpPj-O49coyyjwUHLJk16A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/49127d71/attachment.pl>

From dimitri.liakhovitski at gmail.com  Sat Jul 19 01:05:42 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 18 Jul 2014 19:05:42 -0400
Subject: [R] Weird but interesting behavior of ggplot2 in a loop
In-Reply-To: <CAM_vjukunGJ9c_uV1bWp_d0BX27dVpPj-O49coyyjwUHLJk16A@mail.gmail.com>
References: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
	<CAM_vjukunGJ9c_uV1bWp_d0BX27dVpPj-O49coyyjwUHLJk16A@mail.gmail.com>
Message-ID: <CAN2xGJbimt74+NNbWXPs8aGedRS5Oau2m59vD-VtmmSf7iKGyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/b05ea102/attachment.pl>

From dimitri.liakhovitski at gmail.com  Sat Jul 19 01:06:15 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 18 Jul 2014 19:06:15 -0400
Subject: [R] Weird but interesting behavior of ggplot2 in a loop
In-Reply-To: <CAN2xGJbimt74+NNbWXPs8aGedRS5Oau2m59vD-VtmmSf7iKGyA@mail.gmail.com>
References: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
	<CAM_vjukunGJ9c_uV1bWp_d0BX27dVpPj-O49coyyjwUHLJk16A@mail.gmail.com>
	<CAN2xGJbimt74+NNbWXPs8aGedRS5Oau2m59vD-VtmmSf7iKGyA@mail.gmail.com>
Message-ID: <CAN2xGJZwU8kd6mQ+WLZeFj7iOY5+cxRi+513cCuK1qPDuXFkhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/1b3e33ef/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Jul 19 01:21:41 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 18 Jul 2014 16:21:41 -0700
Subject: [R] Weird but interesting behavior of ggplot2 in a loop
In-Reply-To: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
References: <CAN2xGJaU2Y++_hB820+Hv_4o0PRX7ALYo2m9k2KzC5pyJKGn+g@mail.gmail.com>
Message-ID: <b5ff1c99-9c8d-4003-8a30-e38345a5057d@email.android.com>

FAQ 7.16. ... yes, it applies.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 18, 2014 3:42:14 PM PDT, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>Hello and sorry I am not providing an example. However, I hope you'll
>be
>able to answer my question.
>
>I have a "for" loop. Inside this loop I build 4 plots using ggplot2.
>See 2
>blocks of code below - I have in total 4 of those:
>As I step through the loop manually and run all the code inside the
>loop,
>everything works perfectly and R generates (among other things) 4 .png
>files in my working directory (each size 7 KB).
>
>However, when I run the loop (even when the loop length is 1) the
>generated
>.png files are empty (and size 1 KB). I've never seen anything like
>this.
>My loop is correct - because everything else generated in the loop
>except
>for the images is there. And the image files with right names are also
>there, they are just empty.
>
>Any ideas why this might be happening? I did it first in RStudio and
>then
>just in R Gui.
>Thank you very much!
>
>
>
>  png(forname1,width=700,height=450)
>  ggplot(result.opt, aes(x=prices, y=demand))+
>    geom_line(colour='darkblue',size=1.2)+
>
>scale_x_continuous(breaks=seq(input[1,1],input[nrow(input),1],by=step*6))+
>    scale_y_continuous(breaks=seq(0,1,by=0.1),limits=c(0,1))+
>    xlab("Price") + ylab("Purchase Intent")+
>    labs(title=forname2)+
>    theme(plot.title = element_text(size=16))+
>    theme(axis.title.x=element_text(size=12))+
>    theme(axis.title.y=element_text(size=12))
>  dev.off()
>
>  png(forname2,width=700,height=450)
>  ggplot(result.opt, aes(x=prices, y=revenue))+
>    geom_line(colour='blue',size=1.2)+
>
>scale_x_continuous(breaks=seq(input[1,1],input[nrow(input),1],by=step*6))+
>    # scale_y_continuous(breaks=seq(0,1,by=0.1),limits=c(0,1))+
>    xlab("Price") + ylab("Revenue per Person")+
>    labs(title=forname2)+
>    theme(plot.title = element_text(size=16))+
>    theme(axis.title.x=element_text(size=12))+
>    theme(axis.title.y=element_text(size=12))
>  dev.off()


From ahmedatia80 at gmail.com  Sat Jul 19 01:27:52 2014
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Fri, 18 Jul 2014 16:27:52 -0700
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAF8bMcaAnrP4tcCqLV_vP7V4dEPYw3zYDkeZAtanESWPTGhefA@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>
	<CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>
	<CAF8bMcaAnrP4tcCqLV_vP7V4dEPYw3zYDkeZAtanESWPTGhefA@mail.gmail.com>
Message-ID: <CAG6S0On30t7NaQ-H4x67Rp8CNK_3hKz=O3-ROqD32ShnKgWGhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140718/b4e9a217/attachment.pl>

From marc_grt at yahoo.fr  Sat Jul 19 01:44:38 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sat, 19 Jul 2014 02:44:38 +0300
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0On30t7NaQ-H4x67Rp8CNK_3hKz=O3-ROqD32ShnKgWGhw@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>	<CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>	<CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>	<CAF8bMcaAnrP4tcCqLV_vP7V4dEPYw3zYDkeZAtanESWPTGhefA@mail.gmail.com>
	<CAG6S0On30t7NaQ-H4x67Rp8CNK_3hKz=O3-ROqD32ShnKgWGhw@mail.gmail.com>
Message-ID: <53C9B166.3070204@yahoo.fr>

In the package phenology (in CRAN), I add a function plot_errbar:
plot_errbar(..., errbar.x = NULL, errbar.y = NULL, errbar.x.plus = NULL,
   errbar.x.minus = NULL, errbar.y.plus = NULL, errbar.y.minus = NULL,
   x.plus = NULL, x.minus = NULL, y.plus = NULL, y.minus = NULL,
   errbar.tick = 1/50, errbar.lwd = par("lwd"), errbar.lty = par("lty"),
   errbar.col = par("fg"), errbar.y.polygon = FALSE,
   errbar.y.polygon.list = list(NULL), add = FALSE)

It permits to plot errbar both on x and y.

Sincerely,

Marc Girondot

Le 19/07/2014 02:27, Ahmed Attia a ?crit :
> My problem is getting x and y into the PlotCI. I do not know how to use the
> dput(). But below is my data;
>
>
>
> x  x-Water y  150 74.67 75  150 92.2 97  150 138.2 327.5  150 140.2 142.6
> 150 194.82 333.8  150 226.31 423  150 226.56 590.9  150 240.28 546.6  150
> 241.55 232.3  150 243.07 454.6  350 252.7 352.8  350 257.4 459.7  350 260.09
> 874.2  350 260.5 272.8  350 270.25 359.8  350 272.54 1008  350 286 638.9
> 350 288.3 791  350 288.54 736  350 291.34 816.3  350 297.0 465  350 303.8
> 234.3  350 306.58 601.9  350 310.38 942.9  350 311.3 334.4  350 317.75 522.1
> 350 330.45 563  350 333.78 717.4  350 339.59 851.5  350 341.37 642  350
> 342.7 490.5  350 344.2 487.7  350 344.42 1174  350 345.4 440.7  350 345.44
> 243  350 349.22 834.8  350 354.48 704.9  350 363.4 885  350 365.75 606.7
> 350 366.77 1036.9  350 370.08 898.8  350 371.09 640.9  350 372.69 768.1  350
> 374.24 574.4  350 375.15 200.9  350 375.3 1217  350 376.17 836.4  350 377.7
> 949.8  350 377.7 986.9  350 382.74 458.6  350 384 456.4  350 384.3 1189  350
> 385.9 978.2  350 388.44 379.7  350 391.66 865.7  350 392.44 1026.8  350
> 394.3 663.7  350 398.74 533.1  350 399.72 551.6  350 402.33 341.3  350 410.4
> 889  350 413 1530  350 419.35 1109.8  350 421.19 802.1  350 422.4 896.8  350
> 422.65 995.6  350 428.49 1337  350 433.72 1304.6  350 439.2 1190.4  350
> 439.42 914.3  350 440.43 1016.9  350 443 1266.1  350 446.4 659.3  350 448.05
> 369.3  550 455.34 1206.2  550 456.44 1139.9  550 458.45 1541.1  550 461.52
> 1048.4  550 461.77 486  550 462.45 910.6  550 467.49 1257  550 470.15 880.1
> 550 471.2 1155.7  550 471.32 1275  550 475.22 570.4  550 475.48 1226.6  550
> 481.58 1520  550 484.52 1549.6  550 488.29 1298  550 488.73 887.1  550
> 490.98 1261  550 491.08 1519.5  550 492.76 1082.6  550 499.38 1339.3  550
> 501.31 1121.3  550 503.42 1216.8  550 503.87 723.6  550 505.71 1488.6  550
> 506.74 1613.1  550 510.77 1460.9  550 514.09 1207.1  550 518.72 1167.771
> 550 519.93 1485.1  550 523.09 1025.8  550 526.79 986.5  550 530.34 874.5
> 550 532.89 1408.8  550 534.16 1197.7  550 538.1 1235.1  550 542.06 1219.7
> 550 545.34 1176.2  550 548.89 1366.4  550 550.668 1248  550 551.0 1434.4
> 550 551.84 1092.1  550 552.95 766.5  550 553.68 1465.7  550 556.76 1311.6
> 550 557.59 1247.3  550 558 1288.3  550 558.23 1115.257  550 567.66 1514.2
> 550 571.75 1249.9  550 571.82 1320  550 572.8 1397.2  550 577.89 1228  550
> 578 1580.1  550 578.5 1491.3  550 582.67 1304.3  550 587.75 1188.7  550
> 590.14 1476.8  550 592.07 1644.1  550 592.1 1334.4  550 596.9 1395.7  550
> 600.2 1468  550 602.76 978.3  550 604.01 1183.5  550 604.57 1051.49  550
> 608.98 1408.4  550 610.875 1189.9  550 616.45 1647.9  550 620.7 1193.3  550
> 623.58 1804  550 626.6 1575.8  550 629.16 1187.8  550 635.25 1468.2  550
> 638.34 1276  550 640.32 982.4  550 641 1241.3  550 647.5 1452.4  550 649.24
> 1826.5  750 653.56 1613.7  750 660.36 1731  750 665.22 1271.6  750 665.92
> 1172.369  750 669.03 1403.9  750 669.03 1261  750 669.94 1582.7  750 671.6
> 1296.4  750 673.35 1280.7  750 675.85 1306.8  750 678.43 1697.6  750 679.42
> 1435.1  750 679.48 1315.4  750 682.49 930.7  750 684.68 1612.1  750 685.29
> 1328.3  750 702.74 1111.3  750 704.58 980.6  750 712.97 1766.4  750 713.996
> 1163.7  750 714.4 1458  750 715.14 1238  750 717.14 1553.6  750 718.82
> 1653.9  750 720.55 1343.4  750 729.06 1053.063  750 730.754 1132  750 742.0
> 1293.2  750 755.87 1564.7  750 757.42 1211.7  750 764.03 1420.6  750 765.25
> 1449.4  750 766.08 1839  750 768.09 1579.1  750 769 1546.7  750 772.17
> 1779.6  750 772.41 1193.6  750 777.2 1880.7  750 783.62 1558.8  750 785.9
> 1259.4  750 788.64 1363.6  750 790.09 1398.4  750 793.22 1157.607  750
> 805.67 1135  750 808.99 1617.3  750 812.03 1246.4  750 820.672 1362  750
> 831.4 1586  750 842.51 1362.5  750 852.18 1597  950 852.18 1597  950 861.03
> 1554.4  950 865.26 1358.2  950 870.926 1713  950 872.74 1191.2  950 878.83
> 1544.1  950 895.62 1651.7  950 896.59 1233.2  950 901.22 1209.8  950 935.58
> 1278.7  950 944.11 1215.1  950 966.12 1334.8  950 991.9 1336.9  950 1025.16
> 1542.5  1150 1086.35 1382  1150 1142.5 1447.2  1150 1203.15 1262.4
> x is the x-axis and y is the y-axis. x-Water should be used to produce the
> horizontal error bars. How I can tell the program to do that.
>
> Thanks
>
> AA
>
>
> Ahmed M. Attia
>
>
> Research Assistant
> Dept. of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
> FAX: 001-308-455-4024
>
>
>
> On Fri, Jul 18, 2014 at 3:30 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> Is the original poster having trouble translating the synopsis at the
>> top of the help file to actual code?  He should look at the examples
>> at the bottom of the help file, or better, run them with
>>     example(plotCI)
>> and see if any of the plots looks close to what he wants.
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Jul 18, 2014 at 3:15 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>> The example given in ?plotCI works just fine for me. You'll need to be
>>> more specific about what isn't working, and ideally provide some data
>>> with dput().
>>> Notice the add=TRUE argument in the second call to plotCI().
>>>
>>>
>>>        y<-runif(10)
>>>        err.x<-runif(10)
>>>        err.y<-runif(10)
>>>        plotCI(1:10,y,err.y,pt.bg=par("bg"),pch=21,xlim=c(0,11),
>>> main="plotCI with extra space on the x axis")
>>>        plotCI(1:10,y,err.x,pt.bg=par("bg"),pch=21,err="x",add=TRUE)
>>>
>>> Sarah
>>>
>>> On Fri, Jul 18, 2014 at 6:06 PM, Ahmed Attia <ahmedatia80 at gmail.com>
>> wrote:
>>>> Hi all,
>>>>
>>>> I have been also trying the plotCI but it did not work out
>>>>
>>>> plotCI(x, y = NULL, uiw, liw = uiw, ui, li, err='y', ylim=NULL,
>>>>         xlim=NULL, type="p",  col=par("col"), barcol=col,
>>>>         pt.bg = par("bg"),  sfrac = 0.01, gap=1, lwd=par("lwd"),
>>>>         lty=par("lty"), labels=FALSE, add=FALSE, xlab, ylab,  minbar,
>>>>         maxbar, ... )
>>>>
>>>>
>>>> I searched and looked at the previous plotCI posts below;
>>>>
>>>>
>>>>
>>>>
>> http://www.talkstats.com/showthread.php/51908-Vertical-and-horizontal-error-bars-PlotCI-errbar
>>>>
>>>> Dear R users,
>>>>
>>>> I would appreciate your help in plotting the means with simultaneous
>>>> horizontal and vertical error bars. I use the lineplot.CI but it creates
>>>> the vertical bars only.
>>>>
>>>>
>>>> The attached file has the dataset that I want to graph. The (X) is the
>>>> x-axis values and (y Lint) is the response in y-axis. Therefore, values
>> in
>>>> the x-axis would be 150, 350, 550, .....etc.
>>>>
>>>> At each value of the x-axis would be the average response point (y Lint)
>>>> with vertical and horizontal error bars.
>>>>
>>>> Each value of the x-axis (X) represents a range of values that in x
>> Water.
>>>> The x Water column should be used to draw the horizontal lines.
>>>>
>>>> Thank you so much.
>>>>
>>>> AA
>>>>
>>>>
>>>>
>>>>
>>>> Ahmed M. Attia
>>>>
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ibrahimmalfaki at gmail.com  Sat Jul 19 05:08:49 2014
From: ibrahimmalfaki at gmail.com (Ibrahim Alfaki)
Date: Sat, 19 Jul 2014 07:08:49 +0400
Subject: [R] R code for Forecasting ARDL
Message-ID: <CAPOX_rpPGXBtb84-u5b=CghQ_bbwpLXuFc-p2-RW4O1TvnR2PQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140719/0537d448/attachment.pl>

From ingo at gfz-potsdam.de  Sat Jul 19 12:41:44 2014
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Sat, 19 Jul 2014 12:41:44 +0200
Subject: [R] using postscript() for multiple individual files
Message-ID: <53CA4B68.6030101@gfz-potsdam.de>

Hello,
I try to plot some results of an analysis to multiple individual 
postscript files, like:
   postscript("A1_zonflow.ps",onefile=F)
   plot(s, type = "vectors", idx = 1:12,main="")
   dev.off()
#
   postscript("vectors_paired_zonflow.ps",onefile=F)
   plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
   dev.off()
#
   postscript(file="wcor_zonflow.ps",onefile=F);
   plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")

I expect to obtain three individual files, showing the actual graphics. 
The three files are generated, but the first two appear to be empty, 
only the third file shows the expected graphic.
How can I create three individual (not-empty) postscript files?
I run R version 3.1.1 (2014-07-10) -- "Sock it to Me" on linux

TIA
ingo


From jim at bitwrit.com.au  Sat Jul 19 13:25:01 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 19 Jul 2014 21:25:01 +1000
Subject: [R] help with script to get starting date of blooms
In-Reply-To: <CAAMki4G2UPhQ=j3Dfg=eXdrudwGnzsjJCeVND7ospB4Pibzjog@mail.gmail.com>
References: <CAAMki4G2UPhQ=j3Dfg=eXdrudwGnzsjJCeVND7ospB4Pibzjog@mail.gmail.com>
Message-ID: <2279726.ahgcekOJSd@localhost.localdomain>

On Fri, 18 Jul 2014 10:15:35 AM Veronica Andreo wrote:
> Hi list
> 
> I have a vector, which are remotely sensed chlorophyll values for a 
certain
> pixel in 11 years, then i have a flag or label vector (t_max) that 
consists
> of 0 and 1, which tells me where i have the annual peak (one per 
year, then
> eleven 1 and all the rest are 0).
> 
> I'm interested in extracting the date in which the bloom beggins. For 
that
> matter I'm using a threshold of 5% above the median of the whole 
series.
> 
> I need to go over the chlorophyll data vector (cla) and every time I 
find
> the yearly maximum value (where t_max == 1), i need to go 
backwards in cla
> as many time steps as needed untill I cross the threshold (5% over 
the
> median of cl)... once i crossed that threshold, i need to be sure that 
at
> least for 2 time steps, the value of cla keeps going down (it's below 
the
> threshold)... once that condition is met, i want to get the first 
position
> where cla is higher than that threshold...
> that would be the phytoplankton bloom starting date...
> 
> This is more or less what i was trying, but it does not work and i'm
> stuck... can you please help me??
> 
> cla<- ts of 506 values (every 46 values, i have one year)
> t_max<- vector of 0 & 1; 1 where the yearly cla max occurs (11 
ones & all
> rest 0)
> threshold = 0.05*median(cla)+median(cla)
> 
> for ( t in 1:length(t_max) ) {
>   if ( t_max[t] == 0 )
>   {
> next;
>   } else {
>     if ( (cla[t-1] < threshold) && (cla[t-2)] < threshold) )
> {
>     return which(cla[t])
>     }
>   }
> }
> 
Hi Vero,
I think this does what you want, even though it doesn't do it the way 
you describe above.

cla<-runif(506)+
 rep(c(seq(1,3,length.out=23),seq(3,1,length.out=23)),11)
obs_time<-paste(rep(1:11,each=46),rep(1:46,11),sep="_")
t_max<-rep(0,506)
t_begin<-rep("",11)
for(year in 1:11) {
 threshold<-median(cla[(year-1) * 46 + 1:46]) * 1.05
 max_pos<-(year-1) * 46 + which.max(cla[(year-1)*46+1:46])
 t_max[max_pos]<-1
 threshpos<-(year-1) * 46 + 1
 while(cla[threshpos] < threshold) threshpos <- threshpos + 1
 cat(threshold,cla[threshpos],max_pos,cla[max_pos],"\n")
 t_begin[year]<-obs_time[threshpos]
}

Jim


From murdoch.duncan at gmail.com  Sat Jul 19 13:25:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Jul 2014 06:25:44 -0500
Subject: [R] using postscript() for multiple individual files
In-Reply-To: <53CA4B68.6030101@gfz-potsdam.de>
References: <53CA4B68.6030101@gfz-potsdam.de>
Message-ID: <53CA55B8.4040809@gmail.com>

On 19/07/2014, 5:41 AM, Ingo Wardinski wrote:
> Hello,
> I try to plot some results of an analysis to multiple individual 
> postscript files, like:
>    postscript("A1_zonflow.ps",onefile=F)
>    plot(s, type = "vectors", idx = 1:12,main="")
>    dev.off()
> #
>    postscript("vectors_paired_zonflow.ps",onefile=F)
>    plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
>    dev.off()
> #
>    postscript(file="wcor_zonflow.ps",onefile=F);
>    plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")
> 
> I expect to obtain three individual files, showing the actual graphics. 
> The three files are generated, but the first two appear to be empty, 
> only the third file shows the expected graphic.
> How can I create three individual (not-empty) postscript files?
> I run R version 3.1.1 (2014-07-10) -- "Sock it to Me" on linux

You don't give us a reproducible example.  When I try something similar,
it works for me.

My guess would be that the files were produced, but not in the directory
you expected.

BTW, it doesn't make sense to use onefile=F when you are writing a
single page.  However, I don't think this would stop it from working.

Duncan Murdoch

> 
> TIA
> ingo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mamillerpa at gmail.com  Sat Jul 19 16:57:20 2014
From: mamillerpa at gmail.com (Mark Miller)
Date: Sat, 19 Jul 2014 10:57:20 -0400
Subject: [R] How to bin x,y,z vectors into matrix?
Message-ID: <CAADrioR0nwO4J4QVdga=PGfDrnvUaOsmL0vkSAntSW78-NFFYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140719/60b0d851/attachment.pl>

From sarah.goslee at gmail.com  Sat Jul 19 18:31:39 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 19 Jul 2014 12:31:39 -0400
Subject: [R] How to bin x,y,z vectors into matrix?
In-Reply-To: <CAADrioR0nwO4J4QVdga=PGfDrnvUaOsmL0vkSAntSW78-NFFYg@mail.gmail.com>
References: <CAADrioR0nwO4J4QVdga=PGfDrnvUaOsmL0vkSAntSW78-NFFYg@mail.gmail.com>
Message-ID: <CAM_vjukSxi7DFcfTRNGqSpFLT-UdvKnh0nCPEmH2iGj8fbHcJQ@mail.gmail.com>

Hi Mark,

First you need to use cut() to bin the values. Here's an example:

# generate some fake data
temp <- data.frame(x=runif(20), y=runif(20), z=runif(20))
# bin x and y
temp$x <- cut(temp$x, seq(0, 1, by=.2))
temp$y <- cut(temp$y, seq(0, 1, by=.2))

>From there, there are all sorts of ways to get your desired table. Here are two:

xtabs(z ~ x + y, data=aggregate(z ~ x + y, data=temp, FUN="mean"))

or

library(ecodist)
with(temp, crosstab(x, y, z, "mean"))

On Sat, Jul 19, 2014 at 10:57 AM, Mark Miller <mamillerpa at gmail.com> wrote:
> This is probably a basic question, but I haven't been able to Google
> anything helpful after trying for days.

Using the targeted www.rseek.org search engine is a whole lot more
effective than using base Google for R searches.

Sarah


> I have an R dataframe with x,y,z tuples, where z is a response to x and y
> and can be modeled as a surface.
>
>     > head(temp)
>              x         y        z
>     1 36.55411  965.7779 1644.779
>     2 42.36912  978.9721 1643.957
>     3 58.34699 1183.7426 1846.123
>     4 53.55439 1232.2696 1990.707
>     5 50.76167 1115.2049 1281.988
>     6 51.37299 1059.9088 1597.028
>
> I would like to create a matrix of mean z values, with rows representing
> binned y values and columns representing binned x values, like
>
>                            0<x<40    40<x<60  60<x<80   x>80
>           0<y<800   1000.0    1100.00  1100.00   1000.0
>       800<y<1200 1000.0    1200.00  1200.00   1000.0
>     1200<y<1400 1000.0    1200.00  1200.00   1000.0
>               y<1400 1000.0    1100.00  1100.00   1000.0
> thanks
> Mark


-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Sat Jul 19 18:41:53 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 19 Jul 2014 09:41:53 -0700
Subject: [R] How to bin x,y,z vectors into matrix?
In-Reply-To: <CAADrioR0nwO4J4QVdga=PGfDrnvUaOsmL0vkSAntSW78-NFFYg@mail.gmail.com>
References: <CAADrioR0nwO4J4QVdga=PGfDrnvUaOsmL0vkSAntSW78-NFFYg@mail.gmail.com>
Message-ID: <CAF8bMcZgxRJes5eMJHTd9dsp9REu39sx45sJh8VM-=b=KsQanA@mail.gmail.com>

You could use tapply() and cut() in base R, as in
> tapply(d$z, INDEX=list(y=cut(d$y,breaks=seq(900,1300,by=100)), x=cut(d$x,breaks=seq(35,60,by=5))), FUN=mean)
                   x
y                    (35,40]  (40,45] (45,50]  (50,55]  (55,60]
  (900,1e+03]       1644.779 1643.957      NA       NA       NA
  (1e+03,1.1e+03]         NA       NA      NA 1597.028       NA
  (1.1e+03,1.2e+03]       NA       NA      NA 1281.988 1846.123
  (1.2e+03,1.3e+03]       NA       NA      NA 1990.707       NA

cut() does the binning and tapply() applies the function 'FUN' to each group.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Jul 19, 2014 at 7:57 AM, Mark Miller <mamillerpa at gmail.com> wrote:
> This is probably a basic question, but I haven't been able to Google
> anything helpful after trying for days.
>
> I have an R dataframe with x,y,z tuples, where z is a response to x and y
> and can be modeled as a surface.
>
>     > head(temp)
>              x         y        z
>     1 36.55411  965.7779 1644.779
>     2 42.36912  978.9721 1643.957
>     3 58.34699 1183.7426 1846.123
>     4 53.55439 1232.2696 1990.707
>     5 50.76167 1115.2049 1281.988
>     6 51.37299 1059.9088 1597.028
>
> I would like to create a matrix of mean z values, with rows representing
> binned y values and columns representing binned x values, like
>
>                            0<x<40    40<x<60  60<x<80   x>80
>           0<y<800   1000.0    1100.00  1100.00   1000.0
>       800<y<1200 1000.0    1200.00  1200.00   1000.0
>     1200<y<1400 1000.0    1200.00  1200.00   1000.0
>               y<1400 1000.0    1100.00  1100.00   1000.0
> thanks
> Mark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ingo at gfz-potsdam.de  Sat Jul 19 18:53:42 2014
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Sat, 19 Jul 2014 18:53:42 +0200
Subject: [R] using postscript() for multiple individual files
In-Reply-To: <53CA55B8.4040809@gmail.com>
References: <53CA4B68.6030101@gfz-potsdam.de> <53CA55B8.4040809@gmail.com>
Message-ID: <53CAA296.8000501@gfz-potsdam.de>

On 07/19/2014 01:25 PM, Duncan Murdoch wrote:
> On 19/07/2014, 5:41 AM, Ingo Wardinski wrote:
>> Hello,
>> I try to plot some results of an analysis to multiple individual
>> postscript files, like:
>>     postscript("A1_zonflow.ps",onefile=F)
>>     plot(s, type = "vectors", idx = 1:12,main="")
>>     dev.off()
>> #
>>     postscript("vectors_paired_zonflow.ps",onefile=F)
>>     plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
>>     dev.off()
>> #
>>     postscript(file="wcor_zonflow.ps",onefile=F);
>>     plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")
>>
>> I expect to obtain three individual files, showing the actual graphics.
>> The three files are generated, but the first two appear to be empty,
>> only the third file shows the expected graphic.
>> How can I create three individual (not-empty) postscript files?
>> I run R version 3.1.1 (2014-07-10) -- "Sock it to Me" on linux
>
> You don't give us a reproducible example.  When I try something similar,
> it works for me.
>
> My guess would be that the files were produced, but not in the directory
> you expected.
>
> BTW, it doesn't make sense to use onefile=F when you are writing a
> single page.  However, I don't think this would stop it from working.
>
> Duncan Murdoch

I attached a minimal example below. Note, my problem is not that the 
three individual files are not generated, my problems is that two of 
these files are empty. It seems that only the last plot command is done 
(I also changed the order of the plotting command (plot(vector), 
plot(vector-paired, plot(wcor); plot(wcor), plot(vector),.....)

I run this rscript from a wraping shell-script.
TIA
ingo

#!/usr/bin/Rscript
#_______________________________________________________________________________
{
library(Rssa)
{
   s <- ssa(co2,kind="1d-ssa");
   postscript("vectors.ps")
   plot(s, type = "vectors", idx = 1:12,main="")
   dev.off()
#
   postscript("vectors_paired.ps")
   plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
   dev.off()

   postscript(file="wcor.ps");
   plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")

}
}
#_______________________________________________________________________________


From wdunlap at tibco.com  Sat Jul 19 19:17:48 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 19 Jul 2014 10:17:48 -0700
Subject: [R] using postscript() for multiple individual files
In-Reply-To: <53CAA296.8000501@gfz-potsdam.de>
References: <53CA4B68.6030101@gfz-potsdam.de> <53CA55B8.4040809@gmail.com>
	<53CAA296.8000501@gfz-potsdam.de>
Message-ID: <CAF8bMcYSccg83cJcGq8oUwGoQ-Q7=-nLZZf31RTZrrWvu6iODg@mail.gmail.com>

Wrap all your calls to plot() with print().  E.g., change
   plot(s, type="vectors", idx=1:12, main="")
to
   print(plot(s, type="vectors", idx=1:12, main="")

Some plot methods require their output to be printed to display, some
don't.  Some help files for plot methods mention this requirement,
some don't.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Jul 19, 2014 at 9:53 AM, Ingo Wardinski <ingo at gfz-potsdam.de> wrote:
> On 07/19/2014 01:25 PM, Duncan Murdoch wrote:
>>
>> On 19/07/2014, 5:41 AM, Ingo Wardinski wrote:
>>>
>>> Hello,
>>> I try to plot some results of an analysis to multiple individual
>>> postscript files, like:
>>>     postscript("A1_zonflow.ps",onefile=F)
>>>     plot(s, type = "vectors", idx = 1:12,main="")
>>>     dev.off()
>>> #
>>>     postscript("vectors_paired_zonflow.ps",onefile=F)
>>>     plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
>>>     dev.off()
>>> #
>>>     postscript(file="wcor_zonflow.ps",onefile=F);
>>>     plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")
>>>
>>> I expect to obtain three individual files, showing the actual graphics.
>>> The three files are generated, but the first two appear to be empty,
>>> only the third file shows the expected graphic.
>>> How can I create three individual (not-empty) postscript files?
>>> I run R version 3.1.1 (2014-07-10) -- "Sock it to Me" on linux
>>
>>
>> You don't give us a reproducible example.  When I try something similar,
>> it works for me.
>>
>> My guess would be that the files were produced, but not in the directory
>> you expected.
>>
>> BTW, it doesn't make sense to use onefile=F when you are writing a
>> single page.  However, I don't think this would stop it from working.
>>
>> Duncan Murdoch
>
>
> I attached a minimal example below. Note, my problem is not that the three
> individual files are not generated, my problems is that two of these files
> are empty. It seems that only the last plot command is done (I also changed
> the order of the plotting command (plot(vector), plot(vector-paired,
> plot(wcor); plot(wcor), plot(vector),.....)
>
> I run this rscript from a wraping shell-script.
> TIA
> ingo
>
> #!/usr/bin/Rscript
> #_______________________________________________________________________________
> {
> library(Rssa)
> {
>   s <- ssa(co2,kind="1d-ssa");
>   postscript("vectors.ps")
>   plot(s, type = "vectors", idx = 1:12,main="")
>   dev.off()
> #
>   postscript("vectors_paired.ps")
>   plot(s, type = "paired", idx = 1:12,plot.contrib = FALSE,main="")
>   dev.off()
>
>   postscript(file="wcor.ps");
>   plot(wcor(s,groups=1:50),scales=list(at=c(10,20,30,40,50)),main="")
>
> }
> }
> #_______________________________________________________________________________
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Sat Jul 19 19:01:19 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Sat, 19 Jul 2014 10:01:19 -0700
Subject: [R] nlxb CI
Message-ID: <1405789279.11103.YahooMailBasic@web161604.mail.bf1.yahoo.com>

Dear All,

wonder if someone could point me in the direction of calculating confidence intervals for model parameters generated by nlxb() in the nlmrt package? confint() as is gives the following message: no applicable method for 'vcov' applied to an object of class "nlmrt". appreciate the input,

Andras


From ingo at gfz-potsdam.de  Sat Jul 19 19:23:09 2014
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Sat, 19 Jul 2014 19:23:09 +0200
Subject: [R] using postscript() for multiple individual files
In-Reply-To: <CAF8bMcYSccg83cJcGq8oUwGoQ-Q7=-nLZZf31RTZrrWvu6iODg@mail.gmail.com>
References: <53CA4B68.6030101@gfz-potsdam.de> <53CA55B8.4040809@gmail.com>
	<53CAA296.8000501@gfz-potsdam.de>
	<CAF8bMcYSccg83cJcGq8oUwGoQ-Q7=-nLZZf31RTZrrWvu6iODg@mail.gmail.com>
Message-ID: <53CAA97D.4090909@gfz-potsdam.de>

On 07/19/2014 07:17 PM, William Dunlap wrote:
> Wrap all your calls to plot() with print().  E.g., change
>     plot(s, type="vectors", idx=1:12, main="")
> to
>     print(plot(s, type="vectors", idx=1:12, main="")
>
> Some plot methods require their output to be printed to display, some
> don't.  Some help files for plot methods mention this requirement,
> some don't.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

Many thanks! This does the trick
greets
ingo


From john.archie.mckown at gmail.com  Sat Jul 19 20:46:09 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 19 Jul 2014 13:46:09 -0500
Subject: [R] String comparison, trailing blanks make a difference.
In-Reply-To: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
References: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
Message-ID: <CAAJSdjgaFry_xpJYi-6XiH6Eroaw7E1rty=6NCL4vK7nDrRr5w@mail.gmail.com>

On Fri, Jul 18, 2014 at 11:17 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> Well, this was a shock to me. And I don't really see any documentation
> about it, but perhaps I just can't see it.
>
>>"abc" == "abc "
> [1] FALSE
>
> I guess that I thought of strings in R like I do is some other
> languages where the shorter value is padded with blanks to the length
> of the longer value, then compared. I.e. that trailing blanks didn't
> matter.
>
> The best solution that I have found is to use the str_trim() function
> from the stringr to remove all the trailing blanks after I get the
> data from the SQL data base. I cannot change the SQL schema to make
> the column a varchar instead of a char column. It is a vendor DB. And
> I don't know an ANSI SQL standard way to remove trailing blanks in the
> SELECT command. PostgreSQL has a "trim(trailing ' ' from column)', but
> MS-SQL upchucks on that syntax.
>

Well, here I am - talking to myself ... again.

My "problem" was, of course, of my own making. I am getting my data
via RODBC from MS-SQL Server. I was basically doing a "SELECT * FROM
TABLE". I normally use PostgreSQL, not MS-SQL, and I tend to use the
"TEXT" data type instead of CHAR or VARCHAR. So when I do the SELECT,
I get back my data without trailing blanks. Well, the data I am
reading now is created by a software vendor. I guess in order to be
database independent, the vendor designed his tables to have only
fixed length CHAR, and INT values in it. The fixed length CHAR values
are, naturally, padded on the right with blanks. Of course, now that I
understand this (weird as it is to me), I know to use a SELECT which
specifically lists the columns that I want _and_ does a TRIM() on them
to remove trailing blanks. This will reduce the size, in bytes, in my
data.frame and make it easier to use the comparison operators. Given
how the vendor saves the data, I am quite surprised that they didn't
use SQLite. The tables are simple. There are no "stored procedures",
no VIEWs, no use of SCHEMAs to make subsets. Basically they just want
a simple data store, with the ability to do _simple_ joins. SQLite
seems, to me, to be a better fit than requiring the user to have a
full blown RDMS such as MS-SQL or Oracle.

Well, thanks for the whack on the head to wake me up and make me
really look at my data.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From h.wickham at gmail.com  Sat Jul 19 21:19:42 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 19 Jul 2014 14:19:42 -0500
Subject: [R] String comparison, trailing blanks make a difference.
In-Reply-To: <CAF8bMcY2g6aZ76snG6V13s_oobSL6z8fjimJO3xu3qAWKmjvvw@mail.gmail.com>
References: <CAAJSdjjuFHsqjJWe1SRe2Q_DUwtQ+SZ5RwOtseUtT9Kvau4f5A@mail.gmail.com>
	<CAF8bMcY2g6aZ76snG6V13s_oobSL6z8fjimJO3xu3qAWKmjvvw@mail.gmail.com>
Message-ID: <CABdHhvE6BgQtAL477MFRzwsmByXO0=rR55HxVAc68C=9fWrB8w@mail.gmail.com>

If you have unicode strings, you may need to do even more because
there are often multiple ways of representing the same glyph. I made a
little demo at http://rpubs.com/hadley/unicode-normalisation, since
any unicode characters are likely to get mangled by email.

Hadley

On Fri, Jul 18, 2014 at 11:32 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>"abc" == "abc "
>> [1] FALSE
>
> R does no interpretation of strings when doing comparisons so you do
> have do your own canonicalization.  That may involve removing
> trailing, leading, or all white space or punctuation, converting to
> lower or upper case, mapping nicknames to official names, trimming to
> a fixed number of characters, etc.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Jul 18, 2014 at 9:17 AM, John McKown
> <john.archie.mckown at gmail.com> wrote:
>> Well, this was a shock to me. And I don't really see any documentation
>> about it, but perhaps I just can't see it.
>>
>>>"abc" == "abc "
>> [1] FALSE
>>
>> I guess that I thought of strings in R like I do is some other
>> languages where the shorter value is padded with blanks to the length
>> of the longer value, then compared. I.e. that trailing blanks didn't
>> matter.
>>
>> The best solution that I have found is to use the str_trim() function
>> from the stringr to remove all the trailing blanks after I get the
>> data from the SQL data base. I cannot change the SQL schema to make
>> the column a varchar instead of a char column. It is a vendor DB. And
>> I don't know an ANSI SQL standard way to remove trailing blanks in the
>> SELECT command. PostgreSQL has a "trim(trailing ' ' from column)', but
>> MS-SQL upchucks on that syntax.
>>
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>>
>> Maranatha! <><
>> John McKown
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From adib.mist at gmail.com  Sat Jul 19 19:24:29 2014
From: adib.mist at gmail.com (Adib Shafi)
Date: Sat, 19 Jul 2014 13:24:29 -0400
Subject: [R] understanding the parameters of 'spca' function of 'elasticnet'
	package
In-Reply-To: <53C952A6.5010704@gmail.com>
References: <53C952A6.5010704@gmail.com>
Message-ID: <640f31fb-7ff5-49c1-b85b-c77e7845c831@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140719/7c277972/attachment.pl>

From veroandreo at gmail.com  Sat Jul 19 22:08:05 2014
From: veroandreo at gmail.com (Veronica Andreo)
Date: Sat, 19 Jul 2014 17:08:05 -0300
Subject: [R] help with script to get starting date of blooms
In-Reply-To: <2279726.ahgcekOJSd@localhost.localdomain>
References: <CAAMki4G2UPhQ=j3Dfg=eXdrudwGnzsjJCeVND7ospB4Pibzjog@mail.gmail.com>
	<2279726.ahgcekOJSd@localhost.localdomain>
Message-ID: <CAAMki4GP8u3G7oExbqQ3dWJ2fMNubOH9A5pOZEeZAFWZ6jW8Xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140719/e091c9f4/attachment.pl>

From dstr7320 at uni.sydney.edu.au  Sun Jul 20 05:00:33 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Sun, 20 Jul 2014 03:00:33 +0000
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <53C8FEB3.7080602@auckland.ac.nz>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>
	<53C7F98C.8030803@sapo.pt>
	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
	<1405652409062.49813@uni.sydney.edu.au>,
	<53C8FEB3.7080602@auckland.ac.nz>
Message-ID: <416797a65e7f401e8083b52c963e6c8e@BLUPR01MB035.prod.exchangelabs.com>

It's a plausible use-case. For example, in the example section of a help file.

if(require(aPackage))
{
  # Do computations.
  # Show beginning of first result vector.
  # Show beginning of second result vector.
}

From vishal_c64 at yahoo.com  Sun Jul 20 09:39:36 2014
From: vishal_c64 at yahoo.com (Vishal Chari)
Date: Sun, 20 Jul 2014 00:39:36 -0700
Subject: [R] (no subject)
Message-ID: <1405841976.18417.YahooMailNeo@web163106.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/4202d35b/attachment.pl>

From kevinkunzmann at gmx.net  Sun Jul 20 09:50:56 2014
From: kevinkunzmann at gmx.net (Kevin Kunzmann)
Date: Sun, 20 Jul 2014 09:50:56 +0200
Subject: [R] roxygen2
Message-ID: <53CB74E0.6050801@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/e78ac839/attachment.pl>

From j.bayat194 at gmail.com  Sun Jul 20 10:11:34 2014
From: j.bayat194 at gmail.com (javad bayat)
Date: Sun, 20 Jul 2014 12:41:34 +0430
Subject: [R] spplot help
Message-ID: <CANTxAmLiA8xPBHV47m5vk2EKPHL_wQMoFM1nqUthazmpJteMtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/23ebfc5e/attachment.pl>

From ubernerdy at gmail.com  Sun Jul 20 13:33:57 2014
From: ubernerdy at gmail.com (Ubernerdy)
Date: Sun, 20 Jul 2014 13:33:57 +0200
Subject: [R] help with column substaction with a twist
Message-ID: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/534b12ae/attachment.pl>

From jholtman at gmail.com  Sun Jul 20 15:01:30 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 20 Jul 2014 09:01:30 -0400
Subject: [R] help with column substaction with a twist
In-Reply-To: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
References: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
Message-ID: <CAAxdm-7-dJ9uOUdQb_LEps3G+ZF+zfxKEeZSJFYUCvEAGWoRKQ@mail.gmail.com>

try this:


> # generate test data
> set.seed(1)
> n <- 100
> test <- data.frame(p = sample(10, n, TRUE)
+                 , b = sample(10, n, TRUE)
+                 )
> test$e <- sample(5, n, TRUE) + test$b  # make sure e > b
> # add distance
> test$dist <- ifelse(test$p < test$b
+                 , test$p - test$b
+                 , ifelse(test$p > test$e
+                     , test$p - test$e
+                     , 0L  # within
+                     )
+                 )
> head(test, 10)
    p  b  e dist
1   3  7  9   -4
2   4  4  6    0
3   6  3  6    0
4  10 10 12    0
5   3  7  8   -4
6   9  3  6    3
7  10  2  5    5
8   7  5  6    1
9   7 10 12   -3
10  1  6 10   -5

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Jul 20, 2014 at 7:33 AM, Ubernerdy <ubernerdy at gmail.com> wrote:
> Hello guys!
>
> I have been messing around with R for a while now, but this situation has
> me a bit stumped. I was unable to solve it by reading documentation.
>
> So I have this table (currently in Excel - could export it as csv) with
> values in 3 columns. Let's call them value P (for position), value B
> (beginning) and E (end). P represents the position of a mutation in the
> genome, B and E are the beginnings and ends of a nearby gene that either
> contains the mutation or not.
>
> I am trying to compute the distance between the mutation and the gene.
>
> If the mutation is contained in the gene, that is value P is greater than B
> and lesser than E, the result is 0.
>
> If the mutation is "left" of the gene, the distance is negative and is
> equal to P-B.
>
> If the mutation is "right" of the gene, the distance is positive and is
> equal to P-E.
>
> How would i achieve this in R?
>
> Regards and thanks, S.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Jul 20 15:30:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Jul 2014 08:30:58 -0500
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <1405652409062.49813@uni.sydney.edu.au>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>	<53C7F98C.8030803@sapo.pt>	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
	<1405652409062.49813@uni.sydney.edu.au>
Message-ID: <53CBC492.1000007@gmail.com>

On 17/07/2014, 10:00 PM, Dario Strbenac wrote:
> The example in the question was not inside a user function.

The explanations you were given were slightly inaccurate.  The usual
rule is that results returned at the top level are printed unless they
are marked as invisible.  (There are a few cases where "top level" is
faked, e.g. in example code, and in Sweave.)

When you do something like

if(test) { a; b; c }

you have an expression that returns NULL invisibly if the test is FALSE,
and returns the value of the block (i.e. c) visibly if it is TRUE.  It
is the value of the if that is printed.

There is no difference in the handling of a, b and c:  each is an
expression that returns the value of the corresponding variable without
marking it as invisible.  But none of them are top-level expressions, so
none of them print.

Duncan Murdoch


From john.archie.mckown at gmail.com  Sun Jul 20 17:36:05 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 20 Jul 2014 10:36:05 -0500
Subject: [R] help with column substaction with a twist
In-Reply-To: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
References: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
Message-ID: <CAAJSdjhFPqCXP-27b3U_uii+qjh+yE9AC9DS5ouZu6ZUHuEP=w@mail.gmail.com>

On Sun, Jul 20, 2014 at 6:33 AM, Ubernerdy <ubernerdy at gmail.com> wrote:
> Hello guys!
>
> I have been messing around with R for a while now, but this situation has
> me a bit stumped. I was unable to solve it by reading documentation.
>
> So I have this table (currently in Excel - could export it as csv) with
> values in 3 columns. Let's call them value P (for position), value B
> (beginning) and E (end). P represents the position of a mutation in the
> genome, B and E are the beginnings and ends of a nearby gene that either
> contains the mutation or not.
>
> I am trying to compute the distance between the mutation and the gene.
>
> If the mutation is contained in the gene, that is value P is greater than B
> and lesser than E, the result is 0.
>
> If the mutation is "left" of the gene, the distance is negative and is
> equal to P-B.
>
> If the mutation is "right" of the gene, the distance is positive and is
> equal to P-E.
>
> How would i achieve this in R?
>
> Regards and thanks, S.
>

Jim has given you the answer in R. So why am I "shooting off my
mouth?". Well, good question! <grin/>

But I thought it might be a bit helpful to mention a couple of things.
First, you can do this same calculation in Excel by using the
=IF(logical-expression,true-expression,false-expression) in another
column on the spreadsheet. Just in case you wanted to do it in Excel
in addition to, or instead of, R. And, like the ifelse() function in
R, you can use a "nested" IF() within either, or both, of the value
expressions of the =IF. Something like:

=IF(P<B,P-B,IF(P>E,P-E,0))

where "P", "B", and "E" are replaced by the proper cell names. Of
course, the plus in R is that you can create the distance values "all
at once" because R can work with vectors. Whereas in Excel, you'll
need to put the =IF expression in every cell in the appropriate
column. I mention it only for completeness, just in case you need the
data in the spreadsheet also.

Secondly, you mentioned exporting to a csv. I would _guess_ that you
are using Windows, not a Mac nor Linux. If so, then built into Windows
is an ODBC driver for reading (and writing) from (to) an Excel
spreadsheet. Most users don't know much about ODBC, but it is there.
You might be interested:
http://www.cyberfella.co.uk/2012/06/11/windows7-odbc/
http://msdn.microsoft.com/en-us/library/windows/desktop/dn259722%28v=vs.85%29.aspx
I'm not where I can work my way through it because I'm at home on a
Linux machine. But if you need some step-by-step, I'll be glad to
_try_ on Monday when I'm back in the office. I just set up an ODBC for
accessing MS-SQL and the process is similar with Excel. Or you might
search YouTube, which is where I found out about this, albeit not
using R. On http://Youtube.com try searching on "set up odbc
connections excel" But I didn't really see too many which were
relevant. Most were how to set up ODBC to allow Excel to read from
some other database.

Anyway, once this is done, you could then read the Excel data using
the RODBC driver. Something like:

library(RODBC);
ch <- odbcConnect("Excel"); # The name of the ODBC connection you made above
data <- sqlFetch(ch,"SheetName"); # read all the data in the Excel
workbook in the tab named "SheetName"
# please forgive any errors - not where I can test today

Another possibility is to use an "R native" access via either openxlsx
or XLConnect. I use openxlsx myself, not because it is "better", but
because XLConnect uses Apache POI which means using Java which means
it is not as fast. Well, at least in my assumptions XLConnect must be
slower due to Java. I have not done any performance or reliability
testing. I have done some functionality testing and both seem to work
on my test Excel spreadsheet. In addition, these packages can also
create or replace an Excel spreadsheet by rewriting the ???.xlsx file.
Note this is not an "update in place" like with a real database.
Honestly, for me, these latter are easier to understand.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From pennytianzh at hotmail.com  Sun Jul 20 17:02:59 2014
From: pennytianzh at hotmail.com (=?gb2312?B?1cXM7Mzt?=)
Date: Sun, 20 Jul 2014 15:02:59 +0000
Subject: [R] How to determine if GARCH model has 'false convergence'
Message-ID: <BAY175-W27753FFADB808C7F1AFE0BA3F30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/dd801b8a/attachment.pl>

From ubernerdy at gmail.com  Sun Jul 20 18:05:31 2014
From: ubernerdy at gmail.com (Ubernerdy)
Date: Sun, 20 Jul 2014 18:05:31 +0200
Subject: [R] help with column substaction with a twist
In-Reply-To: <CAAJSdjhFPqCXP-27b3U_uii+qjh+yE9AC9DS5ouZu6ZUHuEP=w@mail.gmail.com>
References: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
	<CAAJSdjhFPqCXP-27b3U_uii+qjh+yE9AC9DS5ouZu6ZUHuEP=w@mail.gmail.com>
Message-ID: <CAEg5pdsY+4A67OG1yC8rFpxEs=esn5YiXd-LY-3eMKDXhPzV2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/4a304494/attachment.pl>

From anoopsshah at gmail.com  Sun Jul 20 19:28:12 2014
From: anoopsshah at gmail.com (Anoop Shah)
Date: Sun, 20 Jul 2014 18:28:12 +0100
Subject: [R] dx accuracy measures from raw data
Message-ID: <0E7574AF-9890-419E-AE9D-978860054AF2@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140720/7b85a081/attachment.pl>

From macqueen1 at llnl.gov  Sun Jul 20 23:10:55 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sun, 20 Jul 2014 21:10:55 +0000
Subject: [R] spplot help
In-Reply-To: <CANTxAmLiA8xPBHV47m5vk2EKPHL_wQMoFM1nqUthazmpJteMtA@mail.gmail.com>
References: <CANTxAmLiA8xPBHV47m5vk2EKPHL_wQMoFM1nqUthazmpJteMtA@mail.gmail.com>
Message-ID: <CFF17DE1.103360%macqueen1@llnl.gov>

I'd suggest asking this question on r-sig-geo.

spplot() uses methods from the lattice package, therefore some types of
customization require the use of methods from that package.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/20/14 1:11 AM, "javad bayat" <j.bayat194 at gmail.com> wrote:

>Dear all
>I am using spplot command to plot my raster. I make it but there is two
>problems with me.
>1- I want to have no border or greater border around the raster
>2- I want to insert a legend with a header aside from its legend.
>
>please help me.
>
>thanks in advance.
>
>-- 
>Best Regards
>Javad Bayat
>M.Sc. Environment Engineering
>Shahid Beheshti (National) University (SBU)
>Alternative Mail: bayat194 at yahoo.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Jul 21 00:46:03 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 20 Jul 2014 15:46:03 -0700
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <53CBC492.1000007@gmail.com>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>	<53C7F98C.8030803@sapo.pt>	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
	<1405652409062.49813@uni.sydney.edu.au>
	<53CBC492.1000007@gmail.com>
Message-ID: <FBA883D3-96F1-4A2B-A7E3-FFFBCDB7F8CD@comcast.net>


On Jul 20, 2014, at 6:30 AM, Duncan Murdoch wrote:

> On 17/07/2014, 10:00 PM, Dario Strbenac wrote:
>> The example in the question was not inside a user function.
> 
> The explanations you were given were slightly inaccurate.  The usual
> rule is that results returned at the top level are printed unless they
> are marked as invisible.  (There are a few cases where "top level" is
> faked, e.g. in example code, and in Sweave.)
> 
> When you do something like
> 
> if(test) { a; b; c }
> 
> you have an expression that returns NULL invisibly if the test is FALSE,
> and returns the value of the block (i.e. c) visibly if it is TRUE.  It
> is the value of the if that is printed.
> 
> There is no difference in the handling of a, b and c:  each is an
> expression that returns the value of the corresponding variable without
> marking it as invisible.  But none of them are top-level expressions, so
> none of them print.

I'm not sure what that last one was intended to mean but it seemed to imply that nothing would be printed if those expressions had values (even if the interpreter were able to find values in one of hte enclosing environments). That would not be what I expected. I think of curved-braces as a function and the results of the last evaluation would be expected to be returned:

> test <- TRUE
> a=2;b=3;c=4
> if(test){a;b;c}
[1] 4

If one of them had no value, an error would be thrown.

> rm(b)
> if(test){a;b;c}
Error: object 'b' not found

-- 

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Mon Jul 21 02:49:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Jul 2014 19:49:52 -0500
Subject: [R] Vector of Numbers Not Output to Screen
In-Reply-To: <FBA883D3-96F1-4A2B-A7E3-FFFBCDB7F8CD@comcast.net>
References: <642c0c1589c44a7a8925a4b57e7c8eb7@BLUPR01MB035.prod.exchangelabs.com>	<CAM_vjunf1BR3b9__FVw2DzZf4w49zXi5-BmX7cp1h6hcntiAdQ@mail.gmail.com>	<53C7F98C.8030803@sapo.pt>	<C58BD676-CC5F-4C9C-9940-5441E03BE43D@comcast.net>,
	<53C87CD3.4020507@auckland.ac.nz>
	<1405652409062.49813@uni.sydney.edu.au>
	<53CBC492.1000007@gmail.com>
	<FBA883D3-96F1-4A2B-A7E3-FFFBCDB7F8CD@comcast.net>
Message-ID: <53CC63B0.6010002@gmail.com>

On 20/07/2014, 5:46 PM, David Winsemius wrote:
> 
> On Jul 20, 2014, at 6:30 AM, Duncan Murdoch wrote:
> 
>> On 17/07/2014, 10:00 PM, Dario Strbenac wrote:
>>> The example in the question was not inside a user function.
>>
>> The explanations you were given were slightly inaccurate.  The usual
>> rule is that results returned at the top level are printed unless they
>> are marked as invisible.  (There are a few cases where "top level" is
>> faked, e.g. in example code, and in Sweave.)
>>
>> When you do something like
>>
>> if(test) { a; b; c }
>>
>> you have an expression that returns NULL invisibly if the test is FALSE,
>> and returns the value of the block (i.e. c) visibly if it is TRUE.  It
>> is the value of the if that is printed.
>>
>> There is no difference in the handling of a, b and c:  each is an
>> expression that returns the value of the corresponding variable without
>> marking it as invisible.  But none of them are top-level expressions, so
>> none of them print.
> 
> I'm not sure what that last one was intended to mean but it seemed to imply that nothing would be printed if those expressions had values (even if the interpreter were able to find values in one of hte enclosing environments). That would not be what I expected. I think of curved-braces as a function and the results of the last evaluation would be expected to be returned:

I don't understand your misunderstanding.  The expression "{ a; b; c }"
(ignore the quotes here and later) is found by evaluating a, then
evaluating b, then evaluating c, and the value of c is returned as the
value of the whole expression.  Braces don't affect visibility, so if c
is 4 and no error occurs, the value of "{ a; b; c }" is a visible 4.

>> test <- TRUE
>> a=2;b=3;c=4
>> if(test){a;b;c}
> [1] 4

In this case, the expression isn't "{ a; b; c }", it's "if (test) { a;
b; c }".  Since test is TRUE, that returns the value of "{ a; b; c }"
visibly, i.e. the value is 4.

If test had been FALSE, the value would be NULL, marked as invisible.
Braces don't affect visibility, but parens do, so

if (FALSE) 4

and

{if (FALSE) 4}

both print nothing, but

(if (FALSE) 4)

will print NULL.  All three versions have the value NULL, as you could
see if you assigned them to a variable, e.g.

x <- if (FALSE) 4
x
x <- {if (FALSE) 4}
x
x <- (if (FALSE) 4)
x

which will print NULL three times.

> 
> If one of them had no value, an error would be thrown.
> 
>> rm(b)
>> if(test){a;b;c}
> Error: object 'b' not found

I don't see what this has to do with the previous discussion.  If you
thought I was talking about errors in expressions, you misunderstood me.

Duncan Murdoch


From petr.pikal at precheza.cz  Mon Jul 21 08:26:02 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 21 Jul 2014 06:26:02 +0000
Subject: [R] Fwd: Plot the means with simultaneous horizontal and
 vertical error bars
In-Reply-To: <CAG6S0On30t7NaQ-H4x67Rp8CNK_3hKz=O3-ROqD32ShnKgWGhw@mail.gmail.com>
References: <CAG6S0On60gwQSzm7hwd4rWobkcyNc+NZbUgt+Op1NsCaO6ikfQ@mail.gmail.com>
	<CAG6S0OnSJvpaXStBYCZhrnvGV--y_v28oXrc9wgGYA+7rrvjxQ@mail.gmail.com>
	<CAM_vjumv+ZUJWtuXzjq1O=SoMXbfBFpjfOT-XMwpPR_ACLqSag@mail.gmail.com>
	<CAF8bMcaAnrP4tcCqLV_vP7V4dEPYw3zYDkeZAtanESWPTGhefA@mail.gmail.com>
	<CAG6S0On30t7NaQ-H4x67Rp8CNK_3hKz=O3-ROqD32ShnKgWGhw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDBFBD@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ahmed Attia
> Sent: Saturday, July 19, 2014 1:28 AM
> To: William Dunlap
> Cc: r-help
> Subject: Re: [R] Fwd: Plot the means with simultaneous horizontal and
> vertical error bars
>
> My problem is getting x and y into the PlotCI. I do not know how to use
> the dput(). But below is my data;

It does not seem to be too complicated provided you read help page.

Assuming your data is named "somedata"

dput(somedata)

or

dput(somedata[1:10,])

outputs data structure on console and if you copy/paste it to your mail, everybody can use it.

Regards
Petr


>
>
>
> x  x-Water y  150 74.67 75  150 92.2 97  150 138.2 327.5  150 140.2
> 142.6 150 194.82 333.8  150 226.31 423  150 226.56 590.9  150 240.28
> 546.6  150
> 241.55 232.3  150 243.07 454.6  350 252.7 352.8  350 257.4 459.7  350
> 260.09
> 874.2  350 260.5 272.8  350 270.25 359.8  350 272.54 1008  350 286
> 638.9 350 288.3 791  350 288.54 736  350 291.34 816.3  350 297.0 465
> 350 303.8
> 234.3  350 306.58 601.9  350 310.38 942.9  350 311.3 334.4  350 317.75
> 522.1 350 330.45 563  350 333.78 717.4  350 339.59 851.5  350 341.37
> 642  350
> 342.7 490.5  350 344.2 487.7  350 344.42 1174  350 345.4 440.7  350
> 345.44
> 243  350 349.22 834.8  350 354.48 704.9  350 363.4 885  350 365.75
> 606.7 350 366.77 1036.9  350 370.08 898.8  350 371.09 640.9  350 372.69
> 768.1  350
> 374.24 574.4  350 375.15 200.9  350 375.3 1217  350 376.17 836.4  350
> 377.7
> 949.8  350 377.7 986.9  350 382.74 458.6  350 384 456.4  350 384.3 1189
> 350
> 385.9 978.2  350 388.44 379.7  350 391.66 865.7  350 392.44 1026.8  350
> 394.3 663.7  350 398.74 533.1  350 399.72 551.6  350 402.33 341.3  350
> 410.4
> 889  350 413 1530  350 419.35 1109.8  350 421.19 802.1  350 422.4 896.8
> 350
> 422.65 995.6  350 428.49 1337  350 433.72 1304.6  350 439.2 1190.4  350
> 439.42 914.3  350 440.43 1016.9  350 443 1266.1  350 446.4 659.3  350
> 448.05
> 369.3  550 455.34 1206.2  550 456.44 1139.9  550 458.45 1541.1  550
> 461.52
> 1048.4  550 461.77 486  550 462.45 910.6  550 467.49 1257  550 470.15
> 880.1 550 471.2 1155.7  550 471.32 1275  550 475.22 570.4  550 475.48
> 1226.6  550
> 481.58 1520  550 484.52 1549.6  550 488.29 1298  550 488.73 887.1  550
> 490.98 1261  550 491.08 1519.5  550 492.76 1082.6  550 499.38 1339.3
> 550
> 501.31 1121.3  550 503.42 1216.8  550 503.87 723.6  550 505.71 1488.6
> 550
> 506.74 1613.1  550 510.77 1460.9  550 514.09 1207.1  550 518.72
> 1167.771 550 519.93 1485.1  550 523.09 1025.8  550 526.79 986.5  550
> 530.34 874.5 550 532.89 1408.8  550 534.16 1197.7  550 538.1 1235.1
> 550 542.06 1219.7 550 545.34 1176.2  550 548.89 1366.4  550 550.668
> 1248  550 551.0 1434.4 550 551.84 1092.1  550 552.95 766.5  550 553.68
> 1465.7  550 556.76 1311.6 550 557.59 1247.3  550 558 1288.3  550 558.23
> 1115.257  550 567.66 1514.2 550 571.75 1249.9  550 571.82 1320  550
> 572.8 1397.2  550 577.89 1228  550
> 578 1580.1  550 578.5 1491.3  550 582.67 1304.3  550 587.75 1188.7  550
> 590.14 1476.8  550 592.07 1644.1  550 592.1 1334.4  550 596.9 1395.7
> 550
> 600.2 1468  550 602.76 978.3  550 604.01 1183.5  550 604.57 1051.49
> 550
> 608.98 1408.4  550 610.875 1189.9  550 616.45 1647.9  550 620.7 1193.3
> 550
> 623.58 1804  550 626.6 1575.8  550 629.16 1187.8  550 635.25 1468.2
> 550
> 638.34 1276  550 640.32 982.4  550 641 1241.3  550 647.5 1452.4  550
> 649.24
> 1826.5  750 653.56 1613.7  750 660.36 1731  750 665.22 1271.6  750
> 665.92
> 1172.369  750 669.03 1403.9  750 669.03 1261  750 669.94 1582.7  750
> 671.6
> 1296.4  750 673.35 1280.7  750 675.85 1306.8  750 678.43 1697.6  750
> 679.42
> 1435.1  750 679.48 1315.4  750 682.49 930.7  750 684.68 1612.1  750
> 685.29
> 1328.3  750 702.74 1111.3  750 704.58 980.6  750 712.97 1766.4  750
> 713.996
> 1163.7  750 714.4 1458  750 715.14 1238  750 717.14 1553.6  750 718.82
> 1653.9  750 720.55 1343.4  750 729.06 1053.063  750 730.754 1132  750
> 742.0
> 1293.2  750 755.87 1564.7  750 757.42 1211.7  750 764.03 1420.6  750
> 765.25
> 1449.4  750 766.08 1839  750 768.09 1579.1  750 769 1546.7  750 772.17
> 1779.6  750 772.41 1193.6  750 777.2 1880.7  750 783.62 1558.8  750
> 785.9
> 1259.4  750 788.64 1363.6  750 790.09 1398.4  750 793.22 1157.607  750
> 805.67 1135  750 808.99 1617.3  750 812.03 1246.4  750 820.672 1362
> 750
> 831.4 1586  750 842.51 1362.5  750 852.18 1597  950 852.18 1597  950
> 861.03
> 1554.4  950 865.26 1358.2  950 870.926 1713  950 872.74 1191.2  950
> 878.83
> 1544.1  950 895.62 1651.7  950 896.59 1233.2  950 901.22 1209.8  950
> 935.58
> 1278.7  950 944.11 1215.1  950 966.12 1334.8  950 991.9 1336.9  950
> 1025.16
> 1542.5  1150 1086.35 1382  1150 1142.5 1447.2  1150 1203.15 1262.4 x is
> the x-axis and y is the y-axis. x-Water should be used to produce the
> horizontal error bars. How I can tell the program to do that.
>
> Thanks
>
> AA
>
>
> Ahmed M. Attia
>
>
> Research Assistant
> Dept. of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
> FAX: 001-308-455-4024
>
>
>
> On Fri, Jul 18, 2014 at 3:30 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
> > Is the original poster having trouble translating the synopsis at the
> > top of the help file to actual code?  He should look at the examples
> > at the bottom of the help file, or better, run them with
> >    example(plotCI)
> > and see if any of the plots looks close to what he wants.
> >
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> > On Fri, Jul 18, 2014 at 3:15 PM, Sarah Goslee
> <sarah.goslee at gmail.com>
> > wrote:
> > > The example given in ?plotCI works just fine for me. You'll need to
> > > be more specific about what isn't working, and ideally provide some
> > > data with dput().
> > > Notice the add=TRUE argument in the second call to plotCI().
> > >
> > >
> > >       y<-runif(10)
> > >       err.x<-runif(10)
> > >       err.y<-runif(10)
> > >       plotCI(1:10,y,err.y,pt.bg=par("bg"),pch=21,xlim=c(0,11),
> > > main="plotCI with extra space on the x axis")
> > >       plotCI(1:10,y,err.x,pt.bg=par("bg"),pch=21,err="x",add=TRUE)
> > >
> > > Sarah
> > >
> > > On Fri, Jul 18, 2014 at 6:06 PM, Ahmed Attia
> <ahmedatia80 at gmail.com>
> > wrote:
> > >> Hi all,
> > >>
> > >> I have been also trying the plotCI but it did not work out
> > >>
> > >> plotCI(x, y = NULL, uiw, liw = uiw, ui, li, err='y', ylim=NULL,
> > >>        xlim=NULL, type="p",  col=par("col"), barcol=col,
> > >>        pt.bg = par("bg"),  sfrac = 0.01, gap=1, lwd=par("lwd"),
> > >>        lty=par("lty"), labels=FALSE, add=FALSE, xlab, ylab,
> minbar,
> > >>        maxbar, ... )
> > >>
> > >>
> > >> I searched and looked at the previous plotCI posts below;
> > >>
> > >>
> > >>
> > >>
> > http://www.talkstats.com/showthread.php/51908-Vertical-and-
> horizontal-
> > error-bars-PlotCI-errbar
> > >>
> > >>
> > >> Dear R users,
> > >>
> > >> I would appreciate your help in plotting the means with
> > >> simultaneous horizontal and vertical error bars. I use the
> > >> lineplot.CI but it creates the vertical bars only.
> > >>
> > >>
> > >> The attached file has the dataset that I want to graph. The (X) is
> > >> the x-axis values and (y Lint) is the response in y-axis.
> > >> Therefore, values
> > in
> > >> the x-axis would be 150, 350, 550, .....etc.
> > >>
> > >> At each value of the x-axis would be the average response point (y
> > >> Lint) with vertical and horizontal error bars.
> > >>
> > >> Each value of the x-axis (X) represents a range of values that in
> x
> > Water.
> > >> The x Water column should be used to draw the horizontal lines.
> > >>
> > >> Thank you so much.
> > >>
> > >> AA
> > >>
> > >>
> > >>
> > >>
> > >> Ahmed M. Attia
> > >>
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From careyshan at gmail.com  Mon Jul 21 12:13:59 2014
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 21 Jul 2014 11:13:59 +0100
Subject: [R] plotly
Message-ID: <CA+jRDxAcwuX-yv12+Loefb59LBvno-Efx1Te9RN7P5iRdVPY4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/9f9d267a/attachment.pl>

From sarah.goslee at gmail.com  Mon Jul 21 13:05:51 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 21 Jul 2014 07:05:51 -0400
Subject: [R] plotly
In-Reply-To: <CA+jRDxAcwuX-yv12+Loefb59LBvno-Efx1Te9RN7P5iRdVPY4Q@mail.gmail.com>
References: <CA+jRDxAcwuX-yv12+Loefb59LBvno-Efx1Te9RN7P5iRdVPY4Q@mail.gmail.com>
Message-ID: <CAM_vjukhL613HUrb0Si+5WrmoW8fsvLewOPVSn01H=Hpe6cPCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/eaec9260/attachment.pl>

From tcmuigai at gmail.com  Mon Jul 21 13:24:31 2014
From: tcmuigai at gmail.com (Charles Thuo)
Date: Mon, 21 Jul 2014 14:24:31 +0300
Subject: [R] packages across different versions of R
Message-ID: <CAAJc=rPLiNcbcnUxnpSxTJmQh3vXMOPdaUygrLLY1VdW=M4jvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/3e3c706f/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Jul 21 13:53:06 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Jul 2014 12:53:06 +0100
Subject: [R] packages across different versions of R
In-Reply-To: <CAAJc=rPLiNcbcnUxnpSxTJmQh3vXMOPdaUygrLLY1VdW=M4jvw@mail.gmail.com>
References: <CAAJc=rPLiNcbcnUxnpSxTJmQh3vXMOPdaUygrLLY1VdW=M4jvw@mail.gmail.com>
Message-ID: <53CCFF22.5020600@stats.ox.ac.uk>

On 21/07/2014 12:24, Charles Thuo wrote:
>   I have just installed R 3.1.1 in a machine where R 3.0.1 is already
> installed.  Is it possible to use packages in the 3.0.1 on the 3.1.1.
> version as the same are in a single workstation.

Perhaps, perhaps not.  It depends in part on your platform which you 
have not told us (see the posting guide).  It is definitely safer to 
reinstall them.  For Window users see 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What_0027s-the-best-way-to-upgrade_003f 
: similar ideas work for other platforms.

The place where using packages for 3.0.1 is least likely to work is OS 
X, but there installing a new binary version of R by default removes 
earlier installations.

>
>
> Charles
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Rainer at krugs.de  Mon Jul 21 14:10:19 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 21 Jul 2014 14:10:19 +0200
Subject: [R] Include plotting symbals pch 16 and 17 into captions / text in
	pdf graph
Message-ID: <m2tx6aq5ec.fsf@krugs.de>


Hi

I want to include the plotting symbols pch=16 and pch=17 in text in
the graph used as labels.

This works:

--8<---------------cut here---------------start------------->8---
plot(0:1,0:1, type="n")
points(0.2, 1, pch=16)
mtext(
        text = "pch=16 (\U25CF)",
        side = 3,
        at   = 0.2,
        line = 1,
    )
points(0.8, 1, pch=17)
mtext(
        text = "pch=17 (\U25B2)",
        side = 3,
        at   = 0.8,
        line = 1
    )
--8<---------------cut here---------------end--------------->8---

But I would need this as a pdf and in Calibri font, which does not
include the UTF symbol \U25B2 (the triangle). I got that far:

--8<---------------cut here---------------start------------->8---

cairo_pdf("utftext.pdf", family="Calibri")
plot(0:1,0:1, type="n")
points(0.2, 1, pch=16)
mtext(
        text = "pch=16 (\U25CF)",
        side = 3,
        at   = 0.2,
        line = 1,
    )
points(0.8, 1, pch=17)
mtext(
        text = "pch=17 (\U25B2)",
        side = 3,
        at   = 0.8,
        line = 1
    )
dev.off()
--8<---------------cut here---------------end--------------->8---

which results in the attached pdf (hope it comes through). If not: the
utf symbol for the upward error is displayed as an empty square with a
question mark in it).

Is there a way that I can show the plotting symbol pch=17 in the caption
when using this font?

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: utftext.pdf
Type: application/pdf
Size: 19165 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/7da08222/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/7da08222/attachment.bin>

From Mark.Fowler at dfo-mpo.gc.ca  Mon Jul 21 15:40:45 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Mon, 21 Jul 2014 10:40:45 -0300
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <53C68258.7050208@gmail.com>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
	<53C68258.7050208@gmail.com>
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F80692156F@marbioexc02.mar.dfo-mpo.ca>

Hi Duncan,
I tried your suggestion, but no luck. The first error is no surprise, it
just confirms the address is lost. The second line suggests it worked,
but it didn't. The session is still remembering the original address.

> tools::startDynamicHelp(FALSE) # shut it down
Warning message:
In file(out, "wt") :
  cannot open file
'C:\Users\fowlerm\AppData\Local\Temp\1\RtmpK09I4B\Rhttpd26c04742884': No
such file or directory
> tools::startDynamicHelp(TRUE)  # start it up
starting httpd help server ... done

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: July 16, 2014 10:47 AM
To: Fowler, Mark; r-help at stat.math.ethz.ch
Subject: Re: [R] two questions - function help and 32vs64 bit sessions

On 14/07/2014, 11:42 AM, Fowler, Mark wrote:
> Hello,
> 
>  
> 
> Two unrelated questions, and neither urgent.
> 
>  
> 
> Windows 7, R 3.0.1. Using R Console, no fancy interface.
> 
>  
> 
> The function help ultimately becomes lost to a session kept running 
> for extended periods (days). I.e. with a new session if you invoke the

> Help menu 'R functions (txt)...' it activates the html help and goes 
> to the named function page. This will work fine for at least a day, 
> but typically the next day invoking the help menu in this fashion will

> fail, as R looks for a temporary address it creates on your computer. 
> This gets lost, possibly due to network administration activity. So 
> then I save and start another session with same Rdata. Trivial enough 
> but irritating. Anybody know how to restore the 'link' without ending 
> and restarting the session?

I never have sessions that last that long, so I haven't tried this, but
I'd expect you could restart the help system in this way:

tools::startDynamicHelp(FALSE) # shut it down
tools::startDynamicHelp(TRUE)  # start it up

Duncan Murdoch

> 
>  
> 
> I have a mix of 32-bit and 64-bit requirements, with 64 the default. I

> became used to starting R sessions directly from the appropriate Rdata

> workspaces. With the latest version I need to start from the generic 
> icon and then load the workspace if I want 32-bit. Anybody know a way 
> to make the Rdata files keep track of which bit version they work 
> with, or some trick that accomplishes the same objective? The 32-bit 
> requirement is usually just RODBC, and the need for it is scattered 
> over lots of workspaces. Again, trivial but a nuisance. A more 
> pragmatic motive is to not oblige users of applications to think about

> it. Any way to make a session switch 'bits' with a source file?
> 
>  
> 
> Mark Fowler
> Population Ecology Division
> Bedford Inst of Oceanography
> Dept Fisheries & Oceans
> Dartmouth NS Canada
> B2Y 4A2
> Tel. (902) 426-3529
> Fax (902) 426-9710
> Email Mark.Fowler at dfo-mpo.gc.ca <mailto:Mark.Fowler at dfo-mpo.gc.ca>
> 
> 
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From m.a.pet at students.uu.nl  Mon Jul 21 16:04:02 2014
From: m.a.pet at students.uu.nl (M.A. Pet)
Date: Mon, 21 Jul 2014 16:04:02 +0200
Subject: [R] Semi Markov warnings ( for dummies)
Message-ID: <CABrBeRkMUcWa8AJazx0HttiTxUwO24Y-4rtjhk1TjSo5s+Z3+Q@mail.gmail.com>

Een ingesloten tekst met niet-gespecificeerde tekenset is gescrubt ...
Naam: niet beschikbaar
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/b622d1a3/attachment.pl>

From murdoch.duncan at gmail.com  Mon Jul 21 16:55:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Jul 2014 10:55:11 -0400
Subject: [R] two questions - function help and 32vs64 bit sessions
In-Reply-To: <CB5182AD107F0943AEF20FD01FB8A7F80692156F@marbioexc02.mar.dfo-mpo.ca>
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
	<53C68258.7050208@gmail.com>
	<CB5182AD107F0943AEF20FD01FB8A7F80692156F@marbioexc02.mar.dfo-mpo.ca>
Message-ID: <53CD29CF.9080006@gmail.com>

On 21/07/2014 9:40 AM, Fowler, Mark wrote:
> Hi Duncan,
> I tried your suggestion, but no luck. The first error is no surprise, it
> just confirms the address is lost. The second line suggests it worked,
> but it didn't. The session is still remembering the original address.
>
> > tools::startDynamicHelp(FALSE) # shut it down
> Warning message:
> In file(out, "wt") :
>    cannot open file
> 'C:\Users\fowlerm\AppData\Local\Temp\1\RtmpK09I4B\Rhttpd26c04742884': No
> such file or directory
> > tools::startDynamicHelp(TRUE)  # start it up
> starting httpd help server ... done

This is a different error than I thought you described.  I thought 
something had shut down the server, but it looks like something has 
deleted your temporary directory.   You might be able to tell your OS 
not to do that (if it was the OS that did), or you can put your 
temporary directory in a location that is less likely to get deleted, 
e.g. by setting the TMPDIR environment variable to somewhere else before 
you start R.  For example, I typically run with TMPDIR set to C:/temp 
when I'm debugging things.

Duncan Murdoch

>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: July 16, 2014 10:47 AM
> To: Fowler, Mark; r-help at stat.math.ethz.ch
> Subject: Re: [R] two questions - function help and 32vs64 bit sessions
>
> On 14/07/2014, 11:42 AM, Fowler, Mark wrote:
> > Hello,
> >
> >
> >
> > Two unrelated questions, and neither urgent.
> >
> >
> >
> > Windows 7, R 3.0.1. Using R Console, no fancy interface.
> >
> >
> >
> > The function help ultimately becomes lost to a session kept running
> > for extended periods (days). I.e. with a new session if you invoke the
>
> > Help menu 'R functions (txt)...' it activates the html help and goes
> > to the named function page. This will work fine for at least a day,
> > but typically the next day invoking the help menu in this fashion will
>
> > fail, as R looks for a temporary address it creates on your computer.
> > This gets lost, possibly due to network administration activity. So
> > then I save and start another session with same Rdata. Trivial enough
> > but irritating. Anybody know how to restore the 'link' without ending
> > and restarting the session?
>
> I never have sessions that last that long, so I haven't tried this, but
> I'd expect you could restart the help system in this way:
>
> tools::startDynamicHelp(FALSE) # shut it down
> tools::startDynamicHelp(TRUE)  # start it up
>
> Duncan Murdoch
>
> >
> >
> >
> > I have a mix of 32-bit and 64-bit requirements, with 64 the default. I
>
> > became used to starting R sessions directly from the appropriate Rdata
>
> > workspaces. With the latest version I need to start from the generic
> > icon and then load the workspace if I want 32-bit. Anybody know a way
> > to make the Rdata files keep track of which bit version they work
> > with, or some trick that accomplishes the same objective? The 32-bit
> > requirement is usually just RODBC, and the need for it is scattered
> > over lots of workspaces. Again, trivial but a nuisance. A more
> > pragmatic motive is to not oblige users of applications to think about
>
> > it. Any way to make a session switch 'bits' with a source file?
> >
> >
> >
> > Mark Fowler
> > Population Ecology Division
> > Bedford Inst of Oceanography
> > Dept Fisheries & Oceans
> > Dartmouth NS Canada
> > B2Y 4A2
> > Tel. (902) 426-3529
> > Fax (902) 426-9710
> > Email Mark.Fowler at dfo-mpo.gc.ca <mailto:Mark.Fowler at dfo-mpo.gc.ca>
> >
> >
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From chrisaa at med.umich.edu  Mon Jul 21 17:33:59 2014
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Mon, 21 Jul 2014 15:33:59 +0000
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <1404997112.53151.YahooMailBasic@web140202.mail.bf1.yahoo.com>
References: <30411786F64EEF46856EFBA2CD9177992C2D7190@UHEXMBSPR03.umhs.med.umich.edu>
	<1404997112.53151.YahooMailBasic@web140202.mail.bf1.yahoo.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C2D7EFA@UHEXMBSPR03.umhs.med.umich.edu>

Hi Paul,
Sorry for the delayed reply.  I was away last week. I'm not clear what you want confirmed about your approach.

(a) "20.57"- computing the rejection region of the analysis.  The formulas implemented at the addresses you gave in your original post are from a reputable source - Lawless (1982) - at least that is claimed in the help file (http://www.swogstat.org/stat/Public/Help/survival1.html).  It seems that another person derived 20.57 from some combination of input.  I don't see how to back calculate what the input was from the information provided.  Perhaps elsewhere in your study protocol there is discussion of accrual time, et al. that can help you.

(b) "16" - the value of the parameter in the null hypothesis is very important as you noted in your response to Terry.  But this is not really a statistical question. It may be derived from historical data, expert opinion, regulatory mandate, or some combination of these and other factors.  Presumably this study was undertaken because 16 was an important number to somebody.

(c) performing the one-sample survival analysis itself.  This is what I did with the data you provided.

# Non-parametric
(km <- survfit(Surv(WKS, 1-CENS) ~ 1, data=hsv, type="kaplan-meier", conf.type="log", conf.int=0.9))
summary(km)

# Compare to median survival = 16
# (Used 90% CI above to get 0.05 one sided test here)
quantile(km, prob=0.5)$lower > 16

# Parametric
(paraExp <- survreg(Surv(WKS, 1-CENS) ~ 1, data=hsv, dist="exponential"))
summary(paraExp)

# Compare to median survival = 16
# That is, compare to beta0 = log(16/log(2)) = 3.1391...
# one sided test
pnorm(c((coef(paraExp) - log(16/log(2))) / sqrt(vcov(paraExp))), lower.tail=FALSE)


Chris

-----Original Message-----
From: Paul Miller [mailto:pjmiller_57 at yahoo.com] 
Sent: Thursday, July 10, 2014 8:59 AM
To: Andrews, Chris
Cc: r-help at r-project.org
Subject: RE: [R] Survival Analysis with an Historical Control


Hi Chris,

Thanks for pointing out the use of "View page source". Very helpful to know.

Do you happen to know anything about how to perform the analysis itself? I haven't been able to find anything confirming that the approach described in my original email (below) is correct. 

Thanks,

Paul

--------------------------------------------
On Wed, 7/9/14, Andrews, Chris <chrisaa at med.umich.edu> wrote:

 Subject: RE: [R] Survival Analysis with an Historical Control
 To: "Paul Miller" <pjmiller_57 at yahoo.com>, "r-help at r-project.org" <r-help at r-project.org>
 Received: Wednesday, July 9, 2014, 11:26 AM
 
 The code is actually
 available at the websites you provide.? Try "View page
 source" in your browser.? The most cryptic code
 isn't needed because the math functions (e.g, incomplete
 gamma function) are available in R.
 
 
 -----Original Message-----
 From: Paul Miller [mailto:pjmiller_57 at yahoo.com]
 
 Sent: Tuesday, July 08, 2014 12:00 PM
 To: r-help at r-project.org
 Subject: [R] Survival Analysis with an
 Historical Control
 
 Hello
 All,
 
 I'm trying to
 figure out how to perform a survival analysis with an
 historical control. I've spent some time looking online
 and in my boooks but haven't found much showing how to
 do this. Was wondering if there is a R package that can do
 it, or if there are resources somewhere that show the actual
 steps one takes, or if some knowledgeable person might be
 willing to share some code. 
 
 Here is a statement that describes the sort of
 analyis I'm being asked to do.
 
 A one-sample parametric test assuming an
 exponential form of survival was used to test the hypothesis
 that the treatment produces a median PFS no greater than the
 historical control PFS of 16 weeks.? A sample median PFS
 greater than 20.57 weeks would fall beyond the critical
 value associated with the null hypothesis, and would be
 considered statistically significant at alpha = .05, 1
 tailed.? 
 
 My understanding
 is that the cutoff of 20.57 weeks was obtained using an
 online calculator that can be found at:
 
 http://www.swogstat.org/stat/public/one_survival.htm
 
 Thus far, I've been unable
 to determine what values were plugged into the calculator to
 get the cutoff.
 
 There's
 another calculator for a nonparamertric test that can be
 found at:
 
 http://www.swogstat.org/stat/public/one_nonparametric_survival.htm
 
 It would be nice to try doing
 this using both a parameteric and a non-parametric model.
 
 So my first question would be
 whether the approach outlined above is valid or if the
 analysis should be done some other way. If the basic idea is
 correct, is it relatively easy (for a Terry Therneau type
 genius) to implement the whole thing using R? The calculator
 is a great tool, but, if reasonable, it would be nice to be
 able to look at some code to see how the numbers actually
 get produced.
 
 Below are
 some sample survival data and code in case this proves
 helpful.
 
 Thanks,
 
 Paul
 
 ###################################
 #### Example Data: GD2 Vaccine ####
 ###################################
 
 connection <-
 textConnection("
 GD2? 1???8
 12? GD2? 3 -12 10? GD2? 6 -52? 7
 GD2?
 7? 28 10? GD2? 8? 44? 6? GD2 10? 14? 8
 GD2 12???3? 8? GD2 14 -52? 9?
 GD2 15? 35 11
 GD2 18???6 13?
 GD2 20? 12? 7? GD2 23? -7 13
 GD2 24
 -52? 9? GD2 26 -52 12? GD2 28? 36 13
 GD2
 31 -52? 8? GD2 33???9 10? GD2 34 -11 16
 GD2 36 -52? 6? GD2 39? 15 14? GD2 40? 13
 13
 GD2 42? 21 13? GD2 44 -24 16? GD2 46
 -52 13
 GD2 48? 28? 9? GD2? 2? 15? 9?
 GD2? 4 -44 10
 GD2? 5? -2 12? GD2?
 9???8? 7? GD2 11? 12? 7
 GD2
 13 -52? 7? GD2 16? 21? 7? GD2 17? 19 11
 GD2 19???6 16? GD2 21? 10 16? GD2
 22 -15? 6
 GD2 25???4 15? GD2
 27? -9? 9? GD2 29? 27 10
 GD2
 30???1 17? GD2 32? 12? 8? GD2 35? 20? 8
 GD2 37 -32? 8? GD2 38? 15? 8? GD2
 41???5 14
 GD2 43? 35 13? GD2
 45? 28? 9? GD2 47???6 15
 ")
 
 hsv
 <- data.frame(scan(connection, list(VAC="",
 PAT=0, WKS=0, X=0)))
 hsv <-
 transform(hsv, CENS=ifelse(WKS < 1, 1, 0),
 WKS=abs(WKS))
 head(hsv)
 
 require("survival")
 
 survObj <- Surv(hsv$WKS,
 hsv$CENS==0) ~ 1
 
 km <-
 survfit(survObj, type=c("kaplan-meier"))
 print(km)
 
 paraExp <- survreg(survObj,
 dist="exponential")
 print(paraExp)
 
 
 **********************************************************
 Electronic Mail is not secure, may not be read
 every day, and should not be used for urgent or sensitive
 issues 
 
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From Mark.Fowler at dfo-mpo.gc.ca  Mon Jul 21 18:57:51 2014
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Mon, 21 Jul 2014 13:57:51 -0300
Subject: [R] FW:  two questions - function help and 32vs64 bit sessions
References: <CB5182AD107F0943AEF20FD01FB8A7F806920F79@marbioexc02.mar.dfo-mpo.ca>
	<53C68258.7050208@gmail.com>
	<CB5182AD107F0943AEF20FD01FB8A7F80692156F@marbioexc02.mar.dfo-mpo.ca>
	<53CD29CF.9080006@gmail.com> 
Message-ID: <CB5182AD107F0943AEF20FD01FB8A7F8069215DD@marbioexc02.mar.dfo-mpo.ca>



-----Original Message-----
From: Fowler, Mark 
Sent: July 21, 2014 1:56 PM
To: 'Duncan Murdoch'
Subject: RE: [R] two questions - function help and 32vs64 bit sessions

The server doesn't shut down, it just kind of shuts everybody else down.
But your mention of TEMPDIR jostled some old memory cells awake, and
essentially answered the question. I do [did] a similar thing with
temporary directories as you discuss, just another directory location.
But that location (R_USER) disappeared when I upgraded (one or all of R
to 2 to 3, OS XP to 7, machine 34 to 62 bit). So R has to create a temp
dir by default. I think that default directory gets derailed during
network-wide system scans, thus Tuesdays and weekends for me.

Sys.getenv('R_USER')
[1] "C:\\Users\\fowlerm\\Documents"
> tempdir()
[1] "C:\\Users\\fowlerm\\AppData\\Local\\Temp\\1\\RtmpeqbLeR"

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Sent: July 21, 2014 11:55 AM
To: Fowler, Mark; r-help at stat.math.ethz.ch
Subject: Re: [R] two questions - function help and 32vs64 bit sessions

On 21/07/2014 9:40 AM, Fowler, Mark wrote:
> Hi Duncan,
> I tried your suggestion, but no luck. The first error is no surprise, 
> it just confirms the address is lost. The second line suggests it 
> worked, but it didn't. The session is still remembering the original
address.
>
> > tools::startDynamicHelp(FALSE) # shut it down
> Warning message:
> In file(out, "wt") :
>    cannot open file
> 'C:\Users\fowlerm\AppData\Local\Temp\1\RtmpK09I4B\Rhttpd26c04742884': 
> No such file or directory
> > tools::startDynamicHelp(TRUE)  # start it up
> starting httpd help server ... done

This is a different error than I thought you described.  I thought
something had shut down the server, but it looks like something has 
deleted your temporary directory.   You might be able to tell your OS 
not to do that (if it was the OS that did), or you can put your
temporary directory in a location that is less likely to get deleted,
e.g. by setting the TMPDIR environment variable to somewhere else before
you start R.  For example, I typically run with TMPDIR set to C:/temp
when I'm debugging things.

Duncan Murdoch

>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: July 16, 2014 10:47 AM
> To: Fowler, Mark; r-help at stat.math.ethz.ch
> Subject: Re: [R] two questions - function help and 32vs64 bit sessions
>
> On 14/07/2014, 11:42 AM, Fowler, Mark wrote:
> > Hello,
> >
> >
> >
> > Two unrelated questions, and neither urgent.
> >
> >
> >
> > Windows 7, R 3.0.1. Using R Console, no fancy interface.
> >
> >
> >
> > The function help ultimately becomes lost to a session kept running 
> > for extended periods (days). I.e. with a new session if you invoke 
> > the
>
> > Help menu 'R functions (txt)...' it activates the html help and goes

> > to the named function page. This will work fine for at least a day, 
> > but typically the next day invoking the help menu in this fashion 
> > will
>
> > fail, as R looks for a temporary address it creates on your
computer.
> > This gets lost, possibly due to network administration activity. So 
> > then I save and start another session with same Rdata. Trivial 
> > enough but irritating. Anybody know how to restore the 'link'
> > without ending and restarting the session?
>
> I never have sessions that last that long, so I haven't tried this, 
> but I'd expect you could restart the help system in this way:
>
> tools::startDynamicHelp(FALSE) # shut it down
> tools::startDynamicHelp(TRUE)  # start it up
>
> Duncan Murdoch
>
> >
> >
> >
> > I have a mix of 32-bit and 64-bit requirements, with 64 the default.

> > I
>
> > became used to starting R sessions directly from the appropriate 
> > Rdata
>
> > workspaces. With the latest version I need to start from the generic

> > icon and then load the workspace if I want 32-bit. Anybody know a 
> > way to make the Rdata files keep track of which bit version they 
> > work with, or some trick that accomplishes the same objective? The 
> > 32-bit requirement is usually just RODBC, and the need for it is 
> > scattered over lots of workspaces. Again, trivial but a nuisance. A 
> > more pragmatic motive is to not oblige users of applications to 
> > think about
>
> > it. Any way to make a session switch 'bits' with a source file?
> >
> >
> >
> > Mark Fowler
> > Population Ecology Division
> > Bedford Inst of Oceanography
> > Dept Fisheries & Oceans
> > Dartmouth NS Canada
> > B2Y 4A2
> > Tel. (902) 426-3529
> > Fax (902) 426-9710
> > Email Mark.Fowler at dfo-mpo.gc.ca <mailto:Mark.Fowler at dfo-mpo.gc.ca>
> >
> >
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From 538280 at gmail.com  Mon Jul 21 20:58:00 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 21 Jul 2014 12:58:00 -0600
Subject: [R] help with column substaction with a twist
In-Reply-To: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
References: <CAEg5pdsX08yJm8uZwP2TWX3_weOjwdPKjkXz1OYjBJ_TbWSWHg@mail.gmail.com>
Message-ID: <CAFEqCdzThkd8Hy_564K_AVbLbqynOzbixcUx7JCy3uBjfHsBOw@mail.gmail.com>

Here is another approach in R (blatantly stealing Jim Holtman's code
to generate sample data):

> set.seed(1)
> n <- 100
> test <- data.frame(p = sample(10, n, TRUE)
+                 , b = sample(10, n, TRUE)
+                 )
> test$e <- sample(5, n, TRUE) + test$b  # make sure e > b
>
> tmp1 <- test$b - test$p
> tmp2 <- test$p - test$e
>
> test$dist <- pmax( tmp1, tmp2, 0 ) * sign( -tmp1 )
>
> head(test, 10)
    p  b  e dist
1   3  7  9   -4
2   4  4  6    0
3   6  3  6    0
4  10 10 12    0
5   3  7  8   -4
6   9  3  6    3
7  10  2  5    5
8   7  5  6    1
9   7 10 12   -3
10  1  6 10   -5
>

You could also skip the 2 temporary variables and just code the
differences inside the pmax and sign functions (using tmp1 will mean
not having to do the same subtraction twice).  If you are happy with
the absolute difference then you can drop the "* sign( -tmp1 )" part.

This works because if p is less than b then tmp1 will be positive and
tmp2 will be negative.  If p is between b and e then both will be
negative (and therefore 0 will be greater than both). If p is greater
than e then tmp2 will be positive and tmp1 negative.  So the maximum
value (pmax computes this for each row/pair/triplet) will be the one
of interest.


On Sun, Jul 20, 2014 at 5:33 AM, Ubernerdy <ubernerdy at gmail.com> wrote:
> Hello guys!
>
> I have been messing around with R for a while now, but this situation has
> me a bit stumped. I was unable to solve it by reading documentation.
>
> So I have this table (currently in Excel - could export it as csv) with
> values in 3 columns. Let's call them value P (for position), value B
> (beginning) and E (end). P represents the position of a mutation in the
> genome, B and E are the beginnings and ends of a nearby gene that either
> contains the mutation or not.
>
> I am trying to compute the distance between the mutation and the gene.
>
> If the mutation is contained in the gene, that is value P is greater than B
> and lesser than E, the result is 0.
>
> If the mutation is "left" of the gene, the distance is negative and is
> equal to P-B.
>
> If the mutation is "right" of the gene, the distance is positive and is
> equal to P-E.
>
> How would i achieve this in R?
>
> Regards and thanks, S.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From russell-lenth at uiowa.edu  Mon Jul 21 17:13:32 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Mon, 21 Jul 2014 15:13:32 +0000
Subject: [R] Weight, weight - do tell me
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E598D12@itsnt443.iowa.uiowa.edu>

This is a question only about terminology.

Suppose I have data categorized by three factors A, B, and C, with cell means ybar_ijk and cell frequencies n_ijk, where I, j, and k index A, B, and C respectively. And suppose I want to summarize the results for factor A by computing some sort of weighted means WM_i, averaging over indices j and k with weights w_jk. Consider these four weighting schemes:

    1. Use equal weights, w_jk = 1
    2. Use weights of w_jk = n_+jk ??(where "+" shows I summed over that index)
    3. Use weights w_jk = n_+j+ * n_++k?? (outer product of the one-factor marginal frequencies)
    4. Use weights w_ijk = n_ijk ??(only one where we use a different set of weights for each i)

Scheme 1 yields the "unweighted" or "least-squares" means, and scheme 4 yields the ordinary means for A, ignoring B and C altogether. Scheme 3 yields weighted averages over k of weighted averages over j (or vice versa).

My question is what to call these schemes, e.g., as a character argument in an R function. Preliminarily, I am calling them "equal", "proportional", "outer", and "actual". The first one is pretty obvious. But maybe there is some existing standard terminology for some or all of the others that I am unaware of (or have forgotten). Any suggestions?

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017


From rajibulmian.r at gmail.com  Mon Jul 21 17:38:14 2014
From: rajibulmian.r at gmail.com (Rajibul Mian)
Date: Mon, 21 Jul 2014 11:38:14 -0400
Subject: [R] Estimation of Zero Inflated Over dispersed Beta Binomial Using
	glamADMB()
Message-ID: <CAKHwTTs4siqM61xmGg1Sh3Sr8D736ZeUevh57FLq0qqHmcMu+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/f2b66c36/attachment.pl>

From j.wilson.13 at aberdeen.ac.uk  Mon Jul 21 18:22:20 2014
From: j.wilson.13 at aberdeen.ac.uk (Wilson, Jenny)
Date: Mon, 21 Jul 2014 16:22:20 +0000
Subject: [R] Error message for corAR1()
Message-ID: <1405959738848.74833@aberdeen.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/6c4bd047/attachment.pl>

From ksullivan7 at ucmerced.edu  Mon Jul 21 19:46:36 2014
From: ksullivan7 at ucmerced.edu (Kristynn Sullivan)
Date: Mon, 21 Jul 2014 10:46:36 -0700
Subject: [R] Generating nonlinear Poisson time series data
Message-ID: <CADDLzvLbMtMk44mCAGg_49b1r7vhBkCSGfg0GvVUoYh7r07v4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/9f0ea819/attachment.pl>

From manthasa_26 at hotmail.com  Mon Jul 21 19:56:08 2014
From: manthasa_26 at hotmail.com (Samantha PameLa)
Date: Mon, 21 Jul 2014 17:56:08 +0000
Subject: [R] deviance as a goodness of fit in GLM
In-Reply-To: <BLU176-W3254B1DACC52EC58B21AFF99F00@phx.gbl>
References: <BLU176-W38B25CEC2618846A22BC8099F00@phx.gbl>,
	<BLU176-W38BF0801E755E9B12FD2F599F00@phx.gbl>,
	<BLU176-W3254B1DACC52EC58B21AFF99F00@phx.gbl>
Message-ID: <BLU176-W431A0C33DB5C0D6331A79299F00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/f121a8ab/attachment.pl>

From wht_crl at yahoo.com  Mon Jul 21 16:54:04 2014
From: wht_crl at yahoo.com (carol white)
Date: Mon, 21 Jul 2014 07:54:04 -0700
Subject: [R] duplicated rows of a matrix
Message-ID: <1405954444.37674.YahooMailNeo@web121505.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/a616947e/attachment.pl>

From arrayprofile at yahoo.com  Mon Jul 21 20:41:38 2014
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 21 Jul 2014 11:41:38 -0700
Subject: [R] standard error of survfit.coxph()
In-Reply-To: <1404150378.93588.YahooMailNeo@web122902.mail.ne1.yahoo.com>
References: <mailman.25.1403949609.14791.r-help@r-project.org>
	<d46aec$hjjlg2@ironport9.mayo.edu>
	<1404150378.93588.YahooMailNeo@web122902.mail.ne1.yahoo.com>
Message-ID: <1405968098.66501.YahooMailNeo@web122905.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/ec5a0a60/attachment.pl>

From wdunlap at tibco.com  Mon Jul 21 21:17:24 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Jul 2014 12:17:24 -0700
Subject: [R] duplicated rows of a matrix
In-Reply-To: <1405954444.37674.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1405954444.37674.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <CAF8bMcakkLpZqnV+RUcoMoQuuO0AU-ZofEb7UPOF_7t=ggr1eQ@mail.gmail.com>

Can you give an example of duplicated() not working on the rows of a matrix?

Here is an example where it does work:
> m <- cbind(c(a=1,b=2,c=3,d=2,e=3,f=4,g=1,h=1), c(11,13,11,13,11,13,13,11))
> class(m)
[1] "matrix"
> m
  [,1] [,2]
a    1   11
b    2   13
c    3   11
d    2   13
e    3   11
f    4   13
g    1   13
h    1   11
> duplicated(m)
[1] FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE
> m[duplicated(m), ]
  [,1] [,2]
d    2   13
e    3   11
h    1   11

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Jul 21, 2014 at 7:54 AM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> is it possible to find the duplicated rows of a matrix without a loop or i have to loop over the rows? duplicated doesn't seem to be helpful
>
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From robert.b.lynch at gmail.com  Mon Jul 21 21:40:56 2014
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Mon, 21 Jul 2014 12:40:56 -0700
Subject: [R] anova.lme
Message-ID: <CACYeG1gvjEutovxLyUOJ9=WmzSMM2V8eJ1Xm4wxcNEvqqPzPSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/13ddf510/attachment.pl>

From wdunlap at tibco.com  Mon Jul 21 22:06:40 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Jul 2014 13:06:40 -0700
Subject: [R] duplicated rows of a matrix
In-Reply-To: <1405972303.3154.YahooMailNeo@web121501.mail.ne1.yahoo.com>
References: <1405954444.37674.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<CAF8bMcakkLpZqnV+RUcoMoQuuO0AU-ZofEb7UPOF_7t=ggr1eQ@mail.gmail.com>
	<1405972303.3154.YahooMailNeo@web121501.mail.ne1.yahoo.com>
Message-ID: <CAF8bMcbwW+drxvPMH=pz=_z1S28bE0OHiC=frmkbuv-eA=rPYA@mail.gmail.com>

duplicated(x), for vector or matrix x, flags any value (row for
matrices) previously seen in x.  To flag all duplicated values (rows
for matrices) you can use the following allDups() function.

   allDups <- function(x) duplicated(x) | duplicated(x, fromLast=TRUE)

> In your example, rows 2,3,4,5,8

Don't you want row 1 also, since rows 1 and 8 contain c(1,11)?  Or I
am again misinterpreting what you want?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Jul 21, 2014 at 12:51 PM, carol white <wht_crl at yahoo.com> wrote:
> I need that duplicated indicate all row indices (occurences) that are
> duplicated. In your example, rows 2,3,4,5,8
>
> Thanks.
>
> Carol
>
>
> On Monday, July 21, 2014 9:17 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>
> Can you give an example of duplicated() not working on the rows of a matrix?
>
> Here is an example where it does work:
>> m <- cbind(c(a=1,b=2,c=3,d=2,e=3,f=4,g=1,h=1), c(11,13,11,13,11,13,13,11))
>> class(m)
> [1] "matrix"
>> m
>   [,1] [,2]
> a    1  11
> b    2  13
> c    3  11
> d    2  13
> e    3  11
> f    4  13
> g    1  13
> h    1  11
>> duplicated(m)
> [1] FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE
>> m[duplicated(m), ]
>   [,1] [,2]
> d    2  13
> e    3  11
> h    1  11
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Jul 21, 2014 at 7:54 AM, carol white <wht_crl at yahoo.com> wrote:
>> Hi,
>> is it possible to find the duplicated rows of a matrix without a loop or i
>> have to loop over the rows? duplicated doesn't seem to be helpful
>>
>> Thanks
>>
>> Carol
>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From dwinsemius at comcast.net  Mon Jul 21 22:37:26 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Jul 2014 13:37:26 -0700
Subject: [R] Include plotting symbals pch 16 and 17 into captions / text
	in pdf graph
In-Reply-To: <m2tx6aq5ec.fsf@krugs.de>
References: <m2tx6aq5ec.fsf@krugs.de>
Message-ID: <9E25688E-DB11-4B28-9A2B-B6E50A3E337E@comcast.net>

It's a hack but this works:

cairo_pdf("utftext.pdf", family="Calibri")
plot(0:1,0:1, type="n")
points(0.2, 1, pch=16)
mtext(
       text = "pch=16 (\U25CF)",
       side = 3,
       at   = 0.2,
       line = 1,
   )
points(0.8, 1, pch=17); points(0.85, 1.1, pch=17, xpd=TRUE)
# par(xpd=TRUE) lets plotting go outside the usual clipping box.

mtext(
       text = "pch=17 (  )",  # makes room for the triangle
       side = 3,
       at   = 0.8,
       line = 1
   )
dev.off()

-- 
David.

On Jul 21, 2014, at 5:10 AM, Rainer M Krug wrote:

> 
> Hi
> 
> I want to include the plotting symbols pch=16 and pch=17 in text in
> the graph used as labels.
> 
> This works:
> 
> --8<---------------cut here---------------start------------->8---
> plot(0:1,0:1, type="n")
> points(0.2, 1, pch=16)
> mtext(
>        text = "pch=16 (\U25CF)",
>        side = 3,
>        at   = 0.2,
>        line = 1,
>    )
> points(0.8, 1, pch=17)
> mtext(
>        text = "pch=17 (\U25B2)",
>        side = 3,
>        at   = 0.8,
>        line = 1
>    )
> --8<---------------cut here---------------end--------------->8---
> 
> But I would need this as a pdf and in Calibri font, which does not
> include the UTF symbol \U25B2 (the triangle). I got that far:
> 
> --8<---------------cut here---------------start------------->8---
> 
> cairo_pdf("utftext.pdf", family="Calibri")
> plot(0:1,0:1, type="n")
> points(0.2, 1, pch=16)
> mtext(
>        text = "pch=16 (\U25CF)",
>        side = 3,
>        at   = 0.2,
>        line = 1,
>    )
> points(0.8, 1, pch=17)
> mtext(
>        text = "pch=17 (\U25B2)",
>        side = 3,
>        at   = 0.8,
>        line = 1
>    )
> dev.off()
> --8<---------------cut here---------------end--------------->8---
> 
> which results in the attached pdf (hope it comes through). If not: the
> utf symbol for the upward error is displayed as an empty square with a
> question mark in it).
> 
> Is there a way that I can show the plotting symbol pch=17 in the caption
> when using this font?
> 
> Thanks,
> 
> Rainer
> 
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> <utftext.pdf>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From brian.s.diggs at gmail.com  Mon Jul 21 23:07:30 2014
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Mon, 21 Jul 2014 14:07:30 -0700
Subject: [R] roxygen2
In-Reply-To: <53CB74E0.6050801@gmx.net>
References: <53CB74E0.6050801@gmx.net>
Message-ID: <53CD8112.5030506@gmail.com>

On 7/20/2014 12:50 AM, Kevin Kunzmann wrote:
> Hi,
>
> I have developed a package and would like to switch documentation to
> roxygen2 from manual :) However
>
>      >roxygen2::roxygenize()
>      First time using roxygen2 4.0. Upgrading automatically...
>      Loading required package: nleqnslv
>      Error in file(filename, "r", encoding = encoding) :
>         cannot open the connection
>      In addition:Warning messages:
>      1: In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>         there is no package called 'nleqnslv'
>      2: In file(filename, "r", encoding = encoding) :
>         cannot open file 'R/misc.R': No such file or directory
>
> gives me this, any ideas? Running R 3.1.1 and the file R/misc.R DOES
> exist. working directory is package directory.

I'd focus on the other warning message first: "there is no package 
called 'nleqnslv'". I don't see a package by that name on CRAN, though 
google helpfully suggested 'nleqslv' as something that does exist.

Do you have a line `library("nleqnslv")` in `R/misc.R`? If so, that may 
be the problem (also, if you do, you should not in general have 
`library` calls in package code; package interdependencies are handled 
by the DEPENDS and IMPORTS fields of the DESCRIPTION file). Or do you 
have a reference to "nleqnslv" in the DESCRIPTION file?

I would get the first warning message cleared up first (especially since 
the second one doesn't make sense to you) and see if the other one goes 
away.

> Best,
>
> Kevin

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From r.turner at auckland.ac.nz  Mon Jul 21 23:51:54 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 22 Jul 2014 09:51:54 +1200
Subject: [R] Semi Markov warnings ( for dummies)
In-Reply-To: <CABrBeRkMUcWa8AJazx0HttiTxUwO24Y-4rtjhk1TjSo5s+Z3+Q@mail.gmail.com>
References: <CABrBeRkMUcWa8AJazx0HttiTxUwO24Y-4rtjhk1TjSo5s+Z3+Q@mail.gmail.com>
Message-ID: <53CD8B7A.8060509@auckland.ac.nz>


If you are going to drive a car you should learn to drive.  Read the 
basic intro material for R.

Where does the function "readdata" come from?  The syntax you use 
(having an assignment inside the function call) is let us say unorthodox 
and highly inadvisable.

Since you got an error reading in your data, where did the data that you 
are trying to analyse come from?

Don't call your data "data".  See fortune(77).

You don't say where the function semiMarkov() comes from; presumably 
from the package "semiMarkov".  Say so.  Do not expect your readers to 
be telepathic.

Don't use Excel to do *anything* (except store data, if you *must*).

I certainly can't help you to debug your errors/warnings without seeing 
your data.  I doubt that anyone else can either.  (I *could* be wrong 
about that; there are some *very* clever and intuitive people on this list.)

cheers,

Rolf Turner

On 22/07/14 02:04, M.A. Pet wrote:
> *Hello,*
>
> I never worked with R before my supervisor asks me to run a semiMarkov
> analysis a month ago. After a long struggle, to date, the code works, but I
> still get some warnings. However, because of my lack of knowledge in R I am
> not possible to figure out the problems or say anything about the influence
> of these warnings on my outcome. Hopefully, someone would help me with
> these ( I think basic) questions.
>
>
> What is the case? I want to do a semiMarkov analysis with 3 states (state
> n, state s and state e). Wherefore I want to run the analysis to see
> whether there is a difference in Hazard Ratio between transitions n? e and s? e.
> Therefore, I???ve got data of nearly 60 persons. In excel, every worksheet
> reflects a person.  To answer my research question I tried to run the
> script for one person.
>
> Unfortunately, I get the following error:
>
>> # read data and convert to correct format (and print tail).
>
>> data <- readdata( input <- 'E1_tijd_stress.csv' )
>
> Error in `$<-.data.frame`(`*tmp*`, "state", value = "s") :
>
>    replacement has 1 row, data has 0
>
> Called from: `$<-`(`*tmp*`, "state", value = "s")
>
>
>
> Furthermore, I used a macro in excel to merge these worksheets into one
> worksheet ( all persons in one file) . However, after running the script I
> saw the following warnings:
>
>> # semi-Markov model without covariates.
>
>> fit.semi.markov <- semiMarkov( data = data, states = states.semi.markov, mtrans = mtrans.semi.markov )
>
>
>
> Iter: 1 fn: 11224.5658  Pars:  1000.00000 412.24725 261.14293
> 66.30789   1.67507   5.59420   0.55746   1.37715   0.59734   0.48604
> 0.73281   0.74205
>
> Iter: 2 fn: 11224.5658  Pars:  1000.00000 412.24425 261.14508
> 66.30635   1.67506   5.59420   0.55746   1.37716   0.59734   0.48604
> 0.73281   0.74206
>
> solnp--> Completed in 2 iterations
>
> Warning messages:
>
> 1: In .safefunx(tmpv, .solnp_fun, .env, ...) :
>
> solnp-->warning: Inf detected in function call...check your function
>
>
> These repeated for 7 times. Or the following warning:
>
>> fit.semi.markov <- semiMarkov( data = data, states = states.semi.markov, mtrans = mtrans.semi.markov )
>
> Iter: 1 fn: 444562.8860         Pars:  1.00000 1.00000 1.00000 1.00000
> 1.00000 1.00000 1.00000 1.00000 1.00000 0.47882 0.72691 0.74627
>
> solnp--> Completed in 1 iterations
>
> Error in svd(X) : infinite or missing values in 'x'
>
> In addition: There were 29 warnings (use warnings() to see them)
>
> 29: In .safefunx(tmpv, .solnp_fun, .env, ...) :
>
> solnp-->warning: NaN detected in function call...check your function
>
>
> Furthermore, I want to control the analysis for some covariates.
>
>> # semi-Markov model with covariates
>
>> fit2 <- semiMarkov( data = data,cov= as.data.frame(data$stress.score), states = states, mtrans = mtrans )
>
> Error in mtrans[as.numeric(substring(trans.hh[i], first = 1, last = 1)),  :
>
>    subscript out of bounds
>
>
> Is someone able to tell me what these warnings exactly mean? Or someone I
> can contact to discuss about this? I understand inf and NaN for example but
> I am not able to figure out what to change in my data format of script (
> the problem is, some of my data run without problems, some does not).
> Hopefully I give enough information, otherwise let me know.
>
> Thank you!
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Rolf Turner
Technical Editor ANZJS


From jfox at mcmaster.ca  Tue Jul 22 03:40:14 2014
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 21 Jul 2014 21:40:14 -0400
Subject: [R] Help with SEM package - model significance
In-Reply-To: <1405989292.40356.YahooMailNeo@web126202.mail.ne1.yahoo.com>
References: <1402888531.88041.YahooMailNeo@web126206.mail.ne1.yahoo.com>
	<web-514722018@cgpsrv2.cis.mcmaster.ca>
	<1405989292.40356.YahooMailNeo@web126202.mail.ne1.yahoo.com>
Message-ID: <web-519505364@cgpsrv2.cis.mcmaster.ca>

Dear Bernado,

 This isn't really a suitable topic to pursue on the r-help list, so I'll just comment briefly:

On Mon, 21 Jul 2014 17:34:52 -0700
 Bernardo Santos <bernardo_brandaum at yahoo.com.br> wrote:
> Hi John,
> 
> Thanks for your reply (1 month later lol).
> In fact maybe the point is that I do not understand exactly the role of latent variables (what they are, and how to define them in R) in SEM.
> Do you have any suggestion of easy basic literature on SEM that can help me with that?
> Most things I have read are old (and use some different statistics programs) and offer examples too far from ecology, than I had some difficulties to understand the method in general.
> 

I have some materials at <http://socserv.mcmaster.ca/jfox/Courses/sem-goettingen/index.html> from a recent workshop on SEMs, including some reading and suggestions for reading, but not I'm afraid from ecology.
 
> But, as far as I understood, SEM is like a simple multiple regression (linear model), but that takes into account the relation of different variables simultaneously, isn't that?
> 

In SEMs the response variable from one regression equation can be an explanatory variable in another, and the models can incorporate latent variables, which aren't measured directly, but rather indirectly through their observable effects ("indicators") or even in some cases through their observable causes.

I hope this helps,
 John

> Thank you very much.
> Best regards,
> 
> Bernardo
> 
> 
> 
> Em Segunda-feira, 16 de Junho de 2014 8:40, John Fox <jfox at mcmaster.ca> escreveu:
>  
> 
> 
> Dear Bernardo,
> 
> The df for the LR chisquare over-identification test come not from the number of observations, but from the difference between the number of observable variances and covariances, on the one hand, and free parameters to estimate, on the other. In your case, these numbers are equal, and so df = 0. The LR chisquare for a just-identified model is also necessarily 0: the model perfectly reproduces the covariational structure of the observed variables. 
> 
> R (and most statistical software) by default writes very small and very large numbers in scientific format. In your case, -2.873188e-13 = -2.87*10^-13, that is, 0 within rounding error. You can change the way numbers are printed with the R scipen option.
> 
> Some other observations:
> 
> (1) Your model is recursive and has no latent variables; you would get the same estimates from OLS regression using lm().
> 
> (2) For quite some time now, the sem package has included specifyEquations() as a more convenient way of specifying a model, in preference to specifyModel(). See ?specifyEquations.
> 
> (3) You don't have to specify the error variances directly; specifyEquations(), or specifyModel(), will supply them.
> 
> I hope this helps,
> John
> 
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> ??? 
> ??? 
> On Sun, 15 Jun 2014 20:15:31 -0700 (PDT)
> Bernardo Santos <bernardo_brandaum at yahoo.com.br> wrote:
> > Dear all,?
> > 
> > I used "sem" function from the package SEM to fit a model. However, I cannot say if the model is correspondent to the data or not (chisquare test).
> > I used the commands:
> > 
> > model1 <- specifyModel()
> > estadio -> compflora, a1, NA
> > estadio -> compfauna, a2, NA
> > estadio -> interacoesobs, a3, NA
> > compflora -> compfauna, b1, NA
> > compflora -> interacoesobs, b2, NA
> > compfauna -> interacoesobs, c1, NA
> > estadio <-> estadio, e1, NA
> > compflora <-> compflora, e2, NA
> > compfauna <-> compfauna, e3, NA
> > interacoesobs <-> interacoesobs, e4, NA
> > 
> > sem1 <- sem(model1, cov.matrix, length(samples))
> > summary(sem1)
> > 
> > and I got the result:
> > 
> > Model Chisquare =? -2.873188e-13?  Df =? 0 Pr(>Chisq) = NA AIC =? 20 BIC =? -2.873188e-13 Normalized Residuals Min.?  1st Qu.? ? Median? ? ? Mean?  3rd Qu.? ? ? Max. 
> > 0.000e+00 0.000e+00 2.957e-16 3.193e-16 5.044e-16 8.141e-16? R-square for Endogenous Variables compflora? ?  compfauna interacoesobs? 0.0657? ? ? ? 0.1056? ? ? ? 0.2319? Parameter Estimates Estimate? ?  Std Error? ? z value? ? Pr(>|z|)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
> > a1 3.027344e-01 1.665395e-01 1.81779316 6.909575e-02 compflora <--- estadio? ? ? ? ? 
> > a2 2.189427e-01 1.767404e-01 1.23878105 2.154266e-01 compfauna <--- estadio? ? ? ? ? 
> > a3 7.314192e-03 1.063613e-01 0.06876742 9.451748e-01 interacoesobs <--- estadio? ? ? 
> > b1 2.422906e-01 1.496290e-01 1.61927587 1.053879e-01 compfauna <--- compflora? ? ? ? 
> > b2 3.029933e-01 9.104901e-02 3.32780446 8.753328e-04 interacoesobs <--- compflora? ? 
> > c1 4.863368e-02 8.638177e-02 0.56300857 5.734290e-01 interacoesobs <--- compfauna? ? 
> > e1 6.918133e+04 1.427102e+04 4.84767986 1.249138e-06 estadio <--> estadio? ? ? ? ? ? 
> > e2 9.018230e+04 1.860319e+04 4.84767986 1.249138e-06 compflora <--> compflora? ? ? ? 
> > e3 9.489661e+04 1.957568e+04 4.84767986 1.249138e-06 compfauna <--> compfauna? ? ? ? 
> > e4 3.328072e+04 6.865289e+03 4.84767986 1.249138e-06 interacoesobs <--> interacoesobs Iterations =? 0 
> > 
> > I understand the results, but I do not know how to interpret the first line that tells me about the model:
> > Model Chisquare =? -2.873188e-13?  Df =? 0 Pr(>Chisq) = NA
> > 
> > How can DF be zero, if the number of observations I used in sem funcition was 48 and I have only 4 variables? What is the p value?
> > 
> > Thanks in advance.
> > Bernardo Niebuhr
> > ??? [[alternative HTML version deleted]]
> > 

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From john.archie.mckown at gmail.com  Tue Jul 22 04:24:22 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 21 Jul 2014 21:24:22 -0500
Subject: [R] Application design.
Message-ID: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>

I'm designing an R based application for my boss. It's not much, but
it might save him some time. What it will be doing is reading data
from an MS-SQL database and creating a number of graphs. At present,
he must log into one server to run a vendor application to display the
data in a grid. He then cuts this data and pastes it into an Excel
spreadsheet. He then generates some graphs in Excel. Which he then
cuts and pastes into a Power Point presentation. Which is the end
result for distribution to others up the food chain.

What I would like to do is read the MS-SQL data base using RODBC and
create the graphs using ggplot2 instead of using Excel. I may end up
being told to create an Excel file as well.

My real question is organizing the R programs to do this. Basically
what I was thinking of was a "master" program. It does the ODBC work
and fetches the data into one, or more, data.frames. I was then
thinking that it would be better to have separate source files for
each graph produced. I would use the source() function in the "master"
R program to load & execute each one in order. Is this a decent
origination? Or would it be better for each "create a graph" R file to
really just define a unique function which the "master" program would
then invoke? I guess this latter would be a good way to keep the
workspace "clean" since all the variables in the functinon would "go
away" when the function ended.

I guess what I'm asking is how others organize the R applications. Oh,
I plan for this to be run by my boss by double clicking on the
"master" R source file, which I will associate with the Rscript
program in Windows. Yes, this is Windows based <sigh/>.

Appreciate your thoughts. Especially if I'm really off track.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From rmh at temple.edu  Tue Jul 22 04:49:40 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 21 Jul 2014 22:49:40 -0400
Subject: [R] Application design.
In-Reply-To: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
References: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
Message-ID: <CAGx1TMCqNXU70yN9ZX+=d1-uFa3jx7O7=HFhOFC8t+d+d0OuWA@mail.gmail.com>

Since your boss is Excel based, you might want to give the appearance
of staying in
that environment.  Take a look at RExcel and RWord, both at rcom.univie.ac.at
RExcel is a seamless integration of Excel and R.

See the book R through Excel that Erich Neuwirth (the author of
RExcel) and I wrote.
http://www.springer.com/mathematics/computational+science+%26+engineering/book/978-1-4419-0051-7

Rich

On Mon, Jul 21, 2014 at 10:24 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> I'm designing an R based application for my boss. It's not much, but
> it might save him some time. What it will be doing is reading data
> from an MS-SQL database and creating a number of graphs. At present,
> he must log into one server to run a vendor application to display the
> data in a grid. He then cuts this data and pastes it into an Excel
> spreadsheet. He then generates some graphs in Excel. Which he then
> cuts and pastes into a Power Point presentation. Which is the end
> result for distribution to others up the food chain.
>
> What I would like to do is read the MS-SQL data base using RODBC and
> create the graphs using ggplot2 instead of using Excel. I may end up
> being told to create an Excel file as well.
>
> My real question is organizing the R programs to do this. Basically
> what I was thinking of was a "master" program. It does the ODBC work
> and fetches the data into one, or more, data.frames. I was then
> thinking that it would be better to have separate source files for
> each graph produced. I would use the source() function in the "master"
> R program to load & execute each one in order. Is this a decent
> origination? Or would it be better for each "create a graph" R file to
> really just define a unique function which the "master" program would
> then invoke? I guess this latter would be a good way to keep the
> workspace "clean" since all the variables in the functinon would "go
> away" when the function ended.
>
> I guess what I'm asking is how others organize the R applications. Oh,
> I plan for this to be run by my boss by double clicking on the
> "master" R source file, which I will associate with the Rscript
> program in Windows. Yes, this is Windows based <sigh/>.
>
> Appreciate your thoughts. Especially if I'm really off track.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wht_crl at yahoo.com  Mon Jul 21 21:51:43 2014
From: wht_crl at yahoo.com (carol white)
Date: Mon, 21 Jul 2014 12:51:43 -0700
Subject: [R] duplicated rows of a matrix
In-Reply-To: <CAF8bMcakkLpZqnV+RUcoMoQuuO0AU-ZofEb7UPOF_7t=ggr1eQ@mail.gmail.com>
References: <1405954444.37674.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<CAF8bMcakkLpZqnV+RUcoMoQuuO0AU-ZofEb7UPOF_7t=ggr1eQ@mail.gmail.com>
Message-ID: <1405972303.3154.YahooMailNeo@web121501.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/11ad09b2/attachment.pl>

From ronald.koelpin at ruhr-uni-bochum.de  Mon Jul 21 21:10:24 2014
From: ronald.koelpin at ruhr-uni-bochum.de (=?ISO-8859-1?Q?Ronald_K=F6lpin?=)
Date: Mon, 21 Jul 2014 21:10:24 +0200
Subject: [R] Maximum likelihood estimation (stats4::mle)
Message-ID: <53CD65A0.3070102@ruhr-uni-bochum.de>

Dear R-Community,

I'm trying to estimate the parameters of a probability distribution
function by maximum likelihood estimation (using the stats4 function
mle()) but can't seem to get it working.

For each unit of observation I have a pair of observations (a, r)
which I assume (both) to be log-normal distributed (iid). Taking the
log of both values I have (iid) normally distributed random variables
and the likelihood function to be estimated is:

L = Product(F(x_i) - F(y_i), i=1..n)

where F is the Normal PDF and (x,y) := (log(a), log(r)). Taking the
log and multiplying by -1 gives the negative loglikelihood

l = Sum(log( F(x_i) - F(y_i) ), i=1..n)

However estimation by mle() produces the error "vmmin is not finite"
and "NaN have been created" - even though put bound on the parameters
mu and sigma (see code below).


library("stats4")

gaps <- matrix(nrow=10, ncol=4, dimnames=list(c(1:10),c("r_i", "a_i",
"log(r_i)", "log(a_i)")))
gaps[,1] <- c(2.6, 1.4, 2.2, 2.9, 2.9, 1.7, 1.3, 1.7, 3.8, 4.5)
gaps[,2] <- c(9.8, 20.5, 8.7, 7.2, 10.3, 11, 4.5, 5.2, 6.7, 7.6)
gaps[,3] <- log(gaps[,1])
gaps[,4] <- log(gaps[,2])

nll <- function(mu, sigma)
{
    if(sigma >= 0 && mu >= 0)
    {
        -sum(log(pnorm(gaps[,3], mean=mu, sd=sigma) - pnorm(gaps[,4],
mean=mu, sd=sigma)))
    }
    else
    {
        NA
    }
}

fit <- mle(nll, start=list(mu=0, sigma=1), nobs=10)
print(fit)


To be honest, I'm stumped and don't quite know what the problem is...

Regards and Thanks,

Ronald K?lpin


From wht_crl at yahoo.com  Mon Jul 21 21:55:52 2014
From: wht_crl at yahoo.com (carol white)
Date: Mon, 21 Jul 2014 12:55:52 -0700
Subject: [R] 1st el of a list of vectors
Message-ID: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/e7c41898/attachment.pl>

From wht_crl at yahoo.com  Mon Jul 21 22:33:05 2014
From: wht_crl at yahoo.com (carol white)
Date: Mon, 21 Jul 2014 13:33:05 -0700
Subject: [R] odd, even indices of a vector
Message-ID: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/2fea19b7/attachment.pl>

From arrayprofile at yahoo.com  Mon Jul 21 23:26:06 2014
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 21 Jul 2014 14:26:06 -0700
Subject: [R] standard error of survfit.coxph()
In-Reply-To: <d46aec$hjjlg2@ironport9.mayo.edu>
References: <mailman.25.1403949609.14791.r-help@r-project.org>
	<d46aec$hjjlg2@ironport9.mayo.edu>
Message-ID: <1405977966.9303.YahooMailNeo@web122903.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/6461c65d/attachment.pl>

From arrayprofile at yahoo.com  Mon Jul 21 23:36:08 2014
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 21 Jul 2014 14:36:08 -0700
Subject: [R] standard error of survfit.coxph()
In-Reply-To: <1405968098.66501.YahooMailNeo@web122905.mail.ne1.yahoo.com>
References: <mailman.25.1403949609.14791.r-help@r-project.org>
	<d46aec$hjjlg2@ironport9.mayo.edu>
	<1404150378.93588.YahooMailNeo@web122902.mail.ne1.yahoo.com>
	<1405968098.66501.YahooMailNeo@web122905.mail.ne1.yahoo.com>
Message-ID: <1405978568.35516.YahooMailNeo@web122903.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/fea08f95/attachment.pl>

From bernardo_brandaum at yahoo.com.br  Tue Jul 22 02:34:52 2014
From: bernardo_brandaum at yahoo.com.br (Bernardo Santos)
Date: Mon, 21 Jul 2014 17:34:52 -0700
Subject: [R] Help with SEM package - model significance
In-Reply-To: <web-514722018@cgpsrv2.cis.mcmaster.ca>
References: <1402888531.88041.YahooMailNeo@web126206.mail.ne1.yahoo.com>
	<web-514722018@cgpsrv2.cis.mcmaster.ca>
Message-ID: <1405989292.40356.YahooMailNeo@web126202.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140721/a48d425f/attachment.pl>

From dwinsemius at comcast.net  Tue Jul 22 06:04:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Jul 2014 21:04:30 -0700
Subject: [R] Maximum likelihood estimation (stats4::mle)
In-Reply-To: <53CD65A0.3070102@ruhr-uni-bochum.de>
References: <53CD65A0.3070102@ruhr-uni-bochum.de>
Message-ID: <5E661D07-64AE-4AFC-B282-A29D9AD2E584@comcast.net>


On Jul 21, 2014, at 12:10 PM, Ronald K?lpin wrote:

> Dear R-Community,
> 
> I'm trying to estimate the parameters of a probability distribution
> function by maximum likelihood estimation (using the stats4 function
> mle()) but can't seem to get it working.
> 
> For each unit of observation I have a pair of observations (a, r)
> which I assume (both) to be log-normal distributed (iid). Taking the
> log of both values I have (iid) normally distributed random variables
> and the likelihood function to be estimated is:
> 
> L = Product(F(x_i) - F(y_i), i=1..n)
> 
> where F is the Normal PDF and (x,y) := (log(a), log(r)). Taking the
> log and multiplying by -1 gives the negative loglikelihood

I don't see the need to multiply by -1. The log of any probability is of necessity less than (or possibly equal to) 0 since probabilities are bounded above by 1. So sums of these number will be negative which then allows you to maximize their sums.

> 
> l = Sum(log( F(x_i) - F(y_i) ), i=1..n)
> 
> However estimation by mle() produces the error "vmmin is not finite"


As I would have predicted. If one maximizes numbers that get larger as probabilities get small this is what would be expected.

-- 
David.

> and "NaN have been created" - even though put bound on the parameters
> mu and sigma (see code below).
> 
> 
> library("stats4")
> 
> gaps <- matrix(nrow=10, ncol=4, dimnames=list(c(1:10),c("r_i", "a_i",
> "log(r_i)", "log(a_i)")))
> gaps[,1] <- c(2.6, 1.4, 2.2, 2.9, 2.9, 1.7, 1.3, 1.7, 3.8, 4.5)
> gaps[,2] <- c(9.8, 20.5, 8.7, 7.2, 10.3, 11, 4.5, 5.2, 6.7, 7.6)
> gaps[,3] <- log(gaps[,1])
> gaps[,4] <- log(gaps[,2])
> 
> nll <- function(mu, sigma)
> {
>    if(sigma >= 0 && mu >= 0)
>    {
>        -sum(log(pnorm(gaps[,3], mean=mu, sd=sigma) - pnorm(gaps[,4],
> mean=mu, sd=sigma)))
>    }
>    else
>    {
>        NA
>    }
> }
> 
> fit <- mle(nll, start=list(mu=0, sigma=1), nobs=10)
> print(fit)
> 
> 
> To be honest, I'm stumped and don't quite know what the problem is...
> 
> Regards and Thanks,
> 
> Ronald K?lpin
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Tue Jul 22 06:08:30 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 22 Jul 2014 00:08:30 -0400
Subject: [R] odd, even indices of a vector
In-Reply-To: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <CAGx1TMC7WdSODB0x6Uegpsp4SYDcmyp0LXxsC-S4wshT3D_naQ@mail.gmail.com>

## these functions assume the argument is integer

odd <- function(x) x%%2 != 0

even <- function(x) x%%2 == 0

evenb <- function(x) !odd(x)

odd(1:10)
even(1:10)
evenb(1:10)

On Mon, Jul 21, 2014 at 4:33 PM, carol white <wht_crl at yahoo.com> wrote:
> Might be a trivial question but how to identify the odd and even indices of a vector?
>
> x = c(1,z,w,2,6,7)
>
> el of odd indices= 1,w,6
> el of even indices= z,2,7
>
> given the def of odd and even in https://stat.ethz.ch/pipermail/r-help/2010-July/244299.html
>
> should a loop be used?
>
> for (i in 1: length(x))
> if (is.odd(i)) print (i)
>
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Jul 22 06:10:27 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 22 Jul 2014 00:10:27 -0400
Subject: [R] 1st el of a list of vectors
In-Reply-To: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>

l = list(c(1,2), c(3,5,6), c(7))

sapply(l, `[`, 1)

On Mon, Jul 21, 2014 at 3:55 PM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> If we have a list of vectors of different lengths, how is it possible to retrieve the first element of the vectors of the list?
>
>
> l = list(c(1,2), c(3,5,6), c(7))
>
> 1,3,7 should be retrieved
>
> Thanks
>
> Carol
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Jul 22 06:10:39 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Jul 2014 21:10:39 -0700
Subject: [R] odd, even indices of a vector
In-Reply-To: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <CACk-te2D3YZnU1X2tHoa7h=q_CGqZ4v4uC3bwZ0bNQXDF3FV1g@mail.gmail.com>

Ms. White:

Unless I have seriously misjudged, you really really really need to go
through an R tutorial -- An Intro to R ships with R, but there are
many on the web -- before posting here further. You do not appear to
have made much of an effort to learn even the basics, and I consider
it unfair to post questions here on basic matters that a tutorial
would tell you about.

And, of course, my apologies if I have gotten it wrong.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Jul 21, 2014 at 1:33 PM, carol white <wht_crl at yahoo.com> wrote:
> Might be a trivial question but how to identify the odd and even indices of a vector?
>
> x = c(1,z,w,2,6,7)
>
> el of odd indices= 1,w,6
> el of even indices= z,2,7
>
> given the def of odd and even in https://stat.ethz.ch/pipermail/r-help/2010-July/244299.html
>
> should a loop be used?
>
> for (i in 1: length(x))
> if (is.odd(i)) print (i)
>
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fhcrc.org  Tue Jul 22 07:37:59 2014
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 21 Jul 2014 22:37:59 -0700
Subject: [R] odd, even indices of a vector
In-Reply-To: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1405974785.97377.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <53CDF8B7.2090005@fhcrc.org>

Hi Carol,

On 07/21/2014 01:33 PM, carol white wrote:
> Might be a trivial question but how to identify the odd and even indices of a vector?
>
> x = c(1,z,w,2,6,7)
>
> el of odd indices= 1,w,6
> el of even indices= z,2,7

The easiest way is to subset your vector with c(TRUE, FALSE) to keep
only the odd indices:

   > letters[c(TRUE, FALSE)]
   [1] "a" "c" "e" "g" "i" "k" "m" "o" "q" "s" "u" "w" "y"

and with c(FALSE, TRUE) to keep only the even indices:

   > letters[c(FALSE, TRUE)]
   [1] "b" "d" "f" "h" "j" "l" "n" "p" "r" "t" "v" "x" "z"

Note that the above doesn't work properly with vector of length < 2.

A method that works independently of the length of the vector (using
the is.odd and is.even functions from the "identifying odd or even
number" post that you referred to):

   x[is.odd(seq_along(x))]

   x[is.even(seq_along(x))]

Hope this helps,
H.

>
> given the def of odd and even in https://stat.ethz.ch/pipermail/r-help/2010-July/244299.html
>
> should a loop be used?
>
> for (i in 1: length(x))
> if (is.odd(i)) print (i)
>
>
> Carol
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Tue Jul 22 07:54:32 2014
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 21 Jul 2014 22:54:32 -0700
Subject: [R] 1st el of a list of vectors
In-Reply-To: <CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>
References: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>
Message-ID: <53CDFC98.9050706@fhcrc.org>

Hi Carol,

On 07/21/2014 09:10 PM, Richard M. Heiberger wrote:
> l = list(c(1,2), c(3,5,6), c(7))
>
> sapply(l, `[`, 1)

Using sapply() works but won't be very efficient if you have a very long
list. If you worry about efficiency, you can do the following (using the
IRanges package from Bioconductor):

   > library(IRanges)
   > eltlens <- elementLengths(l)
   > unlist(l, use.names=FALSE)[cumsum(eltlens) - eltlens + 1L]
   [1] 1 3 7

Only worth if the length of your list is > 100000 though...

Cheers,
H.

PS: See http://bioconductor.org/packages/release/bioc/html/IRanges.html
for how to install the IRanges package.

>
> On Mon, Jul 21, 2014 at 3:55 PM, carol white <wht_crl at yahoo.com> wrote:
>> Hi,
>> If we have a list of vectors of different lengths, how is it possible to retrieve the first element of the vectors of the list?
>>
>>
>> l = list(c(1,2), c(3,5,6), c(7))
>>
>> 1,3,7 should be retrieved
>>
>> Thanks
>>
>> Carol
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From muliadarius at gmail.com  Tue Jul 22 06:46:55 2014
From: muliadarius at gmail.com (Darius Mulia)
Date: Tue, 22 Jul 2014 00:46:55 -0400
Subject: [R] I need help in seeing the code
Message-ID: <CABnVHvByG+A-DX16KTTcAVsZk+Z3VadzAiYrGvwDTfRvC=oH+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/d1257358/attachment.pl>

From sarah.goslee at gmail.com  Tue Jul 22 08:21:53 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 22 Jul 2014 02:21:53 -0400
Subject: [R] I need help in seeing the code
In-Reply-To: <CABnVHvByG+A-DX16KTTcAVsZk+Z3VadzAiYrGvwDTfRvC=oH+A@mail.gmail.com>
References: <CABnVHvByG+A-DX16KTTcAVsZk+Z3VadzAiYrGvwDTfRvC=oH+A@mail.gmail.com>
Message-ID: <CAM_vju=WhgWxnB_qVzqqJUB8DnjzDhfEOzKTF3JNwRGgmhMmJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/4093495c/attachment.pl>

From petr.pikal at precheza.cz  Tue Jul 22 08:31:11 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 22 Jul 2014 06:31:11 +0000
Subject: [R] I need help in seeing the code
In-Reply-To: <CAM_vju=WhgWxnB_qVzqqJUB8DnjzDhfEOzKTF3JNwRGgmhMmJA@mail.gmail.com>
References: <CABnVHvByG+A-DX16KTTcAVsZk+Z3VadzAiYrGvwDTfRvC=oH+A@mail.gmail.com>
	<CAM_vju=WhgWxnB_qVzqqJUB8DnjzDhfEOzKTF3JNwRGgmhMmJA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDC1C6@SRVEXCHMBX.precheza.cz>

Hi

Anyway. AFAIK your code looks OK to me, provided you want find the number of rows without NA in each file.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Sarah Goslee
> Sent: Tuesday, July 22, 2014 8:22 AM
> To: Darius Mulia
> Cc: r-help at r-project.org
> Subject: Re: [R] I need help in seeing the code
>
> Hi Darius,
>
> This is the main R-help list. We don't know anything about your
> Coursera class, including what your code is supposed to do. Not only
> that, this list has a no homework policy.
>
> You need to use the discussion group associated with your course, or
> whatever materials it provides, to get assistance.
>
> Sarah
>
> On Tuesday, July 22, 2014, Darius Mulia <muliadarius at gmail.com> wrote:
>
> > Hi there,
> >
> > I am Darius and I am taking the R Programming course in Coursera. I
> > have a problem that I had spent so much looking for the problem. I
> > wrote my code and I believe that the code works perfectly fine
> because
> > it produces the result as what the course demanded. However, when I
> > tried to submit it, it says that my code is wrong. I do believe I
> make
> > mistake, but I cannot seem to find it. the code is as follow:
> >
> > Complete.R
> >
> > complete <- function(directory, id = 1:332) {
> >   file <- list.files(directory, full.names=TRUE)
> >   nobs <- c()
> >   for (i in id){
> >     file1 <- read.csv(file[i])
> >     nobs1 <- sum(complete.cases(file1))
> >     nobs <- c(nobs, nobs1)
> >     df <- data.frame(nobs)
> >   }
> >   return(data.frame(id,df))
> > }
> >
> >
> > Please give me a hint where I should look at.
> >
> > Thank you very much for your time and concern. I look forward hearing
> > back from you.
> >
> > Sincerely,
> >
> > Darius Mulia.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From highstat at highstat.com  Tue Jul 22 11:21:55 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 22 Jul 2014 10:21:55 +0100
Subject: [R] 2 remaining seats on stats course at Murdoch University
Message-ID: <53CE2D33.6050804@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/a25e3dba/attachment.pl>

From mlscmahe at gmail.com  Tue Jul 22 12:13:14 2014
From: mlscmahe at gmail.com (MLSC)
Date: Tue, 22 Jul 2014 13:13:14 +0300
Subject: [R] how to put two plots of scatterplotMatrix side by side in one
	plot?
Message-ID: <CACboDErOjphgZrK_xwXKc2MZDP5i0K1xY03qbP1i5LZyrFj9-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/ce0834a9/attachment.pl>

From kmersman at smail.uni-koeln.de  Tue Jul 22 12:29:30 2014
From: kmersman at smail.uni-koeln.de (Katharina Mersmann)
Date: Tue, 22 Jul 2014 12:29:30 +0200
Subject: [R] lattice -xyplot
Message-ID: <000601cfa597$d26cbca0$774635e0$@uni-koeln.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/565aed17/attachment.pl>

From pdalgd at gmail.com  Tue Jul 22 15:02:09 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 22 Jul 2014 15:02:09 +0200
Subject: [R] I need help in seeing the code
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDC1C6@SRVEXCHMBX.precheza.cz>
References: <CABnVHvByG+A-DX16KTTcAVsZk+Z3VadzAiYrGvwDTfRvC=oH+A@mail.gmail.com>
	<CAM_vju=WhgWxnB_qVzqqJUB8DnjzDhfEOzKTF3JNwRGgmhMmJA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDC1C6@SRVEXCHMBX.precheza.cz>
Message-ID: <2C87DD2F-94F8-408F-899B-F05E5B6C68EE@gmail.com>


On 22 Jul 2014, at 08:31 , PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> Anyway. AFAIK your code looks OK to me, provided you want find the number of rows without NA in each file.
> 

...however, it is not clear to any of us whether the teacher has been instructing students to avoid expanding the vector of answers on each iteration, or maybe even teaching the semantics of lapply/sapply. It is also not clear that the response should contain the index number rather than the name of each file.

-pd

> Petr
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Sarah Goslee
>> Sent: Tuesday, July 22, 2014 8:22 AM
>> To: Darius Mulia
>> Cc: r-help at r-project.org
>> Subject: Re: [R] I need help in seeing the code
>> 
>> Hi Darius,
>> 
>> This is the main R-help list. We don't know anything about your
>> Coursera class, including what your code is supposed to do. Not only
>> that, this list has a no homework policy.
>> 
>> You need to use the discussion group associated with your course, or
>> whatever materials it provides, to get assistance.
>> 
>> Sarah
>> 
>> On Tuesday, July 22, 2014, Darius Mulia <muliadarius at gmail.com> wrote:
>> 
>>> Hi there,
>>> 
>>> I am Darius and I am taking the R Programming course in Coursera. I
>>> have a problem that I had spent so much looking for the problem. I
>>> wrote my code and I believe that the code works perfectly fine
>> because
>>> it produces the result as what the course demanded. However, when I
>>> tried to submit it, it says that my code is wrong. I do believe I
>> make
>>> mistake, but I cannot seem to find it. the code is as follow:
>>> 
>>> Complete.R
>>> 
>>> complete <- function(directory, id = 1:332) {
>>>  file <- list.files(directory, full.names=TRUE)
>>>  nobs <- c()
>>>  for (i in id){
>>>    file1 <- read.csv(file[i])
>>>    nobs1 <- sum(complete.cases(file1))
>>>    nobs <- c(nobs, nobs1)
>>>    df <- data.frame(nobs)
>>>  }
>>>  return(data.frame(id,df))
>>> }
>>> 
>>> 
>>> Please give me a hint where I should look at.
>>> 
>>> Thank you very much for your time and concern. I look forward hearing
>>> back from you.
>>> 
>>> Sincerely,
>>> 
>>> Darius Mulia.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <javascript:;> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> --
>> Sarah Goslee
>> http://www.stringpage.com
>> http://www.sarahgoslee.com
>> http://www.functionaldiversity.org
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Jul 22 15:26:03 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 22 Jul 2014 15:26:03 +0200
Subject: [R] Maximum likelihood estimation (stats4::mle)
In-Reply-To: <5E661D07-64AE-4AFC-B282-A29D9AD2E584@comcast.net>
References: <53CD65A0.3070102@ruhr-uni-bochum.de>
	<5E661D07-64AE-4AFC-B282-A29D9AD2E584@comcast.net>
Message-ID: <A976A8AD-C2DD-4A93-A672-7245E6DBAC78@gmail.com>


On 22 Jul 2014, at 06:04 , David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Jul 21, 2014, at 12:10 PM, Ronald K?lpin wrote:
> 
>> Dear R-Community,
>> 
>> I'm trying to estimate the parameters of a probability distribution
>> function by maximum likelihood estimation (using the stats4 function
>> mle()) but can't seem to get it working.
>> 
>> For each unit of observation I have a pair of observations (a, r)
>> which I assume (both) to be log-normal distributed (iid). Taking the
>> log of both values I have (iid) normally distributed random variables
>> and the likelihood function to be estimated is:
>> 
>> L = Product(F(x_i) - F(y_i), i=1..n)
>> 
>> where F is the Normal PDF and (x,y) := (log(a), log(r)). Taking the
>> log and multiplying by -1 gives the negative loglikelihood
> 
> I don't see the need to multiply by -1. The log of any probability is of necessity less than (or possibly equal to) 0 since probabilities are bounded above by 1.


Well, mle() wants to minimize -log L by definition. That's just because optimizers tend to prefer to have an objective function to minimize rather than maximize.

However, what is keeping the terms of Product(F(x_i) - F(y_i), i=1..n) from going negative? As far as I can tell, the x_i are bigger than the corresponding y_i, and F is an increasing function so all terms are negative and the log of each term is undefined. Switching the order should help.

Also, what is the rationale for this form of likelihood? Surely not that the x,y pairs are independent lognormals. Looks more like what you'd get from interval censored data. If so, it should be possible to come up with better starting values than mu=0, sd=1.

-pd


> So sums of these number will be negative which then allows you to maximize their sums.
> 
>> 
>> l = Sum(log( F(x_i) - F(y_i) ), i=1..n)
>> 
>> However estimation by mle() produces the error "vmmin is not finite"
> 
> 
> As I would have predicted. If one maximizes numbers that get larger as probabilities get small this is what would be expected.
> 
> -- 
> David.
> 
>> and "NaN have been created" - even though put bound on the parameters
>> mu and sigma (see code below).
>> 
>> 
>> library("stats4")
>> 
>> gaps <- matrix(nrow=10, ncol=4, dimnames=list(c(1:10),c("r_i", "a_i",
>> "log(r_i)", "log(a_i)")))
>> gaps[,1] <- c(2.6, 1.4, 2.2, 2.9, 2.9, 1.7, 1.3, 1.7, 3.8, 4.5)
>> gaps[,2] <- c(9.8, 20.5, 8.7, 7.2, 10.3, 11, 4.5, 5.2, 6.7, 7.6)
>> gaps[,3] <- log(gaps[,1])
>> gaps[,4] <- log(gaps[,2])
>> 
>> nll <- function(mu, sigma)
>> {
>>   if(sigma >= 0 && mu >= 0)
>>   {
>>       -sum(log(pnorm(gaps[,3], mean=mu, sd=sigma) - pnorm(gaps[,4],
>> mean=mu, sd=sigma)))
>>   }
>>   else
>>   {
>>       NA
>>   }
>> }
>> 
>> fit <- mle(nll, start=list(mu=0, sigma=1), nobs=10)
>> print(fit)
>> 
>> 
>> To be honest, I'm stumped and don't quite know what the problem is...
>> 
>> Regards and Thanks,
>> 
>> Ronald K?lpin
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jvadams at usgs.gov  Tue Jul 22 15:54:44 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 22 Jul 2014 08:54:44 -0500
Subject: [R] Weight, weight - do tell me
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E598D12@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E598D12@itsnt443.iowa.uiowa.edu>
Message-ID: <CAN5YmCGsNP86rJ+TXMepA+DzXOnY43mNDpvQ2cfpdMKRGDGqrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/84c21499/attachment.pl>

From john.archie.mckown at gmail.com  Tue Jul 22 16:36:18 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 22 Jul 2014 09:36:18 -0500
Subject: [R] Code formatting question - too ugly?
Message-ID: <CAAJSdjhy8X61h8cvXmiBFWoUUuWwCO-CuXDqP=wmpks_W3B_nA@mail.gmail.com>

I like to keep the individual lines in my source files relatively
short. Mainly so that I can print them, email them, or display them on
a narrow screen without needing to shift left & right. So, for a
really long character string, such as an SQL query, I do something
like:

query=paste0("select CONVERT(smalldatetime,Int_Start_Date,11) as
Int_Start_Date,",
             " CONVERT(smalldatetime,CASE WHEN Int_Start_Time is NULL
then '00:00' ",
             "else
LEFT(Int_Start_Time,2)+':'+SUBSTRING(Int_Start_Time,3,2) end +",
             "':00', 14) as Int_Start_Time",
             ", Int_duration, RTRIM(INTTYPE) AS INTTYPE,"
             " RTRIM(Int_descr) AS Int_descr",
             ", RTRIM(INTSUBT) as INTSUBT, "
             "INDEXX, RTRIM(Label) AS Label",
             ", RTRIM(CHANGED) AS CHANGED, "
             "RTRIM(ALERT) AS ALERT, "
             "RTRIM(RELEASE) AS RELEASE",
             " FROM CPINTVL where Int_Start_Date BETWEEN '",
             startDateChar,"' and '",endDateChar,"'"
             );

So, just as an opinion, is the above "ugly looking" code compared to
just having a really long line? Also, if you/re curious, when I
started most programs were literally punched onto 80 column cards or
displayed on 80 column screens. I still have some damage from this
time (1970s).


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From cscherb1 at gwdg.de  Tue Jul 22 16:47:17 2014
From: cscherb1 at gwdg.de (Scherber, Christoph)
Date: Tue, 22 Jul 2014 16:47:17 +0200
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
Message-ID: <53CE7975.9010408@gwdg.de>

Dear all,

I am trying to express a multinomial GLM (using nnet) as a series of GLM models.

However, when I compare the multinom() predictions to those from GLM, I see differences that I can?t
explain. Can anyone help me out here?

Here comes a reproducible example:

##
# set up data: (don?t care what they are, just for playing)
set.seed(0)
cats=c("oligolectic","polylectic","specialist","generalist")
explan1=c("natural","managed")
explan2=c("meadow","meadow","pasture","pasture")
multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
multiplan1=factor(rep(explan1,50))
multiplan2=factor(rep(explan2,25))

########################
library(nnet)
m2=multinom(multicats~multiplan1)

# predictions from multinomial model
predict(m2,type="probs")

########################
# now set up contrasts for response variable "multicats" (which has 4 levels):

ii=as.numeric(multicats)

g1=glm(I(ii%in%c(1,2)) ~ multiplan1, family = "binomial")
g2=glm(I(ii%in%c(2,3)) ~ multiplan1, family = "binomial")
g3=glm(I(ii%in%c(3,4)) ~ multiplan1, family = "binomial")

r1=predict(g1,type="response")
r2=predict(g2,type="response")
r3=predict(g3,type="response")

# calculate predictions (based on Chapter 8.3 in Dobson 2002, Introduction to GLMs)
ee0=1/(1+r1+r2+r3)
ee1=r1/(1+r1)
ee2=r2/(1+r1+r2)
ee3=r3/(1+r1+r2+r3)

# compare predictions between GLM and multinom fits:
apply(cbind(ee0,ee1,ee2,ee3),2,mean)
apply(predict(m2,type="probs"),2,mean)


#################
[using R 3.1.1 on Windows 7 32-bit]





-- 
PD Dr. Christoph Scherber
Senior Lecturer
DNPW, Agroecology
University of Goettingen
Grisebachstrasse 6
37077 Goettingen
Germany
telephone +49 551 39 8807
facsimile +49 551 39 8806
www.gwdg.de/~cscherb1


From jfox at mcmaster.ca  Tue Jul 22 16:54:33 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 22 Jul 2014 10:54:33 -0400
Subject: [R] how to put two plots of scatterplotMatrix side by side in
	one	plot?
In-Reply-To: <CACboDErOjphgZrK_xwXKc2MZDP5i0K1xY03qbP1i5LZyrFj9-Q@mail.gmail.com>
References: <CACboDErOjphgZrK_xwXKc2MZDP5i0K1xY03qbP1i5LZyrFj9-Q@mail.gmail.com>
Message-ID: <web-519572810@cgpsrv2.cis.mcmaster.ca>

Dear mahe,

This is, I assume, the scatterplotMatrix() function in the car package.

I don't think that you'll be able to do what you want with scatterplotMatrix(), because it uses the pairs() function, which resets par("mfrow"). For the same reason, using pairs() directly won't help. You should, however, and with some work, be able to do what you want using splom() in the lattice package.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Tue, 22 Jul 2014 13:13:14 +0300
 MLSC <mlscmahe at gmail.com> wrote:
> Hello Friends,
> 
> I want to put two plots of scatterplotMatrix side by side in one plot.
> I have tried below command. But somehow below code doesnt join them
> together side by side.
> 
> > par(mfrow=c(1,2));
> > scatterplotMatrix(~ SBP + DBP + Leptin +WC+BMI+Weight | factor(dat2$rs3827103), data=dat2,diagonal='none', pch=c(18),smoother=FALSE,reg.line=lm)
> > scatterplotMatrix(~ SBP + DBP + Leptin +WC+BMI+Weight | factor(dat1$rs3827103), data=dat1,diagonal='none', pch=c(18),smoother=FALSE,reg.line=lm)
> 
> Can anybody suggest me a way to join them together side by side.
> 
> Regards,
> 
> mahe
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Jul 22 17:23:43 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 22 Jul 2014 08:23:43 -0700 (PDT)
Subject: [R] Code formatting question - too ugly?
In-Reply-To: <CAAJSdjhy8X61h8cvXmiBFWoUUuWwCO-CuXDqP=wmpks_W3B_nA@mail.gmail.com>
References: <CAAJSdjhy8X61h8cvXmiBFWoUUuWwCO-CuXDqP=wmpks_W3B_nA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1407220811570.59054@pedal.dcn.davis.ca.us>

On Tue, 22 Jul 2014, John McKown wrote:

> I like to keep the individual lines in my source files relatively
> short. Mainly so that I can print them, email them, or display them on
> a narrow screen without needing to shift left & right. So, for a
> really long character string, such as an SQL query, I do something
> like:
>
> query=paste0("select CONVERT(smalldatetime,Int_Start_Date,11) as
> Int_Start_Date,",
>             " CONVERT(smalldatetime,CASE WHEN Int_Start_Time is NULL
> then '00:00' ",
>             "else
> LEFT(Int_Start_Time,2)+':'+SUBSTRING(Int_Start_Time,3,2) end +",
>             "':00', 14) as Int_Start_Time",
>             ", Int_duration, RTRIM(INTTYPE) AS INTTYPE,"
>             " RTRIM(Int_descr) AS Int_descr",
>             ", RTRIM(INTSUBT) as INTSUBT, "
>             "INDEXX, RTRIM(Label) AS Label",
>             ", RTRIM(CHANGED) AS CHANGED, "
>             "RTRIM(ALERT) AS ALERT, "
>             "RTRIM(RELEASE) AS RELEASE",
>             " FROM CPINTVL where Int_Start_Date BETWEEN '",
>             startDateChar,"' and '",endDateChar,"'"
>             );
>
> So, just as an opinion, is the above "ugly looking" code compared to
> just having a really long line? Also, if you/re curious, when I
> started most programs were literally punched onto 80 column cards or
> displayed on 80 column screens. I still have some damage from this
> time (1970s).

This is out there on the frontier of flame war material, but since your
code is missing a couple of commas that are hard to spot I would say it is 
rather poorly formatted. My formatting style is not exactly compatible 
with most pretty-print styles, but simply recognizing that strings can 
span multiple lines can fix a lot of problems for this particular use 
case:

query <- paste0( "select CONVERT( smalldatetime
                                 , Int_Start_Date
                                 , 11
                                 ) as Int_Start_Dates
                        , CONVERT( smalldatetime
                                 , CASE WHEN Int_Start_Time is NULL
                                        then '00:00'
                                        else LEFT( Int_Start_Time, 2 )
                                           + ':'
                                           + SUBSTRING(Int_Start_Time,3,2)
                                        end
                                   + ':00'
                                 , 14
                                 ) as Int_Start_Time
                        , Int_duration
                        , RTRIM( INTTYPE ) AS INTTYPE
                        , RTRIM( Int_descr ) AS Int_descr
                        , RTRIM( INTSUBT ) as INTSUBT
                        , INDEXX
                        , RTRIM( Label ) AS Label
                        , RTRIM( CHANGED ) AS CHANGED
                        , RTRIM( ALERT ) AS ALERT
                        , RTRIM( RELEASE ) AS RELEASE
                   FROM CPINTVL
                   where Int_Start_Date BETWEEN '"
                , startDateChar
                , "' and '"
                , endDateChar
                ,"'"
                );

By the way... parameterized queries are safer (no SQL injection) and 
faster-executing (well, for repeated use) than pasting input text into 
query text.

Another approach is to store really long strings in data files.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From julian_schulze at arcor.de  Tue Jul 22 10:00:54 2014
From: julian_schulze at arcor.de (Julian Schulze)
Date: Tue, 22 Jul 2014 10:00:54 +0200 (CEST)
Subject: [R] Multiple Imputation of longitudinal data in MICE and
 statistical analyses of object type mids
Message-ID: <1727380956.1810012.1406016054750.JavaMail.ngmail@webmail09.arcor-online.net>

Dear all,

I have a problem with performing statistical analyses of longitudinal data after the imputation of missing values using mice. After the imputation of missings in the wide data-format I convert the extracted data to the longformat. Because of the longitudinal data participants have duplicate rows (3 timepoints) and this causes problems when converting the long-formatted data set into a type mids object. Does anyone know how to create a mids object or something else appropriate after the imputation? I want to use lmer,lme for pooled fixed effects afterwards. I tried a lot of different things, but still cant figure it out.

Thanks in advance and see the code below for a minimal reproducible example:

------------------------------------------------------------
# minimal reproducible example

## Make up some data
set.seed(2)

# ID Variable, Group, 3 Timepoints outcome measure (X1-X3)
Data <- data.frame(
    ID = sort(sample(1:100)),
    GROUP = sample(c(0, 1), 100, replace = TRUE),
    matrix(sample(c(1:5,NA), 300, replace=T), ncol=3)
)

# install.packages("mice")
library(mice)

# Impute the data in wide format
m.out <- mice(Data, maxit = 5, m = 2, seed = 9, pred=quickpred(Data, mincor = 0.0, exclude = c("ID","GROUP"))) # ignore group here for easiness
# mids object?
is.mids(m.out) # TRUE

# Extract imputed data
imp_data <- complete(m.out, action = "long", include = TRUE)[, -2]

# Converting data into long format
# install.packages("reshape")
library(reshape)
imp_long <- melt(imp_data, id=c(".imp","ID","GROUP"))
# sort data
imp_long <- imp_long[order(imp_long$.imp, imp_long$ID, imp_long$GROUP),]
row.names(imp_long)<-NULL

# save as.mids
as.mids(imp_long,.imp=1, .id=2) # doesnt work
as.mids(imp_long) # doesnt work

------------------------------------------------------------

Best,

Julian


From lynn.govaert at gmail.com  Tue Jul 22 13:59:39 2014
From: lynn.govaert at gmail.com (Lynn Govaert)
Date: Tue, 22 Jul 2014 13:59:39 +0200
Subject: [R] repeated anova
Message-ID: <CAPDfU8-R3QP6fQeL-2GBdXp0+GXQ-9kCcL8Ut5sUJNiZ1Ju2SQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/4ee1f881/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 22 10:14:36 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Jul 2014 01:14:36 -0700
Subject: [R] 1st el of a list of vectors
In-Reply-To: <CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>
References: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>
Message-ID: <1406016876.70196.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Or
rapply(l,function(x) x[1])
#[1] 1 3 7


set.seed(42)
?l1 <- replicate(1e6, list(sample(1:5,sample(8),replace=T)))
system.time(r1 <- sapply(l1, `[`, 1))
?#? user? system elapsed 
?# 1.324?? 0.000?? 1.326 

system.time(r2 <- rapply(l1, function(x) x[1]))
#?? user? system elapsed 
#? 0.736?? 0.004?? 0.741 

identical(r1,r2)
#[1] TRUE

system.time({
eltlens <- elementLengths(l1)
?r3 <- unlist(l1, use.names=FALSE)[cumsum(eltlens) - eltlens + 1L]
})
# user? system elapsed 
#? 0.153?? 0.000?? 0.154 


A.K.


On Tuesday, July 22, 2014 12:11 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
l = list(c(1,2), c(3,5,6), c(7))

sapply(l, `[`, 1)

On Mon, Jul 21, 2014 at 3:55 PM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> If we have a list of vectors of different lengths, how is it possible to retrieve the first element of the vectors of the list?
>
>
> l = list(c(1,2), c(3,5,6), c(7))
>
> 1,3,7 should be retrieved
>
> Thanks
>
> Carol
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Tue Jul 22 18:17:37 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 22 Jul 2014 09:17:37 -0700
Subject: [R] 1st el of a list of vectors
In-Reply-To: <1406016876.70196.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1405972552.2305.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<CAGx1TMAuBQ35-8EH-xo4Yote1HsqQj=Y70=U05bxDdH9NEgs7g@mail.gmail.com>
	<1406016876.70196.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CACk-te2ckbR4j7SpQJg+okYySmPBTMDXpncH1D=h4WKZNTS3Kg@mail.gmail.com>

Yes, but note that such comparisons don't necessarily tell you much.
Using your l1 on my computer:

> system.time(r1 <- sapply(l1, `[`, 1))
   user  system elapsed
    1.2     0.0     1.2
> system.time(r2<- rapply(l1,function(x)x[1]))
   user  system elapsed
   0.81    0.00    0.81

## But

> system.time(r3<- unlist(lapply(l1,`[`,1)))
   user  system elapsed
   0.64    0.00    0.66
 ## and

> system.time(r4<- vapply(l1,`[`,1,1))
   user  system elapsed
   0.60    0.00    0.61

sapply() takes a bit of extra time to get the return into the right
data structure. You tell vapply the return type and lapply always
returns a list.

-- Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 22, 2014 at 1:14 AM, arun <smartpink111 at yahoo.com> wrote:
> Or
> rapply(l,function(x) x[1])
> #[1] 1 3 7
>
>
> set.seed(42)
>  l1 <- replicate(1e6, list(sample(1:5,sample(8),replace=T)))
> system.time(r1 <- sapply(l1, `[`, 1))
>  #  user  system elapsed
>  # 1.324   0.000   1.326
>
> system.time(r2 <- rapply(l1, function(x) x[1]))
> #   user  system elapsed
> #  0.736   0.004   0.741
>
> identical(r1,r2)
> #[1] TRUE
>
> system.time({
> eltlens <- elementLengths(l1)
>  r3 <- unlist(l1, use.names=FALSE)[cumsum(eltlens) - eltlens + 1L]
> })
> # user  system elapsed
> #  0.153   0.000   0.154
>
>
> A.K.
>
>
> On Tuesday, July 22, 2014 12:11 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> l = list(c(1,2), c(3,5,6), c(7))
>
> sapply(l, `[`, 1)
>
> On Mon, Jul 21, 2014 at 3:55 PM, carol white <wht_crl at yahoo.com> wrote:
>> Hi,
>> If we have a list of vectors of different lengths, how is it possible to retrieve the first element of the vectors of the list?
>>
>>
>> l = list(c(1,2), c(3,5,6), c(7))
>>
>> 1,3,7 should be retrieved
>>
>> Thanks
>>
>> Carol
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Tue Jul 22 18:18:44 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Tue, 22 Jul 2014 16:18:44 +0000
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
References: <53CE7975.9010408@gwdg.de>
Message-ID: <loom.20140722T180243-904@post.gmane.org>

Scherber, Christoph <cscherb1 <at> gwdg.de> writes:

> 
> Dear all,
> 
> I am trying to express a multinomial GLM (using nnet) as a series of GLM
models.
> 
> However, when I compare the multinom() predictions to those from GLM, I
see differences that I can?t
> explain. Can anyone help me out here?
> 
> Here comes a reproducible example:
> 
> ##
> # set up data: (don?t care what they are, just for playing)
> set.seed(0)
> cats=c("oligolectic","polylectic","specialist","generalist")
> explan1=c("natural","managed")
> explan2=c("meadow","meadow","pasture","pasture")
> multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
> multiplan1=factor(rep(explan1,50))
> multiplan2=factor(rep(explan2,25))
> 
> ########################
> library(nnet)
> m2=multinom(multicats~multiplan1)
> 
> # predictions from multinomial model
> predict(m2,type="probs")
> 
> ########################
> # now set up contrasts for response variable "multicats" (which has 4 levels):

[snip - Christoph's comparison]

Doing the obvious comparison:

ggen.preds <- 
    sapply( levels(multicats), 
            function(x) predict(glm(I(multicats==x)~multiplan1,
                         family=binomial),type="response"))

max(abs(ggen.preds-predict(m2,type="probs")))
## [1] 1.349607e-06

---

The predictions are the same - up to numerical issues in the algorithms.

HTH,

Chuck


From jfox at mcmaster.ca  Tue Jul 22 19:14:57 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 22 Jul 2014 13:14:57 -0400
Subject: [R] repeated anova
In-Reply-To: <CAPDfU8-R3QP6fQeL-2GBdXp0+GXQ-9kCcL8Ut5sUJNiZ1Ju2SQ@mail.gmail.com>
References: <CAPDfU8-R3QP6fQeL-2GBdXp0+GXQ-9kCcL8Ut5sUJNiZ1Ju2SQ@mail.gmail.com>
Message-ID: <web-519605663@cgpsrv2.cis.mcmaster.ca>

Dear Lynn,

On Tue, 22 Jul 2014 13:59:39 +0200
 Lynn Govaert <lynn.govaert at gmail.com> wrote:
> Hi,
> 
> I have a problem with doing a repeated measures ANOVA. I will first give
> you an idea of what my dataset looks like. We have 20 ponds, and for each
> pond we took some individuals (waterfleas), say 10 and tested them along
> two treatments (A and B). Now, for each pond we also know the fish
> background (Fish versus No Fish) and Land use intensity (High versus Low).
> 
> Now, we measure the offspring of the first clutch and second clutch of each
> individual, and we want to see if there is an effect of each of the other
> factors (treatment, background, land use), so we need to do a repeated
> measurement.
> 
> So I rearranged my data where I put the first and second clutch in one
> column, something like this:
> 
> Ponds        Treatment     Background            LandUse          Clutch
>           SizeClutch
> Pond1         A                    Fish                      High
>       1                        10
> Pond1         B                    Fish                      High
>       1                         15
> Pond2         A                    NoFish                  High
>     1                         8
> Pond2         B                    NoFish                  High
>     1                         11
> etc
> Pond20        B                   Fish                      Low
>      1                          12
> Pond1         A                    Fish                      High
>       2                          15
> Pond1         B                    Fish                      High
>       2                           17
> Pond2         A                    NoFish                  High
>     2                          16
> Pond2         B                    NoFish                  High
>     2                           18
> etc
> Pond20       B                    Fish                      Low
>      2                            11
> 
> So I made the Clutch variable myself, to separate between the different
> clutches.
> 
> I then performered the following analysis
> 
> summary(aov(SizeClutch ~ Treatment*Background*LandUse +
> Error(Clutch/Treatment*Background*LandUse) + Ponds , random = ~ Ponds|
> Background*LandUse/Ponds))
> 
> This gives me something, but not exactly what I thought I would get.
> I want to have results for
> Ponds
> LandUse
> Background
> Treatment
> LandUse*Background
> LandUse*Treatment
> LandUse*Background*Treatment
> 
> Clutch
> Clutch*Ponds
> Clutch*LandUse
> Clutch*Background
> Clutch*Treatment
> Clutch*LandUse*Background
> Clutch*LandUse*Treatment
> Clutch*LandUse*Background*Treatment
> 
> and p values for all of the effects.
> Now, I don't know if it is possible to come to these results and if I'm
> doing the repeated measure ANOVA correctly. Also, are there other ways to
> do a repeated measurements in R?

For another approach to repeated-measures ANOVA (and MANOVA), see the section on repeated measures in the R Journal paper at <http://journal.r-project.org/archive/2013-1/fox-friendly-weisberg.pdf>.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

> 
> Thanks in advance.
> Lynn
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pjmiller_57 at yahoo.com  Tue Jul 22 19:06:51 2014
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Tue, 22 Jul 2014 10:06:51 -0700
Subject: [R] Survival Analysis with an Historical Control
In-Reply-To: <30411786F64EEF46856EFBA2CD9177992C2D7EFA@UHEXMBSPR03.umhs.med.umich.edu>
Message-ID: <1406048811.15370.YahooMailBasic@web140203.mail.bf1.yahoo.com>

Hi Chris,

Thanks for your reply. Certainly no need to apologize for a delayed response. Appreciate your taking the time to answer my question. 

My concern was about the value of "16". My understanding is it is based on one expert's opinion. I wondered if this is in keeping with whatever the standard practice might be. I feel uncomfortable with the idea of using this as the basis but perhaps I am alone in feeling this way. My preference would be to see citations from previous studies to justify the number. A meta analysis of results from previous studies might be even better.  

Your code is very interesting. Especially the parametric part. Nice to get an actual p-value for the test.

Thanks,

Paul

--------------------------------------------
On Mon, 7/21/14, Andrews, Chris <chrisaa at med.umich.edu> wrote:

 Subject: RE: [R] Survival Analysis with an Historical Control

 Cc: "r-help at r-project.org" <r-help at r-project.org>
 Received: Monday, July 21, 2014, 10:33 AM

 Hi Paul,
 Sorry for the delayed reply.? I was away last
 week. I'm not clear what you want confirmed about your
 approach.

 (a)
 "20.57"- computing the rejection region of the
 analysis.? The formulas implemented at the addresses you
 gave in your original post are from a reputable source -
 Lawless (1982) - at least that is claimed in the help file
 (http://www.swogstat.org/stat/Public/Help/survival1.html).?
 It seems that another person derived 20.57 from some
 combination of input.? I don't see how to back
 calculate what the input was from the information
 provided.? Perhaps elsewhere in your study protocol there
 is discussion of accrual time, et al. that can help you.

 (b) "16" - the value
 of the parameter in the null hypothesis is very important as
 you noted in your response to Terry.? But this is not
 really a statistical question. It may be derived from
 historical data, expert opinion, regulatory mandate, or some
 combination of these and other factors.? Presumably this
 study was undertaken because 16 was an important number to
 somebody.

 (c) performing
 the one-sample survival analysis itself.? This is what I
 did with the data you provided.

 # Non-parametric
 (km <-
 survfit(Surv(WKS, 1-CENS) ~ 1, data=hsv,
 type="kaplan-meier", conf.type="log",
 conf.int=0.9))
 summary(km)

 # Compare to median survival =
 16
 # (Used 90% CI above to get 0.05 one
 sided test here)
 quantile(km,
 prob=0.5)$lower > 16

 #
 Parametric
 (paraExp <- survreg(Surv(WKS,
 1-CENS) ~ 1, data=hsv, dist="exponential"))
 summary(paraExp)

 # Compare to median survival = 16
 # That is, compare to beta0 = log(16/log(2)) =
 3.1391...
 # one sided test
 pnorm(c((coef(paraExp) - log(16/log(2))) /
 sqrt(vcov(paraExp))), lower.tail=FALSE)


 Chris


From davidmarino838 at gmail.com  Tue Jul 22 19:53:44 2014
From: davidmarino838 at gmail.com (Marino David)
Date: Wed, 23 Jul 2014 01:53:44 +0800
Subject: [R] Partition of sums of squares (ANOVA)
Message-ID: <CABmD0bG5tJ=iQ3Y9gfDaAsVwsjdNuRVX5Wx8D2NHimWfMjGs2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/9a6b48ae/attachment.pl>

From gunter.berton at gene.com  Tue Jul 22 20:08:16 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 22 Jul 2014 11:08:16 -0700
Subject: [R] Partition of sums of squares (ANOVA)
In-Reply-To: <CABmD0bG5tJ=iQ3Y9gfDaAsVwsjdNuRVX5Wx8D2NHimWfMjGs2w@mail.gmail.com>
References: <CABmD0bG5tJ=iQ3Y9gfDaAsVwsjdNuRVX5Wx8D2NHimWfMjGs2w@mail.gmail.com>
Message-ID: <CACk-te1d++kdvRf7EKJ80mEP49kdtKCrcveBpXki3LKxsxW1GQ@mail.gmail.com>

Wrong list!

Try stats.stackexchange.com  for statistics questions. This list is
about R programming related issues.

Also, note that HTML does not work and should not be used here.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 22, 2014 at 10:53 AM, Marino David <davidmarino838 at gmail.com> wrote:
> Hi all r-mailling listers:
>
> Can anyone explain the theory (or the formula) about computing Sum Sq
> (color highligh below) related to regression items?  The link of Wikipedia (
> http://en.wikipedia.org/wiki/Partition_of_sums_of_squares) gives an
> introduction on how to calculate the total, model, and regression sum of
> squares. Is it similar to the Sum Sq computation? Is the regression sum of
> squares equal to (0.000437+ 0.002545+ 0.060984+ 0.062330+ 0.060480)?
>
> Any suggestion will be greatly appreciated.
>
> Thank you!
>
> David
>
> TraingData<-data.frame(
> x1=c(3.532,2.868,2.868,3.532,2.868,2.536,3.864),
> x2=c(1.992,1.992,1.328,1.328,1.328,1.66,1.66),
> y=c(9.040330254,8.900894412,8.701929163,9.057944749,8.701929163,8.74317832,9.10859913)
> )
> lm.sol<-lm(y~1+x1+x2+I(x1^2)+I(x2^2)+I(x1*x2),data=TraingData)
> anova(lm.sol)
>
> Analysis of Variance Table
>
> Response: y
>                 Df     *Sum Sq*     Mean       Sq F    value Pr(>F)
> x1              1    0.000437  0.000437    0.1055    0.8001
> x2              1    0.002545  0.002545    0.6141    0.5768
> I(x1^2)        1    0.060984  0.060984   14.7162    0.1623
> I(x2^2)        1    0.062330  0.062330   15.0409    0.1607
> I(x1 * x2)    1    0.060480  0.060480   14.5945    0.1630
> Residuals   1    0.004144  0.004144
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidmarino838 at gmail.com  Tue Jul 22 20:19:29 2014
From: davidmarino838 at gmail.com (Marino David)
Date: Wed, 23 Jul 2014 02:19:29 +0800
Subject: [R] Partition of sums of squares (ANOVA)
In-Reply-To: <CACk-te1d++kdvRf7EKJ80mEP49kdtKCrcveBpXki3LKxsxW1GQ@mail.gmail.com>
References: <CABmD0bG5tJ=iQ3Y9gfDaAsVwsjdNuRVX5Wx8D2NHimWfMjGs2w@mail.gmail.com>
	<CACk-te1d++kdvRf7EKJ80mEP49kdtKCrcveBpXki3LKxsxW1GQ@mail.gmail.com>
Message-ID: <CABmD0bE+42rbsO6=3kEMp7azDzAw0oGPtotsmF4q4ZyVz9Ee3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/3c5e80df/attachment.pl>

From 538280 at gmail.com  Tue Jul 22 20:29:30 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 22 Jul 2014 12:29:30 -0600
Subject: [R] Application design.
In-Reply-To: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
References: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
Message-ID: <CAFEqCdziHf-ezWDifmukSVXatgbRO8d9_=9bqtjNYzVr5dsfvA@mail.gmail.com>

Here are 2 possibilities to consider.

The shiny package allows a web browser interface to R.  It can run
from a server, but can also run just on a single computer.  You could
set this up like you suggest, where the user would double click on an
icon on the desktop which would then run R, load the package and open
the browser.  The user can then make some selections in the browser
(subset the data, choose cutoffs, etc.) and the resulting graphs and
summaries will show up in the browser window.  I don't know how hard
it is to copy and paste from the browser to power point, but viewing
will be nicely automatic (and possibly just printing or saving the
resulting web page may be enough to pass up the line).

The knitr package along with the pandoc program provides a system for
creating a template file that can then be processed to create a final
result.  Again you could set up an icon on the desktop to run R and
process the template file.  The template file would have the code for
querying the data and producing the graphs and summaries and also how
to display them.  I don't think that knitr/pandoc currently has a way
to directly create power point slides, but it does have tools for
creating pdf or html based slides (I do the pdf ones quite often, yes
on windows) or you can produce a word document as the output that can
then easily be copied/pasted to power point (I do this as well when
clients want to do the copy/paste rather than having me create a
single pdf report).

Also, if you have not already, read the help page ?Startup, this gives
details on what R does as it starts and gives options for
automatically running code when R starts.

On Mon, Jul 21, 2014 at 8:24 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> I'm designing an R based application for my boss. It's not much, but
> it might save him some time. What it will be doing is reading data
> from an MS-SQL database and creating a number of graphs. At present,
> he must log into one server to run a vendor application to display the
> data in a grid. He then cuts this data and pastes it into an Excel
> spreadsheet. He then generates some graphs in Excel. Which he then
> cuts and pastes into a Power Point presentation. Which is the end
> result for distribution to others up the food chain.
>
> What I would like to do is read the MS-SQL data base using RODBC and
> create the graphs using ggplot2 instead of using Excel. I may end up
> being told to create an Excel file as well.
>
> My real question is organizing the R programs to do this. Basically
> what I was thinking of was a "master" program. It does the ODBC work
> and fetches the data into one, or more, data.frames. I was then
> thinking that it would be better to have separate source files for
> each graph produced. I would use the source() function in the "master"
> R program to load & execute each one in order. Is this a decent
> origination? Or would it be better for each "create a graph" R file to
> really just define a unique function which the "master" program would
> then invoke? I guess this latter would be a good way to keep the
> workspace "clean" since all the variables in the functinon would "go
> away" when the function ended.
>
> I guess what I'm asking is how others organize the R applications. Oh,
> I plan for this to be run by my boss by double clicking on the
> "master" R source file, which I will associate with the Rscript
> program in Windows. Yes, this is Windows based <sigh/>.
>
> Appreciate your thoughts. Especially if I'm really off track.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ronald.koelpin at gmail.com  Tue Jul 22 21:01:37 2014
From: ronald.koelpin at gmail.com (=?ISO-8859-1?Q?Ronald_K=F6lpin?=)
Date: Tue, 22 Jul 2014 21:01:37 +0200
Subject: [R] Maximum likelihood estimation (stats4::mle)
In-Reply-To: <A976A8AD-C2DD-4A93-A672-7245E6DBAC78@gmail.com>
References: <53CD65A0.3070102@ruhr-uni-bochum.de>
	<5E661D07-64AE-4AFC-B282-A29D9AD2E584@comcast.net>
	<A976A8AD-C2DD-4A93-A672-7245E6DBAC78@gmail.com>
Message-ID: <53CEB511.2070508@gmail.com>

Thanks, that was exactly it -- switching the values did the trick (and
was actually correct in terms of theory.) And of course, you are right
-- i changed the starting values to mean(x) - mean(y) for mu and
sqrt(var(x-y)) for sigma.

I also see your point about the theoretical justification for the
specific form of the likelihood function: F(x) - F(y) is supposed to
express the probability that a certain lies in the intervall (x,y),
that is x, y are takes as lower and upper bounds for the estimate
respectively. I think the theoretical justification is sound, but i'm
still trying to work out the details.

Thanks a lot anyways for solving my coding problem!

RK

On 22.07.2014 15:26, peter dalgaard wrote:
> 
> On 22 Jul 2014, at 06:04 , David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> 
>> On Jul 21, 2014, at 12:10 PM, Ronald K?lpin wrote:
>> 
>>> Dear R-Community,
>>> 
>>> I'm trying to estimate the parameters of a probability
>>> distribution function by maximum likelihood estimation (using
>>> the stats4 function mle()) but can't seem to get it working.
>>> 
>>> For each unit of observation I have a pair of observations (a,
>>> r) which I assume (both) to be log-normal distributed (iid).
>>> Taking the log of both values I have (iid) normally distributed
>>> random variables and the likelihood function to be estimated
>>> is:
>>> 
>>> L = Product(F(x_i) - F(y_i), i=1..n)
>>> 
>>> where F is the Normal PDF and (x,y) := (log(a), log(r)). Taking
>>> the log and multiplying by -1 gives the negative loglikelihood
>> 
>> I don't see the need to multiply by -1. The log of any
>> probability is of necessity less than (or possibly equal to) 0
>> since probabilities are bounded above by 1.
> 
> 
> Well, mle() wants to minimize -log L by definition. That's just
> because optimizers tend to prefer to have an objective function to
> minimize rather than maximize.
> 
> However, what is keeping the terms of Product(F(x_i) - F(y_i),
> i=1..n) from going negative? As far as I can tell, the x_i are
> bigger than the corresponding y_i, and F is an increasing function
> so all terms are negative and the log of each term is undefined.
> Switching the order should help.
> 
> Also, what is the rationale for this form of likelihood? Surely not
> that the x,y pairs are independent lognormals. Looks more like what
> you'd get from interval censored data. If so, it should be possible
> to come up with better starting values than mu=0, sd=1.
> 
> -pd
> 
> 
>> So sums of these number will be negative which then allows you to
>> maximize their sums.
>> 
>>> 
>>> l = Sum(log( F(x_i) - F(y_i) ), i=1..n)
>>> 
>>> However estimation by mle() produces the error "vmmin is not
>>> finite"
>> 
>> 
>> As I would have predicted. If one maximizes numbers that get
>> larger as probabilities get small this is what would be
>> expected.
>> 
>> -- David.
>> 
>>> and "NaN have been created" - even though put bound on the
>>> parameters mu and sigma (see code below).
>>> 
>>> 
>>> library("stats4")
>>> 
>>> gaps <- matrix(nrow=10, ncol=4, dimnames=list(c(1:10),c("r_i",
>>> "a_i", "log(r_i)", "log(a_i)"))) gaps[,1] <- c(2.6, 1.4, 2.2,
>>> 2.9, 2.9, 1.7, 1.3, 1.7, 3.8, 4.5) gaps[,2] <- c(9.8, 20.5,
>>> 8.7, 7.2, 10.3, 11, 4.5, 5.2, 6.7, 7.6) gaps[,3] <-
>>> log(gaps[,1]) gaps[,4] <- log(gaps[,2])
>>> 
>>> nll <- function(mu, sigma) { if(sigma >= 0 && mu >= 0) { 
>>> -sum(log(pnorm(gaps[,3], mean=mu, sd=sigma) - pnorm(gaps[,4], 
>>> mean=mu, sd=sigma))) } else { NA } }
>>> 
>>> fit <- mle(nll, start=list(mu=0, sigma=1), nobs=10) print(fit)
>>> 
>>> 
>>> To be honest, I'm stumped and don't quite know what the problem
>>> is...
>>> 
>>> Regards and Thanks,
>>> 
>>> Ronald K?lpin
>>> 
>>> ______________________________________________ 
>>> R-help at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>> posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius Alameda, CA, USA
>> 
>> ______________________________________________ 
>> R-help at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Tue Jul 22 22:20:57 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 22 Jul 2014 16:20:57 -0400
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
In-Reply-To: <53CE7975.9010408@gwdg.de>
References: <53CE7975.9010408@gwdg.de>
Message-ID: <web-519644847@cgpsrv2.cis.mcmaster.ca>

Dear Christoph,

If I understand correctly what you've done, the two approaches are not equivalent and should not in general produce the same fitted probabilities.

Letting {a, b} represent logit(a vs. b) = log(Pr(a)/Pr(b)) and {ab, cd} represent logit(a or b vs. c or d), and numbering the response levels 1, 2, 3, 4, then the multinomial logit model fits the logits {2, 1}, {3, 1}, {4, 1}, while your binary logit models are for the logits {12, 34}, {23, 14}, {34, 12}. Note that the first and third are complementary, but even if you had used three distinct logits of this kind, the combined models (which BTW wouldn't be independent) would not be equivalent to the multinomial logit model.

I hope that this helps (and that I've not misconstrued what you did).

Best,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Tue, 22 Jul 2014 16:47:17 +0200
 "Scherber, Christoph" <cscherb1 at gwdg.de> wrote:
> Dear all,
> 
> I am trying to express a multinomial GLM (using nnet) as a series of GLM models.
> 
> However, when I compare the multinom() predictions to those from GLM, I see differences that I can?t
> explain. Can anyone help me out here?
> 
> Here comes a reproducible example:
> 
> ##
> # set up data: (don?t care what they are, just for playing)
> set.seed(0)
> cats=c("oligolectic","polylectic","specialist","generalist")
> explan1=c("natural","managed")
> explan2=c("meadow","meadow","pasture","pasture")
> multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
> multiplan1=factor(rep(explan1,50))
> multiplan2=factor(rep(explan2,25))
> 
> ########################
> library(nnet)
> m2=multinom(multicats~multiplan1)
> 
> # predictions from multinomial model
> predict(m2,type="probs")
> 
> ########################
> # now set up contrasts for response variable "multicats" (which has 4 levels):
> 
> ii=as.numeric(multicats)
> 
> g1=glm(I(ii%in%c(1,2)) ~ multiplan1, family = "binomial")
> g2=glm(I(ii%in%c(2,3)) ~ multiplan1, family = "binomial")
> g3=glm(I(ii%in%c(3,4)) ~ multiplan1, family = "binomial")
> 
> r1=predict(g1,type="response")
> r2=predict(g2,type="response")
> r3=predict(g3,type="response")
> 
> # calculate predictions (based on Chapter 8.3 in Dobson 2002, Introduction to GLMs)
> ee0=1/(1+r1+r2+r3)
> ee1=r1/(1+r1)
> ee2=r2/(1+r1+r2)
> ee3=r3/(1+r1+r2+r3)
> 
> # compare predictions between GLM and multinom fits:
> apply(cbind(ee0,ee1,ee2,ee3),2,mean)
> apply(predict(m2,type="probs"),2,mean)
> 
> 
> #################
> [using R 3.1.1 on Windows 7 32-bit]
> 
> 
> 
> 
> 
> -- 
> PD Dr. Christoph Scherber
> Senior Lecturer
> DNPW, Agroecology
> University of Goettingen
> Grisebachstrasse 6
> 37077 Goettingen
> Germany
> telephone +49 551 39 8807
> facsimile +49 551 39 8806
> www.gwdg.de/~cscherb1
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matt at plot.ly  Tue Jul 22 23:52:34 2014
From: matt at plot.ly (Matt Sundquist)
Date: Tue, 22 Jul 2014 14:52:34 -0700
Subject: [R] plotly
In-Reply-To: <CAM_vjukhL613HUrb0Si+5WrmoW8fsvLewOPVSn01H=Hpe6cPCQ@mail.gmail.com>
References: <CA+jRDxAcwuX-yv12+Loefb59LBvno-Efx1Te9RN7P5iRdVPY4Q@mail.gmail.com>
	<CAM_vjukhL613HUrb0Si+5WrmoW8fsvLewOPVSn01H=Hpe6cPCQ@mail.gmail.com>
Message-ID: <CAJfh0RdGLLhFccDNKp5d0MOerX_wwq=50EhYt1y39SxfJE_7Yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/649a40f7/attachment.pl>

From jenagruhn at gmail.com  Wed Jul 23 00:08:55 2014
From: jenagruhn at gmail.com (Jennifer Gruhn)
Date: Tue, 22 Jul 2014 17:08:55 -0500
Subject: [R] Randomly sample data frame points relative to raster grid cells
Message-ID: <CAA5zFo0eU5DSQq0y46_=j=njMxB=Uwn50-bTONa9qwUKFVrZVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140722/5813965f/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 23 04:50:15 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 22 Jul 2014 19:50:15 -0700
Subject: [R] packages across different versions of R
In-Reply-To: <53CCFF22.5020600@stats.ox.ac.uk>
References: <CAAJc=rPLiNcbcnUxnpSxTJmQh3vXMOPdaUygrLLY1VdW=M4jvw@mail.gmail.com>
	<53CCFF22.5020600@stats.ox.ac.uk>
Message-ID: <EFBA1300-3380-4B54-B642-CB398EB746A6@comcast.net>


On Jul 21, 2014, at 4:53 AM, Prof Brian Ripley wrote:

> On 21/07/2014 12:24, Charles Thuo wrote:
>>  I have just installed R 3.1.1 in a machine where R 3.0.1 is already
>> installed.  Is it possible to use packages in the 3.0.1 on the 3.1.1.
>> version as the same are in a single workstation.
> 
> Perhaps, perhaps not.  It depends in part on your platform which you have not told us (see the posting guide).  It is definitely safer to reinstall them.  For Window users see http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What_0027s-the-best-way-to-upgrade_003f : similar ideas work for other platforms.
> 
> The place where using packages for 3.0.1 is least likely to work is OS X, but there installing a new binary version of R by default removes earlier installations.

It does? That has not been my experience, and I thought that Simon has repeatedly said that the opposite was true. At least for me the older versions persist as well as the packages residing in the library/ directory (and I do not remember overriding any defaults).

(I just needed some extra space this weekend and found that some of the packages with genomic data were taking up quite a bit of space in the 2.15 and 3.0 version Resources/library/ folders.

I thought the usual advice (which is part of the FAQ you linked to)  was to copy the contents of the Versions/<ver-no>/Resources/library/ directory from the prior version to the new similarly named directory and then run:

 update.packages(checkBuilt=TRUE,ask=FALSE) 
# I added that second argument b/c I have a large collection

(This doesn't work for packages only available on r-forge or github.)
-- 
David Winsemius
Alameda, CA, USA


From ccberry at ucsd.edu  Wed Jul 23 06:43:15 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Wed, 23 Jul 2014 04:43:15 +0000
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
References: <53CE7975.9010408@gwdg.de>
	<loom.20140722T180243-904@post.gmane.org>
Message-ID: <loom.20140723T061731-703@post.gmane.org>

Charles Berry <ccberry <at> ucsd.edu> writes:

> 
> Scherber, Christoph <cscherb1 <at> gwdg.de> writes:
> 
> > 
> > Dear all,
> > 
> > I am trying to express a multinomial GLM (using nnet) as a series of GLM
> models.

[deleted]

> 
> Doing the obvious comparison:
> 
> ggen.preds <- 
>     sapply( levels(multicats), 
>             function(x) predict(glm(I(multicats==x)~multiplan1,
>                          family=binomial),type="response"))
> 
> max(abs(ggen.preds-predict(m2,type="probs")))
> ## [1] 1.349607e-06

 
> The predictions are the same - up to numerical issues in the algorithms.
> 

But as John Fox points out this does not hold for the general case.

It worked here because the regressor has two categories.

HTH,

Chuck


From sowmyar at vegainvtech.com  Wed Jul 23 08:26:59 2014
From: sowmyar at vegainvtech.com (Sowmya Rudregowda)
Date: Wed, 23 Jul 2014 11:56:59 +0530
Subject: [R] need help for ppval() and xirr() in R
Message-ID: <CAGEzm4++=_bU25WrEMYq2O5YjZko2jp0bUQTygNn1JM9BSCNWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/91e31436/attachment.pl>

From byron_dom at yahoo.com  Wed Jul 23 06:58:34 2014
From: byron_dom at yahoo.com (Byron Dom)
Date: Tue, 22 Jul 2014 21:58:34 -0700
Subject: [R]  dx accuracy measures from raw data
Message-ID: <1406091514.948.YahooMailNeo@web142802.mail.bf1.yahoo.com>

Here is a partial answer (I think (?))

A common way to display results of this type is as a "receiver operating characteristic." See:?http://en.wikipedia.org/wiki/Receiver_operating_characteristic

It's displayed as a parametric curve where the parameter is the threshold value, the x-value (abscissa) is the false-positive rate and the y value is the true-positive rate. Then, a commonly computed single-number characterization is to compute the area under this curve (AUC) for false-positive rate running from 0 to 1. There are variations on this but I've just described the standard one.

There are multiple R-packages that will do all of this for you. One of them is the pROC package. See?http://cran.at.r-project.org/web/packages/pROC/pROC.pdf.


===============================================================
Date: Sun, 20 Jul 2014 18:28:12 +0100
From: Anoop Shah <anoopsshah at gmail.com>
To:?r-help at r-project.org
Subject: [R] dx accuracy measures from raw data
Message-ID: <0E7574AF-9890-419E-AE9D-978860054AF2 at gmail.com>
Content-Type: text/plain

Hello R users!

I am a medic and have been working with R for about 6 months now.

I was hoping to pick someone?s brain about a diagnostic accuracy study that has now been completed.

I am trying to derive the sensitivity, specificity, NPV and PPV with the corresponding 95% CI from the raw data.

My data is in a data frame as below


g.s??? t1??? t2??? t3??? t3??? t4??? t5??? index
Yes??? 1??? 1??? 1??? 1??? 1??? 1??? 1
Yes??? 1??? 1??? 1??? 1??? 1??? 1??? 2
Yes??? 1??? 1??? 1??? 1??? 1??? 1??? 3
Yes??? 1??? 1??? 1??? 1??? 1??? 1??? 4
Yes??? 1??? 1??? 1??? 1??? 1??? 1??? 5


Each row represents a patient with a unique id (variable: index).

g.s is a binary variable ans represents the results from the gold standard (yes / no).

t1 to t5 are the tests at different thresholds being tested.

t1 to t5 are all binary variables with 1 as yes and 0 as no.

Now i could create separate 2 x 2 tables for each threshold (t1 to t5) against the gold standard and subsequently derive sense, spec, NPV and PPV plus their 95 % CI for each threshold (t1 to t5).

I was however wondering if there was a more efficient way to get these results from the raw data in R.

Hope I have explained my self clearly and thanks a lot in advance!!

Cheers

Anoop
??? [[alternative HTML version deleted]]


From npan1990 at gmail.com  Wed Jul 23 11:51:04 2014
From: npan1990 at gmail.com (npan1990 .)
Date: Wed, 23 Jul 2014 12:51:04 +0300
Subject: [R] Feature Selection and Regression
Message-ID: <CAP8ucyQjY2_MVXSL+7MVUe1GgD9WxWeTqBB3-psK0rEezn=jcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/65590ea3/attachment.pl>

From rchandler-mant at mango-solutions.com  Wed Jul 23 13:06:06 2014
From: rchandler-mant at mango-solutions.com (Richard Chandler-Mant)
Date: Wed, 23 Jul 2014 11:06:06 +0000
Subject: [R] R_HOME setting on Linux
Message-ID: <402978B0F208994A96365BFAE8597126145947EC@mexchange.Mango.local>

I have an installation of R 3.0.2 on a CentOS 6.3 distribution in /opt/R/3.0.2

In the R start-up script (/opt/R/3.0.2/bin/R) the value of R_HOME is set to /opt/R/3.0.2/lib/R and this is the value returned from the R.home() function within an R session.

According to the installation documentation (http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation) the following statement is made about the R home directory:

"prefix/LIBnn/R or libdir/R
all the rest (libraries, on-line help system, ...). Here LIBnn is usually 'lib', but may be 'lib64' on some 64-bit Linux systems. This is known as the R home directory."

So from this I gather that my R linux installation is correct. The issue I am having is running some of the unit tests that are included with the core R application, specifically the reg-tests-1b.R file in the tests directory which contains the following:


## recursive listing of directories
p <- file.path(R.home(), "share","texmf") # always exists, readable lfri <- list.files(p, recursive=TRUE, include.dirs=TRUE) subdirs <- c("bibtex", "tex") lfnd <- setdiff(list.files(p, all.files=TRUE, no..=TRUE), ".svn") stopifnot(!is.na(match(subdirs, lfri)), identical(subdirs, lfnd)) ## the first failed for a few days, unnoticed, in the development version of R

This test is failing for me because R.home() = /opt/R/3.0.2/lib/R and the directory /opt/R/3.0.2/lib/R/share/texmf does not exist but does exist at /opt/R/3.0.2/share/texmf

Is this a bug with the test or an error in my installation?

Thank you in advance for your help.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From ripley at stats.ox.ac.uk  Wed Jul 23 14:11:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Jul 2014 13:11:51 +0100
Subject: [R] R_HOME setting on Linux
In-Reply-To: <402978B0F208994A96365BFAE8597126145947EC@mexchange.Mango.local>
References: <402978B0F208994A96365BFAE8597126145947EC@mexchange.Mango.local>
Message-ID: <53CFA687.9090300@stats.ox.ac.uk>

I am guessing this is a distribution prepared by someone else, with 
non-default settings for where things are installed.  If you do that, 
there is no guarantee that you can test the installed R, as the tests do 
generally assume the standard layout.

If you change this test to use file.path(R.home("share"),"texmf") it is 
more likely to work.

Note too that R 3.0.2 is already 3 versions old, and the posting guide 
asked to you to update before posting.

On 23/07/2014 12:06, Richard Chandler-Mant wrote:
> I have an installation of R 3.0.2 on a CentOS 6.3 distribution in /opt/R/3.0.2
>
> In the R start-up script (/opt/R/3.0.2/bin/R) the value of R_HOME is set to /opt/R/3.0.2/lib/R and this is the value returned from the R.home() function within an R session.
>
> According to the installation documentation (http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation) the following statement is made about the R home directory:
>
> "prefix/LIBnn/R or libdir/R
> all the rest (libraries, on-line help system, ...). Here LIBnn is usually 'lib', but may be 'lib64' on some 64-bit Linux systems. This is known as the R home directory."
>
> So from this I gather that my R linux installation is correct. The issue I am having is running some of the unit tests that are included with the core R application, specifically the reg-tests-1b.R file in the tests directory which contains the following:
>
>
> ## recursive listing of directories
> p <- file.path(R.home(), "share","texmf") # always exists, readable lfri <- list.files(p, recursive=TRUE, include.dirs=TRUE) subdirs <- c("bibtex", "tex") lfnd <- setdiff(list.files(p, all.files=TRUE, no..=TRUE), ".svn") stopifnot(!is.na(match(subdirs, lfri)), identical(subdirs, lfnd)) ## the first failed for a few days, unnoticed, in the development version of R
>
> This test is failing for me because R.home() = /opt/R/3.0.2/lib/R and the directory /opt/R/3.0.2/lib/R/share/texmf does not exist but does exist at /opt/R/3.0.2/share/texmf
>
> Is this a bug with the test or an error in my installation?
>
> Thank you in advance for your help.
>
> --
>
> LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From zadig_1 at excite.com  Wed Jul 23 15:08:16 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 23 Jul 2014 09:08:16 -0400
Subject: [R] Windows R doesn't recognize shortcuts ?
Message-ID: <20140723090816.7569@web006.roc2.bluetie.com>

Hi All,

In Windows 7 , R installation:

R version 3.1.1 Patched (2014-07-14 r66149) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

it doesn't recognize shortcuts in path :

>  list.files(path = "cygwin")
character(0)

cygwin is a shortcut,  in properties window  Target shows : C:\Users\me\cygwin64\home\me
Real path works :

list.files(path = "C:/Users/me/cygwin64/home/me")
  [1] "1010week.sh"            "10week.sh"              "a.R"                    "aa.sh"
....


From murdoch.duncan at gmail.com  Wed Jul 23 15:21:41 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Jul 2014 09:21:41 -0400
Subject: [R] Windows R doesn't recognize shortcuts ?
In-Reply-To: <20140723090816.7569@web006.roc2.bluetie.com>
References: <20140723090816.7569@web006.roc2.bluetie.com>
Message-ID: <53CFB6E5.7000706@gmail.com>

On 23/07/2014 9:08 AM, ce wrote:
> Hi All,
>
> In Windows 7 , R installation:
>
> R version 3.1.1 Patched (2014-07-14 r66149) -- "Sock it to Me"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> it doesn't recognize shortcuts in path :
>
> >  list.files(path = "cygwin")
> character(0)
>
> cygwin is a shortcut,  in properties window  Target shows : C:\Users\me\cygwin64\home\me
> Real path works :
>
> list.files(path = "C:/Users/me/cygwin64/home/me")
>    [1] "1010week.sh"            "10week.sh"              "a.R"                    "aa.sh"
>

I don't think R should recognize that.  Windows wouldn't recognize it 
either, if you used "dir cygwin" in a shell, for example.

Duncan Murdoch


From friendly at yorku.ca  Wed Jul 23 15:31:30 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 23 Jul 2014 09:31:30 -0400
Subject: [R] shading cells in a latex table by value
Message-ID: <53CFB932.1050909@yorku.ca>

I want to create latex tables of values where the cell background is 
shaded according to the
table value.  For example:

set.seed(1) # reproducibility
mat <- matrix(3 * rnorm(12), 3, 4)
rownames(mat) <- letters[1:3]
colnames(mat) <- LETTERS[1:4]

 > round(mat,1)
      A    B   C    D
a -1.9  4.8 1.5 -0.9
b  0.6  1.0 2.2  4.5
c -2.5 -2.5 1.7  1.2

# colors to use:  blue(+), red(-) with two shading levels,
# depending on abs(x) > 2
cols <- c(rgb(0.85,0.85,1),
           rgb(0.7 ,0.7 ,1),
           rgb(1,0.85,0.85),
           rgb(1,0.7 ,0.7 ))
cols <- matrix(cols, 2,2)

cellcol <- apply(mat, 1:2,
                  function(x) {i<-1+(x>0); j<-1+(abs(x)>2); cols[i,j]})
 >
 > cellcol
   A         B         C         D
a "#D9D9FF" "#FFB2B2" "#B2B2FF" "#D9D9FF"
b "#B2B2FF" "#B2B2FF" "#FFB2B2" "#FFB2B2"
c "#FFD9D9" "#FFD9D9" "#B2B2FF" "#B2B2FF"

What I want is to generate a latex table of mat, with each cell colored 
according to cellcol.
I can do this manually as shown below, using the latex colortbl package 
and a macro
\cell{value}{color}.  How can I produce this in R?

# colortab-test.tex -----------------------
%% Latex part:

\documentclass[11pt]{article}
\usepackage{xcolor,colortbl}

# wrap each cell with command to define background color
\newcommand{\cell}[2]{\multicolumn{1}%
    {>{\columncolor{#1}}r}{#2}}

\definecolor{blueA}{rgb}{0.85,0.85,1}
\definecolor{blueB}{rgb}{0.7 ,0.7 ,1}
\definecolor{redA}{rgb}{1,0.85,0.85}
\definecolor{redB}{rgb}{1,0.7 ,0.7 }

\begin{document}

\begin{tabular}{lcccc}
     &  A  & B  & C  & D \\
  a & \cell{-1.9}{redB} & \cell{4.8}{blueA} & \cell{1.5}{blueB} & 
\cell{-0.9}{redB} \\
  b & \cell{0.6}{blueB} & \cell{1.0}{blueB} & \cell{2.2}{blueA} &  
\cell{4.5}{blueA} \\
  c  \cell{-2.5}{redA}  & \cell{-2.5}{redB} & \cell{1.7}{blueB} &  
\cell{1.2}{blueB}  \\
\end{tabular}
\end{document}
# --------------------------------------------


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From zadig_1 at excite.com  Wed Jul 23 15:35:48 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 23 Jul 2014 09:35:48 -0400
Subject: [R] Windows R doesn't recognize shortcuts ?
Message-ID: <20140723093548.427@web007.roc2.bluetie.com>

Indeed DOS command doesn't work neither . cygwin.lnk list itself but not what is in the folder :

dir cygwin
 Volume in drive C is WINDOWS
 Volume Serial Number is F410-6A8D

 Directory of C:\Users\me\Desktop

File Not Found

dir cygwin.lnk
 Volume in drive C is WINDOWS
 Volume Serial Number is F410-6A8D

 Directory of C:\Users\me\Desktop

08/01/2014  04:07 PM             1,424 cygwin.lnk
               1 File(s)          1,424 bytes
               0 Dir(s)  98,285,953,024 bytes free

dir cygwin.lnk/*.*
Invalid switch - "*.*".

R doesn't lsit cygwin.lnk 

> list.files(path = "cygwin.lnk")
character(0)



-----Original Message-----
From: "Duncan Murdoch" [murdoch.duncan at gmail.com]
Date: 07/23/2014 09:21 AM
To: "ce" <zadig_1 at excite.com>, r-help at r-project.org
Subject: Re: [R] Windows R doesn't recognize shortcuts ?

On 23/07/2014 9:08 AM, ce wrote:
> Hi All,
>
> In Windows 7 , R installation:
>
> R version 3.1.1 Patched (2014-07-14 r66149) -- "Sock it to Me"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> it doesn't recognize shortcuts in path :
>
> >  list.files(path = "cygwin")
> character(0)
>
> cygwin is a shortcut,  in properties window  Target shows : C:\Users\me\cygwin64\home\me
> Real path works :
>
> list.files(path = "C:/Users/me/cygwin64/home/me")
>    [1] "1010week.sh"            "10week.sh"              "a.R"                    "aa.sh"
>

I don't think R should recognize that.  Windows wouldn't recognize it 
either, if you used "dir cygwin" in a shell, for example.

Duncan Murdoch


From john.archie.mckown at gmail.com  Wed Jul 23 15:47:55 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 23 Jul 2014 08:47:55 -0500
Subject: [R] Trying to change a qplot() to a ggplot()+
Message-ID: <CAAJSdjjP-9mV=sqsMkA+SLV7C_O6zGGA_szYLKceRT8xmifbGA@mail.gmail.com>

I'm trying to change a qplot to a ggplot. The reason is because I want
two plots of the same data. One a bar char, the other a line graph.
What I'm trying:

#MSU_graph_m1b <-
qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="bar",stat="identity",color=System_alias);

MSU_graph_m1   <-
qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));

MSU_graph_m1b  <- MSU_graph_m1+geom_bar();

#MSU_graph_m1l <- qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="line");

MSU_graph_m1l  <- MSU_graph_m1+geom_line();

The commented lines are what works. What fails is the first ggplit() like:

> MSU_graph_m1   <- qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));
Error in as.matrix.data.frame(x) :
  dims [product 9912] do not match the length of object [9923]
>

cpprdald2_m1 is:
> str(cpprdald2_m1)
'data.frame':   168 obs. of  60 variables:

and Int_Start and LicPrLsys4HSMU are variables in cpprdald2_m1.
Int_Start is a POSIXlt. LicPrLsys4HSMU is a number. I have also tried
with x=as.character(Int_Start) in the aes().

I am using the book "R GRAPHICS COOKBOOK" as my source of examples. I
am obviously oblivious to something.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Wed Jul 23 16:00:45 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 23 Jul 2014 09:00:45 -0500
Subject: [R] Trying to change a qplot() to a ggplot()+
In-Reply-To: <CAAJSdjjP-9mV=sqsMkA+SLV7C_O6zGGA_szYLKceRT8xmifbGA@mail.gmail.com>
References: <CAAJSdjjP-9mV=sqsMkA+SLV7C_O6zGGA_szYLKceRT8xmifbGA@mail.gmail.com>
Message-ID: <CAAJSdjh4qL1b9Q9Q5Mdf4qR4GOMbMvCQrVyV4vms+i=FSSQowg@mail.gmail.com>

I got an off-line reply which fixed my problem. And, it is a good
thing my cataract surgery is soon, no? turns out that qqplot and
ggplot are not the same! <grin/>. But the font in notepad on Windows
is such that I have difficulty in telling the difference.

On Wed, Jul 23, 2014 at 8:47 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> I'm trying to change a qplot to a ggplot. The reason is because I want
> two plots of the same data. One a bar char, the other a line graph.
> What I'm trying:
>
> #MSU_graph_m1b <-
> qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="bar",stat="identity",color=System_alias);
>
> MSU_graph_m1   <-
> qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));
>
> MSU_graph_m1b  <- MSU_graph_m1+geom_bar();
>
> #MSU_graph_m1l <- qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="line");
>
> MSU_graph_m1l  <- MSU_graph_m1+geom_line();
>
> The commented lines are what works. What fails is the first ggplit() like:
>
>> MSU_graph_m1   <- qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));
> Error in as.matrix.data.frame(x) :
>   dims [product 9912] do not match the length of object [9923]
>>
>
> cpprdald2_m1 is:
>> str(cpprdald2_m1)
> 'data.frame':   168 obs. of  60 variables:
>
> and Int_Start and LicPrLsys4HSMU are variables in cpprdald2_m1.
> Int_Start is a POSIXlt. LicPrLsys4HSMU is a number. I have also tried
> with x=as.character(Int_Start) in the aes().
>
> I am using the book "R GRAPHICS COOKBOOK" as my source of examples. I
> am obviously oblivious to something.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From Thierry.ONKELINX at inbo.be  Wed Jul 23 16:00:52 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 23 Jul 2014 14:00:52 +0000
Subject: [R] Trying to change a qplot() to a ggplot()+
In-Reply-To: <CAAJSdjjP-9mV=sqsMkA+SLV7C_O6zGGA_szYLKceRT8xmifbGA@mail.gmail.com>
References: <CAAJSdjjP-9mV=sqsMkA+SLV7C_O6zGGA_szYLKceRT8xmifbGA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC48DB@inbomail.inbo.be>

It is ggplot (double G), not qqplot (double Q)

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens John McKown
Verzonden: woensdag 23 juli 2014 15:48
Aan: r-help
Onderwerp: [R] Trying to change a qplot() to a ggplot()+

I'm trying to change a qplot to a ggplot. The reason is because I want two plots of the same data. One a bar char, the other a line graph.
What I'm trying:

#MSU_graph_m1b <-
qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="bar",stat="identity",color=System_alias);

MSU_graph_m1   <-
qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));

MSU_graph_m1b  <- MSU_graph_m1+geom_bar();

#MSU_graph_m1l <- qplot(Int_Start,LicPrLsys4HMSU,data=cpprdald2_m1,geom="line");

MSU_graph_m1l  <- MSU_graph_m1+geom_line();

The commented lines are what works. What fails is the first ggplit() like:

> MSU_graph_m1   <- qqplot(cpprdald2_m1,aes(x=Int_Start,y=LicPrLsys4HSMU,colour=System_alias));
Error in as.matrix.data.frame(x) :
  dims [product 9912] do not match the length of object [9923]
>

cpprdald2_m1 is:
> str(cpprdald2_m1)
'data.frame':   168 obs. of  60 variables:

and Int_Start and LicPrLsys4HSMU are variables in cpprdald2_m1.
Int_Start is a POSIXlt. LicPrLsys4HSMU is a number. I have also tried with x=as.character(Int_Start) in the aes().

I am using the book "R GRAPHICS COOKBOOK" as my source of examples. I am obviously oblivious to something.

--
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From anoopsshah at gmail.com  Wed Jul 23 16:47:31 2014
From: anoopsshah at gmail.com (Anoop Shah)
Date: Wed, 23 Jul 2014 15:47:31 +0100
Subject: [R] Dx accuracy measures from raw data
References: <0E7574AF-9890-419E-AE9D-978860054AF2@gmail.com>
Message-ID: <A2CE4279-5188-43A2-A7A3-F205D291ED33@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/95d13799/attachment.pl>

From sarah.goslee at gmail.com  Wed Jul 23 17:05:31 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 23 Jul 2014 11:05:31 -0400
Subject: [R] Dx accuracy measures from raw data
In-Reply-To: <A2CE4279-5188-43A2-A7A3-F205D291ED33@gmail.com>
References: <0E7574AF-9890-419E-AE9D-978860054AF2@gmail.com>
	<A2CE4279-5188-43A2-A7A3-F205D291ED33@gmail.com>
Message-ID: <CAM_vju=54bHx9=h_8mgOFH_DNHQF9RhHLRtPTvYJ4nTBDn2XdA@mail.gmail.com>

Hi,

I'm pretty sure you posted this exact question already. Usually if you
don't get any replies, it means your question is badly-formed. Posting
the same thing won't help any. Posting a revised version might.

Your example data is not really helpful to someone trying to suggest R
code, since it's all Yes or 1 values. Using dput() is also a LOT more
useful than trying to copy and paste (especially since you posted HTML
to the list, which tends to get mangled).

Have you looked into any of the many R packages that calculate the
statistics you're interested in, to learn how they expect their data
to be formatted? That would be much more useful than you trying to
reinvent the wheel.

http://www.rseek.org

is a good place to search for R-related information, including
packages functions to do particular things. A search there lists many
options for doing what you want. Your first step should probably be to
investigate them.

Once you've done that, a clear R question posted to the list is far
more likely to receive useful answers. Here's another link that might
be of use to you:

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Also, please keep in mind that this list is very general, and most of
us do not share your subject domain knowledge. The more explicit you
can be about what you want and how, the more useful and abundant the
replies are likely to be.

Sarah


On Wed, Jul 23, 2014 at 10:47 AM, Anoop Shah <anoopsshah at gmail.com> wrote:
> Hello R users!
>
> I am a medic and have been working with R for about 6 months now.
>
> I was hoping to pick someone?s brain about a diagnostic accuracy study that has now been completed.
>
> I am trying to derive the sensitivity, specificity, NPV and PPV with the corresponding 95% CI from the raw data.
>
> My data is in a data frame as below
>
>
> g.s     t1      t2      t3      t3      t4      t5      index
> Yes     1       1       1       1       1       1       1
> Yes     1       1       1       1       1       1       2
> Yes     1       1       1       1       1       1       3
> Yes     1       1       1       1       1       1       4
> Yes     1       1       1       1       1       1       5
>
>
> Each row represents a patient with a unique id (variable: index).
>
> g.s is a binary variable ans represents the results from the gold standard (yes / no).
>
> t1 to t5 are the tests at different thresholds being tested.
>
> t1 to t5 are all binary variables with 1 as yes and 0 as no.
>
> Now i could create separate 2 x 2 tables for each threshold (t1 to t5) against the gold standard and subsequently derive sense, spec, NPV and PPV plus their 95 % CI for each threshold (t1 to t5).
>
> I was however wondering if there was a more efficient way to get these results from the raw data in R.
>
> Hope I have explained my self clearly and thanks a lot in advance!!
>
> Cheers
>
> Anoop
>
> Dr Anoop Shah
> Cardiology Research fellow
> Centre of Cardiovascular sciences
> Chancellors Building
> Room SU 305
> University Of Edinburgh
> Little France
> Edinburgh
> EH16 4SB
>
> Tel: +447766544156
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Wed Jul 23 17:31:43 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Jul 2014 11:31:43 -0400
Subject: [R] shading cells in a latex table by value
In-Reply-To: <53CFB932.1050909@yorku.ca>
References: <53CFB932.1050909@yorku.ca>
Message-ID: <53CFD55F.80108@gmail.com>

On 23/07/2014, 9:31 AM, Michael Friendly wrote:
> I want to create latex tables of values where the cell background is 
> shaded according to the
> table value.  For example:
> 
> set.seed(1) # reproducibility
> mat <- matrix(3 * rnorm(12), 3, 4)
> rownames(mat) <- letters[1:3]
> colnames(mat) <- LETTERS[1:4]
> 
>  > round(mat,1)
>       A    B   C    D
> a -1.9  4.8 1.5 -0.9
> b  0.6  1.0 2.2  4.5
> c -2.5 -2.5 1.7  1.2
> 
> # colors to use:  blue(+), red(-) with two shading levels,
> # depending on abs(x) > 2
> cols <- c(rgb(0.85,0.85,1),
>            rgb(0.7 ,0.7 ,1),
>            rgb(1,0.85,0.85),
>            rgb(1,0.7 ,0.7 ))
> cols <- matrix(cols, 2,2)
> 
> cellcol <- apply(mat, 1:2,
>                   function(x) {i<-1+(x>0); j<-1+(abs(x)>2); cols[i,j]})
>  >
>  > cellcol
>    A         B         C         D
> a "#D9D9FF" "#FFB2B2" "#B2B2FF" "#D9D9FF"
> b "#B2B2FF" "#B2B2FF" "#FFB2B2" "#FFB2B2"
> c "#FFD9D9" "#FFD9D9" "#B2B2FF" "#B2B2FF"
> 
> What I want is to generate a latex table of mat, with each cell colored 
> according to cellcol.
> I can do this manually as shown below, using the latex colortbl package 
> and a macro
> \cell{value}{color}.  How can I produce this in R?
> 
> # colortab-test.tex -----------------------
> %% Latex part:
> 
> \documentclass[11pt]{article}
> \usepackage{xcolor,colortbl}
> 
> # wrap each cell with command to define background color
> \newcommand{\cell}[2]{\multicolumn{1}%
>     {>{\columncolor{#1}}r}{#2}}
> 
> \definecolor{blueA}{rgb}{0.85,0.85,1}
> \definecolor{blueB}{rgb}{0.7 ,0.7 ,1}
> \definecolor{redA}{rgb}{1,0.85,0.85}
> \definecolor{redB}{rgb}{1,0.7 ,0.7 }
> 
> \begin{document}
> 
> \begin{tabular}{lcccc}
>      &  A  & B  & C  & D \\
>   a & \cell{-1.9}{redB} & \cell{4.8}{blueA} & \cell{1.5}{blueB} & 
> \cell{-0.9}{redB} \\
>   b & \cell{0.6}{blueB} & \cell{1.0}{blueB} & \cell{2.2}{blueA} &  
> \cell{4.5}{blueA} \\
>   c  \cell{-2.5}{redA}  & \cell{-2.5}{redB} & \cell{1.7}{blueB} &  
> \cell{1.2}{blueB}  \\
> \end{tabular}
> \end{document}
> # --------------------------------------------

You could do this using the tables package, with a custom format
function.  Normally you would calculate the table entries within the
formula, but you can also convert a matrix.

For example,

colornames <- matrix(c("blueA", "blueB", "redA", "redB"),
                   2,2)

myformat <- function(x) {
  i<-1+(x>0)
  j<-1+(abs(x)>2)
  paste0("\\cell{", round(x,1), "}{", colornames[cbind(i,j)], "}")
}

tab <- as.tabular(mat, like=tabular(Heading()*row ~
Heading()*col*Format(myformat()),
                        data=data.frame(row=rep(letters[1:3],4),
                                        col=rep(LETTERS[1:4],3))))
latex(tab)

produces

\begin{tabular}{lcccc}
\hline
  & A & B & C & \multicolumn{1}{c}{D} \\
\hline
a  & \cell{-1.9}{blueA} & \cell{4.8}{redB} & \cell{1.5}{blueB} &
\cell{-0.9}{blueA} \\
b  & \cell{0.6}{blueB} & \cell{1}{blueB} & \cell{2.2}{redB} &
\cell{4.5}{redB} \\
c  & \cell{-2.5}{redA} & \cell{-2.5}{redA} & \cell{1.7}{blueB} &
\cell{1.2}{blueB} \\
\hline
\end{tabular}

It's a little cumbersome to tack the formatting onto an existing matrix;
the normal expectation is that a tabular() call would be used to compute
the cell values as well.

Duncan Murdoch


From khurram.nadee at gmail.com  Wed Jul 23 17:33:11 2014
From: khurram.nadee at gmail.com (Khurram Nadeem)
Date: Wed, 23 Jul 2014 12:33:11 -0300
Subject: [R] Importing random subsets of a data file
Message-ID: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/75d3f051/attachment.pl>

From sarah.goslee at gmail.com  Wed Jul 23 17:37:17 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 23 Jul 2014 11:37:17 -0400
Subject: [R] Importing random subsets of a data file
In-Reply-To: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
References: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
Message-ID: <CAM_vjumhpPTmPeBEWD5ZXFZ032jG-A7pNhjjyp242ZCNiqFgLg@mail.gmail.com>

Hi,

You can use scan() with the nlines and skip arguments to read in a
single line from anywhere in a file.

Sarah

On Wed, Jul 23, 2014 at 11:33 AM, Khurram Nadeem
<khurram.nadee at gmail.com> wrote:
> Hi R folks,
>
> Here is my problem.
>
> *1.* I have a large data file (say, in .csv or .txt format) containing 1
> million rows and 500 variables (columns).
>
> *2.* My statistical algorithm does not require the entire dataset but just
> a small random sample from the original 1 million rows.
>
> *3. *This algorithm needs to be applied 10000 times, each time generating a
> different random sample from the 'big' file as described in (2) above.
>
> Is there a way to 'import' only a (random) subset of rows from the .csv
> file without importing the entire dataset? A quick search on various R
> forums suggest that read.table() does not have this functionality.
> Obviously, I want to avoid importing the whole file because of memory
> issues. Looking forward to your help.
>
> Thanks,
> Khurram


-- 
Sarah Goslee
http://www.functionaldiversity.org


From friendly at yorku.ca  Wed Jul 23 18:27:02 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 23 Jul 2014 12:27:02 -0400
Subject: [R] shading cells in a latex table by value
In-Reply-To: <53CFD55F.80108@gmail.com>
References: <53CFB932.1050909@yorku.ca> <53CFD55F.80108@gmail.com>
Message-ID: <53CFE256.1070501@yorku.ca>

Thanks, Duncan
That's quite lovely, and makes me appreciate the tables package even more,
so I'll have to study your details.

The more general version of this idea is that rendering values in a latex
table with visual attributes (background color, font color, font family,
font shape, font weight)  according to a function of the cell value
is useful in the same way as visual attributes in plots, but, at
present, far more difficult.

best,
-Michael

On 07/23/2014 11:31 AM, Duncan Murdoch wrote:
> On 23/07/2014, 9:31 AM, Michael Friendly wrote:
>> I want to create latex tables of values where the cell background is
>> shaded according to the
>> table value.  For example:
>>
>> set.seed(1) # reproducibility
>> mat <- matrix(3 * rnorm(12), 3, 4)
>> rownames(mat) <- letters[1:3]
>> colnames(mat) <- LETTERS[1:4]
>>
>>   > round(mat,1)
>>        A    B   C    D
>> a -1.9  4.8 1.5 -0.9
>> b  0.6  1.0 2.2  4.5
>> c -2.5 -2.5 1.7  1.2
>>
>> # colors to use:  blue(+), red(-) with two shading levels,
>> # depending on abs(x) > 2
>> cols <- c(rgb(0.85,0.85,1),
>>             rgb(0.7 ,0.7 ,1),
>>             rgb(1,0.85,0.85),
>>             rgb(1,0.7 ,0.7 ))
>> cols <- matrix(cols, 2,2)
>>
>> cellcol <- apply(mat, 1:2,
>>                    function(x) {i<-1+(x>0); j<-1+(abs(x)>2); cols[i,j]})
>>   >
>>   > cellcol
>>     A         B         C         D
>> a "#D9D9FF" "#FFB2B2" "#B2B2FF" "#D9D9FF"
>> b "#B2B2FF" "#B2B2FF" "#FFB2B2" "#FFB2B2"
>> c "#FFD9D9" "#FFD9D9" "#B2B2FF" "#B2B2FF"
>>
>> What I want is to generate a latex table of mat, with each cell colored
>> according to cellcol.
>> I can do this manually as shown below, using the latex colortbl package
>> and a macro
>> \cell{value}{color}.  How can I produce this in R?
>>
>> # colortab-test.tex -----------------------
>> %% Latex part:
>>
>> \documentclass[11pt]{article}
>> \usepackage{xcolor,colortbl}
>>
>> # wrap each cell with command to define background color
>> \newcommand{\cell}[2]{\multicolumn{1}%
>>      {>{\columncolor{#1}}r}{#2}}
>>
>> \definecolor{blueA}{rgb}{0.85,0.85,1}
>> \definecolor{blueB}{rgb}{0.7 ,0.7 ,1}
>> \definecolor{redA}{rgb}{1,0.85,0.85}
>> \definecolor{redB}{rgb}{1,0.7 ,0.7 }
>>
>> \begin{document}
>>
>> \begin{tabular}{lcccc}
>>       &  A  & B  & C  & D \\
>>    a & \cell{-1.9}{redB} & \cell{4.8}{blueA} & \cell{1.5}{blueB} &
>> \cell{-0.9}{redB} \\
>>    b & \cell{0.6}{blueB} & \cell{1.0}{blueB} & \cell{2.2}{blueA} &
>> \cell{4.5}{blueA} \\
>>    c  \cell{-2.5}{redA}  & \cell{-2.5}{redB} & \cell{1.7}{blueB} &
>> \cell{1.2}{blueB}  \\
>> \end{tabular}
>> \end{document}
>> # --------------------------------------------
> You could do this using the tables package, with a custom format
> function.  Normally you would calculate the table entries within the
> formula, but you can also convert a matrix.
>
> For example,
>
> colornames <- matrix(c("blueA", "blueB", "redA", "redB"),
>                     2,2)
>
> myformat <- function(x) {
>    i<-1+(x>0)
>    j<-1+(abs(x)>2)
>    paste0("\\cell{", round(x,1), "}{", colornames[cbind(i,j)], "}")
> }
>
> tab <- as.tabular(mat, like=tabular(Heading()*row ~
> Heading()*col*Format(myformat()),
>                          data=data.frame(row=rep(letters[1:3],4),
>                                          col=rep(LETTERS[1:4],3))))
> latex(tab)
>
> produces
>
> \begin{tabular}{lcccc}
> \hline
>    & A & B & C & \multicolumn{1}{c}{D} \\
> \hline
> a  & \cell{-1.9}{blueA} & \cell{4.8}{redB} & \cell{1.5}{blueB} &
> \cell{-0.9}{blueA} \\
> b  & \cell{0.6}{blueB} & \cell{1}{blueB} & \cell{2.2}{redB} &
> \cell{4.5}{redB} \\
> c  & \cell{-2.5}{redA} & \cell{-2.5}{redA} & \cell{1.7}{blueB} &
> \cell{1.2}{blueB} \\
> \hline
> \end{tabular}
>
> It's a little cumbersome to tack the formatting onto an existing matrix;
> the normal expectation is that a tabular() call would be used to compute
> the cell values as well.
>
> Duncan Murdoch


-- 
Michael Friendly     Email: friendly at yorku.ca
Professor, Psychology Dept.
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    http://datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ecjbosu at aol.com  Wed Jul 23 14:45:45 2014
From: ecjbosu at aol.com (Joe W. Byers)
Date: Wed, 23 Jul 2014 07:45:45 -0500
Subject: [R] Application design.
In-Reply-To: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
References: <CAAJSdjj03Kgw1-UBcPGdA-MCPT6tsTDOmgJMmG+D3=RSh5mJkg@mail.gmail.com>
Message-ID: <53CFAE79.5080403@aol.com>

On 07/21/2014 09:24 PM, John McKown wrote:
> I'm designing an R based application for my boss. It's not much, but
> it might save him some time. What it will be doing is reading data
> from an MS-SQL database and creating a number of graphs. At present,
> he must log into one server to run a vendor application to display the
> data in a grid. He then cuts this data and pastes it into an Excel
> spreadsheet. He then generates some graphs in Excel. Which he then
> cuts and pastes into a Power Point presentation. Which is the end
> result for distribution to others up the food chain.
>
> What I would like to do is read the MS-SQL data base using RODBC and
> create the graphs using ggplot2 instead of using Excel. I may end up
> being told to create an Excel file as well.
>
> My real question is organizing the R programs to do this. Basically
> what I was thinking of was a "master" program. It does the ODBC work
> and fetches the data into one, or more, data.frames. I was then
> thinking that it would be better to have separate source files for
> each graph produced. I would use the source() function in the "master"
> R program to load & execute each one in order. Is this a decent
> origination? Or would it be better for each "create a graph" R file to
> really just define a unique function which the "master" program would
> then invoke? I guess this latter would be a good way to keep the
> workspace "clean" since all the variables in the functinon would "go
> away" when the function ended.
>
> I guess what I'm asking is how others organize the R applications. Oh,
> I plan for this to be run by my boss by double clicking on the
> "master" R source file, which I will associate with the Rscript
> program in Windows. Yes, this is Windows based <sigh/>.
>
> Appreciate your thoughts. Especially if I'm really off track.
>

John,

Your original plan is simple and straight forward, and is similar to 
many of the processes that I have automated using R.  I use both RJDBC 
and RODBC to connect to a database.  I have wrapper JDBC and ODBC.Pull 
scripts that are wrappers to the other libraries that accept the 
connection parameters and a sql string.  These will return a data.frame, 
and if needed set the mode/class of the columns according to the 
database meta data. You can create a master job that call a function to 
pull the data you need, calls plotting functions, and generates graphs, 
tabular reports, and as suggested Excel files.  I use xlsx to build 
Excel reports.  I use hwriter to generate html reports that I publish. 
I have a small function that loads when I start R call setSources(). 
This allows me load my custom code from different directories like using 
library() or require().

Keep it simple until you are comfortable with your results.
1.  Master Job script (loaded at startup)
2.  Methods for each sub process
	data pull, plots, etc.
3.  An email to or other notification that the process is completed (if 
you want it to run and have your boss log into a share point or other BI 
delivery portal).

Good luck


From dwinsemius at comcast.net  Wed Jul 23 18:55:26 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Jul 2014 09:55:26 -0700
Subject: [R] Importing random subsets of a data file
In-Reply-To: <CAM_vjumhpPTmPeBEWD5ZXFZ032jG-A7pNhjjyp242ZCNiqFgLg@mail.gmail.com>
References: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
	<CAM_vjumhpPTmPeBEWD5ZXFZ032jG-A7pNhjjyp242ZCNiqFgLg@mail.gmail.com>
Message-ID: <1566ED3F-6E05-43BF-8BC2-A0540FC10486@comcast.net>

I think an external program like awk (or gawk) would be better. You can call it with the R system() function if needed.

http://stackoverflow.com/questions/7514896/select-random-3000-lines-from-a-file-with-awk-codes

You might want to sample once and then break into sequential subsets rather than calling 10,000 times.

You have not said whether this is to be done with or without replacement, but if the rows have a unique identifier there is always the `duplicated` function.

-- 
David.

On Jul 23, 2014, at 8:37 AM, Sarah Goslee wrote:

> Hi,
> 
> You can use scan() with the nlines and skip arguments to read in a
> single line from anywhere in a file.
> 
> Sarah
> 
> On Wed, Jul 23, 2014 at 11:33 AM, Khurram Nadeem
> <khurram.nadee at gmail.com> wrote:
>> Hi R folks,
>> 
>> Here is my problem.
>> 
>> *1.* I have a large data file (say, in .csv or .txt format) containing 1
>> million rows and 500 variables (columns).
>> 
>> *2.* My statistical algorithm does not require the entire dataset but just
>> a small random sample from the original 1 million rows.
>> 
>> *3. *This algorithm needs to be applied 10000 times, each time generating a
>> different random sample from the 'big' file as described in (2) above.
>> 
>> Is there a way to 'import' only a (random) subset of rows from the .csv
>> file without importing the entire dataset? A quick search on various R
>> forums suggest that read.table() does not have this functionality.
>> Obviously, I want to avoid importing the whole file because of memory
>> issues. Looking forward to your help.
>> 
>> Thanks,
>> Khurram
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From 538280 at gmail.com  Wed Jul 23 18:56:37 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 23 Jul 2014 10:56:37 -0600
Subject: [R] Importing random subsets of a data file
In-Reply-To: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
References: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
Message-ID: <CAFEqCdxXQ2c6bCbRRzn1fONecCYpQbF62caUhOhpqeWaiTSJBw@mail.gmail.com>

For speed your best choice is probably to load your data into a
database, then pull your samples from the database.  A simple database
is SQLite and there are R packages that work directly with that
database.

Can the later samples contain some of the same rows as previous
samples?  Or once a row is used in a sample, it can never be used
again in a later sample?  If the former you could use R to choose a
sample of "row numbers" then ask the database for those rows (some
databases have the concept of rows built in, others would need a
sequential column of "row numbers" added), then repeat for each
sample.  If the later then you could add a column to the database
based on randomly generated numbers and create an index (sort) by that
column, then select the 1st n observations as the 1st sample, the next
n observations as the 2nd sample, etc.

On Wed, Jul 23, 2014 at 9:33 AM, Khurram Nadeem <khurram.nadee at gmail.com> wrote:
> Hi R folks,
>
> Here is my problem.
>
> *1.* I have a large data file (say, in .csv or .txt format) containing 1
> million rows and 500 variables (columns).
>
> *2.* My statistical algorithm does not require the entire dataset but just
> a small random sample from the original 1 million rows.
>
> *3. *This algorithm needs to be applied 10000 times, each time generating a
> different random sample from the 'big' file as described in (2) above.
>
> Is there a way to 'import' only a (random) subset of rows from the .csv
> file without importing the entire dataset? A quick search on various R
> forums suggest that read.table() does not have this functionality.
> Obviously, I want to avoid importing the whole file because of memory
> issues. Looking forward to your help.
>
> Thanks,
> Khurram
> ------------------------
>  Khurram Nadeem
>  Postdoctoral Research Fellow
>  Department of Mathematics & Statistics
>  Acadia University, NS, Canada.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From khurram.nadee at gmail.com  Wed Jul 23 20:44:54 2014
From: khurram.nadee at gmail.com (Khurram Nadeem)
Date: Wed, 23 Jul 2014 15:44:54 -0300
Subject: [R] Importing random subsets of a data file
In-Reply-To: <CAFEqCdxXQ2c6bCbRRzn1fONecCYpQbF62caUhOhpqeWaiTSJBw@mail.gmail.com>
References: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
	<CAFEqCdxXQ2c6bCbRRzn1fONecCYpQbF62caUhOhpqeWaiTSJBw@mail.gmail.com>
Message-ID: <CABPyHrZCFT_-48TpJd7LW5jw82jN5=BfMFNKCtq4hfMPqR5KYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/0cd7556f/attachment.pl>

From wht_crl at yahoo.com  Wed Jul 23 21:16:15 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 23 Jul 2014 12:16:15 -0700
Subject: [R] corresponding replicated el of one matrix in another matrix or
	vector
Message-ID: <1406142975.84321.YahooMailNeo@web121504.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/2b16cf2d/attachment.pl>

From cscherb1 at gwdg.de  Wed Jul 23 21:54:17 2014
From: cscherb1 at gwdg.de (Christoph Scherber)
Date: Wed, 23 Jul 2014 21:54:17 +0200
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
In-Reply-To: <web-519644847@cgpsrv2.cis.mcmaster.ca>
References: <53CE7975.9010408@gwdg.de> <web-519644847@cgpsrv2.cis.mcmaster.ca>
Message-ID: <53D012E9.9030106@gwdg.de>

Dear John and R-helpers,

Thanks for your replies that were both very helpful.

The reason I was asking is that I?m searching for an easier way to 
incorporate *random effects* in a multinomial model.

I was hoping that *combinations of binomial glmmPQL or lmer calls* might 
be able to do the job - as MCMCglmm would require me to become Bayesian...

Do you think that combinations of binomial GLMs or glmmPQLs/lmer models 
would make sense? (example code again below, still without random effects)

The responses I deal with usually have >50 categories.

Thanks again and best wishes,
Christoph

#Example code again (thanks Charles Berry for pointing me at how to use 
sapply in this context):
#set up data: (don?t care what they are, just for playing)
set.seed(0)
cats=c("oligolectic","polylectic","specialist","generalist")
explan1=c("natural","managed")

multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
multiplan1=factor(rep(explan1,50))

##
library(nnet)
m2=multinom(multicats~multiplan1)

ggen.preds <-
     sapply( levels(multicats),
             function(x) predict(glm(I(multicats==x)~multiplan1,
                          family=binomial),type="response"))

max(abs(ggen.preds-predict(m2,type="probs")))





Am 22.07.2014 22:20, schrieb John Fox:
> Dear Christoph,
>
> If I understand correctly what you've done, the two approaches are not equivalent and should not in general produce the same fitted probabilities.
>
> Letting {a, b} represent logit(a vs. b) = log(Pr(a)/Pr(b)) and {ab, cd} represent logit(a or b vs. c or d), and numbering the response levels 1, 2, 3, 4, then the multinomial logit model fits the logits {2, 1}, {3, 1}, {4, 1}, while your binary logit models are for the logits {12, 34}, {23, 14}, {34, 12}. Note that the first and third are complementary, but even if you had used three distinct logits of this kind, the combined models (which BTW wouldn't be independent) would not be equivalent to the multinomial logit model.
>
> I hope that this helps (and that I've not misconstrued what you did).
>
> Best,
>   John
>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 	
> On Tue, 22 Jul 2014 16:47:17 +0200
>   "Scherber, Christoph" <cscherb1 at gwdg.de> wrote:
>> Dear all,
>>
>> I am trying to express a multinomial GLM (using nnet) as a series of GLM models.
>>
>> However, when I compare the multinom() predictions to those from GLM, I see differences that I can?t
>> explain. Can anyone help me out here?
>>
>> Here comes a reproducible example:
>>
>> ##
>> # set up data: (don?t care what they are, just for playing)
>> set.seed(0)
>> cats=c("oligolectic","polylectic","specialist","generalist")
>> explan1=c("natural","managed")
>> explan2=c("meadow","meadow","pasture","pasture")
>> multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
>> multiplan1=factor(rep(explan1,50))
>> multiplan2=factor(rep(explan2,25))
>>
>> ########################
>> library(nnet)
>> m2=multinom(multicats~multiplan1)
>>
>> # predictions from multinomial model
>> predict(m2,type="probs")
>>
>> ########################
>> # now set up contrasts for response variable "multicats" (which has 4 levels):
>>
>> ii=as.numeric(multicats)
>>
>> g1=glm(I(ii%in%c(1,2)) ~ multiplan1, family = "binomial")
>> g2=glm(I(ii%in%c(2,3)) ~ multiplan1, family = "binomial")
>> g3=glm(I(ii%in%c(3,4)) ~ multiplan1, family = "binomial")
>>
>> r1=predict(g1,type="response")
>> r2=predict(g2,type="response")
>> r3=predict(g3,type="response")
>>
>> # calculate predictions (based on Chapter 8.3 in Dobson 2002, Introduction to GLMs)
>> ee0=1/(1+r1+r2+r3)
>> ee1=r1/(1+r1)
>> ee2=r2/(1+r1+r2)
>> ee3=r3/(1+r1+r2+r3)
>>
>> # compare predictions between GLM and multinom fits:
>> apply(cbind(ee0,ee1,ee2,ee3),2,mean)
>> apply(predict(m2,type="probs"),2,mean)
>>
>>
>> #################
>> [using R 3.1.1 on Windows 7 32-bit]
>>
>>
>>
>>
>>
>> -- 
>> PD Dr. Christoph Scherber
>> Senior Lecturer
>> DNPW, Agroecology
>> University of Goettingen
>> Grisebachstrasse 6
>> 37077 Goettingen
>> Germany
>> telephone +49 551 39 8807
>> facsimile +49 551 39 8806
>> www.gwdg.de/~cscherb1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	
>


From ligges at statistik.tu-dortmund.de  Wed Jul 23 22:06:30 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 23 Jul 2014 22:06:30 +0200
Subject: [R] corresponding replicated el of one matrix in another matrix
 or vector
In-Reply-To: <1406142975.84321.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1406142975.84321.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <53D015C6.8010104@statistik.tu-dortmund.de>



On 23.07.2014 21:16, carol white wrote:
> Hi,
> I have a matrix of unique elements (strings) like v1 and a vector which contains replicated values of the 2nd column of the first matrix.
>
> v1 = cbind(c("1","2","3"),c("a","b","c"))
>
> v2 = c(rep("a",5), rep("c",10), rep("b",3))
>
> How can I add a column to v2 that contains the values of the first column of the first matrix v1 where the 2nd column of v1 matches the values of v2? Do I need to grep by looping over the nrow of v1 which is very time consuming or is there a better solution?
>
> the results should be the same as
>
>
> v3=rbind( c(rep("a",5), rep("c",10), rep("b",3)), c(rep("1",5), rep("3",10), rep("2",3)))


I'd try

t(merge(data.frame(V2=v2), as.data.frame(v1)))


Best,
Uwe Ligges


> ---------------------------------------------------------------
> v1
>       [,1] [,2] [,3]
> [1,] "1"  "2"  "3"
> [2,] "a"  "b"  "c"
>> v2
>   [1] "a" "a" "a" "a" "a" "c" "c" "c" "c" "c" "c" "c" "c" "c" "c" "b" "b" "b"
>> v3
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
> [1,] "a"  "a"  "a"  "a"  "a"  "c"  "c"  "c"  "c"  "c"   "c"   "c"   "c"   "c"
> [2,] "1"  "1"  "1"  "1"  "1"  "3"  "3"  "3"  "3"  "3"   "3"   "3"   "3"   "3"
>       [,15] [,16] [,17] [,18]
> [1,] "c"   "b"   "b"   "b"
> [2,] "3"   "2"   "2"   "2"
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wht_crl at yahoo.com  Wed Jul 23 22:15:01 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 23 Jul 2014 13:15:01 -0700
Subject: [R] corresponding replicated el of one matrix in another matrix
	or vector
In-Reply-To: <53D015C6.8010104@statistik.tu-dortmund.de>
References: <1406142975.84321.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<53D015C6.8010104@statistik.tu-dortmund.de>
Message-ID: <1406146501.93761.YahooMailNeo@web121505.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/b52fb769/attachment.pl>

From ligges at statistik.tu-dortmund.de  Wed Jul 23 22:24:25 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 23 Jul 2014 22:24:25 +0200
Subject: [R] corresponding replicated el of one matrix in another matrix
 or vector
In-Reply-To: <1406146501.93761.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1406142975.84321.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<53D015C6.8010104@statistik.tu-dortmund.de>
	<1406146501.93761.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <53D019F9.8040700@statistik.tu-dortmund.de>



On 23.07.2014 22:15, carol white wrote:
> How to keep the same order of elements as v2 for the new matrix?


Oh, come on, read the help files for the functions I provided!

t(merge(data.frame(V2=v2), as.data.frame(v1), sort = FALSE))

Best,
Uwe Ligges



>> v3
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
> [,13] [,14]
> [1,] "a"  "a"  "a"  "a" "a"  "c"  "c"  "c"  "c"  "c"   "c"   "c"   "c"
> "c"
> [2,] "1"  "1"  "1"  "1"  "1"  "3"  "3"  "3"  "3"  "3"   "3"   "3"
> "3"   "3"
>       [,15] [,16] [,17] [,18]
> [1,] "c"   "b"   "b"   "b"
> [2,] "3"   "2"   "2"   "2"
>
> instead of
>
> t(merge(data.frame(V2=v2), as.data.frame(v1)))
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
> [,14]
> V2 "a"  "a"  "a"  "a"  "a"  "b"  "b"  "b"  "c"  "c"   "c" "c"   "c"   "c"
> V1 "1"  "1"  "1"  "1"  "1"  "2"  "2"  "2"  "3"  "3"   "3"   "3"   "3"   "3"
>     [,15] [,16] [,17] [,18]
> V2 "c"   "c"   "c"   "c"
> V1 "3"   "3"   "3"   "3"
>
>
>
> On Wednesday, July 23, 2014 10:06 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>
>
>
>
> On 23.07.2014 21:16, carol white wrote:
>  > Hi,
>  > I have a matrix of unique elements (strings) like v1 and a vector
> which contains replicated values of the 2nd column of the first matrix.
>  >
>  > v1 = cbind(c("1","2","3"),c("a","b","c"))
>  >
>  > v2 = c(rep("a",5), rep("c",10), rep("b",3))
>  >
>  > How can I add a column to v2 that contains the values of the first
> column of the first matrix v1 where the 2nd column of v1 matches the
> values of v2? Do I need to grep by looping over the nrow of v1 which is
> very time consuming or is there a better solution?
>  >
>  > the results should be the same as
>  >
>  >
>  > v3=rbind( c(rep("a",5), rep("c",10), rep("b",3)), c(rep("1",5),
> rep("3",10), rep("2",3)))
>
>
> I'd try
>
> t(merge(data.frame(V2=v2), as.data.frame(v1)))
>
>
> Best,
> Uwe Ligges
>
>
>
>  > ---------------------------------------------------------------
>  > v1
>  >      [,1] [,2] [,3]
>  > [1,] "1"  "2"  "3"
>  > [2,] "a"  "b"  "c"
>  >> v2
>  >  [1] "a" "a" "a" "a" "a" "c" "c" "c" "c" "c" "c" "c" "c" "c" "c" "b"
> "b" "b"
>  >> v3
>  >      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
> [,13] [,14]
>  > [1,] "a"  "a"  "a"  "a"  "a"  "c"  "c"  "c"  "c"  "c"  "c"  "c"  "c"  "c"
>  > [2,] "1"  "1"  "1"  "1"  "1" "3"  "3"  "3"  "3"  "3"  "3"  "3"  "3"  "3"
>  >      [,15] [,16] [,17] [,18]
>  > [1,] "c"  "b"  "b"  "b"
>  > [2,] "3"  "2"  "2"  "2"
>
>  >     [[alternative HTML version deleted]]
>  >
>  >
>  >
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>
>  >
>
>


From jfox at mcmaster.ca  Wed Jul 23 22:51:36 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Jul 2014 16:51:36 -0400
Subject: [R] Expressing a multinomial GLM as a series of binomial GLMs
In-Reply-To: <53D012E9.9030106@gwdg.de>
References: <53CE7975.9010408@gwdg.de> <web-519644847@cgpsrv2.cis.mcmaster.ca>
	<53D012E9.9030106@gwdg.de>
Message-ID: <web-519811316@cgpsrv2.cis.mcmaster.ca>

Dear Christoph,

I don't see how what you suggest can work in a mixed-effects model. 

In the case you originally raised, of independent observations, you should be able to recover the coefficients for the multinomial logit model by fitting the logits that I suggested in my earlier email, but notice that these are each for a subset of the observations. As well, even in this case, because the binary logit models are not independent, you can't get the log-likelihood for the multinomial logit model by adding the log-likelihoods for the binary logit models. 

Moreover, in the mixed-effects case, you can't AFAICS subset the observations in this manner.

Best,
 John

On Wed, 23 Jul 2014 21:54:17 +0200
 Christoph Scherber <cscherb1 at gwdg.de> wrote:
> Dear John and R-helpers,
> 
> Thanks for your replies that were both very helpful.
> 
> The reason I was asking is that I?m searching for an easier way to incorporate *random effects* in a multinomial model.
> 
> I was hoping that *combinations of binomial glmmPQL or lmer calls* might be able to do the job - as MCMCglmm would require me to become Bayesian...
> 
> Do you think that combinations of binomial GLMs or glmmPQLs/lmer models would make sense? (example code again below, still without random effects)
> 
> The responses I deal with usually have >50 categories.
> 
> Thanks again and best wishes,
> Christoph
> 
> #Example code again (thanks Charles Berry for pointing me at how to use sapply in this context):
> #set up data: (don?t care what they are, just for playing)
> set.seed(0)
> cats=c("oligolectic","polylectic","specialist","generalist")
> explan1=c("natural","managed")
> 
> multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
> multiplan1=factor(rep(explan1,50))
> 
> ##
> library(nnet)
> m2=multinom(multicats~multiplan1)
> 
> ggen.preds <-
>      sapply( levels(multicats),
>              function(x) predict(glm(I(multicats==x)~multiplan1,
>                           family=binomial),type="response"))
> 
> max(abs(ggen.preds-predict(m2,type="probs")))
> 
> 
> 
> 
> 
> Am 22.07.2014 22:20, schrieb John Fox:
> > Dear Christoph,
> >
> > If I understand correctly what you've done, the two approaches are not equivalent and should not in general produce the same fitted probabilities.
> >
> > Letting {a, b} represent logit(a vs. b) = log(Pr(a)/Pr(b)) and {ab, cd} represent logit(a or b vs. c or d), and numbering the response levels 1, 2, 3, 4, then the multinomial logit model fits the logits {2, 1}, {3, 1}, {4, 1}, while your binary logit models are for the logits {12, 34}, {23, 14}, {34, 12}. Note that the first and third are complementary, but even if you had used three distinct logits of this kind, the combined models (which BTW wouldn't be independent) would not be equivalent to the multinomial logit model.
> >
> > I hope that this helps (and that I've not misconstrued what you did).
> >
> > Best,
> >   John
> >
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> > 	
> > On Tue, 22 Jul 2014 16:47:17 +0200
> >   "Scherber, Christoph" <cscherb1 at gwdg.de> wrote:
> >> Dear all,
> >>
> >> I am trying to express a multinomial GLM (using nnet) as a series of GLM models.
> >>
> >> However, when I compare the multinom() predictions to those from GLM, I see differences that I can?t
> >> explain. Can anyone help me out here?
> >>
> >> Here comes a reproducible example:
> >>
> >> ##
> >> # set up data: (don?t care what they are, just for playing)
> >> set.seed(0)
> >> cats=c("oligolectic","polylectic","specialist","generalist")
> >> explan1=c("natural","managed")
> >> explan2=c("meadow","meadow","pasture","pasture")
> >> multicats=factor(sample(cats,replace=T,100,prob=c(0.5,0.2,0.1,0.5)))
> >> multiplan1=factor(rep(explan1,50))
> >> multiplan2=factor(rep(explan2,25))
> >>
> >> ########################
> >> library(nnet)
> >> m2=multinom(multicats~multiplan1)
> >>
> >> # predictions from multinomial model
> >> predict(m2,type="probs")
> >>
> >> ########################
> >> # now set up contrasts for response variable "multicats" (which has 4 levels):
> >>
> >> ii=as.numeric(multicats)
> >>
> >> g1=glm(I(ii%in%c(1,2)) ~ multiplan1, family = "binomial")
> >> g2=glm(I(ii%in%c(2,3)) ~ multiplan1, family = "binomial")
> >> g3=glm(I(ii%in%c(3,4)) ~ multiplan1, family = "binomial")
> >>
> >> r1=predict(g1,type="response")
> >> r2=predict(g2,type="response")
> >> r3=predict(g3,type="response")
> >>
> >> # calculate predictions (based on Chapter 8.3 in Dobson 2002, Introduction to GLMs)
> >> ee0=1/(1+r1+r2+r3)
> >> ee1=r1/(1+r1)
> >> ee2=r2/(1+r1+r2)
> >> ee3=r3/(1+r1+r2+r3)
> >>
> >> # compare predictions between GLM and multinom fits:
> >> apply(cbind(ee0,ee1,ee2,ee3),2,mean)
> >> apply(predict(m2,type="probs"),2,mean)
> >>
> >>
> >> #################
> >> [using R 3.1.1 on Windows 7 32-bit]
> >>
> >>
> >>
> >>
> >>
> >> -- 
> >> PD Dr. Christoph Scherber
> >> Senior Lecturer
> >> DNPW, Agroecology
> >> University of Goettingen
> >> Grisebachstrasse 6
> >> 37077 Goettingen
> >> Germany
> >> telephone +49 551 39 8807
> >> facsimile +49 551 39 8806
> >> www.gwdg.de/~cscherb1
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > 	
> > 	
> 

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From jhwhite at outlook.com  Wed Jul 23 19:56:21 2014
From: jhwhite at outlook.com (James White)
Date: Wed, 23 Jul 2014 13:56:21 -0400
Subject: [R] Importing random subsets of a data file
In-Reply-To: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
References: <CABPyHrYbrYTVMeJd8Y3Hsayhw_0mVnE9kHNBVdS1B+s-iWrdyw@mail.gmail.com>
Message-ID: <BAY173-W3874652BA949F2DF342B8EB9FE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/be12078e/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 23 22:07:32 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Jul 2014 13:07:32 -0700
Subject: [R] filter one entry, in dependence of date
Message-ID: <1406146052.30212.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
If `dat` is the dataset:
dat[!(dat$ID==2 & as.numeric(gsub("-.*","",dat$Month))<5),]
? ID?? Month Value
1? 1 03-2014???? 1
2? 1 04-2014??? 10
3? 1 05-2014??? 50
6? 2 05-2014???? 4
7? 2 06-2014???? 2

A.K.



hello together, i have a short question, maybe you can help me.

I have a data.frame like this one
???? ID??? Month?????? Value
1??? 1???? 03-2014??????? 1
2??? 1???? 04-2014??????? 10
3??? 1???? 05-2014??????? 50
4??? 2???? 03-2014???????? 8
5??? 2???? 04-2014???????? 7
6??? 2???? 05-2014???????? 4
7??? 2???? 06-2014???????? 2

I now want to create another data.frame without the lines from ID==2 which are earlier than 05-2014

The solution look like this one:

???? ID??? Month?????? Value
1??? 1???? 03-2014??????? 1
2??? 1???? 04-2014??????? 10
3??? 1???? 05-2014??????? 50
4??? 2???? 05-2014???????? 4
5??? 2???? 06-2014???????? 2

maybe you can help me.

Best regards. Mat 



From smartpink111 at yahoo.com  Wed Jul 23 21:59:45 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Jul 2014 12:59:45 -0700
Subject: [R] corresponding replicated el of one matrix in another matrix
	or vector
Message-ID: <1406145585.14576.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Try:
rbind(v2,unname(setNames(v1[,1],v1[,2])[v2]))
?? [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
v2 "a"? "a"? "a"? "a"? "a"? "c"? "c"? "c"? "c"? "c"?? "c"?? "c"?? "c"?? "c"? 
?? "1"? "1"? "1"? "1"? "1"? "3"? "3"? "3"? "3"? "3"?? "3"?? "3"?? "3"?? "3"? 
?? [,15] [,16] [,17] [,18]
v2 "c"?? "b"?? "b"?? "b"? 
?? "3"?? "2"?? "2"?? "2"? 
A.K.



Hi,
I have a matrix of unique elements (strings) like v1 and a vector which contains replicated values of the 2nd column of the first matrix.

v1 = cbind(c("1","2","3"),c("a","b","c"))

v2 = c(rep("a",5), rep("c",10), rep("b",3))

How can I add a column to v2 that contains the values of the first column of the first matrix v1 where the 2nd column of v1 matches the values of v2? Do I need to grep by looping over the nrow of v1 which is very time consuming or is there a better solution?

the results should be the same as


v3=rbind( c(rep("a",5), rep("c",10), rep("b",3)), c(rep("1",5), rep("3",10), rep("2",3)))

---------------------------------------------------------------
v1
???? [,1] [,2] [,3]
[1,] "1"? "2"? "3"
[2,] "a"? "b"? "c"
> v2
?[1] "a" "a" "a" "a" "a" "c" "c" "c" "c" "c" "c" "c" "c" "c" "c" "b" "b" "b"
> v3
???? [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
[1,] "a"? "a"? "a"? "a"? "a"? "c"? "c"? "c"? "c"? "c"?? "c"?? "c"?? "c"?? "c" 
[2,] "1"? "1"? "1"? "1"? "1"? "3"? "3"? "3"? "3"? "3"?? "3"?? "3"?? "3"?? "3" 
???? [,15] [,16] [,17] [,18]
[1,] "c"?? "b"?? "b"?? "b" 
[2,] "3"?? "2"?? "2"?? "2"? 



From aurelien.philippot at gmail.com  Thu Jul 24 01:38:46 2014
From: aurelien.philippot at gmail.com (=?UTF-8?Q?Aur=C3=A9lien_Philippot?=)
Date: Wed, 23 Jul 2014 16:38:46 -0700
Subject: [R] Fast function for each row of a data.table
Message-ID: <CAOwh97sz62pdH8PBnkuTgwik60+SHLy24yULWgZ0_qX8GrCH5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/07faf219/attachment.pl>

From leonardo.gama at usp.br  Thu Jul 24 03:25:20 2014
From: leonardo.gama at usp.br (Leonardo Gama)
Date: Wed, 23 Jul 2014 22:25:20 -0300
Subject: [R] Cairo package error: "unable to load..."
Message-ID: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140723/1d737cdb/attachment.pl>

From desolator88 at 163.com  Thu Jul 24 08:40:09 2014
From: desolator88 at 163.com (super)
Date: Thu, 24 Jul 2014 14:40:09 +0800 (CST)
Subject: [R] A question about call()
Message-ID: <6c659a6c.121b6.14767192eba.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/d23500da/attachment.pl>

From ashutosh.nanda at gmail.com  Thu Jul 24 06:11:23 2014
From: ashutosh.nanda at gmail.com (Ashutosh Nanda)
Date: Thu, 24 Jul 2014 00:11:23 -0400
Subject: [R] Problems with Installing RMySQL Package (Windows,
 R: 3.1.0 (64 bit), using RStudio)
Message-ID: <CAMGpciiv07ZVoA=D9jJmVQANYPbtWDvAp-JM3nmnBFnjphb0tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/47911f4a/attachment.pl>

From desolator88 at 163.com  Thu Jul 24 08:41:54 2014
From: desolator88 at 163.com (super)
Date: Thu, 24 Jul 2014 14:41:54 +0800 (CST)
Subject: [R]   A question about call()
Message-ID: <1c89012f.12220.147671ac9d4.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/8fb8468b/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jul 24 08:52:10 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Jul 2014 07:52:10 +0100
Subject: [R] Cairo package error: "unable to load..."
In-Reply-To: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>
References: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>
Message-ID: <53D0AD1A.8090005@stats.ox.ac.uk>

I presume this about the CRAN binary packages for R and Cairo (from 
CRAN, not BioC), in which case you should have asked on R-sig-mac.

But the likely answer is that you forgot to install X11 via XQuartz. 
See the 'R Installation and Administration Manual', and if you need more 
help, use R-sig-mac.

On 24/07/2014 02:25, Leonardo Gama wrote:
> Hi!
>
> I've just installed R on my OS X 10.9 and was trying to make
> arrayQualityMetrics package work. I've installed it via the biocLite
> Bioconductor script, and everything was apparently fine. But when I tried
> to load the package, I've got an issue with the Cairo package...
>
> Then I tried to load only Cairo:
>
>> library("Cairo")
>
> Error : .onLoad failed in loadNamespace() for 'Cairo', details:
>    call: dyn.load(file, DLLpath = DLLpath, ...)
>    error: unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so':
>
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so,
> 6): Library not loaded: /opt/X11/lib/libXrender.1.dylib
>    Referenced from:
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
>    Reason: image not found
> Error: package or namespace load failed for 'Cairo'
>
>> traceback()
>
> 2: stop(gettextf("package or namespace load failed for %s",
> sQuote(package)),
>         call. = FALSE, domain = NA)
> 1: library(Cairo)
>
>
> Verified it version and dependencies:
>
>> packageDescription("Cairo")
>
> Package: Cairo
> Version: 1.5-6
> Title: [...]
> Author: Simon Urbanek <Simon.Urbanek at r-project.org>, Jeffrey Horner <
> jeff.horner at vanderbilt.edu>
> Maintainer: Simon Urbanek <Simon.Urbanek at r-project.org>
> Depends: R (>= 2.4.0)
> Suggests: png
> Enhances: FastRWeb
> Description: [...]
> SystemRequirements: cairo (>= 1.2 http://www.cairographics.org/)
> URL: http://www.rforge.net/Cairo/
> Packaged: 2014-06-26 14:50:25 UTC; svnuser
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2014-06-26 17:15:22
> Built: R 3.1.0; x86_64-apple-darwin13.1.0; 2014-06-27 05:04:27 UTC;
>          unix
> -- File:
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/Meta/package.rds
>
>
> Tried to update it and got another error/warning:
>
>> upgrade.packages("Cairo")
>
> Warning message:
> In doTryCatch(return(expr), name, parentenv, handler) :
>    unable to load shared object
> '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':
>    dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 6):
> Library not loaded: /opt/X11/lib/libSM.6.dylib
>    Referenced from:
> /Library/Frameworks/R.framework/Resources/modules//R_X11.so
>    Reason: image not found
>
>> traceback()
>
> No traceback available
>
>
> And finally:
>
>> sessionInfo()
>
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] C/UTF-8/C/C/C/C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
>> pack
> packBits               packageEvent           packageSlot
>   packageStatus
> package.skeleton       packageHasNamespace    packageSlot<-
>   packageVersion
> packageDescription     packageName            packageStartupMessage
>   package_version
>
>
> I've also verified the cairo.os file cited in the first error message, and
> it was there:
>
> $ file
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
>
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so:
> Mach-O 64-bit dynamically linked shared library x86_64
>
> $ ls -lh
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
>
> -rwxrwxr-x  1 root  admin   3.2M Jun 27 02:04
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
>
>
> I have no idea of what's going wrong. Somebody could help me?
> Thank you, and sorry for the bad English.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jdnewmil at dcn.davis.CA.us  Thu Jul 24 09:07:20 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 24 Jul 2014 00:07:20 -0700
Subject: [R] A question about call()
In-Reply-To: <6c659a6c.121b6.14767192eba.Coremail.desolator88@163.com>
References: <6c659a6c.121b6.14767192eba.Coremail.desolator88@163.com>
Message-ID: <640d0a00-84a4-47f5-b3e5-3526924bd3a8@email.android.com>

Please read the Posting Guide. There is a no HTML policy and a no homework policy.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 23, 2014 11:40:09 PM PDT, super <desolator88 at 163.com> wrote:
>The question is as below:
>Exercises
>1.The following two calls look the same, but are actually different:
>  (a <- call("mean", 1:10))
>#> mean(1:10)
>(b <- call("mean", quote(1:10)))
>#> mean(1:10)
>identical(a, b)
>#> [1] FALSE
>What??s the difference? Which one should you prefer?
>So, how i can figure out this question?  
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mcarrete at upo.es  Thu Jul 24 09:28:51 2014
From: mcarrete at upo.es (Martina Carrete)
Date: Thu, 24 Jul 2014 09:28:51 +0200
Subject: [R] MCMCglmm question
In-Reply-To: <4b9ea3336c8dad89.53ba85df@upo.es>
References: <4b9ea3336c8dad89.53ba85df@upo.es>
Message-ID: <61d0e111712e1a13.53d0d1d3@upo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/59b643d1/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul 24 12:06:33 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 24 Jul 2014 10:06:33 +0000
Subject: [R] Fast function for each row of a data.table
In-Reply-To: <CAOwh97sz62pdH8PBnkuTgwik60+SHLy24yULWgZ0_qX8GrCH5g@mail.gmail.com>
References: <CAOwh97sz62pdH8PBnkuTgwik60+SHLy24yULWgZ0_qX8GrCH5g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDC702@SRVEXCHMBX.precheza.cz>

Hi

If your problem is not bigger than example (regarding columns following maybe can help (I shortened target.column to tc)

dt$target.value <- dt[,3]*(dt$tc==3)+dt[,2]*(dt$tc==2)+dt[,1]*(dt$tc==1)

and changed dt to data frame as I do not use data table. But it shall work with data table too.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Aur?lien Philippot
> Sent: Thursday, July 24, 2014 1:39 AM
> To: R-help at r-project.org
> Subject: [R] Fast function for each row of a data.table
>
> Dear R experts,
>
> I have the following data.table:
>
> dt<- data.table(A=rep(1:5), B=c(20:24), C=rep(30:34),
> target.name=c("A","B", "C","B","A"), target.column=c(1,2,3,2,1),
> target.value=rep(NA,5))
>
> Columns A, B and C are the variables of interest.
> For each row, I want to get the value of the variable given in the
> column target.column. For example, in the second row, I want to get the
> value B.
> (the column target.column just gives the corresponding column index).
>
> I plan to store the results in the column target value.
>
> #### Solution 1: very slow
>
> for (i in (1:5)){
>
> dt$target.value[i]<- dt[i, c(dt[, target.column[i]]), with=FALSE]
>
> }
>
> dt
>
>
> #### Solution 2: faster but still slow
>
> df<- data.frame(dt)
>
> aaa<- lapply(1:5, function(i) df[i,
> which(colnames(df)==df$target.name[i])])
>
> aaa<- do.call("rbind",aaa)
>
> df$target.value<- aaa
> Not convenient on a big data frame because of rbind
>
>
> #### Other tries:
>
> dt[, c(dt$target.name), with=FALSE]
>
> The solution appears on the diagonal term for some reason...
>
>
> The original data.table is big (18 million rows), so time efficiency is
> a primary concern.
> Any advice is very welcome. Thanks for your help.
>
> Aurelien
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From murdoch.duncan at gmail.com  Thu Jul 24 13:15:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Jul 2014 07:15:55 -0400
Subject: [R] A question about call()
In-Reply-To: <1c89012f.12220.147671ac9d4.Coremail.desolator88@163.com>
References: <1c89012f.12220.147671ac9d4.Coremail.desolator88@163.com>
Message-ID: <53D0EAEB.4080409@gmail.com>

On 24/07/2014, 2:41 AM, super wrote:
> The question is as below:
> Exercises
> 1.The following two calls look the same, but are actually different:
>   (a <- call("mean", 1:10))
> #> mean(1:10)

This one creates a call where the first argument is a vector containing
10 elements.

> (b <- call("mean", quote(1:10)))
> #> mean(1:10)

This one creates a call where the first argument is a call to the ":"
function to produce a sequence.

> identical(a, b)
> #> [1] FALSE
> What??s the difference? Which one should you prefer?
> So, how i can figure out this question?  

In this case they deparse the same, but in other cases they wouldn't, e.g.

call("mean", rnorm(10))

appears quite different from

call("mean", quote(rnorm(10)))

The difference is when the evaluation takes place.  Which should you
prefer?  That's up to you.

Duncan Murdoch


From pavneet.arora at uk.rsagroup.com  Thu Jul 24 15:35:54 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Thu, 24 Jul 2014 14:35:54 +0100
Subject: [R] Creating Functions in R
Message-ID: <OF7BDB5794.7B332ADC-ON80257D1F.004AA1B0-80257D1F.004B549D@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/1b9c4b38/attachment.pl>

From simon.urbanek at r-project.org  Thu Jul 24 15:43:28 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Jul 2014 09:43:28 -0400
Subject: [R] Cairo package error: "unable to load..."
In-Reply-To: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>
References: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>
Message-ID: <7F9977BC-6D56-4708-8E60-60A51E14ACF8@r-project.org>

Leonardo,

you don't have X11 installed and it no longer ships with OS X 10.9 - you need to get it from

http://xquartz.macosforge.org

Cheers,
Simon


On Jul 23, 2014, at 9:25 PM, Leonardo Gama <leonardo.gama at usp.br> wrote:

> Hi!
> 
> I've just installed R on my OS X 10.9 and was trying to make arrayQualityMetrics package work. I've installed it via the biocLite Bioconductor script, and everything was apparently fine. But when I tried to load the package, I've got an issue with the Cairo package...
> 
> Then I tried to load only Cairo:
> 
> > library("Cairo")
> 
> Error : .onLoad failed in loadNamespace() for 'Cairo', details:
>   call: dyn.load(file, DLLpath = DLLpath, ...)
>   error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so':
>   dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so, 6): Library not loaded: /opt/X11/lib/libXrender.1.dylib
>   Referenced from: /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
>   Reason: image not found
> Error: package or namespace load failed for ?Cairo?
> 
> > traceback()
> 
> 2: stop(gettextf("package or namespace load failed for %s", sQuote(package)), 
>        call. = FALSE, domain = NA)
> 1: library(Cairo)
> 
> 
> Verified it version and dependencies:
> 
> > packageDescription("Cairo")
> 
> Package: Cairo
> Version: 1.5-6
> Title: [...]
> Author: Simon Urbanek <Simon.Urbanek at r-project.org>, Jeffrey Horner <jeff.horner at vanderbilt.edu>
> Maintainer: Simon Urbanek <Simon.Urbanek at r-project.org>
> Depends: R (>= 2.4.0)
> Suggests: png
> Enhances: FastRWeb
> Description: [...]
> SystemRequirements: cairo (>= 1.2 http://www.cairographics.org/)
> URL: http://www.rforge.net/Cairo/
> Packaged: 2014-06-26 14:50:25 UTC; svnuser
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2014-06-26 17:15:22
> Built: R 3.1.0; x86_64-apple-darwin13.1.0; 2014-06-27 05:04:27 UTC;
>         unix
> -- File: /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/Meta/package.rds
> 
> 
> Tried to update it and got another error/warning:
> 
> > upgrade.packages("Cairo")
> 
> Warning message:
> In doTryCatch(return(expr), name, parentenv, handler) :
>   unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':
>   dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 6): Library not loaded: /opt/X11/lib/libSM.6.dylib
>   Referenced from: /Library/Frameworks/R.framework/Resources/modules//R_X11.so
>   Reason: image not found
> 
> > traceback()
> 
> No traceback available
> 
>  
> And finally:
> 
> > sessionInfo()
> 
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
> 
> locale:
> [1] C/UTF-8/C/C/C/C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
> > pack
> packBits               packageEvent           packageSlot            packageStatus
> package.skeleton       packageHasNamespace    packageSlot<-          packageVersion
> packageDescription     packageName            packageStartupMessage  package_version
> 
> 
> I've also verified the cairo.os file cited in the first error message, and it was there:
> 
> $ file /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> 
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so: Mach-O 64-bit dynamically linked shared library x86_64
> 
> $ ls -lh /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> 
> -rwxrwxr-x  1 root  admin   3.2M Jun 27 02:04 /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> 
> 
> I have no idea of what's going wrong. Somebody could help me?
> Thank you, and sorry for the bad English.
> 
> -- 
> Leonardo Gama, acad?mico
> Ci?ncias Moleculares / Medicina
> Universidade de S?o Paulo, Brasil


From sarah.goslee at gmail.com  Thu Jul 24 16:12:21 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 24 Jul 2014 10:12:21 -0400
Subject: [R] Creating Functions in R
In-Reply-To: <OF7BDB5794.7B332ADC-ON80257D1F.004AA1B0-80257D1F.004B549D@uk.royalsun.com>
References: <OF7BDB5794.7B332ADC-ON80257D1F.004AA1B0-80257D1F.004B549D@uk.royalsun.com>
Message-ID: <CAM_vjun8bN3y2mAmObVz_SSBTjP+_q6-Uu+o3ZeELExCyfDP2Q@mail.gmail.com>

Hi,


On Thu, Jul 24, 2014 at 9:35 AM, Pavneet Arora
<pavneet.arora at uk.rsagroup.com> wrote:
> Hello Guys
> I am new at writing Functions in R, and as a result am struggling with it.
> I am trying to use Google & other resources, but it's hard to find
> solutions when you don't know what to look for.

How about the introduction to R that comes with your installation?
It's got a section on writing
functions, and some other useful information that you seem to not have
learned yet.

> I have the following small dataset
>> dput(sub)
> structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
> 11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA,
> -30L), class = "data.frame")
>
> I want to take each of the value and subtract from a target {in this case
> its 10}.

Thank you for providing data with dput()!

There are a bunch of things wrong with your function, starting with
the lack of need for a function.

If I understand your description correctly, what you actually want is:

sub$deviation <- sub$value - 10

But for educational purposes, here goes:

> This is what I have written in my function so far:
> vmask <- function(data,target){
> for(k in 1:length(data))

this actually loops through the COLUMNS of data, so first you're subtracting
target from week, then from value

> deviation <- data[k]- target

but coincidentally it gives you what you thought you were getting,
because you're overwriting deviation with each value of k, so the week
-target column is never saved. It's a really good idea to explicitly
mark the loop with { } too, to reduce confusion.

> dev <- return(data.frame(cbind(data,deviation)))

Hm. I don't know what you're trying to do with return() here, and
using both data.frame() and cbind() is superfluous. It isn't always
necessary, but I find it useful to explicitly name the columns of your
data frame when you create it, which gives

dev <- data.frame(data, deviation = deviation))

> return(dev)

The last item of a function is what's returned, so all you really need here is

dev

> }
> vmask(sub,10)
> View(dev)

dev only exists within the scope of the function. But you didn't
assign the return value of the function to anything. If you assign it
to an object named dev, then dev will exist in the global environment:

dev <- vmask(sub, 10)


> But when I run this I get the results as expected. But I expected the new
> coloumn to be called "deviation", whereas R just calls in "value.1". How
> can I fix this?
> Also I was hoping to see this new dataset with columns "week", "value",
> and now "deviation" when I use "View(dev) - but it comes up with error
> 'dev not found'. How can i fix this? Also is there anyway instead of me
> making a new dataset called "dev" with the 3 columns, I can just re-use my
> original dataset "sub" and give me all the 3 new columns?
>
> The next step I want to do is to perform a cumulative sum. So looking at
> the results, I want a new coloumn in existing dataset (or new dataset),
> which will now have 4 columns. The 4th column I want to be called "CuSum".
> So the first row of Cusum will be "-0.55", the second = "-0.55+(-2.01)"
> which will give me "-2.56" and so on forth.
>
> How can I do this in R using a function? Please help

You don't need a function. Just add the cumulative sum as a new column.

sub$Cusum <- cumsum(sub$deviation)


Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Thu Jul 24 16:17:09 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 24 Jul 2014 14:17:09 +0000
Subject: [R] Creating Functions in R
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8BBAC@mb02.ads.tamu.edu>

Before you start writing functions, you should learn the basics of R by reading "An Introduction to R" (http://cran.r-project.org/doc/manuals/r-release/R-intro.pdf). Pages 7 and 8 cover what you are asking. There is no need for a for() loop at all and your function is simply overwriting the value of "deviation" so you only get the last value recycled (page 20, "The recycling rule").

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pavneet Arora
Sent: Thursday, July 24, 2014 8:36 AM
To: r-help at r-project.org
Subject: [R] Creating Functions in R

Hello Guys
I am new at writing Functions in R, and as a result am struggling with it. 
I am trying to use Google & other resources, but it's hard to find 
solutions when you don't know what to look for. 

I have the following small dataset
> dput(sub)
structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 
13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 
29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04, 
11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62, 
10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62, 
11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA, 
-30L), class = "data.frame")

I want to take each of the value and subtract from a target {in this case 
its 10}. This is what I have written in my function so far:
vmask <- function(data,target){
for(k in 1:length(data))
deviation <- data[k]- target
dev <- return(data.frame(cbind(data,deviation)))
return(dev)
}
vmask(sub,10)
View(dev)

But when I run this I get the results as expected. But I expected the new 
coloumn to be called "deviation", whereas R just calls in "value.1". How 
can I fix this?
Also I was hoping to see this new dataset with columns "week", "value", 
and now "deviation" when I use "View(dev) - but it comes up with error 
'dev not found'. How can i fix this? Also is there anyway instead of me 
making a new dataset called "dev" with the 3 columns, I can just re-use my 
original dataset "sub" and give me all the 3 new columns?

The next step I want to do is to perform a cumulative sum. So looking at 
the results, I want a new coloumn in existing dataset (or new dataset), 
which will now have 4 columns. The 4th column I want to be called "CuSum". 
So the first row of Cusum will be "-0.55", the second = "-0.55+(-2.01)" 
which will give me "-2.56" and so on forth.

How can I do this in R using a function? Please help



***********************************************************************************************************************************************************************************************************************
MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, Horsham, West Sussex, RH12 1XL. 

Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
************************************************************************************************************************************************************************************************************************

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Jul 24 16:20:13 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 24 Jul 2014 10:20:13 -0400
Subject: [R] Creating Functions in R
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F8BBAC@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA726F8BBAC@mb02.ads.tamu.edu>
Message-ID: <CAAxdm-7xdV6G-pSR4MR1pcFe9aK=0s1VsGFxOzfb50pwfK6BEQ@mail.gmail.com>

Modified your function and also you don't need a function to do this:

sub <- structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA,
-30L), class = "data.frame")

vmask <- function(data,target){
    data$deviation <- data$value - target
    data  # return value
}


newSub <- vmask(sub,10)  # need to assign return value
View(newSub)

# do the same thing without a function
sub$deviation <- sub$value - 10
View(sub)



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Jul 24, 2014 at 10:17 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Before you start writing functions, you should learn the basics of R by reading "An Introduction to R" (http://cran.r-project.org/doc/manuals/r-release/R-intro.pdf). Pages 7 and 8 cover what you are asking. There is no need for a for() loop at all and your function is simply overwriting the value of "deviation" so you only get the last value recycled (page 20, "The recycling rule").
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pavneet Arora
> Sent: Thursday, July 24, 2014 8:36 AM
> To: r-help at r-project.org
> Subject: [R] Creating Functions in R
>
> Hello Guys
> I am new at writing Functions in R, and as a result am struggling with it.
> I am trying to use Google & other resources, but it's hard to find
> solutions when you don't know what to look for.
>
> I have the following small dataset
>> dput(sub)
> structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
> 11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA,
> -30L), class = "data.frame")
>
> I want to take each of the value and subtract from a target {in this case
> its 10}. This is what I have written in my function so far:
> vmask <- function(data,target){
> for(k in 1:length(data))
> deviation <- data[k]- target
> dev <- return(data.frame(cbind(data,deviation)))
> return(dev)
> }
> vmask(sub,10)
> View(dev)
>
> But when I run this I get the results as expected. But I expected the new
> coloumn to be called "deviation", whereas R just calls in "value.1". How
> can I fix this?
> Also I was hoping to see this new dataset with columns "week", "value",
> and now "deviation" when I use "View(dev) - but it comes up with error
> 'dev not found'. How can i fix this? Also is there anyway instead of me
> making a new dataset called "dev" with the 3 columns, I can just re-use my
> original dataset "sub" and give me all the 3 new columns?
>
> The next step I want to do is to perform a cumulative sum. So looking at
> the results, I want a new coloumn in existing dataset (or new dataset),
> which will now have 4 columns. The 4th column I want to be called "CuSum".
> So the first row of Cusum will be "-0.55", the second = "-0.55+(-2.01)"
> which will give me "-2.56" and so on forth.
>
> How can I do this in R using a function? Please help
>
>
>
> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From desolator88 at 163.com  Thu Jul 24 16:55:44 2014
From: desolator88 at 163.com (super)
Date: Thu, 24 Jul 2014 22:55:44 +0800 (CST)
Subject: [R] A question about call()
In-Reply-To: <53D0EAEB.4080409@gmail.com>
References: <1c89012f.12220.147671ac9d4.Coremail.desolator88@163.com>
	<53D0EAEB.4080409@gmail.com>
Message-ID: <b4cfe26.1a70d.14768dee6d6.Coremail.desolator88@163.com>

Thanks a lot, it is much clear to me now,   but i still have a question:<br/>The raw question is from:<br/>Hadley wickham's book advanced r programming, Chapter Meta programming, section expressions, in the part "Creating a call from its components"<br/>He said:<br/>To create a new call from its components, you can use call() or as.call(). The first argument to call() is a string which gives a function name. The other arguments are expressions that represent the arguments of the call.<br/>And He also said in the same section expressions before:<br/>There are four possible components of an expression: constants, names, calls and pairlists.<br/>constants are length one atomic vectors, like "a" or 10. ast() displays them as is<br/>So, i can't figure out are 1:10 and rnorm(10)  both the expressions?  I am confused,  or  1:10 is a expression but it is evaled immediately so the expression actually represent it's value? <br/>I hope you can read the section expressions.
At 2014-07-24 07:15:55, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 24/07/2014, 2:41 AM, super wrote:
>> The question is as below:
>> Exercises
>> 1.The following two calls look the same, but are actually different:
>>   (a <- call("mean", 1:10))
>> #> mean(1:10)
>
>This one creates a call where the first argument is a vector containing
>10 elements.
>
>> (b <- call("mean", quote(1:10)))
>> #> mean(1:10)
>
>This one creates a call where the first argument is a call to the ":"
>function to produce a sequence.
>
>> identical(a, b)
>> #> [1] FALSE
>> What??s the difference? Which one should you prefer?
>> So, how i can figure out this question?  
>
>In this case they deparse the same, but in other cases they wouldn't, e.g.
>
>call("mean", rnorm(10))
>
>appears quite different from
>
>call("mean", quote(rnorm(10)))
>
>The difference is when the evaluation takes place.  Which should you
>prefer?  That's up to you.
>
>Duncan Murdoch
>

From pavneet.arora at uk.rsagroup.com  Thu Jul 24 17:08:00 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Thu, 24 Jul 2014 16:08:00 +0100
Subject: [R] Creating Functions in R
In-Reply-To: <CAM_vjun8bN3y2mAmObVz_SSBTjP+_q6-Uu+o3ZeELExCyfDP2Q@mail.gmail.com>
References: <OF7BDB5794.7B332ADC-ON80257D1F.004AA1B0-80257D1F.004B549D@uk.royalsun.com>
	<CAM_vjun8bN3y2mAmObVz_SSBTjP+_q6-Uu+o3ZeELExCyfDP2Q@mail.gmail.com>
Message-ID: <OF249C7825.2C9897D1-ON80257D1F.0052AAD0-80257D1F.0053C318@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/56e0a28e/attachment.pl>

From Keith.Jewell at campdenbri.co.uk  Thu Jul 24 15:57:45 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 24 Jul 2014 14:57:45 +0100
Subject: [R] Windows R doesn't recognize shortcuts ?
In-Reply-To: <53CFB6E5.7000706@gmail.com>
References: <20140723090816.7569@web006.roc2.bluetie.com>
	<53CFB6E5.7000706@gmail.com>
Message-ID: <lqr3co$7o7$1@ger.gmane.org>

On 23/07/2014 14:21, Duncan Murdoch wrote:
> On 23/07/2014 9:08 AM, ce wrote:
>> Hi All,
>>
>> In Windows 7 , R installation:
>>
>> R version 3.1.1 Patched (2014-07-14 r66149) -- "Sock it to Me"
>> Copyright (C) 2014 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> it doesn't recognize shortcuts in path :
>>
>> >  list.files(path = "cygwin")
>> character(0)
>>
>> cygwin is a shortcut,  in properties window  Target shows :
>> C:\Users\me\cygwin64\home\me
>> Real path works :
>>
>> list.files(path = "C:/Users/me/cygwin64/home/me")
>>    [1] "1010week.sh"            "10week.sh"
>> "a.R"                    "aa.sh"
>>
>
> I don't think R should recognize that.  Windows wouldn't recognize it
> either, if you used "dir cygwin" in a shell, for example.
>
> Duncan Murdoch
>
The "shortcut" which appears as cygwin is actually a file
called cygwin.lnk

readWindowsShellLink {R.utils} reads such files:
 > readWindowsShellLink(con="cygwin.lnk")


From simon.urbanek at r-project.org  Thu Jul 24 18:05:20 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Jul 2014 12:05:20 -0400
Subject: [R] Cairo package error: "unable to load..."
In-Reply-To: <CAP2VF5rgQGN81+kD=burzTn2h2RMZGZUFWW7F=X8hEFQFk7yGg@mail.gmail.com>
References: <CAP2VF5q=o6Ctp_GmGhu9=Jnwentk9XqghD19-y6++cHTWdf=6w@mail.gmail.com>
	<7F9977BC-6D56-4708-8E60-60A51E14ACF8@r-project.org>
	<CAP2VF5rgQGN81+kD=burzTn2h2RMZGZUFWW7F=X8hEFQFk7yGg@mail.gmail.com>
Message-ID: <0FF9E3D0-47E4-4A56-91EB-35855D165B27@r-project.org>


On Jul 24, 2014, at 12:03 PM, Leonardo Gama <leonardo.gama at usp.br> wrote:

> Sorry, Simon. I should have suspected that it was a trivial problem. But there was an X11 app icon in Applications and I assumed it was installed, but was not. This mensgem only appeared when I clicked on such icon:
> 
> <Screen Shot 2014-07-24 at 11.44.31 AM.png>
> 

Yes, as you can see it says

"X11 is *no longer* included with OS X"
[...]
and it asks you if you want to know how to install it - if you continue, it will point you to a page that says that you have to download it from 

http://xquartz.macosforge.org

It doesn't actually do anything - you have to install it yourself - it just tells you how.

Cheers,
Simon




> Thank you again!
> 
> Leonardo
> 
> 
> 2014-07-24 10:43 GMT-03:00 Simon Urbanek <simon.urbanek at r-project.org>:
> Leonardo,
> 
> you don't have X11 installed and it no longer ships with OS X 10.9 - you need to get it from
> 
> http://xquartz.macosforge.org
> 
> Cheers,
> Simon
> 
> 
> On Jul 23, 2014, at 9:25 PM, Leonardo Gama <leonardo.gama at usp.br> wrote:
> 
> > Hi!
> >
> > I've just installed R on my OS X 10.9 and was trying to make arrayQualityMetrics package work. I've installed it via the biocLite Bioconductor script, and everything was apparently fine. But when I tried to load the package, I've got an issue with the Cairo package...
> >
> > Then I tried to load only Cairo:
> >
> > > library("Cairo")
> >
> > Error : .onLoad failed in loadNamespace() for 'Cairo', details:
> >   call: dyn.load(file, DLLpath = DLLpath, ...)
> >   error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so':
> >   dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so, 6): Library not loaded: /opt/X11/lib/libXrender.1.dylib
> >   Referenced from: /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> >   Reason: image not found
> > Error: package or namespace load failed for ?Cairo?
> >
> > > traceback()
> >
> > 2: stop(gettextf("package or namespace load failed for %s", sQuote(package)),
> >        call. = FALSE, domain = NA)
> > 1: library(Cairo)
> >
> >
> > Verified it version and dependencies:
> >
> > > packageDescription("Cairo")
> >
> > Package: Cairo
> > Version: 1.5-6
> > Title: [...]
> > Author: Simon Urbanek <Simon.Urbanek at r-project.org>, Jeffrey Horner <jeff.horner at vanderbilt.edu>
> > Maintainer: Simon Urbanek <Simon.Urbanek at r-project.org>
> > Depends: R (>= 2.4.0)
> > Suggests: png
> > Enhances: FastRWeb
> > Description: [...]
> > SystemRequirements: cairo (>= 1.2 http://www.cairographics.org/)
> > URL: http://www.rforge.net/Cairo/
> > Packaged: 2014-06-26 14:50:25 UTC; svnuser
> > NeedsCompilation: yes
> > Repository: CRAN
> > Date/Publication: 2014-06-26 17:15:22
> > Built: R 3.1.0; x86_64-apple-darwin13.1.0; 2014-06-27 05:04:27 UTC;
> >         unix
> > -- File: /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/Meta/package.rds
> >
> >
> > Tried to update it and got another error/warning:
> >
> > > upgrade.packages("Cairo")
> >
> > Warning message:
> > In doTryCatch(return(expr), name, parentenv, handler) :
> >   unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':
> >   dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 6): Library not loaded: /opt/X11/lib/libSM.6.dylib
> >   Referenced from: /Library/Frameworks/R.framework/Resources/modules//R_X11.so
> >   Reason: image not found
> >
> > > traceback()
> >
> > No traceback available
> >
> >
> > And finally:
> >
> > > sessionInfo()
> >
> > R version 3.1.1 (2014-07-10)
> > Platform: x86_64-apple-darwin13.1.0 (64-bit)
> >
> > locale:
> > [1] C/UTF-8/C/C/C/C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.1.1
> > > pack
> > packBits               packageEvent           packageSlot            packageStatus
> > package.skeleton       packageHasNamespace    packageSlot<-          packageVersion
> > packageDescription     packageName            packageStartupMessage  package_version
> >
> >
> > I've also verified the cairo.os file cited in the first error message, and it was there:
> >
> > $ file /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> >
> > /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so: Mach-O 64-bit dynamically linked shared library x86_64
> >
> > $ ls -lh /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> >
> > -rwxrwxr-x  1 root  admin   3.2M Jun 27 02:04 /Library/Frameworks/R.framework/Versions/3.1/Resources/library/Cairo/libs/Cairo.so
> >
> >
> > I have no idea of what's going wrong. Somebody could help me?
> > Thank you, and sorry for the bad English.
> >
> > --
> > Leonardo Gama, acad?mico
> > Ci?ncias Moleculares / Medicina
> > Universidade de S?o Paulo, Brasil
> 
> 
> 
> 
> -- 
> Leonardo Gama, acad?mico
> Ci?ncias Moleculares / Medicina
> Universidade de S?o Paulo, Brasil


From sarah.goslee at gmail.com  Thu Jul 24 18:25:08 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 24 Jul 2014 12:25:08 -0400
Subject: [R] Creating Functions in R
In-Reply-To: <OF249C7825.2C9897D1-ON80257D1F.0052AAD0-80257D1F.0053C318@uk.royalsun.com>
References: <OF7BDB5794.7B332ADC-ON80257D1F.004AA1B0-80257D1F.004B549D@uk.royalsun.com>
	<CAM_vjun8bN3y2mAmObVz_SSBTjP+_q6-Uu+o3ZeELExCyfDP2Q@mail.gmail.com>
	<OF249C7825.2C9897D1-ON80257D1F.0052AAD0-80257D1F.0053C318@uk.royalsun.com>
Message-ID: <CAM_vju=MqqJFMMz9HVRoAFsT4Trn8JCpAtJjT_PEsR935+3pNQ@mail.gmail.com>

Hi,

On Thu, Jul 24, 2014 at 11:08 AM, Pavneet Arora
<pavneet.arora at uk.rsagroup.com> wrote:
> Hello Sarah
>
> Thank you the detailed explanation, it helped me understand a lot. However,
> I don't understand what you meant by - " It's a really good idea to
> explicitly mark the loop with { } too, to reduce confusion."

Instead of
>   for(k in 1:length(sub))
>   deviation <- sub[k]- target

it's clearer to use

for(k in 1:length(sub)) {
 deviation <- sub[k]- target
}

so it's explicit what's being looped over.

But as I already explained, along with several other people, you not
only don't need a loop, but your loop is overwriting each iteration
and not at all doing what you think it is.

> Also as per your suggestion I tried to say sub$value, but i get the same
> value "-2.01" for each row. Not sure what I did wrong there?

Where did you do that?

>
> This is my code now:
> vmask <- function(sub,target){
>   for(k in 1:length(sub))
>   deviation <- sub[k]- target
>   dev <- data.frame(sub,deviation=deviation)
>   dev
>
>    cusums <- cumsum(dev$deviation)
>    cusums <- data.frame(dev,cusums=cusums)
>    cusums
>
> }
> vmask(sub,10)
> View(dev)
>
> cusums <- vmask(sub,10)
> View(cusums)
>
>
> Also when I try the cusums command, I get the following error:
> Error in data.frame(dev, cusums = cusums) : arguments imply differing number
> of rows: 30, 0
> What does this mean? And how can i fix it?

It means your function is still a mess and you haven't read the
Introduction to R guide.
Your question isn't clear: "when you try it" where? On its own? When
running the function?
There is no "cusums command" either.

If you're determined to use a function, needed or not, lose the loop.

sub <- structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA,
-30L), class = "data.frame")


vmask <- function(sub,target){
   deviation <- sub$value - target
   cusums <- cumsum(deviation)
    data.frame(sub, deviation=deviation,cusums=cusums)
}

vmask(sub, 10)

Note that this makes substantial assumptions about the structure of
the sub argument, namely that it has a column named value.

Sarah




> PS: Thank you so much for helping me with this.
>
>
>
>
> From:        Sarah Goslee <sarah.goslee at gmail.com>
> To:        Pavneet Arora/UK/RoyalSun at RoyalSun
> Cc:        r-help <r-help at r-project.org>
> Date:        24/07/2014 15:04
> Subject:        Re: [R] Creating Functions in R
> ________________________________
>
>
>
> Hi,
>
>
>
> On Thu, Jul 24, 2014 at 9:35 AM, Pavneet Arora
> <pavneet.arora at uk.rsagroup.com> wrote:
>> Hello Guys
>> I am new at writing Functions in R, and as a result am struggling with it.
>> I am trying to use Google & other resources, but it's hard to find
>> solutions when you don't know what to look for.
>
> How about the introduction to R that comes with your installation?
> It's got a section on writing
> functions, and some other useful information that you seem to not have
> learned yet.
>
>
>> I have the following small dataset
>>> dput(sub)
>> structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
>> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
>> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
>> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
>> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
>> 11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA,
>> -30L), class = "data.frame")
>>
>> I want to take each of the value and subtract from a target {in this case
>> its 10}.
>
> Thank you for providing data with dput()!
>
> There are a bunch of things wrong with your function, starting with
> the lack of need for a function.
>
> If I understand your description correctly, what you actually want is:
>
>
> sub$deviation <- sub$value - 10
>
> But for educational purposes, here goes:
>
>
>> This is what I have written in my function so far:
>> vmask <- function(data,target){
>> for(k in 1:length(data))
>
> this actually loops through the COLUMNS of data, so first you're subtracting
> target from week, then from value
>
>
>> deviation <- data[k]- target
>
> but coincidentally it gives you what you thought you were getting,
> because you're overwriting deviation with each value of k, so the week
> -target column is never saved. It's a really good idea to explicitly
> mark the loop with { } too, to reduce confusion.
>
>> dev <- return(data.frame(cbind(data,deviation)))
>
> Hm. I don't know what you're trying to do with return() here, and
> using both data.frame() and cbind() is superfluous. It isn't always
> necessary, but I find it useful to explicitly name the columns of your
> data frame when you create it, which gives
>
> dev <- data.frame(data, deviation = deviation))
>
>> return(dev)
>
> The last item of a function is what's returned, so all you really need here
> is
>
> dev
>
>> }
>> vmask(sub,10)
>> View(dev)
>
> dev only exists within the scope of the function. But you didn't
> assign the return value of the function to anything. If you assign it
> to an object named dev, then dev will exist in the global environment:
>
> dev <- vmask(sub, 10)
>
>
>
>> But when I run this I get the results as expected. But I expected the new
>> coloumn to be called "deviation", whereas R just calls in "value.1". How
>> can I fix this?
>> Also I was hoping to see this new dataset with columns "week", "value",
>> and now "deviation" when I use "View(dev) - but it comes up with error
>> 'dev not found'. How can i fix this? Also is there anyway instead of me
>> making a new dataset called "dev" with the 3 columns, I can just re-use my
>> original dataset "sub" and give me all the 3 new columns?
>>
>> The next step I want to do is to perform a cumulative sum. So looking at
>> the results, I want a new coloumn in existing dataset (or new dataset),
>> which will now have 4 columns. The 4th column I want to be called "CuSum".
>> So the first row of Cusum will be "-0.55", the second = "-0.55+(-2.01)"
>> which will give me "-2.56" and so on forth.
>>
>> How can I do this in R using a function? Please help
>
> You don't need a function. Just add the cumulative sum as a new column.
>
> sub$Cusum <- cumsum(sub$deviation)
>
>
> Sarah
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
>
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From matzke at berkeley.edu  Thu Jul 24 18:27:37 2014
From: matzke at berkeley.edu (Nick Matzke)
Date: Thu, 24 Jul 2014 12:27:37 -0400
Subject: [R] R CMD BATCH *without* saving output
In-Reply-To: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>
References: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>
Message-ID: <CAJdu7BDwSy9BY_T58kFcZZgeGKffuJpR06Eq_x0PvgTgfEwqBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/6e4e9796/attachment.pl>

From matzke at berkeley.edu  Thu Jul 24 18:54:41 2014
From: matzke at berkeley.edu (Nick Matzke)
Date: Thu, 24 Jul 2014 12:54:41 -0400
Subject: [R] R CMD BATCH *without* saving output
In-Reply-To: <CAJdu7BDwSy9BY_T58kFcZZgeGKffuJpR06Eq_x0PvgTgfEwqBQ@mail.gmail.com>
References: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>
	<CAJdu7BDwSy9BY_T58kFcZZgeGKffuJpR06Eq_x0PvgTgfEwqBQ@mail.gmail.com>
Message-ID: <CAJdu7BAYfgfKogcfbW+4_ofNZQPx8sVQZeYH93AwYKatLzWJ4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/69eeda5c/attachment.pl>

From wdunlap at tibco.com  Thu Jul 24 19:42:48 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 24 Jul 2014 10:42:48 -0700
Subject: [R] R CMD BATCH *without* saving output
In-Reply-To: <CAJdu7BAYfgfKogcfbW+4_ofNZQPx8sVQZeYH93AwYKatLzWJ4w@mail.gmail.com>
References: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>
	<CAJdu7BDwSy9BY_T58kFcZZgeGKffuJpR06Eq_x0PvgTgfEwqBQ@mail.gmail.com>
	<CAJdu7BAYfgfKogcfbW+4_ofNZQPx8sVQZeYH93AwYKatLzWJ4w@mail.gmail.com>
Message-ID: <CAF8bMcYKiowsh-nybaMQxU=mVeLUT+OQcutp3jFQsVX-S3vyww@mail.gmail.com>

You also might try wrapping the call to the scripts with capture.output().
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jul 24, 2014 at 9:54 AM, Nick Matzke <matzke at berkeley.edu> wrote:
> Actually, this was the full solution:
>
> At the beginning of the script:
>
> # Suppressing all output/warnings/try errors:
> # Open connection to black hole
> con=file(open="/dev/null")
> # Don't print anything to screen
> sink(file=con, type="output")
> # Don't print messages (e.g. errors/warnings)
> sink(file=con, type="message")
>
>
> At the end of the script:
>
> # Turn off output sink
> sink()
> # Turn off message sink
> sink(type="message")
> # Close connection to black hole
> close(con)
>
>
>
>
> On Thu, Jul 24, 2014 at 12:27 PM, Nick Matzke <matzke at berkeley.edu> wrote:
>
>>
>> On Thu, Jul 24, 2014 at 12:16 PM, Nick Matzke <matzke at nimbios.org> wrote:
>>
>>> Hi all,
>>>
>>> Hi have a series of scripts that print a lot of notes etc. to screen.  I
>>> have to run them on a massive set of input files. The scripts are
>>> self-contained and save the important output to data files in an organized
>>> way.  I don't need the screen output for anything.
>>>
>>> Problems:
>>>
>>> - If I run the script from the R command line, the output printed to
>>> Terminal got so huge that it crashed Terminal (I was running 10 of these at
>>> once)
>>>
>>>  - I tried R CMD BATCH, but this just created .Rout files that are size
>>> 50 GB and counting.
>>>
>>> I suppose I could be a grownup and refactor all my code with print
>>> options that I can turn off, but I would rather be lazy.
>>>
>>> So, is there a way to run R CMD BATCH or something similar, and NOT print
>>> the output to screen or to the .Rout file?
>>>
>>> I tried:
>>>
>>> R CMD BATCH --no-save , but that still seems to save the the screen
>>> output etc. to .Rout.
>>>
>>> Thanks,
>>> Nick
>>>
>>
>>
>> Here is one likely solution to the above question (also, I am now sending
>> from the email address that is subscribed to R-help):
>>
>> Put:
>> sink("/dev/null")
>>
>> ...at the beginning of the script. All screen output now goes to the black
>> hole of /dev/null and is not saved.
>>
>> At the end of the script, put
>> sink()
>>
>> ...to turn this behavior off.
>>
>> (Tip courtesy of Brian O'Meara)
>>
>> There may be even easier solutions, if so, I'm still interested, since I
>> couldn't find anything obvious googling R CMD BATCH (although this function
>> seems to have many options not listed in the help for R CMD BATCH).
>>
>> Thanks,
>> Nick
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pmaclean2011 at yahoo.com  Thu Jul 24 18:23:42 2014
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Thu, 24 Jul 2014 09:23:42 -0700
Subject: [R] Technological/Logistic Substitution Model
Message-ID: <1406219022.74790.YahooMailNeo@web122404.mail.ne1.yahoo.com>

Any one with an idea of estimating the Technological/Logistic substitution model. The model is specified as:
fi(t(j))?= 1/[1-exp(-alpa(t(i))-beta(i)]??? for t <tb and alpha >0
fi(t(j)) = 1-sum(f(j-1))- sum(f(j+1))?????? for tb <=t <= tc
fi(t(j)) = 1/[1+ exp(alpas(t(i)-betas(i))] ?for t >=tc and alphas >0.
?
The models assume that n technologies are introduced to the market, where 1 is the oldest and technology n is the newest,?i and j are subscripts representing the type of technology, fi is the market share, t is a subscript denoting time, alpha, alphas, beta, and betas are parameters, tb and tc are time periods during which the technology i starts to enter the saturation and decline phase, respectively.
?
Any suggestion, reading is helpful.??

Peter Maclean
Department of Economics
UDSM


From matzke at nimbios.org  Thu Jul 24 18:16:58 2014
From: matzke at nimbios.org (Nick Matzke)
Date: Thu, 24 Jul 2014 12:16:58 -0400
Subject: [R] R CMD BATCH *without* saving output
Message-ID: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/648f8f5c/attachment.pl>

From pfeiffss at miamioh.edu  Thu Jul 24 19:07:46 2014
From: pfeiffss at miamioh.edu (Pfeiffer, Steven)
Date: Thu, 24 Jul 2014 13:07:46 -0400
Subject: [R] Using apply() with functions I wrote
Message-ID: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/be4c1631/attachment.pl>

From ferra.xu at yahoo.com  Thu Jul 24 19:25:57 2014
From: ferra.xu at yahoo.com (Ferra Xu)
Date: Thu, 24 Jul 2014 10:25:57 -0700
Subject: [R] Kernel smoothing density function
Message-ID: <1406222757.48256.YahooMailNeo@web125101.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/c1d635f6/attachment.pl>

From hb at biostat.ucsf.edu  Thu Jul 24 22:10:36 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 24 Jul 2014 22:10:36 +0200
Subject: [R] R CMD BATCH *without* saving output
In-Reply-To: <CAF8bMcYKiowsh-nybaMQxU=mVeLUT+OQcutp3jFQsVX-S3vyww@mail.gmail.com>
References: <CAJdu7BDtDKMAbZ45-UvFhZeYhh-hAKd3Cn2yHQdz-qyMif5EXQ@mail.gmail.com>
	<CAJdu7BDwSy9BY_T58kFcZZgeGKffuJpR06Eq_x0PvgTgfEwqBQ@mail.gmail.com>
	<CAJdu7BAYfgfKogcfbW+4_ofNZQPx8sVQZeYH93AwYKatLzWJ4w@mail.gmail.com>
	<CAF8bMcYKiowsh-nybaMQxU=mVeLUT+OQcutp3jFQsVX-S3vyww@mail.gmail.com>
Message-ID: <CAFDcVCRYqEkjFNU113Rz7fNjjdmJS_3W+qRqo6fUw4zSgrE9jQ@mail.gmail.com>

On *nix like systems:
Rscript myscript.R > /dev/null 2>&1

On Windows:
Rscript myscript.R > NUL 2>&1

The above sends both standard output ("1") and standard error ("2") to nirvana.

I prefer using 'Rscript', but the same works with any command
including 'R CMD BATCH'.

/Henrik

PS. Bill, capture.output() would more or less hang your R session for
such large outputs (here "50 GB and counting"), cf.
http://www.jottr.org/2014/05/captureOutput.html

On Thu, Jul 24, 2014 at 7:42 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You also might try wrapping the call to the scripts with capture.output().
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Jul 24, 2014 at 9:54 AM, Nick Matzke <matzke at berkeley.edu> wrote:
>> Actually, this was the full solution:
>>
>> At the beginning of the script:
>>
>> # Suppressing all output/warnings/try errors:
>> # Open connection to black hole
>> con=file(open="/dev/null")
>> # Don't print anything to screen
>> sink(file=con, type="output")
>> # Don't print messages (e.g. errors/warnings)
>> sink(file=con, type="message")
>>
>>
>> At the end of the script:
>>
>> # Turn off output sink
>> sink()
>> # Turn off message sink
>> sink(type="message")
>> # Close connection to black hole
>> close(con)
>>
>>
>>
>>
>> On Thu, Jul 24, 2014 at 12:27 PM, Nick Matzke <matzke at berkeley.edu> wrote:
>>
>>>
>>> On Thu, Jul 24, 2014 at 12:16 PM, Nick Matzke <matzke at nimbios.org> wrote:
>>>
>>>> Hi all,
>>>>
>>>> Hi have a series of scripts that print a lot of notes etc. to screen.  I
>>>> have to run them on a massive set of input files. The scripts are
>>>> self-contained and save the important output to data files in an organized
>>>> way.  I don't need the screen output for anything.
>>>>
>>>> Problems:
>>>>
>>>> - If I run the script from the R command line, the output printed to
>>>> Terminal got so huge that it crashed Terminal (I was running 10 of these at
>>>> once)
>>>>
>>>>  - I tried R CMD BATCH, but this just created .Rout files that are size
>>>> 50 GB and counting.
>>>>
>>>> I suppose I could be a grownup and refactor all my code with print
>>>> options that I can turn off, but I would rather be lazy.
>>>>
>>>> So, is there a way to run R CMD BATCH or something similar, and NOT print
>>>> the output to screen or to the .Rout file?
>>>>
>>>> I tried:
>>>>
>>>> R CMD BATCH --no-save , but that still seems to save the the screen
>>>> output etc. to .Rout.
>>>>
>>>> Thanks,
>>>> Nick
>>>>
>>>
>>>
>>> Here is one likely solution to the above question (also, I am now sending
>>> from the email address that is subscribed to R-help):
>>>
>>> Put:
>>> sink("/dev/null")
>>>
>>> ...at the beginning of the script. All screen output now goes to the black
>>> hole of /dev/null and is not saved.
>>>
>>> At the end of the script, put
>>> sink()
>>>
>>> ...to turn this behavior off.
>>>
>>> (Tip courtesy of Brian O'Meara)
>>>
>>> There may be even easier solutions, if so, I'm still interested, since I
>>> couldn't find anything obvious googling R CMD BATCH (although this function
>>> seems to have many options not listed in the help for R CMD BATCH).
>>>
>>> Thanks,
>>> Nick
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Jul 24 22:11:33 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 24 Jul 2014 13:11:33 -0700
Subject: [R] Using apply() with functions I wrote
In-Reply-To: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>
References: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>
Message-ID: <CACk-te3Bw5NPLhib__Ax5M+UZnjaop6xr5T9WUp4MoYLDHRjkw@mail.gmail.com>

ummm.... R is case sensitive! "fun" != "FUN"

(Have you gone through any R tutorials yet? If not, please do so
before posting further).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Jul 24, 2014 at 10:07 AM, Pfeiffer, Steven <pfeiffss at miamioh.edu> wrote:
> Hello!
>
> Does apply() not work with customized functions?  Here is a simple example:
>
>      AddSeven<-function(n){n+7}
>      AddSeven(3)
>        [1] 10
>      M<-matrix(nrow=2,ncol=2,data=c(1,2,3,4),byrow=TRUE)
>      M
>             [,1] [,2]
>        [1,]    1    2
>        [2,]    3    4
>      apply(x=M,margin=c(1,2),fun=AddSeven)
>        Error in match.fun(FUN) : argument "FUN" is missing, with no default
>
> Thanks for your help!
> -Steve Pfeiffer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pfeiffss at miamioh.edu  Thu Jul 24 22:34:00 2014
From: pfeiffss at miamioh.edu (Pfeiffer, Steven)
Date: Thu, 24 Jul 2014 16:34:00 -0400
Subject: [R] Using apply() with functions I wrote
In-Reply-To: <CACk-te3Bw5NPLhib__Ax5M+UZnjaop6xr5T9WUp4MoYLDHRjkw@mail.gmail.com>
References: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>
	<CACk-te3Bw5NPLhib__Ax5M+UZnjaop6xr5T9WUp4MoYLDHRjkw@mail.gmail.com>
Message-ID: <CAJjjYOnCNskp1Qw1Hy8YutDd0gYzrxpwvVY2UDdq7Psz0COZ6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/5c17b721/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Thu Jul 24 22:38:09 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Fri, 25 Jul 2014 08:38:09 +1200
Subject: [R] Using apply() with functions I wrote
In-Reply-To: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>
References: <CAJjjYO==Ppars3DD72SOn8nhUHUoa2neU6bnF4a24_0bks79OA@mail.gmail.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2281E68D91@AKLEXM01.PFR.CO.NZ>

Tena koe Steven

R is case-sensitive.  FUN is missing (you have supplied fun - and ? and margin) ...

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pfeiffer, Steven
Sent: Friday, 25 July 2014 5:08 a.m.
To: r-help at r-project.org
Subject: [R] Using apply() with functions I wrote

Hello!

Does apply() not work with customized functions?  Here is a simple example:

     AddSeven<-function(n){n+7}
     AddSeven(3)
       [1] 10
     M<-matrix(nrow=2,ncol=2,data=c(1,2,3,4),byrow=TRUE)
     M
            [,1] [,2]
       [1,]    1    2
       [2,]    3    4
     apply(x=M,margin=c(1,2),fun=AddSeven)
       Error in match.fun(FUN) : argument "FUN" is missing, with no default

Thanks for your help!
-Steve Pfeiffer

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From emammendes at gmail.com  Fri Jul 25 00:52:26 2014
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Thu, 24 Jul 2014 19:52:26 -0300
Subject: [R] R-3.1.1 - R CMD INSTALL problem
Message-ID: <8DD98EFF-D07A-4934-BEE0-6C1FD50200F1@gmail.com>

Hello

I have recently upgraded R to the newest version.  Unfortunately my old (fortran and C) R-package cannot be installed anymore (was built before R 3.0.0: please re-install it). 

I have tried R CMD INSTALL package_name but I noticed that R requests gcc-4.8.2 and specific locations for the libraries (gcc and gfortran).   Can someone point me to the documentation on how to install  gcc as R requires, please?

Please note that I have used "brew install gcc" on another mac and soft linked all the necessary libraries so that gcc-4.9.1 can be used as 4.8 (as R requires). However I would like a clean installation.

Many thanks

Ed


From jdnewmil at dcn.davis.CA.us  Fri Jul 25 01:52:50 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 24 Jul 2014 16:52:50 -0700
Subject: [R] R-3.1.1 - R CMD INSTALL problem
In-Reply-To: <8DD98EFF-D07A-4934-BEE0-6C1FD50200F1@gmail.com>
References: <8DD98EFF-D07A-4934-BEE0-6C1FD50200F1@gmail.com>
Message-ID: <927531a2-7103-4adb-ae1e-5ccfb2d8cad7@email.android.com>

You need to rebuild it with an appropriate Depends entry (version of R greater than 3) in the DESCRIPTION file.

Further discussion about how to fix packages belongs on the R-devel mailing list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 24, 2014 3:52:26 PM PDT, "Eduardo M. A. M.Mendes" <emammendes at gmail.com> wrote:
>Hello
>
>I have recently upgraded R to the newest version.  Unfortunately my old
>(fortran and C) R-package cannot be installed anymore (was built before
>R 3.0.0: please re-install it). 
>
>I have tried R CMD INSTALL package_name but I noticed that R requests
>gcc-4.8.2 and specific locations for the libraries (gcc and gfortran). 
>Can someone point me to the documentation on how to install  gcc as R
>requires, please?
>
>Please note that I have used "brew install gcc" on another mac and soft
>linked all the necessary libraries so that gcc-4.9.1 can be used as 4.8
>(as R requires). However I would like a clean installation.
>
>Many thanks
>
>Ed
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lienju at yahoo.fr  Thu Jul 24 23:05:18 2014
From: lienju at yahoo.fr (Julien Million)
Date: Thu, 24 Jul 2014 23:05:18 +0200
Subject: [R] Retrieve Axis coordinates from map
Message-ID: <CFF741AE.1EF5C%lienju@yahoo.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/eb5d3f25/attachment.pl>

From mccormack at molbio.mgh.harvard.edu  Thu Jul 24 23:19:38 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Thu, 24 Jul 2014 17:19:38 -0400
Subject: [R] working on a data frame
Message-ID: <53D1786A.2090508@molbio.mgh.harvard.edu>

I am coming from the perspective of Excel and VBA scripts, but I would 
like to do the following in R.

  I have a data frame with 14 columns and 32,795 rows.

I want to check the value in column 8 (row 1) to see if it is a 0.
If it is not a zero, proceed to the next row and check the value for 
column 8.
If it is a zero, then
a) change the zero to a 1,
b) divide the value in column 9 (row 1) by 1,
c) place the result in column 10 (row 1) and
d) repeat this for each of the other 32,794 rows.

Is this possible with an R script, and is this the way to go about it. 
If it is, could anyone get me started ?

Matthew


From emammendes at gmail.com  Fri Jul 25 02:39:45 2014
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Thu, 24 Jul 2014 21:39:45 -0300
Subject: [R] R-3.1.1 - R CMD INSTALL problem
In-Reply-To: <927531a2-7103-4adb-ae1e-5ccfb2d8cad7@email.android.com>
References: <8DD98EFF-D07A-4934-BEE0-6C1FD50200F1@gmail.com>
	<927531a2-7103-4adb-ae1e-5ccfb2d8cad7@email.android.com>
Message-ID: <4536B4A0-C75F-493D-9BAC-2306B9096B8D@gmail.com>

Many thanks.

With 4.9.1 (as I did) no need to modify Depends.

Ed

PS. I have posted the question to R-devel mailing list. Many thanks.


On Jul 24, 2014, at 8:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:

> You need to rebuild it with an appropriate Depends entry (version of R greater than 3) in the DESCRIPTION file.
> 
> Further discussion about how to fix packages belongs on the R-devel mailing list.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On July 24, 2014 3:52:26 PM PDT, "Eduardo M. A. M.Mendes" <emammendes at gmail.com> wrote:
>> Hello
>> 
>> I have recently upgraded R to the newest version.  Unfortunately my old
>> (fortran and C) R-package cannot be installed anymore (was built before
>> R 3.0.0: please re-install it). 
>> 
>> I have tried R CMD INSTALL package_name but I noticed that R requests
>> gcc-4.8.2 and specific locations for the libraries (gcc and gfortran). 
>> Can someone point me to the documentation on how to install  gcc as R
>> requires, please?
>> 
>> Please note that I have used "brew install gcc" on another mac and soft
>> linked all the necessary libraries so that gcc-4.9.1 can be used as 4.8
>> (as R requires). However I would like a clean installation.
>> 
>> Many thanks
>> 
>> Ed
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From sarah.goslee at gmail.com  Fri Jul 25 02:52:09 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 24 Jul 2014 20:52:09 -0400
Subject: [R] working on a data frame
In-Reply-To: <53D1786A.2090508@molbio.mgh.harvard.edu>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>
Message-ID: <CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/fca2856a/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Fri Jul 25 03:15:04 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Fri, 25 Jul 2014 13:15:04 +1200
Subject: [R] Retrieve Axis coordinates from map
In-Reply-To: <CFF741AE.1EF5C%lienju@yahoo.fr>
References: <CFF741AE.1EF5C%lienju@yahoo.fr>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2281E68DD7@AKLEXM01.PFR.CO.NZ>

Tena koe Julien

I don't use the maps package much, but I suspect par()$usr will allow you to do what you want.

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Julien Million
Sent: Friday, 25 July 2014 9:05 a.m.
To: r-help at r-project.org
Subject: [R] Retrieve Axis coordinates from map

Hi, 

i want to automatise the creation of some maps with R, however, I would need to be able to retrieve the coordinates of the axes that R is automatically generated. 

When using the package MAPS, and creating a map, R will automatically adjust the plot to the region that you are plotting.

for example the two command:
map(regions="Morocco")
or
map(regions="France")
will generate plots with completely different axis and scale. If I want to automatically generate a map and add a legend to it, I would need to be able to retrieve the coordinates of my axis that were automatically generated in order to give coordinate to place my legend on the map.

Basically I would like to automatise the following with a function, and be able to automatically get the coordinates for my legend)

map(regions="Morocco")
map.axes()
legend(-12,34, "blablabla")

map(regions="France")
map.axes()
legend(-150,40, "blablabla")

mapcountry <- function(country) {
map(regions=country)
map.axes()
legend(xxxx, yyyy, "blablabla")
}

I want to be able to extract the xxxx and yyyy automatically to be able to generate the legend within the function.

Thanks

Julien



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From dwinsemius at comcast.net  Fri Jul 25 03:20:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 24 Jul 2014 18:20:14 -0700
Subject: [R] Retrieve Axis coordinates from map
In-Reply-To: <CFF741AE.1EF5C%lienju@yahoo.fr>
References: <CFF741AE.1EF5C%lienju@yahoo.fr>
Message-ID: <6FDEED49-6A67-4C34-843B-D97DE05F9C2F@comcast.net>


On Jul 24, 2014, at 2:05 PM, Julien Million wrote:

> Hi, 
> 
> i want to automatise the creation of some maps with R, however, I would need
> to be able to retrieve the coordinates of the axes that R is automatically
> generated. 
> 
> When using the package MAPS,

Case matters in R so this is the wrong spelling.

> and creating a map, R will automatically adjust
> the plot to the region that you are plotting.
> 
> for example the two command:
> map(regions="Morocco")
> or 
> map(regions="France")
> will generate plots with completely different axis and scale. If I want to
> automatically generate a map and add a legend to it, I would need to be able
> to retrieve the coordinates of my axis that were automatically generated in
> order to give coordinate to place my legend on the map.
> 
> Basically I would like to automatise the following with a function, and be
> able to automatically get the coordinates for my legend)
> 

require(maps)
> map(regions="Morocco")
> map.axes()
> legend(-12,34, "blablabla")

Perhaps something like this:
legend(-12,35.5, paste( paste("Xrange = ", round( par("usr")[1:2],2), collapse=" "), 
                        paste( "Yrange = ", round( par("usr")[3:4],2) , collapse=" "),
                        sep="\n")  )

?par  # since pkg::maps uses base graphics.

> 
> map(regions="France")
> map.axes()
> legend(-150,40, "blablabla")
> 
> mapcountry <- function(country) {
> map(regions=country)
> map.axes()
> legend(xxxx, yyyy, "blablabla")
> }
> 
> I want to be able to extract the xxxx and yyyy automatically to be able to
> generate the legend within the function.
> 
> Thanks
> 
> Julien
> 
> 
> 
> 	[[alternative HTML version deleted]]

r-help is a plain text mailing list.
> 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

And thank you for providing working code.
-- 
David Winsemius
Alameda, CA, USA


From kw1958 at gmail.com  Fri Jul 25 03:36:41 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Thu, 24 Jul 2014 21:36:41 -0400
Subject: [R] XLConnect on Linux Mint Maya
Message-ID: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>

Folks,

I have been trying to get XLConnect to work on my Linux Mint Maya machine.

R works fine but this package doesn't seem to want to build. Here is the message I get after supposedly building XLConnect and rJava:


>> require(XLConnect)
> Loading required package: XLConnect
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>  error: unable to load shared object '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>  libjvm.so: cannot open shared object file: No such file or directory


I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.

The build and the compile seemed to work ok as there were no errors. For example I can generate ggplot2 graphs.

I know this is probably the wrong forum but if someone could gently point me in the right direction I would be very appreciative.

Thanks so much for your time,
KW



--


From mccormack at molbio.mgh.harvard.edu  Fri Jul 25 05:15:35 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew McCormack)
Date: Thu, 24 Jul 2014 23:15:35 -0400
Subject: [R] working on a data frame
In-Reply-To: <CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>
	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
Message-ID: <53D1CBD7.7090108@molbio.mgh.harvard.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/cea8dfac/attachment.pl>

From john.archie.mckown at gmail.com  Fri Jul 25 05:16:30 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 24 Jul 2014 22:16:30 -0500
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
Message-ID: <CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>

On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> Folks,
>
> I have been trying to get XLConnect to work on my Linux Mint Maya machine.
>
> R works fine but this package doesn't seem to want to build. Here is the message I get after supposedly building XLConnect and rJava:
>
>
>>> require(XLConnect)
>> Loading required package: XLConnect
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>  call: dyn.load(file, DLLpath = DLLpath, ...)
>>  error: unable to load shared object '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>  libjvm.so: cannot open shared object file: No such file or directory
>
>
> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>
> The build and the compile seemed to work ok as there were no errors. For example I can generate ggplot2 graphs.
>
> I know this is probably the wrong forum but if someone could gently point me in the right direction I would be very appreciative.
>
> Thanks so much for your time,
> KW

It works fine for me on Fedora 20 (and 19 before it). When I installed
R, it installed into /usr/lib64/R. There exists a file:
/usr/lib64/R/etc/ldpaths which is executed by the R executable script.
This sets up the LD_LIBRARY_PATH to point to the Java installation on
my machine. In the /usr/lib64/R/bin directory, there is a program
called "javareconf". I would suggest that you run this with the -n
switch, like:

R CMD /usr/lib64/R/bin/javareconf -n

This will show you what it _would_ do if you left off the "-n". Make
sure it looks reasonable. If it does, then run the same command,
without the "-n", as the "root" superuser. In my case, that would be:

sudo R CMD /usr/lib64/R/bin/javareconf

You need to be "root" because it update the file
/usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
problem.

===

As a possible alternative to XLConnect, have you looked at openxlsx?
It appears to have the same abilities, just some different syntax. It
says that it is written in C and so should be faster than XLConnect. I
have tested both packages, a little, and they both seem to work well.

Well, it's 22:14 hours here and I wish that I could fall asleep. We're
having problems at work and I know that the "big boss" will blame us
peons if the hardware isn't fixed promptly Despite the fact that we
are only software people and aren't allowed to touch the hardware. Our
management's minds are not using the same logic as mine does.
Frustrating.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From kw1958 at gmail.com  Fri Jul 25 05:36:39 2014
From: kw1958 at gmail.com (kw1958)
Date: Thu, 24 Jul 2014 23:36:39 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
Message-ID: <CACDn=YyQj2YKG8ic9p+vuqsDGxTvMhr846J9DZYdybmu802qKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140724/bfba05ed/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Fri Jul 25 06:06:54 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Fri, 25 Jul 2014 16:06:54 +1200
Subject: [R] working on a data frame
In-Reply-To: <53D1CBD7.7090108@molbio.mgh.harvard.edu>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>
	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
	<53D1CBD7.7090108@molbio.mgh.harvard.edu>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>

Tena koe Matthew

" Column 10 contains the result of the value in column 9 divided by the value in column 8. If the value in column 8==0, then the division can not be done, so  I want to change the zero to a one in order to do the division.".  That being the case, think in terms of vectors, as Sarah says.  Try:

yourData[,10] <- yourData[,9]/yourData[,8]
yourData[yourData[,8]==0,10] <- yourData[yourData[,8]==0,9]

This doesn't change the 0 to 1 in column 8, but it doesn't appear you actually need to do that.

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Matthew McCormack
Sent: Friday, 25 July 2014 3:16 p.m.
To: Sarah Goslee
Cc: r-help at r-project.org
Subject: Re: [R] working on a data frame


On 7/24/2014 8:52 PM, Sarah Goslee wrote:
> Hi,
>
> Your description isn't clear:
>
> On Thursday, July 24, 2014, Matthew <mccormack at molbio.mgh.harvard.edu 
> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>
>     I am coming from the perspective of Excel and VBA scripts, but I
>     would like to do the following in R.
>
>      I have a data frame with 14 columns and 32,795 rows.
>
>     I want to check the value in column 8 (row 1) to see if it is a 0.
>     If it is not a zero, proceed to the next row and check the value
>     for column 8.
>     If it is a zero, then
>     a) change the zero to a 1,
>     b) divide the value in column 9 (row 1) by 1,
>
>
> Row 1, or the row in which column 8 == 0?
All rows in which the value in column 8==0.
> Why do you want to divide by 1?
Column 10 contains the result of the value in column 9 divided by the value in column 8. If the value in column 8==0, then the division can not be done, so  I want to change the zero to a one in order to do the division. This is a fairly standard thing to do with this data. (The data are measurements of amounts at two time points. Sometimes a thing will not be present in the beginning (0), but very present at the later time. Column 10 is the log2 of the change. Infinite is not an easy number to work with, so it is common to change the 0 to a 1. On the other hand, something may be present at time 1, but not at the later time. In this case column 10 would be taking the log2 of a number divided by 0, so again the zero is commonly changed to a one in order to get a useable value in column 10. In both the preceding cases there was a real change, but Inf and NaN are not helpful.)
>
>     c) place the result in column 10 (row 1) and
>
>
> Ditto on the row 1 question.
I want to work on all rows where column 8 (and column 9) contain a zero.
Column 10 contains the result of the value in column 9 divided by the value in column 8. So, for row 1, column 10 row 1 contains the ratio column 9 row 1 divided by column 8 row 1, and so on through the whole
32,000 or so rows.

Most rows do not have a zero in columns 8 or 9. Some rows have  zero in column 8 only, and some rows have a zero in column 9 only. I want to get rid of the zeros in these two columns and then do the division to get a manageable value in column 10. Division by zero and Inf are not considered 'manageable' by me.
> What do you want column 10 to be if column 8 isn't 0? Does it already 
> have a value. I suppose it must.
Yes column 10 does have something, but this something can be Inf or NaN, which I want to get rid of.
>
>     d) repeat this for each of the other 32,794 rows.
>
>     Is this possible with an R script, and is this the way to go about
>     it. If it is, could anyone get me started ?
>
>
> Assuming you want to put the new values in the rows where column 8 == 
> 0, you can do it in two steps:
>
> mydata[,10] <- ifelse(mydata[,8] == 0, mydata[,9]/whatever, 
> mydata[,10]) #where whatever is the thing you want to divide by that 
> probably isn't 1 mydata[,8] <- ifelse(mydata[,8] == 0, 1, mydata[,8])
>
> R programming is best done by thinking about vectorizing things, 
> rather than doing them in loops. Reading the Intro to R that comes 
> with your installation is a good place to start.
Would it be better to change the data frame into a matrix, or something else ?
Thanks for your help.
>
> Sarah
>
>
>     Matthew
>
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From suparna.mitra.sm at gmail.com  Fri Jul 25 08:11:02 2014
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 25 Jul 2014 14:11:02 +0800
Subject: [R] Fwd: Converting Lat Lon data in coordinates in R
In-Reply-To: <CAFdg=fVS+8_ZHsABYs1uj_7nav0_+-gEwnZWu8M6UxU8tHg-ZQ@mail.gmail.com>
References: <CAFdg=fVS+8_ZHsABYs1uj_7nav0_+-gEwnZWu8M6UxU8tHg-ZQ@mail.gmail.com>
Message-ID: <CAFdg=fXU_Gh9eB=_h-qVu+7GOJWLRfUEA5dYBw0YEuJitJbqQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/5a262480/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Fri Jul 25 09:01:03 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 25 Jul 2014 00:01:03 -0700
Subject: [R] Fwd: Converting Lat Lon data in coordinates in R
In-Reply-To: <CAFdg=fXU_Gh9eB=_h-qVu+7GOJWLRfUEA5dYBw0YEuJitJbqQg@mail.gmail.com>
References: <CAFdg=fVS+8_ZHsABYs1uj_7nav0_+-gEwnZWu8M6UxU8tHg-ZQ@mail.gmail.com>
	<CAFdg=fXU_Gh9eB=_h-qVu+7GOJWLRfUEA5dYBw0YEuJitJbqQg@mail.gmail.com>
Message-ID: <e4f84592-1e0a-4e01-ad1a-8d5f75c90636@email.android.com>

Try reading the Posting Guide, and post in plain text (your data is corrupted by the HTML). Then read [1] and use dput to provide the data as you have it in R.

The solution will involve parsing out the pieces of the coordinates and converting them to decimal degrees, but we don't really know how it is currently formatted.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 24, 2014 11:11:02 PM PDT, Suparna Mitra <suparna.mitra.sm at gmail.com> wrote:
>Hi
>???Hello
>,
>
>???Can anybody please let me know
>how can I convert Lat/Lon data in coordinates in R. I was trying to use
>the rgdal package
>??? and proj4 package???
>. But being bit confused how to use S or N information.
>???and degree min second information.
>Any example help will be great.???
>My data looks like:
>Latitude Longitude  22??54'57"S 47??08'50"W  22??49???38??????S
>47??03???49??????W
>22??54'13"S 47??01'08"W  22??50'39"S 47??05'47"W  22??49'10"S
>47??03'34"W
>3??5'47"S 59??59'24"W  2??55'47"S 59??58'32"W  40??49???20??????N
>77??49???58??????W
>
> ???Thanks,
>
>Mitra
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ahmed.nagi at gmail.com  Fri Jul 25 07:12:57 2014
From: ahmed.nagi at gmail.com (Ahmed Nagi)
Date: Fri, 25 Jul 2014 01:12:57 -0400
Subject: [R] Prooblem using RMpi on OSX moutain lion
Message-ID: <CAOuJCRdNg7SFpoph6VfBu4ogzV6Y=UXBj-buONm_9odpAsMP4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/8174a085/attachment.pl>

From ayuship.09 at gmail.com  Fri Jul 25 12:18:35 2014
From: ayuship.09 at gmail.com (Ayushi Pandey)
Date: Fri, 25 Jul 2014 15:48:35 +0530
Subject: [R] svm implementation using RTextTools
Message-ID: <CAE8r6W19MOiuOssX1xN3AOXr8bHGgLxXX1gvFrofdx7FhaLX-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/02a6d237/attachment.pl>

From lienju at yahoo.fr  Fri Jul 25 10:30:12 2014
From: lienju at yahoo.fr (Julien Million)
Date: Fri, 25 Jul 2014 10:30:12 +0200
Subject: [R] Retrieve Axis coordinates from map
In-Reply-To: <6FDEED49-6A67-4C34-843B-D97DE05F9C2F@comcast.net>
References: <CFF741AE.1EF5C%lienju@yahoo.fr>
	<6FDEED49-6A67-4C34-843B-D97DE05F9C2F@comcast.net>
Message-ID: <CFF7E1F7.1EF6F%lienju@yahoo.fr>

Thanks you both, very useful!



On 25/07/14 03:20, "David Winsemius" <dwinsemius at comcast.net> wrote:

>
>On Jul 24, 2014, at 2:05 PM, Julien Million wrote:
>
>> Hi, 
>> 
>> i want to automatise the creation of some maps with R, however, I would
>>need
>> to be able to retrieve the coordinates of the axes that R is
>>automatically
>> generated. 
>> 
>> When using the package MAPS,
>
>Case matters in R so this is the wrong spelling.
>
>> and creating a map, R will automatically adjust
>> the plot to the region that you are plotting.
>> 
>> for example the two command:
>> map(regions="Morocco")
>> or 
>> map(regions="France")
>> will generate plots with completely different axis and scale. If I want
>>to
>> automatically generate a map and add a legend to it, I would need to be
>>able
>> to retrieve the coordinates of my axis that were automatically
>>generated in
>> order to give coordinate to place my legend on the map.
>> 
>> Basically I would like to automatise the following with a function, and
>>be
>> able to automatically get the coordinates for my legend)
>> 
>
>require(maps)
>> map(regions="Morocco")
>> map.axes()
>> legend(-12,34, "blablabla")
>
>Perhaps something like this:
>legend(-12,35.5, paste( paste("Xrange = ", round( par("usr")[1:2],2),
>collapse=" "), 
>                        paste( "Yrange = ", round( par("usr")[3:4],2) ,
>collapse=" "),
>                        sep="\n")  )
>
>?par  # since pkg::maps uses base graphics.
>
>> 
>> map(regions="France")
>> map.axes()
>> legend(-150,40, "blablabla")
>> 
>> mapcountry <- function(country) {
>> map(regions=country)
>> map.axes()
>> legend(xxxx, yyyy, "blablabla")
>> }
>> 
>> I want to be able to extract the xxxx and yyyy automatically to be able
>>to
>> generate the legend within the function.
>> 
>> Thanks
>> 
>> Julien
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>
>r-help is a plain text mailing list.
>> 
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>
>And thank you for providing working code.
>-- 
>David Winsemius
>Alameda, CA, USA
>


From marianna.bolognesi at gmail.com  Fri Jul 25 10:11:25 2014
From: marianna.bolognesi at gmail.com (Marianna Bolognesi)
Date: Fri, 25 Jul 2014 10:11:25 +0200
Subject: [R] clustering with hclust
Message-ID: <CA+rsCaQRQKoupJPU-77JfFTkC7_bsZSVrhs_x+hrr_SP9pRfNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/d405e3da/attachment.pl>

From marcel.au at web.de  Fri Jul 25 12:52:50 2014
From: marcel.au at web.de (marcel Austenfeld)
Date: Fri, 25 Jul 2014 12:52:50 +0200
Subject: [R] Set Conditional Breakpoint with setBreakpoint Function
Message-ID: <trinity-0bc88468-fd55-4a9c-a05c-0f83ab5cbc4a-1406285570521@3capp-webde-bs54>


   Hello,
   i'm searching for a way to realize a conditional breakpoint.
   setBreakpoint is a simple wrapper for the trace function. What i wan't to do
   is similar to the trace function
   described here:
   [1]http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/debug.shtml
   "> trace(fun, quote(if (x > 10) browser()))"
   How can i do this with the setBreakpoint function or are there any other
   alternatives to realize a conditional breakpoint?
   I use the setBreakpoint function in combination with findLineNum for a
   simple R debugging GUI.
   Thank in advance for any help

   Marcel

References

   1. http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/debug.shtml

From ucakche at ucl.ac.uk  Fri Jul 25 13:19:19 2014
From: ucakche at ucl.ac.uk (Christian Hennig)
Date: Fri, 25 Jul 2014 12:19:19 +0100
Subject: [R] clustering with hclust
In-Reply-To: <CA+rsCaQRQKoupJPU-77JfFTkC7_bsZSVrhs_x+hrr_SP9pRfNQ@mail.gmail.com>
References: <CA+rsCaQRQKoupJPU-77JfFTkC7_bsZSVrhs_x+hrr_SP9pRfNQ@mail.gmail.com>
Message-ID: <alpine.GSO.2.00.1407251213020.8690@socrates-a.ucl.ac.uk>

Dear Marianna,

the function agnes in library cluster can compute Ward's method from a raw 
data matrix (at least this is what the help page suggests).

Also, you may not be using the most recent version of hclust. The most 
recent version has a note in its help page that states:

"Two different algorithms are found in the literature for Ward clustering. 
The one used by option "ward.D" (equivalent to the only Ward option "ward" 
in R versions <= 3.0.3) does not implement Ward's (1963) clustering 
criterion, whereas option "ward.D2" implements that criterion (Murtagh and 
Legendre 2013). With the latter, the dissimilarities are squared before 
cluster updating. Note that agnes(*, method="ward") corresponds to 
hclust(*, "ward.D2")."

The Murtagh and Legendre paper has more details on this and is here:
http://arxiv.org/abs/1111.6285
F. Murtagh and P. Legendre, "Ward's hierarchical clustering method: 
clustering criterion and agglomerative algorithm"

It's not clear to me why one would want to use Ward's method for this kind 
of data, but that's your decision of course.

Best wishes,
Christian


On Fri, 25 Jul 2014, Marianna Bolognesi wrote:

> Hi everybody, I have a problem with a cluster analysis.
>
> I am trying to use hclust, method=ward.
>
> The Ward method works with SQUARED Euclidean distances.
>
> Hclust demands "a dissimilarity structure as produced by dist".
>
> Yet, dist does not seem to produce a table of squared euclidean distances,
> starting from cosines.
> In fact, computing manually the squared euclidean distances from cosines
> (d=2(1-cos)) produces a different outcome.
>
> As a consequence, using hclust with ward method on a table of cosines
> tranformed into distances with dist, produces a different dendrogram than
> other programs for hierarchical clustering with ward method (i.e.
> multidendrograms). Weird right??
>
> Computing manually the distances and then feeding them to hclust produces
> an error message. So, I am wondering, what the hell is this dist function
> doing?!
>
> thanks!
>
> marianna
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche


From murdoch.duncan at gmail.com  Fri Jul 25 13:31:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Jul 2014 07:31:08 -0400
Subject: [R] Set Conditional Breakpoint with setBreakpoint Function
In-Reply-To: <trinity-0bc88468-fd55-4a9c-a05c-0f83ab5cbc4a-1406285570521@3capp-webde-bs54>
References: <trinity-0bc88468-fd55-4a9c-a05c-0f83ab5cbc4a-1406285570521@3capp-webde-bs54>
Message-ID: <53D23FFC.3010608@gmail.com>

On 25/07/2014, 6:52 AM, marcel Austenfeld wrote:
> 
>    Hello,
>    i'm searching for a way to realize a conditional breakpoint.
>    setBreakpoint is a simple wrapper for the trace function. What i wan't to do
>    is similar to the trace function
>    described here:
>    [1]http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/debug.shtml
>    "> trace(fun, quote(if (x > 10) browser()))"
>    How can i do this with the setBreakpoint function or are there any other
>    alternatives to realize a conditional breakpoint?
>    I use the setBreakpoint function in combination with findLineNum for a
>    simple R debugging GUI.
>    Thank in advance for any help

The conditional in the trace example is the tracer argument.
setBreakpoint also has a tracer argument; have you tried that?  E.g.

setBreakpoint("foo.R#22", tracer=quote(if (x > 10) browser()))

Duncan Murdoch


From luke.hartigan at bigpond.com  Fri Jul 25 14:22:56 2014
From: luke.hartigan at bigpond.com (Luke Hartigan)
Date: Fri, 25 Jul 2014 22:22:56 +1000
Subject: [R] R function returning a list of variable(s) conditional on the
	value of an option?
Message-ID: <005b01cfa803$2b1f8d10$815ea730$@bigpond.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/3e6aaf9f/attachment.pl>

From marcel.au at web.de  Fri Jul 25 14:49:29 2014
From: marcel.au at web.de (marcel Austenfeld)
Date: Fri, 25 Jul 2014 14:49:29 +0200
Subject: [R]  Set Conditional Breakpoint with setBreakpoint Function
Message-ID: <trinity-d1b1ba81-a2bd-41ee-9320-f5c616226b0e-1406292569227@3capp-webde-bs60>


   Thank you very much. Exactly the information i needed. I always tried
   "quote(if (x > 10) browser())"
   and not
   "tracer=quote(if (x > 10) browser())"
   as the argument.

   Now it works.

From john.archie.mckown at gmail.com  Fri Jul 25 15:07:47 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 25 Jul 2014 08:07:47 -0500
Subject: [R] Problem using ggplot2 with the legend of a stacked bar chart
Message-ID: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>

I am creating two graphs using ggplot2. The graphs are of the same
data. One is a stacked bar chart. The other is a line graph. The code
is below.

<code>
MSU_graph_m1   <- ggplot(cpprdald2_m1,aes(x=Int_Start,
                                          y=LicPrLsys4HMSU,
                                          fill=System_alias,
#                                          color=System_alias,
                                          ymax=LicPrLsys4HMSU_max))+
                  theme(plot.title = element_text(size = rel(3),
vjust=1, face="bold"),
                        panel.grid.major = element_line(color="black",size=1),
                        panel.grid.minor = element_line(color="black",size=1),
                        legend.position="top",
                        legend.direction="horizontal",
                        legend.text = element_text(size=rel(1.5)),
                        axis.line = element_line(size=3, color="black"),
                        axis.text = element_text(angle=90, size=rel(0.9)),
                        axis.title = element_text(size = rel(2)),
                        axis.ticks = element_line(color="black")) +
                  labs(x="Date and Time",y="MSUs",title=title)+

guides(fill=guide_legend(reverse=TRUE,title="LPARs",direction="horizontal"))+
                  scale_x_datetime(breaks = date_breaks('1 day'),
minor_breaks=date_breaks('1 hour'),  labels=date_format("%b %d
%H:%M")) +
                  scale_y_continuous(breaks = seq(0,LicPrLsys4HMSU_max,5L)) +
                  scale_fill_manual(values=c("yellow","blue")) ;
MSU_graph_m1b  <- MSU_graph_m1+geom_bar(size=0.7,stat="identity");
MSU_graph_m1l  <- MSU_graph_m1+geom_line(size=1.5);
#
</code>

Now, if I use the "color=System_alias", the legend shows up where I
want: on the top,  with the horizontal orientation, and labelled
"LPARs". But I want the order reversed. Which I can't see how to do
using this method. So I added the "guides=(fill..." line to reverse
the legend. But now the legend is on the right, vertically oriented,
and labelled "System_alias" (the variable name).

I now have eye strain from looking at the vignettes and in the book "R
Graphics Cookbook" and just can't figure out a way to get what I want.

Now, using Rstudio, I examined what is in MSU_graph_m1. And saw a
variable called "labels". This is a list containing more variables.
Once of which is called "colour". That variable has the value of
"System_alias". I found that if I set it to the value of "LPARs", then
the legend has the proper title. But I don't like doing this sort of
thing.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From popx at j-paine.org  Fri Jul 25 15:26:54 2014
From: popx at j-paine.org (Jocelyn Ireson-Paine)
Date: Fri, 25 Jul 2014 14:26:54 +0100 (BST)
Subject: [R] SASxport function read.xport gives error "object 'w' not found"
Message-ID: <alpine.LRH.2.02.1407251417410.28060@sphinx.mythic-beasts.com>

The subject line says it. I've just tried converting an SAS .xpt file with 
this call:
   > read.xport( 'formats.xpt' )

I get the message
   Error in read.xport("formats.xpt") : object 'w' not found
but there's no explanation about what 'w' is or how I should make it known 
to R. I certainly wasn't expecting to have to provide such a variable, 
unless I've overlooked something in the SASxport documentation.

This is using R version 3.1.0 under Windows 7, and SASxport installed this 
morning: version 1.5.0 (2014-07-21).

Any idea what this 'w' is that read.xport wants me to give it?

The .xpt file is confidential, so I can't make it available, and I don't 
know exactly what's in it. I suspect, however, that it may contain quite a 
bit of text. However, I'm pretty sure that its author used SAS correctly 
when generating it. Other files containing purely numeric data from the 
same author converted OK, using analogous calls to read.xport .

Googling the error didn't find anything.

Thanks,

Jocelyn Ireson-Paine
07768 534 091
http://www.jocelyns-cartoons.co.uk


From dmcp at webmail.co.za  Fri Jul 25 15:44:38 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Fri, 25 Jul 2014 15:44:38 +0200
Subject: [R] R function returning a list of variable(s) conditional on
 the value of an option?
In-Reply-To: <005b01cfa803$2b1f8d10$815ea730$@bigpond.com>
References: <005b01cfa803$2b1f8d10$815ea730$@bigpond.com>
Message-ID: <73cafb607361d1011f1ab80d7d9b972e@www.webmail.co.za>

I don't know about better or more elegant - but see inserts below...

Cheers.

On Fri, 25 Jul 2014 22:22:56 +1000 "Luke Hartigan" <luke.hartigan at bigpond.com>
wrote

> Dear all,
> 
> I have an R function which returns a list of variables; however, within the
> body of the function I would like to incorporate a branch based on a user
> selected option that will mean there will be one different variable to
> return based on the option value.
> 
> I was thinking of doing something like this (only an example):
> 
> foo <- function(x, y, option = TRUE)
> {
>     .
      rtn <- list(x = x, y = y)
>     If (option == TRUE) {
>     #    z = z
          rtn$z <- z
          return(rtn)
>     } else {
>     #    w = w
           rtn$w <- w
           return(rtn)
> }
> #    return(list(x = x, y = y, z = ifelse(option == TRUE, z, NA), w =
> # ifelse(option != TRUE, w, NA))
>     
> }
> 
> However, I was wondering if anyone else had a better idea/method which might
> be more elegant?
> 
> Many thanks,
> Luke
> 
> 
> 
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Cheapest Insurance Quotes!
https://www.outsurance.co.za/insurance-quote/personal/?source=msn&cr=Postit14_468x60_gif&cid=322


From petr.pikal at precheza.cz  Fri Jul 25 15:46:58 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 25 Jul 2014 13:46:58 +0000
Subject: [R] R function returning a list of variable(s) conditional on
 the	value of an option?
In-Reply-To: <005b01cfa803$2b1f8d10$815ea730$@bigpond.com>
References: <005b01cfa803$2b1f8d10$815ea730$@bigpond.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCBF6@SRVEXCHMBX.precheza.cz>

Hi

It is not exactly clear what do you want from your function.

foo <- function(x, y, option = TRUE)

in that cese you want to return list
x,y,z or x,y,z,w with w=NA

the same apply with
foo <- function(x, y, option = FALSE)

return is
x,y,w or x,y,z=NA,w?

anyway I would use option like that

{
x=x
y=y
z=NA
w=NA

if (option == TRUE) {

                z = z
return(x,y,z,w)
        } else {
                w = w
return(x,y,z,w)
}
}


Maybe different approach can be used but without clear description of objects x,y,z,w it is difficult to be more specific.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Luke Hartigan
> Sent: Friday, July 25, 2014 2:23 PM
> To: r-help at r-project.org
> Subject: [R] R function returning a list of variable(s) conditional on
> the value of an option?
>
> Dear all,
>
> I have an R function which returns a list of variables; however, within
> the body of the function I would like to incorporate a branch based on
> a user selected option that will mean there will be one different
> variable to return based on the option value.
>
> I was thinking of doing something like this (only an example):
>
> foo <- function(x, y, option = TRUE)
> {
>       .
>       If (option == TRUE) {
>               z = z
>       } else {
>               w = w
> }
>       return(list(x = x, y = y, z = ifelse(option == TRUE, z, NA), w =
> ifelse(option != TRUE, w, NA))
>
> }
>
> However, I was wondering if anyone else had a better idea/method which
> might be more elegant?
>
> Many thanks,
> Luke
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Fri Jul 25 16:03:20 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 25 Jul 2014 09:03:20 -0500
Subject: [R] Problem using ggplot2 with the legend of a stacked bar chart
In-Reply-To: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>
References: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>
Message-ID: <CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>

<sigh/>
Never mind. I had to specify the label in the "labs=()" portion of the
ggplot(). Why, if I'm going to "get it", do I "get it" only _after_ I
post?

On Fri, Jul 25, 2014 at 8:07 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> I am creating two graphs using ggplot2. The graphs are of the same
> data. One is a stacked bar chart. The other is a line graph. The code
> is below.
>
> <code>
> MSU_graph_m1   <- ggplot(cpprdald2_m1,aes(x=Int_Start,
>                                           y=LicPrLsys4HMSU,
>                                           fill=System_alias,
> #                                          color=System_alias,
>                                           ymax=LicPrLsys4HMSU_max))+
>                   theme(plot.title = element_text(size = rel(3),
> vjust=1, face="bold"),
>                         panel.grid.major = element_line(color="black",size=1),
>                         panel.grid.minor = element_line(color="black",size=1),
>                         legend.position="top",
>                         legend.direction="horizontal",
>                         legend.text = element_text(size=rel(1.5)),
>                         axis.line = element_line(size=3, color="black"),
>                         axis.text = element_text(angle=90, size=rel(0.9)),
>                         axis.title = element_text(size = rel(2)),
>                         axis.ticks = element_line(color="black")) +
>                   labs(x="Date and Time",y="MSUs",title=title)+
>
> guides(fill=guide_legend(reverse=TRUE,title="LPARs",direction="horizontal"))+
>                   scale_x_datetime(breaks = date_breaks('1 day'),
> minor_breaks=date_breaks('1 hour'),  labels=date_format("%b %d
> %H:%M")) +
>                   scale_y_continuous(breaks = seq(0,LicPrLsys4HMSU_max,5L)) +
>                   scale_fill_manual(values=c("yellow","blue")) ;
> MSU_graph_m1b  <- MSU_graph_m1+geom_bar(size=0.7,stat="identity");
> MSU_graph_m1l  <- MSU_graph_m1+geom_line(size=1.5);
> #
> </code>
>
> Now, if I use the "color=System_alias", the legend shows up where I
> want: on the top,  with the horizontal orientation, and labelled
> "LPARs". But I want the order reversed. Which I can't see how to do
> using this method. So I added the "guides=(fill..." line to reverse
> the legend. But now the legend is on the right, vertically oriented,
> and labelled "System_alias" (the variable name).
>
> I now have eye strain from looking at the vignettes and in the book "R
> Graphics Cookbook" and just can't figure out a way to get what I want.
>
> Now, using Rstudio, I examined what is in MSU_graph_m1. And saw a
> variable called "labels". This is a list containing more variables.
> Once of which is called "colour". That variable has the value of
> "System_alias". I found that if I set it to the value of "LPARs", then
> the legend has the proper title. But I don't like doing this sort of
> thing.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From mccormack at molbio.mgh.harvard.edu  Fri Jul 25 19:44:47 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Fri, 25 Jul 2014 13:44:47 -0400
Subject: [R] working on a data frame
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
	<53D1CBD7.7090108@molbio.mgh.harvard.edu>
	<ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>
Message-ID: <53D2978F.10808@molbio.mgh.harvard.edu>

Thank you for your comments, Peter.

A couple of questions.  Can I do something like the following ?

if
yourData[,8]==0,
then
yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]


I think I am just going to have to learn more about R. I thought getting 
into R would be like going from Perl to Python or Java etc., but it 
seems like R programming works differently.

Matthew


On 7/25/2014 12:06 AM, Peter Alspach wrote:
> Tena koe Matthew
>
> " Column 10 contains the result of the value in column 9 divided by the value in column 8. If the value in column 8==0, then the division can not be done, so  I want to change the zero to a one in order to do the division.".  That being the case, think in terms of vectors, as Sarah says.  Try:
>
> yourData[,10] <- yourData[,9]/yourData[,8]
> yourData[yourData[,8]==0,10] <- yourData[yourData[,8]==0,9]
>
> This doesn't change the 0 to 1 in column 8, but it doesn't appear you actually need to do that.
>
> HTH ....
>
> Peter Alspach
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Matthew McCormack
> Sent: Friday, 25 July 2014 3:16 p.m.
> To: Sarah Goslee
> Cc: r-help at r-project.org
> Subject: Re: [R] working on a data frame
>
>
> On 7/24/2014 8:52 PM, Sarah Goslee wrote:
>> Hi,
>>
>> Your description isn't clear:
>>
>> On Thursday, July 24, 2014, Matthew <mccormack at molbio.mgh.harvard.edu
>> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>>
>>      I am coming from the perspective of Excel and VBA scripts, but I
>>      would like to do the following in R.
>>
>>       I have a data frame with 14 columns and 32,795 rows.
>>
>>      I want to check the value in column 8 (row 1) to see if it is a 0.
>>      If it is not a zero, proceed to the next row and check the value
>>      for column 8.
>>      If it is a zero, then
>>      a) change the zero to a 1,
>>      b) divide the value in column 9 (row 1) by 1,
>>
>>
>> Row 1, or the row in which column 8 == 0?
> All rows in which the value in column 8==0.
>> Why do you want to divide by 1?
> Column 10 contains the result of the value in column 9 divided by the value in column 8. If the value in column 8==0, then the division can not be done, so  I want to change the zero to a one in order to do the division. This is a fairly standard thing to do with this data. (The data are measurements of amounts at two time points. Sometimes a thing will not be present in the beginning (0), but very present at the later time. Column 10 is the log2 of the change. Infinite is not an easy number to work with, so it is common to change the 0 to a 1. On the other hand, something may be present at time 1, but not at the later time. In this case column 10 would be taking the log2 of a number divided by 0, so again the zero is commonly changed to a one in order to get a useable value in column 10. In both the preceding cases there was a real change, but Inf and NaN are not helpful.)
>>      c) place the result in column 10 (row 1) and
>>
>>
>> Ditto on the row 1 question.
> I want to work on all rows where column 8 (and column 9) contain a zero.
> Column 10 contains the result of the value in column 9 divided by the value in column 8. So, for row 1, column 10 row 1 contains the ratio column 9 row 1 divided by column 8 row 1, and so on through the whole
> 32,000 or so rows.
>
> Most rows do not have a zero in columns 8 or 9. Some rows have  zero in column 8 only, and some rows have a zero in column 9 only. I want to get rid of the zeros in these two columns and then do the division to get a manageable value in column 10. Division by zero and Inf are not considered 'manageable' by me.
>> What do you want column 10 to be if column 8 isn't 0? Does it already
>> have a value. I suppose it must.
> Yes column 10 does have something, but this something can be Inf or NaN, which I want to get rid of.
>>      d) repeat this for each of the other 32,794 rows.
>>
>>      Is this possible with an R script, and is this the way to go about
>>      it. If it is, could anyone get me started ?
>>
>>
>> Assuming you want to put the new values in the rows where column 8 ==
>> 0, you can do it in two steps:
>>
>> mydata[,10] <- ifelse(mydata[,8] == 0, mydata[,9]/whatever,
>> mydata[,10]) #where whatever is the thing you want to divide by that
>> probably isn't 1 mydata[,8] <- ifelse(mydata[,8] == 0, 1, mydata[,8])
>>
>> R programming is best done by thinking about vectorizing things,
>> rather than doing them in loops. Reading the Intro to R that comes
>> with your installation is a good place to start.
> Would it be better to change the data frame into a matrix, or something else ?
> Thanks for your help.
>> Sarah
>>
>>
>>      Matthew
>>
>>
>>
>>
>> --
>> Sarah Goslee
>> http://www.stringpage.com
>> http://www.sarahgoslee.com
>> http://www.functionaldiversity.org
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be subject to legal privilege.
>   If you are not the intended recipient you must not use, disseminate, distribute or
>   reproduce all or any part of this e-mail or attachments.  If you have received this
>   e-mail in error, please notify the sender and delete all material pertaining to this
>   e-mail.  Any opinion or views expressed in this e-mail are those of the individual
>   sender and may not represent those of The New Zealand Institute for Plant and
>   Food Research Limited.
>


From wdunlap at tibco.com  Fri Jul 25 20:07:24 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 25 Jul 2014 11:07:24 -0700
Subject: [R] working on a data frame
In-Reply-To: <53D2978F.10808@molbio.mgh.harvard.edu>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>
	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
	<53D1CBD7.7090108@molbio.mgh.harvard.edu>
	<ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>
	<53D2978F.10808@molbio.mgh.harvard.edu>
Message-ID: <CAF8bMcaPVzeAQrEXvwqFeOAwTxSqsSK-T=JuJ-=nmFG4=GLB2g@mail.gmail.com>

> if
> yourData[,8]==0,
> then
> yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]

You could do express this in R as
   is8Zero <- yourData[,8] == 0
   yourData[is8Zero, 8] <- 1
   yourData[is8Zero, 10] <- yourData[is8Zero,9] / yourData[is8Zero,8]
Note how logical (Boolean) values are used as subscripts - read the '['
as 'such that' when using logical subscripts.

There are many more ways to express the same thing.

(I am tempted to change the algorithm to avoid the divide by zero problem
by making the quotient (numerator + epsilon)/(denominator + epsilon) where
epsilon is a very small number.  I am assuming that the raw numbers are
counts or at least cannot be negative.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jul 25, 2014 at 10:44 AM, Matthew
<mccormack at molbio.mgh.harvard.edu> wrote:
> Thank you for your comments, Peter.
>
> A couple of questions.  Can I do something like the following ?
>
> if
> yourData[,8]==0,
> then
> yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]
>
>
> I think I am just going to have to learn more about R. I thought getting
> into R would be like going from Perl to Python or Java etc., but it seems
> like R programming works differently.
>
> Matthew
>
>
> On 7/25/2014 12:06 AM, Peter Alspach wrote:
>>
>> Tena koe Matthew
>>
>> " Column 10 contains the result of the value in column 9 divided by the
>> value in column 8. If the value in column 8==0, then the division can not be
>> done, so  I want to change the zero to a one in order to do the division.".
>> That being the case, think in terms of vectors, as Sarah says.  Try:
>>
>> yourData[,10] <- yourData[,9]/yourData[,8]
>> yourData[yourData[,8]==0,10] <- yourData[yourData[,8]==0,9]
>>
>> This doesn't change the 0 to 1 in column 8, but it doesn't appear you
>> actually need to do that.
>>
>> HTH ....
>>
>> Peter Alspach
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Matthew McCormack
>> Sent: Friday, 25 July 2014 3:16 p.m.
>> To: Sarah Goslee
>> Cc: r-help at r-project.org
>> Subject: Re: [R] working on a data frame
>>
>>
>> On 7/24/2014 8:52 PM, Sarah Goslee wrote:
>>>
>>> Hi,
>>>
>>> Your description isn't clear:
>>>
>>> On Thursday, July 24, 2014, Matthew <mccormack at molbio.mgh.harvard.edu
>>> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>>>
>>>      I am coming from the perspective of Excel and VBA scripts, but I
>>>      would like to do the following in R.
>>>
>>>       I have a data frame with 14 columns and 32,795 rows.
>>>
>>>      I want to check the value in column 8 (row 1) to see if it is a 0.
>>>      If it is not a zero, proceed to the next row and check the value
>>>      for column 8.
>>>      If it is a zero, then
>>>      a) change the zero to a 1,
>>>      b) divide the value in column 9 (row 1) by 1,
>>>
>>>
>>> Row 1, or the row in which column 8 == 0?
>>
>> All rows in which the value in column 8==0.
>>>
>>> Why do you want to divide by 1?
>>
>> Column 10 contains the result of the value in column 9 divided by the
>> value in column 8. If the value in column 8==0, then the division can not be
>> done, so  I want to change the zero to a one in order to do the division.
>> This is a fairly standard thing to do with this data. (The data are
>> measurements of amounts at two time points. Sometimes a thing will not be
>> present in the beginning (0), but very present at the later time. Column 10
>> is the log2 of the change. Infinite is not an easy number to work with, so
>> it is common to change the 0 to a 1. On the other hand, something may be
>> present at time 1, but not at the later time. In this case column 10 would
>> be taking the log2 of a number divided by 0, so again the zero is commonly
>> changed to a one in order to get a useable value in column 10. In both the
>> preceding cases there was a real change, but Inf and NaN are not helpful.)
>>>
>>>      c) place the result in column 10 (row 1) and
>>>
>>>
>>> Ditto on the row 1 question.
>>
>> I want to work on all rows where column 8 (and column 9) contain a zero.
>> Column 10 contains the result of the value in column 9 divided by the
>> value in column 8. So, for row 1, column 10 row 1 contains the ratio column
>> 9 row 1 divided by column 8 row 1, and so on through the whole
>> 32,000 or so rows.
>>
>> Most rows do not have a zero in columns 8 or 9. Some rows have  zero in
>> column 8 only, and some rows have a zero in column 9 only. I want to get rid
>> of the zeros in these two columns and then do the division to get a
>> manageable value in column 10. Division by zero and Inf are not considered
>> 'manageable' by me.
>>>
>>> What do you want column 10 to be if column 8 isn't 0? Does it already
>>> have a value. I suppose it must.
>>
>> Yes column 10 does have something, but this something can be Inf or NaN,
>> which I want to get rid of.
>>>
>>>      d) repeat this for each of the other 32,794 rows.
>>>
>>>      Is this possible with an R script, and is this the way to go about
>>>      it. If it is, could anyone get me started ?
>>>
>>>
>>> Assuming you want to put the new values in the rows where column 8 ==
>>> 0, you can do it in two steps:
>>>
>>> mydata[,10] <- ifelse(mydata[,8] == 0, mydata[,9]/whatever,
>>> mydata[,10]) #where whatever is the thing you want to divide by that
>>> probably isn't 1 mydata[,8] <- ifelse(mydata[,8] == 0, 1, mydata[,8])
>>>
>>> R programming is best done by thinking about vectorizing things,
>>> rather than doing them in loops. Reading the Intro to R that comes
>>> with your installation is a good place to start.
>>
>> Would it be better to change the data frame into a matrix, or something
>> else ?
>> Thanks for your help.
>>>
>>> Sarah
>>>
>>>
>>>      Matthew
>>>
>>>
>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.stringpage.com
>>> http://www.sarahgoslee.com
>>> http://www.functionaldiversity.org
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> The contents of this e-mail are confidential and may be subject to legal
>> privilege.
>>   If you are not the intended recipient you must not use, disseminate,
>> distribute or
>>   reproduce all or any part of this e-mail or attachments.  If you have
>> received this
>>   e-mail in error, please notify the sender and delete all material
>> pertaining to this
>>   e-mail.  Any opinion or views expressed in this e-mail are those of the
>> individual
>>   sender and may not represent those of The New Zealand Institute for
>> Plant and
>>   Food Research Limited.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Jul 25 20:20:43 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 25 Jul 2014 13:20:43 -0500
Subject: [R] SASxport function read.xport gives error "object 'w' not
	found"
In-Reply-To: <alpine.LRH.2.02.1407251417410.28060@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1407251417410.28060@sphinx.mythic-beasts.com>
Message-ID: <AFBA800B-CC8E-4634-8359-D6B13A9C2835@me.com>

On Jul 25, 2014, at 8:26 AM, Jocelyn Ireson-Paine <popx at j-paine.org> wrote:

> The subject line says it. I've just tried converting an SAS .xpt file with this call:
>  > read.xport( 'formats.xpt' )
> 
> I get the message
>  Error in read.xport("formats.xpt") : object 'w' not found
> but there's no explanation about what 'w' is or how I should make it known to R. I certainly wasn't expecting to have to provide such a variable, unless I've overlooked something in the SASxport documentation.
> 
> This is using R version 3.1.0 under Windows 7, and SASxport installed this morning: version 1.5.0 (2014-07-21).
> 
> Any idea what this 'w' is that read.xport wants me to give it?
> 
> The .xpt file is confidential, so I can't make it available, and I don't know exactly what's in it. I suspect, however, that it may contain quite a bit of text. However, I'm pretty sure that its author used SAS correctly when generating it. Other files containing purely numeric data from the same author converted OK, using analogous calls to read.xport .
> 
> Googling the error didn't find anything.
> 
> Thanks,
> 
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.co.uk


Have you tried reading the file with the read.xport() function in the foreign package, which is part of the default R installation?

require(foreign)
?read.xport

I would start a fresh R session, just to be sure that the SASxport version is not used unintentionally.

There might be a bug in the SASxport version of the function, which apparently uses some of the foreign package version's code, or there might be something about your xpt file that is causing a problem. You may need to contact Greg, who is the package maintainer for SASxport, to get a sense from him as to what would trigger the error you are experiencing. Otherwise, you may have to trace through the code (see ?debug, for example) with your file and see if you can identify a trigger.

Regards,

Marc Schwartz


From sjkiss at gmail.com  Fri Jul 25 21:34:24 2014
From: sjkiss at gmail.com (Simon Kiss)
Date: Fri, 25 Jul 2014 15:34:24 -0400
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data
	Frame
Message-ID: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>

Hello:
I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 

Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
Thank you
Simon
#Reproducible code
mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))

mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9


From macqueen1 at llnl.gov  Fri Jul 25 22:13:09 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 25 Jul 2014 20:13:09 +0000
Subject: [R] Fwd: Converting Lat Lon data in coordinates in R
In-Reply-To: <CAFdg=fXU_Gh9eB=_h-qVu+7GOJWLRfUEA5dYBw0YEuJitJbqQg@mail.gmail.com>
References: <CAFdg=fVS+8_ZHsABYs1uj_7nav0_+-gEwnZWu8M6UxU8tHg-ZQ@mail.gmail.com>
	<CAFdg=fXU_Gh9eB=_h-qVu+7GOJWLRfUEA5dYBw0YEuJitJbqQg@mail.gmail.com>
Message-ID: <CFF80761.104335%macqueen1@llnl.gov>

The sp package has what you need.

spTransform() will convert from lat/lon to other coordinate systems.

char2dms() will convert lat/lon coordinates formatted as you have them
into numeric lat/lon values. You may wish to use
  as.numeric( char2dms(  [your data] ) )

It will take some effort to get your data structured so that spTransform()
will work with I.

And I suggest asking further questions on r-sig-geo.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/24/14, 11:11 PM, "Suparna Mitra" <suparna.mitra.sm at gmail.com> wrote:

>Hi
>?Hello
>,
>
>?Can anybody please let me know
> how can I convert Lat/Lon data in coordinates in R. I was trying to use
>the rgdal package
>? and proj4 package?
>. But being bit confused how to use S or N information.
>?and degree min second information.
>Any example help will be great.?
>My data looks like:
>  Latitude Longitude  22?54'57"S 47?08'50"W  22?49?38??S 47?03?49??W
>22?54'13"S 47?01'08"W  22?50'39"S 47?05'47"W  22?49'10"S 47?03'34"W
>3?5'47"S 59?59'24"W  2?55'47"S 59?58'32"W  40?49?20??N 77?49?58??W
>
> ?Thanks,
>
>Mitra
>
>	[[alternative HTML version deleted]]
>


From dcarlson at tamu.edu  Fri Jul 25 22:58:10 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 25 Jul 2014 20:58:10 +0000
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A
 Data	Frame
In-Reply-To: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>

I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.

> set.seed(42)
> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
+ "green", "yellow")))))
> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
> mydf2 <- data.frame(t(apply(mydf, 1, order)))
> colnames(mydf2) <- levels(mydf$rank1)
> head(mydf)
   rank1  rank2  rank3 rank4
1 yellow  green    red  blue
2  green   blue yellow   red
3  green yellow    red  blue
4 yellow    red  green  blue
5 yellow    red  green  blue
6 yellow    red   blue green
> head(mydf2)
  blue green red yellow
1    4     2   3      1
2    2     1   4      3
3    4     1   3      2
4    4     3   2      1
5    4     3   2      1
6    3     4   2      1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
Sent: Friday, July 25, 2014 2:34 PM
To: r-help at r-project.org
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame

Hello:
I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 

Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
Thank you
Simon
#Reproducible code
mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))

mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ross at biostat.ucsf.edu  Sat Jul 26 02:11:17 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 25 Jul 2014 17:11:17 -0700
Subject: [R] Redefining reference class makes persistent object partly
	unreadable
Message-ID: <1406333477.29001.290.camel@localhost>

A bunch of .rdata is on the disk, created from reference classes (as in
setRefClass()).  I redefined some of the classes--not by much.  Now when
I read in the rdata it seems to have been damaged, because some parts
have "disappeared".  The data are generally a graph of objects, some of
which (e.g., lists) are conventional rather than reference classes.

The specific  part that I noticed disappearing was actually a list
element.

The redefinition seemed quite minimal: no slots changed and the number
of methods did not change.  In some cases the name changed (from show to
summary) along with the definition, in other cases just the definition
of the function changed.

I've verified the crucial role of the code change by flipping between
different versions of the code.  R 3.0.3 on Debian GNU/Linux.

Context: I implemented a bunch of show reference class methods to
display my results.  Now I want to display them in other forms, and so
am trying to shift to returning a summary object.

Thanks.
Ross Boylan


From michel.arnaud at cirad.fr  Sat Jul 26 09:36:49 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sat, 26 Jul 2014 09:36:49 +0200
Subject: [R] Plotrix and twoord.plot with date on x-axe
In-Reply-To: <CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>
References: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>
	<CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>
Message-ID: <53D35A91.1090308@cirad.fr>

Hello

With package plotrix and  twoord.plot function, I would like to put the 
labels of the ticks values of x-axe which are date (
c("2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011 
Jan", "2012 Jan") with if possible, the angle of labels and x-axe = 40
Any idea ?

Thank you for your help

My dataframe is
TT <-
structure(list(x1 = structure(c(1L, 8L, 15L, 22L, 29L, 36L, 43L,
50L, 57L, 64L, 71L, 77L, 2L, 9L, 16L, 23L, 30L, 37L, 44L, 51L,
58L, 65L, 3L, 10L, 17L, 24L, 31L, 38L, 45L, 52L, 59L, 66L, 72L,
78L, 4L, 11L, 18L, 25L, 32L, 39L, 46L, 53L, 60L, 67L, 73L, 79L,
5L, 12L, 19L, 26L, 33L, 40L, 47L, 54L, 61L, 68L, 74L, 80L, 6L,
13L, 20L, 27L, 34L, 41L, 48L, 55L, 62L, 69L, 75L, 81L, 7L, 14L,
21L, 28L, 35L, 42L, 49L, 56L, 63L, 70L, 76L, 82L), .Label = c("01/01/2006",
"01/01/2007", "01/01/2008", "01/01/2009", "01/01/2010", "01/01/2011",
"01/01/2012", "01/02/2006", "01/02/2007", "01/02/2008", "01/02/2009",
"01/02/2010", "01/02/2011", "01/02/2012", "01/03/2006", "01/03/2007",
"01/03/2008", "01/03/2009", "01/03/2010", "01/03/2011", "01/03/2012",
"01/04/2006", "01/04/2007", "01/04/2008", "01/04/2009", "01/04/2010",
"01/04/2011", "01/04/2012", "01/05/2006", "01/05/2007", "01/05/2008",
"01/05/2009", "01/05/2010", "01/05/2011", "01/05/2012", "01/06/2006",
"01/06/2007", "01/06/2008", "01/06/2009", "01/06/2010", "01/06/2011",
"01/06/2012", "01/07/2006", "01/07/2007", "01/07/2008", "01/07/2009",
"01/07/2010", "01/07/2011", "01/07/2012", "01/08/2006", "01/08/2007",
"01/08/2008", "01/08/2009", "01/08/2010", "01/08/2011", "01/08/2012",
"01/09/2006", "01/09/2007", "01/09/2008", "01/09/2009", "01/09/2010",
"01/09/2011", "01/09/2012", "01/10/2006", "01/10/2007", "01/10/2008",
"01/10/2009", "01/10/2010", "01/10/2011", "01/10/2012", "01/11/2006",
"01/11/2008", "01/11/2009", "01/11/2010", "01/11/2011", "01/11/2012",
"01/12/2006", "01/12/2008", "01/12/2009", "01/12/2010", "01/12/2011",
"01/12/2012"), class = "factor"), y1 = c(2.592356082, 2.345800476,
0.583585821, 5.475129414, 5.475129414, 3.718656646, 3.089374967,
2.301938832, 2.937799758, 2.194943003, 2.54038668, NA, 1.644678741,
1.449029225, 0.956848412, 0.859023655, 0.987578146, 0.843738536,
1.247265662, 1.284694265, 0.980520409, 0.835670652, 0.566612694,
0.401453666, 0.439134806, 1.15846577, 0.687179049, 0.494573266,
0.96702963, 0.504182954, 1.03521455, 0.41886541, 0.401638417,
0.143972524, 0.84561927, 0.551221244, 0.916415951, 1.455635055,
2.866544524, 1.709780054, 1.846827755, 1.451262182, 0.807575275,
1.590211883, 1.542348196, 0.937123964, 1.399639685, 1.091996771,
1.404915044, 1.816230935, 1.468899879, 1.34414673, 1.480941894,
1.325698257, 1.462174427, 1.294317244, 1.348639226, 0.743242205,
1.326535615, 1.288495608, 0.825648931, 0.520199099, 0.631660841,
0.4838471, 0.514975576, 0.644832626, 0.789323515, 0.380945025,
0.386553999, 0.342014493, 0.351664055, 0.188006956, 0.238740258,
0.223667802, 0.063293682, 0.254889318, 0.324071093, 0.323446397,
0.291533728, 0.152346111, 0.429059919, 0.237783277), y2 = c(3.59979021,
3.760067114, 3.668671329, 4.08590604, 3.772684564, 3.833825503,
3.770872483, 3.801879195, 3.776442953, 3.807248322, 3.623087248,
3.85, 3.723986014, 3.67041958, 3.594405594, 3.595244755, 3.457832168,
3.582684564, 3.580839161, 3.555804196, 3.409060403, 3.39885906,
2.707342657, 2.483986014, 2.548881119, 2.797202797, 2.66034965,
2.792447552, 2.597482517, 2.243426573, 2.300629371, 2.323356643,
2.057832168, 2.142167832, 2.829300699, 2.45013986, 2.418531469,
2.77027972, 3.384335664, 3.32048951, 3.297762238, 3.008531469,
2.645034965, 2.965104895, 2.826853147, 2.747342657, 3.053986014,
3.327132867, 2.845874126, 2.961748252, 3.104335664, 3.076153846,
3.259090909, 3.08013986, 3.022727273, 3.016433566, 3.261468531,
2.942237762, 3.217972028, 2.904685315, 2.674755245, 2.436783217,
2.466853147, 2.557272727, 2.696853147, 3.308111888, 3.121468531,
3.144195804, 3.017132867, 3.069160839, 2.985384615, 2.661258741,
2.681188811, 2.746433566, 2.797202797, 2.666713287, 2.474335664,
2.769230769, 2.623356643, 2.764195804, 2.658391608, 2.665594406
), date = structure(1:82, .Label = c("2006-01-01", "2006-02-01",
"2006-03-01", "2006-04-01", "2006-05-01", "2006-06-01", "2006-07-01",
"2006-08-01", "2006-09-01", "2006-10-01", "2006-11-01", "2006-12-01",
"2007-01-01", "2007-02-01", "2007-03-01", "2007-04-01", "2007-05-01",
"2007-06-01", "2007-07-01", "2007-08-01", "2007-09-01", "2007-10-01",
"2008-01-01", "2008-02-01", "2008-03-01", "2008-04-01", "2008-05-01",
"2008-06-01", "2008-07-01", "2008-08-01", "2008-09-01", "2008-10-01",
"2008-11-01", "2008-12-01", "2009-01-01", "2009-02-01", "2009-03-01",
"2009-04-01", "2009-05-01", "2009-06-01", "2009-07-01", "2009-08-01",
"2009-09-01", "2009-10-01", "2009-11-01", "2009-12-01", "2010-01-01",
"2010-02-01", "2010-03-01", "2010-04-01", "2010-05-01", "2010-06-01",
"2010-07-01", "2010-08-01", "2010-09-01", "2010-10-01", "2010-11-01",
"2010-12-01", "2011-01-01", "2011-02-01", "2011-03-01", "2011-04-01",
"2011-05-01", "2011-06-01", "2011-07-01", "2011-08-01", "2011-09-01",
"2011-10-01", "2011-11-01", "2011-12-01", "2012-01-01", "2012-02-01",
"2012-03-01", "2012-04-01", "2012-05-01", "2012-06-01", "2012-07-01",
"2012-08-01", "2012-09-01", "2012-10-01", "2012-11-01", "2012-12-01"
), class = "factor"), datepos = structure(c(2L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 6L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 8L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("",
"2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011 Jan",
"2012 Jan"), class = "factor")), .Names = c("x1", "y1", "y2",
"date", "datepos"), row.names = c(1L, 5L, 6L, 7L, 8L, 9L, 10L,
11L, 12L, 2L, 3L, 4L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
22L, 14L, 23L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 24L, 25L,
26L, 35L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 36L, 37L, 38L,
47L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 48L, 49L, 50L, 59L,
63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 60L, 61L, 62L, 71L, 75L,
76L, 77L, 78L, 79L, 80L, 81L, 82L, 72L, 73L, 74L), class = "data.frame")

# My code is :
MinMaxr <- c(min(TT$y1, na.rm=TRUE), max(TT$y1, na.rm=TRUE))
MinMaxl <- c(min(TT$y2, na.rm=TRUE), max(TT$y2, na.rm=TRUE))

library(plotrix)
twoord.plot(
TT$date, TT$y1, TT$date, TT$y2,
lylim = MinMaxr, rylim = MinMaxl,
ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
do.first="plot_bg();grid(col=\"white\",lty=1)",
lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
xtickpos=TT$date, xticklab=TT$datepos)




-- 
Michel ARNAUD
port: 06.47.43.55.31


From jim at bitwrit.com.au  Sat Jul 26 12:16:37 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 26 Jul 2014 20:16:37 +1000
Subject: [R] Plotrix and twoord.plot with date on x-axe
In-Reply-To: <53D35A91.1090308@cirad.fr>
References: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>
	<CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>
	<53D35A91.1090308@cirad.fr>
Message-ID: <3499769.oi6pRBdCPr@localhost.localdomain>

On Sat, 26 Jul 2014 09:36:49 AM Arnaud Michel wrote:
> Hello
> 
> With package plotrix and  twoord.plot function, I would like to put the
> labels of the ticks values of x-axe which are date (
> c("2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011
> Jan", "2012 Jan") with if possible, the angle of labels and x-axe = 40
> Any idea ?
> 
> Thank you for your help
> 
> My dataframe is
> TT <-
> structure(list(x1 = structure(c(1L, 8L, 15L, 22L, 29L, 36L, 43L,
> 50L, 57L, 64L, 71L, 77L, 2L, 9L, 16L, 23L, 30L, 37L, 44L, 51L,
> 58L, 65L, 3L, 10L, 17L, 24L, 31L, 38L, 45L, 52L, 59L, 66L, 72L,
> 78L, 4L, 11L, 18L, 25L, 32L, 39L, 46L, 53L, 60L, 67L, 73L, 79L,
> 5L, 12L, 19L, 26L, 33L, 40L, 47L, 54L, 61L, 68L, 74L, 80L, 6L,
> 13L, 20L, 27L, 34L, 41L, 48L, 55L, 62L, 69L, 75L, 81L, 7L, 14L,
> 21L, 28L, 35L, 42L, 49L, 56L, 63L, 70L, 76L, 82L), .Label = 
c("01/01/2006",
> "01/01/2007", "01/01/2008", "01/01/2009", "01/01/2010", 
"01/01/2011",
> "01/01/2012", "01/02/2006", "01/02/2007", "01/02/2008", 
"01/02/2009",
> "01/02/2010", "01/02/2011", "01/02/2012", "01/03/2006", 
"01/03/2007",
> "01/03/2008", "01/03/2009", "01/03/2010", "01/03/2011", 
"01/03/2012",
> "01/04/2006", "01/04/2007", "01/04/2008", "01/04/2009", 
"01/04/2010",
> "01/04/2011", "01/04/2012", "01/05/2006", "01/05/2007", 
"01/05/2008",
> "01/05/2009", "01/05/2010", "01/05/2011", "01/05/2012", 
"01/06/2006",
> "01/06/2007", "01/06/2008", "01/06/2009", "01/06/2010", 
"01/06/2011",
> "01/06/2012", "01/07/2006", "01/07/2007", "01/07/2008", 
"01/07/2009",
> "01/07/2010", "01/07/2011", "01/07/2012", "01/08/2006", 
"01/08/2007",
> "01/08/2008", "01/08/2009", "01/08/2010", "01/08/2011", 
"01/08/2012",
> "01/09/2006", "01/09/2007", "01/09/2008", "01/09/2009", 
"01/09/2010",
> "01/09/2011", "01/09/2012", "01/10/2006", "01/10/2007", 
"01/10/2008",
> "01/10/2009", "01/10/2010", "01/10/2011", "01/10/2012", 
"01/11/2006",
> "01/11/2008", "01/11/2009", "01/11/2010", "01/11/2011", 
"01/11/2012",
> "01/12/2006", "01/12/2008", "01/12/2009", "01/12/2010", 
"01/12/2011",
> "01/12/2012"), class = "factor"), y1 = c(2.592356082, 2.345800476,
> 0.583585821, 5.475129414, 5.475129414, 3.718656646, 
3.089374967,
> 2.301938832, 2.937799758, 2.194943003, 2.54038668, NA, 
1.644678741,
> 1.449029225, 0.956848412, 0.859023655, 0.987578146, 
0.843738536,
> 1.247265662, 1.284694265, 0.980520409, 0.835670652, 
0.566612694,
> 0.401453666, 0.439134806, 1.15846577, 0.687179049, 
0.494573266,
> 0.96702963, 0.504182954, 1.03521455, 0.41886541, 0.401638417,
> 0.143972524, 0.84561927, 0.551221244, 0.916415951, 
1.455635055,
> 2.866544524, 1.709780054, 1.846827755, 1.451262182, 
0.807575275,
> 1.590211883, 1.542348196, 0.937123964, 1.399639685, 
1.091996771,
> 1.404915044, 1.816230935, 1.468899879, 1.34414673, 
1.480941894,
> 1.325698257, 1.462174427, 1.294317244, 1.348639226, 
0.743242205,
> 1.326535615, 1.288495608, 0.825648931, 0.520199099, 
0.631660841,
> 0.4838471, 0.514975576, 0.644832626, 0.789323515, 
0.380945025,
> 0.386553999, 0.342014493, 0.351664055, 0.188006956, 
0.238740258,
> 0.223667802, 0.063293682, 0.254889318, 0.324071093, 
0.323446397,
> 0.291533728, 0.152346111, 0.429059919, 0.237783277), y2 = 
c(3.59979021,
> 3.760067114, 3.668671329, 4.08590604, 3.772684564, 
3.833825503,
> 3.770872483, 3.801879195, 3.776442953, 3.807248322, 
3.623087248,
> 3.85, 3.723986014, 3.67041958, 3.594405594, 3.595244755, 
3.457832168,
> 3.582684564, 3.580839161, 3.555804196, 3.409060403, 
3.39885906,
> 2.707342657, 2.483986014, 2.548881119, 2.797202797, 
2.66034965,
> 2.792447552, 2.597482517, 2.243426573, 2.300629371, 
2.323356643,
> 2.057832168, 2.142167832, 2.829300699, 2.45013986, 
2.418531469,
> 2.77027972, 3.384335664, 3.32048951, 3.297762238, 
3.008531469,
> 2.645034965, 2.965104895, 2.826853147, 2.747342657, 
3.053986014,
> 3.327132867, 2.845874126, 2.961748252, 3.104335664, 
3.076153846,
> 3.259090909, 3.08013986, 3.022727273, 3.016433566, 
3.261468531,
> 2.942237762, 3.217972028, 2.904685315, 2.674755245, 
2.436783217,
> 2.466853147, 2.557272727, 2.696853147, 3.308111888, 
3.121468531,
> 3.144195804, 3.017132867, 3.069160839, 2.985384615, 
2.661258741,
> 2.681188811, 2.746433566, 2.797202797, 2.666713287, 
2.474335664,
> 2.769230769, 2.623356643, 2.764195804, 2.658391608, 
2.665594406
> ), date = structure(1:82, .Label = c("2006-01-01", "2006-02-01",
> "2006-03-01", "2006-04-01", "2006-05-01", "2006-06-01", 
"2006-07-01",
> "2006-08-01", "2006-09-01", "2006-10-01", "2006-11-01", 
"2006-12-01",
> "2007-01-01", "2007-02-01", "2007-03-01", "2007-04-01", 
"2007-05-01",
> "2007-06-01", "2007-07-01", "2007-08-01", "2007-09-01", 
"2007-10-01",
> "2008-01-01", "2008-02-01", "2008-03-01", "2008-04-01", 
"2008-05-01",
> "2008-06-01", "2008-07-01", "2008-08-01", "2008-09-01", 
"2008-10-01",
> "2008-11-01", "2008-12-01", "2009-01-01", "2009-02-01", 
"2009-03-01",
> "2009-04-01", "2009-05-01", "2009-06-01", "2009-07-01", 
"2009-08-01",
> "2009-09-01", "2009-10-01", "2009-11-01", "2009-12-01", 
"2010-01-01",
> "2010-02-01", "2010-03-01", "2010-04-01", "2010-05-01", 
"2010-06-01",
> "2010-07-01", "2010-08-01", "2010-09-01", "2010-10-01", 
"2010-11-01",
> "2010-12-01", "2011-01-01", "2011-02-01", "2011-03-01", 
"2011-04-01",
> "2011-05-01", "2011-06-01", "2011-07-01", "2011-08-01", 
"2011-09-01",
> "2011-10-01", "2011-11-01", "2011-12-01", "2012-01-01", 
"2012-02-01",
> "2012-03-01", "2012-04-01", "2012-05-01", "2012-06-01", 
"2012-07-01",
> "2012-08-01", "2012-09-01", "2012-10-01", "2012-11-01", 
"2012-12-01"
> ), class = "factor"), datepos = structure(c(2L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 6L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 8L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("",
> "2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011 Jan",
> "2012 Jan"), class = "factor")), .Names = c("x1", "y1", "y2",
> "date", "datepos"), row.names = c(1L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 2L, 3L, 4L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 14L, 23L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 24L, 25L,
> 26L, 35L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 36L, 37L, 38L,
> 47L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 48L, 49L, 50L, 59L,
> 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 60L, 61L, 62L, 71L, 75L,
> 76L, 77L, 78L, 79L, 80L, 81L, 82L, 72L, 73L, 74L), class = 
"data.frame")
> 
> # My code is :
> MinMaxr <- c(min(TT$y1, na.rm=TRUE), max(TT$y1, na.rm=TRUE))
> MinMaxl <- c(min(TT$y2, na.rm=TRUE), max(TT$y2, na.rm=TRUE))
> 
> library(plotrix)
> twoord.plot(
> TT$date, TT$y1, TT$date, TT$y2,
> lylim = MinMaxr, rylim = MinMaxl,
> ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
> do.first="plot_bg();grid(col=\"white\",lty=1)",
> lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
> xtickpos=TT$date, xticklab=TT$datepos)

Hi Arnaud,
Given your data, the easiest way is:

# change TT$date to a date object (it's a factor)
TT$date<-as.Date(TT$date,"%Y-%m-%d")
# use only the ticks that you want to appear
# but don't display the labels yet
twoord.plot(TT$date, TT$y1, TT$date, TT$y2,
 lylim = MinMaxr, rylim = MinMaxl,
 ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
 do.first="plot_bg();grid(col=\"white\",lty=1)",
 lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
 xtickpos=TT$date[c(1,13,23,35,47,59,71)],
 xticklab=rep("",7))
# display the rotated labels
staxlab(1,at=TT$date[c(1,13,23,35,47,59,71)],
 labels=TT$datepos[c(1,13,23,35,47,59,71)],srt=40)

Jim


From michel.arnaud at cirad.fr  Sat Jul 26 12:36:47 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sat, 26 Jul 2014 12:36:47 +0200
Subject: [R] Plotrix and twoord.plot with date on x-axe
In-Reply-To: <3499769.oi6pRBdCPr@localhost.localdomain>
References: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>	<CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>	<53D35A91.1090308@cirad.fr>
	<3499769.oi6pRBdCPr@localhost.localdomain>
Message-ID: <53D384BF.9030603@cirad.fr>

Perfect Jim, It's fine !
Michel

Le 26/07/2014 12:16, Jim Lemon a ?crit :
> On Sat, 26 Jul 2014 09:36:49 AM Arnaud Michel wrote:
>> Hello
>>
>> With package plotrix and  twoord.plot function, I would like to put the
>> labels of the ticks values of x-axe which are date (
>> c("2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011
>> Jan", "2012 Jan") with if possible, the angle of labels and x-axe = 40
>> Any idea ?
>>
>> Thank you for your help
>>
>> My dataframe is
>> TT <-
>> structure(list(x1 = structure(c(1L, 8L, 15L, 22L, 29L, 36L, 43L,
>> 50L, 57L, 64L, 71L, 77L, 2L, 9L, 16L, 23L, 30L, 37L, 44L, 51L,
>> 58L, 65L, 3L, 10L, 17L, 24L, 31L, 38L, 45L, 52L, 59L, 66L, 72L,
>> 78L, 4L, 11L, 18L, 25L, 32L, 39L, 46L, 53L, 60L, 67L, 73L, 79L,
>> 5L, 12L, 19L, 26L, 33L, 40L, 47L, 54L, 61L, 68L, 74L, 80L, 6L,
>> 13L, 20L, 27L, 34L, 41L, 48L, 55L, 62L, 69L, 75L, 81L, 7L, 14L,
>> 21L, 28L, 35L, 42L, 49L, 56L, 63L, 70L, 76L, 82L), .Label =
> c("01/01/2006",
>> "01/01/2007", "01/01/2008", "01/01/2009", "01/01/2010",
> "01/01/2011",
>> "01/01/2012", "01/02/2006", "01/02/2007", "01/02/2008",
> "01/02/2009",
>> "01/02/2010", "01/02/2011", "01/02/2012", "01/03/2006",
> "01/03/2007",
>> "01/03/2008", "01/03/2009", "01/03/2010", "01/03/2011",
> "01/03/2012",
>> "01/04/2006", "01/04/2007", "01/04/2008", "01/04/2009",
> "01/04/2010",
>> "01/04/2011", "01/04/2012", "01/05/2006", "01/05/2007",
> "01/05/2008",
>> "01/05/2009", "01/05/2010", "01/05/2011", "01/05/2012",
> "01/06/2006",
>> "01/06/2007", "01/06/2008", "01/06/2009", "01/06/2010",
> "01/06/2011",
>> "01/06/2012", "01/07/2006", "01/07/2007", "01/07/2008",
> "01/07/2009",
>> "01/07/2010", "01/07/2011", "01/07/2012", "01/08/2006",
> "01/08/2007",
>> "01/08/2008", "01/08/2009", "01/08/2010", "01/08/2011",
> "01/08/2012",
>> "01/09/2006", "01/09/2007", "01/09/2008", "01/09/2009",
> "01/09/2010",
>> "01/09/2011", "01/09/2012", "01/10/2006", "01/10/2007",
> "01/10/2008",
>> "01/10/2009", "01/10/2010", "01/10/2011", "01/10/2012",
> "01/11/2006",
>> "01/11/2008", "01/11/2009", "01/11/2010", "01/11/2011",
> "01/11/2012",
>> "01/12/2006", "01/12/2008", "01/12/2009", "01/12/2010",
> "01/12/2011",
>> "01/12/2012"), class = "factor"), y1 = c(2.592356082, 2.345800476,
>> 0.583585821, 5.475129414, 5.475129414, 3.718656646,
> 3.089374967,
>> 2.301938832, 2.937799758, 2.194943003, 2.54038668, NA,
> 1.644678741,
>> 1.449029225, 0.956848412, 0.859023655, 0.987578146,
> 0.843738536,
>> 1.247265662, 1.284694265, 0.980520409, 0.835670652,
> 0.566612694,
>> 0.401453666, 0.439134806, 1.15846577, 0.687179049,
> 0.494573266,
>> 0.96702963, 0.504182954, 1.03521455, 0.41886541, 0.401638417,
>> 0.143972524, 0.84561927, 0.551221244, 0.916415951,
> 1.455635055,
>> 2.866544524, 1.709780054, 1.846827755, 1.451262182,
> 0.807575275,
>> 1.590211883, 1.542348196, 0.937123964, 1.399639685,
> 1.091996771,
>> 1.404915044, 1.816230935, 1.468899879, 1.34414673,
> 1.480941894,
>> 1.325698257, 1.462174427, 1.294317244, 1.348639226,
> 0.743242205,
>> 1.326535615, 1.288495608, 0.825648931, 0.520199099,
> 0.631660841,
>> 0.4838471, 0.514975576, 0.644832626, 0.789323515,
> 0.380945025,
>> 0.386553999, 0.342014493, 0.351664055, 0.188006956,
> 0.238740258,
>> 0.223667802, 0.063293682, 0.254889318, 0.324071093,
> 0.323446397,
>> 0.291533728, 0.152346111, 0.429059919, 0.237783277), y2 =
> c(3.59979021,
>> 3.760067114, 3.668671329, 4.08590604, 3.772684564,
> 3.833825503,
>> 3.770872483, 3.801879195, 3.776442953, 3.807248322,
> 3.623087248,
>> 3.85, 3.723986014, 3.67041958, 3.594405594, 3.595244755,
> 3.457832168,
>> 3.582684564, 3.580839161, 3.555804196, 3.409060403,
> 3.39885906,
>> 2.707342657, 2.483986014, 2.548881119, 2.797202797,
> 2.66034965,
>> 2.792447552, 2.597482517, 2.243426573, 2.300629371,
> 2.323356643,
>> 2.057832168, 2.142167832, 2.829300699, 2.45013986,
> 2.418531469,
>> 2.77027972, 3.384335664, 3.32048951, 3.297762238,
> 3.008531469,
>> 2.645034965, 2.965104895, 2.826853147, 2.747342657,
> 3.053986014,
>> 3.327132867, 2.845874126, 2.961748252, 3.104335664,
> 3.076153846,
>> 3.259090909, 3.08013986, 3.022727273, 3.016433566,
> 3.261468531,
>> 2.942237762, 3.217972028, 2.904685315, 2.674755245,
> 2.436783217,
>> 2.466853147, 2.557272727, 2.696853147, 3.308111888,
> 3.121468531,
>> 3.144195804, 3.017132867, 3.069160839, 2.985384615,
> 2.661258741,
>> 2.681188811, 2.746433566, 2.797202797, 2.666713287,
> 2.474335664,
>> 2.769230769, 2.623356643, 2.764195804, 2.658391608,
> 2.665594406
>> ), date = structure(1:82, .Label = c("2006-01-01", "2006-02-01",
>> "2006-03-01", "2006-04-01", "2006-05-01", "2006-06-01",
> "2006-07-01",
>> "2006-08-01", "2006-09-01", "2006-10-01", "2006-11-01",
> "2006-12-01",
>> "2007-01-01", "2007-02-01", "2007-03-01", "2007-04-01",
> "2007-05-01",
>> "2007-06-01", "2007-07-01", "2007-08-01", "2007-09-01",
> "2007-10-01",
>> "2008-01-01", "2008-02-01", "2008-03-01", "2008-04-01",
> "2008-05-01",
>> "2008-06-01", "2008-07-01", "2008-08-01", "2008-09-01",
> "2008-10-01",
>> "2008-11-01", "2008-12-01", "2009-01-01", "2009-02-01",
> "2009-03-01",
>> "2009-04-01", "2009-05-01", "2009-06-01", "2009-07-01",
> "2009-08-01",
>> "2009-09-01", "2009-10-01", "2009-11-01", "2009-12-01",
> "2010-01-01",
>> "2010-02-01", "2010-03-01", "2010-04-01", "2010-05-01",
> "2010-06-01",
>> "2010-07-01", "2010-08-01", "2010-09-01", "2010-10-01",
> "2010-11-01",
>> "2010-12-01", "2011-01-01", "2011-02-01", "2011-03-01",
> "2011-04-01",
>> "2011-05-01", "2011-06-01", "2011-07-01", "2011-08-01",
> "2011-09-01",
>> "2011-10-01", "2011-11-01", "2011-12-01", "2012-01-01",
> "2012-02-01",
>> "2012-03-01", "2012-04-01", "2012-05-01", "2012-06-01",
> "2012-07-01",
>> "2012-08-01", "2012-09-01", "2012-10-01", "2012-11-01",
> "2012-12-01"
>> ), class = "factor"), datepos = structure(c(2L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 6L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 8L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("",
>> "2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011 Jan",
>> "2012 Jan"), class = "factor")), .Names = c("x1", "y1", "y2",
>> "date", "datepos"), row.names = c(1L, 5L, 6L, 7L, 8L, 9L, 10L,
>> 11L, 12L, 2L, 3L, 4L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
>> 22L, 14L, 23L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 24L, 25L,
>> 26L, 35L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 36L, 37L, 38L,
>> 47L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 48L, 49L, 50L, 59L,
>> 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 60L, 61L, 62L, 71L, 75L,
>> 76L, 77L, 78L, 79L, 80L, 81L, 82L, 72L, 73L, 74L), class =
> "data.frame")
>> # My code is :
>> MinMaxr <- c(min(TT$y1, na.rm=TRUE), max(TT$y1, na.rm=TRUE))
>> MinMaxl <- c(min(TT$y2, na.rm=TRUE), max(TT$y2, na.rm=TRUE))
>>
>> library(plotrix)
>> twoord.plot(
>> TT$date, TT$y1, TT$date, TT$y2,
>> lylim = MinMaxr, rylim = MinMaxl,
>> ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
>> do.first="plot_bg();grid(col=\"white\",lty=1)",
>> lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
>> xtickpos=TT$date, xticklab=TT$datepos)
> Hi Arnaud,
> Given your data, the easiest way is:
>
> # change TT$date to a date object (it's a factor)
> TT$date<-as.Date(TT$date,"%Y-%m-%d")
> # use only the ticks that you want to appear
> # but don't display the labels yet
> twoord.plot(TT$date, TT$y1, TT$date, TT$y2,
>   lylim = MinMaxr, rylim = MinMaxl,
>   ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
>   do.first="plot_bg();grid(col=\"white\",lty=1)",
>   lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
>   xtickpos=TT$date[c(1,13,23,35,47,59,71)],
>   xticklab=rep("",7))
> # display the rotated labels
> staxlab(1,at=TT$date[c(1,13,23,35,47,59,71)],
>   labels=TT$datepos[c(1,13,23,35,47,59,71)],srt=40)
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD


From michel.arnaud at cirad.fr  Sat Jul 26 12:37:01 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sat, 26 Jul 2014 12:37:01 +0200
Subject: [R] Plotrix and twoord.plot with date on x-axe
In-Reply-To: <3499769.oi6pRBdCPr@localhost.localdomain>
References: <CAAJSdjgOcn28oY_iZg4i+v4snmkHq6Fn5r-9Uawas=fUsf_msw@mail.gmail.com>	<CAAJSdjgB-eZRN+c+aiEMin-Fe9DsqSNq-Meu2XDfCXdnZzpMRg@mail.gmail.com>	<53D35A91.1090308@cirad.fr>
	<3499769.oi6pRBdCPr@localhost.localdomain>
Message-ID: <53D384CD.5020403@cirad.fr>

Perfect Jim, It's fine !
Thank you
Michel

Le 26/07/2014 12:16, Jim Lemon a ?crit :
> On Sat, 26 Jul 2014 09:36:49 AM Arnaud Michel wrote:
>> Hello
>>
>> With package plotrix and  twoord.plot function, I would like to put the
>> labels of the ticks values of x-axe which are date (
>> c("2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011
>> Jan", "2012 Jan") with if possible, the angle of labels and x-axe = 40
>> Any idea ?
>>
>> Thank you for your help
>>
>> My dataframe is
>> TT <-
>> structure(list(x1 = structure(c(1L, 8L, 15L, 22L, 29L, 36L, 43L,
>> 50L, 57L, 64L, 71L, 77L, 2L, 9L, 16L, 23L, 30L, 37L, 44L, 51L,
>> 58L, 65L, 3L, 10L, 17L, 24L, 31L, 38L, 45L, 52L, 59L, 66L, 72L,
>> 78L, 4L, 11L, 18L, 25L, 32L, 39L, 46L, 53L, 60L, 67L, 73L, 79L,
>> 5L, 12L, 19L, 26L, 33L, 40L, 47L, 54L, 61L, 68L, 74L, 80L, 6L,
>> 13L, 20L, 27L, 34L, 41L, 48L, 55L, 62L, 69L, 75L, 81L, 7L, 14L,
>> 21L, 28L, 35L, 42L, 49L, 56L, 63L, 70L, 76L, 82L), .Label =
> c("01/01/2006",
>> "01/01/2007", "01/01/2008", "01/01/2009", "01/01/2010",
> "01/01/2011",
>> "01/01/2012", "01/02/2006", "01/02/2007", "01/02/2008",
> "01/02/2009",
>> "01/02/2010", "01/02/2011", "01/02/2012", "01/03/2006",
> "01/03/2007",
>> "01/03/2008", "01/03/2009", "01/03/2010", "01/03/2011",
> "01/03/2012",
>> "01/04/2006", "01/04/2007", "01/04/2008", "01/04/2009",
> "01/04/2010",
>> "01/04/2011", "01/04/2012", "01/05/2006", "01/05/2007",
> "01/05/2008",
>> "01/05/2009", "01/05/2010", "01/05/2011", "01/05/2012",
> "01/06/2006",
>> "01/06/2007", "01/06/2008", "01/06/2009", "01/06/2010",
> "01/06/2011",
>> "01/06/2012", "01/07/2006", "01/07/2007", "01/07/2008",
> "01/07/2009",
>> "01/07/2010", "01/07/2011", "01/07/2012", "01/08/2006",
> "01/08/2007",
>> "01/08/2008", "01/08/2009", "01/08/2010", "01/08/2011",
> "01/08/2012",
>> "01/09/2006", "01/09/2007", "01/09/2008", "01/09/2009",
> "01/09/2010",
>> "01/09/2011", "01/09/2012", "01/10/2006", "01/10/2007",
> "01/10/2008",
>> "01/10/2009", "01/10/2010", "01/10/2011", "01/10/2012",
> "01/11/2006",
>> "01/11/2008", "01/11/2009", "01/11/2010", "01/11/2011",
> "01/11/2012",
>> "01/12/2006", "01/12/2008", "01/12/2009", "01/12/2010",
> "01/12/2011",
>> "01/12/2012"), class = "factor"), y1 = c(2.592356082, 2.345800476,
>> 0.583585821, 5.475129414, 5.475129414, 3.718656646,
> 3.089374967,
>> 2.301938832, 2.937799758, 2.194943003, 2.54038668, NA,
> 1.644678741,
>> 1.449029225, 0.956848412, 0.859023655, 0.987578146,
> 0.843738536,
>> 1.247265662, 1.284694265, 0.980520409, 0.835670652,
> 0.566612694,
>> 0.401453666, 0.439134806, 1.15846577, 0.687179049,
> 0.494573266,
>> 0.96702963, 0.504182954, 1.03521455, 0.41886541, 0.401638417,
>> 0.143972524, 0.84561927, 0.551221244, 0.916415951,
> 1.455635055,
>> 2.866544524, 1.709780054, 1.846827755, 1.451262182,
> 0.807575275,
>> 1.590211883, 1.542348196, 0.937123964, 1.399639685,
> 1.091996771,
>> 1.404915044, 1.816230935, 1.468899879, 1.34414673,
> 1.480941894,
>> 1.325698257, 1.462174427, 1.294317244, 1.348639226,
> 0.743242205,
>> 1.326535615, 1.288495608, 0.825648931, 0.520199099,
> 0.631660841,
>> 0.4838471, 0.514975576, 0.644832626, 0.789323515,
> 0.380945025,
>> 0.386553999, 0.342014493, 0.351664055, 0.188006956,
> 0.238740258,
>> 0.223667802, 0.063293682, 0.254889318, 0.324071093,
> 0.323446397,
>> 0.291533728, 0.152346111, 0.429059919, 0.237783277), y2 =
> c(3.59979021,
>> 3.760067114, 3.668671329, 4.08590604, 3.772684564,
> 3.833825503,
>> 3.770872483, 3.801879195, 3.776442953, 3.807248322,
> 3.623087248,
>> 3.85, 3.723986014, 3.67041958, 3.594405594, 3.595244755,
> 3.457832168,
>> 3.582684564, 3.580839161, 3.555804196, 3.409060403,
> 3.39885906,
>> 2.707342657, 2.483986014, 2.548881119, 2.797202797,
> 2.66034965,
>> 2.792447552, 2.597482517, 2.243426573, 2.300629371,
> 2.323356643,
>> 2.057832168, 2.142167832, 2.829300699, 2.45013986,
> 2.418531469,
>> 2.77027972, 3.384335664, 3.32048951, 3.297762238,
> 3.008531469,
>> 2.645034965, 2.965104895, 2.826853147, 2.747342657,
> 3.053986014,
>> 3.327132867, 2.845874126, 2.961748252, 3.104335664,
> 3.076153846,
>> 3.259090909, 3.08013986, 3.022727273, 3.016433566,
> 3.261468531,
>> 2.942237762, 3.217972028, 2.904685315, 2.674755245,
> 2.436783217,
>> 2.466853147, 2.557272727, 2.696853147, 3.308111888,
> 3.121468531,
>> 3.144195804, 3.017132867, 3.069160839, 2.985384615,
> 2.661258741,
>> 2.681188811, 2.746433566, 2.797202797, 2.666713287,
> 2.474335664,
>> 2.769230769, 2.623356643, 2.764195804, 2.658391608,
> 2.665594406
>> ), date = structure(1:82, .Label = c("2006-01-01", "2006-02-01",
>> "2006-03-01", "2006-04-01", "2006-05-01", "2006-06-01",
> "2006-07-01",
>> "2006-08-01", "2006-09-01", "2006-10-01", "2006-11-01",
> "2006-12-01",
>> "2007-01-01", "2007-02-01", "2007-03-01", "2007-04-01",
> "2007-05-01",
>> "2007-06-01", "2007-07-01", "2007-08-01", "2007-09-01",
> "2007-10-01",
>> "2008-01-01", "2008-02-01", "2008-03-01", "2008-04-01",
> "2008-05-01",
>> "2008-06-01", "2008-07-01", "2008-08-01", "2008-09-01",
> "2008-10-01",
>> "2008-11-01", "2008-12-01", "2009-01-01", "2009-02-01",
> "2009-03-01",
>> "2009-04-01", "2009-05-01", "2009-06-01", "2009-07-01",
> "2009-08-01",
>> "2009-09-01", "2009-10-01", "2009-11-01", "2009-12-01",
> "2010-01-01",
>> "2010-02-01", "2010-03-01", "2010-04-01", "2010-05-01",
> "2010-06-01",
>> "2010-07-01", "2010-08-01", "2010-09-01", "2010-10-01",
> "2010-11-01",
>> "2010-12-01", "2011-01-01", "2011-02-01", "2011-03-01",
> "2011-04-01",
>> "2011-05-01", "2011-06-01", "2011-07-01", "2011-08-01",
> "2011-09-01",
>> "2011-10-01", "2011-11-01", "2011-12-01", "2012-01-01",
> "2012-02-01",
>> "2012-03-01", "2012-04-01", "2012-05-01", "2012-06-01",
> "2012-07-01",
>> "2012-08-01", "2012-09-01", "2012-10-01", "2012-11-01",
> "2012-12-01"
>> ), class = "factor"), datepos = structure(c(2L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 6L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 8L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("",
>> "2006 Jan", "2007 Jan", "2008 Jan", "2009 Jan", "2010 Jan", "2011 Jan",
>> "2012 Jan"), class = "factor")), .Names = c("x1", "y1", "y2",
>> "date", "datepos"), row.names = c(1L, 5L, 6L, 7L, 8L, 9L, 10L,
>> 11L, 12L, 2L, 3L, 4L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
>> 22L, 14L, 23L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 24L, 25L,
>> 26L, 35L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 36L, 37L, 38L,
>> 47L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 48L, 49L, 50L, 59L,
>> 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 60L, 61L, 62L, 71L, 75L,
>> 76L, 77L, 78L, 79L, 80L, 81L, 82L, 72L, 73L, 74L), class =
> "data.frame")
>> # My code is :
>> MinMaxr <- c(min(TT$y1, na.rm=TRUE), max(TT$y1, na.rm=TRUE))
>> MinMaxl <- c(min(TT$y2, na.rm=TRUE), max(TT$y2, na.rm=TRUE))
>>
>> library(plotrix)
>> twoord.plot(
>> TT$date, TT$y1, TT$date, TT$y2,
>> lylim = MinMaxr, rylim = MinMaxl,
>> ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
>> do.first="plot_bg();grid(col=\"white\",lty=1)",
>> lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
>> xtickpos=TT$date, xticklab=TT$datepos)
> Hi Arnaud,
> Given your data, the easiest way is:
>
> # change TT$date to a date object (it's a factor)
> TT$date<-as.Date(TT$date,"%Y-%m-%d")
> # use only the ticks that you want to appear
> # but don't display the labels yet
> twoord.plot(TT$date, TT$y1, TT$date, TT$y2,
>   lylim = MinMaxr, rylim = MinMaxl,
>   ylab="YLlab", rylab="YRlab", lcol=2,rcol=4,
>   do.first="plot_bg();grid(col=\"white\",lty=1)",
>   lpch=18, rpch=20, axislab.cex=0.8, cex.main=2,
>   xtickpos=TT$date[c(1,13,23,35,47,59,71)],
>   xticklab=rep("",7))
> # display the rotated labels
> staxlab(1,at=TT$date[c(1,13,23,35,47,59,71)],
>   labels=TT$datepos[c(1,13,23,35,47,59,71)],srt=40)
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD


From wht_crl at yahoo.com  Fri Jul 25 14:42:57 2014
From: wht_crl at yahoo.com (carol white)
Date: Fri, 25 Jul 2014 05:42:57 -0700
Subject: [R] selection of probes, probesets mapping to the same gene
Message-ID: <1406292177.67597.YahooMailNeo@web121503.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/2afd24d2/attachment.pl>

From sowmyar at vegainvtech.com  Fri Jul 25 15:24:44 2014
From: sowmyar at vegainvtech.com (Sowmya Rudregowda)
Date: Fri, 25 Jul 2014 18:54:44 +0530
Subject: [R] Fwd: Need help in finding ppval function and xirr function of
 matlab in R
Message-ID: <CAGEzm4LgtRTKtsBDkGo5kout0+4t1dR_8Q_bca8w8Tot4K150g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/20a56a4b/attachment.pl>

From pierre.lindenbaum at univ-nantes.fr  Fri Jul 25 16:07:28 2014
From: pierre.lindenbaum at univ-nantes.fr (Pierre Lindenbaum)
Date: Fri, 25 Jul 2014 16:07:28 +0200
Subject: [R] R and external C library " cannot open shared object file"
 while LD_LIBRARY_PATH is set
Message-ID: <53D264A0.7030500@univ-nantes.fr>

( cross-posted on SO: http://stackoverflow.com/questions/24955829/ )

I'm building a C extension for R, this library also uses the HDF5 library.

I compiled a dynamic library (gcc flags: -fPIC -shared 
-Wl,-soname,libmy.so -o ../lib/libmy.so in a 'lib' directory:

$ file /path/to/my/lib/libmy.so

      /path/to/my/lib/libmy.so: ELF 64-bit LSB shared object, AMD 
x86-64, version 1 (SYSV), not stripped

LD_LIBRARY_PATH is set:

       $ echo $LD_LIBRARY_PATH
      path/to/hdf5/lib:/path/to/my/lib

and now when I want to load my library in R from the directory 
/path/to/my/src

      dyn.load("libmy.so")

I get the following error:

      Error in dyn.load("libmy.so") :
        unable to load shared object '/path/to/my/src/libmy.so':
        /path/to/my/src/libmy.so: cannot open shared object file: No 
such file or directory
      Execution halted

If libmy.so is moved to my current working directory (I don't want this)

       mv ../lib/libmy.so ./

the library seems to be loaded but R is still missing the symbols from 
the hdf5 library:

      Error in dyn.load("libmy.so") :
        unable to load shared object ' /path/to/my/src/libmy.so':
        /path/to/my/src/libmy.so: undefined symbol: H5T_C_S1_g
      Execution halted

I also tried load("my.so") instead of "libmy.so".

How can I load my dynamic library ?

Thanks
Pierre


From f_j_rod at hotmail.com  Fri Jul 25 18:26:15 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Fri, 25 Jul 2014 18:26:15 +0200
Subject: [R] Determine all specific same dates between two given dates
Message-ID: <BAY168-W66AAAB5D997CB754F9D9BABAFC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/30d36a89/attachment.pl>

From ghonke1 at binghamton.edu  Fri Jul 25 19:20:55 2014
From: ghonke1 at binghamton.edu (garrett honke)
Date: Fri, 25 Jul 2014 13:20:55 -0400
Subject: [R]  Multiple imputation, multinomial response & random effects
Message-ID: <CAGuVH4KrbNvTbpoh7D+ThQmy1PUca0px-kMJi=jz8kbsHXz6+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/9db134ef/attachment.pl>

From brucewmorlan at gmail.com  Fri Jul 25 21:11:41 2014
From: brucewmorlan at gmail.com (Bruce.W Morlan)
Date: Fri, 25 Jul 2014 14:11:41 -0500
Subject: [R]  Reproducibility issue in gbm (32 vs 64 bit)
Message-ID: <CAFKXHWS-vfYFJLrigyFyhHfFbjcrM95Sw5hHZ2GTMmJ=+QYG+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140725/2b777670/attachment.pl>

From florian.ryan at aim.com  Sat Jul 26 14:29:59 2014
From: florian.ryan at aim.com (Florian Ryan)
Date: Sat, 26 Jul 2014 08:29:59 -0400 (EDT)
Subject: [R] Function assignment
Message-ID: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140726/87bfb55b/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Jul 26 15:44:53 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 26 Jul 2014 15:44:53 +0200
Subject: [R] Fwd: Need help in finding ppval function and xirr function
 of matlab in R
In-Reply-To: <CAGEzm4LgtRTKtsBDkGo5kout0+4t1dR_8Q_bca8w8Tot4K150g@mail.gmail.com>
References: <CAGEzm4LgtRTKtsBDkGo5kout0+4t1dR_8Q_bca8w8Tot4K150g@mail.gmail.com>
Message-ID: <53D3B0D5.5020404@statistik.tu-dortmund.de>



On 25.07.2014 15:24, Sowmya Rudregowda wrote:
> Hi,
>
> I am new to R language.Am writing matlab calculations in R language.
> I am searching for functions in R which are equivalent to matlab.
> So, i am not finding equivalent ppval() and xirr() of matlab in R.


And most of us are new to matlab and do not know what ppval and xirr are 
doing.
So perhaps someone is willing to help if you describe what the functions 
should do you are looking for (and in that case Google and friends may 
also be able to help).

Best,
Uwe Ligges




> Please help me in finding the functions.
>
> Thank you
> SowmyaR
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Jul 26 16:07:46 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 26 Jul 2014 16:07:46 +0200
Subject: [R] Determine all specific same dates between two given dates
In-Reply-To: <BAY168-W66AAAB5D997CB754F9D9BABAFC0@phx.gbl>
References: <BAY168-W66AAAB5D997CB754F9D9BABAFC0@phx.gbl>
Message-ID: <53D3B632.8060401@statistik.tu-dortmund.de>



On 25.07.2014 18:26, Frank S. wrote:
> Hi everyone, After trying to find the solution during days, I decided to write in this help list in order to ask  if anyone can help me.I would want to construct an R function, with  "initial", "final" and "specific" dates as 3 arguments (for example, becauseI'm not really sure it is the best way), which returns a vector "v" containing all the specific same dates between the given "initial" and "final" dates (so the vector will contain only the specific date as many times as it appears inside the reference period). The function could have this aspect: myfun <- function(initial=as.Date("initial"), final=as.Date("final"),                             day_specific=day, month_specific=month)                                               { ....                     return(v)                    } Example of what I'm trying to explain: Let's say I want to obtain all the dates 25st September contained between initial="05-07-1990" and final="19-03-1998": myfun (initial=as.Date("05-07-1!
>   998"), final=as.Date("19-03-2003"),             day_specific=25, month_specific=9) The result I would expect is: v = c ("25-09-1998", "25-09-1999", "25-09-2000", "25-09-2001", "25-09-2002") Please, if somebody has any idea how to do the function, it will help me a lot. Thanks in advance!   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


Your mail is messed up (no HTML mails please!)

Many solutions, one may be:

myfun <- function(initial, final, day_specific, month_specific){
     v <- as.Date(paste(format(c(initial, final), "%Y"), month_specific, 
day_specific, sep="-"))
     v <- seq(v[1], v[2], by = "year")
     v[v >= initial & v <= final]
}

initial <- as.Date("05-07-1998", "%d-%m-%Y")
final <- as.Date("19-03-2003", "%d-%m-%Y")
day_specific <- 25
month_specific <- 9

myfun(initial, final, day_specific, month_specific)


From john.archie.mckown at gmail.com  Sat Jul 26 16:37:48 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 26 Jul 2014 09:37:48 -0500
Subject: [R] R and external C library " cannot open shared object file"
 while LD_LIBRARY_PATH is set
In-Reply-To: <53D264A0.7030500@univ-nantes.fr>
References: <53D264A0.7030500@univ-nantes.fr>
Message-ID: <CAAJSdjjZ5E6oyc6PVPx_ffejsLQhmg1hmRKveR0spQSjHR9AqA@mail.gmail.com>

On Fri, Jul 25, 2014 at 9:07 AM, Pierre Lindenbaum
<pierre.lindenbaum at univ-nantes.fr> wrote:
> ( cross-posted on SO: http://stackoverflow.com/questions/24955829/ )
>
> I'm building a C extension for R, this library also uses the HDF5 library.
>
> I compiled a dynamic library (gcc flags: -fPIC -shared -Wl,-soname,libmy.so

I am not any kind of expert, so that this as just a vague possibility
from someone who just wants to try to help. But I am "concerned" about
the options in the above. In particular, you have
"-Wl,-soname,libmy.so" Which looks slightly wrong to me, based on the
man for "ld". I think that, perhaps, this should be:
""-Wl,-soname=libmy.so". Notice the = instead of the ,

> -o ../lib/libmy.so in a 'lib' directory:
>
<snip>
> the library seems to be loaded but R is still missing the symbols from the
> hdf5 library:

Have you looked at the /usr/bin/h5cc-<system type> helper script? It
has some more stuff in it with gcc parameters, such as:
-Wl,z,relro,-rpath -lz -ldl -lm -lhdf5, -lhdf5_hl
apparently the -lhdf5_hl is only needed if

In fact, from my reading, you might want to use "h5cc" instead of
"gcc" to compile your shared library.

>
>      Error in dyn.load("libmy.so") :
>        unable to load shared object ' /path/to/my/src/libmy.so':
>        /path/to/my/src/libmy.so: undefined symbol: H5T_C_S1_g
>      Execution halted
>
> I also tried load("my.so") instead of "libmy.so".
>
> How can I load my dynamic library ?
>
> Thanks
> Pierre

Again, I'm no expert. I'm not even a Linux professional. I work on an
old-style "mainframe" (z/OS from IBM - aka "big iron"). So please
excuse me if I am leading you down a blind alley.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jdnewmil at dcn.davis.CA.us  Sat Jul 26 17:01:05 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 26 Jul 2014 08:01:05 -0700
Subject: [R] Function assignment
In-Reply-To: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>
References: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>
Message-ID: <65606dd6-8c4c-46a3-bb1d-0d9e61fe13d8@email.android.com>

What an awful idea... that would lead to incredibly hard-to-debug programs. No, you cannot do that. What kind of problem has led you to want such a capability? Perhaps we can suggest a simpler way to think about your problem.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 26, 2014 5:29:59 AM PDT, Florian Ryan <florian.ryan at aim.com> wrote:
>Hello,
>
>I would like to use the variable name which i assign the return value
>of a function in a function. Is that possible?
>e.g.
>
>foo <- function(){
>    some not to me known R magic
>}
>
>myVariableName <- foo()
>myVariableName
>[1] "myVariableName"
>
>Hope someone can help me.
>
>Thanks
>Florian
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Sat Jul 26 17:34:20 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 26 Jul 2014 10:34:20 -0500
Subject: [R] R and external C library " cannot open shared object file"
 while LD_LIBRARY_PATH is set
In-Reply-To: <CAAJSdjjZ5E6oyc6PVPx_ffejsLQhmg1hmRKveR0spQSjHR9AqA@mail.gmail.com>
References: <53D264A0.7030500@univ-nantes.fr>
	<CAAJSdjjZ5E6oyc6PVPx_ffejsLQhmg1hmRKveR0spQSjHR9AqA@mail.gmail.com>
Message-ID: <CAAJSdjgU_sTX9Nhvk04o=uBpsD6Pz_--nWPcjbzADorogVWv-A@mail.gmail.com>

OOPS, I forgot to even look at something. Have you looked at the command:

R CMD SHLIB

?? The documentation says:
<quote>
$R CMD SHLIB --help
Usage: R CMD SHLIB [options] files | linker options

Build a shared object for dynamic loading from the specified source or
object files (which are automagically made from their sources) or
linker options.  If not given via '--output', the name for the shared
object is determined from the first source or object file.

Options:
  -h, --help            print short help message and exit
  -v, --version         print version info and exit
  -o, --output=LIB      use LIB as (full) name for the built library
  -c, --clean           remove files created during compilation
  --preclean            remove files created during a previous run
  -n, --dry-run         dry run, showing commands that would be used

Windows only:
  -d, --debug           build a debug DLL

Report bugs at bugs at r-project.org .

</quote>

On Sat, Jul 26, 2014 at 9:37 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Fri, Jul 25, 2014 at 9:07 AM, Pierre Lindenbaum
> <pierre.lindenbaum at univ-nantes.fr> wrote:
>> ( cross-posted on SO: http://stackoverflow.com/questions/24955829/ )
>>
>> I'm building a C extension for R, this library also uses the HDF5 library.
>>
>> I compiled a dynamic library (gcc flags: -fPIC -shared -Wl,-soname,libmy.so
>
> I am not any kind of expert, so that this as just a vague possibility
> from someone who just wants to try to help. But I am "concerned" about
> the options in the above. In particular, you have
> "-Wl,-soname,libmy.so" Which looks slightly wrong to me, based on the
> man for "ld". I think that, perhaps, this should be:
> ""-Wl,-soname=libmy.so". Notice the = instead of the ,
>
>> -o ../lib/libmy.so in a 'lib' directory:
>>
> <snip>
>> the library seems to be loaded but R is still missing the symbols from the
>> hdf5 library:
>
> Have you looked at the /usr/bin/h5cc-<system type> helper script? It
> has some more stuff in it with gcc parameters, such as:
> -Wl,z,relro,-rpath -lz -ldl -lm -lhdf5, -lhdf5_hl
> apparently the -lhdf5_hl is only needed if
>
> In fact, from my reading, you might want to use "h5cc" instead of
> "gcc" to compile your shared library.
>
>>
>>      Error in dyn.load("libmy.so") :
>>        unable to load shared object ' /path/to/my/src/libmy.so':
>>        /path/to/my/src/libmy.so: undefined symbol: H5T_C_S1_g
>>      Execution halted
>>
>> I also tried load("my.so") instead of "libmy.so".
>>
>> How can I load my dynamic library ?
>>
>> Thanks
>> Pierre
>
> Again, I'm no expert. I'm not even a Linux professional. I work on an
> old-style "mainframe" (z/OS from IBM - aka "big iron"). So please
> excuse me if I am leading you down a blind alley.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jdnewmil at dcn.davis.CA.us  Sat Jul 26 19:06:41 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 26 Jul 2014 10:06:41 -0700
Subject: [R] Redefining reference class makes persistent object
	partly	unreadable
In-Reply-To: <1406333477.29001.290.camel@localhost>
References: <1406333477.29001.290.camel@localhost>
Message-ID: <0a6b1bbb-9f26-4e9f-a87c-0d23370b6c73@email.android.com>

This doesn't surprise me, but then I am not a fan of reference classes.

The obvious (to me) answer is to read the objects with the old code and convert them to the new format on the fly or save the data in a more neutral format like csv or json for later use.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 25, 2014 5:11:17 PM PDT, Ross Boylan <ross at biostat.ucsf.edu> wrote:
>A bunch of .rdata is on the disk, created from reference classes (as in
>setRefClass()).  I redefined some of the classes--not by much.  Now
>when
>I read in the rdata it seems to have been damaged, because some parts
>have "disappeared".  The data are generally a graph of objects, some of
>which (e.g., lists) are conventional rather than reference classes.
>
>The specific  part that I noticed disappearing was actually a list
>element.
>
>The redefinition seemed quite minimal: no slots changed and the number
>of methods did not change.  In some cases the name changed (from show
>to
>summary) along with the definition, in other cases just the definition
>of the function changed.
>
>I've verified the crucial role of the code change by flipping between
>different versions of the code.  R 3.0.3 on Debian GNU/Linux.
>
>Context: I implemented a bunch of show reference class methods to
>display my results.  Now I want to display them in other forms, and so
>am trying to shift to returning a summary object.
>
>Thanks.
>Ross Boylan
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Sat Jul 26 20:07:28 2014
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sat, 26 Jul 2014 14:07:28 -0400
Subject: [R] Using R to Compute Covariance
Message-ID: <53D3EE60.1070102@comcast.net>

I have the following data set:
x    y           p
1    1          1/2
2    2          1/4
3    9          1/4

In this case, p represents the probability of the values occurring. I
compute the covariance of x and y by hand and come up with a value of 41/16.
When computing the covariance, I am dividing by n (in this case 3) not n-1.

I now want to use R to find the covarinace. I understand that R will divided
by n-1 not n.  Here are the commands that I issued:

x = c(1,2,3)
y = c(1,2,9)
df =dataframe(x,y)
w1 = c(1/2,1/4,1/4)
cov.wt(df, wt = w1 )

The last command returns:

$cov
     x    y
x 1.1  4.1
y 4.1 17.9

$center
    x    y
1.75 3.25

$n.obs
[1] 3

$wt
[1] 0.50 0.25 0.25

Therefore, I conclude that R is finding the covariance of x and y to be 4.1.
However, I need to adjust that number by multiplying it by 2 and then
dividing by 3. However, when I get that I still do not get 41/16.  What am I
missing?

I thank the group in advance for their responses.

Bob


From macqueen1 at llnl.gov  Sat Jul 26 21:25:14 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sat, 26 Jul 2014 19:25:14 +0000
Subject: [R] Function assignment
In-Reply-To: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>
References: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>
Message-ID: <CFF94CE0.10445C%macqueen1@llnl.gov>

Here is one way:

foo <- function(tmp) assign( tmp, tmp , '.GlobalEnv')



> foo('ick')
> ick
[1] "ick"


Note that you must only use it with a character argument:
> foo(1)
Error in assign(tmp, tmp, ".GlobalEnv") : invalid first argument

Be warned also that assign() should be used very carefully, because it is
easy to unintentionally overwrite objects with it:

> bah <- 3
> bah       
[1] 3
> foo('bah')
> bah
[1] "bah"

Your original bah is gone.

As Jeff suggested, there may be a better way to achieve the same purpose,
whatever that purpose might be. (I hope this wasn?t homework.)

-Don 

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/26/14, 5:29 AM, "Florian Ryan" <florian.ryan at aim.com> wrote:

>Hello,
>
>I would like to use the variable name which i assign the return value
>of a function in a function. Is that possible?
>e.g.
>
>foo <- function(){
>    some not to me known R magic
>}
>
>myVariableName <- foo()
>myVariableName
>[1] "myVariableName"
>
>Hope someone can help me.
>
>Thanks
>Florian
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Jul 26 21:30:54 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 26 Jul 2014 21:30:54 +0200
Subject: [R] Using R to Compute Covariance
In-Reply-To: <53D3EE60.1070102@comcast.net>
References: <53D3EE60.1070102@comcast.net>
Message-ID: <5F52BC7D-95E0-4F9B-9B1C-0FFAB39DE592@gmail.com>

The Details section of ?cov.wt tells you that its divisor is not (n-1) for the "unbiased" method. Or rather, it tells you what it does, and that that amounts to dividing by n-1 _if_ the weights are equal. 

(I never quite figured out under which sampling/weighting model this estimator is actually unbiased, but that is a different story.) 

-pd

On 26 Jul 2014, at 20:07 , Robert Sherry <rsherry8 at comcast.net> wrote:

> I have the following data set:
> x    y           p
> 1    1          1/2
> 2    2          1/4
> 3    9          1/4
> 
> In this case, p represents the probability of the values occurring. I
> compute the covariance of x and y by hand and come up with a value of 41/16.
> When computing the covariance, I am dividing by n (in this case 3) not n-1.
> 
> I now want to use R to find the covarinace. I understand that R will divided
> by n-1 not n.  Here are the commands that I issued:
> 
> x = c(1,2,3)
> y = c(1,2,9)
> df =dataframe(x,y)
> w1 = c(1/2,1/4,1/4)
> cov.wt(df, wt = w1 )
> 
> The last command returns:
> 
> $cov
>    x    y
> x 1.1  4.1
> y 4.1 17.9
> 
> $center
>   x    y
> 1.75 3.25
> 
> $n.obs
> [1] 3
> 
> $wt
> [1] 0.50 0.25 0.25
> 
> Therefore, I conclude that R is finding the covariance of x and y to be 4.1.
> However, I need to adjust that number by multiplying it by 2 and then
> dividing by 3. However, when I get that I still do not get 41/16.  What am I
> missing?
> 
> I thank the group in advance for their responses.
> 
> Bob
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Sat Jul 26 21:50:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 26 Jul 2014 12:50:02 -0700
Subject: [R] Using R to Compute Covariance
In-Reply-To: <53D3EE60.1070102@comcast.net>
References: <53D3EE60.1070102@comcast.net>
Message-ID: <645AC2CD-DBE4-4AA6-BB05-7C120D28D529@comcast.net>


On Jul 26, 2014, at 11:07 AM, Robert Sherry wrote:

> I have the following data set:
> x    y           p
> 1    1          1/2
> 2    2          1/4
> 3    9          1/4
>
> In this case, p represents the probability of the values occurring. I
> compute the covariance of x and y by hand and come up with a value  
> of 41/16.
> When computing the covariance, I am dividing by n (in this case 3)  
> not n-1.
>
> I now want to use R to find the [covariance]. I understand that R  
> will [divide]
> by n-1 not n.

Please read what the help page says about the choice of the method  
parameter.


>  Here are the commands that I issued:
>
> x = c(1,2,3)
> y = c(1,2,9)
> df =dataframe(x,y)

# There's no function named 'dataframe'.\\

> df =data.frame(x,y)
> w1 = c(1/2,1/4,1/4)
> cov.wt(df, wt = w1 )
>

 > cov.wt(df, wt = w1 ,method="ML")$cov[2,1]
[1] 2.5625
 > all.equal (41/16, cov.wt(df, wt = w1 ,method="ML")$cov[2,1] )
[1] TRUE


> The last command returns:
>
> $cov
>    x    y
> x 1.1  4.1
> y 4.1 17.9
>
> $center
>   x    y
> 1.75 3.25
>
> $n.obs
> [1] 3
>
> $wt
> [1] 0.50 0.25 0.25
>
> Therefore, I conclude that R is finding the covariance of x and y to  
> be 4.1.
> However, I need to adjust that number by multiplying it by 2 and then
> dividing by 3. However, when I get that I still do not get 41/16.   
> What am I
> missing?

-- 

David Winsemius, MD
Alameda, CA, USA


From pdalgd at gmail.com  Sat Jul 26 22:03:54 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 26 Jul 2014 22:03:54 +0200
Subject: [R] Function assignment
In-Reply-To: <65606dd6-8c4c-46a3-bb1d-0d9e61fe13d8@email.android.com>
References: <8D176E47326ADFA-2908-31BA1@webmail-m271.sysops.aol.com>
	<65606dd6-8c4c-46a3-bb1d-0d9e61fe13d8@email.android.com>
Message-ID: <721B5B70-1D1C-43DF-9591-922783671C66@gmail.com>


On 26 Jul 2014, at 17:01 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> What an awful idea... that would lead to incredibly hard-to-debug programs. No, you cannot do that. What kind of problem has led you to want such a capability? Perhaps we can suggest a simpler way to think about your problem.

I agree that this is a silly idea, but I actually thought that it could be done by clever manipulation of the call stack. It can if you do the assignment with assign():

> foo <- function()sys.calls()[[1]][[2]]
> assign("z", foo())
> z
[1] "z"
> assign("bah", foo())
> bah
[1] "bah"

but if you do x <- foo(), there is no mention of x or "x" in sys.calls().

Anyways, functions that assume being called in a specific are asking for trouble in all cases where they get called differently.

-pd



> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On July 26, 2014 5:29:59 AM PDT, Florian Ryan <florian.ryan at aim.com> wrote:
>> Hello,
>> 
>> I would like to use the variable name which i assign the return value
>> of a function in a function. Is that possible?
>> e.g.
>> 
>> foo <- function(){
>>   some not to me known R magic
>> }
>> 
>> myVariableName <- foo()
>> myVariableName
>> [1] "myVariableName"
>> 
>> Hope someone can help me.
>> 
>> Thanks
>> Florian
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rsherry8 at comcast.net  Sat Jul 26 22:20:01 2014
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sat, 26 Jul 2014 16:20:01 -0400
Subject: [R] Using R to Compute Covariance
In-Reply-To: <645AC2CD-DBE4-4AA6-BB05-7C120D28D529@comcast.net>
References: <53D3EE60.1070102@comcast.net>
	<645AC2CD-DBE4-4AA6-BB05-7C120D28D529@comcast.net>
Message-ID: <53D40D71.70001@comcast.net>

David,

Thanks for the response. I believe you have solved my problem.

Bob

On 7/26/2014 3:50 PM, David Winsemius wrote:
>
> On Jul 26, 2014, at 11:07 AM, Robert Sherry wrote:
>
>> I have the following data set:
>> x    y           p
>> 1    1          1/2
>> 2    2          1/4
>> 3    9          1/4
>>
>> In this case, p represents the probability of the values occurring. I
>> compute the covariance of x and y by hand and come up with a value of 
>> 41/16.
>> When computing the covariance, I am dividing by n (in this case 3) 
>> not n-1.
>>
>> I now want to use R to find the [covariance]. I understand that R 
>> will [divide]
>> by n-1 not n.
>
> Please read what the help page says about the choice of the method 
> parameter.
>
>
>>  Here are the commands that I issued:
>>
>> x = c(1,2,3)
>> y = c(1,2,9)
>> df =dataframe(x,y)
>
> # There's no function named 'dataframe'.\\
>
>> df =data.frame(x,y)
>> w1 = c(1/2,1/4,1/4)
>> cov.wt(df, wt = w1 )
>>
>
> > cov.wt(df, wt = w1 ,method="ML")$cov[2,1]
> [1] 2.5625
> > all.equal (41/16, cov.wt(df, wt = w1 ,method="ML")$cov[2,1] )
> [1] TRUE
>
>
>> The last command returns:
>>
>> $cov
>>    x    y
>> x 1.1  4.1
>> y 4.1 17.9
>>
>> $center
>>   x    y
>> 1.75 3.25
>>
>> $n.obs
>> [1] 3
>>
>> $wt
>> [1] 0.50 0.25 0.25
>>
>> Therefore, I conclude that R is finding the covariance of x and y to 
>> be 4.1.
>> However, I need to adjust that number by multiplying it by 2 and then
>> dividing by 3. However, when I get that I still do not get 41/16.  
>> What am I
>> missing?
>


From nicomet80 at gmail.com  Sun Jul 27 12:40:59 2014
From: nicomet80 at gmail.com (Nico Met)
Date: Sun, 27 Jul 2014 11:40:59 +0100
Subject: [R] Correlation
Message-ID: <CAMMD=S5+65kKoY2mzr36L5ESwZ9rNNhSTUvTgo70mEGSs9XgZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140727/dbd28799/attachment.pl>

From ruipbarradas at sapo.pt  Sun Jul 27 14:00:42 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 27 Jul 2014 14:00:42 +0200
Subject: [R] Correlation
In-Reply-To: <CAMMD=S5+65kKoY2mzr36L5ESwZ9rNNhSTUvTgo70mEGSs9XgZA@mail.gmail.com>
References: <CAMMD=S5+65kKoY2mzr36L5ESwZ9rNNhSTUvTgo70mEGSs9XgZA@mail.gmail.com>
Message-ID: <53D4E9EA.4060403@sapo.pt>

Hello,

If I understand it correctly the following should do it. Note that it 
removes both columns and rows.


idx <- corData > 0.5
diag(idx) <- FALSE
idx2 <- which(apply(idx, 2, function(x) !any(x)))
corData[-idx2, -idx2]


Use corData[, -idx2] to remove only columns.

Hope this helps,

Rui Barradas

On 27/07/2014 12:40, Nico Met wrote:
> Dear all,
>
> I have written the following code for correlation calculations. I want to
> create a new matrix  from corData) with correlation more than 0.5 only and
> the rest of the columns should be removed. How can I do it?
>
>
> set.seed(1234)
> data<-matrix(rnorm(100),nrow=10)
> data[,1]<-100*(data[,2]+data[,5]+data[,9])
> corData<-cor(data)
>
> Thanks a lot
>
> Nico
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From desolator88 at 163.com  Sun Jul 27 15:41:49 2014
From: desolator88 at 163.com (super)
Date: Sun, 27 Jul 2014 21:41:49 +0800 (CST)
Subject: [R]  How to modify the body of a function?
Message-ID: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140727/1ac08e0d/attachment.pl>

From maede_nourii at yahoo.com  Sun Jul 27 11:08:25 2014
From: maede_nourii at yahoo.com (Maede Nouri)
Date: Sun, 27 Jul 2014 02:08:25 -0700
Subject: [R] function that join my model & these coefficients
Message-ID: <1406452105.41810.YahooMailNeo@web121302.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140727/e28268d2/attachment.pl>

From matandked at gmail.com  Sun Jul 27 09:04:44 2014
From: matandked at gmail.com (=?UTF-8?Q?Mateusz_K=C4=99dzior?=)
Date: Sun, 27 Jul 2014 09:04:44 +0200
Subject: [R] incorrect correlation coefficients
Message-ID: <CANcjKSKn1JR-AEmRgaa7Y4pANHiGi+=VE6DUffpuThBkd8XC6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140727/ce3d37c4/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sun Jul 27 18:10:14 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 27 Jul 2014 18:10:14 +0200
Subject: [R] How to modify the body of a function?
In-Reply-To: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
Message-ID: <53D52466.2070108@statistik.tu-dortmund.de>



On 27.07.2014 15:41, super wrote:
> Suppose that I had a function as below:
> f<-function() {
> return(1)
> }
> i want to change the body of f  to the form like this:
> f<-function(){
> 1
> function() {}
> }
> How can i do the task using body(f) or something else solutions?

See ?body:

  body(f) <- as.call(c(as.name("{"), expression(1, function(){})))

or parts of it by list indexing ("[[") ....

Best,
Uwe Ligges


> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Sun Jul 27 18:25:20 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 27 Jul 2014 09:25:20 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
Message-ID: <CAF8bMcZYx_hy37UjMniKqsfKeabJA1bDLFd8uaPN-br7xmnH9Q@mail.gmail.com>

I find bquote() handy for this sort of manipulation.  E.g.,
> f <- function() { 1 }
> origBody <- body(f)
> newBody <- bquote({ .(origBody) ; .(addedStuff) }, list(origBody=origBody, addedStuff=quote(function(){})))
> body(f) <- newBody
> f
function ()
{
    {
        1
    }
    function() {
    }
}
> f()
function ()
{
}
<environment: 0x2a38350>


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
> Suppose that I had a function as below:
> f<-function() {
> return(1)
> }
> i want to change the body of f  to the form like this:
> f<-function(){
> 1
> function() {}
> }
> How can i do the task using body(f) or something else solutions?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Jul 27 18:39:39 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 27 Jul 2014 09:39:39 -0700
Subject: [R] function that join my model & these coefficients
In-Reply-To: <1406452105.41810.YahooMailNeo@web121302.mail.ne1.yahoo.com>
References: <1406452105.41810.YahooMailNeo@web121302.mail.ne1.yahoo.com>
Message-ID: <f6e7d0da-f0fc-4ea2-8c11-f20638c9a10c@email.android.com>

You should study the theory of regression before proceeding, since the chance of obtaining a significant (useful) result with 400 inputs is negligible.

You should also read the help files for the functions you are using (e.g. ?lm), which in this case mention the coef() function in the See Also section.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 27, 2014 2:08:25 AM PDT, Maede Nouri <maede_nourii at yahoo.com> wrote:
>hello?
>I am new to R language.?I fitted a linear model and my output has about
>300 coefficients. I need to definition a function that join my model &
>these coefficients ! this is difficult because number of?coefficients
>is many.?
>I think there is not?a?provided query for this. I also used
>"fitted(fit) # predicted values" but it can't help me to recieve my
>goal. please help me?in finding the functions and?merge?my model?& its
>coefficients.
>
>
>data2<-subset(data1,pd2<660000)
>> sapply(data2,mode)
>? ? ? ? aid ? ? ? ? act ? ? ? ?acid ? ? ?id_new ? ? ?userid ? ? ? ? pd1
>? ? ? ? pd2 ? ? ? ? pd3 ? ? ? ? pd4 ? ? ? ? pd5 ? ? ? freq1 ? ? ? freq2
>? ? ? freq3?
>? "numeric" ? "numeric" ? "numeric" ? "numeric" "character" "character"
>"character" "character" "character" ? "numeric" ? "numeric" ? "numeric"
>? "numeric"?
>? ? ? freq4 ? ? ? freq5?
>? "numeric" ? "numeric"?
>> fit <- lm(act
>~freq1+freq2+freq3+freq4+freq5+pd1*freq1+pd2*freq2+pd3*freq3+pd4*freq4+pd5*freq5-1,data=data2)
>> summary(fit)
>
>Call:
>lm(formula = act ~ freq1 + freq2 + freq3 + freq4 + freq5 + pd1 *?
>? ? freq1 + pd2 * freq2 + pd3 * freq3 + pd4 * freq4 + pd5 * freq5 -?
>? ? 1, data = data2)
>
>Residuals:
>? ? Min ? ? ?1Q ?Median ? ? ?3Q ? ? Max?
>-26.905 ?-2.843 ? 0.000 ? 1.606 ?33.059?
>
>Coefficients: (233 not defined because of singularities)
>? ? ? ? ? ? ? ? ? Estimate Std. Error t value Pr(>|t|) ? ?
>freq1 ? ? ? ? ? ?1.293e-01 ?1.753e-01 ? 0.738 0.461206 ? ?
>freq2 ? ? ? ? ? ?2.016e-01 ?3.310e-01 ? 0.609 0.542809 ? ?
>freq3 ? ? ? ? ? -4.816e+00 ?2.220e+00 ?-2.169 0.030795 * ?
>freq4 ? ? ? ? ? ?2.395e-01 ?1.751e+00 ? 0.137 0.891272 ? ?
>freq5 ? ? ? ? ? -9.289e+00 ?6.110e+00 ?-1.520 0.129394 ? ?
>pd1630000 ? ? ? ?5.625e+00 ?5.978e+00 ? 0.941 0.347445 ? ?
>pd1646000 ? ? ? ?7.082e+00 ?1.410e+01 ? 0.502 0.615714 ? ?
>pd1648000 ? ? ? ?1.275e+00 ?4.240e+01 ? 0.030 0.976027 ? ?
>pd1651000 ? ? ? ?3.404e+00 ?5.694e+00 ? 0.598 0.550352 ? ?
>pd1656000 ? ? ? -8.177e+00 ?1.017e+01 ?-0.804 0.421906 ? ?
>pd1665000 ? ? ? ?3.795e+00 ?5.649e+00 ? 0.672 0.502231 ? ?
>pd1666000 ? ? ? ?9.805e+00 ?5.857e+00 ? 1.674 0.095058 . ?
>pd2651000 ? ? ? ?4.790e+00 ?6.122e+00 ? 0.782 0.434510 ? ?
>pd2656000 ? ? ? ?1.754e+00 ?5.620e+00 ? 0.312 0.755221 ? ?
>pd2659000 ? ? ? ?4.187e-01 ?9.814e+00 ? 0.043 0.965996 ? ?
>pd3630000 ? ? ? -7.989e+00 ?5.629e+00 ?-1.419 0.156780 ? ?
>pd3646000 ? ? ? -1.638e+00 ?1.772e+01 ?-0.092 0.926444 ? ?
>pd3648000 ? ? ? -4.021e+00 ?7.725e+00 ?-0.521 0.602998 ? ?
>pd3651000 ? ? ? -4.848e+00 ?6.400e+00 ?-0.758 0.449243 ? ?
>pd3656000 ? ? ? -6.105e-01 ?8.732e+00 ?-0.070 0.944303 ? ?
>pd3659000 ? ? ? ?4.474e+00 ?7.483e+00 ? 0.598 0.550296 ? ?
>pd3663000 ? ? ? ?1.299e+02 ?4.969e+01 ? 2.614 0.009360 **?
>pd3737082 ? ? ? ? ? ? ? NA ? ? ? ? NA ? ? ?NA ? ? ? NA ? ?
>pd3737110 ? ? ? ?9.847e+01 ?3.120e+01 ? 3.156 0.001744 **?
>pd3738240 ? ? ? ?5.675e+00 ?1.223e+01 ? 0.464 0.643073 ? ?
>pd4646000 ? ? ? ?8.603e+00 ?1.751e+01 ? 0.491 0.623605 ? ?
>pd4648000 ? ? ? ?3.040e+00 ?4.848e+00 ? 0.627 0.531064 ? ?
>pd4651000 ? ? ? ?9.141e-01 ?5.243e+00 ? 0.174 0.861689 ? ?
>pd5 ? ? ? ? ? ? ?1.132e-06 ?3.440e-06 ? 0.329 0.742355 ? ?
>freq1:pd1646000 ? ? ? ? NA ? ? ? ? NA ? ? ?NA ? ? ? NA ? ?
>freq1:pd1648000 -1.786e+00 ?1.267e+01 ?-0.141 0.888002 ? ?
>freq2:pd2646000 ?1.369e+01 ?1.666e+01 ? 0.822 0.411865 ? ?
>freq2:pd2648000 ?1.396e+00 ?2.172e+00 ? 0.643 0.520933 ? ?
>freq3:pd3693000 ?3.270e+00 ?2.557e+00 ? 1.279 0.201910 ? ?
>freq3:pd3694000 ?7.476e+00 ?3.571e+00 ? 2.094 0.037035 * ?
>freq3:pd3699000 ?5.310e+00 ?2.187e+00 ? 2.429 0.015679 * ?
>
>
>thank you
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pburns at pburns.seanet.com  Sun Jul 27 19:08:33 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 27 Jul 2014 18:08:33 +0100
Subject: [R] incorrect correlation coefficients
In-Reply-To: <CANcjKSKn1JR-AEmRgaa7Y4pANHiGi+=VE6DUffpuThBkd8XC6Q@mail.gmail.com>
References: <CANcjKSKn1JR-AEmRgaa7Y4pANHiGi+=VE6DUffpuThBkd8XC6Q@mail.gmail.com>
Message-ID: <53D53211.4070404@pburns.seanet.com>

If the argument to the function you
give in the 'by' call were 'z' instead
of 'x', then it would have been easier
to see what was wrong.

You are using 'xx' inside the function
rather than 'x'.  I think you want
something like:

function(z) {cor(z$Data1.MEAN,
     z$Data2.MEAN)}

Pat

On 27/07/2014 08:04, Mateusz K?dzior wrote:
> Hello all,
>
> I strongly believe, that my issue is quite easy to resolve. However, I have
> no idea how to find/debug what is wrong and I would blame myself for
> insufficient knowledge about data tables and some useful functions in R! as
> apply, sapply, lapply.
>
> My question is as follows:
>
> I would like to display correlation coefficients in a table (ideally - with
> p-value, but below there's only Pearson correlation coefficients). However,
> my code produces exactly the same values for each period (so something is
> obviously wrong). Could you give me any advice:
>      #first of all, I read my data table from CSV file:
>      imported <- read.table (file="/home/someone/data_for_R.csv",
> header=TRUE, sep='\t', quote='"\'', dec=',', fill=FALSE, comment.char="#",
> na.strings = "NA", nrows = -1, skip = 0, check.names = TRUE, strip.white =
> FALSE, blank.lines.skip = TRUE)
>
>      # Typing: class(imported[["Period"]]) produces:
>      # [1] "factor"
>
>      #Typing: levels(imported[["Period"]]) produces:
>      # [1] "Summer 2010" "Summer 2011" "Winter 2010" "Winter 2011" "Winter
> 2012"
>
>      xx <- imported[c("Period","Data1.MEAN","Data2.MEAN")]
>      result <- by(xx, xx$Period, function(x) {cor(xx$Data1.MEAN,
> xx$Data2.MEAN)})
>      result.dataframe <- as.data.frame(as.matrix(result))
>      result.dataframe$C <- rownames(result)
>
>
> Best regards,
> Mateusz
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From desolator88 at 163.com  Sun Jul 27 19:23:08 2014
From: desolator88 at 163.com (super)
Date: Mon, 28 Jul 2014 01:23:08 +0800 (CST)
Subject: [R] How to modify the body of a function?
In-Reply-To: <CAF8bMcZYx_hy37UjMniKqsfKeabJA1bDLFd8uaPN-br7xmnH9Q@mail.gmail.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZYx_hy37UjMniKqsfKeabJA1bDLFd8uaPN-br7xmnH9Q@mail.gmail.com>
Message-ID: <77efb7a2.5263.14778d8eddb.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/5a824a6e/attachment.pl>

From wdunlap at tibco.com  Sun Jul 27 19:34:14 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 27 Jul 2014 10:34:14 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
Message-ID: <CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>

This is a real hack, but you can redefine return in your function:
> f <- function() {
+     return("early return")
+     "last value in function"
+ }
> f()
[1] "early return"
> f <- function() {
+     return <- function(x)x
+     return("early return")
+     "last value in function"
+ }
> f()
[1] "last value in function"

IMO, well written functions do not have return statements in them.  They
are the equivalent of goto statements.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
> Suppose that I had a function as below:
> f<-function() {
> return(1)
> }
> i want to change the body of f  to the form like this:
> f<-function(){
> 1
> function() {}
> }
> How can i do the task using body(f) or something else solutions?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Sun Jul 27 20:12:54 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 27 Jul 2014 11:12:54 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
Message-ID: <53D54126.3030009@structuremonitoring.com>

On 7/27/2014 10:34 AM, William Dunlap wrote:
> This is a real hack, but you can redefine return in your function:
>> f <- function() {
> +     return("early return")
> +     "last value in function"
> + }
>> f()
> [1] "early return"
>> f <- function() {
> +     return <- function(x)x
> +     return("early return")
> +     "last value in function"
> + }
>> f()
> [1] "last value in function"
>
> IMO, well written functions do not have return statements in them.  They
> are the equivalent of goto statements.


       Is that a fortune or something hotly contested?


       I can understand the sentiment, and I'd like to know if there is 
research behind this?  I understand that "goto" was eliminated from 
modern languages precisely because research indicated it was a major 
source of problems.  This may seem related, but I'd like to see the data 
if anyone knows of such.  I've used "return" in the middle of functions 
to avoid an extra "else" layer after an "if". This may not be smart. 
I'd like to know how stupid it is ;-)


       Thanks for the comment.


       Spencer

> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
>> Suppose that I had a function as below:
>> f<-function() {
>> return(1)
>> }
>> i want to change the body of f  to the form like this:
>> f<-function(){
>> 1
>> function() {}
>> }
>> How can i do the task using body(f) or something else solutions?
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From jdnewmil at dcn.davis.CA.us  Sun Jul 27 20:37:46 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 27 Jul 2014 11:37:46 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <53D54126.3030009@structuremonitoring.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
	<53D54126.3030009@structuremonitoring.com>
Message-ID: <f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>

Well, he did say it was his opinion. Goto has been pretty effectively eliminated from modern programming languages, while return has not.

IMHO the nature of the return statement resembles exception handling more than normal control flow... so I avoid using it. Exceptions are exceptional, and normal control flow leads to the end of the function.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 27, 2014 11:12:54 AM PDT, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
>On 7/27/2014 10:34 AM, William Dunlap wrote:
>> This is a real hack, but you can redefine return in your function:
>>> f <- function() {
>> +     return("early return")
>> +     "last value in function"
>> + }
>>> f()
>> [1] "early return"
>>> f <- function() {
>> +     return <- function(x)x
>> +     return("early return")
>> +     "last value in function"
>> + }
>>> f()
>> [1] "last value in function"
>>
>> IMO, well written functions do not have return statements in them. 
>They
>> are the equivalent of goto statements.
>
>
>       Is that a fortune or something hotly contested?
>
>
>      I can understand the sentiment, and I'd like to know if there is 
>research behind this?  I understand that "goto" was eliminated from 
>modern languages precisely because research indicated it was a major 
>source of problems.  This may seem related, but I'd like to see the
>data 
>if anyone knows of such.  I've used "return" in the middle of functions
>
>to avoid an extra "else" layer after an "if". This may not be smart. 
>I'd like to know how stupid it is ;-)
>
>
>       Thanks for the comment.
>
>
>       Spencer
>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
>>> Suppose that I had a function as below:
>>> f<-function() {
>>> return(1)
>>> }
>>> i want to change the body of f  to the form like this:
>>> f<-function(){
>>> 1
>>> function() {}
>>> }
>>> How can i do the task using body(f) or something else solutions?
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From kafi_dano at yahoo.com  Sun Jul 27 10:41:51 2014
From: kafi_dano at yahoo.com (kafi dano)
Date: Sun, 27 Jul 2014 01:41:51 -0700
Subject: [R] (no subject)
Message-ID: <1406450511.31078.YahooMailNeo@web124703.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140727/b45ca1ee/attachment.pl>

From gunter.berton at gene.com  Sun Jul 27 22:55:26 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 27 Jul 2014 13:55:26 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
	<53D54126.3030009@structuremonitoring.com>
	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>
Message-ID: <CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>

Just an (ignorable) opinion....

I'm not sure I would agree on the exception handling view, but maybe
it often boils down to:

Do you prefer:

a) function(...)
{
if(cond1) {do one} else{
if(cond2) {do two}} else {
if(cond3) {do three}}
results
}

## versus

b) function(...)
{
if(cond1) {do one; return(one)}
if(cond2) {do two; return(two)}
do three; return(three)
}


Personally, I find the logic of the first clearer than the second, but
others may disagree. Or may disagree with my premise altogether.

I would imagine programming sites have discussed these issues
extensively, and that would probably be a better place to look for
thoughts anyway.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Jul 27, 2014 at 11:37 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Well, he did say it was his opinion. Goto has been pretty effectively eliminated from modern programming languages, while return has not.
>
> IMHO the nature of the return statement resembles exception handling more than normal control flow... so I avoid using it. Exceptions are exceptional, and normal control flow leads to the end of the function.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On July 27, 2014 11:12:54 AM PDT, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
>>On 7/27/2014 10:34 AM, William Dunlap wrote:
>>> This is a real hack, but you can redefine return in your function:
>>>> f <- function() {
>>> +     return("early return")
>>> +     "last value in function"
>>> + }
>>>> f()
>>> [1] "early return"
>>>> f <- function() {
>>> +     return <- function(x)x
>>> +     return("early return")
>>> +     "last value in function"
>>> + }
>>>> f()
>>> [1] "last value in function"
>>>
>>> IMO, well written functions do not have return statements in them.
>>They
>>> are the equivalent of goto statements.
>>
>>
>>       Is that a fortune or something hotly contested?
>>
>>
>>      I can understand the sentiment, and I'd like to know if there is
>>research behind this?  I understand that "goto" was eliminated from
>>modern languages precisely because research indicated it was a major
>>source of problems.  This may seem related, but I'd like to see the
>>data
>>if anyone knows of such.  I've used "return" in the middle of functions
>>
>>to avoid an extra "else" layer after an "if". This may not be smart.
>>I'd like to know how stupid it is ;-)
>>
>>
>>       Thanks for the comment.
>>
>>
>>       Spencer
>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
>>>> Suppose that I had a function as below:
>>>> f<-function() {
>>>> return(1)
>>>> }
>>>> i want to change the body of f  to the form like this:
>>>> f<-function(){
>>>> 1
>>>> function() {}
>>>> }
>>>> How can i do the task using body(f) or something else solutions?
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Jul 28 01:29:03 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sun, 27 Jul 2014 23:29:03 +0000
Subject: [R] How to modify the body of a function?
In-Reply-To: <CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
	<53D54126.3030009@structuremonitoring.com>
	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>
	<CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
Message-ID: <CFFAD6FB.104561%macqueen1@llnl.gov>

As long as people are sharing their preferences . . .


I find return() useful in a scenario like the following:

Myfun <- function() {
  {a few lines of code}
  if (condition) return(whatever)
  {Many, many lines of code}
  Results
}

Which I find preferable to

Myfun <- function() {
  { a few lines of code}
  if (condition) {
    Results <- something
  } else {
    {Many, many lines of code}
    Results <- something.else
  }
  Results
}



It is the presence of those many lines of code which separate the opening
and closing brackets after the else that make the former easier to read
and understand (again in my opinion).

I guess this is more along the lines of exception handling.

Also note that this is something of a special case; I don?t in general
advocate using return().

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/27/14, 1:55 PM, "Bert Gunter" <gunter.berton at gene.com> wrote:

>Just an (ignorable) opinion....
>
>I'm not sure I would agree on the exception handling view, but maybe
>it often boils down to:
>
>Do you prefer:
>
>a) function(...)
>{
>if(cond1) {do one} else{
>if(cond2) {do two}} else {
>if(cond3) {do three}}
>results
>}
>
>## versus
>
>b) function(...)
>{
>if(cond1) {do one; return(one)}
>if(cond2) {do two; return(two)}
>do three; return(three)
>}
>
>
>Personally, I find the logic of the first clearer than the second, but
>others may disagree. Or may disagree with my premise altogether.
>
>I would imagine programming sites have discussed these issues
>extensively, and that would probably be a better place to look for
>thoughts anyway.
>
>Cheers,
>Bert
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>(650) 467-7374
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>Clifford Stoll
>
>
>
>
>On Sun, Jul 27, 2014 at 11:37 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Well, he did say it was his opinion. Goto has been pretty effectively
>>eliminated from modern programming languages, while return has not.
>>
>> IMHO the nature of the return statement resembles exception handling
>>more than normal control flow... so I avoid using it. Exceptions are
>>exceptional, and normal control flow leads to the end of the function.
>> 
>>-------------------------------------------------------------------------
>>--
>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>> 
>>-------------------------------------------------------------------------
>>--
>> Sent from my phone. Please excuse my brevity.
>>
>> On July 27, 2014 11:12:54 AM PDT, Spencer Graves
>><spencer.graves at structuremonitoring.com> wrote:
>>>On 7/27/2014 10:34 AM, William Dunlap wrote:
>>>> This is a real hack, but you can redefine return in your function:
>>>>> f <- function() {
>>>> +     return("early return")
>>>> +     "last value in function"
>>>> + }
>>>>> f()
>>>> [1] "early return"
>>>>> f <- function() {
>>>> +     return <- function(x)x
>>>> +     return("early return")
>>>> +     "last value in function"
>>>> + }
>>>>> f()
>>>> [1] "last value in function"
>>>>
>>>> IMO, well written functions do not have return statements in them.
>>>They
>>>> are the equivalent of goto statements.
>>>
>>>
>>>       Is that a fortune or something hotly contested?
>>>
>>>
>>>      I can understand the sentiment, and I'd like to know if there is
>>>research behind this?  I understand that "goto" was eliminated from
>>>modern languages precisely because research indicated it was a major
>>>source of problems.  This may seem related, but I'd like to see the
>>>data
>>>if anyone knows of such.  I've used "return" in the middle of functions
>>>
>>>to avoid an extra "else" layer after an "if". This may not be smart.
>>>I'd like to know how stupid it is ;-)
>>>
>>>
>>>       Thanks for the comment.
>>>
>>>
>>>       Spencer
>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Sun, Jul 27, 2014 at 6:41 AM, super <desolator88 at 163.com> wrote:
>>>>> Suppose that I had a function as below:
>>>>> f<-function() {
>>>>> return(1)
>>>>> }
>>>>> i want to change the body of f  to the form like this:
>>>>> f<-function(){
>>>>> 1
>>>>> function() {}
>>>>> }
>>>>> How can i do the task using body(f) or something else solutions?
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Jul 28 02:14:49 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Jul 2014 20:14:49 -0400
Subject: [R] How to modify the body of a function?
In-Reply-To: <CFFAD6FB.104561%macqueen1@llnl.gov>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>	<53D54126.3030009@structuremonitoring.com>	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>	<CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
	<CFFAD6FB.104561%macqueen1@llnl.gov>
Message-ID: <53D595F9.7050101@gmail.com>

On 27/07/2014, 7:29 PM, MacQueen, Don wrote:
> As long as people are sharing their preferences . . .
> 
> 
> I find return() useful in a scenario like the following:
> 
> Myfun <- function() {
>   {a few lines of code}
>   if (condition) return(whatever)
>   {Many, many lines of code}
>   Results
> }
> 
> Which I find preferable to
> 
> Myfun <- function() {
>   { a few lines of code}
>   if (condition) {
>     Results <- something
>   } else {
>     {Many, many lines of code}
>     Results <- something.else
>   }
>   Results
> }
> 

I tend to agree with you, but wanted to point out a third possibility:


 Myfun <- function() {
   { a few lines of code}
   if (condition) {
     something
   } else {
     {Many, many lines of code}
     something.else
   }
}

In some sense this is the most "R-like", but I like it the least.

Duncan Murdoch
> 
> It is the presence of those many lines of code which separate the opening
> and closing brackets after the else that make the former easier to read
> and understand (again in my opinion).
> 
> I guess this is more along the lines of exception handling.
> 
> Also note that this is something of a special case; I don?t in general
> advocate using return().
>


From spencer.graves at prodsyse.com  Mon Jul 28 02:22:41 2014
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 27 Jul 2014 17:22:41 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <CFFAD6FB.104561%macqueen1@llnl.gov>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>	<53D54126.3030009@structuremonitoring.com>	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>	<CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
	<CFFAD6FB.104561%macqueen1@llnl.gov>
Message-ID: <53D597D1.4070705@prodsyse.com>

On 7/27/2014 4:29 PM, MacQueen, Don wrote:
> As long as people are sharing their preferences . . .
>
>
> I find return() useful in a scenario like the following:
>
> Myfun <- function() {
>    {a few lines of code}
>    if (condition) return(whatever)
>    {Many, many lines of code}
>    Results
> }
>
> Which I find preferable to
>
> Myfun <- function() {
>    { a few lines of code}
>    if (condition) {
>      Results <- something
>    } else {
>      {Many, many lines of code}
>      Results <- something.else
>    }
>    Results
> }
>
>
>
> It is the presence of those many lines of code which separate the opening
> and closing brackets after the else that make the former easier to read
> and understand (again in my opinion).


       Thanks for the comment.  I prefer that style, also.


       However, I'm also sympathetic to  Bill Dunlap's opinion that, 
"They are the equivalent of goto statements." I was hoping to elicit a 
response from someone with a reference to a study suggesting that "  if 
(condition) return(whatever)" is either better than, equivalent to, or 
worse than "if ... else".  I can easily change my preference on this if 
research supports Dunlap and Newmiller against you, Bert Gunter, and me.


       Spencer

> I guess this is more along the lines of exception handling.
>
> Also note that this is something of a special case; I don?t in general
> advocate using return().
>


From wdunlap at tibco.com  Mon Jul 28 02:38:00 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 27 Jul 2014 17:38:00 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <53D595F9.7050101@gmail.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
	<53D54126.3030009@structuremonitoring.com>
	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>
	<CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
	<CFFAD6FB.104561%macqueen1@llnl.gov> <53D595F9.7050101@gmail.com>
Message-ID: <CAF8bMcYmYh+ap0SiCMpgfi5G0BK0HxtkEC-bEKnsSzWYcX7Afw@mail.gmail.com>

The problem with Don's
  if (condition) {
      Results <- something
  } else {
      Results <- somethingElse
  }
is that in a long sequence of if-then-else-if... you have
to check every branch to make sure Results got assigned to
(or that the remaining branches contained a return() or a stop()).

Duncan's version may be more readable if you explicitly assign
the value of the if-then-else to a variable and then return the variable
  Results <- if (condition) {
                       something
                   } else {
                        somethingElse
                   }
  Return

I think the original poster may have wanted to put a trace on a function
that could display the return value of the function, for an arbitrary function.
Having a return() statement makes this more difficult, since you
cannot simply make a transformation from
   origFun <- function(...) body
to
   newFun <- function(...) { retVal <- body ; print(retVal) ; retVal }
I think you really have to make a new function that wraps the original one, like
   newFun <- function(...) { retVal <- origFun(...) ; print(retVal) ; retval }
The latter will not work with functions that that use things like
sys.parent() so you may have to go into the body of the code and patch
those up.

(My preferences are colored by my experience looking for problems in
other people's code.  My own code is always easy to understand but
code other people write can be difficult. :-))


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Jul 27, 2014 at 5:14 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 27/07/2014, 7:29 PM, MacQueen, Don wrote:
>> As long as people are sharing their preferences . . .
>>
>>
>> I find return() useful in a scenario like the following:
>>
>> Myfun <- function() {
>>   {a few lines of code}
>>   if (condition) return(whatever)
>>   {Many, many lines of code}
>>   Results
>> }
>>
>> Which I find preferable to
>>
>> Myfun <- function() {
>>   { a few lines of code}
>>   if (condition) {
>>     Results <- something
>>   } else {
>>     {Many, many lines of code}
>>     Results <- something.else
>>   }
>>   Results
>> }
>>
>
> I tend to agree with you, but wanted to point out a third possibility:
>
>
>  Myfun <- function() {
>    { a few lines of code}
>    if (condition) {
>      something
>    } else {
>      {Many, many lines of code}
>      something.else
>    }
> }
>
> In some sense this is the most "R-like", but I like it the least.
>
> Duncan Murdoch
>>
>> It is the presence of those many lines of code which separate the opening
>> and closing brackets after the else that make the former easier to read
>> and understand (again in my opinion).
>>
>> I guess this is more along the lines of exception handling.
>>
>> Also note that this is something of a special case; I don?t in general
>> advocate using return().
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From desolator88 at 163.com  Mon Jul 28 05:03:53 2014
From: desolator88 at 163.com (super)
Date: Mon, 28 Jul 2014 11:03:53 +0800 (CST)
Subject: [R] How to modify the body of a function?
In-Reply-To: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
Message-ID: <11c14662.9c44.1477aec9f00.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/814e34c7/attachment.pl>

From spencer.graves at structuremonitoring.com  Mon Jul 28 05:27:05 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 27 Jul 2014 20:27:05 -0700
Subject: [R] How to modify the body of a function?
In-Reply-To: <11c14662.9c44.1477aec9f00.Coremail.desolator88@163.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<11c14662.9c44.1477aec9f00.Coremail.desolator88@163.com>
Message-ID: <53D5C309.30205@structuremonitoring.com>

On 7/27/2014 8:03 PM, super wrote:
> Tks for your opinions, let me describe the background for my question:
> The orignal purpose is to call the function which defined in anothor function, e.g.
> f1<-function(){
> x<-1
> f2<-function(x)
> {x}
> f3<-function(){
> 1+1
> }
> a<-1
> return(x+a)
> }
> The real function  f1  may be very long, And i know there is a function named f3 defined in f1. f3 is useful for me.  For some reason, i can't copy and paste f3's source code manually.
> So, with the solution for modifying the body of a  function, i can do the original task as below:
>
>
> oldbody<-body(f1)
> newbody<-bquote({.(redefine);.(oldbody);.(addstuff)},list(redefine=quote(return<-function(x){x}),oldbody=oldbody,addstuff=quote(function(){})))
> body(f1)<-newbody
> closure<-f1()
> ls(environment(closure))
> environment(closure)$f3
>
>
> Is there a easy way to do my original task?
>
>
>
>
>
>
>
>
>
> At 2014-07-27 09:41:49, "super" <desolator88 at 163.com> wrote:
>> Suppose that I had a function as below:
>> f<-function() {
>> return(1)
>> }
>> i want to change the body of f  to the form like this:
>> f<-function(){
>> 1
>> function() {}
>> }
>> How can i do the task using body(f) or something else solutions?


       Have you seen Hadley Wickham (2014) Advanced R 
(http://adv-r.had.co.nz)?  It has material that might help you.


       Based partly on this, I wrote Animate1 in Ecfun on R-Forge. This 
includes "bo <- body(fun)".  Then I played around "bo" to find ways of 
working with it.  For example, if fun is a function, then bo[[1]] is 
'{', and length(bo) = the number of "steps" in the function.  A "step" 
in this case could be several lines of code encased in { }.  This may 
not be a very smart way to wrote solid code, but it allowed me to 
produce code that seemed to give me predictable results with all the 
test examples I gave it.


      If anyone has other good references for this, I'm interested.


       Spencer


>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From desolator88 at 163.com  Mon Jul 28 05:33:11 2014
From: desolator88 at 163.com (super)
Date: Mon, 28 Jul 2014 11:33:11 +0800 (CST)
Subject: [R]  A quesion about Shiny
Message-ID: <7c3a9eaf.a8ad.1477b077359.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/8a61ac16/attachment.pl>

From jim at bitwrit.com.au  Mon Jul 28 05:37:29 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 28 Jul 2014 13:37:29 +1000
Subject: [R] (no subject)
In-Reply-To: <1406450511.31078.YahooMailNeo@web124703.mail.ne1.yahoo.com>
References: <1406450511.31078.YahooMailNeo@web124703.mail.ne1.yahoo.com>
Message-ID: <1414904.N6eETeAI8L@localhost.localdomain>

On Sun, 27 Jul 2014 01:41:51 AM kafi dano wrote:
> Hi. I have a problem in R. I want the command of least median 
squares and
> the package of this estimator
> 
> 
Hi Kafi,
Try the MASS (lmsreg) and robust packages.

Jim


From jim at bitwrit.com.au  Mon Jul 28 05:41:30 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 28 Jul 2014 13:41:30 +1000
Subject: [R] function that join my model & these coefficients
In-Reply-To: <1406452105.41810.YahooMailNeo@web121302.mail.ne1.yahoo.com>
References: <1406452105.41810.YahooMailNeo@web121302.mail.ne1.yahoo.com>
Message-ID: <2721857.6ZHV3JeClJ@localhost.localdomain>

On Sun, 27 Jul 2014 02:08:25 AM Maede Nouri wrote:
> hello 
> I am new to R language. I fitted a linear model and my output has 
about 300
> coefficients. I need to definition a function that join my model & 
these
> coefficients ! this is difficult because number of coefficients is many.  
I
> think there is not a provided query for this. I also used "fitted(fit) #
> predicted values" but it can't help me to recieve my goal. please 
help
> me in finding the functions and merge my model & its coefficients.
> 
> 
> data2<-subset(data1,pd2<660000)
> 
> > sapply(data2,mode)
> 
>         aid         act        acid      id_new      userid         pd1    
>     pd2         pd3         pd4         pd5       freq1       freq2      
> freq3  "numeric"   "numeric"   "numeric"   "numeric" "character"
> "character" "character" "character" "character"   "numeric"   
"numeric"  
> "numeric"   "numeric" freq4       freq5
>   "numeric"   "numeric" 
> 
> > fit <- lm(act
> > 
~freq1+freq2+freq3+freq4+freq5+pd1*freq1+pd2*freq2+pd3*freq3+pd4*freq4+pd
> > 5*freq5-1,data=data2) summary(fit)
> 
> Call:
> lm(formula = act ~ freq1 + freq2 + freq3 + freq4 + freq5 + pd1 * 
>     freq1 + pd2 * freq2 + pd3 * freq3 + pd4 * freq4 + pd5 * freq5 - 
>     1, data = data2)
> 
> Residuals:
>     Min      1Q  Median      3Q     Max 
> -26.905  -2.843   0.000   1.606  33.059 
> 
> Coefficients: (233 not defined because of singularities)
>                   Estimate Std. Error t value Pr(>|t|)    
> freq1            1.293e-01  1.753e-01   0.738 0.461206    
> freq2            2.016e-01  3.310e-01   0.609 0.542809    
> freq3           -4.816e+00  2.220e+00  -2.169 0.030795 *  
> freq4            2.395e-01  1.751e+00   0.137 0.891272    
> freq5           -9.289e+00  6.110e+00  -1.520 0.129394    
> pd1630000        5.625e+00  5.978e+00   0.941 0.347445    
> pd1646000        7.082e+00  1.410e+01   0.502 0.615714    
> pd1648000        1.275e+00  4.240e+01   0.030 0.976027    
> pd1651000        3.404e+00  5.694e+00   0.598 0.550352    
> pd1656000       -8.177e+00  1.017e+01  -0.804 0.421906    
> pd1665000        3.795e+00  5.649e+00   0.672 0.502231    
> pd1666000        9.805e+00  5.857e+00   1.674 0.095058 .  
> pd2651000        4.790e+00  6.122e+00   0.782 0.434510    
> pd2656000        1.754e+00  5.620e+00   0.312 0.755221    
> pd2659000        4.187e-01  9.814e+00   0.043 0.965996    
> pd3630000       -7.989e+00  5.629e+00  -1.419 0.156780    
> pd3646000       -1.638e+00  1.772e+01  -0.092 0.926444    
> pd3648000       -4.021e+00  7.725e+00  -0.521 0.602998    
> pd3651000       -4.848e+00  6.400e+00  -0.758 0.449243    
> pd3656000       -6.105e-01  8.732e+00  -0.070 0.944303    
> pd3659000        4.474e+00  7.483e+00   0.598 0.550296    
> pd3663000        1.299e+02  4.969e+01   2.614 0.009360 ** 
> pd3737082               NA         NA      NA       NA    
> pd3737110        9.847e+01  3.120e+01   3.156 0.001744 ** 
> pd3738240        5.675e+00  1.223e+01   0.464 0.643073    
> pd4646000        8.603e+00  1.751e+01   0.491 0.623605    
> pd4648000        3.040e+00  4.848e+00   0.627 0.531064    
> pd4651000        9.141e-01  5.243e+00   0.174 0.861689    
> pd5              1.132e-06  3.440e-06   0.329 0.742355    
> freq1:pd1646000         NA         NA      NA       NA    
> freq1:pd1648000 -1.786e+00  1.267e+01  -0.141 0.888002    
> freq2:pd2646000  1.369e+01  1.666e+01   0.822 0.411865    
> freq2:pd2648000  1.396e+00  2.172e+00   0.643 0.520933    
> freq3:pd3693000  3.270e+00  2.557e+00   1.279 0.201910    
> freq3:pd3694000  7.476e+00  3.571e+00   2.094 0.037035 *  
> freq3:pd3699000  5.310e+00  2.187e+00   2.429 0.015679 *  
> 
> 
Hi Maede,
The number of singularities strongly suggests that you have way too 
few data points to attempt a model with that many interaction terms. 
Even so, such a model would be exceedingly difficult to interpret. The 
numbered variables wouldn't be repeated observations, would they?

Jim


From rmh at temple.edu  Mon Jul 28 06:00:46 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 28 Jul 2014 00:00:46 -0400
Subject: [R] How to modify the body of a function?
In-Reply-To: <CAF8bMcYmYh+ap0SiCMpgfi5G0BK0HxtkEC-bEKnsSzWYcX7Afw@mail.gmail.com>
References: <5183293.36bb.147780e4e48.Coremail.desolator88@163.com>
	<CAF8bMcZV=j2+HE2LcLK14LMyT+M-S_DhaHnxz0kyd4Gi3Hd0JA@mail.gmail.com>
	<53D54126.3030009@structuremonitoring.com>
	<f239d3e7-b066-4071-8e09-71de2ded62f9@email.android.com>
	<CACk-te0=Y2=vE-WJQ9wt=uZ22kxB48bsDyEMtm+T7rxgcHDJBw@mail.gmail.com>
	<CFFAD6FB.104561%macqueen1@llnl.gov> <53D595F9.7050101@gmail.com>
	<CAF8bMcYmYh+ap0SiCMpgfi5G0BK0HxtkEC-bEKnsSzWYcX7Afw@mail.gmail.com>
Message-ID: <CAGx1TMCSBqBo7QZdRskcmJXhjz6Q9uWtY1RGhFbt=HyJj53o8g@mail.gmail.com>

Now THAT is a fortune:

My preferences are colored by my experience looking for problems in
other people's code.  My own code is always easy to understand but
code other people write can be difficult. :-)

On Sun, Jul 27, 2014 at 8:38 PM, William Dunlap <wdunlap at tibco.com> wrote:
> The problem with Don's
>   if (condition) {
>       Results <- something
>   } else {
>       Results <- somethingElse
>   }
> is that in a long sequence of if-then-else-if... you have
> to check every branch to make sure Results got assigned to
> (or that the remaining branches contained a return() or a stop()).
>
> Duncan's version may be more readable if you explicitly assign
> the value of the if-then-else to a variable and then return the variable
>   Results <- if (condition) {
>                        something
>                    } else {
>                         somethingElse
>                    }
>   Return
>
> I think the original poster may have wanted to put a trace on a function
> that could display the return value of the function, for an arbitrary function.
> Having a return() statement makes this more difficult, since you
> cannot simply make a transformation from
>    origFun <- function(...) body
> to
>    newFun <- function(...) { retVal <- body ; print(retVal) ; retVal }
> I think you really have to make a new function that wraps the original one, like
>    newFun <- function(...) { retVal <- origFun(...) ; print(retVal) ; retval }
> The latter will not work with functions that that use things like
> sys.parent() so you may have to go into the body of the code and patch
> those up.
>
> (My preferences are colored by my experience looking for problems in
> other people's code.  My own code is always easy to understand but
> code other people write can be difficult. :-))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sun, Jul 27, 2014 at 5:14 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 27/07/2014, 7:29 PM, MacQueen, Don wrote:
>>> As long as people are sharing their preferences . . .
>>>
>>>
>>> I find return() useful in a scenario like the following:
>>>
>>> Myfun <- function() {
>>>   {a few lines of code}
>>>   if (condition) return(whatever)
>>>   {Many, many lines of code}
>>>   Results
>>> }
>>>
>>> Which I find preferable to
>>>
>>> Myfun <- function() {
>>>   { a few lines of code}
>>>   if (condition) {
>>>     Results <- something
>>>   } else {
>>>     {Many, many lines of code}
>>>     Results <- something.else
>>>   }
>>>   Results
>>> }
>>>
>>
>> I tend to agree with you, but wanted to point out a third possibility:
>>
>>
>>  Myfun <- function() {
>>    { a few lines of code}
>>    if (condition) {
>>      something
>>    } else {
>>      {Many, many lines of code}
>>      something.else
>>    }
>> }
>>
>> In some sense this is the most "R-like", but I like it the least.
>>
>> Duncan Murdoch
>>>
>>> It is the presence of those many lines of code which separate the opening
>>> and closing brackets after the else that make the former easier to read
>>> and understand (again in my opinion).
>>>
>>> I guess this is more along the lines of exception handling.
>>>
>>> Also note that this is something of a special case; I don?t in general
>>> advocate using return().
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ebarrettcheetham at gmail.com  Mon Jul 28 06:46:08 2014
From: ebarrettcheetham at gmail.com (Elizabeth Barrett-Cheetham)
Date: Mon, 28 Jul 2014 14:46:08 +1000
Subject: [R] Is there a package for EFA with multiple groups?
Message-ID: <CAC_aMJCJnrd-vsgDLjp0E6kS2qSp0EhJtBW01eR3coMBg2E5yQ@mail.gmail.com>

Hello R users,

I?m hoping to run an exploratory and confirmatory factor analysis on a
psychology survey instrument. The data has been collected from
multiple groups, and it?s likely that the data is hierarchical/has 2nd
order factors.

It appears that the lavaan package allows me to run a multiple group
hierarchical confirmatory factor analysis. Yet, I can?t locate a
package that can run the equivalent exploratory analysis.

Could anyone please direct me to an appropriate package?

Many thanks,

Elizabeth


From petr.pikal at precheza.cz  Mon Jul 28 08:43:36 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 28 Jul 2014 06:43:36 +0000
Subject: [R] working on a data frame
In-Reply-To: <CAF8bMcaPVzeAQrEXvwqFeOAwTxSqsSK-T=JuJ-=nmFG4=GLB2g@mail.gmail.com>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>
	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>
	<53D1CBD7.7090108@molbio.mgh.harvard.edu>
	<ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>
	<53D2978F.10808@molbio.mgh.harvard.edu>
	<CAF8bMcaPVzeAQrEXvwqFeOAwTxSqsSK-T=JuJ-=nmFG4=GLB2g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCE35@SRVEXCHMBX.precheza.cz>

Hi

I like to use logical values directly in computations if possible.

yourData[,10] <- yourData[,9]/(yourData[,8]+(yourData[,8]==0))

Logical values are automagicaly considered FALSE=0 and TRUE=1 and can be used in computations. If you really want to change 0 to 1 in column 8 you can use

yourData[,8]  <-  yourData[,8]+(yourData[,8]==0)

without ifelse stuff.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of William Dunlap
> Sent: Friday, July 25, 2014 8:07 PM
> To: Matthew
> Cc: r-help at r-project.org
> Subject: Re: [R] working on a data frame
>
> > if
> > yourData[,8]==0,
> > then
> > yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]
>
> You could do express this in R as
>    is8Zero <- yourData[,8] == 0
>    yourData[is8Zero, 8] <- 1
>    yourData[is8Zero, 10] <- yourData[is8Zero,9] / yourData[is8Zero,8]
> Note how logical (Boolean) values are used as subscripts - read the '['
> as 'such that' when using logical subscripts.
>
> There are many more ways to express the same thing.
>
> (I am tempted to change the algorithm to avoid the divide by zero
> problem by making the quotient (numerator + epsilon)/(denominator +
> epsilon) where epsilon is a very small number.  I am assuming that the
> raw numbers are counts or at least cannot be negative.)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Jul 25, 2014 at 10:44 AM, Matthew
> <mccormack at molbio.mgh.harvard.edu> wrote:
> > Thank you for your comments, Peter.
> >
> > A couple of questions.  Can I do something like the following ?
> >
> > if
> > yourData[,8]==0,
> > then
> > yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]
> >
> >
> > I think I am just going to have to learn more about R. I thought
> > getting into R would be like going from Perl to Python or Java etc.,
> > but it seems like R programming works differently.
> >
> > Matthew
> >
> >
> > On 7/25/2014 12:06 AM, Peter Alspach wrote:
> >>
> >> Tena koe Matthew
> >>
> >> " Column 10 contains the result of the value in column 9 divided by
> >> the value in column 8. If the value in column 8==0, then the
> division
> >> can not be done, so  I want to change the zero to a one in order to
> do the division.".
> >> That being the case, think in terms of vectors, as Sarah says.  Try:
> >>
> >> yourData[,10] <- yourData[,9]/yourData[,8]
> >> yourData[yourData[,8]==0,10] <- yourData[yourData[,8]==0,9]
> >>
> >> This doesn't change the 0 to 1 in column 8, but it doesn't appear
> you
> >> actually need to do that.
> >>
> >> HTH ....
> >>
> >> Peter Alspach
> >>
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >> [mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Matthew McCormack
> >> Sent: Friday, 25 July 2014 3:16 p.m.
> >> To: Sarah Goslee
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] working on a data frame
> >>
> >>
> >> On 7/24/2014 8:52 PM, Sarah Goslee wrote:
> >>>
> >>> Hi,
> >>>
> >>> Your description isn't clear:
> >>>
> >>> On Thursday, July 24, 2014, Matthew
> >>> <mccormack at molbio.mgh.harvard.edu
> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
> >>>
> >>>      I am coming from the perspective of Excel and VBA scripts, but
> I
> >>>      would like to do the following in R.
> >>>
> >>>       I have a data frame with 14 columns and 32,795 rows.
> >>>
> >>>      I want to check the value in column 8 (row 1) to see if it is
> a 0.
> >>>      If it is not a zero, proceed to the next row and check the
> value
> >>>      for column 8.
> >>>      If it is a zero, then
> >>>      a) change the zero to a 1,
> >>>      b) divide the value in column 9 (row 1) by 1,
> >>>
> >>>
> >>> Row 1, or the row in which column 8 == 0?
> >>
> >> All rows in which the value in column 8==0.
> >>>
> >>> Why do you want to divide by 1?
> >>
> >> Column 10 contains the result of the value in column 9 divided by
> the
> >> value in column 8. If the value in column 8==0, then the division
> can
> >> not be done, so  I want to change the zero to a one in order to do
> the division.
> >> This is a fairly standard thing to do with this data. (The data are
> >> measurements of amounts at two time points. Sometimes a thing will
> >> not be present in the beginning (0), but very present at the later
> >> time. Column 10 is the log2 of the change. Infinite is not an easy
> >> number to work with, so it is common to change the 0 to a 1. On the
> >> other hand, something may be present at time 1, but not at the later
> >> time. In this case column 10 would be taking the log2 of a number
> >> divided by 0, so again the zero is commonly changed to a one in
> order
> >> to get a useable value in column 10. In both the preceding cases
> >> there was a real change, but Inf and NaN are not helpful.)
> >>>
> >>>      c) place the result in column 10 (row 1) and
> >>>
> >>>
> >>> Ditto on the row 1 question.
> >>
> >> I want to work on all rows where column 8 (and column 9) contain a
> zero.
> >> Column 10 contains the result of the value in column 9 divided by
> the
> >> value in column 8. So, for row 1, column 10 row 1 contains the ratio
> >> column
> >> 9 row 1 divided by column 8 row 1, and so on through the whole
> 32,000
> >> or so rows.
> >>
> >> Most rows do not have a zero in columns 8 or 9. Some rows have  zero
> >> in column 8 only, and some rows have a zero in column 9 only. I want
> >> to get rid of the zeros in these two columns and then do the
> division
> >> to get a manageable value in column 10. Division by zero and Inf are
> >> not considered 'manageable' by me.
> >>>
> >>> What do you want column 10 to be if column 8 isn't 0? Does it
> >>> already have a value. I suppose it must.
> >>
> >> Yes column 10 does have something, but this something can be Inf or
> >> NaN, which I want to get rid of.
> >>>
> >>>      d) repeat this for each of the other 32,794 rows.
> >>>
> >>>      Is this possible with an R script, and is this the way to go
> about
> >>>      it. If it is, could anyone get me started ?
> >>>
> >>>
> >>> Assuming you want to put the new values in the rows where column 8
> >>> == 0, you can do it in two steps:
> >>>
> >>> mydata[,10] <- ifelse(mydata[,8] == 0, mydata[,9]/whatever,
> >>> mydata[,10]) #where whatever is the thing you want to divide by
> that
> >>> probably isn't 1 mydata[,8] <- ifelse(mydata[,8] == 0, 1,
> >>> mydata[,8])
> >>>
> >>> R programming is best done by thinking about vectorizing things,
> >>> rather than doing them in loops. Reading the Intro to R that comes
> >>> with your installation is a good place to start.
> >>
> >> Would it be better to change the data frame into a matrix, or
> >> something else ?
> >> Thanks for your help.
> >>>
> >>> Sarah
> >>>
> >>>
> >>>      Matthew
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>> Sarah Goslee
> >>> http://www.stringpage.com
> >>> http://www.sarahgoslee.com
> >>> http://www.functionaldiversity.org
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >> The contents of this e-mail are confidential and may be subject to
> >> legal privilege.
> >>   If you are not the intended recipient you must not use,
> >> disseminate, distribute or
> >>   reproduce all or any part of this e-mail or attachments.  If you
> >> have received this
> >>   e-mail in error, please notify the sender and delete all material
> >> pertaining to this
> >>   e-mail.  Any opinion or views expressed in this e-mail are those
> of
> >> the individual
> >>   sender and may not represent those of The New Zealand Institute
> for
> >> Plant and
> >>   Food Research Limited.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From anna.zakrisson at su.se  Mon Jul 28 08:38:16 2014
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Mon, 28 Jul 2014 06:38:16 +0000
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot
Message-ID: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/3c88116a/attachment.pl>

From pavneet.arora at uk.rsagroup.com  Mon Jul 28 11:08:13 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Mon, 28 Jul 2014 10:08:13 +0100
Subject: [R] Differencing between 2 previous values
Message-ID: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/88f5372f/attachment.pl>

From petr.pikal at precheza.cz  Mon Jul 28 11:34:00 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 28 Jul 2014 09:34:00 +0000
Subject: [R] Differencing between 2 previous values
In-Reply-To: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>
References: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCF1E@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Pavneet Arora
> Sent: Monday, July 28, 2014 11:08 AM
> To: r-help at r-project.org
> Subject: [R] Differencing between 2 previous values
>
> Hello All,
>
> I am trying to do a simple thing of calculating the absolute difference
> between 2 previous values. Since my original data consists of 30 rows,
> this column where I am storing my absolute difference values only
> consists of 29 rows (called the ?differ?)! And I am having troubling
> cbind ing the
> 2 columns. Is there any way I can make the first  row of ?differ?
> column as NA?
>
> So my data looks like following
> dput(data)
> tructure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
> 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30), value
> = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04, 11.46, 9.2, 10.34,
> 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62, 10.31, 10, 13, 10.9, 9.33,
> 12.29, 11.5, 10.6, 11.08, 10.38, 11.62, 11.31, 10.52)), .Names =
> c("week", "value"), row.names = c(NA, -30L), class = "data.frame")
>
> This is how I calculate my ?diff? column:
> differ <- abs(diff(data$value))

differ <- c(NA, abs(diff(data$value)))

Regards
Petr

> Which gives me the following results:
> [1] 1.46 1.30 2.37 0.50 1.98 2.14 3.42 2.26 1.14 1.31 2.44 0.96 [13]
> 1.11 0.68 0.71 1.25 0.31 0.31 3.00 2.10 1.57 2.96 0.79 0.90 [25] 0.48
> 0.70 1.24 0.31 0.79
>
> As you can see this only contains 29 rows, so when I try to cbind it to
> my current data, I have an error.
> cbind(differ,data)
> Error in data.frame(..., check.names = FALSE) :
>   arguments imply differing number of rows: 29, 30
>
> What I ideally want is my new dataset to look as:
> Week            Value           Differ
>    1              9.45             NA
>    2              7.99            1.46
>    3              9.29            1.30
>
> And so on?.
>
> ***********************************************************************
> ***********************************************************************
> ***********************************************************************
> **
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No.
> 93792). Registered in England and Wales at St. Mark???s Court, Chart
> Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the
> Financial Conduct Authority and the Prudential Regulation Authority.
> ***********************************************************************
> ***********************************************************************
> ***********************************************************************
> ***
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Mon Jul 28 11:44:06 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 28 Jul 2014 11:44:06 +0200
Subject: [R] Differencing between 2 previous values
In-Reply-To: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>
References: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>
Message-ID: <3C6AD052-AA1D-43DD-84D9-E215B68BF938@gmail.com>


On 28 Jul 2014, at 11:08 , Pavneet Arora <pavneet.arora at uk.rsagroup.com> wrote:

> Hello All,
> 
> I am trying to do a simple thing of calculating the absolute difference 
> between 2 previous values. Since my original data consists of 30 rows, 
> this column where I am storing my absolute difference values only consists 
> of 29 rows (called the ?differ?)! And I am having troubling cbind ing the 
> 2 columns. Is there any way I can make the first  row of ?differ? column 
> as NA?
> 
> So my data looks like following
> dput(data)
> tructure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 
> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04, 
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62, 
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62, 
> 11.31, 10.52)), .Names = c("week", "value"), row.names = c(NA, 
> -30L), class = "data.frame")
> 
> This is how I calculate my ?diff? column:
> differ <- abs(diff(data$value))
> Which gives me the following results:
> [1] 1.46 1.30 2.37 0.50 1.98 2.14 3.42 2.26 1.14 1.31 2.44 0.96
> [13] 1.11 0.68 0.71 1.25 0.31 0.31 3.00 2.10 1.57 2.96 0.79 0.90
> [25] 0.48 0.70 1.24 0.31 0.79
> 
> As you can see this only contains 29 rows, so when I try to cbind it to my 
> current data, I have an error. 
> cbind(differ,data)
> Error in data.frame(..., check.names = FALSE) : 
>  arguments imply differing number of rows: 29, 30
> 
> What I ideally want is my new dataset to look as:
> Week            Value           Differ
>   1              9.45             NA
>   2              7.99            1.46
>   3              9.29            1.30
> 
> And so on?.

The straightforward way is 

data$Differ <- c(NA, abs(diff(data$value)))

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pavneet.arora at uk.rsagroup.com  Mon Jul 28 11:40:39 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Mon, 28 Jul 2014 10:40:39 +0100
Subject: [R] Differencing between 2 previous values
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCF1E@SRVEXCHMBX.precheza.cz>
References: <OFE4A7A783.195B5F85-ON80257D23.00312008-80257D23.0032D27F@uk.royalsun.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCF1E@SRVEXCHMBX.precheza.cz>
Message-ID: <OFE7B9A28F.C223AFEE-ON80257D23.0035209E-80257D23.0035CAAB@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/9f60f67b/attachment.pl>

From f_j_rod at hotmail.com  Mon Jul 28 10:52:14 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 28 Jul 2014 10:52:14 +0200
Subject: [R] Determine all specific same dates between two given dates
In-Reply-To: <53D3B632.8060401@statistik.tu-dortmund.de>
References: <BAY168-W66AAAB5D997CB754F9D9BABAFC0@phx.gbl>,
	<53D3B632.8060401@statistik.tu-dortmund.de>
Message-ID: <BAY168-W38D0B97B60CFD3E61D256ABAFB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/06e8d1fb/attachment.pl>

From pierre.lindenbaum at univ-nantes.fr  Mon Jul 28 10:52:02 2014
From: pierre.lindenbaum at univ-nantes.fr (Pierre Lindenbaum)
Date: Mon, 28 Jul 2014 10:52:02 +0200
Subject: [R] R and external C library " cannot open shared object file"
 while LD_LIBRARY_PATH is set
In-Reply-To: <CAAJSdjjZ5E6oyc6PVPx_ffejsLQhmg1hmRKveR0spQSjHR9AqA@mail.gmail.com>
References: <53D264A0.7030500@univ-nantes.fr>
	<CAAJSdjjZ5E6oyc6PVPx_ffejsLQhmg1hmRKveR0spQSjHR9AqA@mail.gmail.com>
Message-ID: <53D60F32.5090309@univ-nantes.fr>

Thanks but that doesn't work: R cannot load a simple external library 
even if the full path to the directory  is specified in the LD_LIBRARY_PATH.

I posted a minimal example on gist.github:

https://gist.github.com/lindenb/7cd766cbb37de01f6cce

The simple C file is compiled but I'm not able to load the library.

Pierre


(...)
> ( cross-posted on SO: http://stackoverflow.com/questions/24955829/ )
> I'm building a C extension for R, this library also uses the HDF5 library.
>
> I compiled a dynamic library (gcc flags: -fPIC -shared -Wl,-soname,libmy.so
> the library seems to be loaded but R is still missing the symbols from the
> hdf5 library:
>
>> I am not any kind of expert, so that this as just a vague possibility
>> from someone who just wants to try to help. But I am "concerned" about
>> the options in the above. In particular, you have
>> "-Wl,-soname,libmy.so" Which looks slightly wrong to me, based on the
>> man for "ld". I think that, perhaps, this should be:
>> ""-Wl,-soname=libmy.so". Notice the = instead of the ,
>


From florian.ryan at aim.com  Mon Jul 28 10:59:18 2014
From: florian.ryan at aim.com (Florian Ryan)
Date: Mon, 28 Jul 2014 04:59:18 -0400 (EDT)
Subject: [R] Function assignment
Message-ID: <8D17859592FCEDB-29A4-42A@webmail-m164.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/dcb5e213/attachment.pl>

From jwiley.psych at gmail.com  Mon Jul 28 12:22:50 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 28 Jul 2014 20:22:50 +1000
Subject: [R] Is there a package for EFA with multiple groups?
In-Reply-To: <CAC_aMJCJnrd-vsgDLjp0E6kS2qSp0EhJtBW01eR3coMBg2E5yQ@mail.gmail.com>
References: <CAC_aMJCJnrd-vsgDLjp0E6kS2qSp0EhJtBW01eR3coMBg2E5yQ@mail.gmail.com>
Message-ID: <CANz9Z_KiFYB1oOgW0L6aXC=Sz1ncUPL7+StAiMKehMxzU3CPFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/3657d203/attachment.pl>

From pavneet.arora at uk.rsagroup.com  Mon Jul 28 12:19:16 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Mon, 28 Jul 2014 11:19:16 +0100
Subject: [R] using foumula to calculate a column in dataframe
Message-ID: <OF2665735E.D9575416-ON80257D23.0038A5D1-80257D23.00395405@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/72b7cf38/attachment.pl>

From kulupp at online.de  Mon Jul 28 15:07:25 2014
From: kulupp at online.de (Kulupp)
Date: Mon, 28 Jul 2014 15:07:25 +0200
Subject: [R] Calculate depth from regular xyz grid for any coordinate within
 the grid
Message-ID: <53D64B0D.5060300@online.de>

Dear R-experts,

I have a regular grid dataframe (here: the first 50 rows) :

# data frame (regular grid) with x, y (UTM-coordinates) and z (depth)
# x=UTM coordinates (easting, zone 32)
# y=UTM coordinates (northing, zone 32)
# z=river-depth (meters)
df <- data.frame(x=c(3454240, 3454240, 3454240, 3454240, 3454240, 
3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 
3454250, 3454250, 3454250,
                      3454250, 3454250, 3454260, 3454260, 3454260, 
3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 
3454260, 3454260, 3454260,
                      3454260, 3454260, 3454260, 3454260, 3454260, 
3454260, 3454260, 3454260, 3454270, 3454270, 3454270, 3454270, 3454270, 
3454270, 3454270, 3454270,
                      3454270, 3454270),
                  y=c(5970610, 5970620, 5970630, 5970640, 5970650, 
5970610, 5970620, 5970630, 5970640, 5970650, 5970660, 5970670, 5970680, 
5970690, 5970700, 5970710,
                      5970720, 5970730, 5970610, 5970620, 5970630, 
5970640, 5970650, 5970660, 5970670, 5970680, 5970690, 5970700, 5970710, 
5970720, 5970730, 5970740,
                      5970750, 5970760, 5970770, 5970780, 5970790, 
5970800, 5970810, 5970820, 5970610, 5970620, 5970630, 5970640, 5970650, 
5970660, 5970670, 5970680,
                      5970690, 5970700),
                  z= c(-1.5621, -1.5758, -1.5911, -1.6079, -1.6247, 
-1.5704, -1.5840, -1.5976, -1.6113, -1.6249, -1.6385, -1.6521, -1.6658, 
-1.6794, -1.6930, -1.7067,
                       -1.7216, -1.7384, -1.5786, -1.5922, -1.6059, 
-1.6195, -1.6331, -1.6468, -1.6604, -1.6740, -1.6877, -1.7013, -1.7149, 
-1.7285, -1.7422, -1.7558,
                       -1.7694, -1.7831, -1.7967, -1.8103, -1.8239, 
-1.8376, -1.8522, -1.8690, -1.5869, -1.6005, -1.6141, -1.6278, -1.6414, 
-1.6550, -1.6686, -1.6823,
                       -1.6959, -1.7095))
head(df)
plot(df[,1:2], las=3)   # to show that it's a regular grid

My question: is there a function to calculate the depth of any 
coordinate pair (e.g. x=3454263, y=5970687) within the grid, e.g. by 
bilinear interpolation or any other meaningful method?

Thanks a lot for your help in anticipation

Best wishes

Thomas


From sarah.goslee at gmail.com  Mon Jul 28 15:35:38 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 28 Jul 2014 09:35:38 -0400
Subject: [R] Calculate depth from regular xyz grid for any coordinate
 within the grid
In-Reply-To: <53D64B0D.5060300@online.de>
References: <53D64B0D.5060300@online.de>
Message-ID: <CAM_vjum9Wbscw0rLN=s6xkSrt1xbXttbWE9iXhDZ0Pj7En-2fg@mail.gmail.com>

Hi,

The area of statistics you're looking for is called geostatistics.
There are many R packages to conduct such analyses. See the Spatial
task view for some good starting points:

http://cran.r-project.org/web/views/Spatial.html

You'll need to do some homework to understand the various options and
which are best for your data. You might start with Inverse Distance
Weighting.

Sarah

On Mon, Jul 28, 2014 at 9:07 AM, Kulupp <kulupp at online.de> wrote:
> Dear R-experts,
>
> I have a regular grid dataframe (here: the first 50 rows) :
>
> # data frame (regular grid) with x, y (UTM-coordinates) and z (depth)
> # x=UTM coordinates (easting, zone 32)
> # y=UTM coordinates (northing, zone 32)
> # z=river-depth (meters)
> df <- data.frame(x=c(3454240, 3454240, 3454240, 3454240, 3454240, 3454250,
> 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250,
> 3454250, 3454250,
>                      3454250, 3454250, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260,
>                      3454260, 3454260, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260, 3454270, 3454270, 3454270, 3454270, 3454270, 3454270,
> 3454270, 3454270,
>                      3454270, 3454270),
>                  y=c(5970610, 5970620, 5970630, 5970640, 5970650, 5970610,
> 5970620, 5970630, 5970640, 5970650, 5970660, 5970670, 5970680, 5970690,
> 5970700, 5970710,
>                      5970720, 5970730, 5970610, 5970620, 5970630, 5970640,
> 5970650, 5970660, 5970670, 5970680, 5970690, 5970700, 5970710, 5970720,
> 5970730, 5970740,
>                      5970750, 5970760, 5970770, 5970780, 5970790, 5970800,
> 5970810, 5970820, 5970610, 5970620, 5970630, 5970640, 5970650, 5970660,
> 5970670, 5970680,
>                      5970690, 5970700),
>                  z= c(-1.5621, -1.5758, -1.5911, -1.6079, -1.6247, -1.5704,
> -1.5840, -1.5976, -1.6113, -1.6249, -1.6385, -1.6521, -1.6658, -1.6794,
> -1.6930, -1.7067,
>                       -1.7216, -1.7384, -1.5786, -1.5922, -1.6059, -1.6195,
> -1.6331, -1.6468, -1.6604, -1.6740, -1.6877, -1.7013, -1.7149, -1.7285,
> -1.7422, -1.7558,
>                       -1.7694, -1.7831, -1.7967, -1.8103, -1.8239, -1.8376,
> -1.8522, -1.8690, -1.5869, -1.6005, -1.6141, -1.6278, -1.6414, -1.6550,
> -1.6686, -1.6823,
>                       -1.6959, -1.7095))
> head(df)
> plot(df[,1:2], las=3)   # to show that it's a regular grid
>
> My question: is there a function to calculate the depth of any coordinate
> pair (e.g. x=3454263, y=5970687) within the grid, e.g. by bilinear
> interpolation or any other meaningful method?
>
> Thanks a lot for your help in anticipation
>
> Best wishes
>
> Thomas
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From ottorino-luca.pantani at unifi.it  Mon Jul 28 15:46:52 2014
From: ottorino-luca.pantani at unifi.it (ottorino)
Date: Mon, 28 Jul 2014 15:46:52 +0200
Subject: [R] Is dataset "headsize" from MVA or HSAUR2 packages missing or am
 I missing something ?
Message-ID: <1406555212.4763.12.camel@lucaottorino-desktop.agr.unifi.it>

Dear R-helpers,
I've started the study of 

An introductionto applied multivariate analysis with R (Everitt and
Hothorn)

After loading the library, which depends on HSAUR2, it seems that the
dataset "headsize" is not available (as well as "measure" and "exam")

Datasets from the same book are nevertheless available, such as
"heptathlon", "pottery", "USairpollution"

Am I missing something obvious here ?

Thanks in advance

-- 
Ottorino-Luca Pantani, Universit? di Firenze
Dip.to di Scienze delle Produzioni Agroalimentari e  
dell'Ambiente (DISPAA)
P.zle Cascine 28 50144 Firenze Italia
Debian 7.0 wheezy -- GNOME 3.4.2
GNU Emacs 24.4.1 (i486-pc-linux-gnu, GTK+ Version 2.24.10)
ESS version 12.04-4 -- R 3.1.0


From jdnewmil at dcn.davis.CA.us  Mon Jul 28 16:17:11 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 28 Jul 2014 07:17:11 -0700
Subject: [R] Function assignment
In-Reply-To: <8D17859592FCEDB-29A4-42A@webmail-m164.sysops.aol.com>
References: <8D17859592FCEDB-29A4-42A@webmail-m164.sysops.aol.com>
Message-ID: <2f6b27e2-efeb-4d59-b57b-3ebc2b624d1c@email.android.com>

I am sorry but I don't follow your description beyond "use it with an external reference" because external references are external, while the destination of an assignment is an internal reference. If you want the destination to be an object which uses special knowledge (an external reference) to store the value (e.g. by an assignment function) into an external object, then the internal object should have PREVIOUSLY been constructed with that special knowledge about that external reference. Thus I don't follow why you want the external reference to be the destination of an assignment. The replace method seems much more suitable if you want to supply an external key in the course of the assignment.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 28, 2014 1:59:18 AM PDT, Florian Ryan <florian.ryan at aim.com> wrote:
>
>Thank you very much!
>
>The idea was to use it with an external reference and kind of to write
>an constructor 
>for an object which points at this external reference and behaves like
>an R object.
>
>So it would be the same as if I do just
>name <- function("name", someValuesForObjectConstruction)
>but I don't have to provide the names twice.
>Where function returns an object which stores the string "name"
>and knows get, set, ...
>
>and since with 
>setReplaceMethod(f="[", signature="myExternList",
>    definition=function(x, i="character", j="missing", y){
>    setExternReference(i, y)
>    return(x)   
>}
>
>I can get nicely the name inside the bracket (x["name"] <- )
>it seemed possible to get "name" some how out of an name <-
>assignment.
>
>Again thank you very much for hints and advice.
>
> 
>
>Florian Ryan
>florian.ryan at aim.com
>
> 
>
> 
>
>-----Original Message-----
>From: peter dalgaard <pdalgd at gmail.com>
>To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Cc: Florian Ryan <florian.ryan at aim.com>; r-help <r-help at r-project.org>
>Sent: Sat, Jul 26, 2014 10:04 pm
>Subject: Re: [R] Function assignment
>
>
>
>On 26 Jul 2014, at 17:01 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> What an awful idea... that would lead to incredibly hard-to-debug
>programs. 
>No, you cannot do that. What kind of problem has led you to want such a
>
>capability? Perhaps we can suggest a simpler way to think about your
>problem.
>
>I agree that this is a silly idea, but I actually thought that it could
>be done 
>by clever manipulation of the call stack. It can if you do the
>assignment with 
>assign():
>
>> foo <- function()sys.calls()[[1]][[2]]
>> assign("z", foo())
>> z
>[1] "z"
>> assign("bah", foo())
>> bah
>[1] "bah"
>
>but if you do x <- foo(), there is no mention of x or "x" in
>sys.calls().
>
>Anyways, functions that assume being called in a specific are asking
>for trouble 
>in all cases where they get called differently.
>
>-pd
>
>
>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> On July 26, 2014 5:29:59 AM PDT, Florian Ryan <florian.ryan at aim.com>
>wrote:
>>> Hello,
>>> 
>>> I would like to use the variable name which i assign the return
>value
>>> of a function in a function. Is that possible?
>>> e.g.
>>> 
>>> foo <- function(){
>>>   some not to me known R magic
>>> }
>>> 
>>> myVariableName <- foo()
>>> myVariableName
>>> [1] "myVariableName"
>>> 
>>> Hope someone can help me.
>>> 
>>> Thanks
>>> Florian
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


From dulcalma at bigpond.com  Mon Jul 28 17:18:59 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 29 Jul 2014 01:18:59 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>
Message-ID: <002701cfaa77$429d02d0$c7d70870$@bigpond.com>

Hi Anna

Not sure what you want exactly as I do not use themes.

Here is one way  to get your averages and points 

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))
   
 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
             }
) 

HTH
And now some sleep

Duncan

BTW package names are case sensitive like R

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`. .  `. . `. . ><((((:>`. .  `. . `. .><((((:>`. .  `.
. `. .><((((:>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Jul 28 17:26:37 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 28 Jul 2014 11:26:37 -0400
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <002701cfaa77$429d02d0$c7d70870$@bigpond.com>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>
	<002701cfaa77$429d02d0$c7d70870$@bigpond.com>
Message-ID: <CAM_vjun2r0pjrNWCDyQSWd2uVasb698T5dL2C2QjX2kbiQmX1A@mail.gmail.com>

An utterly perfect example of why one shouldn't send HTML mail to this list.

On Mon, Jul 28, 2014 at 11:18 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Anna Not sure what you want exactly as I do not use themes. Here is one way  to get your averages and points  # combine averages into mydata  mydata$mavg <-  c(rep(NA,4), madfStuff1[,3],    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))  xyplot(Value ~ Year, mydata, groups = Type,         allow.multiple = T,         distribute.type = TRUE,         col = c("red","blue","cyan"),          subscripts = TRUE,         panel = panel.superpose,         panel.groups = function(x, y, subscripts, ...,group.number) {                   panel.xyplot(x, y, ...)                    panel.xyplot(x, mydata[subscripts,"mavg"], col = c("red","blue","cyan")[group.number], type = "l")              } And now some sleep Duncan BTW package names are case sensitive like R Duncan Mackay Department of Agronomy and Soil Science University of New England Armidale NSW 2351 Email: home: mackay at northnet.com.au -----Original Message----- From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Anna Zakrisson Braeunlich Sent: Monday, 28 July 2014 16:38 To: r-help at r-project.org Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot Hi lattice users, I would like to add 5-year moving averages to my double y-plot. I have three factors needs to be plotted with moving averages in the same plot. One of these reads off y-axis 1 and two from y-axis 2. I have tried to use the rollmean function from the zoo-packages, but I fail in insering this into lattice (I am not an experienced lattice user). I want to keep the data points in the plot. Find below dummy data and the script as well as annotations further describing my question. thank you in advance! Anna Zakrisson mydata<- data.frame(   Year = 1980:2009,   Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),   Value = rnorm(90, mean = seq(90),                 sd = rep(c(6, 7, 3), each = 10))) library(Lattice) library(LatticeExtra) stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ] stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ] # make moving averages function using zoo and rollmean: library(zoo) library(plyr) f <- function(d)   require(zoo)   data.frame(Year = d$Year[5:length(d$Year)],              mavg = rollmean(d$Value, 5)) # Apply the function to each group as well as both data frames: madfStuff1 <- ddply(stuff1data, "Type", f) madfStuff2_3 <- ddply(stuff12_3data, "Type", f) # Some styles: myStripStyle <- function(which.panel, factor.levels, ...) {   panel.rect(0, 0, 1, 1,              col = bgColors[which.panel],              border = 1)   panel.text(x = 0.5, y = 0.5,              font=2,              lab = factor.levels[which.panel],              col = txtColors[which.panel]) myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",                    lty=1, pch=1,                    ylab = "sweets", strip.left = F,                    strip=myStripStyle,                    xlab = ("Year"),                   panel = function(x,y,...,subscripts){                     panel.xyplot(x, y, pch = 1,col = "black")                     panel.lmline(x,y,col = "black", data=madfStuff1) # here I presume that panel.lmline is wrong.                     # I would like to have my 5 year moving average here, not a straight line.                   }) myplot1 myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",                   lty=1, pch=1,                   ylab = "hours", strip.left = F,                   strip=myStripStyle,                   xlab = ("Year"),                   panel = function(x,y,...,subscripts){                     panel.xyplot(x, y, pch = c(2:3),col = "black") ## what is this "pch" defining? Types?                     #I would like to have different symbols and line types for stuff2 and stuff3                     panel.lmline(x,y,col = "black", data=madfStuff2_3) # wrong! Need my moving averages here!                   }) myplot2 doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,              text = c("stuff1", "stuff2", "stuff3"), columns = 2, col="black") # problem here is that I end up with two lines. I need a double y-plot with one moving average plots that are read off y-axis 1 # and two that reads off y-axis 2. I need to keep the data points in the plot. update(trellis.last.object(),        par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3), pch=c(1:3))) # how come that I only get # lines in my legend text and not the symbols too. I thought "pch" would add symbols?!? Anna Zakrisson Braeunlich PhD student Department of Ecology, Environment and Plant Sciences Stockholm University Svante Arrheniusv. 21A SE-106 91 Stockholm Sweden/Sverige Lives in Berlin. For paper mail: Katzbachstr. 21 D-10965, Berlin Germany/Deutschland E-mail: anna.zakrisson at su.se Tel work: +49-(0)3091541281 Mobile: +49-(0)15777374888 LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b ><((((:>` . .  . . ><((((:>` . .  . .><((((:>` . .  . .><((((:> [[alternative HTML version deleted]] ______________________________________________ R-help at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From mccormack at molbio.mgh.harvard.edu  Mon Jul 28 20:26:26 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Mon, 28 Jul 2014 14:26:26 -0400
Subject: [R] working on a data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCE35@SRVEXCHMBX.precheza.cz>
References: <53D1786A.2090508@molbio.mgh.harvard.edu>	<CAM_vjum_q-s0faX80Qp9c+j1WL1uQxO+BhwzWARWyB4+KsVkHA@mail.gmail.com>	<53D1CBD7.7090108@molbio.mgh.harvard.edu>	<ED8CD182D432434485C7D1787FB06DDC2281E68DF7@AKLEXM01.PFR.CO.NZ>	<53D2978F.10808@molbio.mgh.harvard.edu>
	<CAF8bMcaPVzeAQrEXvwqFeOAwTxSqsSK-T=JuJ-=nmFG4=GLB2g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDCE35@SRVEXCHMBX.precheza.cz>
Message-ID: <53D695D2.9090400@molbio.mgh.harvard.edu>

Thank you very much Peter, Bill and Petr for some great and quite 
elegant solutions. There is a lot I can learn from these.

     Yes to your question Bill about the raw numbers, they are counts 
and they can not be negatives. The data is RNA Sequencing data where 
there are approximately 32,000 genes being measured for changes between 
two conditions. There are some genes that are not present (can not be 
measured) initially, but are present in the second condition, and the 
reverse is true also of some genes that are present initially and then 
not be present in the second condition (these are often the most 
interesting genes). This makes it difficult to compare mathematically 
the changes of all genes, so it is common practice to change the 0's to 
1's and then redo the log2. 1 is considered sufficiently small, actually 
anywhere up to 3 or 5 could be just do to 'background noise' in the 
measurement process, but it is somewhat arbitrary.

Matthew

On 7/28/2014 2:43 AM, PIKAL Petr wrote:
> Hi
>
> I like to use logical values directly in computations if possible.
>
> yourData[,10] <- yourData[,9]/(yourData[,8]+(yourData[,8]==0))
>
> Logical values are automagicaly considered FALSE=0 and TRUE=1 and can be used in computations. If you really want to change 0 to 1 in column 8 you can use
>
> yourData[,8]  <-  yourData[,8]+(yourData[,8]==0)
>
> without ifelse stuff.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of William Dunlap
>> Sent: Friday, July 25, 2014 8:07 PM
>> To: Matthew
>> Cc: r-help at r-project.org
>> Subject: Re: [R] working on a data frame
>>
>>> if
>>> yourData[,8]==0,
>>> then
>>> yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]
>> You could do express this in R as
>>     is8Zero <- yourData[,8] == 0
>>     yourData[is8Zero, 8] <- 1
>>     yourData[is8Zero, 10] <- yourData[is8Zero,9] / yourData[is8Zero,8]
>> Note how logical (Boolean) values are used as subscripts - read the '['
>> as 'such that' when using logical subscripts.
>>
>> There are many more ways to express the same thing.
>>
>> (I am tempted to change the algorithm to avoid the divide by zero
>> problem by making the quotient (numerator + epsilon)/(denominator +
>> epsilon) where epsilon is a very small number.  I am assuming that the
>> raw numbers are counts or at least cannot be negative.)
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Jul 25, 2014 at 10:44 AM, Matthew
>> <mccormack at molbio.mgh.harvard.edu> wrote:
>>> Thank you for your comments, Peter.
>>>
>>> A couple of questions.  Can I do something like the following ?
>>>
>>> if
>>> yourData[,8]==0,
>>> then
>>> yourData[,8]==1, yourData[,10] <- yourData[,9]/yourData[,8]
>>>
>>>
>>> I think I am just going to have to learn more about R. I thought
>>> getting into R would be like going from Perl to Python or Java etc.,
>>> but it seems like R programming works differently.
>>>
>>> Matthew
>>>
>>>
>>> On 7/25/2014 12:06 AM, Peter Alspach wrote:
>>>> Tena koe Matthew
>>>>
>>>> " Column 10 contains the result of the value in column 9 divided by
>>>> the value in column 8. If the value in column 8==0, then the
>> division
>>>> can not be done, so  I want to change the zero to a one in order to
>> do the division.".
>>>> That being the case, think in terms of vectors, as Sarah says.  Try:
>>>>
>>>> yourData[,10] <- yourData[,9]/yourData[,8]
>>>> yourData[yourData[,8]==0,10] <- yourData[yourData[,8]==0,9]
>>>>
>>>> This doesn't change the 0 to 1 in column 8, but it doesn't appear
>> you
>>>> actually need to do that.
>>>>
>>>> HTH ....
>>>>
>>>> Peter Alspach
>>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org
>>>> [mailto:r-help-bounces at r-project.org]
>>>> On Behalf Of Matthew McCormack
>>>> Sent: Friday, 25 July 2014 3:16 p.m.
>>>> To: Sarah Goslee
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] working on a data frame
>>>>
>>>>
>>>> On 7/24/2014 8:52 PM, Sarah Goslee wrote:
>>>>> Hi,
>>>>>
>>>>> Your description isn't clear:
>>>>>
>>>>> On Thursday, July 24, 2014, Matthew
>>>>> <mccormack at molbio.mgh.harvard.edu
>> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>>>>>       I am coming from the perspective of Excel and VBA scripts, but
>> I
>>>>>       would like to do the following in R.
>>>>>
>>>>>        I have a data frame with 14 columns and 32,795 rows.
>>>>>
>>>>>       I want to check the value in column 8 (row 1) to see if it is
>> a 0.
>>>>>       If it is not a zero, proceed to the next row and check the
>> value
>>>>>       for column 8.
>>>>>       If it is a zero, then
>>>>>       a) change the zero to a 1,
>>>>>       b) divide the value in column 9 (row 1) by 1,
>>>>>
>>>>>
>>>>> Row 1, or the row in which column 8 == 0?
>>>> All rows in which the value in column 8==0.
>>>>> Why do you want to divide by 1?
>>>> Column 10 contains the result of the value in column 9 divided by
>> the
>>>> value in column 8. If the value in column 8==0, then the division
>> can
>>>> not be done, so  I want to change the zero to a one in order to do
>> the division.
>>>> This is a fairly standard thing to do with this data. (The data are
>>>> measurements of amounts at two time points. Sometimes a thing will
>>>> not be present in the beginning (0), but very present at the later
>>>> time. Column 10 is the log2 of the change. Infinite is not an easy
>>>> number to work with, so it is common to change the 0 to a 1. On the
>>>> other hand, something may be present at time 1, but not at the later
>>>> time. In this case column 10 would be taking the log2 of a number
>>>> divided by 0, so again the zero is commonly changed to a one in
>> order
>>>> to get a useable value in column 10. In both the preceding cases
>>>> there was a real change, but Inf and NaN are not helpful.)
>>>>>       c) place the result in column 10 (row 1) and
>>>>>
>>>>>
>>>>> Ditto on the row 1 question.
>>>> I want to work on all rows where column 8 (and column 9) contain a
>> zero.
>>>> Column 10 contains the result of the value in column 9 divided by
>> the
>>>> value in column 8. So, for row 1, column 10 row 1 contains the ratio
>>>> column
>>>> 9 row 1 divided by column 8 row 1, and so on through the whole
>> 32,000
>>>> or so rows.
>>>>
>>>> Most rows do not have a zero in columns 8 or 9. Some rows have  zero
>>>> in column 8 only, and some rows have a zero in column 9 only. I want
>>>> to get rid of the zeros in these two columns and then do the
>> division
>>>> to get a manageable value in column 10. Division by zero and Inf are
>>>> not considered 'manageable' by me.
>>>>> What do you want column 10 to be if column 8 isn't 0? Does it
>>>>> already have a value. I suppose it must.
>>>> Yes column 10 does have something, but this something can be Inf or
>>>> NaN, which I want to get rid of.
>>>>>       d) repeat this for each of the other 32,794 rows.
>>>>>
>>>>>       Is this possible with an R script, and is this the way to go
>> about
>>>>>       it. If it is, could anyone get me started ?
>>>>>
>>>>>
>>>>> Assuming you want to put the new values in the rows where column 8
>>>>> == 0, you can do it in two steps:
>>>>>
>>>>> mydata[,10] <- ifelse(mydata[,8] == 0, mydata[,9]/whatever,
>>>>> mydata[,10]) #where whatever is the thing you want to divide by
>> that
>>>>> probably isn't 1 mydata[,8] <- ifelse(mydata[,8] == 0, 1,
>>>>> mydata[,8])
>>>>>
>>>>> R programming is best done by thinking about vectorizing things,
>>>>> rather than doing them in loops. Reading the Intro to R that comes
>>>>> with your installation is a good place to start.
>>>> Would it be better to change the data frame into a matrix, or
>>>> something else ?
>>>> Thanks for your help.
>>>>> Sarah
>>>>>
>>>>>
>>>>>       Matthew
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Sarah Goslee
>>>>> http://www.stringpage.com
>>>>> http://www.sarahgoslee.com
>>>>> http://www.functionaldiversity.org
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> The contents of this e-mail are confidential and may be subject to
>>>> legal privilege.
>>>>    If you are not the intended recipient you must not use,
>>>> disseminate, distribute or
>>>>    reproduce all or any part of this e-mail or attachments.  If you
>>>> have received this
>>>>    e-mail in error, please notify the sender and delete all material
>>>> pertaining to this
>>>>    e-mail.  Any opinion or views expressed in this e-mail are those
>> of
>>>> the individual
>>>>    sender and may not represent those of The New Zealand Institute
>> for
>>>> Plant and
>>>>    Food Research Limited.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From macqueen1 at llnl.gov  Mon Jul 28 20:37:49 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 28 Jul 2014 18:37:49 +0000
Subject: [R] Calculate depth from regular xyz grid for any coordinate
 within the grid
In-Reply-To: <53D64B0D.5060300@online.de>
References: <53D64B0D.5060300@online.de>
Message-ID: <CFFBE65D.104906%macqueen1@llnl.gov>

I believe the interpp() function from the akima package will do what you
want.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/28/14, 6:07 AM, "Kulupp" <kulupp at online.de> wrote:

>Dear R-experts,
>
>I have a regular grid dataframe (here: the first 50 rows) :
>
># data frame (regular grid) with x, y (UTM-coordinates) and z (depth)
># x=UTM coordinates (easting, zone 32)
># y=UTM coordinates (northing, zone 32)
># z=river-depth (meters)
>df <- data.frame(x=c(3454240, 3454240, 3454240, 3454240, 3454240,
>3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250,
>3454250, 3454250, 3454250,
>                      3454250, 3454250, 3454260, 3454260, 3454260,
>3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260,
>3454260, 3454260, 3454260,
>                      3454260, 3454260, 3454260, 3454260, 3454260,
>3454260, 3454260, 3454260, 3454270, 3454270, 3454270, 3454270, 3454270,
>3454270, 3454270, 3454270,
>                      3454270, 3454270),
>                  y=c(5970610, 5970620, 5970630, 5970640, 5970650,
>5970610, 5970620, 5970630, 5970640, 5970650, 5970660, 5970670, 5970680,
>5970690, 5970700, 5970710,
>                      5970720, 5970730, 5970610, 5970620, 5970630,
>5970640, 5970650, 5970660, 5970670, 5970680, 5970690, 5970700, 5970710,
>5970720, 5970730, 5970740,
>                      5970750, 5970760, 5970770, 5970780, 5970790,
>5970800, 5970810, 5970820, 5970610, 5970620, 5970630, 5970640, 5970650,
>5970660, 5970670, 5970680,
>                      5970690, 5970700),
>                  z= c(-1.5621, -1.5758, -1.5911, -1.6079, -1.6247,
>-1.5704, -1.5840, -1.5976, -1.6113, -1.6249, -1.6385, -1.6521, -1.6658,
>-1.6794, -1.6930, -1.7067,
>                       -1.7216, -1.7384, -1.5786, -1.5922, -1.6059,
>-1.6195, -1.6331, -1.6468, -1.6604, -1.6740, -1.6877, -1.7013, -1.7149,
>-1.7285, -1.7422, -1.7558,
>                       -1.7694, -1.7831, -1.7967, -1.8103, -1.8239,
>-1.8376, -1.8522, -1.8690, -1.5869, -1.6005, -1.6141, -1.6278, -1.6414,
>-1.6550, -1.6686, -1.6823,
>                       -1.6959, -1.7095))
>head(df)
>plot(df[,1:2], las=3)   # to show that it's a regular grid
>
>My question: is there a function to calculate the depth of any
>coordinate pair (e.g. x=3454263, y=5970687) within the grid, e.g. by
>bilinear interpolation or any other meaningful method?
>
>Thanks a lot for your help in anticipation
>
>Best wishes
>
>Thomas
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Mon Jul 28 21:31:56 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 29 Jul 2014 05:31:56 +1000
Subject: [R] Calculate depth from regular xyz grid for any coordinate
 within the grid
In-Reply-To: <53D64B0D.5060300@online.de>
References: <53D64B0D.5060300@online.de>
Message-ID: <CAAcGz99E_56idQ5Bz7CeOcPZShE+WBtAzyH6--ruo8buNRqEtQ@mail.gmail.com>

The raster package can readily provide bilinear interpolation:

library(raster)
r <- rasterFromXY(df)
## due diligence, just a guess here you should check
## projection(r) <- "+proj=utm +zone=32 +datum=WGS84"

## coordinates to extract
m <- matrix(c( 3454263, 5970687), ncol = 2)

extract(r, m, method = "bilinear")
[1] -1.686059

## compare with
extract(r, m, method = "simple")
-1.6877

See ?extract - simplest usage is a query matrix of XY coordinates in
the projection used by your raster, it will helpfully transform
queries such as a "Spatial*DataFrame" if needed, as long as both
raster x and query y have sufficient projection metadata (and it's up
to you to make sure that's set right).

(Generally building a raster from "XYZ" data is sub-optimal since
there's so much redundancy in the XY coordinates, and so much room for
things to go wrong in between. But sometimes there's no better option.
)

Cheers, Mike.

On Mon, Jul 28, 2014 at 11:07 PM, Kulupp <kulupp at online.de> wrote:
> Dear R-experts,
>
> I have a regular grid dataframe (here: the first 50 rows) :
>
> # data frame (regular grid) with x, y (UTM-coordinates) and z (depth)
> # x=UTM coordinates (easting, zone 32)
> # y=UTM coordinates (northing, zone 32)
> # z=river-depth (meters)
> df <- data.frame(x=c(3454240, 3454240, 3454240, 3454240, 3454240, 3454250,
> 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250, 3454250,
> 3454250, 3454250,
>                      3454250, 3454250, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260,
>                      3454260, 3454260, 3454260, 3454260, 3454260, 3454260,
> 3454260, 3454260, 3454270, 3454270, 3454270, 3454270, 3454270, 3454270,
> 3454270, 3454270,
>                      3454270, 3454270),
>                  y=c(5970610, 5970620, 5970630, 5970640, 5970650, 5970610,
> 5970620, 5970630, 5970640, 5970650, 5970660, 5970670, 5970680, 5970690,
> 5970700, 5970710,
>                      5970720, 5970730, 5970610, 5970620, 5970630, 5970640,
> 5970650, 5970660, 5970670, 5970680, 5970690, 5970700, 5970710, 5970720,
> 5970730, 5970740,
>                      5970750, 5970760, 5970770, 5970780, 5970790, 5970800,
> 5970810, 5970820, 5970610, 5970620, 5970630, 5970640, 5970650, 5970660,
> 5970670, 5970680,
>                      5970690, 5970700),
>                  z= c(-1.5621, -1.5758, -1.5911, -1.6079, -1.6247, -1.5704,
> -1.5840, -1.5976, -1.6113, -1.6249, -1.6385, -1.6521, -1.6658, -1.6794,
> -1.6930, -1.7067,
>                       -1.7216, -1.7384, -1.5786, -1.5922, -1.6059, -1.6195,
> -1.6331, -1.6468, -1.6604, -1.6740, -1.6877, -1.7013, -1.7149, -1.7285,
> -1.7422, -1.7558,
>                       -1.7694, -1.7831, -1.7967, -1.8103, -1.8239, -1.8376,
> -1.8522, -1.8690, -1.5869, -1.6005, -1.6141, -1.6278, -1.6414, -1.6550,
> -1.6686, -1.6823,
>                       -1.6959, -1.7095))
> head(df)
> plot(df[,1:2], las=3)   # to show that it's a regular grid
>
> My question: is there a function to calculate the depth of any coordinate
> pair (e.g. x=3454263, y=5970687) within the grid, e.g. by bilinear
> interpolation or any other meaningful method?
>
> Thanks a lot for your help in anticipation
>
> Best wishes
>
> Thomas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From ferra.xu at yahoo.com  Mon Jul 28 22:44:15 2014
From: ferra.xu at yahoo.com (Ferra Xu)
Date: Mon, 28 Jul 2014 13:44:15 -0700
Subject: [R] rgl.postscript doesn't show the colors correctly
In-Reply-To: <1406571967.48645.YahooMailNeo@web125106.mail.ne1.yahoo.com>
References: <1406571967.48645.YahooMailNeo@web125106.mail.ne1.yahoo.com>
Message-ID: <1406580255.8402.YahooMailNeo@web125102.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/38795cb9/attachment.pl>

From thomas.worthington at okstate.edu  Mon Jul 28 23:40:34 2014
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Mon, 28 Jul 2014 21:40:34 +0000
Subject: [R] Split PVClust plot
Message-ID: <C1A5238848713043B7C18ED38FFEF1F812B962DA@STWMB01.ad.okstate.edu>

Dear All 

I'm using PVClust to perform hierarchical clustering, for the output plot I can control most of the graphical I need, however the plot is large and I would like to split it vertically into two panels one above the other. Is there a way to plot only part of a PVClust plot, I tried to convert it to a dendrogram with 

result2  = as.dendrogram(result)

however I get the error message "no applicable method for 'as.dendrogram' applied to an object of class "pvclust". I also wondered whether it would be possible to convert to a phylogenetic tree and use the functions in the 'ape' package?

Any suggestion on how to split up a PVclust plot would be greatly appreciated  (code for the plot below)

Thanks
Tom 


result <- pvclust(df.1, method.dist="uncentered", method.hclust="average",nboot=10)
par(mar=c(0,0,0,0))
par(oma=c(0,0,0,0))
plot(result, print.pv =FALSE, col.pv=c("red","",""), print.num=FALSE, float = 0.02, font=1, 
	axes=T, cex =0.85, main="", sub="", xlab="", ylab= "", labels=NULL, hang=-1)
pvrect(result, alpha=0.95)


From jdnewmil at dcn.davis.ca.us  Tue Jul 29 00:13:46 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 28 Jul 2014 15:13:46 -0700 (PDT)
Subject: [R] using foumula to calculate a column in dataframe
In-Reply-To: <OF2665735E.D9575416-ON80257D23.0038A5D1-80257D23.00395405@uk.royalsun.com>
References: <OF2665735E.D9575416-ON80257D23.0038A5D1-80257D23.00395405@uk.royalsun.com>
Message-ID: <alpine.BSF.2.00.1407281458240.33289@pedal.dcn.davis.ca.us>

On Mon, 28 Jul 2014, Pavneet Arora wrote:

> Hello All,
> I need to calculate a column (Vupper) using a formula, but I am not sure
> how to. It will be easier to explain with an example.
>
> Again this is my dataset:
> dput(nd)
> structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
> 11.31, 10.52), cusum = c(-0.550000000000001, -2.56, -3.27, -1.61,
> 0.549999999999999, 0.729999999999999, -1.23, 0.229999999999999,
> -0.570000000000002, -0.230000000000002, -1.2, 0.269999999999998,
> 0.779999999999998, 0.179999999999998, 0.259999999999998,
> -0.370000000000003,
> 0.249999999999996, 0.559999999999997, 0.559999999999997, 3.56,
> 4.46, 3.79, 6.08, 7.58, 8.18, 9.26, 9.64, 11.26, 12.57, 13.09
> )), .Names = c("week", "value", "cusum"), row.names = c(NA, -30L
> ), class = "data.frame")
>
> I have some constants in my data. These are:
> sigma =1, h = 5, k = 0.5
>
> The formula requires me to start from the bottom row (30th in this case).
> The formula for the last row will be row 30th Cusi value (13.09) + h(5) *
> sigma(1) = giving me the value of 18.1
>
> Then the formula for the 29th row for Vupper uses the value of 30th Vupper
> (18.1) + k(0.5) * sigma(1) = giving me the value of 18.6
>
> Similarly the formula for the 28th row for Vupper will use value of 29th
> Vupper(18.6) + k(0.5) * sigma(1) = giving me the value of 19.1
>
> And so on?.

This is a recurrence formula... each value depends on the previous value 
in the sequence. In general these can be computationally expensive in R, 
but there are certain very common cases that have built-in functions with 
which you can build many of the real-world cases you might encounter 
(such as this one).

>
> Also, is there any way to make the formula generalised using loop or
> functions? Because I really don?t want to have to re-write the program if
> my number of rows increase or decrease or if I use another dataset?
>
> So far my function looks like following (Without the Vupper formula in
> there):
> vmask2 <- function(data,target,sigma,h,k){
>  data$deviation <- data$value - target
>  data$cusums <- cumsum(data$deviation)
>  data$ma <- c(NA,abs(diff(data$value)))
>  data$Vupper <- *not sure what to put here*
>
>  data
> }

I avoid using the variable name "data" because there is a base function of 
that name.

sigma <- 1
h <- 5
k <- 0.5

dta$Vupper <- rev( cumsum( c( dta[ nrow(dta), "cusum" ] + h * sigma
                             , rep( 0, nrow(dta) - 1 )
                             )
                             + seq( 0, by=k * sigma, length.out=30L )
                          )
                  )

Note how the terms in your algorithm are re-grouped into vectors that c 
and seq and rep can generate, and cumsum is used to implement the 
recurrence, and the rev function is used to reverse the vector.
If you are going to apply this to long sequences of data, you might want 
to fix the accumulation of floating-point error in the seq call by using 
integers:

dta$Vupper <- rev( cumsum( c( dta[ nrow(dta), "cusum" ] + h * sigma
                             , rep( 0, nrow(dta) - 1 )
                             )
                             + k * sigma * seq( 0L, by=1L, length.out=30L )
                          )
                  )

> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>
> 	[[alternative HTML version deleted]]

Please send your emails in plain text, as the Posting Guide requests. HTML 
often corrupts what you send to the list.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue Jul 29 00:42:32 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 28 Jul 2014 15:42:32 -0700 (PDT)
Subject: [R] using foumula to calculate a column in dataframe
In-Reply-To: <alpine.BSF.2.00.1407281458240.33289@pedal.dcn.davis.ca.us>
References: <OF2665735E.D9575416-ON80257D23.0038A5D1-80257D23.00395405@uk.royalsun.com>
	<alpine.BSF.2.00.1407281458240.33289@pedal.dcn.davis.ca.us>
Message-ID: <alpine.BSF.2.00.1407281539370.33289@pedal.dcn.davis.ca.us>

On Mon, 28 Jul 2014, Jeff Newmiller wrote:

> On Mon, 28 Jul 2014, Pavneet Arora wrote:
>
>> Hello All,
>> I need to calculate a column (Vupper) using a formula, but I am not sure
>> how to. It will be easier to explain with an example.
>> 
>> Again this is my dataset:
>> dput(nd)
>> structure(list(week = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
>> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
>> 29, 30), value = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
>> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
>> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
>> 11.31, 10.52), cusum = c(-0.550000000000001, -2.56, -3.27, -1.61,
>> 0.549999999999999, 0.729999999999999, -1.23, 0.229999999999999,
>> -0.570000000000002, -0.230000000000002, -1.2, 0.269999999999998,
>> 0.779999999999998, 0.179999999999998, 0.259999999999998,
>> -0.370000000000003,
>> 0.249999999999996, 0.559999999999997, 0.559999999999997, 3.56,
>> 4.46, 3.79, 6.08, 7.58, 8.18, 9.26, 9.64, 11.26, 12.57, 13.09
>> )), .Names = c("week", "value", "cusum"), row.names = c(NA, -30L
>> ), class = "data.frame")
>> 
>> I have some constants in my data. These are:
>> sigma =1, h = 5, k = 0.5
>> 
>> The formula requires me to start from the bottom row (30th in this case).
>> The formula for the last row will be row 30th Cusi value (13.09) + h(5) *
>> sigma(1) = giving me the value of 18.1
>> 
>> Then the formula for the 29th row for Vupper uses the value of 30th Vupper
>> (18.1) + k(0.5) * sigma(1) = giving me the value of 18.6
>> 
>> Similarly the formula for the 28th row for Vupper will use value of 29th
>> Vupper(18.6) + k(0.5) * sigma(1) = giving me the value of 19.1
>> 
>> And so on?.
>
> This is a recurrence formula... each value depends on the previous value in 
> the sequence. In general these can be computationally expensive in R, but 
> there are certain very common cases that have built-in functions with which 
> you can build many of the real-world cases you might encounter (such as this 
> one).
>
>> 
>> Also, is there any way to make the formula generalised using loop or
>> functions? Because I really don?t want to have to re-write the program if
>> my number of rows increase or decrease or if I use another dataset?
>> 
>> So far my function looks like following (Without the Vupper formula in
>> there):
>> vmask2 <- function(data,target,sigma,h,k){
>>  data$deviation <- data$value - target
>>  data$cusums <- cumsum(data$deviation)
>>  data$ma <- c(NA,abs(diff(data$value)))
>>  data$Vupper <- *not sure what to put here*
>>
>>  data
>> }
>
> I avoid using the variable name "data" because there is a base function of 
> that name.
>
> sigma <- 1
> h <- 5
> k <- 0.5
>
> dta$Vupper <- rev( cumsum( c( dta[ nrow(dta), "cusum" ] + h * sigma
>                            , rep( 0, nrow(dta) - 1 )
>                            )
>                            + seq( 0, by=k * sigma, length.out=30L )
>                         )
>                 )

Oops... accounted for accumulation twice, once with cumsum and once with 
seq.

dta$Vupper <- rev( rep( dta[ nrow(dta), "cusum" ] + h * sigma, nrow(dta) )
                  + k * sigma * seq( 0L, by=1L, length.out=30L )
                  )


> Note how the terms in your algorithm are re-grouped into vectors that c and 
> seq and rep can generate, and cumsum is used to implement the recurrence, and 
> the rev function is used to reverse the vector.
> If you are going to apply this to long sequences of data, you might want to 
> fix the accumulation of floating-point error in the seq call by using 
> integers:
>
> dta$Vupper <- rev( cumsum( c( dta[ nrow(dta), "cusum" ] + h * sigma
>                            , rep( 0, nrow(dta) - 1 )
>                            )
>                            + k * sigma * seq( 0L, by=1L, length.out=30L )
>                         )
>                 )
>
>> ***********************************************************************************************************************************************************************************************************************
>> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 
>> 93792). Registered in England and Wales at St. Mark???s Court, Chart Way, 
>> Horsham, West Sussex, RH12 1XL.
>> 
>> Authorised by the Prudential Regulation Authority and regulated by the 
>> Financial Conduct Authority and the Prudential Regulation Authority.
>> ************************************************************************************************************************************************************************************************************************
>>
>> 	[[alternative HTML version deleted]]
>
> Please send your emails in plain text, as the Posting Guide requests. HTML 
> often corrupts what you send to the list.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dulcalma at bigpond.com  Tue Jul 29 01:45:05 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 29 Jul 2014 09:45:05 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>
Message-ID: <000601cfaabd$f568f130$e03ad390$@bigpond.com>

I do not know what happened to my last email as this are set up as plain
text so I am sending the code again so I hope this works

I am not sure what you wanted exactly but this will plot the points and
lines of the average.
 
I have not worried about the 2nd axis

Here is one way of doing things  by combining the averages into the
dataframe. 
It makes it easier that way as you do not have to match up the x values

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
            })

Duncan

BTW libraries are case sensitive as well. Is it you editor putting capitals?

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`. .  `. . `. . ><((((:>`. .  `. . `. .><((((:>`. .  `.
. `. .><((((:>

	[[alternative HTML version deleted]]


From shidaxia at yahoo.com  Tue Jul 29 02:48:52 2014
From: shidaxia at yahoo.com (Shi, Tao)
Date: Mon, 28 Jul 2014 17:48:52 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter plots
Message-ID: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>

hi list,

I'm comparing the changes of ~100 analytes in multiple treatment conditions. ?I plotted them in several different xy scattter plots. ?It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown. ?I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine). ?rCharts is nice but so far it can only create one scatter plot at a time.?

Any good suggestions?

Many thanks!

Tao


From vishal_c64 at yahoo.com  Tue Jul 29 05:05:54 2014
From: vishal_c64 at yahoo.com (Vishal Chari)
Date: Mon, 28 Jul 2014 20:05:54 -0700
Subject: [R] Error in validObject(.Object) : while running rqpd package
Message-ID: <1406603154.27734.YahooMailNeo@web163104.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140728/291d7122/attachment.pl>

From yun.jiang at student.unsw.edu.au  Tue Jul 29 03:47:38 2014
From: yun.jiang at student.unsw.edu.au (Jenny Jiang)
Date: Tue, 29 Jul 2014 01:47:38 +0000
Subject: [R] outputting R loop to a csv file
Message-ID: <1406598456417.80848@student.unsw.edu.au>

Hello,


My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales. Currently my research project involves the calculating of some network centrality measures in R by using a loop, however I am having some trouble outputting my loop results to a desired CSV format.


Basically what I am doing is that for each firm year, I will need to calculate four different measures based on director id and connected director id and output these to the CSV file. I have provided in the attachment the code that I used for the R loop and CSV outputting (main-6.R). Using an example CSV file (data example 2), the output result I get is as shown in measure1.csv. As shown in the output file, the results are really messy, where for each firm year, all director ids and each type of measure for all directors are displayed in one cell. However, the desired format of output that I would like is as shown in output data template.xlsx.


As a result, I was just wondering if you could be able to help me to get the desired format that I would like, which would be much easier to enable me to do further research on this.


I cannot be more than appreciated.




Best regards


Jenny

From dcarlson at tamu.edu  Tue Jul 29 05:25:08 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 29 Jul 2014 03:25:08 +0000
Subject: [R] outputting R loop to a csv file
In-Reply-To: <1406598456417.80848@student.unsw.edu.au>
References: <1406598456417.80848@student.unsw.edu.au>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8CF0F@mb02.ads.tamu.edu>

It will be difficult to help since all of the attached files were stripped out of your message. R-help accepts very few formats as attached files and they do not include .R or .csv or .xlsx, but they do include .txt (so you could rename your R and csv files). It will be easier to help if we have enough data to test alternate approaches. The function dput() will convert a sample of your data to text format so that you can paste it into your email or provide it as a .txt file.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jenny Jiang
Sent: Monday, July 28, 2014 8:48 PM
To: r-help at R-project.org
Subject: [R] outputting R loop to a csv file

Hello,


My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales. Currently my research project involves the calculating of some network centrality measures in R by using a loop, however I am having some trouble outputting my loop results to a desired CSV format.


Basically what I am doing is that for each firm year, I will need to calculate four different measures based on director id and connected director id and output these to the CSV file. I have provided in the attachment the code that I used for the R loop and CSV outputting (main-6.R). Using an example CSV file (data example 2), the output result I get is as shown in measure1.csv. As shown in the output file, the results are really messy, where for each firm year, all director ids and each type of measure for all directors are displayed in one cell. However, the desired format of output that I would like is as shown in output data template.xlsx.


As a result, I was just wondering if you could be able to help me to get the desired format that I would like, which would be much easier to enable me to do further research on this.


I cannot be more than appreciated.




Best regards


Jenny


From petr.pikal at precheza.cz  Tue Jul 29 06:39:58 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 29 Jul 2014 04:39:58 +0000
Subject: [R] outputting R loop to a csv file
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F8CF0F@mb02.ads.tamu.edu>
References: <1406598456417.80848@student.unsw.edu.au>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8CF0F@mb02.ads.tamu.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD056@SRVEXCHMBX.precheza.cz>

Hi

Above what David said, there is chance that you do not need cycle for your computation.

From what you describe about your csv files there seems to be some mismatch in your write.csv statement.

Make a small example code together with data set, preferably as an output from dput, and try again to ask.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of David L Carlson
> Sent: Tuesday, July 29, 2014 5:25 AM
> To: Jenny Jiang; r-help at R-project.org
> Subject: Re: [R] outputting R loop to a csv file
>
> It will be difficult to help since all of the attached files were
> stripped out of your message. R-help accepts very few formats as
> attached files and they do not include .R or .csv or .xlsx, but they do
> include .txt (so you could rename your R and csv files). It will be
> easier to help if we have enough data to test alternate approaches. The
> function dput() will convert a sample of your data to text format so
> that you can paste it into your email or provide it as a .txt file.
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jenny Jiang
> Sent: Monday, July 28, 2014 8:48 PM
> To: r-help at R-project.org
> Subject: [R] outputting R loop to a csv file
>
> Hello,
>
>
> My name is Jenny Jiang and I am a Finance Honours research student from
> the University of New South Wales. Currently my research project
> involves the calculating of some network centrality measures in R by
> using a loop, however I am having some trouble outputting my loop
> results to a desired CSV format.
>
>
> Basically what I am doing is that for each firm year, I will need to
> calculate four different measures based on director id and connected
> director id and output these to the CSV file. I have provided in the
> attachment the code that I used for the R loop and CSV outputting
> (main-6.R). Using an example CSV file (data example 2), the output
> result I get is as shown in measure1.csv. As shown in the output file,
> the results are really messy, where for each firm year, all director
> ids and each type of measure for all directors are displayed in one
> cell. However, the desired format of output that I would like is as
> shown in output data template.xlsx.
>
>
> As a result, I was just wondering if you could be able to help me to
> get the desired format that I would like, which would be much easier to
> enable me to do further research on this.
>
>
> I cannot be more than appreciated.
>
>
>
>
> Best regards
>
>
> Jenny
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ottorino-luca.pantani at unifi.it  Tue Jul 29 11:44:01 2014
From: ottorino-luca.pantani at unifi.it (ottorino)
Date: Tue, 29 Jul 2014 11:44:01 +0200
Subject: [R] Is dataset "headsize" from MVA or HSAUR2 packages missing
 or am I missing something ?
In-Reply-To: <1406555212.4763.12.camel@lucaottorino-desktop.agr.unifi.it>
References: <1406555212.4763.12.camel@lucaottorino-desktop.agr.unifi.it>
Message-ID: <1406627041.7182.2.camel@lucaottorino-desktop.agr.unifi.it>

I answer to myself, just in case someone in the future will need this.

The data set for headsize is named "frets", from the name of the author
who collected data in 1921, and it is available once the the library
"boot" is loaded.

Il giorno lun, 28/07/2014 alle 15.46 +0200, ottorino ha scritto:
> Dear R-helpers,
> I've started the study of 
> 
> An introductionto applied multivariate analysis with R (Everitt and
> Hothorn)
> 
> After loading the library, which depends on HSAUR2, it seems that the
> dataset "headsize" is not available (as well as "measure" and "exam")
> 
> Datasets from the same book are nevertheless available, such as
> "heptathlon", "pottery", "USairpollution"
> 
> Am I missing something obvious here ?
> 
> Thanks in advance
>


From wollschlaeger at uni-mainz.de  Tue Jul 29 13:10:29 2014
From: wollschlaeger at uni-mainz.de (Wollschlaeger, Daniel)
Date: Tue, 29 Jul 2014 11:10:29 +0000
Subject: [R] Linear relative rate / excess relative risk models
In-Reply-To: <4168EEE5612D1C4BA7B5387E332F474B055E7A@e14mdb-03.zdv.Uni-Mainz.DE>
References: <4168EEE5612D1C4BA7B5387E332F474B053B96@e14mdb-03.zdv.Uni-Mainz.DE>,
	<55E5E195-5DC6-47ED-B77B-A6E66EA6B468@comcast.net>
	<4168EEE5612D1C4BA7B5387E332F474B054E16@e14mdb-03.zdv.Uni-Mainz.DE>
	<DC885BB5-6BFA-4E5D-A255-DF13776A4190@comcast.net>
	<4168EEE5612D1C4BA7B5387E332F474B055E7A@e14mdb-03.zdv.Uni-Mainz.DE>
Message-ID: <4168EEE5612D1C4BA7B5387E332F474B228C871E@e14mdb-03.zdv.Uni-Mainz.DE>

A while ago, I inquired about fitting excess relative risk models in R. This is a follow-up about what I ended up doing in case the question pops up again.

While I was not successful in using standard tools, switching to Bayesian modeling using rstan (mc-stan.org/rstan.html) worked better. The results closely match those from Epicure.

Using the data here: http://dwoll.de/err/dat.txt
The stan model fit below replicates the results from Epicure here: http://dwoll.de/err/epicure.log

Of course I am still interested in learning about other options or approaches.

Daniel

##-------
## rstan code for fitting an excess relative risk model with linear dose-response
## events = personYears * exp(beta0 + beta1*age + beta2*sex) * (1 +beta3*dose)

dat_code <- '
data {
    int<lower=0> N;
    vector[N] pyears;
    vector[N] age;
    vector[N] sex;
    vector[N] dose;
    int<lower=0> event[N];
}
transformed data {
    vector[N] log_pyears;
    log_pyears <- log(pyears);
}
parameters {
    vector[2] beta;
    real beta0;              # baseline intercept param
    real<lower=0> betaD;     # dose param -> non-negative
}
model {
    # beta0 unspecified -> uniform prior (improper)
    beta  ~ normal(0, 100);  # flat normal prior for params
    betaD ~ cauchy(0, 2.5);  # ok even if not truncated, cf. stan reference
    event ~ poisson_log(log_pyears + beta0 + beta[1]*age + beta[2]*sex +
                        log(1 + betaD*dose));
}
'

library(rstan)
stan_dat <- with(dat,
                 list(pyears=pyears,
                      age=age,
                      sex=sex,
                      N=length(pyears),
                      event=event,
                      dose=dose))

stanFit <- stan(model_code=dat_code, data=stan_dat,
                thin=5, iter=10000, chains=2)

traceplot(stanFit)
stanFit

-----Original Message-----
From: Wollschlaeger, Daniel 
Sent: Thursday, January 9, 2014 10:44 AM
To: David Winsemius
Cc: r-help at r-project.org
Subject: RE: AW: [R] Linear relative rate / excess relative risk models

Thanks for your suggestions! Here are links to simulated data and the Epicure syntax + reference fit:
http://dwoll.de/err/dat.txt
http://dwoll.de/err/epicure.log

The model tested in Epicure is

lambda = exp(alpha0 + alpha1*agePyr)*(1 + beta0*dosePyr*exp(beta1*agePyr))

with counts in variable event and offset pyears.

Many thanks, D

> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Thursday, January 09, 2014 4:33 AM
> To: Wollschlaeger, Daniel
> Cc: r-help at r-project.org
> Subject: Re: AW: [R] Linear relative rate / excess relative risk models
> 
> 
> On Jan 8, 2014, at 3:22 PM, Wollschlaeger, Daniel wrote:
> 
> > If I understand you correctly, that is exactly the approach taken by
> > Atkinson & Therneau: They get the baseline rates from published rate
> > tables from the general population, multiply them by the appropriate
> > person-time from their data to get expected counts, and use this as
> > offset.
> >
> > Unfortunately, I won't have comparable baseline rate tables. And
> > while I could fit a separate model only to the unexposed group for
> > expected counts, I'd prefer to fit both factors (lambda0 and 1+ERR)
> > simultaneously - as it is typically done in the existing literature.
> 
> If you would describe your data situation more completely (ideally
> with a reproducible example) you might get a better answer. It's also
> considered polite on this mailing list to include the email chain, so
> appending original question:
> 
> --
> David
> 
> >
> > Best, Daniel
> >
> > ________________________________________
> > Von: David Winsemius [dwinsemius at comcast.net]
> > Gesendet: Mittwoch, 8. Januar 2014 19:06
> > An: Wollschlaeger, Daniel
> > Cc: r-help at r-project.org
> > Betreff: Re: [R] Linear relative rate / excess relative risk models
> >
> > I would fit a Poisson model to the dose-response data with offsets
> > for the baseline expecteds.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> ============================
> My question is how I can fit linear relative rate models (= excess
> relative risk models, ERR) using R. In radiation epidemiology, ERR
> models are used to analyze dose-response relationships for event rate
> data and have the following form [1]:
> 
> lambda = lambda0(z, alpha) * (1 + ERR(x, beta))
> 
> * lambda is the event rate
> * lambda0 is the baseline rate function for non-exposed persons and
> depends on covariates z with parameters alpha
> * ERR is the excess relative risk function for exposed persons and
> depends on covariates x (among them dose) with parameters beta
> * lambda/lambda0 = 1 + ERR is the relative rate function
> 
> Often, the covariates z are a subset of the covariates x (like sex and
> age). lambda is assumed to be log-linear in lambda0, and ERR typically
> has a linear (or lin-quadratic) dose term as well as a log-linear
> modifying term with other covariates:
> 
> lambda0 = exp(alpha0 + alpha1*z1 + alpha2*z2 + ...)
> ERR = beta0*dose * exp(beta1*x1 + beta2*x2 + ...)
> 
> The data is often grouped in form of life tables with the observed
> event counts and person-years (pyr) for each cell that results from
> categorizing and cross-classifying the covariates. The counts are
> assumed to have a Poisson-distribution with mean mu = lambda*pyr, and
> the usual Poisson-likelihood is used. The interest is less in lambda0,
> but in inference on the dose coefficient beta0 and on the modifier
> coefficients beta.
> 
> In the literature, the specialized Epicure program is almost
> exclusively used. Last year, a similar question on R-sig-Epi [2] did
> not lead to a successful solution (I contacted the author). Atkinson &
> Therneau in [3] discuss excess risk models but get lambda0 separately
> from external data instead of fitting lambda0 as a log-linear term.
> Some R packages sound promising to me (eg., gnm, timereg) but I
> currently don't see how to correctly specify the model.
> 
> Any help on how to approach ERR models in R is highly appreciated!
> With many thanks and best regards


From phaedrusv at gmail.com  Tue Jul 29 15:01:23 2014
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 29 Jul 2014 14:01:23 +0100
Subject: [R] analyzing qualitative data sets
Message-ID: <53D79B23.4000806@gmail.com>

Hello list

I'm just beginning my PhD and am likely to be using lots of surveys in 
my data collection, and am wanting to get my head around the ideas about 
how best to approach the tasks in R.

The data sets I have collected so far for some preliminary practise with 
are made up of the following survey data:

(1) 25 observations x 15 variables of dichotomous nominal (categorical) 
data [basically, yes/ no responses with a couple of missing values]

(2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with some 
missing values], and

(3) 23 observations of free text, typically in the form of one sentence 
or statement, and I will be using RQDA for that part.

So far, I have been able to piece together that I can use the Spearman 
method of the wilcox.text for #2 (ordinal data), but have yet to find 
anything that I can do for the nominal data. I was thinking of using 
frequency tables, but I don't seem to be able to find out too much info 
on it/ how to do that.
Anyway, I have three questions that I'd appreciate members of this list 
taking a swing at for ideas please.

(a) what types of analyses are available to apply to the data types 
above? I have been thinking about MCA using FactoMineR as well as MDS 
using MASS to visualise the data in high dimensional space, but I think 
that I haven't (yet!) figured out how to properly prepare my data sets 
for these, and most texts and tutorials seem to focus mostly on 
quantitative data analysis.

(b) is there anyway that I can automate the Spearman process so that it 
iterates across the set, otherwise it looks like I may have to manually 
take the two columns and keep comparing pairs until I have correlated 
all of the columns with all of the other columns - so is there anyway 
that I can automate this and get the test statistics and p values dumped 
in a table for summarising?

(c) after using RQDA to code the statements, is it feasible to 
reintroduce those codes back into the data set to explore correlations 
among the other columns and the units of coded text to see what 
variables co-occur?

Well, thanks for taking the time to read this - and I look forward to 
any thoughts/ suggestions that might help.

Cheers


From gunter.berton at gene.com  Tue Jul 29 16:27:46 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 29 Jul 2014 07:27:46 -0700
Subject: [R] analyzing qualitative data sets
In-Reply-To: <53D79B23.4000806@gmail.com>
References: <53D79B23.4000806@gmail.com>
Message-ID: <CACk-te2-8CRO1VUvrq9T9ThQXE00oWOcNts4YbDhSF1d-OAtGQ@mail.gmail.com>

1. If you are asking about statistics, this is the wrong list. Post
here instead: stats.stackexchange.com.

2. If you you are asking about what sorts of statistical analyses are
available in R, check the CRAN task views here:
http://cran.r-project.org/web/views/

3. If you are asking about how to program in R and have not already
done so, please read "An Introduction to R" or R web tutorial of your
choice before posting here further.

Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 29, 2014 at 6:01 AM, Sun Shine <phaedrusv at gmail.com> wrote:
> Hello list
>
> I'm just beginning my PhD and am likely to be using lots of surveys in my
> data collection, and am wanting to get my head around the ideas about how
> best to approach the tasks in R.
>
> The data sets I have collected so far for some preliminary practise with are
> made up of the following survey data:
>
> (1) 25 observations x 15 variables of dichotomous nominal (categorical) data
> [basically, yes/ no responses with a couple of missing values]
>
> (2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with some
> missing values], and
>
> (3) 23 observations of free text, typically in the form of one sentence or
> statement, and I will be using RQDA for that part.
>
> So far, I have been able to piece together that I can use the Spearman
> method of the wilcox.text for #2 (ordinal data), but have yet to find
> anything that I can do for the nominal data. I was thinking of using
> frequency tables, but I don't seem to be able to find out too much info on
> it/ how to do that.
> Anyway, I have three questions that I'd appreciate members of this list
> taking a swing at for ideas please.
>
> (a) what types of analyses are available to apply to the data types above? I
> have been thinking about MCA using FactoMineR as well as MDS using MASS to
> visualise the data in high dimensional space, but I think that I haven't
> (yet!) figured out how to properly prepare my data sets for these, and most
> texts and tutorials seem to focus mostly on quantitative data analysis.
>
> (b) is there anyway that I can automate the Spearman process so that it
> iterates across the set, otherwise it looks like I may have to manually take
> the two columns and keep comparing pairs until I have correlated all of the
> columns with all of the other columns - so is there anyway that I can
> automate this and get the test statistics and p values dumped in a table for
> summarising?
>
> (c) after using RQDA to code the statements, is it feasible to reintroduce
> those codes back into the data set to explore correlations among the other
> columns and the units of coded text to see what variables co-occur?
>
> Well, thanks for taking the time to read this - and I look forward to any
> thoughts/ suggestions that might help.
>
> Cheers
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Jul 29 17:01:44 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 29 Jul 2014 09:01:44 -0600
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>

There is the TkBrush function in the TeachingDemos package that gives
brushing in a scatterplot matrix using a Tk interface rather than
ggobi.  There is also the iplots package which allows you to create
multiple scatterplots, histograms, boxplots, barcharts, etc. and
points selected in any one of the plots will then be highlighted in
all the others.  Both of those solutions require R to be installed.

I don't know of any way to get what you want without installing at
least one of ggobi or R (or some other program of similar complexity
to install).

On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
> hi list,
>
> I'm comparing the changes of ~100 analytes in multiple treatment conditions.  I plotted them in several different xy scattter plots.  It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown.  I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine).  rCharts is nice but so far it can only create one scatter plot at a time.
>
> Any good suggestions?
>
> Many thanks!
>
> Tao
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From kw1958 at gmail.com  Tue Jul 29 17:19:33 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 29 Jul 2014 11:19:33 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
Message-ID: <0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>

John Et Al.

I can get rJava and XLConnect to work only if I run as super user.

Note that I have built rJava and XLConnect as super user (otherwise neither package works).


____________________________________________
Without sudo

> require(XLConnect)
Loading required package: XLConnect
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
  libjvm.so: cannot open shared object file: No such file or directory
_____________________________________________
With sudo

 > require(XLConnect)
Loading required package: XLConnect
XLConnect 0.2-7 by Mirai Solutions GmbH
http://www.mirai-solutions.com ,
http://miraisolutions.wordpress.com

______________________________________________
Note that I have changed the ownership (recursively) for rJava and XLConnect because they were previously owned by root. Also note that ggplot2 (included for comparison) was installed the usual way with no problem.

drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/

________________________________________________

Despite "no such file or directory" above:

/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr /home/refserv/>
-rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28 /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so

The file rJava.so exists.

Thanks so much for your time and help,
Best,
KW

--

On Jul 24, 2014, at 11:16 PM, John McKown <john.archie.mckown at gmail.com> wrote:

> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> Folks,
>> 
>> I have been trying to get XLConnect to work on my Linux Mint Maya machine.
>> 
>> R works fine but this package doesn't seem to want to build. Here is the message I get after supposedly building XLConnect and rJava:
>> 
>> 
>>>> require(XLConnect)
>>> Loading required package: XLConnect
>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>> error: unable to load shared object '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>> libjvm.so: cannot open shared object file: No such file or directory
>> 
>> 
>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>> 
>> The build and the compile seemed to work ok as there were no errors. For example I can generate ggplot2 graphs.
>> 
>> I know this is probably the wrong forum but if someone could gently point me in the right direction I would be very appreciative.
>> 
>> Thanks so much for your time,
>> KW
> 
> It works fine for me on Fedora 20 (and 19 before it). When I installed
> R, it installed into /usr/lib64/R. There exists a file:
> /usr/lib64/R/etc/ldpaths which is executed by the R executable script.
> This sets up the LD_LIBRARY_PATH to point to the Java installation on
> my machine. In the /usr/lib64/R/bin directory, there is a program
> called "javareconf". I would suggest that you run this with the -n
> switch, like:
> 
> R CMD /usr/lib64/R/bin/javareconf -n
> 
> This will show you what it _would_ do if you left off the "-n". Make
> sure it looks reasonable. If it does, then run the same command,
> without the "-n", as the "root" superuser. In my case, that would be:
> 
> sudo R CMD /usr/lib64/R/bin/javareconf
> 
> You need to be "root" because it update the file
> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
> problem.
> 
> ===
> 
> As a possible alternative to XLConnect, have you looked at openxlsx?
> It appears to have the same abilities, just some different syntax. It
> says that it is written in C and so should be faster than XLConnect. I
> have tested both packages, a little, and they both seem to work well.
> 
> Well, it's 22:14 hours here and I wish that I could fall asleep. We're
> having problems at work and I know that the "big boss" will blame us
> peons if the hardware isn't fixed promptly Despite the fact that we
> are only software people and aren't allowed to touch the hardware. Our
> management's minds are not using the same logic as mine does.
> Frustrating.
> 
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown


From acefix at rocketmail.com  Tue Jul 29 17:11:09 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 29 Jul 2014 08:11:09 -0700
Subject: [R] venn.diagram, error message: Incorrect number of elements
Message-ID: <1406646669.68250.YahooMailNeo@web164603.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/6a90a83f/attachment.pl>

From leighton at hydrofocus.com  Tue Jul 29 17:24:59 2014
From: leighton at hydrofocus.com (Dave Leighton)
Date: Tue, 29 Jul 2014 08:24:59 -0700
Subject: [R] Copulas and spatial modeling
Message-ID: <CAGGwnOCveKSNbVqrdmekSPp=iVFapMFXz+WA2_3goxaqgXe8Ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/f0989c5a/attachment.pl>

From ramnath.vaidyanathan at mcgill.ca  Tue Jul 29 17:10:57 2014
From: ramnath.vaidyanathan at mcgill.ca (Ramnath Vaidyanathan)
Date: Tue, 29 Jul 2014 11:10:57 -0400
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
Message-ID: <CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/83461846/attachment.pl>

From rmh at temple.edu  Tue Jul 29 17:44:59 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 29 Jul 2014 11:44:59 -0400
Subject: [R] analyzing qualitative data sets
In-Reply-To: <53D79B23.4000806@gmail.com>
References: <53D79B23.4000806@gmail.com>
Message-ID: <CAGx1TMBZAsg0FZDMA1K-KogO300q=_OPSEJj9T280u2pybn8tg@mail.gmail.com>

For your item 2,
(2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with
some missing values], and

I recommend the likert function in the HH package
install.packages("HH")
library(HH)
?likert

Rich

On Tue, Jul 29, 2014 at 9:01 AM, Sun Shine <phaedrusv at gmail.com> wrote:
> Hello list
>
> I'm just beginning my PhD and am likely to be using lots of surveys in my
> data collection, and am wanting to get my head around the ideas about how
> best to approach the tasks in R.
>
> The data sets I have collected so far for some preliminary practise with are
> made up of the following survey data:
>
> (1) 25 observations x 15 variables of dichotomous nominal (categorical) data
> [basically, yes/ no responses with a couple of missing values]
>
> (2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with some
> missing values], and
>
> (3) 23 observations of free text, typically in the form of one sentence or
> statement, and I will be using RQDA for that part.
>
> So far, I have been able to piece together that I can use the Spearman
> method of the wilcox.text for #2 (ordinal data), but have yet to find
> anything that I can do for the nominal data. I was thinking of using
> frequency tables, but I don't seem to be able to find out too much info on
> it/ how to do that.
> Anyway, I have three questions that I'd appreciate members of this list
> taking a swing at for ideas please.
>
> (a) what types of analyses are available to apply to the data types above? I
> have been thinking about MCA using FactoMineR as well as MDS using MASS to
> visualise the data in high dimensional space, but I think that I haven't
> (yet!) figured out how to properly prepare my data sets for these, and most
> texts and tutorials seem to focus mostly on quantitative data analysis.
>
> (b) is there anyway that I can automate the Spearman process so that it
> iterates across the set, otherwise it looks like I may have to manually take
> the two columns and keep comparing pairs until I have correlated all of the
> columns with all of the other columns - so is there anyway that I can
> automate this and get the test statistics and p values dumped in a table for
> summarising?
>
> (c) after using RQDA to code the statements, is it feasible to reintroduce
> those codes back into the data set to explore correlations among the other
> columns and the units of coded text to see what variables co-occur?
>
> Well, thanks for taking the time to read this - and I look forward to any
> thoughts/ suggestions that might help.
>
> Cheers
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Tue Jul 29 15:29:10 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 29 Jul 2014 06:29:10 -0700 (PDT)
Subject: [R] analyzing qualitative data sets
In-Reply-To: <53D79B23.4000806@gmail.com>
References: <53D79B23.4000806@gmail.com>
Message-ID: <alpine.LNX.2.11.1407290623020.8911@localhost>

On Tue, 29 Jul 2014, Sun Shine wrote:

> (a) what types of analyses are available to apply to the data types above?

   Many years ago I consulted to a graduate nursing program; the students
were asking the same questions you ask: what sort of statistics will turn my
sow's ears of survey data into a silk purse of a Masters in Nursing (ed. or
admin. were the two options).

   I'll tell you what I told them. First, decide what question(s) you want to
answer, in detail not generalities. Second, design your surveys so that they
can provide the data you need to answer your questions. Also, know how to
select potential responders.

   I am far from knowledgeable about surveys, but what I do know is that they
are difficult to construct so the responses will allow answers to the
questions of concern.

   You are encouraged to think more about the end result before you seek
magic to rescue inappropriate data.

Rich

-- 
Richard B. Shepard, Ph.D.
Applied Ecosystem Services, Inc. | Troutdale, OR 97060 USA
www.appl-ecosys.com      Voice: 503-667-4517         Fax: 503-667-8863


From reed at graphicacy.com  Tue Jul 29 18:02:31 2014
From: reed at graphicacy.com (Reed Spool)
Date: Tue, 29 Jul 2014 12:02:31 -0400
Subject: [R] Dependency Injection & Inversion of Control for Data
Message-ID: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/e83369ce/attachment.pl>

From paulbernal07 at gmail.com  Tue Jul 29 18:35:44 2014
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 29 Jul 2014 11:35:44 -0500
Subject: [R] Trouble with function nnetar
Message-ID: <CAMOcQfP41rog1VUqrh2cevqKBOZMqgR3ZLuob_+HFBsKXqj_ug@mail.gmail.com>

 I was playing around with the nnetar function in the forecast package,
trying to generate a 3-year forecast (36 months), the R fit result is shown
below:

 #Neural Nets Fitting and Forecast
>
> fit<-nnetar(condataset$ConPcums97)
> fit
Series: condataset$ConPcums97
Model:  NNAR(13)
Call:   nnetar(x = condataset$ConPcums97)

Average of 20 networks, each of which is
a 13-7-1 network with 106 weights
options were - linear output units

sigma^2 estimated as 5.34e+12

Now, R is sending me the following error message:

 x<-forecast(fit, h=36)
Error in predict.nnet(X[[1L]], ...) : missing values in 'x'
>
> forecast(fit)
Error in predict.nnet(X[[1L]], ...) : missing values in 'x'
> x<-forecast(nnetar(condataset$ConPcums97), h=36)
Error in predict.nnet(X[[1L]], ...) : missing values in 'x'

I am attaching the same data I used to try the nnetar function. Can you
give me some guidance or tell me what could be done to generate the
forecast with this function?

Best regards,

Paul

From jdnewmil at dcn.davis.CA.us  Tue Jul 29 18:54:59 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 29 Jul 2014 09:54:59 -0700
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
	<0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
Message-ID: <e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>

Sounds to me like a problem outside of R (off topic here). In particular, it doesn't sound like you are using the appropriate tools (apt-get package manager for R and a JDK; R install.package() for your R packages) to admin your machine. The only thing you should need sudo for is to run apt-get... everything else should be done as a normal user unless you really know what you are doing. I had no problem installing it just now on my Ubuntu machine with OpenJDK. I have no experience with Mint but Google tells me you should be able to use the instructions for Ubuntu... I would expect Google to tell you the same thing if you ask nicely... your most challenging task at this point should be cleaning up the mess you have made by excessive use of sudo ... most likely running R with it (only update your personal R library directories so you are not tempted to go rogue) but you don't say how you installed the jdk so that could also be messed up. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 29, 2014 8:19:33 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>John Et Al.
>
>I can get rJava and XLConnect to work only if I run as super user.
>
>Note that I have built rJava and XLConnect as super user (otherwise
>neither package works).
>
>
>____________________________________________
>Without sudo
>
>> require(XLConnect)
>Loading required package: XLConnect
>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>error: unable to load shared object
>'/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>  libjvm.so: cannot open shared object file: No such file or directory
>_____________________________________________
>With sudo
>
> > require(XLConnect)
>Loading required package: XLConnect
>XLConnect 0.2-7 by Mirai Solutions GmbH
>http://www.mirai-solutions.com ,
>http://miraisolutions.wordpress.com
>
>______________________________________________
>Note that I have changed the ownership (recursively) for rJava and
>XLConnect because they were previously owned by root. Also note that
>ggplot2 (included for comparison) was installed the usual way with no
>problem.
>
>drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
>drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
>drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/
>
>________________________________________________
>
>Despite "no such file or directory" above:
>
>/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr
>/home/refserv/>
>-rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28
>/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so
>
>The file rJava.so exists.
>
>Thanks so much for your time and help,
>Best,
>KW
>
>--
>
>On Jul 24, 2014, at 11:16 PM, John McKown
><john.archie.mckown at gmail.com> wrote:
>
>> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com>
>wrote:
>>> Folks,
>>> 
>>> I have been trying to get XLConnect to work on my Linux Mint Maya
>machine.
>>> 
>>> R works fine but this package doesn't seem to want to build. Here is
>the message I get after supposedly building XLConnect and rJava:
>>> 
>>> 
>>>>> require(XLConnect)
>>>> Loading required package: XLConnect
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>> error: unable to load shared object
>'/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>> libjvm.so: cannot open shared object file: No such file or
>directory
>>> 
>>> 
>>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>>> 
>>> The build and the compile seemed to work ok as there were no errors.
>For example I can generate ggplot2 graphs.
>>> 
>>> I know this is probably the wrong forum but if someone could gently
>point me in the right direction I would be very appreciative.
>>> 
>>> Thanks so much for your time,
>>> KW
>> 
>> It works fine for me on Fedora 20 (and 19 before it). When I
>installed
>> R, it installed into /usr/lib64/R. There exists a file:
>> /usr/lib64/R/etc/ldpaths which is executed by the R executable
>script.
>> This sets up the LD_LIBRARY_PATH to point to the Java installation on
>> my machine. In the /usr/lib64/R/bin directory, there is a program
>> called "javareconf". I would suggest that you run this with the -n
>> switch, like:
>> 
>> R CMD /usr/lib64/R/bin/javareconf -n
>> 
>> This will show you what it _would_ do if you left off the "-n". Make
>> sure it looks reasonable. If it does, then run the same command,
>> without the "-n", as the "root" superuser. In my case, that would be:
>> 
>> sudo R CMD /usr/lib64/R/bin/javareconf
>> 
>> You need to be "root" because it update the file
>> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
>> problem.
>> 
>> ===
>> 
>> As a possible alternative to XLConnect, have you looked at openxlsx?
>> It appears to have the same abilities, just some different syntax. It
>> says that it is written in C and so should be faster than XLConnect.
>I
>> have tested both packages, a little, and they both seem to work well.
>> 
>> Well, it's 22:14 hours here and I wish that I could fall asleep.
>We're
>> having problems at work and I know that the "big boss" will blame us
>> peons if the hardware isn't fixed promptly Despite the fact that we
>> are only software people and aren't allowed to touch the hardware.
>Our
>> management's minds are not using the same logic as mine does.
>> Frustrating.
>> 
>> -- 
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>> 
>> Maranatha! <><
>> John McKown
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Jul 29 18:57:09 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 29 Jul 2014 09:57:09 -0700
Subject: [R] Dependency Injection & Inversion of Control for Data
In-Reply-To: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
References: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
Message-ID: <CAF8bMcbGunKSqPWqa9yBD-if=tkD2CrjHB28zZVdisEioeV8jA@mail.gmail.com>

R is a functional language so you might want to google for 'dependency
injection functional language' and see why dependency injection is not
a hot concept in R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jul 29, 2014 at 9:02 AM, Reed Spool <reed at graphicacy.com> wrote:
> Greetings,
>
> New to R, coming from Java (Spring).
>
> We have many different data sources (CSV's) for our analysis. Some of them
> need preprocessing at the time of analysis - doing it earlier and saving
> the resultant table doesn't make sense.
>
> My code is getting tangled quickly as I try to read.csv my many data files
> and source both the preprocessing stuff as well as my analysis code.
>
> I'm hoping for a streamlined method of injecting the data/code needed into
> my analysis code, instead of imperatively sorting everything out at the top
> of my analysis code.
>
> Googling "Dependency Injection R" and "Inversion of Control R" gave nothing
> useful. Searching for "Dependency Management" brought me to the packrat
> package, but that doesn't seem to have the injection element I'm looking
> for (as I would expect from such a system).
>
> Am I barking up the wrong tree? I can't imagine my problem is a new one.
> How do you solve it?
>
> Cheers,
> Reed
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Jul 29 19:10:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 29 Jul 2014 10:10:48 -0700
Subject: [R] Dependency Injection & Inversion of Control for Data
In-Reply-To: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
References: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
Message-ID: <54af6398-0b29-4b65-87d5-e09f8fb573e4@email.android.com>

Color me mystified. In particular, "preprocessing at the time of analysis"... what is wrong with writing a function that gets your data and cleans it up, then calling it when you feel the time is right?

Note that R is optimized for vector processing (columns), not row-by-row processing, so the sooner you embrace this paradigm will be the sooner you will be productive with it. Where your data do not match this structure the most effective strategy is to transform it to that structure, perhaps using Rcpp or an external tool.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 29, 2014 9:02:31 AM PDT, Reed Spool <reed at graphicacy.com> wrote:
>Greetings,
>
>New to R, coming from Java (Spring).
>
>We have many different data sources (CSV's) for our analysis. Some of
>them
>need preprocessing at the time of analysis - doing it earlier and
>saving
>the resultant table doesn't make sense.
>
>My code is getting tangled quickly as I try to read.csv my many data
>files
>and source both the preprocessing stuff as well as my analysis code.
>
>I'm hoping for a streamlined method of injecting the data/code needed
>into
>my analysis code, instead of imperatively sorting everything out at the
>top
>of my analysis code.
>
>Googling "Dependency Injection R" and "Inversion of Control R" gave
>nothing
>useful. Searching for "Dependency Management" brought me to the packrat
>package, but that doesn't seem to have the injection element I'm
>looking
>for (as I would expect from such a system).
>
>Am I barking up the wrong tree? I can't imagine my problem is a new
>one.
>How do you solve it?
>
>Cheers,
>Reed
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Jul 29 19:45:32 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 29 Jul 2014 10:45:32 -0700
Subject: [R] Dependency Injection & Inversion of Control for Data
In-Reply-To: <CAF8bMcbGunKSqPWqa9yBD-if=tkD2CrjHB28zZVdisEioeV8jA@mail.gmail.com>
References: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
	<CAF8bMcbGunKSqPWqa9yBD-if=tkD2CrjHB28zZVdisEioeV8jA@mail.gmail.com>
Message-ID: <CACk-te2c2vnNOCPSU6NMom=uy1pbdH_Wx5qsVXVHP7-K-Q0CzA@mail.gmail.com>

...
and so it is straightforward to have both data and a preprocessing
function as arguments to an analysis function so that the
preprocessing is done both appropriately and efficiently.  Or to pass
both data and preprocessing function as a single construct.

If this misstates the issue, please say so.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Jul 29, 2014 at 9:57 AM, William Dunlap <wdunlap at tibco.com> wrote:
> R is a functional language so you might want to google for 'dependency
> injection functional language' and see why dependency injection is not
> a hot concept in R.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Jul 29, 2014 at 9:02 AM, Reed Spool <reed at graphicacy.com> wrote:
>> Greetings,
>>
>> New to R, coming from Java (Spring).
>>
>> We have many different data sources (CSV's) for our analysis. Some of them
>> need preprocessing at the time of analysis - doing it earlier and saving
>> the resultant table doesn't make sense.
>>
>> My code is getting tangled quickly as I try to read.csv my many data files
>> and source both the preprocessing stuff as well as my analysis code.
>>
>> I'm hoping for a streamlined method of injecting the data/code needed into
>> my analysis code, instead of imperatively sorting everything out at the top
>> of my analysis code.
>>
>> Googling "Dependency Injection R" and "Inversion of Control R" gave nothing
>> useful. Searching for "Dependency Management" brought me to the packrat
>> package, but that doesn't seem to have the injection element I'm looking
>> for (as I would expect from such a system).
>>
>> Am I barking up the wrong tree? I can't imagine my problem is a new one.
>> How do you solve it?
>>
>> Cheers,
>> Reed
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reed at graphicacy.com  Tue Jul 29 19:49:48 2014
From: reed at graphicacy.com (Reed Spool)
Date: Tue, 29 Jul 2014 13:49:48 -0400
Subject: [R] Dependency Injection & Inversion of Control for Data
In-Reply-To: <54af6398-0b29-4b65-87d5-e09f8fb573e4@email.android.com>
References: <CAKRRKabJU1FXFCLHB=SsXjUJrCM1ohFhqEyVOKbkZ=HYivjpdQ@mail.gmail.com>
	<54af6398-0b29-4b65-87d5-e09f8fb573e4@email.android.com>
Message-ID: <CAKRRKaY+kG0PBSiUE3jMpV_C2x6MFMqZ44g+JT=Vs2hXkMrfuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/5e1c70c6/attachment.pl>

From phaedrusv at gmail.com  Tue Jul 29 20:00:21 2014
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 29 Jul 2014 19:00:21 +0100
Subject: [R] analyzing qualitative data sets
In-Reply-To: <CAGx1TMBZAsg0FZDMA1K-KogO300q=_OPSEJj9T280u2pybn8tg@mail.gmail.com>
References: <53D79B23.4000806@gmail.com>
	<CAGx1TMBZAsg0FZDMA1K-KogO300q=_OPSEJj9T280u2pybn8tg@mail.gmail.com>
Message-ID: <53D7E135.3000708@gmail.com>

Thanks, I'll look into that further.

Cheers


On 29/07/14 16:44, Richard M. Heiberger wrote:
> For your item 2,
> (2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with
> some missing values], and
>
> I recommend the likert function in the HH package
> install.packages("HH")
> library(HH)
> ?likert
>
> Rich
>
> On Tue, Jul 29, 2014 at 9:01 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hello list
>>
>> I'm just beginning my PhD and am likely to be using lots of surveys in my
>> data collection, and am wanting to get my head around the ideas about how
>> best to approach the tasks in R.
>>
>> The data sets I have collected so far for some preliminary practise with are
>> made up of the following survey data:
>>
>> (1) 25 observations x 15 variables of dichotomous nominal (categorical) data
>> [basically, yes/ no responses with a couple of missing values]
>>
>> (2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with some
>> missing values], and
>>
>> (3) 23 observations of free text, typically in the form of one sentence or
>> statement, and I will be using RQDA for that part.
>>
>> So far, I have been able to piece together that I can use the Spearman
>> method of the wilcox.text for #2 (ordinal data), but have yet to find
>> anything that I can do for the nominal data. I was thinking of using
>> frequency tables, but I don't seem to be able to find out too much info on
>> it/ how to do that.
>> Anyway, I have three questions that I'd appreciate members of this list
>> taking a swing at for ideas please.
>>
>> (a) what types of analyses are available to apply to the data types above? I
>> have been thinking about MCA using FactoMineR as well as MDS using MASS to
>> visualise the data in high dimensional space, but I think that I haven't
>> (yet!) figured out how to properly prepare my data sets for these, and most
>> texts and tutorials seem to focus mostly on quantitative data analysis.
>>
>> (b) is there anyway that I can automate the Spearman process so that it
>> iterates across the set, otherwise it looks like I may have to manually take
>> the two columns and keep comparing pairs until I have correlated all of the
>> columns with all of the other columns - so is there anyway that I can
>> automate this and get the test statistics and p values dumped in a table for
>> summarising?
>>
>> (c) after using RQDA to code the statements, is it feasible to reintroduce
>> those codes back into the data set to explore correlations among the other
>> columns and the units of coded text to see what variables co-occur?
>>
>> Well, thanks for taking the time to read this - and I look forward to any
>> thoughts/ suggestions that might help.
>>
>> Cheers
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From phaedrusv at gmail.com  Tue Jul 29 20:01:31 2014
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 29 Jul 2014 19:01:31 +0100
Subject: [R] analyzing qualitative data sets
In-Reply-To: <CACk-te2-8CRO1VUvrq9T9ThQXE00oWOcNts4YbDhSF1d-OAtGQ@mail.gmail.com>
References: <53D79B23.4000806@gmail.com>
	<CACk-te2-8CRO1VUvrq9T9ThQXE00oWOcNts4YbDhSF1d-OAtGQ@mail.gmail.com>
Message-ID: <53D7E17B.30900@gmail.com>

Thanks for the link. I had not been aware of that.


On 29/07/14 15:27, Bert Gunter wrote:
> 1. If you are asking about statistics, this is the wrong list. Post
> here instead: stats.stackexchange.com.
>
> 2. If you you are asking about what sorts of statistical analyses are
> available in R, check the CRAN task views here:
> http://cran.r-project.org/web/views/
>
> 3. If you are asking about how to program in R and have not already
> done so, please read "An Introduction to R" or R web tutorial of your
> choice before posting here further.
>
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Jul 29, 2014 at 6:01 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hello list
>>
>> I'm just beginning my PhD and am likely to be using lots of surveys in my
>> data collection, and am wanting to get my head around the ideas about how
>> best to approach the tasks in R.
>>
>> The data sets I have collected so far for some preliminary practise with are
>> made up of the following survey data:
>>
>> (1) 25 observations x 15 variables of dichotomous nominal (categorical) data
>> [basically, yes/ no responses with a couple of missing values]
>>
>> (2) 25 obs x 14 var of ordinal rank data [5 item Likert-scale, with some
>> missing values], and
>>
>> (3) 23 observations of free text, typically in the form of one sentence or
>> statement, and I will be using RQDA for that part.
>>
>> So far, I have been able to piece together that I can use the Spearman
>> method of the wilcox.text for #2 (ordinal data), but have yet to find
>> anything that I can do for the nominal data. I was thinking of using
>> frequency tables, but I don't seem to be able to find out too much info on
>> it/ how to do that.
>> Anyway, I have three questions that I'd appreciate members of this list
>> taking a swing at for ideas please.
>>
>> (a) what types of analyses are available to apply to the data types above? I
>> have been thinking about MCA using FactoMineR as well as MDS using MASS to
>> visualise the data in high dimensional space, but I think that I haven't
>> (yet!) figured out how to properly prepare my data sets for these, and most
>> texts and tutorials seem to focus mostly on quantitative data analysis.
>>
>> (b) is there anyway that I can automate the Spearman process so that it
>> iterates across the set, otherwise it looks like I may have to manually take
>> the two columns and keep comparing pairs until I have correlated all of the
>> columns with all of the other columns - so is there anyway that I can
>> automate this and get the test statistics and p values dumped in a table for
>> summarising?
>>
>> (c) after using RQDA to code the statements, is it feasible to reintroduce
>> those codes back into the data set to explore correlations among the other
>> columns and the units of coded text to see what variables co-occur?
>>
>> Well, thanks for taking the time to read this - and I look forward to any
>> thoughts/ suggestions that might help.
>>
>> Cheers
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gayonclarke at yahoo.com  Tue Jul 29 20:04:35 2014
From: gayonclarke at yahoo.com (Gayon Clarke)
Date: Tue, 29 Jul 2014 13:04:35 -0500
Subject: [R] Help with splitting up values in a data set
Message-ID: <7CC66B12-9714-4863-B089-D425DC2CC9CC@yahoo.com>

Good day,

I have a data set from a MySQL database with a description field that I want to spilt up the values in order to compare the description of one record to the others. This will help me to identify any patterns with the data being recorded. 

Your help will be gladly appreciated. 

Gayon  


From istazahn at gmail.com  Tue Jul 29 20:22:07 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 29 Jul 2014 14:22:07 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
	<0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
	<e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>
Message-ID: <CA+vqiLFqYCJus7oFEc-MEaTkTJ2a1j0jOtjKm9hdNUF+0bORxQ@mail.gmail.com>

On Tue, Jul 29, 2014 at 12:54 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Sounds to me like a problem outside of R (off topic here).

Possibly, but I suspect that the OP now has two versions of XLConnect
installed, one in the user R library and one in the system-wide R
library.

Keith, try

remove.packages("XLConnect")
remove.packages("rJava")

WITHOUT sudo. Then restart R; you should now get the (working)
system-wide versions of rJava and XLConnect.

HTH,
Ista

 In particular, it doesn't sound like you are using the appropriate
tools (apt-get package manager for R and a JDK; R install.package()
for your R packages) to admin your machine. The only thing you should
need sudo for is to run apt-get... everything else should be done as a
normal user unless you really know what you are doing. I had no
problem installing it just now on my Ubuntu machine with OpenJDK. I
have no experience with Mint but Google tells me you should be able to
use the instructions for Ubuntu... I would expect Google to tell you
the same thing if you ask nicely... your most challenging task at this
point should be cleaning up the mess you have made by excessive use of
sudo ... most likely running R with it (only update your personal R
library directories so you are not tempted to go rogue) but you don't
say how you installed the jdk so that could also be messed up.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On July 29, 2014 8:19:33 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>>John Et Al.
>>
>>I can get rJava and XLConnect to work only if I run as super user.
>>
>>Note that I have built rJava and XLConnect as super user (otherwise
>>neither package works).
>>
>>
>>____________________________________________
>>Without sudo
>>
>>> require(XLConnect)
>>Loading required package: XLConnect
>>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>  call: dyn.load(file, DLLpath = DLLpath, ...)
>>error: unable to load shared object
>>'/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>  libjvm.so: cannot open shared object file: No such file or directory
>>_____________________________________________
>>With sudo
>>
>> > require(XLConnect)
>>Loading required package: XLConnect
>>XLConnect 0.2-7 by Mirai Solutions GmbH
>>http://www.mirai-solutions.com ,
>>http://miraisolutions.wordpress.com
>>
>>______________________________________________
>>Note that I have changed the ownership (recursively) for rJava and
>>XLConnect because they were previously owned by root. Also note that
>>ggplot2 (included for comparison) was installed the usual way with no
>>problem.
>>
>>drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
>>drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
>>drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/
>>
>>________________________________________________
>>
>>Despite "no such file or directory" above:
>>
>>/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr
>>/home/refserv/>
>>-rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28
>>/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so
>>
>>The file rJava.so exists.
>>
>>Thanks so much for your time and help,
>>Best,
>>KW
>>
>>--
>>
>>On Jul 24, 2014, at 11:16 PM, John McKown
>><john.archie.mckown at gmail.com> wrote:
>>
>>> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com>
>>wrote:
>>>> Folks,
>>>>
>>>> I have been trying to get XLConnect to work on my Linux Mint Maya
>>machine.
>>>>
>>>> R works fine but this package doesn't seem to want to build. Here is
>>the message I get after supposedly building XLConnect and rJava:
>>>>
>>>>
>>>>>> require(XLConnect)
>>>>> Loading required package: XLConnect
>>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>>> error: unable to load shared object
>>'/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>>> libjvm.so: cannot open shared object file: No such file or
>>directory
>>>>
>>>>
>>>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>>>>
>>>> The build and the compile seemed to work ok as there were no errors.
>>For example I can generate ggplot2 graphs.
>>>>
>>>> I know this is probably the wrong forum but if someone could gently
>>point me in the right direction I would be very appreciative.
>>>>
>>>> Thanks so much for your time,
>>>> KW
>>>
>>> It works fine for me on Fedora 20 (and 19 before it). When I
>>installed
>>> R, it installed into /usr/lib64/R. There exists a file:
>>> /usr/lib64/R/etc/ldpaths which is executed by the R executable
>>script.
>>> This sets up the LD_LIBRARY_PATH to point to the Java installation on
>>> my machine. In the /usr/lib64/R/bin directory, there is a program
>>> called "javareconf". I would suggest that you run this with the -n
>>> switch, like:
>>>
>>> R CMD /usr/lib64/R/bin/javareconf -n
>>>
>>> This will show you what it _would_ do if you left off the "-n". Make
>>> sure it looks reasonable. If it does, then run the same command,
>>> without the "-n", as the "root" superuser. In my case, that would be:
>>>
>>> sudo R CMD /usr/lib64/R/bin/javareconf
>>>
>>> You need to be "root" because it update the file
>>> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
>>> problem.
>>>
>>> ===
>>>
>>> As a possible alternative to XLConnect, have you looked at openxlsx?
>>> It appears to have the same abilities, just some different syntax. It
>>> says that it is written in C and so should be faster than XLConnect.
>>I
>>> have tested both packages, a little, and they both seem to work well.
>>>
>>> Well, it's 22:14 hours here and I wish that I could fall asleep.
>>We're
>>> having problems at work and I know that the "big boss" will blame us
>>> peons if the hardware isn't fixed promptly Despite the fact that we
>>> are only software people and aren't allowed to touch the hardware.
>>Our
>>> management's minds are not using the same logic as mine does.
>>> Frustrating.
>>>
>>> --
>>> There is nothing more pleasant than traveling and meeting new people!
>>> Genghis Khan
>>>
>>> Maranatha! <><
>>> John McKown
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From doug.reid at ontario.ca  Tue Jul 29 21:57:29 2014
From: doug.reid at ontario.ca (Reid, Doug (MNR))
Date: Tue, 29 Jul 2014 19:57:29 +0000
Subject: [R] Post hoc comparissons
Message-ID: <DA616A2FCD46844DB2333D0BD00DE545133DE3@CTSPIGDCAPMXS31.cihs.ad.gov.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/124d2f9f/attachment.pl>

From sarah.goslee at gmail.com  Tue Jul 29 22:07:59 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 29 Jul 2014 16:07:59 -0400
Subject: [R] venn.diagram, error message: Incorrect number of elements
In-Reply-To: <1406646669.68250.YahooMailNeo@web164603.mail.gq1.yahoo.com>
References: <1406646669.68250.YahooMailNeo@web164603.mail.gq1.yahoo.com>
Message-ID: <CAM_vju=aq5L=X-adNF3KzN7QK-bXo9UWEaLKnMwLaD0RX7Nqjg@mail.gmail.com>

The venn.diagram() function in the package VennDiagram only works with
sizes up to 5.

That isn't horribly clear from the help file, but quite explicit in the code:

    if (0 == length(x) | length(x) > 5) {
        stop("Incorrect number of elements.", call. = FALSE)
    }

If you really need 6, you could presumably look at the way that
venn.diagram() works and add in your own 6-handling code.

Sarah


On Tue, Jul 29, 2014 at 11:11 AM, Fix Ace <acefix at rocketmail.com> wrote:
> Hello, there,
> I have 6 dataset and trying to draw a venn.diagram using R VennDiagram package, but got this error message. Could anybody figure out why?
>
> Thanks
> ===
>> library(VennDiagram)
> Loading required package: grid
>
>> head(A)
>                V1
> 1 F_HO10000
> 2 F_HO10001
> 3 F_HO10002
> 4 F_HO10003
> 5 F_HO10004
> 6 F_HO10005
>> head(B)
>                V1
> 1  F_HO1000
> 2 F_HO10000
> 3 F_HO10001
> 4 F_HO10002
> 5 F_HO10003
> 6 F_HO10004
>> head(C)
>                V1
> 1 F_HO10000
> 2 F_HO10001
> 3 F_HO10002
> 4 F_HO10003
> 5 F_HO10004
> 6 F_HO10005
>> head(D)
>                V1
> 1  F_HO1000
> 2 F_HO10000
> 3 F_HO10001
> 4 F_HO10002
> 5 F_HO10003
> 6 F_HO10004
>> head(E)
>                V1
> 1 F_HO10001
> 2 F_HO10002
> 3 F_HO10004
> 4 F_HO10007
> 5 F_HO10008
> 6 F_HO10009
>> head(F)
>                V1
> 1  F_HO1000
> 2 F_HO10000
> 3 F_HO10001
> 4 F_HO10002
> 5 F_HO10003
> 6 F_HO10004
>> venn.diagram(x=list(A=A[,1], B=B[,1], C=C[,1], D=D[,1], E=E[,1], F=F[,1]), filename="Venn-6.test.tiff", col="transparent", alpha=0.5, fill=c("dodgerblue","goldenrod1","darkorange1","seagreen3","orchid3", "green"), margin=0.2)
> Error: Incorrect number of elements.
>>
>
>         [[alternative HTML version deleted]]
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From r.turner at auckland.ac.nz  Tue Jul 29 22:44:55 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 30 Jul 2014 08:44:55 +1200
Subject: [R] analyzing qualitative data sets
In-Reply-To: <alpine.LNX.2.11.1407290623020.8911@localhost>
References: <53D79B23.4000806@gmail.com>
	<alpine.LNX.2.11.1407290623020.8911@localhost>
Message-ID: <53D807C7.3080102@auckland.ac.nz>



A goldmine of fortunes!!!

cheers,

Rolf

On 30/07/14 01:29, Rich Shepard wrote:
> On Tue, 29 Jul 2014, Sun Shine wrote:
>
>> (a) what types of analyses are available to apply to the data types
>> above?
>
>    Many years ago I consulted to a graduate nursing program; the students
> were asking the same questions you ask: what sort of statistics will
> turn my
> sow's ears of survey data into a silk purse of a Masters in Nursing (ed. or
> admin. were the two options).
>
>    I'll tell you what I told them. First, decide what question(s) you
> want to
> answer, in detail not generalities. Second, design your surveys so that
> they
> can provide the data you need to answer your questions. Also, know how to
> select potential responders.
>
>    I am far from knowledgeable about surveys, but what I do know is that
> they
> are difficult to construct so the responses will allow answers to the
> questions of concern.
>
>    You are encouraged to think more about the end result before you seek
> magic to rescue inappropriate data.

-- 
Rolf Turner
Technical Editor ANZJS


From dcarlson at tamu.edu  Tue Jul 29 23:02:13 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 29 Jul 2014 21:02:13 +0000
Subject: [R] Post hoc comparissons
In-Reply-To: <DA616A2FCD46844DB2333D0BD00DE545133DE3@CTSPIGDCAPMXS31.cihs.ad.gov.on.ca>
References: <DA616A2FCD46844DB2333D0BD00DE545133DE3@CTSPIGDCAPMXS31.cihs.ad.gov.on.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8D350@mb02.ads.tamu.edu>

Look at package multcomp, particularly function cld().

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Reid, Doug (MNR)
Sent: Tuesday, July 29, 2014 2:57 PM
To: r-help at r-project.org
Subject: [R] Post hoc comparissons

Hi Folks,

I have been using the TukeyHSD to conduct post hoc comparisons.  The challenge is I have two interacting factors, one of which has 6 levels (cover types), and the other 2 (study areas).    As a result interpreting the post hoc comparisons is difficult when you get a list of every possible combination (66 of them).  In grad school I was using SAS and I recall most of the post hoc tests that were available there provided a nice summary with letters that made it easy to show which groups differed from one another within an ANOVA model that included a significant interaction.  Is there a way to summarize my result in R that makes it easier to indicate significant post hoc comparisons graphically?

Thanks for your help,

Doug Reid
CNFER
Lakehead University


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From shidaxia at yahoo.com  Tue Jul 29 22:13:16 2014
From: shidaxia at yahoo.com (Shi, Tao)
Date: Tue, 29 Jul 2014 13:13:16 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>
Message-ID: <1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>

Thank you very much, Greg and Ramnath, for the pointers! ?I'll explore more.




On Tuesday, July 29, 2014 8:10 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:



There are plugins for rCharts that help you create custom charts.

Here is a scatterplot matrix example

http://mostlyconjecture.com/2014/02/09/scatterplot-matrix-with-rcharts/


It doesn't support brushing, but I think it won't be hard adding that behavior if you contact its author.

Hope this helps.

Best,
Ramnath



______________________________________
Ramnath Vaidyanathan
Assistant Professor of Operations Management
Desautels Faculty of Management
1001 Sherbrooke Street West
Montreal, QC H3A 1G5
Ph: +1 (514) 398-1457
______________________________________


On Tue, Jul 29, 2014 at 11:01 AM, Greg Snow <538280 at gmail.com> wrote:

There is the TkBrush function in the TeachingDemos package that gives
>brushing in a scatterplot matrix using a Tk interface rather than
>ggobi. ?There is also the iplots package which allows you to create
>multiple scatterplots, histograms, boxplots, barcharts, etc. and
>points selected in any one of the plots will then be highlighted in
>all the others. ?Both of those solutions require R to be installed.
>
>I don't know of any way to get what you want without installing at
>least one of ggobi or R (or some other program of similar complexity
>to install).
>
>On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>> hi list,
>>
>> I'm comparing the changes of ~100 analytes in multiple treatment conditions. ?I plotted them in several different xy scattter plots. ?It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown. ?I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine). ?rCharts is nice but so far it can only create one scatter plot at a time.
>>
>> Any good suggestions?
>>
>> Many thanks!
>>
>> Tao
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>--
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com
>


From sarah.goslee at gmail.com  Tue Jul 29 23:05:05 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 29 Jul 2014 17:05:05 -0400
Subject: [R] Help with splitting up values in a data set
In-Reply-To: <7CC66B12-9714-4863-B089-D425DC2CC9CC@yahoo.com>
References: <7CC66B12-9714-4863-B089-D425DC2CC9CC@yahoo.com>
Message-ID: <CAM_vjumYOc0QKQx=wn=tLOQb8AcbMvCh0n3M7V4qB=Sspt2ECQ@mail.gmail.com>

Hi,

My telepathy is not working today.

Have you already imported your data into R?

If so, what does it look like?

dput(head(yourdata, 20))

is an effective way to provide data on the list. Or if your question
refers to only one column, that's all we need.

But we certainly need to know what the column looks like, and what you
expect to have as the final answer.

This may also be of use:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

On Tue, Jul 29, 2014 at 2:04 PM, Gayon Clarke <gayonclarke at yahoo.com> wrote:
> Good day,
>
> I have a data set from a MySQL database with a description field that I want to spilt up the values in order to compare the description of one record to the others. This will help me to identify any patterns with the data being recorded.
>
> Your help will be gladly appreciated.
>
> Gayon
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gayonclarke at yahoo.com  Wed Jul 30 00:08:40 2014
From: gayonclarke at yahoo.com (Shanae Clarke)
Date: Tue, 29 Jul 2014 15:08:40 -0700
Subject: [R] Help with splitting up values in a data set
In-Reply-To: <CAM_vjumYOc0QKQx=wn=tLOQb8AcbMvCh0n3M7V4qB=Sspt2ECQ@mail.gmail.com>
References: <7CC66B12-9714-4863-B089-D425DC2CC9CC@yahoo.com>
	<CAM_vjumYOc0QKQx=wn=tLOQb8AcbMvCh0n3M7V4qB=Sspt2ECQ@mail.gmail.com>
Message-ID: <1406671720.33626.YahooMailNeo@web141405.mail.bf1.yahoo.com>

Thank you for that link, it was very helpful.

My attempt,

This is what my data set looks like?

dput(head(des,2))
structure(list(description = structure(5:6, .Label = c("\"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"",
"76 cases of box juice had remained in the depot beyond there expiration date. No expiration date was visible, however the case code reflects that these cases had been packaged and had remained beyond the 90days expiry date." 
"59 cases of bottle juice were found in the depot to be beyond there expiration date. The case code reflects that these cases had been packaged and had remained beyond the 90days expiry date.The codes can be found in the Support File.  folder. NB. A customer had order 50 bags which was mistaken to be 150 cases as such they remained in the depot and efforts were being made to sell these cases, however, these 59 cases were not sold."
), class = "factor")), .Names = "description", row.names = 1:2, class = "data.frame")?

Aim:

I want to split up each word in so as to ascertain how frequent the word occurs in each complain case

example: [1] ?"cases" "of" "box" "juice" "had" "remained" "in" "the" "depot" "beyond" "there" "expiration" "date"
	[2] ?"cases" "of" "bottle" "juice" "were" "found" "in" "the" "depot" "to" "be" "beyond" "there" "expiration" "date"

frequent words would be: "cases" "juice", "depot" "expiration" "date"?
it should also tell which case numbers these words were most frequent to: ?
number : 453032, 823041, 041812, 490322

My code thus far:


library (RODBC) 
channel <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd) 
res <- sqlFetch(channel , "casing") 
des <- sqlQuery(channel , "Select description from casing") 
num <- sqlQuery(channel , "Select number from casing") 
cas.des<- as.character(des$num)?
do.call(rbind, strsplit(cas.des, " "))

Results

> library (RODBC) 
> channel <- odbcConnect(dsn=dsn.name,uid=user.name,pwd = pwd) 
> res <- sqlFetch(channel , "casing") 
Warning message: 
closing unused RODBC handle 1 
> des <- sqlQuery(channel , "Select description from casing") 
> num <- sqlQuery(channel , "Select id from casing")
> cas.des<- as.character(des$num) 
> do.call(rbind, strsplit(cas.des, " ")) 
NULL

I don't understand what this means.

My apologies, I only started using R a month now and I have not gotten the full concept of everything.

Could someone please help me. I would gladly appreciate it.?

Gayon.


On Tuesday, July 29, 2014 4:05 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
Hi,

My telepathy is not working today.

Have you already imported your data into R?

If so, what does it look like?

dput(head(yourdata, 20))

is an effective way to provide data on the list. Or if your question
refers to only one column, that's all we need.

But we certainly need to know what the column looks like, and what you
expect to have as the final answer.

This may also be of use:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah




On Tue, Jul 29, 2014 at 2:04 PM, Gayon Clarke <gayonclarke at yahoo.com> wrote:
> Good day,
>
> I have a data set from a MySQL database with a description field that I want to spilt up the values in order to compare the description of one record to the others. This will help me to identify any patterns with the data being recorded.
>
> Your help will be gladly appreciated.
>
> Gayon
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From erinm.hodgess at gmail.com  Wed Jul 30 00:22:56 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Jul 2014 18:22:56 -0400
Subject: [R] a knitr question
Message-ID: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/cb7237b5/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jul 30 00:27:44 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Jul 2014 18:27:44 -0400
Subject: [R] a knitr question
In-Reply-To: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
Message-ID: <CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/e7e19c99/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Wed Jul 30 00:36:05 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 30 Jul 2014 10:36:05 +1200
Subject: [R] a knitr question
In-Reply-To: <CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>

Kia ora Erin

But beware - to quote from Yihui 2013 introduction to knitr

"It is easy to revert to the output with prompts (set option prompt=TRUE), and you will quickly realize the inconvenience to the readers if they want to copy and run the code ..."

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: Wednesday, 30 July 2014 10:28 a.m.
To: r-help at r-project.org
Subject: Re: [R] a knitr question

Sorry:  just solved it.

You simply include "prompt=TRUE" in the <<>> section

Thanks,
Erin



On Tue, Jul 29, 2014 at 6:22 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> When constructing code using knitr, is there a way to get the ">" 
> prompt to appear, please?
>
> Everything else works great!!
>
> Thank you!
>
> Sincerely,
> Erin
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics University of Houston - 
> Downtown
> mailto: erinm.hodgess at gmail.com
>



--
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From xie at yihui.name  Wed Jul 30 00:56:08 2014
From: xie at yihui.name (Yihui Xie)
Date: Tue, 29 Jul 2014 17:56:08 -0500
Subject: [R] a knitr question
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
Message-ID: <CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>

Yeah, it is just my personal opinion. Some users like it, and some do not.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, Jul 29, 2014 at 5:36 PM, Peter Alspach
<Peter.Alspach at plantandfood.co.nz> wrote:
> Kia ora Erin
>
> But beware - to quote from Yihui 2013 introduction to knitr
>
> "It is easy to revert to the output with prompts (set option prompt=TRUE), and you will quickly realize the inconvenience to the readers if they want to copy and run the code ..."
>
> Peter Alspach
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
> Sent: Wednesday, 30 July 2014 10:28 a.m.
> To: r-help at r-project.org
> Subject: Re: [R] a knitr question
>
> Sorry:  just solved it.
>
> You simply include "prompt=TRUE" in the <<>> section
>
> Thanks,
> Erin
>
>
>
> On Tue, Jul 29, 2014 at 6:22 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
>> Hello!
>>
>> When constructing code using knitr, is there a way to get the ">"
>> prompt to appear, please?
>>
>> Everything else works great!!
>>
>> Thank you!
>>
>> Sincerely,
>> Erin
>>
>>
>>
>> --
>> Erin Hodgess
>> Associate Professor
>> Department of Mathematical and Statistics University of Houston -
>> Downtown
>> mailto: erinm.hodgess at gmail.com
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com


From erinm.hodgess at gmail.com  Wed Jul 30 04:17:39 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Jul 2014 22:17:39 -0400
Subject: [R] a knitr question
In-Reply-To: <CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
Message-ID: <CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/f2dadfdd/attachment.pl>

From rmh at temple.edu  Wed Jul 30 05:23:25 2014
From: rmh at temple.edu (Rmh)
Date: Tue, 29 Jul 2014 23:23:25 -0400
Subject: [R] a knitr question
In-Reply-To: <CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
Message-ID: <083FADE2-6CBD-48BC-BBA2-181DCCF36559@temple.edu>

on windows gui, right-click paste-without-prompt (or some similar phrasing) takes the prompts away.

on ESS c-u c-u c-y takes the prompts away

Rich


Sent from my iPhone

> On Jul 29, 2014, at 22:17, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> I was thinking that for teaching, it may be helpful for them to see the
> whole thing.
> 
> 
>> On Tue, Jul 29, 2014 at 6:56 PM, Yihui Xie <xie at yihui.name> wrote:
>> 
>> Yeah, it is just my personal opinion. Some users like it, and some do not.
>> 
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>> 
>> 
>> On Tue, Jul 29, 2014 at 5:36 PM, Peter Alspach
>> <Peter.Alspach at plantandfood.co.nz> wrote:
>>> Kia ora Erin
>>> 
>>> But beware - to quote from Yihui 2013 introduction to knitr
>>> 
>>> "It is easy to revert to the output with prompts (set option
>> prompt=TRUE), and you will quickly realize the inconvenience to the readers
>> if they want to copy and run the code ..."
>>> 
>>> Peter Alspach
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Erin Hodgess
>>> Sent: Wednesday, 30 July 2014 10:28 a.m.
>>> To: r-help at r-project.org
>>> Subject: Re: [R] a knitr question
>>> 
>>> Sorry:  just solved it.
>>> 
>>> You simply include "prompt=TRUE" in the <<>> section
>>> 
>>> Thanks,
>>> Erin
>>> 
>>> 
>>> 
>>> On Tue, Jul 29, 2014 at 6:22 PM, Erin Hodgess <erinm.hodgess at gmail.com>
>>> wrote:
>>> 
>>>> Hello!
>>>> 
>>>> When constructing code using knitr, is there a way to get the ">"
>>>> prompt to appear, please?
>>>> 
>>>> Everything else works great!!
>>>> 
>>>> Thank you!
>>>> 
>>>> Sincerely,
>>>> Erin
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Erin Hodgess
>>>> Associate Professor
>>>> Department of Mathematical and Statistics University of Houston -
>>>> Downtown
>>>> mailto: erinm.hodgess at gmail.com
>>> 
>>> 
>>> 
>>> --
>>> Erin Hodgess
>>> Associate Professor
>>> Department of Mathematical and Statistics University of Houston -
>> Downtown
>>> mailto: erinm.hodgess at gmail.com
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pennytianzh at hotmail.com  Wed Jul 30 00:50:44 2014
From: pennytianzh at hotmail.com (=?gb2312?B?1cXM7Mzt?=)
Date: Tue, 29 Jul 2014 22:50:44 +0000
Subject: [R] Out of example forecasting plot
Message-ID: <BAY175-W3BD51C08443F5F170087EA3F80@phx.gbl>







Dear R helping team,
I am trying to check if the model I fitted is the best fitted model from the data. I have over all 392 data, I want to fit the model in the first 382 data and do 10 step predictions, check whether my model fits the last 10 data well.
Here is the R code I wrote
da<-read.table(file.choose(),header=T)

y <- data.frame(time =
seq(as.Date('2007-01-07'), by = 'weeks', length = 392))

#produce a vector that can show the dates
of the exchange rates.#

ex<-da[,2]
mod <- list()

mod[["linear"]] <- linear(ex, m = 4)

mod[["setar"]] <- setar(ex, m = 4,
thDelay = 1)

mod[["lstar"]] <- lstar(ex, m = 4,
thDelay = 1)

mod[["nnetTs"]] <- nnetTs(ex, m = 4,
size = 3)

mod[["aar"]] <- aar(ex, m = 4)set.seed(10)mod.test <- list()ex.train <- window(ex, end = 380)ex.test <- window(ex, start = 381)mod.test[["linear"]] <- linear(ex.train, m = 4)mod.test[["setar"]] <- setar(ex.train, m = 4, thDelay = 1)mod.test[["lstar"]] <- lstar(ex.train, m = 4, thDelay = 1, trace = FALSE,control = list(maxit = 1e+05))mod.test[["nnet"]] <- nnetTs(ex.train, m = 4, size = 3, control = list(maxit = 1e+05))mod.test[["aar"]] <- aar(ex.train, m = 4)
frc.test <- lapply(mod.test, predict, n.ahead = 10)plot(ex.test, ylim = range(ex))for (i in 1:length(frc.test))     lines(frc.test[[i]], lty = i + 1, col = i + 1)legend(381, 0.5, lty = 1:(length(frc.test) + 1), col = 1:(length(frc.test) +1), legend = c("observed", names(frc.test)))
I am expecting to have some plot like the graph on page 20 of this link http://cran.r-project.org/web/packages/tsDyn/vignettes/tsDyn.pdf
but I get the picture,please see attachment.
here is the first few lines of my data> head(da)    End_Date USD_GBP1 07/01/2007  0.51222 14/01/2007  0.51523 21/01/2007  0.50834 28/01/2007  0.50735 04/02/2007  0.50946 11/02/2007  0.5097
I attached my data as well just in case you may need it.
Thank you very much for your help!!
Kind regards
Penny



 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: weeklyexchange_usd_ukp.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/ae4c205e/attachment.txt>

From abhinabaroy09 at gmail.com  Wed Jul 30 09:08:24 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 30 Jul 2014 12:38:24 +0530
Subject: [R] Count number of change in a specified time interval
Message-ID: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/879f8146/attachment.pl>

From acefix at rocketmail.com  Wed Jul 30 06:55:01 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 29 Jul 2014 21:55:01 -0700
Subject: [R] venn.diagram, error message: Incorrect number of elements
In-Reply-To: <CAM_vju=aq5L=X-adNF3KzN7QK-bXo9UWEaLKnMwLaD0RX7Nqjg@mail.gmail.com>
References: <1406646669.68250.YahooMailNeo@web164603.mail.gq1.yahoo.com>
	<CAM_vju=aq5L=X-adNF3KzN7QK-bXo9UWEaLKnMwLaD0RX7Nqjg@mail.gmail.com>
Message-ID: <1406696101.21365.YahooMailNeo@web164601.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140729/cb986602/attachment.pl>

From lienju at yahoo.fr  Wed Jul 30 11:18:13 2014
From: lienju at yahoo.fr (Julien Million)
Date: Wed, 30 Jul 2014 11:18:13 +0200
Subject: [R] Map with no political border
Message-ID: <CFFE837D.1F0AC%lienju@yahoo.fr>

Hi,

I would like to plot a map without political borders, but not black... I
am mainly using the maps package, and wanted to know if it was possible
with this one, or if I should use something else, like shape file.

If I do

library(maps)
map(fill=T)

I have a map of the world filled in black. I would like to do the same but
with another color and with no political borders (only filled land areas).
If I do

map(fill=T, col=?blue?)

the borders are automatically added, and I cannot find a way to remove
them as the parameters boundary or interior are ignored if fill is true.

Thanks a lot

Julien


From jim at bitwrit.com.au  Wed Jul 30 11:31:15 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 30 Jul 2014 19:31:15 +1000
Subject: [R] Map with no political border
In-Reply-To: <CFFE837D.1F0AC%lienju@yahoo.fr>
References: <CFFE837D.1F0AC%lienju@yahoo.fr>
Message-ID: <1441135.HUcESjWfyl@localhost.localdomain>

On Wed, 30 Jul 2014 11:18:13 AM Julien Million wrote:
> Hi,
> 
> I would like to plot a map without political borders, but not black... I
> am mainly using the maps package, and wanted to know if it was 
possible
> with this one, or if I should use something else, like shape file.
> 
> If I do
> 
> library(maps)
> map(fill=T)
> 
> I have a map of the world filled in black. I would like to do the same but
> with another color and with no political borders (only filled land areas).
> If I do
> 
> map(fill=T, col=?blue?)
> 
> the borders are automatically added, and I cannot find a way to 
remove
> them as the parameters boundary or interior are ignored if fill is true.
> 
Hi Julien,
Try this:

par(fg="blue")
map("world",fill=TRUE,col="blue")

Jim


From lienju at yahoo.fr  Wed Jul 30 11:40:04 2014
From: lienju at yahoo.fr (Julien Million)
Date: Wed, 30 Jul 2014 11:40:04 +0200
Subject: [R] Map with no political border
In-Reply-To: <1441135.HUcESjWfyl@localhost.localdomain>
References: <CFFE837D.1F0AC%lienju@yahoo.fr>
	<1441135.HUcESjWfyl@localhost.localdomain>
Message-ID: <CFFE89F5.1F0E8%lienju@yahoo.fr>

Fantastic Jim! Thanks a lot
Julien
___________________________
Julien Million
Independent Fisheries Consultant




On 30/07/14 11:31, "Jim Lemon" <jim at bitwrit.com.au> wrote:

>On Wed, 30 Jul 2014 11:18:13 AM Julien Million wrote:
>> Hi,
>> 
>> I would like to plot a map without political borders, but not black... I
>> am mainly using the maps package, and wanted to know if it was
>possible
>> with this one, or if I should use something else, like shape file.
>> 
>> If I do
>> 
>> library(maps)
>> map(fill=T)
>> 
>> I have a map of the world filled in black. I would like to do the same
>>but
>> with another color and with no political borders (only filled land
>>areas).
>> If I do
>> 
>> map(fill=T, col=?blue?)
>> 
>> the borders are automatically added, and I cannot find a way to
>remove
>> them as the parameters boundary or interior are ignored if fill is true.
>> 
>Hi Julien,
>Try this:
>
>par(fg="blue")
>map("world",fill=TRUE,col="blue")
>
>Jim
>


From abhishek.dta at gmail.com  Wed Jul 30 10:58:47 2014
From: abhishek.dta at gmail.com (Abhishek Dutta)
Date: Wed, 30 Jul 2014 14:28:47 +0530
Subject: [R] ATTN: Urgent Guidance Needed on scraping tweets for last 10
 years using TwitteR / search twitter function.
Message-ID: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/ba290e68/attachment.pl>

From jon.skoien at jrc.ec.europa.eu  Wed Jul 30 12:09:49 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Wed, 30 Jul 2014 12:09:49 +0200
Subject: [R] Copulas and spatial modeling
In-Reply-To: <CAGGwnOCveKSNbVqrdmekSPp=iVFapMFXz+WA2_3goxaqgXe8Ag@mail.gmail.com>
References: <CAGGwnOCveKSNbVqrdmekSPp=iVFapMFXz+WA2_3goxaqgXe8Ag@mail.gmail.com>
Message-ID: <53D8C46D.7070205@jrc.ec.europa.eu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/42bae901/attachment.pl>

From tim at mlhim.org  Wed Jul 30 13:27:27 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Wed, 30 Jul 2014 08:27:27 -0300
Subject: [R] ATTN: Urgent Guidance Needed on scraping tweets for last 10
 years using TwitteR / search twitter function.
In-Reply-To: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>
References: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>
Message-ID: <CA+=OU3W7idgW4ZmQ8ip-=Qqc+q9+jnQRQkPxxiojW3ka=jKLQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/e07eba60/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jul 30 13:58:18 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Jul 2014 07:58:18 -0400
Subject: [R]  one more knitr question, please
Message-ID: <CACxE24kjZLSwxGwxJ=zY_D3pLWJwxR-RKPiACEHUu5Pxt=a05A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/d38190c0/attachment.pl>

From abhishek.dta at gmail.com  Wed Jul 30 13:49:13 2014
From: abhishek.dta at gmail.com (Abhishek Dutta)
Date: Wed, 30 Jul 2014 17:19:13 +0530
Subject: [R] ATTN: Urgent Guidance Needed on scraping tweets for last 10
 years using TwitteR / search twitter function.
In-Reply-To: <CA+=OU3W7idgW4ZmQ8ip-=Qqc+q9+jnQRQkPxxiojW3ka=jKLQA@mail.gmail.com>
References: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>
	<CA+=OU3W7idgW4ZmQ8ip-=Qqc+q9+jnQRQkPxxiojW3ka=jKLQA@mail.gmail.com>
Message-ID: <CAEkKqL6bumBiXe+dxanvwaAiBzaGpEzDbaNdUXx5C-vCkCfUbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/df6b2aa8/attachment.pl>

From abhinabaroy09 at gmail.com  Wed Jul 30 14:46:06 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 30 Jul 2014 18:16:06 +0530
Subject: [R] DATA SUMMARIZING and REPORTING
Message-ID: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/0489daba/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Jul 30 15:27:21 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 30 Jul 2014 06:27:21 -0700
Subject: [R] one more knitr question, please
In-Reply-To: <CACxE24kjZLSwxGwxJ=zY_D3pLWJwxR-RKPiACEHUu5Pxt=a05A@mail.gmail.com>
References: <CACxE24kjZLSwxGwxJ=zY_D3pLWJwxR-RKPiACEHUu5Pxt=a05A@mail.gmail.com>
Message-ID: <910ab857-e6ed-4c00-98ef-947d445e1831@email.android.com>

In general, I don't thiink so. But are you aware that knitr has its own help forum [1]?

[1] https://groups.google.com/forum/m/#!forum/knitr
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 30, 2014 4:58:18 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello again:
>
>Is there a way to put a page break inside of a code chunk, please?
>
>Thanks,
>Erin


From gunter.berton at gene.com  Wed Jul 30 15:36:45 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 30 Jul 2014 06:36:45 -0700
Subject: [R] DATA SUMMARIZING and REPORTING
In-Reply-To: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
References: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
Message-ID: <CACk-te2CiZbM-HjxtKLdX+NcWUh=_BjdSE8m75HEPqz=G9yFeQ@mail.gmail.com>

Is this homework? There is a no homework policy here.

And stop posting in HTML --- plain text only-- and learn to use ?dput
to post example data.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Jul 30, 2014 at 5:46 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi R-helpers,
>
> I have dataframe like
>
>   ID_CASE         YEAR_MTH       ATT_1             A1              A2
> A3  CB26A 201302 1 146 42 74  CB26A 201302 0 140 50 77  CB26A 201303 0 128
> 36 77  CB26A 201304 1 146 36 72  CB26A 201305 1 134 36 80  CB26A 201305 0
> 148 30 80  CB26A 201306 0 134 20 72  CB26A 201307 1 125 48 79  CB26A 201309
> 0 122 44 74  CB26A 201310 1 126 37 72  CB26A 201310 1 107 43 75
> I want a final dataframe which will look like
>
>   ID_CASE Period  No.ofChange      %Paid  CB26A 201302-2013042  0.414365
> CB26A 201303-201305 2 0.445245  CB26A 201304-201306 1 0.444444  CB26A
> 201305-201307 2 0.460741  CB26A 201306-201308 1 0.461774  CB26A
> 201307-201309 1 0.451327  CB26A 201308-201310 1 0.461378
> where,
> Period = a time period of 3 months which is shifted by 1 month subsequently
>
> No.ofChange = number of time ATT_1 has changed values in this period
>
> %Paid = sum(A3)/(sum(A1)+sum(A2)) for this period
> E.g. for Period=201302-201304,
> %Paid = (74+77+77+72)/((146+140+128+146)+(42+50+36+36))
>
> Period calculation should start from the first YEAR_MTH for the ID_CASE,
> i.e., if for a ID_CASE first YEAR_MTH is 201301 or 201304 then the period
> should be defined accordingly.
>
> I have a dataframe with 400 unique ID_CASE, I need to do it for all ID_CASE.
>
> How can I do it in R?
>
> Regards,
> Abhinaba
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Jul 30 16:01:22 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 30 Jul 2014 14:01:22 +0000
Subject: [R] DATA SUMMARIZING and REPORTING
In-Reply-To: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
References: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD48F@SRVEXCHMBX.precheza.cz>

Hi

Maybe

?aggregate

Use dput for data presentation and no HTML as everything gets scrambled with it.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Abhinaba Roy
> Sent: Wednesday, July 30, 2014 2:46 PM
> To: r-help
> Subject: [R] DATA SUMMARIZING and REPORTING
>
> Hi R-helpers,
>
> I have dataframe like
>
>   ID_CASE         YEAR_MTH       ATT_1             A1              A2
> A3  CB26A 201302 1 146 42 74  CB26A 201302 0 140 50 77  CB26A 201303 0
> 128
> 36 77  CB26A 201304 1 146 36 72  CB26A 201305 1 134 36 80  CB26A 201305
> 0
> 148 30 80  CB26A 201306 0 134 20 72  CB26A 201307 1 125 48 79  CB26A
> 201309 0 122 44 74  CB26A 201310 1 126 37 72  CB26A 201310 1 107 43 75
> I want a final dataframe which will look like
>
>   ID_CASE Period  No.ofChange      %Paid  CB26A 201302-2013042
> 0.414365
> CB26A 201303-201305 2 0.445245  CB26A 201304-201306 1 0.444444  CB26A
> 201305-201307 2 0.460741  CB26A 201306-201308 1 0.461774  CB26A
> 201307-201309 1 0.451327  CB26A 201308-201310 1 0.461378 where, Period
> = a time period of 3 months which is shifted by 1 month subsequently
>
> No.ofChange = number of time ATT_1 has changed values in this period
>
> %Paid = sum(A3)/(sum(A1)+sum(A2)) for this period E.g. for
> Period=201302-201304, %Paid =
> (74+77+77+72)/((146+140+128+146)+(42+50+36+36))
>
> Period calculation should start from the first YEAR_MTH for the
> ID_CASE, i.e., if for a ID_CASE first YEAR_MTH is 201301 or 201304 then
> the period should be defined accordingly.
>
> I have a dataframe with 400 unique ID_CASE, I need to do it for all
> ID_CASE.
>
> How can I do it in R?
>
> Regards,
> Abhinaba
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From istazahn at gmail.com  Wed Jul 30 16:45:09 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 30 Jul 2014 10:45:09 -0400
Subject: [R] a knitr question
In-Reply-To: <CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
Message-ID: <CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>

On Tue, Jul 29, 2014 at 10:17 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> I was thinking that for teaching, it may be helpful for them to see the
> whole thing.

Hopefully you're teaching them to write their code in a script, in
which case the prompt will not be helpful.

Best,
Ista
>
>
> On Tue, Jul 29, 2014 at 6:56 PM, Yihui Xie <xie at yihui.name> wrote:
>
>> Yeah, it is just my personal opinion. Some users like it, and some do not.
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>>
>>
>> On Tue, Jul 29, 2014 at 5:36 PM, Peter Alspach
>> <Peter.Alspach at plantandfood.co.nz> wrote:
>> > Kia ora Erin
>> >
>> > But beware - to quote from Yihui 2013 introduction to knitr
>> >
>> > "It is easy to revert to the output with prompts (set option
>> prompt=TRUE), and you will quickly realize the inconvenience to the readers
>> if they want to copy and run the code ..."
>> >
>> > Peter Alspach
>> >
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Erin Hodgess
>> > Sent: Wednesday, 30 July 2014 10:28 a.m.
>> > To: r-help at r-project.org
>> > Subject: Re: [R] a knitr question
>> >
>> > Sorry:  just solved it.
>> >
>> > You simply include "prompt=TRUE" in the <<>> section
>> >
>> > Thanks,
>> > Erin
>> >
>> >
>> >
>> > On Tue, Jul 29, 2014 at 6:22 PM, Erin Hodgess <erinm.hodgess at gmail.com>
>> > wrote:
>> >
>> >> Hello!
>> >>
>> >> When constructing code using knitr, is there a way to get the ">"
>> >> prompt to appear, please?
>> >>
>> >> Everything else works great!!
>> >>
>> >> Thank you!
>> >>
>> >> Sincerely,
>> >> Erin
>> >>
>> >>
>> >>
>> >> --
>> >> Erin Hodgess
>> >> Associate Professor
>> >> Department of Mathematical and Statistics University of Houston -
>> >> Downtown
>> >> mailto: erinm.hodgess at gmail.com
>> >>
>> >
>> >
>> >
>> > --
>> > Erin Hodgess
>> > Associate Professor
>> > Department of Mathematical and Statistics University of Houston -
>> Downtown
>> > mailto: erinm.hodgess at gmail.com
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From xie at yihui.name  Wed Jul 30 17:34:10 2014
From: xie at yihui.name (Yihui Xie)
Date: Wed, 30 Jul 2014 10:34:10 -0500
Subject: [R] one more knitr question, please
In-Reply-To: <CACxE24kjZLSwxGwxJ=zY_D3pLWJwxR-RKPiACEHUu5Pxt=a05A@mail.gmail.com>
References: <CACxE24kjZLSwxGwxJ=zY_D3pLWJwxR-RKPiACEHUu5Pxt=a05A@mail.gmail.com>
Message-ID: <CANROs4ck4=rgg15RRE_etCq6y0FtV85XNqmx0TTYaEQg+gcvTg@mail.gmail.com>

Not sure if you mean \newpage{}/\pagebreak{} in LaTeX. If that is the
case, it is possible but easy, and I do not understand why you want to
break a code chunk onto two pages. The easiest thing to do is just to
write two code chunks.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Jul 30, 2014 at 6:58 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello again:
>
> Is there a way to put a page break inside of a code chunk, please?
>
> Thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com


From pmaclean2011 at yahoo.com  Wed Jul 30 17:54:25 2014
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Wed, 30 Jul 2014 08:54:25 -0700
Subject: [R] Technological/Logistic substitution model.
Message-ID: <1406735665.69992.YahooMailNeo@web122401.mail.ne1.yahoo.com>

?Any one with an idea of estimating the Technological/Logistic substitution model. 
The model is specified as: 
fi(t(j)) = 1/[1-exp(-alpa(t(i))-beta(i)] for t 0 
fi(t(j)) = 1-sum(f(j-1))- sum(f(j+1)) for tb <=t <= tc 
fi(t(j)) = 1/[1+ exp(alpas(t(i)-betas(i))] for t >=tc and alphas >0. T
The model assume that n technologies are introduced to the market, where 1 is the oldest and technology n is the newest, i and j are subscripts representing the type of technology, fi is the market share, t is a subscript denoting time, alpha, alphas, beta, and betas are parameters, tb and tc are time periods during which the technology i starts to enter the saturation and decline phase, respectively. Any suggestion, reading will be appreciate. 
?
Peter Maclean
Department of Economics
UDSM


From 538280 at gmail.com  Wed Jul 30 18:45:50 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 30 Jul 2014 10:45:50 -0600
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>
	<1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>

Another option that is in developement, but may do what you want is
ggvis (http://ggvis.rstudio.com/).  I have seen an example of brushing
created with ggvis that can then be embedded in a web page.  I am not
sure if you can send the html and support files directly to someone
without R (probably Rstudio) or if you need to upload it to a server
for others to see, but the later is still an option for collaborators
who do not have R installed.

On Tue, Jul 29, 2014 at 2:13 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
> Thank you very much, Greg and Ramnath, for the pointers!  I'll explore more.
>
>
>
>
> On Tuesday, July 29, 2014 8:10 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>
>
>
> There are plugins for rCharts that help you create custom charts.
>
> Here is a scatterplot matrix example
>
> http://mostlyconjecture.com/2014/02/09/scatterplot-matrix-with-rcharts/
>
>
> It doesn't support brushing, but I think it won't be hard adding that behavior if you contact its author.
>
> Hope this helps.
>
> Best,
> Ramnath
>
>
>
> ______________________________________
> Ramnath Vaidyanathan
> Assistant Professor of Operations Management
> Desautels Faculty of Management
> 1001 Sherbrooke Street West
> Montreal, QC H3A 1G5
> Ph: +1 (514) 398-1457
> ______________________________________
>
>
> On Tue, Jul 29, 2014 at 11:01 AM, Greg Snow <538280 at gmail.com> wrote:
>
> There is the TkBrush function in the TeachingDemos package that gives
>>brushing in a scatterplot matrix using a Tk interface rather than
>>ggobi.  There is also the iplots package which allows you to create
>>multiple scatterplots, histograms, boxplots, barcharts, etc. and
>>points selected in any one of the plots will then be highlighted in
>>all the others.  Both of those solutions require R to be installed.
>>
>>I don't know of any way to get what you want without installing at
>>least one of ggobi or R (or some other program of similar complexity
>>to install).
>>
>>On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>> hi list,
>>>
>>> I'm comparing the changes of ~100 analytes in multiple treatment conditions.  I plotted them in several different xy scattter plots.  It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown.  I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine).  rCharts is nice but so far it can only create one scatter plot at a time.
>>>
>>> Any good suggestions?
>>>
>>> Many thanks!
>>>
>>> Tao
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com
>>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From john.archie.mckown at gmail.com  Wed Jul 30 19:08:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 30 Jul 2014 12:08:58 -0500
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09 02:00:00"
Message-ID: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>

"I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
time of 2014-03-09 02:00:00 ?

> q
[1] "2014-03-09 02:00:00"
> is.na(q)
[1] TRUE
> as.POSIXct(q)
[1] NA
> dput(q)
structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
    year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
    gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
"mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class = c("POSIXlt",
"POSIXt"))
> str(q)
 POSIXlt[1:1], format: "2014-03-09 02:00:00"
>


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From murdoch.duncan at gmail.com  Wed Jul 30 19:18:45 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Jul 2014 13:18:45 -0400
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
Message-ID: <53D928F5.1030500@gmail.com>

On 30/07/2014 1:08 PM, John McKown wrote:
> "I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
> time of 2014-03-09 02:00:00 ?
>
> > q
> [1] "2014-03-09 02:00:00"
> > is.na(q)
> [1] TRUE
> > as.POSIXct(q)
> [1] NA
> > dput(q)
> structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
>      year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
>      gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
> "mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class = c("POSIXlt",
> "POSIXt"))

I see an NA in there for the GMT offset, and no timezone.

Duncan Murdoch
> > str(q)
>   POSIXlt[1:1], format: "2014-03-09 02:00:00"
> >
>
>


From john.archie.mckown at gmail.com  Wed Jul 30 19:42:39 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 30 Jul 2014 12:42:39 -0500
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <53D928F5.1030500@gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
Message-ID: <CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>

On Wed, Jul 30, 2014 at 12:18 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 30/07/2014 1:08 PM, John McKown wrote:
>>
>> "I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
>> time of 2014-03-09 02:00:00 ?
>>
>> > q
>> [1] "2014-03-09 02:00:00"
>> > is.na(q)
>> [1] TRUE
>> > as.POSIXct(q)
>> [1] NA
>> > dput(q)
>> structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
>>      year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
>>      gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
>> "mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class =
>> c("POSIXlt",
>> "POSIXt"))
>
>
> I see an NA in there for the GMT offset, and no timezone.

I should have mentioned that I tried other time stamps, generated the
same way as "q" above. They did not fail the is.na() test. I think
that is.na() is doing a as.double() somewhere in there because
as.double(q)  gives  NA as a result.

>
> Duncan Murdoch
>
>> > str(q)
>>   POSIXlt[1:1], format: "2014-03-09 02:00:00"
>> >
>>
>>
>



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From 538280 at gmail.com  Wed Jul 30 19:50:13 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 30 Jul 2014 11:50:13 -0600
Subject: [R] a knitr question
In-Reply-To: <CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
Message-ID: <CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>

My preference when teaching is to have the code and results look the
same as it appears in the R console window, so with the prompts and
without the output commented.  But then I also `purl` my knitr file to
create a script file to give to the students that they can copy and
paste from easily.

On Wed, Jul 30, 2014 at 8:45 AM, Ista Zahn <istazahn at gmail.com> wrote:
> On Tue, Jul 29, 2014 at 10:17 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>> I was thinking that for teaching, it may be helpful for them to see the
>> whole thing.
>
> Hopefully you're teaching them to write their code in a script, in
> which case the prompt will not be helpful.
>
> Best,
> Ista
>>
>>
>> On Tue, Jul 29, 2014 at 6:56 PM, Yihui Xie <xie at yihui.name> wrote:
>>
>>> Yeah, it is just my personal opinion. Some users like it, and some do not.
>>>
>>> Regards,
>>> Yihui
>>> --
>>> Yihui Xie <xieyihui at gmail.com>
>>> Web: http://yihui.name
>>>
>>>
>>> On Tue, Jul 29, 2014 at 5:36 PM, Peter Alspach
>>> <Peter.Alspach at plantandfood.co.nz> wrote:
>>> > Kia ora Erin
>>> >
>>> > But beware - to quote from Yihui 2013 introduction to knitr
>>> >
>>> > "It is easy to revert to the output with prompts (set option
>>> prompt=TRUE), and you will quickly realize the inconvenience to the readers
>>> if they want to copy and run the code ..."
>>> >
>>> > Peter Alspach
>>> >
>>> > -----Original Message-----
>>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On Behalf Of Erin Hodgess
>>> > Sent: Wednesday, 30 July 2014 10:28 a.m.
>>> > To: r-help at r-project.org
>>> > Subject: Re: [R] a knitr question
>>> >
>>> > Sorry:  just solved it.
>>> >
>>> > You simply include "prompt=TRUE" in the <<>> section
>>> >
>>> > Thanks,
>>> > Erin
>>> >
>>> >
>>> >
>>> > On Tue, Jul 29, 2014 at 6:22 PM, Erin Hodgess <erinm.hodgess at gmail.com>
>>> > wrote:
>>> >
>>> >> Hello!
>>> >>
>>> >> When constructing code using knitr, is there a way to get the ">"
>>> >> prompt to appear, please?
>>> >>
>>> >> Everything else works great!!
>>> >>
>>> >> Thank you!
>>> >>
>>> >> Sincerely,
>>> >> Erin
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Erin Hodgess
>>> >> Associate Professor
>>> >> Department of Mathematical and Statistics University of Houston -
>>> >> Downtown
>>> >> mailto: erinm.hodgess at gmail.com
>>> >>
>>> >
>>> >
>>> >
>>> > --
>>> > Erin Hodgess
>>> > Associate Professor
>>> > Department of Mathematical and Statistics University of Houston -
>>> Downtown
>>> > mailto: erinm.hodgess at gmail.com
>>>
>>
>>
>>
>> --
>> Erin Hodgess
>> Associate Professor
>> Department of Mathematical and Statistics
>> University of Houston - Downtown
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From h.wickham at gmail.com  Wed Jul 30 19:54:27 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 30 Jul 2014 12:54:27 -0500
Subject: [R] ATTN: Urgent Guidance Needed on scraping tweets for last 10
 years using TwitteR / search twitter function.
In-Reply-To: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>
References: <CAEkKqL4v1fKKeJJC7dqJxtNgP8pMAXG_PXkXixvgdQrhoPQ2=w@mail.gmail.com>
Message-ID: <CABdHhvEjHn9O6CXmLQKJA0H3ZzLH+04qfEMk_t=2S2v4AgrDPw@mail.gmail.com>

The first twitter message was sent on March 21st, 2006...

Hadley

On Wed, Jul 30, 2014 at 3:58 AM, Abhishek Dutta <abhishek.dta at gmail.com> wrote:
> Hi
>
>
> This is Abhishek and I am trying to look for tweets on 'Election' from
> 2000 to YTD. I have registered on twitter and performed a handshake
> between the systems as well. Next I am trying to fetching tweets
> chronologically using the below code:-
>
>
> tweets1.list = searchTwitter('Election',lang="en",since='2000-07-01',
> until='2014-07-30', cainfo="cacert.pem")
>
>
> All I get in return is 26 line items between 27th - 28th of July only.
>
>
> Can you please help me understand why it gives me so less number of
> tweets, backdated by two days only & also if there is a an alternative
> method of fetching tweets over the last ten years, at the minimum,
> categorized by date ?
>
>
> Many thanks in advance for your guidance. This is an urgent request
> and hence requesting your immediate assistance.
>
>
> Best
>
> Abhishek
>
>
>
>
> --
> Abhishek Dutta
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From wdunlap at tibco.com  Wed Jul 30 19:54:34 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Jul 2014 10:54:34 -0700
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
	<CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
Message-ID: <CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>

> I should have mentioned that I tried other time stamps, generated the
> same way as "q" above.

How did you generate q and in what time zone were you?  Note that 2am
on 9 March 2014 is when 'daylight savings time' started in the parts
of the US where it is observed.  Does 2am exist or do we jump from
1:59:59 to 3:00:00?


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jul 30, 2014 at 10:42 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Wed, Jul 30, 2014 at 12:18 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 30/07/2014 1:08 PM, John McKown wrote:
>>>
>>> "I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
>>> time of 2014-03-09 02:00:00 ?
>>>
>>> > q
>>> [1] "2014-03-09 02:00:00"
>>> > is.na(q)
>>> [1] TRUE
>>> > as.POSIXct(q)
>>> [1] NA
>>> > dput(q)
>>> structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
>>>      year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
>>>      gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
>>> "mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class =
>>> c("POSIXlt",
>>> "POSIXt"))
>>
>>
>> I see an NA in there for the GMT offset, and no timezone.
>
> I should have mentioned that I tried other time stamps, generated the
> same way as "q" above. They did not fail the is.na() test. I think
> that is.na() is doing a as.double() somewhere in there because
> as.double(q)  gives  NA as a result.
>
>>
>> Duncan Murdoch
>>
>>> > str(q)
>>>   POSIXlt[1:1], format: "2014-03-09 02:00:00"
>>> >
>>>
>>>
>>
>
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Jul 30 19:58:04 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 30 Jul 2014 12:58:04 -0500
Subject: [R] Count number of change in a specified time interval
In-Reply-To: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
References: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
Message-ID: <CAN5YmCHcnW8MsaVzkbuJVoWQRY0BC3unu9KPJ0Rbu0Z6HzN-LA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/74b33514/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Jul 30 20:03:06 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 30 Jul 2014 11:03:06 -0700
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
Message-ID: <01a41b7b-1f5f-4a82-b6e0-30ff18fc6807@email.android.com>

Isn't that a timestamp that doesn't exist in standard US timezones? Maybe use a timezone that doesn't consider daylight savings (like "Etc/GMT+5")?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 30, 2014 10:08:58 AM PDT, John McKown <john.archie.mckown at gmail.com> wrote:
>"I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
>time of 2014-03-09 02:00:00 ?
>
>> q
>[1] "2014-03-09 02:00:00"
>> is.na(q)
>[1] TRUE
>> as.POSIXct(q)
>[1] NA
>> dput(q)
>structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
>    year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
>    gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
>"mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class =
>c("POSIXlt",
>"POSIXt"))
>> str(q)
> POSIXlt[1:1], format: "2014-03-09 02:00:00"
>>


From john.archie.mckown at gmail.com  Wed Jul 30 20:07:50 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 30 Jul 2014 13:07:50 -0500
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
	<CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
	<CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>
Message-ID: <CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>

On Wed, Jul 30, 2014 at 12:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> I should have mentioned that I tried other time stamps, generated the
>> same way as "q" above.
>
> How did you generate q and in what time zone were you?

I got it from an MS-SQL data base which is maintained by some
closed-source vendor software. But I manipulate the data in the SELECT
before sending it to R via ODBC. I need to double check the raw data
in the data base.

> Note that 2am
> on 9 March 2014 is when 'daylight savings time' started in the parts
> of the US where it is observed.  Does 2am exist or do we jump from
> 1:59:59 to 3:00:00?

Hum, that hadn't occurred to me. I need to see what is in the DB.

But I think you have found my problem. If I force the timezone to be
GMT, then the problem disappears. So that is what I'll do with this
data.

>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From abhinabaroy09 at gmail.com  Wed Jul 30 20:18:23 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 30 Jul 2014 23:48:23 +0530
Subject: [R] DATA SUMMARIZING and REPORTING
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD48F@SRVEXCHMBX.precheza.cz>
References: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD48F@SRVEXCHMBX.precheza.cz>
Message-ID: <CANtKHPXcR0X5m6NC0iOeb9xdZEoTfChzEOYkKxjpeE7-vr6fLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/e9aeacdb/attachment.pl>

From xie at yihui.name  Wed Jul 30 20:20:16 2014
From: xie at yihui.name (Yihui Xie)
Date: Wed, 30 Jul 2014 13:20:16 -0500
Subject: [R] a knitr question
In-Reply-To: <CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
Message-ID: <CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>

As a reader, I often want to run the code by myself _while_ I'm
reading a particular part of an article/report. I find it convenient
to be able to copy the code as I'm reading it, instead of minimizing
my current window, opening an R script, and running the part that I'm
interested in. Of course, this may not work if the code I copy is not
self-contained; your purl() approach certainly has an advantage
sometimes.

I do not see a whole lot of value in maintaining the same appearance
of the R code in the R console and a report. You can teach your
students what the prompt characters mean, and I think that is enough.
Journal of Statistical Software requires "R> " as the prompt character
(which is worse), and your students will probably be confused when
reading JSS papers if they have been seeing the default prompts all
the time. I see the point of keeping prompts (i.e. I do not completely
disagree), but I do not think it is an essential or important thing to
do. Personally I prefer reading "vanilla" code, and >/+ may confuse my
eyes occasionally, e.g.

> z > 5
> x +
+ y

(More on prompts:
http://yihui.name/en/2013/01/code-pollution-with-command-prompts/)

Re Rich: yes, I'm aware of approaches of post-processing the prompts,
but this problem would not have existed in the first place if we do
not include prompts at all. I'm not sure if it makes much sense to
create some mess and clean it afterwards.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Jul 30, 2014 at 12:50 PM, Greg Snow <538280 at gmail.com> wrote:
> My preference when teaching is to have the code and results look the
> same as it appears in the R console window, so with the prompts and
> without the output commented.  But then I also `purl` my knitr file to
> create a script file to give to the students that they can copy and
> paste from easily.
>


From john.archie.mckown at gmail.com  Wed Jul 30 20:21:22 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 30 Jul 2014 13:21:22 -0500
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
	<CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
	<CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>
	<CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>
Message-ID: <CAAJSdjg8-j8HTvbHokpeFu1923b3FRC-KnEuwz4aJRb3akcUFw@mail.gmail.com>

OK, daylight saving time, may be be cursed, is definitely my problem.
Strangely, the DB has data for time 0000, 0100, 0200, 0400, 0500, ...
2300. It is closed source, so I have _no_ idea how this happened. And
I cannot report bugs because it is no longer supported. The encoding
is a 4 character (digit) field of the form HHMM. Why, I don't know.

But I have a work around which satisfies me and lets me get something
for the boss.

On Wed, Jul 30, 2014 at 1:07 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Wed, Jul 30, 2014 at 12:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> I should have mentioned that I tried other time stamps, generated the
>>> same way as "q" above.
>>
>> How did you generate q and in what time zone were you?
>
> I got it from an MS-SQL data base which is maintained by some
> closed-source vendor software. But I manipulate the data in the SELECT
> before sending it to R via ODBC. I need to double check the raw data
> in the data base.
>
>> Note that 2am
>> on 9 March 2014 is when 'daylight savings time' started in the parts
>> of the US where it is observed.  Does 2am exist or do we jump from
>> 1:59:59 to 3:00:00?
>
> Hum, that hadn't occurred to me. I need to see what is in the DB.
>
> But I think you have found my problem. If I force the timezone to be
> GMT, then the problem disappears. So that is what I'll do with this
> data.
>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From wdunlap at tibco.com  Wed Jul 30 20:23:28 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Jul 2014 11:23:28 -0700
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
	<CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
	<CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>
	<CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>
Message-ID: <CAF8bMcb7d8K98820ocV8VwVP56TvnQDR6H+NiS1GWuq0wb==jQ@mail.gmail.com>

I meant what R commands did you use to change the database's version
of the time/date object to the R version?
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jul 30, 2014 at 11:07 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Wed, Jul 30, 2014 at 12:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> I should have mentioned that I tried other time stamps, generated the
>>> same way as "q" above.
>>
>> How did you generate q and in what time zone were you?
>
> I got it from an MS-SQL data base which is maintained by some
> closed-source vendor software. But I manipulate the data in the SELECT
> before sending it to R via ODBC. I need to double check the raw data
> in the data base.
>
>> Note that 2am
>> on 9 March 2014 is when 'daylight savings time' started in the parts
>> of the US where it is observed.  Does 2am exist or do we jump from
>> 1:59:59 to 3:00:00?
>
> Hum, that hadn't occurred to me. I need to see what is in the DB.
>
> But I think you have found my problem. If I force the timezone to be
> GMT, then the problem disappears. So that is what I'll do with this
> data.
>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


From john.archie.mckown at gmail.com  Wed Jul 30 20:39:07 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 30 Jul 2014 13:39:07 -0500
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAF8bMcb7d8K98820ocV8VwVP56TvnQDR6H+NiS1GWuq0wb==jQ@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
	<53D928F5.1030500@gmail.com>
	<CAAJSdjhacE2mxYFariR03C8UhT8w1BT7+RVJc6PxHPACXOpN4A@mail.gmail.com>
	<CAF8bMcZaQo2Ydk_qGJQMbgPMScuX56EtZ4OtKbm-4-840Y0WHQ@mail.gmail.com>
	<CAAJSdjg5wubjzCAsnYhSgPPEMzGF5PBJPzFzt6oCqw3m36gr0g@mail.gmail.com>
	<CAF8bMcb7d8K98820ocV8VwVP56TvnQDR6H+NiS1GWuq0wb==jQ@mail.gmail.com>
Message-ID: <CAAJSdjjhmD2HDLUyy=AKxf-3yM=DUgNSAk_5pzVJEgp8VYmXUQ@mail.gmail.com>

Probably not the best, but here:

con <- odbcConnect("BMC");
timezone <- Sys.timezone();
#
query=paste0("select CONVERT(smalldatetime,Int_Start_Date,11) as
Int_Start_Date,",
             " CONVERT(smalldatetime,CASE WHEN Int_Start_Time is NULL
then '00:00' ",
             "else
LEFT(Int_Start_Time,2)+':'+SUBSTRING(Int_Start_Time,3,2) end +",
             "':00', 14) as Int_Start_Time",
             ", Int_duration, RTRIM(INTTYPE) AS INTTYPE",
             ", RTRIM(Int_descr) AS Int_descr",
             ", RTRIM(INTSUBT) as INTSUBT",
             ", INDEXX, RTRIM(Label) AS Label",
             ", RTRIM(CHANGED) AS CHANGED",
             ", RTRIM(ALERT) AS ALERT",
             ", RTRIM(RELEASE) AS RELEASE",
             " FROM CPINTVL where Int_Start_Date BETWEEN '",
             startDateChar,"' and '",endDateChar,"'",
             "AND INTTYPE='M'"
);
cpintvl <- sqlQuery(con,
            query,
            stringsAsFactors=FALSE,
            as.is=TRUE);
#
# properly combine start date and time because I couldn't figure out how to
# get MS-SQL to do it for me.
cpintvl$Int_Start <- strptime(paste0(substr(cpintvl$Int_Start_Date,1,11),

substr(cpintvl$Int_Start_Time,12,19)),"%Y-%m-%d %H:%M:%S");

So the actual value was created with the strptime() call at the end.
The rest is just in character form. The Int_Start_Date in the DB is in
yy/mm/dd format as a character field. Int_Start_Time is HHMM as a
character field with leading zeros. The return value from the SELECT
has Start_Int_Date formatted in yyyy-mm-dd as a character string.
Start_Int_Time formatted in hh:mm:ss as a character string.

In any case, you have accurately explained my foolishness. I keep
forgetting about DST because I record _everything_ in my personal DBs
in UTC.

On Wed, Jul 30, 2014 at 1:23 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I meant what R commands did you use to change the database's version
> of the time/date object to the R version?
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Jul 30, 2014 at 11:07 AM, John McKown
> <john.archie.mckown at gmail.com> wrote:
>> On Wed, Jul 30, 2014 at 12:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> I should have mentioned that I tried other time stamps, generated the
>>>> same way as "q" above.
>>>
>>> How did you generate q and in what time zone were you?
>>
>> I got it from an MS-SQL data base which is maintained by some
>> closed-source vendor software. But I manipulate the data in the SELECT
>> before sending it to R via ODBC. I need to double check the raw data
>> in the data base.
>>
>>> Note that 2am
>>> on 9 March 2014 is when 'daylight savings time' started in the parts
>>> of the US where it is observed.  Does 2am exist or do we jump from
>>> 1:59:59 to 3:00:00?
>>
>> Hum, that hadn't occurred to me. I need to see what is in the DB.
>>
>> But I think you have found my problem. If I force the timezone to be
>> GMT, then the problem disappears. So that is what I'll do with this
>> data.
>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>>
>> Maranatha! <><
>> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From ramnath.vaidyanathan at mcgill.ca  Wed Jul 30 18:50:48 2014
From: ramnath.vaidyanathan at mcgill.ca (Ramnath Vaidyanathan)
Date: Wed, 30 Jul 2014 12:50:48 -0400
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>
	<1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>
Message-ID: <CAKO5CYUKnDwHiLq1ix-J7J877iuBPGmLqEUCgr0mH_4eM07z+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/c35b9edf/attachment.pl>

From stergios_marinopoulos at yahoo.com  Wed Jul 30 19:01:56 2014
From: stergios_marinopoulos at yahoo.com (Stergios Marinopoulos)
Date: Wed, 30 Jul 2014 10:01:56 -0700
Subject: [R] xtable problems with xts objects
Message-ID: <1406739716.2111.YahooMailNeo@web163005.mail.bf1.yahoo.com>

Hi, ?I'm having trouble getting xtable to print a simple xts object. ?When the frequency is 1800 seconds I get an error. ?However when frequency(x) is reported as 1 it works. ?I have included example below.


Another question is how can I have the the time index printed in place of the row number? ?

Thanks for your help, ?
--
Stergios Marinopoulos

library(xts)
library(xtable)

# This does not work. ?The indicies are 1800 seconds apart.
x = xts(x=rep(pi, 6), order.by=as.POSIXlt( "2014-01-01 06:30:00" ) + 1800 * 0:5 )?

print(xtable(x))
print(frequency(x)) ?#?[1] 0.0005555556

# This is the error message:
# Error in rep(NA, start(x)[2] - 1) : invalid 'times' argument


# It works when I make the indicies only 1 second apart.
x = xts(rep(pi, 6), as.POSIXlt( "1970-01-01 00:00:00" ) + 0:5 )?
print(xtable(x))
print(frequency(x))  # [1] 1


# Here is a daily data example that works.
library(quantmod)
AAPL = getSymbols("AAPL", auto.assign=FALSE, from="2014-01-01", to="2014-01-10")
print(xtable(AAPL), include.rownames=TRUE)
print(frequency(x))  # [1] 1


From ramiro at precisionbioassay.com  Wed Jul 30 21:56:53 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Wed, 30 Jul 2014 19:56:53 +0000
Subject: [R] binary to R object
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979AFC3B4@MBX023-W1-CA-2.exch023.domain.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/c45977fd/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jul 30 22:07:18 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Jul 2014 16:07:18 -0400
Subject: [R]  a quick list mode question
Message-ID: <CACxE24k5N1c-Bcq2Aj=WFOw1KzSnQCiNFzacxk=7DwY54tPJ9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/8bf44537/attachment.pl>

From wht_crl at yahoo.com  Wed Jul 30 22:13:52 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 30 Jul 2014 13:13:52 -0700
Subject: [R] separate numbers from chars in a string
Message-ID: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/4a4c6531/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jul 30 22:14:00 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Jul 2014 16:14:00 -0400
Subject: [R] a quick list mode question
In-Reply-To: <CACxE24k5N1c-Bcq2Aj=WFOw1KzSnQCiNFzacxk=7DwY54tPJ9g@mail.gmail.com>
References: <CACxE24k5N1c-Bcq2Aj=WFOw1KzSnQCiNFzacxk=7DwY54tPJ9g@mail.gmail.com>
Message-ID: <CACxE24=DDMy=uURZ8sgD+-5+NVsMVAuUM+_eO9+VZmtDQ=7WpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/f1645a94/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Jul 30 22:14:27 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Jul 2014 21:14:27 +0100
Subject: [R] binary to R object
In-Reply-To: <C7338A7EFF31BB4D831BB06C0088778979AFC3B4@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C0088778979AFC3B4@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <53D95223.9080800@stats.ox.ac.uk>

What type actually is 'binary' here?  We cannot tell, as writeBin will 
handle many types.

If 'binary' means a raw vector, two ways:

1) Use load() on a raw connection (see ?rawConnection).

2) Make use of the information in ?readRDS.  You can read the header 
from save() format by skipping the first 5 bytes, then call 
unserialize() on the rest of the raw vector.  (If the save was 
compressed, you need to handle decompression too: see ?memCompress.)

If you want more help, heed the footer of this and every R-help message 
and provide a complete reproducible example.


On 30/07/2014 20:56, Ramiro Barrantes wrote:
> Hello,
>
> I have stored R objects as hexadecimals in a mysql database, I then usually transform them to binary and then save it into a file.  E.g.
>
>    hex <- getBlob   #gets blob from database as hexadecimal
>    binary <- transformToBinary(hex)  #moves from hex to binary
>
> I would usually save them into a file as follows:
>
>    writeBin(object=binary,con="fileName.txt")
>
> Then eventually if I want to use it in R I just load it:
>
>    load("fileName.txt")
>
> However, how can I go from the binary directly into an Robject without writing it to a file?
>
>    say:
>
>    myObject <- unknownFunction(binary)
>
> I hope this is enough detail.  Any help appreciated.
>
> In retrospect, I could have probably used serialize/unserialize and store a serialize string in mysql and unserialize when needed ( or write to a file if necessary), but I didn't know of those when I did this.
>
> Thanks in advance,
>
> Ramiro
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ramiro at precisionbioassay.com  Wed Jul 30 22:22:33 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Wed, 30 Jul 2014 20:22:33 +0000
Subject: [R] binary to R object
In-Reply-To: <53D95223.9080800@stats.ox.ac.uk>
References: <C7338A7EFF31BB4D831BB06C0088778979AFC3B4@MBX023-W1-CA-2.exch023.domain.local>,
	<53D95223.9080800@stats.ox.ac.uk>
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979AFC3CC@MBX023-W1-CA-2.exch023.domain.local>

rawConnection did it!!

Thank you very much!!!
________________________________________
From: Prof Brian Ripley [ripley at stats.ox.ac.uk]
Sent: Wednesday, July 30, 2014 4:14 PM
To: Ramiro Barrantes; r-help at r-project.org
Subject: Re: [R] binary to R object

What type actually is 'binary' here?  We cannot tell, as writeBin will
handle many types.

If 'binary' means a raw vector, two ways:

1) Use load() on a raw connection (see ?rawConnection).

2) Make use of the information in ?readRDS.  You can read the header
from save() format by skipping the first 5 bytes, then call
unserialize() on the rest of the raw vector.  (If the save was
compressed, you need to handle decompression too: see ?memCompress.)

If you want more help, heed the footer of this and every R-help message
and provide a complete reproducible example.


On 30/07/2014 20:56, Ramiro Barrantes wrote:
> Hello,
>
> I have stored R objects as hexadecimals in a mysql database, I then usually transform them to binary and then save it into a file.  E.g.
>
>    hex <- getBlob   #gets blob from database as hexadecimal
>    binary <- transformToBinary(hex)  #moves from hex to binary
>
> I would usually save them into a file as follows:
>
>    writeBin(object=binary,con="fileName.txt")
>
> Then eventually if I want to use it in R I just load it:
>
>    load("fileName.txt")
>
> However, how can I go from the binary directly into an Robject without writing it to a file?
>
>    say:
>
>    myObject <- unknownFunction(binary)
>
> I hope this is enough detail.  Any help appreciated.
>
> In retrospect, I could have probably used serialize/unserialize and store a serialize string in mysql and unserialize when needed ( or write to a file if necessary), but I didn't know of those when I did this.
>
> Thanks in advance,
>
> Ramiro
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jdnewmil at dcn.davis.CA.us  Wed Jul 30 22:23:18 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 30 Jul 2014 13:23:18 -0700
Subject: [R] a quick list mode question
In-Reply-To: <CACxE24k5N1c-Bcq2Aj=WFOw1KzSnQCiNFzacxk=7DwY54tPJ9g@mail.gmail.com>
References: <CACxE24k5N1c-Bcq2Aj=WFOw1KzSnQCiNFzacxk=7DwY54tPJ9g@mail.gmail.com>
Message-ID: <00c14d8e-bec3-41f1-a280-14ce0abaa148@email.android.com>

I don't. Please post code to demonstrate your result when asking a question like this.

test <- list()
mode(test)
[1] "list"
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 30, 2014 1:07:18 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello yet again
>
>I was looking at the class and the mode of a list.  For the class of a
>list, of course I got a list, but for the mode, I got a function.
>
>Why do you get a function, please?
>
>Thanks,
>Erin


From jdnewmil at dcn.davis.CA.us  Wed Jul 30 22:32:47 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 30 Jul 2014 13:32:47 -0700
Subject: [R] Technological/Logistic substitution model.
In-Reply-To: <1406735665.69992.YahooMailNeo@web122401.mail.ne1.yahoo.com>
References: <1406735665.69992.YahooMailNeo@web122401.mail.ne1.yahoo.com>
Message-ID: <f40ec5cb-1cac-4d97-b8dd-ac5f8c461923@email.android.com>

You are repeating yourself. At least post as a reply to your earlier post.

Does

RSiteSearch("technological logistic")

help?

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 30, 2014 8:54:25 AM PDT, Peter Maclean <pmaclean2011 at yahoo.com> wrote:
>?Any one with an idea of estimating the Technological/Logistic
>substitution model. 
>The model is specified as: 
>fi(t(j)) = 1/[1-exp(-alpa(t(i))-beta(i)] for t 0 
>fi(t(j)) = 1-sum(f(j-1))- sum(f(j+1)) for tb <=t <= tc 
>fi(t(j)) = 1/[1+ exp(alpas(t(i)-betas(i))] for t >=tc and alphas >0. T
>The model assume that n technologies are introduced to the market,
>where 1 is the oldest and technology n is the newest, i and j are
>subscripts representing the type of technology, fi is the market share,
>t is a subscript denoting time, alpha, alphas, beta, and betas are
>parameters, tb and tc are time periods during which the technology i
>starts to enter the saturation and decline phase, respectively. Any
>suggestion, reading will be appreciate. 
>?
>Peter Maclean
>Department of Economics
>UDSM
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jul 30 22:49:01 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 30 Jul 2014 21:49:01 +0100
Subject: [R] separate numbers from chars in a string
In-Reply-To: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <53D95A3D.60102@sapo.pt>

Hello,

Maybe ?gregexpr and ?regmatches. SOmething like the following.


m1 <- gregexpr("[a-z]+","absdfds0213451ab")
regmatches("absdfds0213451ab", m1)

m2 <- gregexpr("[0-9]+","absdfds0213451ab")
regmatches("absdfds0213451ab", m2)


Hope this helps,

Rui Barradas

Em 30-07-2014 21:13, carol white escreveu:
> Hi,
> If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?
>
> grep doesn't seem to be helpful
>
> grep("[a-z]","absdfds0213451ab", ignore.case=T)
> [1] 1
>
>
>   grep("[0-9]","absdfds0213451ab", ignore.case=T)
> [1] 1
>
> Thanks
>
> Carol
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Wed Jul 30 22:52:35 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 30 Jul 2014 15:52:35 -0500
Subject: [R] separate numbers from chars in a string
In-Reply-To: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <603C2D2B-0307-4915-97F3-464793416697@me.com>

On Jul 30, 2014, at 3:13 PM, carol white <wht_crl at yahoo.com> wrote:

> Hi,
> If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?
> 
> grep doesn't seem to be helpful
> 
> grep("[a-z]","absdfds0213451ab", ignore.case=T)
> [1] 1
> 
> 
>  grep("[0-9]","absdfds0213451ab", ignore.case=T)
> [1] 1
> 
> Thanks
> 
> Carol


grep() will only tell you that a pattern is present. You want to use gsub() or similar with back references to return parts of the vector.

Will they ALWAYS appear in that pattern (letters, numbers, letters) or is there some level of variation?

If they will always appear as in your example, then one approach is:

> strsplit(gsub("([a-z]+)([0-9]+)([a-z]+)", "\\1 \\2 \\3", "absdfds0213451ab"), " ")
[[1]]
[1] "absdfds" "0213451" "ab"    


The initial gsub() returns the 3 parts separated by a space, which is then used as the split argument to strsplit().

If there will be some variation, you can use multiple calls to gsub() or similar, each getting either the letters or the numbers.

Regards,

Marc Schwartz


From ligges at statistik.tu-dortmund.de  Wed Jul 30 23:05:11 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 30 Jul 2014 23:05:11 +0200
Subject: [R] separate numbers from chars in a string
In-Reply-To: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <53D95E07.20807@statistik.tu-dortmund.de>



On 30.07.2014 22:13, carol white wrote:
> Hi,
> If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?
>
> grep doesn't seem to be helpful
>
> grep("[a-z]","absdfds0213451ab", ignore.case=T)
> [1] 1
>
>
>   grep("[0-9]","absdfds0213451ab", ignore.case=T)
> [1] 1


I'd propose something along:

result <- gsub("^([[:alpha:]]+)([[:digit:]]+)([[:alpha:]]+)$", 
"\\1-\\2-\\3", "absdfds0213451ab")

If you have lots of these strings, you can convert all of them and then

do.call("rbind", strsplit(result, "-"))

or some such.

Best,
Uwe Ligges



> Thanks
>
> Carol
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stergios_marinopoulos at yahoo.com  Wed Jul 30 23:22:47 2014
From: stergios_marinopoulos at yahoo.com (Stergios Marinopoulos)
Date: Wed, 30 Jul 2014 14:22:47 -0700
Subject: [R] xtable problems with xts objects
In-Reply-To: <1406739716.2111.YahooMailNeo@web163005.mail.bf1.yahoo.com>
References: <1406739716.2111.YahooMailNeo@web163005.mail.bf1.yahoo.com>
Message-ID: <1406755367.42852.YahooMailNeo@web163004.mail.bf1.yahoo.com>

Hi, ?I'm having trouble getting xtable to print a simple xts object. ?When the frequency is 1800 I get an error. ?However when frequency(x) is reported as 1 it works. ?I have included example below.



Another question is how can I have the time index printed in place of the row number? ?

Thanks for your help, ?
--
Stergios Marinopoulos

library(xts)
library(xtable)

# This does not work. ?The indices are 1800 seconds apart.
x = xts(x=rep(pi, 6), order.by=as.POSIXlt( "2014-01-01 06:30:00" ) + 1800 * 0:5 )?

print(xtable(x))
print(frequency(x)) ?#?[1] 0.0005555556

# This is the error message:
# Error in rep(NA, start(x)[2] - 1) : invalid 'times' argument


# It works when I make the indices only 1 second apart.
x = xts(rep(pi, 6), as.POSIXlt( "1970-01-01 00:00:00" ) + 0:5 )?
print(xtable(x))
print(frequency(x))? # [1] 1


# Here is a daily data example that works.
library(quantmod)
AAPL = getSymbols("AAPL", auto.assign=FALSE, from="2014-01-01", to="2014-01-10")
print(xtable(AAPL), include.rownames=TRUE)
print(frequency(x))? # [1] 1


From istazahn at gmail.com  Wed Jul 30 23:50:58 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 30 Jul 2014 17:50:58 -0400
Subject: [R] xtable problems with xts objects
In-Reply-To: <1406755367.42852.YahooMailNeo@web163004.mail.bf1.yahoo.com>
References: <1406739716.2111.YahooMailNeo@web163005.mail.bf1.yahoo.com>
	<1406755367.42852.YahooMailNeo@web163004.mail.bf1.yahoo.com>
Message-ID: <CA+vqiLE3s++gQ3-gj_99CCnY9F4M7md=UcGFp3DAVv7EwvBwtw@mail.gmail.com>

Hi Stergios,

I think as.data.frame(x) solves both your problems.

Best,
Ista



On Wed, Jul 30, 2014 at 5:22 PM, Stergios Marinopoulos
<stergios_marinopoulos at yahoo.com> wrote:
> Hi,  I'm having trouble getting xtable to print a simple xts object.  When the frequency is 1800 I get an error.  However when frequency(x) is reported as 1 it works.  I have included example below.
>
>
>
> Another question is how can I have the time index printed in place of the row number?
>
> Thanks for your help,
> --
> Stergios Marinopoulos
>
> library(xts)
> library(xtable)
>
> # This does not work.  The indices are 1800 seconds apart.
> x = xts(x=rep(pi, 6), order.by=as.POSIXlt( "2014-01-01 06:30:00" ) + 1800 * 0:5 )
>
> print(xtable(x))
> print(frequency(x))  # [1] 0.0005555556
>
> # This is the error message:
> # Error in rep(NA, start(x)[2] - 1) : invalid 'times' argument
>
>
> # It works when I make the indices only 1 second apart.
> x = xts(rep(pi, 6), as.POSIXlt( "1970-01-01 00:00:00" ) + 0:5 )
> print(xtable(x))
> print(frequency(x))  # [1] 1
>
>
> # Here is a daily data example that works.
> library(quantmod)
> AAPL = getSymbols("AAPL", auto.assign=FALSE, from="2014-01-01", to="2014-01-10")
> print(xtable(AAPL), include.rownames=TRUE)
> print(frequency(x))  # [1] 1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stergios_marinopoulos at yahoo.com  Thu Jul 31 00:11:43 2014
From: stergios_marinopoulos at yahoo.com (Stergios Marinopoulos)
Date: Wed, 30 Jul 2014 15:11:43 -0700
Subject: [R] xtable problems with xts objects
In-Reply-To: <CA+vqiLE3s++gQ3-gj_99CCnY9F4M7md=UcGFp3DAVv7EwvBwtw@mail.gmail.com>
References: <1406739716.2111.YahooMailNeo@web163005.mail.bf1.yahoo.com>
	<1406755367.42852.YahooMailNeo@web163004.mail.bf1.yahoo.com>
	<CA+vqiLE3s++gQ3-gj_99CCnY9F4M7md=UcGFp3DAVv7EwvBwtw@mail.gmail.com>
Message-ID: <1406758303.60194.YahooMailNeo@web163005.mail.bf1.yahoo.com>

I can live with that.? Thanks Ista!


?
--
Stergios Marinopoulos


----- Original Message -----
From: Ista Zahn <istazahn at gmail.com>
To: Stergios Marinopoulos <stergios_marinopoulos at yahoo.com>
Cc: R. Project Help <r-help at r-project.org>
Sent: Wednesday, July 30, 2014 2:50 PM
Subject: Re: [R] xtable problems with xts objects

Hi Stergios,

I think as.data.frame(x) solves both your problems.

Best,
Ista






On Wed, Jul 30, 2014 at 5:22 PM, Stergios Marinopoulos
<stergios_marinopoulos at yahoo.com> wrote:
> Hi,? I'm having trouble getting xtable to print a simple xts object.? When the frequency is 1800 I get an error.? However when frequency(x) is reported as 1 it works.? I have included example below.
>
>
>
> Another question is how can I have the time index printed in place of the row number?
>
> Thanks for your help,
> --
> Stergios Marinopoulos
>
> library(xts)
> library(xtable)
>
> # This does not work.? The indices are 1800 seconds apart.
> x = xts(x=rep(pi, 6), order.by=as.POSIXlt( "2014-01-01 06:30:00" ) + 1800 * 0:5 )
>
> print(xtable(x))
> print(frequency(x))? # [1] 0.0005555556
>
> # This is the error message:
> # Error in rep(NA, start(x)[2] - 1) : invalid 'times' argument
>
>
> # It works when I make the indices only 1 second apart.
> x = xts(rep(pi, 6), as.POSIXlt( "1970-01-01 00:00:00" ) + 0:5 )
> print(xtable(x))
> print(frequency(x))? # [1] 1
>
>
> # Here is a daily data example that works.
> library(quantmod)
> AAPL = getSymbols("AAPL", auto.assign=FALSE, from="2014-01-01", to="2014-01-10")
> print(xtable(AAPL), include.rownames=TRUE)
> print(frequency(x))? # [1] 1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Thu Jul 31 01:47:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Jul 2014 19:47:51 -0400
Subject: [R] a knitr question
In-Reply-To: <CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
Message-ID: <53D98427.7060700@gmail.com>

On 30/07/2014, 2:20 PM, Yihui Xie wrote:
> As a reader, I often want to run the code by myself _while_ I'm
> reading a particular part of an article/report. I find it convenient
> to be able to copy the code as I'm reading it, instead of minimizing
> my current window, opening an R script, and running the part that I'm
> interested in. Of course, this may not work if the code I copy is not
> self-contained; your purl() approach certainly has an advantage
> sometimes.
> 
> I do not see a whole lot of value in maintaining the same appearance
> of the R code in the R console and a report. You can teach your
> students what the prompt characters mean, and I think that is enough.
> Journal of Statistical Software requires "R> " as the prompt character
> (which is worse), and your students will probably be confused when
> reading JSS papers if they have been seeing the default prompts all
> the time. I see the point of keeping prompts (i.e. I do not completely
> disagree), but I do not think it is an essential or important thing to
> do. Personally I prefer reading "vanilla" code, and >/+ may confuse my
> eyes occasionally, e.g.
> 
>> z > 5
>> x +
> + y
> 
> (More on prompts:
> http://yihui.name/en/2013/01/code-pollution-with-command-prompts/)
> 
> Re Rich: yes, I'm aware of approaches of post-processing the prompts,
> but this problem would not have existed in the first place if we do
> not include prompts at all. I'm not sure if it makes much sense to
> create some mess and clean it afterwards.
> 

So your suggestion is that the R console should not prompt for input?
Do you know of *any* interactive system which doesn't prompt for input?
 How would users be able to tell the difference between R waiting for
input, and R busy on the last calculation?

Duncan Murdoch


> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> 
> 
> On Wed, Jul 30, 2014 at 12:50 PM, Greg Snow <538280 at gmail.com> wrote:
>> My preference when teaching is to have the code and results look the
>> same as it appears in the R console window, so with the prompts and
>> without the output commented.  But then I also `purl` my knitr file to
>> create a script file to give to the students that they can copy and
>> paste from easily.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jwiley.psych at gmail.com  Thu Jul 31 02:06:52 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 31 Jul 2014 10:06:52 +1000
Subject: [R] a knitr question
In-Reply-To: <53D98427.7060700@gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
Message-ID: <CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/76c00524/attachment.pl>

From jmhannon.ucdavis at gmail.com  Thu Jul 31 02:16:37 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 30 Jul 2014 17:16:37 -0700
Subject: [R] a knitr question
In-Reply-To: <CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
	<CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
Message-ID: <CACdH2Zad2SWXBifgNPuCpSfZafu2S7o3kpZ+=17L=8nbu3XvYw@mail.gmail.com>

That's what I thought.  Also, just FYI, the "ed" editor on *nix
systems doesn't have a prompt (at least not by default).  My son
thought I was "trolling" him when I told him that.

-- Mike

On Wed, Jul 30, 2014 at 5:06 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> On Thu, Jul 31, 2014 at 9:47 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 30/07/2014, 2:20 PM, Yihui Xie wrote:
>> > As a reader, I often want to run the code by myself _while_ I'm
>> > reading a particular part of an article/report. I find it convenient
>> > to be able to copy the code as I'm reading it, instead of minimizing
>> > my current window, opening an R script, and running the part that I'm
>> > interested in. Of course, this may not work if the code I copy is not
>> > self-contained; your purl() approach certainly has an advantage
>> > sometimes.
>> >
>> > I do not see a whole lot of value in maintaining the same appearance
>> > of the R code in the R console and a report. You can teach your
>> > students what the prompt characters mean, and I think that is enough.
>> > Journal of Statistical Software requires "R> " as the prompt character
>> > (which is worse), and your students will probably be confused when
>> > reading JSS papers if they have been seeing the default prompts all
>> > the time. I see the point of keeping prompts (i.e. I do not completely
>> > disagree), but I do not think it is an essential or important thing to
>> > do. Personally I prefer reading "vanilla" code, and >/+ may confuse my
>> > eyes occasionally, e.g.
>> >
>> >> z > 5
>> >> x +
>> > + y
>> >
>> > (More on prompts:
>> > http://yihui.name/en/2013/01/code-pollution-with-command-prompts/)
>> >
>> > Re Rich: yes, I'm aware of approaches of post-processing the prompts,
>> > but this problem would not have existed in the first place if we do
>> > not include prompts at all. I'm not sure if it makes much sense to
>> > create some mess and clean it afterwards.
>> >
>>
>> So your suggestion is that the R console should not prompt for input?
>> Do you know of *any* interactive system which doesn't prompt for input?
>>  How would users be able to tell the difference between R waiting for
>> input, and R busy on the last calculation?
>>
>>
> I don't think that this is about prompts in interactive R, but when a
> document is knit, should the echoed code in the report have prompts or not.
>
>
>
>> Duncan Murdoch
>>
>>
>> > Regards,
>> > Yihui
>> > --
>> > Yihui Xie <xieyihui at gmail.com>
>> > Web: http://yihui.name
>> >
>> >
>> > On Wed, Jul 30, 2014 at 12:50 PM, Greg Snow <538280 at gmail.com> wrote:
>> >> My preference when teaching is to have the code and results look the
>> >> same as it appears in the R console window, so with the prompts and
>> >> without the output commented.  But then I also `purl` my knitr file to
>> >> create a script file to give to the students that they can copy and
>> >> paste from easily.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology
> http://joshuawiley.com/
> Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jul 31 03:15:57 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Jul 2014 21:15:57 -0400
Subject: [R] a knitr question
In-Reply-To: <CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
	<CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
Message-ID: <53D998CD.9020606@gmail.com>

On 30/07/2014, 8:06 PM, Joshua Wiley wrote:
> On Thu, Jul 31, 2014 at 9:47 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 30/07/2014, 2:20 PM, Yihui Xie wrote:
>     > As a reader, I often want to run the code by myself _while_ I'm
>     > reading a particular part of an article/report. I find it convenient
>     > to be able to copy the code as I'm reading it, instead of minimizing
>     > my current window, opening an R script, and running the part that I'm
>     > interested in. Of course, this may not work if the code I copy is not
>     > self-contained; your purl() approach certainly has an advantage
>     > sometimes.
>     >
>     > I do not see a whole lot of value in maintaining the same appearance
>     > of the R code in the R console and a report. You can teach your
>     > students what the prompt characters mean, and I think that is enough.
>     > Journal of Statistical Software requires "R> " as the prompt character
>     > (which is worse), and your students will probably be confused when
>     > reading JSS papers if they have been seeing the default prompts all
>     > the time. I see the point of keeping prompts (i.e. I do not completely
>     > disagree), but I do not think it is an essential or important thing to
>     > do. Personally I prefer reading "vanilla" code, and >/+ may confuse my
>     > eyes occasionally, e.g.
>     >
>     >> z > 5
>     >> x +
>     > + y
>     >
>     > (More on prompts:
>     > http://yihui.name/en/2013/01/code-pollution-with-command-prompts/)
>     >
>     > Re Rich: yes, I'm aware of approaches of post-processing the prompts,
>     > but this problem would not have existed in the first place if we do
>     > not include prompts at all. I'm not sure if it makes much sense to
>     > create some mess and clean it afterwards.
>     >
> 
>     So your suggestion is that the R console should not prompt for input?
>     Do you know of *any* interactive system which doesn't prompt for input?
>      How would users be able to tell the difference between R waiting for
>     input, and R busy on the last calculation?
> 
> 
> I don't think that this is about prompts in interactive R, but when a
> document is knit, should the echoed code in the report have prompts or not.

"this problem would not have existed in the first place if we do
not include prompts at all" seems to indicate otherwise.

Duncan Murdoch

> 
>  
> 
>     Duncan Murdoch
> 
> 
>     > Regards,
>     > Yihui
>     > --
>     > Yihui Xie <xieyihui at gmail.com <mailto:xieyihui at gmail.com>>
>     > Web: http://yihui.name
>     >
>     >
>     > On Wed, Jul 30, 2014 at 12:50 PM, Greg Snow <538280 at gmail.com
>     <mailto:538280 at gmail.com>> wrote:
>     >> My preference when teaching is to have the code and results look the
>     >> same as it appears in the R console window, so with the prompts and
>     >> without the output commented.  But then I also `purl` my knitr
>     file to
>     >> create a script file to give to the students that they can copy and
>     >> paste from easily.
>     >>
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> -- 
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology
> http://joshuawiley.com/
> Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518


From wht_crl at yahoo.com  Thu Jul 31 04:46:33 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 30 Jul 2014 19:46:33 -0700
Subject: [R] separate numbers from chars in a string
In-Reply-To: <603C2D2B-0307-4915-97F3-464793416697@me.com>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<603C2D2B-0307-4915-97F3-464793416697@me.com>
Message-ID: <1406774793.72214.YahooMailNeo@web121506.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140730/0b20626e/attachment.pl>

From xie at yihui.name  Thu Jul 31 05:12:54 2014
From: xie at yihui.name (Yihui Xie)
Date: Wed, 30 Jul 2014 22:12:54 -0500
Subject: [R] a knitr question
In-Reply-To: <53D98427.7060700@gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
Message-ID: <CANROs4c+1P3OzDg8LWxRAreJ6EQEwzbGN45Pb_oBROoWhdif2A@mail.gmail.com>

No. That is not my suggestion. Joshua Wiley correctly explained what I
was suggesting. Prompts are useful in the R console, but not
necessarily in a report.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Jul 30, 2014 at 6:47 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> So your suggestion is that the R console should not prompt for input?
> Do you know of *any* interactive system which doesn't prompt for input?
>  How would users be able to tell the difference between R waiting for
> input, and R busy on the last calculation?
>
> Duncan Murdoch


From kartiksingh.jiit at gmail.com  Thu Jul 31 05:35:51 2014
From: kartiksingh.jiit at gmail.com (Kartik Singh)
Date: Thu, 31 Jul 2014 09:05:51 +0530
Subject: [R] Eager To Learn And Contribute!
Message-ID: <CAFf=nraR402FNRMVQ-Zobo2phWVQLrFpukrR5A0xeGZ7n6RpDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/abaef4a3/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 31 05:49:51 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Jul 2014 20:49:51 -0700
Subject: [R] is.na() == TRUE for POSIXlt time / date of "2014-03-09
	02:00:00"
In-Reply-To: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
References: <CAAJSdjj4keJDWa0WKAeCBqs+2gbvR+eWxKOAe8PbZ_kJMMj6XQ@mail.gmail.com>
Message-ID: <1406778591.52277.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Not able to reproduce the problem.
str(q)
# POSIXlt[1:1], format: "2014-03-09 02:00:00"
?is.na(q)
#[1] FALSE
sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-unknown-linux-gnu (64-bit)
A.K.




On Wednesday, July 30, 2014 1:10 PM, John McKown <john.archie.mckown at gmail.com> wrote:
"I'm so confused!" Why does is.na() report TRUE for a POSIXlt date &
time of 2014-03-09 02:00:00 ?

> q
[1] "2014-03-09 02:00:00"
> is.na(q)
[1] TRUE
> as.POSIXct(q)
[1] NA
> dput(q)
structure(list(sec = 0, min = 0L, hour = 2, mday = 9L, mon = 2L,
? ? year = 114L, wday = 0L, yday = 67L, isdst = 0L, zone = "",
? ? gmtoff = NA_integer_), .Names = c("sec", "min", "hour", "mday",
"mon", "year", "wday", "yday", "isdst", "zone", "gmtoff"), class = c("POSIXlt",
"POSIXt"))
> str(q)
POSIXlt[1:1], format: "2014-03-09 02:00:00"
>


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dulcalma at bigpond.com  Thu Jul 31 06:17:28 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 31 Jul 2014 14:17:28 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD39CFE@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>,
	<000601cfaabd$f568f130$e03ad390$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD39CFE@ebox-prod-srv04.win.su.se>
Message-ID: <001201cfac76$57905970$06b10c50$@bigpond.com>

Hi Anna

I am still unsure what you want

1 do you want 1 panel or 3?
2 do you want 1 y axis on the left and 1 on the right 
or 1 y axis on the left and 2 on the right
                                         or 1 on the right varying with
groups in a multipanel plot

For starters try

xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c("black","black","black"), # for points
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })
 
OR

  xyplot(Value ~ Year|Type, mydata,
        allow.multiple = T,
        aspect = 0.75,
        layout = c(1,3),
        groups = Type,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        scales = list(alternating = F),
        col = c("black","black","black"),
        subscripts = TRUE,
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

have a look at 

 ?lattice::axis.default
for yscale.components

This means that you only need 1 xyplot object

if you use doubleYScale you need to xyplot objects 
1 for the points and another for the averages

These are then superimposed with the doubleYScale

Also read and re read ?xyplot
names(trellis.par.get()) give you a list of the names in trellis.par.get() 
and trellis.par.get() gives you all the settings used by  argument
par.settings in xyplot and those in the lattice series
par.settings may help you with themes.

http://lmdvr.r-forge.r-project.org/figures/figures.html
may be instructive

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Wednesday, 30 July 2014 23:59
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan and many thank's for your help!
I could see your first message perfectly.

You solved my problem to some extent. What my problem is, is that I need a
double y plot with two of these moving averages belonging to one axis (both
are temperature measurements, say Stuff 2 and 3, measured in degrees C) the
other one reading off the second axis (a nutrient measurement in mM (say
Stuff1)).

How can I plot Stuff2 and stuff3 moving averages in one plot and stuff1 in
another and then combine them using doubleYscale?

I also have some other annotated questions regarding linetypes. I could
change symbols using pch, but not the line type. Why? See code below:

Many many thank's once again. 

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}    

mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

xyplot(Value ~ Year, mydata, groups = Type,
       allow.multiple = T,
       distribute.type = TRUE,
       col = c("black","black","black"),
       subscripts = TRUE,
       par.settings = simpleTheme(lty=c(1:3), pch=c(1:3)), #why can I change
symbol (pch), but not line type (lty)?
       panel = panel.superpose,
       panel.groups = function(x, y, subscripts, ...,group.number) {
         panel.xyplot(x, y, ...)
         panel.xyplot(x, mydata[subscripts,"mavg"], col =
                        c("black","black","black")[group.number], type =
"l") # tried to change lty here too lty=c(1:3), but # without success
       })

# how can I add a legend specifying the linetype AS WELL AS symbol?
# I tried using:   text = c("stuff1", "stuff2", "stuff3"), columns = 2  but
could not make it work.




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 29 July 2014 01:45
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

I do not know what happened to my last email as this are set up as plain
text so I am sending the code again so I hope this works

I am not sure what you wanted exactly but this will plot the points and
lines of the average.

I have not worried about the 2nd axis

Here is one way of doing things  by combining the averages into the
dataframe.
It makes it easier that way as you do not have to match up the x values

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
            })

Duncan

BTW libraries are case sensitive as well. Is it you editor putting capitals?

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ? `?.
.? `?. .><((((:>

        [[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Thu Jul 31 06:34:36 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Jul 2014 21:34:36 -0700
Subject: [R] DATA SUMMARIZING and REPORTING
In-Reply-To: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
References: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
Message-ID: <1406781276.65427.YahooMailNeo@web142606.mail.bf1.yahoo.com>

For the example, you gave:

x ##dataset

indx <- t(sapply(min(x$MTH_SUPPORT):(max(x$MTH_SUPPORT) - 2), function(x) c(x, x + 
??? 2)))

res <- do.call(rbind, apply(indx, 1, function(.indx) {
??? x1 <- x[x$MTH_SUPPORT >= .indx[1] & x$MTH_SUPPORT <= .indx[2], ]
??? Period <- paste(.indx[1], .indx[2], sep = "-")
??? No.ofChange <- sum(x1$ATT_1[-1] != x1$ATT_1[-length(x1$ATT_1)])
??? Paid = with(x1, sum(A3)/(sum(A1) + sum(A2)))
??? data.frame(ID_CASE = x$ID_CASE[1L], Period, No.ofChange, Paid, stringsAsFactors = F)
}))


?res
? ID_CASE??????? Period No.ofChange????? Paid
1?? CB26A 201302-201304?????????? 2 0.4143646
2?? CB26A 201303-201305?????????? 2 0.4452450
3?? CB26A 201304-201306?????????? 1 0.4444444
4?? CB26A 201305-201307?????????? 2 0.4607407
5?? CB26A 201306-201308?????????? 1 0.4617737
6?? CB26A 201307-201309?????????? 1 0.4513274
7?? CB26A 201308-201310?????????? 1 0.4613779


With multiple ID_CASE, either split the dataset by ID_CASE or on the grouping functions before applying this.


A.K.




On Wednesday, July 30, 2014 8:48 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
Hi R-helpers,

I have dataframe like

? ID_CASE? ? ? ?  YEAR_MTH? ? ?  ATT_1? ? ? ? ? ?  A1? ? ? ? ? ? ? A2
A3? CB26A 201302 1 146 42 74? CB26A 201302 0 140 50 77? CB26A 201303 0 128
36 77? CB26A 201304 1 146 36 72? CB26A 201305 1 134 36 80? CB26A 201305 0
148 30 80? CB26A 201306 0 134 20 72? CB26A 201307 1 125 48 79? CB26A 201309
0 122 44 74? CB26A 201310 1 126 37 72? CB26A 201310 1 107 43 75
I want a final dataframe which will look like

? ID_CASE Period? No.ofChange? ? ? %Paid? CB26A 201302-2013042? 0.414365
CB26A 201303-201305 2 0.445245? CB26A 201304-201306 1 0.444444? CB26A
201305-201307 2 0.460741? CB26A 201306-201308 1 0.461774? CB26A
201307-201309 1 0.451327? CB26A 201308-201310 1 0.461378
where,
Period = a time period of 3 months which is shifted by 1 month subsequently

No.ofChange = number of time ATT_1 has changed values in this period

%Paid = sum(A3)/(sum(A1)+sum(A2)) for this period
E.g. for Period=201302-201304,
%Paid = (74+77+77+72)/((146+140+128+146)+(42+50+36+36))

Period calculation should start from the first YEAR_MTH for the ID_CASE,
i.e., if for a ID_CASE first YEAR_MTH is 201301 or 201304 then the period
should be defined accordingly.

I have a dataframe with 400 unique ID_CASE, I need to do it for all ID_CASE.

How can I do it in R?

Regards,
Abhinaba

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Jul 31 06:51:52 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Jul 2014 21:51:52 -0700
Subject: [R] DATA SUMMARIZING and REPORTING
In-Reply-To: <1406781276.65427.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CANtKHPWkO=5uvGmrhN1o2QVVqyRH-gDAdU8DKM5QUuVUB6DFUQ@mail.gmail.com>
	<1406781276.65427.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1406782312.83414.YahooMailNeo@web142606.mail.bf1.yahoo.com>



With >1 ID_CASE, you may try:

xN <- x
xN$ID_CASE <- "CB27A" #creating another ID_CASE, other data same
x <- rbind(x, xN)
res1 <- do.call(rbind, lapply(split(x, x$ID_CASE), function(.x) {
??? indx <- with(.x, t(sapply(min(MTH_SUPPORT):(max(MTH_SUPPORT) - 2), function(y) c(y, 
??????? y + 2))))
??? do.call(rbind, apply(indx, 1, function(.indx) {
??????? x1 <- .x[with(.x, MTH_SUPPORT >= .indx[1] & MTH_SUPPORT <= .indx[2]), ]
??????? Period <- paste(.indx[1], .indx[2], sep = "-")
??????? x2 <- within(x1, {
??????????? Paid <- sum(A3)/(sum(A1) + sum(A2))
??????????? No.ofChange <- sum(ATT_1[-1] != ATT_1[-length(ATT_1)])
??????? })
??????? data.frame(ID_CASE = .x$ID_CASE[1L], Period, No.ofChange = x2$No.ofChange[1L], 
??????????? Paid = x2$Paid[1L], stringsAsFactors = F)
??? }))
}))

row.names(res1) <- 1:nrow(res1)
> res1
?? ID_CASE??????? Period No.ofChange????? Paid
1??? CB26A 201302-201304?????????? 2 0.4143646
2??? CB26A 201303-201305?????????? 2 0.4452450
3??? CB26A 201304-201306?????????? 1 0.4444444
4??? CB26A 201305-201307?????????? 2 0.4607407
5??? CB26A 201306-201308?????????? 1 0.4617737
6??? CB26A 201307-201309?????????? 1 0.4513274
7??? CB26A 201308-201310?????????? 1 0.4613779
8??? CB27A 201302-201304?????????? 2 0.4143646
9??? CB27A 201303-201305?????????? 2 0.4452450
10?? CB27A 201304-201306?????????? 1 0.4444444
11?? CB27A 201305-201307?????????? 2 0.4607407
12?? CB27A 201306-201308?????????? 1 0.4617737
13?? CB27A 201307-201309?????????? 1 0.4513274
14?? CB27A 201308-201310?????????? 1 0.4613779
A.K.




On Thursday, July 31, 2014 12:34 AM, arun <smartpink111 at yahoo.com> wrote:
For the example, you gave:

x ##dataset

indx <- t(sapply(min(x$MTH_SUPPORT):(max(x$MTH_SUPPORT) - 2), function(x) c(x, x + 
??? 2)))

res <- do.call(rbind, apply(indx, 1, function(.indx) {
??? x1 <- x[x$MTH_SUPPORT >= .indx[1] & x$MTH_SUPPORT <= .indx[2], ]
??? Period <- paste(.indx[1], .indx[2], sep = "-")
??? No.ofChange <- sum(x1$ATT_1[-1] != x1$ATT_1[-length(x1$ATT_1)])
??? Paid = with(x1, sum(A3)/(sum(A1) + sum(A2)))
??? data.frame(ID_CASE = x$ID_CASE[1L], Period, No.ofChange, Paid, stringsAsFactors = F)
}))


?res
? ID_CASE??????? Period No.ofChange????? Paid
1?? CB26A 201302-201304?????????? 2 0.4143646
2?? CB26A 201303-201305?????????? 2 0.4452450
3?? CB26A 201304-201306?????????? 1 0.4444444
4?? CB26A 201305-201307?????????? 2 0.4607407
5?? CB26A 201306-201308?????????? 1 0.4617737
6?? CB26A 201307-201309?????????? 1 0.4513274
7?? CB26A 201308-201310?????????? 1 0.4613779


With multiple ID_CASE, either split the dataset by ID_CASE or on the grouping functions before applying this.


A.K.







On Wednesday, July 30, 2014 8:48 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
Hi R-helpers,

I have dataframe like

? ID_CASE? ? ? ?? YEAR_MTH? ? ?? ATT_1? ? ? ? ? ?? A1? ? ? ? ? ? ? A2
A3? CB26A 201302 1 146 42 74? CB26A 201302 0 140 50 77? CB26A 201303 0 128
36 77? CB26A 201304 1 146 36 72? CB26A 201305 1 134 36 80? CB26A 201305 0
148 30 80? CB26A 201306 0 134 20 72? CB26A 201307 1 125 48 79? CB26A 201309
0 122 44 74? CB26A 201310 1 126 37 72? CB26A 201310 1 107 43 75
I want a final dataframe which will look like

? ID_CASE Period? No.ofChange? ? ? %Paid? CB26A 201302-2013042? 0.414365
CB26A 201303-201305 2 0.445245? CB26A 201304-201306 1 0.444444? CB26A
201305-201307 2 0.460741? CB26A 201306-201308 1 0.461774? CB26A
201307-201309 1 0.451327? CB26A 201308-201310 1 0.461378
where,
Period = a time period of 3 months which is shifted by 1 month subsequently

No.ofChange = number of time ATT_1 has changed values in this period

%Paid = sum(A3)/(sum(A1)+sum(A2)) for this period
E.g. for Period=201302-201304,
%Paid = (74+77+77+72)/((146+140+128+146)+(42+50+36+36))

Period calculation should start from the first YEAR_MTH for the ID_CASE,
i.e., if for a ID_CASE first YEAR_MTH is 201301 or 201304 then the period
should be defined accordingly.

I have a dataframe with 400 unique ID_CASE, I need to do it for all ID_CASE.

How can I do it in R?

Regards,
Abhinaba

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jul 31 07:19:44 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Jul 2014 22:19:44 -0700
Subject: [R] Question
In-Reply-To: <1406742161.21735.YahooMailNeo@web141703.mail.bf1.yahoo.com>
References: <1406742161.21735.YahooMailNeo@web141703.mail.bf1.yahoo.com>
Message-ID: <1406783984.91904.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Farnoosh,

Regarding the first question:

dat2 <- dat1
dat1$Mean <- setNames(unsplit(sapply(split(dat1[,-1], dat1[,1]),rowMeans, na.rm=T),dat1[,1]),NULL)
dat1
? Unit q1 q2 q3???? Mean
1??? A? 3? 1? 2 2.000000
2??? A? 2 NA? 1 1.500000
3??? B? 2? 2? 4 2.666667
4??? B NA? 2? 5 3.500000
5??? C? 3? 2 NA 2.500000
6??? C? 4? 1? 4 3.000000
7??? A? 3? 2 NA 2.500000


second question, is not clear.? Assuming that you want something like this:
?dat2[,-1] <- (!is.na(dat2[,-1]))+0
?dat2$indx <- with(dat2, ave(rep(1, nrow(dat2)), Unit, FUN=cumsum))
?library(reshape2)
dcast(melt(dat2, id.var=c("indx","Unit")), variable+indx~Unit, value.var="value", fill=0)[,-2]
? variable A B C
1?????? q1 1 1 1
2?????? q1 1 0 1
3?????? q1 1 0 0
4?????? q2 1 1 1
5?????? q2 0 1 1
6?????? q2 1 0 0
7?????? q3 1 1 0
8?????? q3 1 1 1
9?????? q3 0 0 0



A.K.



On Wednesday, July 30, 2014 1:42 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:



Hi Arun,


I have two questions, I have a data like below:

dat1<-read.table(text="
Unit ?q1q2q3
A312
A2NA1
B224
BNA25
C32NA
C414
A32NA
",sep="",header=T,stringsAsFactors=F)

I want to get the average of each row by the number of answered questions. For example second row would be (2+1)/2 since there is a NA.

Secondly, I want to pivot the units like:?UnitA, UnitB, Unit C ?as columns and have 1 and zero as values.

Thanks a lot for your help.


From smartpink111 at yahoo.com  Thu Jul 31 08:54:51 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Jul 2014 23:54:51 -0700
Subject: [R] separate numbers from chars in a string
Message-ID: <1406789691.75320.YahooMailNeo@web142602.mail.bf1.yahoo.com>

If you have some variations of the order of numbers followed by chars,

library(stringr)

v1 <- c("absdfds0213451ab", "123abcs4145")
pattern=c("[A-Za-z]+", "\\d+")

do.call(`Map`,c(c,lapply(pattern, function(.pat) str_extract_all(v1, .pat))))
#[[1]]
#[1] "absdfds" "ab"????? "0213451"

#[[2]]
#[1] "abcs" "123"? "4145"
A.K.



Hi,
If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?

grep doesn't seem to be helpful

grep("[a-z]","absdfds0213451ab", ignore.case=T)
[1] 1


?grep("[0-9]","absdfds0213451ab", ignore.case=T)
[1] 1

Thanks

Carol 



From ligges at statistik.tu-dortmund.de  Thu Jul 31 10:17:37 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 31 Jul 2014 10:17:37 +0200
Subject: [R] separate numbers from chars in a string
In-Reply-To: <1406774793.72214.YahooMailNeo@web121506.mail.ne1.yahoo.com>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>	<603C2D2B-0307-4915-97F3-464793416697@me.com>
	<1406774793.72214.YahooMailNeo@web121506.mail.ne1.yahoo.com>
Message-ID: <53D9FBA1.4040007@statistik.tu-dortmund.de>



On 31.07.2014 04:46, carol white wrote:
> There are some level of variation either chars followed by numbers or chars, numbers, chars
>
>
> Perhaps, I should use gsub as you suggested all and if the string is composed of chars followed by numbers, it will return the 3rd part empty?


Please read about regularvexpressions and describe your problem 
accurately. If the last strings are onot always present, use * rather 
than + at the very end of the regular expression.

Best,
Uwe Ligges


> Regards,
>
> Carol
>
>
> On Wednesday, July 30, 2014 10:52 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>
>
> On Jul 30, 2014, at 3:13 PM, carol white <wht_crl at yahoo.com> wrote:
>
>> Hi,
>> If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?
>>
>> grep doesn't seem to be helpful
>>
>> grep("[a-z]","absdfds0213451ab", ignore.case=T)
>> [1] 1
>>
>>
>>    grep("[0-9]","absdfds0213451ab", ignore.case=T)
>> [1] 1
>>
>> Thanks
>>
>> Carol
>
>
> grep() will only tell you that a pattern is present. You want to use gsub() or similar with back references to return parts of the vector.
>
> Will they ALWAYS appear in that pattern (letters, numbers, letters) or is there some level of variation?
>
> If they will always appear as in your example, then one approach is:
>
>> strsplit(gsub("([a-z]+)([0-9]+)([a-z]+)", "\\1 \\2 \\3", "absdfds0213451ab"), " ")
>
> [[1]]
> [1] "absdfds" "0213451" "ab"
>
>
> The initial gsub() returns the 3 parts separated by a space, which is then used as the split argument to strsplit().
>
> If there will be some variation, you can use multiple calls to gsub() or similar, each getting either the letters or the numbers.
>
> Regards,
>
> Marc Schwartz
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Thu Jul 31 10:28:25 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 31 Jul 2014 20:28:25 +1200
Subject: [R] a knitr question
In-Reply-To: <CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>	<53D98427.7060700@gmail.com>
	<CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
Message-ID: <53D9FE29.2050905@auckland.ac.nz>

On 31/07/14 12:06, Joshua Wiley wrote:

<SNIP>

> I don't think that this is about prompts in interactive R, but when a
> document is knit, should the echoed code in the report have prompts or not.

Surely that should be left up to the user.  And as Erin pointed out in 
her second message, it is.  The default is no prompt --- which seems to 
be the style desired by you and Yihui --- but setting prompt=TRUE inside 
the << >> gives prompts for those who want them in their documents.

Since the default is "no prompt", the only meaningful interpretation of 
Yihui's post was the way that Duncan interpreted it.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From Graham.Williams at togaware.com  Thu Jul 31 12:43:08 2014
From: Graham.Williams at togaware.com (Graham Williams)
Date: Thu, 31 Jul 2014 20:43:08 +1000
Subject: [R] fancyRpartPlot and the title at the bottom of the plot....
In-Reply-To: <37273DBD29A7A2408A7736A073A9FA3B8B39A258@mb05.porsuk.anadolu.edu.tr>
References: <37273DBD29A7A2408A7736A073A9FA3B8B39A258@mb05.porsuk.anadolu.edu.tr>
Message-ID: <CAMqPDFH2nNThOgZ_4OYFQj3NDDuv5h0CUGqGjLJ5fwxmwakeQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/86668d38/attachment.pl>

From istazahn at gmail.com  Thu Jul 31 13:02:35 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 31 Jul 2014 07:02:35 -0400
Subject: [R] a knitr question
In-Reply-To: <53D9FE29.2050905@auckland.ac.nz>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
	<CANz9Z_KE9OLPb2y3ybM4Paz8D-UTX3zKWB1tzBfkYik+nK0wWQ@mail.gmail.com>
	<53D9FE29.2050905@auckland.ac.nz>
Message-ID: <CA+vqiLEUjsLgf7FYm7_B+ac7Y-MZov5jhNjpKMj0AAFQv4CLgA@mail.gmail.com>

On Thu, Jul 31, 2014 at 4:28 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 31/07/14 12:06, Joshua Wiley wrote:
>
> <SNIP>
>
>
>> I don't think that this is about prompts in interactive R, but when a
>> document is knit, should the echoed code in the report have prompts or
>> not.
>
>
> Surely that should be left up to the user.  And as Erin pointed out in her
> second message, it is.  The default is no prompt --- which seems to be the
> style desired by you and Yihui --- but setting prompt=TRUE inside the << >>
> gives prompts for those who want them in their documents.
>
> Since the default is "no prompt", the only meaningful interpretation of
> Yihui's post was the way that Duncan interpreted it.

I have no idea why we are parsing Yihui's sentence so carefully and
critically. Yes, in isolation it is ambiguous, but in the context of
the thread it is perfectly clear. The whole conversation is whether it
is a good idea for the user to set <<prompt=TRUE>>.

Best,
Ista

>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jul 31 13:34:02 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 31 Jul 2014 07:34:02 -0400
Subject: [R] a knitr question
In-Reply-To: <CANROs4c+1P3OzDg8LWxRAreJ6EQEwzbGN45Pb_oBROoWhdif2A@mail.gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
	<CANROs4c+1P3OzDg8LWxRAreJ6EQEwzbGN45Pb_oBROoWhdif2A@mail.gmail.com>
Message-ID: <53DA29AA.4070605@gmail.com>

On 30/07/2014, 11:12 PM, Yihui Xie wrote:
> No. That is not my suggestion. Joshua Wiley correctly explained what I
> was suggesting. Prompts are useful in the R console, but not
> necessarily in a report.

Okay, then we agree.  For Erin's purpose (teaching), it is helpful to
beginners if the document looks the same as what they see in the
console.  More sophisticated users don't need the prompts.

Duncan Murdoch

> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> 
> 
> On Wed, Jul 30, 2014 at 6:47 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> So your suggestion is that the R console should not prompt for input?
>> Do you know of *any* interactive system which doesn't prompt for input?
>>  How would users be able to tell the difference between R waiting for
>> input, and R busy on the last calculation?
>>
>> Duncan Murdoch


From john.archie.mckown at gmail.com  Thu Jul 31 13:49:22 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 31 Jul 2014 06:49:22 -0500
Subject: [R] Need(?) way to create a "picture" (or "plot") of a data.frame
Message-ID: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>

OK, I'm probably using the wrong tool for this, but I'm doing
everything else in this project in R, so I'm looking at how to do this
too. I create a number of graphs using ggplot2. I use the png()
function before the print(..graph.variable..) in order to create a PNG
file which can be embedded in a MS PowerPoint display. This is working
fairly well.

But what I need now is a way to create a png file which is basically a
"picture" of what you might see when you simply display a data.frame
using Rstudio or even from the command prompt. I considered just using
sink() and print(), but I have two problems. First, it doesn't create
a PNG output. Second, I need to put in text annotations, title, etc.
So what I need might be what a "geom_data.table" would produce, if
such a thing existed in ggplot2.

Is there another "plotting" package which will do such a weird thing?

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From murdoch.duncan at gmail.com  Thu Jul 31 14:06:40 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 31 Jul 2014 08:06:40 -0400
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
Message-ID: <53DA3150.1070809@gmail.com>

On 31/07/2014, 7:49 AM, John McKown wrote:
> OK, I'm probably using the wrong tool for this, but I'm doing
> everything else in this project in R, so I'm looking at how to do this
> too. I create a number of graphs using ggplot2. I use the png()
> function before the print(..graph.variable..) in order to create a PNG
> file which can be embedded in a MS PowerPoint display. This is working
> fairly well.
> 
> But what I need now is a way to create a png file which is basically a
> "picture" of what you might see when you simply display a data.frame
> using Rstudio or even from the command prompt. I considered just using
> sink() and print(), but I have two problems. First, it doesn't create
> a PNG output. Second, I need to put in text annotations, title, etc.
> So what I need might be what a "geom_data.table" would produce, if
> such a thing existed in ggplot2.
> 
> Is there another "plotting" package which will do such a weird thing?
> 

One way is to use your OS to do a screen (or window) capture, and save
the result to a .png file.

There are also functions like textbox() in the plotrix package which
allow you to display multiple lines of text; use capture.output() to
save what was printed, then textbox() to add it to a plot.

Duncan Murdoch


From jim at bitwrit.com.au  Thu Jul 31 14:17:47 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 31 Jul 2014 22:17:47 +1000
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
Message-ID: <4303476.2ZHkRxsK7X@localhost.localdomain>

On Thu, 31 Jul 2014 06:49:22 AM John McKown wrote:
> OK, I'm probably using the wrong tool for this, but I'm doing
> everything else in this project in R, so I'm looking at how to do this
> too. I create a number of graphs using ggplot2. I use the png()
> function before the print(..graph.variable..) in order to create a PNG
> file which can be embedded in a MS PowerPoint display. This is working
> fairly well.
> 
> But what I need now is a way to create a png file which is basically a
> "picture" of what you might see when you simply display a data.frame
> using Rstudio or even from the command prompt. I considered just 
using
> sink() and print(), but I have two problems. First, it doesn't create
> a PNG output. Second, I need to put in text annotations, title, etc.
> So what I need might be what a "geom_data.table" would produce, if
> such a thing existed in ggplot2.
> 
> Is there another "plotting" package which will do such a weird thing?

Hi John,
Maybe the addtable2plot function (plotrix) with an empty plot.

Jim


From murdoch.duncan at gmail.com  Thu Jul 31 14:18:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 31 Jul 2014 08:18:00 -0400
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <53DA3150.1070809@gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
	<53DA3150.1070809@gmail.com>
Message-ID: <53DA33F8.8030600@gmail.com>

On 31/07/2014, 8:06 AM, Duncan Murdoch wrote:
> On 31/07/2014, 7:49 AM, John McKown wrote:
>> OK, I'm probably using the wrong tool for this, but I'm doing
>> everything else in this project in R, so I'm looking at how to do this
>> too. I create a number of graphs using ggplot2. I use the png()
>> function before the print(..graph.variable..) in order to create a PNG
>> file which can be embedded in a MS PowerPoint display. This is working
>> fairly well.
>>
>> But what I need now is a way to create a png file which is basically a
>> "picture" of what you might see when you simply display a data.frame
>> using Rstudio or even from the command prompt. I considered just using
>> sink() and print(), but I have two problems. First, it doesn't create
>> a PNG output. Second, I need to put in text annotations, title, etc.
>> So what I need might be what a "geom_data.table" would produce, if
>> such a thing existed in ggplot2.
>>
>> Is there another "plotting" package which will do such a weird thing?
>>
> 
> One way is to use your OS to do a screen (or window) capture, and save
> the result to a .png file.
> 
> There are also functions like textbox() in the plotrix package which
> allow you to display multiple lines of text; use capture.output() to
> save what was printed, then textbox() to add it to a plot.

A few more details:  textbox normally wraps text, so use

lines <- paste(capture.output( ... ), "\n")

to get line breaks; you may want to set options("width") first; you may
want par(family="mono") first if you need character alignment.

Duncan Murdoch


From marc_schwartz at me.com  Thu Jul 31 14:40:56 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 31 Jul 2014 07:40:56 -0500
Subject: [R] separate numbers from chars in a string
In-Reply-To: <53D9FBA1.4040007@statistik.tu-dortmund.de>
References: <1406751232.74228.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<603C2D2B-0307-4915-97F3-464793416697@me.com>
	<1406774793.72214.YahooMailNeo@web121506.mail.ne1.yahoo.com>
	<53D9FBA1.4040007@statistik.tu-dortmund.de>
Message-ID: <52F36786-208B-4A8F-8A57-64F124EE7CAB@me.com>


On Jul 31, 2014, at 3:17 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 31.07.2014 04:46, carol white wrote:
>> There are some level of variation either chars followed by numbers or chars, numbers, chars
>> 
>> 
>> Perhaps, I should use gsub as you suggested all and if the string is composed of chars followed by numbers, it will return the 3rd part empty?
> 
> 
> Please read about regularvexpressions and describe your problem accurately. If the last strings are onot always present, use * rather than + at the very end of the regular expression.
> 
> Best,
> Uwe Ligges


Carol,

As Uwe notes, reviewing the documentation for ?regex and the examples in ?gsub can be helpful. There are also online regex resources such as:

  http://www.regular-expressions.info

The question is how much variation might be present. If it will always be up to 3 possible components, then as Uwe indicated, using the '*' instead of '+' will allow for the possibility that one or more patterns will not be present. '*' means that 0 or more of the patterns must be present, whereas '+' requires that at least one or more matches are present.

> strsplit(gsub("([a-z]*)([0-9]*)([a-z]*)", "\\1 \\2 \\3", "absdfds0213451ab"), " ")
[[1]]
[1] "absdfds" "0213451" "ab"   

> strsplit(gsub("([a-z]*)([0-9]*)([a-z]*)", "\\1 \\2 \\3", "absdfds0213451"), " ")
[[1]]
[1] "absdfds" "0213451"

> strsplit(gsub("([a-z]*)([0-9]*)([a-z]*)", "\\1 \\2 \\3", "0213451ab"), " ")
[[1]]
[1] ""        "0213451" "ab"  


Using the 3 back references in the regex above will limit the parsing to up to 3 possible components. If you may have more than 3 you can increase the back reference sequence to some maximum number. However that can get tedious, so you may want to consider multiple passes using strsplit() to extract letters during one pass and then numbers during a second, or write a function to encapsulate that process.

Here are examples using strsplit():

# Get the numbers, using letters as the split
> strsplit("absdfds0213451ab", split = "[a-z]+")
[[1]]
[1] ""        "0213451"

> strsplit("absdfds0213451ab4567", split = "[a-z]+")
[[1]]
[1] ""        "0213451" "4567"   


# Get the letters, using numbers as the split
> strsplit("absdfds0213451ab", split = "[0-9]+")
[[1]]
[1] "absdfds" "ab"     

> strsplit("0213451ab", split = "[0-9]+")
[[1]]
[1] ""   "ab"

> strsplit("0213451ab123xyz789lmn", split = "[0-9]+")
[[1]]
[1] ""    "ab"  "xyz" "lmn"


Regards,

Marc


> 
> 
>> Regards,
>> 
>> Carol
>> 
>> 
>> On Wednesday, July 30, 2014 10:52 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>> 
>> 
>> On Jul 30, 2014, at 3:13 PM, carol white <wht_crl at yahoo.com> wrote:
>> 
>>> Hi,
>>> If I have a string of consecutive chars followed by consecutive numbers and then chars, like "absdfds0213451ab", how to separate the consecutive chars from consecutive numbers?
>>> 
>>> grep doesn't seem to be helpful
>>> 
>>> grep("[a-z]","absdfds0213451ab", ignore.case=T)
>>> [1] 1
>>> 
>>> 
>>>   grep("[0-9]","absdfds0213451ab", ignore.case=T)
>>> [1] 1
>>> 
>>> Thanks
>>> 
>>> Carol
>> 
>> 
>> grep() will only tell you that a pattern is present. You want to use gsub() or similar with back references to return parts of the vector.
>> 
>> Will they ALWAYS appear in that pattern (letters, numbers, letters) or is there some level of variation?
>> 
>> If they will always appear as in your example, then one approach is:
>> 
>>> strsplit(gsub("([a-z]+)([0-9]+)([a-z]+)", "\\1 \\2 \\3", "absdfds0213451ab"), " ")
>> 
>> [[1]]
>> [1] "absdfds" "0213451" "ab"
>> 
>> 
>> The initial gsub() returns the 3 parts separated by a space, which is then used as the split argument to strsplit().
>> 
>> If there will be some variation, you can use multiple calls to gsub() or similar, each getting either the letters or the numbers.
>> 
>> Regards,
>> 
>> Marc Schwartz


From kw1958 at gmail.com  Thu Jul 31 14:46:26 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Thu, 31 Jul 2014 08:46:26 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <CA+vqiLFqYCJus7oFEc-MEaTkTJ2a1j0jOtjKm9hdNUF+0bORxQ@mail.gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
	<0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
	<e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>
	<CA+vqiLFqYCJus7oFEc-MEaTkTJ2a1j0jOtjKm9hdNUF+0bORxQ@mail.gmail.com>
Message-ID: <4359813F-8DA1-4DBC-A45D-4104D226CB3C@gmail.com>

Ista Et Al,
Unfortunately your suggestion to use remove.packages did exactly the reverse of what you thought would happen.

I have cleaned up my installation but still have trouble getting rJava to install properly and of course that means that XLConnect cannot install either.

-------------------------------------
I think this shows that the java-7-openjdk is working.
-------------------------------------
/home/refserv $ sudo R CMD javareconf
Java interpreter : /usr/bin/java
Java version     : 1.7.0_55
Java home path   : /usr/lib/jvm/java-7-openjdk-i386/jre
Java compiler    : /usr/bin/javac
Java headers gen.: /usr/bin/javah
Java archive tool: /usr/bin/jar

trying to compile and link a JNI progam 
detected JNI cpp flags    : -I$(JAVA_HOME)/../include
detected JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/lib/jvm/java-7-openjdk-i386/jre/../include     -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c conftest.c -o conftest.o
gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o conftest.so conftest.o -L/usr/lib/jvm/java-7-openjdk-i386/jre/lib/i386/client -ljvm -L/usr/lib/R/lib -lR


JAVA_HOME        : /usr/lib/jvm/java-7-openjdk-i386/jre
Java library path: $(JAVA_HOME)/lib/i386/client
JNI cpp flags    : -I$(JAVA_HOME)/../include
JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
Updating Java configuration in /usr/lib/R
Done.
___________________________________


-------------------------------------
Purge and re-install rjava
-------------------------------------
/home/refserv $ sudo apt-get --purge remove r-cran-rjava
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following packages will be REMOVED:
  r-cran-rjava*
0 upgraded, 0 newly installed, 1 to remove and 3 not upgraded.
After this operation, 1,651 kB disk space will be freed.
Do you want to continue [Y/n]? y
(Reading database ... 173764 files and directories currently installed.)
Removing r-cran-rjava ...

/home/refserv $ sudo apt-get install r-cran-rjava       
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following NEW packages will be installed:
  r-cran-rjava
0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.
Need to get 0 B/557 kB of archives.
After this operation, 1,651 kB of additional disk space will be used.
Selecting previously unselected package r-cran-rjava.
(Reading database ... 173625 files and directories currently installed.)
Unpacking r-cran-rjava (from .../r-cran-rjava_0.9-3-1_i386.deb) ...
Setting up r-cran-rjava (0.9-3-1) ...
-------------------------------------
-------------------------------------



-------------------------------------
Here I try to install rJava in R 
but it looks like there is a version problem.

Given I am using openjdk above I am not sure why R is looking at the oracle Java
-------------------------------------

home/refserv $ R

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)

........................................ (just cutting down on the output)

> require(rJava)
Loading required package: rJava
Failed with error:  ?package ?rJava? was built before R 3.0.0: please re-install it?
> install.packages("rJava")
Installing package into ?/home/refserv/R/i686-pc-linux-gnu-library/3.1?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.mirrors.hoobly.com/src/contrib/rJava_0.9-6.tar.gz'
Content type 'application/x-gzip' length 567515 bytes (554 Kb)
opened URL
==================================================
downloaded 554 Kb


........................................ (just cutting down on the output)


checking Java support in R... present:
interpreter : '/usr/lib/jvm/java-7-oracle/jre/bin/java'
archiver    : '/usr/lib/jvm/java-7-oracle/bin/jar'
compiler    : '/usr/lib/jvm/java-7-oracle/bin/javac'
header prep.: '/usr/lib/jvm/java-7-oracle/bin/javah'
cpp flags   : '-I/usr/lib/jvm/java-7-oracle/include -I/usr/lib/jvm/java-7-oracle/include/linux'
java libs   : '-L/usr/lib/jvm/java-7-oracle/jre/lib/i386/client -ljvm'
checking whether Java run-time works... ./configure: line 3729: /usr/lib/jvm/java-7-oracle/jre/bin/java: No such file or directory
no
configure: error: Java interpreter '/usr/lib/jvm/java-7-oracle/jre/bin/java' does not work
ERROR: configuration failed for package ?rJava?
* removing ?/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava?

The downloaded source packages are in
	?/tmp/RtmpwvY4Md/downloaded_packages?
Warning message:
In install.packages("rJava") :
  installation of package ?rJava? had non-zero exit status

-------------------------------------
-------------------------------------

Thanks again for your time,
Best,
KW


--

On Jul 29, 2014, at 2:22 PM, Ista Zahn <istazahn at gmail.com> wrote:

> On Tue, Jul 29, 2014 at 12:54 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Sounds to me like a problem outside of R (off topic here).
> 
> Possibly, but I suspect that the OP now has two versions of XLConnect
> installed, one in the user R library and one in the system-wide R
> library.
> 
> Keith, try
> 
> remove.packages("XLConnect")
> remove.packages("rJava")
> 
> WITHOUT sudo. Then restart R; you should now get the (working)
> system-wide versions of rJava and XLConnect.
> 
> HTH,
> Ista
> 
> In particular, it doesn't sound like you are using the appropriate
> tools (apt-get package manager for R and a JDK; R install.package()
> for your R packages) to admin your machine. The only thing you should
> need sudo for is to run apt-get... everything else should be done as a
> normal user unless you really know what you are doing. I had no
> problem installing it just now on my Ubuntu machine with OpenJDK. I
> have no experience with Mint but Google tells me you should be able to
> use the instructions for Ubuntu... I would expect Google to tell you
> the same thing if you ask nicely... your most challenging task at this
> point should be cleaning up the mess you have made by excessive use of
> sudo ... most likely running R with it (only update your personal R
> library directories so you are not tempted to go rogue) but you don't
> say how you installed the jdk so that could also be messed up.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On July 29, 2014 8:19:33 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>>> John Et Al.
>>> 
>>> I can get rJava and XLConnect to work only if I run as super user.
>>> 
>>> Note that I have built rJava and XLConnect as super user (otherwise
>>> neither package works).
>>> 
>>> 
>>> ____________________________________________
>>> Without sudo
>>> 
>>>> require(XLConnect)
>>> Loading required package: XLConnect
>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>> error: unable to load shared object
>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>> libjvm.so: cannot open shared object file: No such file or directory
>>> _____________________________________________
>>> With sudo
>>> 
>>>> require(XLConnect)
>>> Loading required package: XLConnect
>>> XLConnect 0.2-7 by Mirai Solutions GmbH
>>> http://www.mirai-solutions.com ,
>>> http://miraisolutions.wordpress.com
>>> 
>>> ______________________________________________
>>> Note that I have changed the ownership (recursively) for rJava and
>>> XLConnect because they were previously owned by root. Also note that
>>> ggplot2 (included for comparison) was installed the usual way with no
>>> problem.
>>> 
>>> drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
>>> drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
>>> drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/
>>> 
>>> ________________________________________________
>>> 
>>> Despite "no such file or directory" above:
>>> 
>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr
>>> /home/refserv/>
>>> -rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28
>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so
>>> 
>>> The file rJava.so exists.
>>> 
>>> Thanks so much for your time and help,
>>> Best,
>>> KW
>>> 
>>> --
>>> 
>>> On Jul 24, 2014, at 11:16 PM, John McKown
>>> <john.archie.mckown at gmail.com> wrote:
>>> 
>>>> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com>
>>> wrote:
>>>>> Folks,
>>>>> 
>>>>> I have been trying to get XLConnect to work on my Linux Mint Maya
>>> machine.
>>>>> 
>>>>> R works fine but this package doesn't seem to want to build. Here is
>>> the message I get after supposedly building XLConnect and rJava:
>>>>> 
>>>>> 
>>>>>>> require(XLConnect)
>>>>>> Loading required package: XLConnect
>>>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>>>> error: unable to load shared object
>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>>>> libjvm.so: cannot open shared object file: No such file or
>>> directory
>>>>> 
>>>>> 
>>>>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>>>>> 
>>>>> The build and the compile seemed to work ok as there were no errors.
>>> For example I can generate ggplot2 graphs.
>>>>> 
>>>>> I know this is probably the wrong forum but if someone could gently
>>> point me in the right direction I would be very appreciative.
>>>>> 
>>>>> Thanks so much for your time,
>>>>> KW
>>>> 
>>>> It works fine for me on Fedora 20 (and 19 before it). When I
>>> installed
>>>> R, it installed into /usr/lib64/R. There exists a file:
>>>> /usr/lib64/R/etc/ldpaths which is executed by the R executable
>>> script.
>>>> This sets up the LD_LIBRARY_PATH to point to the Java installation on
>>>> my machine. In the /usr/lib64/R/bin directory, there is a program
>>>> called "javareconf". I would suggest that you run this with the -n
>>>> switch, like:
>>>> 
>>>> R CMD /usr/lib64/R/bin/javareconf -n
>>>> 
>>>> This will show you what it _would_ do if you left off the "-n". Make
>>>> sure it looks reasonable. If it does, then run the same command,
>>>> without the "-n", as the "root" superuser. In my case, that would be:
>>>> 
>>>> sudo R CMD /usr/lib64/R/bin/javareconf
>>>> 
>>>> You need to be "root" because it update the file
>>>> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
>>>> problem.
>>>> 
>>>> ===
>>>> 
>>>> As a possible alternative to XLConnect, have you looked at openxlsx?
>>>> It appears to have the same abilities, just some different syntax. It
>>>> says that it is written in C and so should be faster than XLConnect.
>>> I
>>>> have tested both packages, a little, and they both seem to work well.
>>>> 
>>>> Well, it's 22:14 hours here and I wish that I could fall asleep.
>>> We're
>>>> having problems at work and I know that the "big boss" will blame us
>>>> peons if the hardware isn't fixed promptly Despite the fact that we
>>>> are only software people and aren't allowed to touch the hardware.
>>> Our
>>>> management's minds are not using the same logic as mine does.
>>>> Frustrating.
>>>> 
>>>> --
>>>> There is nothing more pleasant than traveling and meeting new people!
>>>> Genghis Khan
>>>> 
>>>> Maranatha! <><
>>>> John McKown
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Thu Jul 31 14:52:53 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 31 Jul 2014 07:52:53 -0500
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <CAOy2GxM_uk2Nf2wy6vF47ZZEAkLVr-gau5xwScUUGNF7b=s5cg@mail.gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
	<53DA3150.1070809@gmail.com> <53DA33F8.8030600@gmail.com>
	<CAOy2GxM_uk2Nf2wy6vF47ZZEAkLVr-gau5xwScUUGNF7b=s5cg@mail.gmail.com>
Message-ID: <CAAJSdjg8MBc76P_BZTWvEfMrKxE7WOjZAOunh88EL8wdpX1bgA@mail.gmail.com>

On Thu, Jul 31, 2014 at 7:34 AM, Jody White <jody at jody-white.com> wrote:
> What about xtable? If it's going to PowerPoint and you're using RStudio,
> what about using knitr and exporting to PowerPoint and use xtable?
>

I'll need to look at those. I'm new to R and am not familiar with
either of those two packages.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From deter088 at umn.edu  Thu Jul 31 15:45:27 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 31 Jul 2014 08:45:27 -0500
Subject: [R] simulation dichotomous data
In-Reply-To: <CABLo8nGjg6kY34-Ym6QAR=D-nbUxz9EdMCe1vTFvPye2CaAzpQ@mail.gmail.com>
References: <CABLo8nGjg6kY34-Ym6QAR=D-nbUxz9EdMCe1vTFvPye2CaAzpQ@mail.gmail.com>
Message-ID: <CAOLJphn4gxmW7_30tUK7BpM_fKQ15eLE7-SuZyOn_QZUURMGiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/dddb06da/attachment.pl>

From arnaud.gaboury at gmail.com  Thu Jul 31 10:27:08 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 31 Jul 2014 10:27:08 +0200
Subject: [R] Regex - subsetting parts of a file name.
Message-ID: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>

A directory is full of data.frames cache files. All these files have
the same pattern:

df.some_name.RData

my.cache.list <- c("df.subject_test.RData", "df.subject_train.RData",
"df.y_test.RData",
"df.y_train.RData")

I want to keep only the part inside the two points. After lots of
headache using grep() when trying something like this:

grep('.(.*?).','df.subject_test.RData',value=T)

 I couldn't find a clean one liner and found this workaround:

my.cache.list <- gsub('df.','',my.cache.list)
my.cache.list <- gsub('.RData','',my.cache.list)

The two above commands do the trick, but a clean one line with some
regex expression would be a more "elegant" way.

Does anyone have any suggestion ?

TY for help


From florian.denzinger at uzh.ch  Thu Jul 31 16:37:28 2014
From: florian.denzinger at uzh.ch (fd)
Date: Thu, 31 Jul 2014 07:37:28 -0700 (PDT)
Subject: [R] Multiple plots and postscripts using split function
Message-ID: <1406817448605-4694850.post@n4.nabble.com>

Hi,

I'm relatively new to R and I would like to do the following:

I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and would like
to do several xy plots with the year on the x-axis and the data values
(measurements) on the y-axis and after that export the different plots to
postcript. 

My .csv file looks something like this (only an example):

NAME				ID		YEAR	VALUE
ADAMS				885		1988		-2
ADAMS				885		1989		0
BAHIA DEL DIABLO		2665		1999		4
BAHIA DEL DIABLO		2665		2000		8
BAHIA DEL DIABLO		2665		2001		19
BAHIA DEL DIABLO		2665		2002		13
BAHIA DEL DIABLO		2665		2003		13
BARTLEY				893		1983		0
BARTLEY				893		1984		-1
BARTLEY				893		1985		0
BARTLEY				893		1988		2
BARTLEY				893		1989		-1
CANADA				877		1972		-1

I have split the different items into groups and I'd like the plots to have
the title of NAME but the filename of the postscript to be exported should
have the ID as filename.

My code so far:

#Set Working Directory:
setwd("/Users/Desktop/FV")
# Read CSV
dat <- read.csv("FV.csv", sep=";", header=TRUE)
# Split Data
ind <- split(x = dat,f = dat[,'ID'])
nam <- names(ind)

sapply(nam, function(x) {
	postscript(x)
	par(mar=c(6,8,6,5), cex=0.8) ????
???	plot(ind[[x]][,c('YEAR','VALUE')], 
	type='b', 
	main = x, 
	xlab="Time [Years]", 
	ylab="Front variation") ?????
	axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-0.3)
???	axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
tcl=-0.3) 
???
	dev.off() 
})

This results in plots with the title and filename of the resulting
postscript being the same. Is there a way to get the plot title out of the
NAME column and the filename out of the ID?

Additionally I'd only like to plot graphs for items with more than 3 data
values. Is this possible to incorporate in the split command?

Another point is that some items have gaps in the time series where no
measurements were taken (in my example: BARTLEY from 1983 to 1985 and 1988
to 1989). I would like to plot using type= 'b' so that the points are
connected with lines, but when doing that, the values between 1985 and 1988
are automatically connected which I don't want. I'd like the plot to start
again at the value where the gap ends (in my example from 1988 onwards). Is
there a solution for this?

Any help is kindly appreciated! Thanks for your help.

Kind regards,
fd



--
View this message in context: http://r.789695.n4.nabble.com/Multiple-plots-and-postscripts-using-split-function-tp4694850.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Thu Jul 31 17:04:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 31 Jul 2014 08:04:44 -0700
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
Message-ID: <ED9DAD68-1BBF-43F3-9106-025A3EDDB245@comcast.net>


On Jul 31, 2014, at 4:49 AM, John McKown wrote:

> OK, I'm probably using the wrong tool for this, but I'm doing
> everything else in this project in R, so I'm looking at how to do this
> too. I create a number of graphs using ggplot2. I use the png()
> function before the print(..graph.variable..) in order to create a PNG
> file which can be embedded in a MS PowerPoint display. This is working
> fairly well.
> 
> But what I need now is a way to create a png file which is basically a
> "picture" of what you might see when you simply display a data.frame
> using Rstudio or even from the command prompt. I considered just using
> sink() and print(), but I have two problems. First, it doesn't create
> a PNG output. Second, I need to put in text annotations, title, etc.
> So what I need might be what a "geom_data.table" would produce, if
> such a thing existed in ggplot2.


Since ggplot2 is based on grid-graphics you should also search on 'grid table text' in the usual places and with the usual tools. My favorite search engine for the Archives is Markmail and my search tool for CRAN functions is sos::findFn. I'm pretty sure that Baptiste Augie has written a function or a package to do this, and I've seen several worked examples on StackOverflow. This is something I fairly quickly found:

http://rpubs.com/baptiste/ftableGrob

-- 

David Winsemius
Alameda, CA, USA


From S.Ellison at LGCGroup.com  Thu Jul 31 17:09:15 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 31 Jul 2014 16:09:15 +0100
Subject: [R] Regex - subsetting parts of a file name.
In-Reply-To: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
References: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6062C90F61@GOLD.corp.lgc-group.com>

> I want to keep only the part inside the two points. After lots of headache
> using grep() when trying something like this:
> 
> grep('.(.*?).','df.subject_test.RData',value=T)
> 
> 
> Does anyone have any suggestion ?

gsub("df\\.(.+)\\.RData", "\\1", 'df.subject_test.RData')


Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From smartpink111 at yahoo.com  Thu Jul 31 17:08:57 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 31 Jul 2014 08:08:57 -0700
Subject: [R] Regex - subsetting parts of a file name.
In-Reply-To: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
References: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
Message-ID: <1406819337.60916.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Try:
gsub(".*\\.(.*)\\..*","\\1", my.cache.list)
[1] "subject_test"? "subject_train" "y_test"??????? "y_train" 

#or

library(stringr)
str_extract(my.cache.list, perl('(?<=\\.).*(?=\\.)'))
[1] "subject_test"? "subject_train" "y_test"??????? "y_train"? 

A.K.




On Thursday, July 31, 2014 11:05 AM, arnaud gaboury <arnaud.gaboury at gmail.com> wrote:
A directory is full of data.frames cache files. All these files have
the same pattern:

df.some_name.RData

my.cache.list <- c("df.subject_test.RData", "df.subject_train.RData",
"df.y_test.RData",
"df.y_train.RData")

I want to keep only the part inside the two points. After lots of
headache using grep() when trying something like this:

grep('.(.*?).','df.subject_test.RData',value=T)

I couldn't find a clean one liner and found this workaround:

my.cache.list <- gsub('df.','',my.cache.list)
my.cache.list <- gsub('.RData','',my.cache.list)

The two above commands do the trick, but a clean one line with some
regex expression would be a more "elegant" way.

Does anyone have any suggestion ?

TY for help

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sarah.goslee at gmail.com  Thu Jul 31 17:13:16 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 31 Jul 2014 11:13:16 -0400
Subject: [R] Regex - subsetting parts of a file name.
In-Reply-To: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
References: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
Message-ID: <CAM_vjumB8p-6dbQ6Hc-1knqaK61VoYj8f2EHJTS=iNGWdnod5A@mail.gmail.com>

Hi,

Here are two possibilities:

R> as.vector(sapply(my.cache.list, function(x)strsplit(x, "\\.")[[1]][2]))
[1] "subject_test"  "subject_train" "y_test"        "y_train"


R> gsub("df\\.(.*)\\.RData", "\\1", my.cache.list)
[1] "subject_test"  "subject_train" "y_test"        "y_train"


Note that "." will match any character, while "\\." matches a period.

Sarah

On Thu, Jul 31, 2014 at 4:27 AM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> A directory is full of data.frames cache files. All these files have
> the same pattern:
>
> df.some_name.RData
>
> my.cache.list <- c("df.subject_test.RData", "df.subject_train.RData",
> "df.y_test.RData",
> "df.y_train.RData")
>
> I want to keep only the part inside the two points. After lots of
> headache using grep() when trying something like this:
>
> grep('.(.*?).','df.subject_test.RData',value=T)
>
>  I couldn't find a clean one liner and found this workaround:
>
> my.cache.list <- gsub('df.','',my.cache.list)
> my.cache.list <- gsub('.RData','',my.cache.list)
>
> The two above commands do the trick, but a clean one line with some
> regex expression would be a more "elegant" way.
>
> Does anyone have any suggestion ?
>
> TY for help
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jrkrideau at inbox.com  Thu Jul 31 17:29:46 2014
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 31 Jul 2014 07:29:46 -0800
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
 data.frame
In-Reply-To: <CAAJSdjg8MBc76P_BZTWvEfMrKxE7WOjZAOunh88EL8wdpX1bgA@mail.gmail.com>
References: <caoy2gxm_uk2nf2wy6vf47zzeaklvr-gau5xwscuugnf7b=s5cg@mail.gmail.com>
	<53da3150.1070809@gmail.com> <53da33f8.8030600@gmail.com>
	<caajsdjjuk4rvglwwff4fl0uwg2_9cuq_yigptc69zewb_yjgyg@mail.gmail.com>
Message-ID: <AA857133061.00000C28jrkrideau@inbox.com>

Have a look at http://www.r-bloggers.com/getting-tables-from-r-output/ for a suggestion. using raw xtable output You end up having to format the table in a word processor or spreadsheet, but it seems to work.  I keep forgetting just how ugly html tables can be.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: john.archie.mckown at gmail.com
> Sent: Thu, 31 Jul 2014 07:52:53 -0500
> To: jody at jody-white.com
> Subject: Re: [R] Need(?) way to create a "picture" (or "plot") of a
> data.frame
> 
> On Thu, Jul 31, 2014 at 7:34 AM, Jody White <jody at jody-white.com> wrote:
>> What about xtable? If it's going to PowerPoint and you're using RStudio,
>> what about using knitr and exporting to PowerPoint and use xtable?
>> 
> 
> I'll need to look at those. I'm new to R and am not familiar with
> either of those two packages.
> 
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From arnaud.gaboury at gmail.com  Thu Jul 31 17:39:59 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 31 Jul 2014 17:39:59 +0200
Subject: [R] Regex - subsetting parts of a file name.
In-Reply-To: <CAM_vjumB8p-6dbQ6Hc-1knqaK61VoYj8f2EHJTS=iNGWdnod5A@mail.gmail.com>
References: <CAK1hC9v03a2d8zd9f9zJXQfkwt=v7g4uQBFDhMduU+NzaW_3gg@mail.gmail.com>
	<CAM_vjumB8p-6dbQ6Hc-1knqaK61VoYj8f2EHJTS=iNGWdnod5A@mail.gmail.com>
Message-ID: <CAK1hC9uOLBsEss8QF0_FKH-gQvg4S0D1vY1xVGj=rXr644LKng@mail.gmail.com>

>
> R> as.vector(sapply(my.cache.list, function(x)strsplit(x, "\\.")[[1]][2]))
> [1] "subject_test"  "subject_train" "y_test"        "y_train"
>
>
> R> gsub("df\\.(.*)\\.RData", "\\1", my.cache.list)
> [1] "subject_test"  "subject_train" "y_test"        "y_train"
>
>
> Note that "." will match any character, while "\\." matches a period.



Thank you for your various suggestions.


From jrkrideau at inbox.com  Thu Jul 31 17:57:10 2014
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 31 Jul 2014 07:57:10 -0800
Subject: [R] Eager To Learn And Contribute!
In-Reply-To: <CAFf=nraR402FNRMVQ-Zobo2phWVQLrFpukrR5A0xeGZ7n6RpDw@mail.gmail.com>
Message-ID: <AAC2A6DCA9D.00000C8Cjrkrideau@inbox.com>

If you are new, one of the best ways to learn and then start contributing is to just read the R-help list a lot.  Even if you don't think that you can answer a specific question you see a lot and you can try to anwser questions even if you don't post a solution.

Welcome to R.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kartiksingh.jiit at gmail.com
> Sent: Thu, 31 Jul 2014 09:05:51 +0530
> To: r-help at r-project.org
> Subject: [R] Eager To Learn And Contribute!
> 
> Hi,
> 
> I am Kartik Singh , an open source enthusiast who is aspiring to be a
> Data
> Scientist .
>  Getting and Cleaning of data and its Analysis through R is something
> that
> fascinates me.
> 
> I am not new to the field of Computer Science or Statistics but R is
> something i have started to learn and explore recently .I have just
> completed an online course on R programming on Coursera by John Hopkins
> University with distinction .
> 
> Some of my skill sets include  programming in c , c++ , basic knowledge
> of
> RDBMS and programming in sql*plus/MySQL
> 
> I have read all the introductory manuals as well as researched a lot on
> the
> R Programming language and was overwhelmed by the power of the R library
> and wish to contribute to the R project in any way possible.
> 
> It would be very kind of you If you could guide me in anyway possible
> because i am very eager to learn and contribute .
> 
> Thank You.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Publish your photos in seconds for FREE
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if4


From lbagua at gmail.com  Thu Jul 31 18:26:23 2014
From: lbagua at gmail.com (Luis Borda de Agua)
Date: Thu, 31 Jul 2014 17:26:23 +0100
Subject: [R] keep information on the number of warnings
Message-ID: <DF81796F-03B8-4745-8F38-B4E991F15C6B@gmail.com>

I?m using R 3.1.0 in OS X 10.9.4 (Mavericks)

I?m running a function Y that calls a function X which occasionally generates a warning. 
Say that I call the function X 1000 times, and out of these 1000 times I get the following message:

"There were 36 warnings (use warnings() to see them)"

How can I store the number 36 in a variable in function Y?

In other words, how can I extract the information on the number of warnings generated?

Thank you in advance,


Lu?s Borda de ?gua


From dwinsemius at comcast.net  Thu Jul 31 18:29:35 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 31 Jul 2014 09:29:35 -0700
Subject: [R] keep information on the number of warnings
In-Reply-To: <DF81796F-03B8-4745-8F38-B4E991F15C6B@gmail.com>
References: <DF81796F-03B8-4745-8F38-B4E991F15C6B@gmail.com>
Message-ID: <09717D99-58DC-41CD-B3F3-C4F068B9B3B5@comcast.net>


On Jul 31, 2014, at 9:26 AM, Luis Borda de Agua wrote:

> I?m using R 3.1.0 in OS X 10.9.4 (Mavericks)
> 
> I?m running a function Y that calls a function X which occasionally generates a warning. 
> Say that I call the function X 1000 times, and out of these 1000 times I get the following message:
> 
> "There were 36 warnings (use warnings() to see them)"
> 
> How can I store the number 36 in a variable in function Y?
> 
> In other words, how can I extract the information on the number of warnings generated?

length(warnings())

-- 

David Winsemius
Alameda, CA, USA


From xie at yihui.name  Thu Jul 31 18:31:14 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 31 Jul 2014 11:31:14 -0500
Subject: [R] a knitr question
In-Reply-To: <53DA29AA.4070605@gmail.com>
References: <CACxE24nY4q9GUp7PV=AAAWJt8XbKJQY6Yks=q0Hu66SdPib+EA@mail.gmail.com>
	<CACxE24=Wh55rjO+werb-x1NarXFLVnX3St7mod4KORSM=wbMCA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2281E68F87@AKLEXM01.PFR.CO.NZ>
	<CANROs4c3DDFe1jjGRapS9aMdx4wtnz-yONMvhOhTjUnKMepCeA@mail.gmail.com>
	<CACxE24k-niOrDd8A=auH19CAhLHgVsMtVRKOM-73Myyr7a+u+Q@mail.gmail.com>
	<CA+vqiLHn9rA5wEAiNqe9f3ughJH8_2FouzMfGT2vpz-f3dWenw@mail.gmail.com>
	<CAFEqCdyt0_wri_ZbwV2qOowBKT+TUkM7yk=z25dhg0Rk8KR-cQ@mail.gmail.com>
	<CANROs4ccAY=GoW59R4bpDRFTMmRNkN_LeR7DLc=Zc-iU0Qr9Kg@mail.gmail.com>
	<53D98427.7060700@gmail.com>
	<CANROs4c+1P3OzDg8LWxRAreJ6EQEwzbGN45Pb_oBROoWhdif2A@mail.gmail.com>
	<53DA29AA.4070605@gmail.com>
Message-ID: <CANROs4fnHyePqU65ar6nrgq+VuK+EEhE23WH0-S9ncwYs9jNaA@mail.gmail.com>

Great.

I also said "I see the point of keeping prompts", and that is why the
chunk option prompt=TRUE is provided in knitr. I may not agree with
your preference, but that does not mean I should stop you completely
from having your own preference.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Jul 31, 2014 at 6:34 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 30/07/2014, 11:12 PM, Yihui Xie wrote:
>> No. That is not my suggestion. Joshua Wiley correctly explained what I
>> was suggesting. Prompts are useful in the R console, but not
>> necessarily in a report.
>
> Okay, then we agree.  For Erin's purpose (teaching), it is helpful to
> beginners if the document looks the same as what they see in the
> console.  More sophisticated users don't need the prompts.
>
> Duncan Murdoch


From dcarlson at tamu.edu  Thu Jul 31 19:57:52 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 31 Jul 2014 17:57:52 +0000
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <1406817448605-4694850.post@n4.nabble.com>
References: <1406817448605-4694850.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8DA2A@mb02.ads.tamu.edu>

This is one of those times when you would do better to just use a loop. It will be easier to debug and to see what is going on. Replace the sapply() call with

for (i in 1:length(ind)) {
	postscript(names(ind[i]))
	par(mar=c(6,8,6,5), cex=0.8)     
   	plot(ind[[i]][,c('YEAR','VALUE')],
		type='b', 
		main = ind[[i]][1, "NAME"],
		. . . other commands . . . )
	dev.off()
}

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of fd
Sent: Thursday, July 31, 2014 9:37 AM
To: r-help at r-project.org
Subject: [R] Multiple plots and postscripts using split function

Hi,

I'm relatively new to R and I would like to do the following:

I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and would like
to do several xy plots with the year on the x-axis and the data values
(measurements) on the y-axis and after that export the different plots to
postcript. 

My .csv file looks something like this (only an example):

NAME				ID		YEAR	VALUE
ADAMS				885		1988		-2
ADAMS				885		1989		0
BAHIA DEL DIABLO		2665		1999		4
BAHIA DEL DIABLO		2665		2000		8
BAHIA DEL DIABLO		2665		2001		19
BAHIA DEL DIABLO		2665		2002		13
BAHIA DEL DIABLO		2665		2003		13
BARTLEY				893		1983		0
BARTLEY				893		1984		-1
BARTLEY				893		1985		0
BARTLEY				893		1988		2
BARTLEY				893		1989		-1
CANADA				877		1972		-1

I have split the different items into groups and I'd like the plots to have
the title of NAME but the filename of the postscript to be exported should
have the ID as filename.

My code so far:

#Set Working Directory:
setwd("/Users/Desktop/FV")
# Read CSV
dat <- read.csv("FV.csv", sep=";", header=TRUE)
# Split Data
ind <- split(x = dat,f = dat[,'ID'])
nam <- names(ind)

sapply(nam, function(x) {
	postscript(x)
	par(mar=c(6,8,6,5), cex=0.8) ????
???	plot(ind[[x]][,c('YEAR','VALUE')], 
	type='b', 
	main = x, 
	xlab="Time [Years]", 
	ylab="Front variation") ?????
	axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-0.3)
???	axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
tcl=-0.3) 
???
	dev.off() 
})

This results in plots with the title and filename of the resulting
postscript being the same. Is there a way to get the plot title out of the
NAME column and the filename out of the ID?

Additionally I'd only like to plot graphs for items with more than 3 data
values. Is this possible to incorporate in the split command?

Another point is that some items have gaps in the time series where no
measurements were taken (in my example: BARTLEY from 1983 to 1985 and 1988
to 1989). I would like to plot using type= 'b' so that the points are
connected with lines, but when doing that, the values between 1985 and 1988
are automatically connected which I don't want. I'd like the plot to start
again at the value where the gap ends (in my example from 1988 onwards). Is
there a solution for this?

Any help is kindly appreciated! Thanks for your help.

Kind regards,
fd



--
View this message in context: http://r.789695.n4.nabble.com/Multiple-plots-and-postscripts-using-split-function-tp4694850.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ben.sully88 at gmail.com  Thu Jul 31 19:27:44 2014
From: ben.sully88 at gmail.com (Ben Sully)
Date: Thu, 31 Jul 2014 10:27:44 -0700 (PDT)
Subject: [R] Writing to gzcon with rawConnection
In-Reply-To: <CAJ_cGTrzi2pO+T174K57x5Jyo716e6XYip+Bz06yjj=9a-nTNw@mail.gmail.com>
References: <CAJ_cGTrzi2pO+T174K57x5Jyo716e6XYip+Bz06yjj=9a-nTNw@mail.gmail.com>
Message-ID: <e994b703-f084-4476-a81d-1fab32d04112@googlegroups.com>

Did you ever manage to solve this problem, Jamie?

Ben

On Friday, 2 May 2014 19:50:27 UTC+1, Jamie Olson wrote:
>
> I would like to encode/decode some text with deflate/gzip, but I'm 
> having trouble. 
>
> Decoding values from a rawConnection is fairly straightforward, but 
> I'm having trouble encoding values and then retrieving them. 
>
> > gz_out <- gzcon(raw_out <- rawConnection(raw(0),open="wb")) 
> > writeLines("test",con=gz_out) 
> > flush(gz_out) 
> > rawConnectionValue(raw_out) 
> Error: cannot allocate vector of size 131069.2 Gb 
> > raw_out <- rawConnection(raw(0),open="wb") 
> > writeLines("test",con=raw_out) 
> > rawConnectionValue(raw_out) 
> [1] 74 65 73 74 0a 
>
>
> Has anyone had success doing this? 
>
> --Jamie 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From shidaxia at yahoo.com  Thu Jul 31 18:17:48 2014
From: shidaxia at yahoo.com (Shi, Tao)
Date: Thu, 31 Jul 2014 09:17:48 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAKO5CYUKnDwHiLq1ix-J7J877iuBPGmLqEUCgr0mH_4eM07z+w@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>	<1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>	<CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>
	<CAKO5CYUKnDwHiLq1ix-J7J877iuBPGmLqEUCgr0mH_4eM07z+w@mail.gmail.com>
Message-ID: <1406823468.74506.YahooMailNeo@web124706.mail.ne1.yahoo.com>

I looked at ggvis briefly before, but didn't notice its brushing capability. ?Now you explained.

Thanks, both!

Tao




On Wednesday, July 30, 2014 9:50 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:



ggvis is an excellent option to do this kind of stuff.

The only limitation currently is that all sorts of interactivity (tooltips, brushing etc.) are done on the server side using Shiny. So you have to upload your HTML to a shiny server for the interactivity to work.

Best,
Ramnath



______________________________________
Ramnath Vaidyanathan
Assistant Professor of Operations Management
Desautels Faculty of Management
1001 Sherbrooke Street West
Montreal, QC H3A 1G5
Ph: +1 (514) 398-1457
______________________________________


On Wed, Jul 30, 2014 at 12:45 PM, Greg Snow <538280 at gmail.com> wrote:

Another option that is in developement, but may do what you want is
>ggvis (http://ggvis.rstudio.com/). ?I have seen an example of brushing
>created with ggvis that can then be embedded in a web page. ?I am not
>sure if you can send the html and support files directly to someone
>without R (probably Rstudio) or if you need to upload it to a server
>for others to see, but the later is still an option for collaborators
>who do not have R installed.
>
>
>On Tue, Jul 29, 2014 at 2:13 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>> Thank you very much, Greg and Ramnath, for the pointers! ?I'll explore more.
>>
>>
>>
>>
>> On Tuesday, July 29, 2014 8:10 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>>
>>
>>
>> There are plugins for rCharts that help you create custom charts.
>>
>> Here is a scatterplot matrix example
>>
>> http://mostlyconjecture.com/2014/02/09/scatterplot-matrix-with-rcharts/
>>
>>
>> It doesn't support brushing, but I think it won't be hard adding that behavior if you contact its author.
>>
>> Hope this helps.
>>
>> Best,
>> Ramnath
>>
>>
>>
>> ______________________________________
>> Ramnath Vaidyanathan
>> Assistant Professor of Operations Management
>> Desautels Faculty of Management
>> 1001 Sherbrooke Street West
>> Montreal, QC H3A 1G5
>> Ph: +1 (514) 398-1457
>> ______________________________________
>>
>>
>> On Tue, Jul 29, 2014 at 11:01 AM, Greg Snow <538280 at gmail.com> wrote:
>>
>> There is the TkBrush function in the TeachingDemos package that gives
>>>brushing in a scatterplot matrix using a Tk interface rather than
>>>ggobi. ?There is also the iplots package which allows you to create
>>>multiple scatterplots, histograms, boxplots, barcharts, etc. and
>>>points selected in any one of the plots will then be highlighted in
>>>all the others. ?Both of those solutions require R to be installed.
>>>
>>>I don't know of any way to get what you want without installing at
>>>least one of ggobi or R (or some other program of similar complexity
>>>to install).
>>>
>>>On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>>> hi list,
>>>>
>>>> I'm comparing the changes of ~100 analytes in multiple treatment conditions. ?I plotted them in several different xy scattter plots. ?It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown. ?I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine). ?rCharts is nice but so far it can only create one scatter plot at a time.
>>>>
>>>> Any good suggestions?
>>>>
>>>> Many thanks!
>>>>
>>>> Tao
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>--
>>>Gregory (Greg) L. Snow Ph.D.
>>>538280 at gmail.com
>>>
>
>
>
>--
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com
>


From 538280 at gmail.com  Thu Jul 31 20:11:51 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 31 Jul 2014 12:11:51 -0600
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <1406823468.74506.YahooMailNeo@web124706.mail.ne1.yahoo.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>
	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>
	<1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>
	<CAKO5CYUKnDwHiLq1ix-J7J877iuBPGmLqEUCgr0mH_4eM07z+w@mail.gmail.com>
	<1406823468.74506.YahooMailNeo@web124706.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdx2u9vRBgp5p0s594HgLp4VfvAq+dTr23Z8P0YJQHmt4A@mail.gmail.com>

The brushing may only be available in the development version of
ggvis.  See here for the example:
https://github.com/rstudio/webinars/tree/master/2014-01


On Thu, Jul 31, 2014 at 10:17 AM, Shi, Tao <shidaxia at yahoo.com> wrote:
> I looked at ggvis briefly before, but didn't notice its brushing capability.  Now you explained.
>
> Thanks, both!
>
> Tao
>
>
>
>
> On Wednesday, July 30, 2014 9:50 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>
>
>
> ggvis is an excellent option to do this kind of stuff.
>
> The only limitation currently is that all sorts of interactivity (tooltips, brushing etc.) are done on the server side using Shiny. So you have to upload your HTML to a shiny server for the interactivity to work.
>
> Best,
> Ramnath
>
>
>
> ______________________________________
> Ramnath Vaidyanathan
> Assistant Professor of Operations Management
> Desautels Faculty of Management
> 1001 Sherbrooke Street West
> Montreal, QC H3A 1G5
> Ph: +1 (514) 398-1457
> ______________________________________
>
>
> On Wed, Jul 30, 2014 at 12:45 PM, Greg Snow <538280 at gmail.com> wrote:
>
> Another option that is in developement, but may do what you want is
>>ggvis (http://ggvis.rstudio.com/).  I have seen an example of brushing
>>created with ggvis that can then be embedded in a web page.  I am not
>>sure if you can send the html and support files directly to someone
>>without R (probably Rstudio) or if you need to upload it to a server
>>for others to see, but the later is still an option for collaborators
>>who do not have R installed.
>>
>>
>>On Tue, Jul 29, 2014 at 2:13 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>> Thank you very much, Greg and Ramnath, for the pointers!  I'll explore more.
>>>
>>>
>>>
>>>
>>> On Tuesday, July 29, 2014 8:10 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>>>
>>>
>>>
>>> There are plugins for rCharts that help you create custom charts.
>>>
>>> Here is a scatterplot matrix example
>>>
>>> http://mostlyconjecture.com/2014/02/09/scatterplot-matrix-with-rcharts/
>>>
>>>
>>> It doesn't support brushing, but I think it won't be hard adding that behavior if you contact its author.
>>>
>>> Hope this helps.
>>>
>>> Best,
>>> Ramnath
>>>
>>>
>>>
>>> ______________________________________
>>> Ramnath Vaidyanathan
>>> Assistant Professor of Operations Management
>>> Desautels Faculty of Management
>>> 1001 Sherbrooke Street West
>>> Montreal, QC H3A 1G5
>>> Ph: +1 (514) 398-1457
>>> ______________________________________
>>>
>>>
>>> On Tue, Jul 29, 2014 at 11:01 AM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>> There is the TkBrush function in the TeachingDemos package that gives
>>>>brushing in a scatterplot matrix using a Tk interface rather than
>>>>ggobi.  There is also the iplots package which allows you to create
>>>>multiple scatterplots, histograms, boxplots, barcharts, etc. and
>>>>points selected in any one of the plots will then be highlighted in
>>>>all the others.  Both of those solutions require R to be installed.
>>>>
>>>>I don't know of any way to get what you want without installing at
>>>>least one of ggobi or R (or some other program of similar complexity
>>>>to install).
>>>>
>>>>On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>>>> hi list,
>>>>>
>>>>> I'm comparing the changes of ~100 analytes in multiple treatment conditions.  I plotted them in several different xy scattter plots.  It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown.  I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine).  rCharts is nice but so far it can only create one scatter plot at a time.
>>>>>
>>>>> Any good suggestions?
>>>>>
>>>>> Many thanks!
>>>>>
>>>>> Tao
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>>--
>>>>Gregory (Greg) L. Snow Ph.D.
>>>>538280 at gmail.com
>>>>
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com
>>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dmck at u.washington.edu  Thu Jul 31 20:09:59 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 31 Jul 2014 11:09:59 -0700
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F8DA2A@mb02.ads.tamu.edu>
References: <1406817448605-4694850.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8DA2A@mb02.ads.tamu.edu>
Message-ID: <60E40404-B895-4A35-847F-CFAA48FAB284@u.washington.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/9b22ee2c/attachment.pl>

From istazahn at gmail.com  Thu Jul 31 20:54:45 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 31 Jul 2014 14:54:45 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <4359813F-8DA1-4DBC-A45D-4104D226CB3C@gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
	<0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
	<e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>
	<CA+vqiLFqYCJus7oFEc-MEaTkTJ2a1j0jOtjKm9hdNUF+0bORxQ@mail.gmail.com>
	<4359813F-8DA1-4DBC-A45D-4104D226CB3C@gmail.com>
Message-ID: <CA+vqiLHL89U-06r6kxOt1N7CHG1_SnSfS+3MMszoC2kWozppVg@mail.gmail.com>

Hi Keith,

So the plot thickens. How is it that you have R 3.1.1 but apt-get
install rJava gives you an old version of the package? This may be
potentially difficult to figure out, but you can try some easy things
first. If I were you I would start with

sudo apt-get remove r-base r-devel
sudo apt-get update
sudo apt-get dist-upgrade
sudo apt-get install r-base r-devel r-cran-rjava
sudo R CM D javareconf


Then restart the computer. Or something like that.

Finally, note that there is a specific mailing list for those running
R on debian (of which mint is a (n indirect) derivative): see
https://stat.ethz.ch/mailman/listinfo/r-sig-debian. You may have
better luck asking your question there.

Best,
Ista

On Thu, Jul 31, 2014 at 8:46 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> Ista Et Al,
> Unfortunately your suggestion to use remove.packages did exactly the reverse of what you thought would happen.
>
> I have cleaned up my installation but still have trouble getting rJava to install properly and of course that means that XLConnect cannot install either.
>
> -------------------------------------
> I think this shows that the java-7-openjdk is working.
> -------------------------------------
> /home/refserv $ sudo R CMD javareconf
> Java interpreter : /usr/bin/java
> Java version     : 1.7.0_55
> Java home path   : /usr/lib/jvm/java-7-openjdk-i386/jre
> Java compiler    : /usr/bin/javac
> Java headers gen.: /usr/bin/javah
> Java archive tool: /usr/bin/jar
>
> trying to compile and link a JNI progam
> detected JNI cpp flags    : -I$(JAVA_HOME)/../include
> detected JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/lib/jvm/java-7-openjdk-i386/jre/../include     -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c conftest.c -o conftest.o
> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o conftest.so conftest.o -L/usr/lib/jvm/java-7-openjdk-i386/jre/lib/i386/client -ljvm -L/usr/lib/R/lib -lR
>
>
> JAVA_HOME        : /usr/lib/jvm/java-7-openjdk-i386/jre
> Java library path: $(JAVA_HOME)/lib/i386/client
> JNI cpp flags    : -I$(JAVA_HOME)/../include
> JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
> Updating Java configuration in /usr/lib/R
> Done.
> ___________________________________
>
>
> -------------------------------------
> Purge and re-install rjava
> -------------------------------------
> /home/refserv $ sudo apt-get --purge remove r-cran-rjava
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> The following packages will be REMOVED:
>   r-cran-rjava*
> 0 upgraded, 0 newly installed, 1 to remove and 3 not upgraded.
> After this operation, 1,651 kB disk space will be freed.
> Do you want to continue [Y/n]? y
> (Reading database ... 173764 files and directories currently installed.)
> Removing r-cran-rjava ...
>
> /home/refserv $ sudo apt-get install r-cran-rjava
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> The following NEW packages will be installed:
>   r-cran-rjava
> 0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.
> Need to get 0 B/557 kB of archives.
> After this operation, 1,651 kB of additional disk space will be used.
> Selecting previously unselected package r-cran-rjava.
> (Reading database ... 173625 files and directories currently installed.)
> Unpacking r-cran-rjava (from .../r-cran-rjava_0.9-3-1_i386.deb) ...
> Setting up r-cran-rjava (0.9-3-1) ...
> -------------------------------------
> -------------------------------------
>
>
>
> -------------------------------------
> Here I try to install rJava in R
> but it looks like there is a version problem.
>
> Given I am using openjdk above I am not sure why R is looking at the oracle Java
> -------------------------------------
>
> home/refserv $ R
>
> R version 3.1.1 (2014-07-10) -- "Sock it to Me"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
>
> ........................................ (just cutting down on the output)
>
>> require(rJava)
> Loading required package: rJava
> Failed with error:  ?package ?rJava? was built before R 3.0.0: please re-install it?
>> install.packages("rJava")
> Installing package into ?/home/refserv/R/i686-pc-linux-gnu-library/3.1?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.mirrors.hoobly.com/src/contrib/rJava_0.9-6.tar.gz'
> Content type 'application/x-gzip' length 567515 bytes (554 Kb)
> opened URL
> ==================================================
> downloaded 554 Kb
>
>
> ........................................ (just cutting down on the output)
>
>
> checking Java support in R... present:
> interpreter : '/usr/lib/jvm/java-7-oracle/jre/bin/java'
> archiver    : '/usr/lib/jvm/java-7-oracle/bin/jar'
> compiler    : '/usr/lib/jvm/java-7-oracle/bin/javac'
> header prep.: '/usr/lib/jvm/java-7-oracle/bin/javah'
> cpp flags   : '-I/usr/lib/jvm/java-7-oracle/include -I/usr/lib/jvm/java-7-oracle/include/linux'
> java libs   : '-L/usr/lib/jvm/java-7-oracle/jre/lib/i386/client -ljvm'
> checking whether Java run-time works... ./configure: line 3729: /usr/lib/jvm/java-7-oracle/jre/bin/java: No such file or directory
> no
> configure: error: Java interpreter '/usr/lib/jvm/java-7-oracle/jre/bin/java' does not work
> ERROR: configuration failed for package ?rJava?
> * removing ?/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava?
>
> The downloaded source packages are in
>         ?/tmp/RtmpwvY4Md/downloaded_packages?
> Warning message:
> In install.packages("rJava") :
>   installation of package ?rJava? had non-zero exit status
>
> -------------------------------------
> -------------------------------------
>
> Thanks again for your time,
> Best,
> KW
>
>
> --
>
> On Jul 29, 2014, at 2:22 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> On Tue, Jul 29, 2014 at 12:54 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> Sounds to me like a problem outside of R (off topic here).
>>
>> Possibly, but I suspect that the OP now has two versions of XLConnect
>> installed, one in the user R library and one in the system-wide R
>> library.
>>
>> Keith, try
>>
>> remove.packages("XLConnect")
>> remove.packages("rJava")
>>
>> WITHOUT sudo. Then restart R; you should now get the (working)
>> system-wide versions of rJava and XLConnect.
>>
>> HTH,
>> Ista
>>
>> In particular, it doesn't sound like you are using the appropriate
>> tools (apt-get package manager for R and a JDK; R install.package()
>> for your R packages) to admin your machine. The only thing you should
>> need sudo for is to run apt-get... everything else should be done as a
>> normal user unless you really know what you are doing. I had no
>> problem installing it just now on my Ubuntu machine with OpenJDK. I
>> have no experience with Mint but Google tells me you should be able to
>> use the instructions for Ubuntu... I would expect Google to tell you
>> the same thing if you ask nicely... your most challenging task at this
>> point should be cleaning up the mess you have made by excessive use of
>> sudo ... most likely running R with it (only update your personal R
>> library directories so you are not tempted to go rogue) but you don't
>> say how you installed the jdk so that could also be messed up.
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On July 29, 2014 8:19:33 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>>>> John Et Al.
>>>>
>>>> I can get rJava and XLConnect to work only if I run as super user.
>>>>
>>>> Note that I have built rJava and XLConnect as super user (otherwise
>>>> neither package works).
>>>>
>>>>
>>>> ____________________________________________
>>>> Without sudo
>>>>
>>>>> require(XLConnect)
>>>> Loading required package: XLConnect
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>> error: unable to load shared object
>>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>> libjvm.so: cannot open shared object file: No such file or directory
>>>> _____________________________________________
>>>> With sudo
>>>>
>>>>> require(XLConnect)
>>>> Loading required package: XLConnect
>>>> XLConnect 0.2-7 by Mirai Solutions GmbH
>>>> http://www.mirai-solutions.com ,
>>>> http://miraisolutions.wordpress.com
>>>>
>>>> ______________________________________________
>>>> Note that I have changed the ownership (recursively) for rJava and
>>>> XLConnect because they were previously owned by root. Also note that
>>>> ggplot2 (included for comparison) was installed the usual way with no
>>>> problem.
>>>>
>>>> drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
>>>> drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
>>>> drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/
>>>>
>>>> ________________________________________________
>>>>
>>>> Despite "no such file or directory" above:
>>>>
>>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr
>>>> /home/refserv/>
>>>> -rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28
>>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so
>>>>
>>>> The file rJava.so exists.
>>>>
>>>> Thanks so much for your time and help,
>>>> Best,
>>>> KW
>>>>
>>>> --
>>>>
>>>> On Jul 24, 2014, at 11:16 PM, John McKown
>>>> <john.archie.mckown at gmail.com> wrote:
>>>>
>>>>> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com>
>>>> wrote:
>>>>>> Folks,
>>>>>>
>>>>>> I have been trying to get XLConnect to work on my Linux Mint Maya
>>>> machine.
>>>>>>
>>>>>> R works fine but this package doesn't seem to want to build. Here is
>>>> the message I get after supposedly building XLConnect and rJava:
>>>>>>
>>>>>>
>>>>>>>> require(XLConnect)
>>>>>>> Loading required package: XLConnect
>>>>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>>>>> error: unable to load shared object
>>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>>>>> libjvm.so: cannot open shared object file: No such file or
>>>> directory
>>>>>>
>>>>>>
>>>>>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>>>>>>
>>>>>> The build and the compile seemed to work ok as there were no errors.
>>>> For example I can generate ggplot2 graphs.
>>>>>>
>>>>>> I know this is probably the wrong forum but if someone could gently
>>>> point me in the right direction I would be very appreciative.
>>>>>>
>>>>>> Thanks so much for your time,
>>>>>> KW
>>>>>
>>>>> It works fine for me on Fedora 20 (and 19 before it). When I
>>>> installed
>>>>> R, it installed into /usr/lib64/R. There exists a file:
>>>>> /usr/lib64/R/etc/ldpaths which is executed by the R executable
>>>> script.
>>>>> This sets up the LD_LIBRARY_PATH to point to the Java installation on
>>>>> my machine. In the /usr/lib64/R/bin directory, there is a program
>>>>> called "javareconf". I would suggest that you run this with the -n
>>>>> switch, like:
>>>>>
>>>>> R CMD /usr/lib64/R/bin/javareconf -n
>>>>>
>>>>> This will show you what it _would_ do if you left off the "-n". Make
>>>>> sure it looks reasonable. If it does, then run the same command,
>>>>> without the "-n", as the "root" superuser. In my case, that would be:
>>>>>
>>>>> sudo R CMD /usr/lib64/R/bin/javareconf
>>>>>
>>>>> You need to be "root" because it update the file
>>>>> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
>>>>> problem.
>>>>>
>>>>> ===
>>>>>
>>>>> As a possible alternative to XLConnect, have you looked at openxlsx?
>>>>> It appears to have the same abilities, just some different syntax. It
>>>>> says that it is written in C and so should be faster than XLConnect.
>>>> I
>>>>> have tested both packages, a little, and they both seem to work well.
>>>>>
>>>>> Well, it's 22:14 hours here and I wish that I could fall asleep.
>>>> We're
>>>>> having problems at work and I know that the "big boss" will blame us
>>>>> peons if the hardware isn't fixed promptly Despite the fact that we
>>>>> are only software people and aren't allowed to touch the hardware.
>>>> Our
>>>>> management's minds are not using the same logic as mine does.
>>>>> Frustrating.
>>>>>
>>>>> --
>>>>> There is nothing more pleasant than traveling and meeting new people!
>>>>> Genghis Khan
>>>>>
>>>>> Maranatha! <><
>>>>> John McKown
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Thu Jul 31 20:56:39 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 31 Jul 2014 11:56:39 -0700
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <60E40404-B895-4A35-847F-CFAA48FAB284@u.washington.edu>
References: <1406817448605-4694850.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8DA2A@mb02.ads.tamu.edu>
	<60E40404-B895-4A35-847F-CFAA48FAB284@u.washington.edu>
Message-ID: <639e0c41-5632-44d9-baa9-e62a00c3a74d@email.android.com>

The range vector is evaluated at the start of the loop, so it is only evaluated once. ind.length would be an unnecessary extra variable.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 31, 2014 11:09:59 AM PDT, Don McKenzie <dmck at u.washington.edu> wrote:
>While you?re at it, assign length(ind) to a variable before starting
>the loop. Otherwise length() is called at each iteration.  e.g.,
>
>ind.length <- length(ind)
>for (i in 1:ind.length)  {
>
>etc.
>
>On Jul 31, 2014, at 10:57 AM, David L Carlson <dcarlson at tamu.edu>
>wrote:
>
>> This is one of those times when you would do better to just use a
>loop. It will be easier to debug and to see what is going on. Replace
>the sapply() call with
>> 
>> for (i in 1:length(ind)) {
>> 	postscript(names(ind[i]))
>> 	par(mar=c(6,8,6,5), cex=0.8)     
>>   	plot(ind[[i]][,c('YEAR','VALUE')],
>> 		type='b', 
>> 		main = ind[[i]][1, "NAME"],
>> 		. . . other commands . . . )
>> 	dev.off()
>> }
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of fd
>> Sent: Thursday, July 31, 2014 9:37 AM
>> To: r-help at r-project.org
>> Subject: [R] Multiple plots and postscripts using split function
>> 
>> Hi,
>> 
>> I'm relatively new to R and I would like to do the following:
>> 
>> I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and
>would like
>> to do several xy plots with the year on the x-axis and the data
>values
>> (measurements) on the y-axis and after that export the different
>plots to
>> postcript. 
>> 
>> My .csv file looks something like this (only an example):
>> 
>> NAME				ID		YEAR	VALUE
>> ADAMS				885		1988		-2
>> ADAMS				885		1989		0
>> BAHIA DEL DIABLO		2665		1999		4
>> BAHIA DEL DIABLO		2665		2000		8
>> BAHIA DEL DIABLO		2665		2001		19
>> BAHIA DEL DIABLO		2665		2002		13
>> BAHIA DEL DIABLO		2665		2003		13
>> BARTLEY				893		1983		0
>> BARTLEY				893		1984		-1
>> BARTLEY				893		1985		0
>> BARTLEY				893		1988		2
>> BARTLEY				893		1989		-1
>> CANADA				877		1972		-1
>> 
>> I have split the different items into groups and I'd like the plots
>to have
>> the title of NAME but the filename of the postscript to be exported
>should
>> have the ID as filename.
>> 
>> My code so far:
>> 
>> #Set Working Directory:
>> setwd("/Users/Desktop/FV")
>> # Read CSV
>> dat <- read.csv("FV.csv", sep=";", header=TRUE)
>> # Split Data
>> ind <- split(x = dat,f = dat[,'ID'])
>> nam <- names(ind)
>> 
>> sapply(nam, function(x) {
>> 	postscript(x)
>> 	par(mar=c(6,8,6,5), cex=0.8)     
>>    	plot(ind[[x]][,c('YEAR','VALUE')], 
>> 	type='b', 
>> 	main = x, 
>> 	xlab="Time [Years]", 
>> 	ylab="Front variation")      
>> 	axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-0.3)
>>    	axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
>> tcl=-0.3) 
>>    
>> 	dev.off() 
>> })
>> 
>> This results in plots with the title and filename of the resulting
>> postscript being the same. Is there a way to get the plot title out
>of the
>> NAME column and the filename out of the ID?
>> 
>> Additionally I'd only like to plot graphs for items with more than 3
>data
>> values. Is this possible to incorporate in the split command?
>> 
>> Another point is that some items have gaps in the time series where
>no
>> measurements were taken (in my example: BARTLEY from 1983 to 1985 and
>1988
>> to 1989). I would like to plot using type= 'b' so that the points are
>> connected with lines, but when doing that, the values between 1985
>and 1988
>> are automatically connected which I don't want. I'd like the plot to
>start
>> again at the value where the gap ends (in my example from 1988
>onwards). Is
>> there a solution for this?
>> 
>> Any help is kindly appreciated! Thanks for your help.
>> 
>> Kind regards,
>> fd
>> 
>> 
>> 
>> --
>> View this message in context:
>http://r.789695.n4.nabble.com/Multiple-plots-and-postscripts-using-split-function-tp4694850.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>Don McKenzie
>Research Ecologist
>Pacific Wildland Fire Sciences Lab
>US Forest Service
>
>Affiliate Professor
>School of Environmental and Forest Sciences
>University of Washington
>dmck at uw.edu
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Jul 31 21:19:45 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 31 Jul 2014 12:19:45 -0700
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <639e0c41-5632-44d9-baa9-e62a00c3a74d@email.android.com>
References: <1406817448605-4694850.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8DA2A@mb02.ads.tamu.edu>
	<60E40404-B895-4A35-847F-CFAA48FAB284@u.washington.edu>
	<639e0c41-5632-44d9-baa9-e62a00c3a74d@email.android.com>
Message-ID: <CAF8bMcZ4NvX0_t78Ai_sKGNMYcw+STD6kbSLZfg9AgzygwaGCA@mail.gmail.com>

Even better is to replace
    for(i in 1:length(something)) {}
with
    for(i in seq_along(something)) {}
The former gives you 2 iterations, the 2nd probably causing an error,
when length(something) is 0.  The latter always gives one iteration
per element of 'something'.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jul 31, 2014 at 11:56 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The range vector is evaluated at the start of the loop, so it is only evaluated once. ind.length would be an unnecessary extra variable.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On July 31, 2014 11:09:59 AM PDT, Don McKenzie <dmck at u.washington.edu> wrote:
>>While you?re at it, assign length(ind) to a variable before starting
>>the loop. Otherwise length() is called at each iteration.  e.g.,
>>
>>ind.length <- length(ind)
>>for (i in 1:ind.length)  {
>>
>>etc.
>>
>>On Jul 31, 2014, at 10:57 AM, David L Carlson <dcarlson at tamu.edu>
>>wrote:
>>
>>> This is one of those times when you would do better to just use a
>>loop. It will be easier to debug and to see what is going on. Replace
>>the sapply() call with
>>>
>>> for (i in 1:length(ind)) {
>>>      postscript(names(ind[i]))
>>>      par(mar=c(6,8,6,5), cex=0.8)
>>>      plot(ind[[i]][,c('YEAR','VALUE')],
>>>              type='b',
>>>              main = ind[[i]][1, "NAME"],
>>>              . . . other commands . . . )
>>>      dev.off()
>>> }
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>[mailto:r-help-bounces at r-project.org] On Behalf Of fd
>>> Sent: Thursday, July 31, 2014 9:37 AM
>>> To: r-help at r-project.org
>>> Subject: [R] Multiple plots and postscripts using split function
>>>
>>> Hi,
>>>
>>> I'm relatively new to R and I would like to do the following:
>>>
>>> I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and
>>would like
>>> to do several xy plots with the year on the x-axis and the data
>>values
>>> (measurements) on the y-axis and after that export the different
>>plots to
>>> postcript.
>>>
>>> My .csv file looks something like this (only an example):
>>>
>>> NAME                         ID              YEAR    VALUE
>>> ADAMS                                885             1988            -2
>>> ADAMS                                885             1989            0
>>> BAHIA DEL DIABLO             2665            1999            4
>>> BAHIA DEL DIABLO             2665            2000            8
>>> BAHIA DEL DIABLO             2665            2001            19
>>> BAHIA DEL DIABLO             2665            2002            13
>>> BAHIA DEL DIABLO             2665            2003            13
>>> BARTLEY                              893             1983            0
>>> BARTLEY                              893             1984            -1
>>> BARTLEY                              893             1985            0
>>> BARTLEY                              893             1988            2
>>> BARTLEY                              893             1989            -1
>>> CANADA                               877             1972            -1
>>>
>>> I have split the different items into groups and I'd like the plots
>>to have
>>> the title of NAME but the filename of the postscript to be exported
>>should
>>> have the ID as filename.
>>>
>>> My code so far:
>>>
>>> #Set Working Directory:
>>> setwd("/Users/Desktop/FV")
>>> # Read CSV
>>> dat <- read.csv("FV.csv", sep=";", header=TRUE)
>>> # Split Data
>>> ind <- split(x = dat,f = dat[,'ID'])
>>> nam <- names(ind)
>>>
>>> sapply(nam, function(x) {
>>>      postscript(x)
>>>      par(mar=c(6,8,6,5), cex=0.8)
>>>      plot(ind[[x]][,c('YEAR','VALUE')],
>>>      type='b',
>>>      main = x,
>>>      xlab="Time [Years]",
>>>      ylab="Front variation")
>>>      axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-0.3)
>>>      axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
>>> tcl=-0.3)
>>>
>>>      dev.off()
>>> })
>>>
>>> This results in plots with the title and filename of the resulting
>>> postscript being the same. Is there a way to get the plot title out
>>of the
>>> NAME column and the filename out of the ID?
>>>
>>> Additionally I'd only like to plot graphs for items with more than 3
>>data
>>> values. Is this possible to incorporate in the split command?
>>>
>>> Another point is that some items have gaps in the time series where
>>no
>>> measurements were taken (in my example: BARTLEY from 1983 to 1985 and
>>1988
>>> to 1989). I would like to plot using type= 'b' so that the points are
>>> connected with lines, but when doing that, the values between 1985
>>and 1988
>>> are automatically connected which I don't want. I'd like the plot to
>>start
>>> again at the value where the gap ends (in my example from 1988
>>onwards). Is
>>> there a solution for this?
>>>
>>> Any help is kindly appreciated! Thanks for your help.
>>>
>>> Kind regards,
>>> fd
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>http://r.789695.n4.nabble.com/Multiple-plots-and-postscripts-using-split-function-tp4694850.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>Don McKenzie
>>Research Ecologist
>>Pacific Wildland Fire Sciences Lab
>>US Forest Service
>>
>>Affiliate Professor
>>School of Environmental and Forest Sciences
>>University of Washington
>>dmck at uw.edu
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>
>>
>>------------------------------------------------------------------------
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Thu Jul 31 21:31:11 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Thu, 31 Jul 2014 15:31:11 -0400
Subject: [R] XLConnect on Linux Mint Maya
In-Reply-To: <CA+vqiLHL89U-06r6kxOt1N7CHG1_SnSfS+3MMszoC2kWozppVg@mail.gmail.com>
References: <69DBC41E-F00B-417B-88D2-B8B6AB574CB6@gmail.com>
	<CAAJSdji-zE3iLrgD3_DD3B2Bk99Rac1M3-ATk2jnktKnz9t5Sw@mail.gmail.com>
	<0714D124-63E6-4337-8DD4-58CB115C2C16@gmail.com>
	<e2564fc4-a53e-474e-8f7c-9a33901b73fe@email.android.com>
	<CA+vqiLFqYCJus7oFEc-MEaTkTJ2a1j0jOtjKm9hdNUF+0bORxQ@mail.gmail.com>
	<4359813F-8DA1-4DBC-A45D-4104D226CB3C@gmail.com>
	<CA+vqiLHL89U-06r6kxOt1N7CHG1_SnSfS+3MMszoC2kWozppVg@mail.gmail.com>
Message-ID: <6DACD6CC-6F7E-46A6-8425-2C705FB434A3@gmail.com>

Thanks Ista,
I will try your procedure next Tuesday. This is going pretty slow because I only work at that machine Tuesday-Thursday.

I will let you know how it goes (lucky you!) by private email as I don't think there is any use in bothering all of r-help.

After trying your suggestions next week I will switch over to the r-sig-debian group and start bothering them.

Thanks again for everyone that chimed in to help me,
Best,
KW

--

On Jul 31, 2014, at 2:54 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Hi Keith,
> 
> So the plot thickens. How is it that you have R 3.1.1 but apt-get
> install rJava gives you an old version of the package? This may be
> potentially difficult to figure out, but you can try some easy things
> first. If I were you I would start with
> 
> sudo apt-get remove r-base r-devel
> sudo apt-get update
> sudo apt-get dist-upgrade
> sudo apt-get install r-base r-devel r-cran-rjava
> sudo R CM D javareconf
> 
> 
> Then restart the computer. Or something like that.
> 
> Finally, note that there is a specific mailing list for those running
> R on debian (of which mint is a (n indirect) derivative): see
> https://stat.ethz.ch/mailman/listinfo/r-sig-debian. You may have
> better luck asking your question there.
> 
> Best,
> Ista
> 
> On Thu, Jul 31, 2014 at 8:46 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> Ista Et Al,
>> Unfortunately your suggestion to use remove.packages did exactly the reverse of what you thought would happen.
>> 
>> I have cleaned up my installation but still have trouble getting rJava to install properly and of course that means that XLConnect cannot install either.
>> 
>> -------------------------------------
>> I think this shows that the java-7-openjdk is working.
>> -------------------------------------
>> /home/refserv $ sudo R CMD javareconf
>> Java interpreter : /usr/bin/java
>> Java version     : 1.7.0_55
>> Java home path   : /usr/lib/jvm/java-7-openjdk-i386/jre
>> Java compiler    : /usr/bin/javac
>> Java headers gen.: /usr/bin/javah
>> Java archive tool: /usr/bin/jar
>> 
>> trying to compile and link a JNI progam
>> detected JNI cpp flags    : -I$(JAVA_HOME)/../include
>> detected JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/lib/jvm/java-7-openjdk-i386/jre/../include     -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c conftest.c -o conftest.o
>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o conftest.so conftest.o -L/usr/lib/jvm/java-7-openjdk-i386/jre/lib/i386/client -ljvm -L/usr/lib/R/lib -lR
>> 
>> 
>> JAVA_HOME        : /usr/lib/jvm/java-7-openjdk-i386/jre
>> Java library path: $(JAVA_HOME)/lib/i386/client
>> JNI cpp flags    : -I$(JAVA_HOME)/../include
>> JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
>> Updating Java configuration in /usr/lib/R
>> Done.
>> ___________________________________
>> 
>> 
>> -------------------------------------
>> Purge and re-install rjava
>> -------------------------------------
>> /home/refserv $ sudo apt-get --purge remove r-cran-rjava
>> Reading package lists... Done
>> Building dependency tree
>> Reading state information... Done
>> The following packages will be REMOVED:
>>  r-cran-rjava*
>> 0 upgraded, 0 newly installed, 1 to remove and 3 not upgraded.
>> After this operation, 1,651 kB disk space will be freed.
>> Do you want to continue [Y/n]? y
>> (Reading database ... 173764 files and directories currently installed.)
>> Removing r-cran-rjava ...
>> 
>> /home/refserv $ sudo apt-get install r-cran-rjava
>> Reading package lists... Done
>> Building dependency tree
>> Reading state information... Done
>> The following NEW packages will be installed:
>>  r-cran-rjava
>> 0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.
>> Need to get 0 B/557 kB of archives.
>> After this operation, 1,651 kB of additional disk space will be used.
>> Selecting previously unselected package r-cran-rjava.
>> (Reading database ... 173625 files and directories currently installed.)
>> Unpacking r-cran-rjava (from .../r-cran-rjava_0.9-3-1_i386.deb) ...
>> Setting up r-cran-rjava (0.9-3-1) ...
>> -------------------------------------
>> -------------------------------------
>> 
>> 
>> 
>> -------------------------------------
>> Here I try to install rJava in R
>> but it looks like there is a version problem.
>> 
>> Given I am using openjdk above I am not sure why R is looking at the oracle Java
>> -------------------------------------
>> 
>> home/refserv $ R
>> 
>> R version 3.1.1 (2014-07-10) -- "Sock it to Me"
>> Copyright (C) 2014 The R Foundation for Statistical Computing
>> Platform: i686-pc-linux-gnu (32-bit)
>> 
>> ........................................ (just cutting down on the output)
>> 
>>> require(rJava)
>> Loading required package: rJava
>> Failed with error:  ?package ?rJava? was built before R 3.0.0: please re-install it?
>>> install.packages("rJava")
>> Installing package into ?/home/refserv/R/i686-pc-linux-gnu-library/3.1?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> trying URL 'http://cran.mirrors.hoobly.com/src/contrib/rJava_0.9-6.tar.gz'
>> Content type 'application/x-gzip' length 567515 bytes (554 Kb)
>> opened URL
>> ==================================================
>> downloaded 554 Kb
>> 
>> 
>> ........................................ (just cutting down on the output)
>> 
>> 
>> checking Java support in R... present:
>> interpreter : '/usr/lib/jvm/java-7-oracle/jre/bin/java'
>> archiver    : '/usr/lib/jvm/java-7-oracle/bin/jar'
>> compiler    : '/usr/lib/jvm/java-7-oracle/bin/javac'
>> header prep.: '/usr/lib/jvm/java-7-oracle/bin/javah'
>> cpp flags   : '-I/usr/lib/jvm/java-7-oracle/include -I/usr/lib/jvm/java-7-oracle/include/linux'
>> java libs   : '-L/usr/lib/jvm/java-7-oracle/jre/lib/i386/client -ljvm'
>> checking whether Java run-time works... ./configure: line 3729: /usr/lib/jvm/java-7-oracle/jre/bin/java: No such file or directory
>> no
>> configure: error: Java interpreter '/usr/lib/jvm/java-7-oracle/jre/bin/java' does not work
>> ERROR: configuration failed for package ?rJava?
>> * removing ?/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava?
>> 
>> The downloaded source packages are in
>>        ?/tmp/RtmpwvY4Md/downloaded_packages?
>> Warning message:
>> In install.packages("rJava") :
>>  installation of package ?rJava? had non-zero exit status
>> 
>> -------------------------------------
>> -------------------------------------
>> 
>> Thanks again for your time,
>> Best,
>> KW
>> 
>> 
>> --
>> 
>> On Jul 29, 2014, at 2:22 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> 
>>> On Tue, Jul 29, 2014 at 12:54 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>> Sounds to me like a problem outside of R (off topic here).
>>> 
>>> Possibly, but I suspect that the OP now has two versions of XLConnect
>>> installed, one in the user R library and one in the system-wide R
>>> library.
>>> 
>>> Keith, try
>>> 
>>> remove.packages("XLConnect")
>>> remove.packages("rJava")
>>> 
>>> WITHOUT sudo. Then restart R; you should now get the (working)
>>> system-wide versions of rJava and XLConnect.
>>> 
>>> HTH,
>>> Ista
>>> 
>>> In particular, it doesn't sound like you are using the appropriate
>>> tools (apt-get package manager for R and a JDK; R install.package()
>>> for your R packages) to admin your machine. The only thing you should
>>> need sudo for is to run apt-get... everything else should be done as a
>>> normal user unless you really know what you are doing. I had no
>>> problem installing it just now on my Ubuntu machine with OpenJDK. I
>>> have no experience with Mint but Google tells me you should be able to
>>> use the instructions for Ubuntu... I would expect Google to tell you
>>> the same thing if you ask nicely... your most challenging task at this
>>> point should be cleaning up the mess you have made by excessive use of
>>> sudo ... most likely running R with it (only update your personal R
>>> library directories so you are not tempted to go rogue) but you don't
>>> say how you installed the jdk so that could also be messed up.
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>                                     Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On July 29, 2014 8:19:33 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>>>>> John Et Al.
>>>>> 
>>>>> I can get rJava and XLConnect to work only if I run as super user.
>>>>> 
>>>>> Note that I have built rJava and XLConnect as super user (otherwise
>>>>> neither package works).
>>>>> 
>>>>> 
>>>>> ____________________________________________
>>>>> Without sudo
>>>>> 
>>>>>> require(XLConnect)
>>>>> Loading required package: XLConnect
>>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>>> error: unable to load shared object
>>>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>>> libjvm.so: cannot open shared object file: No such file or directory
>>>>> _____________________________________________
>>>>> With sudo
>>>>> 
>>>>>> require(XLConnect)
>>>>> Loading required package: XLConnect
>>>>> XLConnect 0.2-7 by Mirai Solutions GmbH
>>>>> http://www.mirai-solutions.com ,
>>>>> http://miraisolutions.wordpress.com
>>>>> 
>>>>> ______________________________________________
>>>>> Note that I have changed the ownership (recursively) for rJava and
>>>>> XLConnect because they were previously owned by root. Also note that
>>>>> ggplot2 (included for comparison) was installed the usual way with no
>>>>> problem.
>>>>> 
>>>>> drwxr-xr-x 11 refserv refserv 4096 Jul 24 14:07 ggplot2/
>>>>> drwxr-xr-x 10 refserv refserv 4096 Jul 29 08:28 rJava/
>>>>> drwxr-xr-x 11 refserv refserv 4096 Jul 29 10:09 XLConnect/
>>>>> 
>>>>> ________________________________________________
>>>>> 
>>>>> Despite "no such file or directory" above:
>>>>> 
>>>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava $ ls -altr
>>>>> /home/refserv/>
>>>>> -rwxr-xr-x 1 refserv refserv 273489 Jul 29 08:28
>>>>> /home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so
>>>>> 
>>>>> The file rJava.so exists.
>>>>> 
>>>>> Thanks so much for your time and help,
>>>>> Best,
>>>>> KW
>>>>> 
>>>>> --
>>>>> 
>>>>> On Jul 24, 2014, at 11:16 PM, John McKown
>>>>> <john.archie.mckown at gmail.com> wrote:
>>>>> 
>>>>>> On Thu, Jul 24, 2014 at 8:36 PM, Keith S Weintraub <kw1958 at gmail.com>
>>>>> wrote:
>>>>>>> Folks,
>>>>>>> 
>>>>>>> I have been trying to get XLConnect to work on my Linux Mint Maya
>>>>> machine.
>>>>>>> 
>>>>>>> R works fine but this package doesn't seem to want to build. Here is
>>>>> the message I get after supposedly building XLConnect and rJava:
>>>>>>> 
>>>>>>> 
>>>>>>>>> require(XLConnect)
>>>>>>>> Loading required package: XLConnect
>>>>>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>>>>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>>>>>>> error: unable to load shared object
>>>>> '/home/refserv/R/i686-pc-linux-gnu-library/3.1/rJava/libs/rJava.so':
>>>>>>>> libjvm.so: cannot open shared object file: No such file or
>>>>> directory
>>>>>>> 
>>>>>>> 
>>>>>>> I purged the openJDK and downloaded the 1.7.0_65 JDK form Oracle.
>>>>>>> 
>>>>>>> The build and the compile seemed to work ok as there were no errors.
>>>>> For example I can generate ggplot2 graphs.
>>>>>>> 
>>>>>>> I know this is probably the wrong forum but if someone could gently
>>>>> point me in the right direction I would be very appreciative.
>>>>>>> 
>>>>>>> Thanks so much for your time,
>>>>>>> KW
>>>>>> 
>>>>>> It works fine for me on Fedora 20 (and 19 before it). When I
>>>>> installed
>>>>>> R, it installed into /usr/lib64/R. There exists a file:
>>>>>> /usr/lib64/R/etc/ldpaths which is executed by the R executable
>>>>> script.
>>>>>> This sets up the LD_LIBRARY_PATH to point to the Java installation on
>>>>>> my machine. In the /usr/lib64/R/bin directory, there is a program
>>>>>> called "javareconf". I would suggest that you run this with the -n
>>>>>> switch, like:
>>>>>> 
>>>>>> R CMD /usr/lib64/R/bin/javareconf -n
>>>>>> 
>>>>>> This will show you what it _would_ do if you left off the "-n". Make
>>>>>> sure it looks reasonable. If it does, then run the same command,
>>>>>> without the "-n", as the "root" superuser. In my case, that would be:
>>>>>> 
>>>>>> sudo R CMD /usr/lib64/R/bin/javareconf
>>>>>> 
>>>>>> You need to be "root" because it update the file
>>>>>> /usr/lib64/R/etc/ldpaths . I am fairly sure this will fix your
>>>>>> problem.
>>>>>> 
>>>>>> ===
>>>>>> 
>>>>>> As a possible alternative to XLConnect, have you looked at openxlsx?
>>>>>> It appears to have the same abilities, just some different syntax. It
>>>>>> says that it is written in C and so should be faster than XLConnect.
>>>>> I
>>>>>> have tested both packages, a little, and they both seem to work well.
>>>>>> 
>>>>>> Well, it's 22:14 hours here and I wish that I could fall asleep.
>>>>> We're
>>>>>> having problems at work and I know that the "big boss" will blame us
>>>>>> peons if the hardware isn't fixed promptly Despite the fact that we
>>>>>> are only software people and aren't allowed to touch the hardware.
>>>>> Our
>>>>>> management's minds are not using the same logic as mine does.
>>>>>> Frustrating.
>>>>>> 
>>>>>> --
>>>>>> There is nothing more pleasant than traveling and meeting new people!
>>>>>> Genghis Khan
>>>>>> 
>>>>>> Maranatha! <><
>>>>>> John McKown
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 


From bogaso.christofer at gmail.com  Thu Jul 31 22:16:37 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 1 Aug 2014 02:01:37 +0545
Subject: [R] Working with the Animation package in R
Message-ID: <CA+dpOJmSJW-UtjHds+4M7x8FDODQaMonrgNDJ4Qo1oU4Br=otw@mail.gmail.com>

Hi again,

I am trying to create a animation with Animation package. I preferred
to create animation with HTML file than through GIF because this
requires additional installation of ImageMagick which is not possible
with my system.

So I just run following code available in help page:

saveHTML({
    par(mar = c(4, 4, 0.5, 0.5))
    for (i in 1:20) {
        plot(runif(20), ylim = c(0, 1))
        ani.pause()
    }
}, img.name = "unif_plot", imgdir = "unif_dir", htmlfile =
"random.html", autobrowse = FALSE,
    title = "Demo of 20 uniform random numbers", description = c("This
is a silly example.\n\n",
        "You can describe it in more detail.", "For example, bla bla..."))

How this code will create an HTML file in default folder with name
random.html and underlying image files are placed in unif_dir which is
again in the default folder.

However my goal is to carry this entire animation package to some
other system. As a first try I moved the unif_dir to some other
location. However in that case, the random.html failed to work
properly.

I will really appreciate if someone previously worked with this
package can help me on how I can achieve my goal.


From jguillen at blue-granite.com  Thu Jul 31 20:57:13 2014
From: jguillen at blue-granite.com (Javier Guillen)
Date: Thu, 31 Jul 2014 18:57:13 +0000
Subject: [R] Configuring Rserve for remote access on Windows Server
Message-ID: <e45f25655e28447ab825debde58b6e6d@BLUPR08MB088.namprd08.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/af68faa1/attachment.pl>

From spencer.graves at structuremonitoring.com  Thu Jul 31 23:56:29 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 31 Jul 2014 14:56:29 -0700
Subject: [R] Working with the Animation package in R
In-Reply-To: <CA+dpOJmSJW-UtjHds+4M7x8FDODQaMonrgNDJ4Qo1oU4Br=otw@mail.gmail.com>
References: <CA+dpOJmSJW-UtjHds+4M7x8FDODQaMonrgNDJ4Qo1oU4Br=otw@mail.gmail.com>
Message-ID: <53DABB8D.3080903@structuremonitoring.com>

On 7/31/2014 1:16 PM, Christofer Bogaso wrote:
> Hi again,
>
> I am trying to create a animation with Animation package. I preferred
> to create animation with HTML file than through GIF because this
> requires additional installation of ImageMagick which is not possible
> with my system.
>
> So I just run following code available in help page:
>
> saveHTML({
>      par(mar = c(4, 4, 0.5, 0.5))
>      for (i in 1:20) {
>          plot(runif(20), ylim = c(0, 1))
>          ani.pause()
>      }
> }, img.name = "unif_plot", imgdir = "unif_dir", htmlfile =
> "random.html", autobrowse = FALSE,
>      title = "Demo of 20 uniform random numbers", description = c("This
> is a silly example.\n\n",
>          "You can describe it in more detail.", "For example, bla bla..."))
>
> How this code will create an HTML file in default folder with name
> random.html and underlying image files are placed in unif_dir which is
> again in the default folder.
>
> However my goal is to carry this entire animation package to some
> other system. As a first try I moved the unif_dir to some other
> location. However in that case, the random.html failed to work
> properly.
>
> I will really appreciate if someone previously worked with this
> package can help me on how I can achieve my goal.

       I can't help with "animation", but other packages might help with 
animation, depending on what you want.


             * sliderInput{shiny} includes an "animate" argument.


             * animate{raster} sequentially plots the layers of a 
RasterStack or RasterBrick* object to create a movie.


       I tried saveVideo{animate} and could not make it work to produce 
what I want.  It calls FFmpeg.  I ultimately subscribed to the FFmpeg 
help list to learn how to use that to do what I wanted. This involved 
creating sequences of png files, each potentially a little different 
from previous ones.  To make this easier, I wrote Animate{Ecfun}.  This 
latter is not yet available on CRAN but is available on R-Forge via 
install.packages("Ecfun", repos="http://R-Forge.R-project.org").  [I'm 
scheduled to talk about this on August 12 at the San Francisco Bay Area 
useR Meetup; "www.meetup.com/R-Users".]


       Hope this helps.
       Spencer

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


