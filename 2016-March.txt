From alnazer.elbedairy at gmail.com  Tue Mar  1 00:49:52 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Mon, 29 Feb 2016 15:49:52 -0800
Subject: [R] help in KNN
Message-ID: <CAD2s_FQR12xuEVR39vVmh71v0XzT1s_-8Es+ubQiRc5mQmAqSQ@mail.gmail.com>

dear all
attached you will find a csv datasets, there are many steps before these
they work properly. but I have errors in these steps I guess. any help
appreciated.

Step1: convert the data from continuous to categorical

##nautodata is the normalized data. I did it in the previous steps.

MPGCat= c(0,10,15,20,25,30, 35, 40)
MPG <- cut(nautodata$mydata.MPG, MPGCat,labels = c(1:7))
nautodata = data.frame(MPG, nautodata[2:7])
nautodata


Step 2: divided into 10 folds: as follow


fold1= nautodata[1:39,]
fold2= nautodata[40:79,]
fold3= nautodata[80:119,]
fold4= nautodata[120:159,]
fold5= nautodata[160:199,]
fold6= nautodata[200:139,]
fold7= nautodata[240:279,]
fold8= nautodata[280:319,]
fold9= nautodata[320:359,]
fold10= nautodata[360:398,]

datafolds= list(fold1, fold2, fold3, fold4,
fold5,fold6,fold7,fold8,fold9,fold10)

step3:
##conduct 10-fold cross validation on KNN

KNNFoldError= c(0,0,0,0,0,0,0,0,0,0)
MGFoldError=  c(0,0,0,0,0,0,0,0,0,0)

for (i in 1:10)
{
trainData = NULL
for(j in 1:10)
{
  if(i !=j)
    {
     trainData = rbind(trainData, datafolds[[j]])
    }
  else
    testData = datafolds[[j]]
}
#print (trainData)
#print(testData)
  targetData = trainData$MPG
  testTargetData = testData$MPG

  trainData$MPG= NULL
  testData$MPG = NULL

  M1 = knn(train=trainData, test=testData, cl=targetData, k=20)
  M2 = MajorityGuessing(testData,MPGCat)
  print(table(testTargetData,M1))
  print(testTargetData)
  print(M1)
  print(M2)

  KNNFoldError[i] = round(mean(testTargetData != M1), 3)
  MGFoldError[i] = round(mean(testTargetData != M2), 3)
  print(KNNFoldError)
  print(MGFoldError)
}

## these are the error I got:
Quitting from lines 80-86 (Lab3 at M.Rmd)
Error in cut.default(nautodata$mydata.MPG, MPGCat, labels = c(1:7)) :
  'x' must be numeric
Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval
-> cut -> cut.default
Execution halted

From John.Janmaat at ubc.ca  Tue Mar  1 05:53:43 2016
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Tue, 1 Mar 2016 04:53:43 +0000
Subject: [R] Copula Regression
In-Reply-To: <063E7F85C84B8C44A6D1A1C47E8728761BCC35DB@exch-ok-mbx01p.ead.ubc.ca>
References: <063E7F85C84B8C44A6D1A1C47E8728761BCC35DB@exch-ok-mbx01p.ead.ubc.ca>
Message-ID: <36e810c0-b288-4f9c-9593-cccd9911afb0@EXCH-OK-HUB02P.ead.ubc.ca>

Well, seem to have solved own problem.

The article "Enjoy the joy of copulas: with a package copula" has a nice appendix that describes precisely how to set up what I am looking for.  The only minor issue is that some of the functions have been deprecated.

So, if anyone is curious, here is the article info (in BibTeX):

@Article{YanJ_2007_CopulasR,
  title={Enjoy the joy of copulas: with a package copula},
  author={Yan, Jun and others},
  journal={Journal of Statistical Software},
  volume={21},
  number={4},
  pages={1--21},
  year={2007}
}

John.

----------
Dr. John Janmaat
Economics (Unit 8), IK Barber School of Arts and Sciences
The University of British Columbia
3333 University Way, Kelowna, BC


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Janmaat, John
Sent: February-29-16 2:55 PM
To: 'r-help at r-project.org'
Subject: [R] Copula Regression

Hello,

I'm trying to figure out how to run copula regressions in R.  I see a couple of packages that do specific versions, but I am hoping to be a bit more flexible.

My specific problem involves two ordered regressions (four levels each) that may be correlated.  Is there a package out there that can do copula regressions with arbitrary marginals?  Alternatively, is there a way to trick functions like GLM into returning observation specific CDF values given a guess for the parameters?

I would prefer to avoid coding this up, as I expect the more tested code I can use, the less likelihood for my own errors to mess up the results.

Thanks,

John.

----------
Dr. John Janmaat
Economics (Unit 8), IK Barber School of Arts and Sciences The University of British Columbia
3333 University Way, Kelowna, BC


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Eric.Hu at gilead.com  Tue Mar  1 01:34:28 2016
From: Eric.Hu at gilead.com (Eric Hu)
Date: Tue, 1 Mar 2016 00:34:28 +0000
Subject: [R] read.alignment() crashes
Message-ID: <7e0adeef240c48d2ab0ffa18159b3eba@FCEXC13PRDN07.na.gilead.com>

Hi, I am trying to read a fasta file with >15K alignedd sequences. However it crashes showing a runtime error. I have tried both R.3.2.3 and R.3.2.1 under windows 7. A smaller fasta file works perfectly fine in either case.

library(seqinr)
myseqs <- read.alignment("aligned_seqs.fasta",format="fasta")

Thanks,
Eric


	[[alternative HTML version deleted]]


From putra_autumn86 at yahoo.com  Tue Mar  1 07:39:17 2016
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Tue, 1 Mar 2016 06:39:17 +0000 (UTC)
Subject: [R] Change NA value into 0
References: <1855241620.1177070.1456814357853.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1855241620.1177070.1456814357853.JavaMail.yahoo@mail.yahoo.com>

Hi R-users,
I have problem regarding my function. My function as below:
gen.m <- function(n,itr){

??? set.seed(1234)
??? 
??? m <- matrix(nrow = n, ncol=4)
?????? a <- matrix(nrow = n, ncol = 1) 
?????? b <- matrix(nrow = n, ncol = 1) 
?????? C <- matrix(nrow = n, ncol = 1) 
?????? d <- matrix(nrow = n, ncol = 1) 
? lambda <- 0.342
??? day0 <- 0.1134
?? 
????? x = matrix(runif(n*itr, 0, 1),nrow = n, ncol = itr)

? y = 0
? for(i in 1:n){
??? a[i] = x[i,1]
??? b[i] = y - (log (a[i])) / lambda
?????? y =? b[i]
??? }

? if (a[1] < day0){
??? C[1] = 0
??? }else{
??? C[1] = 1}
??? 
??? for (i in 1:n){
?????? w = as.integer(b[i])
?????? if (w <= n){
???????? C[w] = 1
???????? }else{
???????? C[w] = 0}
???? }
??? 
? 
??? for (i in 2:n)
?????? rain2 <- cbind(a,b,C,d)
?????? y <- cbind(a,b,C)
?????? return(y)
?? }


? gen.m(31,10)

When i run my output, it gave the result NA. I want the NA values is zero. Hope anyone can help me. Thanks so much.

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Mar  1 07:44:22 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 1 Mar 2016 07:44:22 +0100
Subject: [R] read.alignment() crashes
In-Reply-To: <7e0adeef240c48d2ab0ffa18159b3eba@FCEXC13PRDN07.na.gilead.com>
References: <7e0adeef240c48d2ab0ffa18159b3eba@FCEXC13PRDN07.na.gilead.com>
Message-ID: <56D53A46.3050704@statistik.tu-dortmund.de>



On 01.03.2016 01:34, Eric Hu wrote:
> Hi, I am trying to read a fasta file with >15K alignedd sequences. However it crashes showing a runtime error. I have tried both R.3.2.3 and R.3.2.1 under windows 7. A smaller fasta file works perfectly fine in either case.
>
> library(seqinr)
> myseqs <- read.alignment("aligned_seqs.fasta",format="fasta")

Just an error message or a crash?
In case of an error message: report it. In case of a crash: Report to 
the seqinr maintainer with a reproducible example.

Best,
Uwe Ligges


>
> Thanks,
> Eric
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Mar  1 07:46:39 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 1 Mar 2016 07:46:39 +0100
Subject: [R] Change NA value into 0
In-Reply-To: <1855241620.1177070.1456814357853.JavaMail.yahoo@mail.yahoo.com>
References: <1855241620.1177070.1456814357853.JavaMail.yahoo.ref@mail.yahoo.com>
	<1855241620.1177070.1456814357853.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56D53ACF.7090105@statistik.tu-dortmund.de>

You do

   for(i in 1:n){
     a[i] = x[i,1]

where a has length n and x has iter rows, hence you get NA values for 
all i > iter...

Best,
Uwe Ligges



On 01.03.2016 07:39, smart hendsome via R-help wrote:
> Hi R-users,
> I have problem regarding my function. My function as below:
> gen.m <- function(n,itr){
>
>      set.seed(1234)
>
>      m <- matrix(nrow = n, ncol=4)
>         a <- matrix(nrow = n, ncol = 1)
>         b <- matrix(nrow = n, ncol = 1)
>         C <- matrix(nrow = n, ncol = 1)
>         d <- matrix(nrow = n, ncol = 1)
>    lambda <- 0.342
>      day0 <- 0.1134
>
>        x = matrix(runif(n*itr, 0, 1),nrow = n, ncol = itr)
>
>    y = 0
>    for(i in 1:n){
>      a[i] = x[i,1]
>      b[i] = y - (log (a[i])) / lambda
>         y =  b[i]
>      }
>
>    if (a[1] < day0){
>      C[1] = 0
>      }else{
>      C[1] = 1}
>
>      for (i in 1:n){
>         w = as.integer(b[i])
>         if (w <= n){
>           C[w] = 1
>           }else{
>           C[w] = 0}
>       }
>
>
>      for (i in 2:n)
>         rain2 <- cbind(a,b,C,d)
>         y <- cbind(a,b,C)
>         return(y)
>     }
>
>
>    gen.m(31,10)
>
> When i run my output, it gave the result NA. I want the NA values is zero. Hope anyone can help me. Thanks so much.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Mar  1 07:51:08 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 1 Mar 2016 07:51:08 +0100
Subject: [R] help in KNN
In-Reply-To: <CAD2s_FQR12xuEVR39vVmh71v0XzT1s_-8Es+ubQiRc5mQmAqSQ@mail.gmail.com>
References: <CAD2s_FQR12xuEVR39vVmh71v0XzT1s_-8Es+ubQiRc5mQmAqSQ@mail.gmail.com>
Message-ID: <56D53BDC.4090309@statistik.tu-dortmund.de>

Hmmm, this pretty much looks like homework this list is not intended 
for. Please ask your supervisor/teacher why nautodata$mydata.MPG is not 
numeric if you cannot find that out yourself.

Best,
Uwe Ligges

On 01.03.2016 00:49, Alnazer Elbedairy wrote:
> dear all
> attached you will find a csv datasets, there are many steps before these
> they work properly. but I have errors in these steps I guess. any help
> appreciated.
>
> Step1: convert the data from continuous to categorical
>
> ##nautodata is the normalized data. I did it in the previous steps.
>
> MPGCat= c(0,10,15,20,25,30, 35, 40)
> MPG <- cut(nautodata$mydata.MPG, MPGCat,labels = c(1:7))
> nautodata = data.frame(MPG, nautodata[2:7])
> nautodata
>
>
> Step 2: divided into 10 folds: as follow
>
>
> fold1= nautodata[1:39,]
> fold2= nautodata[40:79,]
> fold3= nautodata[80:119,]
> fold4= nautodata[120:159,]
> fold5= nautodata[160:199,]
> fold6= nautodata[200:139,]
> fold7= nautodata[240:279,]
> fold8= nautodata[280:319,]
> fold9= nautodata[320:359,]
> fold10= nautodata[360:398,]
>
> datafolds= list(fold1, fold2, fold3, fold4,
> fold5,fold6,fold7,fold8,fold9,fold10)
>
> step3:
> ##conduct 10-fold cross validation on KNN
>
> KNNFoldError= c(0,0,0,0,0,0,0,0,0,0)
> MGFoldError=  c(0,0,0,0,0,0,0,0,0,0)
>
> for (i in 1:10)
> {
> trainData = NULL
> for(j in 1:10)
> {
>    if(i !=j)
>      {
>       trainData = rbind(trainData, datafolds[[j]])
>      }
>    else
>      testData = datafolds[[j]]
> }
> #print (trainData)
> #print(testData)
>    targetData = trainData$MPG
>    testTargetData = testData$MPG
>
>    trainData$MPG= NULL
>    testData$MPG = NULL
>
>    M1 = knn(train=trainData, test=testData, cl=targetData, k=20)
>    M2 = MajorityGuessing(testData,MPGCat)
>    print(table(testTargetData,M1))
>    print(testTargetData)
>    print(M1)
>    print(M2)
>
>    KNNFoldError[i] = round(mean(testTargetData != M1), 3)
>    MGFoldError[i] = round(mean(testTargetData != M2), 3)
>    print(KNNFoldError)
>    print(MGFoldError)
> }
>
> ## these are the error I got:
> Quitting from lines 80-86 (Lab3 at M.Rmd)
> Error in cut.default(nautodata$mydata.MPG, MPGCat, labels = c(1:7)) :
>    'x' must be numeric
> Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval
> -> cut -> cut.default
> Execution halted
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Tue Mar  1 08:07:48 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 1 Mar 2016 07:07:48 +0000
Subject: [R] create function for compare two dataframe.
In-Reply-To: <CA+Tq-Roy+qbXRdy_x4p5qGN7L+jm__LNVqX03koy3GewsQAFwA@mail.gmail.com>
References: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BB5@SRVEXCHMBX.precheza.cz>
	<CA+Tq-Roy+qbXRdy_x4p5qGN7L+jm__LNVqX03koy3GewsQAFwA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011E23@SRVEXCHMBX.precheza.cz>

Hi

You said

When I asked this question, I used indent for readability.
So maybe it was added extra space.
I executed same command. It has no extra space.

> str(s1)
'data.frame':    3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  2 0 0
 $ VAL2: int  2 3 2
 $ VAL3: int  3 3 4
> str(s2)
'data.frame':    3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  0 0 0
 $ VAL2: int  2 2 2
 $ VAL3: int  3 3 2

That is why dput(s1) is always preferable for exchanging data instead of text in ***HTML formated*** mail.

Cheers
Petr


From: Hiroyuki Sato [mailto:hiroysato at gmail.com]
Sent: Monday, February 29, 2016 12:04 PM
To: PIKAL Petr; r-help at r-project.org
Subject: Re: [R] create function for compare two dataframe.


Hello Petr.

Thank you for replying.
Your step is better than my step!.

I added one step

> s.dcast <- dcast(s.m, ID+variable~dat)
> subset(s.dcast,df1!=df2)
   ID variable df1 df2
1 ID1     VAL1   2   0
5 ID2     VAL2   3   2
9 ID3     VAL3   4   2

This output is what I wanted!!.


P.S.

When I asked this question, I used indent for readability.
So maybe it was added extra space.
I executed same command. It has no extra space.

> str(s1)
'data.frame':  3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  2 0 0
 $ VAL2: int  2 3 2
 $ VAL3: int  3 3 4
> str(s2)
'data.frame':  3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  0 0 0
 $ VAL2: int  2 2 2
 $ VAL3: int  3 3 2

Best regards.


2016?2?29?(?) 18:16 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:
Hi

You does not need to create function, you can use functions already available.

> s1<- read.table("clipboard", header=T, sep=",")
> s2<- read.table("clipboard", sep=",")

You presented second table without names.
> names(s2) <- names(s1)

> s1
     ID VAL1 VAL2 VAL3
1   ID1    2    2    3
2   ID2    0    3    3
3   ID3    0    2    4
> s2
     ID VAL1 VAL2 VAL3
1   ID1    0    2    3
2   ID2    0    2    3
3   ID3    0    2    2

You need to add a column in which you specify data frame and merge them
> s1$dat<-"df1"
> s2$dat<-"df2"
> s<-merge(s1,s2, all=T)

Now you need to reshape your data

> library(reshape2)

> s.m<-melt(s)
Using ID, dat as id variables
> s.m
      ID dat variable value
1    ID1 df1     VAL1     2
2    ID2 df2     VAL1     0
3    ID2 df1     VAL1     0
4    ID3 df2     VAL1     0
5    ID3 df1     VAL1     0
6    ID1 df2     VAL1     0
7    ID1 df1     VAL2     2
8    ID2 df2     VAL2     2
9    ID2 df1     VAL2     3
10   ID3 df2     VAL2     2
11   ID3 df1     VAL2     2
12   ID1 df2     VAL2     2
13   ID1 df1     VAL3     3
14   ID2 df2     VAL3     3
15   ID2 df1     VAL3     3
16   ID3 df2     VAL3     2
17   ID3 df1     VAL3     4
18   ID1 df2     VAL3     3

And cast the new structure.
> dcast(s.m, ID+variable~dat)
      ID variable df1 df2
1    ID1     VAL1   2  NA
2    ID1     VAL2   2  NA
3    ID1     VAL3   3  NA
4    ID2     VAL1   0   0
5    ID2     VAL2   3   2
6    ID2     VAL3   3   3
7    ID3     VAL1   0   0
8    ID3     VAL2   2   2
9    ID3     VAL3   4   2
10   ID1     VAL1  NA   0
11   ID1     VAL2  NA   2
12   ID1     VAL3  NA   3

This was the point that I was rather surprised but I found a reason. Your ID variable does not have 3 but four values - although ID1 looks the same, in one there is an extra space, therefore you have different ID1 in s1 from ID1 in s2.

That is why it is recommended to use dput() for exchanging data with others.

> str(s)
'data.frame':   6 obs. of  5 variables:
 $ ID  : Factor w/ 4 levels "  ID1","  ID2",..: 1 2 2 3 3 4
 $ VAL1: int  2 0 0 0 0 0
 $ VAL2: int  2 2 3 2 2 2
 $ VAL3: int  3 3 3 2 4 3
 $ dat : chr  "df1" "df2" "df1" "df2" ...

> s1$ID
[1]   ID1   ID2   ID3
Levels:   ID1   ID2   ID3
> s2$ID
[1] ID1     ID2   ID3
Levels:   ID2   ID3 ID1

> str(s1)
'data.frame':   3 obs. of  5 variables:
 $ ID  : Factor w/ 3 levels "  ID1","  ID2",..: 1 2 3
 $ VAL1: int  2 0 0
 $ VAL2: int  2 3 2
 $ VAL3: int  3 3 4
 $ dat : chr  "df1" "df1" "df1"
> str(s2)
'data.frame':   3 obs. of  5 variables:
 $ ID  : Factor w/ 3 levels "  ID2","  ID3",..: 3 1 2
 $ VAL1: int  0 0 0
 $ VAL2: int  2 2 2
 $ VAL3: int  3 3 2
 $ dat : chr  "df2" "df2" "df2"
>

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of
> Hiroyuki Sato
> Sent: Monday, February 29, 2016 9:44 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] create function for compare two dataframe.
>
> Hello
>
> I would like to create a funciton which is create new dataframe for
> compare reslut of two dataframes.
>
>   No.  COLUMN DF1  DF2
>   "1"  "VAL1" "2"  "0" # <- compare ID1,VAL1
>   "2"  "VAL2" "3"  "2" # <- comapre ID2,VAL2
>   "3"  "VAL3" "4"  "2" # <- compare ID3,VAL3
>
> s1 <- read.table("sample1.txt",header=T,sep=',')
> s2 <- read.table("sample2.txt",header=T,sep=',')
> comp_data(df1,df2)
>
> sample1.txt
>   ID,VAL1,VAL2,VAL3
>   ID1,2,2,3
>   ID2,0,3,3
>   ID3,0,2,4
>
> sample2.txt
>   ID1,0,2,3
>   ID2,0,2,3
>   ID3,0,2,2
>
> I created the functions, but I got the following error.
> Could you tell me how to add new frame data?
> Or alternative way?
>
>   1: In `[<-.factor`(`*tmp*`, ri, value = "3") :
>     invalid factor level, NA generated
>   2: In `[<-.factor`(`*tmp*`, ri, value = "VAL3") :
>     invalid factor level, NA generated
>   3: In `[<-.factor`(`*tmp*`, ri, value = "4") :
>     invalid factor level, NA generated
>
>
>
>   comp_data <- function(df1,df2) {
>     #
>     # create null data.frame
>     out <- data.frame(matrix(rep(NA,4),nrow=1))[numeric(0), ]
>     colnames(out) <- c("ID","Site","df1","df2")
>
>     # column names
>     col_names <- colnames(df1)
>
>     # col_size
>     col_size <- ncol(df1)
>     row_size <- nrow(df1)
>
>     for( col in 2:col_size ){
>       for( row in 1:row_size ){
>         if( df1[row,col] != df2[row,col] ){
>           out <-
> rbind(out,c(df1[row,1],col_names[col],df1[row,col],df2[row,col]))
>         }
>       }
>     }
>     out
>   }
>
> Best regards.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From hiroysato at gmail.com  Tue Mar  1 08:13:21 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Tue, 01 Mar 2016 07:13:21 +0000
Subject: [R] create function for compare two dataframe.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011E23@SRVEXCHMBX.precheza.cz>
References: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BB5@SRVEXCHMBX.precheza.cz>
	<CA+Tq-Roy+qbXRdy_x4p5qGN7L+jm__LNVqX03koy3GewsQAFwA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011E23@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+Tq-Rpveivp7UPSeLbiv=6nkozAWDpq5zUC-feJkODuAQg5hg@mail.gmail.com>

Hello Petr

I'll send mail with plain text format at next time.
(I didn't know how to send plain text mail on gmail)

Thanks.



2016?3?1?(?) 16:07 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
>
>
> You said
>
>
>
> When I asked this question, I used indent for readability.
>
> So maybe it was added extra space.
>
> I executed same command. It has no extra space.
>
>
>
> > str(s1)
>
> 'data.frame':    3 obs. of  4 variables:
>
>  $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
>
>  $ VAL1: int  2 0 0
>
>  $ VAL2: int  2 3 2
>
>  $ VAL3: int  3 3 4
>
> > str(s2)
>
> 'data.frame':    3 obs. of  4 variables:
>
>  $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
>
>  $ VAL1: int  0 0 0
>
>  $ VAL2: int  2 2 2
>
>  $ VAL3: int  3 3 2
>
>
>
> That is why dput(s1) is always preferable for exchanging data instead of
> text in ***HTML formated*** mail.
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* Hiroyuki Sato [mailto:hiroysato at gmail.com]
> *Sent:* Monday, February 29, 2016 12:04 PM
> *To:* PIKAL Petr; r-help at r-project.org
> *Subject:* Re: [R] create function for compare two dataframe.
>
>
>
>
>
> Hello Petr.
>
>
>
> Thank you for replying.
>
> Your step is better than my step!.
>
>
>
> I added one step
>
>
>
> > s.dcast <- dcast(s.m, ID+variable~dat)
>
> > subset(s.dcast,df1!=df2)
>
>    ID variable df1 df2
>
> 1 ID1     VAL1   2   0
>
> 5 ID2     VAL2   3   2
>
> 9 ID3     VAL3   4   2
>
>
>
> This output is what I wanted!!.
>
>
>
>
>
> P.S.
>
>
>
> When I asked this question, I used indent for readability.
>
> So maybe it was added extra space.
>
> I executed same command. It has no extra space.
>
>
>
> > str(s1)
>
> 'data.frame':  3 obs. of  4 variables:
>
>  $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
>
>  $ VAL1: int  2 0 0
>
>  $ VAL2: int  2 3 2
>
>  $ VAL3: int  3 3 4
>
> > str(s2)
>
> 'data.frame':  3 obs. of  4 variables:
>
>  $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
>
>  $ VAL1: int  0 0 0
>
>  $ VAL2: int  2 2 2
>
>  $ VAL3: int  3 3 2
>
>
>
> Best regards.
>
>
>
>
>
> 2016?2?29?(?) 18:16 PIKAL Petr <petr.pikal at precheza.cz>:
>
> Hi
>
> You does not need to create function, you can use functions already
> available.
>
> > s1<- read.table("clipboard", header=T, sep=",")
> > s2<- read.table("clipboard", sep=",")
>
> You presented second table without names.
> > names(s2) <- names(s1)
>
> > s1
>      ID VAL1 VAL2 VAL3
> 1   ID1    2    2    3
> 2   ID2    0    3    3
> 3   ID3    0    2    4
> > s2
>      ID VAL1 VAL2 VAL3
> 1   ID1    0    2    3
> 2   ID2    0    2    3
> 3   ID3    0    2    2
>
> You need to add a column in which you specify data frame and merge them
> > s1$dat<-"df1"
> > s2$dat<-"df2"
> > s<-merge(s1,s2, all=T)
>
> Now you need to reshape your data
>
> > library(reshape2)
>
> > s.m<-melt(s)
> Using ID, dat as id variables
> > s.m
>       ID dat variable value
> 1    ID1 df1     VAL1     2
> 2    ID2 df2     VAL1     0
> 3    ID2 df1     VAL1     0
> 4    ID3 df2     VAL1     0
> 5    ID3 df1     VAL1     0
> 6    ID1 df2     VAL1     0
> 7    ID1 df1     VAL2     2
> 8    ID2 df2     VAL2     2
> 9    ID2 df1     VAL2     3
> 10   ID3 df2     VAL2     2
> 11   ID3 df1     VAL2     2
> 12   ID1 df2     VAL2     2
> 13   ID1 df1     VAL3     3
> 14   ID2 df2     VAL3     3
> 15   ID2 df1     VAL3     3
> 16   ID3 df2     VAL3     2
> 17   ID3 df1     VAL3     4
> 18   ID1 df2     VAL3     3
>
> And cast the new structure.
> > dcast(s.m, ID+variable~dat)
>       ID variable df1 df2
> 1    ID1     VAL1   2  NA
> 2    ID1     VAL2   2  NA
> 3    ID1     VAL3   3  NA
> 4    ID2     VAL1   0   0
> 5    ID2     VAL2   3   2
> 6    ID2     VAL3   3   3
> 7    ID3     VAL1   0   0
> 8    ID3     VAL2   2   2
> 9    ID3     VAL3   4   2
> 10   ID1     VAL1  NA   0
> 11   ID1     VAL2  NA   2
> 12   ID1     VAL3  NA   3
>
> This was the point that I was rather surprised but I found a reason. Your
> ID variable does not have 3 but four values - although ID1 looks the same,
> in one there is an extra space, therefore you have different ID1 in s1 from
> ID1 in s2.
>
> That is why it is recommended to use dput() for exchanging data with
> others.
>
> > str(s)
> 'data.frame':   6 obs. of  5 variables:
>  $ ID  : Factor w/ 4 levels "  ID1","  ID2",..: 1 2 2 3 3 4
>  $ VAL1: int  2 0 0 0 0 0
>  $ VAL2: int  2 2 3 2 2 2
>  $ VAL3: int  3 3 3 2 4 3
>  $ dat : chr  "df1" "df2" "df1" "df2" ...
>
> > s1$ID
> [1]   ID1   ID2   ID3
> Levels:   ID1   ID2   ID3
> > s2$ID
> [1] ID1     ID2   ID3
> Levels:   ID2   ID3 ID1
>
> > str(s1)
> 'data.frame':   3 obs. of  5 variables:
>  $ ID  : Factor w/ 3 levels "  ID1","  ID2",..: 1 2 3
>  $ VAL1: int  2 0 0
>  $ VAL2: int  2 3 2
>  $ VAL3: int  3 3 4
>  $ dat : chr  "df1" "df1" "df1"
> > str(s2)
> 'data.frame':   3 obs. of  5 variables:
>  $ ID  : Factor w/ 3 levels "  ID2","  ID3",..: 3 1 2
>  $ VAL1: int  0 0 0
>  $ VAL2: int  2 2 2
>  $ VAL3: int  3 3 2
>  $ dat : chr  "df2" "df2" "df2"
> >
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Hiroyuki Sato
> > Sent: Monday, February 29, 2016 9:44 AM
> > To: r-help at r-project.org
> > Subject: [R] create function for compare two dataframe.
> >
> > Hello
> >
> > I would like to create a funciton which is create new dataframe for
> > compare reslut of two dataframes.
> >
> >   No.  COLUMN DF1  DF2
> >   "1"  "VAL1" "2"  "0" # <- compare ID1,VAL1
> >   "2"  "VAL2" "3"  "2" # <- comapre ID2,VAL2
> >   "3"  "VAL3" "4"  "2" # <- compare ID3,VAL3
> >
> > s1 <- read.table("sample1.txt",header=T,sep=',')
> > s2 <- read.table("sample2.txt",header=T,sep=',')
> > comp_data(df1,df2)
> >
> > sample1.txt
> >   ID,VAL1,VAL2,VAL3
> >   ID1,2,2,3
> >   ID2,0,3,3
> >   ID3,0,2,4
> >
> > sample2.txt
> >   ID1,0,2,3
> >   ID2,0,2,3
> >   ID3,0,2,2
> >
> > I created the functions, but I got the following error.
> > Could you tell me how to add new frame data?
> > Or alternative way?
> >
> >   1: In `[<-.factor`(`*tmp*`, ri, value = "3") :
> >     invalid factor level, NA generated
> >   2: In `[<-.factor`(`*tmp*`, ri, value = "VAL3") :
> >     invalid factor level, NA generated
> >   3: In `[<-.factor`(`*tmp*`, ri, value = "4") :
> >     invalid factor level, NA generated
> >
> >
> >
> >   comp_data <- function(df1,df2) {
> >     #
> >     # create null data.frame
> >     out <- data.frame(matrix(rep(NA,4),nrow=1))[numeric(0), ]
> >     colnames(out) <- c("ID","Site","df1","df2")
> >
> >     # column names
> >     col_names <- colnames(df1)
> >
> >     # col_size
> >     col_size <- ncol(df1)
> >     row_size <- nrow(df1)
> >
> >     for( col in 2:col_size ){
> >       for( row in 1:row_size ){
> >         if( df1[row,col] != df2[row,col] ){
> >           out <-
> > rbind(out,c(df1[row,1],col_names[col],df1[row,col],df2[row,col]))
> >         }
> >       }
> >     }
> >     out
> >   }
> >
> > Best regards.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From b.h.mevik at usit.uio.no  Tue Mar  1 09:26:25 2016
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Tue, 01 Mar 2016 09:26:25 +0100
Subject: [R] Version 3.2.3: package not available error with https
In-Reply-To: <87io17tzf3.fsf@hornfels.zedat.fu-berlin.de> (Loris Bennett's
	message of "Mon, 29 Feb 2016 14:32:32 +0100")
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
	<56D43BD5.2020102@gmail.com>
	<87io17tzf3.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <s3s60x67gem.fsf@varelg.uio.no>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> It seems that R needs libcurl 7.28.0, but my platform (Scientific Linux
> 6.7) only provides version 7.19.7.

We got "bit" by this when upgrading to 3.2.2.  If you cannot upgrade
libcurl on your machine(s), you can put

local({
    options(useHTTPS = FALSE)
})

in the Rprofile.site file, or your ~/.Rprofile.  You still get a
warning, but you do get the list of http repositories.

Come to think about it: would it be an idea if R defaulted to useHTTPS =
FALSE if capabilites("libcur") is FALSE?

-- 
Regards,
Bj?rn-Helge Mevik


From loris.bennett at fu-berlin.de  Tue Mar  1 10:20:08 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 1 Mar 2016 10:20:08 +0100
Subject: [R] Version 3.2.3: package not available error with https
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
	<56D43BD5.2020102@gmail.com>
	<87io17tzf3.fsf@hornfels.zedat.fu-berlin.de>
	<s3s60x67gem.fsf@varelg.uio.no>
Message-ID: <87io165zcn.fsf@hornfels.zedat.fu-berlin.de>

Hi Bj?rn-Helge,

Bj?rn-Helge Mevik <b.h.mevik at usit.uio.no> writes:

> Loris Bennett <loris.bennett at fu-berlin.de> writes:
>
>> It seems that R needs libcurl 7.28.0, but my platform (Scientific Linux
>> 6.7) only provides version 7.19.7.
>
> We got "bit" by this when upgrading to 3.2.2.  If you cannot upgrade
> libcurl on your machine(s), you can put
>
> local({
>     options(useHTTPS = FALSE)
> })
>
> in the Rprofile.site file, or your ~/.Rprofile.  You still get a
> warning, but you do get the list of http repositories.

Thanks for the hint.  I think I'll use the setting Rprofile.site for the
time being until we get an update of libcurl.

> Come to think about it: would it be an idea if R defaulted to useHTTPS =
> FALSE if capabilites("libcur") is FALSE?

+1

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From careyshan at gmail.com  Tue Mar  1 10:54:12 2016
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 1 Mar 2016 09:54:12 +0000
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <CANVKczOj4hxNGp9xGN38wMxbZFv0mLzHSJh2gM82tTinOQgMHA@mail.gmail.com>
References: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
	<CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>
	<CA+jRDxBwYasEFBjvEE7xxtqPmMyofqX_vGNtTiRx57KyH9izkg@mail.gmail.com>
	<3d15e142d9804f4b89ac3cf4090e00d6@EX-0-HT0.lancs.local>
	<CANVKczOj4hxNGp9xGN38wMxbZFv0mLzHSJh2gM82tTinOQgMHA@mail.gmail.com>
Message-ID: <CA+jRDxBDF6wix2bMdS1=JBzaFursV5fReaVKv_s_mEUD7ECfBA@mail.gmail.com>

This is super, thanks!! However, I cannot read in my shapefile. I am using
readShapeSpatial and the error I receive is: Error in getinfo.shape(fn):
Error opening SHP file. The projection is Irish Transverse Mercator!!


Thanks in advance

On Mon, Feb 29, 2016 at 6:35 PM, Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> This probably on the limit of acceptable LOCs on this list but here goes:
>
> makeVchopper <- function(pol){
>     bb = bbox(pol)
>     delta = (bb[2,2] - bb[2,1])/10
>     xmin = bb[1,1]-delta
>     ymin = bb[2,1]-delta
>     ymax = bb[2,2]+delta
>
>     choppoly = function(xmax){
>         readWKT(sprintf("POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))",
>                         xmin,ymin, xmin,ymax, xmax,ymax, xmax,ymin,
> xmin,ymin))
>     }
>     choppoly
> }
>
> slicer <- function(pol, xmin, xmax){
>     bb = bbox(pol)
>     delta = (bb[2,2] - bb[2,1])/10
>     ymax = bb[2,2] + delta
>     ymin = bb[2,1] - delta
>     r = readWKT(sprintf("POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))",
>         xmin,ymin, xmin,ymax, xmax,ymax, xmax,ymin, xmin,ymin))
>     gIntersection(pol,r)
> }
>
> chop_thirds <- function(pol, fractions=c(1/3, 2/3)){
>     chopper = makeVchopper(pol)
>     bb = bbox(pol)
>     xmin = bb[1,1]
>     xmax = bb[1,2]
>
>     totalArea = gArea(pol)
>
>     chopped_area = function(x){
>         gArea(gIntersection(chopper(x),pol))
>     }
>
>     edges = lapply(fractions, function(fraction){
>         target = totalArea * fraction
>         target_function = function(x){
>             chopped_area(x) - target
>         }
>         uniroot(target_function, lower=xmin, upper=xmax)$root
>     })
>
>     xdelta = (xmax-xmin)/10
>     chops = matrix(c(xmin-xdelta, rep(edges,rep(2,length(edges))),
> xmax+xdelta), ncol=2, byrow=TRUE)
>     apply(chops, 1, function(edges){
>         slicer(pol, edges[1], edges[2])
>     })
>
> }
>
> Usage:
>
> library(rgeos)
> library(sp)
> # sample data
> pol <- readWKT(paste("POLYGON((-180 -20, -140 55, 10 0, -140 -60, -180
> -20),","(-150 -20, -100 -10, -110 20, -150 -20))"))
> plot(pol)
>
> # now split
>
> parts = chop_thirds(pol)
> plot(pol)
> plot(parts[[1]], add=TRUE, col=1)
> plot(parts[[2]], add=TRUE, col=2)
> plot(parts[[3]], add=TRUE, col=3)
>
>
> if not convinced:
>
> > gArea(parts[[1]])
> [1] 3375
> > gArea(parts[[2]])
> [1] 3375.001
> > gArea(parts[[3]])
> [1] 3374.999
>
> Can easily chop into quarters too... There's some redundancy in the
> code, and I'm sure it can be improved...
>
> Barry
>
>
>
>
> On Mon, Feb 29, 2016 at 6:14 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> > Sounds like a fun little bit of code to write:
> >
> >  - write a function that will return the area of a slice as a function
> of a parameter X that can vary between some bounds on your shape: left to
> right, or top to bottom etc. E.g. if you want to slice vertically, this
> could be the area of the part of your polygon between the leftmost point
> and a vertical line at X. (Adapt from here perhaps:
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-July/023168.html)
> >  - find the roots of that function for f(X, shape) - 1/3 * totalArea and
> f(X, shape) - 2/3 * totalArea
> >    (
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/uniroot.html )
> >
> > B.
> >
> > On Feb 29, 2016, at 12:57 PM, Shane Carey <careyshan at gmail.com> wrote:
> >
> >> ok thanks!!
> >>
> >> I would like to slice it vertically and have 3 distinct areas of equal
> >> area. So I need to chop it up into 3 areas of equal size essentially.
> >>
> >> There is no tool to do it in QGIS!!
> >>
> >> Thanks
> >>
> >> On Mon, Feb 29, 2016 at 5:51 PM, Barry Rowlingson <
> >> b.rowlingson at lancaster.ac.uk> wrote:
> >>
> >>> On Mon, Feb 29, 2016 at 5:37 PM, Shane Carey <careyshan at gmail.com>
> wrote:
> >>>> Hi,
> >>>>
> >>>> Is it possible to divide a polygon into 3 equal areas using R?
> >>>
> >>> Yes, in an infinite number of ways. Want to narrow it down?
> >>>
> >>> Specifically, you could slice it vertically, horizontally, or at any
> >>> angle between. You could chop it into squares and reassign them (did
> >>> you want **contiguous** areas?). You could choose a point and three
> >>> radii angles that divide the polygon into 3 equal areas in an infinite
> >>> number of ways.
> >>>
> >>> The rgeos package will help you chop polygons up, and then uniroot
> >>> can find the coordinates of lines or radii of angles that chop the
> >>> polygon first into 1/3 & 2/3 then chop the 2/3 into 1/2 and 1/2,
> >>> giving you three equal pieces.
> >>>
> >>>> I cant seem to be able to do it in QGIS.
> >>>
> >>> If it can be done in R it can be done in Python and then it can be
> >>> done in QGIS...
> >>>
> >>> Barry
> >>>
> >>
> >>
> >>
> >> --
> >> Shane
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Shane

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Mar  1 11:22:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 1 Mar 2016 21:22:01 +1100
Subject: [R] legend for vectorplot in rasterVis
In-Reply-To: <CAOV3wDDn-oNOEuJzSQQrWaDDwoji1eXt=juCDhTuMLNc3GxZQw@mail.gmail.com>
References: <CAOV3wDDn-oNOEuJzSQQrWaDDwoji1eXt=juCDhTuMLNc3GxZQw@mail.gmail.com>
Message-ID: <CA+8X3fUyFej=jgVK6au2pzPUKvqT6_489uo18F6c0EEQSePaDw@mail.gmail.com>

Hi Adrienne,
I'm not sure if this will help, but lengthKey in the plotrix package
will display a scale showing the relationship of vector length to
whatever numeric value is being displayed. However, you do have to
sort of the scaling manually.

Jim


On Tue, Mar 1, 2016 at 7:30 AM, Adrienne Wootten <amwootte at ncsu.edu> wrote:
> All,
>
> Your help with this is greatly appreciated!
>
> I'm working with the vectorplot function in rasterVis to produce wind
> vector maps (pretty much like the code in here -
> https://rpubs.com/alobo/vectorplot), but I was wondering about a legend.
>
> The vectors that vectorplot produces are wonderful.  What I'm trying to do
> is get a scale legend to go with it.  In other words, have a vector outside
> the main plot which provides a point of reference for the vectors in the
> plot.  Something alike to what GrADS does (for those familiar), is what I'm
> hoping to get to (for an example, the first chart on this page
> http://www.wishingwork.com/grads/graphics-controls/vector-graphics.html)
>
> I haven't seen this done yet with R, at least not from what I could find
> with all the forums.  If anyone has an idea on how to do this, I
> tremendously appreciate it!
>
> Thanks all!
>
> Adrienne
>
> --
> Adrienne Wootten
> Ph.D Candidate / Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From helmut.schuetz at bebac.at  Tue Mar  1 14:28:49 2016
From: helmut.schuetz at bebac.at (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Tue, 1 Mar 2016 14:28:49 +0100
Subject: [R] Color of points in legend() ignored if plotting to PNG
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70E3A9@mb02.ads.tamu.edu>
References: <56D2EFCA.4020305@bebac.at>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011B23@SRVEXCHMBX.precheza.cz>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70E3A9@mb02.ads.tamu.edu>
Message-ID: <56D59911.7020100@bebac.at>

Hi Boris, Jim, Petr, and David,

I stand corrected; works as desired.

In order to come up with an example I oversimplified my original code 
which contained lwd=0 in the legend.
lwd=0 indeed switches the 'borders' of points off.

Case closed.

Helmut

-- 
Ing. Helmut Schuetz
BEBAC - Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
tel     +43 1 2311746
mobile  +43 699 10792458
e-mail  helmut.schuetz at bebac.at
web     http://bebac.at/
contact http://bebac.at/Contact.htm
forum   http://forum.bebac.at/

This e-mail is confidential and may also be legally privileged. If you
are not the intended recipient please reply to sender, do not disclose
its contents to any person and delete the e-mail. Any unauthorized
review, use, disclosure, copying or distribution is strictly prohibited.


From youtube_b at telus.net  Tue Mar  1 07:35:45 2016
From: youtube_b at telus.net (jake88)
Date: Mon, 29 Feb 2016 22:35:45 -0800
Subject: [R] RSNNS neural network
Message-ID: <000001d17384$9639e930$c2adbb90$@net>

I am new to R and neural networks . So I trained and predicted an elman
network like so :?

require ( RSNNS )?
mydata = read.csv("mydata.csv",header = TRUE)?
mydata.train = mydata[1000:2000,]?
mydata.test = mydata[800:999,]?

fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100?
? ? ?learnFuncParams =c (0.1) , maxit =1000)?
pred <-predict (fit , mydata.test[,2:10])?

So pred contains the predictions . 
The problem I am having is that when I run pred <-predict (fit ,
mydata.test[1,2:10]) repeatedly , it gives me different results each time .
Should not the weights and bias be set permanently in the network and give
the same result everytime   ?  ?


From cli at ifs.ku.dk  Tue Mar  1 11:59:51 2016
From: cli at ifs.ku.dk (Conor Edward Little)
Date: Tue, 1 Mar 2016 10:59:51 +0000
Subject: [R] plotting spline term when frailty term is included
Message-ID: <48B4C6737B68CA44BD55CBE33DE801EF429294E5@P1KITMBX03WC02.unicph.domain>

Dear colleagues,

I'd very much appreciate your help in resolving a problem that I'm having with plotting a spline term.

I have a Cox PH model including a smoothing spline and a frailty term as follows:

   fit<-coxph(Surv(start,end,exit) ~ x + pspline(z) + frailty(a))

When I run a model without a frailty term, I use the following in order to plot the splines:

   termplot(fit, term = 2, se = TRUE, ylab = "Log Hazard", rug=TRUE, xlab = "z_name")

However, when the frailty term is included, it gives this error:

   Error in pred[, first] : subscript out of bounds

What am I doing wrong here? Or is it the case that termplot does not work when splines and frailty are included?

A similar question was asked a number of years ago - as far as I can see it didn't receive an answer (online, at least).
http://r.789695.n4.nabble.com/a-question-in-coxph-td908035.html

Best,
Conor Little



Conor Little
Postdoctoral Researcher
Department of Political Science, University of Copenhagen


	[[alternative HTML version deleted]]


From talk4deepak at gmail.com  Tue Mar  1 13:30:04 2016
From: talk4deepak at gmail.com (deepak aggarwal)
Date: Tue, 1 Mar 2016 18:00:04 +0530
Subject: [R] Help in R code
Message-ID: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>

Hi ,

Seeking your help in coding following requirement in R.

Vector 1 has sentences for ex. vector 1="he is a nice human being","he is
smart and fast in his work"

vector 2 has keywords found in each sentence seperated by comma
for  ex. vector2 for vector 1 =nice,being
vector 2 for vector 1 =smart,work

I want output to be vector 3 which will show 2 words before and after where
match is found

vector 1                                       vector2        vector 3
he is a nice human being              nice,being        is a nice
human,human being
he is smart and fast in his work   smart,work        he is smart,in his work

in all i want vector 3 to how 2 words before and aftr to each word of
vector 2 from vector 1.

really appriciate your quick help on this.

Thanks & Regards
Deepak

	[[alternative HTML version deleted]]


From amwootte at ncsu.edu  Tue Mar  1 15:14:53 2016
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 1 Mar 2016 09:14:53 -0500
Subject: [R] legend for vectorplot in rasterVis
In-Reply-To: <CA+8X3fUyFej=jgVK6au2pzPUKvqT6_489uo18F6c0EEQSePaDw@mail.gmail.com>
References: <CAOV3wDDn-oNOEuJzSQQrWaDDwoji1eXt=juCDhTuMLNc3GxZQw@mail.gmail.com>
	<CA+8X3fUyFej=jgVK6au2pzPUKvqT6_489uo18F6c0EEQSePaDw@mail.gmail.com>
Message-ID: <CAOV3wDCz6OZR3j+dc4K+57=8=_Dixi8kWr0SUriAwsOj=kVn3Q@mail.gmail.com>

Jim,

Thanks!  Interestingly when working with lengthKey it gives me an error
that plot.new hasn't been called after the plot has been created with
vectorplot.  Really bizarre to me.

A

On Tue, Mar 1, 2016 at 5:22 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Adrienne,
> I'm not sure if this will help, but lengthKey in the plotrix package
> will display a scale showing the relationship of vector length to
> whatever numeric value is being displayed. However, you do have to
> sort of the scaling manually.
>
> Jim
>
>
> On Tue, Mar 1, 2016 at 7:30 AM, Adrienne Wootten <amwootte at ncsu.edu>
> wrote:
> > All,
> >
> > Your help with this is greatly appreciated!
> >
> > I'm working with the vectorplot function in rasterVis to produce wind
> > vector maps (pretty much like the code in here -
> > https://rpubs.com/alobo/vectorplot), but I was wondering about a legend.
> >
> > The vectors that vectorplot produces are wonderful.  What I'm trying to
> do
> > is get a scale legend to go with it.  In other words, have a vector
> outside
> > the main plot which provides a point of reference for the vectors in the
> > plot.  Something alike to what GrADS does (for those familiar), is what
> I'm
> > hoping to get to (for an example, the first chart on this page
> > http://www.wishingwork.com/grads/graphics-controls/vector-graphics.html)
> >
> > I haven't seen this done yet with R, at least not from what I could find
> > with all the forums.  If anyone has an idea on how to do this, I
> > tremendously appreciate it!
> >
> > Thanks all!
> >
> > Adrienne
> >
> > --
> > Adrienne Wootten
> > Ph.D Candidate / Graduate Research Assistant
> > State Climate Office of North Carolina
> > Department of Marine, Earth and Atmospheric Sciences
> > North Carolina State University
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrienne Wootten
Ph.D Candidate / Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From amwootte at ncsu.edu  Tue Mar  1 15:18:42 2016
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 1 Mar 2016 09:18:42 -0500
Subject: [R] legend for vectorplot in rasterVis
In-Reply-To: <CAOV3wDCz6OZR3j+dc4K+57=8=_Dixi8kWr0SUriAwsOj=kVn3Q@mail.gmail.com>
References: <CAOV3wDDn-oNOEuJzSQQrWaDDwoji1eXt=juCDhTuMLNc3GxZQw@mail.gmail.com>
	<CA+8X3fUyFej=jgVK6au2pzPUKvqT6_489uo18F6c0EEQSePaDw@mail.gmail.com>
	<CAOV3wDCz6OZR3j+dc4K+57=8=_Dixi8kWr0SUriAwsOj=kVn3Q@mail.gmail.com>
Message-ID: <CAOV3wDAvV_Bb0NO9rw-sdE8iDW22mkcjy2CaWmZrc_X63mEUpg@mail.gmail.com>

All,

Thanks anyway folks, but I'm going to call myself a bonehead and move on
now that I've found it.  The key.arrow argument in vectorplot will do what
I need to make a scale legend.  Thanks all!

Adrienne


On Tue, Mar 1, 2016 at 9:14 AM, Adrienne Wootten <amwootte at ncsu.edu> wrote:

> Jim,
>
> Thanks!  Interestingly when working with lengthKey it gives me an error
> that plot.new hasn't been called after the plot has been created with
> vectorplot.  Really bizarre to me.
>
> A
>
> On Tue, Mar 1, 2016 at 5:22 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Adrienne,
>> I'm not sure if this will help, but lengthKey in the plotrix package
>> will display a scale showing the relationship of vector length to
>> whatever numeric value is being displayed. However, you do have to
>> sort of the scaling manually.
>>
>> Jim
>>
>>
>> On Tue, Mar 1, 2016 at 7:30 AM, Adrienne Wootten <amwootte at ncsu.edu>
>> wrote:
>> > All,
>> >
>> > Your help with this is greatly appreciated!
>> >
>> > I'm working with the vectorplot function in rasterVis to produce wind
>> > vector maps (pretty much like the code in here -
>> > https://rpubs.com/alobo/vectorplot), but I was wondering about a
>> legend.
>> >
>> > The vectors that vectorplot produces are wonderful.  What I'm trying to
>> do
>> > is get a scale legend to go with it.  In other words, have a vector
>> outside
>> > the main plot which provides a point of reference for the vectors in the
>> > plot.  Something alike to what GrADS does (for those familiar), is what
>> I'm
>> > hoping to get to (for an example, the first chart on this page
>> > http://www.wishingwork.com/grads/graphics-controls/vector-graphics.html
>> )
>> >
>> > I haven't seen this done yet with R, at least not from what I could find
>> > with all the forums.  If anyone has an idea on how to do this, I
>> > tremendously appreciate it!
>> >
>> > Thanks all!
>> >
>> > Adrienne
>> >
>> > --
>> > Adrienne Wootten
>> > Ph.D Candidate / Graduate Research Assistant
>> > State Climate Office of North Carolina
>> > Department of Marine, Earth and Atmospheric Sciences
>> > North Carolina State University
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Adrienne Wootten
> Ph.D Candidate / Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
>



-- 
Adrienne Wootten
Ph.D Candidate / Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Tue Mar  1 15:56:33 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 1 Mar 2016 14:56:33 +0000
Subject: [R] how to get the 'starting directory'
Message-ID: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi, it's very difficult for me to understand the fullrefman.pdf document !!!

I open a R script that is in the Git\reposit\gesdyn\jm directory. I 'type' alt + ctrl + R to run it. I would like to get 'Git\reposit\gesdyn\jm' in a variable ...

Getwd() gives something like users\jm\mydocuments

Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From l.sutherland at tecnico.ulisboa.pt  Tue Mar  1 16:01:05 2016
From: l.sutherland at tecnico.ulisboa.pt (Dr. Leigh S. Sutherland)
Date: Tue, 1 Mar 2016 15:01:05 +0000
Subject: [R] Heteroscedastic data due to responses at one factor level being
 too low to measure and assumed to be 0?
Message-ID: <CAEfCOO6CFrU0m8mL6S4LUFgvukPK9MaJjYLgUNmpDVU75iGb6A@mail.gmail.com>

Hello all,

I have a 3-factor experimental design.
The response is the load to break an adhesive joint.

I have a question about Heteroscedastic data ('non-uniform variability',
Google told me that's what it's called - I'm not a statistician, just an
engineer)

*In essence:*

   - At one level of a factor the response values are so low to make them
   un-testable and they have to be assumed to be 0


   - However this gives no variability at that level since all responses
   are 0, (although in reality they may well have similar variability as at
   other levels).


   - This gives heteroscedastic data across the levels of the factor


   - What implications does this have for stats tests that are sensitive to
   Heteroscedastic data?


   - If I need to do anything, what can I do? can I 'superimpose' the same
   variability on level 1 results to give artificial variable values 'around'
   0kg? (this would not at all invalidate the data's validity)

Thanks,
Leigh

-- 
Leigh Sutherland

Centre for Marine Technology and Ocean Engineering (CENTEC)
Instituto Superior T?cnico
Av. Rovisco Pais
1049-001 LISBOA
PORTUGAL

Tel: +351 218 417 947

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Mar  1 16:11:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 1 Mar 2016 15:11:16 +0000
Subject: [R] Help in R code
In-Reply-To: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
References: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50121E8@SRVEXCHMBX.precheza.cz>

Hi

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of deepak
> aggarwal
> Sent: Tuesday, March 01, 2016 1:30 PM
> To: r-help at r-project.org
> Subject: [R] Help in R code
>
> Hi ,
>
> Seeking your help in coding following requirement in R.
>
> Vector 1 has sentences for ex. vector 1="he is a nice human being","he
> is smart and fast in his work"
>
> vector 2 has keywords found in each sentence seperated by comma for
> ex. vector2 for vector 1 =nice,being vector 2 for vector 1 =smart,work
>
> I want output to be vector 3 which will show 2 words before and after
> where match is found
>
> vector 1                                       vector2        vector 3
> he is a nice human being              nice,being        is a nice
> human,human being
> he is smart and fast in his work   smart,work        he is smart,in his
> work
>
> in all i want vector 3 to how 2 words before and aftr to each word of
> vector 2 from vector 1.
>
> really appriciate your quick help on this.

OK. Some very quick help:

1. Do not post in HTML, your mail is barely readable.
2. Send some data by using output from
dput(yourobject)
3. Instead of vaguely explaining what you want to do, prepare desired output and again show it by dput(yourresult)
4. Check if

?strsplit together with ?"%in%" can be of some help.

test <- "he is smart and fast in his work"
> test
[1] "he is smart and fast in his work"
> unlist(strsplit(test, " "))
[1] "he"    "is"    "smart" "and"   "fast"  "in"    "his"   "work"

unlist(strsplit(test, " ")) %in% "smart"
[1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE

Cheers
Petr

>
> Thanks & Regards
> Deepak
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Tue Mar  1 17:05:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 1 Mar 2016 08:05:06 -0800
Subject: [R] Heteroscedastic data due to responses at one factor level
 being too low to measure and assumed to be 0?
In-Reply-To: <CAEfCOO6CFrU0m8mL6S4LUFgvukPK9MaJjYLgUNmpDVU75iGb6A@mail.gmail.com>
References: <CAEfCOO6CFrU0m8mL6S4LUFgvukPK9MaJjYLgUNmpDVU75iGb6A@mail.gmail.com>
Message-ID: <CAGxFJbTwjN+Cf=DXomo23CGmC=gH5PZ1p4kf9HhMFwNeCE2i_Q@mail.gmail.com>

This is a list about the R (statistical) programming language, not a
statistical advice list. That would be (among others)
stats.stackexchange.com, to which you can try posting.

However, recommendation: As you stated, you are well out of your
statistical depth here, and I would strongly advise that you find a
local statistical expert with whom to consult.  For example, this is
an example of (left) censored data, and as you noted, changing all
those lower than detectable limits to 0's may be problematic. There
are packages and functions to deal with this, but you have to know
what you're doing. You don't. So find help.

Personal gratuitous aside (feel free to ignore):  In my over 40 years
of consulting, I have encountered many, perhaps most, engineers, who
have such problems. So it is no dishonor. There just seems to be too
much other important stuff to fit into an engineering education for
there to be time for much statistics training. This comes back to bite
in practice, as you have found.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 1, 2016 at 7:01 AM, Dr. Leigh S. Sutherland
<l.sutherland at tecnico.ulisboa.pt> wrote:
> Hello all,
>
> I have a 3-factor experimental design.
> The response is the load to break an adhesive joint.
>
> I have a question about Heteroscedastic data ('non-uniform variability',
> Google told me that's what it's called - I'm not a statistician, just an
> engineer)
>
> *In essence:*
>
>    - At one level of a factor the response values are so low to make them
>    un-testable and they have to be assumed to be 0
>
>
>    - However this gives no variability at that level since all responses
>    are 0, (although in reality they may well have similar variability as at
>    other levels).
>
>
>    - This gives heteroscedastic data across the levels of the factor
>
>
>    - What implications does this have for stats tests that are sensitive to
>    Heteroscedastic data?
>
>
>    - If I need to do anything, what can I do? can I 'superimpose' the same
>    variability on level 1 results to give artificial variable values 'around'
>    0kg? (this would not at all invalidate the data's validity)
>
> Thanks,
> Leigh
>
> --
> Leigh Sutherland
>
> Centre for Marine Technology and Ocean Engineering (CENTEC)
> Instituto Superior T?cnico
> Av. Rovisco Pais
> 1049-001 LISBOA
> PORTUGAL
>
> Tel: +351 218 417 947
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Mar  1 17:06:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 1 Mar 2016 08:06:39 -0800
Subject: [R] Help in R code
In-Reply-To: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
References: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
Message-ID: <CAGxFJbTEzq9P4YdtRyjz9f0GSDrsJjjMYow-3kxa4fooLP=XqA@mail.gmail.com>

... but if this is homework (it looks like it) ask your teachers for
help, as there is a no homework policy on this list.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 1, 2016 at 4:30 AM, deepak aggarwal <talk4deepak at gmail.com> wrote:
> Hi ,
>
> Seeking your help in coding following requirement in R.
>
> Vector 1 has sentences for ex. vector 1="he is a nice human being","he is
> smart and fast in his work"
>
> vector 2 has keywords found in each sentence seperated by comma
> for  ex. vector2 for vector 1 =nice,being
> vector 2 for vector 1 =smart,work
>
> I want output to be vector 3 which will show 2 words before and after where
> match is found
>
> vector 1                                       vector2        vector 3
> he is a nice human being              nice,being        is a nice
> human,human being
> he is smart and fast in his work   smart,work        he is smart,in his work
>
> in all i want vector 3 to how 2 words before and aftr to each word of
> vector 2 from vector 1.
>
> really appriciate your quick help on this.
>
> Thanks & Regards
> Deepak
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Mar  1 17:11:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 1 Mar 2016 08:11:13 -0800
Subject: [R] Help with SpaceCAP
In-Reply-To: <DB4PR01MB1578783EDAE32C410600932A6BB0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>
References: <DB4PR01MB1570281BD7910608601358DA6BA0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>
	<CAGxFJbRP3Pa9Z9CZ-H_YMd8pvVrmoFvtRwhz7u0r9P5sO8x7iA@mail.gmail.com>
	<DB4PR01MB1578783EDAE32C410600932A6BB0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>
Message-ID: <CAGxFJbRr4bUUfBkQOhKc=iU-TZMR_O3+YY4rz-_VyuYJPhTQzQ@mail.gmail.com>

**Always post back to the list**, which I have cc'ed, not just to me.

There is obviously some problem in your data files. As I have no idea
what their structure is or should be, I have no clue.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 1, 2016 at 8:02 AM, Tara Jane Pirie
<T.J.Pirie at pgr.reading.ac.uk> wrote:
> Hi Burt,
> Here are part of the data, I still get a miss-match but only 1 this time however I have checked it and there is a "1" on that day.
>
>  str(capture)
> 'data.frame':   78 obs. of  3 variables:
>  $ LOC_ID   : int  11 5 1 11 11 11 11 20 11 11 ...
>  $ ANIMAL_ID: int  7 2 1 1 1 6 7 6 1 7 ...
>  $ SO       : int  1 5 6 6 7 7 8 10 16 18 ...
>
>  str(traps)
> 'data.frame':   40 obs. of  94 variables:
>  $ LOC_ID : int  1 5 6 53 7 8 9 12 16 18 ...
>  $ X_Coord: int  230042 229616 231090 230924 232578
>  $ Y_Coord: int  7236722 7235124 7234627 7237063 7234297
>  $ X1     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ X2     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ X3     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ X4     : int  1 1 1 1 1 1 1 1 1 1 ...
>
> <Tcl>
> Error - mismatch in animal capture details and trap deployment details files : location id
> 29 not deployed on SO 22
> Error in if (locso[loc, so + 3] == 0) { :
>   missing value where TRUE/FALSE needed
> Error - mismatch in animal capture details and trap deployment details files : location id
> 29 not deployed on SO 22
> Error in if (locso[loc, so + 3] == 0) { :
>   missing value where TRUE/FALSE needed
>
>
> Kind regards
> Tara Pirie
>
> Doctoral researcher - University of Reading
> People and Wildlife Research group
>
> Tel: +44 (0) 7340967711
>
> ________________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 29 February 2016 17:26
> To: Tara Jane Pirie
> Cc: r-help at r-project.org
> Subject: Re: [R] Help with SpaceCAP
>
> The email server for this list filters out most attachments, including yours.
>
> .txt attachments are generally permitted. As you seem to have
> successfully read the files into R, use dput() to include (a small
> portion if the data are numerous) of the data in your email. Before
> doing so, however, examine your data frame with str().
>
> ?dput
> ?str
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Feb 29, 2016 at 5:08 AM, Tara Jane Pirie
> <T.J.Pirie at pgr.reading.ac.uk> wrote:
>>
>> Hi there,
>>
>> I am trying to load csv files into the spacecap program in R, but I keep getting either or both of the following error messages:
>>
>>
>> Error - mismatch in animal capture details and trap deployment details files : location id 29
>> not deployed on SO 22
>>
>> Error in if (locso[loc, so + 3] == 0) { :
>>   missing value where TRUE/FALSE needed
>>
>> I have checked the headings and only have 3 columns for the capture file and have double checked the trap locs. I have checked the working days for the flagged trap locations, but they are showing "1".
>>
>> Please can you help me understand why I am getting these messages. I have attached the files I have been trying to upload.
>>
>>
>> Kind regards
>> Tara Pirie
>>
>> Doctoral researcher - University of Reading
>> People and Wildlife Research group
>>
>> Tel: +44 (0) 7340967711
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From lucasvignon at live.fr  Tue Mar  1 15:05:11 2016
From: lucasvignon at live.fr (Lucas VIGNON)
Date: Tue, 1 Mar 2016 15:05:11 +0100
Subject: [R] problem with package
Message-ID: <DUB109-W31D7A1244B645280AF941DA9BB0@phx.gbl>

Hello, 
I don't know if you can help me, but I have an issue when i try to install a package and launch it. 
You will find a picture of the screen and the messages that R returns to me. 
I don't understand what's is wrong and what should I do to make the setup of the package sucessful. 
I hope you could help me, 
Yours faithfully, 
Lucas Vignon  		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pb R.png
Type: image/png
Size: 175050 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160301/4429c98b/attachment.png>

From jean-externe.maurice at edf.fr  Tue Mar  1 17:29:20 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 1 Mar 2016 16:29:20 +0000
Subject: [R] source() is 'bombing'
Message-ID: <6d2b9f015b44455d9413ac6ea9aa1b41@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,

This morning, we transfered 2 R files into Git because someone else is going to work with me. A file is the 'main script' and the second contains the functions.
I had problem with the encoding of this second file : French accent were replaced by question mark. Without Git, I could 'reopen with encoding' but with Git, it doesn't work. I tried a lot of things in vain. At the end, I deleted the whole content of the file and paste in it a copy of the same file but in my own directory after a reopen with encoding. I save and commit all; Quit R; restart the PC and open the Git project : all seems ok.

I have asked a question about 'starting directory' but waiting for an answer I write the directory name in the code like :

Source(c:/RepoGit/ ..../plateforme.r)

But when this line is executed a bomb appears.
I tried to add a encoding clause : in vain

I looked at the windows rights, they are the same for both files ...

I added a test.r file in the directory, I can 'source' it ...

The second person can source the second file on her PC,

I'am lost ! If someone has an idea ...

Jean

-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From hodarahmati68 at yahoo.com  Tue Mar  1 17:29:09 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Tue, 1 Mar 2016 16:29:09 +0000 (UTC)
Subject: [R] removing factor values in the main data frame
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>

Hi all,I have the following main data frame:(mydata)?? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and AU,first I get a subset to contain just these two countries:?? ? ? ?submydata=subset(mydata,COUNTRY%in%c("US","AU"))? ? ? ?factor(submydata$COUNTRY)?but after this when I get str of mydata again I have the same data frame with no changes in COUNTRY, however I want mydata to be like:?
? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? $ COUNTRY : Factor w/ 2 levels "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
	[[alternative HTML version deleted]]


From hodarahmati68 at yahoo.com  Tue Mar  1 17:32:13 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Tue, 1 Mar 2016 16:32:13 +0000 (UTC)
Subject: [R] Fw: removing factor values in the main data frame
In-Reply-To: <781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
	<781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2006921614.1747305.1456849933636.JavaMail.yahoo@mail.yahoo.com>




 

 Hi all,I have the following main data frame:(mydata)?? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and AU,first I get a subset to contain just these two countries:?? ? ? ?submydata=subset(mydata,COUNTRY%in%c("US","AU"))? ? ? ?factor(submydata$COUNTRY)?but after this when I get str of mydata again I have the same data frame with no changes in COUNTRY, however I want mydata to be like:?
? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 2 levels "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help

  
	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Mar  1 17:38:48 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 01 Mar 2016 16:38:48 +0000
Subject: [R] removing factor values in the main data frame
In-Reply-To: <781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
	<781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULP3WA0RE2vgGVL=KDmP-bnwPXb3cJ2RvJVv8xv+vABzVQ@mail.gmail.com>

Hi,

I think droplevels(df) is what you are looking for.

Best wishes,
Ulrik

On Tue, 1 Mar 2016 at 17:33 hoda rahmati via R-help <r-help at r-project.org>
wrote:

> Hi all,I have the following main data frame:(mydata)        $ TE : num 40
> 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49 49 28 28 28 28 28 28 28
> 49 ...        $ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8
> 8 ...among the COUNTRY I just need US and AU,first I get a subset to
> contain just these two countries:
>  submydata=subset(mydata,COUNTRY%in%c("US","AU"))
>  factor(submydata$COUNTRY) but after this when I get str of mydata again I
> have the same data frame with no changes in COUNTRY, however I want mydata
> to be like:
>        $ TE : num 40 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49
> 49 28 28 28 28 28 28 28 49 ...       $ COUNTRY : Factor w/ 2 levels
> "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Tue Mar  1 17:41:29 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 1 Mar 2016 11:41:29 -0500
Subject: [R] source() is 'bombing'
In-Reply-To: <6d2b9f015b44455d9413ac6ea9aa1b41@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6d2b9f015b44455d9413ac6ea9aa1b41@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <FFD01129-53EE-46F3-9A20-586F5FA379D6@bigelow.org>

Hi,

I'm a little fuzzy on what a bomb is in this context, but the source() function expects the input argument to be either a connection object or character string.  See ...

?source

Try enclosing you filename with quotes.

Cheers,
Ben


> On Mar 1, 2016, at 11:29 AM, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
> 
> Hi,
> 
> This morning, we transfered 2 R files into Git because someone else is going to work with me. A file is the 'main script' and the second contains the functions.
> I had problem with the encoding of this second file : French accent were replaced by question mark. Without Git, I could 'reopen with encoding' but with Git, it doesn't work. I tried a lot of things in vain. At the end, I deleted the whole content of the file and paste in it a copy of the same file but in my own directory after a reopen with encoding. I save and commit all; Quit R; restart the PC and open the Git project : all seems ok.
> 
> I have asked a question about 'starting directory' but waiting for an answer I write the directory name in the code like :
> 
> Source(c:/RepoGit/ ..../plateforme.r)
> 
> But when this line is executed a bomb appears.
> I tried to add a encoding clause : in vain
> 
> I looked at the windows rights, they are the same for both files ...
> 
> I added a test.r file in the directory, I can 'source' it ...
> 
> The second person can source the second file on her PC,
> 
> I'am lost ! If someone has an idea ...
> 
> Jean
> 
> 
> 
> 
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
> 
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
> 
> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
> ____________________________________________________
> 
> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
> 
> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
> 
> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From hodarahmati68 at yahoo.com  Tue Mar  1 17:42:04 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Tue, 1 Mar 2016 16:42:04 +0000 (UTC)
Subject: [R] removing factor values in the main data frame
In-Reply-To: <CAKVAULP3WA0RE2vgGVL=KDmP-bnwPXb3cJ2RvJVv8xv+vABzVQ@mail.gmail.com>
References: <CAKVAULP3WA0RE2vgGVL=KDmP-bnwPXb3cJ2RvJVv8xv+vABzVQ@mail.gmail.com>
Message-ID: <1056010541.1752073.1456850524137.JavaMail.yahoo@mail.yahoo.com>

I also tried droplevels but after getting str(submydata) again I see no changes in COUNTRY? 

    On Tuesday, March 1, 2016 8:38 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
 

 Hi,

I think droplevels(df) is what you are looking for.

Best wishes,
Ulrik
On Tue, 1 Mar 2016 at 17:33 hoda rahmati via R-help <r-help at r-project.org> wrote:

Hi all,I have the following main data frame:(mydata)?? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and AU,first I get a subset to contain just these two countries:?? ? ? ?submydata=subset(mydata,COUNTRY%in%c("US","AU"))? ? ? ?factor(submydata$COUNTRY)?but after this when I get str of mydata again I have the same data frame with no changes in COUNTRY, however I want mydata to be like:?
? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? $ COUNTRY : Factor w/ 2 levels "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Mar  1 17:55:42 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 01 Mar 2016 16:55:42 +0000
Subject: [R] removing factor values in the main data frame
In-Reply-To: <1056010541.1752073.1456850524137.JavaMail.yahoo@mail.yahoo.com>
References: <CAKVAULP3WA0RE2vgGVL=KDmP-bnwPXb3cJ2RvJVv8xv+vABzVQ@mail.gmail.com>
	<1056010541.1752073.1456850524137.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULM9D9chqUz3QWx+s=iPszCbUUJiBnO6Xz05RxYTYjU7nQ@mail.gmail.com>

Without more information it is hard to see where things go wrong.

To judge from your text, I am not sure you do things correct. You are doing
it along the lines of:
str(mydata)
submydata <- subset(mydata, ... )
submydata <- droplevels(submydata)
str(submydata)

right?


On Tue, 1 Mar 2016 at 17:45 hoda rahmati <hodarahmati68 at yahoo.com> wrote:

> I also tried droplevels but after getting str(submydata) again I see no
> changes in COUNTRY
>
>
> On Tuesday, March 1, 2016 8:38 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>
> Hi,
>
> I think droplevels(df) is what you are looking for.
>
> Best wishes,
> Ulrik
>
> On Tue, 1 Mar 2016 at 17:33 hoda rahmati via R-help <r-help at r-project.org>
> wrote:
>
> Hi all,I have the following main data frame:(mydata)        $ TE : num 40
> 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49 49 28 28 28 28 28 28 28
> 49 ...        $ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8
> 8 ...among the COUNTRY I just need US and AU,first I get a subset to
> contain just these two countries:
>  submydata=subset(mydata,COUNTRY%in%c("US","AU"))
>  factor(submydata$COUNTRY) but after this when I get str of mydata again I
> have the same data frame with no changes in COUNTRY, however I want mydata
> to be like:
>        $ TE : num 40 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49
> 49 28 28 28 28 28 28 28 49 ...       $ COUNTRY : Factor w/ 2 levels
> "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Mar  1 18:33:31 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 1 Mar 2016 17:33:31 +0000
Subject: [R] Fw: removing factor values in the main data frame
In-Reply-To: <2006921614.1747305.1456849933636.JavaMail.yahoo@mail.yahoo.com>
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
	<781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
	<2006921614.1747305.1456849933636.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70E852@mb02.ads.tamu.edu>

You need to learn how to send emails in plain text since html gets mangled on r-help. See your message below. If I understand your question, it has to do with what happens to factor levels when you subset your data. Subsetting a factor does not remove empty factor levels. This is documented on the manual page for subset():

"Factors may have empty levels after subsetting; unused levels are not automatically removed. See droplevels for a way to drop all unused levels from a data frame."

------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hoda rahmati via R-help
Sent: Tuesday, March 1, 2016 10:32 AM
To: r-help at r-project.org
Subject: [R] Fw: removing factor values in the main data frame

Hi all,I have the following main data frame:(mydata)?? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and AU,first I get a subset to contain just these two countries:?? ? ? ?submydata=subset(mydata,COUNTRY%in%c("US","AU"))? ? ? ?factor(submydata$COUNTRY)?but after this when I get str of mydata again I have the same data frame with no changes in COUNTRY, however I want mydata to be like:?
? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 2 levels "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help

  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Tue Mar  1 19:19:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 01 Mar 2016 10:19:18 -0800
Subject: [R] Fw: removing factor values in the main data frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70E852@mb02.ads.tamu.edu>
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
	<781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
	<2006921614.1747305.1456849933636.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70E852@mb02.ads.tamu.edu>
Message-ID: <B47A1EA6-D6E0-47E4-8A36-211F60C9E5F1@dcn.davis.ca.us>

I advocate not converting to factor in the first place.  Delay that until you won't be wanting specific levels to be accounted for. 
-- 
Sent from my phone. Please excuse my brevity.

On March 1, 2016 9:33:31 AM PST, David L Carlson <dcarlson at tamu.edu> wrote:
>You need to learn how to send emails in plain text since html gets
>mangled on r-help. See your message below. If I understand your
>question, it has to do with what happens to factor levels when you
>subset your data. Subsetting a factor does not remove empty factor
>levels. This is documented on the manual page for subset():
>
>"Factors may have empty levels after subsetting; unused levels are not
>automatically removed. See droplevels for a way to drop all unused
>levels from a data frame."
>
>------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77840-4352
>
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hoda
>rahmati via R-help
>Sent: Tuesday, March 1, 2016 10:32 AM
>To: r-help at r-project.org
>Subject: [R] Fw: removing factor values in the main data frame
>
>Hi all,I have the following main data frame:(mydata)?? ? ? ?$ TE : num
>40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num 49 49 28 28 28 28
>28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 27 levels
>"","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and
>AU,first I get a subset to contain just these two countries:?? ? ?
>?submydata=subset(mydata,COUNTRY%in%c("US","AU"))? ? ?
>?factor(submydata$COUNTRY)?but after this when I get str of mydata
>again I have the same data frame with no changes in COUNTRY, however I
>want mydata to be like:?
>? ? ? ?$ TE : num 40 40 20 20 20 20 20 20 20 40 ...?? ? ? ?$ TR : num
>49 49 28 28 28 28 28 28 28 49 ...?? ? ? ?$ COUNTRY : Factor w/ 2 levels
>"","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Mar  1 20:10:08 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Mar 2016 20:10:08 +0100
Subject: [R] Copula Regression
In-Reply-To: <36e810c0-b288-4f9c-9593-cccd9911afb0@EXCH-OK-HUB02P.ead.ubc.ca>
References: <063E7F85C84B8C44A6D1A1C47E8728761BCC35DB@exch-ok-mbx01p.ead.ubc.ca>
	<36e810c0-b288-4f9c-9593-cccd9911afb0@EXCH-OK-HUB02P.ead.ubc.ca>
Message-ID: <22229.59664.572705.301069@stat.math.ethz.ch>

>>>>> Janmaat, John <John.Janmaat at ubc.ca>
>>>>>     on Tue, 1 Mar 2016 04:53:43 +0000 writes:

    > Well, seem to have solved own problem.
    > The article "Enjoy the joy of copulas: with a package copula" has a nice appendix that describes precisely how to set up what I am looking for.  The only minor issue is that some of the functions have been deprecated.

    > So, if anyone is curious, here is the article info (in BibTeX):

    > @Article{YanJ_2007_CopulasR,
    > title={Enjoy the joy of copulas: with a package copula},
    > author={Yan, Jun and others},
    > journal={Journal of Statistical Software},
    > volume={21},
    > number={4},
    > pages={1--21},
    > year={2007}
    > }

Thank you. As that Journal is a free open access journal, the url may be
even more useful:
   https://www.jstatsoft.org/index.php/jss/article/view/v021i04/v21i04.pdf

and (as current maintainer of the 'copula' package)
may I ask you how exactly you solved it (R code) and
why you could not easily replace the calls to the deprecated
functions (e.g. 'dcopula') by calls to their substitutes ?

But indeed, I'm impressed by Jun Yan  who had already added such
example code to the appendix of that paper relatively long ago.

I think it would make sense to add a version of that appendix
as (Rmd) vignette to our copula package.

Martin


    > John.

    > ----------
    > Dr. John Janmaat
    > Economics (Unit 8), IK Barber School of Arts and Sciences
    > The University of British Columbia
    > 3333 University Way, Kelowna, BC


    > -----Original Message-----
    > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Janmaat, John
    > Sent: February-29-16 2:55 PM
    > To: 'r-help at r-project.org'
    > Subject: [R] Copula Regression

    > Hello,

    > I'm trying to figure out how to run copula regressions in R.  I see a couple of packages that do specific versions, but I am hoping to be a bit more flexible.

    > My specific problem involves two ordered regressions (four levels each) that may be correlated.  Is there a package out there that can do copula regressions with arbitrary marginals?  Alternatively, is there a way to trick functions like GLM into returning observation specific CDF values given a guess for the parameters?

    > I would prefer to avoid coding this up, as I expect the more tested code I can use, the less likelihood for my own errors to mess up the results.

    > Thanks,

    > John.

    > ----------
    > Dr. John Janmaat
    > Economics (Unit 8), IK Barber School of Arts and Sciences The University of British Columbia
    > 3333 University Way, Kelowna, BC


    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Mar  1 20:13:08 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Mar 2016 11:13:08 -0800
Subject: [R] plotting spline term when frailty term is included
In-Reply-To: <48B4C6737B68CA44BD55CBE33DE801EF429294E5@P1KITMBX03WC02.unicph.domain>
References: <48B4C6737B68CA44BD55CBE33DE801EF429294E5@P1KITMBX03WC02.unicph.domain>
Message-ID: <A5582CBC-C5EA-4C61-8005-B04CD55637C4@comcast.net>


> On Mar 1, 2016, at 2:59 AM, Conor Edward Little <cli at ifs.ku.dk> wrote:
> 
> Dear colleagues,
> 
> I'd very much appreciate your help in resolving a problem that I'm having with plotting a spline term.
> 
> I have a Cox PH model including a smoothing spline and a frailty term as follows:
> 
>   fit<-coxph(Surv(start,end,exit) ~ x + pspline(z) + frailty(a))
> 
> When I run a model without a frailty term, I use the following in order to plot the splines:
> 
>   termplot(fit, term = 2, se = TRUE, ylab = "Log Hazard", rug=TRUE, xlab = "z_name")
> 
> However, when the frailty term is included, it gives this error:
> 
>   Error in pred[, first] : subscript out of bounds

I think this is due to the inability of `predict` to cope with the frailty model when type="terms". Using the example on the ?frailty page as teh basis for a reproducible example:

> predict(coxph(Surv(time, status) ~ age + frailty(inst, df=4), lung), type="terms")
Error in predict.coxph.penal(coxph(Surv(time, status) ~ age + frailty(inst,  : 
  length of 'dimnames' [2] not equal to array extent

> 

> What am I doing wrong here? Or is it the case that termplot does not work when splines and frailty are included?
> 
> A similar question was asked a number of years ago - as far as I can see it didn't receive an answer (online, at least).
> http://r.789695.n4.nabble.com/a-question-in-coxph-td908035.html


The `?termplot` help-page says that there must be a `predict` method for the object that accepts a "terms"- argument. Therneau advises the use of the 'coxme'-package for mixed effects survival modeling and the `predict.coxme` function does not have a "terms" argument. 

Prediction with frailty: I think that the issue of prediction with frailty models may be more complex than you understand. My level of understanding is inadequate as well, so I tried searching for earlier answers. If Thomas Lumley says it is "hard" then I take him at my word. Appears you would need to do calculation separately for each value of the frailty "term" if you stay with the coxph/frailty environment. Therneau has written:  "Residuals methods for coxme would be an
important addition and is on my to-do list. (But as my wife would pointout, so is a bathroom remodel and she isn't holding her breath.)".  So it appears that the problem is more than just a simple two line bit of code.

Lumley's approach from 10+ years ago: 

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+coxph+frailty+prediction+#query:list%3Aorg.r-project.r-help%20coxph%20frailty%20prediction%20+page:1+mid:qy7nxom3uknj2oop+state:results

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+coxph+frailty+prediction+#query:list%3Aorg.r-project.r-help%20coxph%20frailty%20prediction%20+page:1+mid:nbcdjwfs3jhqjsji+state:results


> 
> Best,
> Conor Little
> 
> 
> 
> Conor Little
> Postdoctoral Researcher
> Department of Political Science, University of Copenhagen
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From talk4deepak at gmail.com  Tue Mar  1 17:30:29 2016
From: talk4deepak at gmail.com (Deepak Aggarwal)
Date: Tue, 1 Mar 2016 22:00:29 +0530
Subject: [R] Help in R code
In-Reply-To: <CAGxFJbTEzq9P4YdtRyjz9f0GSDrsJjjMYow-3kxa4fooLP=XqA@mail.gmail.com>
References: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
	<CAGxFJbTEzq9P4YdtRyjz9f0GSDrsJjjMYow-3kxa4fooLP=XqA@mail.gmail.com>
Message-ID: <864E4F8C-0A9E-484B-AFE1-50969572790B@gmail.com>

Hahaha this is not homework..i am just trying to explore r vs sas

Sent from my iPhone

> On 01-Mar-2016, at 9:36 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... but if this is homework (it looks like it) ask your teachers for
> help, as there is a no homework policy on this list.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Tue, Mar 1, 2016 at 4:30 AM, deepak aggarwal <talk4deepak at gmail.com> wrote:
>> Hi ,
>> 
>> Seeking your help in coding following requirement in R.
>> 
>> Vector 1 has sentences for ex. vector 1="he is a nice human being","he is
>> smart and fast in his work"
>> 
>> vector 2 has keywords found in each sentence seperated by comma
>> for  ex. vector2 for vector 1 =nice,being
>> vector 2 for vector 1 =smart,work
>> 
>> I want output to be vector 3 which will show 2 words before and after where
>> match is found
>> 
>> vector 1                                       vector2        vector 3
>> he is a nice human being              nice,being        is a nice
>> human,human being
>> he is smart and fast in his work   smart,work        he is smart,in his work
>> 
>> in all i want vector 3 to how 2 words before and aftr to each word of
>> vector 2 from vector 1.
>> 
>> really appriciate your quick help on this.
>> 
>> Thanks & Regards
>> Deepak
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Thomas.Lofaro at SurveySampling.com  Tue Mar  1 20:56:17 2016
From: Thomas.Lofaro at SurveySampling.com (Thomas Lofaro)
Date: Tue, 1 Mar 2016 19:56:17 +0000
Subject: [R] FW: Multivariate ARIMA
In-Reply-To: <56C25EC7.9070308@gmail.com>
References: <mailman.1.1455447601.17866.r-help@r-project.org>
	<56C25EC7.9070308@gmail.com>
Message-ID: <BN4PR07MB22109F75CA5078E4FBA72BC593BB0@BN4PR07MB2210.namprd07.prod.outlook.com>

Hi Paul,

Thanks so much for reaching out.  

I read through the link but I am not having any luck.  It seems the first part of the link refers to a single variable ARIMA model with no exogenous variable.  Then the link starts discussing forecasting.

Anyway, I have two columns of data in my matrix (each row represents a new month).  I want column A to predict Column B, where I can adjust the lag to be say 1,2, or 6 months.

Is there any example R code that accomplishes this that you know of?  Apologies for my lack of proficiency in the program.


-----Original Message-----
From: Paul Gilbert [mailto:pgilbert902 at gmail.com] 
Sent: Monday, February 15, 2016 6:27 PM
To: Thomas Lofaro
Cc: r-help at r-project.org
Subject: Re: [R] FW: Multivariate ARIMA

See also package dse.  There are examples in the guide: 
http://cran.at.r-project.org/web/packages/dse/vignettes/Guide.pdf

Paul

On 02/14/2016 06:00 AM, r-help-request at r-project.org wrote:
> Date: Fri, 12 Feb 2016 18:12:37 +0000 From: Thomas 
> Lofaro<Thomas.Lofaro at SurveySampling.com> To:"r-help at R-project.org"
> <r-help at R-project.org> Subject: [R] FW: Multivariate ARIMA 
> Question.... Message-ID:
> <BN4PR07MB22103CC8EB3FF13CCDF00D4D93A90 at BN4PR07MB2210.namprd07.prod.ou
> tlook.com>
>
>  Content-Type: text/plain; charset="UTF-8"
>
> Hi, sorry, I will try to make this short. Essentially, what I am 
> trying to do is run a multivariate ARIMA model predicting one variable 
> with another.  However, the only R packages I have found to 
> accommodate such an analysis are ARIMAX and VAR.  Unfortunately, there 
> don?t seem to be any good tutorials or demonstrations of how to 
> actually perform this analysis in practice, on my two columns of data.  
> I was wondering if anyone knew of a resource that might help (or one 
> that provided an example of r code to accomplish this).
> Thanks sooo much!


From pdalgd at gmail.com  Tue Mar  1 22:29:55 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 1 Mar 2016 22:29:55 +0100
Subject: [R] removing factor values in the main data frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70E852@mb02.ads.tamu.edu>
References: <781855812.1756803.1456849749261.JavaMail.yahoo.ref@mail.yahoo.com>
	<781855812.1756803.1456849749261.JavaMail.yahoo@mail.yahoo.com>
	<2006921614.1747305.1456849933636.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70E852@mb02.ads.tamu.edu>
Message-ID: <AC997441-9237-4805-B9AB-13EB240EE84B@gmail.com>


> On 01 Mar 2016, at 18:33 , David L Carlson <dcarlson at tamu.edu> wrote:
> 
> You need to learn how to send emails in plain text since html gets mangled on r-help. See your message below. If I understand your question, it has to do with what happens to factor levels when you subset your data. Subsetting a factor does not remove empty factor levels. This is documented on the manual page for subset():
> 
> "Factors may have empty levels after subsetting; unused levels are not automatically removed. See droplevels for a way to drop all unused levels from a data frame."
> 

Also check ?"[.factor" and the drop=TRUE argument, which allows you to drop unused level from one particular factor. (Yes, there are good reasons that this is not the default.)

-pd 

> ------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hoda rahmati via R-help
> Sent: Tuesday, March 1, 2016 10:32 AM
> To: r-help at r-project.org
> Subject: [R] Fw: removing factor values in the main data frame
> 
> Hi all,I have the following main data frame:(mydata)        $ TE : num 40 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49 49 28 28 28 28 28 28 28 49 ...        $ COUNTRY : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 ...among the COUNTRY I just need US and AU,first I get a subset to contain just these two countries:        submydata=subset(mydata,COUNTRY%in%c("US","AU"))       factor(submydata$COUNTRY) but after this when I get str of mydata again I have the same data frame with no changes in COUNTRY, however I want mydata to be like: 
>        $ TE : num 40 40 20 20 20 20 20 20 20 40 ...        $ TR : num 49 49 28 28 28 28 28 28 28 49 ...        $ COUNTRY : Factor w/ 2 levels "","AU","US",..: 8 8 8 8 8 8 8 8 8 8Thanks for any help
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From akh22 at pitt.edu  Tue Mar  1 22:46:18 2016
From: akh22 at pitt.edu (Hoji, Akihiko)
Date: Tue, 1 Mar 2016 21:46:18 +0000
Subject: [R] ggplot2-theme(panel.border)
Message-ID: <E44C29C9-A47F-4519-AC14-12C701018467@pitt.edu>

A quick question.  How come data points disappear when ?theme(panel.border=element_rect()) is used and how could I get those points back on the plot ? 

Thanks in advance. 

AH

From alaasindi at icloud.com  Tue Mar  1 21:09:09 2016
From: alaasindi at icloud.com (Alaa Sindi)
Date: Tue, 01 Mar 2016 15:09:09 -0500
Subject: [R] help in maximum likelihood
Message-ID: <99BABC94-4772-415D-9D3C-18D1965B5777@icloud.com>


Hi all,

what is wrong with this code? I am trying to estimate the model parameters by maximizing the likelihood function and I am getting this warning 


Warning message:
In nlm(fn, p = c(-50, 20), hessian = TRUE) :
  NA/Inf replaced by maximum positive value




x <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)
fn <- function(p)
    sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))
            + log(choose(n, y)) ))
out <- nlm(fn, p = c(-50,20), hessian = TRUE)


Thanks

From profjcnash at gmail.com  Wed Mar  2 04:24:50 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 1 Mar 2016 22:24:50 -0500
Subject: [R] help in maximum likelihood
In-Reply-To: <99BABC94-4772-415D-9D3C-18D1965B5777@icloud.com>
References: <99BABC94-4772-415D-9D3C-18D1965B5777@icloud.com>
Message-ID: <56D65D02.4030105@gmail.com>

It's useful to add "print.level=2" inside your call to find that there's
essentially nothing wrong.

Rvmmin doesn't give the msg and numDeriv gives a similar (BUT NOT
EXACTLY THE SAME!) hessian estimate.

It's almost always worthwhile turning on the diagnostic printing when
doing optimization, even if you throw away the output pretty well right
away, because it can often suggest whether the results are reasonable or
rubbish.

JN


On 16-03-01 03:09 PM, Alaa Sindi wrote:
> 
> Hi all,
> 
> what is wrong with this code? I am trying to estimate the model parameters by maximizing the likelihood function and I am getting this warning 
> 
> 
> Warning message:
> In nlm(fn, p = c(-50, 20), hessian = TRUE) :
>   NA/Inf replaced by maximum positive value
> 
> 
> 
> 
> x <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
> y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
> n <- c(59, 60, 62, 56, 63, 59, 62, 60)
> fn <- function(p)
>     sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))
>             + log(choose(n, y)) ))
> out <- nlm(fn, p = c(-50,20), hessian = TRUE)
> 
> 
> Thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jean-externe.maurice at edf.fr  Wed Mar  2 08:01:28 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 07:01:28 +0000
Subject: [R] path + name of the running R file
Message-ID: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,

Is it possible to get the path and name of the running R file ?

Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From petr.pikal at precheza.cz  Wed Mar  2 08:03:07 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Mar 2016 07:03:07 +0000
Subject: [R] Help in R code
In-Reply-To: <CADH3bWLx5i5aw1EvEXsC1-toDFKfBodroQ4=RQNbYn0LVQ+TTw@mail.gmail.com>
References: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50121E8@SRVEXCHMBX.precheza.cz>
	<CADH3bWLx5i5aw1EvEXsC1-toDFKfBodroQ4=RQNbYn0LVQ+TTw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50122E2@SRVEXCHMBX.precheza.cz>

Well, so again, my first answer was maybe too elaborated.

0. Send your replies also to help list.
1. Do not post in HTML.
2. Send some data by using output from
dput(yourobject)
3. Prepare desired output and again show it by dput(yourresult)

I still do not understand your desired output. In first sequence you dropped words ?He is? and ?he?, in second ?word? and ?can be?

Did you check?
4. Check if

?strsplit together with ?"%in%" can be of some help.

test <- "he is smart and fast in his work"
> test
[1] "he is smart and fast in his work"
> unlist(strsplit(test, " "))
[1] "he"    "is"    "smart" "and"   "fast"  "in"    "his"   "work"

unlist(strsplit(test, " ")) %in% "smart"
[1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE

If the above does not work for you, you need to evaluate regular expressions.

See e.g.
?gsub

Cheers
Petr

From: deepak aggarwal [mailto:talk4deepak at gmail.com]
Sent: Tuesday, March 01, 2016 5:06 PM
To: PIKAL Petr
Subject: Re: [R] Help in R code


Sentence

Words

word string

1

he is a nice human being.he has great talent of singing

human,talent

a nice human being .,has great talent of singing

2

Word is having environmental issues which can be solved at local level nw

environmental,local

is having environmental issues which,solved at local level nw


sentence column has 1000 sentences and words have some selected words already written
now i want r code using which i can get word string in such a way that first human is searched in sentence 1 and then 2 words before human and 2 words after human will be writen in word string next it will search word talent and add it to word string

so in nutsheel for every word in words column it will fetch 2 words before and 2 words after where match is found.

Seeking your help on this.

Regards
Deepak

On Tue, Mar 1, 2016 at 8:41 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of deepak
> aggarwal
> Sent: Tuesday, March 01, 2016 1:30 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Help in R code
>
> Hi ,
>
> Seeking your help in coding following requirement in R.
>
> Vector 1 has sentences for ex. vector 1="he is a nice human being","he
> is smart and fast in his work"
>
> vector 2 has keywords found in each sentence seperated by comma for
> ex. vector2 for vector 1 =nice,being vector 2 for vector 1 =smart,work
>
> I want output to be vector 3 which will show 2 words before and after
> where match is found
>
> vector 1                                       vector2        vector 3
> he is a nice human being              nice,being        is a nice
> human,human being
> he is smart and fast in his work   smart,work        he is smart,in his
> work
>
> in all i want vector 3 to how 2 words before and aftr to each word of
> vector 2 from vector 1.
>
> really appriciate your quick help on this.

OK. Some very quick help:

1. Do not post in HTML, your mail is barely readable.
2. Send some data by using output from
dput(yourobject)
3. Instead of vaguely explaining what you want to do, prepare desired output and again show it by dput(yourresult)
4. Check if

?strsplit together with ?"%in%" can be of some help.

test <- "he is smart and fast in his work"
> test
[1] "he is smart and fast in his work"
> unlist(strsplit(test, " "))
[1] "he"    "is"    "smart" "and"   "fast"  "in"    "his"   "work"

unlist(strsplit(test, " ")) %in% "smart"
[1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE

Cheers
Petr

>
> Thanks & Regards
> Deepak
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Mar  2 08:25:10 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Mar 2016 07:25:10 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>

Hi

I am not an expert in making R scripts but what you see probably means that your R session starts in users\jm\mydocuments directory which is set as your working directory.

AFAIK there are basically 2 directories - one with  location of R program
D:\programy\R-devel\bin\i386\Rgui.exe

and one from which the R program is started.

O:\Dokumenty\STAT\pracovni
(this is Windows, I do not have experience with Linux/Mac machines)

So your way of starting a script leads to starting from

users\jm\mydocuments

directory. I also recommend to consult Rlang.pdf manual for programming questions.

As Alt+Ctrl+R does nothing on my PC I searched what it can mean and I found that it is shortcut of R-studio for opening a document. Am I right? If yes it can be a feature of Rstudio.

maybe others more experienced users can give you better answer.

Anyway you can help us to help you if you provide as full info as you can afford.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MAURICE
> Jean - externe
> Sent: Tuesday, March 01, 2016 3:57 PM
> To: r-help at r-project.org
> Subject: [R] how to get the 'starting directory'
>
> Hi, it's very difficult for me to understand the fullrefman.pdf
> document !!!
>
> I open a R script that is in the Git\reposit\gesdyn\jm directory. I
> 'type' alt + ctrl + R to run it. I would like to get
> 'Git\reposit\gesdyn\jm' in a variable ...
>
> Getwd() gives something like users\jm\mydocuments
>
> Jean

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jean-externe.maurice at edf.fr  Wed Mar  2 08:38:00 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 07:38:00 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
Message-ID: <4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>

Thanks Petr,

ALT + CTRL + R is a shortcut in RSTUDIO to RUN ALL

As I shall work with another developer, I installed GIT (a source manager) but now R 'bombs'. I have 3 versions of my R sources (in fact a file with the 'master' and one with all the functions) : one project within Git, one project on a server and the last project on my local machine.

Having the starting directory can give me, in the console or in a text file, the project being used.

In other words I start RStudio in a directory and change projects, each being in its own directory

Is that more clear ?

Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From petr.pikal at precheza.cz  Wed Mar  2 08:40:40 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Mar 2016 07:40:40 +0000
Subject: [R] path + name of the running R file
In-Reply-To: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012366@SRVEXCHMBX.precheza.cz>

Hi

What do you mean by R file?

When you start R session you can get actual working directory by

mydir <-  getwd()

and info about files in this directory by

list.files()

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MAURICE
> Jean - externe
> Sent: Wednesday, March 02, 2016 8:01 AM
> To: r-help at r-project.org
> Subject: [R] path + name of the running R file
>
> Hi,
>
> Is it possible to get the path and name of the running R file ?
>
> Jean

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From aajains at gmail.com  Tue Mar  1 23:07:01 2016
From: aajains at gmail.com (Aashish Jain)
Date: Tue, 1 Mar 2016 16:07:01 -0600
Subject: [R] ggplot2-theme(panel.border)
In-Reply-To: <E44C29C9-A47F-4519-AC14-12C701018467@pitt.edu>
References: <E44C29C9-A47F-4519-AC14-12C701018467@pitt.edu>
Message-ID: <CACE+iTeQUryQZ8VFsFaseR9RHOypg53qpCrDWC_vqJ_=K_vCkg@mail.gmail.com>

You can write "fill = NA" in the argument of element_rect(), that should
solve your problem.

On Tue, Mar 1, 2016 at 3:46 PM, Hoji, Akihiko <akh22 at pitt.edu> wrote:

> A quick question.  How come data points disappear when
> ?theme(panel.border=element_rect()) is used and how could I get those
> points back on the plot ?
>
> Thanks in advance.
>
> AH
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Mar  2 08:50:55 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Mar 2016 07:50:55 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012381@SRVEXCHMBX.precheza.cz>

Hi

Not for me. I do not use Rstudio nor GIT and I use R mainly for interactive statistics. The closest I came to R programming is a set of my functions transformed to a package. So you has to wait for others more experienced in R programming.

Maybe you could try to change your second file with functions to a package, which is R way how to manage user functions.

See

?package.skeleton

for first step.

Cheers
Petr


> -----Original Message-----
> From: MAURICE Jean - externe [mailto:jean-externe.maurice at edf.fr]
> Sent: Wednesday, March 02, 2016 8:38 AM
> To: PIKAL Petr; r-help at r-project.org
> Subject: RE: how to get the 'starting directory'
>
> Thanks Petr,
>
> ALT + CTRL + R is a shortcut in RSTUDIO to RUN ALL
>
> As I shall work with another developer, I installed GIT (a source
> manager) but now R 'bombs'. I have 3 versions of my R sources (in fact
> a file with the 'master' and one with all the functions) : one project
> within Git, one project on a server and the last project on my local
> machine.
>
> Having the starting directory can give me, in the console or in a text
> file, the project being used.
>
> In other words I start RStudio in a directory and change projects, each
> being in its own directory
>
> Is that more clear ?
>
> Jean
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations
> qui y figurent sont strictement confidentielles. Toute utilisation de
> ce Message non conforme ? sa destination, toute diffusion ou toute
> publication totale ou partielle, est interdite sauf autorisation
> expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit
> de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout
> ou partie. Si vous avez re?u ce Message par erreur, merci de le
> supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en
> garder aucune trace sur quelque support que ce soit. Nous vous
> remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour
> du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de
> toute erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely
> for the addressees. The information contained in this Message is
> confidential. Any use of information contained in this Message not in
> accord with its purpose, any dissemination or disclosure, either whole
> or partial, is prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or
> use any part of it. If you have received this message in error, please
> delete it and all copies from your system and notify the sender
> immediately by return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jean-externe.maurice at edf.fr  Wed Mar  2 09:02:57 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 08:02:57 +0000
Subject: [R] path + name of the running R file
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012366@SRVEXCHMBX.precheza.cz>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012366@SRVEXCHMBX.precheza.cz>
Message-ID: <c35029bee1ec488594c1c68947e62d56@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Petr,

I am an old FORTRAN programmer and new to R. The 'philosophy' of R is very very far from FORTRAN ! So, may be I am wrong but :

I want to test 3 projects. In fact, these 3 projects are identical but not in the same directory : one within Git (a source management), one on the server and the last one on my local machine. When I run the one in Git, R bombs (and I have no error code, line number, ...). I try to detect what is wrong. So I add cat(), browser() ... to try to 'narrow' the fault (is that clear ?) and the "source()" command is in my target. So I change the current project every 5 minutes ... So when I launch (start ?) the execution of one project and in some functions , I'd like to have the path + name of the .R file being used (perhaps the 'main' file of Git project is doing a source() on a file on the server instead of the one on the Git directory : do you see what I am looking for ?). In other words, I am not sure 100% of the "source()" command and I want to verify it ...

Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From jdnewmil at dcn.davis.ca.us  Wed Mar  2 09:10:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 02 Mar 2016 00:10:09 -0800
Subject: [R] how to get the 'starting directory'
In-Reply-To: <4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>

I am guessing that it is RStudio that bombs... I have seen that bomb dialog from RStudio but never from R. However,  this is not the RStudio support forum... you should be asking someone involved with that software.
-- 
Sent from my phone. Please excuse my brevity.

On March 1, 2016 11:38:00 PM PST, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
>Thanks Petr,
>
>ALT + CTRL + R is a shortcut in RSTUDIO to RUN ALL
>
>As I shall work with another developer, I installed GIT (a source
>manager) but now R 'bombs'. I have 3 versions of my R sources (in fact
>a file with the 'master' and one with all the functions) : one project
>within Git, one project on a server and the last project on my local
>machine.
>
>Having the starting directory can give me, in the console or in a text
>file, the project being used.
>
>In other words I start RStudio in a directory and change projects, each
>being in its own directory
>
>Is that more clear ?
>
>Jean
>
>
>
>Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
>?tablis ? l'intention exclusive des destinataires et les informations
>qui y figurent sont strictement confidentielles. Toute utilisation de
>ce Message non conforme ? sa destination, toute diffusion ou toute
>publication totale ou partielle, est interdite sauf autorisation
>expresse.
>
>Si vous n'?tes pas le destinataire de ce Message, il vous est interdit
>de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout
>ou partie. Si vous avez re?u ce Message par erreur, merci de le
>supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en
>garder aucune trace sur quelque support que ce soit. Nous vous
>remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour
>du message.
>
>Il est impossible de garantir que les communications par messagerie
>?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de
>toute erreur ou virus.
>____________________________________________________
>
>This message and any attachments (the 'Message') are intended solely
>for the addressees. The information contained in this Message is
>confidential. Any use of information contained in this Message not in
>accord with its purpose, any dissemination or disclosure, either whole
>or partial, is prohibited except formal approval.
>
>If you are not the addressee, you may not copy, forward, disclose or
>use any part of it. If you have received this message in error, please
>delete it and all copies from your system and notify the sender
>immediately by return message.
>
>E-mail communication cannot be guaranteed to be timely secure, error or
>virus-free.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Mar  2 09:13:14 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 2 Mar 2016 19:13:14 +1100
Subject: [R] path + name of the running R file
In-Reply-To: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CA+8X3fV6ms3uctsNsaYH_GJrsV9Mz4wJUokfvLLUMDM0ypYLFw@mail.gmail.com>

Hi Maurice,
If you have used "source" to run an R script, perhaps you could try
something like this:

get.running.file<-function(pattern="source",...) {
 file1 <- tempfile("Rrawhist")
 savehistory(file1)
 rawhist <- readLines(file1)
 unlink(file1)
 last.source<-grep(pattern,rev(rawhist),value=TRUE)[1]
 sourced.file<-unlist(strsplit(last.source,'"'))[2]
 return(sourced.file)
}

This is taken from the "history" function and tries to find the last
"source" command in the command history and extract the name of the
sourced file. It is very rough, but it does work as long as the first
argument to the "source" function is the quoted name of the sourced
file.

Jim


On Wed, Mar 2, 2016 at 6:01 PM, MAURICE Jean - externe
<jean-externe.maurice at edf.fr> wrote:
> Hi,
>
> Is it possible to get the path and name of the running R file ?
>
> Jean
>
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jean-externe.maurice at edf.fr  Wed Mar  2 09:18:33 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 08:18:33 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
Message-ID: <f35c5b05b4d442ba9940f98f87935e2f@NOEINTPEXMU007.NEOPROD.EDF.FR>

I didn?t know that Rstudio was a separate tool ! So now, I have a new field to manage  !

Thanks
Jean



De : jdnewmil at dcn.davis.ca.us [mailto:jdnewmil at dcn.davis.ca.us]
Envoy? : mercredi 2 mars 2016 09:10
? : MAURICE Jean - externe; petr.pikal at precheza.cz; r-help at r-project.org
Objet : Re: [R] how to get the 'starting directory'

I am guessing that it is RStudio that bombs... I have seen that bomb dialog from RStudio but never from R. However, this is not the RStudio support forum... you should be asking someone involved with that software.
--
Sent from my phone. Please excuse my brevity.



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Wed Mar  2 09:20:49 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 08:20:49 +0000
Subject: [R] path + name of the running R file
In-Reply-To: <CA+8X3fV6ms3uctsNsaYH_GJrsV9Mz4wJUokfvLLUMDM0ypYLFw@mail.gmail.com>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CA+8X3fV6ms3uctsNsaYH_GJrsV9Mz4wJUokfvLLUMDM0ypYLFw@mail.gmail.com>
Message-ID: <4c1e830838b14c99a93295b3074e137c@NOEINTPEXMU007.NEOPROD.EDF.FR>

I suppose (think) that, in RStudio the shorcut alt+ctrl+R is converted to a source command so it can work : I try.

Thanks
Jean

-----Message d'origine-----
De?: drjimlemon at gmail.com [mailto:drjimlemon at gmail.com] 
Envoy??: mercredi 2 mars 2016 09:13
??: MAURICE Jean - externe; r-help at r-project.org
Objet?: Re: [R] path + name of the running R file

Hi Maurice,
If you have used "source" to run an R script, perhaps you could try something like this:

get.running.file<-function(pattern="source",...) {
 file1 <- tempfile("Rrawhist")
 savehistory(file1)
 rawhist <- readLines(file1)
 unlink(file1)
 last.source<-grep(pattern,rev(rawhist),value=TRUE)[1]
 sourced.file<-unlist(strsplit(last.source,'"'))[2]
 return(sourced.file)
}

This is taken from the "history" function and tries to find the last "source" command in the command history and extract the name of the sourced file. It is very rough, but it does work as long as the first argument to the "source" function is the quoted name of the sourced file.

Jim



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From jean-externe.maurice at edf.fr  Wed Mar  2 09:50:50 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 08:50:50 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
Message-ID: <5d2b1d485ea048f5a84867cbe901df2d@NOEINTPEXMU007.NEOPROD.EDF.FR>

The message with the bomb is R session .. see picture

Jean

De : jdnewmil at dcn.davis.ca.us [mailto:jdnewmil at dcn.davis.ca.us]
Envoy? : mercredi 2 mars 2016 09:10
? : MAURICE Jean - externe; petr.pikal at precheza.cz; r-help at r-project.org
Objet : Re: [R] how to get the 'starting directory'

I am guessing that it is RStudio that bombs... I have seen that bomb dialog from RStudio but never from R. However, this is not the RStudio support forum... you should be asking someone involved with that software.
--
Sent from my phone. Please excuse my brevity.



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture_bombe_R.PNG
Type: image/png
Size: 15660 bytes
Desc: Capture_bombe_R.PNG
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160302/df346880/attachment.png>

From petr.pikal at precheza.cz  Wed Mar  2 09:50:53 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Mar 2016 08:50:53 +0000
Subject: [R] path + name of the running R file
In-Reply-To: <c35029bee1ec488594c1c68947e62d56@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012366@SRVEXCHMBX.precheza.cz>
	<c35029bee1ec488594c1c68947e62d56@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012410@SRVEXCHMBX.precheza.cz>

Hi Jean

As I said I am not a programmer, although I made some stuff with old languages like Basic (not Visual) or some kind of assembly language from late 80s.
So your questions are out of my depth.

I hope others can give you better insight.

Cheers
Petr


> -----Original Message-----
> From: MAURICE Jean - externe [mailto:jean-externe.maurice at edf.fr]
> Sent: Wednesday, March 02, 2016 9:03 AM
> To: PIKAL Petr; r-help at r-project.org
> Subject: RE: path + name of the running R file
>
> Hi Petr,
>
> I am an old FORTRAN programmer and new to R. The 'philosophy' of R is
> very very far from FORTRAN ! So, may be I am wrong but :
>
> I want to test 3 projects. In fact, these 3 projects are identical but
> not in the same directory : one within Git (a source management), one
> on the server and the last one on my local machine. When I run the one
> in Git, R bombs (and I have no error code, line number, ...). I try to
> detect what is wrong. So I add cat(), browser() ... to try to 'narrow'
> the fault (is that clear ?) and the "source()" command is in my target.
> So I change the current project every 5 minutes ... So when I launch
> (start ?) the execution of one project and in some functions , I'd like
> to have the path + name of the .R file being used (perhaps the 'main'
> file of Git project is doing a source() on a file on the server instead
> of the one on the Git directory : do you see what I am looking for ?).
> In other words, I am not sure 100% of the "source()" command and I want
> to verify it ...
>
> Jean
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations
> qui y figurent sont strictement confidentielles. Toute utilisation de
> ce Message non conforme ? sa destination, toute diffusion ou toute
> publication totale ou partielle, est interdite sauf autorisation
> expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit
> de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout
> ou partie. Si vous avez re?u ce Message par erreur, merci de le
> supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en
> garder aucune trace sur quelque support que ce soit. Nous vous
> remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour
> du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de
> toute erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely
> for the addressees. The information contained in this Message is
> confidential. Any use of information contained in this Message not in
> accord with its purpose, any dissemination or disclosure, either whole
> or partial, is prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or
> use any part of it. If you have received this message in error, please
> delete it and all copies from your system and notify the sender
> immediately by return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jean-externe.maurice at edf.fr  Wed Mar  2 09:53:03 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 08:53:03 +0000
Subject: [R] path + name of the running R file
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012410@SRVEXCHMBX.precheza.cz>
References: <6b6831d704b54f1c939dc594ba6fb3a6@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012366@SRVEXCHMBX.precheza.cz>
	<c35029bee1ec488594c1c68947e62d56@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012410@SRVEXCHMBX.precheza.cz>
Message-ID: <c3a01c76ffc64e30ad5f420af4fa5139@NOEINTPEXMU007.NEOPROD.EDF.FR>

> from late 80s

The good old time !!!!

Jean

-----Message d'origine-----
De?: petr.pikal at precheza.cz [mailto:petr.pikal at precheza.cz] 
Envoy??: mercredi 2 mars 2016 09:51
??: MAURICE Jean - externe; r-help at r-project.org
Objet?: RE: path + name of the running R file

Hi Jean

As I said I am not a programmer, although I made some stuff with old languages like Basic (not Visual) or some kind of assembly language from late 80s.
So your questions are out of my depth.

I hope others can give you better insight.

Cheers
Petr



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From maechler at stat.math.ethz.ch  Wed Mar  2 10:40:12 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Mar 2016 10:40:12 +0100
Subject: [R] how to get the 'starting directory'
In-Reply-To: <5d2b1d485ea048f5a84867cbe901df2d@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
	<5d2b1d485ea048f5a84867cbe901df2d@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <22230.46332.17042.959814@stat.math.ethz.ch>

>>>>> MAURICE Jean <- externe <jean-externe.maurice at edf.fr>>
>>>>>     on Wed, 2 Mar 2016 08:50:50 +0000 writes:

    > The message with the bomb is R session .. see picture
    > Jean

    > De : jdnewmil at dcn.davis.ca.us [mailto:jdnewmil at dcn.davis.ca.us]
    > Envoy? : mercredi 2 mars 2016 09:10
    > ? : MAURICE Jean - externe; petr.pikal at precheza.cz; r-help at r-project.org
    > Objet : Re: [R] how to get the 'starting directory'

    > I am guessing that it is RStudio that bombs... I have seen that bomb dialog from RStudio but never from R. However, this is not the RStudio support forum... you should be asking someone involved with that software.
    > --

    > x[DELETED ATTACHMENT Capture_bombe_R.PNG, PNG image]

Indeed, as Petr guessed correctly, this is what  Rstudio
produces for you.

and, indeed #2, Jean,  you (and many others!) should learn to
distinguish between R and  Rstudio+R ( or ESS+R or StatET+R ).

The more sophisticated these GUIs become, the more often we have
to make this distinction, unfortunately, as the price for
sophistication unfortunately is typically paid by more bugs.
This is not just the case for Rstudio but ESS as well (says a
long time ESS project maintainer).

Martin Maechler, ETH Zurich


From jean-externe.maurice at edf.fr  Wed Mar  2 10:49:07 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 2 Mar 2016 09:49:07 +0000
Subject: [R] how to get the 'starting directory'
In-Reply-To: <22230.46332.17042.959814@stat.math.ethz.ch>
References: <c75bc73110ea4765a4dd71befbcb4915@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012334@SRVEXCHMBX.precheza.cz>
	<4b755543f1f14b46aa04cf59425c5216@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<334382CC-C064-4CDA-B5BC-A8469EC8672A@dcn.davis.ca.us>
	<5d2b1d485ea048f5a84867cbe901df2d@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<22230.46332.17042.959814@stat.math.ethz.ch>
Message-ID: <0ba419d65c134c458b69109705df94f1@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Martin,

And you forgot Git !

So for now, I gave up (abandonned ?) Git

And if Rstudio annoys me once more, I'll abandon it (skip it ?)

I like when things are simple and when I error occurs I like to have a message ...

Jean
PS I know something complicated that is very simple to use : SBB CFF FFS !

-----Message d'origine-----
De?: maechler at stat.math.ethz.ch [mailto:maechler at stat.math.ethz.ch] 
Envoy??: mercredi 2 mars 2016 10:40
??: MAURICE Jean - externe
Cc?: jdnewmil at dcn.davis.ca.us; r-help at r-project.org
Objet?: Re: [R] how to get the 'starting directory'

>>>>> MAURICE Jean <- externe <jean-externe.maurice at edf.fr>>
>>>>>     on Wed, 2 Mar 2016 08:50:50 +0000 writes:

    > The message with the bomb is R session .. see picture
    > Jean

    > De : jdnewmil at dcn.davis.ca.us [mailto:jdnewmil at dcn.davis.ca.us]
    > Envoy? : mercredi 2 mars 2016 09:10
    > ? : MAURICE Jean - externe; petr.pikal at precheza.cz; r-help at r-project.org
    > Objet : Re: [R] how to get the 'starting directory'

    > I am guessing that it is RStudio that bombs... I have seen that bomb dialog from RStudio but never from R. However, this is not the RStudio support forum... you should be asking someone involved with that software.
    > --

    > x[DELETED ATTACHMENT Capture_bombe_R.PNG, PNG image]

Indeed, as Petr guessed correctly, this is what  Rstudio produces for you.

and, indeed #2, Jean,  you (and many others!) should learn to distinguish between R and  Rstudio+R ( or ESS+R or StatET+R ).

The more sophisticated these GUIs become, the more often we have to make this distinction, unfortunately, as the price for sophistication unfortunately is typically paid by more bugs.
This is not just the case for Rstudio but ESS as well (says a long time ESS project maintainer).

Martin Maechler, ETH Zurich



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.


From wht_crl at yahoo.com  Wed Mar  2 14:55:46 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 2 Mar 2016 13:55:46 +0000 (UTC)
Subject: [R] Change the location of R
References: <2018008550.1795737.1456926946163.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2018008550.1795737.1456926946163.JavaMail.yahoo@mail.yahoo.com>

Hi,I have R v 3.0 installed /usr/... and the new version R-3.2.3 in my home under ubuntu. Is it correct to copy the R-3.2.3 directory into /usr/local/lib/R/ or should I reconfig and remake into /usr/local/lib/R/?
Regards,
Carol

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Wed Mar  2 15:51:22 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 2 Mar 2016 15:51:22 +0100
Subject: [R] Change the location of R
References: <2018008550.1795737.1456926946163.JavaMail.yahoo.ref@mail.yahoo.com>
	<2018008550.1795737.1456926946163.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <87bn6xvsph.fsf@hornfels.zedat.fu-berlin.de>

Hi Carol,

carol white via R-help <r-help at r-project.org> writes:

> Hi,I have R v 3.0 installed /usr/... and the new version R-3.2.3 in my
> home under ubuntu. Is it correct to copy the R-3.2.3 directory into
> /usr/local/lib/R/ or should I reconfig and remake into
> /usr/local/lib/R/?
> Regards,
> Carol

The standard way is just to use the --prefix option of configure to
point to the directory in which you want to install R.  However, you can
probably just move the directory as well.  Either way, you need to
ensure that R is found.  For that you will have to do add something like

export R_HOME=/path/to/R/3.2.3/lib64/R 
export PATH=/path/to/R/3.2.3/bin:$PATH

to your .bashrc file (e.g. /home/carol/.bashrc).

HTH

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From ravi.varadhan at jhu.edu  Wed Mar  2 16:05:10 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 2 Mar 2016 15:05:10 +0000
Subject: [R] help in maximum likelihood
Message-ID: <cd5230e4a3ac4f92abc95363183d2e8f@ESGEBEX10.win.ad.jhu.edu>

There is nothing wrong with the optimization.  It is a warning message.  However, this is a good example to show that one should not simply dismiss a warning before understanding what it means.  The MLE parameters are also large, indicating that there is something funky about the model or the data or both.  In your case, there is one major problem with the data:  for the highest dose (value of x), you have all subjects responding, i.e. y = n.  Even for the next lower dose, there is almost complete response.  Where do these data come from? Are they real or fake (simulated) data?

Also, take a look at the eigenvalues of the hessian at the solution.  You will see that there is some ill-conditioning, as the eigenvalues are widely separated.

x <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)

# note: there is no need to have the choose(n, y) term in the likelihood
fn <- function(p)
    sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))) )

out <- nlm(fn, p = c(-50,20), hessian = TRUE)

out

eigen(out$hessian)


Hope this is helpful,
Ravi



Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From Jens.Koch at gmx.li  Wed Mar  2 16:19:21 2016
From: Jens.Koch at gmx.li (Jens Koch)
Date: Wed, 2 Mar 2016 16:19:21 +0100
Subject: [R] discriminant analysis lda under MASS
Message-ID: <trinity-b01a8d19-35db-46e6-b004-de2fca6c1d1b-1456931961732@3capp-gmx-bs66>

Hello all,

I'd like to run a simple discriminant analysis to jump into the topic with the following dataset provided by a textbook:

Gruppe Einwohner Kosten
1 1642 478,2
1 2418 247,3
1 1417 223,6
1 2761 505,6
1 3991 399,3
1 2500 276
1 6261 542,5
1 3260 308,9
1 2516 453,6
1 4451 430,2
1 3504 413,8
1 5431 379,7
1 3523 400,5
1 5471 404,1
2 7172 499,4
2 9419 674,9
2 8780 468,6
2 5070 601,5
2 5780 578,8
2 8630 641,5

The coefficients according to the textbook need to be -0.00170 and -0.01237.

If I put the data into the lda function under MASS, my result is:

Call:
lda(Gruppe ~ Einwohner + Kosten, data = data)

Prior probabilities of groups:
? 1 ? 2
0.7 0.3

Group means:
? Einwohner ? Kosten
1 ?3510.429 390.2357
2 ?7475.167 577.4500

Coefficients of linear discriminants:
? ? ? ? ? ? ? ? ? ?LD1
Einwohner 0.0004751092
Kosten ? ?0.0050994964

I also tried to solve it by an another software package, but there is also not the result I have expected. I know now, that the?solution for the?coefficients is standardized by R and?the discrimination power?is not different at the end of the day.

But: How can I get (calculate) the results printed in the textbook with R?

Thanks in advance,

Jens.


From therneau at mayo.edu  Wed Mar  2 16:55:31 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 02 Mar 2016 09:55:31 -0600
Subject: [R] plotting spline term when frailty term is included
In-Reply-To: <mailman.5.1456916402.6693.r-help@r-project.org>
References: <mailman.5.1456916402.6693.r-help@r-project.org>
Message-ID: <519743$2i710m@ironport10.mayo.edu>



On 03/02/2016 05:00 AM, r-help-request at r-project.org wrote:
> I'd very much appreciate your help in resolving a problem that I'm having with plotting a spline term.
>
> I have a Cox PH model including a smoothing spline and a frailty term as follows:
>
>     fit<-coxph(Surv(start,end,exit) ~ x + pspline(z) + frailty(a))
>
> When I run a model without a frailty term, I use the following in order to plot the splines:
>
>     termplot(fit, term = 2, se = TRUE, ylab = "Log Hazard", rug=TRUE, xlab = "z_name")
>
> However, when the frailty term is included, it gives this error:
>
>     Error in pred[, first] : subscript out of bounds
>
> What am I doing wrong here? Or is it the case that termplot does not work when splines and frailty are included?

There are 3 parts to the answer.
  1. The first is a warning: wrt to mixed effects Cox models, I shifted my energy to coxme 
over 10 years ago.  The "penalized add on to coxph" approach of the frailty function was 
an ok first pass, but is just too limited for any but the simplest models.  I'm unlikely 
fix issues, since there are others much higher on my priority list.

  2. As Dave W. pointed out, the key issue is that predict(type='terms') does not work 
with for a model with two penalized terms, when one is frailty and the other pspline. 
Termplot depends on predict.

  3. Again, as Dave W pointed out, the whole issue of what the "correct" answer would be 
gets much more complicated when one adds random effects to the mix; some things have not 
done because it is not clear where to go.  (Survival curves for a mixed effects model only 
recently got added to my "todo" list, even though it has been on the wish list forever, 
because I finally have a notion of what a good approach would be.)

In your case I'd advise an end run: fit the model using ns() instead of pspline.  I like 
smoothing splines better than regression splines, but the fact is that for most data sets 
they result in nearly identical answers.

Terry T


From rkoenker at illinois.edu  Wed Mar  2 17:47:12 2016
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 2 Mar 2016 10:47:12 -0600
Subject: [R] Functional programming?
Message-ID: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>

I have a (remarkably ugly!!) code snippet  (below) that, given
two simple functions, f and g,  generates
a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
better ways to do this.  I don?t particularly care about the returned list,
I?d be happy to have the final  h_K version of the function,
but I keep losing my way and running into the dreaded:

Error in h[[1]] : object of type 'closure' is not subsettable
or
Error: evaluation nested too deeply: infinite recursion / options(expressions=)?

Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
something more sensible lurking beneath this minimal (toy)  example.

    f <- function(u) function(x) u * x^2
    g <- function(u) function(x) u * log(x)
    set.seed(3)
    a <- runif(5)
    h <- list()
    hit <- list()
    h[[1]] <- f(a[1])
    hit[[1]] <- f(a[1])
    for(i in 2:5){
	ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
	h[[i]] <- eval(parse(text = ht))
	hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
	}
    x <- 1:99/10
    plot(x, h[[1]](x), type = "l")
    for(i in 2:5)
	lines(x, h[[i]](x), col = i)

Thanks,
Roger


From js3786 at drexel.edu  Wed Mar  2 18:03:15 2016
From: js3786 at drexel.edu (Jinggaofu Shi)
Date: Wed, 2 Mar 2016 12:03:15 -0500
Subject: [R] Plot multiple similar equations in r
Message-ID: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>

Hi, there I am new on R. I want to plot a graph like this.

The curves are created by these equations :
(log(0.4)-(0.37273*log(x)-1.79389))/0.17941,
(log(0.5)-(0.37273*log(x)-1.79389))/0.17941,
(log(0.6)-(0.37273*log(x)-1.79389))/0.17941, etc. The equations are
similar, the only difference is the first log(XXX). I already manually draw
the graph by repeating plot() for each equation. But I think there must be
a way to just assign a simple variable like x<-c(0.4,0.5,0.6,0.7), and then
plot all the curves automatically. I tried to use data frame to make a set
of equations, but failed. Could somebody help me? Thank you very much!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: QQ??20160302113702.png
Type: image/png
Size: 85043 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160302/6223ee5d/attachment.png>

From ddalthorp at usgs.gov  Wed Mar  2 18:52:54 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 2 Mar 2016 09:52:54 -0800
Subject: [R] Plot multiple similar equations in r
In-Reply-To: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
References: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
Message-ID: <CAJeYpE9kQSzA2JKJtRGjWnJrQa2OGfiv8tS3SnDNiJ2VVOsGYQ@mail.gmail.com>

A simple solution that will give you an idea of some of the plot parameters:

x<-seq(1,10,length=1000) # values for x-axis
x0<-c(0.4,0.5,0.6,0.7)
miny<-(log(min(x0))-(0.37273*log(max(x))-1.79389))/0.17941 # minimum
y-value to show on graph
maxy<-(log(max(x0))-(0.37273*log(min(x))-1.79389))/0.17941 # maximum
y-value to show on graph
plot(1,1, xlim=range(x), ylim=c(miny,maxy), type='n') # a blank figure to
put lines on
for (i in x0) lines(x,(log(i)-(0.37273*log(x)-1.79389))/0.17941) # putting
the lines on


On Wed, Mar 2, 2016 at 9:03 AM, Jinggaofu Shi <js3786 at drexel.edu> wrote:

> Hi, there I am new on R. I want to plot a graph like this.
>
> The curves are created by these equations :
> (log(0.4)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.5)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.6)-(0.37273*log(x)-1.79389))/0.17941, etc. The equations are
> similar, the only difference is the first log(XXX). I already manually draw
> the graph by repeating plot() for each equation. But I think there must be
> a way to just assign a simple variable like x<-c(0.4,0.5,0.6,0.7), and then
> plot all the curves automatically. I tried to use data frame to make a set
> of equations, but failed. Could somebody help me? Thank you very much!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar  2 19:12:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 2 Mar 2016 10:12:18 -0800
Subject: [R] Functional programming?
In-Reply-To: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
Message-ID: <CAGxFJbThsFpRNjaLdFZwVj=X0KznTZXAU8mbTNUDLt4ofQ=sbQ@mail.gmail.com>

Does this do what you want:

f <- function(u) function(x) u * x^2
g <- function(u) function(x) u * log(x)
set.seed(3)
a <- runif(5)
h <- list()
hit <- list()
h[[1]] <- f(a[1])
hit[[1]] <- f(a[1])
for(i in 2:5)h[[i]] <- eval(bquote(function(x).(h[[i-1]])(x) * g(a[i])(x)))
x <- 1:99/10
plot(x, h[[1]](x), type = "l")
for(i in 2:5){
  i
  lines(x, h[[i]](x), col = i)
}

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 2, 2016 at 8:47 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> I have a (remarkably ugly!!) code snippet  (below) that, given
> two simple functions, f and g,  generates
> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
> better ways to do this.  I don?t particularly care about the returned list,
> I?d be happy to have the final  h_K version of the function,
> but I keep losing my way and running into the dreaded:
>
> Error in h[[1]] : object of type 'closure' is not subsettable
> or
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>
> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
> something more sensible lurking beneath this minimal (toy)  example.
>
>     f <- function(u) function(x) u * x^2
>     g <- function(u) function(x) u * log(x)
>     set.seed(3)
>     a <- runif(5)
>     h <- list()
>     hit <- list()
>     h[[1]] <- f(a[1])
>     hit[[1]] <- f(a[1])
>     for(i in 2:5){
>         ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
>         h[[i]] <- eval(parse(text = ht))
>         hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
>         }
>     x <- 1:99/10
>     plot(x, h[[1]](x), type = "l")
>     for(i in 2:5)
>         lines(x, h[[i]](x), col = i)
>
> Thanks,
> Roger
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Mar  2 19:23:11 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 2 Mar 2016 13:23:11 -0500
Subject: [R] Functional programming?
In-Reply-To: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
Message-ID: <56D72F8F.5030106@gmail.com>

On 02/03/2016 11:47 AM, Roger Koenker wrote:
> I have a (remarkably ugly!!) code snippet  (below) that, given
> two simple functions, f and g,  generates
> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
> better ways to do this.  I don?t particularly care about the returned list,
> I?d be happy to have the final  h_K version of the function,
> but I keep losing my way and running into the dreaded:
>
> Error in h[[1]] : object of type 'closure' is not subsettable
> or
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>
> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
> something more sensible lurking beneath this minimal (toy)  example.
>
>      f <- function(u) function(x) u * x^2
>      g <- function(u) function(x) u * log(x)
>      set.seed(3)
>      a <- runif(5)
>      h <- list()
>      hit <- list()
>      h[[1]] <- f(a[1])
>      hit[[1]] <- f(a[1])
>      for(i in 2:5){
> 	ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
> 	h[[i]] <- eval(parse(text = ht))
> 	hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
> 	}
>      x <- 1:99/10
>      plot(x, h[[1]](x), type = "l")
>      for(i in 2:5)
> 	lines(x, h[[i]](x), col = i)

I don't understand what "hit" is for, but something like this should do it:


hlist <- function(maxk, f,g,a) {
   h <- list()
   h[[1]] <- f(a[1])
   for (j in 2:maxk) {
     h[[j]] <- local({
       k <- j
       function(x) {
         result <- h[[1]](x)
         for (i in 2:k) {
           result <- result*g(a[i])(x)
         }
         result
       }
     })
   }
   h
}

f <- function(u) function(x) u * x^2
g <- function(u) function(x) u * log(x)
set.seed(3)
a <- runif(5)
h <- hlist(5, f, g, a)


From rkoenker at illinois.edu  Wed Mar  2 19:40:58 2016
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 2 Mar 2016 12:40:58 -0600
Subject: [R] Functional programming?
In-Reply-To: <fda9aaa86cd74d6abf515c6910a4696a@CHIHT1.ad.uillinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
	<fda9aaa86cd74d6abf515c6910a4696a@CHIHT1.ad.uillinois.edu>
Message-ID: <DC4FD127-3777-4BB6-8207-658EFDB21DFD@illinois.edu>

Thanks, Duncan and Bert,

Duncan?s version does replicate my result, Bert?s does something a bit different,
now I just need some time to digest what you have done, and try to see how
and why.  Many thanks!!!

Roger

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Mar 2, 2016, at 12:23 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 02/03/2016 11:47 AM, Roger Koenker wrote:
>> I have a (remarkably ugly!!) code snippet  (below) that, given
>> two simple functions, f and g,  generates
>> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
>> better ways to do this.  I don?t particularly care about the returned list,
>> I?d be happy to have the final  h_K version of the function,
>> but I keep losing my way and running into the dreaded:
>> 
>> Error in h[[1]] : object of type 'closure' is not subsettable
>> or
>> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>> 
>> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
>> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
>> something more sensible lurking beneath this minimal (toy)  example.
>> 
>>     f <- function(u) function(x) u * x^2
>>     g <- function(u) function(x) u * log(x)
>>     set.seed(3)
>>     a <- runif(5)
>>     h <- list()
>>     hit <- list()
>>     h[[1]] <- f(a[1])
>>     hit[[1]] <- f(a[1])
>>     for(i in 2:5){
>> 	ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
>> 	h[[i]] <- eval(parse(text = ht))
>> 	hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
>> 	}
>>     x <- 1:99/10
>>     plot(x, h[[1]](x), type = "l")
>>     for(i in 2:5)
>> 	lines(x, h[[i]](x), col = i)
> 
> I don't understand what "hit" is for, but something like this should do it:
> 
> 
> hlist <- function(maxk, f,g,a) {
>   h <- list()
>   h[[1]] <- f(a[1])
>   for (j in 2:maxk) {
>     h[[j]] <- local({
>       k <- j
>       function(x) {
>         result <- h[[1]](x)
>         for (i in 2:k) {
>           result <- result*g(a[i])(x)
>         }
>         result
>       }
>     })
>   }
>   h
> }
> 
> f <- function(u) function(x) u * x^2
> g <- function(u) function(x) u * log(x)
> set.seed(3)
> a <- runif(5)
> h <- hlist(5, f, g, a)


From ddalthorp at usgs.gov  Wed Mar  2 20:04:45 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 2 Mar 2016 11:04:45 -0800
Subject: [R] Plot multiple similar equations in r
In-Reply-To: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
References: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
Message-ID: <CAJeYpE_nWcKZ=niXkd5Q=6Fj2jmKV4MTN0FGTMoaXtTe94NF3g@mail.gmail.com>

Or, if you want easy labels, you can play around with contour graphs.

?contour # will give you info on how to make contour plots

The basic idea is to construct a matrix of z-values...one z for every
combination of x and y
contour(x,y,z)

The x's would then be the x-values you want in
(0.37273*log(x)-1.79389))/0.17941 for whatever range of x's you want
The y's would be values from -5 to 5 (or whatever range you want)
The z's would be values like 0.4, 0.5, etc. or exp(y + x)

?outer # will tell you how to create z from x and y

x<-seq(1,10,length=100) # values for x-axis
y<-seq(2, 10, length=100) # values for y-axis
z<-exp(outer((0.37273*log(x)-1.79389)/0.17941,y,"+"))
contour(x,y,z,levels=seq(.1,1.1,by=.1))

-Dan

On Wed, Mar 2, 2016 at 9:03 AM, Jinggaofu Shi <js3786 at drexel.edu> wrote:

> Hi, there I am new on R. I want to plot a graph like this.
>
> The curves are created by these equations :
> (log(0.4)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.5)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.6)-(0.37273*log(x)-1.79389))/0.17941, etc. The equations are
> similar, the only difference is the first log(XXX). I already manually draw
> the graph by repeating plot() for each equation. But I think there must be
> a way to just assign a simple variable like x<-c(0.4,0.5,0.6,0.7), and then
> plot all the curves automatically. I tried to use data frame to make a set
> of equations, but failed. Could somebody help me? Thank you very much!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From mikko.korpela at aalto.fi  Wed Mar  2 20:25:02 2016
From: mikko.korpela at aalto.fi (Mikko Korpela)
Date: Wed, 2 Mar 2016 21:25:02 +0200
Subject: [R] Functional programming?
In-Reply-To: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
Message-ID: <56D73E0E.9080404@aalto.fi>

On 02.03.2016 18:47, Roger Koenker wrote:
> I have a (remarkably ugly!!) code snippet  (below) that, given
> two simple functions, f and g,  generates
> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
> better ways to do this.  I don?t particularly care about the returned list,
> I?d be happy to have the final  h_K version of the function,
> but I keep losing my way and running into the dreaded:
> 
> Error in h[[1]] : object of type 'closure' is not subsettable
> or
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
> 
> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
> something more sensible lurking beneath this minimal (toy)  example.
> 
>     f <- function(u) function(x) u * x^2
>     g <- function(u) function(x) u * log(x)
>     set.seed(3)
>     a <- runif(5)
>     h <- list()
>     hit <- list()
>     h[[1]] <- f(a[1])
>     hit[[1]] <- f(a[1])
>     for(i in 2:5){
> 	ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
> 	h[[i]] <- eval(parse(text = ht))
> 	hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
> 	}
>     x <- 1:99/10
>     plot(x, h[[1]](x), type = "l")
>     for(i in 2:5)
> 	lines(x, h[[i]](x), col = i)

Here is my (ugly?) suggestion:

f <- function(u) function(x) u * x^2
g <- function(u) function(x) u * log(x)
set.seed(3)
a <- runif(5)
h <- f(a[1])
for (i in 2:5) {
    body(h) <- call("*", body(h),
                    as.call(list(do.call("g", list(a[i])), quote(x))))
}

-- 
Mikko Korpela
Aalto University School of Science
Department of Computer Science


From ggrothendieck at gmail.com  Wed Mar  2 20:29:37 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 2 Mar 2016 14:29:37 -0500
Subject: [R] Functional programming?
In-Reply-To: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
Message-ID: <CAP01uRm-VsupsSUNudW7e9PpQfaGWeWcCXggvJDyhkgrLw1oSg@mail.gmail.com>

This manufactures the functions without using eval by using substitute
to substitute i-1 and a[i] into an expression for the body which is
then assigned to the body of the function:

hh <- vector("list", 5)
hh[[1]] <- f(a[1])
for(i in 2:5) {
     hh[[i]] <- hh[[1]]
     body(hh[[i]]) <- substitute(hh[[iprev]](x) * g(ai)(x), list(iprev
= i-1, ai = a[i]))
}
all.equal(h[[5]](.5), hh[[5]](.5)) # test
## [1] TRUE



This uses quote to define the body of h[[i]] as a call object and then
substitutes in the values of i-1 and a[i] assigning the result to the
body of h[[i]].

h <- vector("list", 5)
h[[1]] <- f(a[1])
for(i in 2:5) {
     h[[i]] <- h[[1]]
     body(hh[[i]]) <- do.call(substitute,
                                           list(quote(hh[[iprev]](x) *
g(ai)(x)),
                                           list(iprev = i-1, ai = a[i])))
}



On Wed, Mar 2, 2016 at 11:47 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> I have a (remarkably ugly!!) code snippet  (below) that, given
> two simple functions, f and g,  generates
> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
> better ways to do this.  I don?t particularly care about the returned list,
> I?d be happy to have the final  h_K version of the function,
> but I keep losing my way and running into the dreaded:
>
> Error in h[[1]] : object of type 'closure' is not subsettable
> or
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>
> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
> something more sensible lurking beneath this minimal (toy)  example.
>
>     f <- function(u) function(x) u * x^2
>     g <- function(u) function(x) u * log(x)
>     set.seed(3)
>     a <- runif(5)
>     h <- list()
>     hit <- list()
>     h[[1]] <- f(a[1])
>     hit[[1]] <- f(a[1])
>     for(i in 2:5){
>         ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
>         h[[i]] <- eval(parse(text = ht))
>         hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
>         }
>     x <- 1:99/10
>     plot(x, h[[1]](x), type = "l")
>     for(i in 2:5)
>         lines(x, h[[i]](x), col = i)
>
> Thanks,
> Roger
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter.4567 at gmail.com  Wed Mar  2 21:17:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 2 Mar 2016 12:17:26 -0800
Subject: [R] Functional programming?
In-Reply-To: <DC4FD127-3777-4BB6-8207-658EFDB21DFD@illinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
	<fda9aaa86cd74d6abf515c6910a4696a@CHIHT1.ad.uillinois.edu>
	<DC4FD127-3777-4BB6-8207-658EFDB21DFD@illinois.edu>
Message-ID: <CAGxFJbRGESai3Txagn4CX+k+heDO=fGXzG1D9e5jy3L5gG-W2Q@mail.gmail.com>

Thanks, Roger:

I think Duncan's approach is far more efficient, but I believe the
following replicates your result and may be a bit easier to
understand.

f <- function(u) function(x) u * x^2
g <- function(u) function(x) u * log(x)
set.seed(3)
a <- runif(5)
h <- list()
hit <- list()
h[[1]] <- f(a[1])
hit[[1]] <- f(a[1])
for(i in 2:5) h[[i]] <- eval(bquote(function(x)h[[.(i-1)]](x)*g(a[.(i)])(x)))
x <- 1:99/10
plot(x, h[[1]](x), type = "l")
for(i in 2:5){
  lines(x, h[[i]](x), col = i)
}

This uses recursion to "unwind" h[[i]] each time it's called, ergo
the inefficiency. But in that sense,anyway,  it seems to be more
"functional."

But certainly feel free to ignore.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 2, 2016 at 10:40 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> Thanks, Duncan and Bert,
>
> Duncan?s version does replicate my result, Bert?s does something a bit different,
> now I just need some time to digest what you have done, and try to see how
> and why.  Many thanks!!!
>
> Roger
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
>
>> On Mar 2, 2016, at 12:23 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 02/03/2016 11:47 AM, Roger Koenker wrote:
>>> I have a (remarkably ugly!!) code snippet  (below) that, given
>>> two simple functions, f and g,  generates
>>> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
>>> better ways to do this.  I don?t particularly care about the returned list,
>>> I?d be happy to have the final  h_K version of the function,
>>> but I keep losing my way and running into the dreaded:
>>>
>>> Error in h[[1]] : object of type 'closure' is not subsettable
>>> or
>>> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>>>
>>> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
>>> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
>>> something more sensible lurking beneath this minimal (toy)  example.
>>>
>>>     f <- function(u) function(x) u * x^2
>>>     g <- function(u) function(x) u * log(x)
>>>     set.seed(3)
>>>     a <- runif(5)
>>>     h <- list()
>>>     hit <- list()
>>>     h[[1]] <- f(a[1])
>>>     hit[[1]] <- f(a[1])
>>>     for(i in 2:5){
>>>      ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
>>>      h[[i]] <- eval(parse(text = ht))
>>>      hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
>>>      }
>>>     x <- 1:99/10
>>>     plot(x, h[[1]](x), type = "l")
>>>     for(i in 2:5)
>>>      lines(x, h[[i]](x), col = i)
>>
>> I don't understand what "hit" is for, but something like this should do it:
>>
>>
>> hlist <- function(maxk, f,g,a) {
>>   h <- list()
>>   h[[1]] <- f(a[1])
>>   for (j in 2:maxk) {
>>     h[[j]] <- local({
>>       k <- j
>>       function(x) {
>>         result <- h[[1]](x)
>>         for (i in 2:k) {
>>           result <- result*g(a[i])(x)
>>         }
>>         result
>>       }
>>     })
>>   }
>>   h
>> }
>>
>> f <- function(u) function(x) u * x^2
>> g <- function(u) function(x) u * log(x)
>> set.seed(3)
>> a <- runif(5)
>> h <- hlist(5, f, g, a)
>


From elopomorph at hotmail.com  Wed Mar  2 21:31:56 2016
From: elopomorph at hotmail.com (Michael)
Date: Wed, 2 Mar 2016 20:31:56 +0000
Subject: [R] output my results into Excel
Message-ID: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>

I can get R to calculate the distance that I want between my data points.  However, I am stuck trying to get R to output the data so I can paste it into Excel.  Instead, R outputs a matrix mess in the console.

Below are the steps I am taking to calculate the distance between my data.  Also, I have 42 different data points.

# Calculate the Euclidean distance between each datapoint using
# the function dist()

PRdist = dist(my_data) ;  PRdist

I would greatly appreciate if someone can tell me how to output my matrix from the dist function into something I can paste into Excel.

Mike




	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Mar  2 21:49:08 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 2 Mar 2016 15:49:08 -0500
Subject: [R] output my results into Excel
In-Reply-To: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <CAM_vjuk19w8b-z+MGEEc0Nf3ojeBkUp2Q25LzRp64oEA0JQk-Q@mail.gmail.com>

Hi Michael,

Googling "export R data to Excel" gives LOTS of advice, including
packages that can write your data directly to Excel spreadsheets.

I don't use Excel, so I haven't tried any of those, but using
write.csv() to export your data will create something that my
colleagues who use Excel have no trouble opening.

Printing to the console, as you did by typing the object name, is not
intended to be an export method.

Sarah

On Wed, Mar 2, 2016 at 3:31 PM, Michael <elopomorph at hotmail.com> wrote:
> I can get R to calculate the distance that I want between my data points.  However, I am stuck trying to get R to output the data so I can paste it into Excel.  Instead, R outputs a matrix mess in the console.
>
> Below are the steps I am taking to calculate the distance between my data.  Also, I have 42 different data points.
>
> # Calculate the Euclidean distance between each datapoint using
> # the function dist()
>
> PRdist = dist(my_data) ;  PRdist
>
> I would greatly appreciate if someone can tell me how to output my matrix from the dist function into something I can paste into Excel.
>
> Mike
>
>
--


From ddalthorp at usgs.gov  Wed Mar  2 21:50:45 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 2 Mar 2016 12:50:45 -0800
Subject: [R] output my results into Excel
In-Reply-To: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <CAJeYpE_y1i3p0W7mS=vu9iFbXeYVjewZgkyeNXZe+uCXMVW+NQ@mail.gmail.com>

Hi Michael,
If you are working in Windows:

# You can put the matrix directly into the clipboard
write.table(PRdist, file = 'clipboard', sep = '\t', row.names = F,
col.names = F)

The "sep" argument tells what character to use for separating columns.
Default for Excel is tab (i.e. '\t')

Default for write.table on a matrix or 2-d array is to write column names
(as "V1", "V2", etc.) and row names ("1", "2", etc.). If you don't want
those added to your matrix, tell R via row.names = FALSE, col.names = FALSE



-Dan

On Wed, Mar 2, 2016 at 12:31 PM, Michael <elopomorph at hotmail.com> wrote:

> I can get R to calculate the distance that I want between my data points.
> However, I am stuck trying to get R to output the data so I can paste it
> into Excel.  Instead, R outputs a matrix mess in the console.
>
> Below are the steps I am taking to calculate the distance between my
> data.  Also, I have 42 different data points.
>
> # Calculate the Euclidean distance between each datapoint using
> # the function dist()
>
> PRdist = dist(my_data) ;  PRdist
>
> I would greatly appreciate if someone can tell me how to output my matrix
> from the dist function into something I can paste into Excel.
>
> Mike
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Wed Mar  2 22:10:02 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 2 Mar 2016 13:10:02 -0800
Subject: [R] output my results into Excel
In-Reply-To: <BLUPR13MB0065E79BC2B69BA22B6A9DD1DEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB006506D9893F02F43797B3AFDEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
	<CAJeYpE_y1i3p0W7mS=vu9iFbXeYVjewZgkyeNXZe+uCXMVW+NQ@mail.gmail.com>
	<BLUPR13MB0065E79BC2B69BA22B6A9DD1DEBC0@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <CAJeYpE_yWx0x50=-FF9G_XBs-6Pdw7fzHpEPiLtzeYr=x2WDTQ@mail.gmail.com>

Sorry, I was assuming your data was a matrix (as you indicated in your
question).

Try:

write.table(as.matrix(PRdist), file = 'clipboard', sep = '\t', row.names =
F, col.names = F)

-Dan

On Wed, Mar 2, 2016 at 1:01 PM, Michael <elopomorph at hotmail.com> wrote:

> I got an error message.
>
>
> > write.table(PRdist, file = 'clipboard', sep = '\t', row.names = F,
> col.names = F)
> Error in as.data.frame.default(x[[i]], optional = TRUE) :
>   cannot coerce class ""dist"" to a data.frame
>
> I think because my PRdist is a value, not a data frame.  However, I am not
> sure.  Any advice?
>
>
> Thanks for your help.
>
>
> Mike
>
>
> ------------------------------
> *From:* Dalthorp, Daniel <ddalthorp at usgs.gov>
> *Sent:* Wednesday, March 2, 2016 3:50 PM
> *To:* Michael
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] output my results into Excel
>
> Hi Michael,
> If you are working in Windows:
>
> # You can put the matrix directly into the clipboard
> write.table(PRdist, file = 'clipboard', sep = '\t', row.names = F,
> col.names = F)
>
> The "sep" argument tells what character to use for separating columns.
> Default for Excel is tab (i.e. '\t')
>
> Default for write.table on a matrix or 2-d array is to write column names
> (as "V1", "V2", etc.) and row names ("1", "2", etc.). If you don't want
> those added to your matrix, tell R via row.names = FALSE, col.names = FALSE
>
>
>
> -Dan
>
> On Wed, Mar 2, 2016 at 12:31 PM, Michael <elopomorph at hotmail.com> wrote:
>
>> I can get R to calculate the distance that I want between my data
>> points.  However, I am stuck trying to get R to output the data so I can
>> paste it into Excel.  Instead, R outputs a matrix mess in the console.
>>
>> Below are the steps I am taking to calculate the distance between my
>> data.  Also, I have 42 different data points.
>>
>> # Calculate the Euclidean distance between each datapoint using
>> # the function dist()
>>
>> PRdist = dist(my_data) ;  PRdist
>>
>> I would greatly appreciate if someone can tell me how to output my matrix
>> from the dist function into something I can paste into Excel.
>>
>> Mike
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
>
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Mar  2 22:22:26 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 2 Mar 2016 21:22:26 +0000
Subject: [R] Plot multiple similar equations in r
In-Reply-To: <CAJeYpE_nWcKZ=niXkd5Q=6Fj2jmKV4MTN0FGTMoaXtTe94NF3g@mail.gmail.com>
References: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
	<CAJeYpE_nWcKZ=niXkd5Q=6Fj2jmKV4MTN0FGTMoaXtTe94NF3g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70EC2E@mb02.ads.tamu.edu>

Another way would be to use matplot() or matlines():

> lx<-c(0.4, 0.5, 0.6, 0.7)
> x <- seq(1, 8, length.out=100)
> myfun <- function(x, k) {(log(k)-(0.37273*log(x)-1.79389))/0.17941}
> y <- sapply(lx, function(k) myfun(x, k))
> matplot(x, a, type="l", col="black", lty=1)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dalthorp, Daniel
Sent: Wednesday, March 2, 2016 1:05 PM
To: Jinggaofu Shi
Cc: r-help at R-project.org (r-help at r-project.org)
Subject: Re: [R] Plot multiple similar equations in r

Or, if you want easy labels, you can play around with contour graphs.

?contour # will give you info on how to make contour plots

The basic idea is to construct a matrix of z-values...one z for every
combination of x and y
contour(x,y,z)

The x's would then be the x-values you want in
(0.37273*log(x)-1.79389))/0.17941 for whatever range of x's you want
The y's would be values from -5 to 5 (or whatever range you want)
The z's would be values like 0.4, 0.5, etc. or exp(y + x)

?outer # will tell you how to create z from x and y

x<-seq(1,10,length=100) # values for x-axis
y<-seq(2, 10, length=100) # values for y-axis
z<-exp(outer((0.37273*log(x)-1.79389)/0.17941,y,"+"))
contour(x,y,z,levels=seq(.1,1.1,by=.1))

-Dan

On Wed, Mar 2, 2016 at 9:03 AM, Jinggaofu Shi <js3786 at drexel.edu> wrote:

> Hi, there I am new on R. I want to plot a graph like this.
>
> The curves are created by these equations :
> (log(0.4)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.5)-(0.37273*log(x)-1.79389))/0.17941,
> (log(0.6)-(0.37273*log(x)-1.79389))/0.17941, etc. The equations are
> similar, the only difference is the first log(XXX). I already manually draw
> the graph by repeating plot() for each equation. But I think there must be
> a way to just assign a simple variable like x<-c(0.4,0.5,0.6,0.7), and then
> plot all the curves automatically. I tried to use data frame to make a set
> of equations, but failed. Could somebody help me? Thank you very much!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Wed Mar  2 23:16:09 2016
From: frainj at gmail.com (John C Frain)
Date: Wed, 2 Mar 2016 22:16:09 +0000
Subject: [R] Seasonal Cointegration
In-Reply-To: <CAM_vju=yZmx7z8MzsmzMxU+JksqhvUJ+WFetvpGvc+k6NB0nvg@mail.gmail.com>
References: <CAOy3Z4DnpkqcEejBtJYZhFvm1+MZfd-yK9UeuzE0pm=AsVLW=Q@mail.gmail.com>
	<CAM_vju=yZmx7z8MzsmzMxU+JksqhvUJ+WFetvpGvc+k6NB0nvg@mail.gmail.com>
Message-ID: <CAHrK516mq08fqeW0DbRAPBW8Yo_GK+eHBRQZDbckJz90Hdkfwg@mail.gmail.com>

tRY HEGY.test() in R package pdr.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 29 February 2016 at 19:14, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Checking Rseek.org turns up this discussion thread:
> http://blog.gmane.org/gmane.comp.lang.r.r-metrics/month=20130601
> which talks about the lack of that method in R.
>
> Sarah
>
> On Mon, Feb 29, 2016 at 2:08 PM, Rafael Costa
> <rafaelcarneirocosta.rc at gmail.com> wrote:
> > Dear R users,
> >
> > Where can I find the codes to Seasonal Coitegration tests (known as EGHL
> > test)? This test was presented on paper ?Seasonal Cointegration: The
> > Japanese Consumption Function.? (Engle, R.F., C.W.J. Granger, S.
> Hylleberg,
> > and H.S. Lee; 1993).
> >
> > I am looking forward  any help.
> >
> > Thanks in advance ,
> >
> > Rafael Costa.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From J.Hillier at lboro.ac.uk  Wed Mar  2 19:00:07 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Wed, 2 Mar 2016 18:00:07 +0000
Subject: [R] Problem installing packages: cannot open file
 '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf'
In-Reply-To: <AM3PR04MB149073365ABB5BACAF678A01A1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB149073365ABB5BACAF678A01A1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <AM3PR04MB149014DFEC23F16391F3893DA1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>


Dear All,


I am a relative newbie to R, and am struggling to install packages on my laptop (although I have managed to on my desktop and a borrowed departmental laptop).


I have tried various packages with the same result. Illustration for

> install.packages("outliers")


.... leads to .....


Error in file(con, "r") : cannot open the connection
Calls: <Anonymous> -> sub -> grep -> readLines -> file
In addition: Warning message:
In file(con, "r") :
  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory

I have tried in both the R environment on command line, and in RStudio, with the same result, and reinstalled and updated both r-base and rstudio-desktop via fink.  Both using a CRAN mirror and using a download (outliers_0.14.tar.gz) seem to produce the same result, and I think they're both working as the output says 'downloaded' (see below)


> install.packages("outliers")
Installing package into ?
(as ? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
Content type 'application/x-gzip' length 15090 bytes (14 KB)
==================================================
downloaded 14 KB


>From looking aroud on the web it seems that the message "In file(con, "r") : cannot open file" just means that R cannot find a file it thinks it needs. However, I've looked in /sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/ both on this machine and the other laptop that is able to install packages, and 'Makeconf' is not in ether of them.


So, I'm thoroughly confused and have run out of ideas.


Please help.


I hope that this is something simple that I'm missing.  If so, a pointer to a manual page or instructions would be gratefully received.


John


p.s - Full output in sequence in case it's useful.


> install.packages("outliers")
Installing package into ?
(as ? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
Content type 'application/x-gzip' length 15090 bytes (14 KB)
==================================================
downloaded 14 KB

Error in file(con, "r") : cannot open the connection
Calls: <Anonymous> -> sub -> grep -> readLines -> file
In addition: Warning message:
In file(con, "r") :
  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory

The downloaded source packages are in
        ?
Warning message:
In install.packages("outliers") :
  installation of package ? had non-zero exit status





-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

	[[alternative HTML version deleted]]


From alaasindi at icloud.com  Wed Mar  2 21:21:44 2016
From: alaasindi at icloud.com (Alaa Sindi)
Date: Wed, 02 Mar 2016 15:21:44 -0500
Subject: [R] help in maximum likelihood
In-Reply-To: <cd5230e4a3ac4f92abc95363183d2e8f@ESGEBEX10.win.ad.jhu.edu>
References: <cd5230e4a3ac4f92abc95363183d2e8f@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <43284B1A-AF5A-4E8A-8162-CBBD8DC01F90@icloud.com>

Thank you very much prof. Ravi,

That was very helpful. Is there a way to get the t and p value for the coefficients?

Thanks 
Alaa
> On Mar 2, 2016, at 10:05 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> 
> There is nothing wrong with the optimization.  It is a warning message.  However, this is a good example to show that one should not simply dismiss a warning before understanding what it means.  The MLE parameters are also large, indicating that there is something funky about the model or the data or both.  In your case, there is one major problem with the data:  for the highest dose (value of x), you have all subjects responding, i.e. y = n.  Even for the next lower dose, there is almost complete response.  Where do these data come from? Are they real or fake (simulated) data?
>  
> Also, take a look at the eigenvalues of the hessian at the solution.  You will see that there is some ill-conditioning, as the eigenvalues are widely separated.
>  
> x <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
> y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
> n <- c(59, 60, 62, 56, 63, 59, 62, 60)
>  
> # note: there is no need to have the choose(n, y) term in the likelihood
> fn <- function(p)
>     sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))) )
>  
> out <- nlm(fn, p = c(-50,20), hessian = TRUE)
>  
> out
>  
> eigen(out$hessian)
>  
>  
> Hope this is helpful,
> Ravi
>  
>  
>  
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>  


	[[alternative HTML version deleted]]


From 911mruofei at tongji.edu.cn  Wed Mar  2 22:06:18 2016
From: 911mruofei at tongji.edu.cn (=?gb2312?B?UnVvZmVpIE1vob7Eqsj0t8mhvw==?=)
Date: Wed, 2 Mar 2016 16:06:18 -0500
Subject: [R] Ruofei Mo - How can I generate correlated data with non-normal
	distribution?
Message-ID: <009d01d174c7$5fa1acc0$1ee50640$@tongji.edu.cn>

Hi, All,

 

I have a question about how to generate correlated data with non-normal
distribution? Basic, I have a variable a that follows a normal distribution,
a ~ N(0,1), then I want to generate another variable b that follows a
uniform distribution, b ~ U(0, 1). Most importantly, I want the correlation
between a and b to be fixed at -.9, cor(a,b) = -.90

 

I tried the following code,

 

### Correlation matrix rmvnorm() function ###

  Cormat <- matrix(c(1, -.9, -.9, 1), ncol = 2)   # Here, I want to create 2
variables that have correlation -.9

  

  ### Theta-Transform-Guessing ###

  DataSet <- data.frame(rmvnorm(1000, mean=c(0, 0), sigma=Cormat))

  Names(DataSet) <- c("a", "trans")

  

  ### Using trans to be transformed into guessing parameters ###

  DataSet$b <- pnorm(DataSet$trans, mean=mean(DataSet$trans),
sd=sd(DataSet$trans)) # Here, I used the pnorm() function to transform one
variable to a U(0, 1)

 

However, the correlation is changed. Can anyone give me some suggestion that
how can I generate the data?

 

Thanks,

Ruofei


	[[alternative HTML version deleted]]


From js3786 at drexel.edu  Wed Mar  2 23:52:20 2016
From: js3786 at drexel.edu (Jinggaofu Shi)
Date: Wed, 2 Mar 2016 17:52:20 -0500
Subject: [R] How to refer a variable in quotes
Message-ID: <CAMb6gE6yq5ywOMf6ZzAOj7U+2oCa1_2ibndpYZ-uZAd-07MA4A@mail.gmail.com>

Hi, there
I am new to R, here is an urgent question.
I want to save several graphs by a for loop. But I don't know how to refer
the variable in the quotes.
Here is my code.

g<-c("g1","g2","g3","g4","g5","g6","g7","g8","g9")
for (u in 1:9) {pdf("g[u]".pdf")
+ plot(1,1, xlim=range(x), ylim=c(-5,5), type='n', xlab ="Femur length
(mm)", ylab = "Z-Score")
+ mtext("g[u]", side = 4)
+ for (i in z) {
+ lines(x,(log(i)-(m[u]*log(x)+c[u]))/r[u])
+ miny<-(log(i)-(m[u]*log(max(x))+c[u]))/r[u]
+ maxx <- exp((log(i)-c[u]+5*r[u])/m[u]);
+ if (miny > -5) {text(max(x),miny+0.3,i)
+ }else {text(maxx+2, -5+0.3,i)}
+  }
+ dev.off()
+ }

In the second line, I want to refer the variable 'g[n]' to the file name
and fifth line i also want to refer the variable as a note. How should I
do? Thank you very much!

-- 
Sincerely,
Jinggaofu Shi
4029 Spring Garden Street
Philadelphia, PA 19104
Email: shijinggaofu at gmail.com
Phone: 215-847-9145

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Wed Mar  2 23:55:35 2016
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 2 Mar 2016 16:55:35 -0600
Subject: [R] Functional programming?
In-Reply-To: <3d1234aa782e49c4908a2403234d0c64@CITESHT1.ad.uillinois.edu>
References: <3D6E9AAB-1BA6-4E2D-AF26-824772E7EE5A@illinois.edu>
	<3d1234aa782e49c4908a2403234d0c64@CITESHT1.ad.uillinois.edu>
Message-ID: <CCCDEA5D-A186-4382-A3CB-5097ADE755E8@illinois.edu>

Thanks again to all.  This was highly educational for me.  As it turned out
Mikiko's suggestion turned out to be most easily adaptable to my real problem.
I?m not at all able to evaluate relative efficiency at this point, but fortunately this isn?t
an important factor (so far) in what I?m trying to do.

As always the knowledge and generosity of the R-help community is inspiring.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Mar 2, 2016, at 1:25 PM, Mikko Korpela <mikko.korpela at aalto.fi> wrote:
> 
> On 02.03.2016 18:47, Roger Koenker wrote:
>> I have a (remarkably ugly!!) code snippet  (below) that, given
>> two simple functions, f and g,  generates
>> a list of new functions h_{k+1} =  h_k * g, k= 1, ?, K.  Surely, there are vastly
>> better ways to do this.  I don?t particularly care about the returned list,
>> I?d be happy to have the final  h_K version of the function,
>> but I keep losing my way and running into the dreaded:
>> 
>> Error in h[[1]] : object of type 'closure' is not subsettable
>> or
>> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
>> 
>> Mainly I?d like to get rid of the horrible, horrible paste/parse/eval evils.  Admittedly
>> the f,g look a bit strange, so you may have to suspend disbelief to imagine that there is
>> something more sensible lurking beneath this minimal (toy)  example.
>> 
>>    f <- function(u) function(x) u * x^2
>>    g <- function(u) function(x) u * log(x)
>>    set.seed(3)
>>    a <- runif(5)
>>    h <- list()
>>    hit <- list()
>>    h[[1]] <- f(a[1])
>>    hit[[1]] <- f(a[1])
>>    for(i in 2:5){
>> 	ht <- paste("function(x) h[[", i-1, "]](x) * g(", a[i], ")(x)")
>> 	h[[i]] <- eval(parse(text = ht))
>> 	hit[[i]] <- function(x) {force(i); return(h[[i]] (x))}
>> 	}
>>    x <- 1:99/10
>>    plot(x, h[[1]](x), type = "l")
>>    for(i in 2:5)
>> 	lines(x, h[[i]](x), col = i)
> 
> Here is my (ugly?) suggestion:
> 
> f <- function(u) function(x) u * x^2
> g <- function(u) function(x) u * log(x)
> set.seed(3)
> a <- runif(5)
> h <- f(a[1])
> for (i in 2:5) {
>    body(h) <- call("*", body(h),
>                    as.call(list(do.call("g", list(a[i])), quote(x))))
> }
> 
> -- 
> Mikko Korpela
> Aalto University School of Science
> Department of Computer Science


From bgunter.4567 at gmail.com  Thu Mar  3 00:17:05 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 2 Mar 2016 15:17:05 -0800
Subject: [R] How to refer a variable in quotes
In-Reply-To: <CAMb6gE6yq5ywOMf6ZzAOj7U+2oCa1_2ibndpYZ-uZAd-07MA4A@mail.gmail.com>
References: <CAMb6gE6yq5ywOMf6ZzAOj7U+2oCa1_2ibndpYZ-uZAd-07MA4A@mail.gmail.com>
Message-ID: <CAGxFJbRCRYSjaNP4dcp6uKOot-TdjXukb+L1Kvba=eaf=mFRfg@mail.gmail.com>

1. Please spend some time with an R tutorial or two to become familiar
with R basics.

2. Please do not post in HTML. This is a plain text email list.

3. See e.g. ?sprintf  or ?paste  for your problem.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 2, 2016 at 2:52 PM, Jinggaofu Shi <js3786 at drexel.edu> wrote:
> Hi, there
> I am new to R, here is an urgent question.
> I want to save several graphs by a for loop. But I don't know how to refer
> the variable in the quotes.
> Here is my code.
>
> g<-c("g1","g2","g3","g4","g5","g6","g7","g8","g9")
> for (u in 1:9) {pdf("g[u]".pdf")
> + plot(1,1, xlim=range(x), ylim=c(-5,5), type='n', xlab ="Femur length
> (mm)", ylab = "Z-Score")
> + mtext("g[u]", side = 4)
> + for (i in z) {
> + lines(x,(log(i)-(m[u]*log(x)+c[u]))/r[u])
> + miny<-(log(i)-(m[u]*log(max(x))+c[u]))/r[u]
> + maxx <- exp((log(i)-c[u]+5*r[u])/m[u]);
> + if (miny > -5) {text(max(x),miny+0.3,i)
> + }else {text(maxx+2, -5+0.3,i)}
> +  }
> + dev.off()
> + }
>
> In the second line, I want to refer the variable 'g[n]' to the file name
> and fifth line i also want to refer the variable as a note. How should I
> do? Thank you very much!
>
> --
> Sincerely,
> Jinggaofu Shi
> 4029 Spring Garden Street
> Philadelphia, PA 19104
> Email: shijinggaofu at gmail.com
> Phone: 215-847-9145
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Mar  3 00:37:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 3 Mar 2016 10:37:55 +1100
Subject: [R] How to refer a variable in quotes
In-Reply-To: <CAMb6gE6yq5ywOMf6ZzAOj7U+2oCa1_2ibndpYZ-uZAd-07MA4A@mail.gmail.com>
References: <CAMb6gE6yq5ywOMf6ZzAOj7U+2oCa1_2ibndpYZ-uZAd-07MA4A@mail.gmail.com>
Message-ID: <CA+8X3fUrGfc5OYNdVbVYXG_Q+UeoJmzVrn+EoHAnR26SZvUqiw@mail.gmail.com>

Hi Jinggaofu,
Try this:

for(u in 1:9) {
 pdffile<-paste(g[u],".pdf",sep="")
 pdf(pdffile)
...
mtext(g[u],side=4)

If you index the vector g, it will return one or more character strings.

Jim


On Thu, Mar 3, 2016 at 9:52 AM, Jinggaofu Shi <js3786 at drexel.edu> wrote:
> Hi, there
> I am new to R, here is an urgent question.
> I want to save several graphs by a for loop. But I don't know how to refer
> the variable in the quotes.
> Here is my code.
>
> g<-c("g1","g2","g3","g4","g5","g6","g7","g8","g9")
> for (u in 1:9) {pdf("g[u]".pdf")
> + plot(1,1, xlim=range(x), ylim=c(-5,5), type='n', xlab ="Femur length
> (mm)", ylab = "Z-Score")
> + mtext("g[u]", side = 4)
> + for (i in z) {
> + lines(x,(log(i)-(m[u]*log(x)+c[u]))/r[u])
> + miny<-(log(i)-(m[u]*log(max(x))+c[u]))/r[u]
> + maxx <- exp((log(i)-c[u]+5*r[u])/m[u]);
> + if (miny > -5) {text(max(x),miny+0.3,i)
> + }else {text(maxx+2, -5+0.3,i)}
> +  }
> + dev.off()
> + }
>
> In the second line, I want to refer the variable 'g[n]' to the file name
> and fifth line i also want to refer the variable as a note. How should I
> do? Thank you very much!
>
> --
> Sincerely,
> Jinggaofu Shi
> 4029 Spring Garden Street
> Philadelphia, PA 19104
> Email: shijinggaofu at gmail.com
> Phone: 215-847-9145
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Mar  3 00:46:11 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Mar 2016 23:46:11 +0000
Subject: [R]
	=?utf-8?q?Ruofei_Mo_-_How_can_I_generate_correlated_data_with?=
	=?utf-8?q?_non-normal=09distribution=3F?=
References: <009d01d174c7$5fa1acc0$1ee50640$@tongji.edu.cn>
Message-ID: <loom.20160303T003533-594@post.gmane.org>

Ruofei Mo????? <911mruofei <at> tongji.edu.cn> writes:

> 
> Hi, All,
> 
> I have a question about how to generate correlated data with non-normal
> distribution? Basic, I have a variable a that follows a normal distribution,
> a ~ N(0,1), then I want to generate another variable b that follows a
> uniform distribution, b ~ U(0, 1). Most importantly, I want the correlation
> between a and b to be fixed at -.9, cor(a,b) = -.90
> 
> I tried the following code,
> 
> ### Correlation matrix rmvnorm() function ###
> 

  I don't know that there's a closed-form solution to this problem.
Here's an attempt to do it by brute force.  By eyeball, you need to
set the nominal rho to about -0.92 to get a realized rho of -0.9.

simfun <- function(rho,n=10000) {
    cormat <- matrix(c(1, rho, rho, 1), ncol = 2)
    dd <- setNames(data.frame(MASS::mvrnorm(1000, mu=c(0,0), Sigma=cormat)),
                   c("a","trans"))
    dd <- transform(dd,
               b=pnorm(trans,mean(trans),sd(trans)))
    dd[,c("a","b")]
}

cvec <- seq(-0.999,-0.85,length=51)
res <- expand.grid(rho=cvec,rep=1:10)
set.seed(101)
res$cor <- sapply(res$rho,
                  function(r) cor(simfun(rho=r,n1e6))[1,2])

par(las=1,bty="l")
plot(cor~rho,data=res)
abline(a=0,b=1,col=2)
abline(h=-0.9,col=4)
abline(v=-0.92,col=4)

From dwinsemius at comcast.net  Thu Mar  3 01:31:49 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Mar 2016 16:31:49 -0800
Subject: [R] Problem installing packages: cannot open file
	'/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf'
In-Reply-To: <AM3PR04MB149014DFEC23F16391F3893DA1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB149073365ABB5BACAF678A01A1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<AM3PR04MB149014DFEC23F16391F3893DA1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <3DC74D54-D42F-4A94-8493-E3D0DA188A08@comcast.net>


> On Mar 2, 2016, at 10:00 AM, John Hillier <J.Hillier at lboro.ac.uk> wrote:
> 
> 
> Dear All,
> 
> 
> I am a relative newbie to R, and am struggling to install packages on my laptop (although I have managed to on my desktop and a borrowed departmental laptop).
> 

The words "my laptop" is rather uninformative. Based on the path below I guessing OSX.
> 
> I have tried various packages with the same result. Illustration for
> 
>> install.packages("outliers")
> 
> 
> .... leads to .....
> 
> 
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory

Installing R inside /sw/.. directory is not a standard location. What does this return:

Sys.getenv( "R_HOME" )

On my version of OSX 10.11 with R installed from the "standard" binary installer package, it returns
[1] "/Library/Frameworks/R.framework/Resources"

> 
> I have tried in both the R environment on command line, and in RStudio, with the same result, and reinstalled and updated both r-base and rstudio-desktop via fink.

fink ,,,, That's probably the reason (again if this is a Mac.) The default installation location is not being chosen. I don't understand why you are not using the binary installer. I've never seen anyone use fink for installation on a Mac but have heard of attempts with MacPorts and homebrew. Simon Urbanek says if you use one of those package installers you are "on your own".  That's a route you should only consider if you have serious NIX-skills.

>  Both using a CRAN mirror and using a download (outliers_0.14.tar.gz) seem to produce the same result, and I think they're both working as the output says 'downloaded' (see below)
> 
> 
>> install.packages("outliers")
> Installing package into ?
> (as ? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
> Content type 'application/x-gzip' length 15090 bytes (14 KB)
> ==================================================
> downloaded 14 KB
> 
> 
>> From looking aroud on the web it seems that the message "In file(con, "r") : cannot open file" just means that R cannot find a file it thinks it needs. However, I've looked in /sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/ both on this machine and the other laptop that is able to install packages, and 'Makeconf' is not in ether of them.

I do have a copy of that program in:

/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf


> 
> 
> So, I'm thoroughly confused and have run out of ideas.

The correct place to post questions about Mac installations is:

r-sig-mac at r-project.org

>Please help.
> 
> 
> I hope that this is something simple that I'm missing.  If so, a pointer to a manual page or instructions would be gratefully received.

https://cran.rstudio.com/bin/macosx/

> 
> 
> John
> 
> 
> p.s - Full output in sequence in case it's useful.
> 
> 
>> install.packages("outliers")
> Installing package into ?
> (as ? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
> Content type 'application/x-gzip' length 15090 bytes (14 KB)
> ==================================================
> downloaded 14 KB
> 
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory
> 
> The downloaded source packages are in
>        ?
> Warning message:
> In install.packages("outliers") :
>  installation of package ? had non-zero exit status
> 
> 
> 
> 
> 
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Sebastien.Bihorel at cognigencorp.com  Thu Mar  3 02:07:47 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Wed, 2 Mar 2016 20:07:47 -0500
Subject: [R] Help with step.gam
Message-ID: <56D78E63.30406@cognigencorp.com>

Hi,

When very simple models are tested in step.gam, I have observed the some 
difference in the final output result based upon the version of the 
package tested.  Is this an expected behavior or a bug in the latest 
version of the gam package?

With gam 1.4:
 > data(gam.data)
 > gam.object <- gam(y~1, data=gam.data)
 > step.object <- step.gam(gam.object, scope=list(x=c('1','x')))
Start:  y ~ 1; AIC= 232.8823
Trial:  y ~  x; AIC= 126.5148
Step :  y ~ x ; AIC= 126.5148
 > step.object
Call:
gam(formula = y ~ x, data = gam.data, trace = FALSE)

Degrees of Freedom: 99 total; 98 Residual
Residual Deviance: 19.53955

With gam 1.9.1 or 1.12:
 > data(gam.data)
 > gam.object <- gam(y~1, data=gam.data)
 > step.object <- step.gam(gam.object, scope=list(x=c('1','x')))
Start:  y ~ 1; AIC= 232.8823
Step:1 y ~ x ; AIC= 126.5148
 > step.object
NULL

Thank you

Sebastien


From mashranga at yahoo.com  Thu Mar  3 03:05:37 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 3 Mar 2016 02:05:37 +0000 (UTC)
Subject: [R] Extract row form a dataframe by row names in another vector and
 factor . Need explanation
References: <61484388.2733173.1456970737104.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <61484388.2733173.1456970737104.JavaMail.yahoo@mail.yahoo.com>

Hi,Here i have written an example to explain my problem
## Data Generationdat<-data.frame(matrix(1:50,ncol=5))
rownames(dat)<-letters[1:10]
colnames(dat)<- c("SA1","SA2","SA3","SA4","SA5")

dat1<-data.frame(matrix(letters[1:20],ncol=4))
colnames(dat1)<-c("AA","BB","CC","DD")

## Row names
v1<-dat1[,"BB"] ? ? ? ? ? ? ? ? ? # Factor
v2<-as.vector(dat1[,"BB"]) ?# Vector

is(v1) # Factor
is(v2) # Vector

# Result
res1<-dat[v1,]
res2<-dat[v2,]
##########################################################i assumed res1 and res2 are same .?but it is not .?Can any body please explain why ??
?
?
Tanvir Ahamed 
G?teborg, Sweden??| mashranga at yahoo.com
	[[alternative HTML version deleted]]


From abinnogoes at gmail.com  Thu Mar  3 06:47:36 2016
From: abinnogoes at gmail.com (Moss Moss)
Date: Wed, 2 Mar 2016 21:47:36 -0800
Subject: [R] Help me
Message-ID: <CACxOM1tceFnAELtOZEKZQ2A2ebPWiPtvKT0bwo9BqRFxWcJvcw@mail.gmail.com>

Please, I need help from you. I am new to R.

I installed R, Rstudio and R Crans or packages that I will like to
use. Thanks for your help on that.

Right now, what do I do? Will I upload the CRAN packages already
installed, so that a GUI interface will come up.

I am working on Location Model and need some help.

Moses


From bhh at xs4all.nl  Thu Mar  3 07:17:01 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 3 Mar 2016 07:17:01 +0100
Subject: [R] Plot multiple similar equations in r
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70EC2E@mb02.ads.tamu.edu>
References: <CAMb6gE5GUEbrTy1J7AoC5kRwG6mzedoDOHR5xO_HXUEFQG2PZA@mail.gmail.com>
	<CAJeYpE_nWcKZ=niXkd5Q=6Fj2jmKV4MTN0FGTMoaXtTe94NF3g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70EC2E@mb02.ads.tamu.edu>
Message-ID: <FD2C4828-2D2E-418C-837B-24FC51FAE7BA@xs4all.nl>


> On 2 Mar 2016, at 22:22, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Another way would be to use matplot() or matlines():
> 
>> lx<-c(0.4, 0.5, 0.6, 0.7)
>> x <- seq(1, 8, length.out=100)
>> myfun <- function(x, k) {(log(k)-(0.37273*log(x)-1.79389))/0.17941}
>> y <- sapply(lx, function(k) myfun(x, k))
>> matplot(x, a, type="l", col="black", lty=1)
> 
> -

Shouldn't the "a" in the call of matplot  be "y"?

Berend

> ------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dalthorp, Daniel
> Sent: Wednesday, March 2, 2016 1:05 PM
> To: Jinggaofu Shi
> Cc: r-help at R-project.org (r-help at r-project.org)
> Subject: Re: [R] Plot multiple similar equations in r
> 
> Or, if you want easy labels, you can play around with contour graphs.
> 
> ?contour # will give you info on how to make contour plots
> 
> The basic idea is to construct a matrix of z-values...one z for every
> combination of x and y
> contour(x,y,z)
> 
> The x's would then be the x-values you want in
> (0.37273*log(x)-1.79389))/0.17941 for whatever range of x's you want
> The y's would be values from -5 to 5 (or whatever range you want)
> The z's would be values like 0.4, 0.5, etc. or exp(y + x)
> 
> ?outer # will tell you how to create z from x and y
> 
> x<-seq(1,10,length=100) # values for x-axis
> y<-seq(2, 10, length=100) # values for y-axis
> z<-exp(outer((0.37273*log(x)-1.79389)/0.17941,y,"+"))
> contour(x,y,z,levels=seq(.1,1.1,by=.1))
> 
> -Dan
> 
> On Wed, Mar 2, 2016 at 9:03 AM, Jinggaofu Shi <js3786 at drexel.edu> wrote:
> 
>> Hi, there I am new on R. I want to plot a graph like this.
>> 
>> The curves are created by these equations :
>> (log(0.4)-(0.37273*log(x)-1.79389))/0.17941,
>> (log(0.5)-(0.37273*log(x)-1.79389))/0.17941,
>> (log(0.6)-(0.37273*log(x)-1.79389))/0.17941, etc. The equations are
>> similar, the only difference is the first log(XXX). I already manually draw
>> the graph by repeating plot() for each equation. But I think there must be
>> a way to just assign a simple variable like x<-c(0.4,0.5,0.6,0.7), and then
>> plot all the curves automatically. I tried to use data frame to make a set
>> of equations, but failed. Could somebody help me? Thank you very much!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Mar  3 07:36:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 02 Mar 2016 22:36:51 -0800
Subject: [R] Extract row form a dataframe by row names in another vector
	and factor . Need explanation
In-Reply-To: <61484388.2733173.1456970737104.JavaMail.yahoo@mail.yahoo.com>
References: <61484388.2733173.1456970737104.JavaMail.yahoo.ref@mail.yahoo.com>
	<61484388.2733173.1456970737104.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <3DEA6174-F0DE-4C3F-B29C-33AE4F09825C@dcn.davis.ca.us>

Posting in HTML makes a mess of your code... learn to post in plain text. 

Not sure what you thought you would accomplish by using as.vector... perhaps you should read the help file ?as.vector.

Did you look at str( dat1 )?

Factors are more closely akin to integers than to characters. Indexing with factors is the same as indexing with the integers that factors are implemented with (see the discussion of factors in the Introduction to R document that comes with R) than indexing with character strings. If you want character indexing,  use character vectors. 

Advice: 98% of the time making a data frame using a matrix causes more damage than help. Data frames are a list of columns, each of which potentially has its own storage mode. Matrices are all one type, implemented as a folded vector. Use named arguments to the data.frame function instead. Also use the stringsAsFactors = FALSE argument to data.frame unless you know you won't want character strings. 
-- 
Sent from my phone. Please excuse my brevity.

On March 2, 2016 6:05:37 PM PST, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
>Hi,Here i have written an example to explain my problem
>## Data Generationdat<-data.frame(matrix(1:50,ncol=5))
>rownames(dat)<-letters[1:10]
>colnames(dat)<- c("SA1","SA2","SA3","SA4","SA5")
>
>dat1<-data.frame(matrix(letters[1:20],ncol=4))
>colnames(dat1)<-c("AA","BB","CC","DD")
>
>## Row names
>v1<-dat1[,"BB"] ? ? ? ? ? ? ? ? ? # Factor
>v2<-as.vector(dat1[,"BB"]) ?# Vector
>
>is(v1) # Factor
>is(v2) # Vector
>
># Result
>res1<-dat[v1,]
>res2<-dat[v2,]
>##########################################################i assumed
>res1 and res2 are same .?but it is not .?Can any body please explain
>why ??
>?
>?
>Tanvir Ahamed 
>G?teborg, Sweden??| mashranga at yahoo.com
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mortezafirouzi at yahoo.com  Thu Mar  3 08:35:07 2016
From: mortezafirouzi at yahoo.com (Morteza Firouzi)
Date: Thu, 3 Mar 2016 07:35:07 +0000 (UTC)
Subject: [R] Help me
In-Reply-To: <CACxOM1tceFnAELtOZEKZQ2A2ebPWiPtvKT0bwo9BqRFxWcJvcw@mail.gmail.com>
References: <CACxOM1tceFnAELtOZEKZQ2A2ebPWiPtvKT0bwo9BqRFxWcJvcw@mail.gmail.com>
Message-ID: <1657279693.2801779.1456990507500.JavaMail.yahoo@mail.yahoo.com>

?Moses,
If I understand correctly, you are installed R and Rstudio.Please do find the package(s) you would like to use.Once you run rstudio, you can search and install the package(s) using the bottom right corner menu:Packages> Install> install from Repository (Cran)> search the package you would like to use in the box below 'Packages',then select the package name, and do not forget to let the default settings for "install dependencies", since you're new the R, and finally Install the package.
Once the package is downloaded and installed, you can see the name of the installed package in the same window. To run it, you have to check the box to load the package.You may find the documentation for each package using 'help()', help(type the package name).For the rest, instead of using "Help me" in the subject line, please mention the package name and your problem, and explain exactly what would you do in the body.
Good Luck.Morteza
 

    On Thursday, March 3, 2016 2:12 PM, Moss Moss <abinnogoes at gmail.com> wrote:
 

 Please, I need help from you. I am new to R.

I installed R, Rstudio and R Crans or packages that I will like to
use. Thanks for your help on that.

Right now, what do I do? Will I upload the CRAN packages already
installed, so that a GUI interface will come up.

I am working on Location Model and need some help.

Moses

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Thu Mar  3 12:57:42 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 3 Mar 2016 11:57:42 +0000 (UTC)
Subject: [R] Extract row form a dataframe by row names in another vector
 and factor . Need explanation
In-Reply-To: <CADv2QyEpzi6f40uGp5yq1spQ-_fQcEpwFeSA6jbYL+K6g60RYw@mail.gmail.com>
References: <CADv2QyEpzi6f40uGp5yq1spQ-_fQcEpwFeSA6jbYL+K6g60RYw@mail.gmail.com>
Message-ID: <857461159.3084659.1457006262854.JavaMail.yahoo@mail.yahoo.com>

Dear Dennis

Thank you very much for your detail reply . It was really helpful to understand.

 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 



________________________________
From: Dennis Murphy <djmuser at gmail.com>

Sent: Thursday, 3 March 2016, 4:38
Subject: Re: [R] Extract row form a dataframe by row names in another vector and factor . Need explanation


Welcome to the wonderful world of factors. In your second case, v2,
the vector is character, so R matches the input character string to
the lookup table of row names. OTOH, v1 is a factor - it behaves
differently when used for subsetting, and this example illustrates why
you shouldn't use them for this purpose. Let's look at it:

> v1
[1] f g h i j
Levels: f g h i j
> str(v1)
Factor w/ 5 levels "f","g","h","i",..: 1 2 3 4 5
> levels(v1)
[1] "f" "g" "h" "i" "j"
> as.integer(v1)
[1] 1 2 3 4 5
> str(levels(v1))
chr [1:5] "f" "g" "h" "i" "j"

When you used v1 to subset rows, it uses the labels of the factor for
subsetting. Since these were not set, R defaults to the factor's
underlying numeric codes. This is why res1 selected the first five
observations. These alternatives do what you want:

dat[levels(v1), ]
dat[as.character(v1), ]    # behaves like v2 (an atomic vector)

# Another approach: define a factor with appropriate labels:

x <- as.character(dat1[, "BB"])
v3 <- factor(x, levels = unique(x), labels = unique(x))
dat[v3, ]

There are a couple alternative avenues you could have chosen (e.g.,
match() or which()), but they are overkill for this simple case.


Your real problem was converting a character matrix to a data frame in
the first place - this converted all of the columns to factors with
different sets of levels:

str(dat1)

This illustrates one of the important differences between data frames
and matrices. In a matrix, every element must be of the same class.
Specifically, a matrix is an atomic vector with a 'dim' attribute. In
contrast, each _column_ of a data frame must have elements of the same
class, but they do not have to be the same class from one column to
the next.

One way to have avoided the conversion to factor would have been to
use the argument stringsAsFactors = FALSE in the data.frame() call -
by default, it is TRUE. More importantly, the conversion to data frame
for dat1 was unnecessary - observe:

> dat1<-matrix(letters[1:20],ncol=4)
> colnames(dat1)<-c("AA","BB","CC","DD")
> dat[dat1[, "BB"], ]
  SA1 SA2 SA3 SA4 SA5
f   6  16  26  36  46
g   7  17  27  37  47
h   8  18  28  38  48
i   9  19  29  39  49
j  10  20  30  40  50

For the same reason, it was unnecessary to convert dat to a data
frame. Let's look at a matrix version instead:

dat2 <- matrix(seq(50), nrow = 10)
rownames(dat2) <- letters[1:10]
colnames(dat2) <- paste0("SA", 1:5)

dat2[dat1[, "BB"], ]     # desired result

Hint: You might want to spend some time to carefully learn the
different major data types in R and the various modes of indexing. In
general, it is not a good default practice to convert matrices to data
frames.

Dennis


On Wed, Mar 2, 2016 at 6:05 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hi,Here i have written an example to explain my problem
> ## Data Generationdat<-data.frame(matrix(1:50,ncol=5))
> rownames(dat)<-letters[1:10]
> colnames(dat)<- c("SA1","SA2","SA3","SA4","SA5")
>
> dat1<-data.frame(matrix(letters[1:20],ncol=4))
> colnames(dat1)<-c("AA","BB","CC","DD")
>
> ## Row names
> v1<-dat1[,"BB"]                   # Factor
> v2<-as.vector(dat1[,"BB"])  # Vector
>
> is(v1) # Factor
> is(v2) # Vector
>
> # Result
> res1<-dat[v1,]
> res2<-dat[v2,]
> ##########################################################i assumed res1 and res2 are same . but it is not . Can any body please explain why ?
>
>
> Tanvir Ahamed

>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jean-externe.maurice at edf.fr  Thu Mar  3 13:57:57 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Thu, 3 Mar 2016 12:57:57 +0000
Subject: [R] ALLOCATE in a FORTRAN subroutine
Message-ID: <e4289da605794c43a8b5e590f8c5633b@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,
I am 'translating' R functions in FORTRAN subroutines.

Very often, an R function gives an  'array' as result and you don't have to bother with the dimension of the array : R creates automatically an array with the good length. It's not really the case with FORTRAN.

Until now, I create an array with the 'max' dimensions in R, give it to FORTRAN; FORTRAN updates the array and R retrieves it. But calculating the 'max' before calling the FORTRAN subroutine can be complicated. Is it possible to create a 'new' array in a FORTRAN subroutine and to make it be read by R ? In my humble opinion, the answer is NO but as I am new to R ...

The other solution, is to work with dummies dimension in FORTRAN but can R work with that ?

TIA
Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From wolfer at ids-mannheim.de  Thu Mar  3 10:47:02 2016
From: wolfer at ids-mannheim.de (Sascha Wolfer)
Date: Thu, 3 Mar 2016 10:47:02 +0100
Subject: [R] Unicode Text Segmentation Algorithms already implemented in R?
Message-ID: <654634FF-DA5C-49EE-A91A-C56CAB506FA4@ids-mannheim.de>

Hello list members,

I am looking for an implementation of Unicode text segmentation (word boundary detection) algorithms in R. You can find information about the algorithms here: http://www.unicode.org/reports/tr29/#Word_Boundaries

The help page for the function ?casefuns? from the excellent ?Unicode? package says: "Other methods will be added eventually (once the Unicode text segmentation algorithm is implemented for detecting word boundaries).? My simple question is: Are these algorithms already implemented in an R package? I didn?t find anything on the web, but I am counting on the power of this list. My Stata-using colleague is already picking at me? (in Stata, the function ?ustrword? does exactly what I want to do in R).

Thanks for your help, have a good day, you all!
Sascha W.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160303/95daccff/attachment.bin>

From sebastien.moretti at unil.ch  Thu Mar  3 14:40:21 2016
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 3 Mar 2016 14:40:21 +0100
Subject: [R] Namespace problem with pre-R 3.0.0 package
Message-ID: <56D83EC5.5000007@unil.ch>

Hi

I have issues with an R package developed in 2004.
It works perfectly in R < 3.
It can be installed in R > 3 but functions are not in the namespace.

Do you know a good - and simple - documentation to help me to solve that?

I have already fixed some problems with R CMD check but remaining ones 
are less trivial.

Regards

--
S?bastien Moretti


From istazahn at gmail.com  Thu Mar  3 14:44:39 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 3 Mar 2016 08:44:39 -0500
Subject: [R] Unicode Text Segmentation Algorithms already implemented in
	R?
In-Reply-To: <654634FF-DA5C-49EE-A91A-C56CAB506FA4@ids-mannheim.de>
References: <654634FF-DA5C-49EE-A91A-C56CAB506FA4@ids-mannheim.de>
Message-ID: <CA+vqiLFfhLweHWAYRWphtogAHH81n8QBdw95VeqZDCNmDOmMzQ@mail.gmail.com>

You searched, but did not tell us what you found, nor why it was unsuitable
for you undescribed use case. So all we can do is guess: my guess is
http://docs.rexamine.com/R-man/stringi/stringi-search-boundaries.html

Best,
Ista
On Mar 3, 2016 8:14 AM, "Sascha Wolfer" <wolfer at ids-mannheim.de> wrote:

> Hello list members,
>
> I am looking for an implementation of Unicode text segmentation (word
> boundary detection) algorithms in R. You can find information about the
> algorithms here: http://www.unicode.org/reports/tr29/#Word_Boundaries
>
> The help page for the function ?casefuns? from the excellent ?Unicode?
> package says: "Other methods will be added eventually (once the Unicode
> text segmentation algorithm is implemented for detecting word boundaries).?
> My simple question is: Are these algorithms already implemented in an R
> package? I didn?t find anything on the web, but I am counting on the power
> of this list. My Stata-using colleague is already picking at me? (in Stata,
> the function ?ustrword? does exactly what I want to do in R).
>
> Thanks for your help, have a good day, you all!
> Sascha W.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Mar  3 15:02:36 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 3 Mar 2016 08:02:36 -0600
Subject: [R] Namespace problem with pre-R 3.0.0 package
In-Reply-To: <56D83EC5.5000007@unil.ch>
References: <56D83EC5.5000007@unil.ch>
Message-ID: <49078CFF-BFBF-4C05-BD48-11B638646E68@me.com>


> On Mar 3, 2016, at 7:40 AM, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
> 
> Hi
> 
> I have issues with an R package developed in 2004.
> It works perfectly in R < 3.
> It can be installed in R > 3 but functions are not in the namespace.
> 
> Do you know a good - and simple - documentation to help me to solve that?
> 
> I have already fixed some problems with R CMD check but remaining ones are less trivial.
> 
> Regards
> 
> --
> S?bastien Moretti


Hi,

First, this is really more of a question for R-package-devel:

  https://stat.ethz.ch/mailman/listinfo/r-package-devel)

not R-Help. :-)

Starting with R 3.0.0 (April of 2013), NAMESPACE files for packages were mandatory, whereas before that, they were optional. That is the primary issue.

If the original package author/maintainer has ceased to update the package, thus not available to assist, the primary documentation that you would need is in the R-Exts manual, specifically:

  https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Package-namespaces

Depending upon the residual errors that you are getting, if you can provide additional details so that folks can provide better assistance, subscribe to and post to R-package-devel for further discussion.

Regards,

Marc Schwartz


From dcarlson at tamu.edu  Thu Mar  3 15:08:19 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 3 Mar 2016 14:08:19 +0000
Subject: [R] discriminant analysis lda under MASS
In-Reply-To: <trinity-b01a8d19-35db-46e6-b004-de2fca6c1d1b-1456931961732@3capp-gmx-bs66>
References: <trinity-b01a8d19-35db-46e6-b004-de2fca6c1d1b-1456931961732@3capp-gmx-bs66>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70EE2E@mb02.ads.tamu.edu>

If the textbook provides the equations, you can work through them directly. But without knowing more, it is hard to say. You could also contact the author of the textbook.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jens Koch
Sent: Wednesday, March 2, 2016 9:19 AM
To: r-help at r-project.org
Subject: [R] discriminant analysis lda under MASS

Hello all,

I'd like to run a simple discriminant analysis to jump into the topic with the following dataset provided by a textbook:

Gruppe Einwohner Kosten
1 1642 478,2
1 2418 247,3
1 1417 223,6
1 2761 505,6
1 3991 399,3
1 2500 276
1 6261 542,5
1 3260 308,9
1 2516 453,6
1 4451 430,2
1 3504 413,8
1 5431 379,7
1 3523 400,5
1 5471 404,1
2 7172 499,4
2 9419 674,9
2 8780 468,6
2 5070 601,5
2 5780 578,8
2 8630 641,5

The coefficients according to the textbook need to be -0.00170 and -0.01237.

If I put the data into the lda function under MASS, my result is:

Call:
lda(Gruppe ~ Einwohner + Kosten, data = data)

Prior probabilities of groups:
? 1 ? 2
0.7 0.3

Group means:
? Einwohner ? Kosten
1 ?3510.429 390.2357
2 ?7475.167 577.4500

Coefficients of linear discriminants:
? ? ? ? ? ? ? ? ? ?LD1
Einwohner 0.0004751092
Kosten ? ?0.0050994964

I also tried to solve it by an another software package, but there is also not the result I have expected. I know now, that the?solution for the?coefficients is standardized by R and?the discrimination power?is not different at the end of the day.

But: How can I get (calculate) the results printed in the textbook with R?

Thanks in advance,

Jens.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From sebastien.moretti at unil.ch  Thu Mar  3 15:10:24 2016
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 3 Mar 2016 15:10:24 +0100
Subject: [R] Namespace problem with pre-R 3.0.0 package
In-Reply-To: <49078CFF-BFBF-4C05-BD48-11B638646E68@me.com>
References: <56D83EC5.5000007@unil.ch>
	<49078CFF-BFBF-4C05-BD48-11B638646E68@me.com>
Message-ID: <56D845D0.80307@unil.ch>

Le 03/03/2016 03:02 PM, Marc Schwartz a ?crit :
>
>> On Mar 3, 2016, at 7:40 AM, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>>
>> Hi
>>
>> I have issues with an R package developed in 2004.
>> It works perfectly in R < 3.
>> It can be installed in R > 3 but functions are not in the namespace.
>>
>> Do you know a good - and simple - documentation to help me to solve that?
>>
>> I have already fixed some problems with R CMD check but remaining ones are less trivial.
>>
>> Regards
>>
>> --
>> S?bastien Moretti
>
>
> Hi,
>
> First, this is really more of a question for R-package-devel:
>
>    https://stat.ethz.ch/mailman/listinfo/r-package-devel)
>
> not R-Help. :-)
>
> Starting with R 3.0.0 (April of 2013), NAMESPACE files for packages were mandatory, whereas before that, they were optional. That is the primary issue.
>
> If the original package author/maintainer has ceased to update the package, thus not available to assist, the primary documentation that you would need is in the R-Exts manual, specifically:
>
>    https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Package-namespaces
>
> Depending upon the residual errors that you are getting, if you can provide additional details so that folks can provide better assistance, subscribe to and post to R-package-devel for further discussion.
>
> Regards,
>
> Marc Schwartz

Thanks Marc

I will subscribe to R-package-devel and add details to my e-mail.

I have already looked at such documentation but they are really not 
clear for me and my problem.

--
S?bastien Moretti


From cdetermanjr at gmail.com  Thu Mar  3 15:31:12 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Thu, 3 Mar 2016 08:31:12 -0600
Subject: [R] RSNNS neural network
In-Reply-To: <000001d17384$9639e930$c2adbb90$@net>
References: <000001d17384$9639e930$c2adbb90$@net>
Message-ID: <CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>

Unfortunately we can only provide so much help without a reproducible
example.  Can you use a dataset that everyone would have access to to
reproduce the problem?  Otherwise it is difficult for anyone to help you.

Regards,
Charles

On Tue, Mar 1, 2016 at 12:35 AM, jake88 <youtube_b at telus.net> wrote:

> I am new to R and neural networks . So I trained and predicted an elman
> network like so :
>
> require ( RSNNS )
> mydata = read.csv("mydata.csv",header = TRUE)
> mydata.train = mydata[1000:2000,]
> mydata.test = mydata[800:999,]
>
> fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100
>      learnFuncParams =c (0.1) , maxit =1000)
> pred <-predict (fit , mydata.test[,2:10])
>
> So pred contains the predictions .
> The problem I am having is that when I run pred <-predict (fit ,
> mydata.test[1,2:10]) repeatedly , it gives me different results each time .
> Should not the weights and bias be set permanently in the network and give
> the same result everytime   ?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Jens.Koch at gmx.li  Thu Mar  3 15:39:42 2016
From: Jens.Koch at gmx.li (Jens Koch)
Date: Thu, 3 Mar 2016 15:39:42 +0100
Subject: [R] discriminant analysis lda under MASS
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70EE2E@mb02.ads.tamu.edu>
References: <trinity-b01a8d19-35db-46e6-b004-de2fca6c1d1b-1456931961732@3capp-gmx-bs66>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70EE2E@mb02.ads.tamu.edu>
Message-ID: <trinity-182b1e74-01e1-4189-8155-2e42b154e560-1457015982614@3capp-gmx-bs35>

Thank you for your answer. Please let me provide additional information:
?
You have a pooled variance covariance matrix S (2x2). The matrix needs to be inverted: S^-1. 

The calculation of the coeffcients is done by S^-1 (average (x1) - average (x2)). average (x1) is the vector of means (2x1) in group 1, average (x2) is the vector of means (2x1) in group 2.

S is as follows [1,1]: 2267168.12; [1,2]: 49088.07 [2,2]: 8381.77
average (x1) is as follows [1,1]: 3510.4; [2,1]: 390.2
average (x2) is as follows [1,1]: 7975.2; [2,1]: 577.5

Means that having the above mentioned formula in mind it is very easy to calculate.

However, my problem is, that I am not able to find any way to get this result by using R. 

Or in another way: What estimates R and is there any possibility to link the both results?

Thanks.


?

Gesendet:?Donnerstag, 03. M?rz 2016 um 15:08 Uhr
Von:?"David L Carlson" <dcarlson at tamu.edu>
An:?"Jens Koch" <Jens.Koch at gmx.li>, "r-help at r-project.org" <r-help at r-project.org>
Betreff:?RE: [R] discriminant analysis lda under MASS
If the textbook provides the equations, you can work through them directly. But without knowing more, it is hard to say. You could also contact the author of the textbook.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jens Koch
Sent: Wednesday, March 2, 2016 9:19 AM
To: r-help at r-project.org
Subject: [R] discriminant analysis lda under MASS

Hello all,

I'd like to run a simple discriminant analysis to jump into the topic with the following dataset provided by a textbook:

Gruppe Einwohner Kosten
1 1642 478,2
1 2418 247,3
1 1417 223,6
1 2761 505,6
1 3991 399,3
1 2500 276
1 6261 542,5
1 3260 308,9
1 2516 453,6
1 4451 430,2
1 3504 413,8
1 5431 379,7
1 3523 400,5
1 5471 404,1
2 7172 499,4
2 9419 674,9
2 8780 468,6
2 5070 601,5
2 5780 578,8
2 8630 641,5

The coefficients according to the textbook need to be -0.00170 and -0.01237.

If I put the data into the lda function under MASS, my result is:

Call:
lda(Gruppe ~ Einwohner + Kosten, data = data)

Prior probabilities of groups:
? 1 ? 2
0.7 0.3

Group means:
? Einwohner ? Kosten
1 ?3510.429 390.2357
2 ?7475.167 577.4500

Coefficients of linear discriminants:
? ? ? ? ? ? ? ? ? ?LD1
Einwohner 0.0004751092
Kosten ? ?0.0050994964

I also tried to solve it by an another software package, but there is also not the result I have expected. I know now, that the?solution for the?coefficients is standardized by R and?the discrimination power?is not different at the end of the day.

But: How can I get (calculate) the results printed in the textbook with R?

Thanks in advance,

Jens.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From J.Hillier at lboro.ac.uk  Thu Mar  3 16:30:22 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Thu, 3 Mar 2016 15:30:22 +0000
Subject: [R] Problem installing packages: cannot open file
 '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf'
In-Reply-To: <3DC74D54-D42F-4A94-8493-E3D0DA188A08@comcast.net>
References: <AM3PR04MB149073365ABB5BACAF678A01A1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<AM3PR04MB149014DFEC23F16391F3893DA1BC0@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<3DC74D54-D42F-4A94-8493-E3D0DA188A08@comcast.net>
Message-ID: <AM3PR04MB14903215C3038AD497ADA070A1BD0@AM3PR04MB1490.eurprd04.prod.outlook.com>

Dear David,

Thank you very much!  I am sending this mail for the record.

I am on mac OSX 10.8.5. The "standard" binary installer packages worked and fixed the problem (R-3.2.1-snowleopard.pkg, RStudio 0.99.891 - Mac OS X 10.6+ (64-bit)).  So, a caution against fink (r-base and rstudio-desktop) for installing R; I assumed it was doing exactly the same thing, but was clearly wrong.

Noted to use r-sig-mac at r-project.org for mac install issues in future.

All the best

John

________________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: 03 March 2016 00:31
To: John Hillier
Cc: r-help at R-project.org
Subject: Re: [R] Problem installing packages: cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf'

> On Mar 2, 2016, at 10:00 AM, John Hillier <J.Hillier at lboro.ac.uk> wrote:
>
>
> Dear All,
>
>
> I am a relative newbie to R, and am struggling to install packages on my laptop (although I have managed to on my desktop and a borrowed departmental laptop).
>

The words "my laptop" is rather uninformative. Based on the path below I guessing OSX.
>
> I have tried various packages with the same result. Illustration for
>
>> install.packages("outliers")
>
>
> .... leads to .....
>
>
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory

Installing R inside /sw/.. directory is not a standard location. What does this return:

Sys.getenv( "R_HOME" )

On my version of OSX 10.11 with R installed from the "standard" binary installer package, it returns
[1] "/Library/Frameworks/R.framework/Resources"

>
> I have tried in both the R environment on command line, and in RStudio, with the same result, and reinstalled and updated both r-base and rstudio-desktop via fink.

fink ,,,, That's probably the reason (again if this is a Mac.) The default installation location is not being chosen. I don't understand why you are not using the binary installer. I've never seen anyone use fink for installation on a Mac but have heard of attempts with MacPorts and homebrew. Simon Urbanek says if you use one of those package installers you are "on your own".  That's a route you should only consider if you have serious NIX-skills.

>  Both using a CRAN mirror and using a download (outliers_0.14.tar.gz) seem to produce the same result, and I think they're both working as the output says 'downloaded' (see below)
>
>
>> install.packages("outliers")
> Installing package into ?
> (as ? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
> Content type 'application/x-gzip' length 15090 bytes (14 KB)
> ==================================================
> downloaded 14 KB
>
>
>> From looking aroud on the web it seems that the message "In file(con, "r") : cannot open file" just means that R cannot find a file it thinks it needs. However, I've looked in /sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/ both on this machine and the other laptop that is able to install packages, and 'Makeconf' is not in ether of them.

I do have a copy of that program in:

/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf


>
>
> So, I'm thoroughly confused and have run out of ideas.

The correct place to post questions about Mac installations is:

r-sig-mac at r-project.org

>Please help.
>
>
> I hope that this is something simple that I'm missing.  If so, a pointer to a manual page or instructions would be gratefully received.

https://cran.rstudio.com/bin/macosx/

>
>
> John
>
>
> p.s - Full output in sequence in case it's useful.
>
>
>> install.packages("outliers")
> Installing package into ?
> (as ? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/outliers_0.14.tar.gz'
> Content type 'application/x-gzip' length 15090 bytes (14 KB)
> ==================================================
> downloaded 14 KB
>
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/sw/Library/Frameworks/R.framework/Versions/3.2/Resources/etc/Makeconf': No such file or directory
>
> The downloaded source packages are in
>        ?
> Warning message:
> In install.packages("outliers") :
>  installation of package ? had non-zero exit status
>
>
>
>
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jafarikia at gmail.com  Thu Mar  3 16:43:26 2016
From: jafarikia at gmail.com (Mohsen Jafarikia)
Date: Thu, 3 Mar 2016 10:43:26 -0500
Subject: [R] PCA on SNP genotypes
Message-ID: <CADs3iXkn5rskVta3XAS6-s3wyWA_LxeExNabzHVvymR5e13f0w@mail.gmail.com>

Hello everyone:

I have about a couple of thousands of samples each with about 100 SNP
genotypes and I would like to do PCA using genotypes. I looked on the
web and found different options available on R for PCA. I was
wondering if I could have advice about the program fits better what I
am trying to do.

Regards,
Mohsen


From armandres at gmail.com  Thu Mar  3 16:53:47 2016
From: armandres at gmail.com (=?utf-8?Q?Andr=C3=A9s_Arag=C3=B3n_Mart=C3=ADnez?=)
Date: Thu, 3 Mar 2016 09:53:47 -0600
Subject: [R] PCA on SNP genotypes
In-Reply-To: <CADs3iXkn5rskVta3XAS6-s3wyWA_LxeExNabzHVvymR5e13f0w@mail.gmail.com>
References: <CADs3iXkn5rskVta3XAS6-s3wyWA_LxeExNabzHVvymR5e13f0w@mail.gmail.com>
Message-ID: <9BD76D0E-FC4F-44AC-881E-F4E29F944FA6@gmail.com>

Mohsen,

Check at Bioconductor.

Andr?s


> El 03/03/2016, a las 9:43, Mohsen Jafarikia <jafarikia at gmail.com> escribi?:
> 
> Hello everyone:
> 
> I have about a couple of thousands of samples each with about 100 SNP
> genotypes and I would like to do PCA using genotypes. I looked on the
> web and found different options available on R for PCA. I was
> wondering if I could have advice about the program fits better what I
> am trying to do.
> 
> Regards,
> Mohsen
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fabio.monteiro1992 at gmail.com  Thu Mar  3 16:25:41 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Thu, 3 Mar 2016 15:25:41 +0000
Subject: [R] package FD
Message-ID: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>

Hello, my name is F?bio and I'm a Marine Ecology student in Portugal.

I'm currently using the FD package for my work and yesterday one message
appeared that I wasn't expecting and I really need your help to try to
figure out what's happening.
I'm using the dbFD function and the following message appeared:

FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic was
 measured as the number of unique trait combinations, NOT as the convex
hull volume.
FDiv: Cannot be computed when only categorical and/or ordinal trait(s)
present in 'x'.

My data:
x is a matrix with species vs functional traits
a is a matrix with species vs sampling (in abundances)

Previously I used the dbFD function and was working just fine. Yesterday I
removed 2 traits and this message appeared.

My traits now are 3 categorical traits and 1 numeric. The 2 trais that I
removed were numeric traits as well. I really need to remove those trait,
but I still need the FDiv to be calculated. Can you explain to me why is
this error occurring? I need to know how the dbFD is measuring the indexes
so I can understanding the error and if I can or can't continue to use this
package (if it applies or not to my goals)

Kind regards

F?bio Monteiro

	[[alternative HTML version deleted]]


From lvenne at ufl.edu  Thu Mar  3 17:13:57 2016
From: lvenne at ufl.edu (Louise Venne)
Date: Thu, 3 Mar 2016 11:13:57 -0500
Subject: [R] Polytonic Vector Analysis
Message-ID: <8686ACB4-6CE6-4E25-A177-707AA00A9A0F@ufl.edu>

I'm looking for an R package to do Polytopic Vector Analysis (PVA) without success. I've checked CRAN, then did a site searched there, scanned the packages list, looked over old Help posting (there was a query about the same back in 2005 or so - only one response that didn?t give much direction as far as I can tell). No luck. 

As best as I can tell PVA is a method similar to factor analysis restricted to only non-negative factors. It allegedly can aid in "source unmixing". Has anyone put together a non-CRAN listed package in the intervening 10 years? 

Other suggestions (or anyone with a lead to the nebulous program given the Ehrlich (2008) citation common in geochemistry articles on PVA) would be greatly appreciated.

Thanks,
Louise

From bhh at xs4all.nl  Thu Mar  3 17:17:35 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 3 Mar 2016 17:17:35 +0100
Subject: [R] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <e4289da605794c43a8b5e590f8c5633b@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <e4289da605794c43a8b5e590f8c5633b@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <FEE799F2-5E0C-4478-A58B-8F900D23DEF6@xs4all.nl>


> On 3 Mar 2016, at 13:57, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
> 
> Hi,
> I am 'translating' R functions in FORTRAN subroutines.
> 
> Very often, an R function gives an  'array' as result and you don't have to bother with the dimension of the array : R creates automatically an array with the good length. It's not really the case with FORTRAN.
> 
> Until now, I create an array with the 'max' dimensions in R, give it to FORTRAN; FORTRAN updates the array and R retrieves it. But calculating the 'max' before calling the FORTRAN subroutine can be complicated. Is it possible to create a 'new' array in a FORTRAN subroutine and to make it be read by R ? In my humble opinion, the answer is NO but as I am new to R ...
> 
> The other solution, is to work with dummies dimension in FORTRAN but can R work with that ?
> 

The question belongs on the R-devel mailinglist.

I do not think you can do what you describe, if I read your question correctly.
You are calling your Fortran routines directly from an R file with .Fortran, I presume?

Your other solution: I don't really understand what you are implying.
Declare them with (:,:) or (*,*), allocate and the return the array? A Fortran95 pointer?
I think  all of that is just a no no.

Is it possible to calculate the required size of the array in a separate routine given some parameters (as can often be done with Lapack routines) before calling the main subroutine?
If so, call the sizing routine and then declare the correctly sized array in your R code and pass it to the main subroutine.

Berend

> TIA
> Jean
> 
> 
> 
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
> 
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
> 
> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
> ____________________________________________________
> 
> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
> 
> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
> 
> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ddalthorp at usgs.gov  Thu Mar  3 17:31:07 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Thu, 3 Mar 2016 08:31:07 -0800
Subject: [R] Ruofei Mo - How can I generate correlated data with
 non-normal distribution?
In-Reply-To: <loom.20160303T003533-594@post.gmane.org>
References: <009d01d174c7$5fa1acc0$1ee50640$@tongji.edu.cn>
	<loom.20160303T003533-594@post.gmane.org>
Message-ID: <CAJeYpE8UxCROWDbZNPg6FvPtWn9Vk=mhw5u9mpYH1BbiYRxrwA@mail.gmail.com>

Ruofei,

Ben's suggestion is simple and gets you close:

require(MASS)
nsim <- 1000000
rho <- -.9
Z <- mvrnorm(nsim, mu=c(0,0),Sigma = cbind(c(1,rho),c(rho, 1)))
U <- pnorm(Z);
a <- Z[,1]
b <- qunif(U[,2])
cor(a,b)

Pearson correlation characterizes the linear relationship between normal
r.v.'s, but there's always a question about what Pearson correlation means
for non-normal r.v.'s....the "close" approach that Ben gave gives a pair of
r.v.'s with a non-linear relationship (because of the pnorm non-linear
transformation), which can be seen if you plot the means of a in bins
across the range of b.

plot(0,0,type='n',xlim=range(a), ylim=c(-.2,1.1))
for (i in seq(0,.99,by=0.01)){
  ind<-which(b>min(b)+i*diff(range(b)) & b<=min(b)+(i+.01)*diff(range(b)))
  points(mean(a[ind]),i-.005,pch=3) # means of a in 100 bins that span the
range of b
}

# so Spearman rank correlation is often used for "correlation" between
non-normal r.v.'s. Exact Spearman correlations can be attained using the
same approach, but adjusting the target correlation.

# to get Spearman correlation of rho = -0.90, use 2*sin(rho*pi/6) in place
of rho in the mvrnorm simulation:
nsim <- 1000000
rho <- -.9
Z <- mvrnorm(nsim, mu=c(0,0),Sigma =
cbind(c(1,2*sin(rho*pi/6)),c(2*sin(rho*pi/6), 1)))
a<-Z[,1]; b<-qunif(pnorm(Z[,2]))
cor(rank(a),rank(b))

# this gives r.v.'s with exact Spearman correlations as desired, while
aiming at Pearson correlation tends to be off by some amount

TargetCorrelation<-seq(-.99, -.1, by=.01)
SimulatedCorrelationP<-numeric(length(TargetCorrelation))
SimulatedCorrelationS<-numeric(length(TargetCorrelation))

nsim<-100000
for (i in 1:length(TargetCorrelation)){
  rho<-TargetCorrelation[i]
  Z <- mvrnorm(nsim, mu=c(0,0),Sigma = cbind(c(1,rho),c(rho, 1)))
  U <- pnorm(Z);
  a <- Z[,1]
  b <- qunif(U[,2])
  SimulatedCorrelationP[i]<-cor(a,b)

  Z <- mvrnorm(nsim, mu=c(0,0),Sigma =
cbind(c(1,2*sin(rho*pi/6)),c(2*sin(rho*pi/6), 1)))
  U <- pnorm(Z);
  a <- Z[,1]
  b <- qunif(U[,2])
  SimulatedCorrelationS[i]<-cor(rank(a),rank(b))
}
plot(TargetCorrelation,SimulatedCorrelationP)
points(TargetCorrelation,SimulatedCorrelationS,pch=20)
lines(c(-1,0),c(-1,0),col=2)
plot(TargetCorrelation,SimulatedCorrelationP)
points(TargetCorrelation,SimulatedCorrelationS,pch=20)
lines(c(-1,0),c(-1,0),col=2)


-Dan

On Wed, Mar 2, 2016 at 3:46 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Ruofei Mo????? <911mruofei <at> tongji.edu.cn> writes:
>
> >
> > Hi, All,
> >
> > I have a question about how to generate correlated data with non-normal
> > distribution? Basic, I have a variable a that follows a normal
> distribution,
> > a ~ N(0,1), then I want to generate another variable b that follows a
> > uniform distribution, b ~ U(0, 1). Most importantly, I want the
> correlation
> > between a and b to be fixed at -.9, cor(a,b) = -.90
> >
> > I tried the following code,
> >
> > ### Correlation matrix rmvnorm() function ###
> >
>
>   I don't know that there's a closed-form solution to this problem.
> Here's an attempt to do it by brute force.  By eyeball, you need to
> set the nominal rho to about -0.92 to get a realized rho of -0.9.
>
> simfun <- function(rho,n=10000) {
>     cormat <- matrix(c(1, rho, rho, 1), ncol = 2)
>     dd <- setNames(data.frame(MASS::mvrnorm(1000, mu=c(0,0),
> Sigma=cormat)),
>                    c("a","trans"))
>     dd <- transform(dd,
>                b=pnorm(trans,mean(trans),sd(trans)))
>     dd[,c("a","b")]
> }
>
> cvec <- seq(-0.999,-0.85,length=51)
> res <- expand.grid(rho=cvec,rep=1:10)
> set.seed(101)
> res$cor <- sapply(res$rho,
>                   function(r) cor(simfun(rho=r,n1e6))[1,2])
>
> par(las=1,bty="l")
> plot(cor~rho,data=res)
> abline(a=0,b=1,col=2)
> abline(h=-0.9,col=4)
> abline(v=-0.92,col=4)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Mar  3 19:06:44 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 3 Mar 2016 18:06:44 +0000
Subject: [R] splAw: RE:  discriminant analysis lda under MASS
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70EF80@mb02.ads.tamu.edu>

I think the answer is in Venables and Ripley, Modern Applied Statistics with S. 4th Edition, 2002, page 332:

"Fisher (1936) introduced a linear discriminant analysis seeking a linear combination
xa of the variables that has a maximal ratio of the separation of the class
means to the within-class variance, that is, maximizing the ratio aTBa/aTWa.
To compute this, choose a sphering (see page 305) xS of the variables so that
they have the identity as their within-group correlation matrix. On the rescaled
variables the problem is to maximize aTBa subject to a = 1, and as we saw
for PCA, this is solved by taking a to be the eigenvector of B corresponding to
the largest eigenvalue."

Where B is the Between-classes covariance matrix.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: Jens Koch [mailto:Jens.Koch at gmx.li] 
Sent: Thursday, March 3, 2016 8:40 AM
To: David L Carlson
Cc: r-help at r-project.org
Subject: splAw: RE: [R] discriminant analysis lda under MASS

Thank you for your answer. Please let me provide additional information:
?
You have a pooled variance covariance matrix S (2x2). The matrix needs to be inverted: S^-1. 

The calculation of the coeffcients is done by S^-1 (average (x1) - average (x2)). average (x1) is the vector of means (2x1) in group 1, average (x2) is the vector of means (2x1) in group 2.

S is as follows [1,1]: 2267168.12; [1,2]: 49088.07 [2,2]: 8381.77
average (x1) is as follows [1,1]: 3510.4; [2,1]: 390.2
average (x2) is as follows [1,1]: 7975.2; [2,1]: 577.5

Means that having the above mentioned formula in mind it is very easy to calculate.

However, my problem is, that I am not able to find any way to get this result by using R. 

Or in another way: What estimates R and is there any possibility to link the both results?

Thanks.


?

Gesendet:?Donnerstag, 03. M?rz 2016 um 15:08 Uhr
Von:?"David L Carlson" <dcarlson at tamu.edu>
An:?"Jens Koch" <Jens.Koch at gmx.li>, "r-help at r-project.org" <r-help at r-project.org>
Betreff:?RE: [R] discriminant analysis lda under MASS
If the textbook provides the equations, you can work through them directly. But without knowing more, it is hard to say. You could also contact the author of the textbook.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jens Koch
Sent: Wednesday, March 2, 2016 9:19 AM
To: r-help at r-project.org
Subject: [R] discriminant analysis lda under MASS

Hello all,

I'd like to run a simple discriminant analysis to jump into the topic with the following dataset provided by a textbook:

Gruppe Einwohner Kosten
1 1642 478,2
1 2418 247,3
1 1417 223,6
1 2761 505,6
1 3991 399,3
1 2500 276
1 6261 542,5
1 3260 308,9
1 2516 453,6
1 4451 430,2
1 3504 413,8
1 5431 379,7
1 3523 400,5
1 5471 404,1
2 7172 499,4
2 9419 674,9
2 8780 468,6
2 5070 601,5
2 5780 578,8
2 8630 641,5

The coefficients according to the textbook need to be -0.00170 and -0.01237.

If I put the data into the lda function under MASS, my result is:

Call:
lda(Gruppe ~ Einwohner + Kosten, data = data)

Prior probabilities of groups:
? 1 ? 2
0.7 0.3

Group means:
? Einwohner ? Kosten
1 ?3510.429 390.2357
2 ?7475.167 577.4500

Coefficients of linear discriminants:
? ? ? ? ? ? ? ? ? ?LD1
Einwohner 0.0004751092
Kosten ? ?0.0050994964

I also tried to solve it by an another software package, but there is also not the result I have expected. I know now, that the?solution for the?coefficients is standardized by R and?the discrimination power?is not different at the end of the day.

But: How can I get (calculate) the results printed in the textbook with R?

Thanks in advance,

Jens.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.

From alaasindi at gmail.com  Thu Mar  3 19:30:16 2016
From: alaasindi at gmail.com (Alaa Sindi)
Date: Thu, 3 Mar 2016 13:30:16 -0500
Subject: [R] estimate likelihood
Message-ID: <1085570E-FFA4-4F30-9587-D2F610181F4C@gmail.com>

Hi all,

Is it possible to estimate the likelihood parameter and test for significant as follows:

x <- c(1.6, 1.7, 1.7, 1.7, 1.8, 1.8, 1.8, 1.8)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)

# note: there is no need to have the choose(n, y) term in the likelihood
fn <- function(p)


z = p[1]+p[2]*x
sum( - (y*z) - n*log(1+exp(z*x))) 

out <- nlm(fn, p = c(-50,20), hessian = TRUE, print.level=2)

out

eigen(out$hessian)
sqrt(diag(solve(out$hessian)))


Thanks

From youtube_b at telus.net  Thu Mar  3 19:30:43 2016
From: youtube_b at telus.net (jake88)
Date: Thu, 3 Mar 2016 10:30:43 -0800
Subject: [R] RSNNS neural network
In-Reply-To: <CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
References: <000001d17384$9639e930$c2adbb90$@net>
	<CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
Message-ID: <000001d1757a$cc380ba0$64a822e0$@net>

Data set attached ?

 

 

require ( RSNNS ) 
mydata = read.csv("mydata.csv",header = TRUE) 

mydata.train = mydata[3000:10000,]

mydata.test = mydata[10005:10006,]

myfit <- elman ( mydata.train[,2:19],mydata.train[,1], size =100 , learnFuncParams =c (0.1) , maxit =1000)

pred <-predict (myfit , mydata.test[,2:19])

 

 

From: Charles Determan [mailto:cdetermanjr at gmail.com] 
Sent: Thursday, March 03, 2016 6:31 AM
To: jake88
Cc: r-help
Subject: Re: [R] RSNNS neural network

 

Unfortunately we can only provide so much help without a reproducible example.  Can you use a dataset that everyone would have access to to reproduce the problem?  Otherwise it is difficult for anyone to help you.

Regards,

Charles

 

On Tue, Mar 1, 2016 at 12:35 AM, jake88 <youtube_b at telus.net> wrote:

I am new to R and neural networks . So I trained and predicted an elman
network like so : 

require ( RSNNS ) 
mydata = read.csv("mydata.csv",header = TRUE) 
mydata.train = mydata[1000:2000,] 
mydata.test = mydata[800:999,] 

fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100 
     learnFuncParams =c (0.1) , maxit =1000) 
pred <-predict (fit , mydata.test[,2:10]) 

So pred contains the predictions .
The problem I am having is that when I run pred <-predict (fit ,
mydata.test[1,2:10]) repeatedly , it gives me different results each time .
Should not the weights and bias be set permanently in the network and give
the same result everytime   ?   

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



No virus found in this message.
Checked by AVG - www.avg.com

03/03/16


From profjcnash at gmail.com  Thu Mar  3 20:54:14 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 3 Mar 2016 14:54:14 -0500
Subject: [R] estimate likelihood
In-Reply-To: <1085570E-FFA4-4F30-9587-D2F610181F4C@gmail.com>
References: <1085570E-FFA4-4F30-9587-D2F610181F4C@gmail.com>
Message-ID: <56D89666.50703@gmail.com>

Not possible, because the hessian is singular. Recoded as follows (your
code should be executable before you put it in a help request).

# asindii2.R -- Is it possible to estimate the likelihood parameter
#    and test for significant as follows:

x <- c(1.6, 1.7, 1.7, 1.7, 1.8, 1.8, 1.8, 1.8)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)

DF <- data.frame(x, y, n)

# note: there is no need to have the choose(n, y) term in the likelihood
fn <- function(p, DF) {
   z <- p[1]+p[2]*DF$x
   sum( - (DF$y*DF$z) - DF$n*log(1+exp(DF$z*DF$x)))
}
out <- nlm(fn, p = c(-50,20), hessian = TRUE, print.level=2, DF=DF)
print(out)

eigen(out$hessian)
sqrt(diag(solve(out$hessian)))
## ----- end of snippet ---


On 16-03-03 01:30 PM, Alaa Sindi wrote:
> Hi all,
> 
> Is it possible to estimate the likelihood parameter and test for significant as follows:
> 
> x <- c(1.6, 1.7, 1.7, 1.7, 1.8, 1.8, 1.8, 1.8)
> y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
> n <- c(59, 60, 62, 56, 63, 59, 62, 60)
> 
> # note: there is no need to have the choose(n, y) term in the likelihood
> fn <- function(p)
> 
> 
> z = p[1]+p[2]*x
> sum( - (y*z) - n*log(1+exp(z*x))) 
> 
> out <- nlm(fn, p = c(-50,20), hessian = TRUE, print.level=2)
> 
> out
> 
> eigen(out$hessian)
> sqrt(diag(solve(out$hessian)))
> 
> 
> Thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Mar  3 21:03:52 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Mar 2016 12:03:52 -0800
Subject: [R] RSNNS neural network
In-Reply-To: <000001d1757a$cc380ba0$64a822e0$@net>
References: <000001d17384$9639e930$c2adbb90$@net>
	<CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
	<000001d1757a$cc380ba0$64a822e0$@net>
Message-ID: <D54ED9C4-FB17-44A9-BED9-2911163C051C@comcast.net>


> On Mar 3, 2016, at 10:30 AM, jake88 <youtube_b at telus.net> wrote:
> 
> Data set attached ?

Perhaps it was, and if you replied-all then it might be in the copy that was sent directly to Charles, but it was not attached after the rhelp mail-server scrubbed it. It wasn't labeled correctly by your email client as MIME-text. Rename it mydata.txt and it will (probably) make it through.

-- 
David.
> 
> require ( RSNNS ) 
> mydata = read.csv("mydata.csv",header = TRUE) 
> 
> mydata.train = mydata[3000:10000,]
> 
> mydata.test = mydata[10005:10006,]
> 
> myfit <- elman ( mydata.train[,2:19],mydata.train[,1], size =100 , learnFuncParams =c (0.1) , maxit =1000)
> 
> pred <-predict (myfit , mydata.test[,2:19])
> 
> 
> 
> 
> 
> From: Charles Determan [mailto:cdetermanjr at gmail.com] 
> Sent: Thursday, March 03, 2016 6:31 AM
> To: jake88
> Cc: r-help
> Subject: Re: [R] RSNNS neural network
> 
> 
> 
> Unfortunately we can only provide so much help without a reproducible example.  Can you use a dataset that everyone would have access to to reproduce the problem?  Otherwise it is difficult for anyone to help you.
> 
> Regards,
> 
> Charles
> 
> 
> 
> On Tue, Mar 1, 2016 at 12:35 AM, jake88 <youtube_b at telus.net> wrote:
> 
> I am new to R and neural networks . So I trained and predicted an elman
> network like so : 
> 
> require ( RSNNS ) 
> mydata = read.csv("mydata.csv",header = TRUE) 
> mydata.train = mydata[1000:2000,] 
> mydata.test = mydata[800:999,] 
> 
> fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100 
>     learnFuncParams =c (0.1) , maxit =1000) 
> pred <-predict (fit , mydata.test[,2:10]) 
> 
> So pred contains the predictions .
> The problem I am having is that when I run pred <-predict (fit ,
> mydata.test[1,2:10]) repeatedly , it gives me different results each time .
> Should not the weights and bias be set permanently in the network and give
> the same result everytime   ?   
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> No virus found in this message.
> Checked by AVG - www.avg.com
> 
> 03/03/16
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kmnanus at gmail.com  Thu Mar  3 21:18:53 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 3 Mar 2016 15:18:53 -0500
Subject: [R] Extracting part of a factor
Message-ID: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>

I have a factor variable that is 6 digits and hyphenated.  For example, 001-014.

I need to extract the first 3 digits to a new variable using mutate in dplyr - in this case 001 - but can?t find a function to do it.

substr will do this for character strings, but I need the variable to remain as a factor.

Is there an R function  or workaround to do this?

 
Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From youtube_b at telus.net  Thu Mar  3 21:33:37 2016
From: youtube_b at telus.net (jake88)
Date: Thu, 3 Mar 2016 12:33:37 -0800
Subject: [R] RSNNS neural network
In-Reply-To: <CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
References: <000001d17384$9639e930$c2adbb90$@net>
	<CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
Message-ID: <000001d1758b$f7779bd0$e666d370$@net>

Data set attached ? rename to mydata.csv .

 

 

require ( RSNNS ) 
mydata = read.csv("mydata.csv",header = TRUE) 

mydata.train = mydata[3000:10000,]

mydata.test = mydata[10005:10006,]

myfit <- elman ( mydata.train[,2:19],mydata.train[,1], size =100 , learnFuncParams =c (0.1) , maxit =1000)

pred <-predict (myfit , mydata.test[,2:19])

 

 

From: Charles Determan [mailto:cdetermanjr at gmail.com] 
Sent: Thursday, March 03, 2016 6:31 AM
To: jake88
Cc: r-help
Subject: Re: [R] RSNNS neural network

 

Unfortunately we can only provide so much help without a reproducible example.  Can you use a dataset that everyone would have access to to reproduce the problem?  Otherwise it is difficult for anyone to help you.

Regards,

Charles

 

On Tue, Mar 1, 2016 at 12:35 AM, jake88 <youtube_b at telus.net> wrote:

I am new to R and neural networks . So I trained and predicted an elman
network like so : 

require ( RSNNS ) 
mydata = read.csv("mydata.csv",header = TRUE) 
mydata.train = mydata[1000:2000,] 
mydata.test = mydata[800:999,] 

fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100 
     learnFuncParams =c (0.1) , maxit =1000) 
pred <-predict (fit , mydata.test[,2:10]) 

So pred contains the predictions .
The problem I am having is that when I run pred <-predict (fit ,
mydata.test[1,2:10]) repeatedly , it gives me different results each time .
Should not the weights and bias be set permanently in the network and give
the same result everytime   ?   

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mydata.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160303/ccd95af7/attachment-0001.txt>

From istazahn at gmail.com  Thu Mar  3 22:14:24 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 3 Mar 2016 16:14:24 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
Message-ID: <CA+vqiLEjrv0jsRe9tZjpUEWAkT47twh+OnD-2-S22Rv5hqKiYQ@mail.gmail.com>

Like this?

x <- factor("001-014")
y <- substr(as.character(x), 1, 3)

Best,
Ista




On Thu, Mar 3, 2016 at 3:18 PM, KMNanus <kmnanus at gmail.com> wrote:
> I have a factor variable that is 6 digits and hyphenated.  For example, 001-014.
>
> I need to extract the first 3 digits to a new variable using mutate in dplyr - in this case 001 - but can?t find a function to do it.
>
> substr will do this for character strings, but I need the variable to remain as a factor.
>
> Is there an R function  or workaround to do this?
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Thu Mar  3 22:52:44 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 3 Mar 2016 13:52:44 -0800
Subject: [R] Extracting part of a factor
In-Reply-To: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
Message-ID: <56D8B22C.5020707@fredhutch.org>

Hi,

On 03/03/2016 12:18 PM, KMNanus wrote:
> I have a factor variable that is 6 digits and hyphenated.  For example, 001-014.
>
> I need to extract the first 3 digits to a new variable using mutate in dplyr - in this case 001 - but can?t find a function to do it.
>
> substr will do this for character strings, but I need the variable to remain as a factor.

What prevents you from calling as.factor() on the result to turn it
back into a factor?

H.

>
> Is there an R function  or workaround to do this?
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kmnanus at gmail.com  Thu Mar  3 23:13:28 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 3 Mar 2016 17:13:28 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <56D8B22C.5020707@fredhutch.org>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
Message-ID: <B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>

When I do that, I get "Error in `$<-.data.frame`(`*tmp*`, "site", value = integer(0)) : 
  replacement has 0 rows, data has 6?

The data frame has 6 rows.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 3, 2016, at 4:52 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> 
> Hi,
> 
> On 03/03/2016 12:18 PM, KMNanus wrote:
>> I have a factor variable that is 6 digits and hyphenated.  For example, 001-014.
>> 
>> I need to extract the first 3 digits to a new variable using mutate in dplyr - in this case 001 - but can?t find a function to do it.
>> 
>> substr will do this for character strings, but I need the variable to remain as a factor.
> 
> What prevents you from calling as.factor() on the result to turn it
> back into a factor?
> 
> H.
> 
>> 
>> Is there an R function  or workaround to do this?
>> 
>> 
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From kmnanus at gmail.com  Thu Mar  3 23:14:13 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 3 Mar 2016 17:14:13 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <CA+vqiLEjrv0jsRe9tZjpUEWAkT47twh+OnD-2-S22Rv5hqKiYQ@mail.gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<CA+vqiLEjrv0jsRe9tZjpUEWAkT47twh+OnD-2-S22Rv5hqKiYQ@mail.gmail.com>
Message-ID: <62786C86-74CD-4C0C-B8AB-5519D86F55B8@gmail.com>

When I did that, I got - 

 "Error in `$<-.data.frame`(`*tmp*`, "site", value = integer(0)) : 
  replacement has 0 rows, data has 6?

The data frame has 6 rows.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 3, 2016, at 4:14 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> Like this?
> 
> x <- factor("001-014")
> y <- substr(as.character(x), 1, 3)
> 
> Best,
> Ista
> 
> 
> 
> 
> On Thu, Mar 3, 2016 at 3:18 PM, KMNanus <kmnanus at gmail.com> wrote:
>> I have a factor variable that is 6 digits and hyphenated.  For example, 001-014.
>> 
>> I need to extract the first 3 digits to a new variable using mutate in dplyr - in this case 001 - but can?t find a function to do it.
>> 
>> substr will do this for character strings, but I need the variable to remain as a factor.
>> 
>> Is there an R function  or workaround to do this?
>> 
>> 
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Mar  3 23:54:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Mar 2016 14:54:54 -0800
Subject: [R] RSNNS neural network
In-Reply-To: <000001d1758b$f7779bd0$e666d370$@net>
References: <000001d17384$9639e930$c2adbb90$@net>
	<CAKxd1KNosniwnDdyqyR+Dfrk4GZm7bowk9rNoyejhppmT=nGZw@mail.gmail.com>
	<000001d1758b$f7779bd0$e666d370$@net>
Message-ID: <C56CA66F-1A6D-4AA8-A551-A28BEF47B23C@comcast.net>


> On Mar 3, 2016, at 12:33 PM, jake88 <youtube_b at telus.net> wrote:
> 
> Data set attached ? rename to mydata.csv .
> 
> 
> 
> 
> 
> require ( RSNNS ) 
> mydata = read.csv("mydata.csv",header = TRUE) 
# Needed to change to mydata.txt
> 
> mydata.train = mydata[3000:10000,]
> 
> mydata.test = mydata[10005:10006,]
> 
> myfit <- elman ( mydata.train[,2:19],mydata.train[,1], size =100 , learnFuncParams =c (0.1) , maxit =1000)
> 
> pred <-predict (myfit , mydata.test[,2:19])
> 
> 


> 
> On Tue, Mar 1, 2016 at 12:35 AM, jake88 <youtube_b at telus.net> wrote:
> 
> I am new to R and neural networks . So I trained and predicted an elman
> network like so : 
> 
> require ( RSNNS ) 
> mydata = read.csv("mydata.csv",header = TRUE) 
> mydata.train = mydata[1000:2000,] 
> mydata.test = mydata[800:999,] 
> 
> fit <- elman ( mydata.train[,2:10],mydata.train[,1], size =100 
>     learnFuncParams =c (0.1) , maxit =1000) 
> pred <-predict (fit , mydata.test[,2:10]) 
> 
> So pred contains the predictions .
> The problem I am having is that when I run pred <-predict (fit ,
> mydata.test[1,2:10]) repeatedly , it gives me different results each time .
> Should not the weights and bias be set permanently in the network and give
> the same result everytime   ?   
> 
> 
I get "different" results with each call as well, but I do also observe that the differences are generally in the 6th or 7th decimal place.

rbind( t( predict (fit , mydata.test[,2:10])),  t( predict (fit , mydata.test[,2:10])))

             800         801         802         803         804         805         806         807
[1,] 0.006875724 0.004711885 0.006329221 0.007906904 0.005760470 0.005573335 0.005393596 0.004476394
[2,] 0.006875725 0.004711647 0.006329220 0.007906901 0.005760474 0.005573337 0.005394077 0.004476394
             808         809         810         811          812         813          814           815
[1,] 0.004994765 0.006582610 0.005095046 0.001079763 -0.001370882 0.006502322 0.0003687060 -0.0004826686
[2,] 0.004994765 0.006582132 0.005094331 0.001079763 -0.001370883 0.006502321 0.0003687064 -0.0004829080

Maybe the network is "thinking different" each time on my Mac?

-- 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Mar  4 00:42:20 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 4 Mar 2016 10:42:20 +1100
Subject: [R] package FD
In-Reply-To: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
Message-ID: <CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>

Hi Fabio,
It is possible that your remaining "numeric" variable is a factor. What does:

class(my_numeric_variable)

say? (where you substitute the name of your "numeric" variable)

Jim


On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
<fabio.monteiro1992 at gmail.com> wrote:
> Hello, my name is F?bio and I'm a Marine Ecology student in Portugal.
>
> I'm currently using the FD package for my work and yesterday one message
> appeared that I wasn't expecting and I really need your help to try to
> figure out what's happening.
> I'm using the dbFD function and the following message appeared:
>
> FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic was
>  measured as the number of unique trait combinations, NOT as the convex
> hull volume.
> FDiv: Cannot be computed when only categorical and/or ordinal trait(s)
> present in 'x'.
>
> My data:
> x is a matrix with species vs functional traits
> a is a matrix with species vs sampling (in abundances)
>
> Previously I used the dbFD function and was working just fine. Yesterday I
> removed 2 traits and this message appeared.
>
> My traits now are 3 categorical traits and 1 numeric. The 2 trais that I
> removed were numeric traits as well. I really need to remove those trait,
> but I still need the FDiv to be calculated. Can you explain to me why is
> this error occurring? I need to know how the dbFD is measuring the indexes
> so I can understanding the error and if I can or can't continue to use this
> package (if it applies or not to my goals)
>
> Kind regards
>
> F?bio Monteiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Fri Mar  4 02:33:43 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 3 Mar 2016 17:33:43 -0800
Subject: [R] Extracting part of a factor
In-Reply-To: <B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
Message-ID: <56D8E5F7.3040404@fredhutch.org>

On 03/03/2016 02:13 PM, KMNanus wrote:
> When I do that,

When you do what exactly?

It's impossible for anyone here to know what you're doing if you
don't show the code.

> I get "Error in `$<-.data.frame`(`*tmp*`, "site", value
> = integer(0)) :
>    replacement has 0 rows, data has 6?
>
> The data frame has 6 rows.

You said you had a factor variable, you never mentioned you had a
data.frame. If the factor variable is part of a data.frame 'df',
then first extract it with something like df$myvar or df[["myvar"]],
and then call substr() followed by as.factor() on it.

H.

>
> Ken
> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>> On Mar 3, 2016, at 4:52 PM, Herv? Pag?s <hpages at fredhutch.org
>> <mailto:hpages at fredhutch.org>> wrote:
>>
>> Hi,
>>
>> On 03/03/2016 12:18 PM, KMNanus wrote:
>>> I have a factor variable that is 6 digits and hyphenated.  For
>>> example, 001-014.
>>>
>>> I need to extract the first 3 digits to a new variable using mutate
>>> in dplyr - in this case 001 - but can?t find a function to do it.
>>>
>>> substr will do this for character strings, but I need the variable to
>>> remain as a factor.
>>
>> What prevents you from calling as.factor() on the result to turn it
>> back into a factor?
>>
>> H.
>>
>>>
>>> Is there an R function  or workaround to do this?
>>>
>>>
>>> Ken
>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From fabio.monteiro1992 at gmail.com  Fri Mar  4 01:30:06 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Fri, 4 Mar 2016 00:30:06 +0000
Subject: [R] package FD
In-Reply-To: <CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
Message-ID: <CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>

i just called trait3 to my variable.

Is this what i'm suppose to wright? class(trait3), or class
(my_trait3_variable?

both give error

2016-03-03 23:42 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Fabio,
> It is possible that your remaining "numeric" variable is a factor. What
> does:
>
> class(my_numeric_variable)
>
> say? (where you substitute the name of your "numeric" variable)
>
> Jim
>
>
> On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
> <fabio.monteiro1992 at gmail.com> wrote:
> > Hello, my name is F?bio and I'm a Marine Ecology student in Portugal.
> >
> > I'm currently using the FD package for my work and yesterday one message
> > appeared that I wasn't expecting and I really need your help to try to
> > figure out what's happening.
> > I'm using the dbFD function and the following message appeared:
> >
> > FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic was
> >  measured as the number of unique trait combinations, NOT as the convex
> > hull volume.
> > FDiv: Cannot be computed when only categorical and/or ordinal trait(s)
> > present in 'x'.
> >
> > My data:
> > x is a matrix with species vs functional traits
> > a is a matrix with species vs sampling (in abundances)
> >
> > Previously I used the dbFD function and was working just fine. Yesterday
> I
> > removed 2 traits and this message appeared.
> >
> > My traits now are 3 categorical traits and 1 numeric. The 2 trais that I
> > removed were numeric traits as well. I really need to remove those trait,
> > but I still need the FDiv to be calculated. Can you explain to me why is
> > this error occurring? I need to know how the dbFD is measuring the
> indexes
> > so I can understanding the error and if I can or can't continue to use
> this
> > package (if it applies or not to my goals)
> >
> > Kind regards
> >
> > F?bio Monteiro
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulhaqz at gmail.com  Fri Mar  4 06:33:05 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Fri, 4 Mar 2016 10:33:05 +0500
Subject: [R] Error in upgrading ggplot2
Message-ID: <CADw4CkvpADQD0sZuXpWxfk+ENcBGswTSD_7kC+1Ace0ZMKH5Tw@mail.gmail.com>

Hi,

I was planning to use GGally, which required me to upgrade ggplot2 but
despite trying multiple times, I have been unable to do so:

The ggplot2 downloads and installs, but when I load it, I get the following
message:

> library("ggplot2", lib.loc="/usr/local/lib/R/site-library")
Error in get(method, envir = home) :
  lazy-load database '/usr/local/lib/R/site-library/ggplot2/R/ggplot2.rdb'
is corrupt
In addition: Warning message:
In get(method, envir = home) : internal error -3 in R_decompress1
Error: package or namespace load failed for ?ggplot2?

The session info is as follows:

> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C         LC_TIME=C
 LC_COLLATE=C         LC_MONETARY=C
 [6] LC_MESSAGES=C        LC_PAPER=C           LC_NAME=C
 LC_ADDRESS=C         LC_TELEPHONE=C
[11] LC_MEASUREMENT=C     LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] scales_0.3.0   reshape2_1.4.1 dplyr_0.4.3

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.3      assertthat_0.1   digest_0.6.8     MASS_7.3-40
 R6_2.1.1         grid_3.2.2
 [7] plyr_1.8.3       gtable_0.1.2     DBI_0.3.1        magrittr_1.5
stringi_1.0-1    lazyeval_0.1.10
[13] proto_0.3-10     tools_3.2.2      stringr_1.0.0    munsell_0.4.2
 parallel_3.2.2   colorspace_1.2-6


Thanks

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar  4 06:56:15 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 03 Mar 2016 21:56:15 -0800
Subject: [R] Error in upgrading ggplot2
In-Reply-To: <CADw4CkvpADQD0sZuXpWxfk+ENcBGswTSD_7kC+1Ace0ZMKH5Tw@mail.gmail.com>
References: <CADw4CkvpADQD0sZuXpWxfk+ENcBGswTSD_7kC+1Ace0ZMKH5Tw@mail.gmail.com>
Message-ID: <8B6EBD4C-CF3C-4D9C-AC16-4E0CBBB7465D@dcn.davis.ca.us>

The usual thing to try in cases like this is another mirror. 

Another worthwhile step is upgrading your R software to the latest... if only to comply with the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On March 3, 2016 9:33:05 PM PST, Burhan ul haq <ulhaqz at gmail.com> wrote:
>Hi,
>
>I was planning to use GGally, which required me to upgrade ggplot2 but
>despite trying multiple times, I have been unable to do so:
>
>The ggplot2 downloads and installs, but when I load it, I get the
>following
>message:
>
>> library("ggplot2", lib.loc="/usr/local/lib/R/site-library")
>Error in get(method, envir = home) :
>lazy-load database
>'/usr/local/lib/R/site-library/ggplot2/R/ggplot2.rdb'
>is corrupt
>In addition: Warning message:
>In get(method, envir = home) : internal error -3 in R_decompress1
>Error: package or namespace load failed for ?ggplot2?
>
>The session info is as follows:
>
>> sessionInfo()
>R version 3.2.2 (2015-08-14)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Ubuntu 14.04.1 LTS
>
>locale:
> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C         LC_TIME=C
> LC_COLLATE=C         LC_MONETARY=C
> [6] LC_MESSAGES=C        LC_PAPER=C           LC_NAME=C
> LC_ADDRESS=C         LC_TELEPHONE=C
>[11] LC_MEASUREMENT=C     LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] scales_0.3.0   reshape2_1.4.1 dplyr_0.4.3
>
>loaded via a namespace (and not attached):
> [1] Rcpp_0.12.3      assertthat_0.1   digest_0.6.8     MASS_7.3-40
> R6_2.1.1         grid_3.2.2
> [7] plyr_1.8.3       gtable_0.1.2     DBI_0.3.1        magrittr_1.5
>stringi_1.0-1    lazyeval_0.1.10
>[13] proto_0.3-10     tools_3.2.2      stringr_1.0.0    munsell_0.4.2
> parallel_3.2.2   colorspace_1.2-6
>
>
>Thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulhaqz at gmail.com  Fri Mar  4 07:44:16 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Fri, 4 Mar 2016 11:44:16 +0500
Subject: [R] Error in upgrading ggplot2
In-Reply-To: <8B6EBD4C-CF3C-4D9C-AC16-4E0CBBB7465D@dcn.davis.ca.us>
References: <CADw4CkvpADQD0sZuXpWxfk+ENcBGswTSD_7kC+1Ace0ZMKH5Tw@mail.gmail.com>
	<8B6EBD4C-CF3C-4D9C-AC16-4E0CBBB7465D@dcn.davis.ca.us>
Message-ID: <CADw4CksfA4cRwpWkRBuuSQ88T4-t=zrSHVjuj7K-5fsW_8Y5hw@mail.gmail.com>

Thanks. I will try both the options 1) another mirror 2) upgrading R, and
revert in case of issues.


Br /

On Fri, Mar 4, 2016 at 10:56 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The usual thing to try in cases like this is another mirror.
>
> Another worthwhile step is upgrading your R software to the latest... if
> only to comply with the Posting Guide.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 3, 2016 9:33:05 PM PST, Burhan ul haq <ulhaqz at gmail.com> wrote:
>>
>> Hi,
>>
>> I was planning to use GGally, which required me to upgrade ggplot2 but
>> despite trying multiple times, I have been unable to do so:
>>
>> The ggplot2 downloads and installs, but when I load it, I get the following
>> message:
>>
>>  library("ggplot2", lib.loc="/usr/local/lib/R/site-library")
>>>
>> Error in get(method, envir = home) :
>>   lazy-load database '/usr/local/lib/R/site-library/ggplot2/R/ggplot2.rdb'
>> is corrupt
>> In addition: Warning message:
>> In get(method, envir = home) : internal error -3 in R_decompress1
>> Error: package or namespace load failed for ?ggplot2?
>>
>> The session info is as follows:
>>
>>  sessionInfo()
>>>
>> R version
>> 3.2.2 (2015-08-14)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.1 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C         LC_TIME=C
>>  LC_COLLATE=C         LC_MONETARY=C
>>  [6] LC_MESSAGES=C        LC_PAPER=C           LC_NAME=C
>>  LC_ADDRESS=C         LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=C     LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] scales_0.3.0   reshape2_1.4.1 dplyr_0.4.3
>>
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.3      assertthat_0.1   digest_0.6.8     MASS_7.3-40
>>  R6_2.1.1         grid_3.2.2
>>  [7] plyr_1.8.3       gtable_0.1.2     DBI_0.3.1        magrittr_1.5
>> stringi_1.0-1    lazyeval_0.1.10
>> [13] proto_0.3-10     tools_3.2.2      stringr_1.0.0    munsell_0.4.2
>>  parallel_3.2.2   colorspace_1.2-6
>>
>>
>> Thanks
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Mar  4 08:15:50 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 4 Mar 2016 18:15:50 +1100
Subject: [R] package FD
In-Reply-To: <CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
Message-ID: <CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>

Hi Fabio,
You should write:

class(...)

where ... is the same as what you would type to have the variable
displayed on the console. Looking at your earlier message, it might
be:

x$trait3

so try:

class(x$trait3)

Jim


On Fri, Mar 4, 2016 at 11:30 AM, Fabio Monteiro
<fabio.monteiro1992 at gmail.com> wrote:
> i just called trait3 to my variable.
>
> Is this what i'm suppose to wright? class(trait3), or class
> (my_trait3_variable?
>
> both give error
>
> 2016-03-03 23:42 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Fabio,
>> It is possible that your remaining "numeric" variable is a factor. What
>> does:
>>
>> class(my_numeric_variable)
>>
>> say? (where you substitute the name of your "numeric" variable)
>>
>> Jim
>>
>>
>> On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
>> <fabio.monteiro1992 at gmail.com> wrote:
>> > Hello, my name is F?bio and I'm a Marine Ecology student in Portugal.
>> >
>> > I'm currently using the FD package for my work and yesterday one message
>> > appeared that I wasn't expecting and I really need your help to try to
>> > figure out what's happening.
>> > I'm using the dbFD function and the following message appeared:
>> >
>> > FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic was
>> >  measured as the number of unique trait combinations, NOT as the convex
>> > hull volume.
>> > FDiv: Cannot be computed when only categorical and/or ordinal trait(s)
>> > present in 'x'.
>> >
>> > My data:
>> > x is a matrix with species vs functional traits
>> > a is a matrix with species vs sampling (in abundances)
>> >
>> > Previously I used the dbFD function and was working just fine. Yesterday
>> > I
>> > removed 2 traits and this message appeared.
>> >
>> > My traits now are 3 categorical traits and 1 numeric. The 2 trais that I
>> > removed were numeric traits as well. I really need to remove those
>> > trait,
>> > but I still need the FDiv to be calculated. Can you explain to me why is
>> > this error occurring? I need to know how the dbFD is measuring the
>> > indexes
>> > so I can understanding the error and if I can or can't continue to use
>> > this
>> > package (if it applies or not to my goals)
>> >
>> > Kind regards
>> >
>> > F?bio Monteiro
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From jean-externe.maurice at edf.fr  Fri Mar  4 08:51:01 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Fri, 4 Mar 2016 07:51:01 +0000
Subject: [R] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <FEE799F2-5E0C-4478-A58B-8F900D23DEF6@xs4all.nl>
References: <e4289da605794c43a8b5e590f8c5633b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<FEE799F2-5E0C-4478-A58B-8F900D23DEF6@xs4all.nl>
Message-ID: <af91484a304d43ff93c0cd271749bb2e@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Berend,


>The question belongs on the R-devel mailinglist.
I try to find this mailing-list ...

>You are calling your Fortran routines directly from an R file with .Fortran, I presume?
Yes. Is there another solution (possibility ?)

>Declare them with (:,:) or (*,*), allocate and the return the array? A Fortran95 pointer?
That was what I wanted to do ...

>I think  all of that is just a no no.
It would be a big problem with memory management but R could copy the result before the memory attached to the FORTRAN subroutine is cleared at the end of the routine. R does so strange things (for an old programmer as I am).

>Is it possible to calculate the required size of the array in a separate routine given some parameters (as can often be done with >Lapack routines) before calling the main subroutine?
>If so, call the sizing routine and then declare the correctly sized array in your R code and pass it to the main subroutine.

It's a good idea : a 'two shots' routine. I'll dig that (I'll work in this direction).

Thanks
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From bhh at xs4all.nl  Fri Mar  4 09:23:01 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 4 Mar 2016 09:23:01 +0100
Subject: [R] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <af91484a304d43ff93c0cd271749bb2e@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <e4289da605794c43a8b5e590f8c5633b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<FEE799F2-5E0C-4478-A58B-8F900D23DEF6@xs4all.nl>
	<af91484a304d43ff93c0cd271749bb2e@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <66AC9173-F9A9-4A41-9B5D-DAFCBCB12059@xs4all.nl>


> On 4 Mar 2016, at 08:51, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
> 
> Hi Berend,
> 
> 
>> The question belongs on the R-devel mailinglist.
> I try to find this mailing-list ...
> 

See https://www.r-project.org/mail.html

>> You are calling your Fortran routines directly from an R file with .Fortran, I presume?
> Yes. Is there another solution (possibility ?)
> 

Yes. Use C to interface with Fortran.

See for example packages: minpack.lm, QZ, expm, nleqslv. And more: rootSolve, ucminf.
There are probably even more.

>> Declare them with (:,:) or (*,*), allocate and the return the array? A Fortran95 pointer?
> That was what I wanted to do ...
> 
>> I think  all of that is just a no no.
> It would be a big problem with memory management but R could copy the result before the memory attached to the FORTRAN subroutine is cleared at the end of the routine. R does so strange things (for an old programmer as I am).
> 
>> Is it possible to calculate the required size of the array in a separate routine given some parameters (as can often be done with >Lapack routines) before calling the main subroutine?
>> If so, call the sizing routine and then declare the correctly sized array in your R code and pass it to the main subroutine.
> 
> It's a good idea : a 'two shots' routine. I'll dig that (I'll work in this direction).
> 

Commercial:  Have a look at (my) packages nleqslv and geigen for that approach.

Berend


From catalinroibu at gmail.com  Fri Mar  4 12:22:07 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Fri, 4 Mar 2016 13:22:07 +0200
Subject: [R] difference between successive values
Message-ID: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>

Dear all!

I want to calculate difference between successive values (cumulative
values) with R. I used diff function, but I want to keep the first values.

Please help me to solve this problem!

Thank you!

Best regards!

CR

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Fri Mar  4 12:28:08 2016
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Fri, 4 Mar 2016 12:28:08 +0100
Subject: [R] difference between successive values
In-Reply-To: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>
References: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>
Message-ID: <20160304122808.7063b1afa41cd3e71a891609@univ-nantes.fr>

Hi,

(1) You should provide a minimal working example;

(2) But anyway, does...

x = sample(10)
c(x[1],diff(x))

... do what you want?

Olivier.


On Fri, 4 Mar 2016
13:22:07 +0200 catalin roibu <catalinroibu at gmail.com> wrote:

> Dear all!
> 
> I want to calculate difference between successive values (cumulative
> values) with R. I used diff function, but I want to keep the first
> values.
> 
> Please help me to solve this problem!
> 
> Thank you!
> 
> Best regards!
> 
> CR
> 
> -- 
> 
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique de Nantes -- UMR6310
  CNRS / Universit? de Nantes
  Chemin de la Censive du Tertre -- BP 81227
  44312 Nantes cedex 3
  France

  http://www.lling.univ-nantes.fr/


From boxuancui at gmail.com  Wed Mar  2 19:46:53 2016
From: boxuancui at gmail.com (Boxuan Cui)
Date: Wed, 2 Mar 2016 13:46:53 -0500
Subject: [R] [R-pkgs] New package: DataExplorer
Message-ID: <CAC-fbYZNnJjwdm7iDfq+=453mAQ0LhpH9Ya-q04ypk1hKhfskQ@mail.gmail.com>

Dear useRs,

I am really excited that my first package is now on CRAN:
https://cran.r-project.org/web/packages/DataExplorer/.

The package aims to simplify the data exploration process before your data
analysis and/or model building process.

Example use case: One day, you get a random dataset that you have no idea
what is in there. You could simply type the following two lines of R code
to quickly visualize things and get started.

*## assume you load the data into R and name it mysterious_data*
*library(DataExplorer)*
*GenerateReport(mysterious_data)*


I am trying to add more functionalities and also vignettes to better
illustrate how to explore your data using this package. Check the GitHub
page for most up-to-date development:
https://github.com/boxuancui/DataExplorer.

I welcome all feedback, suggestions, bug reports and feature requests.
Thank you!


Best,
Boxuan (Bo)

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewmil at dcn.davis.ca.us  Fri Mar  4 15:12:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 04 Mar 2016 06:12:54 -0800
Subject: [R] difference between successive values
In-Reply-To: <20160304122808.7063b1afa41cd3e71a891609@univ-nantes.fr>
References: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>
	<20160304122808.7063b1afa41cd3e71a891609@univ-nantes.fr>
Message-ID: <CA9C1FAD-8FE0-4D23-9E3A-DA88C64A82C0@dcn.davis.ca.us>

"Keep the first values" is imprecise, but mixing an absolute value with a bunch of differences doesn't usually work out well.  I frequently choose among

x <- sample( 10 )
dxright <- c( 0, diff(x) )
dxleft <- c( diff(x), 0 )

for calculation purposes depending on my needs. 
-- 
Sent from my phone. Please excuse my brevity.

On March 4, 2016 3:28:08 AM PST, Olivier Crouzet <olivier.crouzet at univ-nantes.fr> wrote:
>Hi,
>
>(1) You should provide a minimal working example;
>
>(2) But anyway, does...
>
>x = sample(10)
>c(x[1],diff(x))
>
>... do what you want?
>
>Olivier.
>
>
>On Fri, 4 Mar 2016
>13:22:07 +0200 catalin roibu <catalinroibu at gmail.com> wrote:
>
>> Dear all!
>> 
>> I want to calculate difference between successive values (cumulative
>> values) with R. I used diff function, but I want to keep the first
>> values.
>> 
>> Please help me to solve this problem!
>> 
>> Thank you!
>> 
>> Best regards!
>> 
>> CR
>> 
>> -- 
>> 
>> -
>> -
>> Catalin-Constantin ROIBU
>> ?
>> Lecturer PhD, Forestry engineer
>> Forestry Faculty of Suceava
>> Str. Universitatii no. 13, Suceava, 720229, Romania
>> office phone      +4 0230 52 29 78, ext. 531
>> mobile phone    +4 0745 53 18 01
>> FAX:                +4 0230 52 16 64
>> silvic.usv.ro <http://www.usv.ro/>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>
>-- 
>  Olivier Crouzet, PhD
>  Laboratoire de Linguistique de Nantes -- UMR6310
>  CNRS / Universit? de Nantes
>  Chemin de la Censive du Tertre -- BP 81227
>  44312 Nantes cedex 3
>  France
>
>  http://www.lling.univ-nantes.fr/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From catalinroibu at gmail.com  Fri Mar  4 15:59:26 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Fri, 04 Mar 2016 14:59:26 +0000
Subject: [R] difference between successive values
In-Reply-To: <CA9C1FAD-8FE0-4D23-9E3A-DA88C64A82C0@dcn.davis.ca.us>
References: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>
	<20160304122808.7063b1afa41cd3e71a891609@univ-nantes.fr>
	<CA9C1FAD-8FE0-4D23-9E3A-DA88C64A82C0@dcn.davis.ca.us>
Message-ID: <CAEW+BD+jiNx2SU2JzSiPdQyQscxCovj4kJ0vrrW78Uq_xOPAFA@mail.gmail.com>

I mean the first row value

?n Vin, 4 mar. 2016, 16:15 Jeff Newmiller, <jdnewmil at dcn.davis.ca.us> a
scris:

> "Keep the first values" is imprecise, but mixing an absolute value with a
> bunch of differences doesn't usually work out well.  I frequently choose
> among
>
> x <- sample( 10 )
> dxright <- c( 0, diff(x) )
> dxleft <- c( diff(x), 0 )
>
> for calculation purposes depending on my needs.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 4, 2016 3:28:08 AM PST, Olivier Crouzet <
> olivier.crouzet at univ-nantes.fr> wrote:
> >Hi,
> >
> >(1) You should provide a minimal working example;
> >
> >(2) But anyway, does...
> >
> >x = sample(10)
> >c(x[1],diff(x))
> >
> >... do what you want?
> >
> >Olivier.
> >
> >
> >On Fri, 4 Mar 2016
> >13:22:07 +0200 catalin roibu <catalinroibu at gmail.com> wrote:
> >
> >> Dear all!
> >>
> >> I want to calculate difference between successive values (cumulative
> >> values) with R. I used diff function, but I want to keep the first
> >> values.
> >>
> >> Please help me to solve this problem!
> >>
> >> Thank you!
> >>
> >> Best regards!
> >>
> >> CR
> >>
> >> --
> >>
> >> -
> >> -
> >> Catalin-Constantin ROIBU
> >> ?
> >> Lecturer PhD, Forestry engineer
> >> Forestry Faculty of Suceava
> >> Str. Universitatii no. 13, Suceava, 720229, Romania
> >> office phone      +4 0230 52 29 78, ext. 531
> >> mobile phone    +4 0745 53 18 01
> >> FAX:                +4 0230 52 16 64
> >> silvic.usv.ro <http://www.usv.ro/>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html and provide commented,
> >> minimal, self-contained, reproducible code.
> >
> >--
> >  Olivier Crouzet, PhD
> >  Laboratoire de Linguistique de Nantes -- UMR6310
> >  CNRS / Universit? de Nantes
> >  Chemin de la Censive du Tertre -- BP 81227
> >  44312 Nantes cedex 3
> >  France
> >
> >  http://www.lling.univ-nantes.fr/
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
?
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229,
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Fri Mar  4 17:57:08 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 4 Mar 2016 11:57:08 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <56D8E5F7.3040404@fredhutch.org>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
Message-ID: <7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>

Let me see if I can ask the question more clearly - I am trying to extract a section of a hyphenated factor. For example, 001-004 is one observation of test$ken, which is a factor, and I want to set up a new factor variable called place that would have 001 as an observation. If I call mutate(place = (as.character (test$ken)), I can extract 001 from  001-004, but but don't know how to subsequently convert that character string back into a factor.


Or can 001 be extracted from a factor as a factor?

Do you know how to execute either of these approaches?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 3, 2016, at 8:33 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> 
> On 03/03/2016 02:13 PM, KMNanus wrote:
>> When I do that,
> 
> When you do what exactly?
> 
> It's impossible for anyone here to know what you're doing if you
> don't show the code.
> 
>> I get "Error in `$<-.data.frame`(`*tmp*`, "site", value
>> = integer(0)) :
>>   replacement has 0 rows, data has 6?
>> 
>> The data frame has 6 rows.
> 
> You said you had a factor variable, you never mentioned you had a
> data.frame. If the factor variable is part of a data.frame 'df',
> then first extract it with something like df$myvar or df[["myvar"]],
> and then call substr() followed by as.factor() on it.
> 
> H.
> 
>> 
>> Ken
>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>>> On Mar 3, 2016, at 4:52 PM, Herv? Pag?s <hpages at fredhutch.org
>>> <mailto:hpages at fredhutch.org>> wrote:
>>> 
>>> Hi,
>>> 
>>> On 03/03/2016 12:18 PM, KMNanus wrote:
>>>> I have a factor variable that is 6 digits and hyphenated.  For
>>>> example, 001-014.
>>>> 
>>>> I need to extract the first 3 digits to a new variable using mutate
>>>> in dplyr - in this case 001 - but can?t find a function to do it.
>>>> 
>>>> substr will do this for character strings, but I need the variable to
>>>> remain as a factor.
>>> 
>>> What prevents you from calling as.factor() on the result to turn it
>>> back into a factor?
>>> 
>>> H.
>>> 
>>>> 
>>>> Is there an R function  or workaround to do this?
>>>> 
>>>> 
>>>> Ken
>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>> 914-450-0816 (tel)
>>>> 347-730-4813 (fax)
>>>> 
>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> --
>>> Herv? Pag?s
>>> 
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>> 
>>> E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From sarah.goslee at gmail.com  Fri Mar  4 18:49:56 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 4 Mar 2016 12:49:56 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
Message-ID: <CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>

Hi Ken,

You do that with as.factor(), as has already been suggested. You'll need to
provide a reproducible example to show us what's going wrong. Using fake
data is fine, we just need to see some data that look like yours and the
code you're using.

Sarah

On Fri, Mar 4, 2016 at 11:57 AM, KMNanus <kmnanus at gmail.com> wrote:

> Let me see if I can ask the question more clearly - I am trying to extract
> a section of a hyphenated factor. For example, 001-004 is one observation
> of test$ken, which is a factor, and I want to set up a new factor variable
> called place that would have 001 as an observation. If I call mutate(place
> = (as.character (test$ken)), I can extract 001 from  001-004, but but don't
> know how to subsequently convert that character string back into a factor.
>
>
> Or can 001 be extracted from a factor as a factor?
>
> Do you know how to execute either of these approaches?
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> > On Mar 3, 2016, at 8:33 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> >
> > On 03/03/2016 02:13 PM, KMNanus wrote:
> >> When I do that,
> >
> > When you do what exactly?
> >
> > It's impossible for anyone here to know what you're doing if you
> > don't show the code.
> >
> >> I get "Error in `$<-.data.frame`(`*tmp*`, "site", value
> >> = integer(0)) :
> >>   replacement has 0 rows, data has 6?
> >>
> >> The data frame has 6 rows.
> >
> > You said you had a factor variable, you never mentioned you had a
> > data.frame. If the factor variable is part of a data.frame 'df',
> > then first extract it with something like df$myvar or df[["myvar"]],
> > and then call substr() followed by as.factor() on it.
> >
> > H.
> >
> >>
> >> Ken
> >> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> >> 914-450-0816 (tel)
> >> 347-730-4813 (fax)
> >>
> >>
> >>> On Mar 3, 2016, at 4:52 PM, Herv? Pag?s <hpages at fredhutch.org
> >>> <mailto:hpages at fredhutch.org>> wrote:
> >>>
> >>> Hi,
> >>>
> >>> On 03/03/2016 12:18 PM, KMNanus wrote:
> >>>> I have a factor variable that is 6 digits and hyphenated.  For
> >>>> example, 001-014.
> >>>>
> >>>> I need to extract the first 3 digits to a new variable using mutate
> >>>> in dplyr - in this case 001 - but can?t find a function to do it.
> >>>>
> >>>> substr will do this for character strings, but I need the variable to
> >>>> remain as a factor.
> >>>
> >>> What prevents you from calling as.factor() on the result to turn it
> >>> back into a factor?
> >>>
> >>> H.
> >>>
> >>>>
> >>>> Is there an R function  or workaround to do this?
> >>>>
> >>>>
> >>>> Ken
> >>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> >>>> 914-450-0816 (tel)
> >>>> 347-730-4813 (fax)
> >>>>
> >>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>> --
> >>> Herv? Pag?s
> >>>
> >>> Program in Computational Biology
> >>> Division of Public Health Sciences
> >>> Fred Hutchinson Cancer Research Center
> >>> 1100 Fairview Ave. N, M1-B514
> >>> P.O. Box 19024
> >>> Seattle, WA 98109-1024
> >>>
> >>> E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
> >>> Phone:  (206) 667-5791
> >>> Fax:    (206) 667-1319
> >>
> >
> > --
> > Herv? Pag?s
> >
> > Program in Computational Biology
> > Division of Public Health Sciences
> > Fred Hutchinson Cancer Research Center
> > 1100 Fairview Ave. N, M1-B514
> > P.O. Box 19024
> > Seattle, WA 98109-1024
> >
> > E-mail: hpages at fredhutch.org
> > Phone:  (206) 667-5791
> > Fax:    (206) 667-1319
>
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Fri Mar  4 18:38:43 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Fri, 4 Mar 2016 17:38:43 +0000
Subject: [R] help in maximum likelihood
In-Reply-To: <43284B1A-AF5A-4E8A-8162-CBBD8DC01F90@icloud.com>
References: <cd5230e4a3ac4f92abc95363183d2e8f@ESGEBEX10.win.ad.jhu.edu>
	<43284B1A-AF5A-4E8A-8162-CBBD8DC01F90@icloud.com>
Message-ID: <540db37ffc3d470eafef75e800f5563d@ESGEBEX10.win.ad.jhu.edu>

Standard error = sqrt(diag(solve(opt$hessian)))

Ravi

From: Alaa Sindi [mailto:alaasindi at icloud.com]
Sent: Wednesday, March 02, 2016 3:22 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: help in maximum likelihood

Thank you very much prof. Ravi,

That was very helpful. Is there a way to get the t and p value for the coefficients?

Thanks
Alaa
On Mar 2, 2016, at 10:05 AM, Ravi Varadhan <ravi.varadhan at jhu.edu<mailto:ravi.varadhan at jhu.edu>> wrote:

There is nothing wrong with the optimization.  It is a warning message.  However, this is a good example to show that one should not simply dismiss a warning before understanding what it means.  The MLE parameters are also large, indicating that there is something funky about the model or the data or both.  In your case, there is one major problem with the data:  for the highest dose (value of x), you have all subjects responding, i.e. y = n.  Even for the next lower dose, there is almost complete response.  Where do these data come from? Are they real or fake (simulated) data?

Also, take a look at the eigenvalues of the hessian at the solution.  You will see that there is some ill-conditioning, as the eigenvalues are widely separated.

x <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)

# note: there is no need to have the choose(n, y) term in the likelihood
fn <- function(p)
    sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))) )

out <- nlm(fn, p = c(-50,20), hessian = TRUE)

out

eigen(out$hessian)


Hope this is helpful,
Ravi



Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619



	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Mar  4 19:07:27 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 4 Mar 2016 13:07:27 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
Message-ID: <CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>

As everyone has been telling you, as.factor().
If you like the mutate approach, you can call as.factor(test$subject)
to convert it.

Here's a one-liner with reproducible data.


testdata <- structure(list(subject = structure(1:6, .Label = c("001-002",
"002-003", "003-004", "004-005", "005-006", "006-007"), class = "factor"),
    group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
    "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
    1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
    8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names = c("subject",
"group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names = c(NA,
-6L))

testdata$subject <- as.factor(substring(as.character(testdata$subject), 1, 3))

> testdata
  subject group wk1 wk2 wk3 wk4
1     001  boys   2   3   4   5
2     002  boys   7   6   5   4
3     003  boys   9   4   6   1
4     004 girls   5   7   8   9
5     005 girls   2   6   3   8
6     006 girls   1   4   7   4
> str(testdata)
'data.frame': 6 obs. of  6 variables:
 $ subject: Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4

Sarah

On Fri, Mar 4, 2016 at 1:00 PM, KMNanus <kmnanus at gmail.com> wrote:
>
> Here?s the dataset I?m working with, called test -
>
> subject group wk1 wk2 wk3 wk4 place
> 001-002 boys 2 3 4 5
> 002-003 boys 7 6 5 4
> 003-004 boys 9 4 6 1
> 004-005 girls 5 7 8 9
> 005-006 girls 2 6 3 8
> 006-007 girls 1 4 7 4
>
>
> if I call mutate(test, place = substr(subject,1,3), ?001 is the first observation in the place column
>
> But it?s a character and ?subject? is a factor.  I need place to be a factor, too, but I need the observations to be ONLY the first three numbers of ?subject.?
>
> Does that make my request more understandable?


From jdnewmil at dcn.davis.ca.us  Fri Mar  4 21:46:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 04 Mar 2016 12:46:19 -0800
Subject: [R] Extracting part of a factor
In-Reply-To: <CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
Message-ID: <E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>

I much prefer the factor function over the as.factor function for converting character to factor, since you can set the levels in the order you want them to be. 
-- 
Sent from my phone. Please excuse my brevity.

On March 4, 2016 10:07:27 AM PST, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>As everyone has been telling you, as.factor().
>If you like the mutate approach, you can call as.factor(test$subject)
>to convert it.
>
>Here's a one-liner with reproducible data.
>
>
>testdata <- structure(list(subject = structure(1:6, .Label =
>c("001-002",
>"002-003", "003-004", "004-005", "005-006", "006-007"), class =
>"factor"),
>    group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
>    "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
>    1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
>   8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names = c("subject",
>"group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names =
>c(NA,
>-6L))
>
>testdata$subject <- as.factor(substring(as.character(testdata$subject),
>1, 3))
>
>> testdata
>  subject group wk1 wk2 wk3 wk4
>1     001  boys   2   3   4   5
>2     002  boys   7   6   5   4
>3     003  boys   9   4   6   1
>4     004 girls   5   7   8   9
>5     005 girls   2   6   3   8
>6     006 girls   1   4   7   4
>> str(testdata)
>'data.frame': 6 obs. of  6 variables:
> $ subject: Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
> $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
> $ wk1    : int  2 7 9 5 2 1
> $ wk2    : int  3 6 4 7 6 4
> $ wk3    : int  4 5 6 8 3 7
> $ wk4    : int  5 4 1 9 8 4
>
>Sarah
>
>On Fri, Mar 4, 2016 at 1:00 PM, KMNanus <kmnanus at gmail.com> wrote:
>>
>> Here?s the dataset I?m working with, called test -
>>
>> subject group wk1 wk2 wk3 wk4 place
>> 001-002 boys 2 3 4 5
>> 002-003 boys 7 6 5 4
>> 003-004 boys 9 4 6 1
>> 004-005 girls 5 7 8 9
>> 005-006 girls 2 6 3 8
>> 006-007 girls 1 4 7 4
>>
>>
>> if I call mutate(test, place = substr(subject,1,3), ?001 is the first
>observation in the place column
>>
>> But it?s a character and ?subject? is a factor.  I need place to be a
>factor, too, but I need the observations to be ONLY the first three
>numbers of ?subject.?
>>
>> Does that make my request more understandable?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Mar  4 22:32:37 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 4 Mar 2016 16:32:37 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
Message-ID: <CAM_vjum=RjPYY+5VKTBdFr8Zq5Na5yRcN1rOMK5J2ZoAN6EHqw@mail.gmail.com>

You're not saving the result of mutate(). You're just printing it to the screen.

Try instead:
test <- mutate(testdata, place = substr(testdata$subject, 1,3))
test$place <- as.factor(test$place) # or factor() if you'd rather

This is why we ask for reproducible examples with data and code.
Look through the following and see if you understand.


test <- structure(list(subject = structure(1:6, .Label = c("001-002",
"002-003", "003-004", "004-005", "005-006", "006-007"), class = "factor"),
    group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
    "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
    1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
    8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names = c("subject",
"group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names = c(NA,
-6L))

> str(test)
'data.frame': 6 obs. of  6 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4
> mutate(test, place = substr(testdata$subject, 1,3))
  subject group wk1 wk2 wk3 wk4 place
1 001-002  boys   2   3   4   5   001
2 002-003  boys   7   6   5   4   002
3 003-004  boys   9   4   6   1   003
4 004-005 girls   5   7   8   9   004
5 005-006 girls   2   6   3   8   005
6 006-007 girls   1   4   7   4   006
> str(test)
'data.frame': 6 obs. of  6 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4



test <- mutate(testdata, place = substr(testdata$subject, 1,3))
test$place <- as.factor(test$place)

> str(test)
'data.frame': 6 obs. of  7 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4
 $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6



On Fri, Mar 4, 2016 at 4:13 PM, KMNanus <kmnanus at gmail.com> wrote:
> Here?s where I?m stumped -
>
> when I call mutate(test, place = substr(test$subject, 1,3)) to create a
> place variable, I get this, with place as a character variable.
>
>  subject  group   wk1   wk2   wk3   wk4 place
>    (fctr) (fctr) (int) (int) (int) (int) (chr)
> 1 001-002   boys     2     3     4     5   001
> 2 002-003   boys     7     6     5     4   002
> 3 003-004   boys     9     4     6     1   003
> 4 004-005  girls     5     7     8     9   004
> 5 005-006  girls     2     6     3     8   005
> 6 006-007  girls     1     4     7     4   006
>
> When I call test$place <- factor(test$place), I receive the msg  - "Error in
> `$<-.data.frame`(`*tmp*`, "place", value = integer(0)) :
>   replacement has 0 rows, data has 6.
>
> If I call mutate this way - mutate(test, place =
> factor(substr(test$subject,1,3))), I get the same output as above but when I
> call class(test$place), I get NULL and the variable disappears.
>
> I can?t figure out why.
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
> On Mar 4, 2016, at 3:46 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> I much prefer the factor function over the as.factor function for converting
> character to factor, since you can set the levels in the order you want them
> to be.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 4, 2016 10:07:27 AM PST, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> As everyone has been telling you, as.factor().
>> If you like the mutate approach, you can call as.factor(test$subject)
>> to convert it.
>>
>> Here's a one-liner with reproducible data.
>>
>>
>> testdata <- structure(list(subject = structure(1:6, .Label = c("001-002",
>> "002-003", "003-004", "004-005", "005-006", "006-007"), class = "factor"),
>>     group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
>>     "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
>>     1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
>>     8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names = c("subject",
>> "group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names =
>> c(NA,
>> -6L))
>>
>> testdata$subject <- as.factor(substring(as.character(testdata$subject), 1,
>> 3))
>>
>>>
>>> testdata
>>
>>   subject group wk1 wk2 wk3 wk4
>> 1     001  boys   2   3   4   5
>> 2     002  boys   7   6   5   4
>> 3     003  boys   9   4   6   1
>> 4     004 girls   5   7   8   9
>> 5     005 girls   2   6   3   8
>> 6     006 girls   1   4   7   4
>>>
>>>  str(testdata)
>>
>> 'data.frame': 6 obs. of  6 variables:
>>  $ subject: Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>>  $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>>  $ wk1    : int  2 7 9 5 2 1
>>  $ wk2    : int  3 6 4 7 6 4
>>  $ wk3    : int  4 5 6 8 3 7
>>  $ wk4    : int  5 4 1 9 8 4
>>
>> Sarah
>>
>> On Fri, Mar 4, 2016 at 1:00 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>
>>>
>>>  Here?s the dataset
>>> I?m working with, called test -
>>>
>>>  subject group wk1 wk2 wk3 wk4 place
>>>  001-002 boys 2 3 4 5
>>>  002-003 boys 7 6 5 4
>>>  003-004 boys 9 4 6 1
>>>  004-005 girls 5 7 8 9
>>>  005-006 girls 2 6 3 8
>>>  006-007 girls 1 4 7 4
>>>
>>>
>>>  if I call mutate(test, place = substr(subject,1,3), ?001 is the first
>>> observation in the place column
>>>
>>>  But it?s a character and ?subject? is a factor.  I need place to be a
>>> factor, too, but I need the observations to be ONLY the first three numbers
>>> of ?subject.?
>>>
>>>  Does that make my request more understandable?
>>


From jdnewmil at dcn.davis.ca.us  Fri Mar  4 22:35:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 04 Mar 2016 13:35:42 -0800
Subject: [R] Extracting part of a factor
In-Reply-To: <54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
Message-ID: <92936980-B75C-4074-B297-32B88FD1E7C8@dcn.davis.ca.us>

This is not a problem with factor or as.factor, this is a problem with your use of the dplyr package or with bugs in that package. 

Please make a reproducible example, making sure to use the dput function to create the code that initializes the data so we can run your code. Read the Posting Guide for more on reproducibility.

To avoid getting your code messed up in transit to us, make sure you send your email in plain text mode... this is also mentioned in the PG.
-- 
Sent from my phone. Please excuse my brevity.

On March 4, 2016 1:13:54 PM PST, KMNanus <kmnanus at gmail.com> wrote:
>Here?s where I?m stumped - 
>
>when I call mutate(test, place = substr(test$subject, 1,3)) to create a
>place variable, I get this, with place as a character variable. 
>
> subject  group   wk1   wk2   wk3   wk4 place
>   (fctr) (fctr) (int) (int) (int) (int) (chr)
>1 001-002   boys     2     3     4     5   001
>2 002-003   boys     7     6     5     4   002
>3 003-004   boys     9     4     6     1   003
>4 004-005  girls     5     7     8     9   004
>5 005-006  girls     2     6     3     8   005
>6 006-007  girls     1     4     7     4   006
>
>When I call test$place <- factor(test$place), I receive the msg  -
>"Error in `$<-.data.frame`(`*tmp*`, "place", value = integer(0)) : 
>  replacement has 0 rows, data has 6.
>
>If I call mutate this way - mutate(test, place =
>factor(substr(test$subject,1,3))), I get the same output as above but
>when I call class(test$place), I get NULL and the variable disappears.
>
>I can?t figure out why.
>
>Ken
>kmnanus at gmail.com
>914-450-0816 (tel)
>347-730-4813 (fax)
>
>
>
>> On Mar 4, 2016, at 3:46 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> I much prefer the factor function over the as.factor function for
>converting character to factor, since you can set the levels in the
>order you want them to be. 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On March 4, 2016 10:07:27 AM PST, Sarah Goslee
><sarah.goslee at gmail.com> wrote:
>> As everyone has been telling you, as.factor().
>> If you like the mutate approach, you can call as.factor(test$subject)
>> to convert it.
>> 
>> Here's a one-liner with reproducible data.
>> 
>> 
>> testdata <- structure(list(subject = structure(1:6, .Label =
>c("001-002",
>> "002-003", "003-004", "004-005", "005-006", "006-007"), class =
>"factor"),
>>     group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
>>     "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
>>     1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
>>     8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names =
>c("subject",
>> "group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names
>= c(NA,
>> -6L))
>> 
>> testdata$subject <-
>as.factor(substring(as.character(testdata$subject), 1, 3))
>> 
>> 
>> testdata
>>   subject group wk1 wk2 wk3 wk4
>> 1     001  boys   2   3   4   5
>> 2     002  boys   7   6   5   4
>> 3     003  boys   9   4   6   1
>> 4     004 girls   5   7   8   9
>> 5     005 girls   2   6   3   8
>> 6     006 girls   1   4   7   4
>>  str(testdata)
>> 'data.frame': 6 obs. of  6 variables:
>>  $ subject: Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>>  $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>>  $ wk1    : int  2 7 9 5 2 1
>>  $ wk2    : int  3 6 4 7 6 4
>>  $ wk3    : int  4 5 6 8 3 7
>>  $ wk4    : int  5 4 1 9 8 4
>> 
>> Sarah
>> 
>> On Fri, Mar 4, 2016 at 1:00 PM, KMNanus <kmnanus at gmail.com> wrote:
>> 
>>  Here?s the dataset
>> I?m working with, called test -
>> 
>>  subject group wk1 wk2 wk3 wk4 place
>>  001-002 boys 2 3 4 5
>>  002-003 boys 7 6 5 4
>>  003-004 boys 9 4 6 1
>>  004-005 girls 5 7 8 9
>>  005-006 girls 2 6 3 8
>>  006-007 girls 1 4 7 4
>> 
>> 
>>  if I call mutate(test, place = substr(subject,1,3), ?001 is the
>first observation in the place column
>> 
>>  But it?s a character and ?subject? is a factor.  I need place to be
>a factor, too, but I need the observations to be ONLY the first three
>numbers of ?subject.?
>> 
>>  Does that make my request more understandable?
>> 
>> 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal,
>> self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Fri Mar  4 19:00:55 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 4 Mar 2016 13:00:55 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
Message-ID: <CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>

Here?s the dataset I?m working with, called test - 

subject	group	wk1	wk2	wk3	wk4	place
001-002	boys	2	3	4	5  	
002-003	boys	7	6	5	4	
003-004	boys	9	4	6	1	
004-005	girls	5	7	8	9	
005-006	girls	2	6	3	8	
006-007	girls	1	4	7	4	


if I call mutate(test, place = substr(subject,1,3), ?001 is the first observation in the place column

But it?s a character and ?subject? is a factor.  I need place to be a factor, too, but I need the observations to be ONLY the first three numbers of ?subject.?

Does that make my request more understandable?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 4, 2016, at 12:49 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi Ken,
> 
> You do that with as.factor(), as has already been suggested. You'll need to provide a reproducible example to show us what's going wrong. Using fake data is fine, we just need to see some data that look like yours and the code you're using.
> 
> Sarah
> 
> On Fri, Mar 4, 2016 at 11:57 AM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
> Let me see if I can ask the question more clearly - I am trying to extract a section of a hyphenated factor. For example, 001-004 is one observation of test$ken, which is a factor, and I want to set up a new factor variable called place that would have 001 as an observation. If I call mutate(place = (as.character (test$ken)), I can extract 001 from  001-004, but but don't know how to subsequently convert that character string back into a factor.
> 
> 
> Or can 001 be extracted from a factor as a factor?
> 
> Do you know how to execute either of these approaches?
> 
> Ken
> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> 914-450-0816 <tel:914-450-0816> (tel)
> 347-730-4813 <tel:347-730-4813> (fax)
> 
> 
> 
> > On Mar 3, 2016, at 8:33 PM, Herv? Pag?s <hpages at fredhutch.org <mailto:hpages at fredhutch.org>> wrote:
> >
> > On 03/03/2016 02:13 PM, KMNanus wrote:
> >> When I do that,
> >
> > When you do what exactly?
> >
> > It's impossible for anyone here to know what you're doing if you
> > don't show the code.
> >
> >> I get "Error in `$<-.data.frame`(`*tmp*`, "site", value
> >> = integer(0)) :
> >>   replacement has 0 rows, data has 6?
> >>
> >> The data frame has 6 rows.
> >
> > You said you had a factor variable, you never mentioned you had a
> > data.frame. If the factor variable is part of a data.frame 'df',
> > then first extract it with something like df$myvar or df[["myvar"]],
> > and then call substr() followed by as.factor() on it.
> >
> > H.
> >
> >>
> >> Ken
> >> kmnanus at gmail.com <mailto:kmnanus at gmail.com> <mailto:kmnanus at gmail.com <mailto:kmnanus at gmail.com>>
> >> 914-450-0816 <tel:914-450-0816> (tel)
> >> 347-730-4813 <tel:347-730-4813> (fax)
> >>
> >>
> >>> On Mar 3, 2016, at 4:52 PM, Herv? Pag?s <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
> >>> <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>> wrote:
> >>>
> >>> Hi,
> >>>
> >>> On 03/03/2016 12:18 PM, KMNanus wrote:
> >>>> I have a factor variable that is 6 digits and hyphenated.  For
> >>>> example, 001-014.
> >>>>
> >>>> I need to extract the first 3 digits to a new variable using mutate
> >>>> in dplyr - in this case 001 - but can?t find a function to do it.
> >>>>
> >>>> substr will do this for character strings, but I need the variable to
> >>>> remain as a factor.
> >>>
> >>> What prevents you from calling as.factor() on the result to turn it
> >>> back into a factor?
> >>>
> >>> H.
> >>>
> >>>>
> >>>> Is there an R function  or workaround to do this?
> >>>>
> >>>>
> >>>> Ken
> >>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com> <mailto:kmnanus at gmail.com <mailto:kmnanus at gmail.com>>
> >>>> 914-450-0816 <tel:914-450-0816> (tel)
> >>>> 347-730-4813 <tel:347-730-4813> (fax)
> >>>>
> >>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>> --
> >>> Herv? Pag?s
> >>>
> >>> Program in Computational Biology
> >>> Division of Public Health Sciences
> >>> Fred Hutchinson Cancer Research Center
> >>> 1100 Fairview Ave. N, M1-B514
> >>> P.O. Box 19024
> >>> Seattle, WA 98109-1024
> >>>
> >>> E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org> <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>
> >>> Phone:  (206) 667-5791 <tel:%28206%29%20667-5791>
> >>> Fax:    (206) 667-1319 <tel:%28206%29%20667-1319>
> >>
> >
> > --
> > Herv? Pag?s
> >
> > Program in Computational Biology
> > Division of Public Health Sciences
> > Fred Hutchinson Cancer Research Center
> > 1100 Fairview Ave. N, M1-B514
> > P.O. Box 19024
> > Seattle, WA 98109-1024
> >
> > E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
> > Phone:  (206) 667-5791 <tel:%28206%29%20667-5791>
> > Fax:    (206) 667-1319 <tel:%28206%29%20667-1319>
> 


From kmnanus at gmail.com  Fri Mar  4 22:13:54 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 4 Mar 2016 16:13:54 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
Message-ID: <54C7022A-E128-4695-84BA-7714926D0553@gmail.com>

Here?s where I?m stumped - 

when I call mutate(test, place = substr(test$subject, 1,3)) to create a place variable, I get this, with place as a character variable. 

 subject  group   wk1   wk2   wk3   wk4 place
   (fctr) (fctr) (int) (int) (int) (int) (chr)
1 001-002   boys     2     3     4     5   001
2 002-003   boys     7     6     5     4   002
3 003-004   boys     9     4     6     1   003
4 004-005  girls     5     7     8     9   004
5 005-006  girls     2     6     3     8   005
6 006-007  girls     1     4     7     4   006

When I call test$place <- factor(test$place), I receive the msg  - "Error in `$<-.data.frame`(`*tmp*`, "place", value = integer(0)) : 
  replacement has 0 rows, data has 6.

If I call mutate this way - mutate(test, place = factor(substr(test$subject,1,3))), I get the same output as above but when I call class(test$place), I get NULL and the variable disappears.

I can?t figure out why.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 4, 2016, at 3:46 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I much prefer the factor function over the as.factor function for converting character to factor, since you can set the levels in the order you want them to be. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 4, 2016 10:07:27 AM PST, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> As everyone has been telling you, as.factor().
> If you like the mutate approach, you can call as.factor(test$subject)
> to convert it.
> 
> Here's a one-liner with reproducible data.
> 
> 
> testdata <- structure(list(subject = structure(1:6, .Label = c("001-002",
> "002-003", "003-004", "004-005", "005-006", "006-007"), class = "factor"),
>     group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), .Label = c("boys",
>     "girls"), class = "factor"), wk1 = c(2L, 7L, 9L, 5L, 2L,
>     1L), wk2 = c(3L, 6L, 4L, 7L, 6L, 4L), wk3 = c(4L, 5L, 6L,
>     8L, 3L, 7L), wk4 = c(5L, 4L, 1L, 9L, 8L, 4L)), .Names = c("subject",
> "group", "wk1", "wk2", "wk3", "wk4"), class = "data.frame", row.names = c(NA,
> -6L))
> 
> testdata$subject <- as.factor(substring(as.character(testdata$subject), 1, 3))
> 
> 
> testdata
>   subject group wk1 wk2 wk3 wk4
> 1     001  boys   2   3   4   5
> 2     002  boys   7   6   5   4
> 3     003  boys   9   4   6   1
> 4     004 girls   5   7   8   9
> 5     005 girls   2   6   3   8
> 6     006 girls   1   4   7   4
>  str(testdata)
> 'data.frame': 6 obs. of  6 variables:
>  $ subject: Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>  $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>  $ wk1    : int  2 7 9 5 2 1
>  $ wk2    : int  3 6 4 7 6 4
>  $ wk3    : int  4 5 6 8 3 7
>  $ wk4    : int  5 4 1 9 8 4
> 
> Sarah
> 
> On Fri, Mar 4, 2016 at 1:00 PM, KMNanus <kmnanus at gmail.com> wrote:
> 
>  Here?s the dataset
> I?m working with, called test -
> 
>  subject group wk1 wk2 wk3 wk4 place
>  001-002 boys 2 3 4 5
>  002-003 boys 7 6 5 4
>  003-004 boys 9 4 6 1
>  004-005 girls 5 7 8 9
>  005-006 girls 2 6 3 8
>  006-007 girls 1 4 7 4
> 
> 
>  if I call mutate(test, place = substr(subject,1,3), ?001 is the first observation in the place column
> 
>  But it?s a character and ?subject? is a factor.  I need place to be a factor, too, but I need the observations to be ONLY the first three numbers of ?subject.?
> 
>  Does that make my request more understandable?
> 
> 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal,
> self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sat Mar  5 03:21:06 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 4 Mar 2016 21:21:06 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
Message-ID: <BD1539AE-8417-4117-8C5B-ABA3BEF6A76D@utoronto.ca>

LOL you still need to assign it though:


test <- mutate(test, place = factor(substr(test$subject,1,3)))

str(test)
'data.frame':	6 obs. of  7 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4
 $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6


Without assigning the result, the output only gets printed to console. Remember that R is a functional language - a properly written R functio does not change anything, it only returns its result.

:-)


On Mar 4, 2016, at 4:13 PM, KMNanus <kmnanus at gmail.com> wrote:

> If I call mutate this way - mutate(test, place = factor(substr(test$subject,1,3))), I get the same output as above but when I call class(test$place), I get NULL and the variable disappears.


From boris.steipe at utoronto.ca  Sat Mar  5 04:45:56 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 4 Mar 2016 22:45:56 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <4AD5F395-FC7F-4BC2-BD34-461741C268F4@gmail.com>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
	<BD1539AE-8417-4117-8C5B-ABA3BEF6A76D@utoronto.ca>
	<4AD5F395-FC7F-4BC2-BD34-461741C268F4@gmail.com>
Message-ID: <DDBE3209-B4B6-4BBE-AE9E-BC13275F335E@utoronto.ca>

You mean this?
  test$place <- factor(test$place)

You can create a new column in a data frame by assigning something to it. E.g. 
   test$pollywog <- 1:6
... creates that column in "test".

But factor(test$place) was empty, because no such column previously existed, like:
R > factor(test$barbapapa)
factor(0)
Levels: 

So the right hand side has 0 rows, but the left hand side needs six. Of course you could create your column directly:

R > str(test)
'data.frame':	6 obs. of  6 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4
R > test$place <- factor(substr(test$subject,1,3))    # here's were it gets done
R > str(test)
'data.frame':	6 obs. of  7 variables:
 $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
 $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
 $ wk1    : int  2 7 9 5 2 1
 $ wk2    : int  3 6 4 7 6 4
 $ wk3    : int  4 5 6 8 3 7
 $ wk4    : int  5 4 1 9 8 4
 $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6

... it's just that you insisted on mutate().



Cheers,
Boris


On Mar 4, 2016, at 9:31 PM, KMNanus <kmnanus at gmail.com> wrote:

> Boris - 
> 
> Boy, do I feel dumb - that?s exactly what I wanted.  I?ve tried this every way I can think of without assigning the result to the original name of the data frame.  I was trying to assign the result to a variable (test$place).
> 
> Can u pls explain to me why assigning the result to the new variable was wrong?
> 
> BTW, really appreciate your help.
>  
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> <image001.jpg>
> 
>> On Mar 4, 2016, at 9:21 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> 
>> LOL you still need to assign it though:
>> 
>> 
>> test <- mutate(test, place = factor(substr(test$subject,1,3)))
>> 
>> str(test)
>> 'data.frame':	6 obs. of  7 variables:
>> $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
>> $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>> $ wk1    : int  2 7 9 5 2 1
>> $ wk2    : int  3 6 4 7 6 4
>> $ wk3    : int  4 5 6 8 3 7
>> $ wk4    : int  5 4 1 9 8 4
>> $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>> 
>> 
>> Without assigning the result, the output only gets printed to console. Remember that R is a functional language - a properly written R functio does not change anything, it only returns its result.
>> 
>> :-)
>> 
>> 
>> On Mar 4, 2016, at 4:13 PM, KMNanus <kmnanus at gmail.com> wrote:
>> 
>>> If I call mutate this way - mutate(test, place = factor(substr(test$subject,1,3))), I get the same output as above but when I call class(test$place), I get NULL and the variable disappears.
>> 
> 


From istazahn at gmail.com  Sat Mar  5 05:11:45 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 4 Mar 2016 23:11:45 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <DDBE3209-B4B6-4BBE-AE9E-BC13275F335E@utoronto.ca>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
	<BD1539AE-8417-4117-8C5B-ABA3BEF6A76D@utoronto.ca>
	<4AD5F395-FC7F-4BC2-BD34-461741C268F4@gmail.com>
	<DDBE3209-B4B6-4BBE-AE9E-BC13275F335E@utoronto.ca>
Message-ID: <CA+vqiLEu8J6QjGcgNes9nA-+4-59a8Z69VKH-3TCXPGA45diQQ@mail.gmail.com>

I guess this thread has gone on long enough, but I haven't seen anyone
yet suggest what to me seems like the obvious thing if you want to do
this with mutate, namely

testdata <- mutate(testdata, place = as.factor(substr(subject, 1, 3)))

Best,
Ista

On Fri, Mar 4, 2016 at 10:45 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> You mean this?
>   test$place <- factor(test$place)
>
> You can create a new column in a data frame by assigning something to it. E.g.
>    test$pollywog <- 1:6
> ... creates that column in "test".
>
> But factor(test$place) was empty, because no such column previously existed, like:
> R > factor(test$barbapapa)
> factor(0)
> Levels:
>
> So the right hand side has 0 rows, but the left hand side needs six. Of course you could create your column directly:
>
> R > str(test)
> 'data.frame':   6 obs. of  6 variables:
>  $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
>  $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>  $ wk1    : int  2 7 9 5 2 1
>  $ wk2    : int  3 6 4 7 6 4
>  $ wk3    : int  4 5 6 8 3 7
>  $ wk4    : int  5 4 1 9 8 4
> R > test$place <- factor(substr(test$subject,1,3))    # here's were it gets done
> R > str(test)
> 'data.frame':   6 obs. of  7 variables:
>  $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
>  $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>  $ wk1    : int  2 7 9 5 2 1
>  $ wk2    : int  3 6 4 7 6 4
>  $ wk3    : int  4 5 6 8 3 7
>  $ wk4    : int  5 4 1 9 8 4
>  $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>
> ... it's just that you insisted on mutate().
>
>
>
> Cheers,
> Boris
>
>
> On Mar 4, 2016, at 9:31 PM, KMNanus <kmnanus at gmail.com> wrote:
>
>> Boris -
>>
>> Boy, do I feel dumb - that?s exactly what I wanted.  I?ve tried this every way I can think of without assigning the result to the original name of the data frame.  I was trying to assign the result to a variable (test$place).
>>
>> Can u pls explain to me why assigning the result to the new variable was wrong?
>>
>> BTW, really appreciate your help.
>>
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>>
>> <image001.jpg>
>>
>>> On Mar 4, 2016, at 9:21 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>
>>> LOL you still need to assign it though:
>>>
>>>
>>> test <- mutate(test, place = factor(substr(test$subject,1,3)))
>>>
>>> str(test)
>>> 'data.frame':        6 obs. of  7 variables:
>>> $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
>>> $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
>>> $ wk1    : int  2 7 9 5 2 1
>>> $ wk2    : int  3 6 4 7 6 4
>>> $ wk3    : int  4 5 6 8 3 7
>>> $ wk4    : int  5 4 1 9 8 4
>>> $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
>>>
>>>
>>> Without assigning the result, the output only gets printed to console. Remember that R is a functional language - a properly written R functio does not change anything, it only returns its result.
>>>
>>> :-)
>>>
>>>
>>> On Mar 4, 2016, at 4:13 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>
>>>> If I call mutate this way - mutate(test, place = factor(substr(test$subject,1,3))), I get the same output as above but when I call class(test$place), I get NULL and the variable disappears.
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmnanus at gmail.com  Sat Mar  5 03:31:32 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 4 Mar 2016 21:31:32 -0500
Subject: [R] Extracting part of a factor
In-Reply-To: <BD1539AE-8417-4117-8C5B-ABA3BEF6A76D@utoronto.ca>
References: <91FC2EC8-5547-4035-B969-C9B046CA9A3B@gmail.com>
	<56D8B22C.5020707@fredhutch.org>
	<B9120912-5A9C-4E91-8CAD-B5A245EA3ED2@gmail.com>
	<56D8E5F7.3040404@fredhutch.org>
	<7590C5F9-222D-4692-9AED-6013A6BB3324@gmail.com>
	<CAM_vjuky3oVnUj8G8e+J5BYADTykg=Adv1udKn11+91gGpb+9g@mail.gmail.com>
	<CCE903F7-9C8C-49BE-9F7F-5601064F5111@gmail.com>
	<CAM_vjum2ZEUVhOzj65=9gm1=gtOmPGVgfNTSf+k3Cr82YqaimA@mail.gmail.com>
	<E767DC32-9C24-442E-AF1F-7CF9718D5B6E@dcn.davis.ca.us>
	<54C7022A-E128-4695-84BA-7714926D0553@gmail.com>
	<BD1539AE-8417-4117-8C5B-ABA3BEF6A76D@utoronto.ca>
Message-ID: <4AD5F395-FC7F-4BC2-BD34-461741C268F4@gmail.com>

Boris - 

Boy, do I feel dumb - that?s exactly what I wanted.  I?ve tried this every way I can think of without assigning the result to the original name of the data frame.  I was trying to assign the result to a variable (test$place).

Can u pls explain to me why assigning the result to the new variable was wrong?

BTW, really appreciate your help.
 
Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 4, 2016, at 9:21 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> LOL you still need to assign it though:
> 
> 
> test <- mutate(test, place = factor(substr(test$subject,1,3)))
> 
> str(test)
> 'data.frame':	6 obs. of  7 variables:
> $ subject: Factor w/ 6 levels "001-002","002-003",..: 1 2 3 4 5 6
> $ group  : Factor w/ 2 levels "boys","girls": 1 1 1 2 2 2
> $ wk1    : int  2 7 9 5 2 1
> $ wk2    : int  3 6 4 7 6 4
> $ wk3    : int  4 5 6 8 3 7
> $ wk4    : int  5 4 1 9 8 4
> $ place  : Factor w/ 6 levels "001","002","003",..: 1 2 3 4 5 6
> 
> 
> Without assigning the result, the output only gets printed to console. Remember that R is a functional language - a properly written R functio does not change anything, it only returns its result.
> 
> :-)
> 
> 
> On Mar 4, 2016, at 4:13 PM, KMNanus <kmnanus at gmail.com> wrote:
> 
>> If I call mutate this way - mutate(test, place = factor(substr(test$subject,1,3))), I get the same output as above but when I call class(test$place), I get NULL and the variable disappears.
> 


From drjimlemon at gmail.com  Sat Mar  5 10:38:46 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 5 Mar 2016 20:38:46 +1100
Subject: [R] package FD
In-Reply-To: <CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
	<CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>
	<CAG0T74qM12ZTS99zRqDDd8fjKEr2U4+ZgBsMHHvYcqs-0Ab=SA@mail.gmail.com>
	<CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
Message-ID: <CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>

Hi Fabio,
What has probably happened is that ft$trait3 looks like numbers but
when it was read in at least one value could not be read as a number.
The default behavior in R is to transform the variable into a factor:

testcase<-read.table(text="1 2 3 4
 1 2 3 4
 1 2 B 4")
> testcase
 V1 V2 V3 V4
1  1  2  3  4
2  1  2  3  4
3  1  2  B  4
> sapply(testcase,class)
      V1        V2        V3        V4
"integer" "integer"  "factor" "integer"

So testcase$V3 was read in as a factor. There are a couple of things
you can do. First, try to convert the factor to numeric and live with
the NA values that will be generated:

as.numeric(as.character(testcase$V3))
[1]  3  3 NA
Warning message:
NAs introduced by coercion

If the number of non0numeric values in the original data is small and
you can find them:

testcase$V3[3]<-3
as.numeric(as.character(testcase$V3))
[1] 3 3 3

correct the original data and read it in again. I don't really know
enough to answer your second question.

JIm


On Sat, Mar 5, 2016 at 2:58 AM, Fabio Monteiro
<fabio.monteiro1992 at gmail.com> wrote:
> I still have another question. apart from that one
>
> in the dbFD function in FD package there is one option which is if FRic
> should be standardized or not. What does that mean? Why should our shouldn't
> I have the FRic Standardized?
>
> Thank you Jim
>
> 2016-03-04 14:52 GMT+00:00 Fabio Monteiro <fabio.monteiro1992 at gmail.com>:
>>
>> class(ft$trait3)
>> [1] "factor
>>
>>
>> Yes is a factor. And now?
>>
>> Thank you
>>
>> Kind Regards
>> F?bio
>>
>> 2016-03-04 7:15 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>>>
>>> Hi Fabio,
>>> You should write:
>>>
>>> class(...)
>>>
>>> where ... is the same as what you would type to have the variable
>>> displayed on the console. Looking at your earlier message, it might
>>> be:
>>>
>>> x$trait3
>>>
>>> so try:
>>>
>>> class(x$trait3)
>>>
>>> Jim
>>>
>>>
>>> On Fri, Mar 4, 2016 at 11:30 AM, Fabio Monteiro
>>> <fabio.monteiro1992 at gmail.com> wrote:
>>> > i just called trait3 to my variable.
>>> >
>>> > Is this what i'm suppose to wright? class(trait3), or class
>>> > (my_trait3_variable?
>>> >
>>> > both give error
>>> >
>>> > 2016-03-03 23:42 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>>> >>
>>> >> Hi Fabio,
>>> >> It is possible that your remaining "numeric" variable is a factor.
>>> >> What
>>> >> does:
>>> >>
>>> >> class(my_numeric_variable)
>>> >>
>>> >> say? (where you substitute the name of your "numeric" variable)
>>> >>
>>> >> Jim
>>> >>
>>> >>
>>> >> On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
>>> >> <fabio.monteiro1992 at gmail.com> wrote:
>>> >> > Hello, my name is F?bio and I'm a Marine Ecology student in
>>> >> > Portugal.
>>> >> >
>>> >> > I'm currently using the FD package for my work and yesterday one
>>> >> > message
>>> >> > appeared that I wasn't expecting and I really need your help to try
>>> >> > to
>>> >> > figure out what's happening.
>>> >> > I'm using the dbFD function and the following message appeared:
>>> >> >
>>> >> > FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic
>>> >> > was
>>> >> >  measured as the number of unique trait combinations, NOT as the
>>> >> > convex
>>> >> > hull volume.
>>> >> > FDiv: Cannot be computed when only categorical and/or ordinal
>>> >> > trait(s)
>>> >> > present in 'x'.
>>> >> >
>>> >> > My data:
>>> >> > x is a matrix with species vs functional traits
>>> >> > a is a matrix with species vs sampling (in abundances)
>>> >> >
>>> >> > Previously I used the dbFD function and was working just fine.
>>> >> > Yesterday
>>> >> > I
>>> >> > removed 2 traits and this message appeared.
>>> >> >
>>> >> > My traits now are 3 categorical traits and 1 numeric. The 2 trais
>>> >> > that I
>>> >> > removed were numeric traits as well. I really need to remove those
>>> >> > trait,
>>> >> > but I still need the FDiv to be calculated. Can you explain to me
>>> >> > why is
>>> >> > this error occurring? I need to know how the dbFD is measuring the
>>> >> > indexes
>>> >> > so I can understanding the error and if I can or can't continue to
>>> >> > use
>>> >> > this
>>> >> > package (if it applies or not to my goals)
>>> >> >
>>> >> > Kind regards
>>> >> >
>>> >> > F?bio Monteiro
>>> >> >
>>> >> >         [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> >> > http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>
>>
>


From efresbr at hotmail.com  Sat Mar  5 16:31:01 2016
From: efresbr at hotmail.com (Efres B)
Date: Sat, 5 Mar 2016 16:31:01 +0100
Subject: [R] Post: R-help : help with loops
Message-ID: <DUB404-EAS314661A729759D2855A34E2B8BF0@phx.gbl>

Hello.

 

Im trying to post the following message in R-Help. 

 

I think I must send it via email to do so, so here it is:

 

Hello, 
I need help with some code. 
Basically, I have experiments results which I need to process. 

I have 2 dataframes with 3 columns 
Df1 <- data.frame (Date, Cellline, Data) 
Df2 <- data.frame (Date, Cellline, Control) 

I want for the entire column Df1-Data to be subtracted by the corresponding
Df2-Controls which Columns Date and Cellline coincide through some type of
loop. 
So the structure is: 

Df1$Data <- Df1$Data - Df2$Control [when (Df1$Celline == Df2$Celline &
Df1$Date == Df2$Date]) 

Each Control has several dozen Data values which are linked through Data and
Celline. Of course, the data.frames are of different dimensions. 

I've tried several approaches and failed miserably. 
Any suggestions? 

Thank you in advance for any.

 

Thanks.

 


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Mar  5 18:07:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 05 Mar 2016 09:07:58 -0800
Subject: [R] Post: R-help : help with loops
In-Reply-To: <DUB404-EAS314661A729759D2855A34E2B8BF0@phx.gbl>
References: <DUB404-EAS314661A729759D2855A34E2B8BF0@phx.gbl>
Message-ID: <6007BA0F-65B3-46A4-9372-189FB6239084@dcn.davis.ca.us>

You made it. Next time set your email program to send plain text instead of HTML format to avoid us receiving a corrupted version of what you sent. (This is a plain text mailing list. )

You don't need looping, you need ?merge and ?ifelse.

Df1 <- merge( Df1, Df2, all.x = TRUE, by = c ( "Date", "Cellline" ) )
# should now have a Control column in Df1 that is NA where there was no match
Df1$NewData  <- ifelse( is.na( Df1$Control ), Df1$Data, Df1$Data - Df1$Control )

-- 
Sent from my phone. Please excuse my brevity.

On March 5, 2016 7:31:01 AM PST, Efres B <efresbr at hotmail.com> wrote:
>Hello.
>
> 
>
>Im trying to post the following message in R-Help. 
>
> 
>
>I think I must send it via email to do so, so here it is:
>
> 
>
>Hello, 
>I need help with some code. 
>Basically, I have experiments results which I need to process. 
>
>I have 2 dataframes with 3 columns 
>Df1 <- data.frame (Date, Cellline, Data) 
>Df2 <- data.frame (Date, Cellline, Control) 
>
>I want for the entire column Df1-Data to be subtracted by the
>corresponding
>Df2-Controls which Columns Date and Cellline coincide through some type
>of
>loop. 
>So the structure is: 
>
>Df1$Data <- Df1$Data - Df2$Control [when (Df1$Celline == Df2$Celline &
>Df1$Date == Df2$Date]) 
>
>Each Control has several dozen Data values which are linked through
>Data and
>Celline. Of course, the data.frames are of different dimensions. 
>
>I've tried several approaches and failed miserably. 
>Any suggestions? 
>
>Thank you in advance for any.
>
> 
>
>Thanks.
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Sat Mar  5 20:32:23 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sat, 5 Mar 2016 20:32:23 +0100
Subject: [R] trying to reach R-help
Message-ID: <CAHby=D39dzeKNdVcr9iEnXBkhV14W7LX5rZWqOq=_i+rKaMgcA@mail.gmail.com>

Hello, I'm rather desperate so please excuse me if I'm using wrong emails.
I'm sad that the forum at nabble is not functinal as before. I'm by no way
want to critique something. I just don't understand in which way is mailing
better than forum.

I'm subscriber to R-help, but it seems that I'm unabble to reach R-help. I
have sent some emails to r-help at r-project.org, but I get no response. My
new posts aren't listed at http://r.789695.n4.nabble.com/R-help-f789696.html
anymore either.

Can you please tell me if I do something wrong or how should I reach R-help?
Will my post be listed at nabble if reach R-help correctly?

Thank you very much for answer.

	[[alternative HTML version deleted]]


From lauritorgerson at gmail.com  Sat Mar  5 17:58:31 2016
From: lauritorgerson at gmail.com (Lauri Torgerson)
Date: Sat, 5 Mar 2016 11:58:31 -0500
Subject: [R] Wooden Christmas Tree freezing when reading in files in El
	Capitan OS X
In-Reply-To: <CAO9PUv__Na7Xpdvi8gseZXgfz_JMH7Vvit6xJvHHQPe5S9SQPA@mail.gmail.com>
References: <CAO9PUv__Na7Xpdvi8gseZXgfz_JMH7Vvit6xJvHHQPe5S9SQPA@mail.gmail.com>
Message-ID: <CAO9PUv9oA-H5atP2tBcnJgM1bZvkpOzPOMZ7an9jdRC6L-7qKQ@mail.gmail.com>

Hello everyone. Thanks in advance for your patience with my question. I
recently upgraded my operating system to El Capitan and then upgraded R to
3.2.3 (Wooden Christmas Tree). I also installed XQuartz. My problem is that
when I try to read in files using read.csv, R freezes. I have to force quit
every time. I've tried to uninstall/reinstall. I've tried older versions of
R. I've tried working in the R.app and typing directly into the R console.
I've tried clearing the work history, resetting the working directory, and
reading in the file different ways. Has anyone dealt with this and found a
solution? Thanks!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar  5 21:42:52 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Mar 2016 12:42:52 -0800
Subject: [R] trying to reach R-help
In-Reply-To: <CAHby=D39dzeKNdVcr9iEnXBkhV14W7LX5rZWqOq=_i+rKaMgcA@mail.gmail.com>
References: <CAHby=D39dzeKNdVcr9iEnXBkhV14W7LX5rZWqOq=_i+rKaMgcA@mail.gmail.com>
Message-ID: <98A6026E-2C71-429C-9D2A-ADB0B7CFB478@comcast.net>


> On Mar 5, 2016, at 11:32 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> 
> Hello, I'm rather desperate so please excuse me if I'm using wrong emails.
> I'm sad that the forum at nabble is not functinal as before. I'm by no way
> want to critique something. I just don't understand in which way is mailing
> better than forum.

The Nabble "mirror"/"gateway" was a source of spam to the list, so acceptance from postings to its pages was initially severely restricted a year or two ago and then later shut off entirely. Its users seemed to lack an understanding of the need to post in plain text and its interface appeared to be an ongoing source of confusion. This has been explained multiple times on the list.


> I'm subscriber to R-help, but it seems that I'm unabble to reach R-help. I
> have sent some emails to r-help at r-project.org, but I get no response. My
> new posts aren't listed at http://r.789695.n4.nabble.com/R-help-f789696.html
> anymore either.

Although Nabble claimed to be the Rhelp archive, that claim was bogus. The real Archive is at https://stat.ethz.ch/pipermail/r-help/. This ia all described at https://stat.ethz.ch/mailman/listinfo/r-help
> 
> Can you please tell me if I do something wrong or how should I reach R-help?
> Will my post be listed at nabble if reach R-help correctly?
> 
> Thank you very much for answer.
> 
> 	[[alternative HTML version deleted]]

You were able to reach Rhelp with this email. You are subscribed as receiving emails in digest form. One of the sources of confusion for Nabble users was the need to post in plain text.  It's your responsibility to read the Posting Guide and configure your chosen email client properly.


-- 

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sat Mar  5 22:29:23 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 5 Mar 2016 22:29:23 +0100
Subject: [R] Wooden Christmas Tree freezing when reading in files in El
	Capitan OS X
In-Reply-To: <CAO9PUv9oA-H5atP2tBcnJgM1bZvkpOzPOMZ7an9jdRC6L-7qKQ@mail.gmail.com>
References: <CAO9PUv__Na7Xpdvi8gseZXgfz_JMH7Vvit6xJvHHQPe5S9SQPA@mail.gmail.com>
	<CAO9PUv9oA-H5atP2tBcnJgM1bZvkpOzPOMZ7an9jdRC6L-7qKQ@mail.gmail.com>
Message-ID: <99BB1813-DFE0-443D-ABB5-8AB3F1201545@gmail.com>

Explain _exactly_ what you mean by "try to read in files using read.csv" and "reading in the file different ways". Which commands? Is the GUI involved? Otherwise we cannot help.



> On 05 Mar 2016, at 17:58 , Lauri Torgerson <lauritorgerson at gmail.com> wrote:
> 
> Hello everyone. Thanks in advance for your patience with my question. I
> recently upgraded my operating system to El Capitan and then upgraded R to
> 3.2.3 (Wooden Christmas Tree). I also installed XQuartz. My problem is that
> when I try to read in files using read.csv, R freezes. I have to force quit
> every time. I've tried to uninstall/reinstall. I've tried older versions of
> R. I've tried working in the R.app and typing directly into the R console.
> I've tried clearing the work history, resetting the working directory, and
> reading in the file different ways. Has anyone dealt with this and found a
> solution? Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Sat Mar  5 23:21:44 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 6 Mar 2016 09:21:44 +1100
Subject: [R] difference between successive values
In-Reply-To: <CAEW+BD+jiNx2SU2JzSiPdQyQscxCovj4kJ0vrrW78Uq_xOPAFA@mail.gmail.com>
References: <CAEW+BD+5j-QrYJE_A5V5418y7srnzefM9+JQai-K9a_XY5FCwA@mail.gmail.com>
	<20160304122808.7063b1afa41cd3e71a891609@univ-nantes.fr>
	<CA9C1FAD-8FE0-4D23-9E3A-DA88C64A82C0@dcn.davis.ca.us>
	<CAEW+BD+jiNx2SU2JzSiPdQyQscxCovj4kJ0vrrW78Uq_xOPAFA@mail.gmail.com>
Message-ID: <CA+8X3fU3160K5M0Je3h2EFzDcig=DBWdoubN5QA5C19y1BqkWg@mail.gmail.com>

Hi catalin,
I think what you are trying to do is to retrieve the original
observations from the cumulated values. In that case Olivier's
suggestion will do what you want:

c(x[1],diff(x))

Jim


On Sat, Mar 5, 2016 at 1:59 AM, catalin roibu <catalinroibu at gmail.com> wrote:
> I mean the first row value
>
> ?n Vin, 4 mar. 2016, 16:15 Jeff Newmiller, <jdnewmil at dcn.davis.ca.us> a
> scris:
>
>> "Keep the first values" is imprecise, but mixing an absolute value with a
>> bunch of differences doesn't usually work out well.  I frequently choose
>> among
>>
>> x <- sample( 10 )
>> dxright <- c( 0, diff(x) )
>> dxleft <- c( diff(x), 0 )
>>
>> for calculation purposes depending on my needs.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 4, 2016 3:28:08 AM PST, Olivier Crouzet <
>> olivier.crouzet at univ-nantes.fr> wrote:
>> >Hi,
>> >
>> >(1) You should provide a minimal working example;
>> >
>> >(2) But anyway, does...
>> >
>> >x = sample(10)
>> >c(x[1],diff(x))
>> >
>> >... do what you want?
>> >
>> >Olivier.
>> >
>> >
>> >On Fri, 4 Mar 2016
>> >13:22:07 +0200 catalin roibu <catalinroibu at gmail.com> wrote:
>> >
>> >> Dear all!
>> >>
>> >> I want to calculate difference between successive values (cumulative
>> >> values) with R. I used diff function, but I want to keep the first
>> >> values.
>> >>
>> >> Please help me to solve this problem!
>> >>
>> >> Thank you!
>> >>
>> >> Best regards!
>> >>
>> >> CR
>> >>
>> >> --
>> >>
>> >> -
>> >> -
>> >> Catalin-Constantin ROIBU
>> >>
>> >> Lecturer PhD, Forestry engineer
>> >> Forestry Faculty of Suceava
>> >> Str. Universitatii no. 13, Suceava, 720229, Romania
>> >> office phone      +4 0230 52 29 78, ext. 531
>> >> mobile phone    +4 0745 53 18 01
>> >> FAX:                +4 0230 52 16 64
>> >> silvic.usv.ro <http://www.usv.ro/>
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html and provide commented,
>> >> minimal, self-contained, reproducible code.
>> >
>> >--
>> >  Olivier Crouzet, PhD
>> >  Laboratoire de Linguistique de Nantes -- UMR6310
>> >  CNRS / Universit? de Nantes
>> >  Chemin de la Censive du Tertre -- BP 81227
>> >  44312 Nantes cedex 3
>> >  France
>> >
>> >  http://www.lling.univ-nantes.fr/
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
>
> Lecturer PhD, Forestry engineer
>
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229,
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                        +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lordpreetam at gmail.com  Sun Mar  6 08:40:34 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sun, 6 Mar 2016 13:10:34 +0530
Subject: [R] ACF values with confidence limits + Plot Extaction
Message-ID: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>

Hi R-users,

I have a time series of residuals and I want to get the ACF
(autocorrelation) values till lag = 12, along with the 12 upper/lower
confidence limits. I understand that acf(residual) would give me the plot,
but I will also need the actual values as an array etc. Plus, I'll have to
extract the plot from R as well. Is there a way to achieve these two?

Appreciate your help.

Regards,
Preetam

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Mar  6 11:09:21 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 6 Mar 2016 10:09:21 +0000
Subject: [R] ACF values with confidence limits + Plot Extaction
In-Reply-To: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
References: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
Message-ID: <56DC01D1.2010507@dewey.myzen.co.uk>

According to the documentation acf returns what you want. It also says 
that it returns it invisibly if plot = TRUE which I imagine is what you 
are doing.

So try

res <- acf(insert_parameters_here, plot = FALSE)

and then look at res


On 06/03/2016 07:40, Preetam Pal wrote:
> Hi R-users,
>
> I have a time series of residuals and I want to get the ACF
> (autocorrelation) values till lag = 12, along with the 12 upper/lower
> confidence limits. I understand that acf(residual) would give me the plot,
> but I will also need the actual values as an array etc. Plus, I'll have to
> extract the plot from R as well. Is there a way to achieve these two?
>
> Appreciate your help.
>
> Regards,
> Preetam
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From fabio.monteiro1992 at gmail.com  Sun Mar  6 12:57:04 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Sun, 6 Mar 2016 11:57:04 +0000
Subject: [R] package FD
In-Reply-To: <CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
	<CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>
	<CAG0T74qM12ZTS99zRqDDd8fjKEr2U4+ZgBsMHHvYcqs-0Ab=SA@mail.gmail.com>
	<CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
	<CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>
Message-ID: <CAG0T74qy9gddUVQgwJ5eY+AZa=qgWrznfBJdWLstvo8TnkmwkA@mail.gmail.com>

Hey Jim

they are all numeric as you can see

as.numeric(as.character(a$x))
 [1]  20.0  50.0   7.9  25.0  20.0  20.0  15.0  30.0  48.0  75.0  75.0
 25.0 300.0
[14] 103.0  20.0  45.0  15.0  20.0  50.0   6.0  18.0  59.0  70.0  80.0
100.0  40.0
[27]  15.0  30.0  40.0  60.0   9.0  11.0  27.5  75.0  60.0  70.0  70.0
 60.0  20.0
[40]  21.0  50.0  35.0  46.0

F?bio

2016-03-05 9:38 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Fabio,
> What has probably happened is that ft$trait3 looks like numbers but
> when it was read in at least one value could not be read as a number.
> The default behavior in R is to transform the variable into a factor:
>
> testcase<-read.table(text="1 2 3 4
>  1 2 3 4
>  1 2 B 4")
> > testcase
>  V1 V2 V3 V4
> 1  1  2  3  4
> 2  1  2  3  4
> 3  1  2  B  4
> > sapply(testcase,class)
>       V1        V2        V3        V4
> "integer" "integer"  "factor" "integer"
>
> So testcase$V3 was read in as a factor. There are a couple of things
> you can do. First, try to convert the factor to numeric and live with
> the NA values that will be generated:
>
> as.numeric(as.character(testcase$V3))
> [1]  3  3 NA
> Warning message:
> NAs introduced by coercion
>
> If the number of non0numeric values in the original data is small and
> you can find them:
>
> testcase$V3[3]<-3
> as.numeric(as.character(testcase$V3))
> [1] 3 3 3
>
> correct the original data and read it in again. I don't really know
> enough to answer your second question.
>
> JIm
>
>
> On Sat, Mar 5, 2016 at 2:58 AM, Fabio Monteiro
> <fabio.monteiro1992 at gmail.com> wrote:
> > I still have another question. apart from that one
> >
> > in the dbFD function in FD package there is one option which is if FRic
> > should be standardized or not. What does that mean? Why should our
> shouldn't
> > I have the FRic Standardized?
> >
> > Thank you Jim
> >
> > 2016-03-04 14:52 GMT+00:00 Fabio Monteiro <fabio.monteiro1992 at gmail.com
> >:
> >>
> >> class(ft$trait3)
> >> [1] "factor
> >>
> >>
> >> Yes is a factor. And now?
> >>
> >> Thank you
> >>
> >> Kind Regards
> >> F?bio
> >>
> >> 2016-03-04 7:15 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
> >>>
> >>> Hi Fabio,
> >>> You should write:
> >>>
> >>> class(...)
> >>>
> >>> where ... is the same as what you would type to have the variable
> >>> displayed on the console. Looking at your earlier message, it might
> >>> be:
> >>>
> >>> x$trait3
> >>>
> >>> so try:
> >>>
> >>> class(x$trait3)
> >>>
> >>> Jim
> >>>
> >>>
> >>> On Fri, Mar 4, 2016 at 11:30 AM, Fabio Monteiro
> >>> <fabio.monteiro1992 at gmail.com> wrote:
> >>> > i just called trait3 to my variable.
> >>> >
> >>> > Is this what i'm suppose to wright? class(trait3), or class
> >>> > (my_trait3_variable?
> >>> >
> >>> > both give error
> >>> >
> >>> > 2016-03-03 23:42 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
> >>> >>
> >>> >> Hi Fabio,
> >>> >> It is possible that your remaining "numeric" variable is a factor.
> >>> >> What
> >>> >> does:
> >>> >>
> >>> >> class(my_numeric_variable)
> >>> >>
> >>> >> say? (where you substitute the name of your "numeric" variable)
> >>> >>
> >>> >> Jim
> >>> >>
> >>> >>
> >>> >> On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
> >>> >> <fabio.monteiro1992 at gmail.com> wrote:
> >>> >> > Hello, my name is F?bio and I'm a Marine Ecology student in
> >>> >> > Portugal.
> >>> >> >
> >>> >> > I'm currently using the FD package for my work and yesterday one
> >>> >> > message
> >>> >> > appeared that I wasn't expecting and I really need your help to
> try
> >>> >> > to
> >>> >> > figure out what's happening.
> >>> >> > I'm using the dbFD function and the following message appeared:
> >>> >> >
> >>> >> > FRic: Only categorical and/or ordinal trait(s) present in 'x'.
> FRic
> >>> >> > was
> >>> >> >  measured as the number of unique trait combinations, NOT as the
> >>> >> > convex
> >>> >> > hull volume.
> >>> >> > FDiv: Cannot be computed when only categorical and/or ordinal
> >>> >> > trait(s)
> >>> >> > present in 'x'.
> >>> >> >
> >>> >> > My data:
> >>> >> > x is a matrix with species vs functional traits
> >>> >> > a is a matrix with species vs sampling (in abundances)
> >>> >> >
> >>> >> > Previously I used the dbFD function and was working just fine.
> >>> >> > Yesterday
> >>> >> > I
> >>> >> > removed 2 traits and this message appeared.
> >>> >> >
> >>> >> > My traits now are 3 categorical traits and 1 numeric. The 2 trais
> >>> >> > that I
> >>> >> > removed were numeric traits as well. I really need to remove those
> >>> >> > trait,
> >>> >> > but I still need the FDiv to be calculated. Can you explain to me
> >>> >> > why is
> >>> >> > this error occurring? I need to know how the dbFD is measuring the
> >>> >> > indexes
> >>> >> > so I can understanding the error and if I can or can't continue to
> >>> >> > use
> >>> >> > this
> >>> >> > package (if it applies or not to my goals)
> >>> >> >
> >>> >> > Kind regards
> >>> >> >
> >>> >> > F?bio Monteiro
> >>> >> >
> >>> >> >         [[alternative HTML version deleted]]
> >>> >> >
> >>> >> > ______________________________________________
> >>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> > PLEASE do read the posting guide
> >>> >> > http://www.R-project.org/posting-guide.html
> >>> >> > and provide commented, minimal, self-contained, reproducible code.
> >>> >
> >>> >
> >>
> >>
> >
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Mar  6 17:08:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 06 Mar 2016 08:08:12 -0800
Subject: [R] package FD
In-Reply-To: <CAG0T74qy9gddUVQgwJ5eY+AZa=qgWrznfBJdWLstvo8TnkmwkA@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
	<CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>
	<CAG0T74qM12ZTS99zRqDDd8fjKEr2U4+ZgBsMHHvYcqs-0Ab=SA@mail.gmail.com>
	<CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
	<CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>
	<CAG0T74qy9gddUVQgwJ5eY+AZa=qgWrznfBJdWLstvo8TnkmwkA@mail.gmail.com>
Message-ID: <DE25A050-0E7C-4B18-A1D5-8279C1ADBE7E@dcn.davis.ca.us>

That code doesn't show what a$x IS, just what comes out after you force things. The fact that you felt compelled to apply those functions just makes it seem more likely that Jim is onto something. The output of

str( a$x )

would show what kind of data it is, and

dput( a$x )

would let us put the data column into our copy of R and guess about why it might not already be numeric, and

dput( a )

followed by your actual code that uses `a` would give us a possibility to reproduce your actual error.  At this point the cause of the problem seems likely to be in the original input data or the code that you are using to import and manipulate that data, which is where most questions like this seem to end up. 
-- 
Sent from my phone. Please excuse my br
evity.

On March 6, 2016 3:57:04 AM PST, Fabio Monteiro <fabio.monteiro1992 at gmail.com> wrote:
>Hey Jim
>
>they are all numeric as you can see
>
>as.numeric(as.character(a$x))
> [1]  20.0  50.0   7.9  25.0  20.0  20.0  15.0  30.0  48.0  75.0  75.0
> 25.0 300.0
>[14] 103.0  20.0  45.0  15.0  20.0  50.0   6.0  18.0  59.0  70.0  80.0
>100.0  40.0
>[27]  15.0  30.0  40.0  60.0   9.0  11.0  27.5  75.0  60.0  70.0  70.0
> 60.0  20.0
>[40]  21.0  50.0  35.0  46.0
>
>F?bio
>
>2016-03-05 9:38 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>
>> Hi Fabio,
>> What has probably happened is that ft$trait3 looks like numbers but
>> when it was read in at least one value could not be read as a number.
>> The default behavior in R is to transform the variable into a factor:
>>
>> testcase<-read.table(text="1 2 3 4
>>  1 2 3 4
>>  1 2 B 4")
>> > testcase
>>  V1 V2 V3 V4
>> 1  1  2  3  4
>> 2  1  2  3  4
>> 3  1  2  B  4
>> > sapply(testcase,class)
>>       V1        V2        V3        V4
>> "integer" "integer"  "factor" "integer"
>>
>> So testcase$V3 was read in as a factor. There are a couple of things
>> you can do. First, try to convert the factor to numeric and live with
>> the NA values that will be generated:
>>
>> as.numeric(as.character(testcase$V3))
>> [1]  3  3 NA
>> Warning message:
>> NAs introduced by coercion
>>
>> If the number of non0numeric values in the original data is small and
>> you can find them:
>>
>> testcase$V3[3]<-3
>> as.numeric(as.character(testcase$V3))
>> [1] 3 3 3
>>
>> correct the original data and read it in again. I don't really know
>> enough to answer your second question.
>>
>> JIm
>>
>>
>> On Sat, Mar 5, 2016 at 2:58 AM, Fabio Monteiro
>> <fabio.monteiro1992 at gmail.com> wrote:
>> > I still have another question. apart from that one
>> >
>> > in the dbFD function in FD package there is one option which is if
>FRic
>> > should be standardized or not. What does that mean? Why should our
>> shouldn't
>> > I have the FRic Standardized?
>> >
>> > Thank you Jim
>> >
>> > 2016-03-04 14:52 GMT+00:00 Fabio Monteiro
><fabio.monteiro1992 at gmail.com
>> >:
>> >>
>> >> class(ft$trait3)
>> >> [1] "factor
>> >>
>> >>
>> >> Yes is a factor. And now?
>> >>
>> >> Thank you
>> >>
>> >> Kind Regards
>> >> F?bio
>> >>
>> >> 2016-03-04 7:15 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>> >>>
>> >>> Hi Fabio,
>> >>> You should write:
>> >>>
>> >>> class(...)
>> >>>
>> >>> where ... is the same as what you would type to have the variable
>> >>> displayed on the console. Looking at your earlier message, it
>might
>> >>> be:
>> >>>
>> >>> x$trait3
>> >>>
>> >>> so try:
>> >>>
>> >>> class(x$trait3)
>> >>>
>> >>> Jim
>> >>>
>> >>>
>> >>> On Fri, Mar 4, 2016 at 11:30 AM, Fabio Monteiro
>> >>> <fabio.monteiro1992 at gmail.com> wrote:
>> >>> > i just called trait3 to my variable.
>> >>> >
>> >>> > Is this what i'm suppose to wright? class(trait3), or class
>> >>> > (my_trait3_variable?
>> >>> >
>> >>> > both give error
>> >>> >
>> >>> > 2016-03-03 23:42 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:
>> >>> >>
>> >>> >> Hi Fabio,
>> >>> >> It is possible that your remaining "numeric" variable is a
>factor.
>> >>> >> What
>> >>> >> does:
>> >>> >>
>> >>> >> class(my_numeric_variable)
>> >>> >>
>> >>> >> say? (where you substitute the name of your "numeric"
>variable)
>> >>> >>
>> >>> >> Jim
>> >>> >>
>> >>> >>
>> >>> >> On Fri, Mar 4, 2016 at 2:25 AM, Fabio Monteiro
>> >>> >> <fabio.monteiro1992 at gmail.com> wrote:
>> >>> >> > Hello, my name is F?bio and I'm a Marine Ecology student in
>> >>> >> > Portugal.
>> >>> >> >
>> >>> >> > I'm currently using the FD package for my work and yesterday
>one
>> >>> >> > message
>> >>> >> > appeared that I wasn't expecting and I really need your help
>to
>> try
>> >>> >> > to
>> >>> >> > figure out what's happening.
>> >>> >> > I'm using the dbFD function and the following message
>appeared:
>> >>> >> >
>> >>> >> > FRic: Only categorical and/or ordinal trait(s) present in
>'x'.
>> FRic
>> >>> >> > was
>> >>> >> >  measured as the number of unique trait combinations, NOT as
>the
>> >>> >> > convex
>> >>> >> > hull volume.
>> >>> >> > FDiv: Cannot be computed when only categorical and/or
>ordinal
>> >>> >> > trait(s)
>> >>> >> > present in 'x'.
>> >>> >> >
>> >>> >> > My data:
>> >>> >> > x is a matrix with species vs functional traits
>> >>> >> > a is a matrix with species vs sampling (in abundances)
>> >>> >> >
>> >>> >> > Previously I used the dbFD function and was working just
>fine.
>> >>> >> > Yesterday
>> >>> >> > I
>> >>> >> > removed 2 traits and this message appeared.
>> >>> >> >
>> >>> >> > My traits now are 3 categorical traits and 1 numeric. The 2
>trais
>> >>> >> > that I
>> >>> >> > removed were numeric traits as well. I really need to remove
>those
>> >>> >> > trait,
>> >>> >> > but I still need the FDiv to be calculated. Can you explain
>to me
>> >>> >> > why is
>> >>> >> > this error occurring? I need to know how the dbFD is
>measuring the
>> >>> >> > indexes
>> >>> >> > so I can understanding the error and if I can or can't
>continue to
>> >>> >> > use
>> >>> >> > this
>> >>> >> > package (if it applies or not to my goals)
>> >>> >> >
>> >>> >> > Kind regards
>> >>> >> >
>> >>> >> > F?bio Monteiro
>> >>> >> >
>> >>> >> >         [[alternative HTML version deleted]]
>> >>> >> >
>> >>> >> > ______________________________________________
>> >>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>> >>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >> > PLEASE do read the posting guide
>> >>> >> > http://www.R-project.org/posting-guide.html
>> >>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >>> >
>> >>> >
>> >>
>> >>
>> >
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Sun Mar  6 20:06:27 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Mon, 7 Mar 2016 00:36:27 +0530
Subject: [R] ACF values with confidence limits + Plot Extaction
In-Reply-To: <56DC01D1.2010507@dewey.myzen.co.uk>
References: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
	<56DC01D1.2010507@dewey.myzen.co.uk>
Message-ID: <CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>

Thanks, Michael. Appreciate it.
But suppose I go for the plot, how to extract it from R ... say, I want to
save it as a .png file.
Regards,
Preetam

On Sun, Mar 6, 2016 at 3:39 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> According to the documentation acf returns what you want. It also says
> that it returns it invisibly if plot = TRUE which I imagine is what you are
> doing.
>
> So try
>
> res <- acf(insert_parameters_here, plot = FALSE)
>
> and then look at res
>
>
>
> On 06/03/2016 07:40, Preetam Pal wrote:
>
>> Hi R-users,
>>
>> I have a time series of residuals and I want to get the ACF
>> (autocorrelation) values till lag = 12, along with the 12 upper/lower
>> confidence limits. I understand that acf(residual) would give me the plot,
>> but I will also need the actual values as an array etc. Plus, I'll have to
>> extract the plot from R as well. Is there a way to achieve these two?
>>
>> Appreciate your help.
>>
>> Regards,
>> Preetam
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>



-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Sun Mar  6 21:08:32 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Mon, 7 Mar 2016 01:38:32 +0530
Subject: [R] ACF values with confidence limits + Plot Extaction
In-Reply-To: <CANufCk70+7gDsPm1EP9GishBdwLB3bc3ze+=V5T8PH5ScHmMbA@mail.gmail.com>
References: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
	<56DC01D1.2010507@dewey.myzen.co.uk>
	<CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>
	<CANufCk70+7gDsPm1EP9GishBdwLB3bc3ze+=V5T8PH5ScHmMbA@mail.gmail.com>
Message-ID: <CAHVFrXF-YEcRfnY5JJ17Dekxcdqb-tbaoiQy5ppWP6CAxZrGqg@mail.gmail.com>

Thank you very much,Jean-Claude and Michael.

1> @Michael, your suggestion "plot = FALSE" only returns the estimated ACF
values, not the confidence limits at different lags. May be I am missing
something here.Do you know any way around for this?
2>@Jean-Claude, got it, thanks.

Regards,
Preetam

On Mon, Mar 7, 2016 at 1:03 AM, Jean-Claude Arbaut <arbautjc at gmail.com>
wrote:

> a <- as.ts(rnorm(20))
> png("acf.png")
> a.acf <- acf(a)
> dev.off()
>
> # to see what is available
> names(a.acf)
> unclass(a.acf)
>
>
> 2016-03-06 20:06 GMT+01:00 Preetam Pal <lordpreetam at gmail.com>:
> > Thanks, Michael. Appreciate it.
> > But suppose I go for the plot, how to extract it from R ... say, I want
> to
> > save it as a .png file.
> > Regards,
> > Preetam
> >
> > On Sun, Mar 6, 2016 at 3:39 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> > wrote:
> >
> >> According to the documentation acf returns what you want. It also says
> >> that it returns it invisibly if plot = TRUE which I imagine is what you
> are
> >> doing.
> >>
> >> So try
> >>
> >> res <- acf(insert_parameters_here, plot = FALSE)
> >>
> >> and then look at res
> >>
> >>
> >>
> >> On 06/03/2016 07:40, Preetam Pal wrote:
> >>
> >>> Hi R-users,
> >>>
> >>> I have a time series of residuals and I want to get the ACF
> >>> (autocorrelation) values till lag = 12, along with the 12 upper/lower
> >>> confidence limits. I understand that acf(residual) would give me the
> plot,
> >>> but I will also need the actual values as an array etc. Plus, I'll
> have to
> >>> extract the plot from R as well. Is there a way to achieve these two?
> >>>
> >>> Appreciate your help.
> >>>
> >>> Regards,
> >>> Preetam
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >> Michael
> >> http://www.dewey.myzen.co.uk/home.html
> >>
> >
> >
> >
> > --
> > Preetam Pal
> > (+91)-9432212774
> > M-Stat 2nd Year,                                             Room No.
> N-114
> > Statistics Division,                                           C.V.Raman
> > Hall
> > Indian Statistical Institute,                                 B.H.O.S.
> > Kolkata.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Sun Mar  6 21:34:52 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Sun, 6 Mar 2016 15:34:52 -0500
Subject: [R] stargazer summary statistics by group
Message-ID: <56DC946C.9020608@cognigencorp.com>

Hi,

I saw a post on this topic on stackoverflow a while ago. It does not 
seem to have got any reply... Just trying my luck here.

Is there any way to use stargazer to create a table of descriptive 
statistics by group such as the one below?

Thanks

#-------------|-Stat--|--A--|--B--|--Overall-|
# Variable 1  | Stat1 |     |     |          |
#-------------|-------|-----|-----|----------|
#             | Stat2 |     | |          |
#-------------|-------|-----|-----|----------|
#             | ...   |     |     |          |
#-------------|-------|-----|-----|----------|
# Variable 2  | Stat1 |     |     |          |
#-------------|-------|-----|-----|----------|
#             | Stat2 |     | |          |
#-------------|-------|-----|-----|----------|
#             | ...   |     |     |          |
#-------------|-------|-----|-----|----------|
# Variable ...| Stat1 |     |     |          |
#-------------|-------|-----|-----|----------|
#             | Stat2 |     | |          |
#-------------|-------|-----|-----|----------|
#             | ...   |     |     |          |
#-------------|-------|-----|-----|----------|

stat1 and stat2 could mean, sd, median, etc...


From boris.steipe at utoronto.ca  Sun Mar  6 22:04:15 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 6 Mar 2016 16:04:15 -0500
Subject: [R] stargazer summary statistics by group
In-Reply-To: <56DC946C.9020608@cognigencorp.com>
References: <56DC946C.9020608@cognigencorp.com>
Message-ID: <B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>

Does this entry on the Stargazer Cheatsheet come close enough to what you want?
   http://jakeruss.com/cheatsheets/stargazer.html#the-default-summary-statistics-table

B.

On Mar 6, 2016, at 3:34 PM, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:

> Hi,
> 
> I saw a post on this topic on stackoverflow a while ago. It does not seem to have got any reply... Just trying my luck here.
> 
> Is there any way to use stargazer to create a table of descriptive statistics by group such as the one below?
> 
> Thanks
> 
> #-------------|-Stat--|--A--|--B--|--Overall-|
> # Variable 1  | Stat1 |     |     |          |
> #-------------|-------|-----|-----|----------|
> #             | Stat2 |     | |          |
> #-------------|-------|-----|-----|----------|
> #             | ...   |     |     |          |
> #-------------|-------|-----|-----|----------|
> # Variable 2  | Stat1 |     |     |          |
> #-------------|-------|-----|-----|----------|
> #             | Stat2 |     | |          |
> #-------------|-------|-----|-----|----------|
> #             | ...   |     |     |          |
> #-------------|-------|-----|-----|----------|
> # Variable ...| Stat1 |     |     |          |
> #-------------|-------|-----|-----|----------|
> #             | Stat2 |     | |          |
> #-------------|-------|-----|-----|----------|
> #             | ...   |     |     |          |
> #-------------|-------|-----|-----|----------|
> 
> stat1 and stat2 could mean, sd, median, etc...
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Mar  6 22:48:38 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 7 Mar 2016 08:48:38 +1100
Subject: [R] package FD
In-Reply-To: <DE25A050-0E7C-4B18-A1D5-8279C1ADBE7E@dcn.davis.ca.us>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
	<CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>
	<CAG0T74qM12ZTS99zRqDDd8fjKEr2U4+ZgBsMHHvYcqs-0Ab=SA@mail.gmail.com>
	<CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
	<CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>
	<CAG0T74qy9gddUVQgwJ5eY+AZa=qgWrznfBJdWLstvo8TnkmwkA@mail.gmail.com>
	<DE25A050-0E7C-4B18-A1D5-8279C1ADBE7E@dcn.davis.ca.us>
Message-ID: <CA+8X3fVcmLQPmT23un3LyiW2N=hvXgUT88erS68Ek_6Rktr5cQ@mail.gmail.com>

The values in a$x do look numeric. What do you get from:

class(a$x)

If the result is "factor", as it was for your ft$trait3 variable (and
I hope that a$x is the same variable with a different name), then at
least one of those values must have been read in as non-numeric. The
possible reasons for this are many as Jeff noted and may be a
non-printing character that has crept into your original data file. If
your data set is as small as your example, I would start by loading
the original data file into a hex editor and looking for a character
that shouldn't be there. I once had to write a program in C that
scanned very large files of customer data to find just such
troublemakers and tell me where they were.

Jim


From bgunter.4567 at gmail.com  Mon Mar  7 01:09:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 6 Mar 2016 16:09:06 -0800
Subject: [R] ACF values with confidence limits + Plot Extaction
In-Reply-To: <CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>
References: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
	<56DC01D1.2010507@dewey.myzen.co.uk>
	<CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>
Message-ID: <CAGxFJbRRwJKpensRqyfnV_G9aRaWg4ojJf_=9o-gm1iPa2Wy=w@mail.gmail.com>

My word!  Did you try ?png    ?

More to the point, any good R tutorial should provide such info. Pls make
some reasonable efforts on your own before posting here.

Cheers,
Bert


On Sunday, March 6, 2016, Preetam Pal <lordpreetam at gmail.com> wrote:

> Thanks, Michael. Appreciate it.
> But suppose I go for the plot, how to extract it from R ... say, I want to
> save it as a .png file.
> Regards,
> Preetam
>
> On Sun, Mar 6, 2016 at 3:39 PM, Michael Dewey <lists at dewey.myzen.co.uk
> <javascript:;>>
> wrote:
>
> > According to the documentation acf returns what you want. It also says
> > that it returns it invisibly if plot = TRUE which I imagine is what you
> are
> > doing.
> >
> > So try
> >
> > res <- acf(insert_parameters_here, plot = FALSE)
> >
> > and then look at res
> >
> >
> >
> > On 06/03/2016 07:40, Preetam Pal wrote:
> >
> >> Hi R-users,
> >>
> >> I have a time series of residuals and I want to get the ACF
> >> (autocorrelation) values till lag = 12, along with the 12 upper/lower
> >> confidence limits. I understand that acf(residual) would give me the
> plot,
> >> but I will also need the actual values as an array etc. Plus, I'll have
> to
> >> extract the plot from R as well. Is there a way to achieve these two?
> >>
> >> Appreciate your help.
> >>
> >> Regards,
> >> Preetam
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
> >
>
>
>
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Mon Mar  7 01:45:58 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Sun, 6 Mar 2016 19:45:58 -0500
Subject: [R] stargazer summary statistics by group
In-Reply-To: <B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>
References: <56DC946C.9020608@cognigencorp.com>
	<B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>
Message-ID: <56DCCF46.1010306@cognigencorp.com>

Hi Boris,

Sorry, but not really. The example that comes closest is "Flip the table 
axes" but this is not right either.

In the design that I need, the year, month, day, etc... variables would 
each get a block of rows with statistics (mean, sd, median, min, max) 
provided for each level of another variable, these levels being reported 
in columns.

Basically, I need to look at descriptive statistics that are stratified. 
Does this make sense?

Sebastien

On 3/6/2016 4:04 PM, Boris Steipe wrote:
> Does this entry on the Stargazer Cheatsheet come close enough to what you want?
>     http://jakeruss.com/cheatsheets/stargazer.html#the-default-summary-statistics-table
>
> B.
>
> On Mar 6, 2016, at 3:34 PM, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>
>> Hi,
>>
>> I saw a post on this topic on stackoverflow a while ago. It does not seem to have got any reply... Just trying my luck here.
>>
>> Is there any way to use stargazer to create a table of descriptive statistics by group such as the one below?
>>
>> Thanks
>>
>> #-------------|-Stat--|--A--|--B--|--Overall-|
>> # Variable 1  | Stat1 |     |     |          |
>> #-------------|-------|-----|-----|----------|
>> #             | Stat2 |     | |          |
>> #-------------|-------|-----|-----|----------|
>> #             | ...   |     |     |          |
>> #-------------|-------|-----|-----|----------|
>> # Variable 2  | Stat1 |     |     |          |
>> #-------------|-------|-----|-----|----------|
>> #             | Stat2 |     | |          |
>> #-------------|-------|-----|-----|----------|
>> #             | ...   |     |     |          |
>> #-------------|-------|-----|-----|----------|
>> # Variable ...| Stat1 |     |     |          |
>> #-------------|-------|-----|-----|----------|
>> #             | Stat2 |     | |          |
>> #-------------|-------|-----|-----|----------|
>> #             | ...   |     |     |          |
>> #-------------|-------|-----|-----|----------|
>>
>> stat1 and stat2 could mean, sd, median, etc...
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sebastien Bihorel
Associate Director, Pharmacometrics
Buffalo Office: +1-716-633-3463 ext. 323 | Website 
<http://www.cognigencorp.com>
<http://www.simulations-plus.com/Default.aspx>


From jdnewmil at dcn.davis.ca.us  Mon Mar  7 01:52:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 06 Mar 2016 16:52:54 -0800
Subject: [R] stargazer summary statistics by group
In-Reply-To: <56DCCF46.1010306@cognigencorp.com>
References: <56DC946C.9020608@cognigencorp.com>
	<B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>
	<56DCCF46.1010306@cognigencorp.com>
Message-ID: <9FF7658D-A789-4A2B-8CC9-5EFA3762E6E5@dcn.davis.ca.us>

Maybe what you really want is the tables package. 
-- 
Sent from my phone. Please excuse my brevity.

On March 6, 2016 4:45:58 PM PST, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Hi Boris,
>
>Sorry, but not really. The example that comes closest is "Flip the
>table 
>axes" but this is not right either.
>
>In the design that I need, the year, month, day, etc... variables would
>
>each get a block of rows with statistics (mean, sd, median, min, max) 
>provided for each level of another variable, these levels being
>reported 
>in columns.
>
>Basically, I need to look at descriptive statistics that are
>stratified. 
>Does this make sense?
>
>Sebastien
>
>On 3/6/2016 4:04 PM, Boris Steipe wrote:
>> Does this entry on the Stargazer Cheatsheet come close enough to what
>you want?
>>    
>http://jakeruss.com/cheatsheets/stargazer.html#the-default-summary-statistics-table
>>
>> B.
>>
>> On Mar 6, 2016, at 3:34 PM, sbihorel
><Sebastien.Bihorel at cognigencorp.com> wrote:
>>
>>> Hi,
>>>
>>> I saw a post on this topic on stackoverflow a while ago. It does not
>seem to have got any reply... Just trying my luck here.
>>>
>>> Is there any way to use stargazer to create a table of descriptive
>statistics by group such as the one below?
>>>
>>> Thanks
>>>
>>> #-------------|-Stat--|--A--|--B--|--Overall-|
>>> # Variable 1  | Stat1 |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | Stat2 |     | |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | ...   |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>> # Variable 2  | Stat1 |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | Stat2 |     | |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | ...   |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>> # Variable ...| Stat1 |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | Stat2 |     | |          |
>>> #-------------|-------|-----|-----|----------|
>>> #             | ...   |     |     |          |
>>> #-------------|-------|-----|-----|----------|
>>>
>>> stat1 and stat2 could mean, sd, median, etc...
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Sebastien Bihorel
>Associate Director, Pharmacometrics
>Buffalo Office: +1-716-633-3463 ext. 323 | Website 
><http://www.cognigencorp.com>
><http://www.simulations-plus.com/Default.aspx>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mmalten at gmail.com  Mon Mar  7 03:08:23 2016
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Sun, 6 Mar 2016 21:08:23 -0500
Subject: [R] stargazer summary statistics by group
In-Reply-To: <9FF7658D-A789-4A2B-8CC9-5EFA3762E6E5@dcn.davis.ca.us>
References: <56DC946C.9020608@cognigencorp.com>
	<B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>
	<56DCCF46.1010306@cognigencorp.com>
	<9FF7658D-A789-4A2B-8CC9-5EFA3762E6E5@dcn.davis.ca.us>
Message-ID: <CANOgrHZpM-SXevqEbrkghqRYKFxjNVWLzOhTxSuaRRvq1=Wu0g@mail.gmail.com>

https://cran.r-project.org/web/packages/tableone/index.html might help

On Sunday, March 6, 2016, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Maybe what you really want is the tables package.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 6, 2016 4:45:58 PM PST, sbihorel <
> Sebastien.Bihorel at cognigencorp.com <javascript:;>> wrote:
> >Hi Boris,
> >
> >Sorry, but not really. The example that comes closest is "Flip the
> >table
> >axes" but this is not right either.
> >
> >In the design that I need, the year, month, day, etc... variables would
> >
> >each get a block of rows with statistics (mean, sd, median, min, max)
> >provided for each level of another variable, these levels being
> >reported
> >in columns.
> >
> >Basically, I need to look at descriptive statistics that are
> >stratified.
> >Does this make sense?
> >
> >Sebastien
> >
> >On 3/6/2016 4:04 PM, Boris Steipe wrote:
> >> Does this entry on the Stargazer Cheatsheet come close enough to what
> >you want?
> >>
> >
> http://jakeruss.com/cheatsheets/stargazer.html#the-default-summary-statistics-table
> >>
> >> B.
> >>
> >> On Mar 6, 2016, at 3:34 PM, sbihorel
> ><Sebastien.Bihorel at cognigencorp.com <javascript:;>> wrote:
> >>
> >>> Hi,
> >>>
> >>> I saw a post on this topic on stackoverflow a while ago. It does not
> >seem to have got any reply... Just trying my luck here.
> >>>
> >>> Is there any way to use stargazer to create a table of descriptive
> >statistics by group such as the one below?
> >>>
> >>> Thanks
> >>>
> >>> #-------------|-Stat--|--A--|--B--|--Overall-|
> >>> # Variable 1  | Stat1 |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | Stat2 |     | |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | ...   |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> # Variable 2  | Stat1 |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | Stat2 |     | |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | ...   |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> # Variable ...| Stat1 |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | Stat2 |     | |          |
> >>> #-------------|-------|-----|-----|----------|
> >>> #             | ...   |     |     |          |
> >>> #-------------|-------|-----|-----|----------|
> >>>
> >>> stat1 and stat2 could mean, sd, median, etc...
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE
> and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Sebastien Bihorel
> >Associate Director, Pharmacometrics
> >Buffalo Office: +1-716-633-3463 ext. 323 | Website
> ><http://www.cognigencorp.com>
> ><http://www.simulations-plus.com/Default.aspx>
> >
> >______________________________________________
> >R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From mesowmy at gmail.com  Sun Mar  6 17:49:56 2016
From: mesowmy at gmail.com (sowmya s)
Date: Sun, 6 Mar 2016 09:49:56 -0700
Subject: [R] Installing a tar.gz file
Message-ID: <CACPQjjntq0Gj9O3ShPk4eNQfMtpf4E2t29TnseBrhWrm7hoOpg@mail.gmail.com>

Hi:
I am trying to install a tar.gz file and I get the error message,
Warning in install.packages :
  installation of package
?/Users/subraman/Documents/BCA_Data/TDL_Data/tdllicor_0.1-21.tar.gz? had
non-zero exit status

I have tried to gunzip the file and use the .tar file to uninstall and that
does not work either. Previous users have suggested that they had no
problems installing the file up until at least R2.15.1.

Could someone please offer some advice ?
Thank you.
Sowmya

	[[alternative HTML version deleted]]


From arbautjc at gmail.com  Sun Mar  6 20:33:30 2016
From: arbautjc at gmail.com (Jean-Claude Arbaut)
Date: Sun, 6 Mar 2016 20:33:30 +0100
Subject: [R] ACF values with confidence limits + Plot Extaction
In-Reply-To: <CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>
References: <CAHVFrXHqeeiWje4gW3Pb-ZceZaVZzsg9FowQtwxrqQZC4oXYWg@mail.gmail.com>
	<56DC01D1.2010507@dewey.myzen.co.uk>
	<CAHVFrXF5BXfScGBLcAPTSwxU22jrtb0RNnBGnFhQjLGJcmQrGQ@mail.gmail.com>
Message-ID: <CANufCk70+7gDsPm1EP9GishBdwLB3bc3ze+=V5T8PH5ScHmMbA@mail.gmail.com>

a <- as.ts(rnorm(20))
png("acf.png")
a.acf <- acf(a)
dev.off()

# to see what is available
names(a.acf)
unclass(a.acf)


2016-03-06 20:06 GMT+01:00 Preetam Pal <lordpreetam at gmail.com>:
> Thanks, Michael. Appreciate it.
> But suppose I go for the plot, how to extract it from R ... say, I want to
> save it as a .png file.
> Regards,
> Preetam
>
> On Sun, Mar 6, 2016 at 3:39 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>
>> According to the documentation acf returns what you want. It also says
>> that it returns it invisibly if plot = TRUE which I imagine is what you are
>> doing.
>>
>> So try
>>
>> res <- acf(insert_parameters_here, plot = FALSE)
>>
>> and then look at res
>>
>>
>>
>> On 06/03/2016 07:40, Preetam Pal wrote:
>>
>>> Hi R-users,
>>>
>>> I have a time series of residuals and I want to get the ACF
>>> (autocorrelation) values till lag = 12, along with the 12 upper/lower
>>> confidence limits. I understand that acf(residual) would give me the plot,
>>> but I will also need the actual values as an array etc. Plus, I'll have to
>>> extract the plot from R as well. Is there a way to achieve these two?
>>>
>>> Appreciate your help.
>>>
>>> Regards,
>>> Preetam
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>>
>
>
>
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Mon Mar  7 05:00:34 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Sun, 6 Mar 2016 23:00:34 -0500
Subject: [R] stargazer summary statistics by group
In-Reply-To: <CANOgrHZpM-SXevqEbrkghqRYKFxjNVWLzOhTxSuaRRvq1=Wu0g@mail.gmail.com>
References: <56DC946C.9020608@cognigencorp.com>
	<B2BBA348-9F15-4221-AFEE-330019E0E6D6@utoronto.ca>
	<56DCCF46.1010306@cognigencorp.com>
	<9FF7658D-A789-4A2B-8CC9-5EFA3762E6E5@dcn.davis.ca.us>
	<CANOgrHZpM-SXevqEbrkghqRYKFxjNVWLzOhTxSuaRRvq1=Wu0g@mail.gmail.com>
Message-ID: <56DCFCE2.2020706@cognigencorp.com>

Thanks for the suggestions. I will look into these packages.

On 3/6/2016 9:08 PM, Mitchell Maltenfort wrote:
> https://cran.r-project.org/web/packages/tableone/index.html might help
>
> On Sunday, March 6, 2016, Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
> <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>
>     Maybe what you really want is the tables package.
>     --
>     Sent from my phone. Please excuse my brevity.
>
>     On March 6, 2016 4:45:58 PM PST, sbihorel
>     <Sebastien.Bihorel at cognigencorp.com <javascript:;>> wrote:
>     >Hi Boris,
>     >
>     >Sorry, but not really. The example that comes closest is "Flip the
>     >table
>     >axes" but this is not right either.
>     >
>     >In the design that I need, the year, month, day, etc... variables
>     would
>     >
>     >each get a block of rows with statistics (mean, sd, median, min, max)
>     >provided for each level of another variable, these levels being
>     >reported
>     >in columns.
>     >
>     >Basically, I need to look at descriptive statistics that are
>     >stratified.
>     >Does this make sense?
>     >
>     >Sebastien
>     >
>     >On 3/6/2016 4:04 PM, Boris Steipe wrote:
>     >> Does this entry on the Stargazer Cheatsheet come close enough
>     to what
>     >you want?
>     >>
>     >http://jakeruss.com/cheatsheets/stargazer.html#the-default-summary-statistics-table
>     >>
>     >> B.
>     >>
>     >> On Mar 6, 2016, at 3:34 PM, sbihorel
>     ><Sebastien.Bihorel at cognigencorp.com <javascript:;>> wrote:
>     >>
>     >>> Hi,
>     >>>
>     >>> I saw a post on this topic on stackoverflow a while ago. It
>     does not
>     >seem to have got any reply... Just trying my luck here.
>     >>>
>     >>> Is there any way to use stargazer to create a table of descriptive
>     >statistics by group such as the one below?
>     >>>
>     >>> Thanks
>     >>>
>     >>> #-------------|-Stat--|--A--|--B--|--Overall-|
>     >>> # Variable 1  | Stat1 |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | Stat2 |     | |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | ...   |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> # Variable 2  | Stat1 |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | Stat2 |     | |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | ...   |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> # Variable ...| Stat1 |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | Stat2 |     | |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>> #             | ...   |     |     |          |
>     >>> #-------------|-------|-----|-----|----------|
>     >>>
>     >>> stat1 and stat2 could mean, sd, median, etc...
>     >>>
>     >>> ______________________________________________
>     >>> R-help at r-project.org <javascript:;> mailing list -- To
>     UNSUBSCRIBE and more, see
>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> PLEASE do read the posting guide
>     >http://www.R-project.org/posting-guide.html
>     >>> and provide commented, minimal, self-contained, reproducible code.
>     >
>     >--
>     >Sebastien Bihorel
>     >Associate Director, Pharmacometrics
>     >Buffalo Office: +1-716-633-3463 ext. 323 | Website
>     ><http://www.cognigencorp.com>
>     ><http://www.simulations-plus.com/Default.aspx>
>     >
>     >______________________________________________
>     >R-help at r-project.org <javascript:;> mailing list -- To
>     UNSUBSCRIBE and more, see
>     >https://stat.ethz.ch/mailman/listinfo/r-help
>     >PLEASE do read the posting guide
>     >http://www.R-project.org/posting-guide.html
>     >and provide commented, minimal, self-contained, reproducible code.
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE
>     and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
> -- 
> Sent from Gmail Mobile

-- 
Sebastien Bihorel
Associate Director, Pharmacometrics
Buffalo Office: +1-716-633-3463 ext. 323 | Website 
<http://www.cognigencorp.com>
<http://www.simulations-plus.com/Default.aspx>


From ligges at statistik.tu-dortmund.de  Mon Mar  7 07:48:23 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 7 Mar 2016 07:48:23 +0100
Subject: [R] Installing a tar.gz file
In-Reply-To: <CACPQjjntq0Gj9O3ShPk4eNQfMtpf4E2t29TnseBrhWrm7hoOpg@mail.gmail.com>
References: <CACPQjjntq0Gj9O3ShPk4eNQfMtpf4E2t29TnseBrhWrm7hoOpg@mail.gmail.com>
Message-ID: <56DD2437.4040608@statistik.tu-dortmund.de>



On 06.03.2016 17:49, sowmya s wrote:
> Hi:
> I am trying to install a tar.gz file and I get the error message,
> Warning in install.packages :
>    installation of package
> ?/Users/subraman/Documents/BCA_Data/TDL_Data/tdllicor_0.1-21.tar.gz? had
> non-zero exit status


We need at least the full output to be able to guess what went wrong.

Best,
Uwe Ligges


>
> I have tried to gunzip the file and use the .tar file to uninstall and that
> does not work either. Previous users have suggested that they had no
> problems installing the file up until at least R2.15.1.
>
> Could someone please offer some advice ?
> Thank you.
> Sowmya
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From manishm at dbs.com  Mon Mar  7 11:42:42 2016
From: manishm at dbs.com (Manish MAHESHWARI)
Date: Mon, 7 Mar 2016 10:42:42 +0000
Subject: [R] R Server Sizing Guidelines
Message-ID: <8B5BC7735651764E884E3651BAA48D9A08DC8403@W01GMAILDAGA52.reg1.1bank.dbs.com>

Hi All,

Are there any best practices on R Server Sizing Guidelines?
Especially around CPU to Memory Ratio and SDD Disks on the Server?

Thanks,
Manish

CONFIDENTIAL NOTE:
The information contained in this email is intended only...{{dropped:11}}


From petr.pikal at precheza.cz  Mon Mar  7 12:16:01 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 7 Mar 2016 11:16:01 +0000
Subject: [R] Help in R code
In-Reply-To: <CADH3bWKOuv+UGRmf=UphYkj02HPWYrqZTV-PFfZjk1=Hf3oSdg@mail.gmail.com>
References: <CADH3bWLb_4OJO4x7_fwYhTjiH5CUTAu08SrT+9YRpkPRxwzuCQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50121E8@SRVEXCHMBX.precheza.cz>
	<CADH3bWLx5i5aw1EvEXsC1-toDFKfBodroQ4=RQNbYn0LVQ+TTw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50122E2@SRVEXCHMBX.precheza.cz>
	<CADH3bWKeBDrXtPouTozZfFMxPLjtqaK2hPtyP7mKtRr_Yc78UA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50124B0@SRVEXCHMBX.precheza.cz>
	<CADH3bWKOuv+UGRmf=UphYkj02HPWYrqZTV-PFfZjk1=Hf3oSdg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5012ECE@SRVEXCHMBX.precheza.cz>

Hi

Keep your reply to the list.

Hm. There is natural language processing section in Task View. Maybe you could use already developed instruments for processing text. I vaguely remember there was also some article in R journal about text mining.

And searching internet by

R text mining

gave me plenty of possible suggestions including e.g package tm.

First line of your code gave me an error
> s <- unlist(lapply(posText, function(x) { str_split(x, "\n") }))
Error in lapply(posText, function(x) { : object 'posText' not found

And again
you still fail to keep to the recommended way of asking questions

1.       Plain text, not HTML posts

2.       input and output data sent as result of dput(posText[selection])

3.       provide ***reproducible*** code
Instead of trying to persuade all of us to accept your way of mailing you shall comply to ours if you want any reasonable help.

Cheers
Petr



Petr Pikal

From: deepak aggarwal [mailto:talk4deepak at gmail.com]
Sent: Thursday, March 03, 2016 2:07 PM
To: PIKAL Petr
Subject: Re: [R] Help in R code


           I have a column A having sentences and column B have some words. I want to check the part of speech column B word belongs to sentence present in column A.
Currently I am able to get part of speech for a single sentence using following code:
I am trying to get part of speech corresponds to each sentence in text file. Please suggest code for this.


On Wed, Mar 2, 2016 at 3:35 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

AFAIK what you say now is quite different from what you have told before. You want to get rid of all sentences which lack vattrwords.

Maybe it can be done by charmatch
> test<-paste("AAA AAA", "BBB", "CCC CCC", sep=".")
> test
[1] "AAA AAA.BBB.CCC CCC"
>
> test2<-c("AAA", "CCC")
> test.s<-unlist(strsplit(test, "\\.<file:///\\.>"))
> test.s[charmatch(test2, test.s)]
[1] "AAA AAA" "CCC CCC"

BTW, you still fail to keep to the recommended way of asking questions
Plain text, not HTML posts
input and output data sent as result of dput()
provide reproducible code with errors you encountered.

Cheers
Petr



From: deepak aggarwal [mailto:talk4deepak at gmail.com<mailto:talk4deepak at gmail.com>]
Sent: Wednesday, March 02, 2016 8:59 AM
To: PIKAL Petr
Cc: r-help at r-project.org<mailto:r-help at r-project.org>

Subject: Re: [R] Help in R code

Hi Petr,
#loading word to be matched
at_list <- read.delim(file='C:/******/All.txt', header=FALSE, stringsAsFactors=FALSE)
names(at_list) <- c('attr')
at_list$attr <- tolower(at_list$attr)

vattribute<-at_list$attr

#loading sentences to be checked
posText <- read.delim(file='C:/*****/Sentenc.txt', header=FALSE, stringsAsFactors=FALSE)
posText <- unlist(lapply(posText, function(x) { str_split(x, "\n") }))

test<-vattribute

test1 <- unlist(strsplit(posText,split="\\.<file:///\\.>"))
# test1 <- strsplit(posText,".",fixed=TRUE)[[1]]
#test2<- test1[match(test1,test)]
test2<-test1[grep(paste(test, collapse="|"),test1)]

score <- c(test,test2)


#add row
newrow <- c(test1, score)
final_scores <- rbind(newrow)
final_scores
result<-as.data.frame(final_scores)

write.table(result, "C:/******/otput.txt", sep="\t")
 On Wed, Mar 2, 2016 at 12:33 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Well, so again, my first answer was maybe too elaborated.

0. Send your replies also to help list.
1. Do not post in HTML.
2. Send some data by using output from
dput(yourobject)
3. Prepare desired output and again show it by dput(yourresult)
I still do not understand your desired output. In first sequence you dropped words ?He is? and ?he?, in second ?word? and ?can be?

Did you check?
4. Check if

?strsplit together with ?"%in%" can be of some help.

test <- "he is smart and fast in his work"
> test
[1] "he is smart and fast in his work"
> unlist(strsplit(test, " "))
[1] "he"    "is"    "smart" "and"   "fast"  "in"    "his"   "work"

unlist(strsplit(test, " ")) %in% "smart"
[1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
If the above does not work for you, you need to evaluate regular expressions.

See e.g.
?gsub

Cheers
Petr

From: deepak aggarwal [mailto:talk4deepak at gmail.com<mailto:talk4deepak at gmail.com>]
Sent: Tuesday, March 01, 2016 5:06 PM
To: PIKAL Petr
Subject: Re: [R] Help in R code


Sentence

Words

word string

1

he is a nice human being.he has great talent of singing

human,talent

a nice human being .,has great talent of singing

2

Word is having environmental issues which can be solved at local level nw

environmental,local

is having environmental issues which,solved at local level nw


sentence column has 1000 sentences and words have some selected words already written
now i want r code using which i can get word string in such a way that first human is searched in sentence 1 and then 2 words before human and 2 words after human will be writen in word string next it will search word talent and add it to word string

so in nutsheel for every word in words column it will fetch 2 words before and 2 words after where match is found.

Seeking your help on this.

Regards
Deepak

On Tue, Mar 1, 2016 at 8:41 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of deepak
> aggarwal
> Sent: Tuesday, March 01, 2016 1:30 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Help in R code
>
> Hi ,
>
> Seeking your help in coding following requirement in R.
>
> Vector 1 has sentences for ex. vector 1="he is a nice human being","he
> is smart and fast in his work"
>
> vector 2 has keywords found in each sentence seperated by comma for
> ex. vector2 for vector 1 =nice,being vector 2 for vector 1 =smart,work
>
> I want output to be vector 3 which will show 2 words before and after
> where match is found
>
> vector 1                                       vector2        vector 3
> he is a nice human being              nice,being        is a nice
> human,human being
> he is smart and fast in his work   smart,work        he is smart,in his
> work
>
> in all i want vector 3 to how 2 words before and aftr to each word of
> vector 2 from vector 1.
>
> really appriciate your quick help on this.

OK. Some very quick help:

1. Do not post in HTML, your mail is barely readable.
2. Send some data by using output from
dput(yourobject)
3. Instead of vaguely explaining what you want to do, prepare desired output and again show it by dput(yourresult)
4. Check if

?strsplit together with ?"%in%" can be of some help.

test <- "he is smart and fast in his work"
> test
[1] "he is smart and fast in his work"
> unlist(strsplit(test, " "))
[1] "he"    "is"    "smart" "and"   "fast"  "in"    "his"   "work"

unlist(strsplit(test, " ")) %in% "smart"
[1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE

Cheers
Petr

>
> Thanks & Regards
> Deepak
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From hodarahmati68 at yahoo.com  Mon Mar  7 13:21:21 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Mon, 7 Mar 2016 12:21:21 +0000 (UTC)
Subject: [R] merging data frame with world map
References: <728490449.4903372.1457353281880.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <728490449.4903372.1457353281880.JavaMail.yahoo@mail.yahoo.com>

Hi all,I have a data frame which have a column named COUNTRY, I want to merge my data frame with world map from ggmap to plot it on world map, but when I merge my data frame with world map I get 0 observations! Here is my main data frame (mydata): 
??? 'data.frame':?? 269265 obs. of? 470 variables:
???? $ Serial?????? : num? 41568 41568 41568 41568 41568 ...
???? $ Duration???? : num? 218 351 250 200 375 91 236 250 236 322 ...??? 
???? $ COUNTRY????? : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8 
and here is the command for merging with world map: 
???? word_map=merge(world_map,mydata,by.x="region",by.y="country")
???? str(world_map)
???? 'data.frame':?? 0 obs. of? 475 variables:
???? $ Serial?????? : num
???? $ Duration???? : num? 
???? $ COUNTRY????? : chr
how should I correct this world_map structure to have all my observations? And I could not use rworldmap in R 3.2.3,anyone used this library in version 3.2.3?
Thanks for any help.


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Mar  7 14:15:09 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 7 Mar 2016 13:15:09 +0000
Subject: [R] merging data frame with world map
In-Reply-To: <728490449.4903372.1457353281880.JavaMail.yahoo@mail.yahoo.com>
References: <728490449.4903372.1457353281880.JavaMail.yahoo.ref@mail.yahoo.com>
	<728490449.4903372.1457353281880.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56DD7EDD.6050408@dewey.myzen.co.uk>

Inline

On 07/03/2016 12:21, hoda rahmati via R-help wrote:
> Hi all,I have a data frame which have a column named COUNTRY, I want to merge my data frame with world map from ggmap to plot it on world map, but when I merge my data frame with world map I get 0 observations! Here is my main data frame (mydata):
>      'data.frame':   269265 obs. of  470 variables:
>       $ Serial       : num  41568 41568 41568 41568 41568 ...
>       $ Duration     : num  218 351 250 200 375 91 236 250 236 322 ...
>       $ COUNTRY      : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8

COUNTRY

> and here is the command for merging with world map:
>       word_map=merge(world_map,mydata,by.x="region",by.y="country")

country

>       str(world_map)
>       'data.frame':   0 obs. of  475 variables:
>       $ Serial       : num
>       $ Duration     : num
>       $ COUNTRY      : chr
> how should I correct this world_map structure to have all my observations? And I could not use rworldmap in R 3.2.3,anyone used this library in version 3.2.3?
> Thanks for any help.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From boris.steipe at utoronto.ca  Mon Mar  7 14:26:21 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 7 Mar 2016 08:26:21 -0500
Subject: [R] merging data frame with world map
In-Reply-To: <56DD7EDD.6050408@dewey.myzen.co.uk>
References: <728490449.4903372.1457353281880.JavaMail.yahoo.ref@mail.yahoo.com>
	<728490449.4903372.1457353281880.JavaMail.yahoo@mail.yahoo.com>
	<56DD7EDD.6050408@dewey.myzen.co.uk>
Message-ID: <11E169D5-562E-4867-A31F-01C50C52EE7B@utoronto.ca>

And more!
:-)
On Mar 7, 2016, at 8:15 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Inline
> 
> On 07/03/2016 12:21, hoda rahmati via R-help wrote:
>> Hi all,I have a data frame which have a column named COUNTRY, I want to merge my data frame with world map from ggmap to plot it on world map, but when I merge my data frame with world map I get 0 observations! Here is my main data frame (mydata):
>>     'data.frame':   269265 obs. of  470 variables:
>>      $ Serial       : num  41568 41568 41568 41568 41568 ...
>>      $ Duration     : num  218 351 250 200 375 91 236 250 236 322 ...
>>      $ COUNTRY      : Factor w/ 27 levels "","AU","BA","BE",..: 8 8 8 8 8
> 
> COUNTRY
> 
>> and here is the command for merging with world map:
>>      word_map=merge(world_map,mydata,by.x="region",by.y="country")
word_map

> 
> country
> 
>>      str(world_map)
world_map

>>      'data.frame':   0 obs. of  475 variables:
>>      $ Serial       : num
>>      $ Duration     : num
>>      $ COUNTRY      : chr
>> how should I correct this world_map structure to have all my observations? And I could not use rworldmap in R 3.2.3,anyone used this library in version 3.2.3?
>> Thanks for any help.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sunnysingha.analytics at gmail.com  Mon Mar  7 15:13:49 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Mon, 7 Mar 2016 19:43:49 +0530
Subject: [R] Rfacebook -- searchPages() -- help
Message-ID: <DF0F3C91-585C-44E2-ACF2-E144BCF15877@gmail.com>

Hi,
I?m using searchPages() function in ?Rfacebook' package. 

I want to know why I receive 400 pages when i command only 300 pages in the function.
sample code: 
searchPages(?youtube?, n=300, token=fb_oauth)
output printed: 200 pages 400 

Also, the result differs whenever I specify n>200 in the function.

Regards,
Sunny Singha
	[[alternative HTML version deleted]]


From kyle.hamilton at gmail.com  Fri Mar  4 22:43:03 2016
From: kyle.hamilton at gmail.com (Kyle Hamilton)
Date: Fri, 4 Mar 2016 13:43:03 -0800
Subject: [R] [R-pkgs] lavaan.shiny "latent variable analysis with shiny"
Message-ID: <CAN17LWP_y0FezqPw35gNmj=cA1D5C6Totu=OvJ-eM1iam8WTXQ@mail.gmail.com>

Dear R users,

I'm pleased to announce that the first release of lavaan.shiny has
been released to CRAN.

lavaan.shiny "latent variable analysis with shiny" has built in
examples from the lavaan package and currently supports latent growth
curve models, confirmatory factor analysis, and structural equation
modeling. Graphics are handled by the semPlot package.

Currently there is a live demo of lavaan.shiny online which can be
accessed here http://kylehamilton.net/shiny/lavaan.shiny/ it is
recommended that users download the package and run it naively.

The package is developed using GitHub, and more information as well as
the current development version can be found at
https://github.com/kylehamilton/lavaan.shiny


William Kyle Hamilton  -  Graduate Student
University of California, Merced  -  Psychological Sciences
psychology.ucmerced.edu - kylehamilton.com

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Paul.Louisell at pw.utc.com  Mon Mar  7 14:35:07 2016
From: Paul.Louisell at pw.utc.com (Louisell, Paul T           PW)
Date: Mon, 7 Mar 2016 13:35:07 +0000
Subject: [R] Lexical scoping for step and add1 functions
Message-ID: <96E6B0084A068C43B02C637889A5E0B72E3F6E@UUSNWE1N.na.utcmail.com>

Hi,

I've run into a problem calling the step function from within a function; I sent this to the R development list first, but the moderator said it was better suited to R help. My OS is Windows 7 and I'm using R version 3.2.3.

Here's a simple function to help reproduce the error:
      > test.FN
      function(dfr, scope, k=2){
      temp.lm=lm(scope$lower, data=dfr)
      step(temp.lm, scope=scope$upper, k=k)
      }

And here's the code that gives the error when calling the function above:
      # Begin by setting the rng seed.
      > set.seed(523)

      # Generate a design matrix and response.
      > X.des=matrix(abs(rnorm(50*20, sd=4)), nrow=50)
      > Y=20 + X.des[, 1:3] %*% matrix(c(3, -4, 2), nrow=3) + rnorm(50)
      > X.des=cbind(as.data.frame(X.des), Y)

      # Create the lower and upper formula components of a list.
      > test.scope=list(lower=as.formula(Y ~ 1), upper=as.formula(paste("Y ~ ", paste(names(X.des)[1:20], collapse=" + "), sep="")))

      # Run 'test.FN'.
      > test.FN(dfr=X.des, scope=test.scope)
      Start:  AIC=257.58
      Y ~ 1

      Error in is.data.frame(data) : object 'dfr' not found
      > traceback()
      11: is.data.frame(data)
      10: model.frame.default(formula = Y ~ V1 + V2 + V3 + V4 + V5 + V6 +
              V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 +
              V17 + V18 + V19 + V20, data = dfr, drop.unused.levels = TRUE)
      9: stats::model.frame(formula = Y ~ V1 + V2 + V3 + V4 + V5 + V6 +
             V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 +
             V17 + V18 + V19 + V20, data = dfr, drop.unused.levels = TRUE)
      8: eval(expr, envir, enclos)
      7: eval(fcall, env)
      6: model.frame.lm(fob, xlev = object$xlevels)
      5: model.frame(fob, xlev = object$xlevels)
      4: add1.lm(fit, scope$add, scale = scale, trace = trace, k = k,
             ...)
      3: add1(fit, scope$add, scale = scale, trace = trace, k = k, ...)
      2: step(temp.lm, scope = scope$upper, k = k) at #3
      1: test.FN(dfr = X.des, scope = test.scope)

The call to the traceback function indicates add1 doesn't see the dataframe dfr  passed to test.FN. The step function runs fine when I do everything in the global environment without using test.FN. I know the lexical scoping rules are different for objects involving model formulae, but despite a fair amount of experimentation, I haven't found any way to make the step / add1 functions see the dataframe that's passed to test.FN. Any help would be greatly appreciated.

Thanks,

Paul Louisell
Statistical Specialist
Paul.Louisell at pw.utc.com<mailto:Paul.Louisell at pw.utc.com>
860-565-8104

Still, tomorrow's going to be another working day, and I'm trying to get some rest.
That's all, I'm trying to get some rest.
Paul Simon, "American Tune"



	[[alternative HTML version deleted]]


From chettyvk at gmail.com  Mon Mar  7 19:48:28 2016
From: chettyvk at gmail.com (Veerappa Chetty)
Date: Mon, 7 Mar 2016 13:48:28 -0500
Subject: [R] using factor variable in the "DO" function
Message-ID: <CAFpsATbOEUwB_2-VXN8JXL_YgB=5MCs2nsS4JuFb_mQCsBLAPw@mail.gmail.com>

Hi,

The following call does not work:

dfhosp=dat.2.wide.sub %>% group_by(HOSP_NRD)%>%
  do(fitHosp=lm(log(y)~ log(x)+I(log(x)^2)+NCHRONIC+AGE+sex ,data=.))

Error in `$<-.data.frame`(`*tmp*`, "sex", value = integer(0)) :
  replacement has 0 rows, data has 25174

When I use "sex" as a binary variable with values "0" and "1", it works.

Is there a way to use factor in this call?
Thanks.

V.K.Chetty

-- 
Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com,vchetty at bu.edu

	[[alternative HTML version deleted]]


From jesitha.salam at gmail.com  Mon Mar  7 20:23:23 2016
From: jesitha.salam at gmail.com (jessy)
Date: Tue, 8 Mar 2016 00:53:23 +0530
Subject: [R] Problem installing ggplot2 in R 3.2.3
Message-ID: <CALX5n20M58z6VJEjarzV6AJpQGH8Q0E8VGocm1GAZUoM4cX7NQ@mail.gmail.com>

Hi,
I am trying to install ggplot2 in R software but Im getting the following
error message:
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?Rcpp?
Error: package or namespace load failed for ?ggplot2?

Please help me with this issue, whats to be done to rectify it.

Thanks

*Dr. Jesitha Abdul Salam*
*Postdoctoral Researcher*
*School of Marine Sciences*
*Cochin University of Science and Technology*
*Kerala-682016*

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Mar  7 20:37:20 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 7 Mar 2016 14:37:20 -0500
Subject: [R] Problem installing ggplot2 in R 3.2.3
In-Reply-To: <CALX5n20M58z6VJEjarzV6AJpQGH8Q0E8VGocm1GAZUoM4cX7NQ@mail.gmail.com>
References: <CALX5n20M58z6VJEjarzV6AJpQGH8Q0E8VGocm1GAZUoM4cX7NQ@mail.gmail.com>
Message-ID: <CAM_vjunCQ_RO-QfhjOrd1j-wmoMVwAANse3BBoXSzdnKr4d8+Q@mail.gmail.com>

You should install the Rcpp package, as the error message is telling you.

You could also use the dependencies=TRUE argument to install.packages().

Sarah

On Mon, Mar 7, 2016 at 2:23 PM, jessy <jesitha.salam at gmail.com> wrote:
> Hi,
> I am trying to install ggplot2 in R software but Im getting the following
> error message:
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?Rcpp?
> Error: package or namespace load failed for ?ggplot2?
>
> Please help me with this issue, whats to be done to rectify it.
>
> Thanks
>


From jdnewmil at dcn.davis.ca.us  Mon Mar  7 20:46:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 07 Mar 2016 11:46:51 -0800
Subject: [R] Problem installing ggplot2 in R 3.2.3
In-Reply-To: <CALX5n20M58z6VJEjarzV6AJpQGH8Q0E8VGocm1GAZUoM4cX7NQ@mail.gmail.com>
References: <CALX5n20M58z6VJEjarzV6AJpQGH8Q0E8VGocm1GAZUoM4cX7NQ@mail.gmail.com>
Message-ID: <813462B2-F57C-4C1C-8456-FD0965976C27@dcn.davis.ca.us>

Apparently you do not have a required package installed that ggplot2 depends on. How you arrived at that condition is not clear because you have not told us the minimum information mentioned in the Posting Guide.

Since the typical way to install ggplot2 is to use the

install.packages( "ggplot2" )

command,  be sure to let us know what happened when you did that. That command by default installs dependencies as well as the package you asked for.  That means copy and paste your input command and the resulting output from R into your email. Also give us the output from

sessionInfo()

-- 
Sent from my phone. Please excuse my brevity.

On March 7, 2016 11:23:23 AM PST, jessy <jesitha.salam at gmail.com> wrote:
>Hi,
>I am trying to install ggplot2 in R software but Im getting the
>following
>error message:
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>versionCheck
>= vI[[j]]) :
>  there is no package called ?Rcpp?
>Error: package or namespace load failed for ?ggplot2?
>
>Please help me with this issue, whats to be done to rectify it.
>
>Thanks
>
>*Dr. Jesitha Abdul Salam*
>*Postdoctoral Researcher*
>*School of Marine Sciences*
>*Cochin University of Science and Technology*
>*Kerala-682016*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From a.sanders at navitaire.com  Mon Mar  7 21:34:34 2016
From: a.sanders at navitaire.com (a.sanders at navitaire.com)
Date: Mon, 7 Mar 2016 20:34:34 +0000
Subject: [R] Error loading object in stats package
Message-ID: <6b1eb815c3444ddbbf6480e0941e8226@DM2PR42MB111.048d.mgd.msft.net>

I am trying to use a package that uses the package car which uses sigma in the stats package, but apparently my version of the stats package doesn't contain the function sigma. How can I go about fixing this?

Thanks


Error : object 'sigma' is not exported by 'namespace:stats'

In addition: Warning messages:

1: package 'car' was built under R version 3.3.0

2: replacing previous import by 'stats::sigma' when loading 'pbkrtest'

Error: package or namespace load failed for 'car'


SessionInfo:
R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] JGR_1.7-16    iplots_1.1-7  JavaGD_0.6-1  rJava_0.9-8   ggplot2_2.0.0 png_0.1-7

loaded via a namespace (and not attached):
[1] Rcpp_0.12.3      splines_3.2.3    MASS_7.3-45      munsell_0.4.3    colorspace_1.2-6 lattice_0.20-33  minqa_1.2.4
 [8] plyr_1.8.3       tools_3.2.3      nnet_7.3-11      parallel_3.2.3   grid_3.2.3       gtable_0.1.2     nlme_3.1-124
[15] lme4_1.1-10      Matrix_1.2-3     nloptr_1.0.4     scales_0.3.0


	[[alternative HTML version deleted]]


From adamsanders11 at gmail.com  Mon Mar  7 21:46:13 2016
From: adamsanders11 at gmail.com (Adam Sanders)
Date: Mon, 7 Mar 2016 13:46:13 -0700
Subject: [R] stats:sigma doesnt exist in 3.2.3
Message-ID: <CAOBKCDeM5boLcr4k-TOF6TtZhJOz9c4NVY69Su-ctP-iH7jXuQ@mail.gmail.com>

I am trying to use a package that uses the package car which uses sigma in
the stats package, but apparently my version of the stats package doesn?t
contain the function sigma. How can I go about fixing this?



Thanks



Error : object ?sigma? is not exported by 'namespace:stats'

In addition: Warning messages:

1: package ?car? was built under R version 3.3.0

2: replacing previous import by ?stats::sigma? when loading ?pbkrtest?

Error: package or namespace load failed for ?car?





SessionInfo:

R version 3.2.3 (2015-12-10)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252

[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

[1] JGR_1.7-16    iplots_1.1-7  JavaGD_0.6-1  rJava_0.9-8   ggplot2_2.0.0
png_0.1-7



loaded via a namespace (and not attached):

[1] Rcpp_0.12.3      splines_3.2.3    MASS_7.3-45      munsell_0.4.3
colorspace_1.2-6 lattice_0.20-33  minqa_1.2.4

 [8] plyr_1.8.3       tools_3.2.3      nnet_7.3-11      parallel_3.2.3
grid_3.2.3       gtable_0.1.2     nlme_3.1-124

[15] lme4_1.1-10      Matrix_1.2-3     nloptr_1.0.4     scales_0.3.0

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon Mar  7 22:26:36 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 7 Mar 2016 22:26:36 +0100
Subject: [R] stats:sigma doesnt exist in 3.2.3
In-Reply-To: <CAOBKCDeM5boLcr4k-TOF6TtZhJOz9c4NVY69Su-ctP-iH7jXuQ@mail.gmail.com>
References: <CAOBKCDeM5boLcr4k-TOF6TtZhJOz9c4NVY69Su-ctP-iH7jXuQ@mail.gmail.com>
Message-ID: <56DDF20C.7060203@statistik.tu-dortmund.de>



On 07.03.2016 21:46, Adam Sanders wrote:
> I am trying to use a package that uses the package car which uses sigma in
> the stats package, but apparently my version of the stats package doesn?t
> contain the function sigma. How can I go about fixing this?
>
>
>
> Thanks
>
>
>
> Error : object ?sigma? is not exported by 'namespace:stats'
>
> In addition: Warning messages:
>
> 1: package ?car? was built under R version 3.3.0


Hmm, install package car from sources or use a binary that was built for 
R-2.3.2 ather than 3.3.0.

Best,
Uwe Ligges

>
> 2: replacing previous import by ?stats::sigma? when loading ?pbkrtest?
>
> Error: package or namespace load failed for ?car?
>
>
>
>
>
> SessionInfo:
>
> R version 3.2.3 (2015-12-10)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
>
>
>
> locale:
>
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
>
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
>
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> other attached packages:
>
> [1] JGR_1.7-16    iplots_1.1-7  JavaGD_0.6-1  rJava_0.9-8   ggplot2_2.0.0
> png_0.1-7
>
>
>
> loaded via a namespace (and not attached):
>
> [1] Rcpp_0.12.3      splines_3.2.3    MASS_7.3-45      munsell_0.4.3
> colorspace_1.2-6 lattice_0.20-33  minqa_1.2.4
>
>   [8] plyr_1.8.3       tools_3.2.3      nnet_7.3-11      parallel_3.2.3
> grid_3.2.3       gtable_0.1.2     nlme_3.1-124
>
> [15] lme4_1.1-10      Matrix_1.2-3     nloptr_1.0.4     scales_0.3.0
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Mon Mar  7 22:27:06 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 7 Mar 2016 22:27:06 +0100
Subject: [R] Error loading object in stats package
In-Reply-To: <6b1eb815c3444ddbbf6480e0941e8226@DM2PR42MB111.048d.mgd.msft.net>
References: <6b1eb815c3444ddbbf6480e0941e8226@DM2PR42MB111.048d.mgd.msft.net>
Message-ID: <56DDF22A.4060900@statistik.tu-dortmund.de>

See my answer to your other message.

Best,
Uwe Ligges


On 07.03.2016 21:34, a.sanders at navitaire.com wrote:
> I am trying to use a package that uses the package car which uses sigma in the stats package, but apparently my version of the stats package doesn't contain the function sigma. How can I go about fixing this?
>
> Thanks
>
>
> Error : object 'sigma' is not exported by 'namespace:stats'
>
> In addition: Warning messages:
>
> 1: package 'car' was built under R version 3.3.0
>
> 2: replacing previous import by 'stats::sigma' when loading 'pbkrtest'
>
> Error: package or namespace load failed for 'car'
>
>
> SessionInfo:
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] JGR_1.7-16    iplots_1.1-7  JavaGD_0.6-1  rJava_0.9-8   ggplot2_2.0.0 png_0.1-7
>
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.3      splines_3.2.3    MASS_7.3-45      munsell_0.4.3    colorspace_1.2-6 lattice_0.20-33  minqa_1.2.4
>   [8] plyr_1.8.3       tools_3.2.3      nnet_7.3-11      parallel_3.2.3   grid_3.2.3       gtable_0.1.2     nlme_3.1-124
> [15] lme4_1.1-10      Matrix_1.2-3     nloptr_1.0.4     scales_0.3.0
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Mar  7 22:44:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 7 Mar 2016 13:44:44 -0800
Subject: [R] Error loading object in stats package
In-Reply-To: <6b1eb815c3444ddbbf6480e0941e8226@DM2PR42MB111.048d.mgd.msft.net>
References: <6b1eb815c3444ddbbf6480e0941e8226@DM2PR42MB111.048d.mgd.msft.net>
Message-ID: <9EADF73A-5D80-471D-96A9-1A640078F2CD@comcast.net>


> On Mar 7, 2016, at 12:34 PM, <a.sanders at navitaire.com> <a.sanders at navitaire.com> wrote:
> 
> I am trying to use a package that uses the package car which uses sigma in the stats package, but apparently my version of the stats package doesn't contain the function sigma. How can I go about fixing this?
> 
> Thanks
> 
> 
> Error : object 'sigma' is not exported by 'namespace:stats'
> 
> In addition: Warning messages:
> 
> 1: package 'car' was built under R version 3.3.0
> 
> 2: replacing previous import by 'stats::sigma' when loading 'pbkrtest'
> 
> Error: package or namespace load failed for 'car'
> 

If you only provide the error message and not the code or a description of hte actions that lead to the error, you can only get speculation. (There is no function `sigma` in the stats package, although based on this exchange in R help that is about to change.)

> Dec 11, 2015; 12:24pmRe: Updating Package Fails: Help on How to Fix Needed
> 
> 3789 posts
> In reply to this post by William Dunlap
> On 11/12/2015 2:36 PM, William Dunlap wrote: 
> > stats::sigma was added to R recently.  It is is R-devel now, I don't know 
> > about yesterday's R-3.2.3. 
> 
> As Rich saw, it's not.  pbkrtest should have "Depends: R (>= 3.3.0)" 
> instead of "Depends: R (>= 3.0.0)" in its DESCRIPTION. 
> You can see it failed tests on CRAN. 
> 
> Duncan Murdoch
--- end quoted material from Dec posting


> 
> SessionInfo:
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] JGR_1.7-16    iplots_1.1-7  JavaGD_0.6-1  rJava_0.9-8   ggplot2_2.0.0 png_0.1-7
> 
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.3      splines_3.2.3    MASS_7.3-45      munsell_0.4.3    colorspace_1.2-6 lattice_0.20-33  minqa_1.2.4
> [8] plyr_1.8.3       tools_3.2.3      nnet_7.3-11      parallel_3.2.3   grid_3.2.3       gtable_0.1.2     nlme_3.1-124
> [15] lme4_1.1-10      Matrix_1.2-3     nloptr_1.0.4     scales_0.3.0
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gbiondizoccai at gmail.com  Tue Mar  8 00:41:54 2016
From: gbiondizoccai at gmail.com (Giuseppe Biondi Zoccai)
Date: Tue, 8 Mar 2016 00:41:54 +0100
Subject: [R] mice package
Message-ID: <CAF8hvh_KG=z3ZNbAX-KmsVb=3YRH9NF+VFvLCtup5uWuNuDowA@mail.gmail.com>

I am using the mice package to impute some missing values, and it work
nicely.
I am facing a tricky strategic question though.
Basically, I am working on predictors of myocardial infarction, with all
patients having baseline features (eg age, gender), despite a few missing
values.
Some patients have performed also a stress test, with specific continous
details (eg stress duration), but others haven't.
What should I do to capture the information associated with stress test
features?
A complete case analysis will of course exclude all those without a stress
test (roughly 50%).
Is it reasonable to impute with mice the stress features among also those
who did not undergo any stress test?
Or should I best create a factor variable such as stress_status (0- no
stress, 1-stress with low tolerance, 2-stress with high tolerance, and so
forth)?
Thanks for the help
Giuseppe

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar  8 01:33:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 7 Mar 2016 16:33:27 -0800
Subject: [R] mice package
In-Reply-To: <CAF8hvh_KG=z3ZNbAX-KmsVb=3YRH9NF+VFvLCtup5uWuNuDowA@mail.gmail.com>
References: <CAF8hvh_KG=z3ZNbAX-KmsVb=3YRH9NF+VFvLCtup5uWuNuDowA@mail.gmail.com>
Message-ID: <CAGxFJbRxhgmw=vaHzf-UTr+S4Ha8BsNmBDhbumeM6fySjX=P8A@mail.gmail.com>

While your queries certainly intersect R , they are mostly about
statistical methodology for this special kind of missing data. This list is
mostly about R programming. I think you would do better posting to a
statistics list, like stats.stackexchange.com . Advice there might bring
you back here to ask about R implementation, but that's not your current
concern.

Cheers,

Bert

On Monday, March 7, 2016, Giuseppe Biondi Zoccai <gbiondizoccai at gmail.com>
wrote:

> I am using the mice package to impute some missing values, and it work
> nicely.
> I am facing a tricky strategic question though.
> Basically, I am working on predictors of myocardial infarction, with all
> patients having baseline features (eg age, gender), despite a few missing
> values.
> Some patients have performed also a stress test, with specific continous
> details (eg stress duration), but others haven't.
> What should I do to capture the information associated with stress test
> features?
> A complete case analysis will of course exclude all those without a stress
> test (roughly 50%).
> Is it reasonable to impute with mice the stress features among also those
> who did not undergo any stress test?
> Or should I best create a factor variable such as stress_status (0- no
> stress, 1-stress with low tolerance, 2-stress with high tolerance, and so
> forth)?
> Thanks for the help
> Giuseppe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Tue Mar  8 01:47:21 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 8 Mar 2016 00:47:21 +0000 (UTC)
Subject: [R] Extract every 2 element for a list which are not equal in length
References: <633509595.5638722.1457398041789.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <633509595.5638722.1457398041789.JavaMail.yahoo@mail.yahoo.com>

Hi,

a <- c(1:5)b <- c(1:3)
c <- 1
d <- 5
e <- list(a,b,c,d)

# To extract every 1st element 
lapply(e,"[[",1)

## Out-put 
[[1]] 
[1] 1 

[[2]] 
[1] 1 

[[3]] 
[1] 1 

[[4]] 
[1] 5
 
#To extract every 2nd element (Need help in this case)
lapply(e,"[[",2)

## Expected outcome 
[[1]] 
[1] 2 

[[2]] 
[1] 2 

[[3]] 
[1] NA 

[[4]] 
[1] NA 



Any help will be appreciated . Thanks 


Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com


From drjimlemon at gmail.com  Tue Mar  8 03:00:34 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 8 Mar 2016 13:00:34 +1100
Subject: [R] Extract every 2 element for a list which are not equal in
	length
In-Reply-To: <633509595.5638722.1457398041789.JavaMail.yahoo@mail.yahoo.com>
References: <633509595.5638722.1457398041789.JavaMail.yahoo.ref@mail.yahoo.com>
	<633509595.5638722.1457398041789.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fUZqW6mwY8f9F-=oC382oTLhsbggqe+a3toVWyfHxa-mg@mail.gmail.com>

Hi Tanvir,
I think what you want is:

lapply(e,"[",1)
lapply(e,"[",2)

Jim


On Tue, Mar 8, 2016 at 11:47 AM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> a <- c(1:5)b <- c(1:3)
> c <- 1
> d <- 5
> e <- list(a,b,c,d)
>
> # To extract every 1st element
> lapply(e,"[[",1)
>
> ## Out-put
> [[1]]
> [1] 1
>
> [[2]]
> [1] 1
>
> [[3]]
> [1] 1
>
> [[4]]
> [1] 5
>
> #To extract every 2nd element (Need help in this case)
> lapply(e,"[[",2)
>
> ## Expected outcome
> [[1]]
> [1] 2
>
> [[2]]
> [1] 2
>
> [[3]]
> [1] NA
>
> [[4]]
> [1] NA
>
>
>
> Any help will be appreciated . Thanks
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jorgeivanvelez at gmail.com  Tue Mar  8 03:04:30 2016
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Mon, 7 Mar 2016 21:04:30 -0500
Subject: [R] Extract every 2 element for a list which are not equal in
	length
In-Reply-To: <633509595.5638722.1457398041789.JavaMail.yahoo@mail.yahoo.com>
References: <633509595.5638722.1457398041789.JavaMail.yahoo.ref@mail.yahoo.com>
	<633509595.5638722.1457398041789.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKL8G3EzHvYGL=R8vA0abN59DjA2G8rwSdSWykfY0_w8pvf9qQ@mail.gmail.com>

Dear Mohammad,
What's wrong with the result?
Best,
Jorge.-

On Monday, March 7, 2016, Mohammad Tanvir Ahamed via R-help <
r-help at r-project.org> wrote:

> Hi,
>
> a <- c(1:5)b <- c(1:3)
> c <- 1
> d <- 5
> e <- list(a,b,c,d)
>
> # To extract every 1st element
> lapply(e,"[[",1)
>
> ## Out-put
> [[1]]
> [1] 1
>
> [[2]]
> [1] 1
>
> [[3]]
> [1] 1
>
> [[4]]
> [1] 5
>
> #To extract every 2nd element (Need help in this case)
> lapply(e,"[[",2)
>
> ## Expected outcome
> [[1]]
> [1] 2
>
> [[2]]
> [1] 2
>
> [[3]]
> [1] NA
>
> [[4]]
> [1] NA
>
>
>
> Any help will be appreciated . Thanks
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com <javascript:;>
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sent from my phone. Please excuse my brevity and misspelling.

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Tue Mar  8 03:27:04 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 8 Mar 2016 02:27:04 +0000 (UTC)
Subject: [R] Extract every 2 element for a list which are not equal in
 length
In-Reply-To: <CA+8X3fUZqW6mwY8f9F-=oC382oTLhsbggqe+a3toVWyfHxa-mg@mail.gmail.com>
References: <CA+8X3fUZqW6mwY8f9F-=oC382oTLhsbggqe+a3toVWyfHxa-mg@mail.gmail.com>
Message-ID: <1775333935.5594310.1457404024501.JavaMail.yahoo@mail.yahoo.com>

Hi Jim,
 
Thanks . Some how i have messed up mu lapply function.
Worked upon restart. 
 
Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Jim Lemon <drjimlemon at gmail.com>
To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Cc: R-help Mailing List <r-help at r-project.org>
Sent: Tuesday, 8 March 2016, 3:00
Subject: Re: [R] Extract every 2 element for a list which are not equal in length

Hi Tanvir,
I think what you want is:

lapply(e,"[",1)
lapply(e,"[",2)

Jim



On Tue, Mar 8, 2016 at 11:47 AM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> a <- c(1:5)b <- c(1:3)
> c <- 1
> d <- 5
> e <- list(a,b,c,d)
>
> # To extract every 1st element
> lapply(e,"[[",1)
>
> ## Out-put
> [[1]]
> [1] 1
>
> [[2]]
> [1] 1
>
> [[3]]
> [1] 1
>
> [[4]]
> [1] 5
>
> #To extract every 2nd element (Need help in this case)
> lapply(e,"[[",2)
>
> ## Expected outcome
> [[1]]
> [1] 2
>
> [[2]]
> [1] 2
>
> [[3]]
> [1] NA
>
> [[4]]
> [1] NA
>
>
>
> Any help will be appreciated . Thanks
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mashranga at yahoo.com  Tue Mar  8 03:27:38 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 8 Mar 2016 02:27:38 +0000 (UTC)
Subject: [R] Extract every 2 element for a list which are not equal in
 length
In-Reply-To: <CAKL8G3EzHvYGL=R8vA0abN59DjA2G8rwSdSWykfY0_w8pvf9qQ@mail.gmail.com>
References: <CAKL8G3EzHvYGL=R8vA0abN59DjA2G8rwSdSWykfY0_w8pvf9qQ@mail.gmail.com>
Message-ID: <1909077641.5500212.1457404058116.JavaMail.yahoo@mail.yahoo.com>

Hi Jorge,?
Thanks . Some how i have messed up mu lapply function.Worked upon restart.??Tanvir Ahamed 
   G?teborg, Sweden     |  mashranga at yahoo.com 

      From: Jorge I Velez <jorgeivanvelez at gmail.com>
 To: Mohammad Tanvir Ahamed <mashranga at yahoo.com> 
Cc: R-help Mailing List <r-help at r-project.org>
 Sent: Tuesday, 8 March 2016, 3:04
 Subject: Re: [R] Extract every 2 element for a list which are not equal in length
   
Dear Mohammad,What's wrong with?the result?Best,Jorge.-

On Monday, March 7, 2016, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:

Hi,

a <- c(1:5)b <- c(1:3)
c <- 1
d <- 5
e <- list(a,b,c,d)

# To extract every 1st element
lapply(e,"[[",1)

## Out-put
[[1]]
[1] 1

[[2]]
[1] 1

[[3]]
[1] 1

[[4]]
[1] 5

#To extract every 2nd element (Need help in this case)
lapply(e,"[[",2)

## Expected outcome
[[1]]
[1] 2

[[2]]
[1] 2

[[3]]
[1] NA

[[4]]
[1] NA



Any help will be appreciated . Thanks


Tanvir Ahamed
G?teborg, Sweden? |? mashranga at yahoo.com

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


-- 
Sent from my phone. Please excuse my brevity and misspelling. 


  
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Mar  8 09:34:19 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 8 Mar 2016 09:34:19 +0100
Subject: [R] Wooden Christmas Tree freezing when reading in files in El
	Capitan OS X
In-Reply-To: <CAO9PUv-un_ky95D1Q8cBzJMW47efnGLCQ10eQ5gKArfptRm0HA@mail.gmail.com>
References: <CAO9PUv__Na7Xpdvi8gseZXgfz_JMH7Vvit6xJvHHQPe5S9SQPA@mail.gmail.com>
	<CAO9PUv9oA-H5atP2tBcnJgM1bZvkpOzPOMZ7an9jdRC6L-7qKQ@mail.gmail.com>
	<99BB1813-DFE0-443D-ABB5-8AB3F1201545@gmail.com>
	<CAO9PUv-un_ky95D1Q8cBzJMW47efnGLCQ10eQ5gKArfptRm0HA@mail.gmail.com>
Message-ID: <0A704ABC-86AA-4EC1-A934-AA74CA8FE43D@gmail.com>

(Please keep r-help in the loop. Rerouting it there.)

So not read.csv, but Finder interaction is the issue, and you have the obvious workaround. I believe something like this was fixed in the patch versions, but you might as well wait for 3.2.4 on Thursday and retry.

-pd

> On 08 Mar 2016, at 00:58 , Lauri Torgerson <lauritorgerson at gmail.com> wrote:
> 
> My data are in a csv file. I have tried working both in the gui (sending commands over) and directly in the R console. I have used read.csv(file.choose()). I just tried typing read.csv("file name") directly into the console after setting the working directory and that worked.  I have also tried to browse to read in data files using the File->Source File menu but that caused it to freeze. I think I'll just keep R open for the duration of this project so that I don't run into this program again... But for the future, I need to figure out why it keeps freezing. Thank you!
> 
> 
> On Saturday, March 5, 2016, peter dalgaard <pdalgd at gmail.com> wrote:
> Explain _exactly_ what you mean by "try to read in files using read.csv" and "reading in the file different ways". Which commands? Is the GUI involved? Otherwise we cannot help.
> 
> 
> 
> > On 05 Mar 2016, at 17:58 , Lauri Torgerson <lauritorgerson at gmail.com> wrote:
> >
> > Hello everyone. Thanks in advance for your patience with my question. I
> > recently upgraded my operating system to El Capitan and then upgraded R to
> > 3.2.3 (Wooden Christmas Tree). I also installed XQuartz. My problem is that
> > when I try to read in files using read.csv, R freezes. I have to force quit
> > every time. I've tried to uninstall/reinstall. I've tried older versions of
> > R. I've tried working in the R.app and typing directly into the R console.
> > I've tried clearing the work history, resetting the working directory, and
> > reading in the file different ways. Has anyone dealt with this and found a
> > solution? Thanks!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sebastien.moretti at unil.ch  Tue Mar  8 12:01:35 2016
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Tue, 8 Mar 2016 12:01:35 +0100
Subject: [R] .Call works in R 2 not in R 3
Message-ID: <56DEB10F.3080204@unil.ch>

Hi

I inherited a R package done in 2004 that works perfectly in R 2.15.1 
and before, but not in R 3.2.2 ( >= 3).

I have already fixed issues with namespace for functions in R 3 but 
maybe not all of them.

Here is the error message:
Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
"R_cutree" not available for .Call() for package "stats"


Thanks for your help

-- 
S?bastien Moretti


From lauritorgerson at gmail.com  Tue Mar  8 12:43:33 2016
From: lauritorgerson at gmail.com (Lauri Torgerson)
Date: Tue, 8 Mar 2016 06:43:33 -0500
Subject: [R] Wooden Christmas Tree freezing when reading in files in El
 Capitan OS X
In-Reply-To: <0A704ABC-86AA-4EC1-A934-AA74CA8FE43D@gmail.com>
References: <CAO9PUv__Na7Xpdvi8gseZXgfz_JMH7Vvit6xJvHHQPe5S9SQPA@mail.gmail.com>
	<CAO9PUv9oA-H5atP2tBcnJgM1bZvkpOzPOMZ7an9jdRC6L-7qKQ@mail.gmail.com>
	<99BB1813-DFE0-443D-ABB5-8AB3F1201545@gmail.com>
	<CAO9PUv-un_ky95D1Q8cBzJMW47efnGLCQ10eQ5gKArfptRm0HA@mail.gmail.com>
	<0A704ABC-86AA-4EC1-A934-AA74CA8FE43D@gmail.com>
Message-ID: <CAO9PUv-45oByk1VfXZw+XVGbRf4XgxAcW21fCPuiXaMyMggAcg@mail.gmail.com>

Thank you!

On Tuesday, March 8, 2016, peter dalgaard <pdalgd at gmail.com> wrote:

> (Please keep r-help in the loop. Rerouting it there.)
>
> So not read.csv, but Finder interaction is the issue, and you have the
> obvious workaround. I believe something like this was fixed in the patch
> versions, but you might as well wait for 3.2.4 on Thursday and retry.
>
> -pd
>
> > On 08 Mar 2016, at 00:58 , Lauri Torgerson <lauritorgerson at gmail.com
> <javascript:;>> wrote:
> >
> > My data are in a csv file. I have tried working both in the gui (sending
> commands over) and directly in the R console. I have used
> read.csv(file.choose()). I just tried typing read.csv("file name") directly
> into the console after setting the working directory and that worked.  I
> have also tried to browse to read in data files using the File->Source File
> menu but that caused it to freeze. I think I'll just keep R open for the
> duration of this project so that I don't run into this program again... But
> for the future, I need to figure out why it keeps freezing. Thank you!
> >
> >
> > On Saturday, March 5, 2016, peter dalgaard <pdalgd at gmail.com
> <javascript:;>> wrote:
> > Explain _exactly_ what you mean by "try to read in files using read.csv"
> and "reading in the file different ways". Which commands? Is the GUI
> involved? Otherwise we cannot help.
> >
> >
> >
> > > On 05 Mar 2016, at 17:58 , Lauri Torgerson <lauritorgerson at gmail.com
> <javascript:;>> wrote:
> > >
> > > Hello everyone. Thanks in advance for your patience with my question. I
> > > recently upgraded my operating system to El Capitan and then upgraded
> R to
> > > 3.2.3 (Wooden Christmas Tree). I also installed XQuartz. My problem is
> that
> > > when I try to read in files using read.csv, R freezes. I have to force
> quit
> > > every time. I've tried to uninstall/reinstall. I've tried older
> versions of
> > > R. I've tried working in the R.app and typing directly into the R
> console.
> > > I've tried clearing the work history, resetting the working directory,
> and
> > > reading in the file different ways. Has anyone dealt with this and
> found a
> > > solution? Thanks!
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE
> and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk <javascript:;>  Priv: PDalgd at gmail.com
> <javascript:;>
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk <javascript:;>  Priv: PDalgd at gmail.com <javascript:;>
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Mar  8 14:46:25 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 8 Mar 2016 14:46:25 +0100
Subject: [R] .Call works in R 2 not in R 3
In-Reply-To: <56DEB10F.3080204@unil.ch>
References: <56DEB10F.3080204@unil.ch>
Message-ID: <56DED7B1.3030703@statistik.tu-dortmund.de>



On 08.03.2016 12:01, Sebastien Moretti wrote:
> Hi
>
> I inherited a R package done in 2004 that works perfectly in R 2.15.1
> and before, but not in R 3.2.2 ( >= 3).
>
> I have already fixed issues with namespace for functions in R 3 but
> maybe not all of them.
>
> Here is the error message:
> Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
> "R_cutree" not available for .Call() for package "stats"

Why do you .Call() into another package? Rather use the API.

Best,
Uwe Ligges



>
>
> Thanks for your help
>


From sebastien.moretti at unil.ch  Tue Mar  8 14:55:41 2016
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Tue, 8 Mar 2016 14:55:41 +0100
Subject: [R] .Call works in R 2 not in R 3
In-Reply-To: <56DED7B1.3030703@statistik.tu-dortmund.de>
References: <56DEB10F.3080204@unil.ch>
	<56DED7B1.3030703@statistik.tu-dortmund.de>
Message-ID: <56DED9DD.1080507@unil.ch>

>> Hi
>>
>> I inherited a R package done in 2004 that works perfectly in R 2.15.1
>> and before, but not in R 3.2.2 ( >= 3).
>>
>> I have already fixed issues with namespace for functions in R 3 but
>> maybe not all of them.
>>
>> Here is the error message:
>> Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
>> "R_cutree" not available for .Call() for package "stats"
>
> Why do you .Call() into another package? Rather use the API.

Let's say that I am far from a R master.
I never use .Call() myself.

I want the code works again in R >= 3 because R support for R 2 will 
soon be stopped in my institute.
When the code will work again, I could change internals by comparing 
results with R 2 and R 3.

> Best,
> Uwe Ligges
>
>>
>> Thanks for your help

--
S?bastien Moretti


From ligges at statistik.tu-dortmund.de  Tue Mar  8 14:59:31 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 8 Mar 2016 14:59:31 +0100
Subject: [R] .Call works in R 2 not in R 3
In-Reply-To: <56DED9DD.1080507@unil.ch>
References: <56DEB10F.3080204@unil.ch>
	<56DED7B1.3030703@statistik.tu-dortmund.de> <56DED9DD.1080507@unil.ch>
Message-ID: <56DEDAC3.1050703@statistik.tu-dortmund.de>



On 08.03.2016 14:55, Sebastien Moretti wrote:
>>> Hi
>>>
>>> I inherited a R package done in 2004 that works perfectly in R 2.15.1
>>> and before, but not in R 3.2.2 ( >= 3).
>>>
>>> I have already fixed issues with namespace for functions in R 3 but
>>> maybe not all of them.
>>>
>>> Here is the error message:
>>> Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
>>> "R_cutree" not available for .Call() for package "stats"
>>
>> Why do you .Call() into another package? Rather use the API.
>
> Let's say that I am far from a R master.
> I never use .Call() myself.
>
> I want the code works again in R >= 3 because R support for R 2 will
> soon be stopped in my institute.
> When the code will work again, I could change internals by comparing
> results with R 2 and R 3.


Well, the error message above suggets you have R code that uses .Call() 
not compatible with the R version you are using. I do not know where the 
.Call() comes from, ehnce your turn to find it out. You haven?t given 
any other information, not even a traceback().

Best,
Uwe Ligges



>
>> Best,
>> Uwe Ligges
>>
>>>
>>> Thanks for your help
>
> --
> S?bastien Moretti
>


From erich.neuwirth at univie.ac.at  Tue Mar  8 15:13:34 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 8 Mar 2016 15:13:34 +0100
Subject: [R] .Call works in R 2 not in R 3
In-Reply-To: <56DED9DD.1080507@unil.ch>
References: <56DEB10F.3080204@unil.ch>
	<56DED7B1.3030703@statistik.tu-dortmund.de>
	<56DED9DD.1080507@unil.ch>
Message-ID: <9307D691-7E27-4A9E-9B2B-87FE150967B6@univie.ac.at>

cutree is a function available in stats.
So it might be worth a try to just replace

.Call("R_cutree", tree$merge, k, PACKAGE = "stats?)

by

cutree(tree$merge,k)

and see what happens.

checking the source of cutree shows the following call

    ans <- .Call(C_cutree, tree$merge, k)

so replacing R_cutree by C_cutree also might be an option.
But, of course as Uwe recommended,
using a plain R call and not using .Call is the preferred solution.


> On Mar 8, 2016, at 14:55, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
> 
>>> Hi
>>> 
>>> I inherited a R package done in 2004 that works perfectly in R 2.15.1
>>> and before, but not in R 3.2.2 ( >= 3).
>>> 
>>> I have already fixed issues with namespace for functions in R 3 but
>>> maybe not all of them.
>>> 
>>> Here is the error message:
>>> Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
>>> "R_cutree" not available for .Call() for package "stats"
>> 
>> Why do you .Call() into another package? Rather use the API.
> 
> Let's say that I am far from a R master.
> I never use .Call() myself.
> 
> I want the code works again in R >= 3 because R support for R 2 will soon be stopped in my institute.
> When the code will work again, I could change internals by comparing results with R 2 and R 3.
> 
>> Best,
>> Uwe Ligges
>> 
>>> 
>>> Thanks for your help
> 
> --
> S?bastien Moretti
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160308/70835d1c/attachment.bin>

From jdnewmil at dcn.davis.ca.us  Tue Mar  8 16:20:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 08 Mar 2016 07:20:38 -0800
Subject: [R] using factor variable in the "DO" function
In-Reply-To: <CAFpsATbOEUwB_2-VXN8JXL_YgB=5MCs2nsS4JuFb_mQCsBLAPw@mail.gmail.com>
References: <CAFpsATbOEUwB_2-VXN8JXL_YgB=5MCs2nsS4JuFb_mQCsBLAPw@mail.gmail.com>
Message-ID: <78E56C93-E347-4E8F-B994-6BE9F751A078@dcn.davis.ca.us>

You have competing non-standard evaluation tools in play. I would decouple them with a function (untested):

my fit <- function( DF ) { 
    data.frame( HOSP_NRD = .$HOSP_NRD[1]
        , fitHosp = lm(log(y)~ log(x)+I(log(x)^2)+NCHRONIC+AGE+sex
      , data=DF)
      )
}
dfhosp <- ( dat.2.wide.sub
  %>% group_by(HOSP_NRD)
  %>% do( my_fit( . ) )
-- 
Sent from my phone. Please excuse my brevity.

On March 7, 2016 10:48:28 AM PST, Veerappa Chetty <chettyvk at gmail.com> wrote:
>Hi,
>
>The following call does not work:
>
>dfhosp=dat.2.wide.sub %>% group_by(HOSP_NRD)%>%
>  do(fitHosp=lm(log(y)~ log(x)+I(log(x)^2)+NCHRONIC+AGE+sex ,data=.))
>
>Error in `$<-.data.frame`(`*tmp*`, "sex", value = integer(0)) :
>  replacement has 0 rows, data has 25174
>
>When I use "sex" as a binary variable with values "0" and "1", it
>works.
>
>Is there a way to use factor in this call?
>Thanks.
>
>V.K.Chetty
>
>-- 
>Professor of Family Medicine
>Boston University
>Tel: 617-414-6221, Fax:617-414-3345
>emails: chettyvk at gmail.com,vchetty at bu.edu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Tue Mar  8 16:54:38 2016
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 8 Mar 2016 15:54:38 +0000
Subject: [R] Revolutions blog: February 2016 roundup
Message-ID: <DM2PR0301MB0848A0EA1D4CDA2F7695AFD0C8B20@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of February:

A tutorial on presenting interactive versions of R maps in PowerBI:
http://blog.revolutionanalytics.com/2016/02/r-maps-in-powerbi.html

An animation of Japan's population pyramid through 2050 based on US Census Bureau demographic projections:
http://blog.revolutionanalytics.com/2016/02/japans-ageing-population-animated-with-r.html

Interactive visualizations of multivariate data in R with the threejs package:
http://blog.revolutionanalytics.com/2016/02/multivariate_data_with_r.html

New Zealand's tourism ministry uses R and Shiny to create a public dashboard exploring the economic impact of tourism:
http://blog.revolutionanalytics.com/2016/02/explore-new-zealands-tourist-industry-with-r-and-shiny.html

Microsoft uses R to forecast usage of the Xbox One gaming system:
http://blog.revolutionanalytics.com/2016/02/xbox_usage_trends_r.html

R scores highly in the latest Tiobe and Redmonk language rankings:
http://blog.revolutionanalytics.com/2016/02/latest-redmonk-and-tiobe-language-rankings-for-r.html

A minor update to Microsoft R Open 3.2.3: http://blog.revolutionanalytics.com/2016/02/microsoft-r-open-323-update.html

Applications from the Bay Area R User Group: simulating poker tournaments, recommending movies, predicting the Oscars,
and analyzing electronic medical records:
http://blog.revolutionanalytics.com/2016/02/bay-area-user-group-lightning-talks.html

Lionel Henry's proposals to improve the syntax of R:
http://blog.revolutionanalytics.com/2016/02/new-syntax-proposed-for-r-language.html

Repositories of talks given to various R user groups: http://blog.revolutionanalytics.com/2016/02/more_rug_sites.html

RStudio now supports user-created add-ins:
http://blog.revolutionanalytics.com/2016/02/you-can-now-extend-rstudio-with-add-ins.html

Replay of the webinar presented by Derek Norton on Microsoft R Server:
http://blog.revolutionanalytics.com/2016/02/using-microsoft-r-server-to-address-scalability-issues-in-r.html

Accessing data in SQL Server on Azure with R: http://blog.revolutionanalytics.com/2016/02/ms_sql_azure.html

A look at the R community in Poland: http://blog.revolutionanalytics.com/2016/02/r-user-groups-in-poland.html

A tutorial on credit card fraud detection using R and SQL Server:
http://blog.revolutionanalytics.com/2016/02/data-science-deep-dive-with-revoscaler.html

A replay (with slides) of a recent webinar on Microsoft R Open:
http://blog.revolutionanalytics.com/2016/02/introducing-microsoft-r-open-replay-and-slides.html

How to use Microsoft R Open with RStudio: http://blog.revolutionanalytics.com/2016/02/using-mro-with-rstudio.html

The world's longest commercial flights, mapped with R:
http://blog.revolutionanalytics.com/2016/02/mapping-the-worlds-longest-plane-fights.html

How to use PostgresSQL with R: http://blog.revolutionanalytics.com/2016/02/postgressql_r.html

Replay of a presentation by Max Kuhn on predictive modeling with R and the caret package:
http://blog.revolutionanalytics.com/2016/02/applied-predictive-modeling.html

General interest stories (not related to R) in the past month included: performing accents
(http://blog.revolutionanalytics.com/2016/02/because-its-friday-accents.html), realizing a video game world
(http://blog.revolutionanalytics.com/2016/02/because-its-friday-networking-in-destiny.html), combining dance and CGI
(http://blog.revolutionanalytics.com/2016/02/using-microsoft-r-server-to-address-scalability-issues-in-r.html), and a
mysterious rotating illusion
(http://blog.revolutionanalytics.com/2016/02/because-its-friday-the-mysterious-rotating-woman.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html
If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From justacec at gmail.com  Tue Mar  8 11:01:43 2016
From: justacec at gmail.com (Justace Clutter)
Date: Tue, 8 Mar 2016 05:01:43 -0500
Subject: [R] Slow CRAN Mirror Action
Message-ID: <CANimRt76XYDsZwBU_MwDOSZ0=+gSK9t2PB-DMF=PtMEzx027Lw@mail.gmail.com>

I have been creating a local mirror of the CRAN for my works servers.
After a review of the CRAN mirror literature, I settled on the following
command to perform the mirror:

rsync -rtlzv --delete --exclude-from u:\CRANRSYNCFilterRules
cran.r-project.org::CRAN .

Where the CRANRSYNCFilterRules file has the following contents:

///// BEGIN SNIP
- bin/linux
- bin/macos
- bin/macosx
- bin/windows/base/old
#- bin/windows/contrib/*
- bin/windows/contrib/1*
- bin/windows/contrib/2*
- bin/windows/contrib/3.0
- bin/windows/contrib/3.1
+ bin/
+ bin/windows/
+ bin/windows/contrib/
+ bin/windows/contrib/3.2/
+ bin/windows/contrib/3.2/***
///// END SNIP

What I find is that the command tends to redownload a lot of files and I
can never seem to get past the windows/contrib/3.2 directory because I have
to leave work and go home for the day after 7 hours.  Is there something
incorrect with my rsync command which is forcing the redownload of a lot of
packages?  Is there a way to speed this process up?  Thank you for any help.

Version Information: Just in case people feel they need to know
OS: Windows 7
rsync: version 3.0.9  protocol version 30
Network: hardwired to company LAN which has some form of firewall/proxy to
the real internet

Justace

	[[alternative HTML version deleted]]


From st.charalampopoulos at gmail.com  Tue Mar  8 12:58:29 2016
From: st.charalampopoulos at gmail.com (Stefanos charalampopoulos)
Date: Tue, 8 Mar 2016 12:58:29 +0100
Subject: [R] R-package rmgarch
Message-ID: <CAMgciMG+UvD0Edg+iW2BkHOoGYxa3WCWGiEXgLT8gPNVaW2+Hw@mail.gmail.com>

Hi all,

The following questions is regarding to the statistical software R.
Specifically refers to the rmgarch package for time series analysis.

I have a dataset of [1520,34]. I am trying to fit a dcc. I am using
multispec because i want to include many univariate (c(spec1,spec2,spec3)
etc)models to have the comparison as it is done in Cappiello et all (2006).
When after that i am using multifit the model collapses resulting in

error :speclist length not equal to data length.

code: spec1 = ugarchspec(mean.model = list(armaOrder = c(1, 1),include.mean
= TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'),
distribution.model = 'norm')

spec2 = ugarchspec(mean.model = list(armaOrder = c(1, 1),include.mean =
TRUE), variance.model = list(garchOrder = c(1,1), model = 'sGARCH'),
distribution.model = 'norm')

 spec3 = ugarchspec(mean.model = list(armaOrder = c(1, 1),include.mean =
TRUE), variance.model = list(garchOrder = c(1,1), model = 'sGARCH'),
distribution.model = 'norm')

spec4 = ugarchspec(mean.model = list(armaOrder = c(1, 1),include.mean =
TRUE), variance.model = list(garchOrder = c(1,1), model = 'gjrGARCH'),
distribution.model = 'norm')

mspec = multispec( replicate(8.5,c( spec1, spec2, spec3, spec4 )))###i am
using 8.5 to have 8.5x4=34.

cl = makePSOCKcluster(34)

multf = multifit(mspec, data1, cluster = cl,)

Any suggestions?

Thanks in advance,

Best,

Stefanos

	[[alternative HTML version deleted]]


From michael.gang.peng at gmail.com  Tue Mar  8 20:35:46 2016
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Tue, 8 Mar 2016 14:35:46 -0500
Subject: [R] How to avoid endless loop in shiny
Message-ID: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>

Hi,

I added two sliderInput into the app with package "shiny": sliderA and
sliderB. The values in the two sliders are correlated. If I change sliderA,
I used updateSliderInput to update the value in sliderB. And also If I
change sliderB, I used  updateSliderInput to update the value in slideA.

The problem is it is an endless loop. How can I use updateSliderInput
without sending message to update the other slider.

Thank.

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Mar  8 20:39:10 2016
From: HDoran at air.org (Doran, Harold)
Date: Tue, 8 Mar 2016 19:39:10 +0000
Subject: [R] How to avoid endless loop in shiny
In-Reply-To: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>
References: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686012BB7D867@DC1VEX10MB01.air.org>

Michael

It is not possible to answer this question without seeing reproducible code. More importantly, it is better to ask Shiny-related questions on stackoverflow using the Shiny tag or on the Shiny google group.



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Peng
Sent: Tuesday, March 08, 2016 2:36 PM
To: r-help at r-project.org
Subject: [R] How to avoid endless loop in shiny

Hi,

I added two sliderInput into the app with package "shiny": sliderA and sliderB. The values in the two sliders are correlated. If I change sliderA, I used updateSliderInput to update the value in sliderB. And also If I change sliderB, I used  updateSliderInput to update the value in slideA.

The problem is it is an endless loop. How can I use updateSliderInput without sending message to update the other slider.

Thank.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marna.wagley at gmail.com  Tue Mar  8 22:26:25 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Tue, 8 Mar 2016 13:26:25 -0800
Subject: [R] replace text in table R?
Message-ID: <CAMwU6B1bvhikvhrp8g0HmNtHZU0EMNnVtZ0t9oCF_RKkjC14vA@mail.gmail.com>

Hi R Users,
I have been struggling to replace texts in a table by new text. but it
seems crazy as of I am doing it manually in R. I have very big files and
some of the text has to be replaced by another class based on another file
if the name corresponds. I was able to perform following example but it
should be easier if there is a loop. Any suggestions on making a loop for
this example?

Here is the example how I did. I want to assign class into dat1 based on
dat2 table.

dat1<-structure(list(ID = structure(1:8, .Label = c("X127", "X128",
"X129", "X130", "X131", "X132", "X133", "X134"), class = "factor"),
    Name = structure(1:8, .Label = c("Site1", "Site2", "Site3",
    "Site4", "Site5", "Site6", "Site7", "Site8"), class = "factor"),
    Time1 = structure(c(4L, 2L, 3L, 5L, 1L, 1L, 4L, 5L), .Label = c("0",
    "GT", "R", "Tr", "W2"), class = "factor"), Time2 = structure(c(2L,
    1L, 4L, 2L, 1L, 3L, 4L, 1L), .Label = c("0", "GT", "MA",
    "UA"), class = "factor"), Time3 = structure(c(5L, 1L, 4L,
    4L, 2L, 3L, 3L, 1L), .Label = c("0", "GT", "R", "Tr", "Y7"
    ), class = "factor")), .Names = c("ID", "Name", "Time1",
"Time2", "Time3"), class = "data.frame", row.names = c(NA, -8L
))

dat1

dat2<-structure(list(site = structure(c(4L, 2L, 5L, 3L, 6L, 7L, 8L,
1L), .Label = c("GT", "MA", "R", "Tr", "UA", "W1", "W2", "Y7"
), class = "factor"), To.be.assinged = structure(c(1L, 2L, 3L,
1L, 4L, 4L, 1L, 2L), .Label = c("A", "B", "C", "D"), class = "factor")),
.Names = c("site",
"To.be.assinged"), class = "data.frame", row.names = c(NA, -8L
))
dat2

A2 <- as.data.frame(lapply(dat1,function(x)
if(is.character(x)|is.factor(x)) gsub("Tr","A",x) else x))
A3 <- as.data.frame(lapply(A2,function(x) if(is.character(x)|is.factor(x))
gsub("MA","B",x) else x))
A4 <- as.data.frame(lapply(A3,function(x) if(is.character(x)|is.factor(x))
gsub("UA","C",x) else x))
A5 <- as.data.frame(lapply(A4,function(x) if(is.character(x)|is.factor(x))
gsub("R","A",x) else x))
A6 <- as.data.frame(lapply(A5,function(x) if(is.character(x)|is.factor(x))
gsub("W1","D",x) else x))
A7 <- as.data.frame(lapply(A6,function(x) if(is.character(x)|is.factor(x))
gsub("W2","D",x) else x))
A8 <- as.data.frame(lapply(A7,function(x) if(is.character(x)|is.factor(x))
gsub("Y7","A",x) else x))
A9 <- as.data.frame(lapply(A8,function(x) if(is.character(x)|is.factor(x))
gsub("GT","B",x) else x))
A9

Your help is highly appreciated.
Thanks

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Mar  8 22:34:10 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 8 Mar 2016 22:34:10 +0100
Subject: [R] Slow CRAN Mirror Action
In-Reply-To: <CANimRt76XYDsZwBU_MwDOSZ0=+gSK9t2PB-DMF=PtMEzx027Lw@mail.gmail.com>
References: <CANimRt76XYDsZwBU_MwDOSZ0=+gSK9t2PB-DMF=PtMEzx027Lw@mail.gmail.com>
Message-ID: <56DF4552.9050200@statistik.tu-dortmund.de>



On 08.03.2016 11:01, Justace Clutter wrote:
> I have been creating a local mirror of the CRAN for my works servers.
> After a review of the CRAN mirror literature, I settled on the following
> command to perform the mirror:
>
> rsync -rtlzv --delete --exclude-from u:\CRANRSYNCFilterRules
> cran.r-project.org::CRAN .
>
> Where the CRANRSYNCFilterRules file has the following contents:
>
> ///// BEGIN SNIP
> - bin/linux
> - bin/macos
> - bin/macosx
> - bin/windows/base/old
> #- bin/windows/contrib/*
> - bin/windows/contrib/1*
> - bin/windows/contrib/2*
> - bin/windows/contrib/3.0
> - bin/windows/contrib/3.1
> + bin/
> + bin/windows/
> + bin/windows/contrib/
> + bin/windows/contrib/3.2/
> + bin/windows/contrib/3.2/***
> ///// END SNIP
>
> What I find is that the command tends to redownload a lot of files and I
> can never seem to get past the windows/contrib/3.2 directory because I have
> to leave work and go home for the day after 7 hours.  Is there something
> incorrect with my rsync command which is forcing the redownload of a lot of
> packages?  Is there a way to speed this process up?  Thank you for any help.
>

No, we rebuild really many packages on a daily basis. Once a depdendency 
changes you may need to build a new binary. So this is expected.

Best,
Uwe Ligges


> Version Information: Just in case people feel they need to know
> OS: Windows 7
> rsync: version 3.0.9  protocol version 30
> Network: hardwired to company LAN which has some form of firewall/proxy to
> the real internet
>
> Justace
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Tue Mar  8 22:48:25 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 8 Mar 2016 16:48:25 -0500
Subject: [R] replace text in table R?
In-Reply-To: <CAMwU6B1bvhikvhrp8g0HmNtHZU0EMNnVtZ0t9oCF_RKkjC14vA@mail.gmail.com>
References: <CAMwU6B1bvhikvhrp8g0HmNtHZU0EMNnVtZ0t9oCF_RKkjC14vA@mail.gmail.com>
Message-ID: <CAM_vju=gf_t=rbWvbK5q-sgB2+sMTesBG8ds6T79p_qsuqR4hA@mail.gmail.com>

Thanks for the complete reproducible example.

Here's one way to approach the problem; there are many others.

recodeDat <- function(x, invals, outvals) {
x <- as.character(x)
invals <- as.character(invals)
outvals <- as.character(outvals)
# a loop is the most understandable approach
for(i in seq_along(invals)) {
x[x == invals[i]] <- outvals[i]
}
# I would change the zeros to NA values
x[x == "0"] <- NA

factor(x, levels=sort(unique(outvals)))
}

dat1.recode <- dat1
dat1.recode[, 3:ncol(dat1.recode)] <- apply(dat1.recode[,
3:ncol(dat1.recode)], 2, recodeDat, invals=dat2[,1], outvals=dat2[,2])

On Tue, Mar 8, 2016 at 4:26 PM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R Users,
> I have been struggling to replace texts in a table by new text. but it
> seems crazy as of I am doing it manually in R. I have very big files and
> some of the text has to be replaced by another class based on another file
> if the name corresponds. I was able to perform following example but it
> should be easier if there is a loop. Any suggestions on making a loop for
> this example?
>
> Here is the example how I did. I want to assign class into dat1 based on
> dat2 table.
>
> dat1<-structure(list(ID = structure(1:8, .Label = c("X127", "X128",
> "X129", "X130", "X131", "X132", "X133", "X134"), class = "factor"),
>     Name = structure(1:8, .Label = c("Site1", "Site2", "Site3",
>     "Site4", "Site5", "Site6", "Site7", "Site8"), class = "factor"),
>     Time1 = structure(c(4L, 2L, 3L, 5L, 1L, 1L, 4L, 5L), .Label = c("0",
>     "GT", "R", "Tr", "W2"), class = "factor"), Time2 = structure(c(2L,
>     1L, 4L, 2L, 1L, 3L, 4L, 1L), .Label = c("0", "GT", "MA",
>     "UA"), class = "factor"), Time3 = structure(c(5L, 1L, 4L,
>     4L, 2L, 3L, 3L, 1L), .Label = c("0", "GT", "R", "Tr", "Y7"
>     ), class = "factor")), .Names = c("ID", "Name", "Time1",
> "Time2", "Time3"), class = "data.frame", row.names = c(NA, -8L
> ))
>
> dat1
>
> dat2<-structure(list(site = structure(c(4L, 2L, 5L, 3L, 6L, 7L, 8L,
> 1L), .Label = c("GT", "MA", "R", "Tr", "UA", "W1", "W2", "Y7"
> ), class = "factor"), To.be.assinged = structure(c(1L, 2L, 3L,
> 1L, 4L, 4L, 1L, 2L), .Label = c("A", "B", "C", "D"), class = "factor")),
> .Names = c("site",
> "To.be.assinged"), class = "data.frame", row.names = c(NA, -8L
> ))
> dat2
>
> A2 <- as.data.frame(lapply(dat1,function(x)
> if(is.character(x)|is.factor(x)) gsub("Tr","A",x) else x))
> A3 <- as.data.frame(lapply(A2,function(x) if(is.character(x)|is.factor(x))
> gsub("MA","B",x) else x))
> A4 <- as.data.frame(lapply(A3,function(x) if(is.character(x)|is.factor(x))
> gsub("UA","C",x) else x))
> A5 <- as.data.frame(lapply(A4,function(x) if(is.character(x)|is.factor(x))
> gsub("R","A",x) else x))
> A6 <- as.data.frame(lapply(A5,function(x) if(is.character(x)|is.factor(x))
> gsub("W1","D",x) else x))
> A7 <- as.data.frame(lapply(A6,function(x) if(is.character(x)|is.factor(x))
> gsub("W2","D",x) else x))
> A8 <- as.data.frame(lapply(A7,function(x) if(is.character(x)|is.factor(x))
> gsub("Y7","A",x) else x))
> A9 <- as.data.frame(lapply(A8,function(x) if(is.character(x)|is.factor(x))
> gsub("GT","B",x) else x))
> A9
>
> Your help is highly appreciated.
> Thanks
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From 538280 at gmail.com  Wed Mar  9 00:00:07 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Mar 2016 16:00:07 -0700
Subject: [R] How to avoid endless loop in shiny
In-Reply-To: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>
References: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>
Message-ID: <CAFEqCdwsPW+osrHJqYo1bGEGt4iUV2tNScGckwnjNTQdoPCOCw@mail.gmail.com>

You need to use `isolate` on one of the assignments so that it does
not register as an update.  Here are a few lines of code from the
server.R file for an example that I use that has a slider for r
(correlation) and another slider for r^2 and whenever one is changed,
I want the other to update:

  observe({
    updateSliderInput(session, 'r',
value=isolate(ifelse(input$r<0,-1,1))*sqrt(input$r2))
  })

  observe({
    updateSliderInput(session, 'r2', value=input$r^2)
  })


I did end up in a loop once when I happened to choose just the wrong
value and the rounding caused a jumping back and forth, but all the
other times this has worked perfectly without the endless loop.


On Tue, Mar 8, 2016 at 12:35 PM, Michael Peng
<michael.gang.peng at gmail.com> wrote:
> Hi,
>
> I added two sliderInput into the app with package "shiny": sliderA and
> sliderB. The values in the two sliders are correlated. If I change sliderA,
> I used updateSliderInput to update the value in sliderB. And also If I
> change sliderB, I used  updateSliderInput to update the value in slideA.
>
> The problem is it is an endless loop. How can I use updateSliderInput
> without sending message to update the other slider.
>
> Thank.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From santosh2005 at gmail.com  Wed Mar  9 02:19:56 2016
From: santosh2005 at gmail.com (Santosh)
Date: Tue, 8 Mar 2016 17:19:56 -0800
Subject: [R] Testing installed package of rJava in Linux
Message-ID: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>

Dear Rxperts..
I installed rJava on 64-bit Linux system and apparently it installed
without errors.However, I got the following error message when I tried to
test the installed package.

____________________________________________________________________
Error in .jcall("RJavaTools", "Ljava/lang/Object;", "newInstance",
.jfindClass(class),  :
  java.lang.InternalError: Can't connect to X11 window server using ':0' as
the value of the DISPLAY variable.
Calls: new -> new -> .J -> .jcall -> .jcheck -> .Call
Execution halted
____________________________________________________________________

Would highly appreciate your tips/suggestions..

Thanks and much appreciated,
Santosh

	[[alternative HTML version deleted]]


From innocenti at merit.unu.edu  Tue Mar  8 22:31:45 2016
From: innocenti at merit.unu.edu (stefania innocenti)
Date: Tue, 08 Mar 2016 22:31:45 +0100
Subject: [R] ivreg with two endogenous variables and 1 instrument
	respectively
Message-ID: <397-56df4500-1-41ad2d80@167207736>

Hello, 
I am trying to use the ivregress function to estimate a second stage model which looks like the following:

LogGDP=GEO+RULE+OPENNESS

I would like to instrument Rule (RULE) with Settler mortality (SETTLER) and Openness (OPENNESS) with logFrankelRomer (FR). I thus have one instrument per each endogenous variable.

Thus the second stage look like:
RULE=GEO+logFR+SETTLER
OPENNESS=GEO+logFR+SETTLER

Can I do this simultaneously with the ivregress function?

Maybe I got something wrong with the syntax but if I do:
ivregress(logGDP ~RULE+GEO+OPENNESS, c(RULE~SETTLER+FR+GEO, OPENNESS~SETTLER+FR+GEO), mydata), the function bugs and I cannot proceed. 
Of course, I could run the two first stages separately, but the coefficient of the first stage are then wrong. 

The command ivreg(logGDP ~ RULE + GEO +OPEN| GEO + SETTLER+FR) gives me correct second stage coefficients (I checked with what I obtained doing the 2sls by hand). 

But how do I retrieve the first stage coefficients for RULE=GEO+logFR+SETTLER and  OPENNESS=GEO+logFR+SETTLER in this case?

Any advice is more than appreciated.
Thanks a lot in advance. 
Best regards, 
Stefania


From raphaelprates at outlook.com  Wed Mar  9 01:21:28 2016
From: raphaelprates at outlook.com (Raphael Prates)
Date: Wed, 9 Mar 2016 00:21:28 +0000
Subject: [R] QuACN package: getLargestSubgraph -> .validateGraph error
Message-ID: <CP1PR80MB359DA61315AB3464C17B9FFBEB20@CP1PR80MB359.lamprd80.prod.outlook.com>

I am trying to create a network from the matrix that is attached.


> matrixSelecionada <- read.csv("matrix.csv", header = FALSE)

> matrixSelecionada <- data.matrix(matrixSelecionada)


## changing the values of the matrix


> for (i in 1:nrow(matrixSelecionada)) {
                for (j in 1:ncol(matrixSelecionada)) {
                        if (matrixSelecionada[i,j] < 0.01 || i==j) {
                        matrixSelecionada[i,j] <- 0
               } else if (matrixSelecionada[i,j]>=0.01) {
                        matrixSelecionada[i,j] <- 1
                }

                }
                }
> g <- as(matrixSelecionada, "graphNEL")
> g

A graphNEL graph with directed edges
Number of Nodes = 56
Number of Edges = 1256

> glg <- getLargestSubgraph(g)

Error: .validateGraph(g) is not TRUE


But when I do validateGraph

> validGraph(g)
[1] TRUE


From liuguoxiao at made-in-china.com  Wed Mar  9 03:15:23 2016
From: liuguoxiao at made-in-china.com (liuguoxiao at made-in-china.com)
Date: Wed, 9 Mar 2016 10:15:23 +0800
Subject: [R] Error en makebin(data, file) : 'sid' invalid
Message-ID: <2016030910152318778134@made-in-china.com>

 recently I began to use the package 
"arulesSequences" but the algorithm cspade give me this error: 

Error en makebin(data, file) : 'sid' invalid 

when I did executed this script, 
> data<-read.table("E:/zaki.txt",header=TRUE,sep=',') 
data :
"seqid","eventid","page"
"1","1","2211"
"1","2","2488"
"1","3","2239"
"2","1","2240"
"2","2","2488"
"2","3","231"
"2","4","2461"

> page<-factor(data$page) 
> seqid<-as.integer(data$seqid)
> eventid<-as.integer(data$eventid)
> data<-data.frame(page=page)
> data.tran<-as(data,"transactions")
> transactionInfo(data.tran)$sequenceID<-seqid 
> transactionInfo(data.tran)$eventID<-eventid
> transactionInfo(data.tran) 
>result<cspade(data.tran,parameter=list(support=0,maxlen=2),control=list(verbose=TRUE)) 
??


preprocessing ...Error in makebin(data, file) : 'eid' invalid (strict order)
      
????????????????????
Focus Technology Co., Ltd.
MIC?????? ??????  ??????
===============================
??????025-66677777-7505
??????liuguoxiao at made-in-china.com



	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Mar  9 07:41:18 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 9 Mar 2016 07:41:18 +0100
Subject: [R] Testing installed package of rJava in Linux
In-Reply-To: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>
References: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>
Message-ID: <56DFC58E.5010003@statistik.tu-dortmund.de>



On 09.03.2016 02:19, Santosh wrote:
> Dear Rxperts..
> I installed rJava on 64-bit Linux system and apparently it installed
> without errors.However, I got the following error message when I tried to
> test the installed package.
>
> ____________________________________________________________________
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "newInstance",
> .jfindClass(class),  :
>    java.lang.InternalError: Can't connect to X11 window server using ':0' as
> the value of the DISPLAY variable.
> Calls: new -> new -> .J -> .jcall -> .jcheck -> .Call
> Execution halted


Apparently you do not have an X server running or no X forwarding enabled?

Best,
Uwe Ligges


> ____________________________________________________________________
>
> Would highly appreciate your tips/suggestions..
>
> Thanks and much appreciated,
> Santosh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ragia11 at hotmail.com  Wed Mar  9 09:10:49 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Wed, 9 Mar 2016 10:10:49 +0200
Subject: [R] replace text by uniqe number
In-Reply-To: <CAKVAULOYztHoLUr6AorMbiYtZe+4Zg8YHTjjGRDT89cp024UQQ@mail.gmail.com>
References: <DUB125-W90ECDED878F7AC5B18736CB3FF0@phx.gbl>
	<CAGxFJbS7ovHOqqE4kGtrj4D2bdzh80G2hdjaFyB7_MHQhuc-JA@mail.gmail.com>,
	<DUB125-W70EC720B33389D714D927CB3FF0@phx.gbl>
	<CAGxFJbSsREVTz1eRLCtxYXt87HTy04e3K1SRWywyNGZdw3qORg@mail.gmail.com>,
	<CAKVAULOYztHoLUr6AorMbiYtZe+4Zg8YHTjjGRDT89cp024UQQ@mail.gmail.com>
Message-ID: <DUB125-W14927777D0C8D622539401B3B30@phx.gbl>

Dear group
kindly if i had data frame of 2 columns that has repeated URLS ..and want to replace those urls with ID's for each one so the url will have
unique ID, how ?can I do this
thanks in advance
e.g otf ?data

pcworld.com	open.itworld.com
pcworld.com	storage.itworld.com
salon.com	images.salon.com
go.theregister.com	theregister.co.uk
techchuck.com	pcworld.com
ecoustics.com	pcworld.com
?	
Ragia 		 	   		  

From petr.pikal at precheza.cz  Wed Mar  9 09:28:14 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 9 Mar 2016 08:28:14 +0000
Subject: [R] replace text by uniqe number
In-Reply-To: <DUB125-W14927777D0C8D622539401B3B30@phx.gbl>
References: <DUB125-W90ECDED878F7AC5B18736CB3FF0@phx.gbl>
	<CAGxFJbS7ovHOqqE4kGtrj4D2bdzh80G2hdjaFyB7_MHQhuc-JA@mail.gmail.com>,
	<DUB125-W70EC720B33389D714D927CB3FF0@phx.gbl>
	<CAGxFJbSsREVTz1eRLCtxYXt87HTy04e3K1SRWywyNGZdw3qORg@mail.gmail.com>,
	<CAKVAULOYztHoLUr6AorMbiYtZe+4Zg8YHTjjGRDT89cp024UQQ@mail.gmail.com>
	<DUB125-W14927777D0C8D622539401B3B30@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50133A4@SRVEXCHMBX.precheza.cz>

Hi

As you did not provide the data it is only a guess. The values are actually factors and in that case they already have unique numeric code.

you can try

as.numeric(yourdata)

If the values are character you can transfer them to factor and use as.numeric.

as.numeric(as.factor(yourdata))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia .
> Sent: Wednesday, March 09, 2016 9:11 AM
> To: r-help at r-project.org
> Subject: [R] replace text by uniqe number
>
> Dear group
> kindly if i had data frame of 2 columns that has repeated URLS ..and
> want to replace those urls with ID's for each one so the url will have
> unique ID, how  can I do this thanks in advance e.g otf  data
>
> pcworld.com   open.itworld.com
> pcworld.com   storage.itworld.com
> salon.com     images.salon.com
> go.theregister.com    theregister.co.uk
> techchuck.com pcworld.com
> ecoustics.com pcworld.com
>
> Ragia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From jdnewmil at dcn.davis.ca.us  Wed Mar  9 09:39:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 9 Mar 2016 00:39:18 -0800 (PST)
Subject: [R] Lexical scoping for step and add1 functions
In-Reply-To: <96E6B0084A068C43B02C637889A5E0B72E3F6E@UUSNWE1N.na.utcmail.com>
References: <96E6B0084A068C43B02C637889A5E0B72E3F6E@UUSNWE1N.na.utcmail.com>
Message-ID: <alpine.BSF.2.00.1603082357550.75468@pedal.dcn.davis.ca.us>

In a nutshell, formulas carry the environment in which they are 
defined along with the variable names, and your dfr was defined in the 
test.FN environment, but the formulas were defined in the global 
environment. I got this to work by defining the formula character strings 
in the global environment, and then converting those strings to formulas 
in the function. I don't think you can trick lm into referring to the 
global environment from within test.FN so that summaries refer to the 
X.des data frame instead of dfr (but someone could prove me wrong).

################################

test.FN <- function( dfr, scope, k = 2 ) {
   scp <- list( lower = as.formula( scope$lower )
 	     , upper = as.formula( scope$upper )
 	     )
   temp.lm <- lm( scp$lower
                , data = dfr
                )
   step( temp.lm
       , scope = scp
       , k=k
       )
}

# Begin by setting the rng seed.
set.seed( 523 )

# Generate a design matrix and response.
X.des <- matrix( abs( rnorm( 50 * 20, sd = 4 ) ), nrow = 50 )
Y <- 20 + X.des[, 1:3 ] %*% matrix( c( 3, -4, 2 ), nrow = 3 ) + rnorm( 50 )
X.des <- cbind( as.data.frame( X.des ), Y )

# Create the lower and upper formula components of a list.
test.scope <- list( lower = "Y ~ 1"
 		  , upper = paste( "Y ~"
 				 , paste( names( X.des )[ 1:20 ]
 					, collapse = " + "
 					)
 				 , sep=""
 				 )
 		  )
# Run 'test.FN'.
test.FN( dfr = X.des
        , scope = test.scope
        )


On Mon, 7 Mar 2016, Louisell, Paul T PW wrote:

> Hi,
>
> I've run into a problem calling the step function from within a function; I sent this to the R development list first, but the moderator said it was better suited to R help. My OS is Windows 7 and I'm using R version 3.2.3.
>
> Here's a simple function to help reproduce the error:
>      > test.FN
>      function(dfr, scope, k=2){
>      temp.lm=lm(scope$lower, data=dfr)
>      step(temp.lm, scope=scope$upper, k=k)
>      }
>
> And here's the code that gives the error when calling the function above:
>      # Begin by setting the rng seed.
>      > set.seed(523)
>
>      # Generate a design matrix and response.
>      > X.des=matrix(abs(rnorm(50*20, sd=4)), nrow=50)
>      > Y=20 + X.des[, 1:3] %*% matrix(c(3, -4, 2), nrow=3) + rnorm(50)
>      > X.des=cbind(as.data.frame(X.des), Y)
>
>      # Create the lower and upper formula components of a list.
>      > test.scope=list(lower=as.formula(Y ~ 1), upper=as.formula(paste("Y ~ ", paste(names(X.des)[1:20], collapse=" + "), sep="")))
>
>      # Run 'test.FN'.
>      > test.FN(dfr=X.des, scope=test.scope)
>      Start:  AIC=257.58
>      Y ~ 1
>
>      Error in is.data.frame(data) : object 'dfr' not found
>      > traceback()
>      11: is.data.frame(data)
>      10: model.frame.default(formula = Y ~ V1 + V2 + V3 + V4 + V5 + V6 +
>              V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 +
>              V17 + V18 + V19 + V20, data = dfr, drop.unused.levels = TRUE)
>      9: stats::model.frame(formula = Y ~ V1 + V2 + V3 + V4 + V5 + V6 +
>             V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 +
>             V17 + V18 + V19 + V20, data = dfr, drop.unused.levels = TRUE)
>      8: eval(expr, envir, enclos)
>      7: eval(fcall, env)
>      6: model.frame.lm(fob, xlev = object$xlevels)
>      5: model.frame(fob, xlev = object$xlevels)
>      4: add1.lm(fit, scope$add, scale = scale, trace = trace, k = k,
>             ...)
>      3: add1(fit, scope$add, scale = scale, trace = trace, k = k, ...)
>      2: step(temp.lm, scope = scope$upper, k = k) at #3
>      1: test.FN(dfr = X.des, scope = test.scope)
>
> The call to the traceback function indicates add1 doesn't see the dataframe dfr  passed to test.FN. The step function runs fine when I do everything in the global environment without using test.FN. I know the lexical scoping rules are different for objects involving model formulae, but despite a fair amount of experimentation, I haven't found any way to make the step / add1 functions see the dataframe that's passed to test.FN. Any help would be greatly appreciated.
>
> Thanks,
>
> Paul Louisell
> Statistical Specialist
> Paul.Louisell at pw.utc.com<mailto:Paul.Louisell at pw.utc.com>
> 860-565-8104
>
> Still, tomorrow's going to be another working day, and I'm trying to get some rest.
> That's all, I'm trying to get some rest.
> Paul Simon, "American Tune"
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From S.Ellison at LGCGroup.com  Wed Mar  9 12:05:28 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 9 Mar 2016 11:05:28 +0000
Subject: [R] Lexical scoping for step and add1 functions
In-Reply-To: <alpine.BSF.2.00.1603082357550.75468@pedal.dcn.davis.ca.us>
References: <96E6B0084A068C43B02C637889A5E0B72E3F6E@UUSNWE1N.na.utcmail.com>
	<alpine.BSF.2.00.1603082357550.75468@pedal.dcn.davis.ca.us>
Message-ID: <1A8C1289955EF649A09086A153E2672403D1145C7E@GBTEDVPEXCMB04.corp.lgc-group.com>

> In a nutshell, formulas carry the environment in which they are defined along
> with the variable names, and your dfr was defined in the test.FN environment,
> but the formulas were defined in the global environment. I got this to work by
> defining the formula character strings in the global environment, and then
> converting those strings to formulas in the function. I don't think you can trick
> lm into referring to the global environment from within test.FN so that
> summaries refer to the X.des data frame instead of dfr (but someone could
> prove me wrong).

If you want a function to refer to something in the global environment, just refer to the global object in the function. If the object name isn't used in the function's scope, it is sought in the parent environment. So the original code works if 
test.FN <-  function(scope, k=2){
      temp.lm=lm(scope$lower, data=X.des)  ## X.des is sought in parent environment
      step(temp.lm, scope=scope$upper, k=k)
      }

Admittedly, I'd not regard that kind of thing as a good idea; fragile and inflexible. But if you are clear about scope it does work.

Another way to proceed, somewhat more safely, is to wrap the whole thing in a function, passing X.des as dfr, then defining test.FN inside the outer function so that you know where it's going to get dfr from. Something along the lines of

test.step <- function(dfr, Y) {
	test.FN <-  function(scope, k=2){
      		temp.lm=lm(scope$lower, data=dfr)  ## X.des 
		print(temp.lm)
		 step(temp.lm, scope=as.formula(scope$upper), k=k)
      	}
	scope <- list( lower= as.formula('Y~1'), 
		upper=as.formula(paste('Y~', paste(names(dfr[1:20]), collapse="+"))) 
	)
	test.FN(scope=scope)
}

test.step(X.des, Y)


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From wht_crl at yahoo.com  Wed Mar  9 13:09:43 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 9 Mar 2016 12:09:43 +0000 (UTC)
Subject: [R] group by rows
References: <2102849490.5133566.1457525383019.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2102849490.5133566.1457525383019.JavaMail.yahoo@mail.yahoo.com>

How is it possible to group rows of a matrix or a data frame by the same values of the first column?
1 14331 453452 653 3762 45

1 1433,453452 45, 653 376
Thanks 

Carol

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Mar  9 13:59:07 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Mar 2016 07:59:07 -0500
Subject: [R] group by rows
In-Reply-To: <2102849490.5133566.1457525383019.JavaMail.yahoo@mail.yahoo.com>
References: <2102849490.5133566.1457525383019.JavaMail.yahoo.ref@mail.yahoo.com>
	<2102849490.5133566.1457525383019.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>

Possibly aggregate(), but you posted in HTML so your data were mangled.

Please use dput(), post in plain text, and try to explain more clearly
what you want the result to look like.

Sarah

On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help
<r-help at r-project.org> wrote:
> How is it possible to group rows of a matrix or a data frame by the same values of the first column?
> 1 14331 453452 653 3762 45
>
> 1 1433,453452 45, 653 376
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ___________________


From wht_crl at yahoo.com  Wed Mar  9 14:28:19 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 9 Mar 2016 13:28:19 +0000 (UTC)
Subject: [R] group by rows
In-Reply-To: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
References: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
Message-ID: <4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>

What should be FUN in aggregate as no function like mean, sum etc will be applied
Carol 

    On Wednesday, March 9, 2016 1:59 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
 

 Possibly aggregate(), but you posted in HTML so your data were mangled.

Please use dput(), post in plain text, and try to explain more clearly
what you want the result to look like.

Sarah

On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help
<r-help at r-project.org> wrote:
> How is it possible to group rows of a matrix or a data frame by the same values of the first column?
> 1 14331 453452 653 3762 45
>
> 1 1433,453452 45, 653 376
> Thanks
>
> Carol
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ___________________


  
	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Wed Mar  9 14:47:01 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 9 Mar 2016 13:47:01 +0000 (UTC)
Subject: [R] Fw:  group by rows
In-Reply-To: <4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
References: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
	<4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1815673313.5158798.1457531221392.JavaMail.yahoo@mail.yahoo.com>

I found the right usage.
Thanks

     On Wednesday, March 9, 2016 2:28 PM, carol white <wht_crl at yahoo.com> wrote:
 

 What should be FUN in aggregate as no function like mean, sum etc will be applied
Carol 

    On Wednesday, March 9, 2016 1:59 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
 

 Possibly aggregate(), but you posted in HTML so your data were mangled.

Please use dput(), post in plain text, and try to explain more clearly
what you want the result to look like.

Sarah

On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help
<r-help at r-project.org> wrote:
> How is it possible to group rows of a matrix or a data frame by the same values of the first column?
> 1 14331 453452 653 3762 45
>
> 1 1433,453452 45, 653 376
> Thanks
>
> Carol
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ___________________


   

  
	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Mar  9 14:52:49 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 9 Mar 2016 13:52:49 +0000
Subject: [R] group by rows
In-Reply-To: <2102849490.5133566.1457525383019.JavaMail.yahoo@mail.yahoo.com>
References: <2102849490.5133566.1457525383019.JavaMail.yahoo.ref@mail.yahoo.com>
	<2102849490.5133566.1457525383019.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D1145D34@GBTEDVPEXCMB04.corp.lgc-group.com>

> How is it possible to group rows of a matrix or a data frame by the same values
> of the first column?

If you mean _group_ as in SQL GROUP BY, use aggregate() with a count or summary statistic. 

If you mean _sort_, just to get similar values close together, use order()

For example, to sort by the first column of a matrix mm:
oo <- order(mm[,1])
mm[oo,] 

order() also takes multiple sort fields so can sort by several columns simultaneously (eg sort by first column and within that by third column etc).

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From petr.pikal at precheza.cz  Wed Mar  9 14:54:23 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 9 Mar 2016 13:54:23 +0000
Subject: [R] group by rows
In-Reply-To: <4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
References: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
	<4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5013592@SRVEXCHMBX.precheza.cz>

Hi

Without posting some data by dput, you hardly get any sensible answer.

You can use any function which gives you appropriate result, even your own.

Or even silly one like

aggregate(iris[,1:3], list(iris$Species), paste, collapse="")

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of carol
> white via R-help
> Sent: Wednesday, March 09, 2016 2:28 PM
> To: Sarah Goslee
> Cc: R-help Help
> Subject: Re: [R] group by rows
>
> What should be FUN in aggregate as no function like mean, sum etc will
> be applied Carol
>
>     On Wednesday, March 9, 2016 1:59 PM, Sarah Goslee
> <sarah.goslee at gmail.com> wrote:
>
>
>  Possibly aggregate(), but you posted in HTML so your data were
> mangled.
>
> Please use dput(), post in plain text, and try to explain more clearly
> what you want the result to look like.
>
> Sarah
>
> On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help <r-help at r-
> project.org> wrote:
> > How is it possible to group rows of a matrix or a data frame by the
> same values of the first column?
> > 1 14331 453452 653 3762 45
> >
> > 1 1433,453452 45, 653 376
> > Thanks
> >
> > Carol
> >
> >        [[alternative HTML version deleted]]
> >
> > ___________________
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From venkynov10 at gmail.com  Wed Mar  9 15:31:02 2016
From: venkynov10 at gmail.com (Venky)
Date: Wed, 9 Mar 2016 20:01:02 +0530
Subject: [R] Information value
Message-ID: <CAAM-fZ4FkgG+hBe84zV2OVbW00ohF7XBE8-bM6P3KVuUykXtLw@mail.gmail.com>

Hi

I want to find the information value for my overall data.

I have data like this.my data set name is data

Id      smoke    drink   nothing
1         yes        no          no
2         no          yes        yes
3          yes        yes        no
.           .               .           .
Etc

I have tried this code
Iv.mult(data)

Error:There is no function called iv.mult

Please help me to find out the information value for the oveall data.

Please give me the simple functions to calculate information value

Thanks in advance

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Mar  9 15:49:56 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Mar 2016 09:49:56 -0500
Subject: [R] group by rows
In-Reply-To: <4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
References: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
	<4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjumnJVo4ZE2tJZ15mxqOwwZK6FRG_H0HK89tawNBF-A_bw@mail.gmail.com>

On Wed, Mar 9, 2016 at 8:28 AM, carol white <wht_crl at yahoo.com> wrote:
> What should be FUN in aggregate as no function like mean, sum etc will be
> applied

I have no idea, since you haven't told us what you want the results to
look like.


> Carol
>
>
> On Wednesday, March 9, 2016 1:59 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>
> Possibly aggregate(), but you posted in HTML so your data were mangled.
>
> Please use dput(), post in plain text, and try to explain more clearly
> what you want the result to look like.
>
> Sarah
>
> On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help
> <r-help at r-project.org> wrote:
>> How is it possible to group rows of a matrix or a data frame by the same
>> values of the first column?
>> 1 14331 453452 653 3762 45
>>
>> 1 1433,453452 45, 653 376
>> Thanks
>>
>> Carol
>


From sarah.goslee at gmail.com  Wed Mar  9 15:51:02 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Mar 2016 09:51:02 -0500
Subject: [R] Information value
In-Reply-To: <CAAM-fZ4FkgG+hBe84zV2OVbW00ohF7XBE8-bM6P3KVuUykXtLw@mail.gmail.com>
References: <CAAM-fZ4FkgG+hBe84zV2OVbW00ohF7XBE8-bM6P3KVuUykXtLw@mail.gmail.com>
Message-ID: <CAM_vjun7Np6Woi2arLzRNYmndaShv-KzVi2jmBDDqG_wHGVP=Q@mail.gmail.com>

A search on rseek.org for information value turns up several
contributed packages that may do what you want.

Sarah

On Wed, Mar 9, 2016 at 9:31 AM, Venky <venkynov10 at gmail.com> wrote:
> Hi
>
> I want to find the information value for my overall data.
>
> I have data like this.my data set name is data
>
> Id      smoke    drink   nothing
> 1         yes        no          no
> 2         no          yes        yes
> 3          yes        yes        no
> .           .               .           .
> Etc
>
> I have tried this code
> Iv.mult(data)
>
> Error:There is no function called iv.mult
>
> Please help me to find out the information value for the oveall data.
>
> Please give me the simple functions to calculate information value
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>


From lists at dewey.myzen.co.uk  Wed Mar  9 16:22:58 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 9 Mar 2016 15:22:58 +0000
Subject: [R] Information value
In-Reply-To: <CAAM-fZ4FkgG+hBe84zV2OVbW00ohF7XBE8-bM6P3KVuUykXtLw@mail.gmail.com>
References: <CAAM-fZ4FkgG+hBe84zV2OVbW00ohF7XBE8-bM6P3KVuUykXtLw@mail.gmail.com>
Message-ID: <56E03FD2.8060708@dewey.myzen.co.uk>

Just to help next time some comments in-line

On 09/03/2016 14:31, Venky wrote:
> Hi
>
> I want to find the information value for my overall data.
>
> I have data like this.my data set name is data
>

Best not to call your data.frame data as it may conflict with the 
function data()

> Id      smoke    drink   nothing
> 1         yes        no          no
> 2         no          yes        yes
> 3          yes        yes        no
> .           .               .           .
> Etc
>
> I have tried this code
> Iv.mult(data)
>
> Error:There is no function called iv.mult

So you did not actually type Iv.mult as you told us, or alternatively 
the error message is not as you stated. Please give us what you 
_actually_ typed and do not re-type something like it.

You presumably need to find which package contains iv.mult and load it 
first.

>
> Please help me to find out the information value for the oveall data.
>
> Please give me the simple functions to calculate information value
>
> Thanks in advance
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jan.kacaba at gmail.com  Wed Mar  9 16:22:58 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 9 Mar 2016 16:22:58 +0100
Subject: [R] assign a vector to list sequence
Message-ID: <CAHby=D1Dhy2=wfKVFFADWZZmRZRcQMzJw8MmEouZU=RU6sQd6A@mail.gmail.com>

Hello I would like to assign a vector to list sequence. I'm trying my code
bellow, but the output is not what inteded.

# my code
mls=vector(mode="list") # my list
cseq=c(1:3) # my vector
mls[cseq]=cseq

I get following:
[[1]]
[1] 1
[[1]]
[2] 2
[[1]]
[2] 3

What I need is this:
[[1]]
[1] 1 2 3
[[1]]
[2] 1 2 3
[[1]]
[2] 1 2 3

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Mar  9 16:32:34 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Mar 2016 10:32:34 -0500
Subject: [R] assign a vector to list sequence
In-Reply-To: <CAHby=D1Dhy2=wfKVFFADWZZmRZRcQMzJw8MmEouZU=RU6sQd6A@mail.gmail.com>
References: <CAHby=D1Dhy2=wfKVFFADWZZmRZRcQMzJw8MmEouZU=RU6sQd6A@mail.gmail.com>
Message-ID: <CAM_vjuk+P0v+pWkFrSMRqTGdJ6r=9m+f8POJg8Wt=eyrLjPyEw@mail.gmail.com>

Hi,



On Wed, Mar 9, 2016 at 10:22 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> Hello I would like to assign a vector to list sequence. I'm trying my code
> bellow, but the output is not what inteded.
>
> # my code
> mls=vector(mode="list") # my list
> cseq=c(1:3) # my vector
> mls[cseq]=cseq
>
> I get following:
> [[1]]
> [1] 1
> [[1]]
> [2] 2
> [[1]]
> [2] 3
>
> What I need is this:
> [[1]]
> [1] 1 2 3
> [[1]]
> [2] 1 2 3
> [[1]]
> [2] 1 2 3


This doesn't make any sense as an R structure: you have three element
1 in your list.

Here's what I think you might want:
> cseq <- c(1:3) # my vector
> mls <- lapply(cseq, function(x)cseq)
> mls
[[1]]
[1] 1 2 3

[[2]]
[1] 1 2 3

[[3]]
[1] 1 2 3

Sarah


From S.Ellison at LGCGroup.com  Wed Mar  9 16:52:21 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 9 Mar 2016 15:52:21 +0000
Subject: [R] assign a vector to list sequence
In-Reply-To: <CAM_vjuk+P0v+pWkFrSMRqTGdJ6r=9m+f8POJg8Wt=eyrLjPyEw@mail.gmail.com>
References: <CAHby=D1Dhy2=wfKVFFADWZZmRZRcQMzJw8MmEouZU=RU6sQd6A@mail.gmail.com>
	<CAM_vjuk+P0v+pWkFrSMRqTGdJ6r=9m+f8POJg8Wt=eyrLjPyEw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D1145DB5@GBTEDVPEXCMB04.corp.lgc-group.com>

> > What I need is this:
> > [[1]]
> > [1] 1 2 3
> > [[1]]
> > [2] 1 2 3
> > [[1]]
> > [2] 1 2 3

Try
rep(list(1:3), 3)

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From santosh2005 at gmail.com  Wed Mar  9 17:44:12 2016
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 9 Mar 2016 08:44:12 -0800
Subject: [R] Testing installed package of rJava in Linux
In-Reply-To: <56DFC58E.5010003@statistik.tu-dortmund.de>
References: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>
	<56DFC58E.5010003@statistik.tu-dortmund.de>
Message-ID: <CAN_e6XtUez4w_dvLAmh6AXb8MA_XjkZZh+KHVkR804dKQ7p_ZQ@mail.gmail.com>

Thanks for your response. Since the test failed due to X11 connectivity
reasons, is it okay to use it in applications where X11 server connectivity
is not required?
Thanks and much appreciated,
Santosh

On Tue, Mar 8, 2016 at 10:41 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 09.03.2016 02:19, Santosh wrote:
>
>> Dear Rxperts..
>> I installed rJava on 64-bit Linux system and apparently it installed
>> without errors.However, I got the following error message when I tried to
>> test the installed package.
>>
>> ____________________________________________________________________
>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "newInstance",
>> .jfindClass(class),  :
>>    java.lang.InternalError: Can't connect to X11 window server using ':0'
>> as
>> the value of the DISPLAY variable.
>> Calls: new -> new -> .J -> .jcall -> .jcheck -> .Call
>> Execution halted
>>
>
>
> Apparently you do not have an X server running or no X forwarding enabled?
>
> Best,
> Uwe Ligges
>
>
> ____________________________________________________________________
>>
>> Would highly appreciate your tips/suggestions..
>>
>> Thanks and much appreciated,
>> Santosh
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar  9 17:46:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 09 Mar 2016 08:46:06 -0800
Subject: [R] Lexical scoping for step and add1 functions
In-Reply-To: <1A8C1289955EF649A09086A153E2672403D1145C7E@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <96E6B0084A068C43B02C637889A5E0B72E3F6E@UUSNWE1N.na.utcmail.com>
	<alpine.BSF.2.00.1603082357550.75468@pedal.dcn.davis.ca.us>
	<1A8C1289955EF649A09086A153E2672403D1145C7E@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <03209C2D-68FB-4B5C-9FDB-8C58759CFB8A@dcn.davis.ca.us>

So in both my solution and your second option, lm prints that it evaluated the regression in a function context (using dfr) which the user of the function might prefer to be unaware of (they know what X.des is). Your first solution  avoids that but hardcodes access to the global variable so if the user wants to use a different data frame then a different function has to be defined. I am OK with that, but thought that there might be a way to indirectly tell lm to use the global environment via the parameter dfr. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2016 3:05:28 AM PST, S Ellison <S.Ellison at LGCGroup.com> wrote:
>> In a nutshell, formulas carry the environment in which they are
>defined along
>> with the variable names, and your dfr was defined in the test.FN
>environment,
>> but the formulas were defined in the global environment. I got this
>to work by
>> defining the formula character strings in the global environment, and
>then
>> converting those strings to formulas in the function. I don't think
>you can trick
>> lm into referring to the global environment from within test.FN so
>that
>> summaries refer to the X.des data frame instead of dfr (but someone
>could
>> prove me wrong).
>
>If you want a function to refer to something in the global environment,
>just refer to the global object in the function. If the object name
>isn't used in the function's scope, it is sought in the parent
>environment. So the original code works if 
>test.FN <-  function(scope, k=2){
>temp.lm=lm(scope$lower, data=X.des)  ## X.des is sought in parent
>environment
>      step(temp.lm, scope=scope$upper, k=k)
>      }
>
>Admittedly, I'd not regard that kind of thing as a good idea; fragile
>and inflexible. But if you are clear about scope it does work.
>
>Another way to proceed, somewhat more safely, is to wrap the whole
>thing in a function, passing X.des as dfr, then defining test.FN inside
>the outer function so that you know where it's going to get dfr from.
>Something along the lines of
>
>test.step <- function(dfr, Y) {
>	test.FN <-  function(scope, k=2){
>      		temp.lm=lm(scope$lower, data=dfr)  ## X.des 
>		print(temp.lm)
>		 step(temp.lm, scope=as.formula(scope$upper), k=k)
>      	}
>	scope <- list( lower= as.formula('Y~1'), 
>		upper=as.formula(paste('Y~', paste(names(dfr[1:20]), collapse="+"))) 
>	)
>	test.FN(scope=scope)
>}
>
>test.step(X.des, Y)
>
>
>S Ellison
>
>
>
>*******************************************************************
>This email and any attachments are confidential. Any
>use...{{dropped:8}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Wed Mar  9 18:02:28 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2016 18:02:28 +0100 (CET)
Subject: [R] ivreg with two endogenous variables and 1 instrument
 respectively
In-Reply-To: <397-56df4500-1-41ad2d80@167207736>
References: <397-56df4500-1-41ad2d80@167207736>
Message-ID: <alpine.DEB.2.20.1603091757390.2799@paninaro>

On Tue, 8 Mar 2016, stefania innocenti wrote:

> Hello,
> I am trying to use the ivregress function to estimate a second stage 
> model which looks like the following:
>
> LogGDP=GEO+RULE+OPENNESS
>
> I would like to instrument Rule (RULE) with Settler mortality (SETTLER) 
> and Openness (OPENNESS) with logFrankelRomer (FR). I thus have one 
> instrument per each endogenous variable.
>
> Thus the second stage look like:
> RULE=GEO+logFR+SETTLER
> OPENNESS=GEO+logFR+SETTLER
>
> Can I do this simultaneously with the ivregress function?

Which package is this?

> Maybe I got something wrong with the syntax but if I do:
> ivregress(logGDP ~RULE+GEO+OPENNESS, c(RULE~SETTLER+FR+GEO, 
> OPENNESS~SETTLER+FR+GEO), mydata), the function bugs and I cannot 
> proceed.
>
> Of course, I could run the two first stages separately, but the 
> coefficient of the first stage are then wrong.
>
> The command ivreg(logGDP ~ RULE + GEO +OPEN| GEO + SETTLER+FR) gives me 
> correct second stage coefficients (I checked with what I obtained doing 
> the 2sls by hand).

That's package "AER", I presume?

> But how do I retrieve the first stage coefficients for 
> RULE=GEO+logFR+SETTLER and OPENNESS=GEO+logFR+SETTLER in this case?

The ivreg() function from "AER" does not store the first stage results but 
just returns the IV estimates from the second stage. If you want the first 
stage you need to run lm() manually:

lm(cbind(RULE, OPENNESS) ~ GEO + logFR + SETTLER, ...)

> Any advice is more than appreciated.
> Thanks a lot in advance.
> Best regards,
> Stefania
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From J.Hillier at lboro.ac.uk  Wed Mar  9 18:52:24 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Wed, 9 Mar 2016 17:52:24 +0000
Subject: [R] truncpareto() - doesn't like my data and odd error message
Message-ID: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>

Dear All,


I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.


I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).


When I try to run my data, I get the output below. Inputs shown with chevrons.


> pdataH <- data.frame(H_to_fit$Height)
> summary(pdataH)
   H_to_fit.Height
   Min.   :2000
   1st Qu.:2281

   Median :2666
   Mean   :2825
   3rd Qu.:3212
   Max.   :4794
> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
Error in eval(expr, envir, enclos) :
  the value of argument 'lower' is too high (requires '0 < lower < min(y)')


This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.


Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)

Is truncpareto sensitive to not converging?

Am I using completely the wrong command?


Thank you in advance for any assistance you can give.


John


<http://www.inside-r.org/packages/cran/vgam/docs/paretoff><http://www.inside-r.org/packages/cran/vgam/docs/paretoff>p.s - Example that I did get to run.


# Upper truncated Pareto distribution
lower <- 2; upper <- 8; kay <- exp<http://inside-r.org/r-doc/base/exp>(2)
pdata3 <- data.frame<http://inside-r.org/r-doc/base/data.frame>(y = rtruncpareto(n = 100, lower = lower,
                                      upper = upper, shape = kay))
fit3 <- vglm(y ~ 1, truncpareto(lower, upper), data<http://inside-r.org/r-doc/utils/data> = pdata3, trace<http://inside-r.org/r-doc/base/trace> = TRUE)
coef<http://inside-r.org/r-doc/stats/coef>(fit3, matrix<http://inside-r.org/r-doc/base/matrix> = TRUE)
c<http://inside-r.org/r-doc/base/c>(fit3 at misc$lower, fit3 at misc$upper)


and output



> # Upper truncated Pareto distribution
> lower <- 2; upper <- 8; kay <- exp(2)
> pdata3 <- data.frame(y = rtruncpareto(n = 100, lower = lower,
+                                       upper = upper, shape = kay))
> fit3 <- vglm(y ~ 1, truncpareto(lower, upper), data = pdata3, trace = TRUE)
VGLM    linear loop  1 :  loglikelihood = 12.127363
VGLM    linear loop  2 :  loglikelihood = 12.130407
VGLM    linear loop  3 :  loglikelihood = 12.130407
> coef(fit3, matrix = TRUE)
            loge(shape)
(Intercept)    1.955295
> c(fit3 at misc$lower, fit3 at misc$upper)
[1] 2 8


-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Mar  9 19:06:04 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 9 Mar 2016 19:06:04 +0100
Subject: [R] Testing installed package of rJava in Linux
In-Reply-To: <CAN_e6XtUez4w_dvLAmh6AXb8MA_XjkZZh+KHVkR804dKQ7p_ZQ@mail.gmail.com>
References: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>
	<56DFC58E.5010003@statistik.tu-dortmund.de>
	<CAN_e6XtUez4w_dvLAmh6AXb8MA_XjkZZh+KHVkR804dKQ7p_ZQ@mail.gmail.com>
Message-ID: <56E0660C.2080104@statistik.tu-dortmund.de>

I do not get this: If it works it is OK to use it. If it does not work, 
you can't....

Best,
Uwe Kigges





On 09.03.2016 17:44, Santosh wrote:
> Thanks for your response. Since the test failed due to X11 connectivity
> reasons, is it okay to use it in applications where X11 server connectivity
> is not required?
> Thanks and much appreciated,
> Santosh
>
> On Tue, Mar 8, 2016 at 10:41 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
>> wrote:
>
>>
>>
>> On 09.03.2016 02:19, Santosh wrote:
>>
>>> Dear Rxperts..
>>> I installed rJava on 64-bit Linux system and apparently it installed
>>> without errors.However, I got the following error message when I tried to
>>> test the installed package.
>>>
>>> ____________________________________________________________________
>>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "newInstance",
>>> .jfindClass(class),  :
>>>     java.lang.InternalError: Can't connect to X11 window server using ':0'
>>> as
>>> the value of the DISPLAY variable.
>>> Calls: new -> new -> .J -> .jcall -> .jcheck -> .Call
>>> Execution halted
>>>
>>
>>
>> Apparently you do not have an X server running or no X forwarding enabled?
>>
>> Best,
>> Uwe Ligges
>>
>>
>> ____________________________________________________________________
>>>
>>> Would highly appreciate your tips/suggestions..
>>>
>>> Thanks and much appreciated,
>>> Santosh
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stephen at jsidata.ca  Wed Mar  9 20:24:56 2016
From: stephen at jsidata.ca (Stephen Connolly)
Date: Wed, 9 Mar 2016 14:24:56 -0500
Subject: [R] Testing installed package of rJava in Linux
In-Reply-To: <56E0660C.2080104@statistik.tu-dortmund.de>
References: <CAN_e6Xt5sovGtCaN2u-jLUasbfnz1gm9LK4SbMx5jUUy3e3Zxg@mail.gmail.com>
	<56DFC58E.5010003@statistik.tu-dortmund.de>
	<CAN_e6XtUez4w_dvLAmh6AXb8MA_XjkZZh+KHVkR804dKQ7p_ZQ@mail.gmail.com>
	<56E0660C.2080104@statistik.tu-dortmund.de>
Message-ID: <56E07888.50507@jsidata.ca>

The variable DISPLAY is what is causing problems. Run the command 'unset
DISPLAY' before running R .

Stephen


On 09/03/16 01:06 PM, Uwe Ligges wrote:
> I do not get this: If it works it is OK to use it. If it does not work,
> you can't....
> 
> Best,
> Uwe Kigges
> 
> 
> 
> 
> 
> On 09.03.2016 17:44, Santosh wrote:
>> Thanks for your response. Since the test failed due to X11 connectivity
>> reasons, is it okay to use it in applications where X11 server
>> connectivity
>> is not required?
>> Thanks and much appreciated,
>> Santosh
>>
>> On Tue, Mar 8, 2016 at 10:41 PM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de
>>> wrote:
>>
>>>
>>>
>>> On 09.03.2016 02:19, Santosh wrote:
>>>
>>>> Dear Rxperts..
>>>> I installed rJava on 64-bit Linux system and apparently it installed
>>>> without errors.However, I got the following error message when I
>>>> tried to
>>>> test the installed package.
>>>>
>>>> ____________________________________________________________________
>>>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "newInstance",
>>>> .jfindClass(class),  :
>>>>     java.lang.InternalError: Can't connect to X11 window server
>>>> using ':0'
>>>> as
>>>> the value of the DISPLAY variable.
>>>> Calls: new -> new -> .J -> .jcall -> .jcheck -> .Call
>>>> Execution halted
>>>>
>>>
>>>
>>> Apparently you do not have an X server running or no X forwarding
>>> enabled?
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>> ____________________________________________________________________
>>>>
>>>> Would highly appreciate your tips/suggestions..
>>>>
>>>> Thanks and much appreciated,
>>>> Santosh
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Mar  9 20:58:30 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 9 Mar 2016 20:58:30 +0100
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>


> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
> 
> Dear All,
> 
> 
> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
> 
> 
> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
> 
> 
> When I try to run my data, I get the output below. Inputs shown with chevrons.
> 
> 
>> pdataH <- data.frame(H_to_fit$Height)
>> summary(pdataH)
>   H_to_fit.Height
>   Min.   :2000
>   1st Qu.:2281
> 
>   Median :2666
>   Mean   :2825
>   3rd Qu.:3212
>   Max.   :4794
>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
> Error in eval(expr, envir, enclos) :
>  the value of argument 'lower' is too high (requires '0 < lower < min(y)')
> 
> 
> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
> 
> 
> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
> 

Umm, it doesn't seem to have a column called "y"?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kmnanus at gmail.com  Wed Mar  9 19:14:25 2016
From: kmnanus at gmail.com (KMNanus)
Date: Wed, 9 Mar 2016 13:14:25 -0500
Subject: [R] extracting months from a data
Message-ID: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>

I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.

I want to create a variable of just the month.  If I convert the date to a character string, substr is ineffective because some of the dates have 5 characters (3-Oct) and some have 6 (10-Oct).

Is there a date function that accomplishes this easily?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From dwinsemius at comcast.net  Thu Mar 10 00:50:37 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Mar 2016 15:50:37 -0800
Subject: [R] replace text in table R?
In-Reply-To: <CAM_vju=gf_t=rbWvbK5q-sgB2+sMTesBG8ds6T79p_qsuqR4hA@mail.gmail.com>
References: <CAMwU6B1bvhikvhrp8g0HmNtHZU0EMNnVtZ0t9oCF_RKkjC14vA@mail.gmail.com>
	<CAM_vju=gf_t=rbWvbK5q-sgB2+sMTesBG8ds6T79p_qsuqR4hA@mail.gmail.com>
Message-ID: <9759F609-CBDE-4FE8-9D9C-6265D3DDEFAE@comcast.net>


> On Mar 8, 2016, at 1:48 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Thanks for the complete reproducible example.
> 
> Here's one way to approach the problem; there are many others.
> 
> recodeDat <- function(x, invals, outvals) {
> x <- as.character(x)
> invals <- as.character(invals)
> outvals <- as.character(outvals)
> # a loop is the most understandable approach
> for(i in seq_along(invals)) {
> x[x == invals[i]] <- outvals[i]
> }
> # I would change the zeros to NA values
> x[x == "0"] <- NA
> 
> factor(x, levels=sort(unique(outvals)))
> }
> 
> dat1.recode <- dat1
> dat1.recode[, 3:ncol(dat1.recode)] <- apply(dat1.recode[,
> 3:ncol(dat1.recode)], 2, recodeDat, invals=dat2[,1], outvals=dat2[,2])

Here's an lapply approach that gives the same result (complete with the misspelling of 'assigned':

dat1[3:5] <- lapply(dat1[3:5], function(x) dat2$To.be.assinged[ match( x, dat2$site) ])
dat1

`match` is designed for generating selection vectors and does not need preceding calls to as.character for factors.

--
Best;
David.
> 
> On Tue, Mar 8, 2016 at 4:26 PM, Marna Wagley <marna.wagley at gmail.com> wrote:
>> Hi R Users,
>> I have been struggling to replace texts in a table by new text. but it
>> seems crazy as of I am doing it manually in R. I have very big files and
>> some of the text has to be replaced by another class based on another file
>> if the name corresponds. I was able to perform following example but it
>> should be easier if there is a loop. Any suggestions on making a loop for
>> this example?
>> 
>> Here is the example how I did. I want to assign class into dat1 based on
>> dat2 table.
>> 
>> dat1<-structure(list(ID = structure(1:8, .Label = c("X127", "X128",
>> "X129", "X130", "X131", "X132", "X133", "X134"), class = "factor"),
>>    Name = structure(1:8, .Label = c("Site1", "Site2", "Site3",
>>    "Site4", "Site5", "Site6", "Site7", "Site8"), class = "factor"),
>>    Time1 = structure(c(4L, 2L, 3L, 5L, 1L, 1L, 4L, 5L), .Label = c("0",
>>    "GT", "R", "Tr", "W2"), class = "factor"), Time2 = structure(c(2L,
>>    1L, 4L, 2L, 1L, 3L, 4L, 1L), .Label = c("0", "GT", "MA",
>>    "UA"), class = "factor"), Time3 = structure(c(5L, 1L, 4L,
>>    4L, 2L, 3L, 3L, 1L), .Label = c("0", "GT", "R", "Tr", "Y7"
>>    ), class = "factor")), .Names = c("ID", "Name", "Time1",
>> "Time2", "Time3"), class = "data.frame", row.names = c(NA, -8L
>> ))
>> 
>> dat1
>> 
>> dat2<-structure(list(site = structure(c(4L, 2L, 5L, 3L, 6L, 7L, 8L,
>> 1L), .Label = c("GT", "MA", "R", "Tr", "UA", "W1", "W2", "Y7"
>> ), class = "factor"), To.be.assinged = structure(c(1L, 2L, 3L,
>> 1L, 4L, 4L, 1L, 2L), .Label = c("A", "B", "C", "D"), class = "factor")),
>> .Names = c("site",
>> "To.be.assinged"), class = "data.frame", row.names = c(NA, -8L
>> ))
>> dat2
>> 
>> A2 <- as.data.frame(lapply(dat1,function(x)
>> if(is.character(x)|is.factor(x)) gsub("Tr","A",x) else x))
>> A3 <- as.data.frame(lapply(A2,function(x) if(is.character(x)|is.factor(x))
>> gsub("MA","B",x) else x))
>> A4 <- as.data.frame(lapply(A3,function(x) if(is.character(x)|is.factor(x))
>> gsub("UA","C",x) else x))
>> A5 <- as.data.frame(lapply(A4,function(x) if(is.character(x)|is.factor(x))
>> gsub("R","A",x) else x))
>> A6 <- as.data.frame(lapply(A5,function(x) if(is.character(x)|is.factor(x))
>> gsub("W1","D",x) else x))
>> A7 <- as.data.frame(lapply(A6,function(x) if(is.character(x)|is.factor(x))
>> gsub("W2","D",x) else x))
>> A8 <- as.data.frame(lapply(A7,function(x) if(is.character(x)|is.factor(x))
>> gsub("Y7","A",x) else x))
>> A9 <- as.data.frame(lapply(A8,function(x) if(is.character(x)|is.factor(x))
>> gsub("GT","B",x) else x))
>> A9
>> 
>> Your help is highly appreciated.
>> Thanks
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Mar 10 00:52:07 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 09 Mar 2016 15:52:07 -0800
Subject: [R] extracting months from a data
In-Reply-To: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
Message-ID: <BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>

Your dates are incomplete (no year) so I suggest staying away from the date functions for this. Read ?regex and ?sub.

x <- c( "3-Oct", "10-Nov" )
m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )

-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
>I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>
>I want to create a variable of just the month.  If I convert the date
>to a character string, substr is ineffective because some of the dates
>have 5 characters (3-Oct) and some have 6 (10-Oct).
>
>Is there a date function that accomplishes this easily?
>
>Ken
>kmnanus at gmail.com
>914-450-0816 (tel)
>347-730-4813 (fax)
>
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Thu Mar 10 00:54:38 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 9 Mar 2016 15:54:38 -0800
Subject: [R] extracting months from a data
In-Reply-To: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
Message-ID: <CAJeYpE-UFzs-+HvNyjYntjSqCPhs2GygN3KYz=B2xnsPxJJu_Q@mail.gmail.com>

?as.Date

On Wed, Mar 9, 2016 at 10:14 AM, KMNanus <kmnanus at gmail.com> wrote:

> I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>
> I want to create a variable of just the month.  If I convert the date to a
> character string, substr is ineffective because some of the dates have 5
> characters (3-Oct) and some have 6 (10-Oct).
>
> Is there a date function that accomplishes this easily?
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Thu Mar 10 01:15:31 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 9 Mar 2016 16:15:31 -0800
Subject: [R] extracting months from a data
In-Reply-To: <BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
Message-ID: <CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>

Or:

x <- c( "3-Oct", "10-Nov" )
format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')

# the 'paste0' appends a year to the text vector
# the 'as.Date' interprets the strings as dates with format  10-Jun-2016
(e.g.)
# the 'format' returns a string with date in format '%b' (which is just the
name of the month)

On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your dates are incomplete (no year) so I suggest staying away from the
> date functions for this. Read ?regex and ?sub.
>
> x <- c( "3-Oct", "10-Nov" )
> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
> >
> >I want to create a variable of just the month.  If I convert the date
> >to a character string, substr is ineffective because some of the dates
> >have 5 characters (3-Oct) and some have 6 (10-Oct).
> >
> >Is there a date function that accomplishes this easily?
> >
> >Ken
> >kmnanus at gmail.com
> >914-450-0816 (tel)
> >347-730-4813 (fax)
> >
> >
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 10 01:39:24 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 09 Mar 2016 16:39:24 -0800
Subject: [R] extracting months from a data
In-Reply-To: <CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
Message-ID: <EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>

Still not recommended.  That takes more steps, is harder to understand, and will break when given "29-Feb" as input. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2016 4:15:31 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov> wrote:
>Or:
>
>x <- c( "3-Oct", "10-Nov" )
>format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
>
># the 'paste0' appends a year to the text vector
># the 'as.Date' interprets the strings as dates with format 
>10-Jun-2016
>(e.g.)
># the 'format' returns a string with date in format '%b' (which is just
>the
>name of the month)
>
>On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Your dates are incomplete (no year) so I suggest staying away from
>the
>> date functions for this. Read ?regex and ?sub.
>>
>> x <- c( "3-Oct", "10-Nov" )
>> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
>> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>> >
>> >I want to create a variable of just the month.  If I convert the
>date
>> >to a character string, substr is ineffective because some of the
>dates
>> >have 5 characters (3-Oct) and some have 6 (10-Oct).
>> >
>> >Is there a date function that accomplishes this easily?
>> >
>> >Ken
>> >kmnanus at gmail.com
>> >914-450-0816 (tel)
>> >347-730-4813 (fax)
>> >
>> >
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>Dan Dalthorp, PhD
>USGS Forest and Rangeland Ecosystem Science Center
>Forest Sciences Lab, Rm 189
>3200 SW Jefferson Way
>Corvallis, OR 97331
>ph: 541-750-0953
>ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Thu Mar 10 01:49:18 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 9 Mar 2016 16:49:18 -0800
Subject: [R] extracting months from a data
In-Reply-To: <EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
	<EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>
Message-ID: <CAJeYpE9JXEZ7PTAuwK_fgcBCAB5HmfatLBzcwsL4jGLy7cdoCQ@mail.gmail.com>

Good point about 29-Feb...fixed in the following:

format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b')

# Also: The date functions can be used to easily calculate passage of time
and offer good flexibility for formatting output.

-Dan

P.S. "harder to understand" is in the eye of the beholder (as is
"recommended").



On Wed, Mar 9, 2016 at 4:39 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Still not recommended. That takes more steps, is harder to understand, and
> will break when given "29-Feb" as input.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 9, 2016 4:15:31 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov>
> wrote:
>>
>> Or:
>>
>> x <- c( "3-Oct", "10-Nov" )
>> format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
>>
>> # the 'paste0' appends a year to the text vector
>> # the 'as.Date' interprets the strings as dates with format  10-Jun-2016
>> (e.g.)
>> # the 'format' returns a string with date in format '%b' (which is just
>> the name of the month)
>>
>> On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> Your dates are incomplete (no year) so I suggest staying away from the
>>> date functions for this. Read ?regex and ?sub.
>>>
>>> x <- c( "3-Oct", "10-Nov" )
>>> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
>>> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>>> >
>>> >I want to create a variable of just the month.  If I convert the date
>>> >to a character string, substr is ineffective because some of the dates
>>> >have 5 characters (3-Oct) and some have 6 (10-Oct).
>>> >
>>> >Is there a date function that accomplishes this easily?
>>> >
>>> >Ken
>>> >kmnanus at gmail.com
>>> >914-450-0816 (tel)
>>> >347-730-4813 (fax)
>>> >
>>> >
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Dan Dalthorp, PhD
>> USGS Forest and Rangeland Ecosystem Science Center
>> Forest Sciences Lab, Rm 189
>> 3200 SW Jefferson Way
>> Corvallis, OR 97331
>> ph: 541-750-0953
>> ddalthorp at usgs.gov
>>
>>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 10 02:08:35 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 09 Mar 2016 17:08:35 -0800
Subject: [R] extracting months from a data
In-Reply-To: <CAJeYpE9JXEZ7PTAuwK_fgcBCAB5HmfatLBzcwsL4jGLy7cdoCQ@mail.gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
	<EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>
	<CAJeYpE9JXEZ7PTAuwK_fgcBCAB5HmfatLBzcwsL4jGLy7cdoCQ@mail.gmail.com>
Message-ID: <AF439D19-5F1A-42D8-8B36-182CCD453FDD@dcn.davis.ca.us>

How about slower? That is objective.

I use dates all the time so I am quite familiar with what they are good for. However,  I prefer to avoid inventing information such as which year the date should have included unless I have to based on knowledge of the data source. It is not good to mislead the consumer of output about the existence of year information if it wasn't there to begin with. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2016 4:49:18 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov> wrote:
>Good point about 29-Feb...fixed in the following:
>
>format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b')
>
># Also: The date functions can be used to easily calculate passage of
>time
>and offer good flexibility for formatting output.
>
>-Dan
>
>P.S. "harder to understand" is in the eye of the beholder (as is
>"recommended").
>
>
>
>On Wed, Mar 9, 2016 at 4:39 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Still not recommended. That takes more steps, is harder to
>understand, and
>> will break when given "29-Feb" as input.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 9, 2016 4:15:31 PM PST, "Dalthorp, Daniel"
><ddalthorp at usgs.gov>
>> wrote:
>>>
>>> Or:
>>>
>>> x <- c( "3-Oct", "10-Nov" )
>>>
>format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
>>>
>>> # the 'paste0' appends a year to the text vector
>>> # the 'as.Date' interprets the strings as dates with format 
>10-Jun-2016
>>> (e.g.)
>>> # the 'format' returns a string with date in format '%b' (which is
>just
>>> the name of the month)
>>>
>>> On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>>> Your dates are incomplete (no year) so I suggest staying away from
>the
>>>> date functions for this. Read ?regex and ?sub.
>>>>
>>>> x <- c( "3-Oct", "10-Nov" )
>>>> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
>>>>
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com>
>wrote:
>>>> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>>>> >
>>>> >I want to create a variable of just the month.  If I convert the
>date
>>>> >to a character string, substr is ineffective because some of the
>dates
>>>> >have 5 characters (3-Oct) and some have 6 (10-Oct).
>>>> >
>>>> >Is there a date function that accomplishes this easily?
>>>> >
>>>> >Ken
>>>> >kmnanus at gmail.com
>>>> >914-450-0816 (tel)
>>>> >347-730-4813 (fax)
>>>> >
>>>> >
>>>> >
>>>> >______________________________________________
>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >PLEASE do read the posting guide
>>>> >http://www.R-project.org/posting-guide.html
>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>> --
>>> Dan Dalthorp, PhD
>>> USGS Forest and Rangeland Ecosystem Science Center
>>> Forest Sciences Lab, Rm 189
>>> 3200 SW Jefferson Way
>>> Corvallis, OR 97331
>>> ph: 541-750-0953
>>> ddalthorp at usgs.gov
>>>
>>>
>
>
>-- 
>Dan Dalthorp, PhD
>USGS Forest and Rangeland Ecosystem Science Center
>Forest Sciences Lab, Rm 189
>3200 SW Jefferson Way
>Corvallis, OR 97331
>ph: 541-750-0953
>ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Thu Mar 10 02:24:10 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 9 Mar 2016 17:24:10 -0800
Subject: [R] extracting months from a data
In-Reply-To: <AF439D19-5F1A-42D8-8B36-182CCD453FDD@dcn.davis.ca.us>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
	<EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>
	<CAJeYpE9JXEZ7PTAuwK_fgcBCAB5HmfatLBzcwsL4jGLy7cdoCQ@mail.gmail.com>
	<AF439D19-5F1A-42D8-8B36-182CCD453FDD@dcn.davis.ca.us>
Message-ID: <CAJeYpE-RSORWeL5V0wVmnG0JuQJZk3NS+p3x66NTc4hyk-ZZfg@mail.gmail.com>

How about the following, which is both faster and simpler than either the
as.Date(...) or sub(...) solutions discussed earlier:

substring(x,first=nchar(x)-2)

require(microbenchmark)
microbenchmark(format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b'))
# 59.3 microseconds on my computer
microbenchmark(sub( "^\\d+-([A-Za-z]{3})$", "\\1", x ))
# 17.4 microseconds
microbenchmark(substring(x,first=nchar(x)-2))
# 3.6 microseconds

-Dan

On Wed, Mar 9, 2016 at 5:08 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> How about slower? That is objective.
>
> I use dates all the time so I am quite familiar with what they are good
> for. However, I prefer to avoid inventing information such as which year
> the date should have included unless I have to based on knowledge of the
> data source. It is not good to mislead the consumer of output about the
> existence of year information if it wasn't there to begin with.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 9, 2016 4:49:18 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov>
> wrote:
>>
>> Good point about 29-Feb...fixed in the following:
>>
>> format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b')
>>
>> # Also: The date functions can be used to easily calculate passage of
>> time and offer good flexibility for formatting output.
>>
>> -Dan
>>
>> P.S. "harder to understand" is in the eye of the beholder (as is
>> "recommended").
>>
>>
>>
>> On Wed, Mar 9, 2016 at 4:39 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> Still not recommended. That takes more steps, is harder to understand,
>>> and will break when given "29-Feb" as input.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 9, 2016 4:15:31 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov>
>>> wrote:
>>>>
>>>> Or:
>>>>
>>>> x <- c( "3-Oct", "10-Nov" )
>>>> format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
>>>>
>>>> # the 'paste0' appends a year to the text vector
>>>> # the 'as.Date' interprets the strings as dates with format
>>>>  10-Jun-2016 (e.g.)
>>>> # the 'format' returns a string with date in format '%b' (which is just
>>>> the name of the month)
>>>>
>>>> On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller <
>>>> jdnewmil at dcn.davis.ca.us> wrote:
>>>>
>>>>> Your dates are incomplete (no year) so I suggest staying away from the
>>>>> date functions for this. Read ?regex and ?sub.
>>>>>
>>>>> x <- c( "3-Oct", "10-Nov" )
>>>>> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
>>>>>
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
>>>>> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
>>>>> >
>>>>> >I want to create a variable of just the month.  If I convert the date
>>>>> >to a character string, substr is ineffective because some of the dates
>>>>> >have 5 characters (3-Oct) and some have 6 (10-Oct).
>>>>> >
>>>>> >Is there a date function that accomplishes this easily?
>>>>> >
>>>>> >Ken
>>>>> >kmnanus at gmail.com
>>>>> >914-450-0816 (tel)
>>>>> >347-730-4813 (fax)
>>>>> >
>>>>> >
>>>>> >
>>>>> >______________________________________________
>>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >PLEASE do read the posting guide
>>>>> >http://www.R-project.org/posting-guide.html
>>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Dan Dalthorp, PhD
>>>> USGS Forest and Rangeland Ecosystem Science Center
>>>> Forest Sciences Lab, Rm 189
>>>> 3200 SW Jefferson Way
>>>> Corvallis, OR 97331
>>>> ph: 541-750-0953
>>>> ddalthorp at usgs.gov
>>>>
>>>>
>>
>>
>> --
>> Dan Dalthorp, PhD
>> USGS Forest and Rangeland Ecosystem Science Center
>> Forest Sciences Lab, Rm 189
>> 3200 SW Jefferson Way
>> Corvallis, OR 97331
>> ph: 541-750-0953
>> ddalthorp at usgs.gov
>>
>>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Mar 10 02:36:51 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 9 Mar 2016 17:36:51 -0800
Subject: [R] extracting months from a data
In-Reply-To: <CAJeYpE-RSORWeL5V0wVmnG0JuQJZk3NS+p3x66NTc4hyk-ZZfg@mail.gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
	<EC4D8B75-71E4-49BA-A5AB-C319CF2428D0@dcn.davis.ca.us>
	<CAJeYpE9JXEZ7PTAuwK_fgcBCAB5HmfatLBzcwsL4jGLy7cdoCQ@mail.gmail.com>
	<AF439D19-5F1A-42D8-8B36-182CCD453FDD@dcn.davis.ca.us>
	<CAJeYpE-RSORWeL5V0wVmnG0JuQJZk3NS+p3x66NTc4hyk-ZZfg@mail.gmail.com>
Message-ID: <CAF8bMcbvLMbGN=sbe_xpWTY38A6udW1TNfgcjMc3hMM3vVGCtg@mail.gmail.com>

How much do you care about dealing with misformatted date strings, like
"111-Oct"
or "12-Mai"?  Flagging those may be more important than milliseconds of CPU
time.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 9, 2016 at 5:24 PM, Dalthorp, Daniel <ddalthorp at usgs.gov> wrote:

> How about the following, which is both faster and simpler than either the
> as.Date(...) or sub(...) solutions discussed earlier:
>
> substring(x,first=nchar(x)-2)
>
> require(microbenchmark)
> microbenchmark(format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b'))
> # 59.3 microseconds on my computer
> microbenchmark(sub( "^\\d+-([A-Za-z]{3})$", "\\1", x ))
> # 17.4 microseconds
> microbenchmark(substring(x,first=nchar(x)-2))
> # 3.6 microseconds
>
> -Dan
>
> On Wed, Mar 9, 2016 at 5:08 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > How about slower? That is objective.
> >
> > I use dates all the time so I am quite familiar with what they are good
> > for. However, I prefer to avoid inventing information such as which year
> > the date should have included unless I have to based on knowledge of the
> > data source. It is not good to mislead the consumer of output about the
> > existence of year information if it wasn't there to begin with.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On March 9, 2016 4:49:18 PM PST, "Dalthorp, Daniel" <ddalthorp at usgs.gov>
> > wrote:
> >>
> >> Good point about 29-Feb...fixed in the following:
> >>
> >> format(as.Date(paste0(x,"-2016"),format='%d-%b-%Y'),'%b')
> >>
> >> # Also: The date functions can be used to easily calculate passage of
> >> time and offer good flexibility for formatting output.
> >>
> >> -Dan
> >>
> >> P.S. "harder to understand" is in the eye of the beholder (as is
> >> "recommended").
> >>
> >>
> >>
> >> On Wed, Mar 9, 2016 at 4:39 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> Still not recommended. That takes more steps, is harder to understand,
> >>> and will break when given "29-Feb" as input.
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> On March 9, 2016 4:15:31 PM PST, "Dalthorp, Daniel" <
> ddalthorp at usgs.gov>
> >>> wrote:
> >>>>
> >>>> Or:
> >>>>
> >>>> x <- c( "3-Oct", "10-Nov" )
> >>>>
> format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
> >>>>
> >>>> # the 'paste0' appends a year to the text vector
> >>>> # the 'as.Date' interprets the strings as dates with format
> >>>>  10-Jun-2016 (e.g.)
> >>>> # the 'format' returns a string with date in format '%b' (which is
> just
> >>>> the name of the month)
> >>>>
> >>>> On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller <
> >>>> jdnewmil at dcn.davis.ca.us> wrote:
> >>>>
> >>>>> Your dates are incomplete (no year) so I suggest staying away from
> the
> >>>>> date functions for this. Read ?regex and ?sub.
> >>>>>
> >>>>> x <- c( "3-Oct", "10-Nov" )
> >>>>> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
> >>>>>
> >>>>> --
> >>>>> Sent from my phone. Please excuse my brevity.
> >>>>>
> >>>>> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com> wrote:
> >>>>> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
> >>>>> >
> >>>>> >I want to create a variable of just the month.  If I convert the
> date
> >>>>> >to a character string, substr is ineffective because some of the
> dates
> >>>>> >have 5 characters (3-Oct) and some have 6 (10-Oct).
> >>>>> >
> >>>>> >Is there a date function that accomplishes this easily?
> >>>>> >
> >>>>> >Ken
> >>>>> >kmnanus at gmail.com
> >>>>> >914-450-0816 (tel)
> >>>>> >347-730-4813 (fax)
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >______________________________________________
> >>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> >PLEASE do read the posting guide
> >>>>> >http://www.R-project.org/posting-guide.html
> >>>>> >and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> Dan Dalthorp, PhD
> >>>> USGS Forest and Rangeland Ecosystem Science Center
> >>>> Forest Sciences Lab, Rm 189
> >>>> 3200 SW Jefferson Way
> >>>> Corvallis, OR 97331
> >>>> ph: 541-750-0953
> >>>> ddalthorp at usgs.gov
> >>>>
> >>>>
> >>
> >>
> >> --
> >> Dan Dalthorp, PhD
> >> USGS Forest and Rangeland Ecosystem Science Center
> >> Forest Sciences Lab, Rm 189
> >> 3200 SW Jefferson Way
> >> Corvallis, OR 97331
> >> ph: 541-750-0953
> >> ddalthorp at usgs.gov
> >>
> >>
>
>
> --
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Mar 10 02:43:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 10 Mar 2016 12:43:48 +1100
Subject: [R] group by rows
In-Reply-To: <4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
References: <CAM_vjumOYH2xSCdNXowXF7tAfAEYFAguTnfTvSSLBexvKdfz_g@mail.gmail.com>
	<4082055.5173951.1457530099886.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fWVZeaF6M_Ud2Jzbujq3FsNy2hjeY-xPHZVz4iai2Ei_A@mail.gmail.com>

Hi carol,
You could use the "I" function, which will just return what you pass to it.

Jim


On Thu, Mar 10, 2016 at 12:28 AM, carol white via R-help
<r-help at r-project.org> wrote:
> What should be FUN in aggregate as no function like mean, sum etc will be applied
> Carol
>
>     On Wednesday, March 9, 2016 1:59 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
>
>  Possibly aggregate(), but you posted in HTML so your data were mangled.
>
> Please use dput(), post in plain text, and try to explain more clearly
> what you want the result to look like.
>
> Sarah
>
> On Wed, Mar 9, 2016 at 7:09 AM, carol white via R-help
> <r-help at r-project.org> wrote:
>> How is it possible to group rows of a matrix or a data frame by the same values of the first column?
>> 1 14331 453452 653 3762 45
>>
>> 1 1433,453452 45, 653 376
>> Thanks
>>
>> Carol
>>
>>        [[alternative HTML version deleted]]
>>
>> ___________________
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Mar 10 03:38:39 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 10 Mar 2016 13:38:39 +1100
Subject: [R] replace text by uniqe number
In-Reply-To: <DUB125-W14927777D0C8D622539401B3B30@phx.gbl>
References: <DUB125-W90ECDED878F7AC5B18736CB3FF0@phx.gbl>
	<CAGxFJbS7ovHOqqE4kGtrj4D2bdzh80G2hdjaFyB7_MHQhuc-JA@mail.gmail.com>
	<DUB125-W70EC720B33389D714D927CB3FF0@phx.gbl>
	<CAGxFJbSsREVTz1eRLCtxYXt87HTy04e3K1SRWywyNGZdw3qORg@mail.gmail.com>
	<CAKVAULOYztHoLUr6AorMbiYtZe+4Zg8YHTjjGRDT89cp024UQQ@mail.gmail.com>
	<DUB125-W14927777D0C8D622539401B3B30@phx.gbl>
Message-ID: <CA+8X3fV5Fo3oUFmi3i2yVWWymTX4CpBWV7FdWXK1yWb9aaN=Jw@mail.gmail.com>

Hi Ragia,
If you have read in your data frame with read.table or similar and not
specified stringsAsFactors=FALSE, the two columns will already be
factors. However, unless they both contain the same number of unique
values, the numbers associated with those levels won't be the same.
Probably the easiest way to get the same IDs for both is to read in
the data with stringsAsFactors=FALSE and then convert the two columns:

url_levels<-unique(unlist(otf_data))
otf_data[,1]<-factor(otf_data[,1],levels=url_levels)
otf_data[,2]<-factor(otf_data[,2],levels=url_levels)

Jim


On Wed, Mar 9, 2016 at 7:10 PM, Ragia . <ragia11 at hotmail.com> wrote:
> Dear group
> kindly if i had data frame of 2 columns that has repeated URLS ..and want to replace those urls with ID's for each one so the url will have
> unique ID, how  can I do this
> thanks in advance
> e.g otf  data
>
> pcworld.com     open.itworld.com
> pcworld.com     storage.itworld.com
> salon.com       images.salon.com
> go.theregister.com      theregister.co.uk
> techchuck.com   pcworld.com
> ecoustics.com   pcworld.com
>
> Ragia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sunnysingha.analytics at gmail.com  Thu Mar 10 08:56:44 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Thu, 10 Mar 2016 13:26:44 +0530
Subject: [R] Help -- feed data frames, returned from function into list --
Message-ID: <CANOG_FUvog5FoSmTtoWABKvGUA246WcZLnCP=8CDsHWGuBL+-Q@mail.gmail.com>

Hi,
I got a problem. Using loop, I'm trying to feed data frames, returned from
the function, into the list but not all data frames are getting captured.

I have vector with some string values which I want to pass to the function.

*groups* <- c('cocacola', 'youtube','facebook)

for(i in 1:length(groups)){
 g <- list()
 g[[i]] <- searchGroups_mod(*groups[i]*, token=fb_oauth, 10)
}

The result list stores data frame only for the last string in the 'groups'
vector.
Why the List is getting reassigned for each iteration ? Please guide.

Regards,
Sunny Singha.

	[[alternative HTML version deleted]]


From aubologn at ulb.ac.be  Thu Mar 10 08:32:49 2016
From: aubologn at ulb.ac.be (Audrey Bologna)
Date: Thu, 10 Mar 2016 08:32:49 +0100
Subject: [R] Survival analysis with interval censored data
Message-ID: <CAKF44_MB4C=_+PAB43X0FxasL7ng_Aix1-QqoBffX51swNLVuA@mail.gmail.com>

Hi!

Does anyone know about survival analysis using interval censored data and
the intcox package?

I fed different ant colonies with different food (called treatment) and I
measured every 2 days the death of ants. I would like to see if the
treatment can explain a different death of individuals.
Since I checked the death every 2 days, I assume that my datas are interval
censored.
Here is a part of my dataset, an exemple for one colony (1A):

date date2 fate colony condition
1 2 3     1A before
1 4 3     1A before
1 4 3     1A before
1 8 3      1A before
1 14 3      1A before
1 16 3       1A before
1 20 0      1 A before
1 20 0      1A before
1 20 0      1A before
1 20 0      1A before
1 20 0       1A before






date corresponds to the beginning of my experiment: the 21st of January and
I called it 1.
date 2 corresponds to the date of the death: 2= 23rd of Janurary, 3= 25th
of January and so one.
Fate: 3 a death event for interval censored data, 0 when individuals are
still alive.

I created a survival object this way:

surv.object<-Surv(test$date1,test$date,test$fate,type="interval") and here
is a part of what I obtain as a survival object:


[1901] [1,  4] [1,  6] [1,  6] [1,  8] [1,  8] [1,  8] [1,  8] [1, 10] [1,
10] [1, 10]
[1911] [1, 10] [1, 12] [1, 16] [1, 16] [1, 16] [1, 18] [1, 20] 1+      1+
   1+
[1921] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1931] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1941] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1951] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1961] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1971] 1+      1+      1+      1+      1+      1+      1+      1+      1+
   1+
[1981] 1+      1+      1+      1+


However when I try to apply the intcox function, it returns me warnings
messages:

 ex<-intcox(surv.object~test$colony, data=test)
Erreur dans if (any(derivs.wert$g1 <= 0)) { :
  valeur manquante l? o? TRUE / FALSE est requis
De plus : Message d'avis :
In coxph(formula, data) :
  X matrix deemed to be singular; variable 1 2 3 4 5 6 7 8 9 10 11 12 13 14
15 16 17 18 19 22


Can anybody help me?

Thanks a lot


Audrey Bologna - PhD Student
Unit of Social Ecology
Universit? libre de Bruxelles, CP 231
Boulevard du Triomphe
B-1050 Brussels
Belgium

 http://www.ulb.ac.be/sciences/use/bologna.html

	[[alternative HTML version deleted]]


From J.Hillier at lboro.ac.uk  Thu Mar 10 09:22:18 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Thu, 10 Mar 2016 08:22:18 +0000
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
Message-ID: <AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>

Thank you Peter,

I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to 
> pdataH <- data.frame(y = H_to_fit$Height)
This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.

John

-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: 09 March 2016 19:58
To: John Hillier
Cc: r-help at r-project.org
Subject: Re: [R] truncpareto() - doesn't like my data and odd error message

> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>
> Dear All,
>
>
> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>
>
> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>
>
> When I try to run my data, I get the output below. Inputs shown with chevrons.
>
>
>> pdataH <- data.frame(H_to_fit$Height)
>> summary(pdataH)
>   H_to_fit.Height
>   Min.   :2000
>   1st Qu.:2281
>
>   Median :2666
>   Mean   :2825
>   3rd Qu.:3212
>   Max.   :4794
>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
> Error in eval(expr, envir, enclos) :
>  the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>
>
> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>
>
> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>

Umm, it doesn't seem to have a column called "y"?

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bhh at xs4all.nl  Thu Mar 10 09:27:33 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 10 Mar 2016 09:27:33 +0100
Subject: [R] Help -- feed data frames,
	returned from function into list --
In-Reply-To: <CANOG_FUvog5FoSmTtoWABKvGUA246WcZLnCP=8CDsHWGuBL+-Q@mail.gmail.com>
References: <CANOG_FUvog5FoSmTtoWABKvGUA246WcZLnCP=8CDsHWGuBL+-Q@mail.gmail.com>
Message-ID: <978E5BA1-F160-4EC7-8F98-1BB0FCA5397D@xs4all.nl>


> On 10 Mar 2016, at 08:56, Sunny Singha <sunnysingha.analytics at gmail.com> wrote:
> 
> Hi,
> I got a problem. Using loop, I'm trying to feed data frames, returned from
> the function, into the list but not all data frames are getting captured.
> 
> I have vector with some string values which I want to pass to the function.
> 
> *groups* <- c('cocacola', 'youtube','facebook)
> 

You posted in HTML. In a plain text mailing list we see *groups* which is nonsense. You boldified?
Please do not do that and do not post in HTML.

> for(i in 1:length(groups)){
> g <- list()
> g[[i]] <- searchGroups_mod(*groups[i]*, token=fb_oauth, 10)
> }
> 
> The result list stores data frame only for the last string in the 'groups'
> vector.
> Why the List is getting reassigned for each iteration ? Please guide.
> 

Because you are creating the list g inside the loop.
Put the g <- list) before the loop.

> Regards,
> Sunny Singha.
> 
> 	[[alternative HTML version deleted]]__

This is a plain text mailinglist. Do not post in HTML.

Berend

> ____________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sebastien.moretti at unil.ch  Thu Mar 10 09:43:19 2016
From: sebastien.moretti at unil.ch (Sebastien Moretti)
Date: Thu, 10 Mar 2016 09:43:19 +0100
Subject: [R] .Call works in R 2 not in R 3
In-Reply-To: <9307D691-7E27-4A9E-9B2B-87FE150967B6@univie.ac.at>
References: <56DEB10F.3080204@unil.ch>
	<56DED7B1.3030703@statistik.tu-dortmund.de> <56DED9DD.1080507@unil.ch>
	<9307D691-7E27-4A9E-9B2B-87FE150967B6@univie.ac.at>
Message-ID: <56E133A7.5010606@unil.ch>

Hi

Using  cutree(tree$merge, k)  fixed the problem.
In fact had to use  cutree(tree["merge"], k)

Will compare results in R 2 and R 3 now.

Thanks for your help.
S?bastien

> cutree is a function available in stats.
> So it might be worth a try to just replace
>
> .Call("R_cutree", tree$merge, k, PACKAGE = "stats?)
>
> by
>
> cutree(tree$merge,k)
>
> and see what happens.
>
> checking the source of cutree shows the following call
>
>      ans <- .Call(C_cutree, tree$merge, k)
>
> so replacing R_cutree by C_cutree also might be an option.
> But, of course as Uwe recommended,
> using a plain R call and not using .Call is the preferred solution.
>
>
>> On Mar 8, 2016, at 14:55, Sebastien Moretti <sebastien.moretti at unil.ch> wrote:
>>
>>>> Hi
>>>>
>>>> I inherited a R package done in 2004 that works perfectly in R 2.15.1
>>>> and before, but not in R 3.2.2 ( >= 3).
>>>>
>>>> I have already fixed issues with namespace for functions in R 3 but
>>>> maybe not all of them.
>>>>
>>>> Here is the error message:
>>>> Error in .Call("R_cutree", tree$merge, k, PACKAGE = "stats")
>>>> "R_cutree" not available for .Call() for package "stats"
>>>
>>> Why do you .Call() into another package? Rather use the API.
>>
>> Let's say that I am far from a R master.
>> I never use .Call() myself.
>>
>> I want the code works again in R >= 3 because R support for R 2 will soon be stopped in my institute.
>> When the code will work again, I could change internals by comparing results with R 2 and R 3.
>>
>>> Best,
>>> Uwe Ligges
>>>
>>>>
>>>> Thanks for your help

--
S?bastien Moretti


From pdalgd at gmail.com  Thu Mar 10 10:36:09 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 10:36:09 +0100
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
	<AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>

Also if you simultaneously change the 2000 to say 1999?

-p

On 10 Mar 2016, at 09:22 , John Hillier <J.Hillier at lboro.ac.uk> wrote:

> Thank you Peter,
> 
> I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to 
>> pdataH <- data.frame(y = H_to_fit$Height)
> This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.
> 
> John
> 
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
> 
> ________________________________________
> From: peter dalgaard <pdalgd at gmail.com>
> Sent: 09 March 2016 19:58
> To: John Hillier
> Cc: r-help at r-project.org
> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
> 
>> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>> 
>> Dear All,
>> 
>> 
>> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>> 
>> 
>> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>> 
>> 
>> When I try to run my data, I get the output below. Inputs shown with chevrons.
>> 
>> 
>>> pdataH <- data.frame(H_to_fit$Height)
>>> summary(pdataH)
>>  H_to_fit.Height
>>  Min.   :2000
>>  1st Qu.:2281
>> 
>>  Median :2666
>>  Mean   :2825
>>  3rd Qu.:3212
>>  Max.   :4794
>>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
>> Error in eval(expr, envir, enclos) :
>> the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>> 
>> 
>> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>> 
>> 
>> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>> 
> 
> Umm, it doesn't seem to have a column called "y"?
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd.mes at cbs.dk  Thu Mar 10 10:45:50 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 10 Mar 2016 09:45:50 +0000
Subject: [R] R 3.2.4 is released
Message-ID: <F7BD53EB-4322-41F1-9045-577F9E1D2502@cbs.dk>

The build system rolled up  R-3.2.4.tar.gz (codename "Very Secure Dishes") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.4.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:


MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = d2e93152b963acbb53027c355dda539a
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 087f64ddfe922d2a565ff64bb8543039
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 5953104583ed93dc2085a6c80e884e4a
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = ba00f6cc68a823e1741cfa6011f40ccb
MD5 (VERSION-INFO.dcf) = 71584fcd5c399b40750fcd7113521636
MD5 (R-3/R-3.2.4.tar.gz) = 5953104583ed93dc2085a6c80e884e4a


This is the relevant part of the NEWS file

CHANGES IN R 3.2.4:

  NEW FEATURES:

    * install.packages() and related functions now give a more
      informative warning when an attempt is made to install a base
      package.

    * summary(x) now prints with less rounding when x contains infinite
      values. (Request of PR#16620.)

    * provideDimnames() gets an optional unique argument.

    * shQuote() gains type = "cmd2" for quoting in cmd.exe in Windows.
      (Response to PR#16636.)

    * The data.frame method of rbind() gains an optional argument
      stringsAsFactors (instead of only depending on
      getOption("stringsAsFactors")).

    * smooth(x, *) now also works for long vectors.

    * tools::texi2dvi() has a workaround for problems with the texi2dvi
      script supplied by texinfo 6.1.

      It extracts more error messages from the LaTeX logs when in
      emulation mode.

  UTILITIES:

    * R CMD check will leave a log file build_vignettes.log from the
      re-building of vignettes in the .Rcheck directory if there is a
      problem, and always if environment variable
      _R_CHECK_ALWAYS_LOG_VIGNETTE_OUTPUT_ is set to a true value.

  DEPRECATED AND DEFUNCT:

    * Use of SUPPORT_OPENMP from header Rconfig.h is deprecated in
      favour of the standard OpenMP define _OPENMP.

      (This has been the recommendation in the manual for a while now.)

    * The make macro AWK which is long unused by R itself but recorded
      in file etc/Makeconf is deprecated and will be removed in R
      3.3.0.

    * The C header file S.h is no longer documented: its use should be
      replaced by R.h.

  BUG FIXES:

    * kmeans(x, centers = <1-row>) now works. (PR#16623)

    * Vectorize() now checks for clashes in argument names.  (PR#16577)

    * file.copy(overwrite = FALSE) would signal a successful copy when
      none had taken place.  (PR#16576)

    * ngettext() now uses the same default domain as gettext().
      (PR#14605)

    * array(.., dimnames = *) now warns about non-list dimnames and,
      from R 3.3.0, will signal the same error for invalid dimnames as
      matrix() has always done.

    * addmargins() now adds dimnames for the extended margins in all
      cases, as always documented.

    * heatmap() evaluated its add.expr argument in the wrong
      environment.  (PR#16583)

    * require() etc now give the correct entry of lib.loc in the
      warning about an old version of a package masking a newer
      required one.

    * The internal deparser did not add parentheses when necessary,
      e.g. before [] or [[]].  (Reported by Lukas Stadler; additional
      fixes included as well).

    * as.data.frame.vector(*, row.names=*) no longer produces
      'corrupted' data frames from row names of incorrect length, but
      rather warns about them.  This will become an error.

    * url connections with method = "libcurl" are destroyed properly.
      (PR#16681)

    * withCallingHandler() now (again) handles warnings even during S4
      generic's argument evaluation.  (PR#16111)

    * deparse(..., control = "quoteExpressions") incorrectly quoted
      empty expressions.  (PR#16686)

    * format()ting datetime objects ("POSIX[cl]?t") could segfault or
      recycle wrongly.  (PR#16685)

    * plot.ts(<matrix>, las = 1) now does use las.

    * saveRDS(*, compress = "gzip") now works as documented.
      (PR#16653)

    * (Windows only) The Rgui front end did not always initialize the
      console properly, and could cause R to crash.  (PR#16998)

    * dummy.coef.lm() now works in more cases, thanks to a proposal by
      Werner Stahel (PR#16665).  In addition, it now works for
      multivariate linear models ("mlm", manova) thanks to a proposal
      by Daniel Wollschlaeger.

    * The as.hclust() method for "dendrogram"s failed often when there
      were ties in the heights.

    * reorder() and midcache.dendrogram() now are non-recursive and
      hence applicable to somewhat deeply nested dendrograms, thanks to
      a proposal by Suharto Anggono in PR#16424.

    * cor.test() now calculates very small p values more accurately
      (affecting the result only in extreme not statistically relevant
      cases).  (PR#16704)

    * smooth(*, do.ends=TRUE) did not always work correctly in R
      versions between 3.0.0 and 3.2.3.

    * pretty(D) for date-time objects D now also works well if range(D)
      is (much) smaller than a second.  In the case of only one unique
      value in D, the pretty range now is more symmetric around that
      value than previously.

      Similarly, pretty(dt) no longer returns a length 5 vector with
      duplicated entries for Date objects dt which span only a few
      days.

    * The figures in help pages such as ?points were accidentally
      damaged, and did not appear in R 3.2.3.  (PR#16708)

    * available.packages() sometimes deleted the wrong file when
      cleaning up temporary files.  (PR#16712)

    * The X11() device sometimes froze on Red Hat Enterprise Linux 6.
      It now waits for MapNotify events instead of Expose events,
      thanks to Siteshwar Vashisht. (PR#16497)

    * [dpqr]nbinom(*, size=Inf, mu=.) now works as limit case, for
      'dpq' as the Poisson.  (PR#16727)
      pnbinom() no longer loops infinitely in border cases.

    * approxfun(*, method="constant") and hence ecdf() which calls the
      former now correctly "predict" NaN values as NaN.

    * summary.data.frame() now displays NAs in Date columns in all
      cases.  (PR#16709)




-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From milujisb at gmail.com  Thu Mar 10 12:06:38 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 10 Mar 2016 12:06:38 +0100
Subject: [R] Map of Europe at NUTS 2 Level
Message-ID: <CAMLwc7P1ArHa0m0_Bf6G-JTdzuWJUr5VfDyjZ2szCKjeO2AMzA@mail.gmail.com>

Dear all.

I would like to draw a map of France, Italy, Spain, and Portugal at NUTS 2
level. I used the following code:

library(?rgdal?)
library(?RColorBrewer?)
library(?classInt?)
#library(?SmarterPoland?)
library(fields)

# Download Administrative Level data from EuroStat
temp <- tempfile(fileext = ".zip")
download.file("
http://ec.europa.eu/eurostat/cache/GISCO/geodatafiles/NUTS_2010_60M_SH.zip
",
              temp)
unzip(temp)

# Read data
EU_NUTS <- readOGR(dsn = "./NUTS_2010_60M_SH/data", layer =
"NUTS_RG_60M_2010")

# Subset NUTS 2 level data
map_nuts2 <- subset(EU_NUTS, STAT_LEVL_ == 2)

# Draw basic plot
plot(map_nuts2)

This does produce a plot but its rather 'ugle'. Is there any way I can
subset the data further and draw a map for France, Italy, Spain, and
Portugal only? Thank you very much!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Thu Mar 10 15:58:20 2016
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 10 Mar 2016 14:58:20 +0000
Subject: [R] FUNCTION ctree
Message-ID: <1457621899893.22679@unine.ch>

Dear all,


I am using Rstudio. What to do when you get this message?

Error in plot(ctree(Surv(hours, state) ~ soil + volatile, data = data)) :
  could not find function "ctree"

Thank you,


Xavier


From amos.elberg at gmail.com  Mon Mar  7 20:33:40 2016
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Mon, 7 Mar 2016 14:33:40 -0500
Subject: [R] [R-pkgs] rZeppelin: An R notebook that makes Spark easy to use
Message-ID: <CAGaD6pw9Nxb3embEwxysWeO4dtaiY+J36wU+rJOQCJ+MYuhdbw@mail.gmail.com>

rZeppelin is an R interpreter for Apache (incubating) Zeppelin.  Zeppelin
is a notebook, sort of like iPython, built on top of Apache Spark.

rZeppelin makes it possible, for the first time, to create a single data/ML
pipeline that mixes R, scala, and Python code, seamlessly, from a single
interface.  (Without breaking lazy evaluation!)

For R-using data scientists, this means that you can access the full power
of Spark ? including ultra-fast distributed implementations of popular
algorithms ? using R, without having to learn scala, without a dedicated
administrator to manage a Spark or Hadoop cluster, and without spending
more than minimal time to review the SparkR api.

You can load text data using R, quickly create an LDA model using Spark?s
distributed LDA package, tag the text using gensim from Python, and then
visualize and take further steps from R, from a single session using a
single interface.

The full range of Spark packages, including MLLIB and GraphX, which used to
require scala development, can be used in the same pipeline with R.
(Except Spark Streaming, which Zeppelin doesn?t yet support.)

Beyond Spark, R data can be visualized using Zeppelin?s built-in
interactive visualizations.  rZeppelin also leverages knitr to make
available most R visualization and interactive visualization packages.

Many data types are also easily moved between R, scala and Python:  the
languages share a ZeppelinContext, where variables can be added and
extracted with .z.put() and .z.get().

rZeppelin is intended to make Spark part of the R data scientist?s daily
toolbox.

rZeppelin is available here:  https://github.com/elbamos/Zeppelin-With-R

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From sarah.goslee at gmail.com  Thu Mar 10 16:11:41 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 10 Mar 2016 10:11:41 -0500
Subject: [R] FUNCTION ctree
In-Reply-To: <1457621899893.22679@unine.ch>
References: <1457621899893.22679@unine.ch>
Message-ID: <CAM_vju=Xo50UkYTp4mAH9iV4vhoZr70EdoRFfnyABbTnzDtXVA@mail.gmail.com>

Probably load the package that ctree() comes from, possibly party.

library(party)

The code you're looking at should tell you.

On Thu, Mar 10, 2016 at 9:58 AM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear all,
>
>
> I am using Rstudio. What to do when you get this message?
>
> Error in plot(ctree(Surv(hours, state) ~ soil + volatile, data = data)) :
>   could not find function "ctree"
>
> Thank you,
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From erich.neuwirth at univie.ac.at  Thu Mar 10 16:13:24 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 10 Mar 2016 16:13:24 +0100
Subject: [R] FUNCTION ctree
In-Reply-To: <1457621899893.22679@unine.ch>
References: <1457621899893.22679@unine.ch>
Message-ID: <1E7005F1-DA60-4EB3-88BF-03A5BAAAC223@univie.ac.at>

If you do
??ctree
and the package partykit is installed, you will see that this function is defined in this package.
So, you should run
library(partykit)
before running your function call

If partykit is not installed, you need to install it.





> On Mar 10, 2016, at 15:58, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
> 
> Dear all,
> 
> 
> I am using Rstudio. What to do when you get this message?
> 
> Error in plot(ctree(Surv(hours, state) ~ soil + volatile, data = data)) :
>  could not find function "ctree"
> 
> Thank you,
> 
> 
> Xavier
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160310/7ceebfd3/attachment.bin>

From fazulur.r at ocimumbio.com  Thu Mar 10 13:52:45 2016
From: fazulur.r at ocimumbio.com (Fazulur Rehaman)
Date: Thu, 10 Mar 2016 18:22:45 +0530
Subject: [R] Navigation keys not working
Message-ID: <2DDF09AFEB46E54894A3843CEF9CB3A402462F0D8BC6@EXCHMB.ocimumbio.com>

Dear Sir/Madam,

Navigation keys not working in R installed on linux (Linux version 3.10.0-327.10.1.el7.x86_64). I am using R version 3.0.1. When I press up arrow its giving "^[[A".  Could you please suggest me how to overcome this problem.

Here is my R session Info

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> ^[[A^[[A^[[A^[[A^[[A^[[A

Thanks in Advance.
Rehaman

________________________________
This e-mail contains PRIVILEGED AND CONFIDENTIAL INFORMATION intended solely for the use of the addressee(s). If you are not the intended recipient, please notify the sender by e-mail and delete the original message. Further, you are not to copy, disclose, or distribute this e-mail or its contents to any other person and any such actions that are unlawful. This e-mail may contain viruses. Ocimum Biosolutions has taken every reasonable precaution to minimize this risk, but is not liable for any damage you may sustain as a result of any virus in this e-mail. You should carry out your own virus checks before opening the e-mail or attachment.

	[[alternative HTML version deleted]]


From peter.neumaier at gmail.com  Thu Mar 10 12:14:29 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 10 Mar 2016 11:14:29 +0000
Subject: [R] Conversion problem with write.csv and as.character()
Message-ID: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>

Hi all, sorry for double/cross posting, I have sent an initial, similar
question
accidentally to r-sig-finance.

I am writing a matrix (typeof = double) into a CSV file with write.csv.

My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:

> a_fetchdata[1,0]

2016-02-09 07:30:00
> typeof(a_fetchdata[1,0])
[1] "double"

My CSV file contains a sequence of integers (from 1 to x) instead of the
expected date.

I tried to convert, but ran into "Error in dimnames":

> as.character(first_fetchdata[1,0])
Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
  'dimnames' applied to non-array
Called from: as.matrix.xts(x)
Browse[1]> c
>

a) How can I prevent the conversion into integers to happen when writing
into CSV?
b) if a) is not do-able: how can I convert the date in double format to
chars (i.e. with as.character) ?

Thanks in advance,
Peter

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Thu Mar 10 16:24:08 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 10 Mar 2016 09:24:08 -0600
Subject: [R] Conversion problem with write.csv and as.character()
In-Reply-To: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
References: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
Message-ID: <CAPPM_gQyUPrdA5gXzmX5RPcU=NO4Ob6a2uS7DoZTdQHcNdRSPg@mail.gmail.com>

I already answered all your questions on R-SIG-Finance.

On Thu, Mar 10, 2016 at 5:14 AM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> Hi all, sorry for double/cross posting, I have sent an initial, similar
> question
> accidentally to r-sig-finance.
>
> I am writing a matrix (typeof = double) into a CSV file with write.csv.
>
> My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
>
>> a_fetchdata[1,0]
>
> 2016-02-09 07:30:00
>> typeof(a_fetchdata[1,0])
> [1] "double"
>
> My CSV file contains a sequence of integers (from 1 to x) instead of the
> expected date.
>
> I tried to convert, but ran into "Error in dimnames":
>
>> as.character(first_fetchdata[1,0])
> Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
>   'dimnames' applied to non-array
> Called from: as.matrix.xts(x)
> Browse[1]> c
>>
>
> a) How can I prevent the conversion into integers to happen when writing
> into CSV?
> b) if a) is not do-able: how can I convert the date in double format to
> chars (i.e. with as.character) ?
>
> Thanks in advance,
> Peter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From sarah.goslee at gmail.com  Thu Mar 10 16:25:14 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 10 Mar 2016 10:25:14 -0500
Subject: [R] Conversion problem with write.csv and as.character()
In-Reply-To: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
References: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
Message-ID: <CAM_vjukQ-G=SGTs1U9i4h1k1J6XVNxgf8DebE4efOEXK5QUArg@mail.gmail.com>

Hi Peter,

We really need a reproducible example to solve this kind of question.
Please use dput(head(yourdata)) to provide a sample of data (or make
up fake data that shows the same problems), and provide the code
you're using.

Sarah

On Thu, Mar 10, 2016 at 6:14 AM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> Hi all, sorry for double/cross posting, I have sent an initial, similar
> question
> accidentally to r-sig-finance.
>
> I am writing a matrix (typeof = double) into a CSV file with write.csv.
>
> My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
>
>> a_fetchdata[1,0]
>
> 2016-02-09 07:30:00
>> typeof(a_fetchdata[1,0])
> [1] "double"
>
> My CSV file contains a sequence of integers (from 1 to x) instead of the
> expected date.
>
> I tried to convert, but ran into "Error in dimnames":
>
>> as.character(first_fetchdata[1,0])
> Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
>   'dimnames' applied to non-array
> Called from: as.matrix.xts(x)
> Browse[1]> c
>>
>
> a) How can I prevent the conversion into integers to happen when writing
> into CSV?
> b) if a) is not do-able: how can I convert the date in double format to
> chars (i.e. with as.character) ?
>
> Thanks in advance,
> Peter
>


From loris.bennett at fu-berlin.de  Thu Mar 10 16:34:18 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 10 Mar 2016 16:34:18 +0100
Subject: [R] Navigation keys not working
References: <2DDF09AFEB46E54894A3843CEF9CB3A402462F0D8BC6@EXCHMB.ocimumbio.com>
Message-ID: <87r3fimjnp.fsf@hornfels.zedat.fu-berlin.de>

Hi,

Fazulur Rehaman <fazulur.r at ocimumbio.com> writes:

> Dear Sir/Madam,
>
> Navigation keys not working in R installed on linux (Linux version
> 3.10.0-327.10.1.el7.x86_64). I am using R version 3.0.1. When I press
> up arrow its giving "^[[A".  Could you please suggest me how to
> overcome this problem.
>
> Here is my R session Info
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> ^[[A^[[A^[[A^[[A^[[A^[[A
>
> Thanks in Advance.
> Rehaman

It looks as if your version of R may not be linked to the readline
library.  You can check the shared libraries linked to the binary with
'ldd'. e.g.

$ ldd /usr/lib/R/bin/exec/R 
	linux-vdso.so.1 (0x00007fff235ed000)
	libR.so => /usr/lib/libR.so (0x00007f3bfa692000)
	libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f3bfa47c000)
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f3bfa25f000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3bf9eb4000)
	libblas.so.3 => /usr/lib/libblas.so.3 (0x00007f3bf9c34000)
	libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007f3bf9916000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3bf9615000)
	libquadmath.so.0 => /usr/lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007f3bf93d8000)
	libreadline.so.6 => /lib/x86_64-linux-gnu/libreadline.so.6 (0x00007f3bf918e000)
	libpcre.so.3 => /lib/x86_64-linux-gnu/libpcre.so.3 (0x00007f3bf8f20000)
	liblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f3bf8cfd000)
	libbz2.so.1.0 => /lib/x86_64-linux-gnu/libbz2.so.1.0 (0x00007f3bf8aed000)
	libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007f3bf88d2000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f3bf86ca000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f3bf84c6000)
	/lib64/ld-linux-x86-64.so.2 (0x00007f3bfabb8000)
	libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f3bf82b0000)
	libtinfo.so.5 => /lib/x86_64-linux-gnu/libtinfo.so.5 (0x00007f3bf8086000)

For the arrow keys to allow you to traverse the command history, you
will need an entry containing 'libreadline.so'.

If it is missing, you will have to rebuild R, making sure that the
'configure' option '--with-readline=yes' is set.  This is actually the
default, but you are using an old version of R, so it may not have been
back then.  Also your readline library might be in a strange place and
wasn't found by 'configure'.  In that case, you would have to ensure
that it is in the variable $LD_LIBRARY_PATH.

Cheers,

Loris

-- 
This signature is currently under construction.


From Achim.Zeileis at uibk.ac.at  Thu Mar 10 17:17:33 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 10 Mar 2016 17:17:33 +0100 (CET)
Subject: [R] FUNCTION ctree
In-Reply-To: <1E7005F1-DA60-4EB3-88BF-03A5BAAAC223@univie.ac.at>
References: <1457621899893.22679@unine.ch>
	<1E7005F1-DA60-4EB3-88BF-03A5BAAAC223@univie.ac.at>
Message-ID: <alpine.DEB.2.20.1603101716250.3680@paninaro>

Thanks to Erich and Sarah for the clarifications. For those wondering 
whether ctree() from "party" or from "partykit" should be used: the latter 
is the newer and improved implementation.

On Thu, 10 Mar 2016, Erich Neuwirth wrote:

> If you do
> ??ctree
> and the package partykit is installed, you will see that this function is defined in this package.
> So, you should run
> library(partykit)
> before running your function call
>
> If partykit is not installed, you need to install it.
>
>
>
>
>
>> On Mar 10, 2016, at 15:58, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
>>
>> Dear all,
>>
>>
>> I am using Rstudio. What to do when you get this message?
>>
>> Error in plot(ctree(Surv(hours, state) ~ soil + volatile, data = data)) :
>>  could not find function "ctree"
>>
>> Thank you,
>>
>>
>> Xavier
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From J.Hillier at lboro.ac.uk  Thu Mar 10 18:41:27 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Thu, 10 Mar 2016 17:41:27 +0000
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
	<AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>
Message-ID: <AM3PR04MB1490DC721E362CEF120AA258A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>

Thank you Peter,

Yes, it seems to do the same even if I simultaneously make that change.  Output below.

> pdataH <- data.frame(y = H_to_fit$Height)
> summary(pdataH)
       y       
 Min.   :2000  
 1st Qu.:2281  
 Median :2666  
 Mean   :2825  
 3rd Qu.:3212  
 Max.   :4794  
> fit3 <- vglm(y ~ 1, truncpareto(1999, 4794), data = pdataH, trace = TRUE)
Error in eval(expr, envir, enclos) : 
  the value of argument 'upper' is too low (requires 'max(y) < upper')

-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: 10 March 2016 09:36
To: John Hillier
Cc: r-help at r-project.org
Subject: Re: [R] truncpareto() - doesn't like my data and odd error message

Also if you simultaneously change the 2000 to say 1999?

-p

On 10 Mar 2016, at 09:22 , John Hillier <J.Hillier at lboro.ac.uk> wrote:

> Thank you Peter,
>
> I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to
>> pdataH <- data.frame(y = H_to_fit$Height)
> This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.
>
> John
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
> ________________________________________
> From: peter dalgaard <pdalgd at gmail.com>
> Sent: 09 March 2016 19:58
> To: John Hillier
> Cc: r-help at r-project.org
> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>
>> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>>
>> Dear All,
>>
>>
>> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>>
>>
>> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>>
>>
>> When I try to run my data, I get the output below. Inputs shown with chevrons.
>>
>>
>>> pdataH <- data.frame(H_to_fit$Height)
>>> summary(pdataH)
>>  H_to_fit.Height
>>  Min.   :2000
>>  1st Qu.:2281
>>
>>  Median :2666
>>  Mean   :2825
>>  3rd Qu.:3212
>>  Max.   :4794
>>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
>> Error in eval(expr, envir, enclos) :
>> the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>>
>>
>> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>>
>>
>> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>>
>
> Umm, it doesn't seem to have a column called "y"?
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Mar 10 18:49:02 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 18:49:02 +0100
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <AM3PR04MB1490DC721E362CEF120AA258A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
	<AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>
	<AM3PR04MB1490DC721E362CEF120AA258A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <9BDD9369-6929-49C6-A1F0-87809945E721@gmail.com>

Look closer....

-pd


> On 10 Mar 2016, at 18:41 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
> 
> Thank you Peter,
> 
> Yes, it seems to do the same even if I simultaneously make that change.  Output below.
> 
>> pdataH <- data.frame(y = H_to_fit$Height)
>> summary(pdataH)
>       y       
> Min.   :2000  
> 1st Qu.:2281  
> Median :2666  
> Mean   :2825  
> 3rd Qu.:3212  
> Max.   :4794  
>> fit3 <- vglm(y ~ 1, truncpareto(1999, 4794), data = pdataH, trace = TRUE)
> Error in eval(expr, envir, enclos) : 
>  the value of argument 'upper' is too low (requires 'max(y) < upper')
> 
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
> 
> ________________________________________
> From: peter dalgaard <pdalgd at gmail.com>
> Sent: 10 March 2016 09:36
> To: John Hillier
> Cc: r-help at r-project.org
> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
> 
> Also if you simultaneously change the 2000 to say 1999?
> 
> -p
> 
> On 10 Mar 2016, at 09:22 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
> 
>> Thank you Peter,
>> 
>> I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to
>>> pdataH <- data.frame(y = H_to_fit$Height)
>> This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.
>> 
>> John
>> 
>> -------------------------
>> Dr John Hillier
>> Senior Lecturer - Physical Geography
>> Loughborough University
>> 01509 223727
>> 
>> ________________________________________
>> From: peter dalgaard <pdalgd at gmail.com>
>> Sent: 09 March 2016 19:58
>> To: John Hillier
>> Cc: r-help at r-project.org
>> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>> 
>>> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>>> 
>>> Dear All,
>>> 
>>> 
>>> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>>> 
>>> 
>>> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>>> 
>>> 
>>> When I try to run my data, I get the output below. Inputs shown with chevrons.
>>> 
>>> 
>>>> pdataH <- data.frame(H_to_fit$Height)
>>>> summary(pdataH)
>>> H_to_fit.Height
>>> Min.   :2000
>>> 1st Qu.:2281
>>> 
>>> Median :2666
>>> Mean   :2825
>>> 3rd Qu.:3212
>>> Max.   :4794
>>>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
>>> Error in eval(expr, envir, enclos) :
>>> the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>>> 
>>> 
>>> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>>> 
>>> 
>>> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>>> 
>> 
>> Umm, it doesn't seem to have a column called "y"?
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From J.Hillier at lboro.ac.uk  Thu Mar 10 19:03:54 2016
From: J.Hillier at lboro.ac.uk (John Hillier)
Date: Thu, 10 Mar 2016 18:03:54 +0000
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <9BDD9369-6929-49C6-A1F0-87809945E721@gmail.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
	<AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>
	<AM3PR04MB1490DC721E362CEF120AA258A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>,
	<9BDD9369-6929-49C6-A1F0-87809945E721@gmail.com>
Message-ID: <AM3PR04MB149037BE22DC4D6A87F874B7A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>

Dear Peter,

Thank you. Apolgies for not looking closer.  It is the end of a long day. Fixed now, and I have learnt more about correctly interpreting R's manual pages.

For the record .... 

Summary: If input to truncpareto() is not explicitly called 'y' it can produce error messages about the values 'lower', which might be confusing.  So, ensure input is called 'y', and that 'lower' and 'upper' are just outside the range of y.

John

-------------------------
Dr John Hillier
Senior Lecturer - Physical Geography
Loughborough University
01509 223727

________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: 10 March 2016 17:49
To: John Hillier
Cc: r-help at r-project.org
Subject: Re: [R] truncpareto() - doesn't like my data and odd error message

Look closer....

-pd


> On 10 Mar 2016, at 18:41 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>
> Thank you Peter,
>
> Yes, it seems to do the same even if I simultaneously make that change.  Output below.
>
>> pdataH <- data.frame(y = H_to_fit$Height)
>> summary(pdataH)
>       y
> Min.   :2000
> 1st Qu.:2281
> Median :2666
> Mean   :2825
> 3rd Qu.:3212
> Max.   :4794
>> fit3 <- vglm(y ~ 1, truncpareto(1999, 4794), data = pdataH, trace = TRUE)
> Error in eval(expr, envir, enclos) :
>  the value of argument 'upper' is too low (requires 'max(y) < upper')
>
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
>
> ________________________________________
> From: peter dalgaard <pdalgd at gmail.com>
> Sent: 10 March 2016 09:36
> To: John Hillier
> Cc: r-help at r-project.org
> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>
> Also if you simultaneously change the 2000 to say 1999?
>
> -p
>
> On 10 Mar 2016, at 09:22 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>
>> Thank you Peter,
>>
>> I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to
>>> pdataH <- data.frame(y = H_to_fit$Height)
>> This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.
>>
>> John
>>
>> -------------------------
>> Dr John Hillier
>> Senior Lecturer - Physical Geography
>> Loughborough University
>> 01509 223727
>>
>> ________________________________________
>> From: peter dalgaard <pdalgd at gmail.com>
>> Sent: 09 March 2016 19:58
>> To: John Hillier
>> Cc: r-help at r-project.org
>> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>>
>>> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>>>
>>> Dear All,
>>>
>>>
>>> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>>>
>>>
>>> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>>>
>>>
>>> When I try to run my data, I get the output below. Inputs shown with chevrons.
>>>
>>>
>>>> pdataH <- data.frame(H_to_fit$Height)
>>>> summary(pdataH)
>>> H_to_fit.Height
>>> Min.   :2000
>>> 1st Qu.:2281
>>>
>>> Median :2666
>>> Mean   :2825
>>> 3rd Qu.:3212
>>> Max.   :4794
>>>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
>>> Error in eval(expr, envir, enclos) :
>>> the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>>>
>>>
>>> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>>>
>>>
>>> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>>>
>>
>> Umm, it doesn't seem to have a column called "y"?
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From michaeleartz at gmail.com  Thu Mar 10 17:08:45 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 10 Mar 2016 10:08:45 -0600
Subject: [R] Prediction from a rank deficient fit may be misleading
Message-ID: <CA+pG8eP3GGSKioEjcF0KYjqtONyrF3AkBAAqsFd-cx=yhDrBQA@mail.gmail.com>

HI all,
I have the following error -
  >  resultVector <- predict(logitregressmodel, dataset1, type='response')
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading

I have seen on internet that there may be some collinearity in the data and
this is causing that.  How can I be sure?

Thanks

	[[alternative HTML version deleted]]


From santum4 at gmail.com  Thu Mar 10 17:53:51 2016
From: santum4 at gmail.com (Santanu Mukherjee)
Date: Thu, 10 Mar 2016 10:53:51 -0600
Subject: [R] R related issue
Message-ID: <CAL2_-6NbAt710Dj55zWQTTGW0+cmiCPO8d=iFUs_46P6Gny+Pw@mail.gmail.com>

Hi,
I have R and MySQL at the backend. I have used dbGetQuery to get the rows I
want and put it in a data.frame rs2.
Now I want to use that data.frame to do market basket using apriori
it is giving me errors
Error in asMethod(object) : column(s) 1, 2 not logical or a factor.
Discretize the columns first

I tried to dicretize but did not work

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Thu Mar 10 20:51:11 2016
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 10 Mar 2016 19:51:11 +0000
Subject: [R] CANNOT RUN ctree
Message-ID: <1457639471709.91302@unine.ch>

Dear all,
Sorry for question again, but I am desesperating..
I installed already "partykit" But there is stille a message (see below):
the package "partykit" has been compiled with the version R3.1.3.
What should I do now?

I run my function and appears this:

Error in loadNamespace(name) : there is no package called 'Formula'

THANK YOU for ur assistance,

Xavier


install.packages("partykit") Installing package into 'C:/Users/chiribogax/Documents/R/win-library/3.1' (as 'lib' is unspecified) trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/partykit_1.0-5.zip' Content type 'application/zip' length 1215105 bytes (1.2 Mb) opened URL downloaded 1.2 Mb package 'partykit' successfully unpacked and MD5 sums checked The downloaded binary packages are in C:\Users\chiribogax\AppData\Local\Temp\RtmpyugH55\downloaded_packages > library("partykit") Le chargement a n?cessit? le package : grid Warning message: le package 'partykit' a ?t? compil? avec la version R 3.1.3 > plot(ctree(Surv(hours,state)~soil+volatile, data=data)) Error in loadNamespace(name) : there is no package called 'Formula'


From sarah.goslee at gmail.com  Thu Mar 10 21:21:55 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 10 Mar 2016 15:21:55 -0500
Subject: [R] CANNOT RUN ctree
In-Reply-To: <1457639471709.91302@unine.ch>
References: <1457639471709.91302@unine.ch>
Message-ID: <CAM_vjukW5wCc2DgeR3FY7LYO0boxnneU6JMSSeerMcQZaA4rTQ@mail.gmail.com>

In general, you should probably update your R installation.

In specific, you should install the missing package Formula, as the
error message is telling you.

On Thu, Mar 10, 2016 at 2:51 PM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear all,
> Sorry for question again, but I am desesperating..
> I installed already "partykit" But there is stille a message (see below):
> the package "partykit" has been compiled with the version R3.1.3.
> What should I do now?
>
> I run my function and appears this:
>
> Error in loadNamespace(name) : there is no package called 'Formula'
>
> THANK YOU for ur assistance,
>
> Xavier
>
>
> install.packages("partykit") Installing package into 'C:/Users/chiribogax/Documents/R/win-library/3.1' (as 'lib' is unspecified) trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/partykit_1.0-5.zip' Content type 'application/zip' length 1215105 bytes (1.2 Mb) opened URL downloaded 1.2 Mb package 'partykit' successfully unpacked and MD5 sums checked The downloaded binary packages are in C:\Users\chiribogax\AppData\Local\Temp\RtmpyugH55\downloaded_packages > library("partykit") Le chargement a n?cessit? le package : grid Warning message: le package 'partykit' a ?t? compil? avec la version R 3.1.3 > plot(ctree(Surv(hours,state)~soil+volatile, data=data)) Error in loadNamespace(name) : there is no package called 'Formula'
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.gang.peng at gmail.com  Thu Mar 10 21:27:47 2016
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Thu, 10 Mar 2016 15:27:47 -0500
Subject: [R] How to avoid endless loop in shiny
In-Reply-To: <CAFEqCdwsPW+osrHJqYo1bGEGt4iUV2tNScGckwnjNTQdoPCOCw@mail.gmail.com>
References: <CAMjJGR0bDJkWM3-kigg_JnWHszFpjpy0f3sWgNm-_BSFA-uK2g@mail.gmail.com>
	<CAFEqCdwsPW+osrHJqYo1bGEGt4iUV2tNScGckwnjNTQdoPCOCw@mail.gmail.com>
Message-ID: <CAMjJGR1asPR-6D4sNU2WR1ER_xGvh2SgKO=X626ptiM_k0q=3g@mail.gmail.com>

Hi Greg,

Isolate may not solve the problem.  For the following code. It runs only
1-2 times and stopped without isolate. If we update the slider with same
value, it will not send a new message.

library("shiny")

ui <- fluidPage(

  titlePanel("Slider Test"),

  sidebarLayout(
    sidebarPanel(
                  min=2, max=10, value=10),

      sliderInput("sliderB", "B:",
                  min = 1, max = 5, value = 5)
      ),

    mainPanel(
      plotOutput("plot")
    )
  )
)

server <- function(input, output, clientData, session) {

  observeEvent(input$sliderA,{updateSliderInput(session, "sliderB", value =
as.integer(input$sliderA/2))})

  observeEvent(input$sliderB,{updateSliderInput(session, "sliderA", value =
isolate(input$sliderB*2))})
}


shinyApp(server = server, ui = ui)

For example:

set B: 4 -> update A: 8 -> update B: 8 (same, no message, end)

changing of A is tricky
If original A is 10, B is 5.

set A: 9  -> update B: 4 (not same, continue) -> update A: 8 (not same,
continue) -> update B: 4 (same, no message, end)


If original A is 8, B is 4.
set A:9 - > update B: 4(same, no message, end)

isolate doesn't work in this case.

Instead, use the following code:

library("shiny")

ui <- fluidPage(

  titlePanel("Slider Test"),

  sidebarLayout(
    sidebarPanel(
                  min=2, max=10, value=10),

      sliderInput("sliderB", "B:",
                  min = 1, max = 5, value = 5)
      ),

    mainPanel(
      plotOutput("plot")
    )
  )
)

server <- function(input, output, clientData, session) {

server <- function(input, output, clientData, session) {

  ignoreNext <- ""

  observeEvent(input$sliderA,{
      if (ignoreNext == "A") {
        ignoreNext <<- ""
      }
      else{
        valB <- as.integer(input$sliderA/2)
        if(valB != input$sliderB){
          ignoreNext <<- "B"
          updateSliderInput(session, "sliderB", value = valB)
        }
      }
    })

  observeEvent(input$sliderB,{
    if (ignoreNext == "B") {
      ignoreNext <<- ""
    }
    else{
      valA <- as.integer(input$sliderA*2)
      if(valA != input$sliderA){
        ignoreNext <<- "A"
        updateSliderInput(session, "sliderA", value = valA)
      }
    }
    })
}


shinyApp(server = server, ui = ui)

2016-03-08 18:00 GMT-05:00 Greg Snow <538280 at gmail.com>:

> You need to use `isolate` on one of the assignments so that it does
> not register as an update.  Here are a few lines of code from the
> server.R file for an example that I use that has a slider for r
> (correlation) and another slider for r^2 and whenever one is changed,
> I want the other to update:
>
>   observe({
>     updateSliderInput(session, 'r',
> value=isolate(ifelse(input$r<0,-1,1))*sqrt(input$r2))
>   })
>
>   observe({
>     updateSliderInput(session, 'r2', value=input$r^2)
>   })
>
>
> I did end up in a loop once when I happened to choose just the wrong
> value and the rounding caused a jumping back and forth, but all the
> other times this has worked perfectly without the endless loop.
>
>
> On Tue, Mar 8, 2016 at 12:35 PM, Michael Peng
> <michael.gang.peng at gmail.com> wrote:
> > Hi,
> >
> > I added two sliderInput into the app with package "shiny": sliderA and
> > sliderB. The values in the two sliders are correlated. If I change
> sliderA,
> > I used updateSliderInput to update the value in sliderB. And also If I
> > change sliderB, I used  updateSliderInput to update the value in slideA.
> >
> > The problem is it is an endless loop. How can I use updateSliderInput
> > without sending message to update the other slider.
> >
> > Thank.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 10 21:29:29 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 21:29:29 +0100
Subject: [R] truncpareto() - doesn't like my data and odd error message
In-Reply-To: <AM3PR04MB149037BE22DC4D6A87F874B7A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
References: <AM3PR04MB14902D5817778FAD23808FCDA1B30@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B286252D-E42D-40EF-9628-878E7EBB5A1B@gmail.com>
	<AM3PR04MB1490A8507224B7A5B9B8B4FAA1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<B5A54D5B-4494-4076-8783-7310F8445581@gmail.com>
	<AM3PR04MB1490DC721E362CEF120AA258A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
	<9BDD9369-6929-49C6-A1F0-87809945E721@gmail.com>
	<AM3PR04MB149037BE22DC4D6A87F874B7A1B40@AM3PR04MB1490.eurprd04.prod.outlook.com>
Message-ID: <5BB381AF-4134-4A7C-9554-0751FEE4AD12@gmail.com>

Actually, the issue is that the left hand side of the model formula should be the name of the variable under consideration. If you write y ~ 1 there had better be a "y", but without the renaming you could also have used H_to_fit.Height ~ 1.

-pd


> On 10 Mar 2016, at 19:03 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
> 
> Dear Peter,
> 
> Thank you. Apolgies for not looking closer.  It is the end of a long day. Fixed now, and I have learnt more about correctly interpreting R's manual pages.
> 
> For the record .... 
> 
> Summary: If input to truncpareto() is not explicitly called 'y' it can produce error messages about the values 'lower', which might be confusing.  So, ensure input is called 'y', and that 'lower' and 'upper' are just outside the range of y.
> 
> John
> 
> -------------------------
> Dr John Hillier
> Senior Lecturer - Physical Geography
> Loughborough University
> 01509 223727
> 
> ________________________________________
> From: peter dalgaard <pdalgd at gmail.com>
> Sent: 10 March 2016 17:49
> To: John Hillier
> Cc: r-help at r-project.org
> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
> 
> Look closer....
> 
> -pd
> 
> 
>> On 10 Mar 2016, at 18:41 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>> 
>> Thank you Peter,
>> 
>> Yes, it seems to do the same even if I simultaneously make that change.  Output below.
>> 
>>> pdataH <- data.frame(y = H_to_fit$Height)
>>> summary(pdataH)
>>      y
>> Min.   :2000
>> 1st Qu.:2281
>> Median :2666
>> Mean   :2825
>> 3rd Qu.:3212
>> Max.   :4794
>>> fit3 <- vglm(y ~ 1, truncpareto(1999, 4794), data = pdataH, trace = TRUE)
>> Error in eval(expr, envir, enclos) :
>> the value of argument 'upper' is too low (requires 'max(y) < upper')
>> 
>> -------------------------
>> Dr John Hillier
>> Senior Lecturer - Physical Geography
>> Loughborough University
>> 01509 223727
>> 
>> ________________________________________
>> From: peter dalgaard <pdalgd at gmail.com>
>> Sent: 10 March 2016 09:36
>> To: John Hillier
>> Cc: r-help at r-project.org
>> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>> 
>> Also if you simultaneously change the 2000 to say 1999?
>> 
>> -p
>> 
>> On 10 Mar 2016, at 09:22 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>> 
>>> Thank you Peter,
>>> 
>>> I believe this might be the way the error message is hard coded (i.e. it's always y to describe the input).  Anyway, I changed the first line to
>>>> pdataH <- data.frame(y = H_to_fit$Height)
>>> This makes the input 'y' instead of 'H_to_fit.Height', but makes no difference to the outcome/error message.
>>> 
>>> John
>>> 
>>> -------------------------
>>> Dr John Hillier
>>> Senior Lecturer - Physical Geography
>>> Loughborough University
>>> 01509 223727
>>> 
>>> ________________________________________
>>> From: peter dalgaard <pdalgd at gmail.com>
>>> Sent: 09 March 2016 19:58
>>> To: John Hillier
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] truncpareto() - doesn't like my data and odd error message
>>> 
>>>> On 09 Mar 2016, at 18:52 , John Hillier <J.Hillier at lboro.ac.uk> wrote:
>>>> 
>>>> Dear All,
>>>> 
>>>> 
>>>> I am attempting to describe a distribution of height data.  It appears roughly linear on a log-log plot, so Pareto seems sensible.  However, the data are only reliable in a limited range (e.g. 2000 to 4800 m). So, I would like to fit a Pareto distribution to the reliable (i.e. truncated) section of the data.
>>>> 
>>>> 
>>>> I found truncpareto(), and implemented one of its example uses successfully.  Specifically, the third one at http://www.inside-r.org/packages/cran/vgam/docs/paretoff (also see p.s.).
>>>> 
>>>> 
>>>> When I try to run my data, I get the output below. Inputs shown with chevrons.
>>>> 
>>>> 
>>>>> pdataH <- data.frame(H_to_fit$Height)
>>>>> summary(pdataH)
>>>> H_to_fit.Height
>>>> Min.   :2000
>>>> 1st Qu.:2281
>>>> 
>>>> Median :2666
>>>> Mean   :2825
>>>> 3rd Qu.:3212
>>>> Max.   :4794
>>>>> fit3 <- vglm(y ~ 1, truncpareto(2000, 4794), data = pdataH, trace = TRUE)
>>>> Error in eval(expr, envir, enclos) :
>>>> the value of argument 'lower' is too high (requires '0 < lower < min(y)')
>>>> 
>>>> 
>>>> This is odd as the usage format is - truncpareto(lower, upper), and varying 2000 to 1900 and 2100 makes no difference. Neither do smaller or larger variations. From the summary I think that my lowest input is 2000, which I am taking as min(y). I have also played with the upper limit.  pdataH has 2117 observations in it.
>>>> 
>>>> 
>>>> Is this a data format thing? i.e. of pdataH (a tried a few things, but to no avail)
>>>> 
>>> 
>>> Umm, it doesn't seem to have a column called "y"?
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Thu Mar 10 22:29:27 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 11 Mar 2016 08:29:27 +1100
Subject: [R] Conversion problem with write.csv and as.character()
In-Reply-To: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
References: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
Message-ID: <CA+8X3fV5gC6bu3do1arXsLX5+54Dq1FKmkoCa=9N-dB-L87OmA@mail.gmail.com>

Hi Peter,
Have you tried:

a_fetchdata<-format(a_fetchdata,"%Y-%m-%d %H:%M:%S")

before writing the data?

Jim

On Thu, Mar 10, 2016 at 10:14 PM, Peter Neumaier
<peter.neumaier at gmail.com> wrote:
> Hi all, sorry for double/cross posting, I have sent an initial, similar
> question
> accidentally to r-sig-finance.
>
> I am writing a matrix (typeof = double) into a CSV file with write.csv.
>
> My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
>
>> a_fetchdata[1,0]
>
> 2016-02-09 07:30:00
>> typeof(a_fetchdata[1,0])
> [1] "double"
>
> My CSV file contains a sequence of integers (from 1 to x) instead of the
> expected date.
>
> I tried to convert, but ran into "Error in dimnames":
>
>> as.character(first_fetchdata[1,0])
> Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
>   'dimnames' applied to non-array
> Called from: as.matrix.xts(x)
> Browse[1]> c
>>
>
> a) How can I prevent the conversion into integers to happen when writing
> into CSV?
> b) if a) is not do-able: how can I convert the date in double format to
> chars (i.e. with as.character) ?
>
> Thanks in advance,
> Peter
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Mar 10 23:05:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Mar 2016 14:05:31 -0800
Subject: [R] Prediction from a rank deficient fit may be misleading
In-Reply-To: <CA+pG8eP3GGSKioEjcF0KYjqtONyrF3AkBAAqsFd-cx=yhDrBQA@mail.gmail.com>
References: <CA+pG8eP3GGSKioEjcF0KYjqtONyrF3AkBAAqsFd-cx=yhDrBQA@mail.gmail.com>
Message-ID: <4B1EAF5E-D832-4189-BDA9-5B4B3814DE74@comcast.net>


> On Mar 10, 2016, at 8:08 AM, Michael Artz <michaeleartz at gmail.com> wrote:
> 
> HI all,
> I have the following error -
>> resultVector <- predict(logitregressmodel, dataset1, type='response')
> Warning message:
> In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
>  prediction from a rank-deficient fit may be misleading

It wasn't an R error. It was an R warning. Was the `summary` output on logitregressmodel informative? Does the resultVector look sensible given its inputs?


> I have seen on internet that there may be some collinearity in the data and
> this is causing that.  How can I be sure?

Do some diagnostics. After looking carefully at the output of summary(logitregressmodel)  and perhaps summary(dataset1) if it was the original input to the modeling functions, and then you could move on to looking at cross-correlations on things you think are continuous and crosstabs on factor variables and the condition number on the full data matrix.

Lots of stuff turns up on search for "detecting collinearity condition number in r"

> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kmnanus at gmail.com  Thu Mar 10 20:34:05 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 10 Mar 2016 14:34:05 -0500
Subject: [R] Error in make.names(col.names,
	unique = TRUE) : invalid multibyte string at '<ca>14 <4a>ULY 2012'
Message-ID: <B5E2EFA6-2F75-452A-8427-EE5838DD426A@gmail.com>

I?m trying to read in the data below from an Excel file (as a .csv file) in  order to create an age (in years.%years) but am getting the error message in the subject line.

I?ve tried saving the dates as dates in Excel and tried saving the dates as text, both give me the same error message.  Can someone pls tell me what I?m doing wrong?

Gender	DOB	Diagnosis	Screen Date
Male	 14 JULY 2012	No	 05 OCTOBER 2015
Female	 31 OCTOBER 2009	No	 30 NOVEMBER 2015
Female	 08 JULY 2009	No	 06 DECEMBER 2015
Male	 04 JUNE 2011	NA	 11 JANUARY 2016
Female	 21 AUGUST 2009	Yes	 01 FEBRUARY 2016
Male	 05 NOVEMBER 2007	No	 16 FEBRUARY 2016
Male	 01 JUNE 2009	NA	 29 FEBRUARY 2016


 
Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From peter.neumaier at gmail.com  Thu Mar 10 21:37:01 2016
From: peter.neumaier at gmail.com (Peter Neumaier)
Date: Thu, 10 Mar 2016 20:37:01 +0000
Subject: [R] Conversion problem with write.csv and as.character()
In-Reply-To: <CAM_vjukQ-G=SGTs1U9i4h1k1J6XVNxgf8DebE4efOEXK5QUArg@mail.gmail.com>
References: <CAHDRDJVm8S-vOhtf+__J_gh8XSGpzUQ4-A8etWLCxFfd3AE52Q@mail.gmail.com>
	<CAM_vjukQ-G=SGTs1U9i4h1k1J6XVNxgf8DebE4efOEXK5QUArg@mail.gmail.com>
Message-ID: <CAHDRDJXquAqA+sjFas9gyxK9ewH5waEV2ZyNXzJ9KtvTY9T7_w@mail.gmail.com>

All fixed and solved in R-SIG-Finance.

Thanks,
Peter

On Thu, Mar 10, 2016 at 3:25 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi Peter,
>
> We really need a reproducible example to solve this kind of question.
> Please use dput(head(yourdata)) to provide a sample of data (or make
> up fake data that shows the same problems), and provide the code
> you're using.
>
> Sarah
>
> On Thu, Mar 10, 2016 at 6:14 AM, Peter Neumaier
> <peter.neumaier at gmail.com> wrote:
> > Hi all, sorry for double/cross posting, I have sent an initial, similar
> > question
> > accidentally to r-sig-finance.
> >
> > I am writing a matrix (typeof = double) into a CSV file with write.csv.
> >
> > My first column of the matrix is a date in the form yyyy-mm-dd hh:mm:ss:
> >
> >> a_fetchdata[1,0]
> >
> > 2016-02-09 07:30:00
> >> typeof(a_fetchdata[1,0])
> > [1] "double"
> >
> > My CSV file contains a sequence of integers (from 1 to x) instead of the
> > expected date.
> >
> > I tried to convert, but ran into "Error in dimnames":
> >
> >> as.character(first_fetchdata[1,0])
> > Error in dimnames(cd) <- list(as.character(index(x)), colnames(x)) :
> >   'dimnames' applied to non-array
> > Called from: as.matrix.xts(x)
> > Browse[1]> c
> >>
> >
> > a) How can I prevent the conversion into integers to happen when writing
> > into CSV?
> > b) if a) is not do-able: how can I convert the date in double format to
> > chars (i.e. with as.character) ?
> >
> > Thanks in advance,
> > Peter
> >
>

	[[alternative HTML version deleted]]


From rmcgehee at gmail.com  Thu Mar 10 23:00:00 2016
From: rmcgehee at gmail.com (Robert McGehee)
Date: Thu, 10 Mar 2016 17:00:00 -0500
Subject: [R] Regression with factor having1 level
Message-ID: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>

Hello R-helpers,
I'd like a function that given an arbitrary formula and a data frame
returns the residual of the dependent variable, and maintains all NA values.

Here's an example that will give me what I want if my formula is y~x1+x2+x3
and my data frame is df:

resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))

Here's the catch, I do not want my function to ever fail due to a factor
with only one level. A one-level factor may appear because 1) the user
passed it in, or 2) (more common) only one factor in a term is left after
na.exclude removes the other NA values.

Here is the error I would get above if one of the terms was a factor with
one level:
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

Instead of giving me an error, I'd like the function to do just what lm()
normally does when it sees a variable with no variance, ignore the variable
(coefficient is NA) and continue to regress out all the other variables.
Thus if 'x2' is a factor with one variable in the above example, I'd like
the function to return the result of:
resid(lm(y~x1+x3, data=df, na.action=na.exclude))

Can anyone provide me a straight forward recommendation for how to do this?
I feel like it should be easy, but I'm honestly stuck, and my Google
searching for this hasn't gotten anywhere. The key is that I'd like the
solution to be generic enough to work with an arbitrary linear formula, and
not substantially kludgy (like trying ever combination of regressions terms
until one works) as I'll be running this a lot on big data sets and don't
want my computation time swamped by running unnecessary regressions or
checking for number of factors after removing NAs.

Thanks in advance!
--Robert


PS. The Google search feature in the R-help archives appears to be down:
http://tolstoy.newcastle.edu.au/R/

	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Thu Mar 10 23:05:27 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 10 Mar 2016 17:05:27 -0500
Subject: [R] extracting months from a data
In-Reply-To: <CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
References: <A8322A90-715E-4DF9-86A6-84D7349EF6BA@gmail.com>
	<BC95303B-8BD1-4F28-95EC-A85A169F784A@dcn.davis.ca.us>
	<CAJeYpE-4NQGsBq_nNExnECf-to4MGrtQyfjay0jq5aRN99edHw@mail.gmail.com>
Message-ID: <B7D2BFE5-1235-4CFC-A594-570E06D9DDA5@gmail.com>

Thanks for this.  I wasn?t familiar with paste0, so I?ll call that and see if it works.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 9, 2016, at 7:15 PM, Dalthorp, Daniel <ddalthorp at usgs.gov> wrote:
> 
> Or: 
> 
> x <- c( "3-Oct", "10-Nov" )
> format(as.Date(paste0(x,rep("-1970",length(x))),format='%d-%b-%Y'),'%b')
> 
> # the 'paste0' appends a year to the text vector
> # the 'as.Date' interprets the strings as dates with format  10-Jun-2016 (e.g.)
> # the 'format' returns a string with date in format '%b' (which is just the name of the month)
> 
> On Wed, Mar 9, 2016 at 3:52 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
> Your dates are incomplete (no year) so I suggest staying away from the date functions for this. Read ?regex and ?sub.
> 
> x <- c( "3-Oct", "10-Nov" )
> m <- sub( "^\\d+-([A-Za-z]{3})$", "\\1", x )
> 
> --
> Sent from my phone. Please excuse my brevity.
> 
> On March 9, 2016 10:14:25 AM PST, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
> >I have a series of dates in  format 3-Oct, 10-Oct, 20-Oct, etc.
> >
> >I want to create a variable of just the month.  If I convert the date
> >to a character string, substr is ineffective because some of the dates
> >have 5 characters (3-Oct) and some have 6 (10-Oct).
> >
> >Is there a date function that accomplishes this easily?
> >
> >Ken
> >kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> >914-450-0816 (tel)
> >347-730-4813 (fax)
> >
> >
> >
> >______________________________________________
> >R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >and provide commented, minimal, self-contained, reproducible code.
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way 
> Corvallis, OR 97331 
> ph: 541-750-0953
> ddalthorp at usgs.gov <mailto:ddalthorp at usgs.gov>
> 


From michaeleartz at gmail.com  Thu Mar 10 23:21:31 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 10 Mar 2016 16:21:31 -0600
Subject: [R] Prediction from a rank deficient fit may be misleading
In-Reply-To: <4B1EAF5E-D832-4189-BDA9-5B4B3814DE74@comcast.net>
References: <CA+pG8eP3GGSKioEjcF0KYjqtONyrF3AkBAAqsFd-cx=yhDrBQA@mail.gmail.com>
	<4B1EAF5E-D832-4189-BDA9-5B4B3814DE74@comcast.net>
Message-ID: <CA+pG8eOGjXUVF2E+EypQpiXne84nEzh8JU+gzOeS+JHSvt6dWg@mail.gmail.com>

Here is the results of the logistic regression model.  Is it because of the
NA values?

Call:
glm(formula = TARGET_A ~ Contract + Dependents + DeviceProtection +
    gender + InternetService + MonthlyCharges + MultipleLines +
    OnlineBackup + OnlineSecurity + PaperlessBilling + Partner +
    PaymentMethod + PhoneService + SeniorCitizen + StreamingMovies +
    StreamingTV + TechSupport + tenure + TotalCharges, family =
binomial(link = "logit"),
    data = churn_training)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-1.8943  -0.6867  -0.2863   0.7378   3.4259

Coefficients: (7 not defined because of singularities)
                                       Estimate Std. Error z value Pr(>|z|)

(Intercept)                           1.0664928  1.7195494   0.620   0.5351

ContractOne year                     -0.6874005  0.1314227  -5.230 1.69e-07
***
ContractTwo year                     -1.2775385  0.2101193  -6.080 1.20e-09
***
DependentsYes                        -0.1485301  0.1095348  -1.356   0.1751

DeviceProtectionNo internet service  -1.5547306  0.9661837  -1.609   0.1076

DeviceProtectionYes                   0.0459115  0.2114253   0.217   0.8281

genderMale                           -0.0350970  0.0776896  -0.452   0.6514

InternetServiceFiber optic            1.4800374  0.9545398   1.551   0.1210

InternetServiceNo                            NA         NA      NA       NA

MonthlyCharges                       -0.0324614  0.0379646  -0.855   0.3925

MultipleLinesNo phone service         0.0808745  0.7736359   0.105   0.9167

MultipleLinesYes                      0.3990450  0.2131343   1.872   0.0612
.
OnlineBackupNo internet service              NA         NA      NA       NA

OnlineBackupYes                      -0.0328892  0.2081145  -0.158   0.8744

OnlineSecurityNo internet service            NA         NA      NA       NA

OnlineSecurityYes                    -0.2760602  0.2132917  -1.294   0.1956

PaperlessBillingYes                   0.3509944  0.0890884   3.940 8.15e-05
***
PartnerYes                            0.0306815  0.0940650   0.326   0.7443

PaymentMethodCredit card (automatic) -0.0710923  0.1377252  -0.516   0.6057

PaymentMethodElectronic check         0.3074078  0.1137939   2.701   0.0069
**
PaymentMethodMailed check            -0.0201076  0.1377539  -0.146   0.8839

PhoneServiceYes                              NA         NA      NA       NA

SeniorCitizen                         0.1856454  0.1023527   1.814   0.0697
.
StreamingMoviesNo internet service           NA         NA      NA       NA

StreamingMoviesYes                    0.5260087  0.3899615   1.349   0.1774

StreamingTVNo internet service               NA         NA      NA       NA

StreamingTVYes                        0.4781321  0.3905777   1.224   0.2209

TechSupportNo internet service               NA         NA      NA       NA

TechSupportYes                       -0.2511197  0.2181612  -1.151   0.2497

tenure                               -0.0702813  0.0077113  -9.114  < 2e-16
***
TotalCharges                          0.0004276  0.0000874   4.892 9.97e-07
***

On Thu, Mar 10, 2016 at 4:05 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 10, 2016, at 8:08 AM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> >
> > HI all,
> > I have the following error -
> >> resultVector <- predict(logitregressmodel, dataset1, type='response')
> > Warning message:
> > In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==
> :
> >  prediction from a rank-deficient fit may be misleading
>
> It wasn't an R error. It was an R warning. Was the `summary` output on
> logitregressmodel informative? Does the resultVector look sensible given
> its inputs?
>
>
> > I have seen on internet that there may be some collinearity in the data
> and
> > this is causing that.  How can I be sure?
>
> Do some diagnostics. After looking carefully at the output of
> summary(logitregressmodel)  and perhaps summary(dataset1) if it was the
> original input to the modeling functions, and then you could move on to
> looking at cross-correlations on things you think are continuous and
> crosstabs on factor variables and the condition number on the full data
> matrix.
>
> Lots of stuff turns up on search for "detecting collinearity condition
> number in r"
>
> >
> > Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Thu Mar 10 20:56:05 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 10 Mar 2016 19:56:05 +0000
Subject: [R] R related issue
In-Reply-To: <CAL2_-6NbAt710Dj55zWQTTGW0+cmiCPO8d=iFUs_46P6Gny+Pw@mail.gmail.com>
References: <CAL2_-6NbAt710Dj55zWQTTGW0+cmiCPO8d=iFUs_46P6Gny+Pw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276630939679@WAXMXOLYMB025.WAX.wa.lcl>

You haven't provided sufficient information for people to help you.   Please read the posting guide linked to at the bottom of this email.  We need a reproducible example.  You say you tried to discretize but it didn't work.  What did you try (actual code please), and what error messages did you receive?

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Santanu
> Mukherjee
> Sent: Thursday, March 10, 2016 8:54 AM
> To: r-help at r-project.org
> Subject: [R] R related issue
> 
> Hi,
> I have R and MySQL at the backend. I have used dbGetQuery to get the rows
> I want and put it in a data.frame rs2.
> Now I want to use that data.frame to do market basket using apriori it is
> giving me errors Error in asMethod(object) : column(s) 1, 2 not logical or a
> factor.
> Discretize the columns first
> 
> I tried to dicretize but did not work
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Mar 11 01:07:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Mar 2016 16:07:09 -0800
Subject: [R] Prediction from a rank deficient fit may be misleading
In-Reply-To: <CA+pG8eOGjXUVF2E+EypQpiXne84nEzh8JU+gzOeS+JHSvt6dWg@mail.gmail.com>
References: <CA+pG8eP3GGSKioEjcF0KYjqtONyrF3AkBAAqsFd-cx=yhDrBQA@mail.gmail.com>
	<4B1EAF5E-D832-4189-BDA9-5B4B3814DE74@comcast.net>
	<CA+pG8eOGjXUVF2E+EypQpiXne84nEzh8JU+gzOeS+JHSvt6dWg@mail.gmail.com>
Message-ID: <D7861B4F-CA7D-4C79-96A6-D047EB186462@comcast.net>


> On Mar 10, 2016, at 2:21 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> 
> Here is the results of the logistic regression model.  Is it because of the
> NA values?

It's unclear. The InternetServiceNo (an other "No")-values could well be the cause. Many times questionnaires get encoded in a manner that causes complete collinearity and the glm function then "aliases" those levels and displays an NA result for the coefficients. I don't remember the predict function then emitting that warning, but seems possible that including column names for aliased factors would be a well-mannered behavior for software. At any rate I don't see the absurd sorts of coefficients (such as 10 or 20) that I associate with severe numerical pathology.


> 
> Call:
> glm(formula = TARGET_A ~ Contract + Dependents + DeviceProtection +
>    gender + InternetService + MonthlyCharges + MultipleLines +
>    OnlineBackup + OnlineSecurity + PaperlessBilling + Partner +
>    PaymentMethod + PhoneService + SeniorCitizen + StreamingMovies +
>    StreamingTV + TechSupport + tenure + TotalCharges, family =
> binomial(link = "logit"),
>    data = churn_training)
> 
> Deviance Residuals:
>    Min       1Q   Median       3Q      Max
> -1.8943  -0.6867  -0.2863   0.7378   3.4259
> 
> Coefficients: (7 not defined because of singularities)
>                                       Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)                           1.0664928  1.7195494   0.620   0.5351
> 
> ContractOne year                     -0.6874005  0.1314227  -5.230 1.69e-07
> ***
> ContractTwo year                     -1.2775385  0.2101193  -6.080 1.20e-09
> ***
> DependentsYes                        -0.1485301  0.1095348  -1.356   0.1751
> 
> DeviceProtectionNo internet service  -1.5547306  0.9661837  -1.609   0.1076
> 
> DeviceProtectionYes                   0.0459115  0.2114253   0.217   0.8281
> 
> genderMale                           -0.0350970  0.0776896  -0.452   0.6514
> 
> InternetServiceFiber optic            1.4800374  0.9545398   1.551   0.1210
> 
> InternetServiceNo                            NA         NA      NA       NA
> 
> MonthlyCharges                       -0.0324614  0.0379646  -0.855   0.3925
> 
> MultipleLinesNo phone service         0.0808745  0.7736359   0.105   0.9167
> 
> MultipleLinesYes                      0.3990450  0.2131343   1.872   0.0612
> .
> OnlineBackupNo internet service              NA         NA      NA       NA
> 
> OnlineBackupYes                      -0.0328892  0.2081145  -0.158   0.8744
> 
> OnlineSecurityNo internet service            NA         NA      NA       NA
> 
> OnlineSecurityYes                    -0.2760602  0.2132917  -1.294   0.1956
> 
> PaperlessBillingYes                   0.3509944  0.0890884   3.940 8.15e-05
> ***
> PartnerYes                            0.0306815  0.0940650   0.326   0.7443
> 
> PaymentMethodCredit card (automatic) -0.0710923  0.1377252  -0.516   0.6057
> 
> PaymentMethodElectronic check         0.3074078  0.1137939   2.701   0.0069
> **
> PaymentMethodMailed check            -0.0201076  0.1377539  -0.146   0.8839
> 
> PhoneServiceYes                              NA         NA      NA       NA
> 
> SeniorCitizen                         0.1856454  0.1023527   1.814   0.0697
> .
> StreamingMoviesNo internet service           NA         NA      NA       NA
> 
> StreamingMoviesYes                    0.5260087  0.3899615   1.349   0.1774
> 
> StreamingTVNo internet service               NA         NA      NA       NA
> 
> StreamingTVYes                        0.4781321  0.3905777   1.224   0.2209
> 
> TechSupportNo internet service               NA         NA      NA       NA
> 
> TechSupportYes                       -0.2511197  0.2181612  -1.151   0.2497
> 
> tenure                               -0.0702813  0.0077113  -9.114  < 2e-16
> ***
> TotalCharges                          0.0004276  0.0000874   4.892 9.97e-07
> ***
> 
> On Thu, Mar 10, 2016 at 4:05 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> 
>>> On Mar 10, 2016, at 8:08 AM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>> 
>>> HI all,
>>> I have the following error -
>>>> resultVector <- predict(logitregressmodel, dataset1, type='response')
>>> Warning message:
>>> In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==
>> :
>>> prediction from a rank-deficient fit may be misleading
>> 
>> It wasn't an R error. It was an R warning. Was the `summary` output on
>> logitregressmodel informative? Does the resultVector look sensible given
>> its inputs?
>> 
>> 
>>> I have seen on internet that there may be some collinearity in the data
>> and
>>> this is causing that.  How can I be sure?
>> 
>> Do some diagnostics. After looking carefully at the output of
>> summary(logitregressmodel)  and perhaps summary(dataset1) if it was the
>> original input to the modeling functions, and then you could move on to
>> looking at cross-correlations on things you think are continuous and
>> crosstabs on factor variables and the condition number on the full data
>> matrix.
>> 
>> Lots of stuff turns up on search for "detecting collinearity condition
>> number in r"
>> 
>>> 
>>> Thanks
>>> 
>>>      [[alternative HTML version deleted]]
>>> 

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Fri Mar 11 01:29:27 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Mar 2016 00:29:27 +0000
Subject: [R] Regression with factor having1 level
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
Message-ID: <loom.20160311T012323-470@post.gmane.org>

Robert McGehee <rmcgehee <at> gmail.com> writes:

> 
> Hello R-helpers,
> I'd like a function that given an arbitrary formula and a data frame
> returns the residual of the dependent variable, and maintains all
>  NA values.
> 
> Here's an example that will give me what I want if my formula is y~x1+x2+x3
> and my data frame is df:
> 
> resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))
> 
> Here's the catch, I do not want my function to ever fail due to a factor
> with only one level. A one-level factor may appear because 1) the user
> passed it in, or 2) (more common) only one factor in a term is left after
> na.exclude removes the other NA values.
> 

 [snip to try to make Gmane happy]
> 
> Can anyone provide me a straight forward recommendation for how 
> to do this?

  The only approach I can think of is to screen for single-level factors
yourself and remove these factors from the
formula. It's a little tricky; you can't call model.frame() with a single-level
factor (that's where the error comes from), and you have to strip out NA
values yourself so you can see which factors end up with only a single
level after NA removal.


From ddalthorp at usgs.gov  Fri Mar 11 01:32:43 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Thu, 10 Mar 2016 16:32:43 -0800
Subject: [R] Error in make.names(col.names,
 unique = TRUE) : invalid multibyte string at '<ca>14 <4a>ULY 2012'
In-Reply-To: <B5E2EFA6-2F75-452A-8427-EE5838DD426A@gmail.com>
References: <B5E2EFA6-2F75-452A-8427-EE5838DD426A@gmail.com>
Message-ID: <CAJeYpE9VeewpQXcgxMutg5675KptTBFaUf4ayn93G-Gns64NkA@mail.gmail.com>

Hi Ken,
Without seeing your .csv file or how you are trying to read it, it's tough
to diagnose the trouble. I inserted commas between the columns in your data
snippet, pasted into Excel, saved as .csv file called "datesfile.csv" in
the R working directory. Then, the following worked fine for me:

junk<-read.csv("datesfile.csv", header = TRUE)
junk # is a dataframe with headers Gender, DOB, etc.

 # Age at screening (in days):
as.Date(junk$Screen.Date,format="%d %B %Y")-as.Date(junk$DOB,format="%d %B
%Y")

# Age at screening (in years):
as.numeric(as.Date(junk$Screen.Date,format="%d %B
%Y")-as.Date(junk$DOB,format="%d %B %Y"))/365.2425

I hope this helps.

-Dan


On Thu, Mar 10, 2016 at 11:34 AM, KMNanus <kmnanus at gmail.com> wrote:

> I?m trying to read in the data below from an Excel file (as a .csv file)
> in  order to create an age (in years.%years) but am getting the error
> message in the subject line.
>
> I?ve tried saving the dates as dates in Excel and tried saving the dates
> as text, both give me the same error message.  Can someone pls tell me what
> I?m doing wrong?
>
> Gender  DOB     Diagnosis       Screen Date
> Male     14 JULY 2012   No       05 OCTOBER 2015
> Female   31 OCTOBER 2009        No       30 NOVEMBER 2015
> Female   08 JULY 2009   No       06 DECEMBER 2015
> Male     04 JUNE 2011   NA       11 JANUARY 2016
> Female   21 AUGUST 2009 Yes      01 FEBRUARY 2016
> Male     05 NOVEMBER 2007       No       16 FEBRUARY 2016
> Male     01 JUNE 2009   NA       29 FEBRUARY 2016
>
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Mar 11 01:39:24 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Mar 2016 16:39:24 -0800
Subject: [R] Regression with factor having1 level
In-Reply-To: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
Message-ID: <075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>


> On Mar 10, 2016, at 2:00 PM, Robert McGehee <rmcgehee at gmail.com> wrote:
> 
> Hello R-helpers,
> I'd like a function that given an arbitrary formula and a data frame
> returns the residual of the dependent variable,and maintains all NA values.

What does "maintains all NA values" actually mean?
> 
> Here's an example that will give me what I want if my formula is y~x1+x2+x3
> and my data frame is df:
> 
> resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))
> 
> Here's the catch, I do not want my function to ever fail due to a factor
> with only one level. A one-level factor may appear because 1) the user
> passed it in, or 2) (more common) only one factor in a term is left after
> na.exclude removes the other NA values.
> 
> Here is the error I would get

From what code?


> above if one of the terms was a factor with
> one level:
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels

Unable to create that error with the actions you decribe but to not actually offer in coded form:


> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=TRUE, x3=rnorm(10))
> lm(y~x1+x2+x3, dfrm)

Call:
lm(formula = y ~ x1 + x2 + x3, data = dfrm)

Coefficients:
(Intercept)           x1       x2TRUE           x3  
   -0.16274     -0.30032           NA     -0.09093  

> resid(lm(y~x1+x2+x3, data=dfrm, na.action=na.exclude))
          1           2           3           4           5           6 
-0.16097245  0.65408508 -0.70098223 -0.15360434  1.26027872  0.55752239 
          7           8           9          10 
-0.05965653 -2.17480605  1.42917190 -0.65103650 

> 


> Instead of giving me an error, I'd like the function to do just what lm()
> normally does when it sees a variable with no variance, ignore the variable
> (coefficient is NA) and continue to regress out all the other variables.
> Thus if 'x2' is a factor with one variable in the above example, I'd like
> the function to return the result of:
> resid(lm(y~x1+x3, data=df, na.action=na.exclude))
> Can anyone provide me a straight forward recommendation for how to do this?
> I feel like it should be easy, but I'm honestly stuck, and my Google
> searching for this hasn't gotten anywhere. The key is that I'd like the
> solution to be generic enough to work with an arbitrary linear formula, and
> not substantially kludgy (like trying ever combination of regressions terms
> until one works) as I'll be running this a lot on big data sets and don't
> want my computation time swamped by running unnecessary regressions or
> checking for number of factors after removing NAs.
> 
> Thanks in advance!
> --Robert
> 
> 
> PS. The Google search feature in the R-help archives appears to be down:
> http://tolstoy.newcastle.edu.au/R/

It's working for me.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmcgehee at gmail.com  Fri Mar 11 02:03:00 2016
From: rmcgehee at gmail.com (Robert McGehee)
Date: Thu, 10 Mar 2016 20:03:00 -0500
Subject: [R] Regression with factor having1 level
In-Reply-To: <075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
Message-ID: <CAOpVXKqJ9B89VF3NTBKf3ZiVBv7RVujdUvQ-R4tp_5HwLFdrBg@mail.gmail.com>

Here's an example for clarity:

> df <- data.frame(y=c(0,2,4,6,8), x1=c(1,1,2,2,NA),
x2=factor(c("A","A","A","A","B")))
> resid(lm(y~x1+x2, data=df, na.action=na.exclude)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

Note that the x2 factor variable contains two levels, but the "B" level is
excluded in the regression due to the NA value in x1. Hence the error.

Instead of the above error, I would like a function that returns the
residual of the regression without the offending term, which in this case
would be equivalent to:
> resid(lm(y~x1, data=df, na.action=na.exclude)
 1  2  3  4  5
-1  1 -1  1 NA

Note the 5th term returns an NA as there is an NA in the x1 independent
variable, which was what I had meant by maintain NAs.

I'm currently leaning towards rewriting model.matrix.default so that it
removes offending terms rather than give an error, but if someone has done
this already (or something more elegant), that would of course be preferred
:)
--Robert

On Thu, Mar 10, 2016 at 7:39 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 10, 2016, at 2:00 PM, Robert McGehee <rmcgehee at gmail.com> wrote:
> >
> > Hello R-helpers,
> > I'd like a function that given an arbitrary formula and a data frame
> > returns the residual of the dependent variable,and maintains all NA
> values.
>
> What does "maintains all NA values" actually mean?
> >
> > Here's an example that will give me what I want if my formula is
> y~x1+x2+x3
> > and my data frame is df:
> >
> > resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))
> >
> > Here's the catch, I do not want my function to ever fail due to a factor
> > with only one level. A one-level factor may appear because 1) the user
> > passed it in, or 2) (more common) only one factor in a term is left after
> > na.exclude removes the other NA values.
> >
> > Here is the error I would get
>
> From what code?
>
>
> > above if one of the terms was a factor with
> > one level:
> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> >  contrasts can be applied only to factors with 2 or more levels
>
> Unable to create that error with the actions you decribe but to not
> actually offer in coded form:
>
>
> > dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=TRUE, x3=rnorm(10))
> > lm(y~x1+x2+x3, dfrm)
>
> Call:
> lm(formula = y ~ x1 + x2 + x3, data = dfrm)
>
> Coefficients:
> (Intercept)           x1       x2TRUE           x3
>    -0.16274     -0.30032           NA     -0.09093
>
> > resid(lm(y~x1+x2+x3, data=dfrm, na.action=na.exclude))
>           1           2           3           4           5           6
> -0.16097245  0.65408508 -0.70098223 -0.15360434  1.26027872  0.55752239
>           7           8           9          10
> -0.05965653 -2.17480605  1.42917190 -0.65103650
>
> >
>
>
> > Instead of giving me an error, I'd like the function to do just what lm()
> > normally does when it sees a variable with no variance, ignore the
> variable
> > (coefficient is NA) and continue to regress out all the other variables.
> > Thus if 'x2' is a factor with one variable in the above example, I'd like
> > the function to return the result of:
> > resid(lm(y~x1+x3, data=df, na.action=na.exclude))
> > Can anyone provide me a straight forward recommendation for how to do
> this?
> > I feel like it should be easy, but I'm honestly stuck, and my Google
> > searching for this hasn't gotten anywhere. The key is that I'd like the
> > solution to be generic enough to work with an arbitrary linear formula,
> and
> > not substantially kludgy (like trying ever combination of regressions
> terms
> > until one works) as I'll be running this a lot on big data sets and don't
> > want my computation time swamped by running unnecessary regressions or
> > checking for number of factors after removing NAs.
> >
> > Thanks in advance!
> > --Robert
> >
> >
> > PS. The Google search feature in the R-help archives appears to be down:
> > http://tolstoy.newcastle.edu.au/R/
>
> It's working for me.
>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Fri Mar 11 02:45:15 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 11 Mar 2016 01:45:15 +0000
Subject: [R] Regression with factor having1 level
In-Reply-To: <075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Thursday, March 10, 2016 4:39 PM
> To: Robert McGehee
> Cc: r-help at r-project.org
> Subject: Re: [R] Regression with factor having1 level
> 
> 
> > On Mar 10, 2016, at 2:00 PM, Robert McGehee <rmcgehee at gmail.com>
> wrote:
> >
> > Hello R-helpers,
> > I'd like a function that given an arbitrary formula and a data frame
> > returns the residual of the dependent variable,and maintains all NA values.
> 
> What does "maintains all NA values" actually mean?
> >
> > Here's an example that will give me what I want if my formula is
> > y~x1+x2+x3 and my data frame is df:
> >
> > resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))
> >
> > Here's the catch, I do not want my function to ever fail due to a
> > factor with only one level. A one-level factor may appear because 1)
> > the user passed it in, or 2) (more common) only one factor in a term
> > is left after na.exclude removes the other NA values.
> >
> > Here is the error I would get
> 
> From what code?
> 
> 
> > above if one of the terms was a factor with one level:
> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> >  contrasts can be applied only to factors with 2 or more levels
> 
> Unable to create that error with the actions you decribe but to not actually
> offer in coded form:
> 
> 
> > dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=TRUE, x3=rnorm(10))
> > lm(y~x1+x2+x3, dfrm)
> 
> Call:
> lm(formula = y ~ x1 + x2 + x3, data = dfrm)
> 
> Coefficients:
> (Intercept)           x1       x2TRUE           x3
>    -0.16274     -0.30032           NA     -0.09093
> 
> > resid(lm(y~x1+x2+x3, data=dfrm, na.action=na.exclude))
>           1           2           3           4           5           6
> -0.16097245  0.65408508 -0.70098223 -0.15360434  1.26027872  0.55752239
>           7           8           9          10
> -0.05965653 -2.17480605  1.42917190 -0.65103650
> 
> >
> 
> 
> > Instead of giving me an error, I'd like the function to do just what
> > lm() normally does when it sees a variable with no variance, ignore
> > the variable (coefficient is NA) and continue to regress out all the other
> variables.
> > Thus if 'x2' is a factor with one variable in the above example, I'd
> > like the function to return the result of:
> > resid(lm(y~x1+x3, data=df, na.action=na.exclude)) Can anyone provide
> > me a straight forward recommendation for how to do this?
> > I feel like it should be easy, but I'm honestly stuck, and my Google
> > searching for this hasn't gotten anywhere. The key is that I'd like
> > the solution to be generic enough to work with an arbitrary linear
> > formula, and not substantially kludgy (like trying ever combination of
> > regressions terms until one works) as I'll be running this a lot on
> > big data sets and don't want my computation time swamped by running
> > unnecessary regressions or checking for number of factors after removing
> NAs.
> >
> > Thanks in advance!
> > --Robert
> >
> >
> > PS. The Google search feature in the R-help archives appears to be down:
> > http://tolstoy.newcastle.edu.au/R/
> 
> It's working for me.
> 
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

I agree that what is wanted is not clear.  However, if dfrm is created with x2 as a factor, then you get the error message that the OP mentions when you run the regression.

> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


From dwinsemius at comcast.net  Fri Mar 11 08:25:57 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Mar 2016 23:25:57 -0800
Subject: [R] Regression with factor having1 level
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>


> On Mar 10, 2016, at 5:45 PM, Nordlund, Dan (DSHS/RDA) <NordlDJ at dshs.wa.gov> wrote:
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
>> Winsemius
>> Sent: Thursday, March 10, 2016 4:39 PM
>> To: Robert McGehee
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Regression with factor having1 level
>> 
>> 
>>> On Mar 10, 2016, at 2:00 PM, Robert McGehee <rmcgehee at gmail.com>
>> wrote:
>>> 
>>> Hello R-helpers,
>>> I'd like a function that given an arbitrary formula and a data frame
>>> returns the residual of the dependent variable,and maintains all NA values.
>> 
>> What does "maintains all NA values" actually mean?
>>> 
>>> Here's an example that will give me what I want if my formula is
>>> y~x1+x2+x3 and my data frame is df:
>>> 
>>> resid(lm(y~x1+x2+x3, data=df, na.action=na.exclude))
>>> 
>>> Here's the catch, I do not want my function to ever fail due to a
>>> factor with only one level. A one-level factor may appear because 1)
>>> the user passed it in, or 2) (more common) only one factor in a term
>>> is left after na.exclude removes the other NA values.
>>> 
>>> Here is the error I would get
>> 
>> From what code?
>> 
>> 
>>> above if one of the terms was a factor with one level:
>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>> contrasts can be applied only to factors with 2 or more levels
>> 
>> Unable to create that error with the actions you decribe but to not actually
>> offer in coded form:
>> 
>> 
>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=TRUE, x3=rnorm(10))
>>> lm(y~x1+x2+x3, dfrm)
>> 
>> Call:
>> lm(formula = y ~ x1 + x2 + x3, data = dfrm)
>> 
>> Coefficients:
>> (Intercept)           x1       x2TRUE           x3
>>   -0.16274     -0.30032           NA     -0.09093
>> 
>>> resid(lm(y~x1+x2+x3, data=dfrm, na.action=na.exclude))
>>          1           2           3           4           5           6
>> -0.16097245  0.65408508 -0.70098223 -0.15360434  1.26027872  0.55752239
>>          7           8           9          10
>> -0.05965653 -2.17480605  1.42917190 -0.65103650
>> 
>>> 
>> 
>> 
>>> Instead of giving me an error, I'd like the function to do just what
>>> lm() normally does when it sees a variable with no variance, ignore
>>> the variable (coefficient is NA) and continue to regress out all the other
>> variables.
>>> Thus if 'x2' is a factor with one variable in the above example, I'd
>>> like the function to return the result of:
>>> resid(lm(y~x1+x3, data=df, na.action=na.exclude)) Can anyone provide
>>> me a straight forward recommendation for how to do this?
>>> I feel like it should be easy, but I'm honestly stuck, and my Google
>>> searching for this hasn't gotten anywhere. The key is that I'd like
>>> the solution to be generic enough to work with an arbitrary linear
>>> formula, and not substantially kludgy (like trying ever combination of
>>> regressions terms until one works) as I'll be running this a lot on
>>> big data sets and don't want my computation time swamped by running
>>> unnecessary regressions or checking for number of factors after removing
>> NAs.
>>> 
>>> Thanks in advance!
>>> --Robert
>>> 
>>> 
>>> PS. The Google search feature in the R-help archives appears to be down:
>>> http://tolstoy.newcastle.edu.au/R/
>> 
>> It's working for me.
>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> I agree that what is wanted is not clear.  However, if dfrm is created with x2 as a factor, then you get the error message that the OP mentions when you run the regression.
> 
>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>  contrasts can be applied

Yes, and the error appears to come from `model.matrix`:

> model.matrix(y~x1+factor(x2)+x3, dfrm)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels

> model.matrix(y~x1+x2+x3, dfrm)
   (Intercept)          x1 x2TRUE         x3
1            1  0.04887847      1 -0.4199628
2            1 -1.04786688      1  1.3947923
3            1 -0.34896007      1 -2.1873666
4            1 -0.08866061      1  0.1204129
5            1 -0.41111366      1 -1.6631057
6            1 -0.83449110      1  1.1631801
7            1 -0.67887823      1  0.3207544
8            1 -1.12206068      1  0.6012040
9            1  0.05116683      1  0.3598696
10           1  1.74413583      1  0.3608478
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$x2
[1] "contr.treatment"

-- 

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Fri Mar 11 09:40:20 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Mar 2016 09:40:20 +0100
Subject: [R] Regression with factor having1 level
In-Reply-To: <CAOpVXKqJ9B89VF3NTBKf3ZiVBv7RVujdUvQ-R4tp_5HwLFdrBg@mail.gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<CAOpVXKqJ9B89VF3NTBKf3ZiVBv7RVujdUvQ-R4tp_5HwLFdrBg@mail.gmail.com>
Message-ID: <CDB1AB9F-67E5-47C2-B0AD-798743243F95@gmail.com>


> On 11 Mar 2016, at 02:03 , Robert McGehee <rmcgehee at gmail.com> wrote:
> 
>> df <- data.frame(y=c(0,2,4,6,8), x1=c(1,1,2,2,NA),
> x2=factor(c("A","A","A","A","B")))
>> resid(lm(y~x1+x2, data=df, na.action=na.exclude)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Mar 11 09:48:40 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Mar 2016 09:48:40 +0100
Subject: [R] Regression with factor having1 level
In-Reply-To: <71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
	<71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
Message-ID: <FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>


> On 11 Mar 2016, at 08:25 , David Winsemius <dwinsemius at comcast.net> wrote:
>> 
...
>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>> contrasts can be applied
> 
> Yes, and the error appears to come from `model.matrix`:
> 
>> model.matrix(y~x1+factor(x2)+x3, dfrm)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>  contrasts can be applied only to factors with 2 or more levels
> 

Actually not. The above is because you use an explicit factor(x2). The actual smoking gun is this line in lm()

mf$drop.unused.levels <- TRUE

which someone must have thought was a good idea at some point....

model.matrix itself is quite happy to leave factors alone and let subsequent code sort out any singularities, e.g.

> model.matrix(y~x1+x2, data=df[1:2,])
  (Intercept) x1 x2B
1           1  1   0
2           1  1   0
attr(,"assign")
[1] 0 1 2
attr(,"contrasts")
attr(,"contrasts")$x2
[1] "contr.treatment"



>> model.matrix(y~x1+x2+x3, dfrm)
>   (Intercept)          x1 x2TRUE         x3
> 1            1  0.04887847      1 -0.4199628
> 2            1 -1.04786688      1  1.3947923
> 3            1 -0.34896007      1 -2.1873666
> 4            1 -0.08866061      1  0.1204129
> 5            1 -0.41111366      1 -1.6631057
> 6            1 -0.83449110      1  1.1631801
> 7            1 -0.67887823      1  0.3207544
> 8            1 -1.12206068      1  0.6012040
> 9            1  0.05116683      1  0.3598696
> 10           1  1.74413583      1  0.3608478
> attr(,"assign")
> [1] 0 1 2 3
> attr(,"contrasts")
> attr(,"contrasts")$x2
> [1] "contr.treatment"
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From xavier.chiriboga at unine.ch  Fri Mar 11 11:43:53 2016
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 11 Mar 2016 10:43:53 +0000
Subject: [R] How to install package effects
Message-ID: <1457693033141.26137@unine.ch>

Dear all,

How to install function effects in R 3.1.2.?                         I got this:

 plot(effect("soil:volatile", model1))
Error in plot(effect("soil:volatile", model1)) :
  could not find function "effect"
Error in find.package(if (is.null(package)) loadedNamespaces() else package,  :
  there is no package called ''

Thank you very much,

Xavier


From petr.pikal at precheza.cz  Fri Mar 11 12:55:46 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 11 Mar 2016 11:55:46 +0000
Subject: [R] How to install package effects
In-Reply-To: <1457693033141.26137@unine.ch>
References: <1457693033141.26137@unine.ch>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5013C0D@SRVEXCHMBX.precheza.cz>

Hi

Hm. Strange that you did not use any non-base package yet.

install.pakages("effects")
library(effects)

shall do the trick.

And if you are in installing, you could renew your R version which is rather old.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> CHIRIBOGA Xavier
> Sent: Friday, March 11, 2016 11:44 AM
> To: r-help at R-project.org
> Subject: [R] How to install package effects
>
> Dear all,
>
> How to install function effects in R 3.1.2.?                         I
> got this:
>
>  plot(effect("soil:volatile", model1))
> Error in plot(effect("soil:volatile", model1)) :
>   could not find function "effect"
> Error in find.package(if (is.null(package)) loadedNamespaces() else
> package,  :
>   there is no package called ''
>
> Thank you very much,
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Roger.Bivand at nhh.no  Fri Mar 11 12:57:18 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Mar 2016 11:57:18 +0000
Subject: [R] Map of Europe at NUTS 2 Level
References: <CAMLwc7P1ArHa0m0_Bf6G-JTdzuWJUr5VfDyjZ2szCKjeO2AMzA@mail.gmail.com>
Message-ID: <loom.20160311T125100-605@post.gmane.org>

Miluji Sb <milujisb <at> gmail.com> writes:

> 
> Dear all.
> 
> I would like to draw a map of France, Italy, Spain, and Portugal at NUTS 2
> level. I used the following code:
> 
...
> # Subset NUTS 2 level data
> map_nuts2 <- subset(EU_NUTS, STAT_LEVL_ == 2)
> 
> # Draw basic plot
> plot(map_nuts2)

country <- substring(as.character(map_nuts2$NUTS_ID), 1, 2)
map <- c("ES", "FR", "IT", "PT")
map_nuts2a <- map_nuts2[country %in% map,]
plot(map_nuts2)

but this includes all the overseas territories and islands. Use xlim=, ylim=
to exclude these, or select based on knowing their NUTS2 codes:

plot(nuts2a, axes=TRUE, xlim=c(-11.62699, 19.20174), ylim=c(34.35470, 52.04182))

Roger

PS. One gets more, and more rapid replies to this kind of question on R-sig-geo.

> 
> This does produce a plot but its rather 'ugle'. Is there any way I can
> subset the data further and draw a map for France, Italy, Spain, and
> Portugal only? Thank you very much!
> 
> Sincerely,
> 
> Milu
>


From Rainer at krugs.de  Fri Mar 11 12:59:17 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 11 Mar 2016 12:59:17 +0100
Subject: [R] How to install package effects
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5013C0D@SRVEXCHMBX.precheza.cz>
	(PIKAL Petr's message of "Fri, 11 Mar 2016 11:55:46 +0000")
References: <1457693033141.26137@unine.ch>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5013C0D@SRVEXCHMBX.precheza.cz>
Message-ID: <m2ziu56x9m.fsf@krugs.de>

PIKAL Petr <petr.pikal at precheza.cz> writes:

> Hi
>
> Hm. Strange that you did not use any non-base package yet.

True

Small typo:

>
> install.pakages("effects")
install.packages("effects")
         ^^^^^


> library(effects)
>
> shall do the trick.
>
> And if you are in installing, you could renew your R version which is rather old.
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> CHIRIBOGA Xavier
>> Sent: Friday, March 11, 2016 11:44 AM
>> To: r-help at R-project.org
>> Subject: [R] How to install package effects
>>
>> Dear all,
>>
>> How to install function effects in R 3.1.2.?                         I
>> got this:
>>
>>  plot(effect("soil:volatile", model1))
>> Error in plot(effect("soil:volatile", model1)) :
>>   could not find function "effect"
>> Error in find.package(if (is.null(package)) loadedNamespaces() else
>> package,  :
>>   there is no package called ''
>>
>> Thank you very much,
>>
>> Xavier
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________

[snip: disclaimer (52 lines)]

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160311/9a5681b6/attachment.bin>

From javanmard.majid at gmail.com  Fri Mar 11 13:15:33 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Fri, 11 Mar 2016 15:45:33 +0330
Subject: [R] Ipred Bagging Question
Message-ID: <CAA0OCnvHf0XWLYUUtYmWG1Lt8XbGK7aaeQy4gfgohPXweZ2nHg@mail.gmail.com>

Hello everyone

here is the code that implements bagging using ipred package :

library(ipred)
library(mlbench)
data("BostonHousing")
# Test set error (nbagg=25, trees pruned): 3.41 (Breiman, 1996a, Table 8)
mod <- bagging(medv ~ ., data=BostonHousing, coob=TRUE)
print(mod)

it`s output is just RMSE , but I need the values after bagging How can I
have it ?
in addition of values, 95% Confidence interval for each value is needed !?

I appreciate if someone help me

Thanks

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Fri Mar 11 08:57:33 2016
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 11 Mar 2016 07:57:33 +0000
Subject: [R] package Formula????
Message-ID: <1457683053509.48121@unine.ch>

Dear all, again me


I have already updated my version of R. But still appears this message:


plot(ctree(Surv(hours,state)~soil+volatile, data=data))
Error in loadNamespace(name) : there is no package called 'Formula'


I cannot find a package "Formula" in my list of packages. What to do in that case?


Thank you,

Xavier


From Achim.Zeileis at uibk.ac.at  Fri Mar 11 14:24:28 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 11 Mar 2016 14:24:28 +0100 (CET)
Subject: [R] package Formula????
In-Reply-To: <1457683053509.48121@unine.ch>
References: <1457683053509.48121@unine.ch>
Message-ID: <alpine.DEB.2.20.1603111423210.16735@paninaro>

On Fri, 11 Mar 2016, CHIRIBOGA Xavier wrote:

> Dear all, again me
>
>
> I have already updated my version of R. But still appears this message:
>
>
> plot(ctree(Surv(hours,state)~soil+volatile, data=data))
> Error in loadNamespace(name) : there is no package called 'Formula'
>
>
> I cannot find a package "Formula" in my list of packages. What to do in that case?

As you were instructed yesterday: Simply install the package "Formula". 
You can do this in R on the command line

install.packages("Formula")

or using the graphical user interface if you are using one...

>
> Thank you,
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rainer at krugs.de  Fri Mar 11 15:01:56 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 11 Mar 2016 15:01:56 +0100
Subject: [R] specify size of box around legend
Message-ID: <m2lh5p6rl7.fsf@krugs.de>

Hi

assume the following code:

--8<---------------cut here---------------start------------->8---
plot(1,1)
legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
legend(x="topright", legend = LETTERS[1:15], title = "L 3")
--8<---------------cut here---------------end--------------->8---

The box around L 1 is less wide than the box around L 2 due to automatic
sizing of the box.

Is there a way of specifying the width of the box, so that L 1 and L 2
have the same width?

In the same sense: can I also specify the height of the legend, so that
L 1 and L 3 have the same height?

Thanks,

Rainer
-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160311/9314fa85/attachment.bin>

From murdoch.duncan at gmail.com  Fri Mar 11 15:22:22 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 Mar 2016 09:22:22 -0500
Subject: [R] specify size of box around legend
In-Reply-To: <m2lh5p6rl7.fsf@krugs.de>
References: <m2lh5p6rl7.fsf@krugs.de>
Message-ID: <56E2D49E.1030808@gmail.com>

On 11/03/2016 9:01 AM, Rainer M Krug wrote:
> Hi
>
> assume the following code:
>
> --8<---------------cut here---------------start------------->8---
> plot(1,1)
> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
> --8<---------------cut here---------------end--------------->8---
>
> The box around L 1 is less wide than the box around L 2 due to automatic
> sizing of the box.
>
> Is there a way of specifying the width of the box, so that L 1 and L 2
> have the same width?

text.width should work.  (It is in the ?legend help page, along with 
approximately one million other optional arguments.)
>
> In the same sense: can I also specify the height of the legend, so that
> L 1 and L 3 have the same height?

You can add blank entries as fillers to L 1.

Duncan Murdoch


From Roman.Pees at elisabethgruppe.de  Fri Mar 11 13:34:34 2016
From: Roman.Pees at elisabethgruppe.de (Pees, Roman)
Date: Fri, 11 Mar 2016 12:34:34 +0000
Subject: [R] Information to R-Project
Message-ID: <94285800FCFB0F42A2E2D351F4D91F5501233ABBDE@rz-exch-dag02.vgr.local>

Dear Support Team,

Our company needs a new software for scientific statistics.
We have looked at your software " R Project?

I would ask you to provide information on the following criteria:

1) Is the R-Procejt software terminal compatible? We have deployed Citrix.  Are there any Server modules we could use for our company?
2) There are 10 employees who want to use the software concurrently. What are the costs for licensing?
3) Does the ?R Project? software require any Database Connections or other Services?
4) Which technical requirements does the environment has to provide to ensure an optimal peformance?



I thank you for your attention

Sch?ne Gr??e / Sincerly
R. Pees
____________________________

Roman Pees
IT-Abteilung

ST. ELISABETH GRUPPE GmbH
Katholische Kliniken Rhein-Ruhr
Landgrafenstra?e 15
44652 Herne

Mail: Roman.Pees at elisabethgruppe.de<mailto:Roman.Pees at elisabethgruppe.de>
www.elisabethgruppe.de<http://www.elisabethgruppe.de/>

_______________________________________________________________

Mitten in der St. Elisabeth Gruppe:
St. Anna Hospital Herne, Marien Hospital Herne ? Universit?tsklinikum der Ruhr-Universit?t Bochum,
Marien Hospital Witten, Rheumazentrum Ruhrgebiet, St. Marien Hospital Eickel,
Medizinische Reha f?r psychische Gesundheit, G?stehaus St. Elisabeth, Ambulante Pflege, Arztpraxen - MVZ Herne,
Lukas Hospiz Herne, Bildungszentrum Ruhr, Bildungswerk, Krankenpflegeschule, Akademie der Physiotherapie,
Kinder in der St. Elisabeth Gruppe
_______________________________________________________________

Aufsichtsratsvorsitzender: Dr. Johannes Baumann
Gesch?ftsf?hrer: Theo Freitag

Registergericht:
HRB 9735 Amtsgericht Bochum
St.-Nr.: 325/5894/2251


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Mar 11 15:42:02 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 11 Mar 2016 09:42:02 -0500
Subject: [R] Information to R-Project
In-Reply-To: <94285800FCFB0F42A2E2D351F4D91F5501233ABBDE@rz-exch-dag02.vgr.local>
References: <94285800FCFB0F42A2E2D351F4D91F5501233ABBDE@rz-exch-dag02.vgr.local>
Message-ID: <833AF49A-7D2D-4BFE-A711-86BA68257B84@utoronto.ca>

Inline
On Mar 11, 2016, at 7:34 AM, Pees, Roman <Roman.Pees at elisabethgruppe.de> wrote:

> Dear Support Team,
> 
> Our company needs a new software for scientific statistics.
> We have looked at your software " R Project?
> 
> I would ask you to provide information on the following criteria:
> 
> 1) Is the R-Procejt software terminal compatible? We have deployed Citrix.  Are there any Server modules we could use for our company?
Yes.

> 2) There are 10 employees who want to use the software concurrently. What are the costs for licensing?
None.

> 3) Does the ?R Project? software require any Database Connections or other Services?
No.

> 4) Which technical requirements does the environment has to provide to ensure an optimal peformance?
Basic laptop or server specifications are normally sufficient.



B.

> 
> 
> 
> I thank you for your attention
> 
> Sch?ne Gr??e / Sincerly
> R. Pees
> ____________________________
> 
> Roman Pees
> IT-Abteilung
> 
> ST. ELISABETH GRUPPE GmbH
> Katholische Kliniken Rhein-Ruhr
> Landgrafenstra?e 15
> 44652 Herne
> 
> Mail: Roman.Pees at elisabethgruppe.de<mailto:Roman.Pees at elisabethgruppe.de>
> www.elisabethgruppe.de<http://www.elisabethgruppe.de/>
> 
> _______________________________________________________________
> 
> Mitten in der St. Elisabeth Gruppe:
> St. Anna Hospital Herne, Marien Hospital Herne ? Universit?tsklinikum der Ruhr-Universit?t Bochum,
> Marien Hospital Witten, Rheumazentrum Ruhrgebiet, St. Marien Hospital Eickel,
> Medizinische Reha f?r psychische Gesundheit, G?stehaus St. Elisabeth, Ambulante Pflege, Arztpraxen - MVZ Herne,
> Lukas Hospiz Herne, Bildungszentrum Ruhr, Bildungswerk, Krankenpflegeschule, Akademie der Physiotherapie,
> Kinder in der St. Elisabeth Gruppe
> _______________________________________________________________
> 
> Aufsichtsratsvorsitzender: Dr. Johannes Baumann
> Gesch?ftsf?hrer: Theo Freitag
> 
> Registergericht:
> HRB 9735 Amtsgericht Bochum
> St.-Nr.: 325/5894/2251
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Fri Mar 11 15:50:56 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 11 Mar 2016 15:50:56 +0100
Subject: [R] specify size of box around legend
In-Reply-To: <56E2D49E.1030808@gmail.com> (Duncan Murdoch's message of "Fri,
	11 Mar 2016 09:22:22 -0500")
References: <m2lh5p6rl7.fsf@krugs.de> <56E2D49E.1030808@gmail.com>
Message-ID: <m260wt6pbj.fsf@krugs.de>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 11/03/2016 9:01 AM, Rainer M Krug wrote:
>> Hi
>>
>> assume the following code:
>>
>> --8<---------------cut here---------------start------------->8---
>> plot(1,1)
>> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
>> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
>> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
>> --8<---------------cut here---------------end--------------->8---
>>
>> The box around L 1 is less wide than the box around L 2 due to automatic
>> sizing of the box.
>>
>> Is there a way of specifying the width of the box, so that L 1 and L 2
>> have the same width?
>
> text.width should work.  (It is in the ?legend help page, along with
> approximately one million other optional arguments.)

Thanks - that works.

May I suggest to change the documentation from:

--8<---------------cut here---------------start------------->8---
text.width: the width of the legend text in x (?"user"?) coordinates.
          (Should be positive even for a reversed x axis.)  Defaults to
          the proper value computed by ?strwidth(legend)?.
--8<---------------cut here---------------end--------------->8---

to

--8<---------------cut here---------------start------------->8---
text.width: the width of the legend text in x (?"user"?) coordinates.
          (Should be positive even for a reversed x axis.)  If set,
         it is used to compute the width of the legend box. Defaults to
          the proper value computed by ?strwidth(legend)?.
--8<---------------cut here---------------end--------------->8---

to make this clear?


>>
>> In the same sense: can I also specify the height of the legend, so that
>> L 1 and L 3 have the same height?
>
> You can add blank entries as fillers to L 1.

True - but no other parameter to achieve this? Equivalent to text.widht?


Thanks

Rainer


>
> Duncan Murdoch

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160311/5b9c034e/attachment.bin>

From jan.kacaba at gmail.com  Fri Mar 11 15:55:55 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Fri, 11 Mar 2016 15:55:55 +0100
Subject: [R] treating integer(0) and NULL in conditions and loops
Message-ID: <CAHby=D3CbzKjJtq4D8kxHPgmdM+x54qJat3Q6frGGqsO1q_LAw@mail.gmail.com>

Hello, I have following problem in loops. It occurred to me multiple times
bellow is an example.  Inside if() I have sometimes function f(x) which may
return integer(0).  If I test f(x)>1 and f(x)=integer(0) I get error. Maybe
it can be solved more eloquently without loop or swithces. I don't know.

Example:

a=c("ab","abc","abcd","abcde","abcdefghjk") # vector from which new strings
will be constructed
svec=NULL # vector of string
rz=NULL # string

for (i in 1:10){
if (nchar(rz)>6){
  svec[i]=rz
  rz=NULL
}

if (nchar(a[i])+nchar(rz))<6){
  rz=paste(rz,a[i])
}

if (nchar(rz)+nchar(a[i+1]>6){
  svec[i]=rz
  rz=NULL
}
}

I'm not interested how to treat nchar() function in particular but general
function. One solution which comes to mind is to redefine function for
example nchar() function like this:

new.nchar=function(x){
if (length(nchar(rz))==0){z=0}
if (length(nchar(rz))>0){z=nchar(rz)}
return(z)
}

Is it correct way of doing this or is there a better way without the need
of redefining new function?
<derek>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Mar 11 16:15:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 Mar 2016 10:15:06 -0500
Subject: [R] specify size of box around legend
In-Reply-To: <m260wt6pbj.fsf@krugs.de>
References: <m2lh5p6rl7.fsf@krugs.de> <56E2D49E.1030808@gmail.com>
	<m260wt6pbj.fsf@krugs.de>
Message-ID: <56E2E0F9.2040209@gmail.com>

On 11/03/2016 9:50 AM, Rainer M Krug wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> > On 11/03/2016 9:01 AM, Rainer M Krug wrote:
> >> Hi
> >>
> >> assume the following code:
> >>
> >> --8<---------------cut here---------------start------------->8---
> >> plot(1,1)
> >> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
> >> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
> >> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
> >> --8<---------------cut here---------------end--------------->8---
> >>
> >> The box around L 1 is less wide than the box around L 2 due to automatic
> >> sizing of the box.
> >>
> >> Is there a way of specifying the width of the box, so that L 1 and L 2
> >> have the same width?
> >
> > text.width should work.  (It is in the ?legend help page, along with
> > approximately one million other optional arguments.)
>
> Thanks - that works.
>
> May I suggest to change the documentation from:
>
> --8<---------------cut here---------------start------------->8---
> text.width: the width of the legend text in x (?"user"?) coordinates.
>            (Should be positive even for a reversed x axis.)  Defaults to
>            the proper value computed by ?strwidth(legend)?.
> --8<---------------cut here---------------end--------------->8---
>
> to
>
> --8<---------------cut here---------------start------------->8---
> text.width: the width of the legend text in x (?"user"?) coordinates.
>            (Should be positive even for a reversed x axis.)  If set,
>           it is used to compute the width of the legend box. Defaults to
>            the proper value computed by ?strwidth(legend)?.
> --8<---------------cut here---------------end--------------->8---
>
> to make this clear?

I think it's already clear, but if not, this conversation is now in the 
public record, so anyone searching for "width of the legend box" on 
Google should find the help they need soon enough.
>
>
> >>
> >> In the same sense: can I also specify the height of the legend, so that
> >> L 1 and L 3 have the same height?
> >
> > You can add blank entries as fillers to L 1.
>
> True - but no other parameter to achieve this? Equivalent to text.widht?

I've only read the first hundred thousand argument descriptions, and I 
didn't find that.  You'll have to read the other nine hundred thousand 
yourself.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Fri Mar 11 16:55:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 11 Mar 2016 07:55:26 -0800
Subject: [R] Information to R-Project
In-Reply-To: <833AF49A-7D2D-4BFE-A711-86BA68257B84@utoronto.ca>
References: <94285800FCFB0F42A2E2D351F4D91F5501233ABBDE@rz-exch-dag02.vgr.local>
	<833AF49A-7D2D-4BFE-A711-86BA68257B84@utoronto.ca>
Message-ID: <8E99C372-C0EB-4D06-A05B-960BE4EF1DD7@dcn.davis.ca.us>

Q4 is highly dependent on the types of problems that are to be addressed by the user. Large problems may need more RAM, disk space, or separate database facilities to support the problem at hand, but there is nothing about R itself that requires these optional support resources.

OP should be warned that R is open source software and R-help is not a software support team... there is no warranty or support implied by the existence of this mailing list. If such a relationship is desired then it must be contracted with an individual or company that agrees to provide such support (preferably but not necessarily in advance of need).

-- 
Sent from my phone. Please excuse my brevity.

On March 11, 2016 6:42:02 AM PST, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>Inline
>On Mar 11, 2016, at 7:34 AM, Pees, Roman
><Roman.Pees at elisabethgruppe.de> wrote:
>
>> Dear Support Team,
>> 
>> Our company needs a new software for scientific statistics.
>> We have looked at your software " R Project?
>> 
>> I would ask you to provide information on the following criteria:
>> 
>> 1) Is the R-Procejt software terminal compatible? We have deployed
>Citrix.  Are there any Server modules we could use for our company?
>Yes.
>
>> 2) There are 10 employees who want to use the software concurrently.
>What are the costs for licensing?
>None.
>
>> 3) Does the ?R Project? software require any Database Connections or
>other Services?
>No.
>
>> 4) Which technical requirements does the environment has to provide
>to ensure an optimal peformance?
>Basic laptop or server specifications are normally sufficient.
>
>
>
>B.
>
>> 
>> 
>> 
>> I thank you for your attention
>> 
>> Sch?ne Gr??e / Sincerly
>> R. Pees
>> ____________________________
>> 
>> Roman Pees
>> IT-Abteilung
>> 
>> ST. ELISABETH GRUPPE GmbH
>> Katholische Kliniken Rhein-Ruhr
>> Landgrafenstra?e 15
>> 44652 Herne
>> 
>> Mail:
>Roman.Pees at elisabethgruppe.de<mailto:Roman.Pees at elisabethgruppe.de>
>> www.elisabethgruppe.de<http://www.elisabethgruppe.de/>
>> 
>> _______________________________________________________________
>> 
>> Mitten in der St. Elisabeth Gruppe:
>> St. Anna Hospital Herne, Marien Hospital Herne ? Universit?tsklinikum
>der Ruhr-Universit?t Bochum,
>> Marien Hospital Witten, Rheumazentrum Ruhrgebiet, St. Marien Hospital
>Eickel,
>> Medizinische Reha f?r psychische Gesundheit, G?stehaus St. Elisabeth,
>Ambulante Pflege, Arztpraxen - MVZ Herne,
>> Lukas Hospiz Herne, Bildungszentrum Ruhr, Bildungswerk,
>Krankenpflegeschule, Akademie der Physiotherapie,
>> Kinder in der St. Elisabeth Gruppe
>> _______________________________________________________________
>> 
>> Aufsichtsratsvorsitzender: Dr. Johannes Baumann
>> Gesch?ftsf?hrer: Theo Freitag
>> 
>> Registergericht:
>> HRB 9735 Amtsgericht Bochum
>> St.-Nr.: 325/5894/2251
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Mar 11 17:11:41 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Mar 2016 17:11:41 +0100
Subject: [R] Regression with factor having1 level
In-Reply-To: <CAOpVXKruJ7TSg8EnP7Cr8O_sjn1c2nGMV9v7BJQK8Zyg0Kk1MA@mail.gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<CAOpVXKqJ9B89VF3NTBKf3ZiVBv7RVujdUvQ-R4tp_5HwLFdrBg@mail.gmail.com>
	<CDB1AB9F-67E5-47C2-B0AD-798743243F95@gmail.com>
	<CAOpVXKruJ7TSg8EnP7Cr8O_sjn1c2nGMV9v7BJQK8Zyg0Kk1MA@mail.gmail.com>
Message-ID: <D844938B-F9F1-4AAA-9E09-E287DCE53F48@gmail.com>

The one you cite must have been due to fat-fingering (send instead of delete), but there was a later followup to David, w/copy to r-help.

-pd

On 11 Mar 2016, at 16:03 , Robert McGehee <rmcgehee at gmail.com> wrote:

> 
> PS, Peter, wasn't sure if you also meant to add comments, but they
> didn't come through.
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rmcgehee at gmail.com  Fri Mar 11 16:03:01 2016
From: rmcgehee at gmail.com (Robert McGehee)
Date: Fri, 11 Mar 2016 10:03:01 -0500
Subject: [R] Regression with factor having1 level
In-Reply-To: <CDB1AB9F-67E5-47C2-B0AD-798743243F95@gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<CAOpVXKqJ9B89VF3NTBKf3ZiVBv7RVujdUvQ-R4tp_5HwLFdrBg@mail.gmail.com>
	<CDB1AB9F-67E5-47C2-B0AD-798743243F95@gmail.com>
Message-ID: <CAOpVXKruJ7TSg8EnP7Cr8O_sjn1c2nGMV9v7BJQK8Zyg0Kk1MA@mail.gmail.com>

Hi,
In case this is helpful for anyone, I think I've coded a satisfactory
function answering my problem (of handling formulas containing 1-level
factors) by hacking liberally at the model.matrix code to remove any
model terms for which the contrast fails. As it's a problem I've come
across a lot (since my data frames have factors and lots of missing
values), adding support for 1-level factors might be a nice item for
the R Wishlist. I suppose a key question is, does anyone ever _want_
to see the error "contrasts can be applied only to factors with 2 or
more levels", or should the contrasts function just add a column of
all zeros (or ones) to the design matrix and let the modelling
functions handle that the same way it does any other zero-variance
term?

Anyway, my function below:

lmresid <- function(formula, data) {
    mf <- model.frame(formula, data=data, na.action=na.exclude)
    omit <- attr(mf, "na.action")
    t <- terms(mf)
    contr.funs <- as.character(getOption("contrasts"))
    namD <- names(mf)
    for (i in namD) if (is.character(mf[[i]]))
        mf[[i]] <- factor(mf[[i]])
    isF <- vapply(mf, function(x) is.factor(x) || is.logical(x), NA)
    isF[1] <- FALSE
    isOF <- vapply(mf, is.ordered, NA)
    for (nn in namD[isF])
        if (is.null(attr(mf[[nn]], "contrasts"))) {
            noCntr <- try(contrasts(mf[[nn]]) <- contr.funs[1 +
isOF[nn]], silent=TRUE)
            if (inherits(noCntr, "try-error")) {       # Remove term
from model on error
                mf[[nn]] <- NULL
                t <- terms(update(t, as.formula(paste("~ . -", nn))), data=mf)
            }
        }
    ans <- .External2(stats:::C_modelmatrix, t, mf)
    r   <- .lm.fit(ans, mf[[1]])$residual
    stats:::naresid.exclude(omit, r)
}

## Note that lmresid now returns the same values as resid with the
## 1-level factor removed.
df <- data.frame(y=c(0,2,4,6,8), x1=c(1,1,2,2,NA),
x2=factor(c("A","A","A","A","B")))
lmresid(y~x1+x2, data=df)
resid(lm(y~x1, data=df, na.action=na.exclude))

--Robert

PS, Peter, wasn't sure if you also meant to add comments, but they
didn't come through.


On Fri, Mar 11, 2016 at 3:40 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 11 Mar 2016, at 02:03 , Robert McGehee <rmcgehee at gmail.com> wrote:
>>
>>> df <- data.frame(y=c(0,2,4,6,8), x1=c(1,1,2,2,NA),
>> x2=factor(c("A","A","A","A","B")))
>>> resid(lm(y~x1+x2, data=df, na.action=na.exclude)
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From dwinsemius at comcast.net  Fri Mar 11 17:56:48 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Mar 2016 08:56:48 -0800
Subject: [R] Regression with factor having1 level
In-Reply-To: <FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
	<71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
	<FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>
Message-ID: <4E834EF0-EF68-4544-8A39-92ABBF0F4BE4@comcast.net>


> On Mar 11, 2016, at 12:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 11 Mar 2016, at 08:25 , David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
> ...
>>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>>>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>> contrasts can be applied
>> 
>> Yes, and the error appears to come from `model.matrix`:
>> 
>>> model.matrix(y~x1+factor(x2)+x3, dfrm)
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>> contrasts can be applied only to factors with 2 or more levels
>> 
> 
> Actually not. The above is because you use an explicit factor(x2). The actual smoking gun is this line in lm()
> 
> mf$drop.unused.levels <- TRUE

It's possible that modifying model.matrix to allow single level factors would then bump up against that check, but  at the moment the traceback() from an error generated with data that has a single level factor and no call to factor in the formula still implicates code in model.matrix:

> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=factor(TRUE), x3=rnorm(10))
> lm(y~x1+x2+x3, dfrm)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels
> traceback()
5: stop("contrasts can be applied only to factors with 2 or more levels")
4: `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]])
3: model.matrix.default(mt, mf, contrasts)
2: model.matrix(mt, mf, contrasts)
1: lm(y ~ x1 + x2 + x3, dfrm)

-- 
David.

> 
> which someone must have thought was a good idea at some point....
> 
> model.matrix itself is quite happy to leave factors alone and let subsequent code sort out any singularities, e.g.
> 
>> model.matrix(y~x1+x2, data=df[1:2,])
>  (Intercept) x1 x2B
> 1           1  1   0
> 2           1  1   0
> attr(,"assign")
> [1] 0 1 2
> attr(,"contrasts")
> attr(,"contrasts")$x2
> [1] "contr.treatment"
> 
> 
> 
>>> model.matrix(y~x1+x2+x3, dfrm)
>>  (Intercept)          x1 x2TRUE         x3
>> 1            1  0.04887847      1 -0.4199628
>> 2            1 -1.04786688      1  1.3947923
>> 3            1 -0.34896007      1 -2.1873666
>> 4            1 -0.08866061      1  0.1204129
>> 5            1 -0.41111366      1 -1.6631057
>> 6            1 -0.83449110      1  1.1631801
>> 7            1 -0.67887823      1  0.3207544
>> 8            1 -1.12206068      1  0.6012040
>> 9            1  0.05116683      1  0.3598696
>> 10           1  1.74413583      1  0.3608478
>> attr(,"assign")
>> [1] 0 1 2 3
>> attr(,"contrasts")
>> attr(,"contrasts")$x2
>> [1] "contr.treatment"
>> 
>> -- 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA


From jvadams at usgs.gov  Fri Mar 11 18:10:15 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 11 Mar 2016 11:10:15 -0600
Subject: [R] treating integer(0) and NULL in conditions and loops
In-Reply-To: <CAHby=D3CbzKjJtq4D8kxHPgmdM+x54qJat3Q6frGGqsO1q_LAw@mail.gmail.com>
References: <CAHby=D3CbzKjJtq4D8kxHPgmdM+x54qJat3Q6frGGqsO1q_LAw@mail.gmail.com>
Message-ID: <CAN5YmCGT=8cq88m+mZU3Xo-ZZsXh235dKnBfm6FnbZxScM_Dfw@mail.gmail.com>

To reframe the problem ... the issue is not with the function nchar() (or
whatever), it's with the input value rz being null.  I suggest you build
into the loop whatever actions/outputs you want when rz is NULL.

for (i in 1:10){
  if (is.null(rz)) {
    # do something here
  } else {
    if (nchar(rz)>6) {
      # ...
    }
    if (nchar(a[i])+nchar(rz))<6) {
      # ...
    }
    if (nchar(rz)+nchar(a[i+1]>6) {
      # ...
    }
  }
}

Jean


On Fri, Mar 11, 2016 at 8:55 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:

> Hello, I have following problem in loops. It occurred to me multiple times
> bellow is an example.  Inside if() I have sometimes function f(x) which may
> return integer(0).  If I test f(x)>1 and f(x)=integer(0) I get error. Maybe
> it can be solved more eloquently without loop or swithces. I don't know.
>
> Example:
>
> a=c("ab","abc","abcd","abcde","abcdefghjk") # vector from which new strings
> will be constructed
> svec=NULL # vector of string
> rz=NULL # string
>
> for (i in 1:10){
> if (nchar(rz)>6){
>   svec[i]=rz
>   rz=NULL
> }
>
> if (nchar(a[i])+nchar(rz))<6){
>   rz=paste(rz,a[i])
> }
>
> if (nchar(rz)+nchar(a[i+1]>6){
>   svec[i]=rz
>   rz=NULL
> }
> }
>
> I'm not interested how to treat nchar() function in particular but general
> function. One solution which comes to mind is to redefine function for
> example nchar() function like this:
>
> new.nchar=function(x){
> if (length(nchar(rz))==0){z=0}
> if (length(nchar(rz))>0){z=nchar(rz)}
> return(z)
> }
>
> Is it correct way of doing this or is there a better way without the need
> of redefining new function?
> <derek>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 11 18:27:17 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 11 Mar 2016 09:27:17 -0800
Subject: [R] treating integer(0) and NULL in conditions and loops
In-Reply-To: <CAN5YmCGT=8cq88m+mZU3Xo-ZZsXh235dKnBfm6FnbZxScM_Dfw@mail.gmail.com>
References: <CAHby=D3CbzKjJtq4D8kxHPgmdM+x54qJat3Q6frGGqsO1q_LAw@mail.gmail.com>
	<CAN5YmCGT=8cq88m+mZU3Xo-ZZsXh235dKnBfm6FnbZxScM_Dfw@mail.gmail.com>
Message-ID: <CAF8bMcYt1X4S13WsYEz-sbsgUXsMKma5T6edXX04214T6A=Q6g@mail.gmail.com>

I would suggesting using "" instead of NULL for rz, throughout this code.

(I would also suggest making sure the code can be copied into R without
causing a syntax error before posting the request for help.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Mar 11, 2016 at 9:10 AM, Adams, Jean <jvadams at usgs.gov> wrote:

> To reframe the problem ... the issue is not with the function nchar() (or
> whatever), it's with the input value rz being null.  I suggest you build
> into the loop whatever actions/outputs you want when rz is NULL.
>
> for (i in 1:10){
>   if (is.null(rz)) {
>     # do something here
>   } else {
>     if (nchar(rz)>6) {
>       # ...
>     }
>     if (nchar(a[i])+nchar(rz))<6) {
>       # ...
>     }
>     if (nchar(rz)+nchar(a[i+1]>6) {
>       # ...
>     }
>   }
> }
>
> Jean
>
>
> On Fri, Mar 11, 2016 at 8:55 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>
> > Hello, I have following problem in loops. It occurred to me multiple
> times
> > bellow is an example.  Inside if() I have sometimes function f(x) which
> may
> > return integer(0).  If I test f(x)>1 and f(x)=integer(0) I get error.
> Maybe
> > it can be solved more eloquently without loop or swithces. I don't know.
> >
> > Example:
> >
> > a=c("ab","abc","abcd","abcde","abcdefghjk") # vector from which new
> strings
> > will be constructed
> > svec=NULL # vector of string
> > rz=NULL # string
> >
> > for (i in 1:10){
> > if (nchar(rz)>6){
> >   svec[i]=rz
> >   rz=NULL
> > }
> >
> > if (nchar(a[i])+nchar(rz))<6){
> >   rz=paste(rz,a[i])
> > }
> >
> > if (nchar(rz)+nchar(a[i+1]>6){
> >   svec[i]=rz
> >   rz=NULL
> > }
> > }
> >
> > I'm not interested how to treat nchar() function in particular but
> general
> > function. One solution which comes to mind is to redefine function for
> > example nchar() function like this:
> >
> > new.nchar=function(x){
> > if (length(nchar(rz))==0){z=0}
> > if (length(nchar(rz))>0){z=nchar(rz)}
> > return(z)
> > }
> >
> > Is it correct way of doing this or is there a better way without the need
> > of redefining new function?
> > <derek>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Mar 11 23:07:23 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Mar 2016 23:07:23 +0100
Subject: [R] Regression with factor having1 level
In-Reply-To: <4E834EF0-EF68-4544-8A39-92ABBF0F4BE4@comcast.net>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
	<71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
	<FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>
	<4E834EF0-EF68-4544-8A39-92ABBF0F4BE4@comcast.net>
Message-ID: <DC8A8E08-4DFB-4DB5-B94F-7E2BAA49E36F@gmail.com>


> On 11 Mar 2016, at 17:56 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Mar 11, 2016, at 12:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> 
>>> On 11 Mar 2016, at 08:25 , David Winsemius <dwinsemius at comcast.net> wrote:
>>>> 
>> ...
>>>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>>>>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>>> contrasts can be applied
>>> 
>>> Yes, and the error appears to come from `model.matrix`:
>>> 
>>>> model.matrix(y~x1+factor(x2)+x3, dfrm)
>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>> contrasts can be applied only to factors with 2 or more levels
>>> 
>> 
>> Actually not. The above is because you use an explicit factor(x2). The actual smoking gun is this line in lm()
>> 
>> mf$drop.unused.levels <- TRUE
> 
> It's possible that modifying model.matrix to allow single level factors would then bump up against that check, but  at the moment the traceback() from an error generated with data that has a single level factor and no call to factor in the formula still implicates code in model.matrix:

You're missing the point: model.matrix has a beef with 1-level factors, not with 2-level factors of which one level happens to be absent, which is what this thread was originally about. It is lm that via model.frame with drop.unused.levels=TRUE converts the latter factors to the former.

-pd 


> 
>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=factor(TRUE), x3=rnorm(10))
>> lm(y~x1+x2+x3, dfrm)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>  contrasts can be applied only to factors with 2 or more levels
>> traceback()
> 5: stop("contrasts can be applied only to factors with 2 or more levels")
> 4: `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]])
> 3: model.matrix.default(mt, mf, contrasts)
> 2: model.matrix(mt, mf, contrasts)
> 1: lm(y ~ x1 + x2 + x3, dfrm)
> 
> -- 
> David.
> 
>> 
>> which someone must have thought was a good idea at some point....
>> 
>> model.matrix itself is quite happy to leave factors alone and let subsequent code sort out any singularities, e.g.
>> 
>>> model.matrix(y~x1+x2, data=df[1:2,])
>> (Intercept) x1 x2B
>> 1           1  1   0
>> 2           1  1   0
>> attr(,"assign")
>> [1] 0 1 2
>> attr(,"contrasts")
>> attr(,"contrasts")$x2
>> [1] "contr.treatment"
>> 
>> 
>> 
>>>> model.matrix(y~x1+x2+x3, dfrm)
>>> (Intercept)          x1 x2TRUE         x3
>>> 1            1  0.04887847      1 -0.4199628
>>> 2            1 -1.04786688      1  1.3947923
>>> 3            1 -0.34896007      1 -2.1873666
>>> 4            1 -0.08866061      1  0.1204129
>>> 5            1 -0.41111366      1 -1.6631057
>>> 6            1 -0.83449110      1  1.1631801
>>> 7            1 -0.67887823      1  0.3207544
>>> 8            1 -1.12206068      1  0.6012040
>>> 9            1  0.05116683      1  0.3598696
>>> 10           1  1.74413583      1  0.3608478
>>> attr(,"assign")
>>> [1] 0 1 2 3
>>> attr(,"contrasts")
>>> attr(,"contrasts")$x2
>>> [1] "contr.treatment"
>>> 
>>> -- 
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 
> David Winsemius
> Alameda, CA, USA

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Fri Mar 11 23:48:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Mar 2016 14:48:55 -0800
Subject: [R] Regression with factor having1 level
In-Reply-To: <DC8A8E08-4DFB-4DB5-B94F-7E2BAA49E36F@gmail.com>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
	<71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
	<FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>
	<4E834EF0-EF68-4544-8A39-92ABBF0F4BE4@comcast.net>
	<DC8A8E08-4DFB-4DB5-B94F-7E2BAA49E36F@gmail.com>
Message-ID: <BFF9C925-4607-4D5C-8D67-341FCF5E4430@comcast.net>


> On Mar 11, 2016, at 2:07 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 11 Mar 2016, at 17:56 , David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On Mar 11, 2016, at 12:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>> 
>>> 
>>>> On 11 Mar 2016, at 08:25 , David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>> ...
>>>>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>>>>>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
>>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>>>> contrasts can be applied
>>>> 
>>>> Yes, and the error appears to come from `model.matrix`:
>>>> 
>>>>> model.matrix(y~x1+factor(x2)+x3, dfrm)
>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>>> contrasts can be applied only to factors with 2 or more levels
>>>> 
>>> 
>>> Actually not. The above is because you use an explicit factor(x2). The actual smoking gun is this line in lm()
>>> 
>>> mf$drop.unused.levels <- TRUE
>> 
>> It's possible that modifying model.matrix to allow single level factors would then bump up against that check, but  at the moment the traceback() from an error generated with data that has a single level factor and no call to factor in the formula still implicates code in model.matrix:
> 
> You're missing the point: model.matrix has a beef with 1-level factors, not with 2-level factors of which one level happens to be absent, which is what this thread was originally about. It is lm that via model.frame with drop.unused.levels=TRUE converts the latter factors to the former.
> 

I guess I did miss the point. Apologies for being obtuse. I thought that a one level factor would have been "aliased out" when model.matrix "realized" that it was collinear with the intercept. (Further apologies for my projection of cognitive capacites on a machine.) Are you saying it remains desirable that an error be thrown rather than reporting an NA for coefficients and issuing a warning?

-- 
David.


> -pd 
> 
> 
>> 
>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=factor(TRUE), x3=rnorm(10))
>>> lm(y~x1+x2+x3, dfrm)
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>> contrasts can be applied only to factors with 2 or more levels
>>> traceback()
>> 5: stop("contrasts can be applied only to factors with 2 or more levels")
>> 4: `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]])
>> 3: model.matrix.default(mt, mf, contrasts)
>> 2: model.matrix(mt, mf, contrasts)
>> 1: lm(y ~ x1 + x2 + x3, dfrm)
>> 
>> -- 
>> David.
>> 
>>> 
>>> which someone must have thought was a good idea at some point....
>>> 
>>> model.matrix itself is quite happy to leave factors alone and let subsequent code sort out any singularities, e.g.
>>> 
>>>> model.matrix(y~x1+x2, data=df[1:2,])
>>> (Intercept) x1 x2B
>>> 1           1  1   0
>>> 2           1  1   0
>>> attr(,"assign")
>>> [1] 0 1 2
>>> attr(,"contrasts")
>>> attr(,"contrasts")$x2
>>> [1] "contr.treatment"
>>> 
>>> 
>>> 
>>>>> model.matrix(y~x1+x2+x3, dfrm)
>>>> (Intercept)          x1 x2TRUE         x3
>>>> 1            1  0.04887847      1 -0.4199628
>>>> 2            1 -1.04786688      1  1.3947923
>>>> 3            1 -0.34896007      1 -2.1873666
>>>> 4            1 -0.08866061      1  0.1204129
>>>> 5            1 -0.41111366      1 -1.6631057
>>>> 6            1 -0.83449110      1  1.1631801
>>>> 7            1 -0.67887823      1  0.3207544
>>>> 8            1 -1.12206068      1  0.6012040
>>>> 9            1  0.05116683      1  0.3598696
>>>> 10           1  1.74413583      1  0.3608478
>>>> attr(,"assign")
>>>> [1] 0 1 2 3
>>>> attr(,"contrasts")
>>>> attr(,"contrasts")$x2
>>>> [1] "contr.treatment"
>>>> 
>>>> -- 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> -- 
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sat Mar 12 00:57:23 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 12 Mar 2016 00:57:23 +0100
Subject: [R] Regression with factor having1 level
In-Reply-To: <BFF9C925-4607-4D5C-8D67-341FCF5E4430@comcast.net>
References: <CAOpVXKpF=rfJ+9DDB_sqg-ZzCW3wT+HJfExmX91R2qyH5E8a-w@mail.gmail.com>
	<075B442B-C1A6-4C75-9582-BFE6E30172D5@comcast.net>
	<F7E6D18CC2877149AB5296CE54EA27663093988B@WAXMXOLYMB025.WAX.wa.lcl>
	<71F3DC3C-AACA-411C-A074-E51A55B389FF@comcast.net>
	<FA088386-A40A-4BEC-99A7-DEFCB68CF646@gmail.com>
	<4E834EF0-EF68-4544-8A39-92ABBF0F4BE4@comcast.net>
	<DC8A8E08-4DFB-4DB5-B94F-7E2BAA49E36F@gmail.com>
	<BFF9C925-4607-4D5C-8D67-341FCF5E4430@comcast.net>
Message-ID: <EEB91410-B8EC-4FCA-8F67-1E7FC3BAF404@gmail.com>


> On 11 Mar 2016, at 23:48 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Mar 11, 2016, at 2:07 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> 
>>> On 11 Mar 2016, at 17:56 , David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> 
>>>> On Mar 11, 2016, at 12:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>>> 
>>>> 
>>>>> On 11 Mar 2016, at 08:25 , David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>> 
>>>> ...
>>>>>>> dfrm <- data.frame(y=rnorm(10), x1=rnorm(10) ,x2=as.factor(TRUE), x3=rnorm(10))
>>>>>>> lm(y~x1+x2+x3, dfrm, na.action=na.exclude)
>>>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>>>>> contrasts can be applied
>>>>> 
>>>>> Yes, and the error appears to come from `model.matrix`:
>>>>> 
>>>>>> model.matrix(y~x1+factor(x2)+x3, dfrm)
>>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
>>>>> contrasts can be applied only to factors with 2 or more levels
>>>>> 
>>>> 
>>>> Actually not. The above is because you use an explicit factor(x2). The actual smoking gun is this line in lm()
>>>> 
>>>> mf$drop.unused.levels <- TRUE
>>> 
>>> It's possible that modifying model.matrix to allow single level factors would then bump up against that check, but  at the moment the traceback() from an error generated with data that has a single level factor and no call to factor in the formula still implicates code in model.matrix:
>> 
>> You're missing the point: model.matrix has a beef with 1-level factors, not with 2-level factors of which one level happens to be absent, which is what this thread was originally about. It is lm that via model.frame with drop.unused.levels=TRUE converts the latter factors to the former.
>> 
> 
> I guess I did miss the point. Apologies for being obtuse. I thought that a one level factor would have been "aliased out" when model.matrix "realized" that it was collinear with the intercept. (Further apologies for my projection of cognitive capacites on a machine.) Are you saying it remains desirable that an error be thrown rather than reporting an NA for coefficients and issuing a warning?
> 

For the moment I was just analyzing where this came from. Intuitively I'd be leaning in the opposite direction -- dropping factor levels automatically is usually a bad thing.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From javanmard.majid at gmail.com  Sat Mar 12 10:55:48 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Sat, 12 Mar 2016 13:25:48 +0330
Subject: [R]  Ipred Bagging Question
Message-ID: <CAA0OCnvvJC0AjiaSsa-jk6S+N8oardhDWzoZODSDQcA=g6yUQQ@mail.gmail.com>

Hello everyone

here is the code that implements bagging using ipred package :

library(ipred)
library(mlbench)
data("BostonHousing")
# Test set error (nbagg=25, trees pruned): 3.41 (Breiman, 1996a, Table 8)
mod <- bagging(medv ~ ., data=BostonHousing, coob=TRUE)
print(mod)

it`s output is just RMSE , but I need the values after bagging How can I
have it ?
in addition of values, 95% Confidence interval for each value is needed !?

I appreciate if someone help me

Thanks

	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Sat Mar 12 20:27:42 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Sat, 12 Mar 2016 19:27:42 +0000
Subject: [R] Warning message with "projectRaster" (package "raster"): 'from'
 has no cell values
Message-ID: <AMSPR07MB470E8709644BC3625F42A99E2B60@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,



I have two rasters with different resolution and projection.



> r1

class       : RasterLayer

dimensions  : 2510, 5233, 13134830  (nrow, ncol, ncell)

resolution  : 56, 56  (x, y)

extent      : 503198, 796246, 4917498, 5058058  (xmin, xmax, ymin, ymax)

coord. ref. : +proj=utm +zone=18 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0

data source : in memory

names       : layer

values      : 1, 8  (min, max)



> r2

class       : RasterBrick

dimensions  : 3250, 6570, 21352500, 1  (nrow, ncol, ncell, nlayers)

resolution  : 30, 30  (x, y)

extent      : 265380.5, 462480.5, 4984457, 5081957  (xmin, xmax, ymin, ymax)

coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs

data source : H:\users\rast_temp.tif

names       : rast_temp



My objective is to merge the two rasters into a single raster. As the two rasters have different resolution and projection, I have used the function projectRaster (package raster) like this:


r <- projectRaster(from=r1, to=r2, method="ngb", alignOnly=TRUE)



However, I got this warning message:



Warning message:

In projectRaster(x, crs = projection(y)) : 'from' has no cell values



and yet, the two rasters have values:



> hasValues(r1)

[1] TRUE



> hasValues(r2)

[1] TRUE



When I remove the argument "alignOnly=TRUE", the code seems to work but I don't want that r1 has the same projected extent than r2 (I want to keep the original extent of r1).



Why do I get this warning message ?



Thank you very much for your help.

Marine


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Mar 13 02:33:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 12 Mar 2016 17:33:30 -0800
Subject: [R] Warning message with "projectRaster" (package "raster"):
	'from' has no cell values
In-Reply-To: <AMSPR07MB470E8709644BC3625F42A99E2B60@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB470E8709644BC3625F42A99E2B60@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <ABABB83D-8029-4118-8A84-584B61335E91@comcast.net>


> On Mar 12, 2016, at 11:27 AM, Marine Regis <marine.regis at hotmail.fr> wrote:
> 
> Hello,
> 
> 
> 
> I have two rasters with different resolution and projection.

Generally posting questions about spatial functions will get faster and better responses on the sig-geo mailing list:

https://stat.ethz.ch/mailman/listinfo/R-SIG-Geo/

Otherwise it may take a few days for Roger Bivand to come around and do "clean up" by answering and then using his broom to whisk you over there.

-- 
David.
> 
> 
> 
>> r1
> 
> class       : RasterLayer
> 
> dimensions  : 2510, 5233, 13134830  (nrow, ncol, ncell)
> 
> resolution  : 56, 56  (x, y)
> 
> extent      : 503198, 796246, 4917498, 5058058  (xmin, xmax, ymin, ymax)
> 
> coord. ref. : +proj=utm +zone=18 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0
> 
> data source : in memory
> 
> names       : layer
> 
> values      : 1, 8  (min, max)
> 
> 
> 
>> r2
> 
> class       : RasterBrick
> 
> dimensions  : 3250, 6570, 21352500, 1  (nrow, ncol, ncell, nlayers)
> 
> resolution  : 30, 30  (x, y)
> 
> extent      : 265380.5, 462480.5, 4984457, 5081957  (xmin, xmax, ymin, ymax)
> 
> coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> 
> data source : H:\users\rast_temp.tif
> 
> names       : rast_temp
> 
> 
> 
> My objective is to merge the two rasters into a single raster. As the two rasters have different resolution and projection, I have used the function projectRaster (package raster) like this:
> 
> 
> r <- projectRaster(from=r1, to=r2, method="ngb", alignOnly=TRUE)
> 
> 
> 
> However, I got this warning message:
> 
> 
> 
> Warning message:
> 
> In projectRaster(x, crs = projection(y)) : 'from' has no cell values
> 
> 
> 
> and yet, the two rasters have values:
> 
> 
> 
>> hasValues(r1)
> 
> [1] TRUE
> 
> 
> 
>> hasValues(r2)
> 
> [1] TRUE
> 
> 
> 
> When I remove the argument "alignOnly=TRUE", the code seems to work but I don't want that r1 has the same projected extent than r2 (I want to keep the original extent of r1).
> 
> 
> 
> Why do I get this warning message ?
> 
> 
> 
> Thank you very much for your help.
> 
> Marine
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Sun Mar 13 03:47:59 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 13 Mar 2016 13:47:59 +1100
Subject: [R] specify size of box around legend
In-Reply-To: <m2lh5p6rl7.fsf@krugs.de>
References: <m2lh5p6rl7.fsf@krugs.de>
Message-ID: <001201d17cd2$c24eb710$46ec2530$@bigpond.com>

Hi

If you cannot get anything right in base graphics 
You could plot the graph and then use 
library(grid)
viewport(....)
etc
for each of the legends

or even lattice and grid

xyplot(...,
              legend =  list( ....),
)

see https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html

for one way with grid package,  other ways may be using lattice and
lattice::draw.key

I' m a bit rusty on the actual workings

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rainer M
Krug
Sent: Saturday, 12 March 2016 01:02
To: r-help at r-project.org
Subject: [R] specify size of box around legend

Hi

assume the following code:

--8<---------------cut here---------------start------------->8---
plot(1,1)
legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
legend(x="bottomleft", legend = paste(LETTERS[1:10],
letters[1:12],LETTERS[1:10]), title = "L 2")
legend(x="topright", legend = LETTERS[1:15], title = "L 3")
--8<---------------cut here---------------end--------------->8---

The box around L 1 is less wide than the box around L 2 due to automatic
sizing of the box.

Is there a way of specifying the width of the box, so that L 1 and L 2
have the same width?

In the same sense: can I also specify the height of the legend, so that
L 1 and L 3 have the same height?

Thanks,

Rainer
-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982


From drjimlemon at gmail.com  Sun Mar 13 04:33:54 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 13 Mar 2016 14:33:54 +1100
Subject: [R] specify size of box around legend
In-Reply-To: <m2lh5p6rl7.fsf@krugs.de>
References: <m2lh5p6rl7.fsf@krugs.de>
Message-ID: <CA+8X3fX3OW=coMUs7HWgmE113doK=gcPPnf2N8jwUOmn+BJqXA@mail.gmail.com>

Hi Rainer,
You can use the text.width argument and override the calculated legend
text widths.

Jim


On Sat, Mar 12, 2016 at 1:01 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> assume the following code:
>
> --8<---------------cut here---------------start------------->8---
> plot(1,1)
> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
> --8<---------------cut here---------------end--------------->8---
>
> The box around L 1 is less wide than the box around L 2 due to automatic
> sizing of the box.
>
> Is there a way of specifying the width of the box, so that L 1 and L 2
> have the same width?
>
> In the same sense: can I also specify the height of the legend, so that
> L 1 and L 3 have the same height?
>
> Thanks,
>
> Rainer
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From axeldibert at alice.it  Sat Mar 12 18:39:47 2016
From: axeldibert at alice.it (Axel)
Date: Sat, 12 Mar 2016 18:39:47 +0100 (CET)
Subject: [R] Statistical analysis of olive dataset
Message-ID: <1536be9a46f.axeldibert@alice.it>

Hi to all the members of the list!

I am a novice as regards to statistical 
analysis and the use of the R software, so I am experimenting with the dataset 
"olive" included in the package "tourr".
This dataset contains the results of 
the determination of the fatty acids in 572 samples of olive oil from Italy 
(columns from 3 to 10) along with the area and the region of origin of the oil 
(respectively, column 1 and column 2).

The main goal of my analysis is to 
determine which are the fatty acids that characterize the origin of an oil. As 
a secondary goal, I wolud like to insert the results of the chemical analysis 
of an oil that I analyzed (I am a Chemistry student) in order to determine its 
region of production. I do not know if this last thing is possibile.

I am 
using R 3.2.4 on MacOS X El Capitan with the packages "tourr" and "psych" 
loaded.
Here are the commands I have used up to now:

olivenum <- olive[,c(3:
10)]
mean <- colMeans(olivenum)
sd <- sapply(olivenum,sd)
describeBy(olivenum,
olive[2])
pairs(olivenum)
R <- cor(olivenum)
eigen(R)
# Since the first three 
autovalues are greater than 1, these are the main components (column 1, 2 and 
3). But I can determine them also using a scree diagram as following. Right?

autoval <- eigen(R)$values
autovec <- eigen(R)$vectors
pvarsp <- autoval/ncol
(olivenum)
plot(autoval,type="b",main="Scree diagram",xlab="Number of 
components",ylab="Autovalues")
abline(h=1,lwd=3,col="red")

eigen (R)$vectors[,
1:3]
olive.scale <- scale(olivenum,T,T)
points <- olive.scale%*%autovec[,1:3]


#Since I selected three main components (three columns), how should I plot the 
dispersion graph? I do not think that what I have done is right:
plot(points,
main="Dispersion graph",xlab="Component 1",ylab="Component 2")
princomp
(olivenum,cor=T)
#With the following command I obtain a summary of the 
importance of components. For example, the variance of component 1 is about 
0,465, of component 2 is 0,220 and of component 3 is 0,127 with a cumulative 
variance of 0,812. This means that the values in the first three columns of the 
matrix "olivenum" mostly characterize the differences between the observations. 
Right?
summary(princomp(olivenum,cor=T))
screeplot(princomp(olivenum,cor=T))

plot(princomp(olivenum,cor=T)$scores,rownames(olivenum))
abline(h=0,v=0)

I 
determined that three components can explain a great part of variability but I 
don't know which are these components. How should I continue?

Thank you for

attention,
Axel


From kmnanus at gmail.com  Sat Mar 12 23:11:06 2016
From: kmnanus at gmail.com (KMNanus)
Date: Sat, 12 Mar 2016 17:11:06 -0500
Subject: [R] Everything in ggplot2 is blue
Message-ID: <7E6B88B1-E6AC-4F34-B926-B6C8A95E33E1@gmail.com>

I?m working with a data frame called ?Koufax? (his lifetime pitching stats) in order to improve my ggplot2 skills.

I?ve worked with a variety of iterations of ken <- ggplot(koufax, aes(x = W, y = IPouts, color = SO)) + geom_bar(stat = "identity?)  but all the bars come up blue, even if I call... ken +   scale_fill_gradient(low = "red",high = "yellow?).

Has this happened to anyone?  I?m wondering if there?s a package that I need to load through a library call.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From senapati53 at gmail.com  Sat Mar 12 16:54:22 2016
From: senapati53 at gmail.com (Sudhansu Senapati)
Date: Sat, 12 Mar 2016 21:24:22 +0530
Subject: [R] (no subject)
Message-ID: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>

I am not able to install "caret" package in R. Installation is successful
but when I go to Library it says some namespaces not loaded.
Please guide me.

Sudhansu Sekhar Senapati

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Mar 13 05:49:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 12 Mar 2016 20:49:46 -0800
Subject: [R] Statistical analysis of olive dataset
In-Reply-To: <1536be9a46f.axeldibert@alice.it>
References: <1536be9a46f.axeldibert@alice.it>
Message-ID: <CAGxFJbQ==f5ds1uN3kPXkttfXPNbBvUj8NHsgFMGCmfVUkeKPQ@mail.gmail.com>

Inline.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 12, 2016 at 9:39 AM, Axel <axeldibert at alice.it> wrote:
> Hi to all the members of the list!
>
> I am a novice as regards to statistical
> analysis and the use of the R software, so I am experimenting with the dataset
> "olive" included in the package "tourr".

Stop experimenting and spend time with an R tutorial or two? There are
many good ones on the Web. See also
https://www.rstudio.com/online-learning/#R  for some recommendations.




> This dataset contains the results of
> the determination of the fatty acids in 572 samples of olive oil from Italy
> (columns from 3 to 10) along with the area and the region of origin of the oil
> (respectively, column 1 and column 2).
>
> The main goal of my analysis is to
> determine which are the fatty acids that characterize the origin of an oil. As
> a secondary goal, I wolud like to insert the results of the chemical analysis
> of an oil that I analyzed (I am a Chemistry student) in order to determine its
> region of production. I do not know if this last thing is possibile.
>
> I am
> using R 3.2.4 on MacOS X El Capitan with the packages "tourr" and "psych"
> loaded.
> Here are the commands I have used up to now:
>
> olivenum <- olive[,c(3:
> 10)]
> mean <- colMeans(olivenum)
> sd <- sapply(olivenum,sd)
> describeBy(olivenum,
> olive[2])
> pairs(olivenum)
> R <- cor(olivenum)
> eigen(R)
> # Since the first three
> autovalues are greater than 1, these are the main components (column 1, 2 and
> 3). But I can determine them also using a scree diagram as following. Right?
>
> autoval <- eigen(R)$values
> autovec <- eigen(R)$vectors
> pvarsp <- autoval/ncol
> (olivenum)
> plot(autoval,type="b",main="Scree diagram",xlab="Number of
> components",ylab="Autovalues")
> abline(h=1,lwd=3,col="red")
>
> eigen (R)$vectors[,
> 1:3]
> olive.scale <- scale(olivenum,T,T)
> points <- olive.scale%*%autovec[,1:3]
>
>
> #Since I selected three main components (three columns), how should I plot the
> dispersion graph? I do not think that what I have done is right:
> plot(points,
> main="Dispersion graph",xlab="Component 1",ylab="Component 2")
> princomp
> (olivenum,cor=T)
> #With the following command I obtain a summary of the
> importance of components. For example, the variance of component 1 is about
> 0,465, of component 2 is 0,220 and of component 3 is 0,127 with a cumulative
> variance of 0,812. This means that the values in the first three columns of the
> matrix "olivenum" mostly characterize the differences between the observations.
> Right?
> summary(princomp(olivenum,cor=T))
> screeplot(princomp(olivenum,cor=T))
>
> plot(princomp(olivenum,cor=T)$scores,rownames(olivenum))
> abline(h=0,v=0)
>
> I
> determined that three components can explain a great part of variability but I
> don't know which are these components. How should I continue?
>
> Thank you for
>
> attention,
> Axel
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Mar 13 05:53:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 12 Mar 2016 20:53:34 -0800
Subject: [R] (no subject)
In-Reply-To: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>
References: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>
Message-ID: <CAGxFJbQ-Pu9jWHebZVGdmZNRg4F1=405v9d9XHBsaDMPvo1iHw@mail.gmail.com>

**Exactly** what procedures/commands did you use to install the caret package?
(Reply to the list, not to me).

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 12, 2016 at 7:54 AM, Sudhansu Senapati <senapati53 at gmail.com> wrote:
> I am not able to install "caret" package in R. Installation is successful
> but when I go to Library it says some namespaces not loaded.
> Please guide me.
>
> Sudhansu Sekhar Senapati
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Mar 13 08:22:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 13 Mar 2016 18:22:01 +1100
Subject: [R] Statistical analysis of olive dataset
In-Reply-To: <1536be9a46f.axeldibert@alice.it>
References: <1536be9a46f.axeldibert@alice.it>
Message-ID: <CA+8X3fXL8NiEJsX795oce8bWGJPhQBVjWmAM0=ju1ieALSmsdw@mail.gmail.com>

Hi Axel,
It seems to me that cluster analysis could be what you are seeking.
Identify the clusters of different combinations of fatty acids in the
oils. Do they correspond to location? If so, is there a method to
predict the cluster membership of a new set of measurements? Have a
look at the cluster package, which you should have.

Jim


On Sun, Mar 13, 2016 at 4:39 AM, Axel <axeldibert at alice.it> wrote:
> Hi to all the members of the list!
>
> I am a novice as regards to statistical
> analysis and the use of the R software, so I am experimenting with the dataset
> "olive" included in the package "tourr".
> This dataset contains the results of
> the determination of the fatty acids in 572 samples of olive oil from Italy
> (columns from 3 to 10) along with the area and the region of origin of the oil
> (respectively, column 1 and column 2).
>
> The main goal of my analysis is to
> determine which are the fatty acids that characterize the origin of an oil. As
> a secondary goal, I wolud like to insert the results of the chemical analysis
> of an oil that I analyzed (I am a Chemistry student) in order to determine its
> region of production. I do not know if this last thing is possibile.
>
> I am
> using R 3.2.4 on MacOS X El Capitan with the packages "tourr" and "psych"
> loaded.
> Here are the commands I have used up to now:
>
> olivenum <- olive[,c(3:
> 10)]
> mean <- colMeans(olivenum)
> sd <- sapply(olivenum,sd)
> describeBy(olivenum,
> olive[2])
> pairs(olivenum)
> R <- cor(olivenum)
> eigen(R)
> # Since the first three
> autovalues are greater than 1, these are the main components (column 1, 2 and
> 3). But I can determine them also using a scree diagram as following. Right?
>
> autoval <- eigen(R)$values
> autovec <- eigen(R)$vectors
> pvarsp <- autoval/ncol
> (olivenum)
> plot(autoval,type="b",main="Scree diagram",xlab="Number of
> components",ylab="Autovalues")
> abline(h=1,lwd=3,col="red")
>
> eigen (R)$vectors[,
> 1:3]
> olive.scale <- scale(olivenum,T,T)
> points <- olive.scale%*%autovec[,1:3]
>
>
> #Since I selected three main components (three columns), how should I plot the
> dispersion graph? I do not think that what I have done is right:
> plot(points,
> main="Dispersion graph",xlab="Component 1",ylab="Component 2")
> princomp
> (olivenum,cor=T)
> #With the following command I obtain a summary of the
> importance of components. For example, the variance of component 1 is about
> 0,465, of component 2 is 0,220 and of component 3 is 0,127 with a cumulative
> variance of 0,812. This means that the values in the first three columns of the
> matrix "olivenum" mostly characterize the differences between the observations.
> Right?
> summary(princomp(olivenum,cor=T))
> screeplot(princomp(olivenum,cor=T))
>
> plot(princomp(olivenum,cor=T)$scores,rownames(olivenum))
> abline(h=0,v=0)
>
> I
> determined that three components can explain a great part of variability but I
> don't know which are these components. How should I continue?
>
> Thank you for
>
> attention,
> Axel
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sun Mar 13 10:23:51 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 13 Mar 2016 09:23:51 +0000
Subject: [R] Statistical analysis of olive dataset
In-Reply-To: <1536be9a46f.axeldibert@alice.it>
References: <1536be9a46f.axeldibert@alice.it>
Message-ID: <56E531A7.2070402@dewey.myzen.co.uk>

Dear Axel

Since you are using princomp (among other things) you might find the 
biplot function useful on the output of princomp.


I have not studies your code in detail but you do seem to be doing 
several things in multiple ways using functions from different sources. 
I wonder whether it might be better to stick to fewer functions.

On 12/03/2016 17:39, Axel wrote:
> Hi to all the members of the list!
>
> I am a novice as regards to statistical
> analysis and the use of the R software, so I am experimenting with the dataset
> "olive" included in the package "tourr".
> This dataset contains the results of
> the determination of the fatty acids in 572 samples of olive oil from Italy
> (columns from 3 to 10) along with the area and the region of origin of the oil
> (respectively, column 1 and column 2).
>
> The main goal of my analysis is to
> determine which are the fatty acids that characterize the origin of an oil. As
> a secondary goal, I wolud like to insert the results of the chemical analysis
> of an oil that I analyzed (I am a Chemistry student) in order to determine its
> region of production. I do not know if this last thing is possibile.
>
> I am
> using R 3.2.4 on MacOS X El Capitan with the packages "tourr" and "psych"
> loaded.
> Here are the commands I have used up to now:
>
> olivenum <- olive[,c(3:
> 10)]
> mean <- colMeans(olivenum)
> sd <- sapply(olivenum,sd)
> describeBy(olivenum,
> olive[2])
> pairs(olivenum)
> R <- cor(olivenum)
> eigen(R)
> # Since the first three
> autovalues are greater than 1, these are the main components (column 1, 2 and
> 3). But I can determine them also using a scree diagram as following. Right?
>
> autoval <- eigen(R)$values
> autovec <- eigen(R)$vectors
> pvarsp <- autoval/ncol
> (olivenum)
> plot(autoval,type="b",main="Scree diagram",xlab="Number of
> components",ylab="Autovalues")
> abline(h=1,lwd=3,col="red")
>
> eigen (R)$vectors[,
> 1:3]
> olive.scale <- scale(olivenum,T,T)
> points <- olive.scale%*%autovec[,1:3]
>
>
> #Since I selected three main components (three columns), how should I plot the
> dispersion graph? I do not think that what I have done is right:
> plot(points,
> main="Dispersion graph",xlab="Component 1",ylab="Component 2")
> princomp
> (olivenum,cor=T)
> #With the following command I obtain a summary of the
> importance of components. For example, the variance of component 1 is about
> 0,465, of component 2 is 0,220 and of component 3 is 0,127 with a cumulative
> variance of 0,812. This means that the values in the first three columns of the
> matrix "olivenum" mostly characterize the differences between the observations.
> Right?
> summary(princomp(olivenum,cor=T))
> screeplot(princomp(olivenum,cor=T))
>
> plot(princomp(olivenum,cor=T)$scores,rownames(olivenum))
> abline(h=0,v=0)
>
> I
> determined that three components can explain a great part of variability but I
> don't know which are these components. How should I continue?
>
> Thank you for
>
> attention,
> Axel
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From senapati53 at gmail.com  Sat Mar 12 17:02:23 2016
From: senapati53 at gmail.com (Sudhansu Senapati)
Date: Sat, 12 Mar 2016 21:32:23 +0530
Subject: [R] (no subject)
In-Reply-To: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>
References: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>
Message-ID: <CAHMZzY=GLS0YPY_d7GE8PtcLiTNqKeDuxFGa6WaNyri-h1jHwA@mail.gmail.com>

> library(caret)
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?pbkrtest?
In addition: Warning message:
package ?caret? was built under R version 3.2.4
Error: package or namespace load failed for ?caret?

The above message I am getting in R. Please help.

On Sat, Mar 12, 2016 at 9:24 PM, Sudhansu Senapati <senapati53 at gmail.com>
wrote:

> I am not able to install "caret" package in R. Installation is successful
> but when I go to Library it says some namespaces not loaded.
> Please guide me.
>
> Sudhansu Sekhar Senapati
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Sun Mar 13 14:38:57 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 13 Mar 2016 09:38:57 -0400
Subject: [R] Everything in ggplot2 is blue
In-Reply-To: <7E6B88B1-E6AC-4F34-B926-B6C8A95E33E1@gmail.com>
References: <7E6B88B1-E6AC-4F34-B926-B6C8A95E33E1@gmail.com>
Message-ID: <CA+vqiLE0KCZag8ku3GRi62xWE54H93U0k2S51E64pKcZs_6A3g@mail.gmail.com>

color is the border, fill is the inside color. You nees

aes(x = W, y = IPouts, fill = SO)

Best,
Ista
On Mar 12, 2016 10:43 PM, "KMNanus" <kmnanus at gmail.com> wrote:

> I?m working with a data frame called ?Koufax? (his lifetime pitching
> stats) in order to improve my ggplot2 skills.
>
> I?ve worked with a variety of iterations of ken <- ggplot(koufax, aes(x =
> W, y = IPouts, color = SO)) + geom_bar(stat = "identity?)  but all the bars
> come up blue, even if I call... ken +   scale_fill_gradient(low =
> "red",high = "yellow?).
>
> Has this happened to anyone?  I?m wondering if there?s a package that I
> need to load through a library call.
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Sun Mar 13 16:24:59 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 13 Mar 2016 11:24:59 -0400
Subject: [R] Statistical analysis of olive dataset
In-Reply-To: <1536be9a46f.axeldibert@alice.it>
References: <1536be9a46f.axeldibert@alice.it>
Message-ID: <56E5864B.5080409@yorku.ca>

On 3/12/2016 12:39 PM, Axel wrote:
> The main goal of my analysis is to
> determine which are the fatty acids that characterize the origin of an oil. As
> a secondary goal, I wolud like to insert the results of the chemical analysis
> of an oil that I analyzed (I am a Chemistry student) in order to determine its
> region of production. I do not know if this last thing is possibile.

There are already plenty of tools for this; don't bother trying to 
re-invent an already well-working wheel.

* PCA + a biplot will give you a good overview.  With groups, I 
recommend ggbiplot, with data ellipses for the groups.
This shows clear separation along PC1

data(olive, package="tourr")
library(ggbiplot)
olivenum <- olive[,c(3:10)]

olive.pca <- prcomp(olivenum, scale.=TRUE)
summary(olive.pca)

# region should be a factor (area has 9 levels, maybe too confusing)
olive$region <- factor(olive$region, labels=c("North", "Sardinia", "South"))

ggbiplot(olive.pca, obs.scale = 1, var.scale = 1,
          groups = olive$region, ellipse = TRUE, varname.size=4,
          circle = TRUE) +
          theme_bw() +
          theme(legend.direction = 'horizontal',
                legend.position = 'top')


* Discrimination among regions by chemical composition:
A canonical discriminant analysis will show you this in
a low-rank view.  The biggest difference is between the North
vs. the other 2.


# MLM
olive.mlm <- lm(as.matrix(olive[,c(3:10)]) ~ olive$region, data=olive)

# Canonical discriminant analysis

# (need devel. version for ellipses)
# install.packages("candisc", repos="http://R-Forge.R-project.org")
library(candisc)
olive.can <- candisc(olive.mlm)
olive.can
plot(olive.can, ellipse=TRUE)

* You can probably use the predict() method for MASS::lda() to predict
the class for new samples.

hope this helps,
-Michael


From senapati53 at gmail.com  Sun Mar 13 17:56:20 2016
From: senapati53 at gmail.com (Sudhansu Senapati)
Date: Sun, 13 Mar 2016 22:26:20 +0530
Subject: [R] (no subject)
Message-ID: <CAHMZzY=JjhPtBS12b1BvMKX+dTxRPF96sxq32q6vr5Q14tRZOQ@mail.gmail.com>

I have loaded "caret" package to my R successfully with dependencies=TRUE.
But when I go to library(caret), some namespaces are not loaded.
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?pbkrtest?
In addition: Warning messages:
1: package ?caret? was built under R version 3.2.4 Please
2: package ?lattice? was built under R version 3.2.3
3: package ?ggplot2? was built under R version 3.2.3
Error: package or namespace load failed for ?caret?

please guide me.
Sudhansu

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Mar 13 18:05:36 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 13 Mar 2016 17:05:36 +0000
Subject: [R] (no subject)
In-Reply-To: <CAHMZzY=GLS0YPY_d7GE8PtcLiTNqKeDuxFGa6WaNyri-h1jHwA@mail.gmail.com>
References: <CAHMZzY=Tfw8QJHJKAOCqKZfZ=DGDGDOvPoDF+iXZ9TVuFuFchQ@mail.gmail.com>
	<CAHMZzY=GLS0YPY_d7GE8PtcLiTNqKeDuxFGa6WaNyri-h1jHwA@mail.gmail.com>
Message-ID: <56E59DE0.7090609@dewey.myzen.co.uk>

In line

On 12/03/2016 16:02, Sudhansu Senapati wrote:
>> library(caret)
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>    there is no package called ?pbkrtest?

I do not see how this message could be clearer. It means you do not have 
the package pbkrtest.

> In addition: Warning message:
> package ?caret? was built under R version 3.2.4

That is just a warning which you could ignore or upgrade to the most 
recent version of R and it will go away.

> Error: package or namespace load failed for ?caret?
>
> The above message I am getting in R. Please help.
>
> On Sat, Mar 12, 2016 at 9:24 PM, Sudhansu Senapati <senapati53 at gmail.com>
> wrote:
>
>> I am not able to install "caret" package in R. Installation is successful
>> but when I go to Library it says some namespaces not loaded.
>> Please guide me.
>>
>> Sudhansu Sekhar Senapati
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ronencozen at gmail.com  Sun Mar 13 14:31:31 2016
From: ronencozen at gmail.com (Ronen Cohen)
Date: Sun, 13 Mar 2016 15:31:31 +0200
Subject: [R] Utils - View mode - Filter
Message-ID: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>

Can't paste a value to the filter text box, using paste from by
right-clicking the mouse and selecting paste from the context menu.

How to reproduce:
1. view any data-frame
2. from the results copy any token
3. select filter mode
4. right click the mouse and select paste -- nothing happen, you need to
switch to the keyboard CTRL+V in order to paste.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Mar 13 19:07:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 13 Mar 2016 11:07:02 -0700
Subject: [R] Utils - View mode - Filter
In-Reply-To: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
Message-ID: <88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>

Your step 1 is opaque... which command did you use, and were you using any GUI (R itself is command line based), and what operating system are you using? 

There is a Posting Guide mentioned at the bottom of every message on this list that can help you communicate clearly on the list. 
-- 
Sent from my phone. Please excuse my brevity.

On March 13, 2016 6:31:31 AM PDT, Ronen Cohen <ronencozen at gmail.com> wrote:
>Can't paste a value to the filter text box, using paste from by
>right-clicking the mouse and selecting paste from the context menu.
>
>How to reproduce:
>1. view any data-frame
>2. from the results copy any token
>3. select filter mode
>4. right click the mouse and select paste -- nothing happen, you need
>to
>switch to the keyboard CTRL+V in order to paste.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Mar 13 19:58:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 13 Mar 2016 11:58:51 -0700
Subject: [R] Utils - View mode - Filter
In-Reply-To: <CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
	<88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
	<CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>
Message-ID: <9D550DFD-D959-4FDA-9663-AE78C38454A0@dcn.davis.ca.us>

That function is installed by RStudio... it is not part of R. You should report this bug to RStudio.
-- 
Sent from my phone. Please excuse my brevity.

On March 13, 2016 11:10:22 AM PDT, Ronen Cohen <ronencozen at gmail.com> wrote:
>I am using the View command within R-Studio on Win10.
>
>On Sun, Mar 13, 2016 at 8:07 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Your step 1 is opaque... which command did you use, and were you
>using any
>> GUI (R itself is command line based), and what operating system are
>you
>> using?
>>
>> There is a Posting Guide mentioned at the bottom of every message on
>this
>> list that can help you communicate clearly on the list.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 13, 2016 6:31:31 AM PDT, Ronen Cohen <ronencozen at gmail.com>
>> wrote:
>>>
>>> Can't paste a value to the filter text box, using paste from by
>>> right-clicking the mouse and selecting paste from the context menu.
>>>
>>> How to reproduce:
>>> 1. view any data-frame
>>> 2. from the results copy any token
>>> 3. select filter mode
>>> 4. right click the mouse and select paste -- nothing happen, you
>need to
>>> switch to the keyboard CTRL+V in order to paste.
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Mar 13 20:37:42 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 13 Mar 2016 12:37:42 -0700
Subject: [R] Utils - View mode - Filter
In-Reply-To: <9D550DFD-D959-4FDA-9663-AE78C38454A0@dcn.davis.ca.us>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
	<88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
	<CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>
	<9D550DFD-D959-4FDA-9663-AE78C38454A0@dcn.davis.ca.us>
Message-ID: <FD2227A5-7524-4A59-B03C-8F0EC8908161@comcast.net>


> On Mar 13, 2016, at 11:58 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> That function is installed by RStudio... it is not part of R. You should report this bug to RStudio.

I'm not sure that is the case. From the command line of the Mac GUI R.app, there is a `View` function. It brings up an X11 window that displays a dataframe in a spreadsheet format and allows you to a  highlight a cell. If you choose "Copy" from the Edit menu of that window you will not succeed in getting that value to paste elsewhere. It's not a function I've ever found useful (as is the case with the `edit` function)  and quite frankly I would not be sorry to see that facility abandoned.

RStudio has a window that does display data objects and selection of values and copying to the Clipboard does succeed.

-- 
David.

> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 13, 2016 11:10:22 AM PDT, Ronen Cohen <ronencozen at gmail.com> wrote:
>> I am using the View command within R-Studio on Win10.
>> 
>> On Sun, Mar 13, 2016 at 8:07 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> Your step 1 is opaque... which command did you use, and were you
>> using any
>>> GUI (R itself is command line based), and what operating system are
>> you
>>> using?
>>> 
>>> There is a Posting Guide mentioned at the bottom of every message on
>> this
>>> list that can help you communicate clearly on the list.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On March 13, 2016 6:31:31 AM PDT, Ronen Cohen <ronencozen at gmail.com>
>>> wrote:
>>>> 
>>>> Can't paste a value to the filter text box, using paste from by
>>>> right-clicking the mouse and selecting paste from the context menu.
>>>> 
>>>> How to reproduce:
>>>> 1. view any data-frame
>>>> 2. from the results copy any token
>>>> 3. select filter mode
>>>> 4. right click the mouse and select paste -- nothing happen, you
>> need to
>>>> switch to the keyboard CTRL+V in order to paste.
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ------------------------------
>>>> 
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Mon Mar 14 00:10:56 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 13 Mar 2016 16:10:56 -0700
Subject: [R] Utils - View mode - Filter
In-Reply-To: <FD2227A5-7524-4A59-B03C-8F0EC8908161@comcast.net>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
	<88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
	<CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>
	<9D550DFD-D959-4FDA-9663-AE78C38454A0@dcn.davis.ca.us>
	<FD2227A5-7524-4A59-B03C-8F0EC8908161@comcast.net>
Message-ID: <C266C65A-E152-4108-968B-B8D9EE2D45B6@dcn.davis.ca.us>

That is a different implementation of the View function than the one that is active inside RStudio.
-- 
Sent from my phone. Please excuse my brevity.

On March 13, 2016 12:37:42 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Mar 13, 2016, at 11:58 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> That function is installed by RStudio... it is not part of R. You
>should report this bug to RStudio.
>
>I'm not sure that is the case. From the command line of the Mac GUI
>R.app, there is a `View` function. It brings up an X11 window that
>displays a dataframe in a spreadsheet format and allows you to a 
>highlight a cell. If you choose "Copy" from the Edit menu of that
>window you will not succeed in getting that value to paste elsewhere.
>It's not a function I've ever found useful (as is the case with the
>`edit` function)  and quite frankly I would not be sorry to see that
>facility abandoned.
>
>RStudio has a window that does display data objects and selection of
>values and copying to the Clipboard does succeed.
>
>-- 
>David.
>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On March 13, 2016 11:10:22 AM PDT, Ronen Cohen <ronencozen at gmail.com>
>wrote:
>>> I am using the View command within R-Studio on Win10.
>>> 
>>> On Sun, Mar 13, 2016 at 8:07 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>> 
>>>> Your step 1 is opaque... which command did you use, and were you
>>> using any
>>>> GUI (R itself is command line based), and what operating system are
>>> you
>>>> using?
>>>> 
>>>> There is a Posting Guide mentioned at the bottom of every message
>on
>>> this
>>>> list that can help you communicate clearly on the list.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On March 13, 2016 6:31:31 AM PDT, Ronen Cohen
><ronencozen at gmail.com>
>>>> wrote:
>>>>> 
>>>>> Can't paste a value to the filter text box, using paste from by
>>>>> right-clicking the mouse and selecting paste from the context
>menu.
>>>>> 
>>>>> How to reproduce:
>>>>> 1. view any data-frame
>>>>> 2. from the results copy any token
>>>>> 3. select filter mode
>>>>> 4. right click the mouse and select paste -- nothing happen, you
>>> need to
>>>>> switch to the keyboard CTRL+V in order to paste.
>>>>> 
>>>>> [[alternative HTML version deleted]]
>>>>> 
>>>>> ------------------------------
>>>>> 
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar 14 00:26:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 Mar 2016 19:26:32 -0400
Subject: [R] Utils - View mode - Filter
In-Reply-To: <C266C65A-E152-4108-968B-B8D9EE2D45B6@dcn.davis.ca.us>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
	<88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
	<CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>
	<9D550DFD-D959-4FDA-9663-AE78C38454A0@dcn.davis.ca.us>
	<FD2227A5-7524-4A59-B03C-8F0EC8908161@comcast.net>
	<C266C65A-E152-4108-968B-B8D9EE2D45B6@dcn.davis.ca.us>
Message-ID: <56E5F728.5050004@gmail.com>

On 13/03/2016 7:10 PM, Jeff Newmiller wrote:
> That is a different implementation of the View function than the one that is active inside RStudio.
>
There's a lot of confusion here.

View() in RStudio appears to run an RStudio-specific function, and in 
the version I'm running, cut and paste seems to work fine.  If the OP is 
up to date in RStudio and has a problem with that, they should follow 
your advice, and complain to RStudio.

On the other hand, edit() in RStudio runs the hideous X11 version.  X11 
has such a messed up idea of cut and paste I don't know why anyone would 
expect it to work with another system, such as the host MacOS.

I wouldn't be surprised if View() used to run something like edit().  So 
the OP and David should update their RStudio.

Duncan Murdoch


From ronencozen at gmail.com  Sun Mar 13 19:10:22 2016
From: ronencozen at gmail.com (Ronen Cohen)
Date: Sun, 13 Mar 2016 20:10:22 +0200
Subject: [R] Utils - View mode - Filter
In-Reply-To: <88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
References: <CABMg0FNh==nDsC-qMDOVnvEyeq8MZrH4XVpV5Su2tm3eQ8FFVA@mail.gmail.com>
	<88FAB108-A3AA-42C8-96AF-347C0809CD09@dcn.davis.ca.us>
Message-ID: <CABMg0FOHU+KN5rADQg7oFbqMYQrNw1oWsos_x-iYZyjNq0UZ_A@mail.gmail.com>

I am using the View command within R-Studio on Win10.

On Sun, Mar 13, 2016 at 8:07 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your step 1 is opaque... which command did you use, and were you using any
> GUI (R itself is command line based), and what operating system are you
> using?
>
> There is a Posting Guide mentioned at the bottom of every message on this
> list that can help you communicate clearly on the list.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 13, 2016 6:31:31 AM PDT, Ronen Cohen <ronencozen at gmail.com>
> wrote:
>>
>> Can't paste a value to the filter text box, using paste from by
>> right-clicking the mouse and selecting paste from the context menu.
>>
>> How to reproduce:
>> 1. view any data-frame
>> 2. from the results copy any token
>> 3. select filter mode
>> 4. right click the mouse and select paste -- nothing happen, you need to
>> switch to the keyboard CTRL+V in order to paste.
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From ajay.andrews at gmail.com  Sun Mar 13 23:42:09 2016
From: ajay.andrews at gmail.com (Ajay Andrews)
Date: Sun, 13 Mar 2016 15:42:09 -0700
Subject: [R] Best Regression Technique to Use
Message-ID: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>

I have a set of independent variables that are all BINARY, and my dependent
variable is also BINARY. Should I use the logistic regression for this -
using the glm function?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 14 04:16:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 13 Mar 2016 20:16:22 -0700
Subject: [R] Best Regression Technique to Use
In-Reply-To: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
References: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
Message-ID: <CAGxFJbTcq7h25hjyjHYL0tsjN6qqzc0jQEyNT7zbm7-JWsXY5Q@mail.gmail.com>

This query is not really appropriate for this list, which is about R
programming, not statistical advice (although there is certainly some
overlap). You should post to a statistical list like
stats.stackexchange.com. Better yet, since you seem to be out of your
depth statistically, why not find a local statistical expert with whom
to consult?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 13, 2016 at 3:42 PM, Ajay Andrews <ajay.andrews at gmail.com> wrote:
> I have a set of independent variables that are all BINARY, and my dependent
> variable is also BINARY. Should I use the logistic regression for this -
> using the glm function?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sunnysingha.analytics at gmail.com  Mon Mar 14 08:16:26 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 14 Mar 2016 12:46:26 +0530
Subject: [R] Please help -- Cbind data frames within LIST() in R
Message-ID: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>

Hi,
Please help and guide. I want to cbind dataframes within the list object:
List object 'post_data' contains below sampled data frames:

post_data
$posts
      from_id user_name post_msg

$comm
       comm_id from_id message

$Likes
       username like_id


*Note: The columns in each data frame are of unequal length. hence, missing
values will be filled with 'NA' after combining*
Regards,
Sunny

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Mar 14 08:49:03 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 14 Mar 2016 07:49:03 +0000
Subject: [R] Please help -- Cbind data frames within LIST() in R
In-Reply-To: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>
References: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014173@SRVEXCHMBX.precheza.cz>

Hi

There are several options e.g.

http://stackoverflow.com/questions/6988184/combining-two-data-frames-of-different-lengths
http://stackoverflow.com/questions/7196450/create-a-data-frame-of-unequal-lengths

but maybe you want to do actually merging

see

?merge

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sunny
> Singha
> Sent: Monday, March 14, 2016 8:16 AM
> To: r-help
> Subject: [R] Please help -- Cbind data frames within LIST() in R
>
> Hi,
> Please help and guide. I want to cbind dataframes within the list
> object:
> List object 'post_data' contains below sampled data frames:
>
> post_data
> $posts
>       from_id user_name post_msg
>
> $comm
>        comm_id from_id message
>
> $Likes
>        username like_id
>
>
> *Note: The columns in each data frame are of unequal length. hence,
> missing values will be filled with 'NA' after combining* Regards, Sunny
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lists at dewey.myzen.co.uk  Mon Mar 14 10:13:40 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 14 Mar 2016 09:13:40 +0000
Subject: [R] Best Regression Technique to Use
Message-ID: <Zen-1afOZI-0007C7-3N@smarthost01c.mail.zen.net.uk>

Ajay Andrews <ajay.andrews at gmail.com> wrote :

You certainly _can_, whether you _should_ depends on the scientific question. I think you may need to consult someone familiar with your field of study for advice.

> I have a set of independent variables that are all BINARY, and my dependent
> variable is also BINARY. Should I use the logistic regression for this -
> using the glm function?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sunnysingha.analytics at gmail.com  Mon Mar 14 10:37:29 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 14 Mar 2016 15:07:29 +0530
Subject: [R] Please help -- Cbind data frames within LIST() in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014173@SRVEXCHMBX.precheza.cz>
References: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014173@SRVEXCHMBX.precheza.cz>
Message-ID: <CANOG_FUiN0ikA--DGfmwLppch3GrhZE+C_n4JHYiCSmHhv_jYA@mail.gmail.com>

Thanks Petr,
I'm going through the link that you have provided. Merge won't be useful in
my case. Let me give the complete picture of what I'm trying to achieve.

I'm extracting data from fb pages. I have the data frame 'pages_df' which
has all the details of the fb pages. 'Page_id' is the important column in
it to get all the posts from that page.

I have created below function to which page_id is passed and data frame is
created separately for 'posts.csv', 'comments.csv', 'likescsv'.
Ideally this is not what I want as the final output. I want to modify this
function so that it outputs single flat file where columns of
each posts, comments and likes are cbinded.

# Function to scrap facebook pages' posts, comments and likes
page_data_extract <- function(pg_id){
  cat('Extracting list of posts from page', pg_id, '\n')
  page <- getPage(pg_id, token=fb_oauth, since='2016/03/01') # This
function extracts posts metadata from page_id argument specified.

  # Loop to information of the post.
  for(i in 1:nrow(page)){
    path_dat <- <custom_path>
    cat('\nScrapping post \n',page$id[i])

    posts <- getPost(page$id[i], n=100, token =fb_oauth)
    time <- format(Sys.time(), '%b_%d_%Y')
    for(j in 1:length(posts)){
      myfile <- file.path(path_data, paste0(names(posts[j]), time, '_', i,
'.csv'))
      write.csv(posts[[j]], file=myfile, row.names = F)
    }
  }
}

Here I call the above function:
 # Call page_data_extract() function for each pages found to gather posts,
comments & Likes
for(i in 1:nrow(pages_df)){
    e_catch <- try(page_data_extract(pages_df$id[i]))
    if(isTRUE(all.equal(class(e_catch), 'try-error'))){
      cat('No public posts were found for ==
',pages_df$name[i],'(',pages_df$id[i],')\n\n')
    }
}

Regards,
Sunny

On Mon, Mar 14, 2016 at 1:19 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> There are several options e.g.
>
>
> http://stackoverflow.com/questions/6988184/combining-two-data-frames-of-different-lengths
>
> http://stackoverflow.com/questions/7196450/create-a-data-frame-of-unequal-lengths
>
> but maybe you want to do actually merging
>
> see
>
> ?merge
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sunny
> > Singha
> > Sent: Monday, March 14, 2016 8:16 AM
> > To: r-help
> > Subject: [R] Please help -- Cbind data frames within LIST() in R
> >
> > Hi,
> > Please help and guide. I want to cbind dataframes within the list
> > object:
> > List object 'post_data' contains below sampled data frames:
> >
> > post_data
> > $posts
> >       from_id user_name post_msg
> >
> > $comm
> >        comm_id from_id message
> >
> > $Likes
> >        username like_id
> >
> >
> > *Note: The columns in each data frame are of unequal length. hence,
> > missing values will be filled with 'NA' after combining* Regards, Sunny
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Mar 14 10:53:48 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 14 Mar 2016 09:53:48 +0000
Subject: [R] Please help -- Cbind data frames within LIST() in R
In-Reply-To: <CANOG_FUiN0ikA--DGfmwLppch3GrhZE+C_n4JHYiCSmHhv_jYA@mail.gmail.com>
References: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014173@SRVEXCHMBX.precheza.cz>
	<CANOG_FUiN0ikA--DGfmwLppch3GrhZE+C_n4JHYiCSmHhv_jYA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50141F2@SRVEXCHMBX.precheza.cz>

Hi

From: Sunny Singha [mailto:sunnysingha.analytics at gmail.com]
Sent: Monday, March 14, 2016 10:37 AM
To: r-help; PIKAL Petr
Subject: Re: [R] Please help -- Cbind data frames within LIST() in R

Thanks Petr,
I'm going through the link that you have provided. Merge won't be useful in my case. Let me give the complete picture of what I'm trying to achieve.

Why do you think so? If you have several data frames of unequal length with some common column I am almost sure that you want to align all values according to this common column.

I'm extracting data from fb pages. I have the data frame 'pages_df' which has all the details of the fb pages. 'Page_id' is the important column in it to get all the posts from that page.
I have created below function to which page_id is passed and data frame is created separately for 'posts.csv', 'comments.csv', 'likescsv'.
Ideally this is not what I want as the final output. I want to modify this function so that it outputs single flat file where columns of
each posts, comments and likes are cbinded.

# Function to scrap facebook pages' posts, comments and likes
page_data_extract <- function(pg_id){
  cat('Extracting list of posts from page', pg_id, '\n')
  page <- getPage(pg_id, token=fb_oauth, since='2016/03/01') # This function extracts posts metadata from page_id argument specified.
  # Loop to information of the post.
  for(i in 1:nrow(page)){
    path_dat <- <custom_path>
    cat('\nScrapping post \n',page$id[i])

    posts <- getPost(page$id[i], n=100, token =fb_oauth)
    time <- format(Sys.time(), '%b_%d_%Y')
    for(j in 1:length(posts)){
      myfile <- file.path(path_data, paste0(names(posts[j]), time, '_', i, '.csv'))
      write.csv(posts[[j]], file=myfile, row.names = F)
    }
  }
}

I get this error with your code
+     path_dat <- <custom_path>
Error: unexpected '<' in:
"  for(i in 1:nrow(page)){
    path_dat <- <"
>     cat('\nScrapping post \n',page$id[i])
Error in page$id : object of type 'closure' is not subsettable
>
So please follow Posting guide for this help list if you really want some usefull answers:
No HTML, only plain text mails.
Reproducible code
Some toy data e.g. by posting result of
dput(head(pages_df, 20))
Cheers
Petr

Here I call the above function:
 # Call page_data_extract() function for each pages found to gather posts, comments & Likes
for(i in 1:nrow(pages_df)){
    e_catch <- try(page_data_extract(pages_df$id[i]))
    if(isTRUE(all.equal(class(e_catch), 'try-error'))){
      cat('No public posts were found for == ',pages_df$name[i],'(',pages_df$id[i],')\n\n')
    }
}
Regards,
Sunny

On Mon, Mar 14, 2016 at 1:19 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

There are several options e.g.

http://stackoverflow.com/questions/6988184/combining-two-data-frames-of-different-lengths
http://stackoverflow.com/questions/7196450/create-a-data-frame-of-unequal-lengths

but maybe you want to do actually merging

see

?merge

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Sunny
> Singha
> Sent: Monday, March 14, 2016 8:16 AM
> To: r-help
> Subject: [R] Please help -- Cbind data frames within LIST() in R
>
> Hi,
> Please help and guide. I want to cbind dataframes within the list
> object:
> List object 'post_data' contains below sampled data frames:
>
> post_data
> $posts
>       from_id user_name post_msg
>
> $comm
>        comm_id from_id message
>
> $Likes
>        username like_id
>
>
> *Note: The columns in each data frame are of unequal length. hence,
> missing values will be filled with 'NA' after combining* Regards, Sunny
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From jordanmeyer1991 at gmail.com  Mon Mar 14 02:58:00 2016
From: jordanmeyer1991 at gmail.com (Jordan Meyer)
Date: Sun, 13 Mar 2016 21:58:00 -0400
Subject: [R] Best Regression Technique to Use
In-Reply-To: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
References: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
Message-ID: <CAF+g6roBmKt7m9utkCUn1RNqyX7Q80scBWTNONd1NtpU+ubczg@mail.gmail.com>

That would be my recommendation. You can use glm() with the argument family
= binomial().

- Jordan

On Sun, Mar 13, 2016 at 6:42 PM, Ajay Andrews <ajay.andrews at gmail.com>
wrote:

> I have a set of independent variables that are all BINARY, and my dependent
> variable is also BINARY. Should I use the logistic regression for this -
> using the glm function?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v.p at gmx.at  Mon Mar 14 09:43:29 2016
From: v.p at gmx.at (Valentin Pesendorfer)
Date: Mon, 14 Mar 2016 09:43:29 +0100
Subject: [R] RSNNS neural network for image classification in R
Message-ID: <EE3D4DC0-C134-4C03-AF60-66791B64B836@gmx.at>

Hello everybody, 

I'm trying to harness the power of neural networks for image classification of big rasters using the `RSNNS` package in `R`.
 
As for the data preparation and training of the model, everything works perfectly fine and the accuracies look quite promising.
 
Subsequently, I'm trying to classify the raster values using the function `predict` with the trained model. Having a quite big amount of data (rasterstack with the dimension 10980x10980x16), I'm processing the data block by block. And here's the problem:
 
The prediction of the class values is extremely slow. I'm working on a quite powerful machine (Windows x64, 32GB Ram, i7 3.4GHZ quad-core) but still the process is almost literally taking ages. I already reduced the size of my blocks, but still the amount of time needed is unacceptable. Currently I split the data in blocks of 64 rows per block. That would result in a total of 172 blocks. If I assume a linear processing time for each block (in my case 33 minutes !!!), it would take me almost 95 hours to process the whole image. Again, that can not be right. 
 
I've tried other neural network packages and for instance `nnet` classifies bigger blocks like these in under one minute.
 
So please, if you have any pointers on what I'm doing wrong, I'd greatly appreciate it.


Best regards,

Valentin



 
Here's a working example similar to my code:
 
    library(RSNNS)
    
    #example data for training and testing
    dat <- matrix(runif(702720),ncol = 16)
    
    #example data to classify
    rasval <- matrix(runif(11243520),ncol = 16)
    
    dat <- as.data.frame(dat)
    
    #example class labels from 1 to 11
    classes <- matrix(,ncol=1,nrow=nrow(dat))
    classes <- apply(classes,1,function(x) floor(runif(1,0,11)))
    
    dat$classes <- classes
    
    #shuffle dataset
    dat <- dat[sample(nrow(dat)),]
    
    
    datValues <- dat[,1:16]
    datTargets <- decodeClassLabels(dat[,17])
    
    #split dataset
    dat <- splitForTrainingAndTest(datValues, datTargets, ratio=0.15)
    
    #normalize data
    dat <- normTrainingAndTestSet(dat)
    
    #extract normalization variables
    ncolmeans <- attributes(dat$inputsTrain)$normParams$colMeans
    ncolsds <- attributes(dat$inputsTrain)$normParams$colSds
    
    #train model
    model <- mlp(dat$inputsTrain, dat$targetsTrain, size=1, learnFunc="SCG", learnFuncParams=c(0, 0, 0, 0),
                 maxit=400, inputsTest=dat$inputsTest, targetsTest=dat$targetsTest)
    
    #normalize raster data
    rasval <- sweep(sweep(rasval,2,ncolmeans),2,ncolsds,'/')
    
    #Predict classes ##Problem##
    pred <- predict(model,rasval)
 

From damjanfaks2015 at gmail.com  Mon Mar 14 09:43:45 2016
From: damjanfaks2015 at gmail.com (Damjan /)
Date: Mon, 14 Mar 2016 09:43:45 +0100
Subject: [R] please help
Message-ID: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>

Dear all,

with the below 2 files I would like to to the t.test and var.test

but it does not work.

Can you help me ?

thanks

BR
-------------- next part --------------
leto	st_ur
1972	1608.3
1973	1825.6
1974	1646.8
1975	1718.8
1976	1837.5
1977	1905.9
1978	1694.6
1979	1928.3
1980	1632.6
1981	2064.4
1982	1794.7
1983	2079.1
1984	1741.7
1986	1943.9
1987	1867.8
1988	1994
1989	1883.2
1990	2070.8
1991	1908.7
1992	2072
1993	1934.2
1994	1999
1995	1900
1996	1842.8
1997	2156.8
1998	2075.2
1999	1975.5
2000	2337.8
2001	2123.3
2002	2056.9
2003	2294.1
2004	 
2005	1926.6
2006	1927.9
2007	2091.8
2008	2050.8
2009	1944.9
2010	1692.6
2011	2088.1
-------------- next part --------------
leto	st_ur
1961	1804.8
1962	1621.5
1963	1648.8
1964	1660.4
1965	1646
1966	1647.1
1967	1748.7
1968	1721.1
1969	1679.3
1970	1674.5
1971	1845.5
1972	1444.9
1973	1775.3
1974	1631.9
1975	1641.2
1976	1707.7
1977	1561.9
1978	1596.4
1979	1693.7
1980	1576.4
1981	1863.3
1982	1706.4
1983	1957.4
1984	1569
1985	1859.6
1986	1758.3
1987	1792.4
1988	1766.9
1989	1777.6
1990	1986.9
1991	1902
1992	1952.8
1993	1890.9
1994	1965.9
1995	1791.6
1996	1665.9
1997	2062.7
1998	2054.2
1999	1874.6
2000	2243.8
2001	1992.7
2002	1923.8
2003	2251.3
2004	1779.4
2005	1895.9
2006	1886.1
2007	2009.7

From friendly at yorku.ca  Mon Mar 14 13:46:51 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 14 Mar 2016 08:46:51 -0400
Subject: [R] Best Regression Technique to Use
In-Reply-To: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
References: <CACxXXuYxAawieee7xNJTHugymmo+p7Km2tTZp=5GZ=DsZK-8OQ@mail.gmail.com>
Message-ID: <56E6B2BB.6090401@yorku.ca>

On 3/13/2016 6:42 PM, Ajay Andrews wrote:
> I have a set of independent variables that are all BINARY, and my dependent
> variable is also BINARY. Should I use the logistic regression for this -
> using the glm function?
>
> 	[[alternative HTML version deleted]]
>

glm(..., family=binomial) will give you what you want. When the 
independent variables are all categorical, this is sometimes
called a logit model.  Alternatively, you could also fit
a loglinear model, but the logit form is probably simpler.


From S.Ellison at LGCGroup.com  Mon Mar 14 14:00:33 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 14 Mar 2016 13:00:33 +0000
Subject: [R] please help
In-Reply-To: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>
References: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D114658F@GBTEDVPEXCMB04.corp.lgc-group.com>

> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Damjan /
> Subject: [R] please help
> 
> Dear all,
> 
> with the below 2 files I would like to to the t.test and var.test
> 
> but it does not work.
> 
> Can you help me ?
> 

Dear Damjan 
The posting guide at http://www.R-project.org/posting-guide.html is the usual recommended reading; for specific assistance you will need to at least provide the code used to run the tests and give details of the error messages you encountered.

In the mean time, both the tests you refer to apply to tests between two and only two groups. Your files seem to have more than two years, which - at least until my telepathic inference improves - seems likely to cause a problem for t.test and var.test. Perhaps you were looking for pairwise.t.test?

S Ellison





*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From javanmard.majid at gmail.com  Mon Mar 14 14:43:04 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Mon, 14 Mar 2016 17:13:04 +0330
Subject: [R]  Confidence Interval for Ipred Bagging outputs (please help)
Message-ID: <CAA0OCntZpFO+-A9yhLv8AFtWtvRkVR+2PgkUT=Zw6YTkZ1N7jg@mail.gmail.com>

Hello everyone

here is the code that implements bagging using ipred package :

library(ipred)
library(mlbench)
data("BostonHousing")
# Test set error (nbagg=25, trees pruned): 3.41 (Breiman, 1996a, Table 8)
mod <- bagging(medv ~ ., data=BostonHousing, coob=TRUE)
print(mod)
pred <- predict(mod)
pred<- as.data.frame(pred)

How can I have 95% Confidence interval for each predicted values !?

I appreciate if someone help me

Thanks

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Mar 14 15:14:12 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 14 Mar 2016 14:14:12 +0000
Subject: [R] specify size of box around legend
In-Reply-To: <CA+8X3fX3OW=coMUs7HWgmE113doK=gcPPnf2N8jwUOmn+BJqXA@mail.gmail.com>
References: <m2lh5p6rl7.fsf@krugs.de>
	<CA+8X3fX3OW=coMUs7HWgmE113doK=gcPPnf2N8jwUOmn+BJqXA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D719D4F@mb02.ads.tamu.edu>

Also you can specify the upper left/lower right coordinates of the legend box:

# Get the default positions/sizes
plot(1, 1)
a <- legend(x="topleft", legend = x, title = "L 1")
b <- legend(x="bottomleft", legend = y, title = "L 2")

# Use those to change the box size
plot(1, 1)
legend(x=c(a$rect$left, a$rect$left+b$rect$w), y=c(a$rect$top, 
     a$rect$top-a$rect$h), legend = x, title = "L 1")
legend(x="bottomleft", legend = y, title = "L 2")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Saturday, March 12, 2016 9:34 PM
To: Rainer M Krug; r-help mailing list
Subject: Re: [R] specify size of box around legend

Hi Rainer,
You can use the text.width argument and override the calculated legend
text widths.

Jim


On Sat, Mar 12, 2016 at 1:01 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> assume the following code:
>
> --8<---------------cut here---------------start------------->8---
> plot(1,1)
> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
> --8<---------------cut here---------------end--------------->8---
>
> The box around L 1 is less wide than the box around L 2 due to automatic
> sizing of the box.
>
> Is there a way of specifying the width of the box, so that L 1 and L 2
> have the same width?
>
> In the same sense: can I also specify the height of the legend, so that
> L 1 and L 3 have the same height?
>
> Thanks,
>
> Rainer
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar 14 15:23:21 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 14 Mar 2016 14:23:21 +0000
Subject: [R] specify size of box around legend
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D719D4F@mb02.ads.tamu.edu>
References: <m2lh5p6rl7.fsf@krugs.de>
	<CA+8X3fX3OW=coMUs7HWgmE113doK=gcPPnf2N8jwUOmn+BJqXA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D719D4F@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D71BD93@mb02.ads.tamu.edu>

Forgot that I had changed the original example code:

You need this first to get the example to work:
x <- LETTERS[1:10]
y <- paste(LETTERS[1:10], letters[1:12],LETTERS[1:10])

-------
David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Monday, March 14, 2016 9:14 AM
To: Jim Lemon; Rainer M Krug; r-help mailing list
Subject: Re: [R] specify size of box around legend

Also you can specify the upper left/lower right coordinates of the legend box:

# Get the default positions/sizes
plot(1, 1)
a <- legend(x="topleft", legend = x, title = "L 1")
b <- legend(x="bottomleft", legend = y, title = "L 2")

# Use those to change the box size
plot(1, 1)
legend(x=c(a$rect$left, a$rect$left+b$rect$w), y=c(a$rect$top, 
     a$rect$top-a$rect$h), legend = x, title = "L 1")
legend(x="bottomleft", legend = y, title = "L 2")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Saturday, March 12, 2016 9:34 PM
To: Rainer M Krug; r-help mailing list
Subject: Re: [R] specify size of box around legend

Hi Rainer,
You can use the text.width argument and override the calculated legend
text widths.

Jim


On Sat, Mar 12, 2016 at 1:01 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> assume the following code:
>
> --8<---------------cut here---------------start------------->8---
> plot(1,1)
> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
> --8<---------------cut here---------------end--------------->8---
>
> The box around L 1 is less wide than the box around L 2 due to automatic
> sizing of the box.
>
> Is there a way of specifying the width of the box, so that L 1 and L 2
> have the same width?
>
> In the same sense: can I also specify the height of the legend, so that
> L 1 and L 3 have the same height?
>
> Thanks,
>
> Rainer
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Mon Mar 14 15:25:14 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 14 Mar 2016 15:25:14 +0100
Subject: [R] specify size of box around legend
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D719D4F@mb02.ads.tamu.edu>
	(David L. Carlson's message of "Mon, 14 Mar 2016 14:14:12 +0000")
References: <m2lh5p6rl7.fsf@krugs.de>
	<CA+8X3fX3OW=coMUs7HWgmE113doK=gcPPnf2N8jwUOmn+BJqXA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D719D4F@mb02.ads.tamu.edu>
Message-ID: <m237rt5e7p.fsf@krugs.de>

David L Carlson <dcarlson at tamu.edu> writes:

> Also you can specify the upper left/lower right coordinates of the legend box:
>
> # Get the default positions/sizes
> plot(1, 1)
> a <- legend(x="topleft", legend = x, title = "L 1")
> b <- legend(x="bottomleft", legend = y, title = "L 2")
>
> # Use those to change the box size
> plot(1, 1)
> legend(x=c(a$rect$left, a$rect$left+b$rect$w), y=c(a$rect$top, 
>      a$rect$top-a$rect$h), legend = x, title = "L 1")
> legend(x="bottomleft", legend = y, title = "L 2")

Interesting - I like it.

Thanks,

Rainer

>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Saturday, March 12, 2016 9:34 PM
> To: Rainer M Krug; r-help mailing list
> Subject: Re: [R] specify size of box around legend
>
> Hi Rainer,
> You can use the text.width argument and override the calculated legend
> text widths.
>
> Jim
>
>
> On Sat, Mar 12, 2016 at 1:01 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Hi
>>
>> assume the following code:
>>
>> --8<---------------cut here---------------start------------->8---
>> plot(1,1)
>> legend(x="topleft", legend = LETTERS[1:10], title = "L 1")
>> legend(x="bottomleft", legend = paste(LETTERS[1:10], letters[1:12],LETTERS[1:10]), title = "L 2")
>> legend(x="topright", legend = LETTERS[1:15], title = "L 3")
>> --8<---------------cut here---------------end--------------->8---
>>
>> The box around L 1 is less wide than the box around L 2 due to automatic
>> sizing of the box.
>>
>> Is there a way of specifying the width of the box, so that L 1 and L 2
>> have the same width?
>>
>> In the same sense: can I also specify the height of the legend, so that
>> L 1 and L 3 have the same height?
>>
>> Thanks,
>>
>> Rainer
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160314/3a4621e0/attachment.bin>

From david.jessop at ubs.com  Mon Mar 14 15:22:14 2016
From: david.jessop at ubs.com (david.jessop at ubs.com)
Date: Mon, 14 Mar 2016 14:22:14 +0000
Subject: [R] Problems with rstan
Message-ID: <8C841E9FC08E374BA235324BBFEA323B0FCC5C@NLDNC501PN3.UBSPROD.MSAD.UBS.NET>

Hi

I'm having a really odd problem with rstan (and in fact shiny), which is I can't actually load the package:

> ls (all=TRUE)
character(0)
> library (rstan)
Loading required package: ggplot2
Error : .onAttach failed in attachNamespace() for 'rstan', details:
  call: pkgdesc$Packaged
  error: $ operator is invalid for atomic vectors
In addition: Warning messages:
1: package 'rstan' was built under R version 3.2.4
2: In packageDescription("rstan", lib.loc = rstanLib) :
  no package 'rstan' was found
Error: package or namespace load failed for 'rstan'

And for shiny

> library (shiny)
Error : .onAttach failed in attachNamespace() for 'shiny', details:
  call: utils::packageVersion("htmlwidgets")
  error: package 'htmlwidgets' not found
Error: package or namespace load failed for 'shiny'

But I have htmlwidgets in our package folder.    So if I then load htmlwidgets and reload shiny everything is happy.   The packages are installed on a shared drive.

My session is

> sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_2.0.0

loaded via a namespace (and not attached):
[1] Rcpp_0.12.3      digest_0.6.9     mime_0.4         grid_3.2.3       plyr_1.8.3       R6_2.1.1         xtable_1.8-0     gtable_0.2.0
 [9] stats4_3.2.3     scales_0.3.0     tools_3.2.3      munsell_0.4.2    shiny_0.13.0     httpuv_1.3.3     rstan_2.9.0-3    inline_0.3.14
[17] colorspace_1.2-6 htmltools_0.3    gridExtra_2.2.1

Any help gratefully received.

Regards

David
-------------- next part --------------

Visit our website at http://www.ubs.com 

This message contains confidential information and is intended only 
for the individual named. If you are not the named addressee you 
should not disseminate, distribute or copy this e-mail. Please 
notify the sender immediately by e-mail if you have received this 
e-mail by mistake and delete this e-mail from your system. 

E-mails are not encrypted and cannot be guaranteed to be secure or 
error-free as information could be intercepted, corrupted, lost, 
destroyed, arrive late or incomplete, or contain viruses. The sender 
therefore does not accept liability for any errors or omissions in the 
contents of this message which arise as a result of e-mail transmission. 
If verification is required please request a hard-copy version. This 
message is provided for informational purposes and should not be 
construed as a solicitation or offer to buy or sell any securities 
or related financial instruments. 

UBS Limited is a company limited by shares incorporated in the United 
Kingdom registered in England and Wales with number 2035362.  
Registered Office: 1 Finsbury Avenue, London EC2M 2PP
UBS Limited is authorised by the Prudential Regulation Authority 
and regulated by the Financial Conduct Authority and the Prudential 
Regulation Authority.

UBS AG is a public company incorporated with limited liability in
Switzerland domiciled in the Canton of Basel-City and the Canton of
Zurich respectively registered at the Commercial Registry offices in
those Cantons with new Identification No: CHE-101.329.561 as from 18
December 2013 (and prior to 18 December 2013 with Identification
No: CH-270.3.004.646-4) and having respective head offices at
Aeschenvorstadt 1, 4051 Basel and Bahnhofstrasse 45, 8001 Zurich,
Switzerland and is authorised and regulated by the Financial Market
Supervisory Authority in Switzerland.  Registered in the United
Kingdom as a foreign company with No: FC021146 and having a UK
Establishment registered at Companies House, Cardiff, with
No: BR 004507.  The principal office of UK Establishment: 1 Finsbury
Avenue, London EC2M 2PP.  In the United Kingdom, UBS AG is authorised
by the Prudential Regulation Authority and subject to regulation
by the Financial Conduct Authority and limited regulation by the
Prudential Regulation Authority.  Details about the extent of our
regulation by the Prudential Regulation Authority are available
from us on request.

UBS reserves the right to retain all messages. Messages are protected 
and accessed only in legally justified cases. 

From bgunter.4567 at gmail.com  Mon Mar 14 15:45:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 14 Mar 2016 07:45:28 -0700
Subject: [R] please help
In-Reply-To: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>
References: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>
Message-ID: <CAGxFJbTtXKS9VfeuHC6RNtu-+untdiY0OSYcf7HsGeJQz6L8hw@mail.gmail.com>

... also, **if** this is homework, this list has a no homework policy.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 14, 2016 at 1:43 AM, Damjan / <damjanfaks2015 at gmail.com> wrote:
> Dear all,
>
> with the below 2 files I would like to to the t.test and var.test
>
> but it does not work.
>
> Can you help me ?
>
> thanks
>
> BR
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Mon Mar 14 16:06:36 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 14 Mar 2016 07:06:36 -0800
Subject: [R] please help
In-Reply-To: <CADsz97M5Os-+pGt=WYm1Pkxhm+jefEMrR8L61EXUg6fJRc1fkQ@mail.gmail.com>
Message-ID: <BD72E965703.000003C5jrkrideau@inbox.com>



John Kane
Kingston ON Canada


> -----Original Message-----
> From: damjanfaks2015 at gmail.com
> Sent: Mon, 14 Mar 2016 09:43:45 +0100
> To: r-help at r-project.org
> Subject: [R] please help
> 
> Dear all,
> 
> with the below 2 files I would like to to the t.test and var.test
> 
> but it does not work.
> 
> Can you help me ?
> 

Probably but we need to know more about what you are doing. You have told us nothing so far.  

At a guess, you want to do a t-test on the st_ur variable that you have in the two files. Is that correct? Something like this probably will work.

dat1  <-  read.csv("~/Rjunk/sonce_ljubljana.txt", sep = "\t", header = TRUE, stringsAsFactors=FALSE)
dat2  <-  read.csv("~/Rjunk/sonce_murska.txt", sep = "\t", header = TRUE, stringsAsFactors=FALSE)

dat3  <-  merge(dat1, dat2, by = "leto")
names(dat3)  <-  c("leto", "ljubljana", "murska")

with(dat3, t.test(ljubljana, murska))

However you really need to supply much more information on what you are doing.  Please read http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for information on how to ask questions here.


Thank you for providing the data.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From santiago.l.paz at gmail.com  Mon Mar 14 15:35:50 2016
From: santiago.l.paz at gmail.com (Santiago Paz)
Date: Mon, 14 Mar 2016 10:35:50 -0400
Subject: [R] Building a reactive plot with ggplot2 and shiny.
Message-ID: <CAGgCQXBAhT+p0LLrjEbT_jw=SNMdhcah8fkRyK4skMr_d7iWMw@mail.gmail.com>

I'm fairly new with R and shiny and I am trying to make an application
where users can select various variables from a data set and plot the
ratios of the variables in one graph.

Basically: - The user selects the number of ratios they want - The
user then selects which variable will be the numerator and which will
be the denominator. - The a plot should then appear with curves for
each ratio.

My main problem right now is that the plot isn't displayed until all
the numerators and denominators have been selected. I want it to look
such that when you finish specifying one ratio it plots it, then when
you specify another ratio it adds it to the graph. Basically I want
the plot to be reactive so that it updates as you select the ratios.
Here's a basic idea of the code

SERVER


    output$sopPlot <- renderPlot({

    data <- read.csv("data")

    # Introduce function that binds columns, useful when generating
the data frame that includes all ratios
      cbind.all <- function (...)
      {
        nm <- list(...)
        nm <- lapply(nm, as.matrix)
        n <- max(sapply(nm, nrow))
        do.call(cbind, lapply(nm, function(x) rbind(x, matrix(, n -

nrow(x), ncol(x)))))
      }

    # Some variables that are useful in the loop that creates the data
frame of the ratios

      ratio <- as.character(input$nRatios)
      rationum <- as.integer(substr(ratio,2,2))
      Ninput <- c(input$Num1, input$Num2)
      Dinput <- c(input$Den1, input$Den2)

      subData <- data.frame()

    # Loop that will analyze each ratio and create a data frame for
the number of ratios selected

      for (i in 1:rationum){

      numData <- subset(data, Ninput[i])
      numData <- aggregate(Q~Y, data = numData, FUN=sum)

      denData <- subset(data, Dinput[i])
      denData <- aggregate(Q~Y, data = denData, FUN=sum)

      # Combining numerator and denominator data
      subD <-  merge(numData, denData, by.x="Y", by.y="Y")

      # Dividing variables to generate ratio data
      rat<- as.vector(subD$Q.x/subD$Q.y)

      # Insert this data for the ratio into empty dataframe using cbind.all
      subData <- cbind.all(subData, rat)

      # naming each column
      num <- as.character(i)
      colnames(subData)[i] <- paste("Ratio",num, sep=" ")

      subData<- as.data.frame(subData)
    }

    #Reshape data
    subData.long <- melt(subData, id.vars = "Y")

    # Plot

      g <- ggplot(subData.long,aes(Y,value,color=variable))+geom_line()+geom_point()
      g + scale_y_continuous("Ratio") + scale_x_continuous("Year")

    })





UI



      sidebarPanel(
    conditionalPanelselectInput("nRatios", "How Many Ratios:",
                                       choices = c('0'='n0','1'='n1','2'='n2'))

    br()
    ),

    conditionalPanel(condition = "input.analysisType == 'ratio' &
(input.nRatios == 'n1' | input.nRatios == 'n2' | input.nRatios == 'n3'
| input.nRatios == 'n4' | input.nRatios == 'n5')",
                           p(strong("Ratio 1")),
                           selectizeInput("Num1",
                                          "Numerator 1:",
                                          choices = categories,
                                          multiple = TRUE),
                           selectizeInput("Den1",
                                          "Denominator 1:",
                                          choices = categories,
                                          multiple = TRUE),
                           br()

          ),

    # 2
          conditionalPanel(condition = "input.analysisType == 'ratio'
& (input.nRatios == 'n2' | input.nRatios == 'n3' | input.nRatios ==
'n4' | input.nRatios == 'n5')",
                           p(strong("Ratio 2")),
                           selectizeInput("Num2",
                                          "Numerator 2:",
                                          choices = categories,
                                          multiple = TRUE),
                           selectizeInput("Den2",
                                          "Denominator 2:",
                                          choices = categories,
                                          multiple = TRUE),
                           br()

          ),

    mainPanel(
        plotOutput("sopPlot"),
        textOutput("debug")
      )
    ))



I apologize if this is too much text.

I think the biggest problem is that the ratios are subsetted and
stored in subData in the for loop. And the plot is made once subData
is acquired.

Anyway, any help is appreciated. Thanks in advance.


From jrkrideau at inbox.com  Mon Mar 14 16:22:47 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 14 Mar 2016 07:22:47 -0800
Subject: [R] please help
In-Reply-To: <CAGxFJbTtXKS9VfeuHC6RNtu-+untdiY0OSYcf7HsGeJQz6L8hw@mail.gmail.com>
References: <cadsz97m5os-+pgt=wym1pkxhm+jefemrr8l61exug6fjrc1fkq@mail.gmail.com>
Message-ID: <BD971C042D4.00000400jrkrideau@inbox.com>

In line

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bgunter.4567 at gmail.com
> Sent: Mon, 14 Mar 2016 07:45:28 -0700
> To: damjanfaks2015 at gmail.com
> Subject: Re: [R] please help
> 
> ... also, **if** this is homework, this list has a no homework policy.

Very true but it does not read like a homework question.

The two fjles make it look like a newbie question from a poster whose first language is not English.  Or, perhaps more accurately, a question that is not R homework.

What is our policy on homework where the OP is just trying to use R to to solve a problem, say in geography or economics rather than using one of those curst spreadsheet?  

My personal inclination would be to encourage the use of R.

> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Mar 14, 2016 at 1:43 AM, Damjan / <damjanfaks2015 at gmail.com>
> wrote:
>> Dear all,
>> 
>> with the below 2 files I would like to to the t.test and var.test
>> 
>> but it does not work.
>> 
>> Can you help me ?
>> 
>> thanks
>> 
>> BR
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From bgunter.4567 at gmail.com  Mon Mar 14 16:42:56 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 14 Mar 2016 08:42:56 -0700
Subject: [R] Building a reactive plot with ggplot2 and shiny.
In-Reply-To: <CAGgCQXBAhT+p0LLrjEbT_jw=SNMdhcah8fkRyK4skMr_d7iWMw@mail.gmail.com>
References: <CAGgCQXBAhT+p0LLrjEbT_jw=SNMdhcah8fkRyK4skMr_d7iWMw@mail.gmail.com>
Message-ID: <CAGxFJbQ1UngqAPtcbJgT67ord34cs8_1AwtvV-MQ=LaMnZU3fQ@mail.gmail.com>

1. I don't use Shiny, so I may be wrong about this, but--

2. Shiny is an R-Studio product. I believe they have a user support
forum on their website, and you might therefore get a faster and
better answer by posting there (e.g. at Rstudio.com ).


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 14, 2016 at 7:35 AM, Santiago Paz <santiago.l.paz at gmail.com> wrote:
> I'm fairly new with R and shiny and I am trying to make an application
> where users can select various variables from a data set and plot the
> ratios of the variables in one graph.
>
> Basically: - The user selects the number of ratios they want - The
> user then selects which variable will be the numerator and which will
> be the denominator. - The a plot should then appear with curves for
> each ratio.
>
> My main problem right now is that the plot isn't displayed until all
> the numerators and denominators have been selected. I want it to look
> such that when you finish specifying one ratio it plots it, then when
> you specify another ratio it adds it to the graph. Basically I want
> the plot to be reactive so that it updates as you select the ratios.
> Here's a basic idea of the code
>
> SERVER
>
>
>     output$sopPlot <- renderPlot({
>
>     data <- read.csv("data")
>
>     # Introduce function that binds columns, useful when generating
> the data frame that includes all ratios
>       cbind.all <- function (...)
>       {
>         nm <- list(...)
>         nm <- lapply(nm, as.matrix)
>         n <- max(sapply(nm, nrow))
>         do.call(cbind, lapply(nm, function(x) rbind(x, matrix(, n -
>
> nrow(x), ncol(x)))))
>       }
>
>     # Some variables that are useful in the loop that creates the data
> frame of the ratios
>
>       ratio <- as.character(input$nRatios)
>       rationum <- as.integer(substr(ratio,2,2))
>       Ninput <- c(input$Num1, input$Num2)
>       Dinput <- c(input$Den1, input$Den2)
>
>       subData <- data.frame()
>
>     # Loop that will analyze each ratio and create a data frame for
> the number of ratios selected
>
>       for (i in 1:rationum){
>
>       numData <- subset(data, Ninput[i])
>       numData <- aggregate(Q~Y, data = numData, FUN=sum)
>
>       denData <- subset(data, Dinput[i])
>       denData <- aggregate(Q~Y, data = denData, FUN=sum)
>
>       # Combining numerator and denominator data
>       subD <-  merge(numData, denData, by.x="Y", by.y="Y")
>
>       # Dividing variables to generate ratio data
>       rat<- as.vector(subD$Q.x/subD$Q.y)
>
>       # Insert this data for the ratio into empty dataframe using cbind.all
>       subData <- cbind.all(subData, rat)
>
>       # naming each column
>       num <- as.character(i)
>       colnames(subData)[i] <- paste("Ratio",num, sep=" ")
>
>       subData<- as.data.frame(subData)
>     }
>
>     #Reshape data
>     subData.long <- melt(subData, id.vars = "Y")
>
>     # Plot
>
>       g <- ggplot(subData.long,aes(Y,value,color=variable))+geom_line()+geom_point()
>       g + scale_y_continuous("Ratio") + scale_x_continuous("Year")
>
>     })
>
>
>
>
>
> UI
>
>
>
>       sidebarPanel(
>     conditionalPanelselectInput("nRatios", "How Many Ratios:",
>                                        choices = c('0'='n0','1'='n1','2'='n2'))
>
>     br()
>     ),
>
>     conditionalPanel(condition = "input.analysisType == 'ratio' &
> (input.nRatios == 'n1' | input.nRatios == 'n2' | input.nRatios == 'n3'
> | input.nRatios == 'n4' | input.nRatios == 'n5')",
>                            p(strong("Ratio 1")),
>                            selectizeInput("Num1",
>                                           "Numerator 1:",
>                                           choices = categories,
>                                           multiple = TRUE),
>                            selectizeInput("Den1",
>                                           "Denominator 1:",
>                                           choices = categories,
>                                           multiple = TRUE),
>                            br()
>
>           ),
>
>     # 2
>           conditionalPanel(condition = "input.analysisType == 'ratio'
> & (input.nRatios == 'n2' | input.nRatios == 'n3' | input.nRatios ==
> 'n4' | input.nRatios == 'n5')",
>                            p(strong("Ratio 2")),
>                            selectizeInput("Num2",
>                                           "Numerator 2:",
>                                           choices = categories,
>                                           multiple = TRUE),
>                            selectizeInput("Den2",
>                                           "Denominator 2:",
>                                           choices = categories,
>                                           multiple = TRUE),
>                            br()
>
>           ),
>
>     mainPanel(
>         plotOutput("sopPlot"),
>         textOutput("debug")
>       )
>     ))
>
>
>
> I apologize if this is too much text.
>
> I think the biggest problem is that the ratios are subsetted and
> stored in subData in the for loop. And the plot is made once subData
> is acquired.
>
> Anyway, any help is appreciated. Thanks in advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Mon Mar 14 18:41:35 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 14 Mar 2016 12:41:35 -0500
Subject: [R] Find the first occurrence in a list
Message-ID: <C7D9A41B-686C-4312-B646-759303F626F7@me.com>

All,

I am looking to find the first principal payment date on structured MBS cash flow.  I am testing the below to make into a function the correct index is returned.  I am a little unsure. Is this the correct way to think about this problem or is there something already in R that can help?

Glenn

 data <- as.list(c(rep(0, 20), rep(1, 340)))

  f <- function(x){x != 0}

  which(sapply(data, f ) == TRUE)[1]
  
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 14 19:09:41 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 14 Mar 2016 11:09:41 -0700
Subject: [R] Find the first occurrence in a list
In-Reply-To: <C7D9A41B-686C-4312-B646-759303F626F7@me.com>
References: <C7D9A41B-686C-4312-B646-759303F626F7@me.com>
Message-ID: <CAGxFJbTF4_MePJO0-H9Zqqej4=01C9TtA9NFDjxUT55H1TuBiQ@mail.gmail.com>

No.

1.Avoid using the name "data" -- it's already a commonly used function in R.

2. Why do you want it to be a list instead of a vector? Is there a
good reason for this?

Consider:

> d<- c(rep(0, 20), rep(1, 340))
> which(d>0)[1]
[1] 21

3. If you haven't already done so, spend some time with an R tutorial
or two. They typically cover things like this. There are many good
ones on the Web.


Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 14, 2016 at 10:41 AM, Glenn Schultz <glennmschultz at me.com> wrote:
> All,
>
> I am looking to find the first principal payment date on structured MBS cash flow.  I am testing the below to make into a function the correct index is returned.  I am a little unsure. Is this the correct way to think about this problem or is there something already in R that can help?
>
> Glenn
>
>  data <- as.list(c(rep(0, 20), rep(1, 340)))
>
>   f <- function(x){x != 0}
>
>   which(sapply(data, f ) == TRUE)[1]
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sch298 at g.uky.edu  Mon Mar 14 16:49:04 2016
From: sch298 at g.uky.edu (Chattopadhyay, Somsubhra)
Date: Mon, 14 Mar 2016 11:49:04 -0400
Subject: [R] Trend significant at p=0.05?
Message-ID: <CAEZ46xJ_DUvs+n8s1wd0pA5jziCemvbPb2xmWmwzxkjsTx7voQ@mail.gmail.com>

Hi,

I am trying to calculate trends in my climatic time series, using the "Zyp"
package. Initially, I tried with my daily data (I have daily rainfall data
of 30 years) but then both the Zhang method and Yue-Pilon method yielded
unrealistic results. The trend estimates were zero and so were the
confidence limit bounds. But I guess, that is because the noise in the
daily data. So, I converted my time series to annual data and now I see the
attached output. I see that there is a positive trend, but my question is
is this trend significant at 95% confidence interval? I suspect no because
the confidence interval contains zero? Can anyone please confirm?

I also attached the autocorrelation plot of the original time series.

Thanks,
Som

-- 
*Somsubhra Chattopadhyay*
Graduate Research Assistant
Biosystems and Agricultural Engineering Department
University of Kentucky, Lexington, KY 40546
Email: schattop14 at uky.edu
Cell: 9198026951
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ACF.png
Type: image/png
Size: 3898 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160314/33e7a780/attachment.png>

From u.block.mz at gmail.com  Sat Mar 12 17:11:16 2016
From: u.block.mz at gmail.com (Uwe Block)
Date: Sat, 12 Mar 2016 17:11:16 +0100
Subject: [R] [R-pkgs] New package lazysql: Lazy SQL Programming
Message-ID: <CANwJfJR2KoYh1MHz4-J8EPS+9PQ7xRXjubPmnPMbygLLAGO8hw@mail.gmail.com>

Dear R users,

The new package lazysql has been accepted on CRAN
(https://cran.r-project.org/web/packages/lazysql/).

It includes helper functions to build SQL statements under program
control for use with dbGetQuery or dbSendQuery. They are intended to
increase speed of coding and to reduce coding errors. Arguments are
carefully checked, in particular SQL identifiers such as names of
tables or columns.

Currently implemented are:

- date_between: Create SQL string to select date between two given dates.
- in_condition: Create SQL string to select values included (or not
included) in a set of given values.
- natural_key: Create SQL string for joining on matching natural keys.

More patterns will be added as required.

Examples of usage  can be found at
https://github.com/UweBlock/lazysql/blob/master/README.md.

Bug reports, suggestions, and feature requests are highly appreciated
at https://github.com/UweBlock/lazysql/issues.

Have fun,
Uwe

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ragia11 at hotmail.com  Mon Mar 14 22:32:38 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Mon, 14 Mar 2016 23:32:38 +0200
Subject: [R] How to speed up R program
Message-ID: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>





Dear group
I have two R sessions ?running on Ubuntu 14.0x server , and I found that my program will take too long time to be finished( months...!), I used top command and found that ??cpu usage is 21.3%.?

the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6 core

how can I speed the program, kindly I need tutorial or book chapter that helps..
thanks in advance
Ragia

 		 	   		  

From drjimlemon at gmail.com  Mon Mar 14 22:45:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 15 Mar 2016 08:45:56 +1100
Subject: [R] How to speed up R program
In-Reply-To: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
Message-ID: <CA+8X3fXcJSTrhcUyyKXyPoZRRr8OY3PPPy45_nbmuZPz50z1=g@mail.gmail.com>

Hi Ragia,
Improving the efficiency of a program usually requires detailed
analysis of what it is doing and how those operations can be performed
more rapidly. That is to say, without knowing what the program is
supposed to accomplish and how it is doing it now, very little help
can be provided. One thing you might look for is "disk-thrashing"
where your storage media (e.g. hard disk) is being accessed
continuously. This usually indicates that the program is swapping out
data to the disk, which is typically slow compared to processing it in
memory.

Jim


On Tue, Mar 15, 2016 at 8:32 AM, Ragia . <ragia11 at hotmail.com> wrote:
>
>
>
>
> Dear group
> I have two R sessions  running on Ubuntu 14.0x server , and I found that my program will take too long time to be finished( months...!), I used top command and found that   cpu usage is 21.3%.
>
> the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6 core
>
> how can I speed the program, kindly I need tutorial or book chapter that helps..
> thanks in advance
> Ragia
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Mon Mar 14 22:55:48 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Mon, 14 Mar 2016 23:55:48 +0200
Subject: [R] How to speed up R program
In-Reply-To: <CA+8X3fXcJSTrhcUyyKXyPoZRRr8OY3PPPy45_nbmuZPz50z1=g@mail.gmail.com>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>,
	<CA+8X3fXcJSTrhcUyyKXyPoZRRr8OY3PPPy45_nbmuZPz50z1=g@mail.gmail.com>
Message-ID: <DUB125-W582E523710FFDA9E9B967BB3880@phx.gbl>

thanks for answering
the program is simulation it runs on data ( wish is taken from file to memory once) ?but it runs about 10k times and in each mad some calculations ?

hope this clear the problem,?



Ragia?


----------------------------------------
> Date: Tue, 15 Mar 2016 08:45:56 +1100
> Subject: Re: [R] How to speed up R program
> From: drjimlemon at gmail.com
> To: ragia11 at hotmail.com
> CC: r-help at r-project.org
>
> Hi Ragia,
> Improving the efficiency of a program usually requires detailed
> analysis of what it is doing and how those operations can be performed
> more rapidly. That is to say, without knowing what the program is
> supposed to accomplish and how it is doing it now, very little help
> can be provided. One thing you might look for is "disk-thrashing"
> where your storage media (e.g. hard disk) is being accessed
> continuously. This usually indicates that the program is swapping out
> data to the disk, which is typically slow compared to processing it in
> memory.
>
> Jim
>
>
> On Tue, Mar 15, 2016 at 8:32 AM, Ragia . <ragia11 at hotmail.com> wrote:
>>
>>
>>
>>
>> Dear group
>> I have two R sessions running on Ubuntu 14.0x server , and I found that my program will take too long time to be finished( months...!), I used top command and found that cpu usage is 21.3%.
>>
>> the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6 core
>>
>> how can I speed the program, kindly I need tutorial or book chapter that helps..
>> thanks in advance
>> Ragia
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  

From amos.elberg at gmail.com  Mon Mar 14 23:15:06 2016
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Mon, 14 Mar 2016 18:15:06 -0400
Subject: [R] How to speed up R program
In-Reply-To: <DUB125-W582E523710FFDA9E9B967BB3880@phx.gbl>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
	<CA+8X3fXcJSTrhcUyyKXyPoZRRr8OY3PPPy45_nbmuZPz50z1=g@mail.gmail.com>
	<DUB125-W582E523710FFDA9E9B967BB3880@phx.gbl>
Message-ID: <5C04292A-8705-4A17-A8E7-B339F1806B51@gmail.com>

There's no way for anyone to be sure without looking directly at the code. As Jim said, the prime suspect is inefficient use of memory and excessive use of virtual memory.

The book "Advanced R" by Hadley Wickham has a very detailed and easy to understand section on how to benchmark and optimize R code. That is probably your best starting point. That, and watching what happens to memory consumption and vm use while your program is running.

> On Mar 14, 2016, at 5:55 PM, Ragia . <ragia11 at hotmail.com> wrote:
> 
> thanks for answering
> the program is simulation it runs on data ( wish is taken from file to memory once)  but it runs about 10k times and in each mad some calculations ?
> 
> hope this clear the problem, 
> 
> 
> 
> Ragia 
> 
> 
> ----------------------------------------
>> Date: Tue, 15 Mar 2016 08:45:56 +1100
>> Subject: Re: [R] How to speed up R program
>> From: drjimlemon at gmail.com
>> To: ragia11 at hotmail.com
>> CC: r-help at r-project.org
>> 
>> Hi Ragia,
>> Improving the efficiency of a program usually requires detailed
>> analysis of what it is doing and how those operations can be performed
>> more rapidly. That is to say, without knowing what the program is
>> supposed to accomplish and how it is doing it now, very little help
>> can be provided. One thing you might look for is "disk-thrashing"
>> where your storage media (e.g. hard disk) is being accessed
>> continuously. This usually indicates that the program is swapping out
>> data to the disk, which is typically slow compared to processing it in
>> memory.
>> 
>> Jim
>> 
>> 
>>> On Tue, Mar 15, 2016 at 8:32 AM, Ragia . <ragia11 at hotmail.com> wrote:
>>> 
>>> 
>>> 
>>> 
>>> Dear group
>>> I have two R sessions running on Ubuntu 14.0x server , and I found that my program will take too long time to be finished( months...!), I used top command and found that cpu usage is 21.3%.
>>> 
>>> the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6 core
>>> 
>>> how can I speed the program, kindly I need tutorial or book chapter that helps..
>>> thanks in advance
>>> Ragia
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>                         
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Mar 14 23:15:43 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 14 Mar 2016 18:15:43 -0400
Subject: [R] How to speed up R program
In-Reply-To: <DUB125-W582E523710FFDA9E9B967BB3880@phx.gbl>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
	<CA+8X3fXcJSTrhcUyyKXyPoZRRr8OY3PPPy45_nbmuZPz50z1=g@mail.gmail.com>
	<DUB125-W582E523710FFDA9E9B967BB3880@phx.gbl>
Message-ID: <CAM_vjumQca-znWta0ip1z17VRZbwTEGC+OmKVa4cA07uDSEXpQ@mail.gmail.com>

Nobody can help you without a lot more information, though there are
some obvious places to start, like pre-allocating objects rather than
growing them inside a loop.

You can get a good discussion of how to profile your code here:
http://adv-r.had.co.nz/Profiling.html

Sarah

On Mon, Mar 14, 2016 at 5:55 PM, Ragia . <ragia11 at hotmail.com> wrote:
> thanks for answering
> the program is simulation it runs on data ( wish is taken from file to memory once)  but it runs about 10k times and in each mad some calculations ?
>
> hope this clear the problem,
>
>
>
> Ragia
>
>
> ----------------------------------------
>> Date: Tue, 15 Mar 2016 08:45:56 +1100
>> Subject: Re: [R] How to speed up R program
>> From: drjimlemon at gmail.com
>> To: ragia11 at hotmail.com
>> CC: r-help at r-project.org
>>
>> Hi Ragia,
>> Improving the efficiency of a program usually requires detailed
>> analysis of what it is doing and how those operations can be performed
>> more rapidly. That is to say, without knowing what the program is
>> supposed to accomplish and how it is doing it now, very little help
>> can be provided. One thing you might look for is "disk-thrashing"
>> where your storage media (e.g. hard disk) is being accessed
>> continuously. This usually indicates that the program is swapping out
>> data to the disk, which is typically slow compared to processing it in
>> memory.
>>
>> Jim
>>
>>
>> On Tue, Mar 15, 2016 at 8:32 AM, Ragia . <ragia11 at hotmail.com> wrote:
>>>
>>>
>>>
>>>
>>> Dear group
>>> I have two R sessions running on Ubuntu 14.0x server , and I found that my program will take too long time to be finished( months...!), I used top command and found that cpu usage is 21.3%.
>>>
>>> the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6 core
>>>
>>> how can I speed the program, kindly I need tutorial or book chapter that helps..
>>> thanks in advance
>>> Ragia
>>>
>>>


From mashranga at yahoo.com  Mon Mar 14 23:39:48 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Mon, 14 Mar 2016 22:39:48 +0000 (UTC)
Subject: [R] R problem : Error: protect(): protection stack overflow
References: <425839205.1593807.1457995188922.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <425839205.1593807.1457995188922.JavaMail.yahoo@mail.yahoo.com>

Hi, 
i got an error while i am running a big data. Error has explained by the following sample sample 



## Load data 
mdata <- as.matrix(read.table('https://gubox.box.com/shared/static/qh4spcxe2ba5ymzjs0ynh8n8s08af7m0.txt', header = TRUE, check.names = FALSE, sep = '\t')) 

## Install and load library 
source("https://bioconductor.org/biocLite.R") 
biocLite("impute") 
library(impute) 
 
## sets a limit on the number of nested expressions 
options(expressions = 500000)
## Apply k-nearest neighbors for missing value imputation 

res <-impute.knn(mdata) 

Error: protect(): protection stack overflow


If anybody has solution or suggestion, please share. 
Thanks . 

 
 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com


From bgunter.4567 at gmail.com  Tue Mar 15 00:49:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 14 Mar 2016 16:49:17 -0700
Subject: [R] Trend significant at p=0.05?
In-Reply-To: <CAEZ46xJ_DUvs+n8s1wd0pA5jziCemvbPb2xmWmwzxkjsTx7voQ@mail.gmail.com>
References: <CAEZ46xJ_DUvs+n8s1wd0pA5jziCemvbPb2xmWmwzxkjsTx7voQ@mail.gmail.com>
Message-ID: <CAGxFJbT=5Fsm-R+6BFtMZ1QCLX1O17PM+M7S+qt_rcg0b+Sp2Q@mail.gmail.com>

This is not the place for a statistical discussion; it *is* the place
for R programming help.

However, you seem to be confused about confidence intervals and
significance, i.e. P values. You and others may wish to read about why
the "magic" P = .05 significance level is a **bad idea**, contributing
to bad science and irreproducible results, here:

http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503?WT.mc_id=SFB_NNEWS_1508_RHBox

(The original ASA statement is linked, and other relevant references
are provided).

So in other words, you and all others who believe that P values have
scientific value may wish to reconsider that belief.

Best,

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 14, 2016 at 8:49 AM, Chattopadhyay, Somsubhra
<sch298 at g.uky.edu> wrote:
> Hi,
>
> I am trying to calculate trends in my climatic time series, using the "Zyp"
> package. Initially, I tried with my daily data (I have daily rainfall data
> of 30 years) but then both the Zhang method and Yue-Pilon method yielded
> unrealistic results. The trend estimates were zero and so were the
> confidence limit bounds. But I guess, that is because the noise in the
> daily data. So, I converted my time series to annual data and now I see the
> attached output. I see that there is a positive trend, but my question is
> is this trend significant at 95% confidence interval? I suspect no because
> the confidence interval contains zero? Can anyone please confirm?
>
> I also attached the autocorrelation plot of the original time series.
>
> Thanks,
> Som
>
> --
> *Somsubhra Chattopadhyay*
> Graduate Research Assistant
> Biosystems and Agricultural Engineering Department
> University of Kentucky, Lexington, KY 40546
> Email: schattop14 at uky.edu
> Cell: 9198026951
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jean-externe.maurice at edf.fr  Tue Mar 15 08:55:09 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 15 Mar 2016 07:55:09 +0000
Subject: [R] How to speed up R program
In-Reply-To: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
Message-ID: <e6e143c19cc749f58e7e7a3f0e4bbbc8@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Ragia,

If time is really a big problem and you have a lot of datas and you want to use all the cores of the processor, you should use FORTRAN for your calculations. But this is only possible with a real FORTRAN developer and will take some times.

I am an old freelance (61) and I began computing in 1974 with FORTRAN ! I have been hired by a large company in France to translate calculations to FORTRAN. First try : we went from 20 minutes to less than 5 seconds. So it's worth. BUT it is complicated. R is a very permissive and 'near the human' language (I work with hydrological engineers and they can build large R programs) at the opposite, FORTRAN can only do calculations but it does them very very quickly and you must be aware of the hardware on witch you are working and you must take care of integer / real, real4 and real8, .... It's REALLY a computer language.

'modern' FORTRAN are able to use all the cores of the processor and then to have 100% cpu usage. It's INTEL OMP, MPI library, ... but it is another big step.

So it's another way but a difficult one.

Jean in France

PS I spoke of Fortran, but good results can be done with C : C calculations are a little slower than FORTRAN but C possibilities are a lot more 'great' than FORTRAN.
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From petr.pikal at precheza.cz  Tue Mar 15 09:40:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 15 Mar 2016 08:40:29 +0000
Subject: [R] Please help -- Cbind data frames within LIST() in R
In-Reply-To: <CANOG_FXPHqwHpkS_X=WBYrDzKfFvX=Koyy+BPW6hgRMOnB_oEw@mail.gmail.com>
References: <CANOG_FWipeD_JaD2BD5mMtKyRsEcCKkJF4JH=fCoMrwYwJR=_g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014173@SRVEXCHMBX.precheza.cz>
	<CANOG_FUiN0ikA--DGfmwLppch3GrhZE+C_n4JHYiCSmHhv_jYA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50141F2@SRVEXCHMBX.precheza.cz>
	<CANOG_FXPHqwHpkS_X=WBYrDzKfFvX=Koyy+BPW6hgRMOnB_oEw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50143CF@SRVEXCHMBX.precheza.cz>

Hi

Keep your reply on rhelp list (I cc'd it).

Your code is not reproducible:
**only you has such directory
path_data <- 'C:/Users/pc/Documents/Projects/fb'

**where is function searchPages
Searching 10 Pages for  LinkedIn
Error: could not find function "searchPages"

So this is my last effort.

One of my suggestions was rbind.fill from package plyr, which may be not what you wanted. But in te same reply there was also function cbindPad.

Having list lll
dput(lll)
list(structure(list(mikro = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L), .Label = "D", class = "factor"), hod = structure(1:9, .Label = c("12:30:00",
"12:31:00", "12:33:00", "12:34:00", "12:36:00", "12:38:00", "12:39:00",
"12:40:00", "12:45:00"), class = "factor"), cas = c(0L, 1L, 3L,
4L, 6L, 8L, 9L, 10L, 11L)), .Names = c("mikro", "hod", "cas"), class = "data.frame", row.names = c(NA,
-9L)), structure(list(?asm = structure(c(2L, 11L, 9L, 8L, 6L,
4L), .Label = c("1:00", "11:00", "13:00", "15:00", "17:00", "19:00",
"21:00", "23:00", "3:00", "5:00", "7:00", "9:00"), class = "factor"),
    Kontrolor = structure(c(6L, 6L, 6L, 6L, 6L, 6L), .Label = c("CLLAB",
    "KO?UTKOV?", "KOUTN? PETRA", "KOV??OV?", "KRUTILOV?", "LABRTG",
    "NAVR?TILOV?"), class = "factor"), X.R.v?p = c(0.5, 0.8,
    0.2, 0.5, 0.5, 0.2)), .Names = c("?asm", "Kontrolor", "X.R.v?p"
), class = "data.frame", row.names = c(NA, 6L)))

and using function cbindPad

cbindPad <- function(...){
args <- list(...)
n <- sapply(args,nrow)
mx <- max(n)
pad <- function(x, mx){
    if (nrow(x) < mx){
        nms <- colnames(x)
        padTemp <- matrix(NA, mx - nrow(x), ncol(x))
        colnames(padTemp) <- nms
        if (ncol(x)==0) {
          return(padTemp)
        } else {
        return(rbind(x,padTemp))
          }
    }
    else{
        return(x)
    }
}
rs <- lapply(args,pad,mx)
return(do.call(cbind,rs))
}

I get this.

> dput(cbindPad(lll[[1]], lll[[2]]))
structure(list(mikro = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = "D", class = "factor"), hod = structure(1:9, .Label = c("12:30:00",
"12:31:00", "12:33:00", "12:34:00", "12:36:00", "12:38:00", "12:39:00",
"12:40:00", "12:45:00"), class = "factor"), cas = c(0L, 1L, 3L,
4L, 6L, 8L, 9L, 10L, 11L), ?asm = structure(c(2L, 11L, 9L, 8L,
6L, 4L, NA, NA, NA), .Label = c("1:00", "11:00", "13:00", "15:00",
"17:00", "19:00", "21:00", "23:00", "3:00", "5:00", "7:00", "9:00"
), class = "factor"), Kontrolor = structure(c(6L, 6L, 6L, 6L,
6L, 6L, NA, NA, NA), .Label = c("CLLAB", "KO?UTKOV?", "KOUTN? PETRA",
"KOV??OV?", "KRUTILOV?", "LABRTG", "NAVR?TILOV?"), class = "factor"),
    X.R.v?p = c(0.5, 0.8, 0.2, 0.5, 0.5, 0.2, NA, NA, NA)), .Names = c("mikro",
"hod", "cas", "?asm", "Kontrolor", "X.R.v?p"), row.names = c(NA,
9L), class = "data.frame")
>

If this is not what you want, instead of flooding list with your irreproducible code provide input and output data in proper form. (?dput)

Cheers
Petr
 -----Original Message-----
> From: Sunny Singha [mailto:sunnysingha.analytics at gmail.com]
> Sent: Monday, March 14, 2016 11:17 AM
> To: PIKAL Petr
> Subject: Re: [R] Please help -- Cbind data frames within LIST() in R
>
> Petr,
> There is no common column in the data frames ($posts, $comments,
> $likes) within the list. I'm reposting the part of the code in plain
> text format:
>
> library(Rfacebook)
> library(plyr)
> library(data.table)
>
> page_keywords <- c('LinkedIn','youtube', 'facebook') p <- list() for(i
> in 1:length(page_keywords)){
>   cat('Searching 10 Pages for ',page_keywords[i],'\n')
>   p[[i]] <- searchPages(page_keywords[i], token=fb_oauth, 10)
>   cat('Found : ',nrow(p[[i]]),page_keywords[i],'\n\n')
> }
>
> # Appending pages found in the data frame 'pages_df pages_df <-
> rbindlist(p) cat('Category of pages found::: \n',
>     sort(paste0(unique(pages_df$category), '\n')))
>
>
> # Function to scrap facebook pages' posts, comments and likes
> page_data_extract <- function(pg_id){
>   path_data <- 'C:/Users/pc/Documents/Projects/fb'
>   cat('Extracting list of posts from page', pg_id, '\n')
>   page <- getPage(pg_id, token=fb_oauth, since='2016/03/01')
>
>   for(i in 1:nrow(page)){
>     cat('\nScrapping post \n',page$id[i])
>
>     posts <- getPost(page$id[i], n=100, token =fb_oauth)
>     time <- format(Sys.time(), '%b_%d_%Y')
>     for(j in 1:length(posts)){
>       myfile <- file.path(path_data, paste0(names(posts[j]), time, '_',
> i, '.csv'))
>       write.csv(posts[[j]], file=myfile, row.names = F)
>     }
>   }
> }
>
> # Call page_data_extract() function for each pages found to gather
> posts, comments & Likes for(i in 1:nrow(pages_df)){
>     e_catch <- try(page_data_extract(pages_df$id[i]))
>     if(isTRUE(all.equal(class(e_catch), 'try-error'))){
> #      writeLines('No public posts were found for == ')
>       cat('No public posts were found for ==
> ',pages_df$name[i],'(',pages_df$id[i],')\n\n')
>     }
> }
>
> Regards,
> Sunny
>
> On Mon, Mar 14, 2016 at 3:23 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> >
> >
> > From: Sunny Singha [mailto:sunnysingha.analytics at gmail.com]
> > Sent: Monday, March 14, 2016 10:37 AM
> > To: r-help; PIKAL Petr
> > Subject: Re: [R] Please help -- Cbind data frames within LIST() in R
> >
> >
> >
> > Thanks Petr,
> >
> > I'm going through the link that you have provided. Merge won't be
> > useful in my case. Let me give the complete picture of what I'm
> trying to achieve.
> >
> > Why do you think so? If you have several data frames of unequal
> length
> > with some common column I am almost sure that you want to align all
> > values according to this common column.
> >
> >
> > I'm extracting data from fb pages. I have the data frame 'pages_df'
> > which has all the details of the fb pages. 'Page_id' is the important
> > column in it to get all the posts from that page.
> >
> > I have created below function to which page_id is passed and data
> > frame is created separately for 'posts.csv', 'comments.csv',
> 'likescsv'.
> >
> > Ideally this is not what I want as the final output. I want to modify
> > this function so that it outputs single flat file where columns of
> >
> > each posts, comments and likes are cbinded.
> >
> >
> > # Function to scrap facebook pages' posts, comments and likes
> > page_data_extract <- function(pg_id){
> >   cat('Extracting list of posts from page', pg_id, '\n')
> >   page <- getPage(pg_id, token=fb_oauth, since='2016/03/01') # This
> > function extracts posts metadata from page_id argument specified.
> >
> >   # Loop to information of the post.
> >
> >   for(i in 1:nrow(page)){
> >
> >     path_dat <- <custom_path>
> >
> >     cat('\nScrapping post \n',page$id[i])
> >
> >     posts <- getPost(page$id[i], n=100, token =fb_oauth)
> >     time <- format(Sys.time(), '%b_%d_%Y')
> >     for(j in 1:length(posts)){
> >       myfile <- file.path(path_data, paste0(names(posts[j]), time,
> > '_', i,
> > '.csv'))
> >       write.csv(posts[[j]], file=myfile, row.names = F)
> >     }
> >   }
> > }
> >
> > I get this error with your code
> >
> > +     path_dat <- <custom_path>
> >
> > Error: unexpected '<' in:
> >
> > "  for(i in 1:nrow(page)){
> >
> >     path_dat <- <"
> >
> >>     cat('\nScrapping post \n',page$id[i])
> >
> > Error in page$id : object of type 'closure' is not subsettable
> >
> >>
> >
> > So please follow Posting guide for this help list if you really want
> > some usefull answers:
> >
> > No HTML, only plain text mails.
> >
> > Reproducible code
> >
> > Some toy data e.g. by posting result of
> >
> > dput(head(pages_df, 20))
> >
> > Cheers
> >
> > Petr
> >
> >
> > Here I call the above function:
> >  # Call page_data_extract() function for each pages found to gather
> > posts, comments & Likes for(i in 1:nrow(pages_df)){
> >     e_catch <- try(page_data_extract(pages_df$id[i]))
> >     if(isTRUE(all.equal(class(e_catch), 'try-error'))){
> >       cat('No public posts were found for ==
> > ',pages_df$name[i],'(',pages_df$id[i],')\n\n')
> >     }
> > }
> >
> > Regards,
> >
> > Sunny
> >
> >
> >
> > On Mon, Mar 14, 2016 at 1:19 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >
> > Hi
> >
> > There are several options e.g.
> >
> > http://stackoverflow.com/questions/6988184/combining-two-data-frames-
> o
> > f-different-lengths
> > http://stackoverflow.com/questions/7196450/create-a-data-frame-of-
> uneq
> > ual-lengths
> >
> > but maybe you want to do actually merging
> >
> > see
> >
> > ?merge
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Sunny
> >> Singha
> >> Sent: Monday, March 14, 2016 8:16 AM
> >> To: r-help
> >> Subject: [R] Please help -- Cbind data frames within LIST() in R
> >>
> >> Hi,
> >> Please help and guide. I want to cbind dataframes within the list
> >> object:
> >> List object 'post_data' contains below sampled data frames:
> >>
> >> post_data
> >> $posts
> >>       from_id user_name post_msg
> >>
> >> $comm
> >>        comm_id from_id message
> >>
> >> $Likes
> >>        username like_id
> >>
> >>
> >> *Note: The columns in each data frame are of unequal length. hence,
> >> missing values will be filled with 'NA' after combining* Regards,
> >> Sunny
> >>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From andrluis at ualberta.ca  Mon Mar 14 23:20:42 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 14 Mar 2016 16:20:42 -0600
Subject: [R] List funtion
Message-ID: <CAHxKz8ZgH1Qt8vLW-H6xpSQsMNW58teOKn0k+vfBmxvOS2ouCQ@mail.gmail.com>

Dear,

I have the following data:

v1 <- c(8,4,9,12)
v2 <- c(7, 8, 11)
my_list <- list(v1,v2)
rep (my_list,3)

My question is how I can modify my command line to create a list called my_list
containing two copies of the first vector (v1) and three copies of the vector
2 (v2).

The above command line creates 3 copies of both vectors, but I would like
to create 2 copies of one and 3 from the other, and return these results
within my_list object.

Thanks,

Andre

	[[alternative HTML version deleted]]


From raedkuntar92 at gmail.com  Tue Mar 15 01:36:29 2016
From: raedkuntar92 at gmail.com (raed kuntar)
Date: Mon, 14 Mar 2016 19:36:29 -0500
Subject: [R] Faster Block diagnonal matrix formulation in R
Message-ID: <CADDt0JKieVD7wzWZ5rxn8MP+zwyX9r5ZUqpK9Kkd_V4uF3rfRg@mail.gmail.com>

What is the fastest way to create a block diagonal matrix other than bdiag
function in the matrix package which is slow for large datasets

I have provided a reproducible example below


library(Matrix)

cy11=function(a,b,H){

d=outer(a,b,`-`);I=outer(a,b,`==`)

H[1]^2*d^2/H[2]^2+I*H[3]^2

}

x0=c(1,1,0.05)

z=list()

for (i in 1:100)

{

a=rnorm(50,0,10)

b=rnorm(50,0,10)

z[[i]]=cy11(a,a,x0)

}

bdiag(z)

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Tue Mar 15 13:26:20 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 15 Mar 2016 08:26:20 -0400
Subject: [R] R problem : Error: protect(): protection stack overflow
In-Reply-To: <425839205.1593807.1457995188922.JavaMail.yahoo@mail.yahoo.com>
References: <425839205.1593807.1457995188922.JavaMail.yahoo.ref@mail.yahoo.com>
	<425839205.1593807.1457995188922.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56E7FF6C.90601@roswellpark.org>



On 03/14/2016 06:39 PM, Mohammad Tanvir Ahamed via R-help wrote:
> Hi, i got an error while i am running a big data. Error has explained
> by the following sample sample

This is an error in the package, and should be reported to the 
maintainer. Discover the maintainer with the command

     maintainer("impute")


>
>
>
> ## Load data mdata <-
> as.matrix(read.table('https://gubox.box.com/shared/static/qh4spcxe2ba5ymzjs0ynh8n8s08af7m0.txt',
> header = TRUE, check.names = FALSE, sep = '\t'))
>
> ## Install and load library
> source("https://bioconductor.org/biocLite.R") biocLite("impute")
> library(impute)
>
> ## sets a limit on the number of nested expressions
> options(expressions = 500000) ## Apply k-nearest neighbors for
> missing value imputation
>
> res <-impute.knn(mdata)
>
> Error: protect(): protection stack overflow
>
>
> If anybody has solution or suggestion, please share. Thanks .
>
>
>
> Tanvir Ahamed G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From ruipbarradas at sapo.pt  Tue Mar 15 13:41:36 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 15 Mar 2016 12:41:36 +0000
Subject: [R] List funtion
In-Reply-To: <CAHxKz8ZgH1Qt8vLW-H6xpSQsMNW58teOKn0k+vfBmxvOS2ouCQ@mail.gmail.com>
Message-ID: <20160315124136.Horde.c44DHCZU0-qpr1S2jUnLFge@mail.sapo.pt>

Hello,

rep() is vectorized so you can do

rep (my_list, 2:3)

Hope this helps,

Rui Barradas
?

Citando Andr? Luis Neves <andrluis at ualberta.ca>:

> Dear,
>
> I have the following data:
>
> v1 <- c(8,4,9,12)
> v2 <- c(7, 8, 11)
> my_list <- list(v1,v2)
> rep (my_list,3)
>
> My question is how I can modify my command line to create a list  
> called my_list
> containing two copies of the first vector (v1) and three copies of the vector
> 2 (v2).
>
> The above command line creates 3 copies of both vectors, but I would like
> to create 2 copies of one and 3 from the other, and return these results
> within my_list object.
>
> Thanks,
>
> Andre
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Tue Mar 15 13:49:39 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 15 Mar 2016 12:49:39 +0000 (UTC)
Subject: [R] List funtion
In-Reply-To: <CAHxKz8ZgH1Qt8vLW-H6xpSQsMNW58teOKn0k+vfBmxvOS2ouCQ@mail.gmail.com>
References: <CAHxKz8ZgH1Qt8vLW-H6xpSQsMNW58teOKn0k+vfBmxvOS2ouCQ@mail.gmail.com>
Message-ID: <888672653.228182.1458046179069.JavaMail.yahoo@mail.yahoo.com>

> v3<-list(rep(list(v1),2),rep(list(v2),3)) 
> v3 
[[1]] 
[[1]][[1]] 
[1]  8  4  9 12 

[[1]][[2]] 
[1]  8  4  9 12 


[[2]] 
[[2]][[1]] 
[1]  7  8 11 

[[2]][[2]] 
[1]  7  8 11 

[[2]][[3]] 
[1]  7  8 11

if you want to track each list category. 
 Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Andr? Luis Neves <andrluis at ualberta.ca>
To: r-help at r-project.org
Sent: Monday, 14 March 2016, 23:20
Subject: [R] List funtion

Dear,

I have the following data:

v1 <- c(8,4,9,12)
v2 <- c(7, 8, 11)
my_list <- list(v1,v2)
rep (my_list,3)

My question is how I can modify my command line to create a list called my_list
containing two copies of the first vector (v1) and three copies of the vector
2 (v2).

The above command line creates 3 copies of both vectors, but I would like
to create 2 copies of one and 3 from the other, and return these results
within my_list object.

Thanks,

Andre

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mashranga at yahoo.com  Tue Mar 15 14:24:38 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 15 Mar 2016 13:24:38 +0000 (UTC)
Subject: [R] R problem : Error: protect(): protection stack overflow
In-Reply-To: <56E7FF6C.90601@roswellpark.org>
References: <56E7FF6C.90601@roswellpark.org>
Message-ID: <536118950.222226.1458048278835.JavaMail.yahoo@mail.yahoo.com>

Thanks . I have informed package maintainer. 
 Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Martin Morgan <martin.morgan at roswellpark.org>
To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>; R-help Mailing List <r-help at r-project.org>
Sent: Tuesday, 15 March 2016, 13:26
Subject: Re: [R] R problem : Error: protect(): protection stack overflow



On 03/14/2016 06:39 PM, Mohammad Tanvir Ahamed via R-help wrote:
> Hi, i got an error while i am running a big data. Error has explained
> by the following sample sample

This is an error in the package, and should be reported to the 
maintainer. Discover the maintainer with the command

     maintainer("impute")



>
>
>
> ## Load data mdata <-
> as.matrix(read.table('https://gubox.box.com/shared/static/qh4spcxe2ba5ymzjs0ynh8n8s08af7m0.txt',
> header = TRUE, check.names = FALSE, sep = '\t'))
>
> ## Install and load library
> source("https://bioconductor.org/biocLite.R") biocLite("impute")
> library(impute)
>
> ## sets a limit on the number of nested expressions
> options(expressions = 500000) ## Apply k-nearest neighbors for
> missing value imputation
>
> res <-impute.knn(mdata)
>
> Error: protect(): protection stack overflow
>
>
> If anybody has solution or suggestion, please share. Thanks .
>
>
>
> Tanvir Ahamed G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From aleminesh57 at gmail.com  Tue Mar 15 14:19:46 2016
From: aleminesh57 at gmail.com (Betty Betty)
Date: Tue, 15 Mar 2016 14:19:46 +0100
Subject: [R] ivprobit what are formula1 and formula2
Message-ID: <CAOA_h3LJWmZGO1cTC8s9m+k-9V4L3DWJfBTmxAicJanzY7AO3Q@mail.gmail.com>

Dear All,
Can some one explain to me what exactly is formula1 and formula2 in the
ivprobit(formula1, formula2, data = list(), ...).
The manual for ivprobit has quite limited information and i found it
difficult to understand.
Thank you very much!

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Tue Mar 15 16:14:42 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 15 Mar 2016 16:14:42 +0100
Subject: [R] Linear Model and Missing Data in Predictors
Message-ID: <20160315151442.GA3391@localhost.localdomain>

Dear All,
A situation that for sure happens very often: suppose you are in the
following situation

set.seed(1235)
x1 <- seq(30)
x2 <- c(rep(NA, 9), rnorm(19)+9, c(NA, NA))
x3 <- c(rnorm(17)-2, rep(NA, 13))

y <- exp(seq(1,5, length=30))


mm<-lm(y~x1+x2+x3)

i.e. you try a simple linear regression with multiple regressors
which exhibit some missing values.
This is what happens to me while working with some time series which I
use as regressors and whose missing values are padded with NAs.
lm, as a default, disregard the sets of incomplete observations and
therefore drops quite a lot of data.
Is there any way to circumvent this? I mean, is there a way to somehow
come up with a piecewise linear regression where, whenever possible,
all the 3 regressors are used but we switch to 1 or 2 when there are
missing data?
I say this because it is totally unfeasible to try to figure out the
values of the missing data in my regressors, but at the same time I
cannot restrict my model to the intersection of the non-NA values in
the 3 regressors. If this makes sense, do I have to code it myself or
is there any package which already implemented this?
Any suggestion is appreciated.
Cheers

Lorenzo


From jdnewmil at dcn.davis.ca.us  Tue Mar 15 17:36:28 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 15 Mar 2016 09:36:28 -0700
Subject: [R] Linear Model and Missing Data in Predictors
In-Reply-To: <20160315151442.GA3391@localhost.localdomain>
References: <20160315151442.GA3391@localhost.localdomain>
Message-ID: <494ADB63-96FA-4F0F-81FB-E1F7107AC705@dcn.davis.ca.us>

IMHO this is not a question about R... it is a question about statistics whether R is involved or not. As such, a forum like stats.stackexchange.com would be better suited to address this.

FWIW I happen to think that expecting R to solve this for you is unreasonable. 
-- 
Sent from my phone. Please excuse my brevity.

On March 15, 2016 8:14:42 AM PDT, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>Dear All,
>A situation that for sure happens very often: suppose you are in the
>following situation
>
>set.seed(1235)
>x1 <- seq(30)
>x2 <- c(rep(NA, 9), rnorm(19)+9, c(NA, NA))
>x3 <- c(rnorm(17)-2, rep(NA, 13))
>
>y <- exp(seq(1,5, length=30))
>
>
>mm<-lm(y~x1+x2+x3)
>
>i.e. you try a simple linear regression with multiple regressors
>which exhibit some missing values.
>This is what happens to me while working with some time series which I
>use as regressors and whose missing values are padded with NAs.
>lm, as a default, disregard the sets of incomplete observations and
>therefore drops quite a lot of data.
>Is there any way to circumvent this? I mean, is there a way to somehow
>come up with a piecewise linear regression where, whenever possible,
>all the 3 regressors are used but we switch to 1 or 2 when there are
>missing data?
>I say this because it is totally unfeasible to try to figure out the
>values of the missing data in my regressors, but at the same time I
>cannot restrict my model to the intersection of the non-NA values in
>the 3 regressors. If this makes sense, do I have to code it myself or
>is there any package which already implemented this?
>Any suggestion is appreciated.
>Cheers
>
>Lorenzo
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Mar 15 17:47:07 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 15 Mar 2016 09:47:07 -0700
Subject: [R] Linear Model and Missing Data in Predictors
In-Reply-To: <20160315151442.GA3391@localhost.localdomain>
References: <20160315151442.GA3391@localhost.localdomain>
Message-ID: <CAF8bMcZEDR80JXn6Jk4ZVtSPL3051ba_jkqwjc6ewHsyhuYRzg@mail.gmail.com>

One technique for dealing with this is called 'multiple imputation'.
Google for 'multiple imputation in R' to find R packages that implement
it (e.g., the 'mi' package).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 15, 2016 at 8:14 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> A situation that for sure happens very often: suppose you are in the
> following situation
>
> set.seed(1235)
> x1 <- seq(30)
> x2 <- c(rep(NA, 9), rnorm(19)+9, c(NA, NA))
> x3 <- c(rnorm(17)-2, rep(NA, 13))
>
> y <- exp(seq(1,5, length=30))
>
>
> mm<-lm(y~x1+x2+x3)
>
> i.e. you try a simple linear regression with multiple regressors
> which exhibit some missing values.
> This is what happens to me while working with some time series which I
> use as regressors and whose missing values are padded with NAs.
> lm, as a default, disregard the sets of incomplete observations and
> therefore drops quite a lot of data.
> Is there any way to circumvent this? I mean, is there a way to somehow
> come up with a piecewise linear regression where, whenever possible,
> all the 3 regressors are used but we switch to 1 or 2 when there are
> missing data?
> I say this because it is totally unfeasible to try to figure out the
> values of the missing data in my regressors, but at the same time I
> cannot restrict my model to the intersection of the non-NA values in
> the 3 regressors. If this makes sense, do I have to code it myself or
> is there any package which already implemented this?
> Any suggestion is appreciated.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From meherdivya4 at gmail.com  Tue Mar 15 17:53:29 2016
From: meherdivya4 at gmail.com (MEHER DIVYA BARATAM)
Date: Tue, 15 Mar 2016 22:23:29 +0530
Subject: [R] doubt clarification
Message-ID: <CAOOMz7MgVL6a3w3Qi6up9jQCfhOEKJNb_tw0GjQhv8HaG4PcSw@mail.gmail.com>

dear sir/madam,

                        i am a new learner of r software. while plotting a
graph of data which contains date. i have dates on X-axis, while learning i
got to know i have to convert into R understandable language. i got an
error while converting


"as.Date(all.2015$Day,%d-%m-%y)
  Error: unexpected SPECIAL in "as.Date(all.2015$Day,%d-%"   "

so please help me out to solve this error.

thanks and regards
divya

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Mar 15 19:29:09 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Mar 2016 14:29:09 -0400
Subject: [R] doubt clarification
In-Reply-To: <CAOOMz7MgVL6a3w3Qi6up9jQCfhOEKJNb_tw0GjQhv8HaG4PcSw@mail.gmail.com>
References: <CAOOMz7MgVL6a3w3Qi6up9jQCfhOEKJNb_tw0GjQhv8HaG4PcSw@mail.gmail.com>
Message-ID: <56E85475.4030606@gmail.com>

On 15/03/2016 12:53 PM, MEHER DIVYA BARATAM wrote:
> dear sir/madam,
>
>                          i am a new learner of r software. while plotting a
> graph of data which contains date. i have dates on X-axis, while learning i
> got to know i have to convert into R understandable language. i got an
> error while converting
>
>
> "as.Date(all.2015$Day,%d-%m-%y)
>    Error: unexpected SPECIAL in "as.Date(all.2015$Day,%d-%"

You need to put the format in quotes.  R sees %d-% as a "SPECIAL" 
operator, and it is an error for one of those to appear in that position.

So use

as.Date(all.2015$Day, "%d-%m-%y")

(and be careful of the quotes:  these are regular ASCII quotes, not directional quotes which some editors will insert).


Duncan Murdoch


From salnsg at gmail.com  Tue Mar 15 20:02:07 2016
From: salnsg at gmail.com (=?UTF-8?B?0KHQtdGA0LPQtdC5INChLg==?=)
Date: Tue, 15 Mar 2016 22:02:07 +0300
Subject: [R] About calculation of the gravity model in R and STATA software
Message-ID: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>

Dear colleagues!

We spent calculation of the gravity model in R and STATA software.
For calculations we used the standard package glmm in R (with parameter
family = quasipoisson)
and ppml in STATA.

Call the calculation procedure in R:

summary(glmm<-glm(formula=exports ~ ln_GDPimporter + ln_GDPexporter +
ln_GDPimppc + ln_GDPexppc + ln_Distance + ln_Tariff + ln_ExchangeRate +
Contig + Comlang + Colony_CIS + EAEU_CIS + EU_European_Union,
family=quasipoisson(link="log"),data=data_pua))

The results of the calculations in R following:

------------------------------------------------------------------------

Coefficients:
                           Estimate    Std. Error  t value Pr(>|t|)
(Intercept)           -12.53224   15.30072  -0.819  0.41357
ln_GDPimporter       0.10180    0.14988   0.679   0.49765
ln_GDPexporter       0.14612    0.79823    0.183   0.85491
ln_GDPimppc           0.34998    0.30247   1.157   0.24840
ln_GDPexppc           0.65811    0.82189    0.801   0.42409
ln_Distance             0.21838    0.16623    1.314   0.19020
ln_Tariff                 -0.05499    0.04913  -1.119  0.26411
ln_ExchangeRate     -0.11748    0.04275  -2.748  0.00646 **
Contig                      1.48321    0.28684   5.171  4.92e-07 ***
Comlang                  1.50727    0.26199    5.753   2.67e-08 ***
Colony_CIS               2.15272    0.46899   4.590  7.16e-06 ***
EAEU_CIS                -0.94417    0.29315  -3.221  0.00146 **
EU_European_Union  -0.08335    0.76733  -0.109  0.91359
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for quasipoisson family taken to be 2100.979)

    Null deviance: 1886758  on 251  degrees of freedom
Residual deviance:  316332  on 239  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 8

------------------------------------------------------------------------

On the same data, we done calculations in STATA, using ppml procedure.
Call of the calculation procedure in STATA was next:

ppml exports ln_gdpimporter ln_gdpexporter ln_gdpimppc ln_gdpexppc
ln_distance ln_tariff ln_exchangerate contig comlang colony_cis eaeu_cis
eu_european_union

The results of the calculations in STATA were following:

------------------------------------------------------------------------

Iteration 1:   deviance =  425911.3
Iteration 2:   deviance =  327020.8
Iteration 3:   deviance =  316763.3
Iteration 4:   deviance =  316335.1
Iteration 5:   deviance =  316332.3
Iteration 6:   deviance =  316332.3
Iteration 7:   deviance =  316332.3

Number of parameters: 13
Number of observations: 252
Pseudo log-likelihood: -158930.64
R-squared: .75348104
Option strict is: off
-----------------------------------------------------------------------------------
                           |                    Robust
          exports       |      Coef.      Std. Err.          z    P>|z|
   [95% Conf. Interval]
------------------
+----------------------------------------------------------------
   ln_gdpimporter    |   .1018021   .0982091     1.04   0.300
-.0906843    .2942885
   ln_gdpexporter    |   .1461135   1.084255     0.13   0.893
-1.978988    2.271215
      ln_gdpimppc     |    .349982    .201011      1.74   0.082
-.0439924    .7439564
      ln_gdpexppc     |   .6581201   1.098236     0.60   0.549
-1.494383    2.810624
      ln_distance       |   .2183809    .156757     1.39    0.164
-.0888572     .525619
        ln_tariff          |  -.0549914   .0551489    -1.00   0.319
-.1630811    .0530984
  ln_exchangerate    |  -.1174816   .0343881    -3.42   0.001
-.1848812   -.0500821
           contig          |   1.483213    .168467     8.80   0.000
1.153024    1.813402
          comlang       |   1.507272   .2745761     5.49   0.000
.9691126    2.045431
       colony_cis        |   2.152723   .2338133     9.21   0.000
1.694457    2.610988
         eaeu_cis        |  -.9441651   .2469764    -3.82   0.000
-1.42823   -.4601003
eu_european_union |  -.0833477   .4955678    -0.17   0.866     -1.054643
.8879474
            _cons         |  -12.53206   21.18599    -0.59   0.554
-54.05585    28.99172
-----------------------------------------------------------------------------------

As you can see, model coefficients (second column in the results table) are
the same at least until the 4th mark (!)
However, other results (columns in the table of results, since the third)
is not the same.
Could you explain differences in the results?
In particular, why coefficients the same (the first result table columns),
but standard errors is not?
With best regards,
Sergey S.

	[[alternative HTML version deleted]]


From arbautjc at gmail.com  Tue Mar 15 20:05:50 2016
From: arbautjc at gmail.com (Jean-Claude Arbaut)
Date: Tue, 15 Mar 2016 20:05:50 +0100
Subject: [R] Truncated file upon reading a text file with 0xff characters
Message-ID: <CANufCk5D2yT1hb4kRLQPdk-PriuY67jACL7zWO_FJEBU96C2gQ@mail.gmail.com>

Hello R users,

I am having problems to read a CSV file that contains names with character ?.
In case it doesn't print correctly, it's Unicode character 00FF or LATIN SMALL
LETTER Y WITH DIAERESIS.
My computer has Windows 7 and R 3.2.4.

Initially, I configured my computer to run options(encoding="UTF-8")
in my .Rprofile,
since I prefer this encoding, for portability. Good and modern
standard, I thought.
Rather than sending a large file, here is how to reproduce my problem:

  options(encoding="UTF-8")

  f <- file("test.txt", "wb")
  writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
f, size=1)
  close(f)
  read.table("test.txt", encoding="latin1")
  f <- file("test.txt", "rt")
  readLines(f, encoding="latin1")
  close(f)

I write a file with three lines, in binary to avoid any translation:
A
B\xffC
D

Upon reading I get only:

  > read.table("test.txt", encoding="latin1")
    V1
  1  A
  2  B
  Warning messages:
  1: In read.table("test.txt", encoding = "latin1") :
    invalid input found on input connection 'test.txt'
  2: In read.table("test.txt", encoding = "latin1") :
    incomplete final line found by readTableHeader on 'test.txt'
  > readLines(f, encoding="latin1")
  [1] "A" "B"
  Warning messages:
  1: In readLines(f, encoding = "latin1") :
    invalid input found on input connection 'test.txt'
  2: In readLines(f, encoding = "latin1") :
    incomplete final line found on 'test.txt'

Hence the file is truncated. However, character \xff is a valid latin1
character,
as one can check for instance at https://en.wikipedia.org/wiki/ISO/IEC_8859-1
I tried with an UTF-8 version of this file:

  f <- file("test.txt", "wb")
  writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
10)), f, size=1)
  close(f)
  read.table("test.txt", encoding="UTF-8")
  f <- file("test.txt", "rt")
  readLines(f, encoding="UTF-8")
  close(f)

Since this character ? is encoded as two bytes 195, 191 in UTF-8, I would expect
that I get my complete file. But I don't. Instead, I get:

  > read.table("test.txt", encoding="UTF-8")
    V1
  1  A
  2  B
  3  C
  4  D
  Warning message:
  In read.table("test.txt", encoding = "UTF-8") :
    incomplete final line found by readTableHeader on 'test.txt'

  > readLines(f, encoding="UTF-8")
  [1] "A" "B"
  Warning message:
  In readLines(f, encoding = "UTF-8") :
    incomplete final line found on 'test.txt'

I tried all the preceding but with options(encoding="latin1") at the beginning.
For the first attempt, with byte 255, I get:

  > read.table("test.txt", encoding="latin1")
    V1
  1  A
  2  B
  3  C
  4  D
  Warning message:
  In read.table("test.txt", encoding = "latin1") :
    incomplete final line found by readTableHeader on 'test.txt'
  >
  > f <- file("test.txt", "rt")
  > readLines(f, encoding="latin1")

For the other attempt, with 195, 191:

  > read.table("test.txt", encoding="UTF-8")
     V1
  1   A
  2 B?C
  3   D
  >
  > f <- file("test.txt", "rt")
  > readLines(f, encoding="UTF-8")
  [1] "A"   "B?C" "D"
  > close(f)

Thus the second one does indeed work, it seems. Just a check:

  > a <- read.table("test.txt", encoding="UTF-8")
  > Encoding(a$V1)
  [1] "unknown" "UTF-8"   "unknown"

At last, I figured out that with the default encoding in R, both attempts work,
with or without even giving the encoding as a parameter of read.table
or readLines.
However, I don't understand what happens:

  f <- file("test.txt", "wb")
  writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
f, size=1)
  close(f)
  a <- read.table("test.txt", encoding="latin1")$V1
  Encoding(a)
  iconv(a[2], toRaw=T)
  a
  a <- read.table("test.txt")$V1
  Encoding(a)
  iconv(a[2], toRaw=T)
  a

This will yield:

  > a <- read.table("test.txt", encoding="latin1")$V1
  > Encoding(a)
  [1] "unknown" "latin1"  "unknown"
  > iconv(a[2], toRaw=T)
  [[1]]
  [1] 42 ff 43
  > a
  [1] "A"   "B?C" "D"
  >
  > a <- read.table("test.txt")$V1
  > Encoding(a)
  [1] "unknown" "unknown" "unknown"
  > iconv(a[2], toRaw=T)
  [[1]]
  [1] 42 ff 43
  > a
  [1] "A"   "B?C" "D"

The second line is correctly encoded, but the encoding is just not
"marked" in one case.
With the UTF-8 bytes:

  f <- file("test.txt", "wb")
  writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
10)), f, size=1)
  close(f)
  a <- read.table("test.txt", encoding="UTF-8")$V1
  Encoding(a)
  iconv(a[2], toRaw=T)
  a
  a <- read.table("test.txt")$V1
  Encoding(a)
  iconv(a[2], toRaw=T)
  a

This will yield:

> a <- read.table("test.txt", encoding="UTF-8")$V1
> Encoding(a)
[1] "unknown" "UTF-8"   "unknown"
> iconv(a[2], toRaw=T)
[[1]]
[1] 42 c3 bf 43
> a
[1] "A"   "B?C" "D"
> a <- read.table("test.txt")$V1
> Encoding(a)
[1] "unknown" "unknown" "unknown"
> iconv(a[2], toRaw=T)
[[1]]
[1] 42 c3 bf 43
> a
[1] "A"    "B??C" "D"

Both are correctly read (the raw bytes are ok), but the second one doesn't print
correctly because the encoding is not "marked".

My thoughts:
With options(encoding="native.enc"), the characters read are not
translated, and are read
as raw bytes, which can get an encoding mark to print correctly (otherwise it
prints as native, that is mostly latin1).
With options(encoding="latin1"), and reading the UTF-8 file, I guess it's mostly
like the preceding: the characters are read as raw, and marked as
UTF-8, which works.
With options(encoding="latin1"), and reading the latin1 file (with the
0xFF byte),
I don't understand what happens. The file gets truncated almost as if 0xFF were
an EOF character - which is perplexing, since I think that in C, 0xFF
is sometimes
(wrongly) confused with EOF.
And with options(encoding="UTF-8"), I am not sure what happens.

Questions:
* What's wrong with options(encoding="latin1")?
* Is it unsafe to use another option(encoding) than the default
native.enc, on Windows?
* Is it safe to assume that with native.enc R reads raw characters
and, only when requested,
  marks an encoding afterwards? (that is, I get "unknown" by default
which is printed
  as latin1 on Windows, and if I enforce another encoding, it will be
used whatever
  the bytes really are)
* What does really happen with another option(encoding), especially UTF-8?
* If I save a character variable to an Rdata file, is the file usable
on another OS,
  or on the same with another default encoding (by changing
options())? Does it depend
  whether the character string has un "unknown" encoding or an explicit one?
* Is there a way (preferably an options()) to tell R to read text
files as UTF-8 by default?
  Would it work with any one of read.table(), readLines(), or even source()?
  I thought options(encoding="UTF-8") would do, but it fails on the
examples above.

Best regards,

Jean-Claude Arbaut


From jdnewmil at dcn.davis.ca.us  Tue Mar 15 20:37:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 15 Mar 2016 12:37:57 -0700
Subject: [R] About calculation of the gravity model in R and STATA
	software
In-Reply-To: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>
References: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>
Message-ID: <FE39486D-2004-4B04-B8A4-EA69B4022FB3@dcn.davis.ca.us>

I am not the person to answer your question, but have some suggestions:

Make your examples reproducible so others can confirm your results and explore other issues you may not have seen. [1] [2] 

Post your question on the R-sig-mixed mailing list, where mixed models experts hang out, instead of here where the R language is on topic rather than contributed packages like glmm.

I don't know SAS or the glmm package, but the fact that the top description line for the glmm package says it uses Monte  Carlo suggests to me that it might not be "standard" in SAS or R and that your results may vary depending on how you configure it and how the random number seed is initialized. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
[2] See also the Posting Guide mentioned at the bottom of this and every email on this list. 
-- 
Sent from my phone. Please excuse my brevity.

On March 15, 2016 12:02:07 PM PDT, "?????? ?." <salnsg at gmail.com> wrote:
>Dear colleagues!
>
>We spent calculation of the gravity model in R and STATA software.
>For calculations we used the standard package glmm in R (with parameter
>family = quasipoisson)
>and ppml in STATA.
>
>Call the calculation procedure in R:
>
>summary(glmm<-glm(formula=exports ~ ln_GDPimporter + ln_GDPexporter +
>ln_GDPimppc + ln_GDPexppc + ln_Distance + ln_Tariff + ln_ExchangeRate +
>Contig + Comlang + Colony_CIS + EAEU_CIS + EU_European_Union,
>family=quasipoisson(link="log"),data=data_pua))
>
>The results of the calculations in R following:
>
>------------------------------------------------------------------------
>
>Coefficients:
>                           Estimate    Std. Error  t value Pr(>|t|)
>(Intercept)           -12.53224   15.30072  -0.819  0.41357
>ln_GDPimporter       0.10180    0.14988   0.679   0.49765
>ln_GDPexporter       0.14612    0.79823    0.183   0.85491
>ln_GDPimppc           0.34998    0.30247   1.157   0.24840
>ln_GDPexppc           0.65811    0.82189    0.801   0.42409
>ln_Distance             0.21838    0.16623    1.314   0.19020
>ln_Tariff                 -0.05499    0.04913  -1.119  0.26411
>ln_ExchangeRate     -0.11748    0.04275  -2.748  0.00646 **
>Contig                      1.48321    0.28684   5.171  4.92e-07 ***
>Comlang                  1.50727    0.26199    5.753   2.67e-08 ***
>Colony_CIS               2.15272    0.46899   4.590  7.16e-06 ***
>EAEU_CIS                -0.94417    0.29315  -3.221  0.00146 **
>EU_European_Union  -0.08335    0.76733  -0.109  0.91359
>---
>Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>(Dispersion parameter for quasipoisson family taken to be 2100.979)
>
>    Null deviance: 1886758  on 251  degrees of freedom
>Residual deviance:  316332  on 239  degrees of freedom
>AIC: NA
>
>Number of Fisher Scoring iterations: 8
>
>------------------------------------------------------------------------
>
>On the same data, we done calculations in STATA, using ppml procedure.
>Call of the calculation procedure in STATA was next:
>
>ppml exports ln_gdpimporter ln_gdpexporter ln_gdpimppc ln_gdpexppc
>ln_distance ln_tariff ln_exchangerate contig comlang colony_cis
>eaeu_cis
>eu_european_union
>
>The results of the calculations in STATA were following:
>
>------------------------------------------------------------------------
>
>Iteration 1:   deviance =  425911.3
>Iteration 2:   deviance =  327020.8
>Iteration 3:   deviance =  316763.3
>Iteration 4:   deviance =  316335.1
>Iteration 5:   deviance =  316332.3
>Iteration 6:   deviance =  316332.3
>Iteration 7:   deviance =  316332.3
>
>Number of parameters: 13
>Number of observations: 252
>Pseudo log-likelihood: -158930.64
>R-squared: .75348104
>Option strict is: off
>-----------------------------------------------------------------------------------
>                           |                    Robust
>          exports       |      Coef.      Std. Err.          z    P>|z|
>   [95% Conf. Interval]
>------------------
>+----------------------------------------------------------------
>   ln_gdpimporter    |   .1018021   .0982091     1.04   0.300
>-.0906843    .2942885
>   ln_gdpexporter    |   .1461135   1.084255     0.13   0.893
>-1.978988    2.271215
>      ln_gdpimppc     |    .349982    .201011      1.74   0.082
>-.0439924    .7439564
>      ln_gdpexppc     |   .6581201   1.098236     0.60   0.549
>-1.494383    2.810624
>      ln_distance       |   .2183809    .156757     1.39    0.164
>-.0888572     .525619
>        ln_tariff          |  -.0549914   .0551489    -1.00   0.319
>-.1630811    .0530984
>  ln_exchangerate    |  -.1174816   .0343881    -3.42   0.001
>-.1848812   -.0500821
>           contig          |   1.483213    .168467     8.80   0.000
>1.153024    1.813402
>          comlang       |   1.507272   .2745761     5.49   0.000
>.9691126    2.045431
>       colony_cis        |   2.152723   .2338133     9.21   0.000
>1.694457    2.610988
>         eaeu_cis        |  -.9441651   .2469764    -3.82   0.000
>-1.42823   -.4601003
>eu_european_union |  -.0833477   .4955678    -0.17   0.866    
>-1.054643
>.8879474
>            _cons         |  -12.53206   21.18599    -0.59   0.554
>-54.05585    28.99172
>-----------------------------------------------------------------------------------
>
>As you can see, model coefficients (second column in the results table)
>are
>the same at least until the 4th mark (!)
>However, other results (columns in the table of results, since the
>third)
>is not the same.
>Could you explain differences in the results?
>In particular, why coefficients the same (the first result table
>columns),
>but standard errors is not?
>With best regards,
>Sergey S.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Mar 15 21:24:58 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Mar 2016 16:24:58 -0400
Subject: [R] Truncated file upon reading a text file with 0xff characters
In-Reply-To: <CANufCk5D2yT1hb4kRLQPdk-PriuY67jACL7zWO_FJEBU96C2gQ@mail.gmail.com>
References: <CANufCk5D2yT1hb4kRLQPdk-PriuY67jACL7zWO_FJEBU96C2gQ@mail.gmail.com>
Message-ID: <56E86F9A.40201@gmail.com>

I think you've identified a bug (or more than one) here, but your 
message is so long, I haven't had time to go through it all.  I'd 
suggest that you write up a shorter version for the bug list.  The 
shorter version would

1.  Write the latin1 file using writeBin.
2.  Set options(encoding = "") and read it without error.
3.  Set options(encoding = "UTF-8") and get an error even if you 
explicitly set encoding when reading.
4.  Set options(encoding = "latin1") and also get an error with or 
without explicitly setting the encoding.

I would limit the tests to readLines; read.table is much more 
complicated, and isn't necessary to illustrate the problem.  It just 
confuses things by bringing it into the discussion.

You should also avoid bringing text mode connections into the discussion 
unless they are necessary.

Duncan Murdoch

On 15/03/2016 3:05 PM, Jean-Claude Arbaut wrote:
> Hello R users,
>
> I am having problems to read a CSV file that contains names with character ?.
> In case it doesn't print correctly, it's Unicode character 00FF or LATIN SMALL
> LETTER Y WITH DIAERESIS.
> My computer has Windows 7 and R 3.2.4.
>
> Initially, I configured my computer to run options(encoding="UTF-8")
> in my .Rprofile,
> since I prefer this encoding, for portability. Good and modern
> standard, I thought.
> Rather than sending a large file, here is how to reproduce my problem:
>
>    options(encoding="UTF-8")
>
>    f <- file("test.txt", "wb")
>    writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
> f, size=1)
>    close(f)
>    read.table("test.txt", encoding="latin1")
>    f <- file("test.txt", "rt")
>    readLines(f, encoding="latin1")
>    close(f)
>
> I write a file with three lines, in binary to avoid any translation:
> A
> B\xffC
> D
>
> Upon reading I get only:
>
>    > read.table("test.txt", encoding="latin1")
>      V1
>    1  A
>    2  B
>    Warning messages:
>    1: In read.table("test.txt", encoding = "latin1") :
>      invalid input found on input connection 'test.txt'
>    2: In read.table("test.txt", encoding = "latin1") :
>      incomplete final line found by readTableHeader on 'test.txt'
>    > readLines(f, encoding="latin1")
>    [1] "A" "B"
>    Warning messages:
>    1: In readLines(f, encoding = "latin1") :
>      invalid input found on input connection 'test.txt'
>    2: In readLines(f, encoding = "latin1") :
>      incomplete final line found on 'test.txt'
>
> Hence the file is truncated. However, character \xff is a valid latin1
> character,
> as one can check for instance at https://en.wikipedia.org/wiki/ISO/IEC_8859-1
> I tried with an UTF-8 version of this file:
>
>    f <- file("test.txt", "wb")
>    writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
> 10)), f, size=1)
>    close(f)
>    read.table("test.txt", encoding="UTF-8")
>    f <- file("test.txt", "rt")
>    readLines(f, encoding="UTF-8")
>    close(f)
>
> Since this character ? is encoded as two bytes 195, 191 in UTF-8, I would expect
> that I get my complete file. But I don't. Instead, I get:
>
>    > read.table("test.txt", encoding="UTF-8")
>      V1
>    1  A
>    2  B
>    3  C
>    4  D
>    Warning message:
>    In read.table("test.txt", encoding = "UTF-8") :
>      incomplete final line found by readTableHeader on 'test.txt'
>
>    > readLines(f, encoding="UTF-8")
>    [1] "A" "B"
>    Warning message:
>    In readLines(f, encoding = "UTF-8") :
>      incomplete final line found on 'test.txt'
>
> I tried all the preceding but with options(encoding="latin1") at the beginning.
> For the first attempt, with byte 255, I get:
>
>    > read.table("test.txt", encoding="latin1")
>      V1
>    1  A
>    2  B
>    3  C
>    4  D
>    Warning message:
>    In read.table("test.txt", encoding = "latin1") :
>      incomplete final line found by readTableHeader on 'test.txt'
>    >
>    > f <- file("test.txt", "rt")
>    > readLines(f, encoding="latin1")
>
> For the other attempt, with 195, 191:
>
>    > read.table("test.txt", encoding="UTF-8")
>       V1
>    1   A
>    2 B?C
>    3   D
>    >
>    > f <- file("test.txt", "rt")
>    > readLines(f, encoding="UTF-8")
>    [1] "A"   "B?C" "D"
>    > close(f)
>
> Thus the second one does indeed work, it seems. Just a check:
>
>    > a <- read.table("test.txt", encoding="UTF-8")
>    > Encoding(a$V1)
>    [1] "unknown" "UTF-8"   "unknown"
>
> At last, I figured out that with the default encoding in R, both attempts work,
> with or without even giving the encoding as a parameter of read.table
> or readLines.
> However, I don't understand what happens:
>
>    f <- file("test.txt", "wb")
>    writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
> f, size=1)
>    close(f)
>    a <- read.table("test.txt", encoding="latin1")$V1
>    Encoding(a)
>    iconv(a[2], toRaw=T)
>    a
>    a <- read.table("test.txt")$V1
>    Encoding(a)
>    iconv(a[2], toRaw=T)
>    a
>
> This will yield:
>
>    > a <- read.table("test.txt", encoding="latin1")$V1
>    > Encoding(a)
>    [1] "unknown" "latin1"  "unknown"
>    > iconv(a[2], toRaw=T)
>    [[1]]
>    [1] 42 ff 43
>    > a
>    [1] "A"   "B?C" "D"
>    >
>    > a <- read.table("test.txt")$V1
>    > Encoding(a)
>    [1] "unknown" "unknown" "unknown"
>    > iconv(a[2], toRaw=T)
>    [[1]]
>    [1] 42 ff 43
>    > a
>    [1] "A"   "B?C" "D"
>
> The second line is correctly encoded, but the encoding is just not
> "marked" in one case.
> With the UTF-8 bytes:
>
>    f <- file("test.txt", "wb")
>    writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
> 10)), f, size=1)
>    close(f)
>    a <- read.table("test.txt", encoding="UTF-8")$V1
>    Encoding(a)
>    iconv(a[2], toRaw=T)
>    a
>    a <- read.table("test.txt")$V1
>    Encoding(a)
>    iconv(a[2], toRaw=T)
>    a
>
> This will yield:
>
> > a <- read.table("test.txt", encoding="UTF-8")$V1
> > Encoding(a)
> [1] "unknown" "UTF-8"   "unknown"
> > iconv(a[2], toRaw=T)
> [[1]]
> [1] 42 c3 bf 43
> > a
> [1] "A"   "B?C" "D"
> > a <- read.table("test.txt")$V1
> > Encoding(a)
> [1] "unknown" "unknown" "unknown"
> > iconv(a[2], toRaw=T)
> [[1]]
> [1] 42 c3 bf 43
> > a
> [1] "A"    "B??C" "D"
>
> Both are correctly read (the raw bytes are ok), but the second one doesn't print
> correctly because the encoding is not "marked".
>
> My thoughts:
> With options(encoding="native.enc"), the characters read are not
> translated, and are read
> as raw bytes, which can get an encoding mark to print correctly (otherwise it
> prints as native, that is mostly latin1).
> With options(encoding="latin1"), and reading the UTF-8 file, I guess it's mostly
> like the preceding: the characters are read as raw, and marked as
> UTF-8, which works.
> With options(encoding="latin1"), and reading the latin1 file (with the
> 0xFF byte),
> I don't understand what happens. The file gets truncated almost as if 0xFF were
> an EOF character - which is perplexing, since I think that in C, 0xFF
> is sometimes
> (wrongly) confused with EOF.
> And with options(encoding="UTF-8"), I am not sure what happens.
>
> Questions:
> * What's wrong with options(encoding="latin1")?
> * Is it unsafe to use another option(encoding) than the default
> native.enc, on Windows?
> * Is it safe to assume that with native.enc R reads raw characters
> and, only when requested,
>    marks an encoding afterwards? (that is, I get "unknown" by default
> which is printed
>    as latin1 on Windows, and if I enforce another encoding, it will be
> used whatever
>    the bytes really are)
> * What does really happen with another option(encoding), especially UTF-8?
> * If I save a character variable to an Rdata file, is the file usable
> on another OS,
>    or on the same with another default encoding (by changing
> options())? Does it depend
>    whether the character string has un "unknown" encoding or an explicit one?
> * Is there a way (preferably an options()) to tell R to read text
> files as UTF-8 by default?
>    Would it work with any one of read.table(), readLines(), or even source()?
>    I thought options(encoding="UTF-8") would do, but it fails on the
> examples above.
>
> Best regards,
>
> Jean-Claude Arbaut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Tue Mar 15 21:27:20 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 15 Mar 2016 15:27:20 -0500
Subject: [R] Logistic Regression output baseline (reference) category
Message-ID: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>

Hi,
   I am trying to use the summary from the glm function as a data source. I
am using the call sink(<some file>) then
summary(logisticRegModel)$coefficients then sink().  The independent
variables are categorical and thus there is always a baseline value for
every category that is omitted from the glm output.  I am interested in how
to get the Z column for all of the categorical values.  I don't see any row
for the reference category.  How can I get this Z value in the output?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar 15 21:46:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 15 Mar 2016 13:46:27 -0700
Subject: [R] Logistic Regression output baseline (reference) category
In-Reply-To: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
References: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
Message-ID: <CAGxFJbTwkw_sQArv4dqq=oW8U2Q3dmervJLBFY3LQWCr=ziE9w@mail.gmail.com>

The reference category is aliased with the constant term in the
default contr.treatment contrasts.

See ?contr.treatment , ?C, ?contrasts

If you don't know what this means, you should probably consult a local
statistical resource or ask about linear model contrasts at a
statistical help website like stats.stackexchange.com. This list is
for R programming questions.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 15, 2016 at 1:27 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Hi,
>    I am trying to use the summary from the glm function as a data source. I
> am using the call sink(<some file>) then
> summary(logisticRegModel)$coefficients then sink().  The independent
> variables are categorical and thus there is always a baseline value for
> every category that is omitted from the glm output.  I am interested in how
> to get the Z column for all of the categorical values.  I don't see any row
> for the reference category.  How can I get this Z value in the output?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arbautjc at gmail.com  Tue Mar 15 22:00:03 2016
From: arbautjc at gmail.com (Jean-Claude Arbaut)
Date: Tue, 15 Mar 2016 22:00:03 +0100
Subject: [R] Truncated file upon reading a text file with 0xff characters
In-Reply-To: <56E86F9A.40201@gmail.com>
References: <CANufCk5D2yT1hb4kRLQPdk-PriuY67jACL7zWO_FJEBU96C2gQ@mail.gmail.com>
	<56E86F9A.40201@gmail.com>
Message-ID: <CANufCk5T0Mkcdag4uwQ3dExf1ZANhqXnkFHFoWrAnreK9bvYEQ@mail.gmail.com>

Thank you for the answer. I was about to ask why I should avoid text
connections, but actually I just noticed that with a binary connection
for the read, the problem disappears (I mean, I replace "rt" with "rb"
in the file open).
R is even clever enough that, when feeded the latin1 file after an
options(encoding="UTF-8") and no encoding in the readLines, it returns
correctly a string with encoding "unknown" and byte 0xff in the raw
representation (I would have expected at least a warning, but it
silently reads bad UTF-8 bytes as simply raw bytes, it seems)

Thus the text connection does something more that causes a problem.
Maybe it tries to translate characters twice?

And this problem remains with read.table. Not surprising: by
inspecting the source, I see it uses open(file "rt").

Jean-Claude Arbaut


2016-03-15 21:24 GMT+01:00 Duncan Murdoch <murdoch.duncan at gmail.com>:
> I think you've identified a bug (or more than one) here, but your message is
> so long, I haven't had time to go through it all.  I'd suggest that you
> write up a shorter version for the bug list.  The shorter version would
>
> 1.  Write the latin1 file using writeBin.
> 2.  Set options(encoding = "") and read it without error.
> 3.  Set options(encoding = "UTF-8") and get an error even if you explicitly
> set encoding when reading.
> 4.  Set options(encoding = "latin1") and also get an error with or without
> explicitly setting the encoding.
>
> I would limit the tests to readLines; read.table is much more complicated,
> and isn't necessary to illustrate the problem.  It just confuses things by
> bringing it into the discussion.
>
> You should also avoid bringing text mode connections into the discussion
> unless they are necessary.
>
> Duncan Murdoch
>
>
> On 15/03/2016 3:05 PM, Jean-Claude Arbaut wrote:
>>
>> Hello R users,
>>
>> I am having problems to read a CSV file that contains names with character
>> ?.
>> In case it doesn't print correctly, it's Unicode character 00FF or LATIN
>> SMALL
>> LETTER Y WITH DIAERESIS.
>> My computer has Windows 7 and R 3.2.4.
>>
>> Initially, I configured my computer to run options(encoding="UTF-8")
>> in my .Rprofile,
>> since I prefer this encoding, for portability. Good and modern
>> standard, I thought.
>> Rather than sending a large file, here is how to reproduce my problem:
>>
>>    options(encoding="UTF-8")
>>
>>    f <- file("test.txt", "wb")
>>    writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
>> f, size=1)
>>    close(f)
>>    read.table("test.txt", encoding="latin1")
>>    f <- file("test.txt", "rt")
>>    readLines(f, encoding="latin1")
>>    close(f)
>>
>> I write a file with three lines, in binary to avoid any translation:
>> A
>> B\xffC
>> D
>>
>> Upon reading I get only:
>>
>>    > read.table("test.txt", encoding="latin1")
>>      V1
>>    1  A
>>    2  B
>>    Warning messages:
>>    1: In read.table("test.txt", encoding = "latin1") :
>>      invalid input found on input connection 'test.txt'
>>    2: In read.table("test.txt", encoding = "latin1") :
>>      incomplete final line found by readTableHeader on 'test.txt'
>>    > readLines(f, encoding="latin1")
>>    [1] "A" "B"
>>    Warning messages:
>>    1: In readLines(f, encoding = "latin1") :
>>      invalid input found on input connection 'test.txt'
>>    2: In readLines(f, encoding = "latin1") :
>>      incomplete final line found on 'test.txt'
>>
>> Hence the file is truncated. However, character \xff is a valid latin1
>> character,
>> as one can check for instance at
>> https://en.wikipedia.org/wiki/ISO/IEC_8859-1
>> I tried with an UTF-8 version of this file:
>>
>>    f <- file("test.txt", "wb")
>>    writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
>> 10)), f, size=1)
>>    close(f)
>>    read.table("test.txt", encoding="UTF-8")
>>    f <- file("test.txt", "rt")
>>    readLines(f, encoding="UTF-8")
>>    close(f)
>>
>> Since this character ? is encoded as two bytes 195, 191 in UTF-8, I would
>> expect
>> that I get my complete file. But I don't. Instead, I get:
>>
>>    > read.table("test.txt", encoding="UTF-8")
>>      V1
>>    1  A
>>    2  B
>>    3  C
>>    4  D
>>    Warning message:
>>    In read.table("test.txt", encoding = "UTF-8") :
>>      incomplete final line found by readTableHeader on 'test.txt'
>>
>>    > readLines(f, encoding="UTF-8")
>>    [1] "A" "B"
>>    Warning message:
>>    In readLines(f, encoding = "UTF-8") :
>>      incomplete final line found on 'test.txt'
>>
>> I tried all the preceding but with options(encoding="latin1") at the
>> beginning.
>> For the first attempt, with byte 255, I get:
>>
>>    > read.table("test.txt", encoding="latin1")
>>      V1
>>    1  A
>>    2  B
>>    3  C
>>    4  D
>>    Warning message:
>>    In read.table("test.txt", encoding = "latin1") :
>>      incomplete final line found by readTableHeader on 'test.txt'
>>    >
>>    > f <- file("test.txt", "rt")
>>    > readLines(f, encoding="latin1")
>>
>> For the other attempt, with 195, 191:
>>
>>    > read.table("test.txt", encoding="UTF-8")
>>       V1
>>    1   A
>>    2 B?C
>>    3   D
>>    >
>>    > f <- file("test.txt", "rt")
>>    > readLines(f, encoding="UTF-8")
>>    [1] "A"   "B?C" "D"
>>    > close(f)
>>
>> Thus the second one does indeed work, it seems. Just a check:
>>
>>    > a <- read.table("test.txt", encoding="UTF-8")
>>    > Encoding(a$V1)
>>    [1] "unknown" "UTF-8"   "unknown"
>>
>> At last, I figured out that with the default encoding in R, both attempts
>> work,
>> with or without even giving the encoding as a parameter of read.table
>> or readLines.
>> However, I don't understand what happens:
>>
>>    f <- file("test.txt", "wb")
>>    writeBin(as.integer(c(65, 13, 10, 66, 255, 67, 13, 10, 68, 13, 10)),
>> f, size=1)
>>    close(f)
>>    a <- read.table("test.txt", encoding="latin1")$V1
>>    Encoding(a)
>>    iconv(a[2], toRaw=T)
>>    a
>>    a <- read.table("test.txt")$V1
>>    Encoding(a)
>>    iconv(a[2], toRaw=T)
>>    a
>>
>> This will yield:
>>
>>    > a <- read.table("test.txt", encoding="latin1")$V1
>>    > Encoding(a)
>>    [1] "unknown" "latin1"  "unknown"
>>    > iconv(a[2], toRaw=T)
>>    [[1]]
>>    [1] 42 ff 43
>>    > a
>>    [1] "A"   "B?C" "D"
>>    >
>>    > a <- read.table("test.txt")$V1
>>    > Encoding(a)
>>    [1] "unknown" "unknown" "unknown"
>>    > iconv(a[2], toRaw=T)
>>    [[1]]
>>    [1] 42 ff 43
>>    > a
>>    [1] "A"   "B?C" "D"
>>
>> The second line is correctly encoded, but the encoding is just not
>> "marked" in one case.
>> With the UTF-8 bytes:
>>
>>    f <- file("test.txt", "wb")
>>    writeBin(as.integer(c(65, 13, 10, 66, 195, 191, 67, 13, 10, 68, 13,
>> 10)), f, size=1)
>>    close(f)
>>    a <- read.table("test.txt", encoding="UTF-8")$V1
>>    Encoding(a)
>>    iconv(a[2], toRaw=T)
>>    a
>>    a <- read.table("test.txt")$V1
>>    Encoding(a)
>>    iconv(a[2], toRaw=T)
>>    a
>>
>> This will yield:
>>
>> > a <- read.table("test.txt", encoding="UTF-8")$V1
>> > Encoding(a)
>> [1] "unknown" "UTF-8"   "unknown"
>> > iconv(a[2], toRaw=T)
>> [[1]]
>> [1] 42 c3 bf 43
>> > a
>> [1] "A"   "B?C" "D"
>> > a <- read.table("test.txt")$V1
>> > Encoding(a)
>> [1] "unknown" "unknown" "unknown"
>> > iconv(a[2], toRaw=T)
>> [[1]]
>> [1] 42 c3 bf 43
>> > a
>> [1] "A"    "B??C" "D"
>>
>> Both are correctly read (the raw bytes are ok), but the second one doesn't
>> print
>> correctly because the encoding is not "marked".
>>
>> My thoughts:
>> With options(encoding="native.enc"), the characters read are not
>> translated, and are read
>> as raw bytes, which can get an encoding mark to print correctly (otherwise
>> it
>> prints as native, that is mostly latin1).
>> With options(encoding="latin1"), and reading the UTF-8 file, I guess it's
>> mostly
>> like the preceding: the characters are read as raw, and marked as
>> UTF-8, which works.
>> With options(encoding="latin1"), and reading the latin1 file (with the
>> 0xFF byte),
>> I don't understand what happens. The file gets truncated almost as if 0xFF
>> were
>> an EOF character - which is perplexing, since I think that in C, 0xFF
>> is sometimes
>> (wrongly) confused with EOF.
>> And with options(encoding="UTF-8"), I am not sure what happens.
>>
>> Questions:
>> * What's wrong with options(encoding="latin1")?
>> * Is it unsafe to use another option(encoding) than the default
>> native.enc, on Windows?
>> * Is it safe to assume that with native.enc R reads raw characters
>> and, only when requested,
>>    marks an encoding afterwards? (that is, I get "unknown" by default
>> which is printed
>>    as latin1 on Windows, and if I enforce another encoding, it will be
>> used whatever
>>    the bytes really are)
>> * What does really happen with another option(encoding), especially UTF-8?
>> * If I save a character variable to an Rdata file, is the file usable
>> on another OS,
>>    or on the same with another default encoding (by changing
>> options())? Does it depend
>>    whether the character string has un "unknown" encoding or an explicit
>> one?
>> * Is there a way (preferably an options()) to tell R to read text
>> files as UTF-8 by default?
>>    Would it work with any one of read.table(), readLines(), or even
>> source()?
>>    I thought options(encoding="UTF-8") would do, but it fails on the
>> examples above.
>>
>> Best regards,
>>
>> Jean-Claude Arbaut
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Wed Mar 16 02:26:21 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Mar 2016 18:26:21 -0700
Subject: [R] Logistic Regression output baseline (reference) category
In-Reply-To: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
References: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
Message-ID: <03171E24-6856-4E97-A218-1639F299BCF5@comcast.net>


> On Mar 15, 2016, at 1:27 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> 
> Hi,
>   I am trying to use the summary from the glm function as a data source. I
> am using the call sink(<some file>) then
> summary(logisticRegModel)$coefficients then sink().

Since it's a matrix you may need to locate a function that write matrices to files. I seem to remember that the MASS package has one. 

>  The independent
> variables are categorical and thus there is always a baseline value for
> every category that is omitted from the glm output.

Well, it's not really omitted, so much as shared among all variables. For further reading in the halp pages consult:

?model.matrix
?contrasts
?contr.treatment

But you probably need to supplement that with an introductory text that covers R regression defaults.

>  I am interested in how
> to get the Z column for all of the categorical values.

The Z column? You meant the "z value" column. Again, since it's a matrix you need to use column indexing with "["

summary(logisticRegModel)$coefficients[  , "z value"]

Read up on the summary function for glm objects at:

?summary.glm


>  I don't see any row
> for the reference category.

What do you imagine the (Intercept) row to be doing? If you are having difficulty understanding this (which is not really an R-specific issue) there are probably already several explanations to similar questions on:

http://stats.stackexchange.com/

 
> 
> How can I get this Z value in the output?

Asked and answered.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cindy.guo3 at gmail.com  Wed Mar 16 02:58:14 2016
From: cindy.guo3 at gmail.com (cindy Guo)
Date: Tue, 15 Mar 2016 20:58:14 -0500
Subject: [R] pls package
Message-ID: <CAA7sLQn8SGDDHPfTLs_15N4sM9FPmLP3QCgMnNEWgnioZOjRhA@mail.gmail.com>

Hi All,

I am using the cppls function in the pls package, and I want to use cross
validation to determine the best number of components. Since Hastie et al
recommended a "one standard error rule", i.e., choose the most parsimonious
model whose error is no more than one standard error above
the error of the best model, I am wondering how I can get the standard
error of misclassification rate from pls package?

Thank you,
Cindy

	[[alternative HTML version deleted]]


From reichmanj at sbcglobal.net  Wed Mar 16 00:14:25 2016
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Tue, 15 Mar 2016 18:14:25 -0500
Subject: [R] Circular Statistic in R
Message-ID: <000201d17f10$6d7b5aa0$48720fe0$@sbcglobal.net>

R-Help

 

Is it preferable to work in Radians or Degrees when performing circular
statistics.  I'm assuming radians because I'm running into problems in
Degrees.

 

Jeff


	[[alternative HTML version deleted]]


From pmiksza at indiana.edu  Wed Mar 16 01:46:03 2016
From: pmiksza at indiana.edu (Miksza, Peter John)
Date: Wed, 16 Mar 2016 00:46:03 +0000
Subject: [R] Trouble plotting interaction with brkdn.plot from plotrix
	package
Message-ID: <0E1281D5-C52D-47A9-955F-4B9791946B4F@indiana.edu>

Hello,

I'm exploring different ways to plot interactions for mixed-design ANOVA and am having difficulty getting the brkdn.plot() function in the R plotrix package to work.

The interaction.plot() is working fine, but I'd really like to be able to customize the plot more as the brkdn.plot() function seems to be able to do.

Any help pointing out my error(s) would be much appreciated.

Pete Miksza

IU Jacobs School of Music, Bloomington, IN

Here is an example of my code:

set.seed(1976)
Y = rnorm(1600, 5, 2)
A = c(rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200))
B = c(rep(1, 400), rep(2, 400), rep(3, 400), rep(4, 400))
A = factor(A, levels = c(1, 2), labels = c("Treat", "Control"))
B = factor(B, levels = c(1, 2, 3, 4), labels = c("One", "Two", "Three", "Four"))
dat = data.frame(Y, A, B)
str(dat)

# I can't figure out why this doesn't work
library(plotrix)
brkdn.plot("dat$Y", "dat$B", "dat$A", data = dat)

# this works
interaction.plot(dat$B, dat$A, dat$Y, fun = mean)

	[[alternative HTML version deleted]]


From pmiksza at indiana.edu  Wed Mar 16 02:13:22 2016
From: pmiksza at indiana.edu (Miksza, Peter John)
Date: Wed, 16 Mar 2016 01:13:22 +0000
Subject: [R] Trouble plotting interaction with brkdn.plot from plotrix
	package
Message-ID: <2BF471C1-855A-4430-8A3B-9840A2117060@indiana.edu>

Hello,

I'm exploring different ways to plot interactions for mixed-design ANOVA and am having difficulty getting the brkdn.plot() function in the R plotrix package to work.

The interaction.plot() is working fine, but I'd really like to be able to customize the plot more as the brkdn.plot() function seems to be able to do.

Any help pointing out my error(s) would be much appreciated.

Pete Miksza

IU Jacobs School of Music, Bloomington, IN

Here is an example of my code:

set.seed(1976)
Y = rnorm(1600, 5, 2)
A = c(rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200))
B = c(rep(1, 400), rep(2, 400), rep(3, 400), rep(4, 400))
A = factor(A, levels = c(1, 2), labels = c("Treat", "Control"))
B = factor(B, levels = c(1, 2, 3, 4), labels = c("One", "Two", "Three", "Four"))
dat = data.frame(Y, A, B)
str(dat)

# I can't figure out why this doesn't work
library(plotrix)
brkdn.plot("dat$Y", "dat$B", "dat$A", data = dat)

# this works
interaction.plot(dat$B, dat$A, dat$Y, fun = mean)

	[[alternative HTML version deleted]]


From fosu77 at gmail.com  Wed Mar 16 04:28:27 2016
From: fosu77 at gmail.com (Kwabena Fosu-Amankwah)
Date: Wed, 16 Mar 2016 03:28:27 +0000
Subject: [R] Time series plot with Date/Time showing on x-axis
Message-ID: <CAA0akYzSX4YvZmH8gvGxj1Pv+0csfUMrucE=JrGEGA6d8zwZbg@mail.gmail.com>

I would be very grateful if someone can help me with the code or
script on how to plot a time series plot with Date/Time showing on
x-axis for the set of data below:

Date/Time PR     SW TP  SM SHF CO2
28.11.2011 17:39:49 978.4 13.15 30.5 20 NA NA
28.11.2011 17:50:00 978.5 13.11 30.4 20 NA NA
28.11.2011 18:00:00 978.8 13.14 30.3 20 NA NA
28.11.2011 18:10:00 979 13.07 30.1 20 NA NA
28.11.2011 18:20:00 979.2 13.1 30 20 NA NA
28.11.2011 18:30:00 979.4 13.09 29.8 20 NA NA
28.11.2011 18:40:00 979.5 13.08 29.6 20 NA NA
28.11.2011 18:50:00 979.5 13.06 29.5 20 NA NA
28.11.2011 19:00:00 979.6 13.06 29.4 20 NA NA
28.11.2011 19:10:00 979.7 13.05 29.3 20 NA NA
28.11.2011 19:20:00 979.9 13.03 29.2 20 NA NA
28.11.2011 19:30:00 980 13 29.1 20 NA NA
28.11.2011 19:40:00 980 13.03 29 20 NA NA
28.11.2011 19:50:00 980.1 13.03 28.9 20 NA NA
28.11.2011 20:00:00 980.3 13      28.8 20 NA NA
28.11.2011 20:10:00 980.5 12.97 28.7 20 NA NA
28.11.2011 20:20:00 980.8 12.96 28.6 20 NA NA
28.11.2011 20:30:00 981.1 12.95 28.5 20 NA NA
28.11.2011 20:40:00 981.1 12.95 28.4 20 NA NA
28.11.2011 20:50:00 981.2 12.94 28.3 20 NA NA
28.11.2011 21:00:00 981.3 12.93 28.2 20 NA NA
28.11.2011 21:10:00 981.3 12.92 28.1 20 NA NA
28.11.2011 21:20:00 981.5 12.9 28 20 NA NA
28.11.2011 21:30:00 981.6 12.9    27.9 20 NA NA
28.11.2011 21:40:00 981.7 12.88 27.9 20 NA NA
28.11.2011 21:50:00 981.7 12.87 27.8 20 NA NA
28.11.2011 22:00:00 981.7 12.86 27.7 20 NA NA
28.11.2011 22:10:00 981.8 12.85 27.6 20 NA NA
28.11.2011 22:20:00 981.8 12.84 27.5 20 NA NA
28.11.2011 22:30:00 981.8 12.83 27.5 20 NA NA

Thank you

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Mar 16 07:08:02 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 16 Mar 2016 06:08:02 +0000
Subject: [R] Time series plot with Date/Time showing on x-axis
In-Reply-To: <CAA0akYzSX4YvZmH8gvGxj1Pv+0csfUMrucE=JrGEGA6d8zwZbg@mail.gmail.com>
References: <CAA0akYzSX4YvZmH8gvGxj1Pv+0csfUMrucE=JrGEGA6d8zwZbg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014605@SRVEXCHMBX.precheza.cz>

Hi

From your data is not clear if your first column is in POSOX format or character/factor. You can check it by

?str

If it is POSIX, what is wrong in

with(yourdata, plot(Date/Time, SW))

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kwabena
> Fosu-Amankwah
> Sent: Wednesday, March 16, 2016 4:28 AM
> To: r-help at r-project.org
> Subject: [R] Time series plot with Date/Time showing on x-axis
>
> I would be very grateful if someone can help me with the code or script
> on how to plot a time series plot with Date/Time showing on x-axis for
> the set of data below:
>
> Date/Time PR     SW TP  SM SHF CO2
> 28.11.2011 17:39:49 978.4 13.15 30.5 20 NA NA
> 28.11.2011 17:50:00 978.5 13.11 30.4 20 NA NA
> 28.11.2011 18:00:00 978.8 13.14 30.3 20 NA NA
> 28.11.2011 18:10:00 979 13.07 30.1 20 NA NA
> 28.11.2011 18:20:00 979.2 13.1 30 20 NA NA
> 28.11.2011 18:30:00 979.4 13.09 29.8 20 NA NA
> 28.11.2011 18:40:00 979.5 13.08 29.6 20 NA NA
> 28.11.2011 18:50:00 979.5 13.06 29.5 20 NA NA
> 28.11.2011 19:00:00 979.6 13.06 29.4 20 NA NA
> 28.11.2011 19:10:00 979.7 13.05 29.3 20 NA NA
> 28.11.2011 19:20:00 979.9 13.03 29.2 20 NA NA
> 28.11.2011 19:30:00 980 13 29.1 20 NA NA
> 28.11.2011 19:40:00 980 13.03 29 20 NA NA
> 28.11.2011 19:50:00 980.1 13.03 28.9 20 NA NA
> 28.11.2011 20:00:00 980.3 13      28.8 20 NA NA
> 28.11.2011 20:10:00 980.5 12.97 28.7 20 NA NA
> 28.11.2011 20:20:00 980.8 12.96 28.6 20 NA NA
> 28.11.2011 20:30:00 981.1 12.95 28.5 20 NA NA
> 28.11.2011 20:40:00 981.1 12.95 28.4 20 NA NA
> 28.11.2011 20:50:00 981.2 12.94 28.3 20 NA NA
> 28.11.2011 21:00:00 981.3 12.93 28.2 20 NA NA
> 28.11.2011 21:10:00 981.3 12.92 28.1 20 NA NA
> 28.11.2011 21:20:00 981.5 12.9 28 20 NA NA
> 28.11.2011 21:30:00 981.6 12.9    27.9 20 NA NA
> 28.11.2011 21:40:00 981.7 12.88 27.9 20 NA NA
> 28.11.2011 21:50:00 981.7 12.87 27.8 20 NA NA
> 28.11.2011 22:00:00 981.7 12.86 27.7 20 NA NA
> 28.11.2011 22:10:00 981.8 12.85 27.6 20 NA NA
> 28.11.2011 22:20:00 981.8 12.84 27.5 20 NA NA
> 28.11.2011 22:30:00 981.8 12.83 27.5 20 NA NA
>
> Thank you
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Mar 16 07:16:08 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 16 Mar 2016 06:16:08 +0000
Subject: [R] Trouble plotting interaction with brkdn.plot from
	plotrix	package
In-Reply-To: <0E1281D5-C52D-47A9-955F-4B9791946B4F@indiana.edu>
References: <0E1281D5-C52D-47A9-955F-4B9791946B4F@indiana.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014617@SRVEXCHMBX.precheza.cz>

Hi

Thanks for providing working example.

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miksza,
> Peter John
> Sent: Wednesday, March 16, 2016 1:46 AM
> To: r-help at r-project.org
> Subject: [R] Trouble plotting interaction with brkdn.plot from plotrix
> package
>
> Hello,
>
> I'm exploring different ways to plot interactions for mixed-design
> ANOVA and am having difficulty getting the brkdn.plot() function in the
> R plotrix package to work.
>
> The interaction.plot() is working fine, but I'd really like to be able
> to customize the plot more as the brkdn.plot() function seems to be
> able to do.
>
> Any help pointing out my error(s) would be much appreciated.
>
> Pete Miksza
>
> IU Jacobs School of Music, Bloomington, IN
>
> Here is an example of my code:
>
> set.seed(1976)
> Y = rnorm(1600, 5, 2)
> A = c(rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200),
> rep(2, 200), rep(1, 200), rep(2, 200))
> B = c(rep(1, 400), rep(2, 400), rep(3, 400), rep(4, 400))
> A = factor(A, levels = c(1, 2), labels = c("Treat", "Control"))
> B = factor(B, levels = c(1, 2, 3, 4), labels = c("One", "Two", "Three",
> "Four"))
> dat = data.frame(Y, A, B)
> str(dat)
>
> # I can't figure out why this doesn't work
> library(plotrix)
> brkdn.plot("dat$Y", "dat$B", "dat$A", data = dat)

You shall call only variable names not data frame itself.

brkdn.plot("Y", "B", "A", data = dat)
brkdn.plot(Y~B+A, data = dat)

works

Cheers
Petr

>
> # this works
> interaction.plot(dat$B, dat$A, dat$Y, fun = mean)
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Wed Mar 16 09:27:03 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 16 Mar 2016 19:27:03 +1100
Subject: [R] Time series plot with Date/Time showing on x-axis
In-Reply-To: <CAA0akYzSX4YvZmH8gvGxj1Pv+0csfUMrucE=JrGEGA6d8zwZbg@mail.gmail.com>
References: <CAA0akYzSX4YvZmH8gvGxj1Pv+0csfUMrucE=JrGEGA6d8zwZbg@mail.gmail.com>
Message-ID: <CA+8X3fXSs5hGe8nytN7e8b=QzmwgBdDDGmcC3TaA10VWUg=czw@mail.gmail.com>

Hi Kwabena,
Try this:

kfa.df<-read.table(text="Date/Time,PR,SW,TP,SM,SHF,CO2
28.11.2011 17:39:49,978.4,13.15,30.5,20,NA,NA
28.11.2011 17:50:00,978.5,13.11,30.4,20,NA,NA
28.11.2011 18:00:00,978.8,13.14,30.3,20,NA,NA
28.11.2011 18:10:00,979,13.07,30.1,20,NA,NA
28.11.2011 18:20:00,979.2,13.1,30,20,NA,NA
28.11.2011 18:30:00,979.4,13.09,29.8,20,NA,NA
28.11.2011 18:40:00,979.5,13.08,29.6,20,NA,NA
28.11.2011 18:50:00,979.5,13.06,29.5,20,NA,NA
28.11.2011 19:00:00,979.6,13.06,29.4,20,NA,NA
28.11.2011 19:10:00,979.7,13.05,29.3,20,NA,NA
28.11.2011 19:20:00,979.9,13.03,29.2,20,NA,NA
28.11.2011 19:30:00,980,13,29.1,20,NA,NA
28.11.2011 19:40:00,980,13.03,29,20,NA,NA
28.11.2011 19:50:00,980.1,13.03,28.9,20,NA,NA
28.11.2011 20:00:00,980.3,13,28.8,20,NA,NA
28.11.2011 20:10:00,980.5,12.97,28.7,20,NA,NA
28.11.2011 20:20:00,980.8,12.96,28.6,20,NA,NA
28.11.2011 20:30:00,981.1,12.95,28.5,20,NA,NA
28.11.2011 20:40:00,981.1,12.95,28.4,20,NA,NA
28.11.2011 20:50:00,981.2,12.94,28.3,20,NA,NA
28.11.2011 21:00:00,981.3,12.93,28.2,20,NA,NA
28.11.2011 21:10:00,981.3,12.92,28.1,20,NA,NA
28.11.2011 21:20:00,981.5,12.9,28,20,NA,NA
28.11.2011 21:30:00,981.6,12.9,27.9,20,NA,NA
28.11.2011 21:40:00,981.7,12.88,27.9,20,NA,NA
28.11.2011 21:50:00,981.7,12.87,27.8,20,NA,NA
28.11.2011 22:00:00,981.7,12.86,27.7,20,NA,NA
28.11.2011 22:10:00,981.8,12.85,27.6,20,NA,NA
28.11.2011 22:20:00,981.8,12.84,27.5,20,NA,NA
28.11.2011 22:30:00,981.8,12.83,27.5,20,NA,NA",
sep=",",header=TRUE,stringsAsFactors=FALSE)
kfa.df$Date.Time<-strptime(kfa.df$Date.Time,"%d.%m.%Y %H:%M:%S")
library(plotrix)
plot(kfa.df$Date.Time,kfa.df$PR,xaxt="n")
xticklab<-pretty(kfa.df$Date.Time)
staxlab(1,at=xticklab)

Jim


On Wed, Mar 16, 2016 at 2:28 PM, Kwabena Fosu-Amankwah <fosu77 at gmail.com> wrote:
> I would be very grateful if someone can help me with the code or
> script on how to plot a time series plot with Date/Time showing on
> x-axis for the set of data below:
>
> Date/Time PR     SW TP  SM SHF CO2
> 28.11.2011 17:39:49 978.4 13.15 30.5 20 NA NA
> 28.11.2011 17:50:00 978.5 13.11 30.4 20 NA NA
> 28.11.2011 18:00:00 978.8 13.14 30.3 20 NA NA
> 28.11.2011 18:10:00 979 13.07 30.1 20 NA NA
> 28.11.2011 18:20:00 979.2 13.1 30 20 NA NA
> 28.11.2011 18:30:00 979.4 13.09 29.8 20 NA NA
> 28.11.2011 18:40:00 979.5 13.08 29.6 20 NA NA
> 28.11.2011 18:50:00 979.5 13.06 29.5 20 NA NA
> 28.11.2011 19:00:00 979.6 13.06 29.4 20 NA NA
> 28.11.2011 19:10:00 979.7 13.05 29.3 20 NA NA
> 28.11.2011 19:20:00 979.9 13.03 29.2 20 NA NA
> 28.11.2011 19:30:00 980 13 29.1 20 NA NA
> 28.11.2011 19:40:00 980 13.03 29 20 NA NA
> 28.11.2011 19:50:00 980.1 13.03 28.9 20 NA NA
> 28.11.2011 20:00:00 980.3 13      28.8 20 NA NA
> 28.11.2011 20:10:00 980.5 12.97 28.7 20 NA NA
> 28.11.2011 20:20:00 980.8 12.96 28.6 20 NA NA
> 28.11.2011 20:30:00 981.1 12.95 28.5 20 NA NA
> 28.11.2011 20:40:00 981.1 12.95 28.4 20 NA NA
> 28.11.2011 20:50:00 981.2 12.94 28.3 20 NA NA
> 28.11.2011 21:00:00 981.3 12.93 28.2 20 NA NA
> 28.11.2011 21:10:00 981.3 12.92 28.1 20 NA NA
> 28.11.2011 21:20:00 981.5 12.9 28 20 NA NA
> 28.11.2011 21:30:00 981.6 12.9    27.9 20 NA NA
> 28.11.2011 21:40:00 981.7 12.88 27.9 20 NA NA
> 28.11.2011 21:50:00 981.7 12.87 27.8 20 NA NA
> 28.11.2011 22:00:00 981.7 12.86 27.7 20 NA NA
> 28.11.2011 22:10:00 981.8 12.85 27.6 20 NA NA
> 28.11.2011 22:20:00 981.8 12.84 27.5 20 NA NA
> 28.11.2011 22:30:00 981.8 12.83 27.5 20 NA NA
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Wed Mar 16 14:10:08 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 16 Mar 2016 13:10:08 +0000
Subject: [R] About calculation of the gravity model in R and STATA
 software
In-Reply-To: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>
References: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D12003D3@GBTEDVPEXCMB04.corp.lgc-group.com>

> As you can see, model coefficients (second column in the results table) are the
> same at least until the 4th mark (!) However, other results (columns in the
> table of results, since the third) is not the same.
> Could you explain differences in the results?

R and stata are clearly doing different things.
Look up how stata calculates its standard errors (which I note are described as '_robust_ ') and compare that with the documentation for the R function.
Without knowing anything about stata or your data set, my guess would be that R's quasibinomial family is allowing for overdispersion and stata is not.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From pdalgd at gmail.com  Wed Mar 16 14:41:27 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Mar 2016 14:41:27 +0100
Subject: [R] About calculation of the gravity model in R and STATA
	software
In-Reply-To: <1A8C1289955EF649A09086A153E2672403D12003D3@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAM9wezog6OXp3yJ7fgok7W_-yu3wAdTd+v9CU=ebSu8g3_Os3w@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403D12003D3@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <F7AC4DB8-25D9-4750-8EA4-B07CCD5288F8@gmail.com>


On 16 Mar 2016, at 14:10 , S Ellison <S.Ellison at LGCGroup.com> wrote:

>> As you can see, model coefficients (second column in the results table) are the
>> same at least until the 4th mark (!) However, other results (columns in the
>> table of results, since the third) is not the same.
>> Could you explain differences in the results?
> 
> R and stata are clearly doing different things.
> Look up how stata calculates its standard errors (which I note are described as '_robust_ ') and compare that with the documentation for the R function.
> Without knowing anything about stata or your data set, my guess would be that R's quasibinomial family is allowing for overdispersion and stata is not.
> 
> S Ellison

With a dispersion parameter of 2100, that would be rather more of a dramatic difference....

More likely, STATA is using some sort of sandwich estimator whereas R is just upscaling the results for a Poisson regression. You might want to check out package "sandwich".

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Wed Mar 16 15:03:28 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 16 Mar 2016 14:03:28 +0000
Subject: [R] Circular Statistic in R
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7247EC@mb02.ads.tamu.edu>

It is always hard to diagnose unspecified "problems", but it should not matter. You do need to use statistical methods specifically designed for circular data. Even simple descriptive statistics such as the mean, standard deviation, and variance require special functions. Try package circular.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Reichman
Sent: Tuesday, March 15, 2016 6:14 PM
To: r-help at r-project.org
Subject: [R] Circular Statistic in R

R-Help



Is it preferable to work in Radians or Degrees when performing circular
statistics.  I'm assuming radians because I'm running into problems in
Degrees.



Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From from.d.putto at gmail.com  Wed Mar 16 16:38:48 2016
From: from.d.putto at gmail.com (Sheila the angel)
Date: Wed, 16 Mar 2016 16:38:48 +0100
Subject: [R] merge small clusters in R
Message-ID: <CAFinXcQ0vi2pCco6POgkAROhKBmmGbxSUSxsw=sBOi5QKfUmEg@mail.gmail.com>

In R, I have cut a dendrogram into clusters. However some of the clusters
have only few samples. How can I merge the small clusters with nearest big
cuter.

hc <- hclust(dist(USArrests))
plot(hc, cex = 0.6)
rect.hclust(hc, k = 4, border = 2:5)

It gives one cluster with only 2 samples. How can I merge it with nearest
cluster?

Thanks
S.

	[[alternative HTML version deleted]]


From from.d.putto at gmail.com  Wed Mar 16 16:45:13 2016
From: from.d.putto at gmail.com (Sheila the angel)
Date: Wed, 16 Mar 2016 16:45:13 +0100
Subject: [R] (no subject)
In-Reply-To: <CAHMZzY=JjhPtBS12b1BvMKX+dTxRPF96sxq32q6vr5Q14tRZOQ@mail.gmail.com>
References: <CAHMZzY=JjhPtBS12b1BvMKX+dTxRPF96sxq32q6vr5Q14tRZOQ@mail.gmail.com>
Message-ID: <CAFinXcRQjtrzHkG5XXC_3dSa=vM7PpkXMDukV_hD4gHcsPimgw@mail.gmail.com>

Have you tried

install.packages("pbkrtest")



On 13 March 2016 at 17:56, Sudhansu Senapati <senapati53 at gmail.com> wrote:

> I have loaded "caret" package to my R successfully with dependencies=TRUE.
> But when I go to library(caret), some namespaces are not loaded.
> > library(caret)
> Loading required package: lattice
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?pbkrtest?
> In addition: Warning messages:
> 1: package ?caret? was built under R version 3.2.4 Please
> 2: package ?lattice? was built under R version 3.2.3
> 3: package ?ggplot2? was built under R version 3.2.3
> Error: package or namespace load failed for ?caret?
>
> please guide me.
> Sudhansu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From lid.zigh at gmail.com  Wed Mar 16 16:59:13 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Wed, 16 Mar 2016 10:59:13 -0500
Subject: [R] How to reach the column names in a huge .RData file without
	loading it
Message-ID: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>

Hi,
I have a huge .RData file and I need just to get the colnames of it. so is
there any way to reach the column names without loading or reading the
whole file?
Since the file is so big and I need to repeat this process several times,
so it takes so long to load the file first and then take the colnames!

Thanks

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed Mar 16 17:13:14 2016
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 16 Mar 2016 19:13:14 +0300
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
References: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
Message-ID: <CAGh51gSDMvpyU09hU5oUzSJaht0mdUFCpVMPwNVhEz+U-Ln1ug@mail.gmail.com>

I am not sure whether it is possible to get a column name from a dataset
without reading the data.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=oa-2115-c>
Checked
by Avast Antivirus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=oa-2115-c>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Wed, Mar 16, 2016 at 6:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:

> Hi,
> I have a huge .RData file and I need just to get the colnames of it. so is
> there any way to reach the column names without loading or reading the
> whole file?
> Since the file is so big and I need to repeat this process several times,
> so it takes so long to load the file first and then take the colnames!
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar 16 17:52:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 16 Mar 2016 09:52:31 -0700
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
References: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
Message-ID: <CAGxFJbTzFuOY1J0kiFiwGwwfAaZ_U2642POdHVwfSrtFtHyo2Q@mail.gmail.com>

Is it really a .Rdata file? If so, the answer is no, AFAIK, since
.Rdata files are serialized (binary) versions of e.g. worksheets that
can contain many different data objects. "colnames" has no meaning in
this context.

Corrections welcome if I have it wrong!

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 16, 2016 at 8:59 AM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> Hi,
> I have a huge .RData file and I need just to get the colnames of it. so is
> there any way to reach the column names without loading or reading the
> whole file?
> Since the file is so big and I need to repeat this process several times,
> so it takes so long to load the file first and then take the colnames!
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yogesh.mpi at googlemail.com  Wed Mar 16 10:20:49 2016
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Wed, 16 Mar 2016 14:50:49 +0530
Subject: [R] how to calculate spatial correlation between two data sets
Message-ID: <CABShME0OJqUXCdy4M7Fy0gVH3VxjVLjYtiFk2q-TRc0qNzwT+g@mail.gmail.com>

Dear R Users,

I am using R on Windows.

1) How to calculate spatial correlation between point observation at one
location and model simulated data over some particular region. For example,
observation is at only one location 18N, 72 E and model is at 0.5x0.5 grid.
So how to calculate correlation between every grid of model (over the
region 50:100E, 10S:40N) and this point observation at 18N, 72 E. Model
data is in netcdf format and observation is in text format. I would like to
save output fine in netcdf format. We have extracted model data as same day
as observation.

2) Its similar to above but, how to calculate spatial correlation between
 two model simulated data (i.e. grid to grid correlation over the
region50:100E, 10S:40N). One model has 0.25x0.25 and other is has 0.5x0.5
horizontal resolution.  I would like to save output fine in netcdf format

Great Thanks,

Best regards,
Yogesh


-- 
Yogesh K. Tiwari (Dr.rer.nat),
Scientist,
Centre for Climate Change Research,
Indian Institute of Tropical Meteorology,
Homi Bhabha Road,
Pashan,
Pune

	[[alternative HTML version deleted]]


From pmiksza at indiana.edu  Wed Mar 16 11:54:36 2016
From: pmiksza at indiana.edu (Miksza, Peter John)
Date: Wed, 16 Mar 2016 10:54:36 +0000
Subject: [R] Trouble plotting interaction with brkdn.plot from
	plotrix	package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014617@SRVEXCHMBX.precheza.cz>
References: <0E1281D5-C52D-47A9-955F-4B9791946B4F@indiana.edu>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014617@SRVEXCHMBX.precheza.cz>
Message-ID: <154285E3-647D-414A-AF9C-76B76B27801B@indiana.edu>

Thank you very much!

Pete

> On Mar 16, 2016, at 2:16 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> Thanks for providing working example.
> 
> See in line
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Miksza,
>> Peter John
>> Sent: Wednesday, March 16, 2016 1:46 AM
>> To: r-help at r-project.org
>> Subject: [R] Trouble plotting interaction with brkdn.plot from plotrix
>> package
>> 
>> Hello,
>> 
>> I'm exploring different ways to plot interactions for mixed-design
>> ANOVA and am having difficulty getting the brkdn.plot() function in the
>> R plotrix package to work.
>> 
>> The interaction.plot() is working fine, but I'd really like to be able
>> to customize the plot more as the brkdn.plot() function seems to be
>> able to do.
>> 
>> Any help pointing out my error(s) would be much appreciated.
>> 
>> Pete Miksza
>> 
>> IU Jacobs School of Music, Bloomington, IN
>> 
>> Here is an example of my code:
>> 
>> set.seed(1976)
>> Y = rnorm(1600, 5, 2)
>> A = c(rep(1, 200), rep(2, 200), rep(1, 200), rep(2, 200), rep(1, 200),
>> rep(2, 200), rep(1, 200), rep(2, 200))
>> B = c(rep(1, 400), rep(2, 400), rep(3, 400), rep(4, 400))
>> A = factor(A, levels = c(1, 2), labels = c("Treat", "Control"))
>> B = factor(B, levels = c(1, 2, 3, 4), labels = c("One", "Two", "Three",
>> "Four"))
>> dat = data.frame(Y, A, B)
>> str(dat)
>> 
>> # I can't figure out why this doesn't work
>> library(plotrix)
>> brkdn.plot("dat$Y", "dat$B", "dat$A", data = dat)
> 
> You shall call only variable names not data frame itself.
> 
> brkdn.plot("Y", "B", "A", data = dat)
> brkdn.plot(Y~B+A, data = dat)
> 
> works
> 
> Cheers
> Petr
> 
>> 
>> # this works
>> interaction.plot(dat$B, dat$A, dat$Y, fun = mean)
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From lid.zigh at gmail.com  Wed Mar 16 17:59:36 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Wed, 16 Mar 2016 11:59:36 -0500
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <CAGxFJbTzFuOY1J0kiFiwGwwfAaZ_U2642POdHVwfSrtFtHyo2Q@mail.gmail.com>
References: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
	<CAGxFJbTzFuOY1J0kiFiwGwwfAaZ_U2642POdHVwfSrtFtHyo2Q@mail.gmail.com>
Message-ID: <CAMqbV1Ao4w9wAi09GVO352+vt7vfz3oiL0vEgKLgvd9NtF5gew@mail.gmail.com>

Thank you Bert and Frederic.

On Wed, Mar 16, 2016 at 11:52 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Is it really a .Rdata file? If so, the answer is no, AFAIK, since
> .Rdata files are serialized (binary) versions of e.g. worksheets that
> can contain many different data objects. "colnames" has no meaning in
> this context.
>
> Corrections welcome if I have it wrong!
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 16, 2016 at 8:59 AM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> > Hi,
> > I have a huge .RData file and I need just to get the colnames of it. so
> is
> > there any way to reach the column names without loading or reading the
> > whole file?
> > Since the file is so big and I need to repeat this process several times,
> > so it takes so long to load the file first and then take the colnames!
> >
> > Thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Wed Mar 16 18:17:25 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 16 Mar 2016 17:17:25 +0000
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
Message-ID: <CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>

You *might* be able to get them from the raw file...

First, I don't quite know what "colnames" of an .RData file means.
"colnames" are the column names of a matrix (or data frame), so I'll
assume your .RData file contains exactly one data frame and you want
to column names of it.

So let's create one of those:


mydataframe = data.frame(mylongnamehere=runif(3),
anotherlongname=runif(3), z=runif(3), y=runif(3),
aasdkjhasdkjhaskdj=runif(3))
save(mydataframe, file="./test.RData")

Now I'm going to use some Unix utilities to see if there's any
identifiable strings in the file. .RData files are by default
compressed using `gzip`, so I'll `gunzip` them and pipe it into
`strings`:

$ gunzip -c test.RData | strings -t d
      0 RDX2
     35 mydataframe
    230 names
    251 mylongnamehere
    273 anotherlongname
    314 aasdkjhasdkjhaskdj
    347     row.names
    389 class
    410 data.frame


  - thats found the object name (mydataframe) and most of the column
names except the short ones, which are too short for `strings` to
recognise. But if your names are long enough (4 or more chars, I
think) they'll show up.

 Of course you'll have to filter them out from all the other string
output, but they should all appear shortly after the word "names",
since the colnames of a data frame are the "names" attribute of the
data.

 If you don't have a Unix or Mac machine handy you can get these
utilities on Windows via Cygwin but that's another story...

 Barry








On Wed, Mar 16, 2016 at 3:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> Hi,
> I have a huge .RData file and I need just to get the colnames of it. so is
> there any way to reach the column names without loading or reading the
> whole file?
> Since the file is so big and I need to repeat this process several times,
> so it takes so long to load the file first and then take the colnames!
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Mar 16 18:38:40 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 16 Mar 2016 13:38:40 -0400
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
	<CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
Message-ID: <CAGx1TMB3AWqaSuXjz_yoyj+fpSGxbqfjCdVpQUgUoVpytr-P6A@mail.gmail.com>

Barry's solution works with Windows without cygwin.
You do need Rtools, available from the Windows page on CRAN

Rtools does not have "gunzip", but that is just an abbreviation for "gzip -d".

x:\HOME\rmh\HH-R.package>path
path
PATH=c:\Progra~2\Rtools\bin;c:\Progra~2\Rtools\gcc-4.6.3\bin;c:\progra~1\R\R-3.2.3\bin\x64;c:\Progra~1\MikTeX~1.9\miktex\bin\x64;c:\windows;c:\windows\system32

x:\HOME\rmh\HH-R.package>gzip -d -c
c:\Users\rmh.DESKTOP-60G4CCO\test.RData | strings -t d
gzip -d -c c:\Users\rmh.DESKTOP-60G4CCO\test.RData | strings -t d
      0 RDX2
     35 mydataframe
    230 names
    251 mylongnamehere
    273 anotherlongname
    314 aasdkjhasdkjhaskdj
    347 row.names
    389 class
    410 data.frame

On Wed, Mar 16, 2016 at 1:17 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> You *might* be able to get them from the raw file...
>
> First, I don't quite know what "colnames" of an .RData file means.
> "colnames" are the column names of a matrix (or data frame), so I'll
> assume your .RData file contains exactly one data frame and you want
> to column names of it.
>
> So let's create one of those:
>
>
> mydataframe = data.frame(mylongnamehere=runif(3),
> anotherlongname=runif(3), z=runif(3), y=runif(3),
> aasdkjhasdkjhaskdj=runif(3))
> save(mydataframe, file="./test.RData")
>
> Now I'm going to use some Unix utilities to see if there's any
> identifiable strings in the file. .RData files are by default
> compressed using `gzip`, so I'll `gunzip` them and pipe it into
> `strings`:
>
> $ gunzip -c test.RData | strings -t d
>       0 RDX2
>      35 mydataframe
>     230 names
>     251 mylongnamehere
>     273 anotherlongname
>     314 aasdkjhasdkjhaskdj
>     347     row.names
>     389 class
>     410 data.frame
>
>
>   - thats found the object name (mydataframe) and most of the column
> names except the short ones, which are too short for `strings` to
> recognise. But if your names are long enough (4 or more chars, I
> think) they'll show up.
>
>  Of course you'll have to filter them out from all the other string
> output, but they should all appear shortly after the word "names",
> since the colnames of a data frame are the "names" attribute of the
> data.
>
>  If you don't have a Unix or Mac machine handy you can get these
> utilities on Windows via Cygwin but that's another story...
>
>  Barry
>
>
>
>
>
>
>
>
> On Wed, Mar 16, 2016 at 3:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
>> Hi,
>> I have a huge .RData file and I need just to get the colnames of it. so is
>> there any way to reach the column names without loading or reading the
>> whole file?
>> Since the file is so big and I need to repeat this process several times,
>> so it takes so long to load the file first and then take the colnames!
>>
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Mar 16 18:39:47 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 16 Mar 2016 13:39:47 -0400
Subject: [R] merge small clusters in R
In-Reply-To: <CAFinXcQ0vi2pCco6POgkAROhKBmmGbxSUSxsw=sBOi5QKfUmEg@mail.gmail.com>
References: <CAFinXcQ0vi2pCco6POgkAROhKBmmGbxSUSxsw=sBOi5QKfUmEg@mail.gmail.com>
Message-ID: <63F3C102-481E-44DC-ABAD-4F242EF4FC5E@utoronto.ca>

This is not a well defined question, until your notions of "small" and "nearest" are defined. In your specific example

   rect.hclust(hc, k = 3, border = 2:5)

... will do what you are asking for. This is not likely to work in the general case - imagine that your cluster of size two only meets the others at the root: in that case you would be distorting the result significantly if you were to merge it in with another cluster, simply based on membership size. That said, perhaps the package dynamicTreeCut will help you find cuts in a dendrogram that more closely match your intuition.

B.


On Mar 16, 2016, at 11:38 AM, Sheila the angel <from.d.putto at gmail.com> wrote:

> In R, I have cut a dendrogram into clusters. However some of the clusters
> have only few samples. How can I merge the small clusters with nearest big
> cuter.
> 
> hc <- hclust(dist(USArrests))
> plot(hc, cex = 0.6)
> rect.hclust(hc, k = 4, border = 2:5)
> 
> It gives one cluster with only 2 samples. How can I merge it with nearest
> cluster?
> 
> Thanks
> S.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Mar 16 18:55:23 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 16 Mar 2016 13:55:23 -0400
Subject: [R] How to reach the column names in a huge .RData file without
	loading it
In-Reply-To: <CAMqbV1Ao4w9wAi09GVO352+vt7vfz3oiL0vEgKLgvd9NtF5gew@mail.gmail.com>
References: <CAMqbV1D1Jw7EzN4hiN_i-=xSk0Lt3y02TznGY=O2dG7XrD1mcA@mail.gmail.com>
	<CAGxFJbTzFuOY1J0kiFiwGwwfAaZ_U2642POdHVwfSrtFtHyo2Q@mail.gmail.com>
	<CAMqbV1Ao4w9wAi09GVO352+vt7vfz3oiL0vEgKLgvd9NtF5gew@mail.gmail.com>
Message-ID: <25BA0355-5FF3-4525-89A7-F53A54EADC41@utoronto.ca>

However: if you need to repeat the process, as you wrote, you could store the column names in a separate object for future access after your first read.

B.


On Mar 16, 2016, at 12:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:

> Thank you Bert and Frederic.
> 
> On Wed, Mar 16, 2016 at 11:52 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> 
>> Is it really a .Rdata file? If so, the answer is no, AFAIK, since
>> .Rdata files are serialized (binary) versions of e.g. worksheets that
>> can contain many different data objects. "colnames" has no meaning in
>> this context.
>> 
>> Corrections welcome if I have it wrong!
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Wed, Mar 16, 2016 at 8:59 AM, Lida Zeighami <lid.zigh at gmail.com> wrote:
>>> Hi,
>>> I have a huge .RData file and I need just to get the colnames of it. so
>> is
>>> there any way to reach the column names without loading or reading the
>>> whole file?
>>> Since the file is so big and I need to repeat this process several times,
>>> so it takes so long to load the file first and then take the colnames!
>>> 
>>> Thanks
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jttkim at googlemail.com  Wed Mar 16 18:40:54 2016
From: jttkim at googlemail.com (Jan Kim)
Date: Wed, 16 Mar 2016 17:40:54 +0000
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
	<CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
Message-ID: <20160316174053.GD4258@localhost>

Barry: that's an interesting hack.

I do feel compelled to make two comments, though, regarding the
general issue rather than the scraping idea:

(1) If your situation is that that image (.RData file) is the only
copy of the data, you'll need to rescue the data from that as soon as
possible anyway. Something like

    load(".RData");
    write.csv(mydataframe, file = "mydata.csv");

should do this trick. It will be slow, but you'll need to do it just
once, so you might as well enjoy your coffee while you wait. From that
point on, work with the mydata.csv file for getting at the colnames
(and anything else as well).

(2) If there's any chance / risk that scraping data off images is not
a one-off, the time to prevent that from catching on is now. If data is
of any value at all, it should be handled in a sane, portable, textual
format. For tabular data, csv is normally adequate or at least good
enough, but .RData images are never a good idea.

Best regards, Jan

P.S.: I've seen .RData images containing many months worth of interactive
work, and multiple variants of data frames in variables with more or less
similar names, so the set of strings scraped off these will be rather more
bewildering than in Barry's clean example.


On Wed, Mar 16, 2016 at 05:17:25PM +0000, Barry Rowlingson wrote:
> You *might* be able to get them from the raw file...
> 
> First, I don't quite know what "colnames" of an .RData file means.
> "colnames" are the column names of a matrix (or data frame), so I'll
> assume your .RData file contains exactly one data frame and you want
> to column names of it.
> 
> So let's create one of those:
> 
> 
> mydataframe = data.frame(mylongnamehere=runif(3),
> anotherlongname=runif(3), z=runif(3), y=runif(3),
> aasdkjhasdkjhaskdj=runif(3))
> save(mydataframe, file="./test.RData")
> 
> Now I'm going to use some Unix utilities to see if there's any
> identifiable strings in the file. .RData files are by default
> compressed using `gzip`, so I'll `gunzip` them and pipe it into
> `strings`:
> 
> $ gunzip -c test.RData | strings -t d
>       0 RDX2
>      35 mydataframe
>     230 names
>     251 mylongnamehere
>     273 anotherlongname
>     314 aasdkjhasdkjhaskdj
>     347     row.names
>     389 class
>     410 data.frame
> 
> 
>   - thats found the object name (mydataframe) and most of the column
> names except the short ones, which are too short for `strings` to
> recognise. But if your names are long enough (4 or more chars, I
> think) they'll show up.
> 
>  Of course you'll have to filter them out from all the other string
> output, but they should all appear shortly after the word "names",
> since the colnames of a data frame are the "names" attribute of the
> data.
> 
>  If you don't have a Unix or Mac machine handy you can get these
> utilities on Windows via Cygwin but that's another story...
> 
>  Barry
> 
> 
> 
> 
> 
> 
> 
> 
> On Wed, Mar 16, 2016 at 3:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> > Hi,
> > I have a huge .RData file and I need just to get the colnames of it. so is
> > there any way to reach the column names without loading or reading the
> > whole file?
> > Since the file is so big and I need to repeat this process several times,
> > so it takes so long to load the file first and then take the colnames!
> >
> > Thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From highstat at highstat.com  Wed Mar 16 20:13:47 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 16 Mar 2016 20:13:47 +0100
Subject: [R] 8 statistics courses in Australia
Message-ID: <56E9B06B.1020503@highstat.com>

We would like to announce a series of 8 statistics courses in Australia 
in June/July/August 2016. For details and registration:

http://highstat.com/statscourse.htm

Kind regards,

Alain Zuur



Course 1: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches.
Murdoch University, Perth, Australia
6-10 June 2016

Course 2: Introduction to Zero Inflated Models
Australian Institute of Marine Science, Perth, Australia
13-17 June 2016

Course 3: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches
University of Adelaide, Adelaide, Australia
20-24 June 2016

Course 4: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches
Deakin University, Melbourne, Australia
4-8 July 2016

Course 5: Introduction to GAM and GAMM using Bayesian and frequentist tools
CSIRO, Canberra, Australia
11-15 July 2016

Course 6: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches
UNSW, Sydney, Australia
18-22 July 2016

Course 7: Introduction to Zero Inflated Models
UNSW, Sydney, Australia
25-29 July 2016

Course 8: Data exploration, regression, GLM & GAM with introduction to R
Charles Darwin University, Alice Springs, Australia
1-5 August 2016




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From murdoch.duncan at gmail.com  Wed Mar 16 20:18:27 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Mar 2016 15:18:27 -0400
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <20160316174053.GD4258@localhost>
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
	<CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
	<20160316174053.GD4258@localhost>
Message-ID: <56E9B183.6040003@gmail.com>

On 16/03/2016 1:40 PM, Jan Kim wrote:
> Barry: that's an interesting hack.
>
> I do feel compelled to make two comments, though, regarding the
> general issue rather than the scraping idea:
>
> (1) If your situation is that that image (.RData file) is the only
> copy of the data, you'll need to rescue the data from that as soon as
> possible anyway. Something like
>
>      load(".RData");
>      write.csv(mydataframe, file = "mydata.csv");
>
> should do this trick. It will be slow, but you'll need to do it just
> once, so you might as well enjoy your coffee while you wait. From that
> point on, work with the mydata.csv file for getting at the colnames
> (and anything else as well).
>
> (2) If there's any chance / risk that scraping data off images is not
> a one-off, the time to prevent that from catching on is now. If data is
> of any value at all, it should be handled in a sane, portable, textual
> format. For tabular data, csv is normally adequate or at least good
> enough, but .RData images are never a good idea.

I agree with the sentiment, but not with the choice of .csv as a "sane, 
portable, textual format".  CSV has no type information included, so 
strings that contain only digits can turn into numbers (and get rounded 
in the process), things that look like
dates can get converted to different formats, etc.

The .RData format has the disadvantages of being hard to use outside R, 
but at least it is usable in R.

I don't know what I'd recommend if I wanted a portable textual format.  
JSON is close, but it can't handle the full
range of data that R can handle (e.g. no Inf).  dput() on a dataframe is 
text, but nothing but R can read it.

Duncan Murdoch


>
> Best regards, Jan
>
> P.S.: I've seen .RData images containing many months worth of interactive
> work, and multiple variants of data frames in variables with more or less
> similar names, so the set of strings scraped off these will be rather more
> bewildering than in Barry's clean example.
>
>
> On Wed, Mar 16, 2016 at 05:17:25PM +0000, Barry Rowlingson wrote:
> > You *might* be able to get them from the raw file...
> >
> > First, I don't quite know what "colnames" of an .RData file means.
> > "colnames" are the column names of a matrix (or data frame), so I'll
> > assume your .RData file contains exactly one data frame and you want
> > to column names of it.
> >
> > So let's create one of those:
> >
> >
> > mydataframe = data.frame(mylongnamehere=runif(3),
> > anotherlongname=runif(3), z=runif(3), y=runif(3),
> > aasdkjhasdkjhaskdj=runif(3))
> > save(mydataframe, file="./test.RData")
> >
> > Now I'm going to use some Unix utilities to see if there's any
> > identifiable strings in the file. .RData files are by default
> > compressed using `gzip`, so I'll `gunzip` them and pipe it into
> > `strings`:
> >
> > $ gunzip -c test.RData | strings -t d
> >       0 RDX2
> >      35 mydataframe
> >     230 names
> >     251 mylongnamehere
> >     273 anotherlongname
> >     314 aasdkjhasdkjhaskdj
> >     347     row.names
> >     389 class
> >     410 data.frame
> >
> >
> >   - thats found the object name (mydataframe) and most of the column
> > names except the short ones, which are too short for `strings` to
> > recognise. But if your names are long enough (4 or more chars, I
> > think) they'll show up.
> >
> >  Of course you'll have to filter them out from all the other string
> > output, but they should all appear shortly after the word "names",
> > since the colnames of a data frame are the "names" attribute of the
> > data.
> >
> >  If you don't have a Unix or Mac machine handy you can get these
> > utilities on Windows via Cygwin but that's another story...
> >
> >  Barry
> >
> >
> >
> >
> >
> >
> >
> >
> > On Wed, Mar 16, 2016 at 3:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> > > Hi,
> > > I have a huge .RData file and I need just to get the colnames of it. so is
> > > there any way to reach the column names without loading or reading the
> > > whole file?
> > > Since the file is so big and I need to repeat this process several times,
> > > so it takes so long to load the file first and then take the colnames!
> > >
> > > Thanks
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From pd.mes at cbs.dk  Wed Mar 16 21:39:53 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 16 Mar 2016 20:39:53 +0000
Subject: [R] R 3.2.4-revised is released
Message-ID: <A252BB23-7C0A-4495-AE46-BD0CA1003B6B@cbs.dk>

The 3.2.4 release had two annoyances which we would rather not have in an "ultra-stable" release, designed to hang around for the duration of the 3.3 series. One was a relatively minor Makefile issue affecting system using R's bundled lzma library. The other, rather more serious, affected printing and formatting of POSIXlt objects, which would unpredictably get the Daylight Savings Time wrong.

Accordingly a revised version has been created.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.4-revised.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Maintainers of binary versions are requested to rebuild their binaries using the revised sources.


For the R Core Team,

Peter Dalgaard

New md5 sums are

MD5 (NEWS) = b0b43ac87a5b5858098da065966551af
MD5 (R-3/R-3.2.4-revised.tar.gz) = 552b0c8088bab08ca4188797b919a58f

The relevant NEWS file entry is

  BUG FIXES:

    ? format.POSIXlt() behaved wrongly, e.g.,
      format(as.POSIXlt(paste0(1940:2000,"-01-01"), tz="CET"),
      usetz=TRUE) ended in two "CEST" time formats.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

From dcarlson at tamu.edu  Wed Mar 16 22:21:26 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 16 Mar 2016 21:21:26 +0000
Subject: [R] Circular Statistic in R
In-Reply-To: <001d01d17fa1$84757f10$8d607d30$@sbcglobal.net>
References: <000201d17f10$6d7b5aa0$48720fe0$@sbcglobal.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D7237BE@mb02.ads.tamu.edu>
	<001d01d17fa1$84757f10$8d607d30$@sbcglobal.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72494F@mb02.ads.tamu.edu>

The circular() function sets the details of your circular data. Mathematicians think in terms of radians that begin at 3 o'clock and proceed counterclockwise which I believe is the default. Geographers think in terms of degrees that begin at 12 o'clock and proceed clockwise. Unless you get all three attributes set correctly, things can get strange.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: Jeff Reichman [mailto:reichmanj at sbcglobal.net] 
Sent: Wednesday, March 16, 2016 11:33 AM
To: David L Carlson
Subject: RE: [R] Circular Statistic in R

David

Thank you for your comments.  I am using the circular package and find my
data words better when I convert to radians, but I'm lazy and don't like
converting back and forth (radian - degrees); but find when I work in
degrees my results are funky. So I just assumed R prefers radians as opposed
to degrees.  It could also be how I'm using the commands in R when dealing
in degrees. I've just started using the circular package yesterday.

Jeff

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: Wednesday, March 16, 2016 9:01 AM
To: reichmanj at sbcglobal.net
Subject: RE: [R] Circular Statistic in R

It is always hard to diagnose unspecified "problems", but it should not
matter. You do need to use statistical methods specifically designed for
circular data. Even simple descriptive statistics such as the mean, standard
deviation, and variance require special functions. Try package circular.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
Reichman
Sent: Tuesday, March 15, 2016 6:14 PM
To: r-help at r-project.org
Subject: [R] Circular Statistic in R

R-Help



Is it preferable to work in Radians or Degrees when performing circular
statistics.  I'm assuming radians because I'm running into problems in
Degrees.



Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From andrluis at ualberta.ca  Wed Mar 16 22:32:09 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Wed, 16 Mar 2016 15:32:09 -0600
Subject: [R] Plot help
Message-ID: <CAHxKz8ZHBK8XzhE9WPkiMSEK_AeqRzdBoQ15U0McMZYzNA=Rkg@mail.gmail.com>

Dear all:


I was wondering how I modify the plot command below so that the y-axis
displays the numbers in a 4 by 4 scale.


It looks like the plot generated by the commands below shows the y-axis in
a 5 by 5 scale:


Values <- c(1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16)

Values

Log <- log2(Values)

Log

Index <- c(1:9)

Index

##2) Plot

plot (x= Index, y=Values, ylim= c(-16,16), pch= 19, col = "blue")

points (Log, pch = 19, col="green")


Thanks.


Andre

	[[alternative HTML version deleted]]


From albmont at centroin.com.br  Wed Mar 16 22:39:49 2016
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Wed, 16 Mar 2016 17:39:49 -0400
Subject: [R] Typographical error in the documentation of function strwidth?
Message-ID: <205751964.32976515.1458164389749.JavaMail.zimbra@centroin.com.br>

There might be a minor typographical error in the documentation of the function strwidth, namely, from

?strwidth

we get:

"Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds - 1) times the line spacing plus the height of "M" in the selected font. (...)"

I think the correct phrasing should be:

"Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds) times the line spacing plus the (number of linefeeds + 1) times the height of "M" in the selected font. (...)"

Alberto Monteiro


From drjimlemon at gmail.com  Wed Mar 16 22:48:32 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 17 Mar 2016 08:48:32 +1100
Subject: [R] Plot help
In-Reply-To: <CAHxKz8ZHBK8XzhE9WPkiMSEK_AeqRzdBoQ15U0McMZYzNA=Rkg@mail.gmail.com>
References: <CAHxKz8ZHBK8XzhE9WPkiMSEK_AeqRzdBoQ15U0McMZYzNA=Rkg@mail.gmail.com>
Message-ID: <CA+8X3fVnj4+Bzhokrsxb=o7BF-8JTRsJwPuvVbAAGaMHGOft_w@mail.gmail.com>

Hi Andre,
Try this:

plot(x= Index, y=Values, ylim= c(-16,16), pch= 19,
 col = "blue",yaxt="n")
points (Log, pch = 19, col="green")
axis(2,at=seq(-16,16,by=4))

Jim

On Thu, Mar 17, 2016 at 8:32 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear all:
>
>
> I was wondering how I modify the plot command below so that the y-axis
> displays the numbers in a 4 by 4 scale.
>
>
> It looks like the plot generated by the commands below shows the y-axis in
> a 5 by 5 scale:
>
>
> Values <- c(1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16)
>
> Values
>
> Log <- log2(Values)
>
> Log
>
> Index <- c(1:9)
>
> Index
>
> ##2) Plot
>
> plot (x= Index, y=Values, ylim= c(-16,16), pch= 19, col = "blue")
>
> points (Log, pch = 19, col="green")
>
>
> Thanks.
>
>
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Mar 16 23:22:46 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Mar 2016 23:22:46 +0100
Subject: [R] Typographical error in the documentation of function
	strwidth?
In-Reply-To: <205751964.32976515.1458164389749.JavaMail.zimbra@centroin.com.br>
References: <205751964.32976515.1458164389749.JavaMail.zimbra@centroin.com.br>
Message-ID: <99AA4B91-D97B-40B7-A412-B1464D1A63CC@gmail.com>

I don't think so. I'll give you that it should either be the (number of lines - 1)*spacing or (number of linefeeds)*spacing, but it's correct to count the height of "M" only on the top line.

-pd

It is correct as written

> On 16 Mar 2016, at 22:39 , ALBERTO VIEIRA FERREIRA MONTEIRO <albmont at centroin.com.br> wrote:
> 
> There might be a minor typographical error in the documentation of the function strwidth, namely, from
> 
> ?strwidth
> 
> we get:
> 
> "Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds - 1) times the line spacing plus the height of "M" in the selected font. (...)"
> 
> I think the correct phrasing should be:
> 
> "Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds) times the line spacing plus the (number of linefeeds + 1) times the height of "M" in the selected font. (...)"
> 
> Alberto Monteiro
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From macqueen1 at llnl.gov  Thu Mar 17 01:22:48 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 17 Mar 2016 00:22:48 +0000
Subject: [R] How to speed up R program
In-Reply-To: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
References: <DUB125-W68A5DD6122C3E29C9FF258B3880@phx.gbl>
Message-ID: <D30F45E4.167B19%macqueen1@llnl.gov>

You can start with
  ?Rprof
which can help you find out what steps in your calculations are taking the
most time.

Depending on what, exactly, you're doing, look for places where you're
using a data frame when a matrix would serve the purpose. Data frames have
more overhead than matrices.

Sarah Goslee's suggestion to avoid growing in place is a good one.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/14/16, 2:32 PM, "R-help on behalf of Ragia ."
<r-help-bounces at r-project.org on behalf of ragia11 at hotmail.com> wrote:

>
>
>
>
>Dear group
>I have two R sessions  running on Ubuntu 14.0x server , and I found that
>my program will take too long time to be finished( months...!), I used
>top command and found that   cpu usage is 21.3%.
>
>the server is Enterprise SP-64 - 64G E5-1630v3 SoftRaid 2x2 TB Server . 6
>core
>
>how can I speed the program, kindly I need tutorial or book chapter that
>helps..
>thanks in advance
>Ragia
>
> 		 	   		  
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bs13rw at leeds.ac.uk  Wed Mar 16 23:09:41 2016
From: bs13rw at leeds.ac.uk (Rebecca Wooldridge [bs13rw])
Date: Wed, 16 Mar 2016 22:09:41 +0000
Subject: [R] R count.points thinks projections are different
Message-ID: <AM3PR03MB1202A627CDE94C3309B523938B8A0@AM3PR03MB1202.eurprd03.prod.outlook.com>


I am currently working with telemetry data for some cats:


x<-read.csv("CCATS.csv")
obs2<-x[c("ID", "X", "Y")]
dat_df <- obs2 %>% dplyr::select(ID) %>% as.data.frame()
p4s <- "+proj=utm +zone=16 +ellps=clrk66 +datum=NAD27 +units=m +no_defs"
p4s_crs <- CRS(p4s)
xy <- obs2 %>% dplyr::select(X, Y) %>% as.matrix()
xy_sp <- SpatialPointsDataFrame(xy, data = dat_df, proj4string=p4s_crs)

I also have some raster maps of the study area:

> summary(habitat)
Object of class SpatialPixelsDataFrame
Coordinates:
        min       max
x  328048.6  360028.8
y 1841819.0 1874744.0
Is projected: TRUE
proj4string :
[+proj=utm +zone=16 +ellps=clrk66 +datum=NAD27 +units=m +no_defs
+nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat]
Number of points: 13024
Grid attributes:
   cellcentre.offset cellsize cells.dim
s1          328139.5 181.7057       176
s2         1842041.5 444.9324        74
Data attributes:
   elevation        ecosystem         slope             aspect
 Min.   : 1.000   Min.   : 1.00   Min.   :0.00000   Min.   :  0.0
 1st Qu.: 1.000   1st Qu.:15.00   1st Qu.:0.00000   1st Qu.: 90.0
 Median : 2.000   Median :15.00   Median :0.04134   Median : 90.0
 Mean   : 2.263   Mean   :12.85   Mean   :0.05194   Mean   :132.5
 3rd Qu.: 3.000   3rd Qu.:15.00   3rd Qu.:0.08523   3rd Qu.:180.0
 Max.   :11.000   Max.   :18.00   Max.   :0.35079   Max.   :360.0
 NA's   :18                       NA's   :84        NA's   :84

when i try to use the count.points function i get the following message:

Error in count.points(SpatialPoints(x), w) :
  different proj4string in w and xy

but
> identical(proj4string(habitat), proj4string(xy_sp))
[1] TRUE
 and i have also tried
proj4string(xy_sp) <- proj4string(habitat)
and then running again but i still get the same error message.

Any help would be greatly appreciated.

Becky


	[[alternative HTML version deleted]]


From thatsmile333 at hotmail.com  Thu Mar 17 00:07:03 2016
From: thatsmile333 at hotmail.com (John Liu)
Date: Wed, 16 Mar 2016 16:07:03 -0700
Subject: [R] Interpretation of Coefficients of GAM
Message-ID: <BAY175-W38D4FAB75A8AA04B1E720C8B8A0@phx.gbl>

Hi all, 
May I have a  question on how to interpret the coefficients from GAM. 

 

We used  GAM to get propensity scores,  fitting model as below, 

fit  <- gam(group~agegroup+s(GA_Enr)+race+edugroup,
data = datax, family='binomial')

where ?group? is a binary variable for treatment(y/n)

?agegroup?, ?race?,  ?edugroup?  are categorical
variables for age, race, and education years respectively. 

?GA_Enr? is a continuous variable for age at enrollment.
 We added smoothing term to it. 

 

And we  got the propensity scores as below, 

ps <- predict (fit, data = datax) 

 

Next we tried to manually calculate Pscores using the
coefficients from GAM. Our purpose was to compare the ps we manually calculated with the
ps  we obtained from the above line. They are supposed to be the same. 

 

Both coef(fit) and fit$smooth show coefficients from GAM.
  

Now for ?GA_Enr?, we have one ?general coefficient? 
from coef(fit) , here call it coeff1.

And still for ?GA_Enr?, from fit$smooth, we have
?coefficients for each subject?, here call it coeff2. 

 

My question is how to interpret coeff1 and coeff2 and how to
use them to calculate ps for each subject?

 

Thank you so much in advance!
Jen 		 	   		  
	[[alternative HTML version deleted]]


From jttkim at googlemail.com  Thu Mar 17 02:56:14 2016
From: jttkim at googlemail.com (Jan T Kim)
Date: Thu, 17 Mar 2016 01:56:14 +0000
Subject: [R] How to reach the column names in a huge .RData file without
 loading it
In-Reply-To: <56E9B183.6040003@gmail.com>
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
	<CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
	<20160316174053.GD4258@localhost> <56E9B183.6040003@gmail.com>
Message-ID: <20160317015613.GN31227@charran>

On Wed, Mar 16, 2016 at 03:18:27PM -0400, Duncan Murdoch wrote:
> On 16/03/2016 1:40 PM, Jan Kim wrote:
> >Barry: that's an interesting hack.
> >
> >I do feel compelled to make two comments, though, regarding the
> >general issue rather than the scraping idea:
> >
> >(1) If your situation is that that image (.RData file) is the only
> >copy of the data, you'll need to rescue the data from that as soon as
> >possible anyway. Something like
> >
> >     load(".RData");
> >     write.csv(mydataframe, file = "mydata.csv");
> >
> >should do this trick. It will be slow, but you'll need to do it just
> >once, so you might as well enjoy your coffee while you wait. From that
> >point on, work with the mydata.csv file for getting at the colnames
> >(and anything else as well).
> >
> >(2) If there's any chance / risk that scraping data off images is not
> >a one-off, the time to prevent that from catching on is now. If data is
> >of any value at all, it should be handled in a sane, portable, textual
> >format. For tabular data, csv is normally adequate or at least good
> >enough, but .RData images are never a good idea.
> 
> I agree with the sentiment, but not with the choice of .csv as a
> "sane, portable, textual format".  CSV has no type information
> included, so strings that contain only digits can turn into numbers
> (and get rounded in the process), things that look like
> dates can get converted to different formats, etc.

I entirely agree. In hindsight, I should have stated that the .RData files,
as well as the R code to load and extract stuff from them, should be stored
permanently and documented.

> The .RData format has the disadvantages of being hard to use outside
> R, but at least it is usable in R.

yes -- that's why I thought it's a good idea to use R to pluck out the
valuable data, so (1) they can still be accessed even if the .RData
format changes and (2) they're in their own file, separated from the
(potentially homungous, see my P.S.) amount of other stuff caught up
in the image.

But to reiterate, the .RData file should be secured as well if that's
the only remaining primary / original source of the data.

> I don't know what I'd recommend if I wanted a portable textual
> format.  JSON is close, but it can't handle the full
> range of data that R can handle (e.g. no Inf).  dput() on a
> dataframe is text, but nothing but R can read it.

yes, that's the problem with "JSON", it's a JavaScript but not really
an object notation, as it doesn't store class structure metadata.

So again, the best bet is to secure multiple levels, the .RDdata
image to preserve the R types, the R script to be able to identify
the relevant variable(s), and the text version to avoid depending on
availablility of R / an R version still able to read the image format.

Best regards, Jan


> Duncan Murdoch
> 
> 
> >
> >Best regards, Jan
> >
> >P.S.: I've seen .RData images containing many months worth of interactive
> >work, and multiple variants of data frames in variables with more or less
> >similar names, so the set of strings scraped off these will be rather more
> >bewildering than in Barry's clean example.
> >
> >
> >On Wed, Mar 16, 2016 at 05:17:25PM +0000, Barry Rowlingson wrote:
> >> You *might* be able to get them from the raw file...
> >>
> >> First, I don't quite know what "colnames" of an .RData file means.
> >> "colnames" are the column names of a matrix (or data frame), so I'll
> >> assume your .RData file contains exactly one data frame and you want
> >> to column names of it.
> >>
> >> So let's create one of those:
> >>
> >>
> >> mydataframe = data.frame(mylongnamehere=runif(3),
> >> anotherlongname=runif(3), z=runif(3), y=runif(3),
> >> aasdkjhasdkjhaskdj=runif(3))
> >> save(mydataframe, file="./test.RData")
> >>
> >> Now I'm going to use some Unix utilities to see if there's any
> >> identifiable strings in the file. .RData files are by default
> >> compressed using `gzip`, so I'll `gunzip` them and pipe it into
> >> `strings`:
> >>
> >> $ gunzip -c test.RData | strings -t d
> >>       0 RDX2
> >>      35 mydataframe
> >>     230 names
> >>     251 mylongnamehere
> >>     273 anotherlongname
> >>     314 aasdkjhasdkjhaskdj
> >>     347     row.names
> >>     389 class
> >>     410 data.frame
> >>
> >>
> >>   - thats found the object name (mydataframe) and most of the column
> >> names except the short ones, which are too short for `strings` to
> >> recognise. But if your names are long enough (4 or more chars, I
> >> think) they'll show up.
> >>
> >>  Of course you'll have to filter them out from all the other string
> >> output, but they should all appear shortly after the word "names",
> >> since the colnames of a data frame are the "names" attribute of the
> >> data.
> >>
> >>  If you don't have a Unix or Mac machine handy you can get these
> >> utilities on Windows via Cygwin but that's another story...
> >>
> >>  Barry
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> On Wed, Mar 16, 2016 at 3:59 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> >> > Hi,
> >> > I have a huge .RData file and I need just to get the colnames of it. so is
> >> > there any way to reach the column names without loading or reading the
> >> > whole file?
> >> > Since the file is so big and I need to repeat this process several times,
> >> > so it takes so long to load the file first and then take the colnames!
> >> >
> >> > Thanks
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From loris.bennett at fu-berlin.de  Thu Mar 17 08:22:29 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 17 Mar 2016 08:22:29 +0100
Subject: [R] How to reach the column names in a huge .RData file without
	loading it
References: <85d48a0ccfcc47ec942aec6cd0f777ac@EX-0-HT0.lancs.local>
	<CANVKczORSTfLTubZWjcoePz30hrZrAi60UacT3JS4AC-astrTw@mail.gmail.com>
	<20160316174053.GD4258@localhost> <56E9B183.6040003@gmail.com>
	<20160317015613.GN31227@charran>
Message-ID: <878u1hbmbu.fsf@hornfels.zedat.fu-berlin.de>

Jan T Kim <jttkim at googlemail.com> writes:

> On Wed, Mar 16, 2016 at 03:18:27PM -0400, Duncan Murdoch wrote:
>> On 16/03/2016 1:40 PM, Jan Kim wrote:
>> >Barry: that's an interesting hack.
>> >
>> >I do feel compelled to make two comments, though, regarding the
>> >general issue rather than the scraping idea:
>> >
>> >(1) If your situation is that that image (.RData file) is the only
>> >copy of the data, you'll need to rescue the data from that as soon as
>> >possible anyway. Something like
>> >
>> >     load(".RData");
>> >     write.csv(mydataframe, file = "mydata.csv");
>> >
>> >should do this trick. It will be slow, but you'll need to do it just
>> >once, so you might as well enjoy your coffee while you wait. From that
>> >point on, work with the mydata.csv file for getting at the colnames
>> >(and anything else as well).
>> >
>> >(2) If there's any chance / risk that scraping data off images is not
>> >a one-off, the time to prevent that from catching on is now. If data is
>> >of any value at all, it should be handled in a sane, portable, textual
>> >format. For tabular data, csv is normally adequate or at least good
>> >enough, but .RData images are never a good idea.
>> 
>> I agree with the sentiment, but not with the choice of .csv as a
>> "sane, portable, textual format".  CSV has no type information
>> included, so strings that contain only digits can turn into numbers
>> (and get rounded in the process), things that look like
>> dates can get converted to different formats, etc.
>
> I entirely agree. In hindsight, I should have stated that the .RData files,
> as well as the R code to load and extract stuff from them, should be stored
> permanently and documented.
>
>> The .RData format has the disadvantages of being hard to use outside
>> R, but at least it is usable in R.
>
> yes -- that's why I thought it's a good idea to use R to pluck out the
> valuable data, so (1) they can still be accessed even if the .RData
> format changes and (2) they're in their own file, separated from the
> (potentially homungous, see my P.S.) amount of other stuff caught up
> in the image.
>
> But to reiterate, the .RData file should be secured as well if that's
> the only remaining primary / original source of the data.
>
>> I don't know what I'd recommend if I wanted a portable textual
>> format.  JSON is close, but it can't handle the full
>> range of data that R can handle (e.g. no Inf).  dput() on a
>> dataframe is text, but nothing but R can read it.
>
> yes, that's the problem with "JSON", it's a JavaScript but not really
> an object notation, as it doesn't store class structure metadata.
>
> So again, the best bet is to secure multiple levels, the .RDdata
> image to preserve the R types, the R script to be able to identify
> the relevant variable(s), and the text version to avoid depending on
> availablility of R / an R version still able to read the image format.
>
> Best regards, Jan

The package 'h5' provides an R interface to HDF5 files.  I have used
neither, but am aware that HDF5 is a widely used format for storing
complex data structures.  Would that be useful?

Cheers,

Loris

[snip (99 lines)]
-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From cdetermanjr at gmail.com  Wed Mar 16 20:41:24 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 16 Mar 2016 14:41:24 -0500
Subject: [R] [R-pkgs] gpuR 1.1.0 Release
Message-ID: <CAKxd1KMTVTwNGRWGB4kE-S=FdTixLbNdpxnX4xQ7tdS+t5OzpA@mail.gmail.com>

Dear R users,

The next release of gpuR (1.1.0) has been accepted to CRAN (
http://cran.r-project.org/package=gpuR).

There have been multiple additions including:

1. Scalar operations for gpuMatrix/vclMatrix objects (e.g. 2 * X)
2. Unary '-' operator added (e.g. -X)
3. 'slice' and 'block' methods for vector & matrix objects respectively
4. 'deepcopy' methods
5. 'abs', 'max', 'min' methods added
6. 'cbind' & 'rbind' methods added for matrices
7. 't' method
8. 'distance' method for pairwise distances (euclidean and sqEuclidean)

Introductory vignette can be found at
https://cran.r-project.org/web/packages/gpuR/vignettes/gpuR.pdf

Help with installation can be found at
https://github.com/cdeterman/gpuR/wiki

Bug reports, suggestions, and feature requests are appreciated at
https://github.com/cdeterman/gpuR/issues

Happy GPU computing,
Charles

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ivan.calandra at univ-reims.fr  Thu Mar 17 11:29:52 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 17 Mar 2016 11:29:52 +0100
Subject: [R] plot numeric vs character
Message-ID: <56EA8720.4070908@univ-reims.fr>

Dear useRs,

I would like to plot data points in a simple scatterplot. I don't have a 
lot of data per category, so a boxplot does not make sense.

Here are some sample data:
mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9), 
stringsAsFactors=FALSE)

I would like to do that, which throws an error, most likely because x is 
character:
plot(mydf$let, mydf$num)

If I convert to factor(), it plots a boxplot with no possibility (AFAIK) 
to plot points:
mydf$let <- factor(mydf$let)
plot(mydf$let, mydf$num, type='p')

I know I can use the function points() in a somewhat convoluted manner:
plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
axis(side=1, at=1:3, labels=levels(mydf$let))
points(as.numeric(mydf$let), mydf$num)

Isn't there a simple(r) way? Maybe I just missed something obvious...

Thank you in advance for your help,
Ivan

-- 
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/


From petr.pikal at precheza.cz  Thu Mar 17 11:48:34 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 17 Mar 2016 10:48:34 +0000
Subject: [R] plot numeric vs character
In-Reply-To: <56EA8720.4070908@univ-reims.fr>
References: <56EA8720.4070908@univ-reims.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>

Hi

It would be easier if mydf$let was factor

plot(as.numeric(factor(mydf$let)), mydf$num, xaxt="n")
axis(1, at=1:3, levels(factor(mydf$let)))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
> Calandra
> Sent: Thursday, March 17, 2016 11:30 AM
> To: R list
> Cc: Anne CANER
> Subject: [R] plot numeric vs character
>
> Dear useRs,
>
> I would like to plot data points in a simple scatterplot. I don't have
> a lot of data per category, so a boxplot does not make sense.
>
> Here are some sample data:
> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
> stringsAsFactors=FALSE)
>
> I would like to do that, which throws an error, most likely because x
> is
> character:
> plot(mydf$let, mydf$num)
>
> If I convert to factor(), it plots a boxplot with no possibility
> (AFAIK) to plot points:
> mydf$let <- factor(mydf$let)
> plot(mydf$let, mydf$num, type='p')
>
> I know I can use the function points() in a somewhat convoluted manner:
> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n') axis(side=1, at=1:3,
> labels=levels(mydf$let)) points(as.numeric(mydf$let), mydf$num)
>
> Isn't there a simple(r) way? Maybe I just missed something obvious...
>
> Thank you in advance for your help,
> Ivan
>
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ivan.calandra at univ-reims.fr  Thu Mar 17 12:01:14 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 17 Mar 2016 12:01:14 +0100
Subject: [R] plot numeric vs character
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
References: <56EA8720.4070908@univ-reims.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
Message-ID: <56EA8E7A.2020101@univ-reims.fr>

Thanks Petr,

You're right, no need for points().
But is there an even simpler way? I still find it strange that plot() 
does not allow points to be plotted instead of boxplots when x is a 
factor (because boxplots do not always make sense). Is there a good 
reason for that?

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 17/03/2016 11:48, PIKAL Petr a ?crit :
> Hi
>
> It would be easier if mydf$let was factor
>
> plot(as.numeric(factor(mydf$let)), mydf$num, xaxt="n")
> axis(1, at=1:3, levels(factor(mydf$let)))
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
>> Calandra
>> Sent: Thursday, March 17, 2016 11:30 AM
>> To: R list
>> Cc: Anne CANER
>> Subject: [R] plot numeric vs character
>>
>> Dear useRs,
>>
>> I would like to plot data points in a simple scatterplot. I don't have
>> a lot of data per category, so a boxplot does not make sense.
>>
>> Here are some sample data:
>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>> stringsAsFactors=FALSE)
>>
>> I would like to do that, which throws an error, most likely because x
>> is
>> character:
>> plot(mydf$let, mydf$num)
>>
>> If I convert to factor(), it plots a boxplot with no possibility
>> (AFAIK) to plot points:
>> mydf$let <- factor(mydf$let)
>> plot(mydf$let, mydf$num, type='p')
>>
>> I know I can use the function points() in a somewhat convoluted manner:
>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n') axis(side=1, at=1:3,
>> labels=levels(mydf$let)) points(as.numeric(mydf$let), mydf$num)
>>
>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>>
>> Thank you in advance for your help,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Thu Mar 17 12:42:55 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 17 Mar 2016 11:42:55 +0000
Subject: [R] plot numeric vs character
In-Reply-To: <56EA8E7A.2020101@univ-reims.fr>
References: <56EA8720.4070908@univ-reims.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
	<56EA8E7A.2020101@univ-reims.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AF3@SRVEXCHMBX.precheza.cz>

Hi

I am not an expert but it probably results from covenience plot.factor method which calls boxplot when used for or factor data.

See

graphics:::plot.factor
graphics:::boxplot.default

I belive that you can do something with ggplot like (untested)

p <-ggplot(mydf, aes(x=let, y=num))
p+geom_point()
p+geom_jitter()

or change plot.factor method, which is beyound my level.

I considered dotchart but it is used for differnt data structure.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
> Calandra
> Sent: Thursday, March 17, 2016 12:01 PM
> To: R list
> Cc: Anne CANER
> Subject: Re: [R] plot numeric vs character
>
> Thanks Petr,
>
> You're right, no need for points().
> But is there an even simpler way? I still find it strange that plot()
> does not allow points to be plotted instead of boxplots when x is a
> factor (because boxplots do not always make sense). Is there a good
> reason for that?
>
> Ivan
>
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 17/03/2016 11:48, PIKAL Petr a ?crit :
> > Hi
> >
> > It would be easier if mydf$let was factor
> >
> > plot(as.numeric(factor(mydf$let)), mydf$num, xaxt="n") axis(1,
> at=1:3,
> > levels(factor(mydf$let)))
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
> >> Calandra
> >> Sent: Thursday, March 17, 2016 11:30 AM
> >> To: R list
> >> Cc: Anne CANER
> >> Subject: [R] plot numeric vs character
> >>
> >> Dear useRs,
> >>
> >> I would like to plot data points in a simple scatterplot. I don't
> >> have a lot of data per category, so a boxplot does not make sense.
> >>
> >> Here are some sample data:
> >> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
> >> stringsAsFactors=FALSE)
> >>
> >> I would like to do that, which throws an error, most likely because
> x
> >> is
> >> character:
> >> plot(mydf$let, mydf$num)
> >>
> >> If I convert to factor(), it plots a boxplot with no possibility
> >> (AFAIK) to plot points:
> >> mydf$let <- factor(mydf$let)
> >> plot(mydf$let, mydf$num, type='p')
> >>
> >> I know I can use the function points() in a somewhat convoluted
> manner:
> >> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n') axis(side=1, at=1:3,
> >> labels=levels(mydf$let)) points(as.numeric(mydf$let), mydf$num)
> >>
> >> Isn't there a simple(r) way? Maybe I just missed something
> obvious...
> >>
> >> Thank you in advance for your help,
> >> Ivan
> >>
> >> --
> >> Ivan Calandra, PhD
> >> University of Reims Champagne-Ardenne GEGENAA - EA 3795 CREA - 2
> >> esplanade Roland Garros 51100 Reims, France
> >> +33(0)3 26 77 36 89
> >> ivan.calandra at univ-reims.fr
> >> --
> >>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jrkrideau at inbox.com  Thu Mar 17 13:04:47 2016
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 17 Mar 2016 04:04:47 -0800
Subject: [R] plot numeric vs character
In-Reply-To: <56EA8720.4070908@univ-reims.fr>
Message-ID: <E194798E63D.0000090Bjrkrideau@inbox.com>

Another approach using ggplot2 and shamelessly swiped from
http://www.sthda.com/english/wiki/ggplot2-dot-plot-quick-start-guide-r-software-and-data-visualization.

library(ggplot2)
ggplot(mydf, aes(x=let, y=num)) + 
  geom_dotplot(binaxis='y', stackdir='center', dotsize = 0.5)




John Kane
Kingston ON Canada


> -----Original Message-----
> From: ivan.calandra at univ-reims.fr
> Sent: Thu, 17 Mar 2016 11:29:52 +0100
> To: r-help at r-project.org
> Subject: [R] plot numeric vs character
> 
> Dear useRs,
> 
> I would like to plot data points in a simple scatterplot. I don't have a
> lot of data per category, so a boxplot does not make sense.
> 
> Here are some sample data:
> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
> stringsAsFactors=FALSE)
> 
> I would like to do that, which throws an error, most likely because x is
> character:
> plot(mydf$let, mydf$num)
> 
> If I convert to factor(), it plots a boxplot with no possibility (AFAIK)
> to plot points:
> mydf$let <- factor(mydf$let)
> plot(mydf$let, mydf$num, type='p')
> 
> I know I can use the function points() in a somewhat convoluted manner:
> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
> axis(side=1, at=1:3, labels=levels(mydf$let))
> points(as.numeric(mydf$let), mydf$num)
> 
> Isn't there a simple(r) way? Maybe I just missed something obvious...
> 
> Thank you in advance for your help,
> Ivan
> 
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From ivan.calandra at univ-reims.fr  Thu Mar 17 13:26:08 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 17 Mar 2016 13:26:08 +0100
Subject: [R] plot numeric vs character
In-Reply-To: <E194798E63D.0000090Bjrkrideau@inbox.com>
References: <E194798E63D.0000090Bjrkrideau@inbox.com>
Message-ID: <56EAA260.8040803@univ-reims.fr>

So it looks like there is no better "base" solution than Petr's code...
Thank you for your input anyway!

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 17/03/2016 13:04, John Kane a ?crit :
> Another approach using ggplot2 and shamelessly swiped from
> http://www.sthda.com/english/wiki/ggplot2-dot-plot-quick-start-guide-r-software-and-data-visualization.
>
> library(ggplot2)
> ggplot(mydf, aes(x=let, y=num)) +
>    geom_dotplot(binaxis='y', stackdir='center', dotsize = 0.5)
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: ivan.calandra at univ-reims.fr
>> Sent: Thu, 17 Mar 2016 11:29:52 +0100
>> To: r-help at r-project.org
>> Subject: [R] plot numeric vs character
>>
>> Dear useRs,
>>
>> I would like to plot data points in a simple scatterplot. I don't have a
>> lot of data per category, so a boxplot does not make sense.
>>
>> Here are some sample data:
>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>> stringsAsFactors=FALSE)
>>
>> I would like to do that, which throws an error, most likely because x is
>> character:
>> plot(mydf$let, mydf$num)
>>
>> If I convert to factor(), it plots a boxplot with no possibility (AFAIK)
>> to plot points:
>> mydf$let <- factor(mydf$let)
>> plot(mydf$let, mydf$num, type='p')
>>
>> I know I can use the function points() in a somewhat convoluted manner:
>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
>> axis(side=1, at=1:3, labels=levels(mydf$let))
>> points(as.numeric(mydf$let), mydf$num)
>>
>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>>
>> Thank you in advance for your help,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>
>


From boris.steipe at utoronto.ca  Thu Mar 17 13:45:54 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Mar 2016 08:45:54 -0400
Subject: [R] plot numeric vs character
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
References: <56EA8720.4070908@univ-reims.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
Message-ID: <A184C9A1-D977-4B0A-B769-F89C23B909B9@utoronto.ca>

This:

plot(match(mydf$let, letters), mydf$num)


:-)



On Mar 17, 2016, at 6:48 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> It would be easier if mydf$let was factor
> 
> plot(as.numeric(factor(mydf$let)), mydf$num, xaxt="n")
> axis(1, at=1:3, levels(factor(mydf$let)))
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
>> Calandra
>> Sent: Thursday, March 17, 2016 11:30 AM
>> To: R list
>> Cc: Anne CANER
>> Subject: [R] plot numeric vs character
>> 
>> Dear useRs,
>> 
>> I would like to plot data points in a simple scatterplot. I don't have
>> a lot of data per category, so a boxplot does not make sense.
>> 
>> Here are some sample data:
>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>> stringsAsFactors=FALSE)
>> 
>> I would like to do that, which throws an error, most likely because x
>> is
>> character:
>> plot(mydf$let, mydf$num)
>> 
>> If I convert to factor(), it plots a boxplot with no possibility
>> (AFAIK) to plot points:
>> mydf$let <- factor(mydf$let)
>> plot(mydf$let, mydf$num, type='p')
>> 
>> I know I can use the function points() in a somewhat convoluted manner:
>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n') axis(side=1, at=1:3,
>> labels=levels(mydf$let)) points(as.numeric(mydf$let), mydf$num)
>> 
>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>> 
>> Thank you in advance for your help,
>> Ivan
>> 
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Thu Mar 17 13:56:29 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 17 Mar 2016 08:56:29 -0400
Subject: [R] plot numeric vs character
In-Reply-To: <A184C9A1-D977-4B0A-B769-F89C23B909B9@utoronto.ca>
References: <56EA8720.4070908@univ-reims.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5014AAF@SRVEXCHMBX.precheza.cz>
	<A184C9A1-D977-4B0A-B769-F89C23B909B9@utoronto.ca>
Message-ID: <65B4A4B0-0A1D-4847-98D9-0F54CB4F0C48@utoronto.ca>

And let me add the generalized solution - if you don't have just single letters in the column:

plot(match(mydf$let, names(table(mydf$let))), mydf$num)


Cheers,
Boris

On Mar 17, 2016, at 8:45 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> This:
> 
> plot(match(mydf$let, letters), mydf$num)
> 
> 
> :-)
> 
> 
> 
> On Mar 17, 2016, at 6:48 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>> 
>> It would be easier if mydf$let was factor
>> 
>> plot(as.numeric(factor(mydf$let)), mydf$num, xaxt="n")
>> axis(1, at=1:3, levels(factor(mydf$let)))
>> 
>> Cheers
>> Petr
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
>>> Calandra
>>> Sent: Thursday, March 17, 2016 11:30 AM
>>> To: R list
>>> Cc: Anne CANER
>>> Subject: [R] plot numeric vs character
>>> 
>>> Dear useRs,
>>> 
>>> I would like to plot data points in a simple scatterplot. I don't have
>>> a lot of data per category, so a boxplot does not make sense.
>>> 
>>> Here are some sample data:
>>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>>> stringsAsFactors=FALSE)
>>> 
>>> I would like to do that, which throws an error, most likely because x
>>> is
>>> character:
>>> plot(mydf$let, mydf$num)
>>> 
>>> If I convert to factor(), it plots a boxplot with no possibility
>>> (AFAIK) to plot points:
>>> mydf$let <- factor(mydf$let)
>>> plot(mydf$let, mydf$num, type='p')
>>> 
>>> I know I can use the function points() in a somewhat convoluted manner:
>>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n') axis(side=1, at=1:3,
>>> labels=levels(mydf$let)) points(as.numeric(mydf$let), mydf$num)
>>> 
>>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>>> 
>>> Thank you in advance for your help,
>>> Ivan
>>> 
>>> --
>>> Ivan Calandra, PhD
>>> University of Reims Champagne-Ardenne
>>> GEGENAA - EA 3795
>>> CREA - 2 esplanade Roland Garros
>>> 51100 Reims, France
>>> +33(0)3 26 77 36 89
>>> ivan.calandra at univ-reims.fr
>>> --
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> https://publons.com/author/705639/
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From albmont at centroin.com.br  Thu Mar 17 14:27:47 2016
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Thu, 17 Mar 2016 09:27:47 -0400
Subject: [R] Typographical error in the documentation of function
 strwidth?
In-Reply-To: <99AA4B91-D97B-40B7-A412-B1464D1A63CC@gmail.com>
References: <205751964.32976515.1458164389749.JavaMail.zimbra@centroin.com.br>
	<99AA4B91-D97B-40B7-A412-B1464D1A63CC@gmail.com>
Message-ID: <335457963.37530431.1458221267532.JavaMail.zimbra@centroin.com.br>

Peter Dalgaard wrote:

> I don't think so. I'll give you that it should either be the (number of lines - 1)*spacing 
> or (number of linefeeds)*spacing, but it's correct to count the height of "M" only on the top line.
> 
> -pd
> 
> It is correct as written
> 
Ah, ok, I see now. The "line spacing" is not the line spacing, but the inter-line spacing plus
the height of "M":

"Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds - 1) times the line spacing plus the height of "M" in the selected font. For an expression it is the height of the bounding box as computed by plotmath. Thus in both cases it is an estimate of how far above the final baseline the typeset object extends. (It may also extend below the baseline.) The inter-line spacing is controlled by cex, par("lheight") and the ?point size? (but not the actual font in use)"

It's still confusing... Specially since there's no way to get the inter-line spacing except by running

strheight("M\nM") - 2 * strheight("M")

Alberto Monteiro


From pdalgd at gmail.com  Thu Mar 17 15:16:11 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 17 Mar 2016 15:16:11 +0100
Subject: [R] Typographical error in the documentation of function
	strwidth?
In-Reply-To: <335457963.37530431.1458221267532.JavaMail.zimbra@centroin.com.br>
References: <205751964.32976515.1458164389749.JavaMail.zimbra@centroin.com.br>
	<99AA4B91-D97B-40B7-A412-B1464D1A63CC@gmail.com>
	<335457963.37530431.1458221267532.JavaMail.zimbra@centroin.com.br>
Message-ID: <F933F30E-62E6-45F3-8C04-397C1866106C@gmail.com>


On 17 Mar 2016, at 14:27 , ALBERTO VIEIRA FERREIRA MONTEIRO <albmont at centroin.com.br> wrote:

> Peter Dalgaard wrote:
> 
>> I don't think so. I'll give you that it should either be the (number of lines - 1)*spacing 
>> or (number of linefeeds)*spacing, but it's correct to count the height of "M" only on the top line.
>> 
>> -pd
>> 
>> It is correct as written
>> 
> Ah, ok, I see now. The "line spacing" is not the line spacing, but the inter-line spacing plus
> the height of "M":
> 
> "Note that the ?height? of a string is determined only by the number of linefeeds ("\n") it contains: it is the (number of linefeeds - 1) times the line spacing plus the height of "M" in the selected font. For an expression it is the height of the bounding box as computed by plotmath. Thus in both cases it is an estimate of how far above the final baseline the typeset object extends. (It may also extend below the baseline.) The inter-line spacing is controlled by cex, par("lheight") and the ?point size? (but not the actual font in use)"
> 
> It's still confusing... Specially since there's no way to get the inter-line spacing except by running
> 
> strheight("M\nM") - 2 * strheight("M")
> 
> Alberto Monteiro
> 
> 

You still don't get it. It goes like this:

> strheight("M\nM") - strheight("M")
[1] 0.06733925
> 
> (strheight("M\nM\nM") - strheight("M"))/2
[1] 0.06733925
> 
> (strheight("M\nM\nM\nM") - strheight("M"))/3
[1] 0.06733925

which appears to be identical to par("cxy")[2].

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From macqueen1 at llnl.gov  Thu Mar 17 15:43:57 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 17 Mar 2016 14:43:57 +0000
Subject: [R] plot numeric vs character
In-Reply-To: <56EA8720.4070908@univ-reims.fr>
References: <56EA8720.4070908@univ-reims.fr>
Message-ID: <D3101052.167C65%macqueen1@llnl.gov>

Try

require(lattice)
dotplot(num ~ let, data=mydf)



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/17/16, 3:29 AM, "R-help on behalf of Ivan Calandra"
<r-help-bounces at r-project.org on behalf of ivan.calandra at univ-reims.fr>
wrote:

>Dear useRs,
>
>I would like to plot data points in a simple scatterplot. I don't have a
>lot of data per category, so a boxplot does not make sense.
>
>Here are some sample data:
>mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>stringsAsFactors=FALSE)
>
>I would like to do that, which throws an error, most likely because x is
>character:
>plot(mydf$let, mydf$num)
>
>If I convert to factor(), it plots a boxplot with no possibility (AFAIK)
>to plot points:
>mydf$let <- factor(mydf$let)
>plot(mydf$let, mydf$num, type='p')
>
>I know I can use the function points() in a somewhat convoluted manner:
>plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
>axis(side=1, at=1:3, labels=levels(mydf$let))
>points(as.numeric(mydf$let), mydf$num)
>
>Isn't there a simple(r) way? Maybe I just missed something obvious...
>
>Thank you in advance for your help,
>Ivan
>
>-- 
>Ivan Calandra, PhD
>University of Reims Champagne-Ardenne
>GEGENAA - EA 3795
>CREA - 2 esplanade Roland Garros
>51100 Reims, France
>+33(0)3 26 77 36 89
>ivan.calandra at univ-reims.fr
>--
>https://www.researchgate.net/profile/Ivan_Calandra
>https://secure-web.cisco.com/1yNnarZiCKUGYfSH5J2-EbF7-AArb-PmFBicLRM4tZ6aU
>HoIat5tkl5G1tDBWGbmAtfy2rKUMIAZ66QtApYQAaNn3CMmTJjQ1hLMhdkSkvRy5Xybui_V323
>YC17MiU81U_pFgX509cGmkKLXUR0SrR37kW4nS_9dceMbPir9PJL6homj56lCgTPl4i-RnpaGa
>0c3wWDheaJMEnOGkiNM-DTAg-TytL837N8slaOoHk30LoN_nZdOYAbK1afmJdDBChYrPhM28hk
>VbVrP99eKJ8rZl3jO1VsBJ_2fO8BICSQnoamvGo1v9uBfNEP0yswoj9p0zeilFKVII8JQ6CFlx
>jKfohfdIaEfstzBYALjaJSo/https%3A%2F%2Fpublons.com%2Fauthor%2F705639%2F
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From sch298 at g.uky.edu  Thu Mar 17 16:22:48 2016
From: sch298 at g.uky.edu (Chattopadhyay, Somsubhra)
Date: Thu, 17 Mar 2016 11:22:48 -0400
Subject: [R] Error in if (x[j, g] == x[i,
	g]) { : missing value where TRUE/FALSE needed
Message-ID: <CAEZ46xKF=5Erk1oJrfS=GhB6v0mjoEFXdSq_ojc4yCkoXq2UVg@mail.gmail.com>

I am using the "hydroTSM" package and "trend" package to convert my daily
time series into monthly and then analyze the seasonal trend. My code is

y <-read.csv("P-GHCNDUSW00093820.csv",as.is=TRUE)
y$DATE <- as.Date(as.character(y$DATE),format="%Y%m%d")
x <- xts(y$PRCP,y$DATE)
p <- daily2monthly(x, FUN=sum, na.rm = T)
r <- as.ts(p)
SeasonalMannKendall(r)

The last line returns an error like
Error in if (x[j, g] == x[i, g]) { :
  missing value where TRUE/FALSE needed

I suspect that the error is because of the format of the time series object
which may not be correct as in the attached image. It is making the monthly
sums correct however I don't know why there are so many NA values. Each
year should have only 12 values for the 12 months.

Any ideas how to fix this error?


-- 
*Somsubhra Chattopadhyay*
Graduate Research Assistant
Biosystems and Agricultural Engineering Department
University of Kentucky, Lexington, KY 40546
Email: schattop14 at uky.edu
Cell: 9198026951

From nilesh.dighe at monsanto.com  Thu Mar 17 18:18:34 2016
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Thu, 17 Mar 2016 17:18:34 +0000
Subject: [R] sample within a loop
Message-ID: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>

Dear R users,
                My data frame has four "groups" namely A1, B2, C3, & D4.  Each group has 12 rows (variable "plotno).  I like to randomly sample one "plotno" within each "groups" variable and label it as "CONTROL" and label others as "TEST" in a new variable called "entry".  I am trying to do this by looping over the group variable and then sample "plotno" within a given group.  I am ending up with four "CONTROL" plots but they are generated by sampling over all the groups instead of each group.  I need one random "plotno" assigned as a "CONTROL" per group (A1, B2, C3, D4).  I would appreciate any help in modifying my function "funa" or suggest any alternative and better way to do this task.  Below is the dataset and function I am working with.

# dataset (df)
structure(list(plotno = 1:48, groups = c("A1", "A1", "A1", "A1",
"A1", "A1", "A1", "A1", "A1", "A1", "A1", "A1", "B2", "B2", "B2",
"B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "C3", "C3",
"C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "D4",
"D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4"
)), .Names = c("plotno", "groups"), row.names = c(NA, -48L), class = "data.frame")

# function (funa)

function (dataset)

{

    set.seed(1)

    bay <- unique(dataset$groups)

    IND <- c()

    df2 <- dataset

    for (i in bay) {

        IND[i] <- which(plotno %in% sample(plotno, 1))

        df2$entry <- ifelse(df2$plotno %in% IND, "CONTROL", "TEST")

    }

    df2

}


# session info

R version 3.2.1 (2015-06-18)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252

[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



loaded via a namespace (and not attached):

[1] tools_3.2.1

Thanks.
Nilesh


Nilesh Dighe
(806)-252-7492 (Cell)
(806)-741-2019 (Office)


This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Mar 17 18:50:12 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 17 Mar 2016 17:50:12 +0000
Subject: [R] sample within a loop
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <D3103A8B.167C97%macqueen1@llnl.gov>

I would change strategies.

Create a new variable, say,
  num.in.grp <- rep(1:12, 4)

Then sample from 1:12, and add appropriate amounts so that they become row
numbers within the four sets of 12 rows
  ctrls <- ssample(1:12, 4, replace=TRUE) + c(0,12,24,36)

Now that we have four random row numbers, assign entry appropriately
  entry <- rep('TEST', 48)
  entry[ctrls] <- 'CONTROL'

The above is not tested, and makes several assumptions, particularly that
the data frame is sorted by groups and that there are four groups of 12
each. Thus it is does not generalize, not without some work.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/17/16, 10:18 AM, "R-help on behalf of DIGHE, NILESH [AG/2362]"
<r-help-bounces at r-project.org on behalf of nilesh.dighe at monsanto.com>
wrote:

>Dear R users,
>                My data frame has four "groups" namely A1, B2, C3, & D4.
>Each group has 12 rows (variable "plotno).  I like to randomly sample one
>"plotno" within each "groups" variable and label it as "CONTROL" and
>label others as "TEST" in a new variable called "entry".  I am trying to
>do this by looping over the group variable and then sample "plotno"
>within a given group.  I am ending up with four "CONTROL" plots but they
>are generated by sampling over all the groups instead of each group.  I
>need one random "plotno" assigned as a "CONTROL" per group (A1, B2, C3,
>D4).  I would appreciate any help in modifying my function "funa" or
>suggest any alternative and better way to do this task.  Below is the
>dataset and function I am working with.
>
># dataset (df)
>structure(list(plotno = 1:48, groups = c("A1", "A1", "A1", "A1",
>"A1", "A1", "A1", "A1", "A1", "A1", "A1", "A1", "B2", "B2", "B2",
>"B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "C3", "C3",
>"C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "D4",
>"D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4"
>)), .Names = c("plotno", "groups"), row.names = c(NA, -48L), class =
>"data.frame")
>
># function (funa)
>
>function (dataset)
>
>{
>
>    set.seed(1)
>
>    bay <- unique(dataset$groups)
>
>    IND <- c()
>
>    df2 <- dataset
>
>    for (i in bay) {
>
>        IND[i] <- which(plotno %in% sample(plotno, 1))
>
>        df2$entry <- ifelse(df2$plotno %in% IND, "CONTROL", "TEST")
>
>    }
>
>    df2
>
>}
>
>
># session info
>
>R version 3.2.1 (2015-06-18)
>
>Platform: i386-w64-mingw32/i386 (32-bit)
>
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
>
>locale:
>
>[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>States.1252    LC_MONETARY=English_United States.1252
>
>[4] LC_NUMERIC=C                           LC_TIME=English_United
>States.1252
>
>
>
>attached base packages:
>
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
>loaded via a namespace (and not attached):
>
>[1] tools_3.2.1
>
>Thanks.
>Nilesh
>
>
>Nilesh Dighe
>(806)-252-7492 (Cell)
>(806)-741-2019 (Office)
>
>
>This e-mail message may contain privileged and/or confidential
>information, and is intended to be received only by persons entitled
>to receive such information. If you have received this e-mail in error,
>please notify the sender immediately. Please delete it and
>all attachments from any servers, hard drives or any other media. Other
>use of this e-mail by you is strictly prohibited.
>
>All e-mails and attachments sent and received are subject to monitoring,
>reading and archival by Monsanto, including its
>subsidiaries. The recipient of this e-mail is solely responsible for
>checking for the presence of "Viruses" or other "Malware".
>Monsanto, along with its subsidiaries, accepts no liability for any
>damage caused by any such code transmitted by or accompanying
>this e-mail or any attachment.
>
>
>The information contained in this email may be subject to the export
>control laws and regulations of the United States, potentially
>including but not limited to the Export Administration Regulations (EAR)
>and sanctions regulations issued by the U.S. Department of
>Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of
>this information you are obligated to comply with all
>applicable U.S. export laws and regulations.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From shahab.mokari at gmail.com  Thu Mar 17 19:01:19 2016
From: shahab.mokari at gmail.com (shahab)
Date: Thu, 17 Mar 2016 19:01:19 +0100
Subject: [R] Warning message: Computation failed in `stat_bin()`: attempt to
	apply non-function
Message-ID: <CAMZxNF4bya=wwiqixrMgPf+NCZQ_zrnQq0Z7UPppc+q73YAXOg@mail.gmail.com>

Hi,

I am trying to plot a sample dataset using ggplot2, but I am keep getting
the following error message and an empty plot!
Apparently something is wrong in the dataset, but what?

R :
pf<-read.csv('pseudo_facebook.tsv', sep='\t')

ggplot(x=aes(friend_count), data=pf) + geom_histogram()

stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Warning message:
Computation failed in `stat_bin()`:
attempt to apply non-function

The dataset can be found at :
https://s3.amazonaws.com/udacity-hosted-downloads/ud651/pseudo_facebook.tsv

thanks,
/Shahab

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Thu Mar 17 19:23:51 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 17 Mar 2016 18:23:51 +0000 (UTC)
Subject: [R] sample within a loop
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <1688301551.366280.1458239031487.JavaMail.yahoo@mail.yahoo.com>

Hi, 

you can try

df1<-split(df,df$groups) 

lapply(df1, function(x) 
{ 
 x<-cbind(x,entry=0) 
 sam <- sample(x$plotno,1) 
 x$entry[which(x$plotno==sam)]<-"CONTROL" 
 x$entry[which(!x$plotno==sam)]<-"TEST" 
 x 
} 
)

 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 



________________________________
From: "DIGHE, NILESH [AG/2362]" <nilesh.dighe at monsanto.com>
To: "r-help at r-project.org" <r-help at r-project.org> 
Sent: Thursday, 17 March 2016, 18:18
Subject: [R] sample within a loop


Dear R users,
                My data frame has four "groups" namely A1, B2, C3, & D4.  Each group has 12 rows (variable "plotno).  I like to randomly sample one "plotno" within each "groups" variable and label it as "CONTROL" and label others as "TEST" in a new variable called "entry".  I am trying to do this by looping over the group variable and then sample "plotno" within a given group.  I am ending up with four "CONTROL" plots but they are generated by sampling over all the groups instead of each group.  I need one random "plotno" assigned as a "CONTROL" per group (A1, B2, C3, D4).  I would appreciate any help in modifying my function "funa" or suggest any alternative and better way to do this task.  Below is the dataset and function I am working with.

# dataset (df)
structure(list(plotno = 1:48, groups = c("A1", "A1", "A1", "A1",
"A1", "A1", "A1", "A1", "A1", "A1", "A1", "A1", "B2", "B2", "B2",
"B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "C3", "C3",
"C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "D4",
"D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4"
)), .Names = c("plotno", "groups"), row.names = c(NA, -48L), class = "data.frame")

# function (funa)

function (dataset)

{

    set.seed(1)

    bay <- unique(dataset$groups)

    IND <- c()

    df2 <- dataset

    for (i in bay) {

        IND[i] <- which(plotno %in% sample(plotno, 1))

        df2$entry <- ifelse(df2$plotno %in% IND, "CONTROL", "TEST")

    }

    df2

}


# session info

R version 3.2.1 (2015-06-18)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252

[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



loaded via a namespace (and not attached):

[1] tools_3.2.1

Thanks.
Nilesh


Nilesh Dighe
(806)-252-7492 (Cell)
(806)-741-2019 (Office)


This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nilesh.dighe at monsanto.com  Thu Mar 17 20:32:44 2016
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Thu, 17 Mar 2016 19:32:44 +0000
Subject: [R] sample within a loop
In-Reply-To: <1688301551.366280.1458239031487.JavaMail.yahoo@mail.yahoo.com>
References: <24156952D190E841BF8E66CB59FAB94A4DD0EB2E@STLWEXMBXPRD14.na.ds.monsanto.com>
	<1688301551.366280.1458239031487.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <24156952D190E841BF8E66CB59FAB94A4DD0EE47@STLWEXMBXPRD14.na.ds.monsanto.com>

Tanvir & Don:  Thanks a lot for your solutions.  Both solutions work great.  I really appreciate your help.
Regards,
Nilesh

-----Original Message-----
From: Mohammad Tanvir Ahamed [mailto:mashranga at yahoo.com] 
Sent: Thursday, March 17, 2016 1:24 PM
To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
Subject: Re: [R] sample within a loop

Hi, 

you can try

df1<-split(df,df$groups) 

lapply(df1, function(x) 
{ 
 x<-cbind(x,entry=0) 
 sam <- sample(x$plotno,1) 
 x$entry[which(x$plotno==sam)]<-"CONTROL" 
 x$entry[which(!x$plotno==sam)]<-"TEST" 
 x 
} 
)

 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 



________________________________
From: "DIGHE, NILESH [AG/2362]" <nilesh.dighe at monsanto.com>
To: "r-help at r-project.org" <r-help at r-project.org> 
Sent: Thursday, 17 March 2016, 18:18
Subject: [R] sample within a loop


Dear R users,
                My data frame has four "groups" namely A1, B2, C3, & D4.  Each group has 12 rows (variable "plotno).  I like to randomly sample one "plotno" within each "groups" variable and label it as "CONTROL" and label others as "TEST" in a new variable called "entry".  I am trying to do this by looping over the group variable and then sample "plotno" within a given group.  I am ending up with four "CONTROL" plots but they are generated by sampling over all the groups instead of each group.  I need one random "plotno" assigned as a "CONTROL" per group (A1, B2, C3, D4).  I would appreciate any help in modifying my function "funa" or suggest any alternative and better way to do this task.  Below is the dataset and function I am working with.

# dataset (df)
structure(list(plotno = 1:48, groups = c("A1", "A1", "A1", "A1",
"A1", "A1", "A1", "A1", "A1", "A1", "A1", "A1", "B2", "B2", "B2",
"B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "B2", "C3", "C3",
"C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "C3", "D4",
"D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4", "D4"
)), .Names = c("plotno", "groups"), row.names = c(NA, -48L), class = "data.frame")

# function (funa)

function (dataset)

{

    set.seed(1)

    bay <- unique(dataset$groups)

    IND <- c()

    df2 <- dataset

    for (i in bay) {

        IND[i] <- which(plotno %in% sample(plotno, 1))

        df2$entry <- ifelse(df2$plotno %in% IND, "CONTROL", "TEST")

    }

    df2

}


# session info

R version 3.2.1 (2015-06-18)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252

[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



loaded via a namespace (and not attached):

[1] tools_3.2.1

Thanks.
Nilesh


Nilesh Dighe
(806)-252-7492 (Cell)
(806)-741-2019 (Office)


This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

From xavier.chiriboga at unine.ch  Thu Mar 17 21:47:35 2016
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 17 Mar 2016 20:47:35 +0000
Subject: [R] ERROR in make.link(link)
Message-ID: <1458247655362.26392@unine.ch>

Dear all,


I am using R version 3.1.3. I want to run this model:

m1<-glmer(hours~soil*volatile+(1|replicate),  data=data,    family=Gamma(link = "inv"))


But I got this:

Erreur within make.link(link) : 'inv' link not recognised


What to do in this case?


THANK YOU for help!


Xavier

PhD candidate

Biology

UNINE, Switzerlnad


From dwinsemius at comcast.net  Thu Mar 17 21:53:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Mar 2016 13:53:01 -0700
Subject: [R] Error in if (x[j, g] == x[i,
	g]) { : missing value where TRUE/FALSE needed
In-Reply-To: <CAEZ46xKF=5Erk1oJrfS=GhB6v0mjoEFXdSq_ojc4yCkoXq2UVg@mail.gmail.com>
References: <CAEZ46xKF=5Erk1oJrfS=GhB6v0mjoEFXdSq_ojc4yCkoXq2UVg@mail.gmail.com>
Message-ID: <B2B152A3-E0F7-4B5B-838A-EC6F254B836E@comcast.net>


> On Mar 17, 2016, at 8:22 AM, Chattopadhyay, Somsubhra <sch298 at g.uky.edu> wrote:
> 
> I am using the "hydroTSM" package and "trend" package to convert my daily
> time series into monthly and then analyze the seasonal trend. My code is
> 
> y <-read.csv("P-GHCNDUSW00093820.csv",as.is=TRUE)
> y$DATE <- as.Date(as.character(y$DATE),format="%Y%m%d")
> x <- xts(y$PRCP,y$DATE)
> p <- daily2monthly(x, FUN=sum, na.rm = T)
> r <- as.ts(p)
> SeasonalMannKendall(r)
> 
> The last line returns an error like
> Error in if (x[j, g] == x[i, g]) { :
>  missing value where TRUE/FALSE needed

After each line of code you should be examining the results of `str` applied to the results to see if you are actually succeeding. And given the error message you might consider looking at:

 sum( is.na( y$DATE))


> 
> I suspect that the error is because of the format of the time series object
> which may not be correct as in the attached image.


No image attached. Read the info page and the posting guide again.

> It is making the monthly
> sums correct however I don't know why there are so many NA values. Each
> year should have only 12 values for the 12 months.
> 
> Any ideas how to fix this error?
> 
> 
> -- 
> *Somsubhra Chattopadhyay*

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Mar 17 21:56:35 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Mar 2016 13:56:35 -0700
Subject: [R] ERROR in make.link(link)
In-Reply-To: <1458247655362.26392@unine.ch>
References: <1458247655362.26392@unine.ch>
Message-ID: <6099C1A2-DE1B-4B9E-889E-13B3B90FD239@comcast.net>


> On Mar 17, 2016, at 1:47 PM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
> 
> Dear all,
> 
> 
> I am using R version 3.1.3. I want to run this model:
> 
> m1<-glmer(hours~soil*volatile+(1|replicate),  data=data,    family=Gamma(link = "inv"))
> 
> 
> But I got this:
> 
> Erreur within make.link(link) : 'inv' link not recognised
> 
> 
> What to do in this case?

Have you tried omitting an argument to Gamma? The default is "inverse" and "inv" may not be matching "inverse".

-- 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Mar 17 22:11:29 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 18 Mar 2016 10:11:29 +1300
Subject: [R] [FORGED]  ERROR in make.link(link)
In-Reply-To: <1458247655362.26392@unine.ch>
References: <1458247655362.26392@unine.ch>
Message-ID: <56EB1D81.5030907@auckland.ac.nz>

On 18/03/16 09:47, CHIRIBOGA Xavier wrote:
> Dear all,
>
>
> I am using R version 3.1.3. I want to run this model:
>
> m1<-glmer(hours~soil*volatile+(1|replicate),  data=data,    family=Gamma(link = "inv"))
>
>
> But I got this:
>
> Erreur within make.link(link) : 'inv' link not recognised
>
>
> What to do in this case?

What to do?  Use the correct syntax! Your call should be:

     family=Gamma(link="inverse")

The name of the link must be specified *completely*; partial matching is 
not used, for fairly obvious reasons.

Actually you could just do "family=Gamma" since "inverse" is the 
*default* link.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dulcalma at bigpond.com  Fri Mar 18 00:52:08 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 18 Mar 2016 10:52:08 +1100
Subject: [R] plot numeric vs character
In-Reply-To: <56EAA260.8040803@univ-reims.fr>
References: <E194798E63D.0000090Bjrkrideau@inbox.com>
	<56EAA260.8040803@univ-reims.fr>
Message-ID: <000801d180a8$05305650$0f9102f0$@bigpond.com>

I haven't been following the thread but!
If you want to use lattice xyplot

# create x values in their right position -- 
# assuming equal spacing
mydf$x = rep(1:3, each = 3)

library(lattice)
xyplot(num ~ x, mydf,
             scales = list(x = list(at = 1:3, label = letters[1:3])),
             xlab = "")

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
Calandra
Sent: Thursday, 17 March 2016 23:26
To: R list
Cc: Anne CANER
Subject: Re: [R] plot numeric vs character

So it looks like there is no better "base" solution than Petr's code...
Thank you for your input anyway!

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 17/03/2016 13:04, John Kane a ?crit :
> Another approach using ggplot2 and shamelessly swiped from
>
http://www.sthda.com/english/wiki/ggplot2-dot-plot-quick-start-guide-r-softw
are-and-data-visualization.
>
> library(ggplot2)
> ggplot(mydf, aes(x=let, y=num)) +
>    geom_dotplot(binaxis='y', stackdir='center', dotsize = 0.5)
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: ivan.calandra at univ-reims.fr
>> Sent: Thu, 17 Mar 2016 11:29:52 +0100
>> To: r-help at r-project.org
>> Subject: [R] plot numeric vs character
>>
>> Dear useRs,
>>
>> I would like to plot data points in a simple scatterplot. I don't have a
>> lot of data per category, so a boxplot does not make sense.
>>
>> Here are some sample data:
>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>> stringsAsFactors=FALSE)
>>
>> I would like to do that, which throws an error, most likely because x is
>> character:
>> plot(mydf$let, mydf$num)
>>
>> If I convert to factor(), it plots a boxplot with no possibility (AFAIK)
>> to plot points:
>> mydf$let <- factor(mydf$let)
>> plot(mydf$let, mydf$num, type='p')
>>
>> I know I can use the function points() in a somewhat convoluted manner:
>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
>> axis(side=1, at=1:3, labels=levels(mydf$let))
>> points(as.numeric(mydf$let), mydf$num)
>>
>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>>
>> Thank you in advance for your help,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bharathsivaram at gmail.com  Fri Mar 18 01:48:57 2016
From: bharathsivaram at gmail.com (Bharath Sivaram)
Date: Thu, 17 Mar 2016 20:48:57 -0400
Subject: [R] Error with fortify() and and incorrect output of facet_wrap
 when plotting spatial census data
Message-ID: <CAEpW0Dg2F1uUNn-NGJSG9+Gy9L4v_j31VOC66kjqkAnhsaq5TQ@mail.gmail.com>

I am trying to plot the US census data using ggplot2. I was able to plot
the data for one specific year ( all states) and generate the map with
correct data. When I try to combine a couple of years together to analyse
the trend over a period, I am getting errors with both Fortify and
facet_wrap.

When I use fortify after combining multiple years to the @dataof the
spatial object I get this error:

Error in maptools::unionSpatialPolygons(cp, attr[, region]) : input lengths
differ

I tried to implement the solution provided in this stackoverflow
question Drawing
maps based on census data using ggplot2
<http://stackoverflow.com/questions/12233966/drawing-maps-based-on-census-data-using-ggplot2>
but
that does not seem to work for me.

Since I am not sure of the purpose behind using region="id in fortify, I
used the function without it. Fortify works fine but I am facing issues
with the output of Facet_Wrap(). I seem to face the same issue as this user R,
Incorrect output from ggplot2 and facet_wrap when using spatial data
<http://stackoverflow.com/questions/30083382/r-incorrect-output-from-ggplot2-and-facet-wrap-when-using-spatial-data>
but
the question is not answered.

I have followed the steps mentioned in
http://spatial.ly/2013/12/introduction-spatial-data-ggplot2/ and I am not
able to figure out the issue


Code:

#Import the data from the web and make it tidy.  This data includes
years      from 1900-2000

url<-"http://www.demographia.com/db-state1900.htm"
pop_00<-readHTMLTable(url,which = 1,skip=1,stringsAsFactors=FALSE)
pop_00<-tbl_df(pop_00)
pop_00<-pop_00%>%gather(date,pop,-State)%>%filter(date!="2003")
colnames(pop_00)[1]<-"name"
#Import 2010 data from
https://www.census.gov/popest/data/national/totals/2015/files/NST-EST2015-alldata.csv

uspop_10<-read.csv("NST-EST2015-alldata.csv")
poptidy<-tbl_df(uspop_10)
colnames(poptidy)<-tolower(colnames(poptidy))
poptidy<-select(poptidy,c(name,census2010pop))
poptidy<-poptidy%>%gather(date,pop,-name)
poptidy$date<-gsub("census2010pop","2010",poptidy$date)
pop_sub<-rbind(poptidy,pop_00)
pop_sub$pop<-as.numeric(pop_sub$pop)
# Download list of states to filter unwanted rows in the pop_sub table

url_state<-"http://www.columbia.edu/~sue/state-fips.html"
state_fips<-readHTMLTable(url_state,which=1)
pop_sub<-filter(pop_sub,name %in% state_fips$`State or District`)
# Shape file of US https://www.census.gov/geo/maps-
data/data/cbf/cbf_state.html

usmap<-readOGR("cb_2014_us_state_500k",layer="cb_2014_us_state_500k")
colnames(usmap at data)<-tolower(colnames(usmap at data))
usmap at data<-left_join(usmap at data,pop_sub,"name")
usmap at data$id <-row.names(usmap at data)
usmap_f<-fortify(usmap,region="id")
usmap_f<-inner_join(usmap_f,usmap at data,"id")
           ggplot(usmap_f)+aes(long,lat,group=group,fill=pop/1000)+geom_polygon()+facet_wrap(~date)+coord_map(xlim=c(-150,-50),ylim=c(20,50))+scale_fill_gradient2(low="green",mid="blue",high="red",midpoint=15000,name="Population
in Thousands")+geom_path(colour="black", lwd=0.05)


Thanks
Bharath Sivaraman

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Fri Mar 18 09:46:36 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 18 Mar 2016 09:46:36 +0100
Subject: [R] plot numeric vs character
In-Reply-To: <CADv2QyFyjGnNJWQhMPRCL4u83iAoQCS+cYKud+0uLvWVLoFnmA@mail.gmail.com>
References: <56EA8720.4070908@univ-reims.fr>
	<CADv2QyFyjGnNJWQhMPRCL4u83iAoQCS+cYKud+0uLvWVLoFnmA@mail.gmail.com>
Message-ID: <56EBC06C.5050404@univ-reims.fr>

That does the trick with base functions!
Thanks Dennis.

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 17/03/2016 20:48, Dennis Murphy a ?crit :
> Hi:
>
> Try
>
> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>                     stringsAsFactors=FALSE)
>
> stripchart(num ~ let, data = mydf, pch = 19, vertical = TRUE)
>
>
> Dennis
>
> On Thu, Mar 17, 2016 at 3:29 AM, Ivan Calandra
> <ivan.calandra at univ-reims.fr> wrote:
>> Dear useRs,
>>
>> I would like to plot data points in a simple scatterplot. I don't have a lot
>> of data per category, so a boxplot does not make sense.
>>
>> Here are some sample data:
>> mydf <- data.frame(let=rep(letters[1:3],each=3), num=rnorm(9),
>> stringsAsFactors=FALSE)
>>
>> I would like to do that, which throws an error, most likely because x is
>> character:
>> plot(mydf$let, mydf$num)
>>
>> If I convert to factor(), it plots a boxplot with no possibility (AFAIK) to
>> plot points:
>> mydf$let <- factor(mydf$let)
>> plot(mydf$let, mydf$num, type='p')
>>
>> I know I can use the function points() in a somewhat convoluted manner:
>> plot(mydf$num, xlim=c(1,3), type='n', xaxt='n')
>> axis(side=1, at=1:3, labels=levels(mydf$let))
>> points(as.numeric(mydf$let), mydf$num)
>>
>> Isn't there a simple(r) way? Maybe I just missed something obvious...
>>
>> Thank you in advance for your help,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Fri Mar 18 10:02:28 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Fri, 18 Mar 2016 22:02:28 +1300
Subject: [R] What "method" does sort() use?
Message-ID: <20160318090228.GA2013@slingshot.co.nz>

I don't follow why this happens:

> sort(c(LETTERS[1:5], letters[1:5]))
 [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E"

The help for sort() says:

  method: character string specifying the algorithm used.  Not
          available for partial sorting.  Can be abbreviated.

But what are the methods available?  The help mentions xtfrm but that
doesn't illuminate, I'd have thought that at least by default it would
have something to do with ASCII codes.  But that's not the case since
all the uppercase ones would be before the lowercase ones.

I know something different is happening but I don't know what it is
(do you, Mr Jones?).  Apologies to Bob Dylan.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From pdalgd at gmail.com  Fri Mar 18 10:13:59 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 18 Mar 2016 10:13:59 +0100
Subject: [R] What "method" does sort() use?
In-Reply-To: <20160318090228.GA2013@slingshot.co.nz>
References: <20160318090228.GA2013@slingshot.co.nz>
Message-ID: <C86BBDF5-72D8-4260-954B-172A522E1049@gmail.com>


On 18 Mar 2016, at 10:02 , Patrick Connolly <p_connolly at slingshot.co.nz> wrote:

> I don't follow why this happens:
> 
>> sort(c(LETTERS[1:5], letters[1:5]))
> [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E"
> 
> The help for sort() says:
> 
>  method: character string specifying the algorithm used.  Not
>          available for partial sorting.  Can be abbreviated.
> 
> But what are the methods available?  The help mentions xtfrm but that
> doesn't illuminate, I'd have thought that at least by default it would
> have something to do with ASCII codes.  But that's not the case since
> all the uppercase ones would be before the lowercase ones.
> 
> I know something different is happening but I don't know what it is
> (do you, Mr Jones?).  Apologies to Bob Dylan.
> 


Um, read _all_ of the help file?

sort.int(x, partial = NULL, na.last = NA, decreasing = FALSE,
         method = c("shell", "quick"), index.return = FALSE)

[snip]

Method "shell" uses Shellsort (an O(n^{4/3}) variant from Sedgewick (1986)). If x has names a stable modification is used, so ties are not reordered. (This only matters if names are present.)

Method "quick" uses Singleton (1969)'s implementation of Hoare's Quicksort method and is only available when x is numeric (double or integer) and partial is NULL. (For other types of x Shellsort is used, silently.) It is normally somewhat faster than Shellsort (perhaps 50% faster on vectors of length a million and twice as fast at a billion) but has poor performance in the rare worst case. (Peto's modification using a pseudo-random midpoint is used to make the worst case rarer.) This is not a stable sort, and ties may be reordered.

Factors with less than 100,000 levels are sorted by radix sorting when method is not supplied: see sort.list.

-pd


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Mar 18 10:19:40 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 18 Mar 2016 10:19:40 +0100
Subject: [R] What "method" does sort() use?
In-Reply-To: <C86BBDF5-72D8-4260-954B-172A522E1049@gmail.com>
References: <20160318090228.GA2013@slingshot.co.nz>
	<C86BBDF5-72D8-4260-954B-172A522E1049@gmail.com>
Message-ID: <4993E91C-AA99-42D0-9781-093D6CA7425B@gmail.com>

Ooops, that was answering the question you actually asked. The one you meant to ask is answered by this  part:

The sort order for character vectors will depend on the collating sequence of the locale in use: see Comparison. 

...and collating sequences is a weird and woolly subject, where you cannot even be sure that locales of the same name on two different platforms sort strings in the same order.

-pd



On 18 Mar 2016, at 10:13 , peter dalgaard <pdalgd at gmail.com> wrote:

> 
> On 18 Mar 2016, at 10:02 , Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
> 
>> I don't follow why this happens:
>> 
>>> sort(c(LETTERS[1:5], letters[1:5]))
>> [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E"
>> 
>> The help for sort() says:
>> 
>> method: character string specifying the algorithm used.  Not
>>         available for partial sorting.  Can be abbreviated.
>> 
>> But what are the methods available?  The help mentions xtfrm but that
>> doesn't illuminate, I'd have thought that at least by default it would
>> have something to do with ASCII codes.  But that's not the case since
>> all the uppercase ones would be before the lowercase ones.
>> 
>> I know something different is happening but I don't know what it is
>> (do you, Mr Jones?).  Apologies to Bob Dylan.
>> 
> 
> 
> Um, read _all_ of the help file?
> 
> sort.int(x, partial = NULL, na.last = NA, decreasing = FALSE,
>         method = c("shell", "quick"), index.return = FALSE)
> 
> [snip]
> 
> Method "shell" uses Shellsort (an O(n^{4/3}) variant from Sedgewick (1986)). If x has names a stable modification is used, so ties are not reordered. (This only matters if names are present.)
> 
> Method "quick" uses Singleton (1969)'s implementation of Hoare's Quicksort method and is only available when x is numeric (double or integer) and partial is NULL. (For other types of x Shellsort is used, silently.) It is normally somewhat faster than Shellsort (perhaps 50% faster on vectors of length a million and twice as fast at a billion) but has poor performance in the rare worst case. (Peto's modification using a pseudo-random midpoint is used to make the worst case rarer.) This is not a stable sort, and ties may be reordered.
> 
> Factors with less than 100,000 levels are sorted by radix sorting when method is not supplied: see sort.list.
> 
> -pd
> 
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From danprec at hotmail.com  Fri Mar 18 10:45:53 2016
From: danprec at hotmail.com (Daniel Preciado)
Date: Fri, 18 Mar 2016 10:45:53 +0100
Subject: [R] R / G GUI freezes saving plot
Message-ID: <BLU436-SMTP5F33697FC01377EF52D0CA08C0@phx.gbl>

Randomly, whenever I try to save a plot, R becomes unresponsive and has to be killed. This happens almost every time.

R version 3.2.4 (2016-03-10) -- "Very Secure Dishes?
Platform: x86_64-apple-darwin13.4.0 (64-bit)
R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0
Os el capitan 10.11.3 (Although the problem was present in previous versions)

How to prevent this?




	[[alternative HTML version deleted]]


From jordanmeyer1991 at gmail.com  Fri Mar 18 14:30:29 2016
From: jordanmeyer1991 at gmail.com (Jordan Meyer)
Date: Fri, 18 Mar 2016 09:30:29 -0400
Subject: [R] R / G GUI freezes saving plot
In-Reply-To: <BLU436-SMTP5F33697FC01377EF52D0CA08C0@phx.gbl>
References: <BLU436-SMTP5F33697FC01377EF52D0CA08C0@phx.gbl>
Message-ID: <CAF+g6rqGy8YQ-sNMU+ZWrGu5ckTPiTWpmYyBuQoihdnUeSof+w@mail.gmail.com>

Are there any particular types of plotting you are doing when it becomes
unresponsive? If so, it would be helpful to see an example.

On Fri, Mar 18, 2016 at 5:45 AM, Daniel Preciado <danprec at hotmail.com>
wrote:

> Randomly, whenever I try to save a plot, R becomes unresponsive and has to
> be killed. This happens almost every time.
>
> R version 3.2.4 (2016-03-10) -- "Very Secure Dishes?
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0
> Os el capitan 10.11.3 (Although the problem was present in previous
> versions)
>
> How to prevent this?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From danprec at hotmail.com  Fri Mar 18 14:52:57 2016
From: danprec at hotmail.com (Daniel Preciado)
Date: Fri, 18 Mar 2016 14:52:57 +0100
Subject: [R] R / G GUI freezes saving plot
In-Reply-To: <CAF+g6rqGy8YQ-sNMU+ZWrGu5ckTPiTWpmYyBuQoihdnUeSof+w@mail.gmail.com>
References: <BLU436-SMTP5F33697FC01377EF52D0CA08C0@phx.gbl>
	<CAF+g6rqGy8YQ-sNMU+ZWrGu5ckTPiTWpmYyBuQoihdnUeSof+w@mail.gmail.com>
Message-ID: <BLU437-SMTP55FE42D3B0ACC108412606A08C0@phx.gbl>

No, nothing particular at all I would say. I generate plots either with functions from base R (such as plot() ) or ggplot2. Plotting functions are fine, so long as I don?t try to save them?. I also noted that the issue is most frequent when I save the plots from the menu (File>Save as) than if I save them from the command line using for example pdf() (But it still happens sometimes saving files from the command line).

From:  Jordan Meyer <jordanmeyer1991 at gmail.com>
Date:  Friday 18 March 2016 at 14:30
To:  dp <danprec at hotmail.com>
Cc:  <r-help at r-project.org>
Subject:  Re: [R] R / G GUI freezes saving plot

Are there any particular types of plotting you are doing when it becomes unresponsive? If so, it would be helpful to see an example.

On Fri, Mar 18, 2016 at 5:45 AM, Daniel Preciado <danprec at hotmail.com> wrote:
Randomly, whenever I try to save a plot, R becomes unresponsive and has to be killed. This happens almost every time.

R version 3.2.4 (2016-03-10) -- "Very Secure Dishes?
Platform: x86_64-apple-darwin13.4.0 (64-bit)
R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0
Os el capitan 10.11.3 (Although the problem was present in previous versions)

How to prevent this?




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Fri Mar 18 15:42:13 2016
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 18 Mar 2016 07:42:13 -0700
Subject: [R] dev.new() throws error from command line
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74C1003818E5@EXVMBX018-3.exch018.msoutlookonline.net>

I am running in Windows 8. I noticed this particular problem running a script in R 2.9.2 from the command line.

I have an r script that I wrote some time ago. It is fairly complicated and does a lot of time-consuming optimizations, following which it populates a SQL database with the results. The whole thing takes maybe 10-15 minutes to run.

Because it takes a while to run, I have it automatically kicking off in the early morning using a command-line instruction from System Scheduler.

The script ran fine for a long time...actually, for a few years. Recently, it started to run but kill out at one point. When I run it from a new R session, manually pasting in the script, it runs fine.

After some elementary debugging I discovered that the error is happening when I call dev.new() . Again, this never had a problem before, and it doesn't have a problem when run in the R window, but when the script is run in the command line it throws this error:

"no suitable unused file name for pdf()"

No idea what this means as I'm not calling a pdf device...unless somehow when it's command-line R assumes you don't want a window but a pdf. If that's the case I still can't figure out why there's suddenly a problem finding "unused file names."

Any suggestions would be welcome!

Thanks,

Mike

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


________________________________
This email and any attachments are confidential and inte...{{dropped:9}}


From bgunter.4567 at gmail.com  Fri Mar 18 16:32:23 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 18 Mar 2016 08:32:23 -0700
Subject: [R] dev.new() throws error from command line
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74C1003818E5@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74C1003818E5@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <CAGxFJbS+Fx8EA_73SFmXfgEqzspmwMDAzGG+xKZs-z-+7Se4BA@mail.gmail.com>

1. This is just a semi-educated guess on my part -- hopefully you'll
get a better response from someone else. But consider:

2. Read carefully the "dev.new" section of ?dev. My guess on that
basis is that the default given by getOption("device") is set in your
R window, but not in a command line script. So you might try
explicitly setting it in your script first and see if that fixes
things.

3. I have no idea why this should have changed from earlier versions.
Perhaps a bug???

4. Please again note point1. Ny guess could be complete nonsense. Caveat emptor!

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 18, 2016 at 7:42 AM, Michael Ashton
<m.ashton at enduringinvestments.com> wrote:
> I am running in Windows 8. I noticed this particular problem running a script in R 2.9.2 from the command line.
>
> I have an r script that I wrote some time ago. It is fairly complicated and does a lot of time-consuming optimizations, following which it populates a SQL database with the results. The whole thing takes maybe 10-15 minutes to run.
>
> Because it takes a while to run, I have it automatically kicking off in the early morning using a command-line instruction from System Scheduler.
>
> The script ran fine for a long time...actually, for a few years. Recently, it started to run but kill out at one point. When I run it from a new R session, manually pasting in the script, it runs fine.
>
> After some elementary debugging I discovered that the error is happening when I call dev.new() . Again, this never had a problem before, and it doesn't have a problem when run in the R window, but when the script is run in the command line it throws this error:
>
> "no suitable unused file name for pdf()"
>
> No idea what this means as I'm not calling a pdf device...unless somehow when it's command-line R assumes you don't want a window but a pdf. If that's the case I still can't figure out why there's suddenly a problem finding "unused file names."
>
> Any suggestions would be welcome!
>
> Thanks,
>
> Mike
>
> Michael Ashton, CFA
> Managing Principal
>
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
>
>
> ________________________________
> This email and any attachments are confidential and inte...{{dropped:9}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Fri Mar 18 17:39:10 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 18 Mar 2016 08:39:10 -0800
Subject: [R] Warning message: Computation failed in `stat_bin()`:
 attempt to apply non-function
In-Reply-To: <CAMZxNF4bya=wwiqixrMgPf+NCZQ_zrnQq0Z7UPppc+q73YAXOg@mail.gmail.com>
Message-ID: <F08C6D795CB.0000072Bjrkrideau@inbox.com>

> ggplot(x=aes(friend_count), data=pf) + geom_histogram()

The x= in the above statement is wrong

ggplot(aes(friend_count), data=pf) + geom_histogram()
will work but it looks funny.


The more common way to write the command would likely be:
ggplot(pf, aes(friend_count)) + geom_histogram()


The tat_bin() message is  just a warning.
Your data set has ~ 99,000 rows of data and geom_histogram() 's default is 30 bins which is probably too few to for you to see what is happening.  Come to 

Change the default binwidth to something a bit more manageable or perhaps use geom_density() to look at the distribution.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shahab.mokari at gmail.com
> Sent: Thu, 17 Mar 2016 19:01:19 +0100
> To: r-help at r-project.org
> Subject: [R] Warning message: Computation failed in `stat_bin()`: attempt
> to apply non-function
> 
> Hi,
> 
> I am trying to plot a sample dataset using ggplot2, but I am keep getting
> the following error message and an empty plot!
> Apparently something is wrong in the dataset, but what?
> 
> R :
> pf<-read.csv('pseudo_facebook.tsv', sep='\t')
> 
> ggplot(x=aes(friend_count), data=pf) + geom_histogram()
> 
> stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
> Warning message:
> Computation failed in `stat_bin()`:
> attempt to apply non-function
> 
> The dataset can be found at :
> https://s3.amazonaws.com/udacity-hosted-downloads/ud651/pseudo_facebook.tsv
> 
> thanks,
> /Shahab
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From Nazatulshima.Hassan at liverpool.ac.uk  Fri Mar 18 17:00:20 2016
From: Nazatulshima.Hassan at liverpool.ac.uk (Hassan, Nazatulshima)
Date: Fri, 18 Mar 2016 16:00:20 +0000
Subject: [R] variable selection using residual difference
Message-ID: <B653E9EFB809DA4ABF9EFA0944845675059FBD31@BHEXMBX2.livad.liv.ac.uk>

I have the following example dataset
set.seed(2001)
n <- 100
Y <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
X1 <- sample(x=c(0,1,2), size=n, replace=TRUE, prob=c(0.1,0.4,0.5))
X2 <- sample(x=c(0,1,2), size=n, replace=TRUE, prob=c(0.5,0.25,0.25))
X3 <- c(0,2,2,2,2,2,2,2,0,2,0,2,2,0,0,0,0,0,2,0,0,2,2,0,0,2,2,2,0,2,0,2,0,2,1,2,1,1,1,1,1,1,1,1,1,1,1,0,1,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0)

dat <- data.frame(Y,X1,X2,X3)

I fit a logistic regression model to each of the variable to rank them based on the residual difference (highest to lowest). To simplify I got the rank as X3,X1 and X2. Then, I fit a second order model as follows and again calculate the res_dif :
mod1 <- glm(Y~X3+X1, family=binomial, data=dat)
mod1$null.deviance-mod1$deviance
mod2 <- glm(Y~X3+X2, family=binomial,data=dat)
mod2$null.deviance-mod2$deviance

Again, I will rank the model based on res_dif (highest to lowest). So here, I choose mod2. From there I will fit the third order model as follows :
mod3 <- glm(Y~X3+X2+X1, family=binomial, data=dat)
mod3$null.deviance-mod3$deviance

Basically, this continues until it fits the maximum number of variables that you have in the data.
My aim is to do variable selection based on res_dif instead of AIC, BIC or R2. Since my actual dataset is dealing with 100 of variables, I wonder how can I apply this using loop function.

Any suggestions would be appreciated.

Kind Regards
Shima


	[[alternative HTML version deleted]]


From hehuan86 at vt.edu  Fri Mar 18 17:44:57 2016
From: hehuan86 at vt.edu (Hehuan Liao)
Date: Fri, 18 Mar 2016 12:44:57 -0400
Subject: [R] Party package: varimp(..., conditional=TRUE) error
Message-ID: <CA+g3MWgYMeqgmH_to6GXn54jrLaav4x9Hr4Uwz2qQbyc7CEMcQ@mail.gmail.com>

Hello,

I'm running up against similar problems as described previously:
https://stat.ethz.ch/pipermail/r-help/2011-October/292897.html

I've tried to set threshold=0.99, however, I got another error message:
 "Error: cannot allocate vector of size 52.8 Gb"

I tried to run my code on a supercomputer with 100GB memory, however, I got
another error message: "Error: cannot allocate vector of size 127.8 Gb"

So, I guess that it might not be a real problem with memory size. Does
anyone know what's wrong?

Thanks!
Cathy

	[[alternative HTML version deleted]]


From shahab.mokari at gmail.com  Fri Mar 18 19:01:09 2016
From: shahab.mokari at gmail.com (shahab)
Date: Fri, 18 Mar 2016 19:01:09 +0100
Subject: [R] Warning message: Computation failed in `stat_bin()`:
 attempt to apply non-function
In-Reply-To: <F08C6D795CB.0000072Bjrkrideau@inbox.com>
References: <CAMZxNF4bya=wwiqixrMgPf+NCZQ_zrnQq0Z7UPppc+q73YAXOg@mail.gmail.com>
	<F08C6D795CB.0000072Bjrkrideau@inbox.com>
Message-ID: <CAMZxNF4kuMtQJb49cBRpPyWtmA2SNCz_ao_EJze=FFxuXfgN-g@mail.gmail.com>

Thanks all for the help. Yes it works now, my stupid mistake.

On Friday, 18 March 2016, John Kane <jrkrideau at inbox.com> wrote:

> > ggplot(x=aes(friend_count), data=pf) + geom_histogram()
>
> The x= in the above statement is wrong
>
> ggplot(aes(friend_count), data=pf) + geom_histogram()
> will work but it looks funny.
>
>
> The more common way to write the command would likely be:
> ggplot(pf, aes(friend_count)) + geom_histogram()
>
>
> The tat_bin() message is  just a warning.
> Your data set has ~ 99,000 rows of data and geom_histogram() 's default is
> 30 bins which is probably too few to for you to see what is happening.
> Come to
>
> Change the default binwidth to something a bit more manageable or perhaps
> use geom_density() to look at the distribution.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: shahab.mokari at gmail.com <javascript:;>
> > Sent: Thu, 17 Mar 2016 19:01:19 +0100
> > To: r-help at r-project.org <javascript:;>
> > Subject: [R] Warning message: Computation failed in `stat_bin()`: attempt
> > to apply non-function
> >
> > Hi,
> >
> > I am trying to plot a sample dataset using ggplot2, but I am keep getting
> > the following error message and an empty plot!
> > Apparently something is wrong in the dataset, but what?
> >
> > R :
> > pf<-read.csv('pseudo_facebook.tsv', sep='\t')
> >
> > ggplot(x=aes(friend_count), data=pf) + geom_histogram()
> >
> > stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
> > Warning message:
> > Computation failed in `stat_bin()`:
> > attempt to apply non-function
> >
> > The dataset can be found at :
> >
> https://s3.amazonaws.com/udacity-hosted-downloads/ud651/pseudo_facebook.tsv
> >
> > thanks,
> > /Shahab
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar 18 19:52:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 18 Mar 2016 11:52:19 -0700
Subject: [R] variable selection using residual difference
In-Reply-To: <B653E9EFB809DA4ABF9EFA0944845675059FBD31@BHEXMBX2.livad.liv.ac.uk>
References: <B653E9EFB809DA4ABF9EFA0944845675059FBD31@BHEXMBX2.livad.liv.ac.uk>
Message-ID: <CAGxFJbR4u_wKhBKkS63BaAFPHrSMYFBumTSqFBAKGp=eJ+sVxQ@mail.gmail.com>

Suggestion:

Don't do this!

I suggest that you consult with a local statistician or post to a
statistical website like stats.stackexchange.com for what might be
sensible procedures for variable selection (a complex and
controversial topic!) and why what you propose is or is not a good
idea (don't trust me!).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 18, 2016 at 9:00 AM, Hassan, Nazatulshima
<Nazatulshima.Hassan at liverpool.ac.uk> wrote:
> I have the following example dataset
> set.seed(2001)
> n <- 100
> Y <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
> X1 <- sample(x=c(0,1,2), size=n, replace=TRUE, prob=c(0.1,0.4,0.5))
> X2 <- sample(x=c(0,1,2), size=n, replace=TRUE, prob=c(0.5,0.25,0.25))
> X3 <- c(0,2,2,2,2,2,2,2,0,2,0,2,2,0,0,0,0,0,2,0,0,2,2,0,0,2,2,2,0,2,0,2,0,2,1,2,1,1,1,1,1,1,1,1,1,1,1,0,1,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0)
>
> dat <- data.frame(Y,X1,X2,X3)
>
> I fit a logistic regression model to each of the variable to rank them based on the residual difference (highest to lowest). To simplify I got the rank as X3,X1 and X2. Then, I fit a second order model as follows and again calculate the res_dif :
> mod1 <- glm(Y~X3+X1, family=binomial, data=dat)
> mod1$null.deviance-mod1$deviance
> mod2 <- glm(Y~X3+X2, family=binomial,data=dat)
> mod2$null.deviance-mod2$deviance
>
> Again, I will rank the model based on res_dif (highest to lowest). So here, I choose mod2. From there I will fit the third order model as follows :
> mod3 <- glm(Y~X3+X2+X1, family=binomial, data=dat)
> mod3$null.deviance-mod3$deviance
>
> Basically, this continues until it fits the maximum number of variables that you have in the data.
> My aim is to do variable selection based on res_dif instead of AIC, BIC or R2. Since my actual dataset is dealing with 100 of variables, I wonder how can I apply this using loop function.
>
> Any suggestions would be appreciated.
>
> Kind Regards
> Shima
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Fri Mar 18 22:28:35 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 18 Mar 2016 14:28:35 -0700
Subject: [R] Reshaping an array - how does it work in R
Message-ID: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>

Hi All:

I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:

myData[noLat, no Lon, noTime].

It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:

myData[noLat*noLon, noTime].  Normally this would be easy:

myData<- array(myData,dim=c(noLat*noLon,noTime))

My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.

Thanks,

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From toth.denes at ttk.mta.hu  Fri Mar 18 22:56:23 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Fri, 18 Mar 2016 22:56:23 +0100
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
Message-ID: <56EC7987.2070602@ttk.mta.hu>

Hi Roy,

R (usually) makes a copy if the dimensionality of an array is modified, 
even if you use this syntax:
x <- array(1:24, c(2, 3, 4))
dim(x) <- c(6, 4)

See also ?tracemem, ?data.table::address, ?pryr::address and other tools 
to trace if an internal copy is done.

Workaround: use data.table::setattr or bit::setattr to modify the 
dimensions in place (i.e., without making a copy). Risk: if you modify 
an object by reference, all other objects which point to the same memory 
address will be modified silently, too.

HTH,
   Denes



On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
> Hi All:
>
> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>
> myData[noLat, no Lon, noTime].
>
> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>
> myData[noLat*noLon, noTime].  Normally this would be easy:
>
> myData<- array(myData,dim=c(noLat*noLon,noTime))
>
> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>
> Thanks,
>
> -Roy
>
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Fri Mar 18 22:56:44 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 18 Mar 2016 14:56:44 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
Message-ID: <CAGxFJbTsnMi0YxCkMNeZan4jcsQgtRjCGNWRV7GEXFXM8k0ARA@mail.gmail.com>

arrays are vectors stored in column major order.  So the answer is: reindexing.

Does this make it clear:

> v <- array(1:24,dim=2:4)
> as.vector(v)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

> v
, , 1

     [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6

, , 2

     [,1] [,2] [,3]
[1,]    7    9   11
[2,]    8   10   12

, , 3

     [,1] [,2] [,3]
[1,]   13   15   17
[2,]   14   16   18

, , 4

     [,1] [,2] [,3]
[1,]   19   21   23
[2,]   20   22   24

> w <- array(as.vector(v),dim=c(6,4)) ## you would use v instead of w for the assignment
> w
     [,1] [,2] [,3] [,4]
[1,]    1    7   13   19
[2,]    2    8   14   20
[3,]    3    9   15   21
[4,]    4   10   16   22
[5,]    5   11   17   23
[6,]    6   12   18   24
> identical(as.vector(w), as.vector(v))
[1] TRUE


However copying may occur anyway as part of R's semantics. Others will
have to help you on that, as the details here are beyond me.

Cheers,
Bert



Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 18, 2016 at 2:28 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>
> myData[noLat, no Lon, noTime].
>
> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>
> myData[noLat*noLon, noTime].  Normally this would be easy:
>
> myData<- array(myData,dim=c(noLat*noLon,noTime))
>
> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>
> Thanks,
>
> -Roy
>
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Fri Mar 18 23:11:17 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 18 Mar 2016 15:11:17 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <CAGxFJbTsnMi0YxCkMNeZan4jcsQgtRjCGNWRV7GEXFXM8k0ARA@mail.gmail.com>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<CAGxFJbTsnMi0YxCkMNeZan4jcsQgtRjCGNWRV7GEXFXM8k0ARA@mail.gmail.com>
Message-ID: <AB0A0853-E3C1-40CE-B82C-6B4E85DE7C0C@noaa.gov>


> On Mar 18, 2016, at 2:56 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> However copying may occur anyway as part of R's semantics. Others will
> have to help you on that, as the details here are beyond me.
> 
> Cheers,
> Bert

Hi Bert:

Thanks for your response.  The only part I was concerned with is whether a copy was made, that is what my memory usage would be.  Sorry if that wasn?t clear in the original.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jdnewmil at dcn.davis.ca.us  Fri Mar 18 23:11:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 18 Mar 2016 15:11:38 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
Message-ID: <34353705-675E-47DD-856F-3714B7C93F3F@dcn.davis.ca.us>

R always makes a copy for this kind of operation. There are some operations that don't make copies, but I don't think this one qualifies. 

-- 
Sent from my phone. Please excuse my brevity.

On March 18, 2016 2:28:35 PM PDT, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>Hi All:
>
>I am working with a very large array.  if noLat is the number of
>latitudes, noLon the number of longitudes and noTime the number of 
>time periods, the array is of the form:
>
>myData[noLat, no Lon, noTime].
>
>It is read in this way because that is how it is stored in a (series)
>of netcdf files.  For the analysis I need to do, I need instead the
>array:
>
>myData[noLat*noLon, noTime].  Normally this would be easy:
>
>myData<- array(myData,dim=c(noLat*noLon,noTime))
>
>My question is how does this command work in R - does it make a copy of
>the existing array, with different indices for the dimensions, or does
>it just redo the indices and leave the given array as is?  The reason
>for this question is my array is 30GB in memory, and I don?t have
>enough space to have a copy of the array in memory.  If the latter I
>will have to figure out a work around to bring in only part of the data
>at a time and put it into the proper locations.
>
>Thanks,
>
>-Roy
>
>
>
>**********************
>"The contents of this message do not reflect any position of the U.S.
>Government or NOAA."
>**********************
>Roy Mendelssohn
>Supervisory Operations Research Analyst
>NOAA/NMFS
>Environmental Research Division
>Southwest Fisheries Science Center
>***Note new address and phone***
>110 Shaffer Road
>Santa Cruz, CA 95060
>Phone: (831)-420-3666
>Fax: (831) 420-3980
>e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
>"Old age and treachery will overcome youth and skill."
>"From those who have been given much, much will be expected" 
>"the arc of the moral universe is long, but it bends toward justice"
>-MLK Jr.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Fri Mar 18 23:15:28 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 18 Mar 2016 15:15:28 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <56EC7987.2070602@ttk.mta.hu>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
Message-ID: <777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>

Thanks.  That is what I needed to know.  I don?t want to play around with some of the other suggestions, as I don?t totally understand what they do, and don?t want to risk messing up something and not be aware of it.

There is a way to read in the data chunks at a time and reshape it and put, it into the (reshaped) larger array, harder to program but probably worth the pain to be certain of what I am doing.

I had a feeling a copy was made, just wanted to make certain of it.

Thanks again,

-Roy

> On Mar 18, 2016, at 2:56 PM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
> 
> Hi Roy,
> 
> R (usually) makes a copy if the dimensionality of an array is modified, even if you use this syntax:
> x <- array(1:24, c(2, 3, 4))
> dim(x) <- c(6, 4)
> 
> See also ?tracemem, ?data.table::address, ?pryr::address and other tools to trace if an internal copy is done.
> 
> Workaround: use data.table::setattr or bit::setattr to modify the dimensions in place (i.e., without making a copy). Risk: if you modify an object by reference, all other objects which point to the same memory address will be modified silently, too.
> 
> HTH,
>  Denes
> 
> 
> 
> On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>> Hi All:
>> 
>> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>> 
>> myData[noLat, no Lon, noTime].
>> 
>> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>> 
>> myData[noLat*noLon, noTime].  Normally this would be easy:
>> 
>> myData<- array(myData,dim=c(noLat*noLon,noTime))
>> 
>> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>> 
>> Thanks,
>> 
>> -Roy
>> 
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From henrik.bengtsson at gmail.com  Sat Mar 19 03:37:59 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 18 Mar 2016 19:37:59 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>
Message-ID: <CAFDcVCSLzf7JBsm=x9Nj6RS1QCEKFabS00KxNdc_ozk=mCW33w@mail.gmail.com>

On Fri, Mar 18, 2016 at 3:15 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Thanks.  That is what I needed to know.  I don?t want to play around with some of the other suggestions, as I don?t totally understand what they do, and don?t want to risk messing up something and not be aware of it.
>
> There is a way to read in the data chunks at a time and reshape it and put, it into the (reshaped) larger array, harder to program but probably worth the pain to be certain of what I am doing.

I recommend this approach; whenever I work with reasonable large data
(that may become even larger in the future), I try to implement a
constant-memory version of the algorithm, which often comes down to
processing data in chunks.  The simplest version of this is to read
all data into memory and the subset, but if you can read data in in
chunks that is even better.

Though, I'm curious to what matrix operations you wish to perform.
Because if you wish to do regular summation, then base::.rowSums() and
base::.colSums() allow you to override the default dimensions on the
fly without inducing extra copies, e.g.

> X <- array(1:24, dim=c(2,3,4))
> .rowSums(X, m=6, n=4)
[1] 40 44 48 52 56 60
> rowSums(matrix(X, nrow=6, ncol=4))
[1] 40 44 48 52 56 60

For other types of calculations, you might want to look at
matrixStats.  It has partial(*) support for overriding the default
dimensions in a similar fashion.  For instance,

> library("matrixStats")
> rowVars(X, dim.=c(6,4))

The above effectively calculates rowVars(matrix(X, nrow=6, ncol=4))
without making copies.

(*) By partial I mean that this is a feature that hasn't been pushed
through to all of matrixStats functions, cf.
https://github.com/HenrikBengtsson/matrixStats/issues/83.

Cheers,

Henrik
(author of matrixStats)

>
> I had a feeling a copy was made, just wanted to make certain of it.
>
> Thanks again,
>
> -Roy
>
>> On Mar 18, 2016, at 2:56 PM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
>>
>> Hi Roy,
>>
>> R (usually) makes a copy if the dimensionality of an array is modified, even if you use this syntax:
>> x <- array(1:24, c(2, 3, 4))
>> dim(x) <- c(6, 4)
>>
>> See also ?tracemem, ?data.table::address, ?pryr::address and other tools to trace if an internal copy is done.
>>
>> Workaround: use data.table::setattr or bit::setattr to modify the dimensions in place (i.e., without making a copy). Risk: if you modify an object by reference, all other objects which point to the same memory address will be modified silently, too.
>>
>> HTH,
>>  Denes
>>
>>
>>
>> On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>>> Hi All:
>>>
>>> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>>>
>>> myData[noLat, no Lon, noTime].
>>>
>>> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>>>
>>> myData[noLat*noLon, noTime].  Normally this would be easy:
>>>
>>> myData<- array(myData,dim=c(noLat*noLon,noTime))
>>>
>>> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>>>
>>> Thanks,
>>>
>>> -Roy
>>>
>>>
>>>
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new address and phone***
>>> 110 Shaffer Road
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Sat Mar 19 04:28:55 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 18 Mar 2016 20:28:55 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <CAFDcVCSLzf7JBsm=x9Nj6RS1QCEKFabS00KxNdc_ozk=mCW33w@mail.gmail.com>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>
	<CAFDcVCSLzf7JBsm=x9Nj6RS1QCEKFabS00KxNdc_ozk=mCW33w@mail.gmail.com>
Message-ID: <915638FE-A003-445E-B334-54FCE2C2221C@noaa.gov>

Hi Henrik:

I want to do want in oceanography is called an EOF, which is just a PCA analysis. Unless I am missing something, in R I need to flatten my 3-D matrix into a 2-D data matrix. I can fit the entire 30GB matrix into memory, and I believe I have enough memory to do the PCA by constraining the number of components returned .  What I don?t think I have enough memory for is an operation that makes a copy of the matrix.

As I said, in theory I know how to do the flattening, it a simple command, but in practice I don?t have enough memory.  So I spent the afternoon rewriting my code to read in parts of the data at a time and then putting those in the appropriate places of a matrix already flattened of appropriate size.  In case someone is wondering, on the 3D grid the matrix is [1001,1001,3650].  So I create an empty matrix size [1001*1001,3650], and read in a slice of the lat-lon grid, and map those into the appropriate places in the flattened matrix.  By reading in appropriately sized chunks  my memory usage is not pushed too far.

-Roy


> On Mar 18, 2016, at 7:37 PM, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> On Fri, Mar 18, 2016 at 3:15 PM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Thanks.  That is what I needed to know.  I don?t want to play around with some of the other suggestions, as I don?t totally understand what they do, and don?t want to risk messing up something and not be aware of it.
>> 
>> There is a way to read in the data chunks at a time and reshape it and put, it into the (reshaped) larger array, harder to program but probably worth the pain to be certain of what I am doing.
> 
> I recommend this approach; whenever I work with reasonable large data
> (that may become even larger in the future), I try to implement a
> constant-memory version of the algorithm, which often comes down to
> processing data in chunks.  The simplest version of this is to read
> all data into memory and the subset, but if you can read data in in
> chunks that is even better.
> 
> Though, I'm curious to what matrix operations you wish to perform.
> Because if you wish to do regular summation, then base::.rowSums() and
> base::.colSums() allow you to override the default dimensions on the
> fly without inducing extra copies, e.g.
> 
>> X <- array(1:24, dim=c(2,3,4))
>> .rowSums(X, m=6, n=4)
> [1] 40 44 48 52 56 60
>> rowSums(matrix(X, nrow=6, ncol=4))
> [1] 40 44 48 52 56 60
> 
> For other types of calculations, you might want to look at
> matrixStats.  It has partial(*) support for overriding the default
> dimensions in a similar fashion.  For instance,
> 
>> library("matrixStats")
>> rowVars(X, dim.=c(6,4))
> 
> The above effectively calculates rowVars(matrix(X, nrow=6, ncol=4))
> without making copies.
> 
> (*) By partial I mean that this is a feature that hasn't been pushed
> through to all of matrixStats functions, cf.
> https://github.com/HenrikBengtsson/matrixStats/issues/83.
> 
> Cheers,
> 
> Henrik
> (author of matrixStats)
> 
>> 
>> I had a feeling a copy was made, just wanted to make certain of it.
>> 
>> Thanks again,
>> 
>> -Roy
>> 
>>> On Mar 18, 2016, at 2:56 PM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
>>> 
>>> Hi Roy,
>>> 
>>> R (usually) makes a copy if the dimensionality of an array is modified, even if you use this syntax:
>>> x <- array(1:24, c(2, 3, 4))
>>> dim(x) <- c(6, 4)
>>> 
>>> See also ?tracemem, ?data.table::address, ?pryr::address and other tools to trace if an internal copy is done.
>>> 
>>> Workaround: use data.table::setattr or bit::setattr to modify the dimensions in place (i.e., without making a copy). Risk: if you modify an object by reference, all other objects which point to the same memory address will be modified silently, too.
>>> 
>>> HTH,
>>> Denes
>>> 
>>> 
>>> 
>>> On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>>>> Hi All:
>>>> 
>>>> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>>>> 
>>>> myData[noLat, no Lon, noTime].
>>>> 
>>>> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>>>> 
>>>> myData[noLat*noLon, noTime].  Normally this would be easy:
>>>> 
>>>> myData<- array(myData,dim=c(noLat*noLon,noTime))
>>>> 
>>>> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>>>> 
>>>> Thanks,
>>>> 
>>>> -Roy
>>>> 
>>>> 
>>>> 
>>>> **********************
>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>> **********************
>>>> Roy Mendelssohn
>>>> Supervisory Operations Research Analyst
>>>> NOAA/NMFS
>>>> Environmental Research Division
>>>> Southwest Fisheries Science Center
>>>> ***Note new address and phone***
>>>> 110 Shaffer Road
>>>> Santa Cruz, CA 95060
>>>> Phone: (831)-420-3666
>>>> Fax: (831) 420-3980
>>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>> 
>>>> "Old age and treachery will overcome youth and skill."
>>>> "From those who have been given much, much will be expected"
>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From key4real at gmail.com  Fri Mar 18 21:14:26 2016
From: key4real at gmail.com (Kwamme Yeboah)
Date: Fri, 18 Mar 2016 20:14:26 +0000
Subject: [R] [FORGED] ERROR in make.link(link)
In-Reply-To: <1458249763336.1301832042@boxbe>
References: <1458247655362.26392@unine.ch>
	<1458249763336.1301832042@boxbe>
Message-ID: <CA+WUScJQkSsqg7L9s55jJH4kJTVM4Uy9LXUBNdKqtSMaNhyUEw@mail.gmail.com>

Can I pls see your data, Xavier?

On Thu, Mar 17, 2016 at 9:11 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> [image: Boxbe] <https://www.boxbe.com/overview> Rolf Turner (
> r.turner at auckland.ac.nz) is not on your Guest List
> <https://www.boxbe.com/approved-list?tc_serial=24757387828&tc_rand=39608388&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&token=0%2FXWnc%2Bs5vfE04mrJ4%2FHaCGkD8C0vVNNSQdoa4FR7b452kzfBykf8Qibi5Rss2Ss&key=qdoDouA7VhiR35TTy4riJKnWNQ2K4N5%2BJaIAhoeU2Js%3D>
> | Approve sender
> <https://www.boxbe.com/anno?tc_serial=24757387828&tc_rand=39608388&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&token=0%2FXWnc%2Bs5vfE04mrJ4%2FHaCGkD8C0vVNNSQdoa4FR7b452kzfBykf8Qibi5Rss2Ss&key=qdoDouA7VhiR35TTy4riJKnWNQ2K4N5%2BJaIAhoeU2Js%3D>
> | Approve domain
> <https://www.boxbe.com/anno?tc_serial=24757387828&tc_rand=39608388&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&dom&token=0%2FXWnc%2Bs5vfE04mrJ4%2FHaCGkD8C0vVNNSQdoa4FR7b452kzfBykf8Qibi5Rss2Ss&key=qdoDouA7VhiR35TTy4riJKnWNQ2K4N5%2BJaIAhoeU2Js%3D>
>
> On 18/03/16 09:47, CHIRIBOGA Xavier wrote:
>
>> Dear all,
>>
>>
>> I am using R version 3.1.3. I want to run this model:
>>
>> m1<-glmer(hours~soil*volatile+(1|replicate),  data=data,
>> family=Gamma(link = "inv"))
>>
>>
>> But I got this:
>>
>> Erreur within make.link(link) : 'inv' link not recognised
>>
>>
>> What to do in this case?
>>
>
> What to do?  Use the correct syntax! Your call should be:
>
>     family=Gamma(link="inverse")
>
> The name of the link must be specified *completely*; partial matching is
> not used, for fairly obvious reasons.
>
> Actually you could just do "family=Gamma" since "inverse" is the *default*
> link.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
KEY.

	[[alternative HTML version deleted]]


From reichmanj at sbcglobal.net  Fri Mar 18 23:00:00 2016
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Fri, 18 Mar 2016 17:00:00 -0500
Subject: [R] Exporting Commands and Results
Message-ID: <000001d18161$85080080$8f180180$@sbcglobal.net>

R-Users

 

I know sink("filename") will export my results to a file but how do I export
both commands and results in R?

 

Jeff


	[[alternative HTML version deleted]]


From leegi001 at umn.edu  Fri Mar 18 21:58:49 2016
From: leegi001 at umn.edu (Cathy Lee Gierke)
Date: Fri, 18 Mar 2016 15:58:49 -0500
Subject: [R] degree sign
Message-ID: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>

I have searched and tried many things but cannot get anything to work.  I
just want to print out a degree sign after a the Orthophase number.

The following list of "xl" values are all ones I have tried.  Granted they
are not what I want, but I have tried them all, and none of them print out
a degree symbol...

#                   xl = expression(paste("Orthophase [", {
#                   }^o, "]"))
                  #xl<-~degree~C
                  #xl<-parse(text = ~degree)
                  #xl<-parse(text = paste(" ", "~degree", sep = ""))
                  #xl<-expression(~degree)
                  xl <- parse(text = paste(Orthophase[i,j], "*degree ~ S",
sep = ""))


                  printXlab<-paste("Orthophase    ",Orthophase[i,j],xl,"
  ")

plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
xlab=printXlab,.....


Cathy Lee Gierke

*"We are what we repeatedly do.  Excellence, then, is not an act, but a
habit." Aristotle*

	[[alternative HTML version deleted]]


From palakkeel at gmail.com  Sat Mar 19 07:18:40 2016
From: palakkeel at gmail.com (Prashobh Palakkeel)
Date: Sat, 19 Mar 2016 11:48:40 +0530
Subject: [R] How to save an object in a function
Message-ID: <CA+1Zn4jGhzwnv2d0-96jFtCZ1AVBi42jFujfaghm2Ja2yY16JQ@mail.gmail.com>

This is the code for permutations from the package "gtools"

fn_perm_list <-
  function (n, r, v = 1:n)
  {
    if (r == 1)
      matrix(v, n, 1)
    else if (n == 1)
      matrix(v, 1, r)
    else {
      X <- NULL
      for (i in 1:n) X <- rbind(X, cbind(v[i], fn_perm_list(n - 1, r - 1,
v[-i])))
      X

    }

  }

How to save X as an object(matrix) while running the function












with regards,

Prashobh

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 19 08:06:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Mar 2016 00:06:54 -0700
Subject: [R] How to save an object in a function
In-Reply-To: <CA+1Zn4jGhzwnv2d0-96jFtCZ1AVBi42jFujfaghm2Ja2yY16JQ@mail.gmail.com>
References: <CA+1Zn4jGhzwnv2d0-96jFtCZ1AVBi42jFujfaghm2Ja2yY16JQ@mail.gmail.com>
Message-ID: <33993595-83BD-414E-9AA8-7417C9F19560@comcast.net>


> On Mar 18, 2016, at 11:18 PM, Prashobh Palakkeel <palakkeel at gmail.com> wrote:
> 
> This is the code for permutations from the package "gtools"
> 
> fn_perm_list <-
>  function (n, r, v = 1:n)
>  {
>    if (r == 1)
>      matrix(v, n, 1)
>    else if (n == 1)
>      matrix(v, 1, r)
>    else {
>      X <- NULL
>      for (i in 1:n) X <- rbind(X, cbind(v[i], fn_perm_list(n - 1, r - 1,
> v[-i])))
>      X
> 
>    }
> 
>  }
> 
> How to save X as an object(matrix) while running the function


 X <- fn_perm_list(n, r, v)

-- 

David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Sat Mar 19 08:12:39 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 19 Mar 2016 08:12:39 +0100
Subject: [R] degree sign
In-Reply-To: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
Message-ID: <56ECFBE7.9080708@statistik.tu-dortmund.de>



On 18.03.2016 21:58, Cathy Lee Gierke wrote:
> I have searched and tried many things but cannot get anything to work.  I
> just want to print out a degree sign after a the Orthophase number.
>
> The following list of "xl" values are all ones I have tried.  Granted they
> are not what I want, but I have tried them all, and none of them print out
> a degree symbol...
>
> #                   xl = expression(paste("Orthophase [", {
> #                   }^o, "]"))
>                    #xl<-~degree~C
>                    #xl<-parse(text = ~degree)
>                    #xl<-parse(text = paste(" ", "~degree", sep = ""))
>                    #xl<-expression(~degree)
>                    xl <- parse(text = paste(Orthophase[i,j], "*degree ~ S",
> sep = ""))
>
>
>                    printXlab<-paste("Orthophase    ",Orthophase[i,j],xl,"
>    ")
>
> plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
> xlab=printXlab,.....


It has to be an expression, you must not use paste() around it:

plot(MyData$time.hour[plotData], newData[plotData], type="l", xaxt="n",
      xlab = expression("Orthophase    " * Orthophase[i,j] * degree))

Best,
Uwe Ligges




>
> Cathy Lee Gierke
>
> *"We are what we repeatedly do.  Excellence, then, is not an act, but a
> habit." Aristotle*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From javanmard.majid at gmail.com  Sat Mar 19 08:19:53 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Sat, 19 Mar 2016 10:49:53 +0330
Subject: [R] Is not really anybody answer me ????
Message-ID: <CAA0OCnvhDeC1V8J9q=kc0ko544eLqJf+kFeqh4W8YGSbQ9W+3Q@mail.gmail.com>

Hello

I asked a question 3 times, but I got no answer for each of them.


Thanks to R mailing list

	[[alternative HTML version deleted]]


From tsjerkw at gmail.com  Sat Mar 19 08:59:48 2016
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sat, 19 Mar 2016 08:59:48 +0100
Subject: [R] Is not really anybody answer me ????
In-Reply-To: <CAA0OCnvhDeC1V8J9q=kc0ko544eLqJf+kFeqh4W8YGSbQ9W+3Q@mail.gmail.com>
References: <CAA0OCnvhDeC1V8J9q=kc0ko544eLqJf+kFeqh4W8YGSbQ9W+3Q@mail.gmail.com>
Message-ID: <CABzE1SgyqUcbhQfbxFpcnPjUhzjEoDxErEdvH1B3UAa0g9fa3Q@mail.gmail.com>

Hi Majid,

Maybe no one knew the answer, or the question was not understood. There's
no central board assigning questions to answerers, so sometimes questions
do not find one. You don't have a right to get an answer, but you ask
someone to invest time and do you a favor. Maybe this can be of some value:

http://www.catb.org/esr/faqs/smart-questions.html

Regards,

Tsjerk
On Mar 19, 2016 08:21, "Majid Javanmard" <javanmard.majid at gmail.com> wrote:

> Hello
>
> I asked a question 3 times, but I got no answer for each of them.
>
>
> Thanks to R mailing list
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 19 10:16:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Mar 2016 02:16:09 -0700
Subject: [R] Is not really anybody answer me ????
In-Reply-To: <CAA0OCnvhDeC1V8J9q=kc0ko544eLqJf+kFeqh4W8YGSbQ9W+3Q@mail.gmail.com>
References: <CAA0OCnvhDeC1V8J9q=kc0ko544eLqJf+kFeqh4W8YGSbQ9W+3Q@mail.gmail.com>
Message-ID: <379FBC44-3340-4F18-A86E-F314B3047A30@comcast.net>


> On Mar 19, 2016, at 12:19 AM, Majid Javanmard <javanmard.majid at gmail.com> wrote:
> 
> Hello
> 
> I asked a question 3 times, but I got no answer for each of them.

You get a decision tree from the bagging function. Precisely what would a confidence interval look like for such a prediction? 

(I don't think this is really an R coding question. Seems more likely that the lack of any "answer" stems from a difference in your understanding of statistics versus our understanding of the subject.)

You also didn't get any answer on StackOverflow. (It's not really on-topic there, either.) Perhaps you can cast your question in the direction of stats.stackexchange.com where differences in understanding of statistics may be on topic. You should search there to see if it's been already asked and answered.


> 
> Thanks to R mailing list
> 
> 	[[alternative HTML version deleted]]

Please post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Sat Mar 19 15:14:00 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 19 Mar 2016 06:14:00 -0800
Subject: [R] Exporting Commands and Results
In-Reply-To: <000001d18161$85080080$8f180180$@sbcglobal.net>
Message-ID: <FBDA9EF8D3A.0000021Ajrkrideau@inbox.com>

 Perhaps knitr (http://yihui.name/knitr/)? 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: reichmanj at sbcglobal.net
> Sent: Fri, 18 Mar 2016 17:00:00 -0500
> To: r-help at r-project.org
> Subject: [R] Exporting Commands and Results
> 
> R-Users
> 
> 
> 
> I know sink("filename") will export my results to a file but how do I
> export
> both commands and results in R?
> 
> 
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From bgunter.4567 at gmail.com  Sat Mar 19 15:58:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 19 Mar 2016 07:58:02 -0700
Subject: [R] Exporting Commands and Results
In-Reply-To: <000001d18161$85080080$8f180180$@sbcglobal.net>
References: <000001d18161$85080080$8f180180$@sbcglobal.net>
Message-ID: <CAGxFJbSwf0gAZ2smtwE01Rv8oB=7ysjkdttNy4o7Rzw42uX-xw@mail.gmail.com>

?savehistory

may also be relevant, depending on what you wish to do and how hard
you want to work.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 18, 2016 at 3:00 PM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Users
>
>
>
> I know sink("filename") will export my results to a file but how do I export
> both commands and results in R?
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jordanmeyer1991 at gmail.com  Sat Mar 19 16:06:55 2016
From: jordanmeyer1991 at gmail.com (Jordan Meyer)
Date: Sat, 19 Mar 2016 11:06:55 -0400
Subject: [R] Exporting Commands and Results
In-Reply-To: <CAGxFJbSwf0gAZ2smtwE01Rv8oB=7ysjkdttNy4o7Rzw42uX-xw@mail.gmail.com>
References: <000001d18161$85080080$8f180180$@sbcglobal.net>
	<CAGxFJbSwf0gAZ2smtwE01Rv8oB=7ysjkdttNy4o7Rzw42uX-xw@mail.gmail.com>
Message-ID: <CAF+g6rqTyZUtrc5+KY2jY2cdSR2+VYFgfkc14mYS_9ytPiUATw@mail.gmail.com>

You may want to try sink(filename, split=TRUE). If you have particularly
lengthy commands that you wish to save, you can run your syntax file using
source(filename, echo=TRUE, max.deparse.length=Inf) to keep R from
truncating the commands.
On Mar 19, 2016 10:59 AM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> ?savehistory
>
> may also be relevant, depending on what you wish to do and how hard
> you want to work.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 18, 2016 at 3:00 PM, Jeff Reichman <reichmanj at sbcglobal.net>
> wrote:
> > R-Users
> >
> >
> >
> > I know sink("filename") will export my results to a file but how do I
> export
> > both commands and results in R?
> >
> >
> >
> > Jeff
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Sat Mar 19 16:18:54 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 19 Mar 2016 08:18:54 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <915638FE-A003-445E-B334-54FCE2C2221C@noaa.gov>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>
	<CAFDcVCSLzf7JBsm=x9Nj6RS1QCEKFabS00KxNdc_ozk=mCW33w@mail.gmail.com>
	<915638FE-A003-445E-B334-54FCE2C2221C@noaa.gov>
Message-ID: <CAFDcVCQKCfuRtP_keadQ2HpszpYXg_kg+dy6E9vLjrKjiyHbVg@mail.gmail.com>

On Fri, Mar 18, 2016 at 8:28 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi Henrik:
>
> I want to do want in oceanography is called an EOF, which is just a PCA analysis. Unless I am missing something, in R I need to flatten my 3-D matrix into a 2-D data matrix. I can fit the entire 30GB matrix into memory, and I believe I have enough memory to do the PCA by constraining the number of components returned .  What I don?t think I have enough memory for is an operation that makes a copy of the matrix.
>
> As I said, in theory I know how to do the flattening, it a simple command, but in practice I don?t have enough memory.  So I spent the afternoon rewriting my code to read in parts of the data at a time and then putting those in the appropriate places of a matrix already flattened of appropriate size.  In case someone is wondering, on the 3D grid the matrix is [1001,1001,3650].  So I create an empty matrix size [1001*1001,3650], and read in a slice of the lat-lon grid, and map those into the appropriate places in the flattened matrix.  By reading in appropriately sized chunks  my memory usage is not pushed too far.

Sounds good.  There's another small caveat. Make sure to specify the
'data' argument for matrix() we allocating an "empty" matrix, e.g.

    X <- matrix(NA_real_, nrow=1001*1001, ncol=3650)

This will give you a double matrix with all missing value.  If you use
the default

    X <- matrix(nrow=1001*1001, ncol=3650)

you'll get a logical matrix, which will introduce a copy as soon as
you assign a double value (e.g. X[1,1] <- 3.14). The latter is a
complete waste of memory/time. See
http://www.jottr.org/2014/06/matrixNA-wrong-way.html for details.

/Henrik

>
> -Roy
>
>
>> On Mar 18, 2016, at 7:37 PM, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> On Fri, Mar 18, 2016 at 3:15 PM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>> Thanks.  That is what I needed to know.  I don?t want to play around with some of the other suggestions, as I don?t totally understand what they do, and don?t want to risk messing up something and not be aware of it.
>>>
>>> There is a way to read in the data chunks at a time and reshape it and put, it into the (reshaped) larger array, harder to program but probably worth the pain to be certain of what I am doing.
>>
>> I recommend this approach; whenever I work with reasonable large data
>> (that may become even larger in the future), I try to implement a
>> constant-memory version of the algorithm, which often comes down to
>> processing data in chunks.  The simplest version of this is to read
>> all data into memory and the subset, but if you can read data in in
>> chunks that is even better.
>>
>> Though, I'm curious to what matrix operations you wish to perform.
>> Because if you wish to do regular summation, then base::.rowSums() and
>> base::.colSums() allow you to override the default dimensions on the
>> fly without inducing extra copies, e.g.
>>
>>> X <- array(1:24, dim=c(2,3,4))
>>> .rowSums(X, m=6, n=4)
>> [1] 40 44 48 52 56 60
>>> rowSums(matrix(X, nrow=6, ncol=4))
>> [1] 40 44 48 52 56 60
>>
>> For other types of calculations, you might want to look at
>> matrixStats.  It has partial(*) support for overriding the default
>> dimensions in a similar fashion.  For instance,
>>
>>> library("matrixStats")
>>> rowVars(X, dim.=c(6,4))
>>
>> The above effectively calculates rowVars(matrix(X, nrow=6, ncol=4))
>> without making copies.
>>
>> (*) By partial I mean that this is a feature that hasn't been pushed
>> through to all of matrixStats functions, cf.
>> https://github.com/HenrikBengtsson/matrixStats/issues/83.
>>
>> Cheers,
>>
>> Henrik
>> (author of matrixStats)
>>
>>>
>>> I had a feeling a copy was made, just wanted to make certain of it.
>>>
>>> Thanks again,
>>>
>>> -Roy
>>>
>>>> On Mar 18, 2016, at 2:56 PM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
>>>>
>>>> Hi Roy,
>>>>
>>>> R (usually) makes a copy if the dimensionality of an array is modified, even if you use this syntax:
>>>> x <- array(1:24, c(2, 3, 4))
>>>> dim(x) <- c(6, 4)
>>>>
>>>> See also ?tracemem, ?data.table::address, ?pryr::address and other tools to trace if an internal copy is done.
>>>>
>>>> Workaround: use data.table::setattr or bit::setattr to modify the dimensions in place (i.e., without making a copy). Risk: if you modify an object by reference, all other objects which point to the same memory address will be modified silently, too.
>>>>
>>>> HTH,
>>>> Denes
>>>>
>>>>
>>>>
>>>> On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>>>>> Hi All:
>>>>>
>>>>> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>>>>>
>>>>> myData[noLat, no Lon, noTime].
>>>>>
>>>>> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>>>>>
>>>>> myData[noLat*noLon, noTime].  Normally this would be easy:
>>>>>
>>>>> myData<- array(myData,dim=c(noLat*noLon,noTime))
>>>>>
>>>>> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>>>>>
>>>>> Thanks,
>>>>>
>>>>> -Roy
>>>>>
>>>>>
>>>>>
>>>>> **********************
>>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>>> **********************
>>>>> Roy Mendelssohn
>>>>> Supervisory Operations Research Analyst
>>>>> NOAA/NMFS
>>>>> Environmental Research Division
>>>>> Southwest Fisheries Science Center
>>>>> ***Note new address and phone***
>>>>> 110 Shaffer Road
>>>>> Santa Cruz, CA 95060
>>>>> Phone: (831)-420-3666
>>>>> Fax: (831) 420-3980
>>>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>>>
>>>>> "Old age and treachery will overcome youth and skill."
>>>>> "From those who have been given much, much will be expected"
>>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new address and phone***
>>> 110 Shaffer Road
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>


From roy.mendelssohn at noaa.gov  Sat Mar 19 17:03:00 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 19 Mar 2016 09:03:00 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <CAFDcVCQKCfuRtP_keadQ2HpszpYXg_kg+dy6E9vLjrKjiyHbVg@mail.gmail.com>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<777C8708-ADFC-4C4F-8ADF-4978F3A9B8E2@noaa.gov>
	<CAFDcVCSLzf7JBsm=x9Nj6RS1QCEKFabS00KxNdc_ozk=mCW33w@mail.gmail.com>
	<915638FE-A003-445E-B334-54FCE2C2221C@noaa.gov>
	<CAFDcVCQKCfuRtP_keadQ2HpszpYXg_kg+dy6E9vLjrKjiyHbVg@mail.gmail.com>
Message-ID: <71CEF124-BEC5-4BFD-B733-92278B4D1188@noaa.gov>


> On Mar 19, 2016, at 8:18 AM, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> On Fri, Mar 18, 2016 at 8:28 PM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi Henrik:
>> 
>> I want to do want in oceanography is called an EOF, which is just a PCA analysis. Unless I am missing something, in R I need to flatten my 3-D matrix into a 2-D data matrix. I can fit the entire 30GB matrix into memory, and I believe I have enough memory to do the PCA by constraining the number of components returned .  What I don?t think I have enough memory for is an operation that makes a copy of the matrix.
>> 
>> As I said, in theory I know how to do the flattening, it a simple command, but in practice I don?t have enough memory.  So I spent the afternoon rewriting my code to read in parts of the data at a time and then putting those in the appropriate places of a matrix already flattened of appropriate size.  In case someone is wondering, on the 3D grid the matrix is [1001,1001,3650].  So I create an empty matrix size [1001*1001,3650], and read in a slice of the lat-lon grid, and map those into the appropriate places in the flattened matrix.  By reading in appropriately sized chunks  my memory usage is not pushed too far.
> 
> Sounds good.  There's another small caveat. Make sure to specify the
> 'data' argument for matrix() we allocating an "empty" matrix, e.g.
> 
>    X <- matrix(NA_real_, nrow=1001*1001, ncol=3650)
> 
> This will give you a double matrix with all missing value.  If you use
> the default
> 
>    X <- matrix(nrow=1001*1001, ncol=3650)
> 
> you'll get a logical matrix, which will introduce a copy as soon as
> you assign a double value (e.g. X[1,1] <- 3.14). The latter is a
> complete waste of memory/time. See
> http://www.jottr.org/2014/06/matrixNA-wrong-way.html for details.
> 
> /Henrik

Thanks.  Yes one time for some reason I can?t remember I did ?NA  where that is documented but it is not something you would think of offhand.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From micka.youngman at gmail.com  Sat Mar 19 08:36:21 2016
From: micka.youngman at gmail.com (Majid Javanmard)
Date: Sat, 19 Mar 2016 11:06:21 +0330
Subject: [R] Confidence Interval for Ipred Bagging outputs ?
Message-ID: <CAE_B1gbqMfTydCayX+hOCun6k=QnXnrh_sBxbZo4Xd9fa_g0oQ@mail.gmail.com>

Hello everyone

here is the code that implements bagging using ipred package in R :

library(ipred)
library(mlbench)
data("BostonHousing")
# Test set error (nbagg=25, trees pruned): 3.41 (Breiman, 1996a, Table 8)
mod <- bagging(medv ~ ., data=BostonHousing, coob=TRUE)
print(mod)
pred <- predict(mod)
pred<- as.data.frame(pred)

How can I have 95% Confidence interval for each predicted values !?

I appreciate if someone help me

Thanks

	[[alternative HTML version deleted]]


From mahmoudfarid30 at yahoo.com  Sat Mar 19 14:17:38 2016
From: mahmoudfarid30 at yahoo.com (mahmoudfarid30 at yahoo.com)
Date: Sat, 19 Mar 2016 13:17:38 +0000 (UTC)
Subject: [R] summation involving multiple summations
References: <1301609081.1165799.1458393458601.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1301609081.1165799.1458393458601.JavaMail.yahoo@mail.yahoo.com>

Dear R Experts 

I've a function which involves multiple summations, and the number of summations depends on a 
random variable named (n-r), where n is known but r is random and r<n. 

So, if , for example , n-r=3, the function is: 

>n_r=3 
>fx=function(x)sum(sapply(1:n_r, function(j1) {sum(sapply(1:(j1), function(j2){sum(sapply(1:(j2), function(j3){(j1>j2)*(j2>j3)/(x+exp(tc[j1]+tc[j2]+tc[j3])^4}))}))}))} 

The value of r will be generated from a simulation process, so in one iteration r may be equal to 0, and in another iteration it might be equal to 2 and so on, and accordingly  (n-r) is either 1, 2, or 3. And this makes the body of the summation different every time. 


Here's my  trail code in the simple case when n=3: 

library(nleqslv) 
N=100;n=3 
a=matrix(0,nrow=N,ncol=1) 
for(i in 1:N){ 
tc=matrix(0, nrow=n, ncol=1) 
t=matrix(0, nrow=n, ncol=1) 
c=matrix(0,nrow=n,ncol=1) 
for(j in 1: n){ 
t[j]=rexp(1,rate=3) 

c[j]=rexp(1, rate =2) 
if (t[j]>=c[j]) {tc[j]=t[j]} 
} 
n_r=nrow(tc) 
if(n_r==1){fx=function(x)sum(sapply(1:n-3, function(j1){1/(x+exp(tc[j1]))^4})) 
a[i]=nleqslv(0.5, fx)$x 
} 
if(n_r==2){fx=function(x)sum(sapply(1:n-2, function(j1){sum(sapply(1:(j1),function(j2){(j1>j2)/(x+exp(tc[j1]+tc[j2]))^4}))})) 
a[i]=nleqslv(0.5, fx)$x 
} 
if(n_r==3){fx=function(x)sum(sapply(1:n, function(j1) {sum(sapply(1:(j1), function(j2){sum(sapply(1:(j2), 
function(j3){(j1>j2)*(j2>j3)/(x+exp(tc[j1]+tc[j2]+tc[j3]))^4}))}))})) 
a[i]=nleqslv(0.5, fx)$x 
} 
} 

Is there any other way to write a loop that could be executed for any value of r instead of putting the if ()  statement for each single value of r , as n may take large values reaching 30, for instance. 

Any help or recommendation for a reference that can help me would be appreciated . 
Thank you
Mahmoud Farid


From prasad.prasad.kale at gmail.com  Sat Mar 19 15:09:35 2016
From: prasad.prasad.kale at gmail.com (Prasad Kale)
Date: Sat, 19 Mar 2016 19:39:35 +0530
Subject: [R] How To Start R Studio After Installation
Message-ID: <CAHKdztUFLL26Uj9KzJ9nPMdhXeN2_4Y3PR1gQdfzKiX3okmdgQ@mail.gmail.com>

Hello,

I am new to 'R' and just now installed R as well as 'R Studio' on my
personal desktop.

Firstly I have downloaded R and I am able open the same as well.

Afterwords I have downloaded and installed the 'R Studio' but i don't know
from where I can open the 'R Studio'. As I am not finding a short cut from
where I can open the 'R Studio'.

Please Help..

	[[alternative HTML version deleted]]


From reichmanj at sbcglobal.net  Sat Mar 19 17:36:29 2016
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Sat, 19 Mar 2016 11:36:29 -0500
Subject: [R] Exporting Commands and Results
In-Reply-To: <CAKJpBtL7vii7GbnDXWGvVtyH6ecgd25JyTm4oXP0vPKnuQwv9w@mail.gmail.com>
References: <000001d18161$85080080$8f180180$@sbcglobal.net>
	<CAKJpBtL7vii7GbnDXWGvVtyH6ecgd25JyTm4oXP0vPKnuQwv9w@mail.gmail.com>
Message-ID: <002601d181fd$7db99b80$792cd280$@sbcglobal.net>

 

Perfect!!!

 

From: Anders Alexandersson [mailto:andersalex at gmail.com] 
Sent: Saturday, March 19, 2016 6:26 AM
To: reichmanj at sbcglobal.net
Subject: Re: [R] Exporting Commands and Results

 

https://codeandculture.wordpress.com/2014/10/09/what-is-the-word-for-log-in-r/

 

On Fri, Mar 18, 2016 at 6:00 PM, Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Users



I know sink("filename") will export my results to a file but how do I export
both commands and results in R?



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Mar 19 17:44:23 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 19 Mar 2016 08:44:23 -0800
Subject: [R] How To Start R Studio After Installation
In-Reply-To: <CAHKdztUFLL26Uj9KzJ9nPMdhXeN2_4Y3PR1gQdfzKiX3okmdgQ@mail.gmail.com>
Message-ID: <FD2ABCB4F8C.000002EBjrkrideau@inbox.com>

What is your operating system?  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: prasad.prasad.kale at gmail.com
> Sent: Sat, 19 Mar 2016 19:39:35 +0530
> To: r-help at r-project.org
> Subject: [R] How To Start R Studio After Installation
> 
> Hello,
> 
> I am new to 'R' and just now installed R as well as 'R Studio' on my
> personal desktop.
> 
> Firstly I have downloaded R and I am able open the same as well.
> 
> Afterwords I have downloaded and installed the 'R Studio' but i don't
> know
> from where I can open the 'R Studio'. As I am not finding a short cut
> from
> where I can open the 'R Studio'.
> 
> Please Help..
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From boris.steipe at utoronto.ca  Sat Mar 19 17:45:30 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 19 Mar 2016 12:45:30 -0400
Subject: [R] Persistent state in a function?
Message-ID: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>

Dear all -

I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
 -A- how can I keep the table in an environment that is private to the function but persistent for the session?
 -B- how can I store and reload such table?
 -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?


For illustration ...

-----------------------------------

myDist <- function(a, b) { 
    # retrieve or calculate distances 
    if (!exists("Vals")) {
        Vals <<- numeric() # the lookup table for distance values
                           # here, created in the global env.
    }
    key <- sprintf("X%d.%d", a, b)
    thisDist <- Vals[key]
    if (is.na(thisDist)) {          # Hasn't been calculated yet ...
        cat("Calculating ... ")
        thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
        Vals[key] <<- thisDist      # store in global table
    }
    return(thisDist)
}


# run this
set.seed(112358)

for (i in 1:10) {
    x <- sample(1:3, 2)
    print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
}


Thanks!
Boris


From bgunter.4567 at gmail.com  Sat Mar 19 17:56:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 19 Mar 2016 09:56:18 -0700
Subject: [R] Persistent state in a function?
In-Reply-To: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
Message-ID: <CAGxFJbRqcXBQDwdy5QfFOsvsmAxLJphD8jYQ1DvbRB5ZpFmBbQ@mail.gmail.com>

Use an environment to hold your table.

?new.env

or

?local

(I leave it to you to work out details)

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 19, 2016 at 9:45 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Dear all -
>
> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>  -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>  -B- how can I store and reload such table?
>  -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>
>
> For illustration ...
>
> -----------------------------------
>
> myDist <- function(a, b) {
>     # retrieve or calculate distances
>     if (!exists("Vals")) {
>         Vals <<- numeric() # the lookup table for distance values
>                            # here, created in the global env.
>     }
>     key <- sprintf("X%d.%d", a, b)
>     thisDist <- Vals[key]
>     if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>         cat("Calculating ... ")
>         thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>         Vals[key] <<- thisDist      # store in global table
>     }
>     return(thisDist)
> }
>
>
> # run this
> set.seed(112358)
>
> for (i in 1:10) {
>     x <- sample(1:3, 2)
>     print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> }
>
>
> Thanks!
> Boris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erich.neuwirth at univie.ac.at  Sat Mar 19 18:11:27 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sat, 19 Mar 2016 18:11:27 +0100
Subject: [R] Persistent state in a function?
In-Reply-To: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
Message-ID: <5051652B-B487-4FC8-8EBC-E32DDD8B6592@univie.ac.at>

package memoise
might help you

> On 19 Mar 2016, at 17:45, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> Dear all -
> 
> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
> -A- how can I keep the table in an environment that is private to the function but persistent for the session?
> -B- how can I store and reload such table?
> -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
> 
> 
> For illustration ...
> 
> -----------------------------------
> 
> myDist <- function(a, b) {
>    # retrieve or calculate distances
>    if (!exists("Vals")) {
>        Vals <<- numeric() # the lookup table for distance values
>                           # here, created in the global env.
>    }
>    key <- sprintf("X%d.%d", a, b)
>    thisDist <- Vals[key]
>    if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>        cat("Calculating ... ")
>        thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>        Vals[key] <<- thisDist      # store in global table
>    }
>    return(thisDist)
> }
> 
> 
> # run this
> set.seed(112358)
> 
> for (i in 1:10) {
>    x <- sample(1:3, 2)
>    print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> }
> 
> 
> Thanks!
> Boris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160319/ed1cbd29/attachment.bin>

From dwinsemius at comcast.net  Sat Mar 19 19:15:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Mar 2016 11:15:16 -0700
Subject: [R] Confidence Interval for Ipred Bagging outputs ?
In-Reply-To: <CAE_B1gbqMfTydCayX+hOCun6k=QnXnrh_sBxbZo4Xd9fa_g0oQ@mail.gmail.com>
References: <CAE_B1gbqMfTydCayX+hOCun6k=QnXnrh_sBxbZo4Xd9fa_g0oQ@mail.gmail.com>
Message-ID: <91208CA2-DA04-490F-A2CC-2E4DD80E0B5E@comcast.net>


> On Mar 19, 2016, at 12:36 AM, Majid Javanmard <micka.youngman at gmail.com> wrote:
> 
> Hello everyone
> 
> here is the code that implements bagging using ipred package in R :
> 
> library(ipred)
> library(mlbench)
> data("BostonHousing")
> # Test set error (nbagg=25, trees pruned): 3.41 (Breiman, 1996a, Table 8)
> mod <- bagging(medv ~ ., data=BostonHousing, coob=TRUE)
> print(mod)
> pred <- predict(mod)
> pred<- as.data.frame(pred)
> 
> How can I have 95% Confidence interval for each predicted values !?

Perhaps you really mean prediction intervals, since none of those results really a parameters. I don't think it makes sense to talk about 95%CI's in the context of a bagging procedure because there really is no single model. In any case it has already been suggested that this is not really an R coding problem but rather a conceptual problem. You were advised to post further questions on stats.stackexchange.com (if you were unable to find an answered question), the first hit on a Google search for "confidence Interval randomForest":

 http://stats.stackexchange.com/questions/56895/do-the-predictions-of-a-random-forest-model-have-a-prediction-interval

-- 

David Winsemius
Alameda, CA, USA


From lorenzo.isella at gmail.com  Sat Mar 19 21:28:48 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 19 Mar 2016 21:28:48 +0100
Subject: [R] Orthogonal Nonlinear Least-Squares Regression in R
Message-ID: <20160319202848.GA1409@chicca>

Dear All,
I am trying my hands at orthogonal least square regression.
Have a look for instance at


http://bit.ly/1pB2aHX

https://cran.r-project.org/web/packages/onls/index.html

http://bit.ly/1XDkkTL

docs.scipy.org/doc/external/odrpack_guide.pdf

However, I am experiencing some problems with a simple example, just
to compare the results to a simple linear fit.

Have a look at the following snippet

################################################

library(onls)

dd <- structure(list(de_emp_mn_agg = c(9226, 9404, 9604, 10183, 10788,
11352, 11984, 12921, 14057, 15235, 15560, 15738, 16039, 16729,
17332, 18398, 19458, 20001, 19861, 20690, 21495, 21869, 22145,
22521), de_emp_ind_agg = c(43862, 40621, 37884, 36039, 35228,
34336, 33684, 33816, 33593, 33861, 33817, 33139, 32250, 31796,
31276, 30934, 31340, 32078, 31366, 30800, 31410, 31975, 32120,
32254), de_gov_exp_agg = c(1183695, 1281056, 1334560, 1390475,
1439175, 1472564, 1495661, 1520460, 1565451, 1604454, 1654996,
1672559, 1701664, 1722003, 1751547, 1793235, 1824640, 1874300,
1894248, 1939610, 2001224, 2056539, 2104642, 2156210), berd =
c(26245.5,
26579, 25933, 25910, 26816.6, 27211, 28909.8, 30334.44, 33622.55,
35600, 36331.9, 36950, 38029, 38363, 38651.038, 41148, 43034,
46073, 45275, 46929, 51077.2, 53790.1, 53566.2, 56226)), row.names =
c(NA,
24L), .Names = c("de_emp_mn_agg", "de_emp_ind_agg", "de_gov_exp_agg",
"berd"), class = "data.frame")


mm1 <- lm(berd~ de_emp_mn_agg+
                  de_emp_ind_agg+
		   de_gov_exp_agg ,
                  data=dd)
		  
#and now this fails

mm3 <- onls(berd~ K+ A*de_emp_mn_agg+
                  B*de_emp_ind_agg+
		    D*de_gov_exp_agg,
		    data=dd,
		    start = list(K=-5e4, A= 1,B =1, D=0.1 ))
						      



################################################


I get this error message

Error in mf[[varNamesRHS]] : recursive indexing failed at level 2

What am I doing wrong?

Here is my sessionInfo()

> sessionInfo()
R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
     [9] LC_ADDRESS=C              LC_TELEPHONE=C
     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] onls_0.1-1       minpack.lm_1.2-0


Any suggestion is appreciated.
Many thanks

Lorenzo


From kmnanus at gmail.com  Sat Mar 19 17:50:56 2016
From: kmnanus at gmail.com (KMNanus)
Date: Sat, 19 Mar 2016 12:50:56 -0400
Subject: [R] How To Start R Studio After Installation
In-Reply-To: <CAHKdztUFLL26Uj9KzJ9nPMdhXeN2_4Y3PR1gQdfzKiX3okmdgQ@mail.gmail.com>
References: <CAHKdztUFLL26Uj9KzJ9nPMdhXeN2_4Y3PR1gQdfzKiX3okmdgQ@mail.gmail.com>
Message-ID: <EEE96D46-F50C-4CE0-9D1F-344408B8AA88@gmail.com>

If you?re on a mac, just go into finder, then applications. highlight R studio and drag it to the dock.  Then double-click it and r studio should start.

If you?re on Windows, I don?t have a clue.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 19, 2016, at 10:09 AM, Prasad Kale <prasad.prasad.kale at gmail.com> wrote:
> 
> Hello,
> 
> I am new to 'R' and just now installed R as well as 'R Studio' on my
> personal desktop.
> 
> Firstly I have downloaded R and I am able open the same as well.
> 
> Afterwords I have downloaded and installed the 'R Studio' but i don't know
> from where I can open the 'R Studio'. As I am not finding a short cut from
> where I can open the 'R Studio'.
> 
> Please Help..
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leegi001 at umn.edu  Sat Mar 19 21:58:17 2016
From: leegi001 at umn.edu (Cathy Lee Gierke)
Date: Sat, 19 Mar 2016 15:58:17 -0500
Subject: [R] degree sign
In-Reply-To: <DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
	<DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
Message-ID: <CAOeg=_8z90YVUWZphxo9a-ZpVHPD0C3NiuzCh8or4dP+LQBBwg@mail.gmail.com>

My actual plot call is long and complicated, so I tried to simplify it in
the last message.....here is the actual, using David's proposed solution.
It is not working.   What I want to see printed is the following (with
degree symbols after 73 and 296).  Since I reuse this string in various
ways, I would like to build a variable to hold it that I can plug into
plots when needed:


*Hours from Reference Time: 201302060000 Model span = 24.00 hrs     o ?73
  b ?296*

So I set xlab=printXlab value with David's solution, below, in the plot
(this is the actual printXlab value, instead of the simplified one):


* xl = bquote( .(Orthophase[i,j] )*degree )**printXlab<-paste("Hours from
Reference Time:",RefTimeString,"Model span
=",format(magDt,digits=3,nsmall=2),"hrs    o",Orthophase[i,j],xl,"
b",Bathyphase[i,j])  *

and here is the result I get (weird duplicates....but most importantly, no
degree symbol:

Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 *
Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 ?73
Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 degree

b ?296 b ?296

b ?296
----------------------
So, I tried to set xlab as Uwe's proposal (without paste, and without
commas):
printXlab<-expression("Hours from Reference Time:" RefTimeString "Model
span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] *
degree"     b"* Bathyphase[i,j] * degree)     #  degree~C

I get "unexpected symbol at ^RefTimeStrng" so it doesn't like the missing
commas.

Then I try it with commas, except around the degree parts:
printXlab<-expression("Hours from Reference Time:" RefTimeString "Model
span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] *
degree"     b"* Bathyphase[i,j] * degree)     #  degree~C

It runs, but here is what prints:

Hours from Reference Time:
?Then I try with all commas replaced by *:
printXlab<-expression("Hours from Reference Time:"* RefTimeString *"Model
span =" * format(magDt,digits=3,nsmall=2) * "hrs    o" * Orthophase[i,j] *
degree * "     b"* Bathyphase[i,j] * degree * " ")     #  degree~C

?And I get degree signs (sort of)!!  But the rest is wrong. The variables
are not evaluated:

Hours from Reference Time:RefTimeStringModel span =format(magDt, 3, 2)hrs
oOrthophasei? bBathyphasei?
?I don't really understand what state is required for the degrees to
print....?

Cathy Lee Gierke

*"We are what we repeatedly do.  Excellence, then, is not an act, but a
habit." Aristotle*

On Sat, Mar 19, 2016 at 2:04 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 18, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> >
> > I have searched and tried many things but cannot get anything to work.  I
> > just want to print out a degree sign after a the Orthophase number.
> >
> > The following list of "xl" values are all ones I have tried.  Granted
> they
> > are not what I want, but I have tried them all, and none of them print
> out
> > a degree symbol...
> >
> > #                   xl = expression(paste("Orthophase [", {
> > #                   }^o, "]"))
> >                  #xl<-~degree~C
> >                  #xl<-parse(text = ~degree)
> >                  #xl<-parse(text = paste(" ", "~degree", sep = ""))
> >                  #xl<-expression(~degree)
> >                  xl <- parse(text = paste(Orthophase[i,j], "*degree ~ S",
> > sep = ""))
> >
> >
> >                  printXlab<-paste("Orthophase    ",Orthophase[i,j],xl,"
> >  ")
> >
> > plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
> > xlab=printXlab,.....
>
> Ya' know Cathy. It would be nice if you would say what it was that you
> actually wanted to do rather than offering multiple failures This does not
> throw an error:
>
> xl = expression(paste("Orthophase [", {
>                   }^o, "]"))
> plot(1,1,type="l", xaxt="n", xlab=xl)
>
>
>
> But perhaps you want to pull in an evaluated result from an object in the
> workspace? This should work:
>
> Orthophase <- matrix( 4:1, 2)
> i=1;j=1
> xl = bquote( .(Orthophase [i,j] )*degree )
> plot(1,1,type="l", xaxt="n",
> xlab=xl)
>
> >
> >
> > Cathy Lee Gierke
> >
> > *"We are what we repeatedly do.  Excellence, then, is not an act, but a
> > habit." Aristotle*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Mar 19 22:57:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Mar 2016 17:57:56 -0400
Subject: [R] Persistent state in a function?
In-Reply-To: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
Message-ID: <56EDCB64.3080505@gmail.com>

On 19/03/2016 12:45 PM, Boris Steipe wrote:
> Dear all -
>
> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>   -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>   -B- how can I store and reload such table?
>   -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>
>
> For illustration ...
>
> -----------------------------------
>
> myDist <- function(a, b) {
>      # retrieve or calculate distances
>      if (!exists("Vals")) {
>          Vals <<- numeric() # the lookup table for distance values
>                             # here, created in the global env.
>      }
>      key <- sprintf("X%d.%d", a, b)
>      thisDist <- Vals[key]
>      if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>          cat("Calculating ... ")
>          thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>          Vals[key] <<- thisDist      # store in global table
>      }
>      return(thisDist)
> }
>
>
> # run this
> set.seed(112358)
>
> for (i in 1:10) {
>      x <- sample(1:3, 2)
>      print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> }


Use local() to create a persistent environment for the function.  For 
example:

f <- local({
   x <- NULL
   function(y) {
     cat("last x was ", x, "\n")
     x <<- y
   }
})

Then:

 > f(3)
last x was
 > f(4)
last x was  3
 > f(12)
last x was  4

Duncan Murdoch


From jordanmeyer1991 at gmail.com  Sat Mar 19 23:10:33 2016
From: jordanmeyer1991 at gmail.com (Jordan Meyer)
Date: Sat, 19 Mar 2016 18:10:33 -0400
Subject: [R] How To Start R Studio After Installation
In-Reply-To: <CAF+g6roAC3M-ZGk-zFQVgEXE19rJdz8jP8RFe37mt7MrvmRmsQ@mail.gmail.com>
References: <CAHKdztUFLL26Uj9KzJ9nPMdhXeN2_4Y3PR1gQdfzKiX3okmdgQ@mail.gmail.com>
	<EEE96D46-F50C-4CE0-9D1F-344408B8AA88@gmail.com>
	<CAF+g6roAC3M-ZGk-zFQVgEXE19rJdz8jP8RFe37mt7MrvmRmsQ@mail.gmail.com>
Message-ID: <CAF+g6ro7fo8Mm9d1Uapp=i+22wD4rwp03KouGh_-gTE9vKQe4A@mail.gmail.com>

Forgot to reply to list...
On Mar 19, 2016 6:09 PM, "Jordan Meyer" <jordanmeyer1991 at gmail.com> wrote:

> I'd you used a different administrator account on your (Windows) computer
> during installation, you may have unintentionally installed it only for
> that account. (For example, you used an administrator account different
> from your own to authorize permissions.)
> On Mar 19, 2016 5:33 PM, "KMNanus" <kmnanus at gmail.com> wrote:
>
>> If you?re on a mac, just go into finder, then applications. highlight R
>> studio and drag it to the dock.  Then double-click it and r studio should
>> start.
>>
>> If you?re on Windows, I don?t have a clue.
>>
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>>
>>
>>
>> > On Mar 19, 2016, at 10:09 AM, Prasad Kale <prasad.prasad.kale at gmail.com>
>> wrote:
>> >
>> > Hello,
>> >
>> > I am new to 'R' and just now installed R as well as 'R Studio' on my
>> > personal desktop.
>> >
>> > Firstly I have downloaded R and I am able open the same as well.
>> >
>> > Afterwords I have downloaded and installed the 'R Studio' but i don't
>> know
>> > from where I can open the 'R Studio'. As I am not finding a short cut
>> from
>> > where I can open the 'R Studio'.
>> >
>> > Please Help..
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Sun Mar 20 03:19:26 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Sun, 20 Mar 2016 15:19:26 +1300
Subject: [R] What "method" does sort() use?
In-Reply-To: <4993E91C-AA99-42D0-9781-093D6CA7425B@gmail.com>
References: <20160318090228.GA2013@slingshot.co.nz>
	<C86BBDF5-72D8-4260-954B-172A522E1049@gmail.com>
	<4993E91C-AA99-42D0-9781-093D6CA7425B@gmail.com>
Message-ID: <20160320021925.GB2013@slingshot.co.nz>

I did look at the Comparison help but totally overlooked this part;

     Comparison of strings in character vectors is lexicographic within
     the strings using the collating sequence of the locale in use: see
     ?locales?.  The collating sequence of locales such as ?en_US? is
     normally different from ?C? (which should use ASCII) and can be
     surprising.  

I've recently changed to a different Linux distribution and was trying
to work out why I was getting a different order of the factor levels
even though it was the same code.  I thought I'd inadvertantly changed
something somehow.

Much clearer now -- even if still confusing.  

Thanks for the pointer.


On Fri, 18-Mar-2016 at 10:19AM +0100, peter dalgaard wrote:

|> Ooops, that was answering the question you actually asked. The one you meant to ask is answered by this  part:
|> 
|> The sort order for character vectors will depend on the collating sequence of the locale in use: see Comparison. 
|> 
|> ...and collating sequences is a weird and woolly subject, where you cannot even be sure that locales of the same name on two different platforms sort strings in the same order.
|> 
|> -pd
|> 
|> 
|> 
|> On 18 Mar 2016, at 10:13 , peter dalgaard <pdalgd at gmail.com> wrote:
|> 
|> > 
|> > On 18 Mar 2016, at 10:02 , Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> > 
|> >> I don't follow why this happens:
|> >> 
|> >>> sort(c(LETTERS[1:5], letters[1:5]))
|> >> [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E"
|> >> 
|> >> The help for sort() says:
|> >> 
|> >> method: character string specifying the algorithm used.  Not
|> >>         available for partial sorting.  Can be abbreviated.
|> >> 
|> >> But what are the methods available?  The help mentions xtfrm but that
|> >> doesn't illuminate, I'd have thought that at least by default it would
|> >> have something to do with ASCII codes.  But that's not the case since
|> >> all the uppercase ones would be before the lowercase ones.
|> >> 
|> >> I know something different is happening but I don't know what it is
|> >> (do you, Mr Jones?).  Apologies to Bob Dylan.
|> >> 
|> > 
|> > 
|> > Um, read _all_ of the help file?
|> > 
|> > sort.int(x, partial = NULL, na.last = NA, decreasing = FALSE,
|> >         method = c("shell", "quick"), index.return = FALSE)
|> > 
|> > [snip]
|> > 
|> > Method "shell" uses Shellsort (an O(n^{4/3}) variant from Sedgewick (1986)). If x has names a stable modification is used, so ties are not reordered. (This only matters if names are present.)
|> > 
|> > Method "quick" uses Singleton (1969)'s implementation of Hoare's Quicksort method and is only available when x is numeric (double or integer) and partial is NULL. (For other types of x Shellsort is used, silently.) It is normally somewhat faster than Shellsort (perhaps 50% faster on vectors of length a million and twice as fast at a billion) but has poor performance in the rare worst case. (Peto's modification using a pseudo-random midpoint is used to make the worst case rarer.) This is not a stable sort, and ties may be reordered.
|> > 
|> > Factors with less than 100,000 levels are sorted by radix sorting when method is not supplied: see sort.list.
|> > 
|> > -pd
|> > 
|> > 
|> > -- 
|> > Peter Dalgaard, Professor,
|> > Center for Statistics, Copenhagen Business School
|> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
|> > Phone: (+45)38153501
|> > Office: A 4.23
|> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
|> 
|> -- 
|> Peter Dalgaard, Professor,
|> Center for Statistics, Copenhagen Business School
|> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
|> Phone: (+45)38153501
|> Office: A 4.23
|> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
|> 

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From kristi.glover at hotmail.com  Sun Mar 20 15:15:03 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 20 Mar 2016 14:15:03 +0000
Subject: [R] Problem in selecting rows in R
Message-ID: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi R Users,
Some individuals recorded multiple within a time period. But, I want to select the row of last site within each time period for each individual. I spent a substantial time, but no luck in selecting the rows. Would you give me a hint for this one? I have a very large data set, but this is just an example.
Thanks for your help.

I want to get dat2 from dat1.

dat1<-structure(list(sn = 1:16, Species = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
"Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 3L, 1L, 2L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 4L, 1L, 3L), .Label = c("SiteA",
"SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time = structure(c(1L, 5L, 6L, 6L, 6L, 2L, 3L, 11L, 8L, 10L, 1L, 1L, 4L, 4L, 7L, 9L), .Label = c("1/15/15",
"1/17/15", "1/29/15", "2/17/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"),
    Month = structure(c(3L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 4L, 1L, 3L, 3L, 2L, 2L, 2L, 4L), .Label = c("April", "Feb", "Jan",
    "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -16L))
dat1
#---
dat2<-structure(list(sn = c(1L, 5L, 6L, 9L, 10L, 11L, 12L, 15L, 16L), Species = structure(c(1L, 1L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
"Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", "SiteB",
"SiteC"), class = "factor"), Time = structure(c(1L, 3L, 2L, 5L, 7L, 1L, 1L, 4L, 6L), .Label = c("1/15/15", "1/17/15", "2/27/15",
"2/28/15", "3/27/15", "3/5/15", "4/19/15"), class = "factor"), Month = structure(c(3L, 2L, 3L, 4L, 1L, 3L, 3L, 2L, 4L), .Label = c("April",
    "Feb", "Jan", "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -9L))
dat2

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Mar 20 16:14:45 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 20 Mar 2016 15:14:45 +0000
Subject: [R] Problem in selecting rows in R
In-Reply-To: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <56EEBE65.9050403@dewey.myzen.co.uk>

Dear Kristi

You do not say what you have tried but I would have thought the key to a 
solution was to split your problem up by site and write a function to 
select the last observation within each site. I am not quite clear 
whether this is the last in time or the last occurring row so I just 
give a hint below as to functions

?aggregate
?by
?strplit
?lapply

which may all be relevant here.

On 20/03/2016 14:15, Kristi Glover wrote:
> Hi R Users,
> Some individuals recorded multiple within a time period. But, I want to select the row of last site within each time period for each individual. I spent a substantial time, but no luck in selecting the rows. Would you give me a hint for this one? I have a very large data set, but this is just an example.
> Thanks for your help.
>
> I want to get dat2 from dat1.
>
> dat1<-structure(list(sn = 1:16, Species = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 3L, 1L, 2L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 4L, 1L, 3L), .Label = c("SiteA",
> "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time = structure(c(1L, 5L, 6L, 6L, 6L, 2L, 3L, 11L, 8L, 10L, 1L, 1L, 4L, 4L, 7L, 9L), .Label = c("1/15/15",
> "1/17/15", "1/29/15", "2/17/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"),
>      Month = structure(c(3L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 4L, 1L, 3L, 3L, 2L, 2L, 2L, 4L), .Label = c("April", "Feb", "Jan",
>      "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -16L))
> dat1
> #---
> dat2<-structure(list(sn = c(1L, 5L, 6L, 9L, 10L, 11L, 12L, 15L, 16L), Species = structure(c(1L, 1L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", "SiteB",
> "SiteC"), class = "factor"), Time = structure(c(1L, 3L, 2L, 5L, 7L, 1L, 1L, 4L, 6L), .Label = c("1/15/15", "1/17/15", "2/27/15",
> "2/28/15", "3/27/15", "3/5/15", "4/19/15"), class = "factor"), Month = structure(c(3L, 2L, 3L, 4L, 1L, 3L, 3L, 2L, 4L), .Label = c("April",
>      "Feb", "Jan", "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -9L))
> dat2
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From boris.steipe at utoronto.ca  Sun Mar 20 16:21:06 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 20 Mar 2016 11:21:06 -0400
Subject: [R] Problem in selecting rows in R
In-Reply-To: <56EEBE65.9050403@dewey.myzen.co.uk>
References: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
	<56EEBE65.9050403@dewey.myzen.co.uk>
Message-ID: <58C19B86-04DD-4DAC-8B75-1326275F090C@utoronto.ca>

Don't post in HTML, but thanks for providing dput() outout.

This code tries to follow your specifications, assuming by "time period" you mean days. The result doesn't look like your desired example though, because that is not compatible with your specs and I can't guess what you want to do differently. E.g your species 2 is observed on three different days:

6   6     Sp2         SiteB 2015-01-17   Jan
7   7     Sp2         SiteD 2015-01-29   Feb
8   8     Sp2         SiteC 2015-07-03 March

... yet your dat2 contains only the first observation in Jan.

Also note that there are conflicts like this:

3   3     Sp1         SiteA 2015-02-27 
4   4     Sp1         SiteB 2015-02-27 

... that you have not specified how to resolve. Is there an ordering
implied such that SiteB is the "last site"?


Finally, your data is messy: youhave Sp2 and SP3, SiteC and SIteD - if you don't pay better attention that's going to bite you one day.



Here's working code, you should be able to solve it entirely based on
this:

# Step 1: most of your columns are factors. This doesn't matter much
#         except for Time. For time this is the Wrong Way, since time
#         is ordered. We replace ...
datNew <- dat1
datNew$Time <-  strptime(as.character(dat1$Time), format="%m/%d/%y")

# Step 2: Your problem is solved with a combination of order() and duplicated().
#         In order to make the ordering of species/site unique we generate
#         an auxiliary column.
datNew$key <- paste(datNew$Species, datNew$Time, sep=".")

# Step 3: Now we order the rows by $key and $Observed.site, in decreasing order
datNew <- datNew[ order(datNew$key, datNew$Observed.site, decreasing=TRUE), ]

# Step 4: Then we drop all but the first row from each species/site
#         block. The first row is the last date (decreasing sort, remember!)
datNew <- datNew[!duplicated(datNew$key), ]

# Step 5: We can drop the keys and order ascending
#         to make it look more like your example. Now we have
#         one site on each day for each individual.
datNew <- datNew[order(datNew$key), colnames(datNew) != "key"]
datNew



B.


On Mar 20, 2016, at 11:14 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Kristi
> 
> You do not say what you have tried but I would have thought the key to a solution was to split your problem up by site and write a function to select the last observation within each site. I am not quite clear whether this is the last in time or the last occurring row so I just give a hint below as to functions
> 
> ?aggregate
> ?by
> ?strplit
> ?lapply
> 
> which may all be relevant here.
> 
> On 20/03/2016 14:15, Kristi Glover wrote:
>> Hi R Users,
>> Some individuals recorded multiple within a time period. But, I want to select the row of last site within each time period for each individual. I spent a substantial time, but no luck in selecting the rows. Would you give me a hint for this one? I have a very large data set, but this is just an example.
>> Thanks for your help.
>> 
>> I want to get dat2 from dat1.
>> 
>> dat1<-structure(list(sn = 1:16, Species = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
>> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 3L, 1L, 2L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 4L, 1L, 3L), .Label = c("SiteA",
>> "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time = structure(c(1L, 5L, 6L, 6L, 6L, 2L, 3L, 11L, 8L, 10L, 1L, 1L, 4L, 4L, 7L, 9L), .Label = c("1/15/15",
>> "1/17/15", "1/29/15", "2/17/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"),
>>     Month = structure(c(3L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 4L, 1L, 3L, 3L, 2L, 2L, 2L, 4L), .Label = c("April", "Feb", "Jan",
>>     "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -16L))
>> dat1
>> #---
>> dat2<-structure(list(sn = c(1L, 5L, 6L, 9L, 10L, 11L, 12L, 15L, 16L), Species = structure(c(1L, 1L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
>> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", "SiteB",
>> "SiteC"), class = "factor"), Time = structure(c(1L, 3L, 2L, 5L, 7L, 1L, 1L, 4L, 6L), .Label = c("1/15/15", "1/17/15", "2/27/15",
>> "2/28/15", "3/27/15", "3/5/15", "4/19/15"), class = "factor"), Month = structure(c(3L, 2L, 3L, 4L, 1L, 3L, 3L, 2L, 4L), .Label = c("April",
>>     "Feb", "Jan", "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -9L))
>> dat2
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Mar 20 17:08:00 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 20 Mar 2016 09:08:00 -0700
Subject: [R] Problem in selecting rows in R
In-Reply-To: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CAGxFJbTMb2wSa5TfZ=K1qhscr98U2wPjGHhj0znxJoN5vRkg-Q@mail.gmail.com>

Your example is wrong: What happened to Sp2 on 1/29?

You have also apparently mixed up lower and upper case: "Sp1", "SP3" .
This will likely cause you great grief, so try to avoid or fix this in
your work.

Anyway, there are tons of ways to  do this. dplyR is particularly good
at this sort of thing, I believe, so you might want to learn it.
However, I tend to use just base R, in which it is also pretty
straightforward.

1) I assume "time period" = Month. Please be clear in what you mean in
future. To get the final result neatly arranged, you could use date
functions, after first converting your Time column to POSIX. You could
then use the month() function to get the month, properly orderd.
However, as this is a bit complicated, I'll just use brute force to
order the Month factor manually:

dat1$Month <- with(dat1,ordered(as.character(Month),lev=c("Jan","Feb","March","April")))

2) Then this does what you want I think (there are more elegant ways,
certainly):

do.call(rbind, with(dat1,by(dat1, list(Species,Month), FUN
=function(x)x[nrow(x),])))


(You can use the order() function to order the data frame by Species
if you want to do this)


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 20, 2016 at 7:15 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R Users,
> Some individuals recorded multiple within a time period. But, I want to select the row of last site within each time period for each individual. I spent a substantial time, but no luck in selecting the rows. Would you give me a hint for this one? I have a very large data set, but this is just an example.
> Thanks for your help.
>
> I want to get dat2 from dat1.
>
> dat1<-structure(list(sn = 1:16, Species = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 3L, 1L, 2L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 4L, 1L, 3L), .Label = c("SiteA",
> "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time = structure(c(1L, 5L, 6L, 6L, 6L, 2L, 3L, 11L, 8L, 10L, 1L, 1L, 4L, 4L, 7L, 9L), .Label = c("1/15/15",
> "1/17/15", "1/29/15", "2/17/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"),
>     Month = structure(c(3L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 4L, 1L, 3L, 3L, 2L, 2L, 2L, 4L), .Label = c("April", "Feb", "Jan",
>     "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -16L))
> dat1
> #---
> dat2<-structure(list(sn = c(1L, 5L, 6L, 9L, 10L, 11L, 12L, 15L, 16L), Species = structure(c(1L, 1L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", "SiteB",
> "SiteC"), class = "factor"), Time = structure(c(1L, 3L, 2L, 5L, 7L, 1L, 1L, 4L, 6L), .Label = c("1/15/15", "1/17/15", "2/27/15",
> "2/28/15", "3/27/15", "3/5/15", "4/19/15"), class = "factor"), Month = structure(c(3L, 2L, 3L, 4L, 1L, 3L, 3L, 2L, 4L), .Label = c("April",
>     "Feb", "Jan", "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -9L))
> dat2
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Sun Mar 20 18:06:41 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 20 Mar 2016 17:06:41 +0000
Subject: [R] Problem in selecting rows in R
In-Reply-To: <58C19B86-04DD-4DAC-8B75-1326275F090C@utoronto.ca>
References: <BY2PR13MB0454B6B725376197B415C17DFA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>
	<56EEBE65.9050403@dewey.myzen.co.uk>,
	<58C19B86-04DD-4DAC-8B75-1326275F090C@utoronto.ca>
Message-ID: <BY2PR13MB0454140D569AFC6199BAAA92FA8E0@BY2PR13MB0454.namprd13.prod.outlook.com>

Dear Bert, Boris and Michael,
Thanks for your help. I noticed the example data was not compatible with my specification. The messy example embarrassed me.  I tested the codes you sent me both codes worked perfectly fine. Please accept my sincere thanks. 

KG

________________________________________
From: Boris Steipe <boris.steipe at utoronto.ca>
Sent: March 20, 2016 9:21 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] Problem in selecting rows in R

Don't post in HTML, but thanks for providing dput() outout.

This code tries to follow your specifications, assuming by "time period" you mean days. The result doesn't look like your desired example though, because that is not compatible with your specs and I can't guess what you want to do differently. E.g your species 2 is observed on three different days:

6   6     Sp2         SiteB 2015-01-17   Jan
7   7     Sp2         SiteD 2015-01-29   Feb
8   8     Sp2         SiteC 2015-07-03 March

... yet your dat2 contains only the first observation in Jan.

Also note that there are conflicts like this:

3   3     Sp1         SiteA 2015-02-27
4   4     Sp1         SiteB 2015-02-27

... that you have not specified how to resolve. Is there an ordering
implied such that SiteB is the "last site"?


Finally, your data is messy: youhave Sp2 and SP3, SiteC and SIteD - if you don't pay better attention that's going to bite you one day.



Here's working code, you should be able to solve it entirely based on
this:

# Step 1: most of your columns are factors. This doesn't matter much
#         except for Time. For time this is the Wrong Way, since time
#         is ordered. We replace ...
datNew <- dat1
datNew$Time <-  strptime(as.character(dat1$Time), format="%m/%d/%y")

# Step 2: Your problem is solved with a combination of order() and duplicated().
#         In order to make the ordering of species/site unique we generate
#         an auxiliary column.
datNew$key <- paste(datNew$Species, datNew$Time, sep=".")

# Step 3: Now we order the rows by $key and $Observed.site, in decreasing order
datNew <- datNew[ order(datNew$key, datNew$Observed.site, decreasing=TRUE), ]

# Step 4: Then we drop all but the first row from each species/site
#         block. The first row is the last date (decreasing sort, remember!)
datNew <- datNew[!duplicated(datNew$key), ]

# Step 5: We can drop the keys and order ascending
#         to make it look more like your example. Now we have
#         one site on each day for each individual.
datNew <- datNew[order(datNew$key), colnames(datNew) != "key"]
datNew



B.


On Mar 20, 2016, at 11:14 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Kristi
>
> You do not say what you have tried but I would have thought the key to a solution was to split your problem up by site and write a function to select the last observation within each site. I am not quite clear whether this is the last in time or the last occurring row so I just give a hint below as to functions
>
> ?aggregate
> ?by
> ?strplit
> ?lapply
>
> which may all be relevant here.
>
> On 20/03/2016 14:15, Kristi Glover wrote:
>> Hi R Users,
>> Some individuals recorded multiple within a time period. But, I want to select the row of last site within each time period for each individual. I spent a substantial time, but no luck in selecting the rows. Would you give me a hint for this one? I have a very large data set, but this is just an example.
>> Thanks for your help.
>>
>> I want to get dat2 from dat1.
>>
>> dat1<-structure(list(sn = 1:16, Species = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
>> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 3L, 1L, 2L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 4L, 1L, 3L), .Label = c("SiteA",
>> "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time = structure(c(1L, 5L, 6L, 6L, 6L, 2L, 3L, 11L, 8L, 10L, 1L, 1L, 4L, 4L, 7L, 9L), .Label = c("1/15/15",
>> "1/17/15", "1/29/15", "2/17/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"),
>>     Month = structure(c(3L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 4L, 1L, 3L, 3L, 2L, 2L, 2L, 4L), .Label = c("April", "Feb", "Jan",
>>     "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -16L))
>> dat1
>> #---
>> dat2<-structure(list(sn = c(1L, 5L, 6L, 9L, 10L, 11L, 12L, 15L, 16L), Species = structure(c(1L, 1L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
>> "Sp2", "SP3", "Sp4", "Sp5"), class = "factor"), Observed.site = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", "SiteB",
>> "SiteC"), class = "factor"), Time = structure(c(1L, 3L, 2L, 5L, 7L, 1L, 1L, 4L, 6L), .Label = c("1/15/15", "1/17/15", "2/27/15",
>> "2/28/15", "3/27/15", "3/5/15", "4/19/15"), class = "factor"), Month = structure(c(3L, 2L, 3L, 4L, 1L, 3L, 3L, 2L, 4L), .Label = c("April",
>>     "Feb", "Jan", "March"), class = "factor")), .Names = c("sn", "Species", "Observed.site", "Time", "Month"), class = "data.frame", row.names = c(NA, -9L))
>> dat2
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Mon Mar 21 03:02:08 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 20 Mar 2016 19:02:08 -0700
Subject: [R] degree sign
In-Reply-To: <CAOeg=_8PF4-pGNT+R7=Ka9S9Trc=szG8NhG+7AFjmCAvfO1tyA@mail.gmail.com>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
	<DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
	<CAOeg=_8z90YVUWZphxo9a-ZpVHPD0C3NiuzCh8or4dP+LQBBwg@mail.gmail.com>
	<A3499F20-7779-4AF2-BF14-DD05D716B121@comcast.net>
	<CAOeg=_8PF4-pGNT+R7=Ka9S9Trc=szG8NhG+7AFjmCAvfO1tyA@mail.gmail.com>
Message-ID: <56D7A030-38BF-40E9-A00B-651F0F4860DC@comcast.net>


It's a bit puzzling that neither of my replies to your postings have appeared on the R help list Archive. I normally reply-all to questions and despite the fact that you are sending in a formatted style, I have my client configured to reply in plain text. My client "Sent folder" has copies and the email addressees include r-help at r-project.org. I suppose this is a further "test" posting sent as reply-to-all. If it does not appear, then perhaps I can track down the problem by examining headers.


-- 
David.


> On Mar 19, 2016, at 9:44 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> 
> Wonderful!  That works.  
> 
> Cathy Lee Gierke
> 
> "We are what we repeatedly do.  Excellence, then, is not an act, but a habit." Aristotle
> 
> On Sat, Mar 19, 2016 at 6:44 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 19, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> >
> > My actual plot call is long and complicated, so I tried to simplify it in the last message.....here is the actual, using David's proposed solution.  It is not working.   What I want to see printed is the following (with degree symbols after 73 and 296).
> 
> 
> >  Since I reuse this string in various ways, I would like to build a variable to hold it that I can plug into plots when needed:
> > Hours from Reference Time: 201302060000
> > Model span = 24.00 hrs     o ?73     b ?296
> 
> The degree-object in plotmath needs to be placed within an R object of class expression.
> 
> For multi-line expression delivery in the outer portions of a graphic, I would recommend using mtext:
> 
> -------------
> 
> myexpr <- expression("Hours from Reference Time: 201302060000",
>                       "Model span = 24.00 hrs     o ?73"*degree*phantom("      ")*"b ?296"*degree)
> 
> plot(1,1)
>  mtext(myexpr[[1]] , side=1,line=2)
>  mtext(myexpr[[2]] , side=1,line=3)
> 
> >
> > So I set xlab=printXlab value with David's solution, below, in the plot (this is the actual printXlab value, instead of the simplified one):
> >
> >  xl = bquote( .(Orthophase[i,j] )*degree )
> > printXlab<-paste("Hours from Reference Time:",RefTimeString,"Model span =",format(magDt,digits=3,nsmall=2),"hrs    o",Orthophase[i,j],xl,"     b",Bathyphase[i,j])
> 
> If you are tryng to substitute
> >
> > and here is the result I get (weird duplicates....but most importantly, no degree symbol:
> >
> >
> > Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 * Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 ?73 Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 degree
> >
> > b ?296 b ?296
> >
> > b ?296
> >
> > ----------------------
> > So, I tried to set xlab as Uwe's proposal (without paste, and without commas):
> > printXlab<-expression("Hours from Reference Time:" RefTimeString "Model span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] * degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
> 
> You may want to use substitute or bquote to create an expression that has evaluated values (if you will) for:
> 
> Orthophase[i,j]
> Bathyphase[i,j]
> 
> Something like this
> 
>  orth=3.56
>  bathy=5.87
>  RefTimeStr <- "test"
>  magDT <- "1999-01-01";
>  printXlab  <-  list( bquote("Hours from Reference Time:"~ .(RefTimeStr)),
>          bquote("Model span ="*.(format(magDt,digits=3,nsmall=2))* " hrs    o" * .(orth) * degree*"C     b"* .(bathy) * degree*C))
>  plot(1,1, xlab="")
>  mtext(sapply( printXlab, as.expression) , side=1,
>            line=2:3)
> 
> 
> --
> David.
> 
> >
> > I get "unexpected symbol at ^RefTimeStrng" so it doesn't like the missing commas.
> >
> > Then I try it with commas, except around the degree parts:
> > printXlab<-expression("Hours from Reference Time:" RefTimeString "Model span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] * degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
> >
> > It runs, but here is what prints:
> > Hours from Reference Time:
> >
> > ?Then I try with all commas replaced by *:
> > printXlab<-expression("Hours from Reference Time:"* RefTimeString *"Model span =" * format(magDt,digits=3,nsmall=2) * "hrs    o" * Orthophase[i,j] * degree * "     b"* Bathyphase[i,j] * degree * " ")     #  degree~C
> >
> > ?And I get degree signs (sort of)!!  But the rest is wrong. The variables are not evaluated:
> > Hours from Reference Time:RefTimeStringModel span =format(magDt, 3, 2)hrs oOrthophasei? bBathyphasei?
> >
> > ?I don't really understand what state is required for the degrees to print....?
> 
> >
> > Cathy Lee Gierke
> >
> > "We are what we repeatedly do.  Excellence, then, is not an act, but a habit." Aristotle
> >
> > On Sat, Mar 19, 2016 at 2:04 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Mar 18, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> > >
> > > I have searched and tried many things but cannot get anything to work.  I
> > > just want to print out a degree sign after a the Orthophase number.
> > >
> > > The following list of "xl" values are all ones I have tried.  Granted they
> > > are not what I want, but I have tried them all, and none of them print out
> > > a degree symbol...
> > >
> > > #                   xl = expression(paste("Orthophase [", {
> > > #                   }^o, "]"))
> > >                  #xl<-~degree~C
> > >                  #xl<-parse(text = ~degree)
> > >                  #xl<-parse(text = paste(" ", "~degree", sep = ""))
> > >                  #xl<-expression(~degree)
> > >                  xl <- parse(text = paste(Orthophase[i,j], "*degree ~ S",
> > > sep = ""))
> > >
> > >
> > >                  printXlab<-paste("Orthophase    ",Orthophase[i,j],xl,"
> > >  ")
> > >
> > > plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
> > > xlab=printXlab,.....
> >
> > Ya' know Cathy. It would be nice if you would say what it was that you actually wanted to do rather than offering multiple failures This does not throw an error:
> >
> > xl = expression(paste("Orthophase [", {
> >                   }^o, "]"))
> > plot(1,1,type="l", xaxt="n", xlab=xl)
> >
> >
> >
> > But perhaps you want to pull in an evaluated result from an object in the workspace? This should work:
> >
> > Orthophase <- matrix( 4:1, 2)
> > i=1;j=1
> > xl = bquote( .(Orthophase [i,j] )*degree )
> > plot(1,1,type="l", xaxt="n",
> > xlab=xl)
> >
> > >
> > >
> > > Cathy Lee Gierke
> > >
> > > *"We are what we repeatedly do.  Excellence, then, is not an act, but a
> > > habit." Aristotle*
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Mon Mar 21 03:29:07 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 21 Mar 2016 15:29:07 +1300
Subject: [R] [FORGED] Re:  degree sign
In-Reply-To: <56D7A030-38BF-40E9-A00B-651F0F4860DC@comcast.net>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
	<DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
	<CAOeg=_8z90YVUWZphxo9a-ZpVHPD0C3NiuzCh8or4dP+LQBBwg@mail.gmail.com>
	<A3499F20-7779-4AF2-BF14-DD05D716B121@comcast.net>
	<CAOeg=_8PF4-pGNT+R7=Ka9S9Trc=szG8NhG+7AFjmCAvfO1tyA@mail.gmail.com>
	<56D7A030-38BF-40E9-A00B-651F0F4860DC@comcast.net>
Message-ID: <56EF5C73.4010704@auckland.ac.nz>

On 21/03/16 15:02, David Winsemius wrote:
>
> It's a bit puzzling that neither of my replies to [Cathy Lee Gierke's]
> postings have > appeared on the R help list Archive. I normally reply-all
> to questions and despite the fact that you are sending in a formatted
> style, I have my client configured to reply in plain text. My client
> "Sent folder" has copies and the email addressees include
> r-help at r-project.org. I suppose this is a further "test" posting sent
> as reply-to-all. If it does not appear, then perhaps I can track down
> the problem by examining headers.

I can confirm receiving your latest message, and that searching my 
deleted messages reveals no trace of any postings from you on the 
subject of "degree sign".  Weird.  I guess the Paranoids must be out to 
get you.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From santib2002 at gmail.com  Sun Mar 20 01:43:10 2016
From: santib2002 at gmail.com (santib2002 at gmail.com)
Date: Sat, 19 Mar 2016 21:43:10 -0300
Subject: [R] HELP! Mann whitney in r
In-Reply-To: <CABPcGafajzBnnNU6ewc3AeUj8ZRAGT6VvZpJ1y4Ht9pt0u1Gfg@mail.gmail.com>
References: <CABPcGafajzBnnNU6ewc3AeUj8ZRAGT6VvZpJ1y4Ht9pt0u1Gfg@mail.gmail.com>
Message-ID: <CABPcGacaaHcAeZUMx=m5RqDONTta4HNT5Yh_ELQzdbv549n2VQ@mail.gmail.com>

This may be really basic, but could you help me with this issue?
I have an excel file named table1.xls.
I need to input this table in r, in order to calculate mann whitney between
columns 1 and 2.
Could you please show me how to do this task?

	[[alternative HTML version deleted]]


From leegi001 at umn.edu  Sun Mar 20 05:44:43 2016
From: leegi001 at umn.edu (Cathy Lee Gierke)
Date: Sat, 19 Mar 2016 23:44:43 -0500
Subject: [R] degree sign
In-Reply-To: <A3499F20-7779-4AF2-BF14-DD05D716B121@comcast.net>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
	<DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
	<CAOeg=_8z90YVUWZphxo9a-ZpVHPD0C3NiuzCh8or4dP+LQBBwg@mail.gmail.com>
	<A3499F20-7779-4AF2-BF14-DD05D716B121@comcast.net>
Message-ID: <CAOeg=_8PF4-pGNT+R7=Ka9S9Trc=szG8NhG+7AFjmCAvfO1tyA@mail.gmail.com>

Wonderful!  That works.

Cathy Lee Gierke

*"We are what we repeatedly do.  Excellence, then, is not an act, but a
habit." Aristotle*

On Sat, Mar 19, 2016 at 6:44 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 19, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> >
> > My actual plot call is long and complicated, so I tried to simplify it
> in the last message.....here is the actual, using David's proposed
> solution.  It is not working.   What I want to see printed is the following
> (with degree symbols after 73 and 296).
>
>
> >  Since I reuse this string in various ways, I would like to build a
> variable to hold it that I can plug into plots when needed:
> > Hours from Reference Time: 201302060000
> > Model span = 24.00 hrs     o ?73     b ?296
>
> The degree-object in plotmath needs to be placed within an R object of
> class expression.
>
> For multi-line expression delivery in the outer portions of a graphic, I
> would recommend using mtext:
>
> -------------
>
> myexpr <- expression("Hours from Reference Time: 201302060000",
>                       "Model span = 24.00 hrs     o ?73"*degree*phantom("
>     ")*"b ?296"*degree)
>
> plot(1,1)
>  mtext(myexpr[[1]] , side=1,line=2)
>  mtext(myexpr[[2]] , side=1,line=3)
>
> >
> > So I set xlab=printXlab value with David's solution, below, in the plot
> (this is the actual printXlab value, instead of the simplified one):
> >
> >  xl = bquote( .(Orthophase[i,j] )*degree )
> > printXlab<-paste("Hours from Reference Time:",RefTimeString,"Model span
> =",format(magDt,digits=3,nsmall=2),"hrs    o",Orthophase[i,j],xl,"
>  b",Bathyphase[i,j])
>
> If you are tryng to substitute
> >
> > and here is the result I get (weird duplicates....but most importantly,
> no degree symbol:
> >
> >
> > Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 *
> Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 ?73
> Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 degree
> >
> > b ?296 b ?296
> >
> > b ?296
> >
> > ----------------------
> > So, I tried to set xlab as Uwe's proposal (without paste, and without
> commas):
> > printXlab<-expression("Hours from Reference Time:" RefTimeString "Model
> span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] *
> degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
>
> You may want to use substitute or bquote to create an expression that has
> evaluated values (if you will) for:
>
> Orthophase[i,j]
> Bathyphase[i,j]
>
> Something like this
>
>  orth=3.56
>  bathy=5.87
>  RefTimeStr <- "test"
>  magDT <- "1999-01-01";
>  printXlab  <-  list( bquote("Hours from Reference Time:"~ .(RefTimeStr)),
>          bquote("Model span ="*.(format(magDt,digits=3,nsmall=2))* " hrs
>   o" * .(orth) * degree*"C     b"* .(bathy) * degree*C))
>  plot(1,1, xlab="")
>  mtext(sapply( printXlab, as.expression) , side=1,
>            line=2:3)
>
>
> --
> David.
>
> >
> > I get "unexpected symbol at ^RefTimeStrng" so it doesn't like the
> missing commas.
> >
> > Then I try it with commas, except around the degree parts:
> > printXlab<-expression("Hours from Reference Time:" RefTimeString "Model
> span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j] *
> degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
> >
> > It runs, but here is what prints:
> > Hours from Reference Time:
> >
> > ?Then I try with all commas replaced by *:
> > printXlab<-expression("Hours from Reference Time:"* RefTimeString
> *"Model span =" * format(magDt,digits=3,nsmall=2) * "hrs    o" *
> Orthophase[i,j] * degree * "     b"* Bathyphase[i,j] * degree * " ")     #
> degree~C
> >
> > ?And I get degree signs (sort of)!!  But the rest is wrong. The
> variables are not evaluated:
> > Hours from Reference Time:RefTimeStringModel span =format(magDt, 3,
> 2)hrs oOrthophasei? bBathyphasei?
> >
> > ?I don't really understand what state is required for the degrees to
> print....?
>
> >
> > Cathy Lee Gierke
> >
> > "We are what we repeatedly do.  Excellence, then, is not an act, but a
> habit." Aristotle
> >
> > On Sat, Mar 19, 2016 at 2:04 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Mar 18, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu>
> wrote:
> > >
> > > I have searched and tried many things but cannot get anything to
> work.  I
> > > just want to print out a degree sign after a the Orthophase number.
> > >
> > > The following list of "xl" values are all ones I have tried.  Granted
> they
> > > are not what I want, but I have tried them all, and none of them print
> out
> > > a degree symbol...
> > >
> > > #                   xl = expression(paste("Orthophase [", {
> > > #                   }^o, "]"))
> > >                  #xl<-~degree~C
> > >                  #xl<-parse(text = ~degree)
> > >                  #xl<-parse(text = paste(" ", "~degree", sep = ""))
> > >                  #xl<-expression(~degree)
> > >                  xl <- parse(text = paste(Orthophase[i,j], "*degree ~
> S",
> > > sep = ""))
> > >
> > >
> > >                  printXlab<-paste("Orthophase    ",Orthophase[i,j],xl,"
> > >  ")
> > >
> > > plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
> > > xlab=printXlab,.....
> >
> > Ya' know Cathy. It would be nice if you would say what it was that you
> actually wanted to do rather than offering multiple failures This does not
> throw an error:
> >
> > xl = expression(paste("Orthophase [", {
> >                   }^o, "]"))
> > plot(1,1,type="l", xaxt="n", xlab=xl)
> >
> >
> >
> > But perhaps you want to pull in an evaluated result from an object in
> the workspace? This should work:
> >
> > Orthophase <- matrix( 4:1, 2)
> > i=1;j=1
> > xl = bquote( .(Orthophase [i,j] )*degree )
> > plot(1,1,type="l", xaxt="n",
> > xlab=xl)
> >
> > >
> > >
> > > Cathy Lee Gierke
> > >
> > > *"We are what we repeatedly do.  Excellence, then, is not an act, but a
> > > habit." Aristotle*
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From santib2002 at gmail.com  Sun Mar 20 18:37:51 2016
From: santib2002 at gmail.com (santib2002 at gmail.com)
Date: Sun, 20 Mar 2016 14:37:51 -0300
Subject: [R] Help! Mann whitney
Message-ID: <CABPcGadG1LGq1LvTN-rvq=c6F98MzefiE9MYWoQsq+qaZA6u4A@mail.gmail.com>

This may be really basic, but could you help me with this issue?
I have an excel file named table1.xls.
I need to input this table in r, in order to calculate mann whitney between
columns 1 and 2.
Could you please show me how to do this task?

	[[alternative HTML version deleted]]


From leegi001 at umn.edu  Mon Mar 21 03:04:46 2016
From: leegi001 at umn.edu (Cathy Lee Gierke)
Date: Sun, 20 Mar 2016 21:04:46 -0500
Subject: [R] degree sign
In-Reply-To: <56D7A030-38BF-40E9-A00B-651F0F4860DC@comcast.net>
References: <CAOeg=__RuY-m-WSv86tehHdi1S3e28eaUiRTq9_7YXDxatmEAg@mail.gmail.com>
	<DDEE3BA4-D414-47B6-A475-D80DBA30272B@comcast.net>
	<CAOeg=_8z90YVUWZphxo9a-ZpVHPD0C3NiuzCh8or4dP+LQBBwg@mail.gmail.com>
	<A3499F20-7779-4AF2-BF14-DD05D716B121@comcast.net>
	<CAOeg=_8PF4-pGNT+R7=Ka9S9Trc=szG8NhG+7AFjmCAvfO1tyA@mail.gmail.com>
	<56D7A030-38BF-40E9-A00B-651F0F4860DC@comcast.net>
Message-ID: <CAOeg=_8iJfR3rmMWGiNDNZqtbT+ec=Yp7mBf-wC26ADOpkDrXg@mail.gmail.com>

Would it make any difference that I am not a member of the list?  Did you
see Uwe's response?

Cathy Lee Gierke

*"We are what we repeatedly do.  Excellence, then, is not an act, but a
habit." Aristotle*

On Sun, Mar 20, 2016 at 9:02 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> It's a bit puzzling that neither of my replies to your postings have
> appeared on the R help list Archive. I normally reply-all to questions and
> despite the fact that you are sending in a formatted style, I have my
> client configured to reply in plain text. My client "Sent folder" has
> copies and the email addressees include r-help at r-project.org. I suppose
> this is a further "test" posting sent as reply-to-all. If it does not
> appear, then perhaps I can track down the problem by examining headers.
>
>
> --
> David.
>
>
> > On Mar 19, 2016, at 9:44 PM, Cathy Lee Gierke <leegi001 at umn.edu> wrote:
> >
> > Wonderful!  That works.
> >
> > Cathy Lee Gierke
> >
> > "We are what we repeatedly do.  Excellence, then, is not an act, but a
> habit." Aristotle
> >
> > On Sat, Mar 19, 2016 at 6:44 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Mar 19, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu>
> wrote:
> > >
> > > My actual plot call is long and complicated, so I tried to simplify it
> in the last message.....here is the actual, using David's proposed
> solution.  It is not working.   What I want to see printed is the following
> (with degree symbols after 73 and 296).
> >
> >
> > >  Since I reuse this string in various ways, I would like to build a
> variable to hold it that I can plug into plots when needed:
> > > Hours from Reference Time: 201302060000
> > > Model span = 24.00 hrs     o ?73     b ?296
> >
> > The degree-object in plotmath needs to be placed within an R object of
> class expression.
> >
> > For multi-line expression delivery in the outer portions of a graphic, I
> would recommend using mtext:
> >
> > -------------
> >
> > myexpr <- expression("Hours from Reference Time: 201302060000",
> >                       "Model span = 24.00 hrs     o
> ?73"*degree*phantom("      ")*"b ?296"*degree)
> >
> > plot(1,1)
> >  mtext(myexpr[[1]] , side=1,line=2)
> >  mtext(myexpr[[2]] , side=1,line=3)
> >
> > >
> > > So I set xlab=printXlab value with David's solution, below, in the
> plot (this is the actual printXlab value, instead of the simplified one):
> > >
> > >  xl = bquote( .(Orthophase[i,j] )*degree )
> > > printXlab<-paste("Hours from Reference Time:",RefTimeString,"Model
> span =",format(magDt,digits=3,nsmall=2),"hrs    o",Orthophase[i,j],xl,"
>  b",Bathyphase[i,j])
> >
> > If you are tryng to substitute
> > >
> > > and here is the result I get (weird duplicates....but most
> importantly, no degree symbol:
> > >
> > >
> > > Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 *
> Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 ?73
> Hours from Reference Time: 201302060000 Model span = 24.00 hrs o ?73 degree
> > >
> > > b ?296 b ?296
> > >
> > > b ?296
> > >
> > > ----------------------
> > > So, I tried to set xlab as Uwe's proposal (without paste, and without
> commas):
> > > printXlab<-expression("Hours from Reference Time:" RefTimeString
> "Model span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j]
> * degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
> >
> > You may want to use substitute or bquote to create an expression that
> has evaluated values (if you will) for:
> >
> > Orthophase[i,j]
> > Bathyphase[i,j]
> >
> > Something like this
> >
> >  orth=3.56
> >  bathy=5.87
> >  RefTimeStr <- "test"
> >  magDT <- "1999-01-01";
> >  printXlab  <-  list( bquote("Hours from Reference Time:"~
> .(RefTimeStr)),
> >          bquote("Model span ="*.(format(magDt,digits=3,nsmall=2))* "
> hrs    o" * .(orth) * degree*"C     b"* .(bathy) * degree*C))
> >  plot(1,1, xlab="")
> >  mtext(sapply( printXlab, as.expression) , side=1,
> >            line=2:3)
> >
> >
> > --
> > David.
> >
> > >
> > > I get "unexpected symbol at ^RefTimeStrng" so it doesn't like the
> missing commas.
> > >
> > > Then I try it with commas, except around the degree parts:
> > > printXlab<-expression("Hours from Reference Time:" RefTimeString
> "Model span =" format(magDt,digits=3,nsmall=2) "hrs    o" * Orthophase[i,j]
> * degree"     b"* Bathyphase[i,j] * degree)     #  degree~C
> > >
> > > It runs, but here is what prints:
> > > Hours from Reference Time:
> > >
> > > ?Then I try with all commas replaced by *:
> > > printXlab<-expression("Hours from Reference Time:"* RefTimeString
> *"Model span =" * format(magDt,digits=3,nsmall=2) * "hrs    o" *
> Orthophase[i,j] * degree * "     b"* Bathyphase[i,j] * degree * " ")     #
> degree~C
> > >
> > > ?And I get degree signs (sort of)!!  But the rest is wrong. The
> variables are not evaluated:
> > > Hours from Reference Time:RefTimeStringModel span =format(magDt, 3,
> 2)hrs oOrthophasei? bBathyphasei?
> > >
> > > ?I don't really understand what state is required for the degrees to
> print....?
> >
> > >
> > > Cathy Lee Gierke
> > >
> > > "We are what we repeatedly do.  Excellence, then, is not an act, but a
> habit." Aristotle
> > >
> > > On Sat, Mar 19, 2016 at 2:04 AM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Mar 18, 2016, at 1:58 PM, Cathy Lee Gierke <leegi001 at umn.edu>
> wrote:
> > > >
> > > > I have searched and tried many things but cannot get anything to
> work.  I
> > > > just want to print out a degree sign after a the Orthophase number.
> > > >
> > > > The following list of "xl" values are all ones I have tried.
> Granted they
> > > > are not what I want, but I have tried them all, and none of them
> print out
> > > > a degree symbol...
> > > >
> > > > #                   xl = expression(paste("Orthophase [", {
> > > > #                   }^o, "]"))
> > > >                  #xl<-~degree~C
> > > >                  #xl<-parse(text = ~degree)
> > > >                  #xl<-parse(text = paste(" ", "~degree", sep = ""))
> > > >                  #xl<-expression(~degree)
> > > >                  xl <- parse(text = paste(Orthophase[i,j], "*degree
> ~ S",
> > > > sep = ""))
> > > >
> > > >
> > > >                  printXlab<-paste("Orthophase
> ",Orthophase[i,j],xl,"
> > > >  ")
> > > >
> > > > plot(MyData$time.hour[plotData],newData[plotData],type="l", xaxt="n",
> > > > xlab=printXlab,.....
> > >
> > > Ya' know Cathy. It would be nice if you would say what it was that you
> actually wanted to do rather than offering multiple failures This does not
> throw an error:
> > >
> > > xl = expression(paste("Orthophase [", {
> > >                   }^o, "]"))
> > > plot(1,1,type="l", xaxt="n", xlab=xl)
> > >
> > >
> > >
> > > But perhaps you want to pull in an evaluated result from an object in
> the workspace? This should work:
> > >
> > > Orthophase <- matrix( 4:1, 2)
> > > i=1;j=1
> > > xl = bquote( .(Orthophase [i,j] )*degree )
> > > plot(1,1,type="l", xaxt="n",
> > > xlab=xl)
> > >
> > > >
> > > >
> > > > Cathy Lee Gierke
> > > >
> > > > *"We are what we repeatedly do.  Excellence, then, is not an act,
> but a
> > > > habit." Aristotle*
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Mar 21 04:32:09 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 21 Mar 2016 14:32:09 +1100
Subject: [R] HELP! Mann whitney in r
In-Reply-To: <CABPcGacaaHcAeZUMx=m5RqDONTta4HNT5Yh_ELQzdbv549n2VQ@mail.gmail.com>
References: <CABPcGafajzBnnNU6ewc3AeUj8ZRAGT6VvZpJ1y4Ht9pt0u1Gfg@mail.gmail.com>
	<CABPcGacaaHcAeZUMx=m5RqDONTta4HNT5Yh_ELQzdbv549n2VQ@mail.gmail.com>
Message-ID: <CA+8X3fUPe4PG6A0_KUrG0fp0PEb1TXPOBfHEKJMNER-7fEXTgA@mail.gmail.com>

Hi santib2002,
If you only have the XLS file, you could install the "xlsx" package
and read that into R.

install.packages("xlsx")
read.xls(table1.xls)

If you can load it into Excel and export it as CSV format, you can
read it with the read.csv function:

read.csv("table1.csv")

Jim



On Sun, Mar 20, 2016 at 11:43 AM,  <santib2002 at gmail.com> wrote:
> This may be really basic, but could you help me with this issue?
> I have an excel file named table1.xls.
> I need to input this table in r, in order to calculate mann whitney between
> columns 1 and 2.
> Could you please show me how to do this task?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Mar 21 05:48:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 20 Mar 2016 21:48:42 -0700
Subject: [R] HELP! Mann whitney in r
In-Reply-To: <CABPcGacaaHcAeZUMx=m5RqDONTta4HNT5Yh_ELQzdbv549n2VQ@mail.gmail.com>
References: <CABPcGafajzBnnNU6ewc3AeUj8ZRAGT6VvZpJ1y4Ht9pt0u1Gfg@mail.gmail.com>
	<CABPcGacaaHcAeZUMx=m5RqDONTta4HNT5Yh_ELQzdbv549n2VQ@mail.gmail.com>
Message-ID: <CAGxFJbS0ng4SKmDH+FHtOnR647v8irDjtBSs3ATO99ez7fST0A@mail.gmail.com>

Jim has graciously replied but:

1. Please do not double post -- that's spam;
2. This is a plain text list, so avoid  html -- it can get mangled
(though here it didn't).
3. Spend some time with an R tutorial or two. They typically cover
basic topics such as this, and there are many good ones on the Web. It
is often faster, and you'll learn a lot of good stuff so that you
won't need to post and hope here as often.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 19, 2016 at 5:43 PM,  <santib2002 at gmail.com> wrote:
> This may be really basic, but could you help me with this issue?
> I have an excel file named table1.xls.
> I need to input this table in r, in order to calculate mann whitney between
> columns 1 and 2.
> Could you please show me how to do this task?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Mon Mar 21 05:50:26 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 21 Mar 2016 04:50:26 +0000
Subject: [R] How to remove second row if above row contain <NA>?
Message-ID: <BY2PR13MB04541A7CF5BD22F0FF45D347FA8F0@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi R user, 
Is there any easiest way to delete the second row if the first row contains NA?
Here is the example. A file "dat" contains 13 rows, in which there are 2 NAs. one "NA" is in row 1 and another in row 10. Therefore, I want to delete row 2 and row 11 (just want to delete a row of underneath of the row contains "NA"). I have table with almost 15000 rows. The attached table is just an example.
Your help is highly appreciated. 

I want to dat1 from dat

dat<-structure(list(s = c(1L, 2L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L), Species.x = structure(c(NA, 1L, 1L, 2L, 2L, 2L, 
3L, 3L, 4L, NA, 5L, 5L, 5L), .Label = c("Sp1", "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.x = structure(c(NA, 1L, 
1L, 2L, 1L, 1L, 2L, 1L, 2L, NA, 1L, 1L, 1L), .Label = c("", "marked"), class = "factor"), observedSite.x = structure(c(NA, 3L, 1L, 
2L, 4L, 3L, 1L, 2L, 2L, NA, 5L, 1L, 3L), .Label = c("SiteA", "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time.x = structure(c(NA, 
4L, 5L, 2L, 3L, 10L, 7L, 9L, 1L, NA, 2L, 6L, 8L), .Label = c("1/15/15", "1/17/15", "2/18/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", 
"3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.x = structure(c(NA, 1L, 2L, 1L, 2L, 3L, 3L, 4L, 1L, NA, 1L, 2L, 3L), .Label = c("T1", 
"T2", "T3", "T4"), class = "factor"), Species.y = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L), .Label = c("Sp1", 
"Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.y = structure(c(2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L), .Label = c("", 
"marked"), class = "factor"), observedSite.y = structure(c(1L, 3L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 1L, 3L), .Label = c("SiteA", 
"SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time.y = structure(c(1L, 4L, 5L, 2L, 3L, 10L, 7L, 9L, 1L, 1L, 2L, 6L, 8L), .Label = c("1/15/15", 
"1/17/15", "2/18/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.y = structure(c(1L, 
1L, 2L, 1L, 2L, 3L, 3L, 4L, 1L, 1L, 1L, 2L, 3L), .Label = c("T1", "T2", "T3", "T4"), class = "factor")), .Names = c("s", "Species.x", "sign.x", "observedSite.x", "Time.x", "Month.x", "Species.y", "sign.y", "observedSite.y", "Time.y", "Month.y"), class = "data.frame", row.names = c(NA, -13L))

dat1<-structure(list(X = c(1L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 12L, 13L), s = c(1L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 15L, 16L), 
    Species.x = structure(c(NA, 1L, 2L, 2L, 2L, 3L, 3L, 4L, NA,  5L, 5L), .Label = c("Sp1", "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), 
    sign.x = structure(c(NA, 1L, 2L, 1L, 1L, 2L, 1L, 2L, NA, 1L, 1L), .Label = c("", "marked"), class = "factor"), observedSite.x = structure(c(NA, 
    1L, 2L, 4L, 3L, 1L, 2L, 2L, NA, 1L, 3L), .Label = c("SiteA", "SiteB", "SiteC", "SiteD"), class = "factor"), Time.x = structure(c(NA, 
    4L, 2L, 3L, 9L, 6L, 8L, 1L, NA, 5L, 7L), .Label = c("1/15/15", "1/17/15", "2/18/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", 
    "4/19/15", "7/3/15"), class = "factor"), Month.x = structure(c(NA, 2L, 1L, 2L, 3L, 3L, 4L, 1L, NA, 2L, 3L), .Label = c("T1", 
    "T2", "T3", "T4"), class = "factor"), Species.y = structure(c(1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1", 
    "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.y = structure(c(2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L), .Label = c("", "marked"
    ), class = "factor"), observedSite.y = structure(c(1L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA", 
    "SiteB", "SiteC", "SiteD"), class = "factor"), Time.y = structure(c(1L, 4L, 2L, 3L, 9L, 6L, 8L, 1L, 1L, 5L, 7L), .Label = c("1/15/15", 
    "1/17/15", "2/18/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.y = structure(c(1L, 
    2L, 1L, 2L, 3L, 3L, 4L, 1L, 1L, 2L, 3L), .Label = c("T1", "T2", "T3", "T4"), class = "factor")), .Names = c("X", "s", 
"Species.x", "sign.x", "observedSite.x", "Time.x", "Month.x", "Species.y", "sign.y", "observedSite.y", "Time.y", "Month.y"), class = "data.frame", row.names = c(NA, -11L))

From bgunter.4567 at gmail.com  Mon Mar 21 06:05:48 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 20 Mar 2016 22:05:48 -0700
Subject: [R] How to remove second row if above row contain <NA>?
In-Reply-To: <BY2PR13MB04541A7CF5BD22F0FF45D347FA8F0@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB04541A7CF5BD22F0FF45D347FA8F0@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CAGxFJbQN3PTd07coNotqLgLamQEpxo+c+P-Y-Qt4-iMnGdeoBw@mail.gmail.com>

?complete.cases

hence, using ?which and basic indexing operations:

dat1 <- dat[ -(which(! complete.cases(dat))+1), ]

(It's a nice example of what you can do with indexing in R)

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 20, 2016 at 9:50 PM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R user,
> Is there any easiest way to delete the second row if the first row contains NA?
> Here is the example. A file "dat" contains 13 rows, in which there are 2 NAs. one "NA" is in row 1 and another in row 10. Therefore, I want to delete row 2 and row 11 (just want to delete a row of underneath of the row contains "NA"). I have table with almost 15000 rows. The attached table is just an example.
> Your help is highly appreciated.
>
> I want to dat1 from dat
>
> dat<-structure(list(s = c(1L, 2L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L), Species.x = structure(c(NA, 1L, 1L, 2L, 2L, 2L,
> 3L, 3L, 4L, NA, 5L, 5L, 5L), .Label = c("Sp1", "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.x = structure(c(NA, 1L,
> 1L, 2L, 1L, 1L, 2L, 1L, 2L, NA, 1L, 1L, 1L), .Label = c("", "marked"), class = "factor"), observedSite.x = structure(c(NA, 3L, 1L,
> 2L, 4L, 3L, 1L, 2L, 2L, NA, 5L, 1L, 3L), .Label = c("SiteA", "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time.x = structure(c(NA,
> 4L, 5L, 2L, 3L, 10L, 7L, 9L, 1L, NA, 2L, 6L, 8L), .Label = c("1/15/15", "1/17/15", "2/18/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15",
> "3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.x = structure(c(NA, 1L, 2L, 1L, 2L, 3L, 3L, 4L, 1L, NA, 1L, 2L, 3L), .Label = c("T1",
> "T2", "T3", "T4"), class = "factor"), Species.y = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L, 5L), .Label = c("Sp1",
> "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.y = structure(c(2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L), .Label = c("",
> "marked"), class = "factor"), observedSite.y = structure(c(1L, 3L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 5L, 1L, 3L), .Label = c("SiteA",
> "SiteB", "SiteC", "SiteD", "SIteD"), class = "factor"), Time.y = structure(c(1L, 4L, 5L, 2L, 3L, 10L, 7L, 9L, 1L, 1L, 2L, 6L, 8L), .Label = c("1/15/15",
> "1/17/15", "2/18/15", "2/25/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.y = structure(c(1L,
> 1L, 2L, 1L, 2L, 3L, 3L, 4L, 1L, 1L, 1L, 2L, 3L), .Label = c("T1", "T2", "T3", "T4"), class = "factor")), .Names = c("s", "Species.x", "sign.x", "observedSite.x", "Time.x", "Month.x", "Species.y", "sign.y", "observedSite.y", "Time.y", "Month.y"), class = "data.frame", row.names = c(NA, -13L))
>
> dat1<-structure(list(X = c(1L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 12L, 13L), s = c(1L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 15L, 16L),
>     Species.x = structure(c(NA, 1L, 2L, 2L, 2L, 3L, 3L, 4L, NA,  5L, 5L), .Label = c("Sp1", "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"),
>     sign.x = structure(c(NA, 1L, 2L, 1L, 1L, 2L, 1L, 2L, NA, 1L, 1L), .Label = c("", "marked"), class = "factor"), observedSite.x = structure(c(NA,
>     1L, 2L, 4L, 3L, 1L, 2L, 2L, NA, 1L, 3L), .Label = c("SiteA", "SiteB", "SiteC", "SiteD"), class = "factor"), Time.x = structure(c(NA,
>     4L, 2L, 3L, 9L, 6L, 8L, 1L, NA, 5L, 7L), .Label = c("1/15/15", "1/17/15", "2/18/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15",
>     "4/19/15", "7/3/15"), class = "factor"), Month.x = structure(c(NA, 2L, 1L, 2L, 3L, 3L, 4L, 1L, NA, 2L, 3L), .Label = c("T1",
>     "T2", "T3", "T4"), class = "factor"), Species.y = structure(c(1L, 1L, 2L, 2L, 2L, 3L, 3L, 4L, 5L, 5L, 5L), .Label = c("Sp1",
>     "Sp2", "Sp3", "Sp4", "Sp5"), class = "factor"), sign.y = structure(c(2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L), .Label = c("", "marked"
>     ), class = "factor"), observedSite.y = structure(c(1L, 1L, 2L, 4L, 3L, 1L, 2L, 2L, 3L, 1L, 3L), .Label = c("SiteA",
>     "SiteB", "SiteC", "SiteD"), class = "factor"), Time.y = structure(c(1L, 4L, 2L, 3L, 9L, 6L, 8L, 1L, 1L, 5L, 7L), .Label = c("1/15/15",
>     "1/17/15", "2/18/15", "2/27/15", "2/28/15", "3/27/15", "3/5/15", "4/19/15", "7/3/15"), class = "factor"), Month.y = structure(c(1L,
>     2L, 1L, 2L, 3L, 3L, 4L, 1L, 1L, 2L, 3L), .Label = c("T1", "T2", "T3", "T4"), class = "factor")), .Names = c("X", "s",
> "Species.x", "sign.x", "observedSite.x", "Time.x", "Month.x", "Species.y", "sign.y", "observedSite.y", "Time.y", "Month.y"), class = "data.frame", row.names = c(NA, -11L))
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Mon Mar 21 10:41:35 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 21 Mar 2016 10:41:35 +0100
Subject: [R] Persistent state in a function?
In-Reply-To: <56EDCB64.3080505@gmail.com>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56EDCB64.3080505@gmail.com>
Message-ID: <22255.49615.801521.211082@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Sat, 19 Mar 2016 17:57:56 -0400 writes:

    > On 19/03/2016 12:45 PM, Boris Steipe wrote:
    >> Dear all -
    >> 
    >> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
    >> -A- how can I keep the table in an environment that is private to the function but persistent for the session?
    >> -B- how can I store and reload such table?
    >> -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
    >> 
    >> 
    >> For illustration ...
    >> 
    >> -----------------------------------
    >> 
    >> myDist <- function(a, b) {
    >> # retrieve or calculate distances
    >> if (!exists("Vals")) {
    >> Vals <<- numeric() # the lookup table for distance values
    >> # here, created in the global env.
    >> }
    >> key <- sprintf("X%d.%d", a, b)
    >> thisDist <- Vals[key]
    >> if (is.na(thisDist)) {          # Hasn't been calculated yet ...
    >> cat("Calculating ... ")
    >> thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
    >> Vals[key] <<- thisDist      # store in global table
    >> }
    >> return(thisDist)
    >> }
    >> 
    >> 
    >> # run this
    >> set.seed(112358)
    >> 
    >> for (i in 1:10) {
    >> x <- sample(1:3, 2)
    >> print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
    >> }


    > Use local() to create a persistent environment for the function.  For 
    > example:

    > f <- local({
    > x <- NULL
    > function(y) {
    > cat("last x was ", x, "\n")
    > x <<- y
    > }
    > })

    > Then:

    >> f(3)
    > last x was
    >> f(4)
    > last x was  3
    >> f(12)
    > last x was  4

    > Duncan Murdoch

Yes, indeed.
Or use another function {than 'local()'} which returns a
function:  The functions  approxfun(), splinefun() and ecdf()
are "base R" functions which return functions "with a
non-trivial environment" as I use to say.

Note that this is *the* proper R way solving your problem.

The fact that this works as it works is called "lexical scoping"
and also the reason why (((regular, i.e., non-primitive)))
functions in R are called closures.
When R was created > 20 years ago, this has been the
distinguishing language feature of R (in comparison to S / S-plus).

Enjoy! - Martin


From eglenn at mit.edu  Fri Mar 18 14:29:47 2016
From: eglenn at mit.edu (Ezra Haber Glenn)
Date: Fri, 18 Mar 2016 09:29:47 -0400
Subject: [R] [R-pkgs] acs version 2.0: an R package to download and analyze
 data from the US Census
Message-ID: <86pourhq2c.wl%eglenn@mit.edu>


We are pleased to announce the release of version 2.0 of the "acs"
package, now available on CRAN
<http://cran.r-project.org/web/packages/acs/index.html>.

The package allows users to download, manipulate, analyze, and present
demographic data from the U.S. Census, with special tools and methods
to simplify the tasks of working with estimates and standard errors
contained in data from the American Community Survey (ACS).  

Version 2.0 of the package provides full support for all ACS data
available through the Census API -- including the most recent 2014
data -- as well as Decennial Census Data from 1990, 2000, and 2010.
Users can work with existing census geographies (states, counties,
tracts, block-groups, places, zip code areas, congressional districts,
school districts, etc.), or create and save their own custom
geographies with the package's "geo.make()" function.

For more information please visit:
<http://eglenn.scripts.mit.edu/citystate/2016/03/acs-version-2-0-now-on-cran>,
and the newly-updated "Working with acs.R" user guide at
<http://dusp.mit.edu/sites/dusp.mit.edu/files/attachments/publications/working_with_acs_R_v_2.0.pdf>.

Special thanks to package beta testers (Ari, Arin, Bethany, Emma,
John, and Michael) and the entire acs-r community, as well as to Uwe
and Kurt at CRAN for their infinite patience and continuing care and
stewardship of the system.

--
Ezra Haber Glenn, AICP
Department of Urban Studies and Planning
Massachusetts Institute of Technology
77 Massachusetts Ave., Room 7-337
Cambridge, MA 02139
eglenn at mit.edu 
http://dusp.mit.edu/faculty/ezra-glenn | http://eglenn.scripts.mit.edu/citystate/
617.253.2024 (w)
617.721.7131 (c)

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sunnysingha.analytics at gmail.com  Mon Mar 21 12:53:59 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 21 Mar 2016 17:23:59 +0530
Subject: [R] Please guide -- Error during export in csv format
Message-ID: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>

Please guide,
I'm exporting data in '.csv' format in the Windows user directory, I
have full access to. The write operation happens within a for loop.

Each iteration exports data in csv format in the user directory. The
issue is that the  data gets exported for all the 9 iterations but
fails for 10th iteration giving below error message.

Error in file(file, ifelse(append, "a", "w")) :
  cannot open the connection
In addition: Warning message:
In file(file, ifelse(append, "a", "w")) :
  cannot open file './/posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i
d<U+1ED3>ng h?nh c?ng line_752518568125567.csv': Invalid argument
Called from: file(file, ifelse(append, "a", "w"))

The export directory path is current directory with 'name' extracted as below:
my.file1:  .//likes_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
h?nh c?ng line_752518568125567.csv
my.file2:  .//posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
h?nh c?ng line_752518568125567.csv

I wondering if the error is due to the the complicated filename ?
Below is the line of code I have used within loop to export data.

   my.file1 <- file.path('./', paste0('likes','_',name,'_',grp_id,'.csv'))
    my.file2 <- file.path('./', paste0('posts','_',name,'_',grp_id,'.csv'))

    write.csv(posts_frame, file=my.file2, row.names = F)
    write.csv(likes_frame, file = my.file1, row.names = F)

Regards,
Sunny


From btupper at bigelow.org  Mon Mar 21 13:05:52 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 21 Mar 2016 08:05:52 -0400
Subject: [R] Please guide -- Error during export in csv format
In-Reply-To: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>
References: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>
Message-ID: <D80BB3E8-199D-4022-99D3-80CFAE4612F3@bigelow.org>

Hi,

You are defeating the purpose of the file.path() function by providing a path separator in the first argument; you used './', but try instead...

my.file1 <- file.path('.', paste0('likes','_',name,'_',grp_id,'.csv'))

Also, there appear to be spaces in the 'name' argument - that might be causing you an issue but it is hard to know.  You might try wrapping the value of my.file1 in quotes using shQuote() or maybe even dQuote() - I'm not sure as I am not on Windows.

Cheers,
Ben

> On Mar 21, 2016, at 7:53 AM, Sunny Singha <sunnysingha.analytics at gmail.com> wrote:
> 
> Please guide,
> I'm exporting data in '.csv' format in the Windows user directory, I
> have full access to. The write operation happens within a for loop.
> 
> Each iteration exports data in csv format in the user directory. The
> issue is that the  data gets exported for all the 9 iterations but
> fails for 10th iteration giving below error message.
> 
> Error in file(file, ifelse(append, "a", "w")) :
>  cannot open the connection
> In addition: Warning message:
> In file(file, ifelse(append, "a", "w")) :
>  cannot open file './/posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i
> d<U+1ED3>ng h?nh c?ng line_752518568125567.csv': Invalid argument
> Called from: file(file, ifelse(append, "a", "w"))
> 
> The export directory path is current directory with 'name' extracted as below:
> my.file1:  .//likes_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
> h?nh c?ng line_752518568125567.csv
> my.file2:  .//posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
> h?nh c?ng line_752518568125567.csv
> 
> I wondering if the error is due to the the complicated filename ?
> Below is the line of code I have used within loop to export data.
> 
>   my.file1 <- file.path('./', paste0('likes','_',name,'_',grp_id,'.csv'))
>    my.file2 <- file.path('./', paste0('posts','_',name,'_',grp_id,'.csv'))
> 
>    write.csv(posts_frame, file=my.file2, row.names = F)
>    write.csv(likes_frame, file = my.file1, row.names = F)
> 
> Regards,
> Sunny
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From ashenkin at ufl.edu  Mon Mar 21 13:59:46 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Mon, 21 Mar 2016 12:59:46 +0000
Subject: [R] Fit a smooth closed shape through 4 points
Message-ID: <56EFF042.8000705@ufl.edu>

Hello all,

I have sets of 4 x/y points through which I would like to fit closed, 
smoothed shapes that go through those 4 points exactly.  smooth.spline 
doesn't like my data, since there are only 3 unique x points, and even 
then, i'm not sure smooth.spline likes making closed shapes.

Might anyone else have suggestions for fitting algorithms I could employ?

Thanks,
Allie


shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim = c(4L,
2L), .Dimnames = list(NULL, c("x", "y")))

smooth.spline(shapepoints)

# repeat the first point to close the shape
shapepoints = rbind(shapepoints, shapepoints[1,])

smooth.spline(shapepoints)


From sunnysingha.analytics at gmail.com  Mon Mar 21 13:59:50 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 21 Mar 2016 18:29:50 +0530
Subject: [R] Please guide -- Error during export in csv format
In-Reply-To: <CANOG_FX5twRxTYp9USaxLVhgAdecXUhV2XeFFApjQUxNmgHbrQ@mail.gmail.com>
References: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>
	<D80BB3E8-199D-4022-99D3-80CFAE4612F3@bigelow.org>
	<CANOG_FX5twRxTYp9USaxLVhgAdecXUhV2XeFFApjQUxNmgHbrQ@mail.gmail.com>
Message-ID: <CANOG_FVTYv7Nt9krgwCaoctnm1YwEk13jjn7Ck7-wUzNsNk_3A@mail.gmail.com>

(Re-posting after including R-help)

Thanks Ben,
Changing './' and '.' and shQuote() didn't work. I'm trying dQuote().
For your information the 'name' value retrieved is --> H?i nh?ng ng??i
??ng h?nh c?ng

I guess the string is in Vietnamese language. As you would have
observed in error message it wasn't interpreted as above but some
other nonsensical characters (posts_H<U+1ED9>i nh<U+1EEF>ng
ngu<U+1EDD>i d<U+1ED3>ng
> h?nh c?ng line).
Is there a workaround to handle such strings ?

Regards,
Sunny

On Mon, Mar 21, 2016 at 6:29 PM, Sunny Singha
<sunnysingha.analytics at gmail.com> wrote:
> Thanks Ben,
> Changing './' and '.' and shQuote() didn't work. I'm trying dQuote().
> For your information the 'name' value retrieved is --> H?i nh?ng ng??i
> ??ng h?nh c?ng
>
> I guess the string is in Vietnamese language. As you would have
> observed in error message it wasn't interpreted as above but some
> other nonsensical characters (posts_H<U+1ED9>i nh<U+1EEF>ng
> ngu<U+1EDD>i d<U+1ED3>ng
>> h?nh c?ng line).
> Is there a workaround to handle such strings ?
>
> Regards,
> Sunny
>
> On Mon, Mar 21, 2016 at 5:35 PM, Ben Tupper <btupper at bigelow.org> wrote:
>> Hi,
>>
>> You are defeating the purpose of the file.path() function by providing a path separator in the first argument; you used './', but try instead...
>>
>> my.file1 <- file.path('.', paste0('likes','_',name,'_',grp_id,'.csv'))
>>
>> Also, there appear to be spaces in the 'name' argument - that might be causing you an issue but it is hard to know.  You might try wrapping the value of my.file1 in quotes using shQuote() or maybe even dQuote() - I'm not sure as I am not on Windows.
>>
>> Cheers,
>> Ben
>>
>>> On Mar 21, 2016, at 7:53 AM, Sunny Singha <sunnysingha.analytics at gmail.com> wrote:
>>>
>>> Please guide,
>>> I'm exporting data in '.csv' format in the Windows user directory, I
>>> have full access to. The write operation happens within a for loop.
>>>
>>> Each iteration exports data in csv format in the user directory. The
>>> issue is that the  data gets exported for all the 9 iterations but
>>> fails for 10th iteration giving below error message.
>>>
>>> Error in file(file, ifelse(append, "a", "w")) :
>>>  cannot open the connection
>>> In addition: Warning message:
>>> In file(file, ifelse(append, "a", "w")) :
>>>  cannot open file './/posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i
>>> d<U+1ED3>ng h?nh c?ng line_752518568125567.csv': Invalid argument
>>> Called from: file(file, ifelse(append, "a", "w"))
>>>
>>> The export directory path is current directory with 'name' extracted as below:
>>> my.file1:  .//likes_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
>>> h?nh c?ng line_752518568125567.csv
>>> my.file2:  .//posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
>>> h?nh c?ng line_752518568125567.csv
>>>
>>> I wondering if the error is due to the the complicated filename ?
>>> Below is the line of code I have used within loop to export data.
>>>
>>>   my.file1 <- file.path('./', paste0('likes','_',name,'_',grp_id,'.csv'))
>>>    my.file2 <- file.path('./', paste0('posts','_',name,'_',grp_id,'.csv'))
>>>
>>>    write.csv(posts_frame, file=my.file2, row.names = F)
>>>    write.csv(likes_frame, file = my.file1, row.names = F)
>>>
>>> Regards,
>>> Sunny
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>


From cdetermanjr at gmail.com  Mon Mar 21 14:10:39 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 21 Mar 2016 08:10:39 -0500
Subject: [R] Fit a smooth closed shape through 4 points
In-Reply-To: <56EFF042.8000705@ufl.edu>
References: <56EFF042.8000705@ufl.edu>
Message-ID: <CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>

Hi Allie,

What is you goal here?  Do you just want to plot a curve to the data?  Do
you want a function to approximate the data?

You may find the functions spline() and splinefun() useful.

Quick point though, with so few points you are only going to get a very
rough approximation no matter the method used.

Regards,
Charles


On Mon, Mar 21, 2016 at 7:59 AM, Alexander Shenkin <ashenkin at ufl.edu> wrote:

> Hello all,
>
> I have sets of 4 x/y points through which I would like to fit closed,
> smoothed shapes that go through those 4 points exactly.  smooth.spline
> doesn't like my data, since there are only 3 unique x points, and even
> then, i'm not sure smooth.spline likes making closed shapes.
>
> Might anyone else have suggestions for fitting algorithms I could employ?
>
> Thanks,
> Allie
>
>
> shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim = c(4L,
> 2L), .Dimnames = list(NULL, c("x", "y")))
>
> smooth.spline(shapepoints)
>
> # repeat the first point to close the shape
> shapepoints = rbind(shapepoints, shapepoints[1,])
>
> smooth.spline(shapepoints)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar 21 14:53:44 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Mar 2016 09:53:44 -0400
Subject: [R] Please guide -- Error during export in csv format
In-Reply-To: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>
References: <CANOG_FWyO1ye+uV_xbt7Gv_HsJ8AaDwa2aMPMqjygoweZo1umw@mail.gmail.com>
Message-ID: <56EFFCE8.10704@gmail.com>

On 21/03/2016 7:53 AM, Sunny Singha wrote:
> Please guide,
> I'm exporting data in '.csv' format in the Windows user directory, I
> have full access to. The write operation happens within a for loop.
>
> Each iteration exports data in csv format in the user directory. The
> issue is that the  data gets exported for all the 9 iterations but
> fails for 10th iteration giving below error message.
>
> Error in file(file, ifelse(append, "a", "w")) :
>    cannot open the connection
> In addition: Warning message:
> In file(file, ifelse(append, "a", "w")) :
>    cannot open file './/posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i
> d<U+1ED3>ng h?nh c?ng line_752518568125567.csv': Invalid argument
> Called from: file(file, ifelse(append, "a", "w"))
>
> The export directory path is current directory with 'name' extracted as below:
> my.file1:  .//likes_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
> h?nh c?ng line_752518568125567.csv
> my.file2:  .//posts_H<U+1ED9>i nh<U+1EEF>ng ngu<U+1EDD>i d<U+1ED3>ng
> h?nh c?ng line_752518568125567.csv
>
> I wondering if the error is due to the the complicated filename ?
> Below is the line of code I have used within loop to export data.
>
>     my.file1 <- file.path('./', paste0('likes','_',name,'_',grp_id,'.csv'))
>      my.file2 <- file.path('./', paste0('posts','_',name,'_',grp_id,'.csv'))
>
>      write.csv(posts_frame, file=my.file2, row.names = F)
>      write.csv(likes_frame, file = my.file1, row.names = F)
>

The <U+1ED9> and similar strings represent Unicode characters.  I would 
guess that they are being translated to the <U+1ED9> format before being 
used as a filename, and the < and > symbols are not allowed in filenames 
in Windows.

This is a limitation of the way R handles non-ASCII characters in 
Windows, and there's not much you can do about it other than avoiding 
characters which do not display in Latin1 (or whatever R sees as your 
native character set).

Duncan Murdoch


From ashenkin at ufl.edu  Mon Mar 21 15:04:15 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Mon, 21 Mar 2016 14:04:15 +0000
Subject: [R] Fit a smooth closed shape through 4 points
In-Reply-To: <CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>
References: <56EFF042.8000705@ufl.edu>
	<CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>
Message-ID: <56EFFF5F.4040204@ufl.edu>

Thanks for your reply, Charles.  spline() doesn't seem to fit a closed 
shape; rather, it's producing a parabola.  Perhaps I'm missing an 
argument I should include?

grid.xspline() seems to get close to what I need, but it returns a grob 
object - not sure how to work with those as shapes per se.

My goal is to produce a 2D shape from which I can calculate area, 
average widths, and other such things.  The context is that we have 
measured tree crowns in a manner that has produced 4 points such as 
these from two offset axes.  We want to use the resulting shapes for our 
calculations.

(incidentally, my original points were off - here are the correct ones)

shapepoints = structure(list(x = c(8.9, 0, -7.7, 0, 8.9), y = c(0, 2, 0, 
-3.8,
0)), .Names = c("x", "y"), row.names = c(NA, -5L), class = "data.frame")

plot(spline(shapepoints))

Thanks,
Allie

On 3/21/2016 1:10 PM, Charles Determan wrote:
> Hi Allie,
>
> What is you goal here?  Do you just want to plot a curve to the data?
> Do you want a function to approximate the data?
>
> You may find the functions spline() and splinefun() useful.
>
> Quick point though, with so few points you are only going to get a very
> rough approximation no matter the method used.
>
> Regards,
> Charles
>
>
> On Mon, Mar 21, 2016 at 7:59 AM, Alexander Shenkin <ashenkin at ufl.edu
> <mailto:ashenkin at ufl.edu>> wrote:
>
>     Hello all,
>
>     I have sets of 4 x/y points through which I would like to fit
>     closed, smoothed shapes that go through those 4 points exactly.
>     smooth.spline doesn't like my data, since there are only 3 unique x
>     points, and even then, i'm not sure smooth.spline likes making
>     closed shapes.
>
>     Might anyone else have suggestions for fitting algorithms I could
>     employ?
>
>     Thanks,
>     Allie
>
>
>     shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim = c(4L,
>     2L), .Dimnames = list(NULL, c("x", "y")))
>
>     smooth.spline(shapepoints)
>
>     # repeat the first point to close the shape
>     shapepoints = rbind(shapepoints, shapepoints[1,])
>
>     smooth.spline(shapepoints)
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From S.Ellison at LGCGroup.com  Mon Mar 21 15:51:52 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 21 Mar 2016 14:51:52 +0000
Subject: [R] Fit a smooth closed shape through 4 points
In-Reply-To: <56EFFF5F.4040204@ufl.edu>
References: <56EFF042.8000705@ufl.edu>
	<CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>
	<56EFFF5F.4040204@ufl.edu>
Message-ID: <1A8C1289955EF649A09086A153E2672403D1200C83@GBTEDVPEXCMB04.corp.lgc-group.com>

Is there a reason not to use the convex hull for area calculations? Any curve you put through the points would surely be at least as arbitrary as a straight line.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alexander
> Shenkin
> Sent: 21 March 2016 14:04
> To: r-help
> Subject: Re: [R] Fit a smooth closed shape through 4 points
> 
> Thanks for your reply, Charles.  spline() doesn't seem to fit a closed shape;
> rather, it's producing a parabola.  Perhaps I'm missing an argument I should
> include?
> 
> grid.xspline() seems to get close to what I need, but it returns a grob object -
> not sure how to work with those as shapes per se.
> 
> My goal is to produce a 2D shape from which I can calculate area, average
> widths, and other such things.  The context is that we have measured tree
> crowns in a manner that has produced 4 points such as these from two offset
> axes.  We want to use the resulting shapes for our calculations.
> 
> (incidentally, my original points were off - here are the correct ones)
> 
> shapepoints = structure(list(x = c(8.9, 0, -7.7, 0, 8.9), y = c(0, 2, 0, -3.8, 0)),
> .Names = c("x", "y"), row.names = c(NA, -5L), class = "data.frame")
> 
> plot(spline(shapepoints))
> 
> Thanks,
> Allie
> 
> On 3/21/2016 1:10 PM, Charles Determan wrote:
> > Hi Allie,
> >
> > What is you goal here?  Do you just want to plot a curve to the data?
> > Do you want a function to approximate the data?
> >
> > You may find the functions spline() and splinefun() useful.
> >
> > Quick point though, with so few points you are only going to get a
> > very rough approximation no matter the method used.
> >
> > Regards,
> > Charles
> >
> >
> > On Mon, Mar 21, 2016 at 7:59 AM, Alexander Shenkin <ashenkin at ufl.edu
> > <mailto:ashenkin at ufl.edu>> wrote:
> >
> >     Hello all,
> >
> >     I have sets of 4 x/y points through which I would like to fit
> >     closed, smoothed shapes that go through those 4 points exactly.
> >     smooth.spline doesn't like my data, since there are only 3 unique x
> >     points, and even then, i'm not sure smooth.spline likes making
> >     closed shapes.
> >
> >     Might anyone else have suggestions for fitting algorithms I could
> >     employ?
> >
> >     Thanks,
> >     Allie
> >
> >
> >     shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim = c(4L,
> >     2L), .Dimnames = list(NULL, c("x", "y")))
> >
> >     smooth.spline(shapepoints)
> >
> >     # repeat the first point to close the shape
> >     shapepoints = rbind(shapepoints, shapepoints[1,])
> >
> >     smooth.spline(shapepoints)
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bgunter.4567 at gmail.com  Mon Mar 21 16:19:33 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 21 Mar 2016 08:19:33 -0700
Subject: [R] Persistent state in a function?
In-Reply-To: <22255.49615.801521.211082@stat.math.ethz.ch>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56EDCB64.3080505@gmail.com>
	<22255.49615.801521.211082@stat.math.ethz.ch>
Message-ID: <CAGxFJbSEDV7hiu=CraJyLuqMCHu9dg=oexoug6GaZLBxT+tKWg@mail.gmail.com>

Martin, All:

A very nice point! Perhaps the following may help to illustrate it.

g <- function(){
  x <- NULL
  function(y){cat("result is ",x," \n"); x <<- y}
}


> f <- g()

> rm(g) # g is deleted but its environment remains as the environment of f

> f(1)
result is

> f(3)
result is  1

> f(5)
result is  3


Best,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 21, 2016 at 2:41 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Sat, 19 Mar 2016 17:57:56 -0400 writes:
>
>     > On 19/03/2016 12:45 PM, Boris Steipe wrote:
>     >> Dear all -
>     >>
>     >> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>     >> -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>     >> -B- how can I store and reload such table?
>     >> -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>     >>
>     >>
>     >> For illustration ...
>     >>
>     >> -----------------------------------
>     >>
>     >> myDist <- function(a, b) {
>     >> # retrieve or calculate distances
>     >> if (!exists("Vals")) {
>     >> Vals <<- numeric() # the lookup table for distance values
>     >> # here, created in the global env.
>     >> }
>     >> key <- sprintf("X%d.%d", a, b)
>     >> thisDist <- Vals[key]
>     >> if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>     >> cat("Calculating ... ")
>     >> thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>     >> Vals[key] <<- thisDist      # store in global table
>     >> }
>     >> return(thisDist)
>     >> }
>     >>
>     >>
>     >> # run this
>     >> set.seed(112358)
>     >>
>     >> for (i in 1:10) {
>     >> x <- sample(1:3, 2)
>     >> print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
>     >> }
>
>
>     > Use local() to create a persistent environment for the function.  For
>     > example:
>
>     > f <- local({
>     > x <- NULL
>     > function(y) {
>     > cat("last x was ", x, "\n")
>     > x <<- y
>     > }
>     > })
>
>     > Then:
>
>     >> f(3)
>     > last x was
>     >> f(4)
>     > last x was  3
>     >> f(12)
>     > last x was  4
>
>     > Duncan Murdoch
>
> Yes, indeed.
> Or use another function {than 'local()'} which returns a
> function:  The functions  approxfun(), splinefun() and ecdf()
> are "base R" functions which return functions "with a
> non-trivial environment" as I use to say.
>
> Note that this is *the* proper R way solving your problem.
>
> The fact that this works as it works is called "lexical scoping"
> and also the reason why (((regular, i.e., non-primitive)))
> functions in R are called closures.
> When R was created > 20 years ago, this has been the
> distinguishing language feature of R (in comparison to S / S-plus).
>
> Enjoy! - Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Mar 21 16:30:17 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Mar 2016 11:30:17 -0400
Subject: [R] Persistent state in a function?
In-Reply-To: <CAGxFJbSEDV7hiu=CraJyLuqMCHu9dg=oexoug6GaZLBxT+tKWg@mail.gmail.com>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56EDCB64.3080505@gmail.com>
	<22255.49615.801521.211082@stat.math.ethz.ch>
	<CAGxFJbSEDV7hiu=CraJyLuqMCHu9dg=oexoug6GaZLBxT+tKWg@mail.gmail.com>
Message-ID: <56F01389.1050605@gmail.com>

On 21/03/2016 11:19 AM, Bert Gunter wrote:
> Martin, All:
>
> A very nice point! Perhaps the following may help to illustrate it.
>
> g <- function(){
>    x <- NULL
>    function(y){cat("result is ",x," \n"); x <<- y}
> }
>
>
> > f <- g()
>
> > rm(g) # g is deleted but its environment remains as the environment of f

That's not quite the jargon we use.  The environment of g would probably 
be the global environment.  The thing that gets left behind is the 
evaluation frame (or environment) of the call g().  Its parent 
environment is the environment of g.

Duncan Murdoch
>
> > f(1)
> result is
>
> > f(3)
> result is  1
>
> > f(5)
> result is  3
>
>
> Best,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Mar 21, 2016 at 2:41 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> >>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
> >>>>>>     on Sat, 19 Mar 2016 17:57:56 -0400 writes:
> >
> >     > On 19/03/2016 12:45 PM, Boris Steipe wrote:
> >     >> Dear all -
> >     >>
> >     >> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
> >     >> -A- how can I keep the table in an environment that is private to the function but persistent for the session?
> >     >> -B- how can I store and reload such table?
> >     >> -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
> >     >>
> >     >>
> >     >> For illustration ...
> >     >>
> >     >> -----------------------------------
> >     >>
> >     >> myDist <- function(a, b) {
> >     >> # retrieve or calculate distances
> >     >> if (!exists("Vals")) {
> >     >> Vals <<- numeric() # the lookup table for distance values
> >     >> # here, created in the global env.
> >     >> }
> >     >> key <- sprintf("X%d.%d", a, b)
> >     >> thisDist <- Vals[key]
> >     >> if (is.na(thisDist)) {          # Hasn't been calculated yet ...
> >     >> cat("Calculating ... ")
> >     >> thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
> >     >> Vals[key] <<- thisDist      # store in global table
> >     >> }
> >     >> return(thisDist)
> >     >> }
> >     >>
> >     >>
> >     >> # run this
> >     >> set.seed(112358)
> >     >>
> >     >> for (i in 1:10) {
> >     >> x <- sample(1:3, 2)
> >     >> print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> >     >> }
> >
> >
> >     > Use local() to create a persistent environment for the function.  For
> >     > example:
> >
> >     > f <- local({
> >     > x <- NULL
> >     > function(y) {
> >     > cat("last x was ", x, "\n")
> >     > x <<- y
> >     > }
> >     > })
> >
> >     > Then:
> >
> >     >> f(3)
> >     > last x was
> >     >> f(4)
> >     > last x was  3
> >     >> f(12)
> >     > last x was  4
> >
> >     > Duncan Murdoch
> >
> > Yes, indeed.
> > Or use another function {than 'local()'} which returns a
> > function:  The functions  approxfun(), splinefun() and ecdf()
> > are "base R" functions which return functions "with a
> > non-trivial environment" as I use to say.
> >
> > Note that this is *the* proper R way solving your problem.
> >
> > The fact that this works as it works is called "lexical scoping"
> > and also the reason why (((regular, i.e., non-primitive)))
> > functions in R are called closures.
> > When R was created > 20 years ago, this has been the
> > distinguishing language feature of R (in comparison to S / S-plus).
> >
> > Enjoy! - Martin
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Mon Mar 21 16:44:55 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 21 Mar 2016 16:44:55 +0100
Subject: [R] Fit a smooth closed shape through 4 points
In-Reply-To: <56EFFF5F.4040204@ufl.edu>
References: <56EFF042.8000705@ufl.edu>
	<CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>
	<56EFFF5F.4040204@ufl.edu>
Message-ID: <CAJuCY5z4pssUHdT=dsOdNDF-w4JFofpZ43n3VCmCS2N7XLAsjw@mail.gmail.com>

Dear Allie,

You could use elliptic fourier analysis

shapepoints = structure(list(x = c(8.9, 0, -7.7, 0, 8.9), y = c(0, 2, 0,
-3.8,
0)), .Names = c("x", "y"), row.names = c(NA, -5L), class = "data.frame")

shapepoints$Theta <- seq(0, 2 * pi, length = nrow(shapepoints))
model <- lm(cbind(x, y) ~ I(sin(Theta)) + I(cos(Theta)), data = shapepoints)
model2 <- lm(cbind(x, y) ~ I(sin(Theta)) + I(cos(Theta)) + I(sin(2 *
Theta)) + I(cos(2 * Theta)), data = shapepoints)

newdata <- data.frame(Theta = seq(0, 2 * pi, length = 41))
plot(predict(model, newdata = newdata), type = "l", xlim = c(-10, 10), ylim
= c(-10, 10))
points(shapepoints, col = "red")
plot(predict(model2, newdata = newdata), type = "l", xlim = c(-10, 10),
ylim = c(-10, 10))
points(shapepoints, col = "red")

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-21 15:04 GMT+01:00 Alexander Shenkin <ashenkin at ufl.edu>:

> Thanks for your reply, Charles.  spline() doesn't seem to fit a closed
> shape; rather, it's producing a parabola.  Perhaps I'm missing an argument
> I should include?
>
> grid.xspline() seems to get close to what I need, but it returns a grob
> object - not sure how to work with those as shapes per se.
>
> My goal is to produce a 2D shape from which I can calculate area, average
> widths, and other such things.  The context is that we have measured tree
> crowns in a manner that has produced 4 points such as these from two offset
> axes.  We want to use the resulting shapes for our calculations.
>
> (incidentally, my original points were off - here are the correct ones)
>
> shapepoints = structure(list(x = c(8.9, 0, -7.7, 0, 8.9), y = c(0, 2, 0,
> -3.8,
> 0)), .Names = c("x", "y"), row.names = c(NA, -5L), class = "data.frame")
>
> plot(spline(shapepoints))
>
> Thanks,
> Allie
>
> On 3/21/2016 1:10 PM, Charles Determan wrote:
>
>> Hi Allie,
>>
>> What is you goal here?  Do you just want to plot a curve to the data?
>> Do you want a function to approximate the data?
>>
>> You may find the functions spline() and splinefun() useful.
>>
>> Quick point though, with so few points you are only going to get a very
>> rough approximation no matter the method used.
>>
>> Regards,
>> Charles
>>
>>
>> On Mon, Mar 21, 2016 at 7:59 AM, Alexander Shenkin <ashenkin at ufl.edu
>> <mailto:ashenkin at ufl.edu>> wrote:
>>
>>     Hello all,
>>
>>     I have sets of 4 x/y points through which I would like to fit
>>     closed, smoothed shapes that go through those 4 points exactly.
>>     smooth.spline doesn't like my data, since there are only 3 unique x
>>     points, and even then, i'm not sure smooth.spline likes making
>>     closed shapes.
>>
>>     Might anyone else have suggestions for fitting algorithms I could
>>     employ?
>>
>>     Thanks,
>>     Allie
>>
>>
>>     shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim = c(4L,
>>     2L), .Dimnames = list(NULL, c("x", "y")))
>>
>>     smooth.spline(shapepoints)
>>
>>     # repeat the first point to close the shape
>>     shapepoints = rbind(shapepoints, shapepoints[1,])
>>
>>     smooth.spline(shapepoints)
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 21 17:06:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 21 Mar 2016 09:06:22 -0700
Subject: [R] Persistent state in a function?
In-Reply-To: <56F01389.1050605@gmail.com>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56EDCB64.3080505@gmail.com>
	<22255.49615.801521.211082@stat.math.ethz.ch>
	<CAGxFJbSEDV7hiu=CraJyLuqMCHu9dg=oexoug6GaZLBxT+tKWg@mail.gmail.com>
	<56F01389.1050605@gmail.com>
Message-ID: <CAGxFJbR+Xw0fbx=iFGF5eeit66+zAYE=zKDTEj1+5EWGSKgeWQ@mail.gmail.com>

Yes, Duncan.  My statement was wrong. I should have said that it's the
environment/evaluation frame of f = g(). Thank you for the correction.
Still, I hope my example was helpful.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 21, 2016 at 8:30 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 21/03/2016 11:19 AM, Bert Gunter wrote:
>>
>> Martin, All:
>>
>> A very nice point! Perhaps the following may help to illustrate it.
>>
>> g <- function(){
>>    x <- NULL
>>    function(y){cat("result is ",x," \n"); x <<- y}
>> }
>>
>>
>> > f <- g()
>>
>> > rm(g) # g is deleted but its environment remains as the environment of f
>
>
> That's not quite the jargon we use.  The environment of g would probably be
> the global environment.  The thing that gets left behind is the evaluation
> frame (or environment) of the call g().  Its parent environment is the
> environment of g.
>
> Duncan Murdoch
>>
>>
>> > f(1)
>> result is
>>
>> > f(3)
>> result is  1
>>
>> > f(5)
>> result is  3
>>
>>
>> Best,
>> Bert
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Mar 21, 2016 at 2:41 AM, Martin Maechler
>> <maechler at stat.math.ethz.ch> wrote:
>> >>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>> >>>>>>     on Sat, 19 Mar 2016 17:57:56 -0400 writes:
>> >
>> >     > On 19/03/2016 12:45 PM, Boris Steipe wrote:
>> >     >> Dear all -
>> >     >>
>> >     >> I need to have a function maintain a persistent lookup table of
>> > results for an expensive calculation, a named vector or hash. I know that I
>> > can just keep the table in the global environment. One problem with this
>> > approach is that the function should be able to delete/recalculate the table
>> > and I don't like side-effects in the global environment. This table really
>> > should be private. What I don't know is:
>> >     >> -A- how can I keep the table in an environment that is private to
>> > the function but persistent for the session?
>> >     >> -B- how can I store and reload such table?
>> >     >> -C- most importantly: is that the right strategy to initialize
>> > and maintain state in a function in the first place?
>> >     >>
>> >     >>
>> >     >> For illustration ...
>> >     >>
>> >     >> -----------------------------------
>> >     >>
>> >     >> myDist <- function(a, b) {
>> >     >> # retrieve or calculate distances
>> >     >> if (!exists("Vals")) {
>> >     >> Vals <<- numeric() # the lookup table for distance values
>> >     >> # here, created in the global env.
>> >     >> }
>> >     >> key <- sprintf("X%d.%d", a, b)
>> >     >> thisDist <- Vals[key]
>> >     >> if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>> >     >> cat("Calculating ... ")
>> >     >> thisDist <- sqrt(a^2 + b^2) # calculate with some expensive
>> > function ...
>> >     >> Vals[key] <<- thisDist      # store in global table
>> >     >> }
>> >     >> return(thisDist)
>> >     >> }
>> >     >>
>> >     >>
>> >     >> # run this
>> >     >> set.seed(112358)
>> >     >>
>> >     >> for (i in 1:10) {
>> >     >> x <- sample(1:3, 2)
>> >     >> print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
>> >     >> }
>> >
>> >
>> >     > Use local() to create a persistent environment for the function.
>> > For
>> >     > example:
>> >
>> >     > f <- local({
>> >     > x <- NULL
>> >     > function(y) {
>> >     > cat("last x was ", x, "\n")
>> >     > x <<- y
>> >     > }
>> >     > })
>> >
>> >     > Then:
>> >
>> >     >> f(3)
>> >     > last x was
>> >     >> f(4)
>> >     > last x was  3
>> >     >> f(12)
>> >     > last x was  4
>> >
>> >     > Duncan Murdoch
>> >
>> > Yes, indeed.
>> > Or use another function {than 'local()'} which returns a
>> > function:  The functions  approxfun(), splinefun() and ecdf()
>> > are "base R" functions which return functions "with a
>> > non-trivial environment" as I use to say.
>> >
>> > Note that this is *the* proper R way solving your problem.
>> >
>> > The fact that this works as it works is called "lexical scoping"
>> > and also the reason why (((regular, i.e., non-primitive)))
>> > functions in R are called closures.
>> > When R was created > 20 years ago, this has been the
>> > distinguishing language feature of R (in comparison to S / S-plus).
>> >
>> > Enjoy! - Martin
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From mark.pahuta at gmail.com  Mon Mar 21 17:44:52 2016
From: mark.pahuta at gmail.com (Markian Pahuta)
Date: Mon, 21 Mar 2016 12:44:52 -0400
Subject: [R] survROC, interval censoring?
Message-ID: <CAAsFppx-vwYsU5HipgyTZhhnyWPeXiSF_LR=fAYeppRnsqkzjg@mail.gmail.com>

Hello,

I would like to generate an ROC curve for cumulative cases. However, my
data are interval censored.

I know the risksetROC package handles interval censored data. However, I am
interested in cumulative disease... consequently I believe the survivalROC
package may be more appropriate.

In the function survivalROC(), if I specify "entry", will the function
automatically assume interval censoring?

Thank you

-- 
--- Mark

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Mon Mar 21 18:27:47 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Mon, 21 Mar 2016 19:27:47 +0200
Subject: [R] get values out of combined object
Message-ID: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>


?
?Dear group
I have the following variable ? v_neighbours and it holds a vector of the following :
?gawker.com ? ? ?gle.am ? jezebel.com?
? ? ? ? ? 1 ? ? ? ? ?16 ? ? ? ? ?28?

three urls and their id ...when I call the class(v_neighbours?) ?the result is ?"integer"
how can I get the factor numeric values ?( 1,16,28) out of this variable.

thanks in advance
R.Ibrahim 		 	   		  

From ruipbarradas at sapo.pt  Mon Mar 21 19:25:29 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 21 Mar 2016 18:25:29 +0000
Subject: [R] get values out of combined object
In-Reply-To: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
References: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
Message-ID: <20160321182529.Horde.P3kLYTouEOJW8DyZwEiBafA@mail.sapo.pt>

Hello,

Apparently your v_neighbours is a named vector of integers, so

v_neighbours[1:3]

or just

v_neighbours

will do the job(!)

Hope this helps,

Rui Barradas


Quoting "Ragia ." <ragia11 at hotmail.com>:

> ?
> ?Dear group
> I have the following variable ? v_neighbours and it holds a vector  
> of the following :
> ?gawker.com ? ? ?gle.am ? jezebel.com?
> ? ? ? ? ? 1 ? ? ? ? ?16 ? ? ? ? ?28?
>
> three urls and their id ...when I call the class(v_neighbours?) ?the  
> result is ?"integer"
> how can I get the factor numeric values ?( 1,16,28) out of this variable.
>
> thanks in advance
> R.Ibrahim
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From honkit at stanford.edu  Mon Mar 21 19:30:01 2016
From: honkit at stanford.edu (Stephen HK WONG)
Date: Mon, 21 Mar 2016 18:30:01 +0000
Subject: [R] how to use vectorization instead of for loop
Message-ID: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>

Dear All,


I have a dataframe like below but with many thousands rows,

structure(list(gene_id = structure(1:6, .Label = c("0610005C13Rik",
"0610007P14Rik", "0610009B22Rik", "0610009L18Rik", "0610009O20Rik",
"0610010B08Rik,OTTMUSG00000016609"), class = "factor"), log2.fold_change. = c(0.0114463,
-0.0960262, 0.00805151, -0.179981, -0.0629098, 0.155979), p_value = c(1,
0.77915, 0.98265, 0.68665, 0.85035, 0.72235), new.value = c("NA",
"NA", "NA", "NA", "NA", "NA")), .Names = c("gene_id", "log2.fold_change.",
"p_value", "new.value"), row.names = c(NA, 6L), class = "data.frame")


I want to check if second column is positive or negative value, then I will do some calculation and put the new value in last column. I can do this with for loop like below but it is not efficient. Is there a better way to use a vectorization method instead of loop? Many thanks!


for (i in 1:nrow(dataframe)) {

if dataframe[i, 2]>0 {

dataframe[i, 4]<- 1 * (1/dataframe[i,3])} else{

dataframe[i, 4] <- -1* (1/dataframe[i,3])}

}


-------------------------------------------------------

Stephen H.K. WONG, PhD.

Stanford University

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Mon Mar 21 19:38:15 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 22 Mar 2016 07:38:15 +1300
Subject: [R] Fit a smooth closed shape through 4 points
In-Reply-To: <56EFFF5F.4040204@ufl.edu>
References: <56EFF042.8000705@ufl.edu>
	<CAKxd1KNTVu7zHGh0xS5K92YEfhuMvCe0koe81kPebXktUF2Z8Q@mail.gmail.com>
	<56EFFF5F.4040204@ufl.edu>
Message-ID: <56F03F97.5080303@stat.auckland.ac.nz>

Hi

If Xsplines give you the shape you want, then you can retrieve points on 
the boundary of the shape using xsplinePoints().  For example ...

shapepoints <- structure(list(x = c(8.9, 0, -7.7, 0, 8.9),
                               y = c(0, 2, 0, -3.8, 0)),
                          .Names = c("x", "y"),
                          row.names = c(NA, -5L),
                          class = "data.frame")

library(grid)
grid.newpage()
pushViewport(dataViewport(shapepoints[,1], shapepoints[,2]))
grid.points(shapepoints[,1], shapepoints[,2], default.units="native")
grid.xspline(shapepoints[-1,1], shapepoints[-1,2],
              default.units="native", shape=-1, open=FALSE)

xsg <- xsplineGrob(shapepoints[-1,1], shapepoints[-1,2],
                    default.units="native", shape=-1, open=FALSE)
# THIS is the information I think you want
trace <- xsplinePoints(xsg)
grid.points(trace$x, trace$y, default.units="native",
             size=unit(1, "mm"), pch=16)

Paul

On 22/03/16 03:04, Alexander Shenkin wrote:
> Thanks for your reply, Charles.  spline() doesn't seem to fit a closed
> shape; rather, it's producing a parabola.  Perhaps I'm missing an
> argument I should include?
>
> grid.xspline() seems to get close to what I need, but it returns a grob
> object - not sure how to work with those as shapes per se.
>
> My goal is to produce a 2D shape from which I can calculate area,
> average widths, and other such things.  The context is that we have
> measured tree crowns in a manner that has produced 4 points such as
> these from two offset axes.  We want to use the resulting shapes for our
> calculations.
>
> (incidentally, my original points were off - here are the correct ones)
>
> shapepoints = structure(list(x = c(8.9, 0, -7.7, 0, 8.9), y = c(0, 2, 0,
> -3.8,
> 0)), .Names = c("x", "y"), row.names = c(NA, -5L), class = "data.frame")
>
> plot(spline(shapepoints))
>
> Thanks,
> Allie
>
> On 3/21/2016 1:10 PM, Charles Determan wrote:
>> Hi Allie,
>>
>> What is you goal here?  Do you just want to plot a curve to the data?
>> Do you want a function to approximate the data?
>>
>> You may find the functions spline() and splinefun() useful.
>>
>> Quick point though, with so few points you are only going to get a very
>> rough approximation no matter the method used.
>>
>> Regards,
>> Charles
>>
>>
>> On Mon, Mar 21, 2016 at 7:59 AM, Alexander Shenkin <ashenkin at ufl.edu
>> <mailto:ashenkin at ufl.edu>> wrote:
>>
>>     Hello all,
>>
>>     I have sets of 4 x/y points through which I would like to fit
>>     closed, smoothed shapes that go through those 4 points exactly.
>>     smooth.spline doesn't like my data, since there are only 3 unique x
>>     points, and even then, i'm not sure smooth.spline likes making
>>     closed shapes.
>>
>>     Might anyone else have suggestions for fitting algorithms I could
>>     employ?
>>
>>     Thanks,
>>     Allie
>>
>>
>>     shapepoints = structure(c(8.9, 0, -7.7, 0, 0, 2, 0, 3.8), .Dim =
>> c(4L,
>>     2L), .Dimnames = list(NULL, c("x", "y")))
>>
>>     smooth.spline(shapepoints)
>>
>>     # repeat the first point to close the shape
>>     shapepoints = rbind(shapepoints, shapepoints[1,])
>>
>>     smooth.spline(shapepoints)
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From kmnanus at gmail.com  Mon Mar 21 15:40:26 2016
From: kmnanus at gmail.com (KMNanus)
Date: Mon, 21 Mar 2016 10:40:26 -0400
Subject: [R] Help! Mann whitney
In-Reply-To: <CABPcGadG1LGq1LvTN-rvq=c6F98MzefiE9MYWoQsq+qaZA6u4A@mail.gmail.com>
References: <CABPcGadG1LGq1LvTN-rvq=c6F98MzefiE9MYWoQsq+qaZA6u4A@mail.gmail.com>
Message-ID: <6F3A09F6-2138-456C-8D39-6B40C20534DF@gmail.com>

Here?s how I did it - 

Save the xlsx file as a .csv.  Then call read.csv(?your file.csv?) and you should be in.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 20, 2016, at 1:37 PM, <santib2002 at gmail.com> <santib2002 at gmail.com> wrote:
> 
> This may be really basic, but could you help me with this issue?
> I have an excel file named table1.xls.
> I need to input this table in r, in order to calculate mann whitney between
> columns 1 and 2.
> Could you please show me how to do this task?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Mar 21 19:50:15 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 21 Mar 2016 18:50:15 +0000
Subject: [R] how to use vectorization instead of for loop
In-Reply-To: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
References: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
Message-ID: <20160321185015.Horde.tcX-Ct_n14JW8EJnGAegPhA@mail.sapo.pt>

Hello,

I've renamed your dataframe to 'dat'. Since ?ifelse is vectorized, try

dat[, 4] <- ifelse(dat[, 2] > 0, 1 * (1/dat[,3]), -1* (1/dat[,3]))

Oh, and why do you multiply by 1 and by -1?
It would simply be 1/dat[,3] and -1/dat[,3].

Hope this helps,

Rui Barradas


Quoting Stephen HK WONG <honkit at stanford.edu>:

> Dear All,
>
>
> I have a dataframe like below but with many thousands rows,
>
> structure(list(gene_id = structure(1:6, .Label = c("0610005C13Rik",
> "0610007P14Rik", "0610009B22Rik", "0610009L18Rik", "0610009O20Rik",
> "0610010B08Rik,OTTMUSG00000016609"), class = "factor"),  
> log2.fold_change. = c(0.0114463,
> -0.0960262, 0.00805151, -0.179981, -0.0629098, 0.155979), p_value = c(1,
> 0.77915, 0.98265, 0.68665, 0.85035, 0.72235), new.value = c("NA",
> "NA", "NA", "NA", "NA", "NA")), .Names = c("gene_id", "log2.fold_change.",
> "p_value", "new.value"), row.names = c(NA, 6L), class = "data.frame")
>
>
> I want to check if second column is positive or negative value, then  
> I will do some calculation and put the new value in last column. I  
> can do this with for loop like below but it is not efficient. Is  
> there a better way to use a vectorization method instead of loop?  
> Many thanks!
>
>
> for (i in 1:nrow(dataframe)) {
>
> if dataframe[i, 2]>0 {
>
> dataframe[i, 4]<- 1 * (1/dataframe[i,3])} else{
>
> dataframe[i, 4] <- -1* (1/dataframe[i,3])}
>
> }
>
>
> -------------------------------------------------------
>
> Stephen H.K. WONG, PhD.
>
> Stanford University
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rodrigo at rodrigobotafogo.com  Mon Mar 21 15:26:19 2016
From: rodrigo at rodrigobotafogo.com (Rodrigo Botafogo)
Date: Mon, 21 Mar 2016 11:26:19 -0300
Subject: [R]  Reshaping an array - how does it work in R
Message-ID: <CAAKc=GCkJ=OSSKvHXdYdw=rjsrwsMJm57mqA4nVCxwr5a4VB5g@mail.gmail.com>

Roy,

I have implemented a Ruby Gem (SciCom) with exactly your use case in mind.
SciCom is based on Renjin, an R interpreter for the JVM.  So, this reply is
about R, but not about GnuR.  If this is not proper behavior, please let me
know.  I?ve looked at the posting guidelines and it seems to be ok.

SciCom interfaces with another Ruby Gem: MDArray.  MDArray is a
multidimensional array class that is based on NetCDF-Java.  It can read
netcdf files and store them in a multidimensional array.  MDArray can be
reshaped and also sliced and diced as you can do with NetCDF.  Reshaping an
MDArray does not require any copying, it is just index manipulations.

An MDArray can then be "send" to SciCom.  This is not really sending, since
there is no data copying either and the array is just wrapped in such a way
that it can be used in Renjin.  In Renjin you could use normal R functions
to process this data and do your analysis.

The data in SciCom can thus be viewed either as an R array, to which R
sematics apply and reshaping will copy the data, or as an MDArray, and
reshaping and slicing/dicing does not do any copying.  It is up to the
developer to be careful how to see the data and operate on it.

There are however two showstoppers: i) Renjin does not load all CRAN
packages yet.  So, there is a good chance that if you need a package for
your PCA analysis, that this will not be loaded; ii) SciCom/Renjin do not
support any graphics such as plot/ggplot.

References:

Renjin: http://www.renjin.org/
NetCDF-Java:
http://www.unidata.ucar.edu/software/thredds/current/netcdf-java/
MDArray: https://github.com/rbotafogo/mdarray/wiki
SciCom:
    https://github.com/rbotafogo/scicom

https://github.com/rbotafogo/scicom/wiki/A-(not-so)-Short-Introduction-to-SciCom

-- 
Rodrigo Botafogo

	[[alternative HTML version deleted]]


From f.toepfer at komet.net  Mon Mar 21 12:44:17 2016
From: f.toepfer at komet.net (=?iso-8859-1?q?Felix_T=F6pfer?=)
Date: Mon, 21 Mar 2016 12:44:17 +0100
Subject: [R] possible to use the program for commercial reasons?
Message-ID: <0e701933-ed0c-4a2c-8500-60108a4f77a0@komet.net>

Dear R-Team,
 
I am a scientist actually working in parallel as data analyst for an advertisment auditing company. Therefore i would use your software for commercial reasons right now. Is this allowed, o rare there special licences?
 
Best Regards,
 
Felix T?pfer
B?roassistenz
 
----------------------------------------
Kollat Media Team GmbH
Novalisstra?e 11/F
10115 Berlin
Tel:  +49(0)30 - 97 00 59 20
Fax: +49(0)30-  97 00 59 19
www.komet.net

Gesch?ftsf?hrer Jens W. Kollat

HR Charlottenburg HRB 93042
Ust ID: DE814008722
Deutsche Bank: BLZ 10070024  Kto: 1081884
	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Mon Mar 21 20:01:01 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 21 Mar 2016 12:01:01 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <CAAKc=GCkJ=OSSKvHXdYdw=rjsrwsMJm57mqA4nVCxwr5a4VB5g@mail.gmail.com>
References: <CAAKc=GCkJ=OSSKvHXdYdw=rjsrwsMJm57mqA4nVCxwr5a4VB5g@mail.gmail.com>
Message-ID: <4DA232A3-37D0-4D73-A5A1-6D060F01F6E8@noaa.gov>

Thanks for the info, but I will stay with regular R.  Work -arounds for what I want to do just took some thought and programming, I just didn?t know if R copied the array  or just manipulated indices, and given the size of the array I am memory limited.  

This gets into the old thing of whether it is better to pass arrays by reference or value.  As an old Fortran programmer, that is one nice thing that could be done in Fortran - since arrays are passed by reference, the indices could be manipulated in the same memory space by passing to a subroutine, or through an equivalence statement.  But all of these things have trade-offs.

-Roy






> On Mar 21, 2016, at 7:26 AM, Rodrigo Botafogo <rodrigo at rodrigobotafogo.com> wrote:
> 
> Roy,
> 
> I have implemented a Ruby Gem (SciCom) with exactly your use case in mind.
> SciCom is based on Renjin, an R interpreter for the JVM.  So, this reply is
> about R, but not about GnuR.  If this is not proper behavior, please let me
> know.  I?ve looked at the posting guidelines and it seems to be ok.
> 
> SciCom interfaces with another Ruby Gem: MDArray.  MDArray is a
> multidimensional array class that is based on NetCDF-Java.  It can read
> netcdf files and store them in a multidimensional array.  MDArray can be
> reshaped and also sliced and diced as you can do with NetCDF.  Reshaping an
> MDArray does not require any copying, it is just index manipulations.
> 
> An MDArray can then be "send" to SciCom.  This is not really sending, since
> there is no data copying either and the array is just wrapped in such a way
> that it can be used in Renjin.  In Renjin you could use normal R functions
> to process this data and do your analysis.
> 
> The data in SciCom can thus be viewed either as an R array, to which R
> sematics apply and reshaping will copy the data, or as an MDArray, and
> reshaping and slicing/dicing does not do any copying.  It is up to the
> developer to be careful how to see the data and operate on it.
> 
> There are however two showstoppers: i) Renjin does not load all CRAN
> packages yet.  So, there is a good chance that if you need a package for
> your PCA analysis, that this will not be loaded; ii) SciCom/Renjin do not
> support any graphics such as plot/ggplot.
> 
> References:
> 
> Renjin: http://www.renjin.org/
> NetCDF-Java:
> http://www.unidata.ucar.edu/software/thredds/current/netcdf-java/
> MDArray: https://github.com/rbotafogo/mdarray/wiki
> SciCom:
>    https://github.com/rbotafogo/scicom
> 
> https://github.com/rbotafogo/scicom/wiki/A-(not-so)-Short-Introduction-to-SciCom
> 
> -- 
> Rodrigo Botafogo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From marc_schwartz at me.com  Mon Mar 21 20:05:15 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 21 Mar 2016 14:05:15 -0500
Subject: [R] possible to use the program for commercial reasons?
In-Reply-To: <0e701933-ed0c-4a2c-8500-60108a4f77a0@komet.net>
References: <0e701933-ed0c-4a2c-8500-60108a4f77a0@komet.net>
Message-ID: <45C90127-0FE8-4FAE-B146-E3AFA3B536D7@me.com>


> On Mar 21, 2016, at 6:44 AM, Felix T?pfer <f.toepfer at komet.net> wrote:
> 
> Dear R-Team,
> 
> I am a scientist actually working in parallel as data analyst for an advertisment auditing company. Therefore i would use your software for commercial reasons right now. Is this allowed, o rare there special licences?
> 
> Best Regards,
> 
> Felix T?pfer
> B?roassistenz

Hi,

See this FAQ:

  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f

There are a significant number of R users in a commercial/for-profit setting, me being one of them. There is nothing in the R license that prevents you from *using* R in a commercial setting.

There are a limited number of third party add-on packages that are on CRAN however, that do have non-commercial use only restrictions, so just be aware of that.

The GPL, which is the license under which R is released and referenced in the above FAQ, has certain requirements if you wish to copy/distribute R and/or if you develop code which "links" to R in certain ways and wish to copy/distribute that work. If this is your use case, you should consult legal counsel familiar with open source licenses, since there can be requirements that would require you to make your source code available.

Regards,

Marc


From ragia11 at hotmail.com  Mon Mar 21 20:34:38 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Mon, 21 Mar 2016 21:34:38 +0200
Subject: [R] get values out of Structure
In-Reply-To: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
References: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
Message-ID: <DUB125-W55957AF03458F810EB6AC3B38F0@phx.gbl>



?accept my apology for resending..

? Dear group
?I have the following variable v_neighbours and it holds a vector of the following :

? gawker.com gle.am jezebel.com
? 1 16 28

to have a copy,?

?dput(v_neighbours)
structure(c(1L, 16L, 28L), .Names = c("gawker.com", "gle.am",?"jezebel.com"))

?3 urls and their id ...when I call the class(v_neighbours ) the result is "integer"
? how can I get the factor numeric values ( 1,16,28) out of this variable.
? thanks in advance
? R.Ibrahim
 		 	   		  

From honkit at stanford.edu  Mon Mar 21 21:34:15 2016
From: honkit at stanford.edu (Stephen HK WONG)
Date: Mon, 21 Mar 2016 20:34:15 +0000
Subject: [R] how to use vectorization instead of for loop
In-Reply-To: <20160321185015.Horde.tcX-Ct_n14JW8EJnGAegPhA@mail.sapo.pt>
References: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>,
	<20160321185015.Horde.tcX-Ct_n14JW8EJnGAegPhA@mail.sapo.pt>
Message-ID: <BLUPR0201MB1524AEB898E1979AAE9F93B0A88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>

So much thanks Rui, the code can be so simple and fast. 

By the way, ifelse is good for two conditions, in my case, either >0, or <0, I found there's a lot of row with value "Inf", I want to keep it in new column, how do I do that using ifelse ?

Thanks.

________________________________________
From: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
Sent: Monday, March 21, 2016 11:50 AM
To: Stephen HK WONG
Cc: r-help at r-project.org
Subject: Re: [R] how to use vectorization instead of for loop

Hello,

I've renamed your dataframe to 'dat'. Since ?ifelse is vectorized, try

dat[, 4] <- ifelse(dat[, 2] > 0, 1 * (1/dat[,3]), -1* (1/dat[,3]))

Oh, and why do you multiply by 1 and by -1?
It would simply be 1/dat[,3] and -1/dat[,3].

Hope this helps,

Rui Barradas


Quoting Stephen HK WONG <honkit at stanford.edu>:

> Dear All,
>
>
> I have a dataframe like below but with many thousands rows,
>
> structure(list(gene_id = structure(1:6, .Label = c("0610005C13Rik",
> "0610007P14Rik", "0610009B22Rik", "0610009L18Rik", "0610009O20Rik",
> "0610010B08Rik,OTTMUSG00000016609"), class = "factor"),
> log2.fold_change. = c(0.0114463,
> -0.0960262, 0.00805151, -0.179981, -0.0629098, 0.155979), p_value = c(1,
> 0.77915, 0.98265, 0.68665, 0.85035, 0.72235), new.value = c("NA",
> "NA", "NA", "NA", "NA", "NA")), .Names = c("gene_id", "log2.fold_change.",
> "p_value", "new.value"), row.names = c(NA, 6L), class = "data.frame")
>
>
> I want to check if second column is positive or negative value, then
> I will do some calculation and put the new value in last column. I
> can do this with for loop like below but it is not efficient. Is
> there a better way to use a vectorization method instead of loop?
> Many thanks!
>
>
> for (i in 1:nrow(dataframe)) {
>
> if dataframe[i, 2]>0 {
>
> dataframe[i, 4]<- 1 * (1/dataframe[i,3])} else{
>
> dataframe[i, 4] <- -1* (1/dataframe[i,3])}
>
> }
>
>
> -------------------------------------------------------
>
> Stephen H.K. WONG, PhD.
>
> Stanford University
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Mar 21 21:53:28 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 21 Mar 2016 20:53:28 +0000
Subject: [R] get values out of combined object
In-Reply-To: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
References: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>
Message-ID: <D315AC0B.16828B%macqueen1@llnl.gov>

Here, by example, might be what you're looking for:

> v <- c(a=1, b=3, c=25)
> v
 a  b  c 
 1  3 25 
> unname(v)
[1]  1  3 25


However, this has nothing to do with factors, and don't know what you mean
by the "factor numeric values" of an object that isn't a factor.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/21/16, 10:27 AM, "R-help on behalf of Ragia ."
<r-help-bounces at r-project.org on behalf of ragia11 at hotmail.com> wrote:

>
> 
> Dear group
>I have the following variable   v_neighbours and it holds a vector of the
>following :
> gawker.com      gle.am   jezebel.com
>          1          16          28
>
>three urls and their id ...when I call the class(v_neighbours )  the
>result is  "integer"
>how can I get the factor numeric values  ( 1,16,28) out of this variable.
>
>thanks in advance
>R.Ibrahim 		 	   		
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Mon Mar 21 22:07:41 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Mon, 21 Mar 2016 16:07:41 -0500
Subject: [R] installing packages
Message-ID: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>

Dear R community,

When I install or update a package, R prints the waring below.  I go to the
?downloaded_packages? folder in the Temp file and manually move the new or
updated package to the folder ?3.2?.   How can I instruct R to download new
and updates packages into the ?3.2? folder?

Warning in install.packages :

  unable to move temporary installation
?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme



The downloaded binary packages are in


C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages



Thank for your help.

James F. Henson

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Mar 21 22:45:17 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 21 Mar 2016 21:45:17 +0000
Subject: [R] how to use vectorization instead of for loop
In-Reply-To: <BLUPR0201MB1524AEB898E1979AAE9F93B0A88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
References: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
	<20160321185015.Horde.tcX-Ct_n14JW8EJnGAegPhA@mail.sapo.pt>
	<BLUPR0201MB1524AEB898E1979AAE9F93B0A88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
Message-ID: <20160321214517.Horde.Ip65Nhiis77P3ofDoRcRELS@mail.sapo.pt>

Hello,

Use combined ifelses, more or less like the following.

ifelse(dat[, 2] == Inf, do this, ifelse(dat[, 2] > 0, 1 * (1/dat[,3]),  
-1* (1/dat[,3])))

Rui Barradas
?

Citando Stephen HK WONG <honkit at stanford.edu>:

> So much thanks Rui, the code can be so simple and fast.
>
> By the way, ifelse is good for two conditions, in my case, either  
> >0, or <0, I found there's a lot of row with value "Inf", I want to  
> keep it in new column, how do I do that using ifelse ?
>
> Thanks.
>
> ________________________________________
> From: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
> Sent: Monday, March 21, 2016 11:50 AM
> To: Stephen HK WONG
> Cc: r-help at r-project.org
> Subject: Re: [R] how to use vectorization instead of for loop
>
> Hello,
>
> I've renamed your dataframe to 'dat'. Since ?ifelse is vectorized, try
>
> dat[, 4] <- ifelse(dat[, 2] > 0, 1 * (1/dat[,3]), -1* (1/dat[,3]))
>
> Oh, and why do you multiply by 1 and by -1?
> It would simply be 1/dat[,3] and -1/dat[,3].
>
> Hope this helps,
>
> Rui Barradas
>
> Quoting Stephen HK WONG <honkit at stanford.edu>:
>> Dear All,
>>
>> I have a dataframe like below but with many thousands rows,
>>
>> structure(list(gene_id = structure(1:6, .Label = c("0610005C13Rik",
>> "0610007P14Rik", "0610009B22Rik", "0610009L18Rik", "0610009O20Rik",
>> "0610010B08Rik,OTTMUSG00000016609"), class = "factor"),
>> log2.fold_change. = c(0.0114463,
>> -0.0960262, 0.00805151, -0.179981, -0.0629098, 0.155979), p_value = c(1,
>> 0.77915, 0.98265, 0.68665, 0.85035, 0.72235), new.value = c("NA",
>> "NA", "NA", "NA", "NA", "NA")), .Names = c("gene_id", "log2.fold_change.",
>> "p_value", "new.value"), row.names = c(NA, 6L), class = "data.frame")
>>
>> I want to check if second column is positive or negative value, then
>> I will do some calculation and put the new value in last column. I
>> can do this with for loop like below but it is not efficient. Is
>> there a better way to use a vectorization method instead of loop?
>> Many thanks!
>>
>> for (i in 1:nrow(dataframe)) {
>>
>> if dataframe[i, 2]>0 {
>>
>> dataframe[i, 4]<- 1 * (1/dataframe[i,3])} else{
>>
>> dataframe[i, 4] <- -1* (1/dataframe[i,3])}
>>
>> }
>>
>> -------------------------------------------------------
>>
>> Stephen H.K. WONG, PhD.
>>
>> Stanford University
>>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide  
>> http://www.R-project.org/posting-guide.htmland provide commented,  
>> minimal, self-contained, reproducible code.
>
> ?

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon Mar 21 23:02:03 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2016 23:02:03 +0100
Subject: [R] installing packages
In-Reply-To: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
References: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
Message-ID: <56F06F5B.5050203@statistik.tu-dortmund.de>



On 21.03.2016 22:07, James Henson wrote:
> Dear R community,
>
> When I install or update a package, R prints the waring below.  I go to the
> ?downloaded_packages? folder in the Temp file and manually move the new or
> updated package to the folder ?3.2?.   How can I instruct R to download new
> and updates packages into the ?3.2? folder?
>
> Warning in install.packages :
>
>    unable to move temporary installation
> ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
> to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme


I guess you had nlme loaded? Start a fresh R without loading nlme, then 
R should be able to move the temp installation.

Best,
Uwe Ligges

>
>
> The downloaded binary packages are in
>
>
> C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages
>
>
>
> Thank for your help.
>
> James F. Henson
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ddalthorp at usgs.gov  Mon Mar 21 23:09:50 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Mon, 21 Mar 2016 15:09:50 -0700
Subject: [R] how to use vectorization instead of for loop
In-Reply-To: <20160321214517.Horde.Ip65Nhiis77P3ofDoRcRELS@mail.sapo.pt>
References: <BLUPR0201MB15245A71B15B01D9B0A2522EA88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
	<20160321185015.Horde.tcX-Ct_n14JW8EJnGAegPhA@mail.sapo.pt>
	<BLUPR0201MB1524AEB898E1979AAE9F93B0A88F0@BLUPR0201MB1524.namprd02.prod.outlook.com>
	<20160321214517.Horde.Ip65Nhiis77P3ofDoRcRELS@mail.sapo.pt>
Message-ID: <CAJeYpE_jBbSMzM0Q6C-8cnV_rre4xrZaEMvwhGskzTMH6VpOqw@mail.gmail.com>

or simpler and faster:

dat[,4] <- sign(dat[,2])/dat[,3] # your original loop

dat <- cbind(dat, dat[,2] == Inf)  # append a new column with indicator for
which rows have dat[,2] = Inf


On Mon, Mar 21, 2016 at 2:45 PM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Use combined ifelses, more or less like the following.
>
> ifelse(dat[, 2] == Inf, do this, ifelse(dat[, 2] > 0, 1 * (1/dat[,3]),
> -1* (1/dat[,3])))
>
> Rui Barradas
>
>
> Citando Stephen HK WONG <honkit at stanford.edu>:
>
> > So much thanks Rui, the code can be so simple and fast.
> >
> > By the way, ifelse is good for two conditions, in my case, either
> > >0, or <0, I found there's a lot of row with value "Inf", I want to
> > keep it in new column, how do I do that using ifelse ?
> >
> > Thanks.
> >
> > ________________________________________
> > From: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
> > Sent: Monday, March 21, 2016 11:50 AM
> > To: Stephen HK WONG
> > Cc: r-help at r-project.org
> > Subject: Re: [R] how to use vectorization instead of for loop
> >
> > Hello,
> >
> > I've renamed your dataframe to 'dat'. Since ?ifelse is vectorized, try
> >
> > dat[, 4] <- ifelse(dat[, 2] > 0, 1 * (1/dat[,3]), -1* (1/dat[,3]))
> >
> > Oh, and why do you multiply by 1 and by -1?
> > It would simply be 1/dat[,3] and -1/dat[,3].
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Quoting Stephen HK WONG <honkit at stanford.edu>:
> >> Dear All,
> >>
> >> I have a dataframe like below but with many thousands rows,
> >>
> >> structure(list(gene_id = structure(1:6, .Label = c("0610005C13Rik",
> >> "0610007P14Rik", "0610009B22Rik", "0610009L18Rik", "0610009O20Rik",
> >> "0610010B08Rik,OTTMUSG00000016609"), class = "factor"),
> >> log2.fold_change. = c(0.0114463,
> >> -0.0960262, 0.00805151, -0.179981, -0.0629098, 0.155979), p_value = c(1,
> >> 0.77915, 0.98265, 0.68665, 0.85035, 0.72235), new.value = c("NA",
> >> "NA", "NA", "NA", "NA", "NA")), .Names = c("gene_id",
> "log2.fold_change.",
> >> "p_value", "new.value"), row.names = c(NA, 6L), class = "data.frame")
> >>
> >> I want to check if second column is positive or negative value, then
> >> I will do some calculation and put the new value in last column. I
> >> can do this with for loop like below but it is not efficient. Is
> >> there a better way to use a vectorization method instead of loop?
> >> Many thanks!
> >>
> >> for (i in 1:nrow(dataframe)) {
> >>
> >> if dataframe[i, 2]>0 {
> >>
> >> dataframe[i, 4]<- 1 * (1/dataframe[i,3])} else{
> >>
> >> dataframe[i, 4] <- -1* (1/dataframe[i,3])}
> >>
> >> }
> >>
> >> -------------------------------------------------------
> >>
> >> Stephen H.K. WONG, PhD.
> >>
> >> Stanford University
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.htmland provide commented,
> >> minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Mar 22 01:15:04 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 21 Mar 2016 16:15:04 -0800
Subject: [R] installing packages
In-Reply-To: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
Message-ID: <1A3F6700F06.000008F0jrkrideau@inbox.com>

Can you load the downloaded library? 
If so I'd not worry about it.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jfhenson1 at gmail.com
> Sent: Mon, 21 Mar 2016 16:07:41 -0500
> To: r-help at r-project.org
> Subject: [R] installing packages
> 
> Dear R community,
> 
> When I install or update a package, R prints the waring below.  I go to
> the
> ?downloaded_packages? folder in the Temp file and manually move the new
> or
> updated package to the folder ?3.2?.   How can I instruct R to download
> new
> and updates packages into the ?3.2? folder?
> 
> Warning in install.packages :
> 
>   unable to move temporary installation
> ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
> to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme
> 
> 
> 
> The downloaded binary packages are in
> 
> 
> C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages
> 
> 
> 
> Thank for your help.
> 
> James F. Henson
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From martin.seilmayer at freenet.de  Mon Mar 21 21:03:28 2016
From: martin.seilmayer at freenet.de (Martin Seilmayer)
Date: Mon, 21 Mar 2016 21:03:28 +0100
Subject: [R]  GPIB-compatible instrument control with R
In-Reply-To: <CAN=2HaKpbpJUD1gV5P3eHgEonhL5uckEwa==pFsRonudLCLjxg@mail.gmail.com>
References: <CAN=2HaKpbpJUD1gV5P3eHgEonhL5uckEwa==pFsRonudLCLjxg@mail.gmail.com>
Message-ID: <56F05390.7010208@freenet.de>

Hi,

I know this comes late but it should be mentioned. Since Jan 2016 there 
is a package "serial" on CRAN, which provides an interface to the serial 
RS232 RS485 RS422 com ports within R.

Best
Martin


From kmnanus at gmail.com  Mon Mar 21 22:10:01 2016
From: kmnanus at gmail.com (KMNanus)
Date: Mon, 21 Mar 2016 17:10:01 -0400
Subject: [R] installing packages
In-Reply-To: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
References: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
Message-ID: <65BFF5D6-48D1-4B4B-AD0E-61537ED8ECEC@gmail.com>

Have you set your working directory to the ?3.2? folder?
Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 21, 2016, at 5:07 PM, James Henson <jfhenson1 at gmail.com> wrote:
> 
> Dear R community,
> 
> When I install or update a package, R prints the waring below.  I go to the
> ?downloaded_packages? folder in the Temp file and manually move the new or
> updated package to the folder ?3.2?.   How can I instruct R to download new
> and updates packages into the ?3.2? folder?
> 
> Warning in install.packages :
> 
>  unable to move temporary installation
> ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
> to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme
> 
> 
> 
> The downloaded binary packages are in
> 
> 
> C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages
> 
> 
> 
> Thank for your help.
> 
> James F. Henson
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Mar 22 03:57:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 21 Mar 2016 19:57:58 -0700
Subject: [R] installing packages
In-Reply-To: <65BFF5D6-48D1-4B4B-AD0E-61537ED8ECEC@gmail.com>
References: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
	<65BFF5D6-48D1-4B4B-AD0E-61537ED8ECEC@gmail.com>
Message-ID: <42B66F6C-E061-4BCF-A18B-F32001E58658@dcn.davis.ca.us>

I hope not.  That directory is not for working in. suggestion to restart R sounds most likely to fix the issue. 
-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2016 2:10:01 PM PDT, KMNanus <kmnanus at gmail.com> wrote:
>Have you set your working directory to the ?3.2? folder?
>Ken
>kmnanus at gmail.com
>914-450-0816 (tel)
>347-730-4813 (fax)
>
>
>
>> On Mar 21, 2016, at 5:07 PM, James Henson <jfhenson1 at gmail.com>
>wrote:
>> 
>> Dear R community,
>> 
>> When I install or update a package, R prints the waring below.  I go
>to the
>> ?downloaded_packages? folder in the Temp file and manually move the
>new or
>> updated package to the folder ?3.2?.   How can I instruct R to
>download new
>> and updates packages into the ?3.2? folder?
>> 
>> Warning in install.packages :
>> 
>>  unable to move temporary installation
>>
>?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
>> to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme
>> 
>> 
>> 
>> The downloaded binary packages are in
>> 
>> 
>>
>C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages
>> 
>> 
>> 
>> Thank for your help.
>> 
>> James F. Henson
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Tue Mar 22 05:44:22 2016
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 21 Mar 2016 23:44:22 -0500
Subject: [R] regex - extracting src url
Message-ID: <CAM-xyZhFJtxQcEwhYJRTGfuOxubsLcPK9463q1tSicXTupBMKQ@mail.gmail.com>

Hi,I have a DF with a column with "html", like this:

<IMG SRC="
https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"
BORDER="0" HEIGHT="1" WIDTH="1" ALT="Advertisement">


I need to get this:


https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
?


I've got this so far:


https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?\"
BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement


With this is the code I've used:

carreras_normal$Impression.Tag..image. <-
gsub("<img.+?src=[\"'](.*?)[\"'].*?>","\\1",carreras_normal$Impression.Tag..image.,
                                  ignore.case = T)



*But I still need to use get rid of this part:*


https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
?*\" BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement*


Thank you for your help.

Omar Gonz?les.

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Tue Mar 22 05:48:59 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Tue, 22 Mar 2016 06:48:59 +0200
Subject: [R] get values out of combined object
In-Reply-To: <D315AC0B.16828B%macqueen1@llnl.gov>
References: <DUB125-W322F541660454764D2B82AB38F0@phx.gbl>,
	<D315AC0B.16828B%macqueen1@llnl.gov>
Message-ID: <DUB125-W1122C5A73556631F81E44CB3800@phx.gbl>

many thanks...it solved my problem...and I will review what is factors..( I think I have misunderstanding in this)

RagiA

?


----------------------------------------
> From: macqueen1 at llnl.gov
> To: ragia11 at hotmail.com; r-help at r-project.org
> Subject: Re: [R] get values out of combined object
> Date: Mon, 21 Mar 2016 20:53:28 +0000
>
> Here, by example, might be what you're looking for:
>
>> v <- c(a=1, b=3, c=25)
>> v
> a b c
> 1 3 25
>> unname(v)
> [1] 1 3 25
>
>
> However, this has nothing to do with factors, and don't know what you mean
> by the "factor numeric values" of an object that isn't a factor.
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 3/21/16, 10:27 AM, "R-help on behalf of Ragia ."
> <r-help-bounces at r-project.org on behalf of ragia11 at hotmail.com> wrote:
>
>>
>>
>> Dear group
>>I have the following variable v_neighbours and it holds a vector of the
>>following :
>> gawker.com gle.am jezebel.com
>> 1 16 28
>>
>>three urls and their id ...when I call the class(v_neighbours ) the
>>result is "integer"
>>how can I get the factor numeric values ( 1,16,28) out of this variable.
>>
>>thanks in advance
>>R.Ibrahim
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
 		 	   		  

From bgunter.4567 at gmail.com  Tue Mar 22 06:13:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 21 Mar 2016 22:13:14 -0700
Subject: [R] regex - extracting src url
In-Reply-To: <CAM-xyZhFJtxQcEwhYJRTGfuOxubsLcPK9463q1tSicXTupBMKQ@mail.gmail.com>
References: <CAM-xyZhFJtxQcEwhYJRTGfuOxubsLcPK9463q1tSicXTupBMKQ@mail.gmail.com>
Message-ID: <CAGxFJbTeCr4QngRD6eA0iSrMgQfUkoO=T=VMgLYUkge=njkZpg@mail.gmail.com>

?strsplit  #I think
My "solution" assumes a fixed format for the URL's as shown in your
example. If that is not the case, it doesn't work.

> y <- '<IMG SRC="https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"
+ BORDER="0" HEIGHT="1" WIDTH="1" ALT="Advertisement">'

> y  ## checking that the URL is as expected

[1] "<IMG SRC=\"https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?\"\nBORDER=\"0\"
HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement\">"


> lapply(strsplit(y,"\""),"[",2) ## should work on a vector of URL's, y

[[1]]
[1] "https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"



Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 21, 2016 at 9:44 PM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> Hi,I have a DF with a column with "html", like this:
>
> <IMG SRC="
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"
> BORDER="0" HEIGHT="1" WIDTH="1" ALT="Advertisement">
>
>
> I need to get this:
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
> ?
>
>
> I've got this so far:
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?\"
> BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement
>
>
> With this is the code I've used:
>
> carreras_normal$Impression.Tag..image. <-
> gsub("<img.+?src=[\"'](.*?)[\"'].*?>","\\1",carreras_normal$Impression.Tag..image.,
>                                   ignore.case = T)
>
>
>
> *But I still need to use get rid of this part:*
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
> ?*\" BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement*
>
>
> Thank you for your help.
>
> Omar Gonz?les.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Tue Mar 22 10:20:33 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Mar 2016 10:20:33 +0100
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <56EC7987.2070602@ttk.mta.hu>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
Message-ID: <22257.3681.787925.965424@stat.math.ethz.ch>

>>>>> D?nes T?th <toth.denes at ttk.mta.hu>
>>>>>     on Fri, 18 Mar 2016 22:56:23 +0100 writes:

    > Hi Roy,
    > R (usually) makes a copy if the dimensionality of an array is modified, 
    > even if you use this syntax:

    > x <- array(1:24, c(2, 3, 4))
    > dim(x) <- c(6, 4)

    > See also ?tracemem, ?data.table::address, ?pryr::address and other tools 
    > to trace if an internal copy is done.

Well, without using strange (;-) packages,  indeed standard R's
tracemem(), notably the help page is a good pointer.

According to the help page memory tracing is enabled in the
default R binaries for Windows and OS X.
For Linux (where I, as R developer, compile R myself anyway),
one needs to configure with --enable-memory-profiling .

Now, let's try:

   > x <- array(rnorm(47), dim = c(1000,50, 40))
   > tracemem(x)
   [1] "<0x7f79a498a010>"
   > dim(x) <- c(1000* 50, 40)
   > x[5] <- pi
   > tracemem(x)
   [1] "<0x7f79a498a010>"
   > 

So, *BOTH*  the re-dimensioning  *AND*  the  sub-assignment did
*NOT* make a copy.

Indeed, R has become much smarter  in these things in recent
years ... not thanks to me, but very much thanks to
Luke Tierney (from R-core), and also thanks to contributions from "outside",
notably Tomas Kalibera.

And hence: *NO* such strange workarounds are needed in this specific case: 

    > Workaround: use data.table::setattr or bit::setattr to modify the 
    > dimensions in place (i.e., without making a copy). Risk: if you modify 
    > an object by reference, all other objects which point to the same memory 
    > address will be modified silently, too.

Martin Maechler, ETH Zurich  (and R-core)

    > HTH,
    > Denes

(generally, your contributions help indeed, Denes, thank you!)


    > On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
    >> Hi All:
    >> 
    >> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
    >> 
    >> myData[noLat, no Lon, noTime].
    >> 
    >> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
    >> 
    >> myData[noLat*noLon, noTime].  Normally this would be easy:
    >> 
    >> myData<- array(myData,dim=c(noLat*noLon,noTime))
    >> 
    >> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
    >> 
    >> Thanks,
    >> 
    >> -Roy


From toth.denes at ttk.mta.hu  Tue Mar 22 10:55:58 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Tue, 22 Mar 2016 10:55:58 +0100
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <22257.3681.787925.965424@stat.math.ethz.ch>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<22257.3681.787925.965424@stat.math.ethz.ch>
Message-ID: <56F116AE.20903@ttk.mta.hu>


Hi Martin,


On 03/22/2016 10:20 AM, Martin Maechler wrote:
>>>>>> >>>>>D?nes T?th<toth.denes at ttk.mta.hu>
>>>>>> >>>>>     on Fri, 18 Mar 2016 22:56:23 +0100 writes:
>      > Hi Roy,
>      > R (usually) makes a copy if the dimensionality of an array is modified,
>      > even if you use this syntax:
>
>      > x <- array(1:24, c(2, 3, 4))
>      > dim(x) <- c(6, 4)
>
>      > See also ?tracemem, ?data.table::address, ?pryr::address and other tools
>      > to trace if an internal copy is done.
>
> Well, without using strange (;-) packages,  indeed standard R's
> tracemem(), notably the help page is a good pointer.
>
> According to the help page memory tracing is enabled in the
> default R binaries for Windows and OS X.
> For Linux (where I, as R developer, compile R myself anyway),
> one needs to configure with --enable-memory-profiling .
>
> Now, let's try:
>
>     > x <- array(rnorm(47), dim = c(1000,50, 40))
>     > tracemem(x)
>     [1] "<0x7f79a498a010>"
>     > dim(x) <- c(1000* 50, 40)
>     > x[5] <- pi
>     > tracemem(x)
>     [1] "<0x7f79a498a010>"
>     >
>
> So,*BOTH*   the re-dimensioning*AND*   the  sub-assignment did
> *NOT*  make a copy.

This is interesting. First I wanted to demonstrate to Roy that recent R 
versions are smart enough not to make any copy during reshaping an 
array. Then I put together an example (similar to yours) and realized 
that after several reshapes, R starts to copy the array. So I had to 
modify my suggestion... And now, I realized that this was an 
RStudio-issue. At least on Linux, a standard R terminal behaves as you 
described, however, RStudio (version 0.99.862, which is not the very 
latest) tends to create copies (quite randomly, at least to me). If I 
have time I will test this more thoroughly and file a report to RStudio 
if it turns out to be a bug.

Denes

>
> Indeed, R has become much smarter  in these things in recent
> years ... not thanks to me, but very much thanks to
> Luke Tierney (from R-core), and also thanks to contributions from "outside",
> notably Tomas Kalibera.
>
> And hence:*NO*  such strange workarounds are needed in this specific case:
>
>      > Workaround: use data.table::setattr or bit::setattr to modify the
>      > dimensions in place (i.e., without making a copy). Risk: if you modify
>      > an object by reference, all other objects which point to the same memory
>      > address will be modified silently, too.
>
> Martin Maechler, ETH Zurich  (and R-core)
>
>      > HTH,
>      > Denes
>
> (generally, your contributions help indeed, Denes, thank you!)
>
>
>      > On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>      >> Hi All:
>      >>
>      >> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>      >>
>      >> myData[noLat, no Lon, noTime].
>      >>
>      >> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>      >>
>      >> myData[noLat*noLon, noTime].  Normally this would be easy:
>      >>
>      >> myData<- array(myData,dim=c(noLat*noLon,noTime))
>      >>
>      >> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>      >>
>      >> Thanks,
>      >>
>      >> -Roy
>


From martin.morgan at roswellpark.org  Tue Mar 22 11:27:46 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 22 Mar 2016 06:27:46 -0400
Subject: [R] regex - extracting src url
In-Reply-To: <CAM-xyZhFJtxQcEwhYJRTGfuOxubsLcPK9463q1tSicXTupBMKQ@mail.gmail.com>
References: <CAM-xyZhFJtxQcEwhYJRTGfuOxubsLcPK9463q1tSicXTupBMKQ@mail.gmail.com>
Message-ID: <56F11E22.1090303@roswellpark.org>



On 03/22/2016 12:44 AM, Omar Andr? Gonz?les D?az wrote:
> Hi,I have a DF with a column with "html", like this:
>
> <IMG SRC="
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"
> BORDER="0" HEIGHT="1" WIDTH="1" ALT="Advertisement">
>
>
> I need to get this:
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
> ?
>
>
> I've got this so far:
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?\"
> BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement
>
>
> With this is the code I've used:
>
> carreras_normal$Impression.Tag..image. <-
> gsub("<img.+?src=[\"'](.*?)[\"'].*?>","\\1",carreras_normal$Impression.Tag..image.,
>                                    ignore.case = T)
>
>
>
> *But I still need to use get rid of this part:*
>
>
> https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=
> ?*\" BORDER=\"0\" HEIGHT=\"1\" WIDTH=\"1\" ALT=\"Advertisement*
>
>
> Thank you for your help.

You're querying an xml string, so use xpath, e.g., via the XML library

 > as.character(xmlParse(y)[["//IMG/@SRC"]])
[1] 
"https://ad.doubleclick.net/ddm/trackimp/N344006.1960500FACEBOOKAD/B9589414.130145906;dc_trk_aid=303019819;dc_trk_cid=69763238;ord=[timestamp];dc_lat=;dc_rdid=;tag_for_child_directed_treatment=?"

`xmlParse()` translates the character string into  an XML document. `[[` 
subsets the document to extract a single element. "//IMG/@SRC" follows 
the xpath specification (this section 
https://www.w3.org/TR/xpath-31/#abbrev of the specification provides a 
quick guide) to find, starting from the 'root' of the document, a node, 
at any depth, labeled IMG containing an attribute labeled SRC.

A variation, if there were several IMG tags to be extracted, would be

   xpathSApply(xmlParse(y), "//IMG/@SRC", as.character)

>
> Omar Gonz?les.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From mviljamaa at kapsi.fi  Tue Mar 22 13:04:19 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Tue, 22 Mar 2016 14:04:19 +0200
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
Message-ID: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>

I?m doing some optimisation that I first did with normal Poisson (only parameter theta was estimated), but now I?m doing the same with a zero-inflated Poisson model which
gives me two estimated parameters theta and p (p is also pi in some notation).

My question is, is there something equivalent to dpois that would use both of the parameters (or is the p parameter possibly unnecessary)?

I?m calculating the ?fit? of the Poisson model

i.e. like

x = c(0,1,2,3,4,5,6)
y = c(3062,587,284,103,33,4,2)
fit1 <- sum(y)*dpois(x, est_theta)

and then comparing fit1 to the real observations.
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 22 13:17:25 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 22 Mar 2016 13:17:25 +0100
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
Message-ID: <CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>

Dear Matti,

What about this?

dzeroinflpois <- function(x, lambda, zero){
  ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
}
plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:

> I?m doing some optimisation that I first did with normal Poisson (only
> parameter theta was estimated), but now I?m doing the same with a
> zero-inflated Poisson model which
> gives me two estimated parameters theta and p (p is also pi in some
> notation).
>
> My question is, is there something equivalent to dpois that would use both
> of the parameters (or is the p parameter possibly unnecessary)?
>
> I?m calculating the ?fit? of the Poisson model
>
> i.e. like
>
> x = c(0,1,2,3,4,5,6)
> y = c(3062,587,284,103,33,4,2)
> fit1 <- sum(y)*dpois(x, est_theta)
>
> and then comparing fit1 to the real observations.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Tue Mar 22 13:25:05 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Tue, 22 Mar 2016 14:25:05 +0200
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
Message-ID: <D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>

Could you clarify what are the parameters and why it?s formulated that way?

-Matti

> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Matti,
> 
> What about this?
> 
> dzeroinflpois <- function(x, lambda, zero){
>   ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
> }
> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
> 
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>>:
> I?m doing some optimisation that I first did with normal Poisson (only parameter theta was estimated), but now I?m doing the same with a zero-inflated Poisson model which
> gives me two estimated parameters theta and p (p is also pi in some notation).
> 
> My question is, is there something equivalent to dpois that would use both of the parameters (or is the p parameter possibly unnecessary)?
> 
> I?m calculating the ?fit? of the Poisson model
> 
> i.e. like
> 
> x = c(0,1,2,3,4,5,6)
> y = c(3062,587,284,103,33,4,2)
> fit1 <- sum(y)*dpois(x, est_theta)
> 
> and then comparing fit1 to the real observations.
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 22 13:30:44 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 22 Mar 2016 13:30:44 +0100
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
Message-ID: <CAJuCY5yfD9oPF+R5_G7sJBNk_mZO-YHw7pkpZJG8NjjbGwMj=A@mail.gmail.com>

zero = proportion of zero inflation part
lamba = expected value of poisson part

There was a typo in the distribution. It should multiple by (1 - zero)
instead of divide by it.

dzeroinflpois <- function(x, lambda, zero){
  ifelse(x == 0, zero, 0) + dpois(x, lambda) * (1 - zero)
}

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-22 13:25 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:

> Could you clarify what are the parameters and why it?s formulated that way?
>
> -Matti
>
> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Matti,
>
> What about this?
>
> dzeroinflpois <- function(x, lambda, zero){
>   ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
> }
> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>
>> I?m doing some optimisation that I first did with normal Poisson (only
>> parameter theta was estimated), but now I?m doing the same with a
>> zero-inflated Poisson model which
>> gives me two estimated parameters theta and p (p is also pi in some
>> notation).
>>
>> My question is, is there something equivalent to dpois that would use
>> both of the parameters (or is the p parameter possibly unnecessary)?
>>
>> I?m calculating the ?fit? of the Poisson model
>>
>> i.e. like
>>
>> x = c(0,1,2,3,4,5,6)
>> y = c(3062,587,284,103,33,4,2)
>> fit1 <- sum(y)*dpois(x, est_theta)
>>
>> and then comparing fit1 to the real observations.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Tue Mar 22 13:50:43 2016
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Tue, 22 Mar 2016 14:50:43 +0200
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
Message-ID: <76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>

And why is the first term of ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)

ifelse(x == 0, zero, 0)

rather than something corresponding to

zero+(1-zero)e^{-lambda}

https://en.wikipedia.org/wiki/Zero-inflated_model#Zero-inflated_Poisson

> On 22 Mar 2016, at 14:25, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
> 
> Could you clarify what are the parameters and why it?s formulated that way?
> 
> -Matti
> 
>> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>> wrote:
>> 
>> Dear Matti,
>> 
>> What about this?
>> 
>> dzeroinflpois <- function(x, lambda, zero){
>>   ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
>> }
>> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
>> 
>> 
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner 
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> 
>> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>>:
>> I?m doing some optimisation that I first did with normal Poisson (only parameter theta was estimated), but now I?m doing the same with a zero-inflated Poisson model which
>> gives me two estimated parameters theta and p (p is also pi in some notation).
>> 
>> My question is, is there something equivalent to dpois that would use both of the parameters (or is the p parameter possibly unnecessary)?
>> 
>> I?m calculating the ?fit? of the Poisson model
>> 
>> i.e. like
>> 
>> x = c(0,1,2,3,4,5,6)
>> y = c(3062,587,284,103,33,4,2)
>> fit1 <- sum(y)*dpois(x, est_theta)
>> 
>> and then comparing fit1 to the real observations.
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 22 13:58:09 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 22 Mar 2016 13:58:09 +0100
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
	<76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>
Message-ID: <CAJuCY5zdiNY1LyteoG=gZFA14aShpeM0yKLTEurPAZun5413ZQ@mail.gmail.com>

dpois(0, lambda) == e^(-lambda)

The wikipedia formula is
ifelse(x == 0, zero + dpois(0, lambda) * (1-zero), dpois(x, lambda) *
(1-zero))

or

ifelse(x == 0, zero + dpois(x, lambda) * (1-zero), dpois(x, lambda) *
(1-zero))

so we can move the dpois() out of the ifelse()

ifelse(x == 0, zero, 0)  + dpois(x, lambda) * (1-zero)



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-22 13:50 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:

> And why is the first term of ifelse(x == 0, zero, 0) + dpois(x, lambda) /
> (1 - zero)
>
> ifelse(x == 0, zero, 0)
>
> rather than something corresponding to
>
> zero+(1-zero)e^{-lambda}
>
> https://en.wikipedia.org/wiki/Zero-inflated_model#Zero-inflated_Poisson
>
> On 22 Mar 2016, at 14:25, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>
> Could you clarify what are the parameters and why it?s formulated that way?
>
> -Matti
>
> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Matti,
>
> What about this?
>
> dzeroinflpois <- function(x, lambda, zero){
>   ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
> }
> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>
>> I?m doing some optimisation that I first did with normal Poisson (only
>> parameter theta was estimated), but now I?m doing the same with a
>> zero-inflated Poisson model which
>> gives me two estimated parameters theta and p (p is also pi in some
>> notation).
>>
>> My question is, is there something equivalent to dpois that would use
>> both of the parameters (or is the p parameter possibly unnecessary)?
>>
>> I?m calculating the ?fit? of the Poisson model
>>
>> i.e. like
>>
>> x = c(0,1,2,3,4,5,6)
>> y = c(3062,587,284,103,33,4,2)
>> fit1 <- sum(y)*dpois(x, est_theta)
>>
>> and then comparing fit1 to the real observations.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Tue Mar 22 15:21:20 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 22 Mar 2016 07:21:20 -0700
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <56F116AE.20903@ttk.mta.hu>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<22257.3681.787925.965424@stat.math.ethz.ch>
	<56F116AE.20903@ttk.mta.hu>
Message-ID: <EE20290D-7D29-46F6-BB74-2978253D2B1A@noaa.gov>

Thanks all.  This is interesting, and for what I am doing worthwhile and helpful.  I have to be careful in each operation whether a copy is made or not,  and knowing this allows me to test on small examples what any command will do before I use,

Thanks again, I appreciate all the help.  I will have a related question, but will put it under a different heading.

-Roy
> On Mar 22, 2016, at 2:55 AM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
> 
> 
> Hi Martin,
> 
> 
> On 03/22/2016 10:20 AM, Martin Maechler wrote:
>>>>>>> >>>>>D?nes T?th<toth.denes at ttk.mta.hu>
>>>>>>> >>>>>     on Fri, 18 Mar 2016 22:56:23 +0100 writes:
>>     > Hi Roy,
>>     > R (usually) makes a copy if the dimensionality of an array is modified,
>>     > even if you use this syntax:
>> 
>>     > x <- array(1:24, c(2, 3, 4))
>>     > dim(x) <- c(6, 4)
>> 
>>     > See also ?tracemem, ?data.table::address, ?pryr::address and other tools
>>     > to trace if an internal copy is done.
>> 
>> Well, without using strange (;-) packages,  indeed standard R's
>> tracemem(), notably the help page is a good pointer.
>> 
>> According to the help page memory tracing is enabled in the
>> default R binaries for Windows and OS X.
>> For Linux (where I, as R developer, compile R myself anyway),
>> one needs to configure with --enable-memory-profiling .
>> 
>> Now, let's try:
>> 
>>    > x <- array(rnorm(47), dim = c(1000,50, 40))
>>    > tracemem(x)
>>    [1] "<0x7f79a498a010>"
>>    > dim(x) <- c(1000* 50, 40)
>>    > x[5] <- pi
>>    > tracemem(x)
>>    [1] "<0x7f79a498a010>"
>>    >
>> 
>> So,*BOTH*   the re-dimensioning*AND*   the  sub-assignment did
>> *NOT*  make a copy.
> 
> This is interesting. First I wanted to demonstrate to Roy that recent R versions are smart enough not to make any copy during reshaping an array. Then I put together an example (similar to yours) and realized that after several reshapes, R starts to copy the array. So I had to modify my suggestion... And now, I realized that this was an RStudio-issue. At least on Linux, a standard R terminal behaves as you described, however, RStudio (version 0.99.862, which is not the very latest) tends to create copies (quite randomly, at least to me). If I have time I will test this more thoroughly and file a report to RStudio if it turns out to be a bug.
> 
> Denes
> 
>> 
>> Indeed, R has become much smarter  in these things in recent
>> years ... not thanks to me, but very much thanks to
>> Luke Tierney (from R-core), and also thanks to contributions from "outside",
>> notably Tomas Kalibera.
>> 
>> And hence:*NO*  such strange workarounds are needed in this specific case:
>> 
>>     > Workaround: use data.table::setattr or bit::setattr to modify the
>>     > dimensions in place (i.e., without making a copy). Risk: if you modify
>>     > an object by reference, all other objects which point to the same memory
>>     > address will be modified silently, too.
>> 
>> Martin Maechler, ETH Zurich  (and R-core)
>> 
>>     > HTH,
>>     > Denes
>> 
>> (generally, your contributions help indeed, Denes, thank you!)
>> 
>> 
>>     > On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
>>     >> Hi All:
>>     >>
>>     >> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
>>     >>
>>     >> myData[noLat, no Lon, noTime].
>>     >>
>>     >> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
>>     >>
>>     >> myData[noLat*noLon, noTime].  Normally this would be easy:
>>     >>
>>     >> myData<- array(myData,dim=c(noLat*noLon,noTime))
>>     >>
>>     >> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
>>     >>
>>     >> Thanks,
>>     >>
>>     >> -Roy

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From roy.mendelssohn at noaa.gov  Tue Mar 22 15:42:10 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 22 Mar 2016 07:42:10 -0700
Subject: [R] Memory usage in prcomp
Message-ID: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>

Hi All:

I am running prcomp on a very large array, roughly [500000, 3650].  The array itself is 16GB.  I am running on a Unix machine and am running ?top? at the same time and am quite surprised to see that the application memory usage is 76GB.  I have the ?tol? set very high  (.8) so that it should only pull out a few components.  I am surprised at this memory usage because prcomp uses the SVD if I am not mistaken, and when I take guesses at the size of the SVD matrices they shouldn?t be that large.   While I can fit this  in, for a variety of reasons I would like to reduce the memory footprint.  She questions:

1.  I am running with ?center=FALSE? and ?scale=TRUE?.  Would I save memory if I scaled the data first myself, saved the result, cleared out the workspace, read the scaled data back in and did the prcomp call?  Basically are the intermediate calculations for scaling kept in memory after use.

2. I don?t know how prcomp memory usage compares to a direct call to ?svn? which allows me to explicitly set how many  singular vectors to compute (I only need like the first five at most).  prcomp is convenient because it does a lot of the other work for me


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From maechler at stat.math.ethz.ch  Tue Mar 22 18:00:27 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Mar 2016 18:00:27 +0100
Subject: [R] Memory usage in prcomp
In-Reply-To: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
Message-ID: <22257.31275.659023.572089@stat.math.ethz.ch>

>>>>> Roy Mendelssohn <- NOAA Federal <roy.mendelssohn at noaa.gov>>
>>>>>     on Tue, 22 Mar 2016 07:42:10 -0700 writes:

    > Hi All:
    > I am running prcomp on a very large array, roughly [500000, 3650].  The array itself is 16GB.  I am running on a Unix machine and am running ?top? at the same time and am quite surprised to see that the application memory usage is 76GB.  I have the ?tol? set very high  (.8) so that it should only pull out a few components.  I am surprised at this memory usage because prcomp uses the SVD if I am not mistaken, and when I take guesses at the size of the SVD matrices they shouldn?t be that large.   While I can fit this  in, for a variety of reasons I would like to reduce the memory footprint.  She questions:

    > 1.  I am running with ?center=FALSE? and ?scale=TRUE?.  Would I save memory if I scaled the data first myself, saved the result, cleared out the workspace, read the scaled data back in and did the prcomp call?  Basically are the intermediate calculations for scaling kept in memory after use.

    > 2. I don?t know how prcomp memory usage compares to a direct call to ?svn? which allows me to explicitly set how many  singular vectors to compute (I only need like the first five at most).  prcomp is convenient because it does a lot of the other work for me

For your example, where p := ncol(x)  is 3650  but you only want
the first 5 PCs, it would be *considerably* more efficient to
use svd(..., nv = 5) directly.

So I would take  stats:::prcomp.default  and modify it
correspondingly.

This seems such a useful idea in general that I consider
updating the function in R with a new optional 'rank.'  argument which
you'd set to 5 in your case.

Scrutinizing R's underlying svd() code however, I know see that
there are typicall still two other [n x p] matrices created (on
in R's La.svd(), one in C code) ... which I think should be
unnecessary in this case... but that would really be another
topic (for R-devel , not R-help).

Martin


From jan.kacaba at gmail.com  Tue Mar 22 18:08:26 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Tue, 22 Mar 2016 18:08:26 +0100
Subject: [R] R studio kniter
Message-ID: <CAHby=D35=ZayP2RyZ+eBTUWffO=y-h7wc-nJfDzD2vfZeaVBJg@mail.gmail.com>

Hello, is it possible to run kiniter by script instead by clicking on
button compile PDF?

Say I have "texfile.rnw" and "myscript.R". I would like to knit texfile.rnw
by runnig script "myscript.R".
In "myscript.R" I would write something like this:
knit("texfile.rnw")

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Mar 22 18:30:44 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 22 Mar 2016 13:30:44 -0400
Subject: [R] R studio kniter
In-Reply-To: <CAHby=D35=ZayP2RyZ+eBTUWffO=y-h7wc-nJfDzD2vfZeaVBJg@mail.gmail.com>
References: <CAHby=D35=ZayP2RyZ+eBTUWffO=y-h7wc-nJfDzD2vfZeaVBJg@mail.gmail.com>
Message-ID: <56F18144.8050801@gmail.com>

On 22/03/2016 1:08 PM, Jan Kacaba wrote:
> Hello, is it possible to run kiniter by script instead by clicking on
> button compile PDF?
>
> Say I have "texfile.rnw" and "myscript.R". I would like to knit texfile.rnw
> by runnig script "myscript.R".
> In "myscript.R" I would write something like this:
> knit("texfile.rnw")

That exact command works.  It will produce a .tex file; if you want to 
continue on to produce a PDF, you need

knit2pdf("texfile.rnw")

instead.

Duncan Murdoch


From roy.mendelssohn at noaa.gov  Tue Mar 22 18:36:33 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 22 Mar 2016 10:36:33 -0700
Subject: [R] Memory usage in prcomp
In-Reply-To: <22257.31275.659023.572089@stat.math.ethz.ch>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
Message-ID: <D9DC5E5C-80C1-4EF0-9022-B199D02D4710@noaa.gov>


> On Mar 22, 2016, at 10:00 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Roy Mendelssohn <- NOAA Federal <roy.mendelssohn at noaa.gov>>
>>>>>>    on Tue, 22 Mar 2016 07:42:10 -0700 writes:
> 
>> Hi All:
>> I am running prcomp on a very large array, roughly [500000, 3650].  The array itself is 16GB.  I am running on a Unix machine and am running ?top? at the same time and am quite surprised to see that the application memory usage is 76GB.  I have the ?tol? set very high  (.8) so that it should only pull out a few components.  I am surprised at this memory usage because prcomp uses the SVD if I am not mistaken, and when I take guesses at the size of the SVD matrices they shouldn?t be that large.   While I can fit this  in, for a variety of reasons I would like to reduce the memory footprint.  She questions:
> 
>> 1.  I am running with ?center=FALSE? and ?scale=TRUE?.  Would I save memory if I scaled the data first myself, saved the result, cleared out the workspace, read the scaled data back in and did the prcomp call?  Basically are the intermediate calculations for scaling kept in memory after use.
> 
>> 2. I don?t know how prcomp memory usage compares to a direct call to ?svn? which allows me to explicitly set how many  singular vectors to compute (I only need like the first five at most).  prcomp is convenient because it does a lot of the other work for me
> 
> For your example, where p := ncol(x)  is 3650  but you only want
> the first 5 PCs, it would be *considerably* more efficient to
> use svd(..., nv = 5) directly.
> 
> So I would take  stats:::prcomp.default  and modify it
> correspondingly.
> 
> This seems such a useful idea in general that I consider
> updating the function in R with a new optional 'rank.'  argument which
> you'd set to 5 in your case.
> 
> Scrutinizing R's underlying svd() code however, I know see that
> there are typicall still two other [n x p] matrices created (on
> in R's La.svd(), one in C code) ... which I think should be
> unnecessary in this case... but that would really be another
> topic (for R-devel , not R-help).
> 
> Martin
> 


Thanks.  It is easy enough to recode using SVN, and I think I will.    It gives me a ;title more control on what the algorithm does.

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ctstackh at uab.edu  Tue Mar 22 20:32:15 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Tue, 22 Mar 2016 19:32:15 +0000
Subject: [R] Help batch saving elements of a list into unique files
Message-ID: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>

Hello!


The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.


This is what I call to split up the original file:


out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)


I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt


Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."


If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!


Best,

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu<http://uab.edu/>
Knowledge that will change your world


	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Tue Mar 22 18:17:24 2016
From: eliza_botto at outlook.com (Eliza Botto)
Date: Tue, 22 Mar 2016 17:17:24 +0000
Subject: [R] arranging axis within plotting area
Message-ID: <SNT152-W88D5EA286CFBD0FA2F63CE9A800@phx.gbl>

Dear useRs,
I have defined two matrices "prop" and "ELE" in the following manner
> dput(prop)
structure(c(122.466666666667, 87.1500875, 94.3647755102041, 84.8471625, 95.2767755102041, 84.15558125, 121.846666666667, 90.75970625, 98.2028979591837, 87.1500875, 88.2953043478261, 72.81219375, 88.234, 85.73326875, 82.4549743589744, 82.6041125, 96.1123888888889, 62.77575625, 86.9222790697674, 64.74370625, 57.2601860465116, 58.98126875, 91.7883555555556, 84.8471625, 92.170347826087, 84.15558125, 91.398085106383, 91.79875, 108.423025641026, 72.81219375), .Dim = c(2L, 15L), .Dimnames = list(c("ori", "sat"), c("Ba", "Gd", "Ko", "Mu", "Mz", "Bg", "Do", "Gk", "Ka", "Mn", "Na", "Rw", "Rb", "Kh", "Sk")))
> dput(ELE)
c(995.4, 813.5, 614, 2291, 702, 1038, 2571, 461, 700, 171, 2500, 1615, 587, 1209, 1981)
Then I gave the following commands to make a plot
colours <- c("black", "grey")
barplot(prop,ylab = "Numbers", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours,ylim=c(0,250))
axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42), labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42), labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
par(new=TRUE)
barplot(ELE, pch=15,  xlab="", ylab="", 
    axes=FALSE, type="b", col="red",yaxt = "n",ylim = rev(c(0,4500)))
mtext("Cell Density",side=4,col="red",line=1) 
axis(4, ylim=c(0,7000), col="red",col.axis="red",las=1,cex.lab=0.5,cex.axis=0.7)
The problem is that the second Y-axis is somewhat located outside the plot and not visible. I kindly, require your help on it.
Thanks in advance,
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From jacob at forestlidar.org  Tue Mar 22 18:46:13 2016
From: jacob at forestlidar.org (jacob at forestlidar.org)
Date: Tue, 22 Mar 2016 13:46:13 -0400
Subject: [R] bug (?) with lapply / clusterMap / clusterApply etc
Message-ID: <20160322134613.Horde.DbR3Sc7N8pC0MCZ1r7v59s1@server194.web-hosting.com>


Hello I have encountered a bug(?) with the parallel package. When run  
from within a function, the parLapply function appears to be copying  
the entire parent environment (environment of interior of function)  
into all child nodes in the cluster, one node at a time - which is  
very very slow - and the copied contents are not even accessible  
within the child nodes even though they are apparent in the memory  
footprint. This happens when parLapply is run from within a function.  
I may be misusing the terms "parent" and "node" here...

The below code demonstrates the issue. The same parallel command is  
used twice within the function, once before creating a large object,  
and once afterwards. Both commands should take a nearly identical  
amount of time. Initially the parallel code takes less than 1/100th of  
a second, but in the second iteration requires hundreds of times  
longer...

Example Code:

      #create a cluster of nodes
      if(!"clus1" %in% ls()) clus1=makeCluster(10)

      #function used to demonstrate bug
      rows_fn1=function(x,clus){

          #first set of parallel code
           
print(system.time(parLapply(clus,1:5,function(z){y=rnorm(5000);return(mean(y))})))

          #create large vector
          x=rnorm(10^7)

          #second set
           
print(system.time(parLapply(clus,1:5,function(z){y=rnorm(5000);return(mean(y))})))

      }

      #demonstrate bug - watch task manager and see windows slowly  
copy the vector to each node in the cluster
      rows_fn1(1:5000,clus1)

Although the child nodes bloat proportionally to the size of x in the  
parent environment, x is not available in the child nodes. The code  
above can be tweaked to add more variables (x1,x2,x3 ...) and the  
child nodes will bloat to the same degree.

I am working on Windows Server 2012, I am using 64bit R version 3.2.1.  
I upgraded to 3.2.4revised and observed the same bug.

I have googled for this issue and have not encountered any other  
individuals having a similar problem.

I have attempted to reboot my machine without effect (aside from the obvious).

Any suggestions would be greatly appreciated!

With regards,

Jacob L Strunk
Forest Biometrician (PhD), Statistician (MSc)
and Data Munger


From kwannok.c at gmail.com  Tue Mar 22 05:04:08 2016
From: kwannok.c at gmail.com (Kwan Nok Chan)
Date: Tue, 22 Mar 2016 12:04:08 +0800
Subject: [R] splm: fixed effects for time-invariant variables
Message-ID: <CAGtX+Xb581LVbk45yL5RqwEHa4RDqe0_mNtsDPyMTDnLvjTjmw@mail.gmail.com>

Dear users:

Has anyone tried using splm to estimate a fixed effects model with one or
more time-invariant variables?

I may have missed something in the manual, but there isn't a clear way to
switch to estimators (e.g. first difference) suited for data like that in
splm.

My colleagues and I are very interested to include splm in the analysis
because spatial models in other mainstream programs do not support temporal
variance.

Best regards,

K Chan

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Mar 22 22:31:42 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 08:31:42 +1100
Subject: [R] arranging axis within plotting area
In-Reply-To: <SNT152-W88D5EA286CFBD0FA2F63CE9A800@phx.gbl>
References: <SNT152-W88D5EA286CFBD0FA2F63CE9A800@phx.gbl>
Message-ID: <CA+8X3fXh=WUfc=tA5U+oLLEDrK3jcei0=UOFFw2qdFWepUV1Mg@mail.gmail.com>

Hi Eliza,
I think you only need to change the margins and the placement of the
right axis label:

colours <- c("black", "grey")
par(mar=c(5,4,4,4))
barplot(prop,ylab = "Numbers", cex.lab = 1.5, cex.main = 1.4,
 beside=TRUE, col=colours,ylim=c(0,250))
axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42),
 labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42),
 labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
par(new=TRUE)
barplot(ELE, pch=15,  xlab="", ylab="",
 axes=FALSE, type="b", col="red",yaxt = "n",
 ylim = rev(c(0,4500)))
mtext("Cell Density",side=4,col="red",line=3)
axis(4, ylim=c(0,7000), col="red",col.axis="red",
 las=1,cex.lab=0.5,cex.axis=0.7)

Jim


On Wed, Mar 23, 2016 at 4:17 AM, Eliza Botto <eliza_botto at outlook.com> wrote:
> Dear useRs,
> I have defined two matrices "prop" and "ELE" in the following manner
>> dput(prop)
> structure(c(122.466666666667, 87.1500875, 94.3647755102041, 84.8471625, 95.2767755102041, 84.15558125, 121.846666666667, 90.75970625, 98.2028979591837, 87.1500875, 88.2953043478261, 72.81219375, 88.234, 85.73326875, 82.4549743589744, 82.6041125, 96.1123888888889, 62.77575625, 86.9222790697674, 64.74370625, 57.2601860465116, 58.98126875, 91.7883555555556, 84.8471625, 92.170347826087, 84.15558125, 91.398085106383, 91.79875, 108.423025641026, 72.81219375), .Dim = c(2L, 15L), .Dimnames = list(c("ori", "sat"), c("Ba", "Gd", "Ko", "Mu", "Mz", "Bg", "Do", "Gk", "Ka", "Mn", "Na", "Rw", "Rb", "Kh", "Sk")))
>> dput(ELE)
> c(995.4, 813.5, 614, 2291, 702, 1038, 2571, 461, 700, 171, 2500, 1615, 587, 1209, 1981)
> Then I gave the following commands to make a plot
> colours <- c("black", "grey")
> barplot(prop,ylab = "Numbers", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours,ylim=c(0,250))
> axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42), labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
> axis(side=3,xlim=c(0,45), at=c(6,12,18,24,30,36,42), labels=c("Gd","Mu","Bg","Gk","Mn","Rw","Kh"))
> par(new=TRUE)
> barplot(ELE, pch=15,  xlab="", ylab="",
>     axes=FALSE, type="b", col="red",yaxt = "n",ylim = rev(c(0,4500)))
> mtext("Cell Density",side=4,col="red",line=1)
> axis(4, ylim=c(0,7000), col="red",col.axis="red",las=1,cex.lab=0.5,cex.axis=0.7)
> The problem is that the second Y-axis is somewhat located outside the plot and not visible. I kindly, require your help on it.
> Thanks in advance,
> Eliza
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar 22 22:48:22 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 08:48:22 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>

Hi Christian,
This untested script might get you going (assuming you want a CSV format):

for(affdf in 1:length(out)) {
 names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
 write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

Jim


On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Hello!
>
>
> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>
>
> This is what I call to split up the original file:
>
>
> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>
>
> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>
>
> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>
>
> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu<http://uab.edu/>
> Knowledge that will change your world
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar 22 23:39:18 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 09:39:18 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>

Okay, I just snipped off the first token in the header labels assuming
that there would be no more periods. Try this:

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="."))
}
for(affdf in 1:length(out)) {
names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

Jim

On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Jim,
>
> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>
> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 4:48 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Hi Christian,
> This untested script might get you going (assuming you want a CSV format):
>
> for(affdf in 1:length(out)) {
>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> }
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Hello!
>>
>>
>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>
>>
>> This is what I call to split up the original file:
>>
>>
>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>
>>
>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>
>>
>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>
>>
>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu<http://uab.edu/>
>> Knowledge that will change your world
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar 22 23:46:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 09:46:55 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>

Sorry, should be:

names(out[[affdf]])<-
 lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)

Jim


On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Thank you, Jim. I got this error returned:
>
> Error in strsplit(names(out[[affdf]])) :
>   argument "split" is missing, with no default
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 5:39 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Okay, I just snipped off the first token in the header labels assuming
> that there would be no more periods. Try this:
>
> drop_token1<-function(x) {
>  return(paste(x[2:length(x)],sep="."))
> }
> for(affdf in 1:length(out)) {
> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> }
>
> Jim
>
> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Jim,
>>
>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>
>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 4:48 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Hi Christian,
>> This untested script might get you going (assuming you want a CSV format):
>>
>> for(affdf in 1:length(out)) {
>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> }
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Hello!
>>>
>>>
>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>
>>>
>>> This is what I call to split up the original file:
>>>
>>>
>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>
>>>
>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>
>>>
>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>
>>>
>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>
>>>
>>> Best,
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu<http://uab.edu/>
>>> Knowledge that will change your world
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Mar 23 00:02:46 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 10:02:46 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>

I think it's the "unlist". I can only test this with one set of made
up names at a time.

names(out[[affdf]])<-
 lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)

Jim


On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> This is what I ran:
>
>> drop_token1<-function(x) {
> +   return(paste(x[2:length(x)],sep="."))
> + }
>> for(affdf in 1:length(out)) {
> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> + }
> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>   'names' attribute [1148] must be the same length as the vector [118]
>>
>
> This is what the header was before:
>
> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>
> There was no output due to the error.
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 5:46 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Sorry, should be:
>
> names(out[[affdf]])<-
>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Thank you, Jim. I got this error returned:
>>
>> Error in strsplit(names(out[[affdf]])) :
>>   argument "split" is missing, with no default
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 5:39 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Okay, I just snipped off the first token in the header labels assuming
>> that there would be no more periods. Try this:
>>
>> drop_token1<-function(x) {
>>  return(paste(x[2:length(x)],sep="."))
>> }
>> for(affdf in 1:length(out)) {
>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> }
>>
>> Jim
>>
>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Jim,
>>>
>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>
>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>
>>> Best,
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Hi Christian,
>>> This untested script might get you going (assuming you want a CSV format):
>>>
>>> for(affdf in 1:length(out)) {
>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> }
>>>
>>> Jim
>>>
>>>
>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Hello!
>>>>
>>>>
>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>
>>>>
>>>> This is what I call to split up the original file:
>>>>
>>>>
>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>
>>>>
>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>
>>>>
>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>
>>>>
>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>
>>>>
>>>> Best,
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu<http://uab.edu/>
>>>> Knowledge that will change your world
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Mar 23 00:24:04 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 10:24:04 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
	<BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>

Transcription. I forgot the "collapse" argument when I wrote the email:

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="",collapse="."))
}

Jim


On Wed, Mar 23, 2016 at 10:14 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
>  For some reason, it's not concatenating.
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 6:02 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> I think it's the "unlist". I can only test this with one set of made
> up names at a time.
>
> names(out[[affdf]])<-
>  lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> This is what I ran:
>>
>>> drop_token1<-function(x) {
>> +   return(paste(x[2:length(x)],sep="."))
>> + }
>>> for(affdf in 1:length(out)) {
>> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> + }
>> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>>   'names' attribute [1148] must be the same length as the vector [118]
>>>
>>
>> This is what the header was before:
>>
>> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>
>> There was no output due to the error.
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 5:46 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Sorry, should be:
>>
>> names(out[[affdf]])<-
>>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Thank you, Jim. I got this error returned:
>>>
>>> Error in strsplit(names(out[[affdf]])) :
>>>   argument "split" is missing, with no default
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 5:39 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Okay, I just snipped off the first token in the header labels assuming
>>> that there would be no more periods. Try this:
>>>
>>> drop_token1<-function(x) {
>>>  return(paste(x[2:length(x)],sep="."))
>>> }
>>> for(affdf in 1:length(out)) {
>>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> }
>>>
>>> Jim
>>>
>>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Jim,
>>>>
>>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>
>>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>>
>>>> Best,
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu
>>>> Knowledge that will change your world
>>>>
>>>>
>>>> ________________________________________
>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>>> To: Christian T Stackhouse (Campus)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>
>>>> Hi Christian,
>>>> This untested script might get you going (assuming you want a CSV format):
>>>>
>>>> for(affdf in 1:length(out)) {
>>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>> }
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>>> <ctstackh at uab.edu> wrote:
>>>>> Hello!
>>>>>
>>>>>
>>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>>
>>>>>
>>>>> This is what I call to split up the original file:
>>>>>
>>>>>
>>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>>
>>>>>
>>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>>
>>>>>
>>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>>
>>>>>
>>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>>
>>>>>
>>>>> Best,
>>>>>
>>>>> Christian T. Stackhouse | Graduate Student
>>>>> GBS Neuroscience Theme
>>>>> Department of Neurosurgery
>>>>> Department of Radiation Oncology
>>>>> UAB | The University of Alabama at Birmingham
>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>
>>>>> uab.edu<http://uab.edu/>
>>>>> Knowledge that will change your world
>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Mar 23 02:46:42 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 23 Mar 2016 12:46:42 +1100
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <BLUPR0701MB197081C2695234CCAF1C5A64C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
	<BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>
	<BLUPR0701MB197081C2695234CCAF1C5A64C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fWudm0yx0XtxtcAAq9j7fY3h0xNFvZ0OnqF2BBrF5UDLg@mail.gmail.com>

Okay. Got some lunch, I can think about this with both halves of the brain.

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="",collapse="."))
}
affnames<-c("X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL",
 "X1.Classical.10.11.1_.HuEx.1_0.st.v2..CEL")
affnames.split<-strsplit(affnames,"[.]")
lapply(affnames.split,drop_token1)
[[1]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

[[2]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

This what I get with a toy example. So, I think that:

for(affdf in 1:length(out)) {
names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]),drop_token1)
write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

should work.

Jim


On Wed, Mar 23, 2016 at 11:16 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> I re ran it and this is what I got: 11.1_.HuEx.1_0.st.v2..CEL
> Should be: 10.11.1_.HuEx.1_0.st.v2..CEL
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 6:24 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Transcription. I forgot the "collapse" argument when I wrote the email:
>
> drop_token1<-function(x) {
>  return(paste(x[2:length(x)],sep="",collapse="."))
> }
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 10:14 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
>>  For some reason, it's not concatenating.
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 6:02 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> I think it's the "unlist". I can only test this with one set of made
>> up names at a time.
>>
>> names(out[[affdf]])<-
>>  lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> This is what I ran:
>>>
>>>> drop_token1<-function(x) {
>>> +   return(paste(x[2:length(x)],sep="."))
>>> + }
>>>> for(affdf in 1:length(out)) {
>>> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> + }
>>> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>>>   'names' attribute [1148] must be the same length as the vector [118]
>>>>
>>>
>>> This is what the header was before:
>>>
>>> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>
>>> There was no output due to the error.
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 5:46 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Sorry, should be:
>>>
>>> names(out[[affdf]])<-
>>>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>>
>>> Jim
>>>
>>>
>>> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Thank you, Jim. I got this error returned:
>>>>
>>>> Error in strsplit(names(out[[affdf]])) :
>>>>   argument "split" is missing, with no default
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu
>>>> Knowledge that will change your world
>>>>
>>>>
>>>> ________________________________________
>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>> Sent: Tuesday, March 22, 2016 5:39 PM
>>>> To: Christian T Stackhouse (Campus)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>
>>>> Okay, I just snipped off the first token in the header labels assuming
>>>> that there would be no more periods. Try this:
>>>>
>>>> drop_token1<-function(x) {
>>>>  return(paste(x[2:length(x)],sep="."))
>>>> }
>>>> for(affdf in 1:length(out)) {
>>>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>>>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>> }
>>>>
>>>> Jim
>>>>
>>>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>>>> <ctstackh at uab.edu> wrote:
>>>>> Jim,
>>>>>
>>>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>>
>>>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>>>
>>>>> Best,
>>>>>
>>>>> Christian T. Stackhouse | Graduate Student
>>>>> GBS Neuroscience Theme
>>>>> Department of Neurosurgery
>>>>> Department of Radiation Oncology
>>>>> UAB | The University of Alabama at Birmingham
>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>
>>>>> uab.edu
>>>>> Knowledge that will change your world
>>>>>
>>>>>
>>>>> ________________________________________
>>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>>>> To: Christian T Stackhouse (Campus)
>>>>> Cc: r-help at r-project.org
>>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>>
>>>>> Hi Christian,
>>>>> This untested script might get you going (assuming you want a CSV format):
>>>>>
>>>>> for(affdf in 1:length(out)) {
>>>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>>> }
>>>>>
>>>>> Jim
>>>>>
>>>>>
>>>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>>>> <ctstackh at uab.edu> wrote:
>>>>>> Hello!
>>>>>>
>>>>>>
>>>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>>>
>>>>>>
>>>>>> This is what I call to split up the original file:
>>>>>>
>>>>>>
>>>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>>>
>>>>>>
>>>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>>>
>>>>>>
>>>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>>>
>>>>>>
>>>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>>>
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Christian T. Stackhouse | Graduate Student
>>>>>> GBS Neuroscience Theme
>>>>>> Department of Neurosurgery
>>>>>> Department of Radiation Oncology
>>>>>> UAB | The University of Alabama at Birmingham
>>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>>
>>>>>> uab.edu<http://uab.edu/>
>>>>>> Knowledge that will change your world
>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.


From ctstackh at uab.edu  Tue Mar 22 23:13:27 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Tue, 22 Mar 2016 22:13:27 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
Message-ID: <BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>

Jim,

It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL

Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!

Best,

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 4:48 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Hi Christian,
This untested script might get you going (assuming you want a CSV format):

for(affdf in 1:length(out)) {
 names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
 write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

Jim


On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Hello!
>
>
> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>
>
> This is what I call to split up the original file:
>
>
> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>
>
> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>
>
> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>
>
> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu<http://uab.edu/>
> Knowledge that will change your world
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ctstackh at uab.edu  Tue Mar 22 23:43:12 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Tue, 22 Mar 2016 22:43:12 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
Message-ID: <BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>

Thank you, Jim. I got this error returned: 

Error in strsplit(names(out[[affdf]])) : 
  argument "split" is missing, with no default

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 5:39 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Okay, I just snipped off the first token in the header labels assuming
that there would be no more periods. Try this:

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="."))
}
for(affdf in 1:length(out)) {
names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

Jim

On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Jim,
>
> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>
> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 4:48 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Hi Christian,
> This untested script might get you going (assuming you want a CSV format):
>
> for(affdf in 1:length(out)) {
>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> }
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Hello!
>>
>>
>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>
>>
>> This is what I call to split up the original file:
>>
>>
>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>
>>
>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>
>>
>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>
>>
>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu<http://uab.edu/>
>> Knowledge that will change your world
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From ctstackh at uab.edu  Tue Mar 22 23:57:45 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Tue, 22 Mar 2016 22:57:45 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
Message-ID: <BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>

This is what I ran:

> drop_token1<-function(x) {
+   return(paste(x[2:length(x)],sep="."))
+ }
> for(affdf in 1:length(out)) {
+   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
+   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
+ }
Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  : 
  'names' attribute [1148] must be the same length as the vector [118]
> 

This is what the header was before:

X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL

There was no output due to the error.

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 5:46 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Sorry, should be:

names(out[[affdf]])<-
 lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)

Jim


On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Thank you, Jim. I got this error returned:
>
> Error in strsplit(names(out[[affdf]])) :
>   argument "split" is missing, with no default
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 5:39 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Okay, I just snipped off the first token in the header labels assuming
> that there would be no more periods. Try this:
>
> drop_token1<-function(x) {
>  return(paste(x[2:length(x)],sep="."))
> }
> for(affdf in 1:length(out)) {
> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> }
>
> Jim
>
> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Jim,
>>
>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>
>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 4:48 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Hi Christian,
>> This untested script might get you going (assuming you want a CSV format):
>>
>> for(affdf in 1:length(out)) {
>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> }
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Hello!
>>>
>>>
>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>
>>>
>>> This is what I call to split up the original file:
>>>
>>>
>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>
>>>
>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>
>>>
>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>
>>>
>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>
>>>
>>> Best,
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu<http://uab.edu/>
>>> Knowledge that will change your world
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

From ctstackh at uab.edu  Wed Mar 23 00:14:57 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Tue, 22 Mar 2016 23:14:57 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
Message-ID: <BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>

Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
 For some reason, it's not concatenating.

Best,

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 6:02 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

I think it's the "unlist". I can only test this with one set of made
up names at a time.

names(out[[affdf]])<-
 lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)

Jim


On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> This is what I ran:
>
>> drop_token1<-function(x) {
> +   return(paste(x[2:length(x)],sep="."))
> + }
>> for(affdf in 1:length(out)) {
> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
> + }
> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>   'names' attribute [1148] must be the same length as the vector [118]
>>
>
> This is what the header was before:
>
> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>
> There was no output due to the error.
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 5:46 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Sorry, should be:
>
> names(out[[affdf]])<-
>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Thank you, Jim. I got this error returned:
>>
>> Error in strsplit(names(out[[affdf]])) :
>>   argument "split" is missing, with no default
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 5:39 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Okay, I just snipped off the first token in the header labels assuming
>> that there would be no more periods. Try this:
>>
>> drop_token1<-function(x) {
>>  return(paste(x[2:length(x)],sep="."))
>> }
>> for(affdf in 1:length(out)) {
>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> }
>>
>> Jim
>>
>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Jim,
>>>
>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>
>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>
>>> Best,
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Hi Christian,
>>> This untested script might get you going (assuming you want a CSV format):
>>>
>>> for(affdf in 1:length(out)) {
>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> }
>>>
>>> Jim
>>>
>>>
>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Hello!
>>>>
>>>>
>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>
>>>>
>>>> This is what I call to split up the original file:
>>>>
>>>>
>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>
>>>>
>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>
>>>>
>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>
>>>>
>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>
>>>>
>>>> Best,
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu<http://uab.edu/>
>>>> Knowledge that will change your world
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From ctstackh at uab.edu  Wed Mar 23 01:16:26 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Wed, 23 Mar 2016 00:16:26 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
	<BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>
Message-ID: <BLUPR0701MB197081C2695234CCAF1C5A64C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>

I re ran it and this is what I got: 11.1_.HuEx.1_0.st.v2..CEL
Should be: 10.11.1_.HuEx.1_0.st.v2..CEL

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 6:24 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Transcription. I forgot the "collapse" argument when I wrote the email:

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="",collapse="."))
}

Jim


On Wed, Mar 23, 2016 at 10:14 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
>  For some reason, it's not concatenating.
>
> Best,
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 6:02 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> I think it's the "unlist". I can only test this with one set of made
> up names at a time.
>
> names(out[[affdf]])<-
>  lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> This is what I ran:
>>
>>> drop_token1<-function(x) {
>> +   return(paste(x[2:length(x)],sep="."))
>> + }
>>> for(affdf in 1:length(out)) {
>> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>> + }
>> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>>   'names' attribute [1148] must be the same length as the vector [118]
>>>
>>
>> This is what the header was before:
>>
>> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>
>> There was no output due to the error.
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 5:46 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> Sorry, should be:
>>
>> names(out[[affdf]])<-
>>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> Thank you, Jim. I got this error returned:
>>>
>>> Error in strsplit(names(out[[affdf]])) :
>>>   argument "split" is missing, with no default
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 5:39 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Okay, I just snipped off the first token in the header labels assuming
>>> that there would be no more periods. Try this:
>>>
>>> drop_token1<-function(x) {
>>>  return(paste(x[2:length(x)],sep="."))
>>> }
>>> for(affdf in 1:length(out)) {
>>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> }
>>>
>>> Jim
>>>
>>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Jim,
>>>>
>>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>
>>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>>
>>>> Best,
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu
>>>> Knowledge that will change your world
>>>>
>>>>
>>>> ________________________________________
>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>>> To: Christian T Stackhouse (Campus)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>
>>>> Hi Christian,
>>>> This untested script might get you going (assuming you want a CSV format):
>>>>
>>>> for(affdf in 1:length(out)) {
>>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>> }
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>>> <ctstackh at uab.edu> wrote:
>>>>> Hello!
>>>>>
>>>>>
>>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>>
>>>>>
>>>>> This is what I call to split up the original file:
>>>>>
>>>>>
>>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>>
>>>>>
>>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>>
>>>>>
>>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>>
>>>>>
>>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>>
>>>>>
>>>>> Best,
>>>>>
>>>>> Christian T. Stackhouse | Graduate Student
>>>>> GBS Neuroscience Theme
>>>>> Department of Neurosurgery
>>>>> Department of Radiation Oncology
>>>>> UAB | The University of Alabama at Birmingham
>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>
>>>>> uab.edu<http://uab.edu/>
>>>>> Knowledge that will change your world
>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.

From ctstackh at uab.edu  Wed Mar 23 03:59:41 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Wed, 23 Mar 2016 02:59:41 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fWudm0yx0XtxtcAAq9j7fY3h0xNFvZ0OnqF2BBrF5UDLg@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
	<BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>
	<BLUPR0701MB197081C2695234CCAF1C5A64C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fWudm0yx0XtxtcAAq9j7fY3h0xNFvZ0OnqF2BBrF5UDLg@mail.gmail.com>
Message-ID: <BLUPR0701MB197093F3F7C5514349C772B9C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>

I ran:

drop_token1<-function(x) {
  return(paste(x[2:length(x)],sep="",collapse="."))
}
for(affdf in 1:length(out)) {
  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

I got the files out with headers:

10.11.1_.HuEx.1_0.st.v2..CEL

Minus the first two tokens (X0. and Classical.)

I really appreciate you helping me with this. I'd never have figured this out  in a timely manner.

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 8:46 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Okay. Got some lunch, I can think about this with both halves of the brain.

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="",collapse="."))
}
affnames<-c("X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL",
 "X1.Classical.10.11.1_.HuEx.1_0.st.v2..CEL")
affnames.split<-strsplit(affnames,"[.]")
lapply(affnames.split,drop_token1)
[[1]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

[[2]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

This what I get with a toy example. So, I think that:

for(affdf in 1:length(out)) {
names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]),drop_token1)
write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

should work.

Jim


On Wed, Mar 23, 2016 at 11:16 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> I re ran it and this is what I got: 11.1_.HuEx.1_0.st.v2..CEL
> Should be: 10.11.1_.HuEx.1_0.st.v2..CEL
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 6:24 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Transcription. I forgot the "collapse" argument when I wrote the email:
>
> drop_token1<-function(x) {
>  return(paste(x[2:length(x)],sep="",collapse="."))
> }
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 10:14 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
>>  For some reason, it's not concatenating.
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 6:02 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> I think it's the "unlist". I can only test this with one set of made
>> up names at a time.
>>
>> names(out[[affdf]])<-
>>  lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> This is what I ran:
>>>
>>>> drop_token1<-function(x) {
>>> +   return(paste(x[2:length(x)],sep="."))
>>> + }
>>>> for(affdf in 1:length(out)) {
>>> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> + }
>>> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>>>   'names' attribute [1148] must be the same length as the vector [118]
>>>>
>>>
>>> This is what the header was before:
>>>
>>> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>
>>> There was no output due to the error.
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 5:46 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Sorry, should be:
>>>
>>> names(out[[affdf]])<-
>>>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>>
>>> Jim
>>>
>>>
>>> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Thank you, Jim. I got this error returned:
>>>>
>>>> Error in strsplit(names(out[[affdf]])) :
>>>>   argument "split" is missing, with no default
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu
>>>> Knowledge that will change your world
>>>>
>>>>
>>>> ________________________________________
>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>> Sent: Tuesday, March 22, 2016 5:39 PM
>>>> To: Christian T Stackhouse (Campus)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>
>>>> Okay, I just snipped off the first token in the header labels assuming
>>>> that there would be no more periods. Try this:
>>>>
>>>> drop_token1<-function(x) {
>>>>  return(paste(x[2:length(x)],sep="."))
>>>> }
>>>> for(affdf in 1:length(out)) {
>>>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>>>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>> }
>>>>
>>>> Jim
>>>>
>>>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>>>> <ctstackh at uab.edu> wrote:
>>>>> Jim,
>>>>>
>>>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>>
>>>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>>>
>>>>> Best,
>>>>>
>>>>> Christian T. Stackhouse | Graduate Student
>>>>> GBS Neuroscience Theme
>>>>> Department of Neurosurgery
>>>>> Department of Radiation Oncology
>>>>> UAB | The University of Alabama at Birmingham
>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>
>>>>> uab.edu
>>>>> Knowledge that will change your world
>>>>>
>>>>>
>>>>> ________________________________________
>>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>>>> To: Christian T Stackhouse (Campus)
>>>>> Cc: r-help at r-project.org
>>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>>
>>>>> Hi Christian,
>>>>> This untested script might get you going (assuming you want a CSV format):
>>>>>
>>>>> for(affdf in 1:length(out)) {
>>>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>>> }
>>>>>
>>>>> Jim
>>>>>
>>>>>
>>>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>>>> <ctstackh at uab.edu> wrote:
>>>>>> Hello!
>>>>>>
>>>>>>
>>>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>>>
>>>>>>
>>>>>> This is what I call to split up the original file:
>>>>>>
>>>>>>
>>>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>>>
>>>>>>
>>>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>>>
>>>>>>
>>>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>>>
>>>>>>
>>>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>>>
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Christian T. Stackhouse | Graduate Student
>>>>>> GBS Neuroscience Theme
>>>>>> Department of Neurosurgery
>>>>>> Department of Radiation Oncology
>>>>>> UAB | The University of Alabama at Birmingham
>>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>>
>>>>>> uab.edu<http://uab.edu/>
>>>>>> Knowledge that will change your world
>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.

From urs at kleinholdermann.de  Tue Mar 22 22:36:54 2016
From: urs at kleinholdermann.de (urs)
Date: Tue, 22 Mar 2016 22:36:54 +0100
Subject: [R] How to extend an existing linear mixed effects model using lme
	in R?
Message-ID: <56F1BAF6.3090306@kleinholdermann.de>

Dear list,

I fitted a linear mixed effects model using lme in R on a relatively 
large data set. Now I want to extend this model, introducing an 
additional fixed effect on a subset of the data without altering 
coefficients estimated on the original dataset. I.e.

original model for example:
m1 = lme(y~a+b,random=~1|id,data=D)

now I want to do something similiar to
m2 = update(m1,~.+c,data=d)

Where d is a subset of D. The values of the new predictor c are only 
available for this subset. However, I would like to keep the originally 
estimated coefficients of the model m1 with regard to predictors a and 
b. If I use update as described above coefficients for all predictors 
(a,b,c) are estimated again on the smaller dataset d. Any suggestions on 
how I can estimate the effect of c while keeping the old coefficient 
values for a and b? Or is this for some reason a bad idea altogether?

Urs


From catalinroibu at gmail.com  Wed Mar 23 10:36:58 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Wed, 23 Mar 2016 11:36:58 +0200
Subject: [R] adding points in plot loop
Message-ID: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>

Dear R users,

I have a dataframe with 6 columns and I want to create a plot (with for
loop). My question is how to add points in the for loop? I tried this code,
but without success.

vv<-rbind(colnames(ext))
for(i in 1:ncol(vv)){
  with(ext, plot(rownames(ext), ext[,i], type="p",las=1,
bty="n",cex.main=2, cex.axis=1.5))
}

Please help me to solve that!

Best regards!

CR


-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 23 10:55:43 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Mar 2016 05:55:43 -0400
Subject: [R] adding points in plot loop
In-Reply-To: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>
References: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>
Message-ID: <56F2681F.2060106@gmail.com>

On 23/03/2016 5:36 AM, catalin roibu wrote:
> Dear R users,
>
> I have a dataframe with 6 columns and I want to create a plot (with for
> loop). My question is how to add points in the for loop? I tried this code,
> but without success.
>
> vv<-rbind(colnames(ext))
> for(i in 1:ncol(vv)){
>    with(ext, plot(rownames(ext), ext[,i], type="p",las=1,
> bty="n",cex.main=2, cex.axis=1.5))
> }
>
> Please help me to solve that!

You can call the points() function to add points to an existing plot. 
The main difficulty is that the initial call to plot() establishes the 
axes and coordinate system; if later points fall outside the plot area, 
they won't be shown.  So you may need to work out xlim and ylim in advance.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Wed Mar 23 12:29:52 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Mar 2016 12:29:52 +0100
Subject: [R] adding points in plot loop --> try using matplot() !
In-Reply-To: <56F2681F.2060106@gmail.com>
References: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>
	<56F2681F.2060106@gmail.com>
Message-ID: <22258.32304.283721.172001@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Wed, 23 Mar 2016 05:55:43 -0400 writes:

    > On 23/03/2016 5:36 AM, catalin roibu wrote:
    >> Dear R users,
    >> 
    >> I have a dataframe with 6 columns and I want to create a plot (with for
    >> loop). My question is how to add points in the for loop? I tried this code,
    >> but without success.
    >> 
    >> vv<-rbind(colnames(ext))
    >> for(i in 1:ncol(vv)){
    >> with(ext, plot(rownames(ext), ext[,i], type="p",las=1,
    >> bty="n",cex.main=2, cex.axis=1.5))
    >> }
    >> 
    >> Please help me to solve that!

    > You can call the points() function to add points to an existing plot. 
    > The main difficulty is that the initial call to plot() establishes the 
    > axes and coordinate system; if later points fall outside the plot area, 
    > they won't be shown.  So you may need to work out xlim and ylim in advance.

Indeed!  ... and that's why R has inherited the  matplot() / matlines()
utility functions from S for about 20 years now. These do plot
all the columns of a numeric matrix and solve the xlim/ylim problem for you.

As the above R code is not reproducible (we do not have your 'ext'), 
I have not tried if your use of "rownames"/"colnames" is easily
portable to matplot.  If not (which I doubt), just take
matplot() as a template to writer your own function.
BTW: Your usage of  with(.) seems entirely unnecessary ..

Martin Maechler


From petr.pikal at precheza.cz  Wed Mar 23 13:47:38 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 23 Mar 2016 12:47:38 +0000
Subject: [R] adding points in plot loop
In-Reply-To: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>
References: <CAEW+BDJnp93q6Mubd2vGKhn1o0b21OOadyGcwn84WsgoHpa3sw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5015A7D@SRVEXCHMBX.precheza.cz>

Hi

Anothar approach is to reshape your ext data frame

As you did not show your data I use my own.

> dput(mikro)
structure(list(cas = c(0L, 2L, 3L, 5L, 6L, 8L, 9L, 10L, 12L,
17L, 23L), zr = c(0.19, 0.115, 0.073, 0.068, 0.052, 0.055, 0.048,
0.047, 0.047, 0.045, 0.045), zrred = c(0.145, 0.07, 0.028, 0.023,
0.007, 0.01, 0.003, 0.002, 0.002, 0, 0), drt = c(0.397260273972603,
0.191780821917808, 0.0767123287671233, 0.063013698630137, 0.0191780821917808,
0.0273972602739726, 0.00821917808219179, 0.00547945205479452,
0.00547945205479452, 0, 0), drtf = c(0, 0.589041095890411, 0.723287671232877,
0.863013698630137, 0.904109589041096, 0.950684931506849, 0.968493150684931,
0.975342465753425, 0.986301369863014, 1, 1)), .Names = c("cas",
"zr", "zrred", "drt", "drtf"), row.names = c(NA, -11L), class = "data.frame")
>

library(reshape2)
mikro.m<-melt(mikro, id.vars="cas")
plot(mikro.m$cas, mikro.m$value, type="n")
points(mikro.m$cas, mikro.m$value, pch=as.numeric(mikro.m$variable))

Or you can use ggplot.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of catalin
> roibu
> Sent: Wednesday, March 23, 2016 10:37 AM
> To: R Project Help
> Subject: [R] adding points in plot loop
>
> Dear R users,
>
> I have a dataframe with 6 columns and I want to create a plot (with for
> loop). My question is how to add points in the for loop? I tried this
> code, but without success.
>
> vv<-rbind(colnames(ext))
> for(i in 1:ncol(vv)){
>   with(ext, plot(rownames(ext), ext[,i], type="p",las=1,
> bty="n",cex.main=2, cex.axis=1.5)) }
>
> Please help me to solve that!
>
> Best regards!
>
> CR
>
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Wed Mar 23 15:46:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 23 Mar 2016 07:46:43 -0700
Subject: [R] How to extend an existing linear mixed effects model using
 lme in R?
In-Reply-To: <56F1BAF6.3090306@kleinholdermann.de>
References: <56F1BAF6.3090306@kleinholdermann.de>
Message-ID: <CAGxFJbS7HdP0NmgDxAPgV8ET0bhB1MQJ1ppFD_cqDFTy11A2LQ@mail.gmail.com>

You should post this on the mixed models list instead of here:

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 22, 2016 at 2:36 PM, urs <urs at kleinholdermann.de> wrote:
> Dear list,
>
> I fitted a linear mixed effects model using lme in R on a relatively large
> data set. Now I want to extend this model, introducing an additional fixed
> effect on a subset of the data without altering coefficients estimated on
> the original dataset. I.e.
>
> original model for example:
> m1 = lme(y~a+b,random=~1|id,data=D)
>
> now I want to do something similiar to
> m2 = update(m1,~.+c,data=d)
>
> Where d is a subset of D. The values of the new predictor c are only
> available for this subset. However, I would like to keep the originally
> estimated coefficients of the model m1 with regard to predictors a and b. If
> I use update as described above coefficients for all predictors (a,b,c) are
> estimated again on the smaller dataset d. Any suggestions on how I can
> estimate the effect of c while keeping the old coefficient values for a and
> b? Or is this for some reason a bad idea altogether?
>
> Urs
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Wed Mar 23 16:15:26 2016
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 23 Mar 2016 09:15:26 -0600
Subject: [R] summation involving multiple summations
In-Reply-To: <1301609081.1165799.1458393458601.JavaMail.yahoo@mail.yahoo.com>
References: <1301609081.1165799.1458393458601.JavaMail.yahoo.ref@mail.yahoo.com>
	<1301609081.1165799.1458393458601.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAFEqCdxdG5DMMM+9C7SfRvRq-OTcYE8iWP7qPM0T-AtU5WxFyQ@mail.gmail.com>

You can create a list of functions then use subscripting.  E.g.:

funvec <- c(sin, cos, tan)

for(i in 1:3) {
 print(funvec[[i]](pi/6))
}

Just create the list with the different functions that you want to
call, then subscript that list with your n_r variable.

You can also look at ?switch, but I think the list of functions may
work better for you.


On Sat, Mar 19, 2016 at 7:17 AM, Mahmoud via R-help
<r-help at r-project.org> wrote:
> Dear R Experts
>
> I've a function which involves multiple summations, and the number of summations depends on a
> random variable named (n-r), where n is known but r is random and r<n.
>
> So, if , for example , n-r=3, the function is:
>
>>n_r=3
>>fx=function(x)sum(sapply(1:n_r, function(j1) {sum(sapply(1:(j1), function(j2){sum(sapply(1:(j2), function(j3){(j1>j2)*(j2>j3)/(x+exp(tc[j1]+tc[j2]+tc[j3])^4}))}))}))}
>
> The value of r will be generated from a simulation process, so in one iteration r may be equal to 0, and in another iteration it might be equal to 2 and so on, and accordingly  (n-r) is either 1, 2, or 3. And this makes the body of the summation different every time.
>
>
> Here's my  trail code in the simple case when n=3:
>
> library(nleqslv)
> N=100;n=3
> a=matrix(0,nrow=N,ncol=1)
> for(i in 1:N){
> tc=matrix(0, nrow=n, ncol=1)
> t=matrix(0, nrow=n, ncol=1)
> c=matrix(0,nrow=n,ncol=1)
> for(j in 1: n){
> t[j]=rexp(1,rate=3)
>
> c[j]=rexp(1, rate =2)
> if (t[j]>=c[j]) {tc[j]=t[j]}
> }
> n_r=nrow(tc)
> if(n_r==1){fx=function(x)sum(sapply(1:n-3, function(j1){1/(x+exp(tc[j1]))^4}))
> a[i]=nleqslv(0.5, fx)$x
> }
> if(n_r==2){fx=function(x)sum(sapply(1:n-2, function(j1){sum(sapply(1:(j1),function(j2){(j1>j2)/(x+exp(tc[j1]+tc[j2]))^4}))}))
> a[i]=nleqslv(0.5, fx)$x
> }
> if(n_r==3){fx=function(x)sum(sapply(1:n, function(j1) {sum(sapply(1:(j1), function(j2){sum(sapply(1:(j2),
> function(j3){(j1>j2)*(j2>j3)/(x+exp(tc[j1]+tc[j2]+tc[j3]))^4}))}))}))
> a[i]=nleqslv(0.5, fx)$x
> }
> }
>
> Is there any other way to write a loop that could be executed for any value of r instead of putting the if ()  statement for each single value of r , as n may take large values reaching 30, for instance.
>
> Any help or recommendation for a reference that can help me would be appreciated .
> Thank you
> Mahmoud Farid
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From maechler at stat.math.ethz.ch  Wed Mar 23 16:27:33 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Mar 2016 16:27:33 +0100
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <CAJuCY5zdiNY1LyteoG=gZFA14aShpeM0yKLTEurPAZun5413ZQ@mail.gmail.com>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
	<76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>
	<CAJuCY5zdiNY1LyteoG=gZFA14aShpeM0yKLTEurPAZun5413ZQ@mail.gmail.com>
Message-ID: <22258.46565.245172.694785@stat.math.ethz.ch>

>>>>> Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>>>     on Tue, 22 Mar 2016 13:58:09 +0100 writes:

    > dpois(0, lambda) == e^(-lambda)
    > The wikipedia formula is
    > ifelse(x == 0, zero + dpois(0, lambda) * (1-zero), dpois(x, lambda) *
    > (1-zero))

    > or

    > ifelse(x == 0, zero + dpois(x, lambda) * (1-zero), dpois(x, lambda) *
    > (1-zero))

    > so we can move the dpois() out of the ifelse()

    > ifelse(x == 0, zero, 0)  + dpois(x, lambda) * (1-zero)

Nice!  Thank you, Thierry.

Even nicer for symmetry reasons (and much faster) is *not* to use ifelse(), 
so we'd get

dzipois <- function(x, lambda, zero)
  (x == 0) * zero +  dpois(x, lambda) * (1-zero)

However, numerically correctly adding the  'log = FALSE'
argument which all good "density" functions have in R --
((and which you *should* use as  log = TRUE  for the
  log-likelihood if you want to become more professional))
is a bit tricky.

The x == 0 case at least needs care for large lambda and/or
small 'zero' (= pi).
All this is related on how to accurately compute  f(L) = log(1 - exp(- L))
which I call   log1mexp(L) in my still-not-submitted paper
available as one of the Rmpfr vignettes at
https://cloud.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf

BTW:  There are at least 3-4 R packages which deal with zero-inflated
      poisson in some ways, notably the recommended  'mgcv'
      package which comes bundled with every R.


Martin Maechler,
ETH ZUrich

    > ir. Thierry Onkelinx
    > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
    > Forest
    > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
    > Kliniekstraat 25
    > 1070 Anderlecht
    > Belgium

    > To call in the statistician after the experiment is done may be no more
    > than asking him to perform a post-mortem examination: he may be able to say
    > what the experiment died of. ~ Sir Ronald Aylmer Fisher
    > The plural of anecdote is not data. ~ Roger Brinner
    > The combination of some data and an aching desire for an answer does not
    > ensure that a reasonable answer can be extracted from a given body of data.
    > ~ John Tukey

    > 2016-03-22 13:50 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:

    >> And why is the first term of ifelse(x == 0, zero, 0) + dpois(x, lambda) /
    >> (1 - zero)
    >> 
    >> ifelse(x == 0, zero, 0)
    >> 
    >> rather than something corresponding to
    >> 
    >> zero+(1-zero)e^{-lambda}
    >> 
    >> https://en.wikipedia.org/wiki/Zero-inflated_model#Zero-inflated_Poisson
    >> 
    >> On 22 Mar 2016, at 14:25, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
    >> 
    >> Could you clarify what are the parameters and why it?s formulated that way?
    >> 
    >> -Matti
    >> 
    >> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be>
    >> wrote:
    >> 
    >> Dear Matti,
    >> 
    >> What about this?
    >> 
    >> dzeroinflpois <- function(x, lambda, zero){
    >> ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
    >> }
    >> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
    >> 
    >> 
    >> 
    >> ir. Thierry Onkelinx
    >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
    >> Forest
    >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
    >> Kliniekstraat 25
    >> 1070 Anderlecht
    >> Belgium
    >> 
    >> To call in the statistician after the experiment is done may be no more
    >> than asking him to perform a post-mortem examination: he may be able to say
    >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
    >> The plural of anecdote is not data. ~ Roger Brinner
    >> The combination of some data and an aching desire for an answer does not
    >> ensure that a reasonable answer can be extracted from a given body of data.
    >> ~ John Tukey
    >> 
    >> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
    >> 
    >>> I?m doing some optimisation that I first did with normal Poisson (only
    >>> parameter theta was estimated), but now I?m doing the same with a
    >>> zero-inflated Poisson model which
    >>> gives me two estimated parameters theta and p (p is also pi in some
    >>> notation).
    >>> 
    >>> My question is, is there something equivalent to dpois that would use
    >>> both of the parameters (or is the p parameter possibly unnecessary)?
    >>> 
    >>> I?m calculating the ?fit? of the Poisson model
    >>> 
    >>> i.e. like
    >>> 
    >>> x = c(0,1,2,3,4,5,6)
    >>> y = c(3062,587,284,103,33,4,2)
    >>> fit1 <- sum(y)*dpois(x, est_theta)
    >>> 
    >>> and then comparing fit1 to the real observations.
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide
    >>> http://www.R-project.org/posting-guide.html
    >>> <http://www.r-project.org/posting-guide.html>
    >>> and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> 
    >> 
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Wed Mar 23 17:25:22 2016
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 23 Mar 2016 10:25:22 -0600
Subject: [R] Persistent state in a function?
In-Reply-To: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
Message-ID: <CAFEqCdzV1NA=uvKrt6Dg3tVn74_wUttuYwch6e6cHmQoZjTjHQ@mail.gmail.com>

Boris,

You may want to look into the R6 package.  This package has tools that
help create objects (environments) with methods that can use and
change the object.  You can have your persistent table stored as part
of your object and then create methods that will use and modify the
table within the object.

On Sat, Mar 19, 2016 at 10:45 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Dear all -
>
> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>  -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>  -B- how can I store and reload such table?
>  -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>
>
> For illustration ...
>
> -----------------------------------
>
> myDist <- function(a, b) {
>     # retrieve or calculate distances
>     if (!exists("Vals")) {
>         Vals <<- numeric() # the lookup table for distance values
>                            # here, created in the global env.
>     }
>     key <- sprintf("X%d.%d", a, b)
>     thisDist <- Vals[key]
>     if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>         cat("Calculating ... ")
>         thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>         Vals[key] <<- thisDist      # store in global table
>     }
>     return(thisDist)
> }
>
>
> # run this
> set.seed(112358)
>
> for (i in 1:10) {
>     x <- sample(1:3, 2)
>     print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> }
>
>
> Thanks!
> Boris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jacob at forestlidar.org  Wed Mar 23 17:54:59 2016
From: jacob at forestlidar.org (jacob at forestlidar.org)
Date: Wed, 23 Mar 2016 12:54:59 -0400
Subject: [R] bug (?) with lapply / clusterMap / clusterApply etc
In-Reply-To: <56F1E774.6030408@roswellpark.org>
References: <20160322134613.Horde.DbR3Sc7N8pC0MCZ1r7v59s1@server194.web-hosting.com>
	<56F1E774.6030408@roswellpark.org>
Message-ID: <20160323125459.Horde.Ivzq_n6Ro0n0WmmwAUNq5ub@server194.web-hosting.com>

Very informative! Thank you.

Quoting Martin Morgan <martin.morgan at roswellpark.org>:

> On 03/22/2016 01:46 PM, jacob at forestlidar.org wrote:
>>
>> Hello I have encountered a bug(?) with the parallel package. When run
>> from within a function, the parLapply function appears to be copying the
>> entire parent environment (environment of interior of function) into all
>> child nodes in the cluster, one node at a time - which is very very slow
>> - and the copied contents are not even accessible within the child nodes
>> even though they are apparent in the memory footprint. This happens when
>> parLapply is run from within a function. I may be misusing the terms
>> "parent" and "node" here...
>>
>> The below code demonstrates the issue. The same parallel command is used
>> twice within the function, once before creating a large object, and once
>> afterwards. Both commands should take a nearly identical amount of time.
>> Initially the parallel code takes less than 1/100th of a second, but in
>> the second iteration requires hundreds of times longer...
>>
>> Example Code:
>>
>>      #create a cluster of nodes
>>      if(!"clus1" %in% ls()) clus1=makeCluster(10)
>>
>>      #function used to demonstrate bug
>>      rows_fn1=function(x,clus){
>>
>>          #first set of parallel code
>>
>> print(system.time(parLapply(clus,1:5,function(z){y=rnorm(5000);return(mean(y))})))
>>
>>
>>          #create large vector
>>          x=rnorm(10^7)
>>
>>          #second set
>>
>> print(system.time(parLapply(clus,1:5,function(z){y=rnorm(5000);return(mean(y))})))
>>
>>
>>      }
>>
>>      #demonstrate bug - watch task manager and see windows slowly copy
>> the vector to each node in the cluster
>>      rows_fn1(1:5000,clus1)
>>
>> Although the child nodes bloat proportionally to the size of x in the
>> parent environment, x is not available in the child nodes. The code
>
> With this
>
>     library(parallel)
>     cl <- makeCluster(2)
>     f <- function() {
>         x <- 10
>         parSapply(cl, 1:5, function(i) x * i)
>     }
>
> we see both that x is available, and why (so that symbols available  
> in the environment in which FUN is defined are available, just like  
> serial evaluation) the variable is copied
>
>> f()
> [1] 10 20 30 40 50
>
> Defining the function in the global environment, rather than in the  
> body of a function, avoids copying implicit state,
>
>     cl <- makeCluster(2)
>     FUN <- function(i) x * i
>     f <- function() {
>         x <- 10
>         parSapply(cl, 1:5, FUN)
>     }
>
> but requires that all arguments are defined / passed
>
>> f()
> Error in checkForRemoteErrors(val) (from #3) :
>   2 nodes produced errors; first error: object 'x' not found
>
> updating the function definition and use
>
>     FUN <- function(i, x) x * i
>     f <- function() {
>         x <- 10
>         parSapply(cl, 1:5, FUN, x)
>     }
>
>> f()
> [1] 10 20 30 40 50
>
> The foreach package tries to be smart and export only symbols used  
> (but can be tricked)
>
>     library(foreach)
>     library(doSNOW)
>     registerDoSNOW(cl)
>     g <- function() {
>         x <- 10
>         foreach(i=1:2) %dopar% { get("x") }
>     }
>
>> g()  # fails because 'x' is not referenced directly so not exported
> Error in { (from #3) : task 1 failed - "object 'x' not found"
>
> versus
>
>     g <- function() {
>         x <- 10
>         foreach(i=1:2) %dopar% { get("x"); x }
>     }
>
> and
>
>> g()  # works because 'x' referenced and exported
> [[1]]
> [1] 10
>
> [[2]]
> [1] 10
>
>
> Martin
>
>> above can be tweaked to add more variables (x1,x2,x3 ...) and the child
>> nodes will bloat to the same degree.
>>
>> I am working on Windows Server 2012, I am using 64bit R version 3.2.1. I
>> upgraded to 3.2.4revised and observed the same bug.
>>
>> I have googled for this issue and have not encountered any other
>> individuals having a similar problem.
>>
>> I have attempted to reboot my machine without effect (aside from the
>> obvious).
>>
>> Any suggestions would be greatly appreciated!
>>
>> With regards,
>>
>> Jacob L Strunk
>> Forest Biometrician (PhD), Statistician (MSc)
>> and Data Munger
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> This email message may contain legally privileged and/or  
> confidential information.  If you are not the intended recipient(s),  
> or the employee or agent responsible for the delivery of this  
> message to the intended recipient(s), you are hereby notified that  
> any disclosure, copying, distribution, or use of this email message  
> is prohibited.  If you have received this message in error, please  
> notify the sender immediately by e-mail and delete this email  
> message from your computer. Thank you.


From maechler at stat.math.ethz.ch  Wed Mar 23 18:25:12 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Mar 2016 18:25:12 +0100
Subject: [R] Reshaping an array - how does it work in R
In-Reply-To: <56F116AE.20903@ttk.mta.hu>
References: <2C31231B-2029-4745-96C0-62474527CF83@noaa.gov>
	<56EC7987.2070602@ttk.mta.hu>
	<22257.3681.787925.965424@stat.math.ethz.ch>
	<56F116AE.20903@ttk.mta.hu>
Message-ID: <22258.53624.696094.93711@stat.math.ethz.ch>

>>>>> D?nes T?th <toth.denes at ttk.mta.hu>
>>>>>     on Tue, 22 Mar 2016 10:55:58 +0100 writes:

    > Hi Martin,


    > On 03/22/2016 10:20 AM, Martin Maechler wrote:
    >>>>>>> >>>>>D?nes T?th<toth.denes at ttk.mta.hu>
    >>>>>>> >>>>>     on Fri, 18 Mar 2016 22:56:23 +0100 writes:
    >> > Hi Roy,
    >> > R (usually) makes a copy if the dimensionality of an array is modified,
    >> > even if you use this syntax:
    >> 
    >> > x <- array(1:24, c(2, 3, 4))
    >> > dim(x) <- c(6, 4)
    >> 
    >> > See also ?tracemem, ?data.table::address, ?pryr::address and other tools
    >> > to trace if an internal copy is done.
    >> 
    >> Well, without using strange (;-) packages,  indeed standard R's
    >> tracemem(), notably the help page is a good pointer.
    >> 
    >> According to the help page memory tracing is enabled in the
    >> default R binaries for Windows and OS X.
    >> For Linux (where I, as R developer, compile R myself anyway),
    >> one needs to configure with --enable-memory-profiling .
    >> 
    >> Now, let's try:
    >> 
    >> > x <- array(rnorm(47), dim = c(1000,50, 40))
    >> > tracemem(x)
    >> [1] "<0x7f79a498a010>"
    >> > dim(x) <- c(1000* 50, 40)
    >> > x[5] <- pi
    >> > tracemem(x)
    >> [1] "<0x7f79a498a010>"
    >> >
    >> 
    >> So,*BOTH*   the re-dimensioning*AND*   the  sub-assignment did
    >> *NOT*  make a copy.

    > This is interesting. First I wanted to demonstrate to Roy that recent R 
    > versions are smart enough not to make any copy during reshaping an 
    > array. Then I put together an example (similar to yours) and realized 
    > that after several reshapes, R starts to copy the array. So I had to 
    > modify my suggestion... And now, I realized that this was an 
    > RStudio-issue. At least on Linux, a standard R terminal behaves as you 
    > described, however, RStudio (version 0.99.862, which is not the very 
    > latest) tends to create copies (quite randomly, at least to me). If I 
    > have time I will test this more thoroughly and file a report to RStudio 
    > if it turns out to be a bug.

Interesting, indeed.

I can confirm the bugous  Rstudio behavior
using the latest version of Rstudio (64 bit Linux, Fedora 22)
      RStudio Version 0.99.891 ? ? 2009-2016 RStudio, Inc.

The attached small R script is very transparent in demonstrating
the problem.
If you have a tracemem-enabled version of R, the output is even
more revealing, inside Rstudio it gives

> showAdr <- function(x) {
+     if(capabilities("profmem")) {
+         tracemem(x)
+     } else {
+         cat("R version not configured for memory tracing\n")
+         .Internal(inspect(x))# also works w/o tracemem
+     }
+ }
> x <- array(rnorm(47), dim = c(1000, 50, 40))
> showAdr(x)
[1] "<0x7fad78b37010>"
> dim(x) <- c(1000*50, 40) # *no* copying
tracemem[0x7fad78b37010 -> 0x7fad77bf4010]: 
> showAdr(x) # Rstudio "fails" and has copied x
[1] "<0x7fad77bf4010>"
> x[3] <- pi
tracemem[0x7fad77bf4010 -> 0x1ad05f50]: 
> showAdr(x)
[1] "<0x1ad05f50>"
> ## in R, R CMD BATCH, also from ESS: there is *no* copying
> ## However, in Rstudio copying has happened!
>

Martin


    > Denes

    >> 
    >> Indeed, R has become much smarter  in these things in recent
    >> years ... not thanks to me, but very much thanks to
    >> Luke Tierney (from R-core), and also thanks to contributions from "outside",
    >> notably Tomas Kalibera.
    >> 
    >> And hence:*NO*  such strange workarounds are needed in this specific case:
    >> 
    >> > Workaround: use data.table::setattr or bit::setattr to modify the
    >> > dimensions in place (i.e., without making a copy). Risk: if you modify
    >> > an object by reference, all other objects which point to the same memory
    >> > address will be modified silently, too.
    >> 
    >> Martin Maechler, ETH Zurich  (and R-core)
    >> 
    >> > HTH,
    >> > Denes
    >> 
    >> (generally, your contributions help indeed, Denes, thank you!)
    >> 
    >> 
    >> > On 03/18/2016 10:28 PM, Roy Mendelssohn - NOAA Federal wrote:
    >> >> Hi All:
    >> >>
    >> >> I am working with a very large array.  if noLat is the number of latitudes, noLon the number of longitudes and noTime the number of  time periods, the array is of the form:
    >> >>
    >> >> myData[noLat, no Lon, noTime].
    >> >>
    >> >> It is read in this way because that is how it is stored in a (series) of netcdf files.  For the analysis I need to do, I need instead the array:
    >> >>
    >> >> myData[noLat*noLon, noTime].  Normally this would be easy:
    >> >>
    >> >> myData<- array(myData,dim=c(noLat*noLon,noTime))
    >> >>
    >> >> My question is how does this command work in R - does it make a copy of the existing array, with different indices for the dimensions, or does it just redo the indices and leave the given array as is?  The reason for this question is my array is 30GB in memory, and I don?t have enough space to have a copy of the array in memory.  If the latter I will have to figure out a work around to bring in only part of the data at a time and put it into the proper locations.
    >> >>
    >> >> Thanks,
    >> >>
    >> >> -Roy


From acx at lanl.gov  Wed Mar 23 18:42:21 2016
From: acx at lanl.gov (Castro, Alonso)
Date: Wed, 23 Mar 2016 17:42:21 +0000
Subject: [R] Limits of detection with package pls
Message-ID: <D318319C.2D03D%acx@lanl.gov>

I'm using package pls to perform partial least squares regression. Data is four spectra (13178 intensity measurements each) that correspond to 4 concentrations.

out <- plsr(concentration ~ intensity, ncomp=2, data=libs, validation = "LOO")

Does the package have a command to calculate limits of detection? I have seen conflicting descriptions on how to do this in the literature.

Thanks, Alonso.

	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Wed Mar 23 20:15:37 2016
From: eliza_botto at outlook.com (Eliza Botto)
Date: Wed, 23 Mar 2016 19:15:37 +0000
Subject: [R] test hypothesis in R
Message-ID: <SNT152-W23AAFAA7BD33013A82842E9A810@phx.gbl>

Dear All,
I want to test a hypothesis in R by using student' t-test (P-values).
The hypothesis is that model A produces lesser error than model B at ten stations. Obviously, Null Hypothesis (H0) is that the error produces by model A is not lower than model B.
The error magnitudes are 

#model A
> dput(mA)
c(36.1956086452583, 34.9996207622861, 36.435733025221, 37.2003157636202, 36.1318687775115, 37.164132533536, 35.2028759357069, 36.7719835944373, 38.3861425339751, 37.4174132119744)
#model B
> dput(mB)
c(39.7655211768704, 40.1730916643841, 39.3699055738618, 39.401619831763, 41.1218634441457, 39.1968630742826, 40.5265825061639, 40.4674956975404, 40.5954427072364, 41.4875529130543)

Now can I test my hypothesis in R?
Thankyou very much in Advance,
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From landronimirc at gmail.com  Wed Mar 23 20:59:04 2016
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 23 Mar 2016 20:59:04 +0100
Subject: [R] Why missing values are not allowed in 'poly'?
Message-ID: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>

Dear all,
I'm a bit surprised by this behavior in poly:

x <- c(NA, 1:10)
poly(x, degree = 2, raw=TRUE)
## Error in poly(x, degree = 2, raw = TRUE) :
##   missing values are not allowed in 'poly'
x^2
## [1] NA 1 4 9 16 25 36 49 64 81 100

As you can see, poly() will fail if the vector contains NAs, whereas
it is perfectly possible to obtain the square of the vector manually.

Is there a reason for this limitation in poly?

Regards,
Liviu


-- 
Do you think you know what math is?
http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
Or what it means to be intelligent?
http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
Think again:
http://www.ideasroadshow.com/library


From wdunlap at tibco.com  Wed Mar 23 21:29:31 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 23 Mar 2016 13:29:31 -0700
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
Message-ID: <CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>

I think the worst aspect of this restriction in poly() is that when
you use poly in the formula of a model-fitting function you cannot
have any missing values in the data, even if you supply
na.action=na.exclude.

  > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
  Warning message:
  In log(y) : NaNs produced
  > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
  Error in poly(x, 3) : missing values are not allowed in 'poly'

Thus people are pushed to using a less stable formulation like
  > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d, na.action=na.exclude)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic <landronimirc at gmail.com>
wrote:

> Dear all,
> I'm a bit surprised by this behavior in poly:
>
> x <- c(NA, 1:10)
> poly(x, degree = 2, raw=TRUE)
> ## Error in poly(x, degree = 2, raw = TRUE) :
> ##   missing values are not allowed in 'poly'
> x^2
> ## [1] NA 1 4 9 16 25 36 49 64 81 100
>
> As you can see, poly() will fail if the vector contains NAs, whereas
> it is perfectly possible to obtain the square of the vector manually.
>
> Is there a reason for this limitation in poly?
>
> Regards,
> Liviu
>
>
> --
> Do you think you know what math is?
> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
> Or what it means to be intelligent?
> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
> Think again:
> http://www.ideasroadshow.com/library
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From landronimirc at gmail.com  Wed Mar 23 21:41:30 2016
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 23 Mar 2016 21:41:30 +0100
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
	<CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
Message-ID: <CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>

On Wed, Mar 23, 2016 at 9:29 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I think the worst aspect of this restriction in poly() is that when
> you use poly in the formula of a model-fitting function you cannot
> have any missing values in the data, even if you supply
> na.action=na.exclude.
>
>   > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
>   Warning message:
>   In log(y) : NaNs produced
>   > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
>   Error in poly(x, 3) : missing values are not allowed in 'poly'
>
> Thus people are pushed to using a less stable formulation like
>   > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d, na.action=na.exclude)
>
My difficulty precisely. What's more, I inspected the code for `poly`
and at least for the simple case of raw=TRUE it seems trivial to
support NAs. It suffices to change line 15 of the function:
if (anyNA(x)) stop("missing values are not allowed in 'poly'")

to:
if (!raw && anyNA(x)) stop("missing values are not allowed in 'poly'")

This way for raw polynomials estimation continues unimpeded. With the
change above, I get this:
> poly(x, degree = 2, raw=TRUE)
       1 2
[1,] NA NA
[2,] 1 1
[3,] 2 4
[4,] 3 9
[5,] 4 16
[6,] 5 25
[7,] 6 36
[8,] 7 49
[9,] 8 64
[10,] 9 81
[11,] 10 100
attr(,"degree")
[1] 1 2
attr(,"class")
[1] "poly" "matrix"


Regards,
Liviu


>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic <landronimirc at gmail.com>
> wrote:
>>
>> Dear all,
>> I'm a bit surprised by this behavior in poly:
>>
>> x <- c(NA, 1:10)
>> poly(x, degree = 2, raw=TRUE)
>> ## Error in poly(x, degree = 2, raw = TRUE) :
>> ##   missing values are not allowed in 'poly'
>> x^2
>> ## [1] NA 1 4 9 16 25 36 49 64 81 100
>>
>> As you can see, poly() will fail if the vector contains NAs, whereas
>> it is perfectly possible to obtain the square of the vector manually.
>>
>> Is there a reason for this limitation in poly?
>>
>> Regards,
>> Liviu
>>
>>
>> --
>> Do you think you know what math is?
>> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
>> Or what it means to be intelligent?
>> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
>> Think again:
>> http://www.ideasroadshow.com/library
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Do you think you know what math is?
http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
Or what it means to be intelligent?
http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
Think again:
http://www.ideasroadshow.com/library


From ruipbarradas at sapo.pt  Wed Mar 23 21:44:20 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 23 Mar 2016 20:44:20 +0000
Subject: [R] test hypothesis in R
In-Reply-To: <SNT152-W23AAFAA7BD33013A82842E9A810@phx.gbl>
Message-ID: <20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>

Hello,

Try

?t.test
t.test(mA, mB, alternative = "greater")

Hope this helps,

Rui Barradas
?

Citando Eliza Botto <eliza_botto at outlook.com>:

> Dear All,
> I want to test a hypothesis in R by using student' t-test (P-values).
> The hypothesis is that model A produces lesser error than model B at  
> ten stations. Obviously, Null Hypothesis (H0) is that the error  
> produces by model A is not lower than model B.
> The error magnitudes are
>
> #model A
>> dput(mA)
>
> c(36.1956086452583, 34.9996207622861, 36.435733025221,  
> 37.2003157636202, 36.1318687775115, 37.164132533536,  
> 35.2028759357069, 36.7719835944373, 38.3861425339751,  
> 37.4174132119744)
> #model B
>> dput(mB)
>
> c(39.7655211768704, 40.1730916643841, 39.3699055738618,  
> 39.401619831763, 41.1218634441457, 39.1968630742826,  
> 40.5265825061639, 40.4674956975404, 40.5954427072364,  
> 41.4875529130543)
>
> Now can I test my hypothesis in R?
> Thankyou very much in Advance,
> Eliza
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Wed Mar 23 21:47:50 2016
From: eliza_botto at outlook.com (Eliza Botto)
Date: Wed, 23 Mar 2016 20:47:50 +0000
Subject: [R] test hypothesis in R
In-Reply-To: <20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>
References: <SNT152-W23AAFAA7BD33013A82842E9A810@phx.gbl>,
	<20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>
Message-ID: <SNT152-W16137BAB45C9E9C91080FC9A810@phx.gbl>

Thnx Rui,
Just one point though
Should it be alternative="greater" or "less"? Since alternative hypothesis is that model A produced less error.
regards,
Eliza

Date: Wed, 23 Mar 2016 20:44:20 +0000
From: ruipbarradas at sapo.pt
To: eliza_botto at outlook.com
CC: r-help at r-project.org
Subject: Re: [R] test hypothesis in R








Hello,



Try



?t.test

t.test(mA, mB, alternative = "greater")



Hope this helps,



Rui Barradas

 

Citando Eliza Botto <eliza_botto at outlook.com>:


Dear All,

I want to test a hypothesis in R by using student' t-test (P-values).

The hypothesis is that model A produces lesser error than model B at ten stations. Obviously, Null Hypothesis (H0) is that the error produces by model A is not lower than model B.

The error magnitudes are



#model A


dput(mA)


c(36.1956086452583, 34.9996207622861, 36.435733025221, 37.2003157636202, 36.1318687775115, 37.164132533536, 35.2028759357069, 36.7719835944373, 38.3861425339751, 37.4174132119744)

#model B

dput(mB)


c(39.7655211768704, 40.1730916643841, 39.3699055738618, 39.401619831763, 41.1218634441457, 39.1968630742826, 40.5265825061639, 40.4674956975404, 40.5954427072364, 41.4875529130543)



Now can I test my hypothesis in R?

Thankyou very much in Advance,

Eliza

        [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.



 		 	   		  
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Mar 23 21:56:35 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 23 Mar 2016 13:56:35 -0700
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
	<CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
	<CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>
Message-ID: <CAF8bMcaeRraaaYb4Eb6vVZcTR1y77w=NhP2w3xT1-YTweKpADA@mail.gmail.com>

I don't know what is in R's poly(), but if it is like S+'s or TERR's then
one could do

            if (anyNA(x))  {
                nax <- na.exclude(x)
                px <- poly(x = nax, degree = degree, coefs = coefs, raw =
raw, simple = simple)
                px <- structure(naresid(attr(nax, "na.action"), px), coefs
= attr(px, "coefs"), degree = attr(px, "degree"), class = attr(px, "class"))
                return(px)
            }

and get nice results in the usual raw=FALSE case as well.  Similar stuff
could be done in the multivariate cases.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 23, 2016 at 1:41 PM, Liviu Andronic <landronimirc at gmail.com>
wrote:

> On Wed, Mar 23, 2016 at 9:29 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > I think the worst aspect of this restriction in poly() is that when
> > you use poly in the formula of a model-fitting function you cannot
> > have any missing values in the data, even if you supply
> > na.action=na.exclude.
> >
> >   > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
> >   Warning message:
> >   In log(y) : NaNs produced
> >   > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
> >   Error in poly(x, 3) : missing values are not allowed in 'poly'
> >
> > Thus people are pushed to using a less stable formulation like
> >   > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d, na.action=na.exclude)
> >
> My difficulty precisely. What's more, I inspected the code for `poly`
> and at least for the simple case of raw=TRUE it seems trivial to
> support NAs. It suffices to change line 15 of the function:
> if (anyNA(x)) stop("missing values are not allowed in 'poly'")
>
> to:
> if (!raw && anyNA(x)) stop("missing values are not allowed in 'poly'")
>
> This way for raw polynomials estimation continues unimpeded. With the
> change above, I get this:
> > poly(x, degree = 2, raw=TRUE)
>        1 2
> [1,] NA NA
> [2,] 1 1
> [3,] 2 4
> [4,] 3 9
> [5,] 4 16
> [6,] 5 25
> [7,] 6 36
> [8,] 7 49
> [9,] 8 64
> [10,] 9 81
> [11,] 10 100
> attr(,"degree")
> [1] 1 2
> attr(,"class")
> [1] "poly" "matrix"
>
>
> Regards,
> Liviu
>
>
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic <landronimirc at gmail.com
> >
> > wrote:
> >>
> >> Dear all,
> >> I'm a bit surprised by this behavior in poly:
> >>
> >> x <- c(NA, 1:10)
> >> poly(x, degree = 2, raw=TRUE)
> >> ## Error in poly(x, degree = 2, raw = TRUE) :
> >> ##   missing values are not allowed in 'poly'
> >> x^2
> >> ## [1] NA 1 4 9 16 25 36 49 64 81 100
> >>
> >> As you can see, poly() will fail if the vector contains NAs, whereas
> >> it is perfectly possible to obtain the square of the vector manually.
> >>
> >> Is there a reason for this limitation in poly?
> >>
> >> Regards,
> >> Liviu
> >>
> >>
> >> --
> >> Do you think you know what math is?
> >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
> >> Or what it means to be intelligent?
> >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
> >> Think again:
> >> http://www.ideasroadshow.com/library
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> --
> Do you think you know what math is?
> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
> Or what it means to be intelligent?
> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
> Think again:
> http://www.ideasroadshow.com/library
>

	[[alternative HTML version deleted]]


From ctstackh at uab.edu  Wed Mar 23 21:39:20 2016
From: ctstackh at uab.edu (Christian T Stackhouse (Campus))
Date: Wed, 23 Mar 2016 20:39:20 +0000
Subject: [R] Help batch saving elements of a list into unique files
In-Reply-To: <CA+8X3fWudm0yx0XtxtcAAq9j7fY3h0xNFvZ0OnqF2BBrF5UDLg@mail.gmail.com>
References: <BLUPR0701MB1970190164BE1EA3E686B7B8C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fWX--N7jmUc2h8vKZeoNZJdmR7xiF=agXJcWyAPZuSG1w@mail.gmail.com>
	<BLUPR0701MB1970FBF908939DDAE27F647BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fURVb_O0i4iWW0Ac=PZubehQ84kwz7ujSEzr1mzN+fi0A@mail.gmail.com>
	<BLUPR0701MB1970FB0E35EDFE080C7DE37BC7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUoMj9Nw4pVse9jC-tcZfCzcXieTwf7s6o0bY+LsLjHSA@mail.gmail.com>
	<BLUPR0701MB19703E3395E07FF696914C29C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fVFWPT6jT3=QCxgw23-COLG7HVDFqx_F9V7GX8A3XKyug@mail.gmail.com>
	<BLUPR0701MB1970368B197675183C65EE98C7800@BLUPR0701MB1970.namprd07.prod.outlook.com>
	<CA+8X3fUigLTjAvq55hywG_wA37M-rveMUF1Bg2fcyd2L-ng_og@mail.gmail.com>
	<BLUPR0701MB197081C2695234CCAF1C5A64C7810@BLUPR0701MB1970.namprd07.prod.outlook.com>,
	<CA+8X3fWudm0yx0XtxtcAAq9j7fY3h0xNFvZ0OnqF2BBrF5UDLg@mail.gmail.com>
Message-ID: <BLUPR0701MB19709D5676FB7CE556E7924EC7810@BLUPR0701MB1970.namprd07.prod.outlook.com>

Jim, 

I wanted to thank you for your help and let you know I came up with a very simple solution to the header issue. I made a vector of the original header names before the split and fed that to names in your for loop:

h1 <- colnames(affymatrix)

for(affdf in 1:length(out)) {
  names(out[[affdf]])<-h1[2:119]
  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

Thank you for showing me how to save these files iteratively. I'm generating hundreds if not more than a thousand small files for batch operation.. Not something I wanted to tackle manually.

Sincerely,

Christian T. Stackhouse | Graduate Student
GBS Neuroscience Theme
Department of Neurosurgery
Department of Radiation Oncology
UAB | The University of Alabama at Birmingham
Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com

uab.edu
Knowledge that will change your world


________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 22, 2016 8:46 PM
To: Christian T Stackhouse (Campus)
Cc: r-help at r-project.org
Subject: Re: [R] Help batch saving elements of a list into unique files

Okay. Got some lunch, I can think about this with both halves of the brain.

drop_token1<-function(x) {
 return(paste(x[2:length(x)],sep="",collapse="."))
}
affnames<-c("X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL",
 "X1.Classical.10.11.1_.HuEx.1_0.st.v2..CEL")
affnames.split<-strsplit(affnames,"[.]")
lapply(affnames.split,drop_token1)
[[1]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

[[2]]
[1] "Classical.10.11.1_.HuEx.1_0.st.v2..CEL"

This what I get with a toy example. So, I think that:

for(affdf in 1:length(out)) {
names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]),drop_token1)
write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
}

should work.

Jim


On Wed, Mar 23, 2016 at 11:16 AM, Christian T Stackhouse (Campus)
<ctstackh at uab.edu> wrote:
> I re ran it and this is what I got: 11.1_.HuEx.1_0.st.v2..CEL
> Should be: 10.11.1_.HuEx.1_0.st.v2..CEL
>
> Christian T. Stackhouse | Graduate Student
> GBS Neuroscience Theme
> Department of Neurosurgery
> Department of Radiation Oncology
> UAB | The University of Alabama at Birmingham
> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>
> uab.edu
> Knowledge that will change your world
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, March 22, 2016 6:24 PM
> To: Christian T Stackhouse (Campus)
> Cc: r-help at r-project.org
> Subject: Re: [R] Help batch saving elements of a list into unique files
>
> Transcription. I forgot the "collapse" argument when I wrote the email:
>
> drop_token1<-function(x) {
>  return(paste(x[2:length(x)],sep="",collapse="."))
> }
>
> Jim
>
>
> On Wed, Mar 23, 2016 at 10:14 AM, Christian T Stackhouse (Campus)
> <ctstackh at uab.edu> wrote:
>> Very close! The header now looks like this: c("10", "11", "1_", "HuEx", "1_0", "st", "v2", "", "CEL")
>>  For some reason, it's not concatenating.
>>
>> Best,
>>
>> Christian T. Stackhouse | Graduate Student
>> GBS Neuroscience Theme
>> Department of Neurosurgery
>> Department of Radiation Oncology
>> UAB | The University of Alabama at Birmingham
>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>
>> uab.edu
>> Knowledge that will change your world
>>
>>
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, March 22, 2016 6:02 PM
>> To: Christian T Stackhouse (Campus)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>
>> I think it's the "unlist". I can only test this with one set of made
>> up names at a time.
>>
>> names(out[[affdf]])<-
>>  lapply(strsplit(names(out[[affdf]]),"[.]"),drop_token1)
>>
>> Jim
>>
>>
>> On Wed, Mar 23, 2016 at 9:57 AM, Christian T Stackhouse (Campus)
>> <ctstackh at uab.edu> wrote:
>>> This is what I ran:
>>>
>>>> drop_token1<-function(x) {
>>> +   return(paste(x[2:length(x)],sep="."))
>>> + }
>>>> for(affdf in 1:length(out)) {
>>> +   names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>> +   write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>> + }
>>> Error in names(out[[affdf]]) <- lapply(unlist(strsplit(names(out[[affdf]]),  :
>>>   'names' attribute [1148] must be the same length as the vector [118]
>>>>
>>>
>>> This is what the header was before:
>>>
>>> X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>
>>> There was no output due to the error.
>>>
>>> Christian T. Stackhouse | Graduate Student
>>> GBS Neuroscience Theme
>>> Department of Neurosurgery
>>> Department of Radiation Oncology
>>> UAB | The University of Alabama at Birmingham
>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>
>>> uab.edu
>>> Knowledge that will change your world
>>>
>>>
>>> ________________________________________
>>> From: Jim Lemon <drjimlemon at gmail.com>
>>> Sent: Tuesday, March 22, 2016 5:46 PM
>>> To: Christian T Stackhouse (Campus)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>
>>> Sorry, should be:
>>>
>>> names(out[[affdf]])<-
>>>  lapply(unlist(strsplit(names(out[[affdf]]),"[.]")),drop_token1)
>>>
>>> Jim
>>>
>>>
>>> On Wed, Mar 23, 2016 at 9:43 AM, Christian T Stackhouse (Campus)
>>> <ctstackh at uab.edu> wrote:
>>>> Thank you, Jim. I got this error returned:
>>>>
>>>> Error in strsplit(names(out[[affdf]])) :
>>>>   argument "split" is missing, with no default
>>>>
>>>> Christian T. Stackhouse | Graduate Student
>>>> GBS Neuroscience Theme
>>>> Department of Neurosurgery
>>>> Department of Radiation Oncology
>>>> UAB | The University of Alabama at Birmingham
>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>
>>>> uab.edu
>>>> Knowledge that will change your world
>>>>
>>>>
>>>> ________________________________________
>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>> Sent: Tuesday, March 22, 2016 5:39 PM
>>>> To: Christian T Stackhouse (Campus)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>
>>>> Okay, I just snipped off the first token in the header labels assuming
>>>> that there would be no more periods. Try this:
>>>>
>>>> drop_token1<-function(x) {
>>>>  return(paste(x[2:length(x)],sep="."))
>>>> }
>>>> for(affdf in 1:length(out)) {
>>>> names(out[[affdf]])<-lapply(unlist(strsplit(names(out[[affdf]]))),drop_token1)
>>>> write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>> }
>>>>
>>>> Jim
>>>>
>>>> On Wed, Mar 23, 2016 at 9:13 AM, Christian T Stackhouse (Campus)
>>>> <ctstackh at uab.edu> wrote:
>>>>> Jim,
>>>>>
>>>>> It worked! It wrote out the files, but unfortunately, it didn't work for the file headers. I should have mentioned this is what the headers look like: X0.Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>> After running your script, that header changes to: 10. I'd just like to remove the "X0." prefix or in the case of file 189 the "X188." prefix leaving: Classical.10.11.1_.HuEx.1_0.st.v2..CEL
>>>>>
>>>>> Thank you so much for your help! I'll try playing with it myself, but if you have any further insights they would be greatly appreciated!
>>>>>
>>>>> Best,
>>>>>
>>>>> Christian T. Stackhouse | Graduate Student
>>>>> GBS Neuroscience Theme
>>>>> Department of Neurosurgery
>>>>> Department of Radiation Oncology
>>>>> UAB | The University of Alabama at Birmingham
>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>
>>>>> uab.edu
>>>>> Knowledge that will change your world
>>>>>
>>>>>
>>>>> ________________________________________
>>>>> From: Jim Lemon <drjimlemon at gmail.com>
>>>>> Sent: Tuesday, March 22, 2016 4:48 PM
>>>>> To: Christian T Stackhouse (Campus)
>>>>> Cc: r-help at r-project.org
>>>>> Subject: Re: [R] Help batch saving elements of a list into unique files
>>>>>
>>>>> Hi Christian,
>>>>> This untested script might get you going (assuming you want a CSV format):
>>>>>
>>>>> for(affdf in 1:length(out)) {
>>>>>  names(out[[affdf]])<-lapply(strsplit(names(out[[affdf]]),"[.]"),"[",2)
>>>>>  write.csv(out[[affdf]],file=paste("affymetrix",affdf,".txt",sep=""))
>>>>> }
>>>>>
>>>>> Jim
>>>>>
>>>>>
>>>>> On Wed, Mar 23, 2016 at 6:32 AM, Christian T Stackhouse (Campus)
>>>>> <ctstackh at uab.edu> wrote:
>>>>>> Hello!
>>>>>>
>>>>>>
>>>>>> The overall goal I have is taking a large data frame and splitting it into several smaller data frames (preserving column headers) which I can save as txt files to feed into my APACHE ANY23 server for conversion into RDF.
>>>>>>
>>>>>>
>>>>>> This is what I call to split up the original file:
>>>>>>
>>>>>>
>>>>>> out <- split(affymetrix, (seq(nrow(affymetrix))-1) %/% 140)
>>>>>>
>>>>>>
>>>>>> I have a list (out) of length 187 for which each element is a dataframe. I want to iteratively save each data frame as a separate tab file with a naming structure such as: affymetrix1.txt, affymetrix2.txt, ... affymetrix187.txt
>>>>>>
>>>>>>
>>>>>> Before that, I need to modify the headers to remove a prefix "X0. , X1., ... X187." that was introduced during my original splitting. I need to remove all characters before and including the first "."
>>>>>>
>>>>>>
>>>>>> If anyone has a better way of doing this, please let me know. Otherwise, help with how to perform batch editing of the headers and batch saving of the files would be greatly appreciated!
>>>>>>
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Christian T. Stackhouse | Graduate Student
>>>>>> GBS Neuroscience Theme
>>>>>> Department of Neurosurgery
>>>>>> Department of Radiation Oncology
>>>>>> UAB | The University of Alabama at Birmingham
>>>>>> Hazelrig-Salter Radiation Oncology Center | 1700 6th Ave S | Birmingham, AL 35233
>>>>>> M: 919.724.6890 | ctstackh at uab.edu | cstackhouse at uabmc.edu | ctstackh at gmail.com
>>>>>>
>>>>>> uab.edu<http://uab.edu/>
>>>>>> Knowledge that will change your world
>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.

From martin.morgan at roswellpark.org  Wed Mar 23 22:58:47 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 23 Mar 2016 17:58:47 -0400
Subject: [R] Persistent state in a function?
In-Reply-To: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
Message-ID: <56F31197.1080402@roswellpark.org>

Use a local environment to as a place to store state. Update with <<- 
and resolve symbol references through lexical scope E.g.,

     persist <- local({
         last <- NULL                # initialize
         function(value) {
             if (!missing(value))
                 last <<- value      # update with <<-
             last                    # use
         }
     })

and in action

 > persist("foo")
[1] "foo"
 > persist()
[1] "foo"
 > persist("bar")
[1] "bar"
 > persist()
[1] "bar"

A variant is to use a 'factory' function

     factory <- function(init) {
         stopifnot(!missing(init))
         last <- init
         function(value) {
             if (!missing(value))
                 last <<- value
             last
         }
     }

and

 > p1 = factory("foo")
 > p2 = factory("bar")
 > c(p1(), p2())
[1] "foo" "bar"
 > c(p1(), p2("foo"))
[1] "foo" "foo"
 > c(p1(), p2())
[1] "foo" "foo"

The 'bank account' exercise in section 10.7 of RShowDoc("R-intro") 
illustrates this.

Martin

On 03/19/2016 12:45 PM, Boris Steipe wrote:
> Dear all -
>
> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>   -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>   -B- how can I store and reload such table?
>   -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>
>
> For illustration ...
>
> -----------------------------------
>
> myDist <- function(a, b) {
>      # retrieve or calculate distances
>      if (!exists("Vals")) {
>          Vals <<- numeric() # the lookup table for distance values
>                             # here, created in the global env.
>      }
>      key <- sprintf("X%d.%d", a, b)
>      thisDist <- Vals[key]
>      if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>          cat("Calculating ... ")
>          thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>          Vals[key] <<- thisDist      # store in global table
>      }
>      return(thisDist)
> }
>
>
> # run this
> set.seed(112358)
>
> for (i in 1:10) {
>      x <- sample(1:3, 2)
>      print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
> }
>
>
> Thanks!
> Boris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From boris.steipe at utoronto.ca  Wed Mar 23 23:41:59 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 23 Mar 2016 18:41:59 -0400
Subject: [R] Persistent state in a function?
In-Reply-To: <56F31197.1080402@roswellpark.org>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56F31197.1080402@roswellpark.org>
Message-ID: <8239D36E-C242-4563-815D-1C318F68957C@utoronto.ca>

All -
Thanks, this has been a real eye-opener.

Here's my variation based on what I've learned so far. It's based on Bert's earlier function-returning-a-closure example. I hope I got the terminology right.

# ========================================================

makeCache <- function(){   # returns a "closure",
	                   # i.e. a function
	                   # plus its private, lexically
	                   # scoped environment

   myCache <- numeric()  # a variable that we want to persist;
                         # makeCache() creates the 
                         # environment that holds myCache and
                         # the function useCache() that uses myCache

   useCache <- function(x){
 	  myCache <<- c(myCache, x)  # appends a value to myCache
 	                             # <<- does _not_ assign to the
 	                             # global environment, but searches
 	                             # through the parent environments
 	                             # and assigns to the global environment
 	                             # only if no match was found along
 	                             # the way.
 	  print(myCache)
   }
   
   return(useCache)     # return the function plus its environment
}

# ======= creating instances of the closure and using them

cacheThis <- makeCache() # cacheThis is the closure that was created
                         # by makeCache

cacheThis(17)  # 17
cacheThis(13)  # 17 13
cacheThis(11)  # 17 13 11


cacheThat <- makeCache() # create another closure

cacheThat(1)  # 1
cacheThat(2)  # 1 2
cacheThat(3)  # 1 2 3
cacheThat(5)  # 1 2 3 5

# ======= accessing the private variables

# The caches for cacheThis() and cacheThat() are not visible
# from the (default) global environment:
ls()  # [1] "cacheThat" "cacheThis" "makeCache" 

# To access them from the global environment, use
# ls(), exists(), get() and assign(), with their environment
# argument:
 
ls.str(envir = environment(cacheThis))

ls.str(envir = environment(cacheThat))

exists("myCache", envir = environment(cacheThat))
exists("noSuchThing", envir = environment(cacheThat))

# The following won't work - save() needs a name as symbol or string:
save(get("myCache", envir = environment(cacheThis)), file="myCache.Rdata")

# do this instead:
tmp <- get("myCache", envir = environment(cacheThis))
save(tmp, file="myCache.Rdata")
rm(tmp)

# add a number we don't want...
cacheThis(6) # 17 13 11 6

# restore cache from saved version
load("myCache.Rdata") # this recreates "tmp"
assign("myCache", tmp, envir = environment(cacheThis))

# cache another prime ...
cacheThis(7) # 17 13 11 7

# etc.

# ========================================================

I don't yet understand the pros and cons of using local() instead of a generating function. From my current understanding, local() should end up doing the same thing - I think that's why Martin calls one a "variant" of the other. But I'll play some more with this later today. Is there a Preferred Way?

memoise has some nice ideas - such as creating a hash from the arguments passed into a function to see if the cached results need to be recomputed. In my use case, I'd like to have more explicit access to the cached results to be able to store, reload and otherwise manipulate them.

I haven't looked at R6 yet.

Cheers,
Boris












On Mar 23, 2016, at 5:58 PM, Martin Morgan <martin.morgan at roswellpark.org> wrote:

> Use a local environment to as a place to store state. Update with <<- and resolve symbol references through lexical scope E.g.,
> 
>    persist <- local({
>        last <- NULL                # initialize
>        function(value) {
>            if (!missing(value))
>                last <<- value      # update with <<-
>            last                    # use
>        }
>    })
> 
> and in action
> 
> > persist("foo")
> [1] "foo"
> > persist()
> [1] "foo"
> > persist("bar")
> [1] "bar"
> > persist()
> [1] "bar"
> 
> A variant is to use a 'factory' function
> 
>    factory <- function(init) {
>        stopifnot(!missing(init))
>        last <- init
>        function(value) {
>            if (!missing(value))
>                last <<- value
>            last
>        }
>    }
> 
> and
> 
> > p1 = factory("foo")
> > p2 = factory("bar")
> > c(p1(), p2())
> [1] "foo" "bar"
> > c(p1(), p2("foo"))
> [1] "foo" "foo"
> > c(p1(), p2())
> [1] "foo" "foo"
> 
> The 'bank account' exercise in section 10.7 of RShowDoc("R-intro") illustrates this.
> 
> Martin
> 
> On 03/19/2016 12:45 PM, Boris Steipe wrote:
>> Dear all -
>> 
>> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>>  -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>>  -B- how can I store and reload such table?
>>  -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>> 
>> 
>> For illustration ...
>> 
>> -----------------------------------
>> 
>> myDist <- function(a, b) {
>>     # retrieve or calculate distances
>>     if (!exists("Vals")) {
>>         Vals <<- numeric() # the lookup table for distance values
>>                            # here, created in the global env.
>>     }
>>     key <- sprintf("X%d.%d", a, b)
>>     thisDist <- Vals[key]
>>     if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>>         cat("Calculating ... ")
>>         thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>>         Vals[key] <<- thisDist      # store in global table
>>     }
>>     return(thisDist)
>> }
>> 
>> 
>> # run this
>> set.seed(112358)
>> 
>> for (i in 1:10) {
>>     x <- sample(1:3, 2)
>>     print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
>> }
>> 
>> 
>> Thanks!
>> Boris
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From ruipbarradas at sapo.pt  Thu Mar 24 00:21:31 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 23 Mar 2016 23:21:31 +0000
Subject: [R] test hypothesis in R
In-Reply-To: <SNT152-W16137BAB45C9E9C91080FC9A810@phx.gbl>
References: <SNT152-W23AAFAA7BD33013A82842E9A810@phx.gbl>
	<20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>
	<SNT152-W16137BAB45C9E9C91080FC9A810@phx.gbl>
Message-ID: <20160323232131.Horde.gUb6sVCfdMgCWHDPy3IyTjl@mail.sapo.pt>

Sorry, but in your original post you said that " Null Hypothesis (H0)  
is that the error produces by model A is not lower than model B".
If now is that model A produces less error change to  
alternative="less". The relevant part in the help page ?t.test is

alternative = "greater" is the alternative that x has a larger mean than y.

Rui Barradas
?

Citando Eliza Botto <eliza_botto at outlook.com>:

> Thnx Rui, ?
> Just one point though
> ?
> Should it be alternative="greater" or "less"? Since alternative  
> hypothesis is that model A produced less error.
> ?
> regards,
> ?
> Eliza
> ?
> -------------------------
> Date: Wed, 23 Mar 2016 20:44:20 +0000
> From: ruipbarradas at sapo.pt
> To: eliza_botto at outlook.com
> CC: r-help at r-project.org
> Subject: Re: [R] test hypothesis in R

> Dear All,
> I want to test a hypothesis in R by using student' t-test (P-values).
> The hypothesis is that model A produces lesser error than model B at  
> ten stations. Obviously, Null Hypothesis (H0) is that the error  
> produces by model A is not lower than model B.
> The error magnitudes are
>
> #model A
>> dput(mA)
>
> c(36.1956086452583, 34.9996207622861, 36.435733025221,  
> 37.2003157636202, 36.1318687775115, 37.164132533536,  
> 35.2028759357069, 36.7719835944373, 38.3861425339751,  
> 37.4174132119744)
> #model B
>> dput(mB)
>
> c(39.7655211768704, 40.1730916643841, 39.3699055738618,  
> 39.401619831763, 41.1218634441457, 39.1968630742826,  
> 40.5265825061639, 40.4674956975404, 40.5954427072364,  
> 41.4875529130543)
>
> Now can I test my hypothesis in R?
> Thankyou very much in Advance,
> Eliza
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar 24 01:41:21 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Mar 2016 17:41:21 -0700
Subject: [R] test hypothesis in R
In-Reply-To: <20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>
References: <20160323204420.Horde.molEpqP-gWDhDJsqbQyQU-E@mail.sapo.pt>
Message-ID: <AF037BDF-EE27-4BE0-953C-2800B3E30772@comcast.net>


> On Mar 23, 2016, at 1:44 PM, ruipbarradas at sapo.pt wrote:
> 
> Hello,
> 
> Try
> 
> ?t.test
> t.test(mA, mB, alternative = "greater")
> 
> Hope this helps,
> 
> Rui Barradas
>  
> 
> Citando Eliza Botto <eliza_botto at outlook.com>:
> 
>> Dear All,
>> I want to test a hypothesis in R by using student' t-test (P-values).
>> The hypothesis is that model A produces lesser error than model B at  
>> ten stations. Obviously, Null Hypothesis (H0) is that the error  
>> produces by model A is not lower than model B.

NOT "obviously". You only get to do one-sided tests when the scientific question would not allow the possibility of a departure to "the other side".

Two-sided tests are the norm in scientific literature, often to the experimenter's distress when they haven't done a thoughtful (non-optimistic) power analysis and their results are inconclusive as a result. Your hypothesis _should_ have been constructed _before_ you saw the data. That is if you want to be an ethical scientist.


>> The error magnitudes are
>> 
>> #model A
>>> dput(mA)
>> 
>> c(36.1956086452583, 34.9996207622861, 36.435733025221,  
>> 37.2003157636202, 36.1318687775115, 37.164132533536,  
>> 35.2028759357069, 36.7719835944373, 38.3861425339751,  
>> 37.4174132119744)
>> #model B
>>> dput(mB)
>> 
>> c(39.7655211768704, 40.1730916643841, 39.3699055738618,  
>> 39.401619831763, 41.1218634441457, 39.1968630742826,  
>> 40.5265825061639, 40.4674956975404, 40.5954427072364,  
>> 41.4875529130543)

Those are not models. They are just vectors of numbers. And they seem unlikely to be residual errors of a linear model since they are not centered on zero. I doubt there is enough in your presentation for a sensible comment on the proper analysis.

-- 

David.

>> 
>> Now can I test my hypothesis in R?
>> Thankyou very much in Advance,
>> Eliza
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________



David Winsemius
Alameda, CA, USA


From neale at sinenomine.net  Wed Mar 23 22:48:53 2016
From: neale at sinenomine.net (Neale Ferguson)
Date: Wed, 23 Mar 2016 21:48:53 +0000
Subject: [R] Problems installing docopt
Message-ID: <D3188783.6065E%neale@sinenomine.net>

Hi,
 I?ve seen similar questions when googling this problem but none of them
seem directly related to what I am seeing. Doing an install.r docopt craps
out with stringi build complaining:

Error in iconv(x, "latin1", "ASCII") :
   unsupported conversion from 'latin1' to 'ASCII'


Searching came up with issues relating to using the C locale and the need
to use en_US.UTF-8. However, my locale is already set up as such:

# locale
LANG=en_US.UTF-8
LC_CTYPE="en_US.UTF-8"
LC_NUMERIC="en_US.UTF-8"
LC_TIME="en_US.UTF-8"
LC_COLLATE="en_US.UTF-8"
LC_MONETARY="en_US.UTF-8"
LC_MESSAGES="en_US.UTF-8"
LC_PAPER="en_US.UTF-8"
LC_NAME="en_US.UTF-8"
LC_ADDRESS="en_US.UTF-8"
LC_TELEPHONE="en_US.UTF-8"
LC_MEASUREMENT="en_US.UTF-8"
LC_IDENTIFICATION="en_US.UTF-8"
LC_ALL=en_US.UTF-8


I?m at a loss as to what look at next. (This is on a CentOS 7.1 system/)

Neale


From dwinsemius at comcast.net  Thu Mar 24 04:53:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Mar 2016 20:53:46 -0700
Subject: [R] Problems installing docopt
In-Reply-To: <D3188783.6065E%neale@sinenomine.net>
References: <D3188783.6065E%neale@sinenomine.net>
Message-ID: <02FC03A0-43F9-4911-952B-E29CEF0260CD@comcast.net>


> On Mar 23, 2016, at 2:48 PM, Neale Ferguson <neale at sinenomine.net> wrote:
> 
> Hi,
> I?ve seen similar questions when googling this problem but none of them
> seem directly related to what I am seeing. Doing an install.r docopt craps
> out with stringi build complaining:
> 
> Error in iconv(x, "latin1", "ASCII") :
>   unsupported conversion from 'latin1' to 'ASCII'

That doesn't look like a full console log.


> Searching came up with issues relating to using the C locale and the need
> to use en_US.UTF-8. However, my locale is already set up as such:
> 
> # locale
> LANG=en_US.UTF-8
> LC_CTYPE="en_US.UTF-8"
> LC_NUMERIC="en_US.UTF-8"
> LC_TIME="en_US.UTF-8"
> LC_COLLATE="en_US.UTF-8"
> LC_MONETARY="en_US.UTF-8"
> LC_MESSAGES="en_US.UTF-8"
> LC_PAPER="en_US.UTF-8"
> LC_NAME="en_US.UTF-8"
> LC_ADDRESS="en_US.UTF-8"
> LC_TELEPHONE="en_US.UTF-8"
> LC_MEASUREMENT="en_US.UTF-8"
> LC_IDENTIFICATION="en_US.UTF-8"
> LC_ALL=en_US.UTF-8
> 
> 
> I?m at a loss as to what look at next. (This is on a CentOS 7.1 system/)

Isn't this the sort of question that should first be posed to the maintainer? And when doing so, do post a more complete description of your versions.

(I had no difficulty with either the the binary or the source installs of docopt with dependencies=TRUE for version 0.4.3.3 (with stringi version 1.0-1 already in place) on a Mac running 3.2.3 Patched (2016-01-25 r70000) -- "Wooden Christmas-Tree"). It did not appear to me that the package required any compilation and that agrees with the DESCRIPTION file.

-- 

David Winsemius
Alameda, CA, USA


From ulhaqz at gmail.com  Thu Mar 24 11:30:11 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Thu, 24 Mar 2016 15:30:11 +0500
Subject: [R] Splitting a vector into data frame
Message-ID: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>

Hi,

1. I have scraped some data from the web, subset shown below

> dput(temp.data)
c("Armenia", "Armenia", "43827", "39200", "35700", "36700", "39341",
"30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
"0", "0", "0", "0", "Austria", "Austria", "135417", "166200",
"144500", "147300", "163211", "162536", "155412", "133667", "134962",
"146440", "131188", "100001", "100000", "80000", "35000")

2. The corresponding list of countries, is as follows

> dput(raw.country)
c("Armenia", "Austria", "Belarus", "Belgium", "Brazil", "Bulgaria",
"Canada", "Castile-Leon (Hiszania)", "Catalonia", "Chile", "Colombia",
"Costarica", "Croatia", "Cyprus", "Czech Republic", "Ecuador",
"Estonia", "Finland", "France", "Georgia", "Germany", "Ghana",
"Greece", "Hungary", "Indonesia", "Iran", "Ireland", "Israel",
"Italy", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Macedonia",
"Malaysia", "Mexico", "Moldova", "Mongolia", "Netherland", "Norway",
"Pakistan", "Panama", "Paraguay", "Peru", "Poland", "Portugal",
"Puertorico", "Romania", "Russia", "Serbia", "Slovakia", "Slovenia",
"Spain", "Sweden", "Switzerland", "Tunisia", "Ukraine", "United Kingdom",
"USA", "Venezuela", "Vltava", "World Total")


3. I want to organize the data into a data frame, where each row will
contain the 20 values for the corresponding country.
It needs to ignore the country name which appears twice.Something like:

Armenia "43827", "39200", "35700", "36700", "39341",
"30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
"0", "0", "0", "0",

"Austria", "135417", "166200",
"144500", "147300", "163211", "162536", "155412", "133667", "134962",
"146440", "131188", "100001", "100000", "80000", "35000"

and so on


Thanks /

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Mar 24 11:40:24 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 24 Mar 2016 06:40:24 -0400
Subject: [R] Splitting a vector into data frame
In-Reply-To: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
References: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
Message-ID: <6F1613A2-F151-47E1-855E-24E580C3EC04@utoronto.ca>

Your data rows have different numbers of columns. Thus your problem is not sufficiently specified.

B. 
On Mar 24, 2016, at 6:30 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:

> Hi,
> 
> 1. I have scraped some data from the web, subset shown below
> 
>> dput(temp.data)
> c("Armenia", "Armenia", "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0", "Austria", "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000")
> 
> 2. The corresponding list of countries, is as follows
> 
>> dput(raw.country)
> c("Armenia", "Austria", "Belarus", "Belgium", "Brazil", "Bulgaria",
> "Canada", "Castile-Leon (Hiszania)", "Catalonia", "Chile", "Colombia",
> "Costarica", "Croatia", "Cyprus", "Czech Republic", "Ecuador",
> "Estonia", "Finland", "France", "Georgia", "Germany", "Ghana",
> "Greece", "Hungary", "Indonesia", "Iran", "Ireland", "Israel",
> "Italy", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Macedonia",
> "Malaysia", "Mexico", "Moldova", "Mongolia", "Netherland", "Norway",
> "Pakistan", "Panama", "Paraguay", "Peru", "Poland", "Portugal",
> "Puertorico", "Romania", "Russia", "Serbia", "Slovakia", "Slovenia",
> "Spain", "Sweden", "Switzerland", "Tunisia", "Ukraine", "United Kingdom",
> "USA", "Venezuela", "Vltava", "World Total")
> 
> 
> 3. I want to organize the data into a data frame, where each row will
> contain the 20 values for the corresponding country.
> It needs to ignore the country name which appears twice.Something like:
> 
> Armenia "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0",
> 
> "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000"
> 
> and so on
> 
> 
> Thanks /
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Mar 24 11:48:34 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 24 Mar 2016 21:48:34 +1100
Subject: [R] Splitting a vector into data frame
In-Reply-To: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
References: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
Message-ID: <CA+8X3fX3V6ob=J5kCuEr1m9icfPRoVgRHmETo_86L3-H2Lx_Jg@mail.gmail.com>

Hi Burhan,
As all of your values seem to be character, perhaps:

country.df<-as.data.frame(matrix(temp.data,ncol=22,byrow=TRUE)[,2:21])

if there really are 2 country names and 20 values for each country. As
Boris has pointed out, there are different numbers of values following
the country names in your example.

Jim


On Thu, Mar 24, 2016 at 9:30 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:
> Hi,
>
> 1. I have scraped some data from the web, subset shown below
>
>> dput(temp.data)
> c("Armenia", "Armenia", "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0", "Austria", "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000")
>
> 2. The corresponding list of countries, is as follows
>
>> dput(raw.country)
> c("Armenia", "Austria", "Belarus", "Belgium", "Brazil", "Bulgaria",
> "Canada", "Castile-Leon (Hiszania)", "Catalonia", "Chile", "Colombia",
> "Costarica", "Croatia", "Cyprus", "Czech Republic", "Ecuador",
> "Estonia", "Finland", "France", "Georgia", "Germany", "Ghana",
> "Greece", "Hungary", "Indonesia", "Iran", "Ireland", "Israel",
> "Italy", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Macedonia",
> "Malaysia", "Mexico", "Moldova", "Mongolia", "Netherland", "Norway",
> "Pakistan", "Panama", "Paraguay", "Peru", "Poland", "Portugal",
> "Puertorico", "Romania", "Russia", "Serbia", "Slovakia", "Slovenia",
> "Spain", "Sweden", "Switzerland", "Tunisia", "Ukraine", "United Kingdom",
> "USA", "Venezuela", "Vltava", "World Total")
>
>
> 3. I want to organize the data into a data frame, where each row will
> contain the 20 values for the corresponding country.
> It needs to ignore the country name which appears twice.Something like:
>
> Armenia "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0",
>
> "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000"
>
> and so on
>
>
> Thanks /
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Thu Mar 24 11:53:50 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 24 Mar 2016 11:53:50 +0100
Subject: [R] Splitting a vector into data frame
In-Reply-To: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
References: <CADw4CkuyVB3svuD9Yt=s2GHpPVxNr1oYZ6478wdhk9cpRtuekQ@mail.gmail.com>
Message-ID: <56F3C73E.2090008@univ-reims.fr>

Hi!

As Boris explained, if you do not always have the same number of values 
per country, you need to provide more details, e.g. should the empty 
cells be filled with NA?

But if you do always have 20 values per country (unlike in your sample 
data), then this could work for you:
mydf <- data.frame(matrix(temp.data, nrow=2, ncol=22, byrow=TRUE))
You can then subset to remove the 1st column:
mydf[-1]

HTH,
Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 24/03/2016 11:30, Burhan ul haq a ?crit :
> Hi,
>
> 1. I have scraped some data from the web, subset shown below
>
>> dput(temp.data)
> c("Armenia", "Armenia", "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0", "Austria", "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000")
>
> 2. The corresponding list of countries, is as follows
>
>> dput(raw.country)
> c("Armenia", "Austria", "Belarus", "Belgium", "Brazil", "Bulgaria",
> "Canada", "Castile-Leon (Hiszania)", "Catalonia", "Chile", "Colombia",
> "Costarica", "Croatia", "Cyprus", "Czech Republic", "Ecuador",
> "Estonia", "Finland", "France", "Georgia", "Germany", "Ghana",
> "Greece", "Hungary", "Indonesia", "Iran", "Ireland", "Israel",
> "Italy", "Kazakhstan", "Kyrgyzstan", "Latvia", "Lithuania", "Macedonia",
> "Malaysia", "Mexico", "Moldova", "Mongolia", "Netherland", "Norway",
> "Pakistan", "Panama", "Paraguay", "Peru", "Poland", "Portugal",
> "Puertorico", "Romania", "Russia", "Serbia", "Slovakia", "Slovenia",
> "Spain", "Sweden", "Switzerland", "Tunisia", "Ukraine", "United Kingdom",
> "USA", "Venezuela", "Vltava", "World Total")
>
>
> 3. I want to organize the data into a data frame, where each row will
> contain the 20 values for the corresponding country.
> It needs to ignore the country name which appears twice.Something like:
>
> Armenia "43827", "39200", "35700", "36700", "39341",
> "30571", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", " 0",
> "0", "0", "0", "0",
>
> "Austria", "135417", "166200",
> "144500", "147300", "163211", "162536", "155412", "133667", "134962",
> "146440", "131188", "100001", "100000", "80000", "35000"
>
> and so on
>
>
> Thanks /
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Thu Mar 24 12:54:14 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Mar 2016 12:54:14 +0100
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <CAF8bMcaeRraaaYb4Eb6vVZcTR1y77w=NhP2w3xT1-YTweKpADA@mail.gmail.com>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
	<CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
	<CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>
	<CAF8bMcaeRraaaYb4Eb6vVZcTR1y77w=NhP2w3xT1-YTweKpADA@mail.gmail.com>
Message-ID: <22259.54630.533896.719922@stat.math.ethz.ch>

>>>>> William Dunlap via R-help <r-help at r-project.org>
>>>>>     on Wed, 23 Mar 2016 13:56:35 -0700 writes:

    > I don't know what is in R's poly(), but if it is like S+'s or TERR's then
    > one could do

    > if (anyNA(x))  {
    > nax <- na.exclude(x)
    > px <- poly(x = nax, degree = degree, coefs = coefs, raw =
    > raw, simple = simple)
    > px <- structure(naresid(attr(nax, "na.action"), px), coefs
    > = attr(px, "coefs"), degree = attr(px, "degree"), class = attr(px, "class"))
    > return(px)
    > }

    > and get nice results in the usual raw=FALSE case as well.  Similar stuff
    > could be done in the multivariate cases.

I don't have too much time for that now,
and I know that Bill Dunlap cannot provide patches for R --- for 
good reasons, though it's a pity for us! ---
but you can, Liviu!
So, and  as you see at every startup of R :

   "R is a collaborative project with many contributors."

I'm willing to try "good-looking" patches.
(to the *sources*, *NOT* to a printout of the function in your R console!)

Martin Maechler
ETH Zurich and R Core Team.

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

    > On Wed, Mar 23, 2016 at 1:41 PM, Liviu Andronic <landronimirc at gmail.com>
    > wrote:

    >> On Wed, Mar 23, 2016 at 9:29 PM, William Dunlap <wdunlap at tibco.com> wrote:
    >> > I think the worst aspect of this restriction in poly() is that when
    >> > you use poly in the formula of a model-fitting function you cannot
    >> > have any missing values in the data, even if you supply
    >> > na.action=na.exclude.
    >> >
    >> >   > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
    >> >   Warning message:
    >> >   In log(y) : NaNs produced
    >> >   > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
    >> >   Error in poly(x, 3) : missing values are not allowed in 'poly'
    >> >
    >> > Thus people are pushed to using a less stable formulation like
    >> >   > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d, na.action=na.exclude)
    >> >
    >> My difficulty precisely. What's more, I inspected the code for `poly`
    >> and at least for the simple case of raw=TRUE it seems trivial to
    >> support NAs. It suffices to change line 15 of the function:
    >> if (anyNA(x)) stop("missing values are not allowed in 'poly'")
    >> 
    >> to:
    >> if (!raw && anyNA(x)) stop("missing values are not allowed in 'poly'")
    >> 
    >> This way for raw polynomials estimation continues unimpeded. With the
    >> change above, I get this:
    >> > poly(x, degree = 2, raw=TRUE)
    >> 1 2
    >> [1,] NA NA
    >> [2,] 1 1
    >> [3,] 2 4
    >> [4,] 3 9
    >> [5,] 4 16
    >> [6,] 5 25
    >> [7,] 6 36
    >> [8,] 7 49
    >> [9,] 8 64
    >> [10,] 9 81
    >> [11,] 10 100
    >> attr(,"degree")
    >> [1] 1 2
    >> attr(,"class")
    >> [1] "poly" "matrix"
    >> 
    >> 
    >> Regards,
    >> Liviu
    >> 
    >> 
    >> >
    >> > Bill Dunlap
    >> > TIBCO Software
    >> > wdunlap tibco.com
    >> >
    >> > On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic <landronimirc at gmail.com
    >> >
    >> > wrote:
    >> >>
    >> >> Dear all,
    >> >> I'm a bit surprised by this behavior in poly:
    >> >>
    >> >> x <- c(NA, 1:10)
    >> >> poly(x, degree = 2, raw=TRUE)
    >> >> ## Error in poly(x, degree = 2, raw = TRUE) :
    >> >> ##   missing values are not allowed in 'poly'
    >> >> x^2
    >> >> ## [1] NA 1 4 9 16 25 36 49 64 81 100
    >> >>
    >> >> As you can see, poly() will fail if the vector contains NAs, whereas
    >> >> it is perfectly possible to obtain the square of the vector manually.
    >> >>
    >> >> Is there a reason for this limitation in poly?
    >> >>
    >> >> Regards,
    >> >> Liviu
    >> >>
    >> >>
    >> >> --
    >> >> Do you think you know what math is?
    >> >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
    >> >> Or what it means to be intelligent?
    >> >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
    >> >> Think again:
    >> >> http://www.ideasroadshow.com/library
    >> >>
    >> >> ______________________________________________
    >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> PLEASE do read the posting guide
    >> >> http://www.R-project.org/posting-guide.html
    >> >> and provide commented, minimal, self-contained, reproducible code.
    >> >
    >> >
    >> 
    >> 
    >> 
    >> --
    >> Do you think you know what math is?
    >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
    >> Or what it means to be intelligent?
    >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
    >> Think again:
    >> http://www.ideasroadshow.com/library
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Thu Mar 24 13:11:43 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 24 Mar 2016 08:11:43 -0400
Subject: [R] How to make a function aware of its own call arguments
Message-ID: <56F3D97F.1080607@cognigencorp.com>

Hi,

Please consider the following functions:

myf1 <- function(x,fun){
   if (is.null(fun)){
     x
   } else {
     do.call(fun, list(x))
   }
}

myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){

   if (myf1(b,fun)>0 & <c was not provided in function call>){
     c <- b
   }
   print(list(a,b,c))
}

myf2(a=2,b=3,fun=exp)
myf2(a=2,b=3,fun=exp,c=4)

I need to replace "<c was not provided in function call>" by some code 
that would make myf2 aware of it own calls and of the fact that the c 
argument was provided or not in the function calls.

Thanks for your help

Sebastien


From jdnewmil at dcn.davis.ca.us  Thu Mar 24 13:47:17 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 24 Mar 2016 05:47:17 -0700
Subject: [R] How to make a function aware of its own call arguments
In-Reply-To: <56F3D97F.1080607@cognigencorp.com>
References: <56F3D97F.1080607@cognigencorp.com>
Message-ID: <4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>

Don't provide a default value for c in the parameter list.  Then you can use the missing() function to make decisions, including whether to generate a default value for c or not.
-- 
Sent from my phone. Please excuse my brevity.

On March 24, 2016 5:11:43 AM PDT, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Hi,
>
>Please consider the following functions:
>
>myf1 <- function(x,fun){
>   if (is.null(fun)){
>     x
>   } else {
>     do.call(fun, list(x))
>   }
>}
>
>myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){
>
>   if (myf1(b,fun)>0 & <c was not provided in function call>){
>     c <- b
>   }
>   print(list(a,b,c))
>}
>
>myf2(a=2,b=3,fun=exp)
>myf2(a=2,b=3,fun=exp,c=4)
>
>I need to replace "<c was not provided in function call>" by some code 
>that would make myf2 aware of it own calls and of the fact that the c 
>argument was provided or not in the function calls.
>
>Thanks for your help
>
>Sebastien
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Thu Mar 24 14:06:06 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 24 Mar 2016 09:06:06 -0400
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <22258.46565.245172.694785@stat.math.ethz.ch>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
	<76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>
	<CAJuCY5zdiNY1LyteoG=gZFA14aShpeM0yKLTEurPAZun5413ZQ@mail.gmail.com>
	<22258.46565.245172.694785@stat.math.ethz.ch>
Message-ID: <56F3E63E.1020408@yorku.ca>

Neat!
It would be nice to complete dzipois() with the corresponding rzipois() 
and pzipois() functions.  I would have found these useful in my new book,
http://ddar.datavis.ca

-Michael

On 3/23/2016 11:27 AM, Martin Maechler wrote:
>>>>>> Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>>>>      on Tue, 22 Mar 2016 13:58:09 +0100 writes:
>
>      > dpois(0, lambda) == e^(-lambda)
>      > The wikipedia formula is
>      > ifelse(x == 0, zero + dpois(0, lambda) * (1-zero), dpois(x, lambda) *
>      > (1-zero))
>
>      > or
>
>      > ifelse(x == 0, zero + dpois(x, lambda) * (1-zero), dpois(x, lambda) *
>      > (1-zero))
>
>      > so we can move the dpois() out of the ifelse()
>
>      > ifelse(x == 0, zero, 0)  + dpois(x, lambda) * (1-zero)
>
> Nice!  Thank you, Thierry.
>
> Even nicer for symmetry reasons (and much faster) is *not* to use ifelse(),
> so we'd get
>
> dzipois <- function(x, lambda, zero)
>    (x == 0) * zero +  dpois(x, lambda) * (1-zero)
>
> However, numerically correctly adding the  'log = FALSE'
> argument which all good "density" functions have in R --
> ((and which you *should* use as  log = TRUE  for the
>    log-likelihood if you want to become more professional))
> is a bit tricky.
>
> The x == 0 case at least needs care for large lambda and/or
> small 'zero' (= pi).
> All this is related on how to accurately compute  f(L) = log(1 - exp(- L))
> which I call   log1mexp(L) in my still-not-submitted paper
> available as one of the Rmpfr vignettes at
> https://cloud.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf
>
> BTW:  There are at least 3-4 R packages which deal with zero-inflated
>        poisson in some ways, notably the recommended  'mgcv'
>        package which comes bundled with every R.
>
>
> Martin Maechler,
> ETH ZUrich
>
>      > ir. Thierry Onkelinx
>      > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>      > Forest
>      > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>      > Kliniekstraat 25
>      > 1070 Anderlecht
>      > Belgium
>
>      > To call in the statistician after the experiment is done may be no more
>      > than asking him to perform a post-mortem examination: he may be able to say
>      > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>      > The plural of anecdote is not data. ~ Roger Brinner
>      > The combination of some data and an aching desire for an answer does not
>      > ensure that a reasonable answer can be extracted from a given body of data.
>      > ~ John Tukey
>
>      > 2016-03-22 13:50 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>
>      >> And why is the first term of ifelse(x == 0, zero, 0) + dpois(x, lambda) /
>      >> (1 - zero)
>      >>
>      >> ifelse(x == 0, zero, 0)
>      >>
>      >> rather than something corresponding to
>      >>
>      >> zero+(1-zero)e^{-lambda}
>      >>
>      >> https://en.wikipedia.org/wiki/Zero-inflated_model#Zero-inflated_Poisson
>      >>
>      >> On 22 Mar 2016, at 14:25, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>      >>
>      >> Could you clarify what are the parameters and why it?s formulated that way?
>      >>
>      >> -Matti
>      >>
>      >> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>      >> wrote:
>      >>
>      >> Dear Matti,
>      >>
>      >> What about this?
>      >>
>      >> dzeroinflpois <- function(x, lambda, zero){
>      >> ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
>      >> }
>      >> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
>      >>
>      >>
>      >>
>      >> ir. Thierry Onkelinx
>      >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>      >> Forest
>      >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>      >> Kliniekstraat 25
>      >> 1070 Anderlecht
>      >> Belgium
>      >>
>      >> To call in the statistician after the experiment is done may be no more
>      >> than asking him to perform a post-mortem examination: he may be able to say
>      >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>      >> The plural of anecdote is not data. ~ Roger Brinner
>      >> The combination of some data and an aching desire for an answer does not
>      >> ensure that a reasonable answer can be extracted from a given body of data.
>      >> ~ John Tukey
>      >>
>      >> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>      >>
>      >>> I?m doing some optimisation that I first did with normal Poisson (only
>      >>> parameter theta was estimated), but now I?m doing the same with a
>      >>> zero-inflated Poisson model which
>      >>> gives me two estimated parameters theta and p (p is also pi in some
>      >>> notation).
>      >>>
>      >>> My question is, is there something equivalent to dpois that would use
>      >>> both of the parameters (or is the p parameter possibly unnecessary)?
>      >>>
>      >>> I?m calculating the ?fit? of the Poisson model
>      >>>
>      >>> i.e. like
>      >>>
>      >>> x = c(0,1,2,3,4,5,6)
>      >>> y = c(3062,587,284,103,33,4,2)
>      >>> fit1 <- sum(y)*dpois(x, est_theta)
>      >>>
>      >>> and then comparing fit1 to the real observations.
>      >>> [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>      >>> <http://www.r-project.org/posting-guide.html>
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >>
>      >>
>      >>
>
>      > [[alternative HTML version deleted]]
>
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From friendly at yorku.ca  Thu Mar 24 14:06:06 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 24 Mar 2016 09:06:06 -0400
Subject: [R] Is there dpois equivalent for zero-inflated Poisson?
In-Reply-To: <22258.46565.245172.694785@stat.math.ethz.ch>
References: <BE4EA125-4915-47F2-A7D2-73112F086DF0@kapsi.fi>
	<CAJuCY5yEhaFS+BuC+FOjBiQmh02FwZhmJCG3q=RZtNjEco7pUA@mail.gmail.com>
	<D020C12B-92EE-4AE2-8E24-C6536B4B4294@kapsi.fi>
	<76201BB4-76CC-4E5D-982A-2C2422A1D4A7@kapsi.fi>
	<CAJuCY5zdiNY1LyteoG=gZFA14aShpeM0yKLTEurPAZun5413ZQ@mail.gmail.com>
	<22258.46565.245172.694785@stat.math.ethz.ch>
Message-ID: <56F3E63E.1020408@yorku.ca>

Neat!
It would be nice to complete dzipois() with the corresponding rzipois() 
and pzipois() functions.  I would have found these useful in my new book,
http://ddar.datavis.ca

-Michael

On 3/23/2016 11:27 AM, Martin Maechler wrote:
>>>>>> Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>>>>      on Tue, 22 Mar 2016 13:58:09 +0100 writes:
>
>      > dpois(0, lambda) == e^(-lambda)
>      > The wikipedia formula is
>      > ifelse(x == 0, zero + dpois(0, lambda) * (1-zero), dpois(x, lambda) *
>      > (1-zero))
>
>      > or
>
>      > ifelse(x == 0, zero + dpois(x, lambda) * (1-zero), dpois(x, lambda) *
>      > (1-zero))
>
>      > so we can move the dpois() out of the ifelse()
>
>      > ifelse(x == 0, zero, 0)  + dpois(x, lambda) * (1-zero)
>
> Nice!  Thank you, Thierry.
>
> Even nicer for symmetry reasons (and much faster) is *not* to use ifelse(),
> so we'd get
>
> dzipois <- function(x, lambda, zero)
>    (x == 0) * zero +  dpois(x, lambda) * (1-zero)
>
> However, numerically correctly adding the  'log = FALSE'
> argument which all good "density" functions have in R --
> ((and which you *should* use as  log = TRUE  for the
>    log-likelihood if you want to become more professional))
> is a bit tricky.
>
> The x == 0 case at least needs care for large lambda and/or
> small 'zero' (= pi).
> All this is related on how to accurately compute  f(L) = log(1 - exp(- L))
> which I call   log1mexp(L) in my still-not-submitted paper
> available as one of the Rmpfr vignettes at
> https://cloud.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf
>
> BTW:  There are at least 3-4 R packages which deal with zero-inflated
>        poisson in some ways, notably the recommended  'mgcv'
>        package which comes bundled with every R.
>
>
> Martin Maechler,
> ETH ZUrich
>
>      > ir. Thierry Onkelinx
>      > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>      > Forest
>      > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>      > Kliniekstraat 25
>      > 1070 Anderlecht
>      > Belgium
>
>      > To call in the statistician after the experiment is done may be no more
>      > than asking him to perform a post-mortem examination: he may be able to say
>      > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>      > The plural of anecdote is not data. ~ Roger Brinner
>      > The combination of some data and an aching desire for an answer does not
>      > ensure that a reasonable answer can be extracted from a given body of data.
>      > ~ John Tukey
>
>      > 2016-03-22 13:50 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>
>      >> And why is the first term of ifelse(x == 0, zero, 0) + dpois(x, lambda) /
>      >> (1 - zero)
>      >>
>      >> ifelse(x == 0, zero, 0)
>      >>
>      >> rather than something corresponding to
>      >>
>      >> zero+(1-zero)e^{-lambda}
>      >>
>      >> https://en.wikipedia.org/wiki/Zero-inflated_model#Zero-inflated_Poisson
>      >>
>      >> On 22 Mar 2016, at 14:25, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>      >>
>      >> Could you clarify what are the parameters and why it?s formulated that way?
>      >>
>      >> -Matti
>      >>
>      >> On 22 Mar 2016, at 14:17, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>      >> wrote:
>      >>
>      >> Dear Matti,
>      >>
>      >> What about this?
>      >>
>      >> dzeroinflpois <- function(x, lambda, zero){
>      >> ifelse(x == 0, zero, 0) + dpois(x, lambda) / (1 - zero)
>      >> }
>      >> plot(x, dzeroinflpois(x, lambda = 10, zero = 0.2), type = "l")
>      >>
>      >>
>      >>
>      >> ir. Thierry Onkelinx
>      >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>      >> Forest
>      >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>      >> Kliniekstraat 25
>      >> 1070 Anderlecht
>      >> Belgium
>      >>
>      >> To call in the statistician after the experiment is done may be no more
>      >> than asking him to perform a post-mortem examination: he may be able to say
>      >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>      >> The plural of anecdote is not data. ~ Roger Brinner
>      >> The combination of some data and an aching desire for an answer does not
>      >> ensure that a reasonable answer can be extracted from a given body of data.
>      >> ~ John Tukey
>      >>
>      >> 2016-03-22 13:04 GMT+01:00 Matti Viljamaa <mviljamaa at kapsi.fi>:
>      >>
>      >>> I?m doing some optimisation that I first did with normal Poisson (only
>      >>> parameter theta was estimated), but now I?m doing the same with a
>      >>> zero-inflated Poisson model which
>      >>> gives me two estimated parameters theta and p (p is also pi in some
>      >>> notation).
>      >>>
>      >>> My question is, is there something equivalent to dpois that would use
>      >>> both of the parameters (or is the p parameter possibly unnecessary)?
>      >>>
>      >>> I?m calculating the ?fit? of the Poisson model
>      >>>
>      >>> i.e. like
>      >>>
>      >>> x = c(0,1,2,3,4,5,6)
>      >>> y = c(3062,587,284,103,33,4,2)
>      >>> fit1 <- sum(y)*dpois(x, est_theta)
>      >>>
>      >>> and then comparing fit1 to the real observations.
>      >>> [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>      >>> <http://www.r-project.org/posting-guide.html>
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >>
>      >>
>      >>
>
>      > [[alternative HTML version deleted]]
>
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Sebastien.Bihorel at cognigencorp.com  Thu Mar 24 15:28:57 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 24 Mar 2016 10:28:57 -0400
Subject: [R] How to make a function aware of its own call arguments
In-Reply-To: <4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>
References: <56F3D97F.1080607@cognigencorp.com>
	<4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>
Message-ID: <56F3F9A9.1070705@cognigencorp.com>

Hi,

Thanks for your suggestion.

missing(x) works only if x is not altered within the function, which is 
not the case in my actual function (which is more complex than the 
example function I send in my previous post).

Are you aware of any function what would query the original function 
call arguments no matter what happens in the function?

Sebastien

On 3/24/2016 8:47 AM, Jeff Newmiller wrote:
> Don't provide a default value for c in the parameter list. Then you 
> can use the missing() function to make decisions, including whether to 
> generate a default value for c or not.
> -- 
> Sent from my phone. Please excuse my brevity.
>
> On March 24, 2016 5:11:43 AM PDT, sbihorel 
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>
>     Hi,
>
>     Please consider the following functions:
>
>     myf1 <- function(x,fun){
>         if (is.null(fun)){
>           x
>         } else {
>           do.call(fun, list(x))
>         }
>     }
>
>     myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){
>
>         if (myf1(b,fun)>0 & <c was not provided in function call>){
>           c <- b
>         }
>         print(list(a,b,c))
>     }
>
>     myf2(a=2,b=3,fun=exp)
>     myf2(a=2,b=3,fun=exp,c=4)
>
>     I need to replace "<c was not provided in function call>" by some code
>     that would make myf2 aware of it own calls and of the fact that the c
>     argument was provided or not in the function calls.
>
>     Thanks for your help
>
>     Sebastien
>
>     ------------------------------------------------------------------------
>
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE d
>       o read
>     the posting guidehttp://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
-- Sebastien Bihorel Associate Director, Pharmacometrics Buffalo Office: 
+1-716-633-3463 ext. 323 | Website <http://www.cognigencorp.com> 
<http://www.simulations-plus.com/Default.aspx>


From neale at sinenomine.net  Thu Mar 24 15:32:53 2016
From: neale at sinenomine.net (Neale Ferguson)
Date: Thu, 24 Mar 2016 14:32:53 +0000
Subject: [R] Problems installing docopt
In-Reply-To: <02FC03A0-43F9-4911-952B-E29CEF0260CD@comcast.net>
References: <D3188783.6065E%neale@sinenomine.net>
	<02FC03A0-43F9-4911-952B-E29CEF0260CD@comcast.net>
Message-ID: <D3196BA5.608D4%neale@sinenomine.net>

The problem was that this was in a Docker container which is based on a
strip down base image. While I had restored glibc-common and its locale
information, there was still stuff removed from glibc that was required.
Reinstalled it and building cleanly.

Thanks, Neale

On 3/23/16, 11:53 PM, +ACI-David Winsemius+ACI- +ADw-dwinsemius+AEA-comcast.net+AD4- wrote:

+AD4-
+AD4APg- On Mar 23, 2016, at 2:48 PM, Neale Ferguson +ADw-neale+AEA-sinenomine.net+AD4-
+AD4APg-wrote:
+AD4APg- 
+AD4APg- Hi,
+AD4APg- I+ALk-ve seen similar questions when googling this problem but none of them
+AD4APg- seem directly related to what I am seeing. Doing an install.r docopt
+AD4APg-craps
+AD4APg- out with stringi build complaining:
+AD4APg- 
+AD4APg- Error in iconv(x, +ACI-latin1+ACI-, +ACI-ASCII+ACI-) :
+AD4APg-   unsupported conversion from 'latin1' to 'ASCII'


From murdoch.duncan at gmail.com  Thu Mar 24 15:40:52 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Mar 2016 10:40:52 -0400
Subject: [R] How to make a function aware of its own call arguments
In-Reply-To: <56F3F9A9.1070705@cognigencorp.com>
References: <56F3D97F.1080607@cognigencorp.com>
	<4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>
	<56F3F9A9.1070705@cognigencorp.com>
Message-ID: <56F3FC74.9020501@gmail.com>

On 24/03/2016 10:28 AM, sbihorel wrote:
> Hi,
>
> Thanks for your suggestion.
>
> missing(x) works only if x is not altered within the function, which is
> not the case in my actual function (which is more complex than the
> example function I send in my previous post).

That's not quite true:  missing(x) works *before* x is altered within 
the function.  It works even if x has a default value.

So your myf2 could just use missing(c):

myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){

    if (myf1(b,fun)>0 && missing(c)){
      c <- b
    }
    print(list(a,b,c))
}


>
> Are you aware of any function what would query the original function
> call arguments no matter what happens in the function?

The match.call() function does that, but I think you don't need that:

f <- function(x = 1, ...) {
   x <- 2
   match.call()
}
f(3)
## Prints:  f(x = 3)

Duncan Murdoch

>
> Sebastien
>
> On 3/24/2016 8:47 AM, Jeff Newmiller wrote:
> > Don't provide a default value for c in the parameter list. Then you
> > can use the missing() function to make decisions, including whether to
> > generate a default value for c or not.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On March 24, 2016 5:11:43 AM PDT, sbihorel
> > <Sebastien.Bihorel at cognigencorp.com> wrote:
> >
> >     Hi,
> >
> >     Please consider the following functions:
> >
> >     myf1 <- function(x,fun){
> >         if (is.null(fun)){
> >           x
> >         } else {
> >           do.call(fun, list(x))
> >         }
> >     }
> >
> >     myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){
> >
> >         if (myf1(b,fun)>0 & <c was not provided in function call>){
> >           c <- b
> >         }
> >         print(list(a,b,c))
> >     }
> >
> >     myf2(a=2,b=3,fun=exp)
> >     myf2(a=2,b=3,fun=exp,c=4)
> >
> >     I need to replace "<c was not provided in function call>" by some code
> >     that would make myf2 aware of it own calls and of the fact that the c
> >     argument was provided or not in the function calls.
> >
> >     Thanks for your help
> >
> >     Sebastien
> >
> >     ------------------------------------------------------------------------
> >
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE d
> >       o read
> >     the posting guidehttp://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> -- Sebastien Bihorel Associate Director, Pharmacometrics Buffalo Office:
> +1-716-633-3463 ext. 323 | Website <http://www.cognigencorp.com>
> <http://www.simulations-plus.com/Default.aspx>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Thu Mar 24 16:04:30 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 24 Mar 2016 11:04:30 -0400
Subject: [R] How to make a function aware of its own call arguments
In-Reply-To: <56F3FC74.9020501@gmail.com>
References: <56F3D97F.1080607@cognigencorp.com>
	<4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>
	<56F3F9A9.1070705@cognigencorp.com> <56F3FC74.9020501@gmail.com>
Message-ID: <56F401FE.9060104@cognigencorp.com>

Thanks for the precision.

On 3/24/2016 10:40 AM, Duncan Murdoch wrote:
> On 24/03/2016 10:28 AM, sbihorel wrote:
>> Hi,
>>
>> Thanks for your suggestion.
>>
>> missing(x) works only if x is not altered within the function, which is
>> not the case in my actual function (which is more complex than the
>> example function I send in my previous post).
>
> That's not quite true:  missing(x) works *before* x is altered within 
> the function.  It works even if x has a default value.
>
> So your myf2 could just use missing(c):
>
> myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){
>
>    if (myf1(b,fun)>0 && missing(c)){
>      c <- b
>    }
>    print(list(a,b,c))
> }
>
>
>>
>> Are you aware of any function what would query the original function
>> call arguments no matter what happens in the function?
>
> The match.call() function does that, but I think you don't need that:
>
> f <- function(x = 1, ...) {
>   x <- 2
>   match.call()
> }
> f(3)
> ## Prints:  f(x = 3)
>
> Duncan Murdoch
>
>>
>> Sebastien
>>
>> On 3/24/2016 8:47 AM, Jeff Newmiller wrote:
>> > Don't provide a default value for c in the parameter list. Then you
>> > can use the missing() function to make decisions, including whether to
>> > generate a default value for c or not.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On March 24, 2016 5:11:43 AM PDT, sbihorel
>> > <Sebastien.Bihorel at cognigencorp.com> wrote:
>> >
>> >     Hi,
>> >
>> >     Please consider the following functions:
>> >
>> >     myf1 <- function(x,fun){
>> >         if (is.null(fun)){
>> >           x
>> >         } else {
>> >           do.call(fun, list(x))
>> >         }
>> >     }
>> >
>> >     myf2 <- function(a=1, b=2, fun=NULL, c=myfun1(b,fun)){
>> >
>> >         if (myf1(b,fun)>0 & <c was not provided in function call>){
>> >           c <- b
>> >         }
>> >         print(list(a,b,c))
>> >     }
>> >
>> >     myf2(a=2,b=3,fun=exp)
>> >     myf2(a=2,b=3,fun=exp,c=4)
>> >
>> >     I need to replace "<c was not provided in function call>" by 
>> some code
>> >     that would make myf2 aware of it own calls and of the fact that 
>> the c
>> >     argument was provided or not in the function calls.
>> >
>> >     Thanks for your help
>> >
>> >     Sebastien
>> >
>> > 
>> ------------------------------------------------------------------------
>> >
>> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >     https://stat.ethz.ch/mailman/listinfo/r-help
>> >     PLEASE d
>> >       o read
>> >     the posting guidehttp://www.R-project.org/posting-guide.html
>> >     and provide commented, minimal, self-contained, reproducible code.
>> >
>> -- Sebastien Bihorel Associate Director, Pharmacometrics Buffalo Office:
>> +1-716-633-3463 ext. 323 | Website <http://www.cognigencorp.com>
>> <http://www.simulations-plus.com/Default.aspx>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Sebastien Bihorel
Associate Director, Pharmacometrics
Buffalo Office: +1-716-633-3463 ext. 323 | Website 
<http://www.cognigencorp.com>
<http://www.simulations-plus.com/Default.aspx>


From S.Ellison at LGCGroup.com  Thu Mar 24 16:16:53 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 24 Mar 2016 15:16:53 +0000
Subject: [R] How to make a function aware of its own call arguments
In-Reply-To: <56F3F9A9.1070705@cognigencorp.com>
References: <56F3D97F.1080607@cognigencorp.com>
	<4E4DF6B6-1787-497E-B46E-172ABCC68D1D@dcn.davis.ca.us>
	<56F3F9A9.1070705@cognigencorp.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D128F50A@GBTEDVPEXCMB04.corp.lgc-group.com>


> Are you aware of any function what would query the original function call
> arguments no matter what happens in the function?

Use missing() first.
If you can't use missing() first, or use it early in a parent function and pass a flag, you could perhaps pass a copy of the parent function call to the daughter function and see if an argument was included in the call. Example:

f1 <- function(x,  ...) {
	if(missing(x)) x<-3
	f2(x, match.call())
}

f2 <- function(x, f1.call) {
	testx <- if(is.null(f1.call$x)) "x was absent in f1" else "x specified in f1"
	xval <- paste("x now set to", x)
	
	cat(sprintf("%s\n%s\n",testx, xval))
	
}

f1()

f1(x=2)





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From akothapa at umass.edu  Thu Mar 24 13:13:35 2016
From: akothapa at umass.edu (Anusha Kothapalli)
Date: Thu, 24 Mar 2016 08:13:35 -0400
Subject: [R] Fwd: question on constrOptim
In-Reply-To: <CAP2wHKk36-3tV3XRqrRmtfVs6H36cKLeQOaA_zJB+JwTnTU0+w@mail.gmail.com>
References: <CAP2wHKk36-3tV3XRqrRmtfVs6H36cKLeQOaA_zJB+JwTnTU0+w@mail.gmail.com>
Message-ID: <CAP2wHKmjJZ=WWR00ifEVS2YRAf-36c-z1riBn9DSPL_VUzoRgw@mail.gmail.com>

---------- Forwarded message ----------
From: *Anusha Kothapalli* <akothapa at umass.edu>
Date: Wednesday, March 23, 2016
Subject: question on constrOptim
To: R-core at r-project.org


To Whom It May Concern,

We are using constrOptim to maximize a log likelihood function. The
constrOptim call returns values, however, they are *exactly identical* to
the initial values we input. Our ci, ui, gradient, etc. match the
requirements for use of this function. So we are out of ideas. Would you
happen to know how to make constrOptim run multiple iterations and/or
return values that aren't equal to our initial values?
Any input you have would be greatly appreciated!

Thanks :)

	[[alternative HTML version deleted]]


From heshamibb at yahoo.com  Thu Mar 24 13:08:38 2016
From: heshamibb at yahoo.com (hehsham alpukhity)
Date: Thu, 24 Mar 2016 12:08:38 +0000 (UTC)
Subject: [R] Export the result k-means cluster to CSV file
References: <450698016.4737247.1458821318483.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <450698016.4737247.1458821318483.JavaMail.yahoo@mail.yahoo.com>

Hello Everyone :?i have ?done the clustering ?process by k-means cluster, then i try to save[Export ] the groups of clustering, to txt, or CSV files , how i can do that #########################################clusrer.data <- function(data,n) {
miRNA.exp.cluster <- scale(t(miRNA.exp))
k.means.fit <- kmeans(miRNA.exp.cluster,n)k.means.fit#i try to save the results of k-means cluster by this code :?
k.means.fit <- as.data.frame(k.means.fit)write.csv(k.means.fit, file="k-meanReslut.csv")

#x<-k.means.fit$clusters#write.csv(x, file="k-meanReslut.csv")

}
the result:K-means clustering with 5 clusters of sizes 8, 6, 7, 20, 18
####################33

thanks for all.
??

	[[alternative HTML version deleted]]


From fromnorden at gmail.com  Thu Mar 24 14:34:45 2016
From: fromnorden at gmail.com (Andreu Ferrero Gmail)
Date: Thu, 24 Mar 2016 14:34:45 +0100
Subject: [R] glmer() -> corrected AUC optimism by bootstraping technic
	bootMer() [internal validation of a mixed-effects-model]
References: <AB462640-4B92-4112-9EB8-4F65DABC69DB@gmail.com>
Message-ID: <0AC52DE0-B964-4A18-9106-0CF7C8B6A77D@gmail.com>



> 
> 
> I would like to do an internal validation of a discriminative ability of a mixed effects models.
> 
> Here is my scrip:
> 
> ###########################
> ####bootMer-> boot AUC#####
> ###########################
> 
> library(lme4)
> library(lattice)
> data(cbpp)
> 
> #fit a model
> 
> cbpp$Y<-cbpp$incidence>=1
> glmm<-glmer(Y~period + size + (1|herd), family=binomial, data=cbpp)
> glmm
> 
> ##### funcio: versio 3 - no cal posar endpoint en la funcio
> ##########################################################
> 
> 
> 
> AUCFun <- function(fit) {
>  library(pROC)
>  pred<-predict(fit, type="response")
>  AUC<-as.numeric(auc(fit at resp$y, pred))
> }
> 
> 
> #test
> 
> (AUCFun(glmm))
> 
> ###run bootMer: AUCFun
> 
> 
> 
> system.time(AUC.boot <- bootMer(glmm,nsim=100,FUN=AUCFun,seed=1982, use.u=TRUE,
>                                type="parametric", parallel="multicore", ncpus=2))
> 
> 
> #...
> 
> (boot.ci(AUC.boot, index =c(1,1), type="norm"))
> 
> roc(cbpp$Y, predict(glmm, type="response"))
> 
> 
> #Now it seems more reasonable, bias as "optimism"... but still do not know #if I am just doing a AUC with bootstrap CI 
> **************************************************************************************************************************************
> 
> 
> 


From murdoch.duncan at gmail.com  Thu Mar 24 18:09:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Mar 2016 13:09:42 -0400
Subject: [R] Fwd: question on constrOptim
In-Reply-To: <CAP2wHKmjJZ=WWR00ifEVS2YRAf-36c-z1riBn9DSPL_VUzoRgw@mail.gmail.com>
References: <CAP2wHKk36-3tV3XRqrRmtfVs6H36cKLeQOaA_zJB+JwTnTU0+w@mail.gmail.com>
	<CAP2wHKmjJZ=WWR00ifEVS2YRAf-36c-z1riBn9DSPL_VUzoRgw@mail.gmail.com>
Message-ID: <56F41F56.5000404@gmail.com>

On 24/03/2016 8:13 AM, Anusha Kothapalli wrote:
> ---------- Forwarded message ----------
> From: *Anusha Kothapalli* <akothapa at umass.edu>
> Date: Wednesday, March 23, 2016
> Subject: question on constrOptim
> To: R-core at r-project.org
>
>
> To Whom It May Concern,
>
> We are using constrOptim to maximize a log likelihood function. The
> constrOptim call returns values, however, they are *exactly identical* to
> the initial values we input. Our ci, ui, gradient, etc. match the
> requirements for use of this function. So we are out of ideas. Would you
> happen to know how to make constrOptim run multiple iterations and/or
> return values that aren't equal to our initial values?
> Any input you have would be greatly appreciated!

Modify your objective function to print out the arguments it is given 
and the result it produces.  You'll likely see something wrong when you 
look at those.

If you still can't figure out the problem, simplify things enough to 
post to R-help, and post it there.  It needs to be in a form that 
someone else can run.  (Don't email it just to me, send it to the list.)

Duncan Murdoch


From ulhaqz at gmail.com  Thu Mar 24 12:16:43 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Thu, 24 Mar 2016 16:16:43 +0500
Subject: [R] R-help Digest, Vol 157, Issue 25
In-Reply-To: <mailman.3.1458817202.12516.r-help@r-project.org>
References: <mailman.3.1458817202.12516.r-help@r-project.org>
Message-ID: <CADw4CkvoPC+wwzYj2L4jLtvE90H=vQ9-qGLAV5NZGbT-4O+M8A@mail.gmail.com>

Thanks to Boris Steipe, Jim Lemon and  Ivan Calandra for replying.

I messed up while copying, there are equal number of values for each
country.

@ Ivan,

In case there were different number of values, and we wanted to fill in with
1) NA, or
2)  "average of the rest of values"

in the missing values, how would we "impute" such data.


Thanks again /

	[[alternative HTML version deleted]]


From fabio.monteiro1992 at gmail.com  Thu Mar 24 18:13:44 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Thu, 24 Mar 2016 17:13:44 +0000
Subject: [R] package FD
In-Reply-To: <CA+8X3fVcmLQPmT23un3LyiW2N=hvXgUT88erS68Ek_6Rktr5cQ@mail.gmail.com>
References: <CAG0T74ru-HY04WjGnxC=q8k3VKVqLYAh+gB=-UpE_pjErJejag@mail.gmail.com>
	<CA+8X3fWZjaE==TBGFqbwisyX2P2FRh=yqzcPZZ+FHDJviS2ugQ@mail.gmail.com>
	<CAG0T74pktgKpfbpjCGb3dzHPg-oEbM6gR9OfrD_6G3D8iJW9_g@mail.gmail.com>
	<CA+8X3fXxEO9bFt4VUCo5KYveVOzp=n6_dSnyAEsA=tkKGbu3Uw@mail.gmail.com>
	<CAG0T74qM12ZTS99zRqDDd8fjKEr2U4+ZgBsMHHvYcqs-0Ab=SA@mail.gmail.com>
	<CAG0T74putX0RxgpnG2bbg55MXiJWruJqGjnC1dz7VSsCREHz+g@mail.gmail.com>
	<CA+8X3fWxx6OW_PKYTMuiSnTkL+TNO4yJg=ui3POPQ7TCTR-jVA@mail.gmail.com>
	<CAG0T74qy9gddUVQgwJ5eY+AZa=qgWrznfBJdWLstvo8TnkmwkA@mail.gmail.com>
	<DE25A050-0E7C-4B18-A1D5-8279C1ADBE7E@dcn.davis.ca.us>
	<CA+8X3fVcmLQPmT23un3LyiW2N=hvXgUT88erS68Ek_6Rktr5cQ@mail.gmail.com>
Message-ID: <CAG0T74rQe5epHDGTdDx6LQtSSs9ydQ13TGZ0-_my1qFrGt7stg@mail.gmail.com>

Hi again

Is there any way to check the relations between dbFD indexes?

Function cor for example? I can't manage to put the informations correctly

I want to see the relationships between the dbFD output (nbsp, sing.sp,
FRic, FEve, FDiv, FDis and RaoQ)

How should I type it?

Thank you

F?bio

2016-03-06 21:48 GMT+00:00 Jim Lemon <drjimlemon at gmail.com>:

> The values in a$x do look numeric. What do you get from:
>
> class(a$x)
>
> If the result is "factor", as it was for your ft$trait3 variable (and
> I hope that a$x is the same variable with a different name), then at
> least one of those values must have been read in as non-numeric. The
> possible reasons for this are many as Jeff noted and may be a
> non-printing character that has crept into your original data file. If
> your data set is as small as your example, I would start by loading
> the original data file into a hex editor and looking for a character
> that shouldn't be there. I once had to write a program in C that
> scanned very large files of customer data to find just such
> troublemakers and tell me where they were.
>
> Jim
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 24 18:18:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 24 Mar 2016 10:18:41 -0700
Subject: [R] Fwd: question on constrOptim
In-Reply-To: <CAP2wHKmjJZ=WWR00ifEVS2YRAf-36c-z1riBn9DSPL_VUzoRgw@mail.gmail.com>
References: <CAP2wHKk36-3tV3XRqrRmtfVs6H36cKLeQOaA_zJB+JwTnTU0+w@mail.gmail.com>
	<CAP2wHKmjJZ=WWR00ifEVS2YRAf-36c-z1riBn9DSPL_VUzoRgw@mail.gmail.com>
Message-ID: <675ACC3B-F681-4A90-A64F-C0043B398342@dcn.davis.ca.us>

You are unlikely to get help on this without a reproducible example. One obvious possibility is that those values are already optimal. Another is that you are not invoking the optimization properly. 
-- 
Sent from my phone. Please excuse my brevity.

On March 24, 2016 5:13:35 AM PDT, Anusha Kothapalli <akothapa at umass.edu> wrote:
>---------- Forwarded message ----------
>From: *Anusha Kothapalli* <akothapa at umass.edu>
>Date: Wednesday, March 23, 2016
>Subject: question on constrOptim
>To: R-core at r-project.org
>
>
>To Whom It May Concern,
>
>We are using constrOptim to maximize a log likelihood function. The
>constrOptim call returns values, however, they are *exactly identical*
>to
>the initial values we input. Our ci, ui, gradient, etc. match the
>requirements for use of this function. So we are out of ideas. Would
>you
>happen to know how to make constrOptim run multiple iterations and/or
>return values that aren't equal to our initial values?
>Any input you have would be greatly appreciated!
>
>Thanks :)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 24 18:21:16 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 24 Mar 2016 10:21:16 -0700
Subject: [R] glmer() -> corrected AUC optimism by bootstraping technic
 bootMer() [internal validation of a mixed-effects-model]
In-Reply-To: <0AC52DE0-B964-4A18-9106-0CF7C8B6A77D@gmail.com>
References: <AB462640-4B92-4112-9EB8-4F65DABC69DB@gmail.com>
	<0AC52DE0-B964-4A18-9106-0CF7C8B6A77D@gmail.com>
Message-ID: <CAGxFJbTXKj9D+q+2ROwaUa48hRWb9M0-VYK4=Qv6tNT_kZ0xrQ@mail.gmail.com>

1. I cannot find a question here. Maybe I missed it. Maybe you should
be clearer.

2. You should most this on the mixed-models list, rather than here:

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 24, 2016 at 6:34 AM, Andreu Ferrero Gmail
<fromnorden at gmail.com> wrote:
>
>
>>
>>
>> I would like to do an internal validation of a discriminative ability of a mixed effects models.
>>
>> Here is my scrip:
>>
>> ###########################
>> ####bootMer-> boot AUC#####
>> ###########################
>>
>> library(lme4)
>> library(lattice)
>> data(cbpp)
>>
>> #fit a model
>>
>> cbpp$Y<-cbpp$incidence>=1
>> glmm<-glmer(Y~period + size + (1|herd), family=binomial, data=cbpp)
>> glmm
>>
>> ##### funcio: versio 3 - no cal posar endpoint en la funcio
>> ##########################################################
>>
>>
>>
>> AUCFun <- function(fit) {
>>  library(pROC)
>>  pred<-predict(fit, type="response")
>>  AUC<-as.numeric(auc(fit at resp$y, pred))
>> }
>>
>>
>> #test
>>
>> (AUCFun(glmm))
>>
>> ###run bootMer: AUCFun
>>
>>
>>
>> system.time(AUC.boot <- bootMer(glmm,nsim=100,FUN=AUCFun,seed=1982, use.u=TRUE,
>>                                type="parametric", parallel="multicore", ncpus=2))
>>
>>
>> #...
>>
>> (boot.ci(AUC.boot, index =c(1,1), type="norm"))
>>
>> roc(cbpp$Y, predict(glmm, type="response"))
>>
>>
>> #Now it seems more reasonable, bias as "optimism"... but still do not know #if I am just doing a AUC with bootstrap CI
>> **************************************************************************************************************************************
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Thu Mar 24 18:49:49 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 24 Mar 2016 17:49:49 +0000
Subject: [R] Export the result k-means cluster to CSV file
In-Reply-To: <450698016.4737247.1458821318483.JavaMail.yahoo@mail.yahoo.com>
References: <450698016.4737247.1458821318483.JavaMail.yahoo.ref@mail.yahoo.com>
	<450698016.4737247.1458821318483.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D128F582@GBTEDVPEXCMB04.corp.lgc-group.com>

> Hello Everyone :?i have ?done the clustering ?process by k-means cluster, then i
> try to save[Export ] the groups of clustering, to txt, or CSV files , how i can do
> that 

Depends what you want.
You can save the whole object for reloading using save()

The cluster members can be written to text files using write(cl$cluster, file="<some file name>").
The whole thing can be written, without names, using something like

lapply(cl, write, file="cluster.txt", append=TRUE)
#Using cl from the first example in ?kmeans

If you need sensible breaks and names in the file, you'll have to roll your own alternative write routines. For example

Write <- function(NN, x, filename="cluster.txt", ...) {
	write(NN, filename, append=TRUE, ...)
	write(x[[NN]], filename, append=TRUE, ...)
	cat("\n", file=filename, append=TRUE, ...)
}

lapply(names(cl), Write, x=cl, filename="myclust.txt")

(Ignore the NULLs returned)

Anything more structured than that and you'll have to write a write.kmeans replacement for write that structures the results as you need them later.


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From rainbowafmb at gmail.com  Thu Mar 24 19:08:51 2016
From: rainbowafmb at gmail.com (Tsai Rainbow)
Date: Thu, 24 Mar 2016 19:08:51 +0100
Subject: [R] K mean clustering with extra constraints
Message-ID: <CAPkig1XsmSWBQeLAQ5JrQWdcxzYx-4ZE3MFEhvHj5uwhBrqarA@mail.gmail.com>

Hi, I am a new R user. I have seen the use of kmeans in clustering.
However, I would like to ask how I can add more constraints to the kmeans.
For example, I have a set of data for a 10 nodes network,

price = c(84, 96, 57, 53, 90, 94, 81, 66, 93, 54)

I want to use K mean to to group this set of data into two group. However,
nodes in the same group should be in the same group. they are connected as
below.

 mymatrix <- rbind(
+      c(1,1,2,3,3,3,2,1,1,1),
+      c(1,1,1,2,2,2,1,1,1,1),
+      c(2,1,1,1,1,1,1,1,2,2),
+      c(3,2,1,1,1,1,1,2,3,3),
+      c(3,2,1,1,1,1,1,2,3,3),
+      c(3,2,1,1,1,1,1,2,2,2),
+      c(2,1,1,1,1,1,1,1,2,2),
+      c(1,1,1,2,2,2,1,1,1,1),
+      c(1,1,2,3,3,2,2,1,1,1),
+      c(1,1,2,3,3,2,2,1,1,1))

How can I do it in R. I greatly appreciate your help. I wish a happy
Easter.

Hanna

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Mar 24 19:12:31 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 24 Mar 2016 14:12:31 -0400
Subject: [R] R-help Digest, Vol 157, Issue 25
In-Reply-To: <CADw4CkvoPC+wwzYj2L4jLtvE90H=vQ9-qGLAV5NZGbT-4O+M8A@mail.gmail.com>
References: <mailman.3.1458817202.12516.r-help@r-project.org>
	<CADw4CkvoPC+wwzYj2L4jLtvE90H=vQ9-qGLAV5NZGbT-4O+M8A@mail.gmail.com>
Message-ID: <C0D5C337-F13A-4048-A1BC-2D08EE122D28@utoronto.ca>

If the number of values are always the same, the proposed strategies will work for you. If they are not the same, you need a completely different approach. Most importantly, you will need to figure out which columns correspond to missing values. Is it always the last ones that are dropped? If not, then you have a problem because the values will be misaligned and you can't fix that unless you know what values to expect.

Proper imputation depends on the semantics of the data, there are no (sensible) general rules. You need to consider whether the values are missing at random, or whether there is a higher probability for smaller values to be missing etc. That will determine whether you should be imputing from row-averages, column averages, averages over a defined subset - or perhaps better than averages: replacing with random observed values. This _really_ depends on the data and the objectives of your analysis.

B.


On Mar 24, 2016, at 7:16 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:

> Thanks to Boris Steipe, Jim Lemon and  Ivan Calandra for replying.
> 
> I messed up while copying, there are equal number of values for each
> country.
> 
> @ Ivan,
> 
> In case there were different number of values, and we wanted to fill in with
> 1) NA, or
> 2)  "average of the rest of values"
> 
> in the missing values, how would we "impute" such data.
> 
> 
> Thanks again /
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Thu Mar 24 23:31:44 2016
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Thu, 24 Mar 2016 17:31:44 -0500
Subject: [R] K mean clustering with extra constraints
In-Reply-To: <CAPkig1XsmSWBQeLAQ5JrQWdcxzYx-4ZE3MFEhvHj5uwhBrqarA@mail.gmail.com>
References: <CAPkig1XsmSWBQeLAQ5JrQWdcxzYx-4ZE3MFEhvHj5uwhBrqarA@mail.gmail.com>
Message-ID: <20160324173144.07752a3d3e04ab30813b5958@inbox.com>

Hannah,

Let me see if I can understand your question. 

You have 10 observations of a single variable (perhaps some sort of price?).

You also have an equivalence matrix between these observations (which you possibly called nodes) which stipulates if they are connected together or not. Given that you have this matrix, it is not clear to me why you want further (k-means or other) clustering.

The only thing that seems to me to be reasonable to check is whether two or more of the groups can be merged. But that has nothing to do with clustering.

I may have misunderstood the problem, so sorry. 

Btw, no, the k-means function in R can not handle constraints. 

Ranjan



On Thu, 24 Mar 2016 19:08:51 +0100 Tsai Rainbow <rainbowafmb at gmail.com> wrote:

> Hi, I am a new R user. I have seen the use of kmeans in clustering.
> However, I would like to ask how I can add more constraints to the kmeans.
> For example, I have a set of data for a 10 nodes network,
> 
> price = c(84, 96, 57, 53, 90, 94, 81, 66, 93, 54)
> 
> I want to use K mean to to group this set of data into two group. However,
> nodes in the same group should be in the same group. they are connected as
> below.
> 
>  mymatrix <- rbind(
> +      c(1,1,2,3,3,3,2,1,1,1),
> +      c(1,1,1,2,2,2,1,1,1,1),
> +      c(2,1,1,1,1,1,1,1,2,2),
> +      c(3,2,1,1,1,1,1,2,3,3),
> +      c(3,2,1,1,1,1,1,2,3,3),
> +      c(3,2,1,1,1,1,1,2,2,2),
> +      c(2,1,1,1,1,1,1,1,2,2),
> +      c(1,1,1,2,2,2,1,1,1,1),
> +      c(1,1,2,3,3,2,2,1,1,1),
> +      c(1,1,2,3,3,2,2,1,1,1))
> 
> How can I do it in R. I greatly appreciate your help. I wish a happy
> Easter.
> 
> Hanna
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Send any screenshot to your friends in seconds...
Works in all emails, instant messengers, blogs, forums and social networks.
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if2 for FREE


From plessthanpointohfive at gmail.com  Thu Mar 24 22:14:53 2016
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Thu, 24 Mar 2016 21:14:53 +0000
Subject: [R] Trouble reshaping data to my satisfaction
In-Reply-To: <F94335071BCFAD4888499D87E41D3F757397320E@EMBX-CLFT4.cdc.gov>
References: <F94335071BCFAD4888499D87E41D3F757397320E@EMBX-CLFT4.cdc.gov>
Message-ID: <CAOxgQ=XLQN7ZdwFz+NbSXJ3nEi3KUkUsKZDZ0QzhVs6J73bB7g@mail.gmail.com>

#I am having a lot of trouble reshaping this data.
#This is just an examination of sample size on the margin of error that I
did for a colleague.
#Nothing complicated.
#But restructuring the data...another story

#Here's code to produce the dataset:


n <- seq(10000, 100000, by=10000)

P <- seq(0.1, 0.5, by=0.1)

Meff <- seq(3, 8, by=1)


# 4 age groups by 2 sex categories - these are population distribution
sizes - order is males 18-29, females 18-29, males 30-44,females 30-44,
males 45-59, females 45-59, males 60+, females 60+

Age1 <- data.frame(matrix(c(0.196598808, 0.224390935, 0.149289474,
0.151446387,0.08750253, 0.076399683, 0.060799283, 0.053572898), nrow=4,
ncol=2, byrow=T, dimnames=list(seq(1,4, by=1), c("Males", "Females"))))

MOE <- NULL

for (i in n){
   for (p in P){
      for (m in Meff){
         for (a in Age1[,1]){

         ni <- i * a
         M <- sqrt((1.92^2)*p*(1-p)*m/ni)
  dta <- data.frame(a, i, ni, p, m, M)

         colnames(dta) <- c("Proportion", "Total_n", "Stratum_n", "P",
"Meff", "MOE")

         dta$Sex <- "Males"
MOE <- rbind(MOE, dta)

}

         for (a in Age1[,2]){

         ni <- i * a
         M <- sqrt((1.92^2)*p*(1-p)*m/ni)
  dta <- data.frame(a, i, ni, p, m, M)

         colnames(dta) <- c("Proportion", "Total_n", "Stratum_n", "P",
"Meff", "MOE")

         dta$Sex <- "Females"
MOE <- rbind(MOE, dta)

}
}
}
}

# What I want is data that looks like:
# Meff  Proportion  Sample Size  Males_0.1 Females_0.1 Males_0.2
Females_0.2 ..... Males_0.5 Females_0.5

#I'm stumped on how to reshape this.

#I tried this but it gave me the attached output (yuck):


library(reshape2)

library(plyr)


tmp <- ddply(MOE, .(Meff), mutate, id=paste(Meff, Sex, seq_along(MOE)))

wd <- dcast(tmp, id + Meff ~ P + Sex, value.var="MOE")

From hiroysato at gmail.com  Fri Mar 25 05:49:52 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Fri, 25 Mar 2016 04:49:52 +0000
Subject: [R] How to add no data entries into current dataframe?
Message-ID: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>

Hello members

Question

Could you tell me how to add ID 100, 104, 105 values with zero?

1, Source data


ID 100, 104 and 105 has no values.


> s
ID DATE VAR CODE
1 101 20160301 1 PDT1
2 102 20160301 1 PDT2
3 103 20160301 1 PDT3
4 103 20160302 1 PDT3

s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
structure(c(1L,
2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")), .Names
= c("ID",
"DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
-4L))

src <- 100:106


2, Expect output

ID PDT1 PDT2 PDT3
1 100 0 0 0
2 101 1 0 0
3 102 0 1 0
4 103 0 0 2
5 104 0 0 0
6 105 0 0 0

3, Convert process.

I can convert data "s" like following.

> library(reshape2)
> dcast(s,ID ~ CODE, value.var="VAR",sum)
ID PDT1 PDT2 PDT3
1 101 1 0 0
2 102 0 1 0
3 103 0 0 2

Could you tell me how to add 100, 104, 105 values into convert results?


Regards.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Mar 25 05:58:11 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 25 Mar 2016 04:58:11 +0000
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
Message-ID: <CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>

Hi Hiroyuki,

The row bind function rbind() is what you need

s <- dcast(s,ID ~ CODE, value.var="VAR",sum)
df2 <- data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0)
rbind(s, df2)

hope this helps
Ulrik

On Fri, 25 Mar 2016 at 05:52 Hiroyuki Sato <hiroysato at gmail.com> wrote:

> Hello members
>
> Question
>
> Could you tell me how to add ID 100, 104, 105 values with zero?
>
> 1, Source data
>
>
> ID 100, 104 and 105 has no values.
>
>
> > s
> ID DATE VAR CODE
> 1 101 20160301 1 PDT1
> 2 102 20160301 1 PDT2
> 3 103 20160301 1 PDT3
> 4 103 20160302 1 PDT3
>
> s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
> 20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
> structure(c(1L,
> 2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")), .Names
> = c("ID",
> "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
> -4L))
>
> src <- 100:106
>
>
> 2, Expect output
>
> ID PDT1 PDT2 PDT3
> 1 100 0 0 0
> 2 101 1 0 0
> 3 102 0 1 0
> 4 103 0 0 2
> 5 104 0 0 0
> 6 105 0 0 0
>
> 3, Convert process.
>
> I can convert data "s" like following.
>
> > library(reshape2)
> > dcast(s,ID ~ CODE, value.var="VAR",sum)
> ID PDT1 PDT2 PDT3
> 1 101 1 0 0
> 2 102 0 1 0
> 3 103 0 0 2
>
> Could you tell me how to add 100, 104, 105 values into convert results?
>
>
> Regards.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hiroysato at gmail.com  Fri Mar 25 06:09:46 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Fri, 25 Mar 2016 05:09:46 +0000
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
	<CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>
Message-ID: <CA+Tq-RoqZjt9uMob=-2kUPGwnUwj875BL3Y=tvOn4KFf-feSRA@mail.gmail.com>

Hello Ulrik

Thank you for replying.

The real data has many IDs( about 3,000 IDS). So I want to find missing
values with function or something.
If 104 not in s, then add 104 value with all column zero.

And also real data has many columns( 80 ~ 5,000, columns. it is not fixed
length ).
So I would like to add values with function or something too

ex) I can't write following statement.
  data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0, ... PDT5000 =
0)

Do you have any good idea?

Regards.




2016?3?25?(?) 13:58 Ulrik Stervbo <ulrik.stervbo at gmail.com>:

> Hi Hiroyuki,
>
> The row bind function rbind() is what you need
>
> s <- dcast(s,ID ~ CODE, value.var="VAR",sum)
> df2 <- data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0)
> rbind(s, df2)
>
> hope this helps
> Ulrik
>
> On Fri, 25 Mar 2016 at 05:52 Hiroyuki Sato <hiroysato at gmail.com> wrote:
>
>> Hello members
>>
>> Question
>>
>> Could you tell me how to add ID 100, 104, 105 values with zero?
>>
>> 1, Source data
>>
>>
>> ID 100, 104 and 105 has no values.
>>
>>
>> > s
>> ID DATE VAR CODE
>> 1 101 20160301 1 PDT1
>> 2 102 20160301 1 PDT2
>> 3 103 20160301 1 PDT3
>> 4 103 20160302 1 PDT3
>>
>> s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
>> 20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
>> structure(c(1L,
>> 2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")),
>> .Names
>> = c("ID",
>> "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
>> -4L))
>>
>> src <- 100:106
>>
>>
>> 2, Expect output
>>
>> ID PDT1 PDT2 PDT3
>> 1 100 0 0 0
>> 2 101 1 0 0
>> 3 102 0 1 0
>> 4 103 0 0 2
>> 5 104 0 0 0
>> 6 105 0 0 0
>>
>> 3, Convert process.
>>
>> I can convert data "s" like following.
>>
>> > library(reshape2)
>> > dcast(s,ID ~ CODE, value.var="VAR",sum)
>> ID PDT1 PDT2 PDT3
>> 1 101 1 0 0
>> 2 102 0 1 0
>> 3 103 0 0 2
>>
>> Could you tell me how to add 100, 104, 105 values into convert results?
>>
>>
>> Regards.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar 25 06:37:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 24 Mar 2016 22:37:41 -0700
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <CA+Tq-RoqZjt9uMob=-2kUPGwnUwj875BL3Y=tvOn4KFf-feSRA@mail.gmail.com>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
	<CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>
	<CA+Tq-RoqZjt9uMob=-2kUPGwnUwj875BL3Y=tvOn4KFf-feSRA@mail.gmail.com>
Message-ID: <12F5C459-D233-41F4-B758-43C40FE1C25D@dcn.davis.ca.us>

Suggested reading

An Introduction to R, section 5.3

The Posting Guide, mentioned at the bottom of this message, which mentions that this is a pain text mailing list so don't post in HTML (it gets mangled).
-- 
Sent from my phone. Please excuse my brevity.

On March 24, 2016 10:09:46 PM PDT, Hiroyuki Sato <hiroysato at gmail.com> wrote:
>Hello Ulrik
>
>Thank you for replying.
>
>The real data has many IDs( about 3,000 IDS). So I want to find missing
>values with function or something.
>If 104 not in s, then add 104 value with all column zero.
>
>And also real data has many columns( 80 ~ 5,000, columns. it is not
>fixed
>length ).
>So I would like to add values with function or something too
>
>ex) I can't write following statement.
>data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0, ... PDT5000
>=
>0)
>
>Do you have any good idea?
>
>Regards.
>
>
>
>
>2016?3?25?(?) 13:58 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
>
>> Hi Hiroyuki,
>>
>> The row bind function rbind() is what you need
>>
>> s <- dcast(s,ID ~ CODE, value.var="VAR",sum)
>> df2 <- data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0)
>> rbind(s, df2)
>>
>> hope this helps
>> Ulrik
>>
>> On Fri, 25 Mar 2016 at 05:52 Hiroyuki Sato <hiroysato at gmail.com>
>wrote:
>>
>>> Hello members
>>>
>>> Question
>>>
>>> Could you tell me how to add ID 100, 104, 105 values with zero?
>>>
>>> 1, Source data
>>>
>>>
>>> ID 100, 104 and 105 has no values.
>>>
>>>
>>> > s
>>> ID DATE VAR CODE
>>> 1 101 20160301 1 PDT1
>>> 2 102 20160301 1 PDT2
>>> 3 103 20160301 1 PDT3
>>> 4 103 20160302 1 PDT3
>>>
>>> s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE =
>c(20160301L,
>>> 20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
>>> structure(c(1L,
>>> 2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")),
>>> .Names
>>> = c("ID",
>>> "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
>>> -4L))
>>>
>>> src <- 100:106
>>>
>>>
>>> 2, Expect output
>>>
>>> ID PDT1 PDT2 PDT3
>>> 1 100 0 0 0
>>> 2 101 1 0 0
>>> 3 102 0 1 0
>>> 4 103 0 0 2
>>> 5 104 0 0 0
>>> 6 105 0 0 0
>>>
>>> 3, Convert process.
>>>
>>> I can convert data "s" like following.
>>>
>>> > library(reshape2)
>>> > dcast(s,ID ~ CODE, value.var="VAR",sum)
>>> ID PDT1 PDT2 PDT3
>>> 1 101 1 0 0
>>> 2 102 0 1 0
>>> 3 103 0 0 2
>>>
>>> Could you tell me how to add 100, 104, 105 values into convert
>results?
>>>
>>>
>>> Regards.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Mar 25 06:58:40 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 25 Mar 2016 05:58:40 +0000
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <12F5C459-D233-41F4-B758-43C40FE1C25D@dcn.davis.ca.us>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
	<CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>
	<CA+Tq-RoqZjt9uMob=-2kUPGwnUwj875BL3Y=tvOn4KFf-feSRA@mail.gmail.com>
	<12F5C459-D233-41F4-B758-43C40FE1C25D@dcn.davis.ca.us>
Message-ID: <CAKVAULNyp0QiR1Ye4Kr030OGfBWG=5fa4nXGBhwTdCxnTRU_xQ@mail.gmail.com>

You could make a vector with all possible IDs. Use %in% to get just those
that are missing.

missing.id <- c (101:1000)
missing.id <- missing.id[! missing.id %in% s $ID]

Df2 <- data.frame(ID = missing.id,
CODE = paste0 (PDT, missing.id),
VAR = 0)

Modify your original data.frame so you can rind df2 and cast as you already
do.

I haven't tested the above and you might have to tweak it a bit.

Hope it helps
Ulrik
,
Jeff Newmiller <jdnewmil at dcn.davis.ca.us> schrieb am Fr., 25. M?rz 2016
06:37:

> Suggested reading
>
> An Introduction to R, section 5.3
>
> The Posting Guide, mentioned at the bottom of this message, which mentions
> that this is a pain text mailing list so don't post in HTML (it gets
> mangled).
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 24, 2016 10:09:46 PM PDT, Hiroyuki Sato <hiroysato at gmail.com>
> wrote:
>
>> Hello Ulrik
>>
>> Thank you for replying.
>>
>> The real data has many IDs( about 3,000 IDS). So I want to find missing
>> values with function or something.
>> If 104 not in s, then add 104 value with all column zero.
>>
>> And also real data has many columns( 80 ~ 5,000, columns. it is not fixed
>> length ).
>> So I would like to add values with function or something too
>>
>> ex) I can't write following statement.
>>   data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0, ... PDT5000 =
>> 0)
>>
>> Do you have any good idea?
>>
>> Regards.
>>
>>
>>
>>
>> 2016?3?25?(?) 13:58 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
>>
>>  Hi Hiroyuki,
>>>
>>>  The row bind function rbind() is what you need
>>>
>>>  s <- dcast(s,ID ~ CODE, value.var="VAR",sum)
>>>  df2 <-
>>> data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0)
>>>  rbind(s, df2)
>>>
>>>  hope this helps
>>>  Ulrik
>>>
>>>  On Fri, 25 Mar 2016 at 05:52 Hiroyuki Sato <hiroysato at gmail.com> wrote:
>>>
>>>  Hello members
>>>>
>>>>  Question
>>>>
>>>>  Could you tell me how to add ID 100, 104, 105 values with zero?
>>>>
>>>>  1, Source data
>>>>
>>>>
>>>>  ID 100, 104 and 105 has no values.
>>>>
>>>>
>>>>  s
>>>>>
>>>>  ID DATE VAR CODE
>>>>  1 101 20160301 1 PDT1
>>>>  2 102 20160301 1 PDT2
>>>>  3 103 20160301 1 PDT3
>>>>  4 103 20160302 1 PDT3
>>>>
>>>>  s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
>>>>  20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
>>>>
>>>> structure(c(1L,
>>>>  2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")),
>>>>  .Names
>>>>  = c("ID",
>>>>  "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
>>>>  -4L))
>>>>
>>>>  src <- 100:106
>>>>
>>>>
>>>>  2, Expect output
>>>>
>>>>  ID PDT1 PDT2 PDT3
>>>>  1 100 0 0 0
>>>>  2 101 1 0 0
>>>>  3 102 0 1 0
>>>>  4 103 0 0 2
>>>>  5 104 0 0 0
>>>>  6 105 0 0 0
>>>>
>>>>  3, Convert process.
>>>>
>>>>  I can convert data "s" like following.
>>>>
>>>>  library(reshape2)
>>>>>  dcast(s,ID ~ CODE, value.var="VAR",sum)
>>>>>
>>>>  ID PDT1 PDT2 PDT3
>>>>  1 101 1 0 0
>>>>  2 102 0 1 0
>>>>  3 103 0 0 2
>>>>
>>>>  Could you tell me how to add 100, 104, 105 values into convert results?
>>>>
>>>>
>>>>  Regards.
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ------------------------------
>>>>
>>>>  R-help at r-project.org mailing
>>>> list -- To UNSUBSCRIBE and more, see
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide
>>>>  http://www.R-project.org/posting-guide.html
>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>  [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From hiroysato at gmail.com  Fri Mar 25 07:53:54 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Fri, 25 Mar 2016 15:53:54 +0900
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <CAKVAULNyp0QiR1Ye4Kr030OGfBWG=5fa4nXGBhwTdCxnTRU_xQ@mail.gmail.com>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
	<CAKVAULOnc9UY4NibbKKZwrs+HWyXc_4CPNpssBOXgiS5ynkBfQ@mail.gmail.com>
	<CA+Tq-RoqZjt9uMob=-2kUPGwnUwj875BL3Y=tvOn4KFf-feSRA@mail.gmail.com>
	<12F5C459-D233-41F4-B758-43C40FE1C25D@dcn.davis.ca.us>
	<CAKVAULNyp0QiR1Ye4Kr030OGfBWG=5fa4nXGBhwTdCxnTRU_xQ@mail.gmail.com>
Message-ID: <CA+Tq-RqUy75oH7fpLhUmwFn8Tjc99a-s8jo1jyTeCfUmScypAQ@mail.gmail.com>

Hello Ulrik and Jeff

Thank you for replying.

I succeed to create data frame following steps.

s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
structure(c(1L,
2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")),
.Names = c("ID",
"DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
-4L))

missing.id <- c(100:105)
missing.id <- missing.id[! missing.id %in% s $ID]

df2 <- data.frame(ID=missing.id,DATE="20160301",CODE="PDT1",VAR=0)

r <- dcast(rbind(s,df2),ID ~ CODE, value.var="VAR",sum)

r
   ID PDT1 PDT2 PDT3
1 100    0    0    0
2 101    1    0    0
3 102    0    1    0
4 103    0    0    2
5 104    0    0    0
6 105    0    0    0

Thanks again.

P.S.
I send this e-mail from gmail not inbox. so content should be plain text.



2016-03-25 14:58 GMT+09:00 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
> You could make a vector with all possible IDs. Use %in% to get just those
> that are missing.
>
> missing.id <- c (101:1000)
> missing.id <- missing.id[! missing.id %in% s $ID]
>
> Df2 <- data.frame(ID = missing.id,
> CODE = paste0 (PDT, missing.id),
> VAR = 0)
>
> Modify your original data.frame so you can rind df2 and cast as you already
> do.
>
> I haven't tested the above and you might have to tweak it a bit.
>
> Hope it helps
> Ulrik
> ,
>
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> schrieb am Fr., 25. M?rz 2016
> 06:37:
>>
>> Suggested reading
>>
>> An Introduction to R, section 5.3
>>
>> The Posting Guide, mentioned at the bottom of this message, which mentions
>> that this is a pain text mailing list so don't post in HTML (it gets
>> mangled).
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 24, 2016 10:09:46 PM PDT, Hiroyuki Sato <hiroysato at gmail.com>
>> wrote:
>>>
>>> Hello Ulrik
>>>
>>> Thank you for replying.
>>>
>>> The real data has many IDs( about 3,000 IDS). So I want to find missing
>>> values with function or something.
>>> If 104 not in s, then add 104 value with all column zero.
>>>
>>> And also real data has many columns( 80 ~ 5,000, columns. it is not fixed
>>> length ).
>>> So I would like to add values with function or something too
>>>
>>> ex) I can't write following statement.
>>>   data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0, ... PDT5000
>>> =
>>> 0)
>>>
>>> Do you have any good idea?
>>>
>>> Regards.
>>>
>>>
>>>
>>>
>>> 2016?3?25?(?) 13:58 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
>>>
>>>>  Hi Hiroyuki,
>>>>
>>>>  The row bind function rbind() is what you need
>>>>
>>>>  s <- dcast(s,ID ~ CODE, value.var="VAR",sum)
>>>>  df2 <-
>>>> data.frame(ID = c(104, 105), PDT1 = 0, PDT2  = 0, PDT3 = 0)
>>>>  rbind(s, df2)
>>>>
>>>>  hope this helps
>>>>  Ulrik
>>>>
>>>>  On Fri, 25 Mar 2016 at 05:52 Hiroyuki Sato <hiroysato at gmail.com> wrote:
>>>>
>>>>>  Hello members
>>>>>
>>>>>  Question
>>>>>
>>>>>  Could you tell me how to add ID 100, 104, 105 values with zero?
>>>>>
>>>>>  1, Source data
>>>>>
>>>>>
>>>>>  ID 100, 104 and 105 has no values.
>>>>>
>>>>>
>>>>>>  s
>>>>>
>>>>>  ID DATE VAR CODE
>>>>>  1 101 20160301 1 PDT1
>>>>>  2 102 20160301 1 PDT2
>>>>>  3 103 20160301 1 PDT3
>>>>>  4 103 20160302 1 PDT3
>>>>>
>>>>>  s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE =
>>>>> c(20160301L,
>>>>>  20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
>>>>>
>>>>> structure(c(1L,
>>>>>  2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")),
>>>>>  .Names
>>>>>  = c("ID",
>>>>>  "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
>>>>>  -4L))
>>>>>
>>>>>  src <- 100:106
>>>>>
>>>>>
>>>>>  2, Expect output
>>>>>
>>>>>  ID PDT1 PDT2 PDT3
>>>>>  1 100 0 0 0
>>>>>  2 101 1 0 0
>>>>>  3 102 0 1 0
>>>>>  4 103 0 0 2
>>>>>  5 104 0 0 0
>>>>>  6 105 0 0 0
>>>>>
>>>>>  3, Convert process.
>>>>>
>>>>>  I can convert data "s" like following.
>>>>>
>>>>>>  library(reshape2)
>>>>>>  dcast(s,ID ~ CODE, value.var="VAR",sum)
>>>>>
>>>>>  ID PDT1 PDT2 PDT3
>>>>>  1 101 1 0 0
>>>>>  2 102 0 1 0
>>>>>  3 103 0 0 2
>>>>>
>>>>>  Could you tell me how to add 100, 104, 105 values into convert
>>>>> results?
>>>>>
>>>>>
>>>>>  Regards.
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ________________________________
>>>>>
>>>>>  R-help at r-project.org mailing
>>>>> list -- To UNSUBSCRIBE and more, see
>>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>  PLEASE do read the posting guide
>>>>>  http://www.R-project.org/posting-guide.html
>>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>>
>>>
>>> ________________________________
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.



-- 
Hiroyuki Sato


From drjimlemon at gmail.com  Fri Mar 25 10:46:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 25 Mar 2016 20:46:13 +1100
Subject: [R] Trouble reshaping data to my satisfaction
In-Reply-To: <CAOxgQ=XLQN7ZdwFz+NbSXJ3nEi3KUkUsKZDZ0QzhVs6J73bB7g@mail.gmail.com>
References: <F94335071BCFAD4888499D87E41D3F757397320E@EMBX-CLFT4.cdc.gov>
	<CAOxgQ=XLQN7ZdwFz+NbSXJ3nEi3KUkUsKZDZ0QzhVs6J73bB7g@mail.gmail.com>
Message-ID: <CA+8X3fXJCSFZhdfve-t+H31mK709oquVoMv2JqHPfU96Pzp3Lg@mail.gmail.com>

Hi Jennifer,
This is very hacky, but I think it does most of what you want. I can't
really work out what "Sample Size" is supposed to be:

MOERS<-data.frame(MOE[MOE$SEX_P=="Males_0.1",c("Meff","Proportion")],
 Males_0.1=MOE[MOE$SEX_P=="Males_0.1","MOE"],
 Females_0.1=MOE[MOE$SEX_P=="Females_0.1","MOE"],
 Males_0.2=MOE[MOE$SEX_P=="Males_0.2","MOE"],
 Females_0.2=MOE[MOE$SEX_P=="Females_0.2","MOE"],
 Males_0.3=MOE[MOE$SEX_P=="Males_0.3","MOE"],
 Females_0.3=MOE[MOE$SEX_P=="Females_0.3","MOE"],
 Males_0.4=MOE[MOE$SEX_P=="Males_0.4","MOE"],
 Females_0.4=MOE[MOE$SEX_P=="Females_0.4","MOE"],
 Males_0.5=MOE[MOE$SEX_P=="Males_0.5","MOE"],
 Females_0.5=MOE[MOE$SEX_P=="Females_0.5","MOE"])

Jim


On Fri, Mar 25, 2016 at 8:14 AM, Jennifer Sabatier
<plessthanpointohfive at gmail.com> wrote:
> #I am having a lot of trouble reshaping this data.
> #This is just an examination of sample size on the margin of error that I
> did for a colleague.
> #Nothing complicated.
> #But restructuring the data...another story
>
> #Here's code to produce the dataset:
>
>
> n <- seq(10000, 100000, by=10000)
>
> P <- seq(0.1, 0.5, by=0.1)
>
> Meff <- seq(3, 8, by=1)
>
>
> # 4 age groups by 2 sex categories - these are population distribution
> sizes - order is males 18-29, females 18-29, males 30-44,females 30-44,
> males 45-59, females 45-59, males 60+, females 60+
>
> Age1 <- data.frame(matrix(c(0.196598808, 0.224390935, 0.149289474,
> 0.151446387,0.08750253, 0.076399683, 0.060799283, 0.053572898), nrow=4,
> ncol=2, byrow=T, dimnames=list(seq(1,4, by=1), c("Males", "Females"))))
>
> MOE <- NULL
>
> for (i in n){
>    for (p in P){
>       for (m in Meff){
>          for (a in Age1[,1]){
>
>          ni <- i * a
>          M <- sqrt((1.92^2)*p*(1-p)*m/ni)
>   dta <- data.frame(a, i, ni, p, m, M)
>
>          colnames(dta) <- c("Proportion", "Total_n", "Stratum_n", "P",
> "Meff", "MOE")
>
>          dta$Sex <- "Males"
> MOE <- rbind(MOE, dta)
>
> }
>
>          for (a in Age1[,2]){
>
>          ni <- i * a
>          M <- sqrt((1.92^2)*p*(1-p)*m/ni)
>   dta <- data.frame(a, i, ni, p, m, M)
>
>          colnames(dta) <- c("Proportion", "Total_n", "Stratum_n", "P",
> "Meff", "MOE")
>
>          dta$Sex <- "Females"
> MOE <- rbind(MOE, dta)
>
> }
> }
> }
> }
>
> # What I want is data that looks like:
> # Meff  Proportion  Sample Size  Males_0.1 Females_0.1 Males_0.2
> Females_0.2 ..... Males_0.5 Females_0.5
>
> #I'm stumped on how to reshape this.
>
> #I tried this but it gave me the attached output (yuck):
>
>
> library(reshape2)
>
> library(plyr)
>
>
> tmp <- ddply(MOE, .(Meff), mutate, id=paste(Meff, Sex, seq_along(MOE)))
>
> wd <- dcast(tmp, id + Meff ~ P + Sex, value.var="MOE")
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Fri Mar 25 14:31:51 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 25 Mar 2016 13:31:51 +0000
Subject: [R] rms package: output interpretation
Message-ID: <6d6ae7c014fa48e7b5cd337171d593d5@ex13-live-mbn1.ad.kent.ac.uk>

Hi everybody,

I am trying to run a logistic regression using the rms package. Here is the output of my model.

Logistic Regression Model

lrm(formula = stock.market.crash ~ crash.t.1.to.t.L + MA.inflator.monthly +
    realized.volatility.10 + MA.MP.100 + MA.UI.100 + MA.DEI.100 +
    MA.UPR.100, data = FDL.model_monthly)
                     Model Likelihood     Discrimination    Rank Discrim.
                        Ratio Test            Indexes          Indexes
Obs            45    LR chi2     21.57    R2       0.529    C       0.889
 0             30    d.f.            7    g        2.789    Dxy     0.778
 1             15    Pr(> chi2) 0.0030    gr      16.267    gamma   0.778
max |deriv| 6e-06                         gp       0.340    tau-a   0.354
                                          Brier    0.131

                       Coef      S.E.     Wald Z Pr(>|Z|)
Intercept               -11.6543   5.9683 -1.95  0.0509
crash.t.1.to.t.L         -4.5335   2.5705 -1.76  0.0778
MA.inflator.monthly      -2.4400   1.2735 -1.92  0.0554
realized.volatility.10   24.7952  10.3298  2.40  0.0164
MA.MP.100                 6.9404   4.1511  1.67  0.0945
MA.UI.100              -125.7101  54.5219 -2.31  0.0211
MA.DEI.100              519.9589 255.0241  2.04  0.0415
MA.UPR.100                2.6938   2.2209  1.21  0.2252


I am a bit confused regarding the interpretation of the chi2 and its p-value. Can anybody help me interpret the results? I get a high R2 but chi2 seems to be significant and high. How do I interpret these results in the rms package?

Thanks in advance.

	[[alternative HTML version deleted]]


From jchen at Parametricafund.com  Fri Mar 25 11:39:33 2016
From: jchen at Parametricafund.com (Jun Chen)
Date: Fri, 25 Mar 2016 06:39:33 -0400
Subject: [R] size issue with source
Message-ID: <C36D4CF172AD0543869AC75A615E64B642615F29D1@PARAMETRICAMAIL.bj.local>

Hello:

I have met an issue when I use the function "source".

For example, we use function source to read a txt file, say all.txt, which contains three function: A, B, C. Then I use the function save to save individual function A to a file say Abig, whose size on the drive is Abigsize. While I can source the file Abig to get back function A after which I save the updated A function to file Asmall, whose size on the drive is Asmallsize. Abigsize is much bigger than Asmallsize. It seems that Abig inherited its memory information from all.txt instead of its own size.

Would you please help me with the issue?

Best.


________________________________
NOTICE TO RECIPIENTS: The information contained in and a...{{dropped:23}}


From jessyesther.missengue2 at mail.dcu.ie  Fri Mar 25 14:10:53 2016
From: jessyesther.missengue2 at mail.dcu.ie (Jessy-Esther Missengue)
Date: Fri, 25 Mar 2016 13:10:53 +0000
Subject: [R] Performance Analytics Modigliani Code help
Message-ID: <CAL-SLAzGi-uYEUXFk0rBPK8_TvQSb-dS-Jf2AdQOXV=9Xgp4Fg@mail.gmail.com>

Hi all,

I am researching performance of funds in the FTSE100 and am using the
Modigliani function in the PerformanceAnalytics package.

I have attached my raw data for your reference.

When I try to use the Modigliani code as follows:

Modigliani (a,b,c=0)
where a is my data set "1000 RANDOM...", b is the data of FTSE "FTSE
ALLSHARE..." returns, c is the risk free rate "LIBOR".

This code returns the data attached "Modigliani from R" which seems to be a
calculation for only the first 2 columns of my data set. I would have
expected to have R return the same amount of rows and columns when using
the Modigliani function i.e 108 rows and 1001 columns.

Is there something I need to add to the code to have it calculate for each
row/column?

Thanks,
Jessy *very confused student*

From kmnanus at gmail.com  Fri Mar 25 15:07:10 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 25 Mar 2016 10:07:10 -0400
Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
Message-ID: <FB59391B-C0CF-4048-A038-BB1889B9B561@gmail.com>

I have called geom_hline to insert a horizontal line on the y axis of a plot at a given point.

How can I insert the corresponding tick and its value on the y axis itself?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From bgunter.4567 at gmail.com  Fri Mar 25 15:59:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 25 Mar 2016 07:59:30 -0700
Subject: [R] How to add no data entries into current dataframe?
In-Reply-To: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
References: <CA+Tq-RpTMmCNw+7g5TQECqn8YzmaxQB3B4NT0o+RBn88vk0BqA@mail.gmail.com>
Message-ID: <CAGxFJbQ2f+AgJ9GNBRWs1vA-wPLrd__Sng55HTapPDPqVE_o-A@mail.gmail.com>

?rbind


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 24, 2016 at 9:49 PM, Hiroyuki Sato <hiroysato at gmail.com> wrote:
> Hello members
>
> Question
>
> Could you tell me how to add ID 100, 104, 105 values with zero?
>
> 1, Source data
>
>
> ID 100, 104 and 105 has no values.
>
>
>> s
> ID DATE VAR CODE
> 1 101 20160301 1 PDT1
> 2 102 20160301 1 PDT2
> 3 103 20160301 1 PDT3
> 4 103 20160302 1 PDT3
>
> s <- structure(list(ID = c(101L, 102L, 103L, 103L), DATE = c(20160301L,
> 20160301L, 20160301L, 20160302L), VAR = c(1L, 1L, 1L, 1L), CODE =
> structure(c(1L,
> 2L, 3L, 3L), .Label = c("PDT1", "PDT2", "PDT3"), class = "factor")), .Names
> = c("ID",
> "DATE", "VAR", "CODE"), class = "data.frame", row.names = c(NA,
> -4L))
>
> src <- 100:106
>
>
> 2, Expect output
>
> ID PDT1 PDT2 PDT3
> 1 100 0 0 0
> 2 101 1 0 0
> 3 102 0 1 0
> 4 103 0 0 2
> 5 104 0 0 0
> 6 105 0 0 0
>
> 3, Convert process.
>
> I can convert data "s" like following.
>
>> library(reshape2)
>> dcast(s,ID ~ CODE, value.var="VAR",sum)
> ID PDT1 PDT2 PDT3
> 1 101 1 0 0
> 2 102 0 1 0
> 3 103 0 0 2
>
> Could you tell me how to add 100, 104, 105 values into convert results?
>
>
> Regards.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Fri Mar 25 16:13:07 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 25 Mar 2016 11:13:07 -0400
Subject: [R] size issue with source
In-Reply-To: <C36D4CF172AD0543869AC75A615E64B642615F29D1@PARAMETRICAMAIL.bj.local>
References: <C36D4CF172AD0543869AC75A615E64B642615F29D1@PARAMETRICAMAIL.bj.local>
Message-ID: <4126E65E-564C-44D5-A107-EBF23DB6CCC7@utoronto.ca>

I can't tell what's happening here unless I see the actual code that produces the behaviour. Just the code should be fine, no need to attach your big file. Also: what exactly is the issue you need to solve?

B.


On Mar 25, 2016, at 6:39 AM, Jun Chen <jchen at Parametricafund.com> wrote:

> Hello:
> 
> I have met an issue when I use the function "source".
> 
> For example, we use function source to read a txt file, say all.txt, which contains three function: A, B, C. Then I use the function save to save individual function A to a file say Abig, whose size on the drive is Abigsize. While I can source the file Abig to get back function A after which I save the updated A function to file Asmall, whose size on the drive is Asmallsize. Abigsize is much bigger than Asmallsize. It seems that Abig inherited its memory information from all.txt instead of its own size.
> 
> Would you please help me with the issue?
> 
> Best.
> 
> 
> ________________________________
> NOTICE TO RECIPIENTS: The information contained in and a...{{dropped:23}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Mar 25 18:03:19 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 25 Mar 2016 10:03:19 -0700
Subject: [R] rms package: output interpretation
In-Reply-To: <6d6ae7c014fa48e7b5cd337171d593d5@ex13-live-mbn1.ad.kent.ac.uk>
References: <6d6ae7c014fa48e7b5cd337171d593d5@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <D8BA8FFD-014A-4EBA-A4FB-3157A151F0A1@comcast.net>


> On Mar 25, 2016, at 6:31 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Hi everybody,
> 
> I am trying to run a logistic regression using the rms package. Here is the output of my model.
> 
> Logistic Regression Model
> 
> lrm(formula = stock.market.crash ~ crash.t.1.to.t.L + MA.inflator.monthly +
>    realized.volatility.10 + MA.MP.100 + MA.UI.100 + MA.DEI.100 +
>    MA.UPR.100, data = FDL.model_monthly)
>                     Model Likelihood     Discrimination    Rank Discrim.
>                        Ratio Test            Indexes          Indexes
> Obs            45    LR chi2     21.57    R2       0.529    C       0.889
> 0             30    d.f.            7    g        2.789    Dxy     0.778
> 1             15    Pr(> chi2) 0.0030    gr      16.267    gamma   0.778
> max |deriv| 6e-06                         gp       0.340    tau-a   0.354
>                                          Brier    0.131
> 
>                       Coef      S.E.     Wald Z Pr(>|Z|)
> Intercept               -11.6543   5.9683 -1.95  0.0509
> crash.t.1.to.t.L         -4.5335   2.5705 -1.76  0.0778
> MA.inflator.monthly      -2.4400   1.2735 -1.92  0.0554
> realized.volatility.10   24.7952  10.3298  2.40  0.0164
> MA.MP.100                 6.9404   4.1511  1.67  0.0945
> MA.UI.100              -125.7101  54.5219 -2.31  0.0211
> MA.DEI.100              519.9589 255.0241  2.04  0.0415
> MA.UPR.100                2.6938   2.2209  1.21  0.2252
> 
> 
> I am a bit confused regarding the interpretation of the chi2 and its p-value. Can anybody help me interpret the results?

I don't think anyone can help you unless you first describe the structure of the data. I worry that you are analyzing some sort of panel structure and have not yet accounted for autocorrelation in monthly measures.


> I get a high R2 but chi2 seems to be significant and high. How do I interpret these results in the rms package?

This suggests you need to talk to someone with deeper statistical background, and that's not really what r-help bills itself as providing. Is this part of an education experience or task? Do you have a supervisor that could be consulted?


-- 

David Winsemius
Alameda, CA, USA


From boris.steipe at utoronto.ca  Fri Mar 25 19:35:36 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 25 Mar 2016 14:35:36 -0400
Subject: [R] Persistent state in a function?
In-Reply-To: <8239D36E-C242-4563-815D-1C318F68957C@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56F31197.1080402@roswellpark.org>
	<8239D36E-C242-4563-815D-1C318F68957C@utoronto.ca>
Message-ID: <CE82F1C0-493F-4809-AA12-93B138DBB886@utoronto.ca>

To follow on, for the record, here's the code example using local() instead:
Comments appreciated.

# ======= CODE
cacheThis <- local({   # creates a closure, assigned to "cacheThis"

   myCache <- numeric()            # a persistent variable in the closure's environment
   useCache <- function(x){        # a function 
       myCache <<- c(myCache, x)
       print(myCache)
   }
})

# ======= /CODE
Using the function and accessing the local variable if need be is the same as below.

Pros and Cons:
It seems to me that the difference between the two approaches is only:
- using local(), I need to duplicate the code if I want more than one instance of the closure. The code seems more explicit however in that the contents of the local environment is clearly spelled out.
- using makeCache() in my earlier post, I don't duplicate the code. I see why Martin calls this a 'factory' function. I return() the function that does the work, and its local environment plus local variables implicitly come along. It's a bit less explicit now, because the definition of makeCache() could be far away in the code.

Other?

Terminology:
I would say
- cacheThis() is a closure in the global environment.
- useCache() is a function in that closure.
- myCache is a variable in useCache()'s local environment.
I have previously referred to the "local environment" as being "private". This informal use of the word "private" may be confusing since it means something else in other languages.

Encapsulation:
The obvious purpose of this is to encapsulate the persistent variable to prevent it from getting corrupted. So it would be nice to have getter and setter functions. In memoise, Hadley makes these elements of a list which I find a neat idea.


# ======= CODE: adding additional functions

cacheThis <- local({   

    myCache <- numeric()  
    functions <- list(
        calc = function(x){        
            myCache <<- c(myCache, x)
            print(myCache)
        },
        get = function() {
            return(myCache)
        },
        set = function(x) {
            myCache <<- x 
        }
    )
})

cacheThis$calc(17)   # 17
cacheThis$calc(13)   # 17 13
cacheThis$calc(10)   # 17 13 10

cacheThis$get()      # 17 13 10

cacheThis$set(c(17, 13, 11)) 

cacheThis$calc(7)    # 17 13 11 7

# =======  /CODE

Cheers,
Boris


On Mar 23, 2016, at 6:41 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> All -
> Thanks, this has been a real eye-opener.
> 
> Here's my variation based on what I've learned so far. It's based on Bert's earlier function-returning-a-closure example. I hope I got the terminology right.
> 
> # ========================================================
> 
> makeCache <- function(){   # returns a "closure",
> 	                   # i.e. a function
> 	                   # plus its private, lexically
> 	                   # scoped environment
> 
>   myCache <- numeric()  # a variable that we want to persist;
>                         # makeCache() creates the 
>                         # environment that holds myCache and
>                         # the function useCache() that uses myCache
> 
>   useCache <- function(x){
> 	  myCache <<- c(myCache, x)  # appends a value to myCache
> 	                             # <<- does _not_ assign to the
> 	                             # global environment, but searches
> 	                             # through the parent environments
> 	                             # and assigns to the global environment
> 	                             # only if no match was found along
> 	                             # the way.
> 	  print(myCache)
>   }
> 
>   return(useCache)     # return the function plus its environment
> }
> 
> # ======= creating instances of the closure and using them
> 
> cacheThis <- makeCache() # cacheThis is the closure that was created
>                         # by makeCache
> 
> cacheThis(17)  # 17
> cacheThis(13)  # 17 13
> cacheThis(11)  # 17 13 11
> 
> 
> cacheThat <- makeCache() # create another closure
> 
> cacheThat(1)  # 1
> cacheThat(2)  # 1 2
> cacheThat(3)  # 1 2 3
> cacheThat(5)  # 1 2 3 5
> 
> # ======= accessing the private variables
> 
> # The caches for cacheThis() and cacheThat() are not visible
> # from the (default) global environment:
> ls()  # [1] "cacheThat" "cacheThis" "makeCache" 
> 
> # To access them from the global environment, use
> # ls(), exists(), get() and assign(), with their environment
> # argument:
> 
> ls.str(envir = environment(cacheThis))
> 
> ls.str(envir = environment(cacheThat))
> 
> exists("myCache", envir = environment(cacheThat))
> exists("noSuchThing", envir = environment(cacheThat))
> 
> # The following won't work - save() needs a name as symbol or string:
> save(get("myCache", envir = environment(cacheThis)), file="myCache.Rdata")
> 
> # do this instead:
> tmp <- get("myCache", envir = environment(cacheThis))
> save(tmp, file="myCache.Rdata")
> rm(tmp)
> 
> # add a number we don't want...
> cacheThis(6) # 17 13 11 6
> 
> # restore cache from saved version
> load("myCache.Rdata") # this recreates "tmp"
> assign("myCache", tmp, envir = environment(cacheThis))
> 
> # cache another prime ...
> cacheThis(7) # 17 13 11 7
> 
> # etc.
> 
> # ========================================================
> 
> I don't yet understand the pros and cons of using local() instead of a generating function. From my current understanding, local() should end up doing the same thing - I think that's why Martin calls one a "variant" of the other. But I'll play some more with this later today. Is there a Preferred Way?
> 
> memoise has some nice ideas - such as creating a hash from the arguments passed into a function to see if the cached results need to be recomputed. In my use case, I'd like to have more explicit access to the cached results to be able to store, reload and otherwise manipulate them.
> 
> I haven't looked at R6 yet.
> 
> Cheers,
> Boris
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Mar 23, 2016, at 5:58 PM, Martin Morgan <martin.morgan at roswellpark.org> wrote:
> 
>> Use a local environment to as a place to store state. Update with <<- and resolve symbol references through lexical scope E.g.,
>> 
>>   persist <- local({
>>       last <- NULL                # initialize
>>       function(value) {
>>           if (!missing(value))
>>               last <<- value      # update with <<-
>>           last                    # use
>>       }
>>   })
>> 
>> and in action
>> 
>>> persist("foo")
>> [1] "foo"
>>> persist()
>> [1] "foo"
>>> persist("bar")
>> [1] "bar"
>>> persist()
>> [1] "bar"
>> 
>> A variant is to use a 'factory' function
>> 
>>   factory <- function(init) {
>>       stopifnot(!missing(init))
>>       last <- init
>>       function(value) {
>>           if (!missing(value))
>>               last <<- value
>>           last
>>       }
>>   }
>> 
>> and
>> 
>>> p1 = factory("foo")
>>> p2 = factory("bar")
>>> c(p1(), p2())
>> [1] "foo" "bar"
>>> c(p1(), p2("foo"))
>> [1] "foo" "foo"
>>> c(p1(), p2())
>> [1] "foo" "foo"
>> 
>> The 'bank account' exercise in section 10.7 of RShowDoc("R-intro") illustrates this.
>> 
>> Martin
>> 
>> On 03/19/2016 12:45 PM, Boris Steipe wrote:
>>> Dear all -
>>> 
>>> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>>> -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>>> -B- how can I store and reload such table?
>>> -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>>> 
>>> 
>>> For illustration ...
>>> 
>>> -----------------------------------
>>> 
>>> myDist <- function(a, b) {
>>>    # retrieve or calculate distances
>>>    if (!exists("Vals")) {
>>>        Vals <<- numeric() # the lookup table for distance values
>>>                           # here, created in the global env.
>>>    }
>>>    key <- sprintf("X%d.%d", a, b)
>>>    thisDist <- Vals[key]
>>>    if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>>>        cat("Calculating ... ")
>>>        thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>>>        Vals[key] <<- thisDist      # store in global table
>>>    }
>>>    return(thisDist)
>>> }
>>> 
>>> 
>>> # run this
>>> set.seed(112358)
>>> 
>>> for (i in 1:10) {
>>>    x <- sample(1:3, 2)
>>>    print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
>>> }
>>> 
>>> 
>>> Thanks!
>>> Boris
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Fri Mar 25 20:43:36 2016
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 25 Mar 2016 13:43:36 -0600
Subject: [R] Persistent state in a function?
In-Reply-To: <8239D36E-C242-4563-815D-1C318F68957C@utoronto.ca>
References: <80A26C96-CB8F-40FC-9297-0490E16B327E@utoronto.ca>
	<56F31197.1080402@roswellpark.org>
	<8239D36E-C242-4563-815D-1C318F68957C@utoronto.ca>
Message-ID: <CAFEqCdwHEXHAiMwKKV=PeopZPaESmGH4maQfPhN1-nL5-88KFw@mail.gmail.com>

Here is the rough equivalent to what you did but using the R6 package:

library(R6)

Cache <- R6Class("Cache",
  public = list(
    myCache = numeric(0),
    add = function(x) {
      self$myCache <- c(self$myCache, x)
      print(self$myCache)
    }
  )
)

cacheThis <- Cache$new()

cacheThis$add(17)
cacheThis$add(13)
cacheThis$add(11)

cacheThat <- Cache$new()

cacheThat$add(1)
cacheThat$add(2)
cacheThat$add(3)
cacheThat$add(5)

cacheThis$myCache


It has the same main advantages, the syntax is a little different.
But one nice thing is that you can access the individual caches in a
more simple manner (don't need get, assign, and <<-).  You could make
the cache private instead of public if you want it harder to access
the cache.




On Wed, Mar 23, 2016 at 4:41 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> All -
> Thanks, this has been a real eye-opener.
>
> Here's my variation based on what I've learned so far. It's based on Bert's earlier function-returning-a-closure example. I hope I got the terminology right.
>
> # ========================================================
>
> makeCache <- function(){   # returns a "closure",
>                            # i.e. a function
>                            # plus its private, lexically
>                            # scoped environment
>
>    myCache <- numeric()  # a variable that we want to persist;
>                          # makeCache() creates the
>                          # environment that holds myCache and
>                          # the function useCache() that uses myCache
>
>    useCache <- function(x){
>           myCache <<- c(myCache, x)  # appends a value to myCache
>                                      # <<- does _not_ assign to the
>                                      # global environment, but searches
>                                      # through the parent environments
>                                      # and assigns to the global environment
>                                      # only if no match was found along
>                                      # the way.
>           print(myCache)
>    }
>
>    return(useCache)     # return the function plus its environment
> }
>
> # ======= creating instances of the closure and using them
>
> cacheThis <- makeCache() # cacheThis is the closure that was created
>                          # by makeCache
>
> cacheThis(17)  # 17
> cacheThis(13)  # 17 13
> cacheThis(11)  # 17 13 11
>
>
> cacheThat <- makeCache() # create another closure
>
> cacheThat(1)  # 1
> cacheThat(2)  # 1 2
> cacheThat(3)  # 1 2 3
> cacheThat(5)  # 1 2 3 5
>
> # ======= accessing the private variables
>
> # The caches for cacheThis() and cacheThat() are not visible
> # from the (default) global environment:
> ls()  # [1] "cacheThat" "cacheThis" "makeCache"
>
> # To access them from the global environment, use
> # ls(), exists(), get() and assign(), with their environment
> # argument:
>
> ls.str(envir = environment(cacheThis))
>
> ls.str(envir = environment(cacheThat))
>
> exists("myCache", envir = environment(cacheThat))
> exists("noSuchThing", envir = environment(cacheThat))
>
> # The following won't work - save() needs a name as symbol or string:
> save(get("myCache", envir = environment(cacheThis)), file="myCache.Rdata")
>
> # do this instead:
> tmp <- get("myCache", envir = environment(cacheThis))
> save(tmp, file="myCache.Rdata")
> rm(tmp)
>
> # add a number we don't want...
> cacheThis(6) # 17 13 11 6
>
> # restore cache from saved version
> load("myCache.Rdata") # this recreates "tmp"
> assign("myCache", tmp, envir = environment(cacheThis))
>
> # cache another prime ...
> cacheThis(7) # 17 13 11 7
>
> # etc.
>
> # ========================================================
>
> I don't yet understand the pros and cons of using local() instead of a generating function. From my current understanding, local() should end up doing the same thing - I think that's why Martin calls one a "variant" of the other. But I'll play some more with this later today. Is there a Preferred Way?
>
> memoise has some nice ideas - such as creating a hash from the arguments passed into a function to see if the cached results need to be recomputed. In my use case, I'd like to have more explicit access to the cached results to be able to store, reload and otherwise manipulate them.
>
> I haven't looked at R6 yet.
>
> Cheers,
> Boris
>
>
>
>
>
>
>
>
>
>
>
>
> On Mar 23, 2016, at 5:58 PM, Martin Morgan <martin.morgan at roswellpark.org> wrote:
>
>> Use a local environment to as a place to store state. Update with <<- and resolve symbol references through lexical scope E.g.,
>>
>>    persist <- local({
>>        last <- NULL                # initialize
>>        function(value) {
>>            if (!missing(value))
>>                last <<- value      # update with <<-
>>            last                    # use
>>        }
>>    })
>>
>> and in action
>>
>> > persist("foo")
>> [1] "foo"
>> > persist()
>> [1] "foo"
>> > persist("bar")
>> [1] "bar"
>> > persist()
>> [1] "bar"
>>
>> A variant is to use a 'factory' function
>>
>>    factory <- function(init) {
>>        stopifnot(!missing(init))
>>        last <- init
>>        function(value) {
>>            if (!missing(value))
>>                last <<- value
>>            last
>>        }
>>    }
>>
>> and
>>
>> > p1 = factory("foo")
>> > p2 = factory("bar")
>> > c(p1(), p2())
>> [1] "foo" "bar"
>> > c(p1(), p2("foo"))
>> [1] "foo" "foo"
>> > c(p1(), p2())
>> [1] "foo" "foo"
>>
>> The 'bank account' exercise in section 10.7 of RShowDoc("R-intro") illustrates this.
>>
>> Martin
>>
>> On 03/19/2016 12:45 PM, Boris Steipe wrote:
>>> Dear all -
>>>
>>> I need to have a function maintain a persistent lookup table of results for an expensive calculation, a named vector or hash. I know that I can just keep the table in the global environment. One problem with this approach is that the function should be able to delete/recalculate the table and I don't like side-effects in the global environment. This table really should be private. What I don't know is:
>>>  -A- how can I keep the table in an environment that is private to the function but persistent for the session?
>>>  -B- how can I store and reload such table?
>>>  -C- most importantly: is that the right strategy to initialize and maintain state in a function in the first place?
>>>
>>>
>>> For illustration ...
>>>
>>> -----------------------------------
>>>
>>> myDist <- function(a, b) {
>>>     # retrieve or calculate distances
>>>     if (!exists("Vals")) {
>>>         Vals <<- numeric() # the lookup table for distance values
>>>                            # here, created in the global env.
>>>     }
>>>     key <- sprintf("X%d.%d", a, b)
>>>     thisDist <- Vals[key]
>>>     if (is.na(thisDist)) {          # Hasn't been calculated yet ...
>>>         cat("Calculating ... ")
>>>         thisDist <- sqrt(a^2 + b^2) # calculate with some expensive function ...
>>>         Vals[key] <<- thisDist      # store in global table
>>>     }
>>>     return(thisDist)
>>> }
>>>
>>>
>>> # run this
>>> set.seed(112358)
>>>
>>> for (i in 1:10) {
>>>     x <- sample(1:3, 2)
>>>     print(sprintf("d(%d, %d) = %f", x[1], x[2], myDist(x[1], x[2])))
>>> }
>>>
>>>
>>> Thanks!
>>> Boris
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jrkrideau at inbox.com  Fri Mar 25 22:15:33 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 25 Mar 2016 13:15:33 -0800
Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
In-Reply-To: <FB59391B-C0CF-4048-A038-BB1889B9B561@gmail.com>
Message-ID: <4AF8C07DC4E.0000088Fjrkrideau@inbox.com>

You might abe able to do it by using scale_y_continuous() but it would be a great help to see some (minimal) code and some sample data.

Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html

Re  scale_y_continuous() have a look at http://stackoverflow.com/questions/22228696/specify-tick-marks-on-y-axis-ggplot2 which might suggest some approaches.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kmnanus at gmail.com
> Sent: Fri, 25 Mar 2016 10:07:10 -0400
> To: r-help at r-project.org
> Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
> 
> I have called geom_hline to insert a horizontal line on the y axis of a
> plot at a given point.
> 
> How can I insert the corresponding tick and its value on the y axis
> itself?
> 
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From r.turner at auckland.ac.nz  Fri Mar 25 23:13:45 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Mar 2016 11:13:45 +1300
Subject: [R] [FORGED] Manually inserting an extra tick on the y axis in
 ggplot2
In-Reply-To: <FB59391B-C0CF-4048-A038-BB1889B9B561@gmail.com>
References: <FB59391B-C0CF-4048-A038-BB1889B9B561@gmail.com>
Message-ID: <56F5B819.6090905@auckland.ac.nz>

On 26/03/16 03:07, KMNanus wrote:
> I have called geom_hline to insert a horizontal line on the y axis of a plot at a given point.
>
> How can I insert the corresponding tick and its value on the y axis itself?

I think that axis() is what you need, but it's hard to tell without a 
reproducible example.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jenny.vanderpluym at noaa.gov  Fri Mar 25 19:11:36 2016
From: jenny.vanderpluym at noaa.gov (Jenny Vander Pluym - NOAA Federal)
Date: Fri, 25 Mar 2016 14:11:36 -0400
Subject: [R] Question about Imager
Message-ID: <CAJbh8euTq-Q018y1Q9PsoKBsr6est=AvzTR6MOoVqayneaNSsg@mail.gmail.com>

Hello!

I found the imager package but have a question. Is it possible to construct
a collage or 4 images after resizing them?

I would like to batch make some collages (A LOT of them) and have only been
able to automate certain steps of the process in Photoshop. I would like to
be able to automate the process and save a lot of time and clicking.

Thank you for your time,

Jenny Vander Pluym

-- 
Jenny Vander Pluym
NOAA's National Centers for Coastal Ocean Science
Research and Communications Specialist
101 Pivers Island Rd.
Beaufort, NC 28516-9722 cell: 252.728.8777
What is NCCOS up to? <http://coastalscience.noaa.gov/news/>

"The contents of this message are mine personally and do not necessarily
reflect any position of the Government or the National Oceanic and
Atmospheric Administration."




-- 
Jenny Vander Pluym
NOAA's National Centers for Coastal Ocean Science
Research and Communications Specialist
101 Pivers Island Rd.
Beaufort, NC 28516-9722 cell: 252.728.8777
What is NCCOS up to? <http://coastalscience.noaa.gov/news/>

"The contents of this message are mine personally and do not necessarily
reflect any position of the Government or the National Oceanic and
Atmospheric Administration."

	[[alternative HTML version deleted]]


From santum4 at gmail.com  Fri Mar 25 19:47:33 2016
From: santum4 at gmail.com (Santanu Mukherjee)
Date: Fri, 25 Mar 2016 13:47:33 -0500
Subject: [R] converting a class dataframe (chars) to transaction class
Message-ID: <CAL2_-6N7Ztk3V29Ao24VOXTrpha8jaGVW7tNOSSKkioqCCvOvw@mail.gmail.com>

Running R backend MySQL - ran a query
<dataframe> <- Query
the resulting dataframe contains 2 columns and both are chars.
Need to change the dataframe class to transaction class
as I need to run Apriori algorithm
how to do that?

Thanks
Santanu

	[[alternative HTML version deleted]]


From ehandler at macalester.edu  Fri Mar 25 21:09:42 2016
From: ehandler at macalester.edu (Eric Handler)
Date: Fri, 25 Mar 2016 15:09:42 -0500
Subject: [R] fftImg() error: fftw_access_func
Message-ID: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>

Hello-

My name is Eric Handler and I am an academic technologist supporting
the Science Division(7 academic departments) at Macalester College in
Saint Paul, MN. The faculty use R for a variety of teaching and
research tasks around campus. I administer our RStudio instance and
have encountered an error I can't resolve. A student working on an
independent research project has reported that he received the
following error when attempting to use the ripa function fftImg():

Error in .C("fftw_access_func", as.complex(img), as.integer(w),
as.integer(h),  :
  "fftw_access_func" not available for .C() for package "ripa"

I've been able to recreate this error in RStudio as well as directly
in R. I've also recreated the error across different platforms(Ubuntu,
Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
below:

R version 3.2.3 (2015-12-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.3 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  tcltk     stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
[1] fftw_1.0-3 ripa_2.0-2

loaded via a namespace (and not attached):
[1] tools_3.2.3 Rcpp_0.12.3

A google search for "fftw_access_func" doesn't reveal anything modern
on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)

Can someone help me get the student functional with fftImg() or
alternately, tell me it is a known issue and an alternative option(if
available) for the student?

Thanks,
Eric

--
Eric Handler
Academic Information Associate - Science Division
Macalester College - Saint Paul, MN
Olin-Rice 124
Office: 651-696-6016
View my calendar: http://goo.gl/SbxLOu


From kmnanus at gmail.com  Fri Mar 25 23:16:21 2016
From: kmnanus at gmail.com (KMNanus)
Date: Fri, 25 Mar 2016 18:16:21 -0400
Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
In-Reply-To: <4AF8C07DC4E.0000088Fjrkrideau@inbox.com>
References: <4AF8C07DC4E.0000088Fjrkrideau@inbox.com>
Message-ID: <B6095966-7C97-46C1-A2CD-3ECE23A97343@gmail.com>

Thanks.  Actually, found a good answer online - 

I wanted a horizontal line with a y intercept of 12.6.

I set m <- 12.6

I drew the line with geom_hline then added geom_text(aes(0,m,label = m, vjust = -1))

which worked just fine.  

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Mar 25, 2016, at 5:15 PM, John Kane <jrkrideau at inbox.com> wrote:
> 
> You might abe able to do it by using scale_y_continuous() but it would be a great help to see some (minimal) code and some sample data.
> 
> Please have a look at
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html
> 
> Re  scale_y_continuous() have a look at http://stackoverflow.com/questions/22228696/specify-tick-marks-on-y-axis-ggplot2 which might suggest some approaches.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: kmnanus at gmail.com
>> Sent: Fri, 25 Mar 2016 10:07:10 -0400
>> To: r-help at r-project.org
>> Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
>> 
>> I have called geom_hline to insert a horizontal line on the y axis of a
>> plot at a given point.
>> 
>> How can I insert the corresponding tick and its value on the y axis
>> itself?
>> 
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
> 


From art_med_ahmed at yahoo.fr  Fri Mar 25 23:43:02 2016
From: art_med_ahmed at yahoo.fr (Mohamed Benahmed)
Date: Fri, 25 Mar 2016 22:43:02 +0000 (UTC)
Subject: [R] Error in FUN(X[[i]], ...)
References: <1074354293.665198.1458945782923.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1074354293.665198.1458945782923.JavaMail.yahoo@mail.yahoo.com>

hello,

I have to show the graph of simulation "car2car"(link of code source?https://github.com/cawka/ndnSIM-nom-rapid-car2car) but when I run the cmd ./run.py -s figure-4-data-propagation-vs-distance I have this error?
_____________________________________________
..........
./build/car-relay --run=5 --distance=155
./build/car-relay --run=6 --distance=155
./build/car-relay --run=7 --distance=155
./build/car-relay --run=8 --distance=155
./build/car-relay --run=9 --distance=155
./build/car-relay --run=10 --distance=155
Warning message:
closing unused connection 3 (results/figure-4-data-propagation-vs-distance/car-relay-in-cache.txt.bz2)?
Warning message:
`axis.ticks.margin` is deprecated. Please set `margin` property? of `axis.text` instead?
Error in FUN(X[[i]], ...) :?
? Theme element 'text' has NULL property: margin, debug
Calls: <Anonymous> ... element_render -> calc_element -> lapply -> FUN -> lapply -> FUN
Execution halted
---------------------------------------------------
[[elided Yahoo spam]]

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sat Mar 26 02:03:00 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 25 Mar 2016 21:03:00 -0400
Subject: [R] Question about Imager
In-Reply-To: <CAJbh8euTq-Q018y1Q9PsoKBsr6est=AvzTR6MOoVqayneaNSsg@mail.gmail.com>
References: <CAJbh8euTq-Q018y1Q9PsoKBsr6est=AvzTR6MOoVqayneaNSsg@mail.gmail.com>
Message-ID: <4F1DE9E9-0E22-4A05-B6CD-939BA1BF0BB6@bigelow.org>

Hi,

I can't answer your collage question but I am very glad that you brought imager to my attention - it looks great.  

That said, you might give ImageJ or its cousin Fiji a look for the task you have.  There are hundreds of examples and a nice (easy!) macro language coupled to the user interface.

http://rsb.info.nih.gov/ij/
http://imagej.net/Fiji

Cheers,
Ben

> On Mar 25, 2016, at 2:11 PM, Jenny Vander Pluym - NOAA Federal <jenny.vanderpluym at noaa.gov> wrote:
> 
> Hello!
> 
> I found the imager package but have a question. Is it possible to construct
> a collage or 4 images after resizing them?
> 
> I would like to batch make some collages (A LOT of them) and have only been
> able to automate certain steps of the process in Photoshop. I would like to
> be able to automate the process and save a lot of time and clicking.
> 
> Thank you for your time,
> 
> Jenny Vander Pluym
> 
> -- 
> Jenny Vander Pluym
> NOAA's National Centers for Coastal Ocean Science
> Research and Communications Specialist
> 101 Pivers Island Rd.
> Beaufort, NC 28516-9722 cell: 252.728.8777
> What is NCCOS up to? <http://coastalscience.noaa.gov/news/>
> 
> "The contents of this message are mine personally and do not necessarily
> reflect any position of the Government or the National Oceanic and
> Atmospheric Administration."
> 
> 
> 
> 
> -- 
> Jenny Vander Pluym
> NOAA's National Centers for Coastal Ocean Science
> Research and Communications Specialist
> 101 Pivers Island Rd.
> Beaufort, NC 28516-9722 cell: 252.728.8777
> What is NCCOS up to? <http://coastalscience.noaa.gov/news/>
> 
> "The contents of this message are mine personally and do not necessarily
> reflect any position of the Government or the National Oceanic and
> Atmospheric Administration."
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From michaeleartz at gmail.com  Sat Mar 26 06:19:35 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Sat, 26 Mar 2016 00:19:35 -0500
Subject: [R] Logistic Regression output baseline (reference) category
In-Reply-To: <03171E24-6856-4E97-A218-1639F299BCF5@comcast.net>
References: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
	<03171E24-6856-4E97-A218-1639F299BCF5@comcast.net>
Message-ID: <CA+pG8eNpNT=ppJdKWbiWZP-0xjEoz6g9OKAnYvGo3XwzBuY=-Q@mail.gmail.com>

Hi,
  I have now read an introductory text on regression and I think I do
understand what the intercept is doing.  However, my original question is
still unanswered.  I understand that the intercept term is the constant
that each other term is measured against.  I think baseline is a good word
for it.  However, it does not represent any one of the x variables by
itself.  Is there a way in R, to extrapolate the individual x variable
intercepts from the equation somehow.


On Tue, Mar 15, 2016 at 8:26 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 15, 2016, at 1:27 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> >
> > Hi,
> >   I am trying to use the summary from the glm function as a data source.
> I
> > am using the call sink(<some file>) then
> > summary(logisticRegModel)$coefficients then sink().
>
> Since it's a matrix you may need to locate a function that write matrices
> to files. I seem to remember that the MASS package has one.
>
> >  The independent
> > variables are categorical and thus there is always a baseline value for
> > every category that is omitted from the glm output.
>
> Well, it's not really omitted, so much as shared among all variables. For
> further reading in the halp pages consult:
>
> ?model.matrix
> ?contrasts
> ?contr.treatment
>
> But you probably need to supplement that with an introductory text that
> covers R regression defaults.
>
> >  I am interested in how
> > to get the Z column for all of the categorical values.
>
> The Z column? You meant the "z value" column. Again, since it's a matrix
> you need to use column indexing with "["
>
> summary(logisticRegModel)$coefficients[  , "z value"]
>
> Read up on the summary function for glm objects at:
>
> ?summary.glm
>
>
> >  I don't see any row
> > for the reference category.
>
> What do you imagine the (Intercept) row to be doing? If you are having
> difficulty understanding this (which is not really an R-specific issue)
> there are probably already several explanations to similar questions on:
>
> http://stats.stackexchange.com/
>
>
> >
> > How can I get this Z value in the output?
>
> Asked and answered.
>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 26 07:39:13 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 25 Mar 2016 23:39:13 -0700
Subject: [R] Logistic Regression output baseline (reference) category
In-Reply-To: <CA+pG8eNpNT=ppJdKWbiWZP-0xjEoz6g9OKAnYvGo3XwzBuY=-Q@mail.gmail.com>
References: <CA+pG8eMrcY3pcCiS40C6BiHJFLSSZ=9KPjnxqYXtrZVxRmgPtA@mail.gmail.com>
	<03171E24-6856-4E97-A218-1639F299BCF5@comcast.net>
	<CA+pG8eNpNT=ppJdKWbiWZP-0xjEoz6g9OKAnYvGo3XwzBuY=-Q@mail.gmail.com>
Message-ID: <43F0441B-3718-41F3-BBC9-047FA0BA418D@comcast.net>


> On Mar 25, 2016, at 10:19 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> 
> Hi,
>  I have now read an introductory text on regression and I think I do
> understand what the intercept is doing.  However, my original question is
> still unanswered.  I understand that the intercept term is the constant
> that each other term is measured against.  I think baseline is a good word
> for it.  However, it does not represent any one of the x variables by
> itself.

It represents all of the X variables at their reference levels. There are no individual intercepts on a variable-by-variable basis. You accepted the notion of "baseline" You cannot parcel out single variable intercepts. What would they actually mean anyhow?



>  Is there a way in R, to extrapolate the individual x variable
> intercepts from the equation somehow.

If you describe the process by which that could be calculated, we might have basis for discussion, but as it is I think you still need to be studying the theory more. I don't intend any further resspones on R-help where these questions are off-topic, so you should direct any further questions to stats.stackexchange.com

> 
> 
> On Tue, Mar 15, 2016 at 8:26 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> 
>>> On Mar 15, 2016, at 1:27 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>> 
>>> Hi,
>>>  I am trying to use the summary from the glm function as a data source.
>> I
>>> am using the call sink(<some file>) then
>>> summary(logisticRegModel)$coefficients then sink().
>> 
>> Since it's a matrix you may need to locate a function that write matrices
>> to files. I seem to remember that the MASS package has one.
>> 
>>> The independent
>>> variables are categorical and thus there is always a baseline value for
>>> every category that is omitted from the glm output.
>> 
>> Well, it's not really omitted, so much as shared among all variables. For
>> further reading in the halp pages consult:
>> 
>> ?model.matrix
>> ?contrasts
>> ?contr.treatment
>> 
>> But you probably need to supplement that with an introductory text that
>> covers R regression defaults.
>> 
>>> I am interested in how
>>> to get the Z column for all of the categorical values.
>> 
>> The Z column? You meant the "z value" column. Again, since it's a matrix
>> you need to use column indexing with "["
>> 
>> summary(logisticRegModel)$coefficients[  , "z value"]
>> 
>> Read up on the summary function for glm objects at:
>> 
>> ?summary.glm
>> 
>> 
>>> I don't see any row
>>> for the reference category.
>> 
>> What do you imagine the (Intercept) row to be doing? If you are having
>> difficulty understanding this (which is not really an R-specific issue)
>> there are probably already several explanations to similar questions on:
>> 
>> http://stats.stackexchange.com/
>> 
>> 
>>> 
>>> How can I get this Z value in the output?
>> 
>> Asked and answered.
>> 

David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Sat Mar 26 08:33:54 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 26 Mar 2016 08:33:54 +0100
Subject: [R] fftImg() error: fftw_access_func
In-Reply-To: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
References: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
Message-ID: <56F63B62.3090805@statistik.tu-dortmund.de>

Please report problems in packages to the corresponding package 
maintainer, CCing here ..

Best,
Uwe Ligges


On 25.03.2016 21:09, Eric Handler wrote:
> Hello-
>
> My name is Eric Handler and I am an academic technologist supporting
> the Science Division(7 academic departments) at Macalester College in
> Saint Paul, MN. The faculty use R for a variety of teaching and
> research tasks around campus. I administer our RStudio instance and
> have encountered an error I can't resolve. A student working on an
> independent research project has reported that he received the
> following error when attempting to use the ripa function fftImg():
>
> Error in .C("fftw_access_func", as.complex(img), as.integer(w),
> as.integer(h),  :
>    "fftw_access_func" not available for .C() for package "ripa"
>
> I've been able to recreate this error in RStudio as well as directly
> in R. I've also recreated the error across different platforms(Ubuntu,
> Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
> below:
>
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.3 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] parallel  tcltk     stats     graphics  grDevices utils     datasets
> [8] methods   base
>
> other attached packages:
> [1] fftw_1.0-3 ripa_2.0-2
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.3 Rcpp_0.12.3
>
> A google search for "fftw_access_func" doesn't reveal anything modern
> on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
> doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)
>
> Can someone help me get the student functional with fftImg() or
> alternately, tell me it is a known issue and an alternative option(if
> available) for the student?
>
> Thanks,
> Eric
>
> --
> Eric Handler
> Academic Information Associate - Science Division
> Macalester College - Saint Paul, MN
> Olin-Rice 124
> Office: 651-696-6016
> View my calendar: http://goo.gl/SbxLOu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shelby_leonard26 at yahoo.com  Sat Mar 26 02:32:57 2016
From: shelby_leonard26 at yahoo.com (Shelby Leonard)
Date: Sat, 26 Mar 2016 01:32:57 +0000 (UTC)
Subject: [R] Coxph model treating all the values of 1 variable as separate
 variables PLEASE HELP!!
References: <1666680761.576397.1458955977773.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1666680761.576397.1458955977773.JavaMail.yahoo@mail.yahoo.com>


I have been working for 12 hours now on trying to fix my cox model. I have a large data set (n>300) and In my model I have time in months, status (1=dead), and change represents my variable. I am trying to determine if the variable change is predicitive of survival.?? ? I have used this exact code before but for some reason now it is not working I get the following error message?
? ? Warning message:
In fitter(X, Y, strats, offset, init, control, weights = weights, ?:? Ran out of iterations and did not converge
And the output is taking all of the individual values of change as separate variables when I instead want them to be taken together as the same variable?

This is my code:model.1<-coxph(Surv(time, status)~change)

I also have tried adding in a 2nd time and using all the variations of the same formula I could find. In addition to the warning message this is what my output looks like?
instead of?
I have no idea why this is happening!!
Thanks

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2016-03-25 at 9.26.30 PM.png
Type: image/png
Size: 499434 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160326/53424269/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2016-03-25 at 9.32.04 PM.png
Type: image/png
Size: 207019 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160326/53424269/attachment-0003.png>

From marc_schwartz at me.com  Sat Mar 26 12:39:38 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 26 Mar 2016 06:39:38 -0500
Subject: [R] Coxph model treating all the values of 1 variable as
 separate variables PLEASE HELP!!
In-Reply-To: <1666680761.576397.1458955977773.JavaMail.yahoo@mail.yahoo.com>
References: <1666680761.576397.1458955977773.JavaMail.yahoo.ref@mail.yahoo.com>
	<1666680761.576397.1458955977773.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A3ABAFEA-648D-495A-A14C-A012DAD990DE@me.com>


> On Mar 25, 2016, at 8:32 PM, Shelby Leonard <shelby_leonard26 at yahoo.com> wrote:
> 
> 
> I have been working for 12 hours now on trying to fix my cox model. I have a large data set (n>300) and In my model I have time in months, status (1=dead), and change represents my variable. I am trying to determine if the variable change is predicitive of survival.     I have used this exact code before but for some reason now it is not working I get the following error message 
>     Warning message:
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :  Ran out of iterations and did not converge
> And the output is taking all of the individual values of change as separate variables when I instead want them to be taken together as the same variable 
> 
> This is my code:model.1<-coxph(Surv(time, status)~change)
> 
> I also have tried adding in a 2nd time and using all the variations of the same formula I could find. In addition to the warning message this is what my output looks like 
> instead of 
> I have no idea why this is happening!!
> Thanks
> 


The output that you attached, which you could have copied and pasted into the e-mail as monospaced text, rather than attaching as a screen capture, suggests that your 'change' variable has been coerced to a factor (categorical variable) rather than being treated as continuous.

Thus, you need to figure out where in your code, before you create the model, this is happening.

Trace through your code, step by step if need be, keeping track of how the 'change' variable is being created or manipulated. Use:

 str(change)

to see what data type and/or class the 'change' variable is at each step. See ?str. Somewhere along the way, it becomes a factor instead of numeric.

If you imported it via something like read.table() from an external data file, check to see what the result of that operation is, as non-numeric values in that column can result in the entire column being coerced to a factor.

Regards,

Marc Schwartz


From jrkrideau at inbox.com  Sat Mar 26 13:37:05 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 26 Mar 2016 04:37:05 -0800
Subject: [R] Manually inserting an extra tick on the y axis in ggplot2
In-Reply-To: <B6095966-7C97-46C1-A2CD-3ECE23A97343@gmail.com>
References: <4af8c07dc4e.0000088fjrkrideau@inbox.com>
Message-ID: <53048675109.00000181jrkrideau@inbox.com>

?Oh yes, looks good. 

I misread your request and thought that you wanted it integrated with the labels on the y-axis.

John Kane
Kingston ON Canada

-----Original Message-----
From: kmnanus at gmail.com
Sent: Fri, 25 Mar 2016 18:16:21 -0400
To: jrkrideau at inbox.com
Subject: Re: [R] Manually inserting an extra tick on the y axis in ggplot2

Thanks. ?Actually, found a good answer online -?

I wanted a horizontal line with a y intercept of 12.6.

I set m <- 12.6

I drew the line with geom_hline then added?geom_text(aes(0,m,label =?m, vjust = -1))

which worked just fine. ?

 Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)

On Mar 25, 2016, at 5:15 PM, John Kane <jrkrideau at inbox.com> wrote:

You might abe able to do it by using scale_y_continuous() but it would be a great help to see some (minimal) code and some sample data.

Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] and/or http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]

Re ?scale_y_continuous() have a look at http://stackoverflow.com/questions/22228696/specify-tick-marks-on-y-axis-ggplot2 [http://stackoverflow.com/questions/22228696/specify-tick-marks-on-y-axis-ggplot2] which might suggest some approaches.

John Kane
Kingston ON Canada

	-----Original Message-----
From: kmnanus at gmail.com
Sent: Fri, 25 Mar 2016 10:07:10 -0400
To: r-help at r-project.org
Subject: [R] Manually inserting an extra tick on the y axis in ggplot2

I have called geom_hline to insert a horizontal line on the y axis of a
plot at a given point.

How can I insert the corresponding tick and its value on the y axis
itself?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] to find out more!

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From jrkrideau at inbox.com  Sat Mar 26 14:19:19 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 26 Mar 2016 05:19:19 -0800
Subject: [R] fftImg() error: fftw_access_func
In-Reply-To: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
Message-ID: <5362F4C2891.000001A0jrkrideau@inbox.com>

It would be helpful if you actually supplied your code and a minimal data set to for people to examine.

Please have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html.

I'm not clear if you are reporting a general R problem or a specific package with the ripa package.  If it looks like it is the latter you probably bring it to the attention of the package maintainer who may or may not monitor this mailing group.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: ehandler at macalester.edu
> Sent: Fri, 25 Mar 2016 15:09:42 -0500
> To: r-help at r-project.org
> Subject: [R] fftImg() error: fftw_access_func
> 
> Hello-
> 
> My name is Eric Handler and I am an academic technologist supporting
> the Science Division(7 academic departments) at Macalester College in
> Saint Paul, MN. The faculty use R for a variety of teaching and
> research tasks around campus. I administer our RStudio instance and
> have encountered an error I can't resolve. A student working on an
> independent research project has reported that he received the
> following error when attempting to use the ripa function fftImg():
> 
> Error in .C("fftw_access_func", as.complex(img), as.integer(w),
> as.integer(h),  :
>   "fftw_access_func" not available for .C() for package "ripa"
> 
> I've been able to recreate this error in RStudio as well as directly
> in R. I've also recreated the error across different platforms(Ubuntu,
> Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
> below:
> 
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.3 (El Capitan)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] parallel  tcltk     stats     graphics  grDevices utils     datasets
> [8] methods   base
> 
> other attached packages:
> [1] fftw_1.0-3 ripa_2.0-2
> 
> loaded via a namespace (and not attached):
> [1] tools_3.2.3 Rcpp_0.12.3
> 
> A google search for "fftw_access_func" doesn't reveal anything modern
> on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
> doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)
> 
> Can someone help me get the student functional with fftImg() or
> alternately, tell me it is a known issue and an alternative option(if
> available) for the student?
> 
> Thanks,
> Eric
> 
> --
> Eric Handler
> Academic Information Associate - Science Division
> Macalester College - Saint Paul, MN
> Olin-Rice 124
> Office: 651-696-6016
> View my calendar: http://goo.gl/SbxLOu
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From shelby_leonard26 at yahoo.com  Sat Mar 26 16:42:01 2016
From: shelby_leonard26 at yahoo.com (Shelby Leonard)
Date: Sat, 26 Mar 2016 15:42:01 +0000 (UTC)
Subject: [R] fftImg() error: fftw_access_func
In-Reply-To: <5362F4C2891.000001A0jrkrideau@inbox.com>
References: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
	<5362F4C2891.000001A0jrkrideau@inbox.com>
Message-ID: <182643837.1037880.1459006921861.JavaMail.yahoo@mail.yahoo.com>

So do i need to resend?the email to someone else? sorry i am just confused 

    On Saturday, March 26, 2016 9:21 AM, John Kane <jrkrideau at inbox.com> wrote:
 

 It would be helpful if you actually supplied your code and a minimal data set to for people to examine.

Please have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html.

I'm not clear if you are reporting a general R problem or a specific package with the ripa package.? If it looks like it is the latter you probably bring it to the attention of the package maintainer who may or may not monitor this mailing group.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: ehandler at macalester.edu
> Sent: Fri, 25 Mar 2016 15:09:42 -0500
> To: r-help at r-project.org
> Subject: [R] fftImg() error: fftw_access_func
> 
> Hello-
> 
> My name is Eric Handler and I am an academic technologist supporting
> the Science Division(7 academic departments) at Macalester College in
> Saint Paul, MN. The faculty use R for a variety of teaching and
> research tasks around campus. I administer our RStudio instance and
> have encountered an error I can't resolve. A student working on an
> independent research project has reported that he received the
> following error when attempting to use the ripa function fftImg():
> 
> Error in .C("fftw_access_func", as.complex(img), as.integer(w),
> as.integer(h),? :
>? "fftw_access_func" not available for .C() for package "ripa"
> 
> I've been able to recreate this error in RStudio as well as directly
> in R. I've also recreated the error across different platforms(Ubuntu,
> Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
> below:
> 
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.3 (El Capitan)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] parallel? tcltk? ? stats? ? graphics? grDevices utils? ? datasets
> [8] methods? base
> 
> other attached packages:
> [1] fftw_1.0-3 ripa_2.0-2
> 
> loaded via a namespace (and not attached):
> [1] tools_3.2.3 Rcpp_0.12.3
> 
> A google search for "fftw_access_func" doesn't reveal anything modern
> on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
> doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)
> 
> Can someone help me get the student functional with fftImg() or
> alternately, tell me it is a known issue and an alternative option(if
> available) for the student?
> 
> Thanks,
> Eric
> 
> --
> Eric Handler
> Academic Information Associate - Science Division
> Macalester College - Saint Paul, MN
> Olin-Rice 124
> Office: 651-696-6016
> View my calendar: http://goo.gl/SbxLOu
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
[[elided Yahoo spam]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 26 20:23:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 26 Mar 2016 12:23:11 -0700
Subject: [R] fftImg() error: fftw_access_func
In-Reply-To: <182643837.1037880.1459006921861.JavaMail.yahoo@mail.yahoo.com>
References: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
	<5362F4C2891.000001A0jrkrideau@inbox.com>
	<182643837.1037880.1459006921861.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <516653E1-A56B-4337-9589-3E556EEA4E58@comcast.net>


> On Mar 26, 2016, at 8:42 AM, Shelby Leonard via R-help <r-help at r-project.org> wrote:
> 
> So do i need to resend the email to someone else? sorry i am just confused 

Perhaps. 

The code needed to find the maintainer is at the end of this scrape of a console "dialog" and scroll to the bottom if you want the proper address for reporting problems with package:ripa, 

.... but _first_ you should be checking to see if you have all the system dependencies:


> require(ripa)
Loading required package: ripa
Loading required package: tcltk
Loading required package: parallel

Attaching package: ?ripa?

The following object is masked from ?package:rms?:

    contrast

The following object is masked from ?package:Hmisc?:

    zoom

> packageDescription("ripa")
Package: ripa
Version: 2.0-2
Date: 2014-05-29
Title: R Image Processing and Analysis
Authors at R: c(person("Talita", "Perciano", role = c("aut", "cre"),
       email = "talitaperciano at gmail.com"), person("Alejandro", "C
       Frery", role = "ctb", email = "acfrery at pq.cnpq.br"))
Maintainer: Talita Perciano <talitaperciano at gmail.com>
Depends: R (>= 2.8.1), tcltk, parallel
Suggests: e1071, rggobi, reshape, methods, jpeg, png, tkrplot,
       fftw, foreach, doSNOW
Enhances: doMC
SystemRequirements: BWidget, Tktable, Img, libjpeg

# ============
# My guess is that you do not have all of the systemRequirements on this machine. 
# Or if you do, then perhaps they are not in a directory in which the package expects to find them.
# =============

Description: A package including various functions for image
       processing and analysis. With this package is possible to
       process and analyse RGB, LAN (multispectral) and AVIRIS
       (hyperspectral) images. This packages also provides
       functions for reading JPEG files, extracted from the
       archived 'rimage' package.
License: GPL (>= 2) | file LICENSE
Imports: Rcpp (>= 0.11.0)
LinkingTo: Rcpp
URL: http://www.r-project.org
Packaged: 2014-05-30 20:18:57 UTC; Talita Perciano
Author: Talita Perciano [aut, cre], Alejandro C Frery [ctb]
NeedsCompilation: yes
Repository: CRAN
Date/Publication: 2014-05-31 01:32:57
Built: R 3.2.0; x86_64-apple-darwin13.4.0; 2015-04-21 02:07:55
       UTC; unix

-- File: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/ripa/Meta/package.rds 
> ? fftImg
>   data(logo)
>   plot(normalize(fftImg(logo)))
Error in .C("fftw_access_func", as.complex(img), as.integer(w), as.integer(h),  : 
  "fftw_access_func" not available for .C() for package "ripa"

> require(fftw)
Loading required package: fftw

# Tried that thinking (Incorrectly) the missing routine might be supplied in that package.

> data(logo)
>   plot(normalize(fftImg(logo)))
Error in .C("fftw_access_func", as.complex(img), as.integer(w), as.integer(h),  : 
  "fftw_access_func" not available for .C() for package "ripa"
> maintainer('ripa')
[1] "Talita Perciano <talitaperciano at gmail.com>"

-- 

David


> 
>    On Saturday, March 26, 2016 9:21 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
> 
> It would be helpful if you actually supplied your code and a minimal data set to for people to examine.
> 
> Please have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html.
> 
> I'm not clear if you are reporting a general R problem or a specific package with the ripa package.  If it looks like it is the latter you probably bring it to the attention of the package maintainer who may or may not monitor this mailing group.
> 
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: ehandler at macalester.edu
>> Sent: Fri, 25 Mar 2016 15:09:42 -0500
>> To: r-help at r-project.org
>> Subject: [R] fftImg() error: fftw_access_func
>> 
>> Hello-
>> 
>> My name is Eric Handler and I am an academic technologist supporting
>> the Science Division(7 academic departments) at Macalester College in
>> Saint Paul, MN. The faculty use R for a variety of teaching and
>> research tasks around campus. I administer our RStudio instance and
>> have encountered an error I can't resolve. A student working on an
>> independent research project has reported that he received the
>> following error when attempting to use the ripa function fftImg():
>> 
>> Error in .C("fftw_access_func", as.complex(img), as.integer(w),
>> as.integer(h),  :
>>   "fftw_access_func" not available for .C() for package "ripa"
>> 
>> I've been able to recreate this error in RStudio as well as directly
>> in R. I've also recreated the error across different platforms(Ubuntu,
>> Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
>> below:
>> 
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11.3 (El Capitan)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] parallel  tcltk    stats    graphics  grDevices utils    datasets
>> [8] methods  base
>> 
>> other attached packages:
>> [1] fftw_1.0-3 ripa_2.0-2
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.3 Rcpp_0.12.3
>> 
>> A google search for "fftw_access_func" doesn't reveal anything modern
>> on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
>> doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)
>> 
>> Can someone help me get the student functional with fftImg() or
>> alternately, tell me it is a known issue and an alternative option(if
>> available) for the student?
>> 
>> Thanks,
>> Eric
>> 
>> --
>> Eric Handler
>> Academic Information Associate - Science Division
>> Macalester College - Saint Paul, MN
>> Olin-Rice 124
>> Office: 651-696-6016
>> View my calendar: http://goo.gl/SbxLOu
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> [[elided Yahoo spam]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From naresh_gurbuxani at hotmail.com  Sun Mar 27 17:46:12 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sun, 27 Mar 2016 11:46:12 -0400
Subject: [R] help with function calls
Message-ID: <SNT150-W6477690A34C5B8E79A24ECFA850@phx.gbl>

I have a data frame with with several columns of parameters and one column of function name which should be used with these parameters. ?My goal is to call the appropriate function for each row and summarize the results in a list or data frame. ?I can partition the data frame according to function name, then call each function at a time. ?Is there a more elegant way to achieve this result with one call only?

Below is an example. ?Here the functions are simple. ?It is possible to write a function that incorporates both ?the functions. ?It is not so easy in my actual task. ?My goal is to make one call and obtain res.df.

Thanks,
Naresh



sum.sq <- function(x) {return(sum(x^2))}

sum.cube <- function(x) {return(sum(x^3))}

input.df <- data.frame(x1 = c(1,2,3,4), x2 = c(2,3,4,5), x3 = c(3,4,5,6), method = c(rep("sum.sq", 2), rep("sum.cube", 2)), case = c("a", "b", "c", "d"))

library(plyr)

res.df1 <- ddply(subset(input.df, method == "sum.sq"), c("case"), function(df) {
x.vec <- c(df$x1, df$x2, df$x3)
return(data.frame(sum.power = sum.sq(x.vec)))
})

res.df2 <- ddply(subset(input.df, method == "sum.cube"), c("case"), function(df) {
x.vec <- c(df$x1, df$x2, df$x3)
return(data.frame(sum.power = sum.cube(x.vec)))
})

res.df <- rbind(res.df1, res.df2)
res.df <- merge(res.df, input.df[,c("method", "case")], by = "case")



 		 	   		  

From npsathas at uth.gr  Sun Mar 27 17:52:09 2016
From: npsathas at uth.gr (PSATHAS NILOS-HRISTOS)
Date: Sun, 27 Mar 2016 18:52:09 +0300
Subject: [R] Open source project that needs performance optimizations
Message-ID: <20160327185209.Horde.QjOb3YwYCXMbenG9HAKtbw1@webmail.uth.gr>

Hello,
i am an undergraduate student on computer engineering and im  
considering to do my thesis to an open source project and make  
performance optimizations and/or add parallelism to it where possible  
(or even better make use of GPU). Do you think that R-project is a  
good candidate?

Thanks,
Psathas Neilos


From Larry.John at anser.org  Sun Mar 27 18:14:09 2016
From: Larry.John at anser.org (John, Larry)
Date: Sun, 27 Mar 2016 16:14:09 +0000
Subject: [R] Issue with var command in stats package
Message-ID: <F26D18C3423DD149B0C3203622C7270F06D62A10@HQNEX1.anser.org>

Am using R version 3.2.4 in a fully updated version of Windows 7 and the most current versions of coorplot, FactoMineR and factoextra to support multiple correspondence analysis. However, today, a line of code that worked just fine on one set of data produced an error message on a different set of data.

Specifically, when I ran:

corrplot(var$contrib, is.corr = FALSE)

I received the following message:

> corrplot(var$contrib, is.corr = FALSE)
Error in var$contrib : object of type 'closure' is not subsettable

Can you please tell me what this error message means and roughly what I might need to do to correct it? If necessary, I can provide the original data files.

Many thanks for your kind help.

Very Respectfully,

Larry John
Principal Analyst
ANSER

From sarah.goslee at gmail.com  Sun Mar 27 18:20:08 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 27 Mar 2016 12:20:08 -0400
Subject: [R] Issue with var command in stats package
In-Reply-To: <F26D18C3423DD149B0C3203622C7270F06D62A10@HQNEX1.anser.org>
References: <F26D18C3423DD149B0C3203622C7270F06D62A10@HQNEX1.anser.org>
Message-ID: <CAM_vjumF7Q0rt=yEDwhXkneZ_TKqQRyr6bkrpNG8nTki58w=Uw@mail.gmail.com>

Somewhere you'd named an R object var, which is also the name of the function.

There's no way to access part of a function with $ so
var$contrib
is throwing the closure error, which is telling you that you can't
index a function.


Sarah


On Sun, Mar 27, 2016 at 12:14 PM, John, Larry <Larry.John at anser.org> wrote:
> Am using R version 3.2.4 in a fully updated version of Windows 7 and the most current versions of coorplot, FactoMineR and factoextra to support multiple correspondence analysis. However, today, a line of code that worked just fine on one set of data produced an error message on a different set of data.
>
> Specifically, when I ran:
>
> corrplot(var$contrib, is.corr = FALSE)
>
> I received the following message:
>
>> corrplot(var$contrib, is.corr = FALSE)
> Error in var$contrib : object of type 'closure' is not subsettable
>
> Can you please tell me what this error message means and roughly what I might need to do to correct it? If necessary, I can provide the original data files.
>
> Many thanks for your kind help.
>
> Very Respectfully,
>
> Larry John
> Principal Analyst
> ANSER


From dwinsemius at comcast.net  Sun Mar 27 18:28:50 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 27 Mar 2016 09:28:50 -0700
Subject: [R] Issue with var command in stats package
In-Reply-To: <F26D18C3423DD149B0C3203622C7270F06D62A10@HQNEX1.anser.org>
References: <F26D18C3423DD149B0C3203622C7270F06D62A10@HQNEX1.anser.org>
Message-ID: <7B29E6B0-D4BC-46CD-89C7-CB972FB238C2@comcast.net>


> On Mar 27, 2016, at 9:14 AM, John, Larry <Larry.John at anser.org> wrote:
> 
> Am using R version 3.2.4 in a fully updated version of Windows 7 and the most current versions of coorplot, FactoMineR and factoextra to support multiple correspondence analysis. However, today, a line of code that worked just fine on one set of data produced an error message on a different set of data.
> 
> Specifically, when I ran:
> 
> corrplot(var$contrib, is.corr = FALSE)
> 
> I received the following message:
> 
>> corrplot(var$contrib, is.corr = FALSE)
> Error in var$contrib : object of type 'closure' is not subsettable

Since there is apparently not an object in your workspace named `var`, the interpreter is instead finding the function named `var` (which delivers the variance of a vector) and then is trying to apply the `$`-function to it .... but there is no `$`-method for functions. 

> 
> Can you please tell me what this error message means and roughly what I might need to do to correct it? If necessary, I can provide the original data files.

I doubt that the error is in your data. You need to find the section of code that was supposed to be creating an object named `var` and hopefully you now understand why that naming convention was a bad idea. Rewrite that section of code to use objects having more meaningful names, which will result in errors that are more helpful to you in the future.

-- 

David Winsemius
Alameda, CA, USA


From rsherry8 at comcast.net  Sun Mar 27 18:50:15 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sun, 27 Mar 2016 12:50:15 -0400
Subject: [R] Open source project that needs performance optimizations
In-Reply-To: <20160327185209.Horde.QjOb3YwYCXMbenG9HAKtbw1@webmail.uth.gr>
References: <20160327185209.Horde.QjOb3YwYCXMbenG9HAKtbw1@webmail.uth.gr>
Message-ID: <56F80F47.6060503@comcast.net>

I am not up on the internals of R but there does seem some run for 
parallelism. Are we talking about special hardware? or running this on 
an Intel Box? If it is the second, then I am thinking threads would be 
the way to go. Please consider the following
R statements:
     for( i in 1:30 )    a[i] = f1(i)
Would it make sense to  setup a separate thread for each call to f1?  I 
think it in most cases, the answer is no but on some machines and 
depending on the running time of f1, it could be a big win. Also, does 
the user have to change his code, or would R be
smart enough to do the work behind the scenes. I consider the second to 
be significantly better than the first.

You may also want to look at the following URL
http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors

Bob

On 3/27/2016 11:52 AM, PSATHAS NILOS-HRISTOS wrote:
> Hello,
> i am an undergraduate student on computer engineering and im 
> considering to do my thesis to an open source project and make 
> performance optimizations and/or add parallelism to it where possible 
> (or even better make use of GPU). Do you think that R-project is a 
> good candidate?
>
> Thanks,
> Psathas Neilos
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hamidreza153 at yahoo.com  Sun Mar 27 18:52:02 2016
From: hamidreza153 at yahoo.com (HAMID REZA ASHRAFI)
Date: Sun, 27 Mar 2016 16:52:02 +0000 (UTC)
Subject: [R] Robust ANCOVA
References: <862738374.1254636.1459097522717.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>

HiI have a set of data with two independent variables, a pretest (covariate) and posttest (dependent variable).Can anyone help me run robust ANCOVA?If you wish I can send you the data file.yours
	[[alternative HTML version deleted]]


From farzana.akbari2013 at gmail.com  Sun Mar 27 19:10:35 2016
From: farzana.akbari2013 at gmail.com (farzana akbari)
Date: Sun, 27 Mar 2016 07:10:35 -1000
Subject: [R] loading
Message-ID: <CAL3rq9g3yNpir97WQz7hWo12jRvGfp=+ZbUxHwoF5jMw9X0O3g@mail.gmail.com>

 hi I install plm and pglm packages but I  can not load no one of them. the
massage of loading plm is

> library(plm)
Loading required package: Formula


and for pglm is



> library(pglm)
Loading required package: maxLik
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum
likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI
10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik'
package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/

can you help me? and also when i wanna Formula package there is no massage
. for installing Formula massage is
--- Please select a CRAN mirror for use in this session ---
Warning: package ?Formula? is in use and will not be installed


i used  3.1.3  and  3.2.4 ver *64  and  32  and my computer is 64 bit



please help me

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sun Mar 27 19:54:55 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 27 Mar 2016 19:54:55 +0200
Subject: [R] loading
In-Reply-To: <CAL3rq9g3yNpir97WQz7hWo12jRvGfp=+ZbUxHwoF5jMw9X0O3g@mail.gmail.com>
References: <CAL3rq9g3yNpir97WQz7hWo12jRvGfp=+ZbUxHwoF5jMw9X0O3g@mail.gmail.com>
Message-ID: <56F81E6F.60706@statistik.tu-dortmund.de>

Err, you already loaded it, there is not necessarily another message. 
Just try the functions you want to use. ..

Best,
Uwe Ligges



On 27.03.2016 19:10, farzana akbari wrote:
>   hi I install plm and pglm packages but I  can not load no one of them. the
> massage of loading plm is
>
>> library(plm)
> Loading required package: Formula
>
>
> and for pglm is
>
>
>
>> library(pglm)
> Loading required package: maxLik
> Loading required package: miscTools
>
> Please cite the 'maxLik' package as:
> Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum
> likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI
> 10.1007/s00180-010-0217-1.
>
> If you have questions, suggestions, or comments regarding the 'maxLik'
> package, please use a forum or 'tracker' at maxLik's R-Forge site:
> https://r-forge.r-project.org/projects/maxlik/
>
> can you help me? and also when i wanna Formula package there is no massage
> . for installing Formula massage is
> --- Please select a CRAN mirror for use in this session ---
> Warning: package ?Formula? is in use and will not be installed
>
>
> i used  3.1.3  and  3.2.4 ver *64  and  32  and my computer is 64 bit
>
>
>
> please help me
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Sun Mar 27 20:35:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 27 Mar 2016 11:35:38 -0700
Subject: [R] help with function calls
In-Reply-To: <SNT150-W6477690A34C5B8E79A24ECFA850@phx.gbl>
References: <SNT150-W6477690A34C5B8E79A24ECFA850@phx.gbl>
Message-ID: <CAGxFJbRwFvv=ph66Eki2RaETYJhd7Z5wKpHX-9eh0wa9R-dG-A@mail.gmail.com>

1. return() is not needed in R functions (it's harmless, however). You
might wish to go through an R function tutorial (many good ones are on
the web) to learn about what slick things you can do with functions in
R.

2. The following is just a brute force loop, so more elegant
approaches are likely possible, but this seems to do what you want:

sapply(seq_len(nrow(input.df)),
       function(i)do.call(input.df[i,4],list(x=unlist(input.df[i,1:3])))
      )

## see ?do.call

3. I suspect that a change in your data structure might facilitate
your task, but of course, not knowing the task, I would not know what
changes would be useful. See ?switch  for something that might be
related to what you are trying to do.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 27, 2016 at 8:46 AM, Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
> I have a data frame with with several columns of parameters and one column of function name which should be used with these parameters.  My goal is to call the appropriate function for each row and summarize the results in a list or data frame.  I can partition the data frame according to function name, then call each function at a time.  Is there a more elegant way to achieve this result with one call only?
>
> Below is an example.  Here the functions are simple.  It is possible to write a function that incorporates both  the functions.  It is not so easy in my actual task.  My goal is to make one call and obtain res.df.
>
> Thanks,
> Naresh
>
>
>
> sum.sq <- function(x) {return(sum(x^2))}
>
> sum.cube <- function(x) {return(sum(x^3))}
>
> input.df <- data.frame(x1 = c(1,2,3,4), x2 = c(2,3,4,5), x3 = c(3,4,5,6), method = c(rep("sum.sq", 2), rep("sum.cube", 2)), case = c("a", "b", "c", "d"))
>
> library(plyr)
>
> res.df1 <- ddply(subset(input.df, method == "sum.sq"), c("case"), function(df) {
> x.vec <- c(df$x1, df$x2, df$x3)
> return(data.frame(sum.power = sum.sq(x.vec)))
> })
>
> res.df2 <- ddply(subset(input.df, method == "sum.cube"), c("case"), function(df) {
> x.vec <- c(df$x1, df$x2, df$x3)
> return(data.frame(sum.power = sum.cube(x.vec)))
> })
>
> res.df <- rbind(res.df1, res.df2)
> res.df <- merge(res.df, input.df[,c("method", "case")], by = "case")
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Mar 27 20:44:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 27 Mar 2016 11:44:43 -0700
Subject: [R] help with function calls
In-Reply-To: <CAGxFJbRwFvv=ph66Eki2RaETYJhd7Z5wKpHX-9eh0wa9R-dG-A@mail.gmail.com>
References: <SNT150-W6477690A34C5B8E79A24ECFA850@phx.gbl>
	<CAGxFJbRwFvv=ph66Eki2RaETYJhd7Z5wKpHX-9eh0wa9R-dG-A@mail.gmail.com>
Message-ID: <CAGxFJbR8=PFgQ0gO9vLqcBwT_fGY6U5DoduV+Q8N_H45+bSrhQ@mail.gmail.com>

OOPS! I forgot to tell you that I first changed the "method" column,
which is a factor, to character, with

input.df$method <- as.character(input.df$method)

Then things will work properly.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 27, 2016 at 11:35 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 1. return() is not needed in R functions (it's harmless, however). You
> might wish to go through an R function tutorial (many good ones are on
> the web) to learn about what slick things you can do with functions in
> R.
>
> 2. The following is just a brute force loop, so more elegant
> approaches are likely possible, but this seems to do what you want:
>
> sapply(seq_len(nrow(input.df)),
>        function(i)do.call(input.df[i,4],list(x=unlist(input.df[i,1:3])))
>       )
>
> ## see ?do.call
>
> 3. I suspect that a change in your data structure might facilitate
> your task, but of course, not knowing the task, I would not know what
> changes would be useful. See ?switch  for something that might be
> related to what you are trying to do.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Mar 27, 2016 at 8:46 AM, Naresh Gurbuxani
> <naresh_gurbuxani at hotmail.com> wrote:
>> I have a data frame with with several columns of parameters and one column of function name which should be used with these parameters.  My goal is to call the appropriate function for each row and summarize the results in a list or data frame.  I can partition the data frame according to function name, then call each function at a time.  Is there a more elegant way to achieve this result with one call only?
>>
>> Below is an example.  Here the functions are simple.  It is possible to write a function that incorporates both  the functions.  It is not so easy in my actual task.  My goal is to make one call and obtain res.df.
>>
>> Thanks,
>> Naresh
>>
>>
>>
>> sum.sq <- function(x) {return(sum(x^2))}
>>
>> sum.cube <- function(x) {return(sum(x^3))}
>>
>> input.df <- data.frame(x1 = c(1,2,3,4), x2 = c(2,3,4,5), x3 = c(3,4,5,6), method = c(rep("sum.sq", 2), rep("sum.cube", 2)), case = c("a", "b", "c", "d"))
>>
>> library(plyr)
>>
>> res.df1 <- ddply(subset(input.df, method == "sum.sq"), c("case"), function(df) {
>> x.vec <- c(df$x1, df$x2, df$x3)
>> return(data.frame(sum.power = sum.sq(x.vec)))
>> })
>>
>> res.df2 <- ddply(subset(input.df, method == "sum.cube"), c("case"), function(df) {
>> x.vec <- c(df$x1, df$x2, df$x3)
>> return(data.frame(sum.power = sum.cube(x.vec)))
>> })
>>
>> res.df <- rbind(res.df1, res.df2)
>> res.df <- merge(res.df, input.df[,c("method", "case")], by = "case")
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From massimo.bressan at arpa.veneto.it  Sun Mar 27 23:45:33 2016
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Sun, 27 Mar 2016 23:45:33 +0200 (CEST)
Subject: [R] 'split-lapply' vs. 'aggregate'
Message-ID: <492484067.5300589.1459115133468.JavaMail.zimbra@arpa.veneto.it>

this might be a trivial question (eventually sorry for that!) but I definitely can not catch the problem here... 

please consider the following reproducible example: why of different results through 'split-lapply' vs. 'aggregate'? 
I've been also through a check against different methods (e.g. data.table, dplyr) and the results were always consistent with 'split-lapply' but apparently not with 'aggregate' 

I must be certainly wrong! 
could someone point me in the right direction? 

thanks 

## 

s <- split(airquality, airquality$Month) 
ls <- lapply(s, function(x) {colMeans(x[c("Ozone", "Solar.R", "Wind")], na.rm = TRUE)}) 
do.call(rbind, ls) 

# slightly different results with 
aggregate(.~ Month, airquality[-c(4,6)], mean, na.rm=TRUE) 

## 

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Mar 28 02:35:24 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 28 Mar 2016 00:35:24 +0000
Subject: [R] 'split-lapply' vs. 'aggregate'
In-Reply-To: <492484067.5300589.1459115133468.JavaMail.zimbra@arpa.veneto.it>
References: <492484067.5300589.1459115133468.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F64ADB@FHSDB2D11-2.csu.mcmaster.ca>

Dear Massimo,

The difference is in the handling of NAs. Try, e.g., airquality <- na.omit(airquality) and compare again.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Massimo Bressan [massimo.bressan at arpa.veneto.it]
Sent: March 27, 2016 5:45 PM
To: r-help at r-project.org
Subject: [R] 'split-lapply' vs. 'aggregate'

this might be a trivial question (eventually sorry for that!) but I definitely can not catch the problem here...

please consider the following reproducible example: why of different results through 'split-lapply' vs. 'aggregate'?
I've been also through a check against different methods (e.g. data.table, dplyr) and the results were always consistent with 'split-lapply' but apparently not with 'aggregate'

I must be certainly wrong!
could someone point me in the right direction?

thanks

##

s <- split(airquality, airquality$Month)
ls <- lapply(s, function(x) {colMeans(x[c("Ozone", "Solar.R", "Wind")], na.rm = TRUE)})
do.call(rbind, ls)

# slightly different results with
aggregate(.~ Month, airquality[-c(4,6)], mean, na.rm=TRUE)

##

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Mar 28 03:48:26 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 28 Mar 2016 12:48:26 +1100
Subject: [R] Robust ANCOVA
In-Reply-To: <862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>
References: <862738374.1254636.1459097522717.JavaMail.yahoo.ref@mail.yahoo.com>
	<862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fUGNVcD_gHGCaG9fptbD4659Jqwdf1qQENZ+1pSJW_81A@mail.gmail.com>

Hi Hamid,
This looks a bit like a repeated measures analysis, but for a simple
introduction to ANCOVA using R see the latter part of the following:

http://www.stat.columbia.edu/~martin/W2024/R8.pdf

Jim

On Mon, Mar 28, 2016 at 3:52 AM, HAMID REZA ASHRAFI via R-help
<r-help at r-project.org> wrote:
> HiI have a set of data with two independent variables, a pretest (covariate) and posttest (dependent variable).Can anyone help me run robust ANCOVA?If you wish I can send you the data file.yours
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Mar 28 03:58:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 27 Mar 2016 18:58:09 -0700
Subject: [R] help with function calls
In-Reply-To: <CAGxFJbR8=PFgQ0gO9vLqcBwT_fGY6U5DoduV+Q8N_H45+bSrhQ@mail.gmail.com>
References: <SNT150-W6477690A34C5B8E79A24ECFA850@phx.gbl>
	<CAGxFJbRwFvv=ph66Eki2RaETYJhd7Z5wKpHX-9eh0wa9R-dG-A@mail.gmail.com>
	<CAGxFJbR8=PFgQ0gO9vLqcBwT_fGY6U5DoduV+Q8N_H45+bSrhQ@mail.gmail.com>
Message-ID: <CAGxFJbTEsv=vJhLEwPWNCP+vmaLy4RfPZx6+d4xWSSYyi8Vedg@mail.gmail.com>

...
and here is a maybe slightly neater approach using ?mapply (again with
the method column changed to character():

f <- function(meth,i,fr) do.call(meth,list((fr[i,])))

mapply(FUN=f,meth=input.df[,4],seq_len(nrow(input.df)),
       MoreArgs = list(fr = input.df[,1:3]) )


Cheers,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 27, 2016 at 11:44 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> OOPS! I forgot to tell you that I first changed the "method" column,
> which is a factor, to character, with
>
> input.df$method <- as.character(input.df$method)
>
> Then things will work properly.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Mar 27, 2016 at 11:35 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 1. return() is not needed in R functions (it's harmless, however). You
>> might wish to go through an R function tutorial (many good ones are on
>> the web) to learn about what slick things you can do with functions in
>> R.
>>
>> 2. The following is just a brute force loop, so more elegant
>> approaches are likely possible, but this seems to do what you want:
>>
>> sapply(seq_len(nrow(input.df)),
>>        function(i)do.call(input.df[i,4],list(x=unlist(input.df[i,1:3])))
>>       )
>>
>> ## see ?do.call
>>
>> 3. I suspect that a change in your data structure might facilitate
>> your task, but of course, not knowing the task, I would not know what
>> changes would be useful. See ?switch  for something that might be
>> related to what you are trying to do.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Mar 27, 2016 at 8:46 AM, Naresh Gurbuxani
>> <naresh_gurbuxani at hotmail.com> wrote:
>>> I have a data frame with with several columns of parameters and one column of function name which should be used with these parameters.  My goal is to call the appropriate function for each row and summarize the results in a list or data frame.  I can partition the data frame according to function name, then call each function at a time.  Is there a more elegant way to achieve this result with one call only?
>>>
>>> Below is an example.  Here the functions are simple.  It is possible to write a function that incorporates both  the functions.  It is not so easy in my actual task.  My goal is to make one call and obtain res.df.
>>>
>>> Thanks,
>>> Naresh
>>>
>>>
>>>
>>> sum.sq <- function(x) {return(sum(x^2))}
>>>
>>> sum.cube <- function(x) {return(sum(x^3))}
>>>
>>> input.df <- data.frame(x1 = c(1,2,3,4), x2 = c(2,3,4,5), x3 = c(3,4,5,6), method = c(rep("sum.sq", 2), rep("sum.cube", 2)), case = c("a", "b", "c", "d"))
>>>
>>> library(plyr)
>>>
>>> res.df1 <- ddply(subset(input.df, method == "sum.sq"), c("case"), function(df) {
>>> x.vec <- c(df$x1, df$x2, df$x3)
>>> return(data.frame(sum.power = sum.sq(x.vec)))
>>> })
>>>
>>> res.df2 <- ddply(subset(input.df, method == "sum.cube"), c("case"), function(df) {
>>> x.vec <- c(df$x1, df$x2, df$x3)
>>> return(data.frame(sum.power = sum.cube(x.vec)))
>>> })
>>>
>>> res.df <- rbind(res.df1, res.df2)
>>> res.df <- merge(res.df, input.df[,c("method", "case")], by = "case")
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From satish.vadlamani at gmail.com  Mon Mar 28 02:56:07 2016
From: satish.vadlamani at gmail.com (Satish Vadlamani)
Date: Sun, 27 Mar 2016 17:56:07 -0700
Subject: [R] How to form groups for this specific problem?
Message-ID: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>

Hello All:
I would like to get some help with the following problem and understand how
this can be done in R efficiently. The header is given in the data frame.

*Component, TLA*
C1, TLA1
C2, TLA1
C1, TLA2
C3, TLA2
C4, TLA3
C5, TLA3

Notice that C1 is a component of TLA1 and TLA2.

I would like to form groups of mutually exclusive subsets and create a new
column called group for this subset. For the above data, the subsets and
the new group column value will be like so:

*Component, TLA, Group*
C1, TLA1, 1
C2, TLA1, 1
C1, TLA2, 1
C3, TLA2, 1
C4, TLA3, 2
C5, TLA3, 2

Appreciate any help on this. I could have looped through the observations
and tried some logic but I did not try that yet.

-- 

Satish Vadlamani

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Mar 28 04:30:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 27 Mar 2016 19:30:31 -0700
Subject: [R] Robust ANCOVA
In-Reply-To: <862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>
References: <862738374.1254636.1459097522717.JavaMail.yahoo.ref@mail.yahoo.com>
	<862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <3089FB6F-BDC4-4083-8D5F-C75B4CBBFFAC@comcast.net>


> On Mar 27, 2016, at 9:52 AM, HAMID REZA ASHRAFI via R-help <r-help at r-project.org> wrote:
> 
> HiI have a set of data with two independent variables, a pretest (covariate) and posttest (dependent variable).Can anyone help me run robust ANCOVA?If you wish I can send you the data file.yours
> 	[[alternative HTML version deleted]]

https://cran.r-project.org/web/views/Robust.html

help(pac=MASS, rlm)

# A starting point perhaps:

MASS::rlm( Post ~ pre +IV1 + IV2, data=yourdataframe)


-- 


David Winsemius
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Mon Mar 28 10:24:18 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Mar 2016 10:24:18 +0200
Subject: [R] Robust ANCOVA
In-Reply-To: <3089FB6F-BDC4-4083-8D5F-C75B4CBBFFAC@comcast.net>
References: <862738374.1254636.1459097522717.JavaMail.yahoo.ref@mail.yahoo.com>
	<862738374.1254636.1459097522717.JavaMail.yahoo@mail.yahoo.com>
	<3089FB6F-BDC4-4083-8D5F-C75B4CBBFFAC@comcast.net>
Message-ID: <22264.59954.919241.878977@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Sun, 27 Mar 2016 19:30:31 -0700 writes:

    >> On Mar 27, 2016, at 9:52 AM, HAMID REZA ASHRAFI via
    >> R-help <r-help at r-project.org> wrote:
    >> 
    >> HiI have a set of data with two independent variables, a
    >> pretest (covariate) and posttest (dependent variable).Can
    >> anyone help me run robust ANCOVA?If you wish I can send
    >> you the data file.yours [[alternative HTML version
    >> deleted]]

    > https://cran.r-project.org/web/views/Robust.html

    > help(pac=MASS, rlm)

    > # A starting point perhaps:

    > MASS::rlm( Post ~ pre +IV1 + IV2, data=yourdataframe)

    > David Winsemius Alameda, CA, USA

Indeed.
Or use the more sophisticated (and somewhat more robust /
efficient) methods from package 'robustbase'

install.packages("robustbase")
require("robustbase")
fm <- lmrob(Post ~ pre +IV1 + IV2, setting = "KS2014",
            data=yourdataframe)


where recent research lead to the recommendation of  setting="KS2014",
which indeed maybe relevant for "ANCOVA".

Martin Maechler, ETH Zurich
(and maintainer of 'robustbase', hence "biased" !)


From sunnysingha.analytics at gmail.com  Mon Mar 28 15:46:36 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 28 Mar 2016 19:16:36 +0530
Subject: [R] Please guide -- UTF-8 locale setting fails on Windows on writing
Message-ID: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>

Hi,
I think I'm experiencing an issue regarding system Locale. I have
exported '.csv' formatted data frames gathered from various social
media platforms like facebook/twitter/G+, etc.

I observe many variable/columns consists of strings formatted similar to below:
"<U+0645><U+062D><U+0645><U+062F>
<U+0627><U+0644><U+0633><U+0648><U+0627><U+062D>"

As expected and I confirmed, in social media data, they are strings in
different languages.
Platform details are provide in the end of this mail. OS locale is set
to English (United States) hence 'R' locale is 'English_United
States.1252'

I have attempted to change it to UTF-8 but receives below warning message:

Warning message:
In Sys.setlocale("LC_ALL", "UTF-8") :
  OS reports request to set locale to "UTF-8" cannot be honored


I have gone through below forums but no resolution so far:
--- http://stackoverflow.com/questions/20571147/how-to-set-unicode-locale-in-r
--- https://stat.ethz.ch/pipermail/r-devel/2013-November/067940.html
--- http://stackoverflow.com/questions/19877676/write-utf-8-files-from-r
--- https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
--- http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/

I'm not sure whether the issue is while reading/extracting the data
from media or while writing/exporting in Windows directory, but I
don't experience similar issue in my personal Mac machine. I need some
clarification here.

How could I export the data just as I see on web ?  Please guide.

Regards,
Sunny

Platform I'm using::::::::::::::::::::::::::::
Operating System : Windows 7 Professional SP1
R version details:
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          2.3
year           2015
month          12
day            10
svn rev        69752
language       R
version.string R version 3.2.3 (2015-12-10)
nickname       Wooden Christmas-Tree


From nalimilan at club.fr  Mon Mar 28 16:09:53 2016
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 28 Mar 2016 16:09:53 +0200
Subject: [R] Please guide -- UTF-8 locale setting fails on Windows on
 writing
In-Reply-To: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>
References: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>
Message-ID: <1459174193.645.27.camel@club.fr>

Le lundi 28 mars 2016 ? 19:16 +0530, Sunny Singha a ?crit?:
> Hi,
> I think I'm experiencing an issue regarding system Locale. I have
> exported '.csv' formatted data frames gathered from various social
> media platforms like facebook/twitter/G+, etc.
> 
> I observe many variable/columns consists of strings formatted similar to below:
> "
> "
> 
> As expected and I confirmed, in social media data, they are strings in
> different languages.
> Platform details are provide in the end of this mail. OS locale is set
> to English (United States) hence 'R' locale is 'English_United
> States.1252'
> 
> I have attempted to change it to UTF-8 but receives below warning message:
> 
> Warning message:
> In Sys.setlocale("LC_ALL", "UTF-8") :
> ? OS reports request to set locale to "UTF-8" cannot be honored
You don't need to set the locale. Just pass an appropriate value (e.g.
"UTF-8") to read.csv() or write.csv()'s fileEncoding argument.

You also didn't tell us what program you used to read these files. Some
might guess the encoding incorrectly, or require you to choose it
manually.


Regards

> I have gone through below forums but no resolution so far:
> --- http://stackoverflow.com/questions/20571147/how-to-set-unicode-locale-in-r
> --- https://stat.ethz.ch/pipermail/r-devel/2013-November/067940.html
> --- http://stackoverflow.com/questions/19877676/write-utf-8-files-from-r
> --- https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
> --- http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/
> 
> I'm not sure whether the issue is while reading/extracting the data
> from media or while writing/exporting in Windows directory, but I
> don't experience similar issue in my personal Mac machine. I need some
> clarification here.
> 
> How could I export the data just as I see on web ???Please guide.
> 
> Regards,
> Sunny
> 
> Platform I'm using::::::::::::::::::::::::::::
> Operating System : Windows 7 Professional SP1
> R version details:
> platform???????x86_64-w64-mingw32
> arch???????????x86_64
> os?????????????mingw32
> system?????????x86_64, mingw32
> status
> major??????????3
> minor??????????2.3
> year???????????2015
> month??????????12
> day????????????10
> svn rev????????69752
> language???????R
> version.string R version 3.2.3 (2015-12-10)
> nickname???????Wooden Christmas-Tree
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Mar 28 16:34:55 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 28 Mar 2016 10:34:55 -0400
Subject: [R] How to form groups for this specific problem?
In-Reply-To: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
References: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
Message-ID: <CAM_vjunURQVYAnf+CnB2sya2o9gmdSugPML_R7c3qx3kfVbP-w@mail.gmail.com>

It isn't at all clear to me how you are creating the groups. They
aren't the unique combinations of Component and TLA. They might be
based only on TLA value: in your example TLA1 and TLA2 form one group,
and TLA3 the other.

Without understanding your logic, I can't replicate it with R code.

Sarah

On Sun, Mar 27, 2016 at 8:56 PM, Satish Vadlamani
<satish.vadlamani at gmail.com> wrote:
> Hello All:
> I would like to get some help with the following problem and understand how
> this can be done in R efficiently. The header is given in the data frame.
>
> *Component, TLA*
> C1, TLA1
> C2, TLA1
> C1, TLA2
> C3, TLA2
> C4, TLA3
> C5, TLA3
>
> Notice that C1 is a component of TLA1 and TLA2.
>
> I would like to form groups of mutually exclusive subsets and create a new
> column called group for this subset. For the above data, the subsets and
> the new group column value will be like so:
>
> *Component, TLA, Group*
> C1, TLA1, 1
> C2, TLA1, 1
> C1, TLA2, 1
> C3, TLA2, 1
> C4, TLA3, 2
> C5, TLA3, 2
>
> Appreciate any help on this. I could have looped through the observations
> and tried some logic but I did not try that yet.
>
> --
>
> Satish Vadlamani
>
>         [[alternative HTML version deleted]]
>
And please don't post in HTML.


From sunnysingha.analytics at gmail.com  Mon Mar 28 16:42:19 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 28 Mar 2016 20:12:19 +0530
Subject: [R] Please guide -- UTF-8 locale setting fails on Windows on
	writing
In-Reply-To: <1459174193.645.27.camel@club.fr>
References: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>
	<1459174193.645.27.camel@club.fr>
Message-ID: <CANOG_FW5f+PpsybYoiAikYAt=Ew-njdx75wAgDjrLiPuMv+dcg@mail.gmail.com>

Milan,
Ok, Let me take a case of facebook. I used Rfacebook package
 to get posts (getPost()) which returns list() of data frames(post,
comments, Likes)

let me demonstrate 2 cases of read and write just as you suggested,
Case 1:::::::::
Lets say one of the facebook comment has below string value, in
Japanese language-->
"?????? - ???????? ?????"

On R console I now assign above string to variableas: x <- "?????? -
???????? ?????"
and write it as below:
write.csv(x, file='x.csv', row.names=F, fileEncoding='UTF-8')
I get this string in the file
""<U+4E16><U+754C><U+9910><U+798F><U+4E8B><U+5DE5> -
<U+9910><U+5EF3><U+54E1><U+5DE5><U+6C92><U+7CBE><U+6253><U+91C7> "

Case 2::::::::::::::
I create a notepad 'x.txt' and save Japanese string "?????? - ???????? ?????"
and read it as below:
read.table('x.txt', fileEncoding='UTF-8'), I get below output:

  V1
1  ?
Warning messages:
1: In read.table("x.txt", fileEncoding = "UTF-8") :
  invalid input found on input connection 'x.txt'
2: In read.table("x.txt", fileEncoding = "UTF-8") :
  incomplete final line found by readTableHeader on 'x.txt'

Above was for demonstration, I'm infact reading social media data
extracted, which ultimately is somewhere using httr package and
returning data frames.
I'm not sure how should I get it handled in Windows as I don't observe
this behavior in Mac where system locase is set to 'en_US.UTF-8'

Regards,
Sunny




On Mon, Mar 28, 2016 at 7:39 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le lundi 28 mars 2016 ? 19:16 +0530, Sunny Singha a ?crit :
>> Hi,
>> I think I'm experiencing an issue regarding system Locale. I have
>> exported '.csv' formatted data frames gathered from various social
>> media platforms like facebook/twitter/G+, etc.
>>
>> I observe many variable/columns consists of strings formatted similar to below:
>> "
>> "
>>
>> As expected and I confirmed, in social media data, they are strings in
>> different languages.
>> Platform details are provide in the end of this mail. OS locale is set
>> to English (United States) hence 'R' locale is 'English_United
>> States.1252'
>>
>> I have attempted to change it to UTF-8 but receives below warning message:
>>
>> Warning message:
>> In Sys.setlocale("LC_ALL", "UTF-8") :
>>   OS reports request to set locale to "UTF-8" cannot be honored
> You don't need to set the locale. Just pass an appropriate value (e.g.
> "UTF-8") to read.csv() or write.csv()'s fileEncoding argument.
>
> You also didn't tell us what program you used to read these files. Some
> might guess the encoding incorrectly, or require you to choose it
> manually.
>
>
> Regards
>
>> I have gone through below forums but no resolution so far:
>> --- http://stackoverflow.com/questions/20571147/how-to-set-unicode-locale-in-r
>> --- https://stat.ethz.ch/pipermail/r-devel/2013-November/067940.html
>> --- http://stackoverflow.com/questions/19877676/write-utf-8-files-from-r
>> --- https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
>> --- http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/
>>
>> I'm not sure whether the issue is while reading/extracting the data
>> from media or while writing/exporting in Windows directory, but I
>> don't experience similar issue in my personal Mac machine. I need some
>> clarification here.
>>
>> How could I export the data just as I see on web ?  Please guide.
>>
>> Regards,
>> Sunny
>>
>> Platform I'm using::::::::::::::::::::::::::::
>> Operating System : Windows 7 Professional SP1
>> R version details:
>> platform       x86_64-w64-mingw32
>> arch           x86_64
>> os             mingw32
>> system         x86_64, mingw32
>> status
>> major          3
>> minor          2.3
>> year           2015
>> month          12
>> day            10
>> svn rev        69752
>> language       R
>> version.string R version 3.2.3 (2015-12-10)
>> nickname       Wooden Christmas-Tree
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Mar 28 18:09:35 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 28 Mar 2016 11:09:35 -0500
Subject: [R] How to form groups for this specific problem?
In-Reply-To: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
References: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
Message-ID: <CAN5YmCGDLwb32Zy+cdQ4YgsEAGRGaXccGxdCLQfQjKLvKtKvcQ@mail.gmail.com>

Satish,

If you rearrange your data into a network of nodes and edges, you can use
the igraph package to identify disconnected (mutually exclusive) groups.

# example data
df <- data.frame(
  Component = c("C1", "C2", "C1", "C3", "C4", "C5"),
  TLA = c("TLA1", "TLA1", "TLA2", "TLA2", "TLA3", "TLA3")
)

# characterize data as a network of nodes and edges
nodes <- levels(unlist(df))
edges <- apply(df, 2, match, nodes)

# use the igraph package to identify disconnected groups
library(igraph)
g <- graph(edges)
ngroup <- clusters(g)$membership
df$Group <- ngroup[match(df$Component, nodes)]
df

  Component  TLA Group
1        C1 TLA1     1
2        C2 TLA1     1
3        C1 TLA2     1
4        C3 TLA2     1
5        C4 TLA3     2
6        C5 TLA3     2

Jean

On Sun, Mar 27, 2016 at 7:56 PM, Satish Vadlamani <
satish.vadlamani at gmail.com> wrote:

> Hello All:
> I would like to get some help with the following problem and understand how
> this can be done in R efficiently. The header is given in the data frame.
>
> *Component, TLA*
> C1, TLA1
> C2, TLA1
> C1, TLA2
> C3, TLA2
> C4, TLA3
> C5, TLA3
>
> Notice that C1 is a component of TLA1 and TLA2.
>
> I would like to form groups of mutually exclusive subsets and create a new
> column called group for this subset. For the above data, the subsets and
> the new group column value will be like so:
>
> *Component, TLA, Group*
> C1, TLA1, 1
> C2, TLA1, 1
> C1, TLA2, 1
> C3, TLA2, 1
> C4, TLA3, 2
> C5, TLA3, 2
>
> Appreciate any help on this. I could have looped through the observations
> and tried some logic but I did not try that yet.
>
> --
>
> Satish Vadlamani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Mon Mar 28 18:21:56 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Mon, 28 Mar 2016 11:21:56 -0500
Subject: [R] Could not find function even though I have all necessary
	packages
Message-ID: <CA+pG8eOL--WFdr8Hay1eC7UFEk6yfif=PXWxj1R0oZ1Mabqeww@mail.gmail.com>

Hi,
  I am getting the error,

Error: could not find function "createDataPartition"

when I do the code
dataFrame_data <- createDataPartition(data$colA, p=.7, list=FALSE)

even though I have run already

install.packages("caret", dependencies = c("Depends", "Imports",
"Suggests"))
and
install.packages("caret")

those worked and I then ran
library(caret)

does anyone know why I'm unable to use this function?

	[[alternative HTML version deleted]]


From nalimilan at club.fr  Mon Mar 28 18:28:38 2016
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 28 Mar 2016 18:28:38 +0200
Subject: [R] Please guide -- UTF-8 locale setting fails on Windows on
 writing
In-Reply-To: <CANOG_FW5f+PpsybYoiAikYAt=Ew-njdx75wAgDjrLiPuMv+dcg@mail.gmail.com>
References: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>
	<1459174193.645.27.camel@club.fr>
	<CANOG_FW5f+PpsybYoiAikYAt=Ew-njdx75wAgDjrLiPuMv+dcg@mail.gmail.com>
Message-ID: <1459182518.645.33.camel@club.fr>

Le lundi 28 mars 2016 ? 20:12 +0530, Sunny Singha a ?crit?:
> Milan,
> Ok, Let me take a case of facebook. I used Rfacebook package
> ?to get posts (getPost()) which returns list() of data frames(post,
> comments, Likes)
> 
> let me demonstrate 2 cases of read and write just as you suggested,
> Case 1:::::::::
> Lets say one of the facebook comment has below string value, in
> Japanese language-->
> "?????? - ???????? ?????"
> 
> On R console I now assign above string to variableas: x <- "?????? -
> ???????? ?????"
> and write it as below:
> write.csv(x, file='x.csv', row.names=F, fileEncoding='UTF-8')
> I get this string in the file
> "" -
>  "
But how do you read back the contents of the file? You need to specify
the encoding when reading it too.

> Case 2::::::::::::::
> I create a notepad 'x.txt' and save Japanese string "?????? - ???????? ?????"
> and read it as below:
> read.table('x.txt', fileEncoding='UTF-8'), I get below output:
> 
> ? V1
> 1???
> Warning messages:
> 1: In read.table("x.txt", fileEncoding = "UTF-8") :
> ? invalid input found on input connection 'x.txt'
> 2: In read.table("x.txt", fileEncoding = "UTF-8") :
> ? incomplete final line found by readTableHeader on 'x.txt'
Are you sure the notepad saved the text as UTF-8?

> Above was for demonstration, I'm infact reading social media data
> extracted, which ultimately is somewhere using httr package and
> returning data frames.
> I'm not sure how should I get it handled in Windows as I don't observe
> this behavior in Mac where system locase is set to 'en_US.UTF-8'
> 
> Regards,
> Sunny
> 
> 
> 
> 
> On Mon, Mar 28, 2016 at 7:39 PM, Milan Bouchet-Valat  wrote:
> > 
> > Le lundi 28 mars 2016 ? 19:16 +0530, Sunny Singha a ?crit :
> > > 
> > > Hi,
> > > I think I'm experiencing an issue regarding system Locale. I have
> > > exported '.csv' formatted data frames gathered from various social
> > > media platforms like facebook/twitter/G+, etc.
> > > 
> > > I observe many variable/columns consists of strings formatted similar to below:
> > > "
> > > "
> > > 
> > > As expected and I confirmed, in social media data, they are strings in
> > > different languages.
> > > Platform details are provide in the end of this mail. OS locale is set
> > > to English (United States) hence 'R' locale is 'English_United
> > > States.1252'
> > > 
> > > I have attempted to change it to UTF-8 but receives below warning message:
> > > 
> > > Warning message:
> > > In Sys.setlocale("LC_ALL", "UTF-8") :
> > > ? OS reports request to set locale to "UTF-8" cannot be honored
> > You don't need to set the locale. Just pass an appropriate value (e.g.
> > "UTF-8") to read.csv() or write.csv()'s fileEncoding argument.
> > 
> > You also didn't tell us what program you used to read these files. Some
> > might guess the encoding incorrectly, or require you to choose it
> > manually.
> > 
> > 
> > Regards
> > 
> > > 
> > > I have gone through below forums but no resolution so far:
> > > --- http://stackoverflow.com/questions/20571147/how-to-set-unicode-locale-in-r
> > > --- https://stat.ethz.ch/pipermail/r-devel/2013-November/067940.html
> > > --- http://stackoverflow.com/questions/19877676/write-utf-8-files-from-r
> > > --- https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
> > > --- http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/
> > > 
> > > I'm not sure whether the issue is while reading/extracting the data
> > > from media or while writing/exporting in Windows directory, but I
> > > don't experience similar issue in my personal Mac machine. I need some
> > > clarification here.
> > > 
> > > How could I export the data just as I see on web ???Please guide.
> > > 
> > > Regards,
> > > Sunny
> > > 
> > > Platform I'm using::::::::::::::::::::::::::::
> > > Operating System : Windows 7 Professional SP1
> > > R version details:
> > > platform???????x86_64-w64-mingw32
> > > arch???????????x86_64
> > > os?????????????mingw32
> > > system?????????x86_64, mingw32
> > > status
> > > major??????????3
> > > minor??????????2.3
> > > year???????????2015
> > > month??????????12
> > > day????????????10
> > > svn rev????????69752
> > > language???????R
> > > version.string R version 3.2.3 (2015-12-10)
> > > nickname???????Wooden Christmas-Tree
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Mon Mar 28 18:55:53 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 28 Mar 2016 16:55:53 +0000
Subject: [R] Open source project that needs performance optimizations
Message-ID: <248E6FA047A8C746BA491485764190F53D395C91@ESESSMB207.ericsson.se>

Yes, I think it is worth evaluating what available at:

https://cran.r-project.org/web/views/HighPerformanceComputing.html

and as a thesis to tackle a "real-life" use case where R language and some of those High Performance Computing packages
are used to solve problems about.
Or you may implement a new R package to provide solution to a performance optimization scenario of your interest.

Also consider what available at:

http://www.teraproc.com/front-page-posts/r-on-demand/


Best,

--
GG



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Mar 28 18:57:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 28 Mar 2016 09:57:19 -0700
Subject: [R] Could not find function even though I have all
	necessary	packages
In-Reply-To: <CA+pG8eOL--WFdr8Hay1eC7UFEk6yfif=PXWxj1R0oZ1Mabqeww@mail.gmail.com>
References: <CA+pG8eOL--WFdr8Hay1eC7UFEk6yfif=PXWxj1R0oZ1Mabqeww@mail.gmail.com>
Message-ID: <14BC04FD-7AFA-4E9B-8438-37DA098E159C@dcn.davis.ca.us>

Post plain text only please. 

Are you sure it loaded?  Verify with sessionInfo()...
-- 
Sent from my phone. Please excuse my brevity.

On March 28, 2016 9:21:56 AM PDT, Michael Artz <michaeleartz at gmail.com> wrote:
>Hi,
>  I am getting the error,
>
>Error: could not find function "createDataPartition"
>
>when I do the code
>dataFrame_data <- createDataPartition(data$colA, p=.7, list=FALSE)
>
>even though I have run already
>
>install.packages("caret", dependencies = c("Depends", "Imports",
>"Suggests"))
>and
>install.packages("caret")
>
>those worked and I then ran
>library(caret)
>
>does anyone know why I'm unable to use this function?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Mon Mar 28 19:01:44 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Mon, 28 Mar 2016 12:01:44 -0500
Subject: [R] Could not find function even though I have all necessary
	packages
In-Reply-To: <14BC04FD-7AFA-4E9B-8438-37DA098E159C@dcn.davis.ca.us>
References: <CA+pG8eOL--WFdr8Hay1eC7UFEk6yfif=PXWxj1R0oZ1Mabqeww@mail.gmail.com>
	<14BC04FD-7AFA-4E9B-8438-37DA098E159C@dcn.davis.ca.us>
Message-ID: <CA+pG8eP9fmF-ywm-or7vxTGMaW7wmpyvN1PGCjoduDNZ_vid2w@mail.gmail.com>

Thanks.  SessionInfo() did not show it.

This is the error when I try library(caret)


> library(caret)
Loading required package: ggplot2
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?munsell?
Error: package ?ggplot2? could not be loaded

I tried installing.packages("ggplot2") and then I ran
library(ggplot2) and it gave me error

Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?munsell?
Error: package or namespace load failed for ?ggplot2?



On Mon, Mar 28, 2016 at 11:57 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Post plain text only please.
>
> Are you sure it loaded? Verify with sessionInfo()...
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 28, 2016 9:21:56 AM PDT, Michael Artz <michaeleartz at gmail.com>
> wrote:
>
>> Hi,
>>   I am getting the error,
>>
>> Error: could not find function "createDataPartition"
>>
>> when I do the code
>> dataFrame_data <- createDataPartition(data$colA, p=.7, list=FALSE)
>>
>> even though I have run already
>>
>> install.packages("caret", dependencies = c("Depends", "Imports",
>> "Suggests"))
>> and
>> install.packages("caret")
>>
>> those worked and I then ran
>> library(caret)
>>
>> does anyone know why I'm unable to use this function?
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Mon Mar 28 19:13:01 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Mon, 28 Mar 2016 12:13:01 -0500
Subject: [R] Could not find function even though I have all necessary
	packages
In-Reply-To: <CA+pG8eP9fmF-ywm-or7vxTGMaW7wmpyvN1PGCjoduDNZ_vid2w@mail.gmail.com>
References: <CA+pG8eOL--WFdr8Hay1eC7UFEk6yfif=PXWxj1R0oZ1Mabqeww@mail.gmail.com>
	<14BC04FD-7AFA-4E9B-8438-37DA098E159C@dcn.davis.ca.us>
	<CA+pG8eP9fmF-ywm-or7vxTGMaW7wmpyvN1PGCjoduDNZ_vid2w@mail.gmail.com>
Message-ID: <CA+pG8eNya_7FANiTLpUAg=8Nn=LFs696Gz=F_RbX=+1nY9_REw@mail.gmail.com>

Thank you everyone I got it!

I needed to install munsell was all.  I was giving a typo when I tried to
install munsell

On Mon, Mar 28, 2016 at 12:01 PM, Michael Artz <michaeleartz at gmail.com>
wrote:

> Thanks.  SessionInfo() did not show it.
>
> This is the error when I try library(caret)
>
>
> > library(caret)
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?munsell?
> Error: package ?ggplot2? could not be loaded
>
> I tried installing.packages("ggplot2") and then I ran
> library(ggplot2) and it gave me error
>
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?munsell?
> Error: package or namespace load failed for ?ggplot2?
>
>
>
> On Mon, Mar 28, 2016 at 11:57 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
> > wrote:
>
>> Post plain text only please.
>>
>> Are you sure it loaded? Verify with sessionInfo()...
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 28, 2016 9:21:56 AM PDT, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>
>>> Hi,
>>>   I am getting the error,
>>>
>>> Error: could not find function "createDataPartition"
>>>
>>> when I do the code
>>> dataFrame_data <- createDataPartition(data$colA, p=.7, list=FALSE)
>>>
>>> even though I have run already
>>>
>>> install.packages("caret", dependencies = c("Depends", "Imports",
>>> "Suggests"))
>>> and
>>> install.packages("caret")
>>>
>>> those worked and I then ran
>>> library(caret)
>>>
>>> does anyone know why I'm unable to use this function?
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Mar 28 20:32:13 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Mar 2016 11:32:13 -0700
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <22259.54630.533896.719922@stat.math.ethz.ch>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
	<CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
	<CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>
	<CAF8bMcaeRraaaYb4Eb6vVZcTR1y77w=NhP2w3xT1-YTweKpADA@mail.gmail.com>
	<22259.54630.533896.719922@stat.math.ethz.ch>
Message-ID: <CAF8bMcbiD4oQ==ACeH5rd3Hbxn89YEZNus28G85+H8c=BMPYig@mail.gmail.com>

If poly were to be changed to allow NA's, how should it act in the
multivariate case when raw=FALSE?

Suppose x1 had an NA in position 1 only and x2 had NA in position 2 only.
Should the output matrix have NAs in all columns of rows 1 and 2 with its
coefs attribute reflectiing only the data in na.omit(cbind(x1,x2))?  This
would make the output matrix orthonormal after NA removal.

Or should it remove NAs from the input vectors independently?  This is
analogous to what predict.poly() currently does - different columns of the
output will have different patterns of NAs.

An example of the first method would be:
> poly(c(NA,2,5,7,8), c(1,NA,3,4,9), degree=2)
            1.0        2.0        0.1         1.1        0.2
[1,]         NA         NA         NA          NA         NA
[2,]         NA         NA         NA          NA         NA
[3,] -0.7715167  0.2672612 -0.5132649  0.39599247  0.6350006
[4,]  0.1543033 -0.8017837 -0.2932942 -0.04525628 -0.7620008
[5,]  0.6172134  0.5345225  0.8065591  0.49781910  0.1270001
attr(,"degree")
[1] 1 2 1 2 2
attr(,"coefs")
[[1]]
[[1]]$alpha
[1] 6.666667 6.190476

[[1]]$norm2
[1] 1.000000 3.000000 4.666667 2.571429

[[2]]
[[2]]$alpha
[1] 5.333333 6.989247

[[2]]$norm2
[1]  1.00000  3.00000 20.66667 14.51613
attr(,"class")
[1] "poly"   "matrix"

and the second
>  poly(c(NA,2,5,7,8), c(1,NA,3,4,9), degree=2)
            1.0        2.0         0.1         1.1        0.2
[1,]         NA         NA -0.55132280          NA  0.6398330
[2,] -0.7637626  0.3988620          NA          NA         NA
[3,] -0.1091089 -0.7407437 -0.21204723  0.02313625 -0.3442756
[4,]  0.3273268 -0.1709409 -0.04240945 -0.01388175 -0.6106021
[5,]  0.5455447  0.5128226  0.80577948  0.43958875  0.3150447
attr(,"degree")
[1] 1 2 1 2 2
attr(,"coefs")
[[1]]
[[1]]$alpha
[1] 5.500000 4.357143

[[1]]$norm2
[1]  1.00000  4.00000 21.00000 56.57143

[[2]]
[[2]]$alpha
[1] 4.250000 6.289568

[[2]]$norm2
[1]   1.0000   4.0000  34.7500 176.6331
attr(,"class")
[1] "poly"   "matrix"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 24, 2016 at 4:54 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> William Dunlap via R-help <r-help at r-project.org>
> >>>>>     on Wed, 23 Mar 2016 13:56:35 -0700 writes:
>
>     > I don't know what is in R's poly(), but if it is like S+'s or TERR's
> then
>     > one could do
>
>     > if (anyNA(x))  {
>     > nax <- na.exclude(x)
>     > px <- poly(x = nax, degree = degree, coefs = coefs, raw =
>     > raw, simple = simple)
>     > px <- structure(naresid(attr(nax, "na.action"), px), coefs
>     > = attr(px, "coefs"), degree = attr(px, "degree"), class = attr(px,
> "class"))
>     > return(px)
>     > }
>
>     > and get nice results in the usual raw=FALSE case as well.  Similar
> stuff
>     > could be done in the multivariate cases.
>
> I don't have too much time for that now,
> and I know that Bill Dunlap cannot provide patches for R --- for
> good reasons, though it's a pity for us! ---
> but you can, Liviu!
> So, and  as you see at every startup of R :
>
>    "R is a collaborative project with many contributors."
>
> I'm willing to try "good-looking" patches.
> (to the *sources*, *NOT* to a printout of the function in your R console!)
>
> Martin Maechler
> ETH Zurich and R Core Team.
>
>     > Bill Dunlap
>     > TIBCO Software
>     > wdunlap tibco.com
>
>     > On Wed, Mar 23, 2016 at 1:41 PM, Liviu Andronic <
> landronimirc at gmail.com>
>     > wrote:
>
>     >> On Wed, Mar 23, 2016 at 9:29 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>     >> > I think the worst aspect of this restriction in poly() is that
> when
>     >> > you use poly in the formula of a model-fitting function you cannot
>     >> > have any missing values in the data, even if you supply
>     >> > na.action=na.exclude.
>     >> >
>     >> >   > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
>     >> >   Warning message:
>     >> >   In log(y) : NaNs produced
>     >> >   > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
>     >> >   Error in poly(x, 3) : missing values are not allowed in 'poly'
>     >> >
>     >> > Thus people are pushed to using a less stable formulation like
>     >> >   > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d,
> na.action=na.exclude)
>     >> >
>     >> My difficulty precisely. What's more, I inspected the code for
> `poly`
>     >> and at least for the simple case of raw=TRUE it seems trivial to
>     >> support NAs. It suffices to change line 15 of the function:
>     >> if (anyNA(x)) stop("missing values are not allowed in 'poly'")
>     >>
>     >> to:
>     >> if (!raw && anyNA(x)) stop("missing values are not allowed in
> 'poly'")
>     >>
>     >> This way for raw polynomials estimation continues unimpeded. With
> the
>     >> change above, I get this:
>     >> > poly(x, degree = 2, raw=TRUE)
>     >> 1 2
>     >> [1,] NA NA
>     >> [2,] 1 1
>     >> [3,] 2 4
>     >> [4,] 3 9
>     >> [5,] 4 16
>     >> [6,] 5 25
>     >> [7,] 6 36
>     >> [8,] 7 49
>     >> [9,] 8 64
>     >> [10,] 9 81
>     >> [11,] 10 100
>     >> attr(,"degree")
>     >> [1] 1 2
>     >> attr(,"class")
>     >> [1] "poly" "matrix"
>     >>
>     >>
>     >> Regards,
>     >> Liviu
>     >>
>     >>
>     >> >
>     >> > Bill Dunlap
>     >> > TIBCO Software
>     >> > wdunlap tibco.com
>     >> >
>     >> > On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic <
> landronimirc at gmail.com
>     >> >
>     >> > wrote:
>     >> >>
>     >> >> Dear all,
>     >> >> I'm a bit surprised by this behavior in poly:
>     >> >>
>     >> >> x <- c(NA, 1:10)
>     >> >> poly(x, degree = 2, raw=TRUE)
>     >> >> ## Error in poly(x, degree = 2, raw = TRUE) :
>     >> >> ##   missing values are not allowed in 'poly'
>     >> >> x^2
>     >> >> ## [1] NA 1 4 9 16 25 36 49 64 81 100
>     >> >>
>     >> >> As you can see, poly() will fail if the vector contains NAs,
> whereas
>     >> >> it is perfectly possible to obtain the square of the vector
> manually.
>     >> >>
>     >> >> Is there a reason for this limitation in poly?
>     >> >>
>     >> >> Regards,
>     >> >> Liviu
>     >> >>
>     >> >>
>     >> >> --
>     >> >> Do you think you know what math is?
>     >> >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
>     >> >> Or what it means to be intelligent?
>     >> >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
>     >> >> Think again:
>     >> >> http://www.ideasroadshow.com/library
>     >> >>
>     >> >> ______________________________________________
>     >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
>     >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> >> PLEASE do read the posting guide
>     >> >> http://www.R-project.org/posting-guide.html
>     >> >> and provide commented, minimal, self-contained, reproducible
> code.
>     >> >
>     >> >
>     >>
>     >>
>     >>
>     >> --
>     >> Do you think you know what math is?
>     >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
>     >> Or what it means to be intelligent?
>     >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
>     >> Think again:
>     >> http://www.ideasroadshow.com/library
>     >>
>
>     > [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From landronimirc at gmail.com  Mon Mar 28 21:04:33 2016
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 28 Mar 2016 21:04:33 +0200
Subject: [R] Why missing values are not allowed in 'poly'?
In-Reply-To: <CAF8bMcbiD4oQ==ACeH5rd3Hbxn89YEZNus28G85+H8c=BMPYig@mail.gmail.com>
References: <CABxs9Vm+TOQyLW8NrGpno=5zHsHh6F2d59VdS72mxBGf2piuYg@mail.gmail.com>
	<CAF8bMcaSDp8L0L9Qd2UJQOdPR-kCew3C11o6Bk2ZwxQBr=L2Pw@mail.gmail.com>
	<CABxs9Vn8WUakb0i840Jv6ictpPnrgmVF6iWkh5RXMzSXOVHiWg@mail.gmail.com>
	<CAF8bMcaeRraaaYb4Eb6vVZcTR1y77w=NhP2w3xT1-YTweKpADA@mail.gmail.com>
	<22259.54630.533896.719922@stat.math.ethz.ch>
	<CAF8bMcbiD4oQ==ACeH5rd3Hbxn89YEZNus28G85+H8c=BMPYig@mail.gmail.com>
Message-ID: <CABxs9V=3QT6xDJYvD4mqcSraWcA_OhEy4QcHaO=M1CRpKrgv4w@mail.gmail.com>

On Mon, Mar 28, 2016 at 8:32 PM, William Dunlap <wdunlap at tibco.com> wrote:
> If poly were to be changed to allow NA's, how should it act in the
> multivariate case when raw=FALSE?
>
Thank you Bill for looking into this. I was playing myself with your
proposed code to come up with a clean patch, and ran into the same
queries as you did, i.e. what to do when the NA structure is different
in the multivariate case? In the univariate case or in the
multivariate case when the NA structure is identical things are
straightforward. But in the multivariate case with differing NA
structure I'm not sure what is the expected output.

Regards,
Liviu


> Suppose x1 had an NA in position 1 only and x2 had NA in position 2 only.
> Should the output matrix have NAs in all columns of rows 1 and 2 with its
> coefs attribute reflectiing only the data in na.omit(cbind(x1,x2))?  This
> would make the output matrix orthonormal after NA removal.
>
> Or should it remove NAs from the input vectors independently?  This is
> analogous to what predict.poly() currently does - different columns of the
> output will have different patterns of NAs.
>
> An example of the first method would be:
>> poly(c(NA,2,5,7,8), c(1,NA,3,4,9), degree=2)
>             1.0        2.0        0.1         1.1        0.2
> [1,]         NA         NA         NA          NA         NA
> [2,]         NA         NA         NA          NA         NA
> [3,] -0.7715167  0.2672612 -0.5132649  0.39599247  0.6350006
> [4,]  0.1543033 -0.8017837 -0.2932942 -0.04525628 -0.7620008
> [5,]  0.6172134  0.5345225  0.8065591  0.49781910  0.1270001
> attr(,"degree")
> [1] 1 2 1 2 2
> attr(,"coefs")
> [[1]]
> [[1]]$alpha
> [1] 6.666667 6.190476
>
> [[1]]$norm2
> [1] 1.000000 3.000000 4.666667 2.571429
>
> [[2]]
> [[2]]$alpha
> [1] 5.333333 6.989247
>
> [[2]]$norm2
> [1]  1.00000  3.00000 20.66667 14.51613
> attr(,"class")
> [1] "poly"   "matrix"
>
> and the second
>>  poly(c(NA,2,5,7,8), c(1,NA,3,4,9), degree=2)
>             1.0        2.0         0.1         1.1        0.2
> [1,]         NA         NA -0.55132280          NA  0.6398330
> [2,] -0.7637626  0.3988620          NA          NA         NA
> [3,] -0.1091089 -0.7407437 -0.21204723  0.02313625 -0.3442756
> [4,]  0.3273268 -0.1709409 -0.04240945 -0.01388175 -0.6106021
> [5,]  0.5455447  0.5128226  0.80577948  0.43958875  0.3150447
> attr(,"degree")
> [1] 1 2 1 2 2
> attr(,"coefs")
> [[1]]
> [[1]]$alpha
> [1] 5.500000 4.357143
>
> [[1]]$norm2
> [1]  1.00000  4.00000 21.00000 56.57143
>
> [[2]]
> [[2]]$alpha
> [1] 4.250000 6.289568
>
> [[2]]$norm2
> [1]   1.0000   4.0000  34.7500 176.6331
> attr(,"class")
> [1] "poly"   "matrix"
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Mar 24, 2016 at 4:54 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>> >>>>> William Dunlap via R-help <r-help at r-project.org>
>> >>>>>     on Wed, 23 Mar 2016 13:56:35 -0700 writes:
>>
>>     > I don't know what is in R's poly(), but if it is like S+'s or TERR's
>> then
>>     > one could do
>>
>>     > if (anyNA(x))  {
>>     > nax <- na.exclude(x)
>>     > px <- poly(x = nax, degree = degree, coefs = coefs, raw =
>>     > raw, simple = simple)
>>     > px <- structure(naresid(attr(nax, "na.action"), px), coefs
>>     > = attr(px, "coefs"), degree = attr(px, "degree"), class = attr(px,
>> "class"))
>>     > return(px)
>>     > }
>>
>>     > and get nice results in the usual raw=FALSE case as well.  Similar
>> stuff
>>     > could be done in the multivariate cases.
>>
>> I don't have too much time for that now,
>> and I know that Bill Dunlap cannot provide patches for R --- for
>> good reasons, though it's a pity for us! ---
>> but you can, Liviu!
>> So, and  as you see at every startup of R :
>>
>>    "R is a collaborative project with many contributors."
>>
>> I'm willing to try "good-looking" patches.
>> (to the *sources*, *NOT* to a printout of the function in your R console!)
>>
>> Martin Maechler
>> ETH Zurich and R Core Team.
>>
>>     > Bill Dunlap
>>     > TIBCO Software
>>     > wdunlap tibco.com
>>
>>     > On Wed, Mar 23, 2016 at 1:41 PM, Liviu Andronic
>> <landronimirc at gmail.com>
>>     > wrote:
>>
>>     >> On Wed, Mar 23, 2016 at 9:29 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>     >> > I think the worst aspect of this restriction in poly() is that
>> when
>>     >> > you use poly in the formula of a model-fitting function you
>> cannot
>>     >> > have any missing values in the data, even if you supply
>>     >> > na.action=na.exclude.
>>     >> >
>>     >> >   > d <- transform(data.frame(y=c(-1,1:10)), x=log(y))
>>     >> >   Warning message:
>>     >> >   In log(y) : NaNs produced
>>     >> >   > fit <- lm(y ~ poly(x, 3), data=d, na.action=na.exclude)
>>     >> >   Error in poly(x, 3) : missing values are not allowed in 'poly'
>>     >> >
>>     >> > Thus people are pushed to using a less stable formulation like
>>     >> >   > fit <- lm(y ~ x + I(x^2) + I(x^3), data=d,
>> na.action=na.exclude)
>>     >> >
>>     >> My difficulty precisely. What's more, I inspected the code for
>> `poly`
>>     >> and at least for the simple case of raw=TRUE it seems trivial to
>>     >> support NAs. It suffices to change line 15 of the function:
>>     >> if (anyNA(x)) stop("missing values are not allowed in 'poly'")
>>     >>
>>     >> to:
>>     >> if (!raw && anyNA(x)) stop("missing values are not allowed in
>> 'poly'")
>>     >>
>>     >> This way for raw polynomials estimation continues unimpeded. With
>> the
>>     >> change above, I get this:
>>     >> > poly(x, degree = 2, raw=TRUE)
>>     >> 1 2
>>     >> [1,] NA NA
>>     >> [2,] 1 1
>>     >> [3,] 2 4
>>     >> [4,] 3 9
>>     >> [5,] 4 16
>>     >> [6,] 5 25
>>     >> [7,] 6 36
>>     >> [8,] 7 49
>>     >> [9,] 8 64
>>     >> [10,] 9 81
>>     >> [11,] 10 100
>>     >> attr(,"degree")
>>     >> [1] 1 2
>>     >> attr(,"class")
>>     >> [1] "poly" "matrix"
>>     >>
>>     >>
>>     >> Regards,
>>     >> Liviu
>>     >>
>>     >>
>>     >> >
>>     >> > Bill Dunlap
>>     >> > TIBCO Software
>>     >> > wdunlap tibco.com
>>     >> >
>>     >> > On Wed, Mar 23, 2016 at 12:59 PM, Liviu Andronic
>> <landronimirc at gmail.com
>>     >> >
>>     >> > wrote:
>>     >> >>
>>     >> >> Dear all,
>>     >> >> I'm a bit surprised by this behavior in poly:
>>     >> >>
>>     >> >> x <- c(NA, 1:10)
>>     >> >> poly(x, degree = 2, raw=TRUE)
>>     >> >> ## Error in poly(x, degree = 2, raw = TRUE) :
>>     >> >> ##   missing values are not allowed in 'poly'
>>     >> >> x^2
>>     >> >> ## [1] NA 1 4 9 16 25 36 49 64 81 100
>>     >> >>
>>     >> >> As you can see, poly() will fail if the vector contains NAs,
>> whereas
>>     >> >> it is perfectly possible to obtain the square of the vector
>> manually.
>>     >> >>
>>     >> >> Is there a reason for this limitation in poly?
>>     >> >>
>>     >> >> Regards,
>>     >> >> Liviu
>>     >> >>
>>     >> >>
>>     >> >> --
>>     >> >> Do you think you know what math is?
>>     >> >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
>>     >> >> Or what it means to be intelligent?
>>     >> >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
>>     >> >> Think again:
>>     >> >> http://www.ideasroadshow.com/library
>>     >> >>
>>     >> >> ______________________________________________
>>     >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>>     >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> >> PLEASE do read the posting guide
>>     >> >> http://www.R-project.org/posting-guide.html
>>     >> >> and provide commented, minimal, self-contained, reproducible
>> code.
>>     >> >
>>     >> >
>>     >>
>>     >>
>>     >>
>>     >> --
>>     >> Do you think you know what math is?
>>     >> http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
>>     >> Or what it means to be intelligent?
>>     >> http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
>>     >> Think again:
>>     >> http://www.ideasroadshow.com/library
>>     >>
>>
>>     > [[alternative HTML version deleted]]
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Do you think you know what math is?
http://www.ideasroadshow.com/issues/ian-stewart-2013-08-02
Or what it means to be intelligent?
http://www.ideasroadshow.com/issues/john-duncan-2013-08-30
Think again:
http://www.ideasroadshow.com/library


From heba_eldeeb2000 at yahoo.com  Mon Mar 28 22:19:47 2016
From: heba_eldeeb2000 at yahoo.com (heba eldeeb)
Date: Mon, 28 Mar 2016 20:19:47 +0000 (UTC)
Subject: [R] help in maximum likelihood estimation
References: <626469436.1258328.1459196387595.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>

 Dear AllI'm trying to find the maximum likelihood estimator ?of a certain distribution using nlm command but I receive an error as:
?non-finite value supplied by 'nlm'
can't figure?out what is wrong in my function
Any help? 
Thank you in advance



	[[alternative HTML version deleted]]


From satish.vadlamani at gmail.com  Mon Mar 28 20:15:54 2016
From: satish.vadlamani at gmail.com (Satish Vadlamani)
Date: Mon, 28 Mar 2016 11:15:54 -0700
Subject: [R] How to form groups for this specific problem?
In-Reply-To: <CAN5YmCGDLwb32Zy+cdQ4YgsEAGRGaXccGxdCLQfQjKLvKtKvcQ@mail.gmail.com>
References: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
	<CAN5YmCGDLwb32Zy+cdQ4YgsEAGRGaXccGxdCLQfQjKLvKtKvcQ@mail.gmail.com>
Message-ID: <CAK3+11Rb=1NN6J0HktFaZWFC82H2658Rh1=PsT+=GdTtZ1dg_w@mail.gmail.com>

Jean:
Wow. Thank you so much for this. I will read up igraph and then see if this
is going to work for me for the larger dataset.

Thanks for the wonderful snippet code you wrote. Basically, the requirement
is this:
TLA1 (Top Level Assembly) and its components should belong to the same
group. If a component belongs to a different TLA (say TLA2), then that TLA1
and all of its components should belong to the same as that of TLA1.

Are these types of questions appropriate for this group?

Thanks,
Satish


On Mar 28, 2016 9:10 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:

> Satish,
>
> If you rearrange your data into a network of nodes and edges, you can use
> the igraph package to identify disconnected (mutually exclusive) groups.
>
> # example data
> df <- data.frame(
>   Component = c("C1", "C2", "C1", "C3", "C4", "C5"),
>   TLA = c("TLA1", "TLA1", "TLA2", "TLA2", "TLA3", "TLA3")
> )
>
> # characterize data as a network of nodes and edges
> nodes <- levels(unlist(df))
> edges <- apply(df, 2, match, nodes)
>
> # use the igraph package to identify disconnected groups
> library(igraph)
> g <- graph(edges)
> ngroup <- clusters(g)$membership
> df$Group <- ngroup[match(df$Component, nodes)]
> df
>
>   Component  TLA Group
> 1        C1 TLA1     1
> 2        C2 TLA1     1
> 3        C1 TLA2     1
> 4        C3 TLA2     1
> 5        C4 TLA3     2
> 6        C5 TLA3     2
>
> Jean
>
> On Sun, Mar 27, 2016 at 7:56 PM, Satish Vadlamani <
> satish.vadlamani at gmail.com> wrote:
>
>> Hello All:
>> I would like to get some help with the following problem and understand
>> how
>> this can be done in R efficiently. The header is given in the data frame.
>>
>> *Component, TLA*
>> C1, TLA1
>> C2, TLA1
>> C1, TLA2
>> C3, TLA2
>> C4, TLA3
>> C5, TLA3
>>
>> Notice that C1 is a component of TLA1 and TLA2.
>>
>> I would like to form groups of mutually exclusive subsets and create a new
>> column called group for this subset. For the above data, the subsets and
>> the new group column value will be like so:
>>
>> *Component, TLA, Group*
>> C1, TLA1, 1
>> C2, TLA1, 1
>> C1, TLA2, 1
>> C3, TLA2, 1
>> C4, TLA3, 2
>> C5, TLA3, 2
>>
>> Appreciate any help on this. I could have looped through the observations
>> and tried some logic but I did not try that yet.
>>
>> --
>>
>> Satish Vadlamani
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Mar 29 00:32:10 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 29 Mar 2016 11:32:10 +1300
Subject: [R] [FORGED]  help in maximum likelihood estimation
In-Reply-To: <626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>
References: <626469436.1258328.1459196387595.JavaMail.yahoo.ref@mail.yahoo.com>
	<626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56F9B0EA.6060609@auckland.ac.nz>

On 29/03/16 09:19, heba eldeeb via R-help wrote:
>   Dear All
> I'm trying to find the maximum likelihood estimator of a certain
> distribution using nlm command but I receive an error as:
> non-finite value supplied by 'nlm' can't figure out what is wrong in
> my function Any help? Thank you in advance.

Sorry, the mind_read() function in R has not yet been written.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wdunlap at tibco.com  Tue Mar 29 01:44:41 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Mar 2016 16:44:41 -0700
Subject: [R] [FORGED] help in maximum likelihood estimation
In-Reply-To: <56F9B0EA.6060609@auckland.ac.nz>
References: <626469436.1258328.1459196387595.JavaMail.yahoo.ref@mail.yahoo.com>
	<626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>
	<56F9B0EA.6060609@auckland.ac.nz>
Message-ID: <CAF8bMcb8ROJ+wvJC+pY088d9vCQsttt=eH3qmvwbNkYJQO8j-Q@mail.gmail.com>

Using the print.level=2 argument to nlm can help track this down.
Also, set options(warn=1) before calling nlm so warnings get printed
as soon as they are generated.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 28, 2016 at 3:32 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 29/03/16 09:19, heba eldeeb via R-help wrote:
>
>>   Dear All
>> I'm trying to find the maximum likelihood estimator of a certain
>> distribution using nlm command but I receive an error as:
>> non-finite value supplied by 'nlm' can't figure out what is wrong in
>> my function Any help? Thank you in advance.
>>
>
> Sorry, the mind_read() function in R has not yet been written.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Tue Mar 29 08:46:04 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Tue, 29 Mar 2016 12:16:04 +0530
Subject: [R] Please guide -- UTF-8 locale setting fails on Windows on
	writing
In-Reply-To: <1459182518.645.33.camel@club.fr>
References: <CANOG_FU6qXkMdYBvYQ2gZL4r9vxEETvFBu9D6fSg+eJAvFgUgQ@mail.gmail.com>
	<1459174193.645.27.camel@club.fr>
	<CANOG_FW5f+PpsybYoiAikYAt=Ew-njdx75wAgDjrLiPuMv+dcg@mail.gmail.com>
	<1459182518.645.33.camel@club.fr>
Message-ID: <CANOG_FU_=mqAQu3oKYpBfbTA42p6eQu9UGd5TzyaYNrM06Bk-g@mail.gmail.com>

Milan,
Anwer to your queries:
-- But how do you read back the contents of the file? You need to specify
the encoding when reading it too.
Answer: I read back as stated in 'Case 2'

-- Are you sure the notepad saved the text as UTF-8?
Answer: Yes.

Regards,
Sunny

On Mon, Mar 28, 2016 at 9:58 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le lundi 28 mars 2016 ? 20:12 +0530, Sunny Singha a ?crit :
>> Milan,
>> Ok, Let me take a case of facebook. I used Rfacebook package
>>  to get posts (getPost()) which returns list() of data frames(post,
>> comments, Likes)
>>
>> let me demonstrate 2 cases of read and write just as you suggested,
>> Case 1:::::::::
>> Lets say one of the facebook comment has below string value, in
>> Japanese language-->
>> "?????? - ???????? ?????"
>>
>> On R console I now assign above string to variableas: x <- "?????? -
>> ???????? ?????"
>> and write it as below:
>> write.csv(x, file='x.csv', row.names=F, fileEncoding='UTF-8')
>> I get this string in the file
>> "" -
>>  "
> But how do you read back the contents of the file? You need to specify
> the encoding when reading it too.
>
>> Case 2::::::::::::::
>> I create a notepad 'x.txt' and save Japanese string "?????? - ???????? ?????"
>> and read it as below:
>> read.table('x.txt', fileEncoding='UTF-8'), I get below output:
>>
>>   V1
>> 1  ?
>> Warning messages:
>> 1: In read.table("x.txt", fileEncoding = "UTF-8") :
>>   invalid input found on input connection 'x.txt'
>> 2: In read.table("x.txt", fileEncoding = "UTF-8") :
>>   incomplete final line found by readTableHeader on 'x.txt'
> Are you sure the notepad saved the text as UTF-8?
>
>> Above was for demonstration, I'm infact reading social media data
>> extracted, which ultimately is somewhere using httr package and
>> returning data frames.
>> I'm not sure how should I get it handled in Windows as I don't observe
>> this behavior in Mac where system locase is set to 'en_US.UTF-8'
>>
>> Regards,
>> Sunny
>>
>>
>>
>>
>> On Mon, Mar 28, 2016 at 7:39 PM, Milan Bouchet-Valat  wrote:
>> >
>> > Le lundi 28 mars 2016 ? 19:16 +0530, Sunny Singha a ?crit :
>> > >
>> > > Hi,
>> > > I think I'm experiencing an issue regarding system Locale. I have
>> > > exported '.csv' formatted data frames gathered from various social
>> > > media platforms like facebook/twitter/G+, etc.
>> > >
>> > > I observe many variable/columns consists of strings formatted similar to below:
>> > > "
>> > > "
>> > >
>> > > As expected and I confirmed, in social media data, they are strings in
>> > > different languages.
>> > > Platform details are provide in the end of this mail. OS locale is set
>> > > to English (United States) hence 'R' locale is 'English_United
>> > > States.1252'
>> > >
>> > > I have attempted to change it to UTF-8 but receives below warning message:
>> > >
>> > > Warning message:
>> > > In Sys.setlocale("LC_ALL", "UTF-8") :
>> > >   OS reports request to set locale to "UTF-8" cannot be honored
>> > You don't need to set the locale. Just pass an appropriate value (e.g.
>> > "UTF-8") to read.csv() or write.csv()'s fileEncoding argument.
>> >
>> > You also didn't tell us what program you used to read these files. Some
>> > might guess the encoding incorrectly, or require you to choose it
>> > manually.
>> >
>> >
>> > Regards
>> >
>> > >
>> > > I have gone through below forums but no resolution so far:
>> > > --- http://stackoverflow.com/questions/20571147/how-to-set-unicode-locale-in-r
>> > > --- https://stat.ethz.ch/pipermail/r-devel/2013-November/067940.html
>> > > --- http://stackoverflow.com/questions/19877676/write-utf-8-files-from-r
>> > > --- https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
>> > > --- http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/
>> > >
>> > > I'm not sure whether the issue is while reading/extracting the data
>> > > from media or while writing/exporting in Windows directory, but I
>> > > don't experience similar issue in my personal Mac machine. I need some
>> > > clarification here.
>> > >
>> > > How could I export the data just as I see on web ?  Please guide.
>> > >
>> > > Regards,
>> > > Sunny
>> > >
>> > > Platform I'm using::::::::::::::::::::::::::::
>> > > Operating System : Windows 7 Professional SP1
>> > > R version details:
>> > > platform       x86_64-w64-mingw32
>> > > arch           x86_64
>> > > os             mingw32
>> > > system         x86_64, mingw32
>> > > status
>> > > major          3
>> > > minor          2.3
>> > > year           2015
>> > > month          12
>> > > day            10
>> > > svn rev        69752
>> > > language       R
>> > > version.string R version 3.2.3 (2015-12-10)
>> > > nickname       Wooden Christmas-Tree
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.


From barvazduck at gmail.com  Tue Mar 29 10:50:56 2016
From: barvazduck at gmail.com (raz)
Date: Tue, 29 Mar 2016 11:50:56 +0300
Subject: [R] how can I count data points outside the main plot line?
Message-ID: <CAGHW+oKsTjNiPD=kFAxZU5PubuM=26BZW-pW92PDtkHjN_Tngw@mail.gmail.com>

How can I count data points that lay outside of the main plot line?
I have a plot in which most data points create a sigmoid line, but some are
spread throughout the plot area, these points dont fit the curve. I would
like to count them to know the ratio between the main curve and the data
points that dont fit, any ideas?

Thanks,

Raz

-- 
\m/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Mar 29 11:14:12 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 29 Mar 2016 09:14:12 +0000
Subject: [R] how can I count data points outside the main plot line?
In-Reply-To: <CAGHW+oKsTjNiPD=kFAxZU5PubuM=26BZW-pW92PDtkHjN_Tngw@mail.gmail.com>
References: <CAGHW+oKsTjNiPD=kFAxZU5PubuM=26BZW-pW92PDtkHjN_Tngw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5017AFE@SRVEXCHMBX.precheza.cz>

Hi

Did you try residuals and/or influence.measures?

Cheers
Petr


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of raz
Sent: Tuesday, March 29, 2016 10:51 AM
To: r-help at r-project.org
Subject: [R] how can I count data points outside the main plot line?

How can I count data points that lay outside of the main plot line?
I have a plot in which most data points create a sigmoid line, but some are spread throughout the plot area, these points dont fit the curve. I would like to count them to know the ratio between the main curve and the data points that dont fit, any ideas?

Thanks,

Raz

--
\m/

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Tue Mar 29 11:23:38 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 29 Mar 2016 20:23:38 +1100
Subject: [R] Performance Analytics Modigliani Code help
In-Reply-To: <CAL-SLAzGi-uYEUXFk0rBPK8_TvQSb-dS-Jf2AdQOXV=9Xgp4Fg@mail.gmail.com>
References: <CAL-SLAzGi-uYEUXFk0rBPK8_TvQSb-dS-Jf2AdQOXV=9Xgp4Fg@mail.gmail.com>
Message-ID: <CA+8X3fUx_hCMGZEJfe=B5EymQ9S5GgWPBf2qjNjqeJHRPgkiGg@mail.gmail.com>

Hi Jessy,
I had a look at:

http://www.rdocumentation.org/packages/PerformanceAnalytics/functions/Modigliani

and it doesn't include a "Value" section, so I don't know what the
return value should be. Have you tried running the examples to see
what they return?

Jim

On Sat, Mar 26, 2016 at 12:10 AM, Jessy-Esther Missengue
<jessyesther.missengue2 at mail.dcu.ie> wrote:
> Hi all,
>
> I am researching performance of funds in the FTSE100 and am using the
> Modigliani function in the PerformanceAnalytics package.
>
> I have attached my raw data for your reference.
>
> When I try to use the Modigliani code as follows:
>
> Modigliani (a,b,c=0)
> where a is my data set "1000 RANDOM...", b is the data of FTSE "FTSE
> ALLSHARE..." returns, c is the risk free rate "LIBOR".
>
> This code returns the data attached "Modigliani from R" which seems to be a
> calculation for only the first 2 columns of my data set. I would have
> expected to have R return the same amount of rows and columns when using
> the Modigliani function i.e 108 rows and 1001 columns.
>
> Is there something I need to add to the code to have it calculate for each
> row/column?
>
> Thanks,
> Jessy *very confused student*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Tue Mar 29 12:33:14 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 29 Mar 2016 10:33:14 +0000
Subject: [R] how can I count data points outside the main plot line?
Message-ID: <248E6FA047A8C746BA491485764190F53D395FDA@ESESSMB207.ericsson.se>

As a "quick solution", I would explore the use of stat_smooth() and then extract fit data from,
as herein shown:

library(ggplot2)
p <- qplot(hp, wt, data=mtcars) + stat_smooth(method="loess")
p
ggplot_build(p)$data[[2]]

           x        y     ymin     ymax        se PANEL group  colour   fill
1   52.00000 1.993594 1.149150 2.838038 0.4111133     1    -1 #3366FF grey60
2   55.58228 2.039986 1.303264 2.776709 0.3586695     1    -1 #3366FF grey60
3   59.16456 2.087067 1.443076 2.731058 0.3135236     1    -1 #3366FF grey60

Reference:

http://stackoverflow.com/questions/9789871/method-to-extract-stat-smooth-line-fit


In place of mtcars, your dataset.

Then, some more work to compare each (x,y) of your dataset with {(x,ymin), (x.ymax)} of
table above and to determine if (x,y) point stays within the smooth lines band or not.

Anyway, I would be interested in hearing about other approaches.

--

Best,

GG

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Mar 29 14:11:19 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 29 Mar 2016 07:11:19 -0500
Subject: [R] How to form groups for this specific problem?
In-Reply-To: <CAK3+11Rb=1NN6J0HktFaZWFC82H2658Rh1=PsT+=GdTtZ1dg_w@mail.gmail.com>
References: <CAK3+11Svq4VSjsyhX6dNUcaXZrz4HZYyKHRBXwMA9Ty76VrMyQ@mail.gmail.com>
	<CAN5YmCGDLwb32Zy+cdQ4YgsEAGRGaXccGxdCLQfQjKLvKtKvcQ@mail.gmail.com>
	<CAK3+11Rb=1NN6J0HktFaZWFC82H2658Rh1=PsT+=GdTtZ1dg_w@mail.gmail.com>
Message-ID: <CAN5YmCEwVt4tSg7pSv24sGR1QNWfqwV8tRFMW_mhpZ6Uo+4V5Q@mail.gmail.com>

You're welcome, Satish.

Yes, questions that are seeking solutions in R code are appropriate for
this group.  It's helpful if you provide sample data (for example, using
dput()) and sample R code that folks can use.  And it's helpful if you show
the results that you are hoping to achieve (as you did).

Jean

On Mon, Mar 28, 2016 at 1:15 PM, Satish Vadlamani <
satish.vadlamani at gmail.com> wrote:

> Jean:
> Wow. Thank you so much for this. I will read up igraph and then see if
> this is going to work for me for the larger dataset.
>
> Thanks for the wonderful snippet code you wrote. Basically, the
> requirement is this:
> TLA1 (Top Level Assembly) and its components should belong to the same
> group. If a component belongs to a different TLA (say TLA2), then that TLA1
> and all of its components should belong to the same as that of TLA1.
>
> Are these types of questions appropriate for this group?
>
> Thanks,
> Satish
>
>
> On Mar 28, 2016 9:10 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:
>
>> Satish,
>>
>> If you rearrange your data into a network of nodes and edges, you can use
>> the igraph package to identify disconnected (mutually exclusive) groups.
>>
>> # example data
>> df <- data.frame(
>>   Component = c("C1", "C2", "C1", "C3", "C4", "C5"),
>>   TLA = c("TLA1", "TLA1", "TLA2", "TLA2", "TLA3", "TLA3")
>> )
>>
>> # characterize data as a network of nodes and edges
>> nodes <- levels(unlist(df))
>> edges <- apply(df, 2, match, nodes)
>>
>> # use the igraph package to identify disconnected groups
>> library(igraph)
>> g <- graph(edges)
>> ngroup <- clusters(g)$membership
>> df$Group <- ngroup[match(df$Component, nodes)]
>> df
>>
>>   Component  TLA Group
>> 1        C1 TLA1     1
>> 2        C2 TLA1     1
>> 3        C1 TLA2     1
>> 4        C3 TLA2     1
>> 5        C4 TLA3     2
>> 6        C5 TLA3     2
>>
>> Jean
>>
>> On Sun, Mar 27, 2016 at 7:56 PM, Satish Vadlamani <
>> satish.vadlamani at gmail.com> wrote:
>>
>>> Hello All:
>>> I would like to get some help with the following problem and understand
>>> how
>>> this can be done in R efficiently. The header is given in the data frame.
>>>
>>> *Component, TLA*
>>> C1, TLA1
>>> C2, TLA1
>>> C1, TLA2
>>> C3, TLA2
>>> C4, TLA3
>>> C5, TLA3
>>>
>>> Notice that C1 is a component of TLA1 and TLA2.
>>>
>>> I would like to form groups of mutually exclusive subsets and create a
>>> new
>>> column called group for this subset. For the above data, the subsets and
>>> the new group column value will be like so:
>>>
>>> *Component, TLA, Group*
>>> C1, TLA1, 1
>>> C2, TLA1, 1
>>> C1, TLA2, 1
>>> C3, TLA2, 1
>>> C4, TLA3, 2
>>> C5, TLA3, 2
>>>
>>> Appreciate any help on this. I could have looped through the observations
>>> and tried some logic but I did not try that yet.
>>>
>>> --
>>>
>>> Satish Vadlamani
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Tue Mar 29 15:02:18 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 29 Mar 2016 13:02:18 +0000
Subject: [R] converting a class dataframe (chars) to transaction class
Message-ID: <248E6FA047A8C746BA491485764190F53D3960A4@ESESSMB207.ericsson.se>


mydf <- data.frame(d1 = LETTERS[1:10], d2 = letters[11:20])

> str(mydf)
'data.frame':   10 obs. of  2 variables:
$ d1: Factor w/ 10 levels "A","B","C","D",..: 1 2 3 4 5 6 7 8 9 10
$ d2: Factor w/ 10 levels "k","l","m","n",..: 1 2 3 4 5 6 7 8 9 10
>

library(arules)
trans1 <- as(mydf, "transactions")


> trans1
transactions in sparse format with
10 transactions (rows) and
20 items (columns)

> str(trans1)
Formal class 'transactions' [package "arules"] with 3 slots
  ..@ data       :Formal class 'ngCMatrix' [package "Matrix"] with 5 slots
  .. .. ..@ i       : int [1:20] 0 10 1 11 2 12 3 13 4 14 ...
  .. .. ..@ p       : int [1:11] 0 2 4 6 8 10 12 14 16 18 ...
  .. .. ..@ Dim     : int [1:2] 20 10
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ factors : list()
  ..@ itemInfo   :'data.frame': 20 obs. of  3 variables:
  .. ..$ labels   : chr [1:20] "d1=A" "d1=B" "d1=C" "d1=D" ...
  .. ..$ variables: Factor w/ 2 levels "d1","d2": 1 1 1 1 1 1 1 1 1 1 ...
  .. ..$ levels   : Factor w/ 20 levels "A","B","C","D",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..@ itemsetInfo:'data.frame': 10 obs. of  1 variable:
  .. ..$ transactionID: chr [1:10] "1" "2" "3" "4" ...>


Reference:

http://www.inside-r.org/packages/cran/arules/docs/transactionInfo


--

Best,

GG

	[[alternative HTML version deleted]]


From dblouin at lsu.edu  Tue Mar 29 13:10:01 2016
From: dblouin at lsu.edu (David C Blouin)
Date: Tue, 29 Mar 2016 11:10:01 +0000
Subject: [R] How to solve an NLME problem?
Message-ID: <BN1PR06MB0721A0E3A55BCD52EAFE015BD870@BN1PR06MB072.namprd06.prod.outlook.com>

I have a nonlinear model where I want to include random coefficients for a sample of random SUBJECTS. The fixed effects part of the model is Y ~ B + (T - B) / (1 + 10**(X - C)) and I would like to include random coefficients b for B, t for T, and c for C. The model is a fairly well-known three-parameter log-inhibitor model where Y is a measure of growth at X = log(CONCENTRATION), B is the unknown lower asymptote, T is the unknown upper asymptote, and C is the unknown log(IC50), where IC50 is the half maximal inhibitory concentration. I do not know how to solve this problem in R, where I am assuming NLME contains the appropriate methodology.

	[[alternative HTML version deleted]]


From pnovack-gottshall at ben.edu  Fri Mar 25 19:26:04 2016
From: pnovack-gottshall at ben.edu (Novack-Gottshall, Philip M.)
Date: Fri, 25 Mar 2016 18:26:04 +0000
Subject: [R] [R-pkgs] New R package for K-S goodness-of-fit tests
Message-ID: <8CF6FE2C677EA94F94FA6285289BAE68755B549B@BENMAIL02.ben.pri>

Greetings,

We wanted to announce a new R package 'KScorrect' that carries out the Lilliefors correction to the Kolmogorov-Smirnoff test for use in (one-sample) goodness-of-fit tests.

It's well-established it's inappropriate to use the K-S test when sample statistics are used to estimate parameters, which results in substantially increased Type-II errors. This warning is mentioned in the ks.test Help page, but no general solution is currently available for non-normal distributions.

The 'KScorrect' package corrects for the bias by using Monte Carlo simulation, a solution first recommended by Lilliefors (1967) but not widely heeded. The primary function 'LcKS()' is written to complement, and can be used directly in place of, 'ks.test()'. It can be used with most continuous distribution functions, including normal, univariate mixture of normals, lognormal, uniform, loguniform (flat when data are log-transformed), exponential, gamma, and Weibull distributions, and corresponding maximum-likelihood parameters are estimated automatically from the provided sample.

Distribution functions are provided in the package for the loguniform and univariate mixture of normal distributions, which are not included in the R base installation.

Simple examples are provided by calling example(KScorrect) or example(LcKS).

Additional details are available at https://cran.r-project.org/web/packages/KScorrect. Bug reports, suggestions, and feature requests are encouraged at https://github.com/pnovack-gottshall/KScorrect. 

We hope you find the functions useful when conducting goodness-of-fit tests using the K-S test.

Sincerely,
Phil Novack-Gottshall and Steve Wang

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 Phil Novack-Gottshall
 Associate Professor
 Department of Biological Sciences
 Benedictine University
 5700 College Road 
 Lisle, IL 60532

 pnovack-gottshall at ben.edu
 Phone: 630-829-6514
 Fax: 630-829-6547
 Office: 332 Birck Hall
 Lab: 316 Birck Hall
 http://www.ben.edu/faculty/pnovack-gottshall
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From prasad.prasad.kale at gmail.com  Tue Mar 29 17:37:53 2016
From: prasad.prasad.kale at gmail.com (Prasad Kale)
Date: Tue, 29 Mar 2016 21:07:53 +0530
Subject: [R] Can forecasting is possible through R Studio on the basis of
 past experience of data
Message-ID: <CAHKdztUTd+00akfJ+E2CRrWLwrZAN4xNSaW+YAUG_ECz85YpDg@mail.gmail.com>

Hi All,

I am very new to the R. I just want to ask whether through R Studio can I
able to build forecasting module.

Means on the basis of past experience can I able to predict future trend.

To start up can you please provide me any useful links or documents so by
referring this i will try at my end.

Thanks in advance.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue Mar 29 17:51:02 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 29 Mar 2016 11:51:02 -0400
Subject: [R] Can forecasting is possible through R Studio on the basis
	of past experience of data
In-Reply-To: <CAHKdztUTd+00akfJ+E2CRrWLwrZAN4xNSaW+YAUG_ECz85YpDg@mail.gmail.com>
References: <CAHKdztUTd+00akfJ+E2CRrWLwrZAN4xNSaW+YAUG_ECz85YpDg@mail.gmail.com>
Message-ID: <76DA2D0B-C57E-4CD0-BA38-9B0EAAF94322@utoronto.ca>

R Studio is basically a wrapper for R. To find out more about how to work with R, just use Google. Or, for a more focussed experience, navigate to  www.rseek.org

B.


On Mar 29, 2016, at 11:37 AM, Prasad Kale <prasad.prasad.kale at gmail.com> wrote:

> Hi All,
> 
> I am very new to the R. I just want to ask whether through R Studio can I
> able to build forecasting module.
> 
> Means on the basis of past experience can I able to predict future trend.
> 
> To start up can you please provide me any useful links or documents so by
> referring this i will try at my end.
> 
> Thanks in advance.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Mar 29 18:25:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 29 Mar 2016 09:25:28 -0700
Subject: [R] Can forecasting is possible through R Studio on the basis
 of past experience of data
In-Reply-To: <CAHKdztUTd+00akfJ+E2CRrWLwrZAN4xNSaW+YAUG_ECz85YpDg@mail.gmail.com>
References: <CAHKdztUTd+00akfJ+E2CRrWLwrZAN4xNSaW+YAUG_ECz85YpDg@mail.gmail.com>
Message-ID: <CAGxFJbQokdHT5+ZkqOrDqfD0D4+AaG4g-Wp1dZTD83-bL6_Q5w@mail.gmail.com>

You should have first searched the RStudio website, where you would have found:

https://www.rstudio.com/online-learning/#R


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 29, 2016 at 8:37 AM, Prasad Kale
<prasad.prasad.kale at gmail.com> wrote:
> Hi All,
>
> I am very new to the R. I just want to ask whether through R Studio can I
> able to build forecasting module.
>
> Means on the basis of past experience can I able to predict future trend.
>
> To start up can you please provide me any useful links or documents so by
> referring this i will try at my end.
>
> Thanks in advance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Tue Mar 29 19:04:05 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 29 Mar 2016 18:04:05 +0100
Subject: [R] Export the result k-means cluster to CSV file
In-Reply-To: <98011800.188384.1458981965760.JavaMail.yahoo@mail.yahoo.com>
References: <1A8C1289955EF649A09086A153E2672403D128F582@GBTEDVPEXCMB04.corp.lgc-group.com>
	<98011800.188384.1458981965760.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D128F870@GBTEDVPEXCMB04.corp.lgc-group.com>

> i am confusing about your code , i can not get the  the desired result . can you
> more clear for the code?
The code I suggested just  provided a structured text output of the kmeans object.

If you want a cluster-by-cluster output of the original data, you will need to write a function that does what you want for each cluster. For example you could write a function that would take a cluster index as the first argument, the kmeans object as a second argument, and the original data as the third. Then you can use something like lapply to apply that function to each subset of your data.

For example, again using the example in kmeans, a simple list of the cluster coordinate sets can be obtained using 
by.index <- function(index, km, x) {
	x[km$cluster==index, ] #returns the subset of original data in cluster (index)
}

lapply(unique(cl$cluster), by.index, km=cl, x=x)
	#cl was the kmeans object generated from the data set x used in the example
	#Using unique(cl$cluster) means that all the clusters identified in the kmeans object are included in the list

This generates a list, identified by cluster index number, that contains the coordinates for each cluster. If you assign that list to an object you can then write a separate function to format and write out the coordinates and use lapply to run that on the list. Or you can include formatted write calls in the by.index function, writing to a file as before.


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From marc_grt at yahoo.fr  Tue Mar 29 20:24:55 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 29 Mar 2016 20:24:55 +0200
Subject: [R] help in maximum likelihood estimation
In-Reply-To: <626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>
References: <626469436.1258328.1459196387595.JavaMail.yahoo.ref@mail.yahoo.com>
	<626469436.1258328.1459196387595.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56FAC877.1020705@yahoo.fr>

Le 28/03/2016 22:19, heba eldeeb via R-help a ?crit :
>   Dear AllI'm trying to find the maximum likelihood estimator  of a certain distribution using nlm command but I receive an error as:
>   non-finite value supplied by 'nlm'
> can't figure out what is wrong in my function
> Any help?
> Thank you in advance
>
>
Hi,

Whitout rproducible example, it will be impossible to help you 
efficiently. See https://www.r-project.org/posting-guide.html
Anyway, this error means that your function returns NA or error for some 
combination of parameters.

Marc


From heba_eldeeb2000 at yahoo.com  Tue Mar 29 21:29:01 2016
From: heba_eldeeb2000 at yahoo.com (heba eldeeb)
Date: Tue, 29 Mar 2016 19:29:01 +0000 (UTC)
Subject: [R] [FORGED]  help in maximum likelihood estimation
In-Reply-To: <873137371.1971427.1459278914401.JavaMail.yahoo@mail.yahoo.com>
References: <816FC11A-5BAF-4F0D-8F8A-A6B2379FE936@yahoo.com>
	<873137371.1971427.1459278914401.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1440320533.2028454.1459279741047.JavaMail.yahoo@mail.yahoo.com>

Dear Rolf
I wish this function is written as soon as possible to know how anyone spend time to reply as you did

Thanks
 

    On Tuesday, March 29, 2016 9:07 PM, Heba <Heba_eldeeb2000 at yahoo.com> wrote:
 

 Dear Rolf
I wish this function is written as soon as possible to know how anyone spend time to reply as you did

Thanks

Sent from my iPhone

> On Mar 29, 2016, at 12:32 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> On 29/03/16 09:19, heba eldeeb via R-help wrote:
>>? Dear All
>> I'm trying to find the maximum likelihood estimator of a certain
>> distribution using nlm command but I receive an error as:
>> non-finite value supplied by 'nlm' can't figure out what is wrong in
>> my function Any help? Thank you in advance.
> 
> Sorry, the mind_read() function in R has not yet been written.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

  
	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Tue Mar 29 21:42:29 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 29 Mar 2016 21:42:29 +0200
Subject: [R] R logo size in package information tab of Rstudio
Message-ID: <56FADAA5.2040302@yahoo.fr>

Two different sizes of R logo are shown in Rstudio in the Help at the 
package level.

For example, numderiv shows a nice discreet logo located at (in MacosX):
/Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/logo.jpg
whereas packrat shows a huge logo located at:
/Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg

The choice between both depends on the path indicated in the file 
Index.html located in html folder for each package.

It would be better to have svg version of Rlogo.svg of the same size 
than logo.jpg (I have converted the Rlogo.svg into the same size than 
logo.jpg and it looks much better whit the new version).

Sincerely

Marc





From lorenzo.isella at gmail.com  Tue Mar 29 21:48:56 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 29 Mar 2016 21:48:56 +0200
Subject: [R] Total Least Squares Regression
Message-ID: <20160329194856.GA1388@chicca>

Dear All,
I am looking for an R package to handle total least square regression
(TLS).

See http://bit.ly/1pSf4Bg

I am in a situation in which I have errors in both the dependent
variables X (plural because I have several predictors) and the
independent variable y.
I found several discussion inside and outside the R mailing list, e.g.

http://bit.ly/1pSfveQ

http://bit.ly/1RDAPuA (stackexchange)

In my understanding, when the variance of the error on all the
predictors and the dependent variable is identical, the problem
reduces to the orthogonal least squares and that is partially
addressed in the stackexchange link.
However, there are some bits missing

1) in the example given in stackexchange, how do I calculate the
confidence intervals of my prediction?
2) Suppose that the variances of the errors in the predictors and the
independent variables are not identical and I have somehow estimated
their ratio. How can I then generalize the example in the stackexchange link?

To fix the ideas, I paste some R code a the end of the email. Any
suggestion is welcome.
Many thanks

Lorenzo

#########################################################

library(dplyr)


tls <- function(X,y){

v <- prcomp(cbind(X,y))$rotation
 beta <- -v[-ncol(v),ncol(v)] / v[ncol(v),ncol(v)]
 return(beta)

}

tls_beta0 <- function(X,y, beta){
    beta0 <- mean(y)-sum(colMeans(X)*beta)
        return(beta0)

}


## some data to work upon

dd <- structure(list(mn = c(9226, 9404, 9604, 10183, 10788, 11352,
11984, 12921, 14057, 15235, 15560, 15738, 16039, 16729, 17332,
18398, 19458, 20001, 19861, 20690, 21495, 21869, 22145, 22521
), ind = c(43862, 40621, 37884, 36039, 35228, 34336, 33684, 33816,
33593, 33861, 33817, 33139, 32250, 31796, 31276, 30934, 31340,
32078, 31366, 30800, 31410, 31975, 32120, 32254), gov = c(1183695,
1281056, 1334560, 1390475, 1439175, 1472564, 1495661, 1520460,
1565451, 1604454, 1654996, 1672559, 1701664, 1722003, 1751547,
1793235, 1824640, 1874300, 1894248, 1939610, 2001224, 2056539,
2104642, 2156210), berd = c(26245.5, 26579, 25933, 25910, 26816.6,
27211, 28909.8, 30334.44, 33622.55, 35600, 36331.9, 36950, 38029,
38363, 38651.038, 41148, 43034, 46073, 45275, 46929, 51077.2,
53790.1, 53566.2, 56226)), row.names = c(NA, 24L), .Names = c("mn",
"ind", "gov", "berd"), class = "data.frame")


y <- dd$berd
X <- select(dd,mn, ind, gov)


beta_perp <- tls(X,y)
beta0_perp <- tls_beta0(X,y, beta_perp)


mymodel <- beta0_perp+beta_perp[1]*X[ ,1]+beta_perp[2]*X[ ,2]+
    beta_perp[3]*X[ ,3]


## what is the confidence level of my model?
## what if I do not assume that the error variance is the same for all
## the regressors in X and for the independent variable in y?


From jdnewmil at dcn.davis.ca.us  Tue Mar 29 22:23:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 29 Mar 2016 13:23:09 -0700
Subject: [R] [FORGED]  help in maximum likelihood estimation
In-Reply-To: <1440320533.2028454.1459279741047.JavaMail.yahoo@mail.yahoo.com>
References: <816FC11A-5BAF-4F0D-8F8A-A6B2379FE936@yahoo.com>
	<873137371.1971427.1459278914401.JavaMail.yahoo@mail.yahoo.com>
	<1440320533.2028454.1459279741047.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <C0EC86A2-3A46-494D-9595-4B09C10AC75F@dcn.davis.ca.us>

The R software is a product of many individuals contributions... when you implement that function please contribute it. 

Until then, a little more effort on your part really is needed to convey your problem clearly... the usual standard of clarity is a minimal reproducible example. Discussions of such are found in multiple places on the Internet, including the Posting Guide mentioned in the footer of this message, which also mentions the need to post in plain text rather than html to avoid corruption of your message on the mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On March 29, 2016 12:29:01 PM PDT, heba eldeeb via R-help <r-help at r-project.org> wrote:
>Dear Rolf
>I wish this function is written as soon as possible to know how anyone
>spend time to reply as you did
>
>Thanks
> 
>
>On Tuesday, March 29, 2016 9:07 PM, Heba <Heba_eldeeb2000 at yahoo.com>
>wrote:
> 
>
> Dear Rolf
>I wish this function is written as soon as possible to know how anyone
>spend time to reply as you did
>
>Thanks
>
>Sent from my iPhone
>
>> On Mar 29, 2016, at 12:32 AM, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>> 
>>> On 29/03/16 09:19, heba eldeeb via R-help wrote:
>>>? Dear All
>>> I'm trying to find the maximum likelihood estimator of a certain
>>> distribution using nlm command but I receive an error as:
>>> non-finite value supplied by 'nlm' can't figure out what is wrong in
>>> my function Any help? Thank you in advance.
>> 
>> Sorry, the mind_read() function in R has not yet been written.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> -- 
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Mar 29 22:42:34 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 29 Mar 2016 20:42:34 +0000
Subject: [R] How to solve an NLME problem?
References: <BN1PR06MB0721A0E3A55BCD52EAFE015BD870@BN1PR06MB072.namprd06.prod.outlook.com>
Message-ID: <loom.20160329T224008-917@post.gmane.org>

David C Blouin <dblouin <at> lsu.edu> writes:

>  I have a nonlinear model where I want to include random
> coefficients for a sample of random SUBJECTS. The fixed effects part
> of the model is Y ~ B + (T - B) / (1 + 10**(X - C)) and I would like
> to include random coefficients b for B, t for T, and c for C. The
> model is a fairly well-known three-parameter log-inhibitor model
> where Y is a measure of growth at X = log(CONCENTRATION), B is the
> unknown lower asymptote, T is the unknown upper asymptote, and C is
> the unknown log(IC50), where IC50 is the half maximal inhibitory
> concentration. I do not know how to solve this problem in R, where I
> am assuming NLME contains the appropriate methodology.
> [[alternative HTML version deleted]]

  something like

  nlme(Y ~ B + (T - B) / (1 + 10**(X - C)),
       random=B+T+C~group,
       data=your_data,
       start=list(fixed=c(B=something,T=something2,C=something3)))

 Follow-ups to r-sig-mixed-models at r-project.org, please ...


From jan.kacaba at gmail.com  Tue Mar 29 23:39:05 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Tue, 29 Mar 2016 23:39:05 +0200
Subject: [R] Accented characters, windows
Message-ID: <CAHby=D0oUKa9mNyLR7mSHTGtZC1tHzEipt2cy2BJPnEPTE3YqQ@mail.gmail.com>

I have problem with accented characters. My OS is Win 8.1 and I'm using
RStudio.

I make string :
av="?????"

When I call "av" I get result bellow.
> av
[1] "?????"

The resulting characters are different. I have similar problem when I write
string to a file. In RGUI if I call "av" it prints characters correctly,
but using "write" function to print string in a file results in the same
problem.

Can you please help me how to deal with it?

	[[alternative HTML version deleted]]


From jennifer.wu2 at mail.mcgill.ca  Tue Mar 29 22:47:35 2016
From: jennifer.wu2 at mail.mcgill.ca (Jennifer Wu, Miss)
Date: Tue, 29 Mar 2016 20:47:35 +0000
Subject: [R] Convergence issues when using ns splines (pkg: spline) in Cox
 model (coxph) even when changing coxph.control
Message-ID: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>

Hi,

I am currently using R v3.2.3 and on Windows 10 OS 64Bit.

I am having convergence issues when I use coxph with a interaction term (glarg*bca_py) and interaction term with the restricted cubic spline (glarg*bca_time_ns). I use survival and spline package to create the Cox model and cubic splines respectively. Without the interaction term and/or spline, I have no convergence problem. I read some forums about changing the iterations and I have but it did not work. I was just wondering if I am using the inter.max and outer.max appropriately. I read the survival manual, other R-help and stackoverflow pages and it suggested changing the iterations but it doesn't specify what is the max I can go. I ran something similar in SAS and did not run into a convergence problem.

This is my code:

bca_time_ns <- ns(ins_ca$bca_py, knots=3, Boundary.knots=range(2,5,10))
test <- ins_ca$glarg*ins_ca$bca_py
test1 <- ins_ca$glarg*bca_time_ns

coxit <- coxph.control(iter.max=10000, outer.max=10000)

bca<-coxph(Surv(bca_py,bca) ~ glarg + test + test1 + age + calyr + diab_dur + hba1c + adm_met + adm_sulfo + adm_tzd + adm_oth +
            med_statin + med_aspirin + med_nsaids + bmi_cat + ccscat + alc + smk, data=ins_ca, control=coxit, ties=c("breslow"))


This is the error message I get:

Warning message:
In fitter(X, Y, strats, offset, init, control, weights = weights,  :
  Ran out of iterations and did not converge



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 30 00:44:15 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 29 Mar 2016 18:44:15 -0400
Subject: [R] R logo size in package information tab of Rstudio
In-Reply-To: <56FADAA5.2040302@yahoo.fr>
References: <56FADAA5.2040302@yahoo.fr>
Message-ID: <56FB053F.7030200@gmail.com>

On 29/03/2016 3:42 PM, Marc Girondot via R-help wrote:
> Two different sizes of R logo are shown in Rstudio in the Help at the
> package level.
>
> For example, numderiv shows a nice discreet logo located at (in MacosX):
> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/logo.jpg
> whereas packrat shows a huge logo located at:
> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg
>
> The choice between both depends on the path indicated in the file
> Index.html located in html folder for each package.
>
> It would be better to have svg version of Rlogo.svg of the same size
> than logo.jpg (I have converted the Rlogo.svg into the same size than
> logo.jpg and it looks much better whit the new version).
>

What versions are you talking about?  I'd guess your packages were built 
with different versions of R if they ended up with different links to 
the logo.

Why is RStudio relevant here?  I don't think RStudio does anything with 
the R help files other than to display them in its built-in browser.



Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Mar 30 00:56:05 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 29 Mar 2016 18:56:05 -0400
Subject: [R] Accented characters, windows
In-Reply-To: <CAHby=D0oUKa9mNyLR7mSHTGtZC1tHzEipt2cy2BJPnEPTE3YqQ@mail.gmail.com>
References: <CAHby=D0oUKa9mNyLR7mSHTGtZC1tHzEipt2cy2BJPnEPTE3YqQ@mail.gmail.com>
Message-ID: <56FB0805.9060706@gmail.com>

On 29/03/2016 5:39 PM, Jan Kacaba wrote:
> I have problem with accented characters. My OS is Win 8.1 and I'm using
> RStudio.
>
> I make string :
> av="?????"
>
> When I call "av" I get result bellow.
>> av
> [1] "?????"
>
> The resulting characters are different. I have similar problem when I write
> string to a file. In RGUI if I call "av" it prints characters correctly,
> but using "write" function to print string in a file results in the same
> problem.
>
> Can you please help me how to deal with it?

You don't say what code page you're using.

R in Windows has a long standing problem that it works mainly in the 
local code page, rather than working in UTF-8 as most other systems do. 
  (This is due to the fact that when the internationalization was put 
in, UTF-8 was exotic, rather than ubiquitous as it is now.)  So R can 
store UTF-8 strings on any system, but for display it converts them to 
the local code page, and that conversion can lose information if the 
characters aren't supported locally.

With your string, I don't see the same thing as you, I see

"e?cr?"

which is also incorrect, but looks a little closer, because it does a 
better approximation in my code page.

So if you think my result is better than yours, you could change your 
system to code page 437 as I'm using, but that will probably cause you 
worse problems.

Probably the only short term solution that would be satisfactory is to 
stop using Windows.  At some point in the future the internal character 
handling in R needs an overhaul, but that's a really big, really 
thankless job.  Perhaps Microsoft/Revolution will donate some programmer 
time to do it, but more likely, it will wait for volunteers in R Core to 
do it.  I don't think it will happen in 2016.

Duncan Murdoch


From marine.regis at hotmail.fr  Wed Mar 30 02:53:38 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Wed, 30 Mar 2016 00:53:38 +0000
Subject: [R] Compute the Gini coefficient
Message-ID: <AMSPR07MB470B0BB75B152E879FD30C5E2980@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,

I would like to build a Lorenz curve and calculate a Gini coefficient in order to find how much parasites does the top 20% most infected hosts support.

Here is my data set:

Number of parasites per host:
parasites = c(0,1,2,3,4,5,6,7,8,9,10)

Number of hosts associated with each number of parasites given above:
hosts = c(18,20,28,19,16,10,3,1,0,0,0)

To represent the Lorenz curve:
I manually calculated the cumulative percentage of parasites and hosts:

cumul_parasites <- cumsum(parasites)/max(cumsum(parasites))
cumul_hosts <- cumsum(hosts)/max(cumsum(hosts))
plot(cumul_hosts, cumul_parasites, type= "l")

>From this Lorenz curve, how can I calculate the Gini coefficient with the function "gini" in R (package reldist) given that the vector "hosts" is not a vector of weights ?

Thank you very much for your help.
Have a nice day
Marine


	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Wed Mar 30 01:52:14 2016
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Tue, 29 Mar 2016 23:52:14 +0000 (UTC)
Subject: [R] Filtering based on the occurrence
References: <1033398224.2193436.1459295534804.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1033398224.2193436.1459295534804.JavaMail.yahoo@mail.yahoo.com>

Hello,?
I have a data set similar to below and I wanted to keep the observations after the first occurrence of these department: "B", "D", "F".For example for ID=2, the observation with deps=B and anything after will be kept in the data. For ID=3, observations with deps=D and anything after will be included.
Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1)?deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")df <- data.frame(Subject, dates, deps)df
The final data should look like this:final<-c("2 2011-01-02 ? ?B","2 2011-01-03 ? ?C","3 2011-01-05 ? ?D","3 2011-01-06 ? ?A","4 2011-01-07 ? ?F","4 2011-01-08 ? ?G","5 2011-01-10 ? ?F","5 2011-01-11 ? ?A","5 2011-01-12 ? ?D")?Thank you tons for your help.?
Farnoosh


	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Mar 30 06:07:49 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 30 Mar 2016 06:07:49 +0200
Subject: [R] R logo size in package information tab of Rstudio
In-Reply-To: <56FB053F.7030200@gmail.com>
References: <56FADAA5.2040302@yahoo.fr> <56FB053F.7030200@gmail.com>
Message-ID: <56FB5115.9090705@yahoo.fr>

Here are my R session information:
 > sessionInfo()
R version 3.3.0 alpha (2016-03-24 r70373)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.4 (El Capitan)

locale:
[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8

If the help is displayed within the R gui using:
help(package='packrat')

The Rlogo.svg is scaled correctly.

However if the help is shown within Rstudio, the Rlogo.svg is not scaled 
corrected and is shown at huge size.

The choice of logo displayed in the help comes from the file in folder 
html within each package. For example for package numDeriv, within the 
file: 
/Library/Frameworks/R.framework/Versions/3.3/Resources/library/numDeriv/html/00Index.html

There is this link:
</head><body>
<h1> Accurate Numerical Derivatives
<img class="toplogo" src="../../../doc/html/logo.jpg" alt="[R logo]" />
</h1>

Whereas for packrat package, within the file
/Library/Frameworks/R.framework/Versions/3.3/Resources/library/packrat/html/00Index.html

The link is this one:
</head><body>
<h1> A Dependency Management System for Projects and their R Package
Dependencies
<img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]" />
</h1>

And the Rlogo.svg is badly scaled in Rstudio Version 0.99.1119 (beta) or 
in public 0.99.893 version.

So there are two solutions. Or Rstudio changes the way they scale 
Rlogo.svg, or Rlogo.svg is correctly scaled during R install. Here is a 
Rlogo.svg correctly scaled to replace the original version:
http://www.ese.u-psud.fr/epc/conservation/CRAN/Rlogo.svg

Sincerely,

Marc


Le 30/03/2016 00:44, Duncan Murdoch a ?crit :
> On 29/03/2016 3:42 PM, Marc Girondot via R-help wrote:
>> Two different sizes of R logo are shown in Rstudio in the Help at the
>> package level.
>>
>> For example, numderiv shows a nice discreet logo located at (in MacosX):
>> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/logo.jpg
>> whereas packrat shows a huge logo located at:
>> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg 
>>
>>
>> The choice between both depends on the path indicated in the file
>> Index.html located in html folder for each package.
>>
>> It would be better to have svg version of Rlogo.svg of the same size
>> than logo.jpg (I have converted the Rlogo.svg into the same size than
>> logo.jpg and it looks much better whit the new version).
>>
>
> What versions are you talking about?  I'd guess your packages were 
> built with different versions of R if they ended up with different 
> links to the logo.
>
> Why is RStudio relevant here?  I don't think RStudio does anything 
> with the R help files other than to display them in its built-in browser.
>
>
>
> Duncan Murdoch
>
>


From jdnewmil at dcn.davis.ca.us  Wed Mar 30 06:18:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 29 Mar 2016 21:18:19 -0700
Subject: [R] R logo size in package information tab of Rstudio
In-Reply-To: <56FB5115.9090705@yahoo.fr>
References: <56FADAA5.2040302@yahoo.fr> <56FB053F.7030200@gmail.com>
	<56FB5115.9090705@yahoo.fr>
Message-ID: <8C7E135A-E0FE-4D88-BF52-44B09EB6F32D@dcn.davis.ca.us>

You are not clarifying yet. If this requires RStudio to reproduce then this question doesn't belong here. I am not yet convinced that RStudio IS required, but every time you mention it the water gets muddier. 
-- 
Sent from my phone. Please excuse my brevity.

On March 29, 2016 9:07:49 PM PDT, Marc Girondot via R-help <r-help at r-project.org> wrote:
>Here are my R session information:
> > sessionInfo()
>R version 3.3.0 alpha (2016-03-24 r70373)
>Platform: x86_64-apple-darwin13.4.0 (64-bit)
>Running under: OS X 10.11.4 (El Capitan)
>
>locale:
>[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8
>
>If the help is displayed within the R gui using:
>help(package='packrat')
>
>The Rlogo.svg is scaled correctly.
>
>However if the help is shown within Rstudio, the Rlogo.svg is not
>scaled 
>corrected and is shown at huge size.
>
>The choice of logo displayed in the help comes from the file in folder 
>html within each package. For example for package numDeriv, within the 
>file: 
>/Library/Frameworks/R.framework/Versions/3.3/Resources/library/numDeriv/html/00Index.html
>
>There is this link:
></head><body>
><h1> Accurate Numerical Derivatives
><img class="toplogo" src="../../../doc/html/logo.jpg" alt="[R logo]" />
></h1>
>
>Whereas for packrat package, within the file
>/Library/Frameworks/R.framework/Versions/3.3/Resources/library/packrat/html/00Index.html
>
>The link is this one:
></head><body>
><h1> A Dependency Management System for Projects and their R Package
>Dependencies
><img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]"
>/>
></h1>
>
>And the Rlogo.svg is badly scaled in Rstudio Version 0.99.1119 (beta)
>or 
>in public 0.99.893 version.
>
>So there are two solutions. Or Rstudio changes the way they scale 
>Rlogo.svg, or Rlogo.svg is correctly scaled during R install. Here is a
>
>Rlogo.svg correctly scaled to replace the original version:
>http://www.ese.u-psud.fr/epc/conservation/CRAN/Rlogo.svg
>
>Sincerely,
>
>Marc
>
>
>Le 30/03/2016 00:44, Duncan Murdoch a ?crit :
>> On 29/03/2016 3:42 PM, Marc Girondot via R-help wrote:
>>> Two different sizes of R logo are shown in Rstudio in the Help at
>the
>>> package level.
>>>
>>> For example, numderiv shows a nice discreet logo located at (in
>MacosX):
>>>
>/Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/logo.jpg
>>> whereas packrat shows a huge logo located at:
>>>
>/Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg
>
>>>
>>>
>>> The choice between both depends on the path indicated in the file
>>> Index.html located in html folder for each package.
>>>
>>> It would be better to have svg version of Rlogo.svg of the same size
>>> than logo.jpg (I have converted the Rlogo.svg into the same size
>than
>>> logo.jpg and it looks much better whit the new version).
>>>
>>
>> What versions are you talking about?  I'd guess your packages were 
>> built with different versions of R if they ended up with different 
>> links to the logo.
>>
>> Why is RStudio relevant here?  I don't think RStudio does anything 
>> with the R help files other than to display them in its built-in
>browser.
>>
>>
>>
>> Duncan Murdoch
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Mar 30 08:28:36 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 30 Mar 2016 08:28:36 +0200
Subject: [R] R logo size in package information
In-Reply-To: <8C7E135A-E0FE-4D88-BF52-44B09EB6F32D@dcn.davis.ca.us>
References: <56FADAA5.2040302@yahoo.fr> <56FB053F.7030200@gmail.com>
	<56FB5115.9090705@yahoo.fr>
	<8C7E135A-E0FE-4D88-BF52-44B09EB6F32D@dcn.davis.ca.us>
Message-ID: <56FB7214.4040109@yahoo.fr>

Le 30/03/2016 06:18, Jeff Newmiller a ?crit :
> You are not clarifying yet. If this requires RStudio to reproduce then 
> this question doesn't belong here. I am not yet convinced that RStudio 
> IS required, but every time you mention it the water gets muddier.
I try to be shorter:

There is bad interaction between Rlogo.svg installed by R and Rstudio:
So there are two solutions. Or Rstudio changes the way they scale 
Rlogo.svg, or Rlogo.svg is differently scaled during R install. Here is 
a Rlogo.svg correctly scaled to replace the original version hat is 
located at 
/Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg for 
R 3.3 MacOSX version:
http://www.ese.u-psud.fr/epc/conservation/CRAN/Rlogo.svg

Marc


From petr.pikal at precheza.cz  Wed Mar 30 09:42:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 30 Mar 2016 07:42:51 +0000
Subject: [R] how can I count data points outside the main plot line?
In-Reply-To: <CAGHW+o+HwEvk+APscQMai20ZaWFQP9aof3v=7gG3LrNuHsC6qQ@mail.gmail.com>
References: <CAGHW+oKsTjNiPD=kFAxZU5PubuM=26BZW-pW92PDtkHjN_Tngw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5017AFE@SRVEXCHMBX.precheza.cz>
	<CAGHW+o+HwEvk+APscQMai20ZaWFQP9aof3v=7gG3LrNuHsC6qQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5017DA4@SRVEXCHMBX.precheza.cz>

Hi Raz

Keep your responses to the rhelp list.
Did you try residuals function?


DNase1 <- subset(DNase, Run == 1)
DNase1[12,3]<-0.1
fm1DNase1 <- nls(density ~ SSlogis(log(conc), Asym, xmid, scal), DNase1)
resid(fm1DNase1)
[1] -3.273213e-02 -3.173213e-02 -7.798226e-03 -4.798226e-03 -7.665433e-05
[6]  8.923346e-03  4.956802e-02  4.656802e-02  9.936101e-02  9.436101e-02
[11]  2.233609e-01 -6.956391e-01  1.334304e-01  1.634304e-01 -2.106923e-02
[16] -4.106923e-02
attr(,"label")
1] "Residuals"
plot(resid(fm1DNase1))

You can use the threshold for selecting values departing from your model.

> sum(abs(resid(fm1DNase1))>0.4)
[1] 1
> sum(abs(resid(fm1DNase1))>0.2)
[1] 2
> sum(abs(resid(fm1DNase1))>0.1)
[1] 4
>

Cheers
Petr


From: raz [mailto:barvazduck at gmail.com]
Sent: Wednesday, March 30, 2016 8:31 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] how can I count data points outside the main plot line?

Hi Petr,
Thanks for your reply, if you have time can you elaborate more about your suggestions, I dont understand what you meant..
Thanks
Raz

On Tue, Mar 29, 2016 at 12:14 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Did you try residuals and/or influence.measures?

Cheers
Petr


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of raz
Sent: Tuesday, March 29, 2016 10:51 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] how can I count data points outside the main plot line?

How can I count data points that lay outside of the main plot line?
I have a plot in which most data points create a sigmoid line, but some are spread throughout the plot area, these points dont fit the curve. I would like to count them to know the ratio between the main curve and the data points that dont fit, any ideas?

Thanks,

Raz

--
\m/
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



--
\m/

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Mar 30 10:13:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 30 Mar 2016 19:13:29 +1100
Subject: [R] Filtering based on the occurrence
In-Reply-To: <1033398224.2193436.1459295534804.JavaMail.yahoo@mail.yahoo.com>
References: <1033398224.2193436.1459295534804.JavaMail.yahoo.ref@mail.yahoo.com>
	<1033398224.2193436.1459295534804.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fWcO0OL1EHgtEDEKa8Mfd851EUk=efttgkFBKwmVy4+og@mail.gmail.com>

Hi Farnoosh,
Despite my deep suspicion that this answer will solve a useless
problem, try this:

last_subject<-0
keep_deps<-c("B","D","F")
keep_rows<-NULL
for(rowindex in 1:dim(df)[1]) {
 if(df[rowindex,"Subject"] != last_subject) {
  last_subject<-df[rowindex,"Subject"]
  start_keeping<-0
 }
 if(df[rowindex,"deps"] %in% keep_deps) start_keeping<-1
 if(start_keeping) keep_rows<-c(keep_rows,rowindex)
}
final<-matrix(unlist(lapply(df[keep_rows,],as.character)),ncol=3)

I find it terribly hard to ignore puzzles.

Jim


On Wed, Mar 30, 2016 at 10:52 AM, Farnoosh Sheikhi via R-help
<r-help at r-project.org> wrote:
> Hello,
> I have a data set similar to below and I wanted to keep the observations after the first occurrence of these department: "B", "D", "F".For example for ID=2, the observation with deps=B and anything after will be kept in the data. For ID=3, observations with deps=D and anything after will be included.
> Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1) deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")df <- data.frame(Subject, dates, deps)df
> The final data should look like this:final<-c("2 2011-01-02    B","2 2011-01-03    C","3 2011-01-05    D","3 2011-01-06    A","4 2011-01-07    F","4 2011-01-08    G","5 2011-01-10    F","5 2011-01-11    A","5 2011-01-12    D") Thank you tons for your help.
> Farnoosh
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Wed Mar 30 10:33:25 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Wed, 30 Mar 2016 08:33:25 +0000
Subject: [R] Filtering based on the occurrence
Message-ID: <248E6FA047A8C746BA491485764190F53D3974D1@ESESSMB207.ericsson.se>


# your code
Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")
dates <- seq(as.Date('2011-01-01'),as.Date('2011-01-12'), by = 1)
deps <- c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")
df <- data.frame(Subject, dates, deps)
df
final<-c("2 2011-01-02    B","2 2011-01-03    C","3 2011-01-05    D","3 2011-01-06    A",
         "4 2011-01-07    F","4 2011-01-08    G","5 2011-01-10    F","5 2011-01-11    A",
         "5 2011-01-12    D")

# here below my code
dep.list <- c("B", "D", "F")
sel.row = NULL
for (dep in dep.list) {
  f <- which(df$deps == dep)
  sel.row <- c(sel.row, c(f, f+1))
}
sel.row[sel.row > nrow(df)] <- NA
sel.row <- na.omit(sel.row)
df.sel <- df[sel.row,]
df.sel.ord <- df.sel[order(df.sel$dates),]

# showing and comparing with final
> df.sel.ord
   Subject      dates deps
2        2 2011-01-02    B
3        2 2011-01-03    C
5        3 2011-01-05    D
6        3 2011-01-06    A
7        4 2011-01-07    F
8        4 2011-01-08    G
10       5 2011-01-10    F
11       5 2011-01-11    A
12       5 2011-01-12    D

> data.frame(final)
              final
1 2 2011-01-02    B
2 2 2011-01-03    C
3 3 2011-01-05    D
4 3 2011-01-06    A
5 4 2011-01-07    F
6 4 2011-01-08    G
7 5 2011-01-10    F
8 5 2011-01-11    A
9 5 2011-01-12    D

--

Best

GG


	[[alternative HTML version deleted]]


From goran.brostrom at umu.se  Wed Mar 30 11:40:56 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Wed, 30 Mar 2016 11:40:56 +0200
Subject: [R] Convergence issues when using ns splines (pkg: spline) in
 Cox model (coxph) even when changing coxph.control
In-Reply-To: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
References: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
Message-ID: <56FB9F28.6070405@umu.se>

Hi Jennifer,

see below.

On 2016-03-29 22:47, Jennifer Wu, Miss wrote:
> Hi,
>
> I am currently using R v3.2.3 and on Windows 10 OS 64Bit.
>
> I am having convergence issues when I use coxph with a interaction
> term (glarg*bca_py) and interaction term with the restricted cubic
> spline (glarg*bca_time_ns).

Comment on interactions: (i) You should not create interaction terms 
'manually' but rather in the formula in the call to coxph ('*' means 
different things in a formula and on the command line). That assures 
that you get the main effects included. In your formula, you are missing 
the main effects 'bca_py' and 'bca_time_ns'. Is that intentional? In a 
few exceptional cases it may make sense to drop a main affect, but 
generally not. (ii) Convergence problems may also occur with 
interactions of variables that are not centered, so try to center 
involved covariates.

Your 'coxph.control' values have nothing to do with your convergence 
problem.

And try to provide reproducible code, in your case, the data set. If it 
is not possible, maybe you can scale it down to include only the 
problematic variables (with some fake values, if necessary) and just a 
few cases, but enough to show your problem.

G?ran Brostr?m

 > I use survival and spline package to
> create the Cox model and cubic splines respectively. Without the
> interaction term and/or spline, I have no convergence problem. I read
> some forums about changing the iterations and I have but it did not
> work. I was just wondering if I am using the inter.max and outer.max
> appropriately. I read the survival manual, other R-help and
> stackoverflow pages and it suggested changing the iterations but it
> doesn't specify what is the max I can go. I ran something similar in
> SAS and did not run into a convergence problem.
>
> This is my code:
>
> bca_time_ns <- ns(ins_ca$bca_py, knots=3,
> Boundary.knots=range(2,5,10)) test <- ins_ca$glarg*ins_ca$bca_py
> test1 <- ins_ca$glarg*bca_time_ns
>
> coxit <- coxph.control(iter.max=10000, outer.max=10000)
>
> bca<-coxph(Surv(bca_py,bca) ~ glarg + test + test1 + age + calyr +
> diab_dur + hba1c + adm_met + adm_sulfo + adm_tzd + adm_oth +
> med_statin + med_aspirin + med_nsaids + bmi_cat + ccscat + alc + smk,
> data=ins_ca, control=coxit, ties=c("breslow"))
>
>
> This is the error message I get:
>
> Warning message: In fitter(X, Y, strats, offset, init, control,
> weights = weights,  : Ran out of iterations and did not converge
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From erich.neuwirth at univie.ac.at  Wed Mar 30 11:57:31 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 30 Mar 2016 11:57:31 +0200
Subject: [R] Compute the Gini coefficient
In-Reply-To: <AMSPR07MB470B0BB75B152E879FD30C5E2980@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB470B0BB75B152E879FD30C5E2980@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <04863639-C891-49C8-B210-ADD5BBCE518F@univie.ac.at>


> On 30 Mar 2016, at 02:53, Marine Regis <marine.regis at hotmail.fr> wrote:
> 
> Hello,
> 
> I would like to build a Lorenz curve and calculate a Gini coefficient in order to find how much parasites does the top 20% most infected hosts support.
> 
> Here is my data set:
> 
> Number of parasites per host:
> parasites = c(0,1,2,3,4,5,6,7,8,9,10)
> 
> Number of hosts associated with each number of parasites given above:
> hosts = c(18,20,28,19,16,10,3,1,0,0,0)
> 
> To represent the Lorenz curve:
> I manually calculated the cumulative percentage of parasites and hosts:
> 
> cumul_parasites <- cumsum(parasites)/max(cumsum(parasites))
> cumul_hosts <- cumsum(hosts)/max(cumsum(hosts))
> plot(cumul_hosts, cumul_parasites, type= "l?)


Your values in hosts are frequencies. So you need to calculate

cumul_hosts = cumsum(hosts)/sum(hosts)
cumul_parasites = cumsum(hosts*parasites)/sum(parasites)

The Lorenz curves starts at (0,0), so to draw it, you need to extend these vectors

cumul_hosts = c(0,cumul_hosts)
cumul_parasites = c(0,cumul_parasites)

plot(cumul_hosts,cum9l_parasites,type=?l?)


The Gini coefficient can be calculated as
library(reldist)
gini(parasites,hosts)


If you want to check, you can ?recreate? the original data (number of parasited for each host) with

num_parasites = rep(parasites,hosts)

and
gini(num_parasites)

will also give you the Gini coefficient you want.



> 

>> From this Lorenz curve, how can I calculate the Gini coefficient with the function "gini" in R (package reldist) given that the vector "hosts" is not a vector of weights ?
> 
> Thank you very much for your help.
> Have a nice day
> Marine
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160330/84c0177d/attachment.bin>

From Achim.Zeileis at uibk.ac.at  Wed Mar 30 12:05:30 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 30 Mar 2016 12:05:30 +0200 (CEST)
Subject: [R] Compute the Gini coefficient
In-Reply-To: <04863639-C891-49C8-B210-ADD5BBCE518F@univie.ac.at>
References: <AMSPR07MB470B0BB75B152E879FD30C5E2980@AMSPR07MB470.eurprd07.prod.outlook.com>
	<04863639-C891-49C8-B210-ADD5BBCE518F@univie.ac.at>
Message-ID: <alpine.DEB.2.20.1603301203320.6554@paninaro>

On Wed, 30 Mar 2016, Erich Neuwirth wrote:

>
>> On 30 Mar 2016, at 02:53, Marine Regis <marine.regis at hotmail.fr> wrote:
>>
>> Hello,
>>
>> I would like to build a Lorenz curve and calculate a Gini coefficient in order to find how much parasites does the top 20% most infected hosts support.
>>
>> Here is my data set:
>>
>> Number of parasites per host:
>> parasites = c(0,1,2,3,4,5,6,7,8,9,10)
>>
>> Number of hosts associated with each number of parasites given above:
>> hosts = c(18,20,28,19,16,10,3,1,0,0,0)
>>
>> To represent the Lorenz curve:
>> I manually calculated the cumulative percentage of parasites and hosts:
>>
>> cumul_parasites <- cumsum(parasites)/max(cumsum(parasites))
>> cumul_hosts <- cumsum(hosts)/max(cumsum(hosts))
>> plot(cumul_hosts, cumul_parasites, type= "l?)
>
>
> Your values in hosts are frequencies. So you need to calculate
>
> cumul_hosts = cumsum(hosts)/sum(hosts)
> cumul_parasites = cumsum(hosts*parasites)/sum(parasites)

That's what I thought as well but Marine explicitly said that the 'host' 
are _not_ weights. Hence I was confused what this would actually mean.

Using the "ineq" package you can also do
plot(Lc(parasites, hosts))

> The Lorenz curves starts at (0,0), so to draw it, you need to extend these vectors
>
> cumul_hosts = c(0,cumul_hosts)
> cumul_parasites = c(0,cumul_parasites)
>
> plot(cumul_hosts,cum9l_parasites,type=?l?)
>
>
> The Gini coefficient can be calculated as
> library(reldist)
> gini(parasites,hosts)
>
>
> If you want to check, you can ?recreate? the original data (number of parasited for each host) with
>
> num_parasites = rep(parasites,hosts)
>
> and
> gini(num_parasites)
>
> will also give you the Gini coefficient you want.
>
>
>
>>
>
>>> From this Lorenz curve, how can I calculate the Gini coefficient with the function "gini" in R (package reldist) given that the vector "hosts" is not a vector of weights ?
>>
>> Thank you very much for your help.
>> Have a nice day
>> Marine
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From therneau at mayo.edu  Wed Mar 30 14:13:04 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 30 Mar 2016 07:13:04 -0500
Subject: [R] convergence issues with coxph
In-Reply-To: <mailman.5.1459332003.13061.r-help@r-project.org>
References: <mailman.5.1459332003.13061.r-help@r-project.org>
Message-ID: <519743$2o43ii@ironport10.mayo.edu>

Failure to converge in a coxph model is very rare.  If the program does not make it in 20 
iterations it likely will never converge, so your control argument will do little.

Without the data set I have no way to guess what is happening.  My first question, 
however, is to ask how many events you have, e.g. table(bca).  I count 19 covariates on 
the right hand side, and a good rule of thumb is that one should have at least 5- 10 
endpoints per covariate for simple numerical stability and 10-20 for statistical 
stability.  That means 100-200 events.  Most medical data sets have fewer than this. A 
data set with 5000 rows and 4 death counts as "4" in this calculation by the way.

   I am always interested in data sets that push the boundaries of the code and can look 
deeper if you want to send me a copy.  Details of how things are coded can matter, e.g., 
centered covariates.  Otherwise there is little we can do.

Terry Therneau


On 03/30/2016 05:00 AM, r-help-request at r-project.org wrote:
> I am having convergence issues when I use coxph with a interaction term (glarg*bca_py) and interaction term with the restricted cubic spline (glarg*bca_time_ns). I use survival and spline package to create the Cox model and cubic splines respectively. Without the interaction term and/or spline, I have no convergence problem. I read some forums about changing the iterations and I have but it did not work. I was just wondering if I am using the inter.max and outer.max appropriately. I read the survival manual, other R-help and stackoverflow pages and it suggested changing the iterations but it doesn't specify what is the max I can go. I ran something similar in SAS and did not run into a convergence problem.
>
> This is my code:
>
> bca_time_ns <- ns(ins_ca$bca_py, knots=3, Boundary.knots=range(2,5,10))
> test <- ins_ca$glarg*ins_ca$bca_py
> test1 <- ins_ca$glarg*bca_time_ns
>
> coxit <- coxph.control(iter.max=10000, outer.max=10000)
>
> bca<-coxph(Surv(bca_py,bca) ~ glarg + test + test1 + age + calyr + diab_dur + hba1c + adm_met + adm_sulfo + adm_tzd + adm_oth +
>              med_statin + med_aspirin + med_nsaids + bmi_cat + ccscat + alc + smk, data=ins_ca, control=coxit, ties=c("breslow"))


From utz.ryan at gmail.com  Wed Mar 30 17:03:16 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Wed, 30 Mar 2016 11:03:16 -0400
Subject: [R] ts or xts with high-frequency data within a year
Message-ID: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>

Hello,

I have a time series that represents data sampled every 15-minutes. The
data currently run from November through February, 8623 total readings.
There are definitely daily periodic trends and non-stationary long-term
trends. I would love to decompose this using basic time series analysis.

However, every time I attempt decomposition, I get the

Error in decompose( ) : time series has no or less than 2 periods

Is it only possible to do basic time-series analysis if you have a year or
more worth of data? That seems absurd to me, since there is definite
periodicity and the data are a time series. I have tried every manner of
specifying frequency= with no luck (96 does not work). All manner of
searching for help has turned up fruitless.

Can I only do this after I wait another year or two?

Thanks,
Ryan

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar 30 17:18:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 30 Mar 2016 08:18:52 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
References: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
Message-ID: <CAGxFJbROoU1=xvBSagbEkFeovoaV2W_P28EOjiM6gJUEjutDxA@mail.gmail.com>

Code please.

Reproducible example?(e.g. 1st 100 values)

"PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code."

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
> Hello,
>
> I have a time series that represents data sampled every 15-minutes. The
> data currently run from November through February, 8623 total readings.
> There are definitely daily periodic trends and non-stationary long-term
> trends. I would love to decompose this using basic time series analysis.
>
> However, every time I attempt decomposition, I get the
>
> Error in decompose( ) : time series has no or less than 2 periods
>
> Is it only possible to do basic time-series analysis if you have a year or
> more worth of data? That seems absurd to me, since there is definite
> periodicity and the data are a time series. I have tried every manner of
> specifying frequency= with no luck (96 does not work). All manner of
> searching for help has turned up fruitless.
>
> Can I only do this after I wait another year or two?
>
> Thanks,
> Ryan
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Mar 30 17:29:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 30 Mar 2016 08:29:02 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAGxFJbROoU1=xvBSagbEkFeovoaV2W_P28EOjiM6gJUEjutDxA@mail.gmail.com>
References: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
	<CAGxFJbROoU1=xvBSagbEkFeovoaV2W_P28EOjiM6gJUEjutDxA@mail.gmail.com>
Message-ID: <CAGxFJbQyx4AMFbEfPszOC=B0_r7-HnXfPyi4xALHNNdWYtU4VQ@mail.gmail.com>

I "think" the problem is that you failed to set the "frequency"
attribute of your time series, so it defaults to 1. A time series with
one observation per period cannot be decomposed, since the error term
is confounded with the "seasonality", which is essentially your error
message.

Again, a guess, as you provided no code.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 30, 2016 at 8:18 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Code please.
>
> Reproducible example?(e.g. 1st 100 values)
>
> "PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code."
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>> Hello,
>>
>> I have a time series that represents data sampled every 15-minutes. The
>> data currently run from November through February, 8623 total readings.
>> There are definitely daily periodic trends and non-stationary long-term
>> trends. I would love to decompose this using basic time series analysis.
>>
>> However, every time I attempt decomposition, I get the
>>
>> Error in decompose( ) : time series has no or less than 2 periods
>>
>> Is it only possible to do basic time-series analysis if you have a year or
>> more worth of data? That seems absurd to me, since there is definite
>> periodicity and the data are a time series. I have tried every manner of
>> specifying frequency= with no luck (96 does not work). All manner of
>> searching for help has turned up fruitless.
>>
>> Can I only do this after I wait another year or two?
>>
>> Thanks,
>> Ryan
>>
>> --
>>
>> Ryan Utz, Ph.D.
>> Assistant professor of water resources
>> *chatham**UNIVERSITY*
>> Home/Cell: (724) 272-7769
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Wed Mar 30 17:31:43 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Wed, 30 Mar 2016 10:31:43 -0500
Subject: [R] installing packages
In-Reply-To: <42B66F6C-E061-4BCF-A18B-F32001E58658@dcn.davis.ca.us>
References: <CABPq8JOnSQdN+tk1RHX1JD7g0XY7P9HgiK1NcPbPRp+fPG4PfQ@mail.gmail.com>
	<65BFF5D6-48D1-4B4B-AD0E-61537ED8ECEC@gmail.com>
	<42B66F6C-E061-4BCF-A18B-F32001E58658@dcn.davis.ca.us>
Message-ID: <CABPq8JPCnKZxu5b2D_aA=FcpVprYbxa+fX2q6q5qtKGjnK5f_g@mail.gmail.com>

To All,
Thanks for your help.

I uninstalled R, the 3.2 library and R Studio.  Reinstalled R and R Studio.
Now the temp files move the newly installed packages into the
R-.23.2.4revised library.

> .libPaths()
[1] "C:/Users/james_henson/Desktop/Documents/R/win-library/3.2"
[2] "C:/Program Files/R/R-3.2.4revised/library"





On Mon, Mar 21, 2016 at 9:57 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I hope not. That directory is not for working in. suggestion to restart R
> sounds most likely to fix the issue.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 21, 2016 2:10:01 PM PDT, KMNanus <kmnanus at gmail.com> wrote:
>>
>> Have you set your working directory to the ?3.2? folder?
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>>
>>
>>
>>  On Mar 21, 2016, at 5:07 PM, James Henson <jfhenson1 at gmail.com> wrote:
>>>
>>>  Dear R community,
>>>
>>>  When I install or update a package, R prints the waring below.  I go to the
>>>  ?downloaded_packages? folder in the Temp file and manually move the new or
>>>  updated package to the folder ?3.2?.   How can I instruct R to download new
>>>  and updates packages into the ?3.2? folder?
>>>
>>>  Warning in install.packages :
>>>
>>>   unable to move temporary installation
>>>  ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\file1c5c6f1731c8\nlme?
>>>  to ?C:\Users\james_henson\Desktop\Documents\R\win-library\3.2\nlme
>>>
>>>
>>>
>>>  The downloaded binary packages are in
>>>
>>>
>>>  C:\Users\james_henson\AppData\Local\Temp\RtmpIZmUa3\downloaded_packages
>>>
>>>
>>>
>>>  Thank for your help.
>>>
>>>  James F. Henson
>>>
>>>   [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Mar 30 17:37:47 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 30 Mar 2016 10:37:47 -0500
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAGxFJbQyx4AMFbEfPszOC=B0_r7-HnXfPyi4xALHNNdWYtU4VQ@mail.gmail.com>
References: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
	<CAGxFJbROoU1=xvBSagbEkFeovoaV2W_P28EOjiM6gJUEjutDxA@mail.gmail.com>
	<CAGxFJbQyx4AMFbEfPszOC=B0_r7-HnXfPyi4xALHNNdWYtU4VQ@mail.gmail.com>
Message-ID: <CAPPM_gRcw-XA6GS-e5Q62+oUKcU_SRwnnc9Fv=8SY5xEBK6Rjw@mail.gmail.com>

On Wed, Mar 30, 2016 at 10:29 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I "think" the problem is that you failed to set the "frequency"
> attribute of your time series, so it defaults to 1. A time series with
> one observation per period cannot be decomposed, since the error term
> is confounded with the "seasonality", which is essentially your error
> message.
>
> Again, a guess, as you provided no code.
>
Another guess is that you're running into issues with converting xts
to/from ts.  That currently doesn't work well, so you should convert
to zoo and make sure your frequency attribute makes sense before
attempting to decompose.

> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 30, 2016 at 8:18 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Code please.
>>
>> Reproducible example?(e.g. 1st 100 values)
>>
>> "PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code."
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>>> Hello,
>>>
>>> I have a time series that represents data sampled every 15-minutes. The
>>> data currently run from November through February, 8623 total readings.
>>> There are definitely daily periodic trends and non-stationary long-term
>>> trends. I would love to decompose this using basic time series analysis.
>>>
>>> However, every time I attempt decomposition, I get the
>>>
>>> Error in decompose( ) : time series has no or less than 2 periods
>>>
>>> Is it only possible to do basic time-series analysis if you have a year or
>>> more worth of data? That seems absurd to me, since there is definite
>>> periodicity and the data are a time series. I have tried every manner of
>>> specifying frequency= with no luck (96 does not work). All manner of
>>> searching for help has turned up fruitless.
>>>
>>> Can I only do this after I wait another year or two?
>>>
>>> Thanks,
>>> Ryan
>>>
>>> --
>>>
>>> Ryan Utz, Ph.D.
>>> Assistant professor of water resources
>>> *chatham**UNIVERSITY*
>>> Home/Cell: (724) 272-7769
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From utz.ryan at gmail.com  Wed Mar 30 17:43:34 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Wed, 30 Mar 2016 11:43:34 -0400
Subject: [R] ts or xts with high-frequency data within a year
Message-ID: <CAKJ8KVgoTgbgJTi377VvYF9fVjZ++h3-LfM_1usxqE-nr1bWyA@mail.gmail.com>

Sorry about not providing code; I didn't think to just simulate dummy code.

Here's a situation where I have <1 year of data, hourly time sampling, and
the error that I get using my actual data:

###

X=as.data.frame(1:6000)
X[2]=seq.POSIXt(ISOdate(2015,11,1),by='hour',length.out=6000)
X[3]=sample(100,size=6000,replace=T)

Y=xts(X[,3],order.by=X[,2])
decompose(Y)

Z=ts(X[,2],start=c(2015,11),frequency=24*365)
plot(decompose(Z))

###

Am I missing something obvious here? I hope so...

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From rubeldas at yahoo.com  Wed Mar 30 07:35:30 2016
From: rubeldas at yahoo.com (Rubel Das)
Date: Wed, 30 Mar 2016 05:35:30 +0000 (UTC)
Subject: [R] difficult to find index value
References: <1322572236.216169.1459316130261.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1322572236.216169.1459316130261.JavaMail.yahoo@mail.yahoo.com>

?Dear R group memberI tried couple of hours to figure out the solution of following.match function behaves strange from value 0.7 and 1.7

> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .6, periodlimint)> indexAtest[1] 6> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .7, periodlimint)> indexAtest[1] NA> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .8, periodlimint)> indexAtest[1] 8> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( 1.7, periodlimint)> indexAtest[1] NA
it will be helpful if you provide your comment
RegardsRubel?

	[[alternative HTML version deleted]]


From prieto.anamaria at gmail.com  Wed Mar 30 11:59:35 2016
From: prieto.anamaria at gmail.com (=?UTF-8?Q?Ana_Mar=C3=ADa_Prieto?=)
Date: Wed, 30 Mar 2016 11:59:35 +0200
Subject: [R] Multinomial mixed models with glmmADMB
Message-ID: <CABWDN=j6HnmEQjLY06H=UTv66kUQso3DvL3Ao2evL672HGNrOQ@mail.gmail.com>

Dear r-helpers,

I want to run a multinomial mixed effects model with the glmmADMB package
of R. I have read the available information of the programm but i couldn't
find which family or link has to be used for multinomial data. In the
examples are only shown models with Poisson, negative binomial and
truncated binomial /poisson families.

Use of this package for multinomial mixed models has already been published
(http://www.sciencedirect.com/science/article/pii/S0378112715007288).

Thanks a lot in advance for your answers.

Ana

-- 
Ana Mar?a Prieto Ram?rez
PhD student
Departement of Conservation Biology
Center for Environmental Research UFZ, Leipzig
Zoologisches Forschungsmuseum Alexander Koenig
University of Bonn

	[[alternative HTML version deleted]]


From jonathan.halls at rocketmail.com  Wed Mar 30 13:46:54 2016
From: jonathan.halls at rocketmail.com (Jonathan Halls)
Date: Wed, 30 Mar 2016 11:46:54 +0000 (UTC)
Subject: [R] Problems with pooling Multiply Imuputed datasets,
 of a multilevel logistic model, using (MICE)
References: <2068068560.2496954.1459338414186.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2068068560.2496954.1459338414186.JavaMail.yahoo@mail.yahoo.com>

I am having problems with the MICE package in R, particularity with pooling the imputed data sets.
I am running a multilevel binomial logistic regression, with Level1 - topic (participant response to 10 questions on different topics, e.g. T_Darkness, T_Day) nested within Level2 - individuals. 
The model is created using R2MLwiN, the formula is 
> fit1 <-runMLwiN( c(probit(T_Darkness, cons), probit(T_Day, cons), probit(T_Light, cons), probit(T_Night, cons), probit(T_Rain, cons), probit(T_Rainbows, cons), probit(T_Snow, cons), probit(T_Storms, cons), probit(T_Waterfalls, cons), probit(T_Waves, cons)) ~ 1, D=c("Mixed", "Binomial", "Binomial","Binomial","Binomial", "Binomial", "Binomial", "Binomial", "Binomial", "Binomial" ,"Binomial"), estoptions = list(EstM = 0), data=data)Unfortunately, there is missing data in all of the Level1 (topic) responses. I have been using the mice package ([CRAN][1]) to multiply impute the missing values. 
I can fit the model to the imputed datasets, using the formula 
> fitMI <- (with(MI.Data, runMLwiN( c(probit(T_Darkness, cons), probit(T_Day, cons), probit(T_Light, cons), probit(T_Night, cons), probit(T_Rain, cons), probit(T_Rainbows, cons), probit(T_Snow, cons), probit(T_Storms, cons), probit(T_Waterfalls, cons), probit(T_Waves, cons)) ~ 1, D=c("Mixed", "Binomial", "Binomial","Binomial","Binomial", "Binomial", "Binomial", "Binomial", "Binomial", "Binomial" ,"Binomial"), estoptions = list(EstM = 0), data=data)))
 However, when I come to pool the analyses with the call code > pool(fitMI) it fails, with the Error:Error in pool(with(tempData, runMLwiN(c(probit(T_Darkness, cons), probit(T_Day, : Object has no coef() method.
I am not sure why it is saying there is no coefficient, as the analyses of the individual MI datasets provide both fixed parts (coefficients) and random parts (covariances)
Any help with what is going wrong would be much appreciated. I should warn you that this is my first foray into using R and multilevel modelling. Also I know there is a MlwiN package ([REALCOM][2]) that can do this but I don't have the background to use the MLwiN software outside of R.
thanks
johnny

?R reproducible example
Libraries used
 > library(R2MLwiN) > library(mice)
Subset of data`
 > T_Darkness <- c(0, 1, 0, 0, 0, 0, 0, 1, 0, 0, NA, 0, 0, 0, NA, 1, 0, NA,NA, 1, 0, 0, 0, 1, 0, 0, 0, NA, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, NA, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, NA, 1, 0) 
> T_Day <- c(0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, NA, 0, 0, 0, 0, NA, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, NA, NA, 0) 
> T_Light <- c(0, 0, NA, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, NA, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0) 
> T_Night <- c(0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,NA, 0, NA, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, NA, 0, 0) 
> T_Rain <- c(1, 0, 0, 1, 1, 0, 0, NA, 0, 1, 0, 0, 1, 0, 0, 0, 0, NA, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, NA, 0, 0, 0, 0, 1, 0, 0, 0, NA, 1, NA, 0, 0, 0, 0, 1, NA, 1, 0, 0, 0, 0, 1, NA, 0, 0) 
> T_Rainbows <- c(1, 1, 1, 1, 0, 1, 0, 1, 0, 1, NA, 1, 1, 0, 0, 1, 0, NA, 0, 1, 0, NA, 0, 1, 0, 0, 0, 0, 0, NA, 0, 0, 0, NA, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, NA, 1, 0, 1, NA, 0, 0, 1, 0, 1, 1, 1, 0, 1) 
> T_Snow <- c(0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, NA, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, NA, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, NA, 0, 0, 1, NA, 1, 0, 1, 1, 0, 0, 0, 0, 0, NA, 0, 0, 0) 
> T_Storms <- c(0, 0, 0, 1, 1, 1, 0, 1, 0, 1, NA, 0, 0, 0, 0, 1, 0, NA, 0, 0, 1, 0, 0, NA, 1, 1, NA, 0, 0, NA, 0, 1, 0, NA, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, NA, 1, 0, NA, 0, 0, 0, 1, 1, 0, 1, NA, NA, 1) 
> T_Waterfalls <- c(0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, 1, 0, NA, 1, 0, 1, 0, 0, 0, NA, 0, 0, 0, NA, NA, 0) 
> T_Waves <- c(0, 1, 0, 1, 1, 0, 1, NA, 0, 0, NA, 0, 0, 0, NA, 1, 0, 0, 0, 0, 1, 0, NA, 0, NA, 0, 0, NA, 0, 0, 0, 0, 0, 0, NA, 1, 0, 0, 0, 1, 0, 0, NA, 0, 1, 0, 0, 0, 0, 0, 1, 1, NA, 1, 1, NA, 0, 0, 0, NA, 0, 0, 0, NA, 0, 0) 
> data <- data.frame (T_Darkness, T_Day, T_Light, T_Night, T_Rain, T_Rainbows, T_Snow, T_Storms, T_Waterfalls, T_Waves) 
> data$cons <- 1

Data imputed using mice with
 > MI.Data <- mice(data,m=5,maxit=50,meth='pmm',seed=500)

	[[alternative HTML version deleted]]


From ehandler at macalester.edu  Wed Mar 30 16:45:52 2016
From: ehandler at macalester.edu (Eric Handler)
Date: Wed, 30 Mar 2016 09:45:52 -0500
Subject: [R] fftImg() error: fftw_access_func
In-Reply-To: <516653E1-A56B-4337-9589-3E556EEA4E58@comcast.net>
References: <CAHr=b60TpzWc=6bb_U3ZvXeHgvSULz2ieAEi6wDSuo4wxX5MEg@mail.gmail.com>
	<5362F4C2891.000001A0jrkrideau@inbox.com>
	<182643837.1037880.1459006921861.JavaMail.yahoo@mail.yahoo.com>
	<516653E1-A56B-4337-9589-3E556EEA4E58@comcast.net>
Message-ID: <CAHr=b60TkLU_KuiofPBjOaUZ3HX-W_hN9Gx=gMWbqTuPjk+mKA@mail.gmail.com>

Took me a few days to get a reply from the student. The code he is running is:

library(ripa)

img<-readJPEG( "arthurs-seat.jpg" )
hist(fftImg(img))

I see the same error as the student on many systems. When I run
require(ripa) on the machine I mentioned before:

> require('ripa')
Loading required package: ripa
Loading required package: tcltk
Loading required package: parallel

>img<-readJPEG( "arthurs-seat.jpg" )
>hist(fftImg(img))
Error in .C("fftw_access_func", as.complex(img), as.integer(w),
as.integer(h),  :
  "fftw_access_func" not available for .C() for package "ripa"

If I should take the conversation off of r-help as I loop in the
package maintainer, please let me know.

Thanks,
Eric

--
Eric Handler
Academic Information Associate - Science Division
Macalester College - Saint Paul, MN
Olin-Rice 124
Office: 651-696-6016
View my calendar: http://goo.gl/SbxLOu

On Sat, Mar 26, 2016 at 2:23 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Mar 26, 2016, at 8:42 AM, Shelby Leonard via R-help <r-help at r-project.org> wrote:
>>
>> So do i need to resend the email to someone else? sorry i am just confused
>
> Perhaps.
>
> The code needed to find the maintainer is at the end of this scrape of a console "dialog" and scroll to the bottom if you want the proper address for reporting problems with package:ripa,
>
> .... but _first_ you should be checking to see if you have all the system dependencies:
>
>
>> require(ripa)
> Loading required package: ripa
> Loading required package: tcltk
> Loading required package: parallel
>
> Attaching package: ?ripa?
>
> The following object is masked from ?package:rms?:
>
>     contrast
>
> The following object is masked from ?package:Hmisc?:
>
>     zoom
>
>> packageDescription("ripa")
> Package: ripa
> Version: 2.0-2
> Date: 2014-05-29
> Title: R Image Processing and Analysis
> Authors at R: c(person("Talita", "Perciano", role = c("aut", "cre"),
>        email = "talitaperciano at gmail.com"), person("Alejandro", "C
>        Frery", role = "ctb", email = "acfrery at pq.cnpq.br"))
> Maintainer: Talita Perciano <talitaperciano at gmail.com>
> Depends: R (>= 2.8.1), tcltk, parallel
> Suggests: e1071, rggobi, reshape, methods, jpeg, png, tkrplot,
>        fftw, foreach, doSNOW
> Enhances: doMC
> SystemRequirements: BWidget, Tktable, Img, libjpeg
>
> # ============
> # My guess is that you do not have all of the systemRequirements on this machine.
> # Or if you do, then perhaps they are not in a directory in which the package expects to find them.
> # =============
>
> Description: A package including various functions for image
>        processing and analysis. With this package is possible to
>        process and analyse RGB, LAN (multispectral) and AVIRIS
>        (hyperspectral) images. This packages also provides
>        functions for reading JPEG files, extracted from the
>        archived 'rimage' package.
> License: GPL (>= 2) | file LICENSE
> Imports: Rcpp (>= 0.11.0)
> LinkingTo: Rcpp
> URL: http://www.r-project.org
> Packaged: 2014-05-30 20:18:57 UTC; Talita Perciano
> Author: Talita Perciano [aut, cre], Alejandro C Frery [ctb]
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2014-05-31 01:32:57
> Built: R 3.2.0; x86_64-apple-darwin13.4.0; 2015-04-21 02:07:55
>        UTC; unix
>
> -- File: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/ripa/Meta/package.rds
>> ? fftImg
>>   data(logo)
>>   plot(normalize(fftImg(logo)))
> Error in .C("fftw_access_func", as.complex(img), as.integer(w), as.integer(h),  :
>   "fftw_access_func" not available for .C() for package "ripa"
>
>> require(fftw)
> Loading required package: fftw
>
> # Tried that thinking (Incorrectly) the missing routine might be supplied in that package.
>
>> data(logo)
>>   plot(normalize(fftImg(logo)))
> Error in .C("fftw_access_func", as.complex(img), as.integer(w), as.integer(h),  :
>   "fftw_access_func" not available for .C() for package "ripa"
>> maintainer('ripa')
> [1] "Talita Perciano <talitaperciano at gmail.com>"
>
> --
>
> David
>
>
>>
>>    On Saturday, March 26, 2016 9:21 AM, John Kane <jrkrideau at inbox.com> wrote:
>>
>>
>> It would be helpful if you actually supplied your code and a minimal data set to for people to examine.
>>
>> Please have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html.
>>
>> I'm not clear if you are reporting a general R problem or a specific package with the ripa package.  If it looks like it is the latter you probably bring it to the attention of the package maintainer who may or may not monitor this mailing group.
>>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: ehandler at macalester.edu
>>> Sent: Fri, 25 Mar 2016 15:09:42 -0500
>>> To: r-help at r-project.org
>>> Subject: [R] fftImg() error: fftw_access_func
>>>
>>> Hello-
>>>
>>> My name is Eric Handler and I am an academic technologist supporting
>>> the Science Division(7 academic departments) at Macalester College in
>>> Saint Paul, MN. The faculty use R for a variety of teaching and
>>> research tasks around campus. I administer our RStudio instance and
>>> have encountered an error I can't resolve. A student working on an
>>> independent research project has reported that he received the
>>> following error when attempting to use the ripa function fftImg():
>>>
>>> Error in .C("fftw_access_func", as.complex(img), as.integer(w),
>>> as.integer(h),  :
>>>   "fftw_access_func" not available for .C() for package "ripa"
>>>
>>> I've been able to recreate this error in RStudio as well as directly
>>> in R. I've also recreated the error across different platforms(Ubuntu,
>>> Mac OS X 10.10 and 10.11). My test platform's sessionInfo() output is
>>> below:
>>>
>>> R version 3.2.3 (2015-12-10)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.11.3 (El Capitan)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] parallel  tcltk    stats    graphics  grDevices utils    datasets
>>> [8] methods  base
>>>
>>> other attached packages:
>>> [1] fftw_1.0-3 ripa_2.0-2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.2.3 Rcpp_0.12.3
>>>
>>> A google search for "fftw_access_func" doesn't reveal anything modern
>>> on this topic, only mentions of OS 10.4 and 10.5 and rimage, which
>>> doesn't seem to exist anymore(perhaps it was a predecessor to RIPA?)
>>>
>>> Can someone help me get the student functional with fftImg() or
>>> alternately, tell me it is a known issue and an alternative option(if
>>> available) for the student?
>>>
>>> Thanks,
>>> Eric
>>>
>>> --
>>> Eric Handler
>>> Academic Information Associate - Science Division
>>> Macalester College - Saint Paul, MN
>>> Olin-Rice 124
>>> Office: 651-696-6016
>>> View my calendar: http://goo.gl/SbxLOu
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> [[elided Yahoo spam]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From murdoch.duncan at gmail.com  Wed Mar 30 18:46:50 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Mar 2016 12:46:50 -0400
Subject: [R] R logo size in package information tab of Rstudio
In-Reply-To: <56FADAA5.2040302@yahoo.fr>
References: <56FADAA5.2040302@yahoo.fr>
Message-ID: <56FC02FA.4090704@gmail.com>

On 29/03/2016 3:42 PM, Marc Girondot via R-help wrote:
> Two different sizes of R logo are shown in Rstudio in the Help at the
> package level.
>
> For example, numderiv shows a nice discreet logo located at (in MacosX):
> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/logo.jpg
> whereas packrat shows a huge logo located at:
> /Library/Frameworks/R.framework/Versions/3.3/Resources/doc/html/Rlogo.svg
>
> The choice between both depends on the path indicated in the file
> Index.html located in html folder for each package.
>
> It would be better to have svg version of Rlogo.svg of the same size
> than logo.jpg (I have converted the Rlogo.svg into the same size than
> logo.jpg and it looks much better whit the new version).

I've now managed to duplicate this.  It's an RStudio bug, not an R bug.  
They are not using the R.css file that sets the size of the logo (or 
perhaps they're using an older version of it).

I'm not completely up to date on RStudio, so it may be that you can fix 
it by updating.  I've bcc'd support at RStudio to let them know about 
this; not sure if that will get through.

Duncan Murdoch


From wdunlap at tibco.com  Wed Mar 30 19:03:03 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Mar 2016 10:03:03 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
References: <CAKJ8KVjuxUcX82O1KHVhTct1ZVTMn3BANYA4L594Q0=QP7Bzfw@mail.gmail.com>
Message-ID: <CAF8bMcaMCwEqNSnwnxgQ44Oi6K0ovYDJdA+-MOexxvKUVdQ37w@mail.gmail.com>

You said you specified frequency=96 when you constructed the time
series, but when I do that the decomposition looks reasonable:

> time <- seq(0,9,by=1/96) # 15-minute intervals, assuming time unit is day
> measurement <- sqrt(time) + 1/(1.2+sin(time*2*pi)) +
rnorm(length(time),0,.3)
> plot(decompose(ts(measurement, frequency=96)))

How is your code different from the above?



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:

> Hello,
>
> I have a time series that represents data sampled every 15-minutes. The
> data currently run from November through February, 8623 total readings.
> There are definitely daily periodic trends and non-stationary long-term
> trends. I would love to decompose this using basic time series analysis.
>
> However, every time I attempt decomposition, I get the
>
> Error in decompose( ) : time series has no or less than 2 periods
>
> Is it only possible to do basic time-series analysis if you have a year or
> more worth of data? That seems absurd to me, since there is definite
> periodicity and the data are a time series. I have tried every manner of
> specifying frequency= with no luck (96 does not work). All manner of
> searching for help has turned up fruitless.
>
> Can I only do this after I wait another year or two?
>
> Thanks,
> Ryan
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Mar 30 19:21:05 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 30 Mar 2016 13:21:05 -0400
Subject: [R] difficult to find index value
In-Reply-To: <1322572236.216169.1459316130261.JavaMail.yahoo@mail.yahoo.com>
References: <1322572236.216169.1459316130261.JavaMail.yahoo.ref@mail.yahoo.com>
	<1322572236.216169.1459316130261.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+vqiLGaM0nOg6CSCnGG6S_cmiKfExgxi-2x_4oWb=sMS1rBSA@mail.gmail.com>

FAQ 7.31 I think. Here are a couple things you can try.

close_enough <- function(x, y) isTRUE(all.equal(x, y))

periodlimint<-seq(from=0.1, to=50, by=0.1)

indexAtest <- which(sapply(periodlimint, close_enough, y = 0.7))

match( as.character(.7), periodlimint)

Best,
Ista

On Wed, Mar 30, 2016 at 1:35 AM, Rubel Das via R-help
<r-help at r-project.org> wrote:
>  Dear R group memberI tried couple of hours to figure out the solution of following.match function behaves strange from value 0.7 and 1.7
>
>> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .6, periodlimint)> indexAtest[1] 6> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .7, periodlimint)> indexAtest[1] NA> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( .8, periodlimint)> indexAtest[1] 8> periodlimint<-seq(from=0.1, to=50, by=0.1)> indexAtest<-match( 1.7, periodlimint)> indexAtest[1] NA
> it will be helpful if you provide your comment
> RegardsRubel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jan.kacaba at gmail.com  Wed Mar 30 21:42:47 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 30 Mar 2016 21:42:47 +0200
Subject: [R] Accented characters, windows
In-Reply-To: <56FB0805.9060706@gmail.com>
References: <CAHby=D0oUKa9mNyLR7mSHTGtZC1tHzEipt2cy2BJPnEPTE3YqQ@mail.gmail.com>
	<56FB0805.9060706@gmail.com>
Message-ID: <CAHby=D0zKSF16BgD7zqAsoUOs=1SCrx_-Trn4ZCADCV-ZfzhTg@mail.gmail.com>

Duncun, thank you for your reply. My encoding is:

> Sys.getlocale('LC_CTYPE')
[1] "Czech_Czech Republic.1250"

In RStudio I use UTF-8. I tried also other recommended encodings but some
characters are still misrepresented.

I've found solution to this. To correctly display strings in RStudio I have
to convert strings:
iconv(x,"CP1250","UTF-8")

If I want to write string into file:
zz=file("myfile.txt", "w", encoding="UTF-8")
cat(x,file = zz, sep = "\n")

It seems there is no need using icon() if I just need to write string to a
file.

I hope there is no problem processing strings with other functions like
paste, strsplit, grep though.

Derek

2016-03-30 0:56 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 29/03/2016 5:39 PM, Jan Kacaba wrote:
>
>> I have problem with accented characters. My OS is Win 8.1 and I'm using
>> RStudio.
>>
>> I make string :
>> av="?????"
>>
>> When I call "av" I get result bellow.
>>
>>> av
>>>
>> [1] "?????"
>>
>> The resulting characters are different. I have similar problem when I
>> write
>> string to a file. In RGUI if I call "av" it prints characters correctly,
>> but using "write" function to print string in a file results in the same
>> problem.
>>
>> Can you please help me how to deal with it?
>>
>
> You don't say what code page you're using.
>
> R in Windows has a long standing problem that it works mainly in the local
> code page, rather than working in UTF-8 as most other systems do.  (This is
> due to the fact that when the internationalization was put in, UTF-8 was
> exotic, rather than ubiquitous as it is now.)  So R can store UTF-8 strings
> on any system, but for display it converts them to the local code page, and
> that conversion can lose information if the characters aren't supported
> locally.
>
> With your string, I don't see the same thing as you, I see
>
> "e?cr?"
>
> which is also incorrect, but looks a little closer, because it does a
> better approximation in my code page.
>
> So if you think my result is better than yours, you could change your
> system to code page 437 as I'm using, but that will probably cause you
> worse problems.
>
> Probably the only short term solution that would be satisfactory is to
> stop using Windows.  At some point in the future the internal character
> handling in R needs an overhaul, but that's a really big, really thankless
> job.  Perhaps Microsoft/Revolution will donate some programmer time to do
> it, but more likely, it will wait for volunteers in R Core to do it.  I
> don't think it will happen in 2016.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From javanmard.majid at gmail.com  Wed Mar 30 23:04:01 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Thu, 31 Mar 2016 01:34:01 +0430
Subject: [R]  Bagging Question
Message-ID: <CAA0OCnsUjhV=MbyGsJARBkm8pgGZ0x-o61pncZ9k2tMJoeaqAg@mail.gmail.com>

Hello

here is the  code implements bagging that I copied from net (
http://www.r-bloggers.com/improve-predictive-performance-in-r-with-bagging/)
:

set.seed(10)
y<-c(1:1000)
x1<-c(1:1000)*runif(1000,min=0,max=2)
x2<-c(1:1000)*runif(1000,min=0,max=2)
x3<-c(1:1000)*runif(1000,min=0,max=2)

lm_fit<-lm(y~x1+x2+x3)
summary(lm_fit)

set.seed(10)
all_data<-data.frame(y,x1,x2,x3)
positions <- sample(nrow(all_data),size=floor((nrow(all_data)/4)*3))
training<- all_data[positions,]
testing<- all_data[-positions,]

lm_fit<-lm(y~x1+x2+x3,data=training)
predictions<-predict(lm_fit,newdata=testing)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))

library(foreach)
length_divisor<-4
iterations<-1000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
  training_positions <- sample(nrow(training),
size=floor((nrow(training)/length_divisor)))
  train_pos<-1:nrow(training) %in% training_positions
  lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
  predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))


1) How to rank in sequence  Training and Testing in a column ?!
2) How can I have prediction interval for each predicted value ?!

Thanks

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar 30 23:06:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Mar 2016 14:06:05 -0700
Subject: [R] Convergence issues when using ns splines (pkg: spline) in
	Cox model (coxph) even when changing coxph.control
In-Reply-To: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
References: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
Message-ID: <B546726A-64CB-4AC0-A634-9696061450B0@comcast.net>


> On Mar 29, 2016, at 1:47 PM, Jennifer Wu, Miss <jennifer.wu2 at mail.mcgill.ca> wrote:
> 
> Hi,
> 
> I am currently using R v3.2.3 and on Windows 10 OS 64Bit.
> 
> I am having convergence issues when I use coxph with a interaction term (glarg*bca_py) and interaction term with the restricted cubic spline (glarg*bca_time_ns). I use survival and spline package to create the Cox model and cubic splines respectively. Without the interaction term and/or spline, I have no convergence problem. I read some forums about changing the iterations and I have but it did not work. I was just wondering if I am using the inter.max and outer.max appropriately. I read the survival manual, other R-help and stackoverflow pages and it suggested changing the iterations but it doesn't specify what is the max I can go. I ran something similar in SAS and did not run into a convergence problem.
> 
> This is my code:
> 
> bca_time_ns <- ns(ins_ca$bca_py, knots=3, Boundary.knots=range(2,5,10))
> test <- ins_ca$glarg*ins_ca$bca_py
> test1 <- ins_ca$glarg*bca_time_ns

In your `coxph` call the variable 'bca_py' is the survival time and yet here you are constructing not just one but two interactions (one of which is a vector but the other one a matrix) between 'glarg' and your survival times. Is this some sort of effort to identify a violation of proportionality over the course of a study?

Brostr?m sagely points out that these interactions are not in the data-object and subsequent efforts to refer to them may be confounded by the multiple environments from which data would be coming into the model. Better to have everything come in from the data-object.

The fact that SAS did not have a problem with this rather self-referential or circular model may be a poor reflection on SAS rather than on the survival package. Unlike Therneau or Brostr?m who asked for data, I suggest the problem lies with the model construction and you should be reading what Therneau has written about identification of non-proportionality and identification of time dependence of effects. See Chapter 6 of his "Modeling Survival Data".

-- 

David Winsemius
Alameda, CA, USA
> 
> coxit <- coxph.control(iter.max=10000, outer.max=10000)
> 
> bca<-coxph(Surv(bca_py,bca) ~ glarg + test + test1 + age + calyr + diab_dur + hba1c + adm_met + adm_sulfo + adm_tzd + adm_oth +
>            med_statin + med_aspirin + med_nsaids + bmi_cat + ccscat + alc + smk, data=ins_ca, control=coxit, ties=c("breslow"))
> 
> 
> This is the error message I get:
> 
> Warning message:
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :
>  Ran out of iterations and did not converge
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From javanmard.majid at gmail.com  Wed Mar 30 23:13:21 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Thu, 31 Mar 2016 01:43:21 +0430
Subject: [R] Boosting Algorithm for Regression (Adaboost.R2)
Message-ID: <CAA0OCnvVON0=FWsoxvO7btJJwWKdBgoAQK1qMzqpJberH3VBFw@mail.gmail.com>

Hello

I am new to R , Is there any code to run Adaboost.R2 in r ?!
I wrote a code from example of gbm package, but I can not have prediction
interval would you help me ?!


library(gbm)
mm <- read.table("E:/bagg.txt",TRUE)
xnam <- paste("x", 1:50, sep="")
fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+")))
gbm1 <- gbm(fmla, data=mm, n.trees=100, distribution="gaussian",
interaction.depth=3, bag.fraction=0.5, train.fraction=1.0, shrinkage=0.1,
keep.data=TRUE)
pred <- predict(gbm1,n.trees=100)
pred <- as.data.frame(pred)


Thanks

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar 30 23:25:55 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 30 Mar 2016 14:25:55 -0700
Subject: [R] Boosting Algorithm for Regression (Adaboost.R2)
In-Reply-To: <CAA0OCnvVON0=FWsoxvO7btJJwWKdBgoAQK1qMzqpJberH3VBFw@mail.gmail.com>
References: <CAA0OCnvVON0=FWsoxvO7btJJwWKdBgoAQK1qMzqpJberH3VBFw@mail.gmail.com>
Message-ID: <CAGxFJbRmqBiWfdocoWmcXupWV7ss-0JH5uFrujV_91JdXMhZWQ@mail.gmail.com>

https://cran.r-project.org/web/views/MachineLearning.html

What do you mean by Prediction Interval? I doubt that this has clear
meaning in the boosting context. You might want to follow up this
statistical question on a statistical or machine learning list like
stats.stackexchange.com  .


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 30, 2016 at 2:13 PM, Majid Javanmard
<javanmard.majid at gmail.com> wrote:
> Hello
>
> I am new to R , Is there any code to run Adaboost.R2 in r ?!
> I wrote a code from example of gbm package, but I can not have prediction
> interval would you help me ?!
>
>
> library(gbm)
> mm <- read.table("E:/bagg.txt",TRUE)
> xnam <- paste("x", 1:50, sep="")
> fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+")))
> gbm1 <- gbm(fmla, data=mm, n.trees=100, distribution="gaussian",
> interaction.depth=3, bag.fraction=0.5, train.fraction=1.0, shrinkage=0.1,
> keep.data=TRUE)
> pred <- predict(gbm1,n.trees=100)
> pred <- as.data.frame(pred)
>
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Thu Mar 31 00:28:44 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Thu, 31 Mar 2016 00:28:44 +0200
Subject: [R] Convergence issues when using ns splines (pkg: spline) in
 Cox model (coxph) even when changing coxph.control
In-Reply-To: <B546726A-64CB-4AC0-A634-9696061450B0@comcast.net>
References: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
	<B546726A-64CB-4AC0-A634-9696061450B0@comcast.net>
Message-ID: <56FC531C.8000205@umu.se>



On 2016-03-30 23:06, David Winsemius wrote:
>
>> On Mar 29, 2016, at 1:47 PM, Jennifer Wu, Miss
>> <jennifer.wu2 at mail.mcgill.ca> wrote:
>>
>> Hi,
>>
>> I am currently using R v3.2.3 and on Windows 10 OS 64Bit.
>>
>> I am having convergence issues when I use coxph with a interaction
>> term (glarg*bca_py) and interaction term with the restricted cubic
>> spline (glarg*bca_time_ns). I use survival and spline package to
>> create the Cox model and cubic splines respectively. Without the
>> interaction term and/or spline, I have no convergence problem. I
>> read some forums about changing the iterations and I have but it
>> did not work. I was just wondering if I am using the inter.max and
>> outer.max appropriately. I read the survival manual, other R-help
>> and stackoverflow pages and it suggested changing the iterations
>> but it doesn't specify what is the max I can go. I ran something
>> similar in SAS and did not run into a convergence problem.
>>
>> This is my code:
>>
>> bca_time_ns <- ns(ins_ca$bca_py, knots=3,
>> Boundary.knots=range(2,5,10)) test <- ins_ca$glarg*ins_ca$bca_py
>> test1 <- ins_ca$glarg*bca_time_ns
>
> In your `coxph` call the variable 'bca_py' is the survival time and

Right David: I didn't notice that the 'missing main effect' in fact was 
part of the survival object! And as you say: Time to rethink the whole 
model.

G?ran

> yet here you are constructing not just one but two interactions (one
> of which is a vector but the other one a matrix) between 'glarg' and
> your survival times. Is this some sort of effort to identify a
> violation of proportionality over the course of a study?
>
> Brostr?m sagely points out that these interactions are not in the
> data-object and subsequent efforts to refer to them may be confounded
> by the multiple environments from which data would be coming into the
> model. Better to have everything come in from the data-object.
>
> The fact that SAS did not have a problem with this rather
> self-referential or circular model may be a poor reflection on SAS
> rather than on the survival package. Unlike Therneau or Brostr?m who
> asked for data, I suggest the problem lies with the model
> construction and you should be reading what Therneau has written
> about identification of non-proportionality and identification of
> time dependence of effects. See Chapter 6 of his "Modeling Survival
> Data".
>


From utz.ryan at gmail.com  Thu Mar 31 02:37:24 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Wed, 30 Mar 2016 20:37:24 -0400
Subject: [R] ts or xts with high-frequency data within a year
Message-ID: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>

Bill, Josh, and Bert,

Thanks for your responses. I still can't quite get this when I use actual
dates. Here's an example of what is going wrong:

X=as.data.frame(1:6000)
X[2]=seq.POSIXt(ISOdate(2015,11,1),by='hour',length.out=6000)
X[3]=sample(100,size=6000,replace=T)

Y=xts(X[,3],order.by=X[,2])
decompose(Y)

Z=ts(X[,2],frequency=24*365)
plot(decompose(Z))

When I specify an actual date/time (rather than just a number as Bill
posited), it does not like anything short of a year. This seems like I'm
overlooking something obvious, but I can't get this for the life of me...

Thanks for your time,
r


On Wed, Mar 30, 2016 at 1:03 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You said you specified frequency=96 when you constructed the time
> series, but when I do that the decomposition looks reasonable:
>
> > time <- seq(0,9,by=1/96) # 15-minute intervals, assuming time unit is day
> > measurement <- sqrt(time) + 1/(1.2+sin(time*2*pi)) +
> rnorm(length(time),0,.3)
> > plot(decompose(ts(measurement, frequency=96)))
>
> How is your code different from the above?
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>
>> Hello,
>>
>> I have a time series that represents data sampled every 15-minutes. The
>> data currently run from November through February, 8623 total readings.
>> There are definitely daily periodic trends and non-stationary long-term
>> trends. I would love to decompose this using basic time series analysis.
>>
>> However, every time I attempt decomposition, I get the
>>
>> Error in decompose( ) : time series has no or less than 2 periods
>>
>> Is it only possible to do basic time-series analysis if you have a year or
>> more worth of data? That seems absurd to me, since there is definite
>> periodicity and the data are a time series. I have tried every manner of
>> specifying frequency= with no luck (96 does not work). All manner of
>> searching for help has turned up fruitless.
>>
>> Can I only do this after I wait another year or two?
>>
>> Thanks,
>> Ryan
>>
>> --
>>
>> Ryan Utz, Ph.D.
>> Assistant professor of water resources
>> *chatham**UNIVERSITY*
>> Home/Cell: (724) 272-7769
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From normanmath1 at gmail.com  Thu Mar 31 00:56:26 2016
From: normanmath1 at gmail.com (Norman Pat)
Date: Thu, 31 Mar 2016 09:56:26 +1100
Subject: [R] R how to find outliers and zero mean columns?
Message-ID: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>

Hi team

I am new to R so please help me to do this task.

Please find the  attached data sample. But in the original data frame I
have 350 features and 400000 observations.

I need to carryout these tasks.

1. How to Identify features (names) that have all zeros?

2. How to remove features that have all zeros from the dataset?

3. How to identify features (names) that have outliers such as 99999,-1 in
the data frame.

4. How to remove outliers?


Many thanks

From dwinsemius at comcast.net  Thu Mar 31 03:20:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Mar 2016 18:20:16 -0700
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
Message-ID: <16154647-7D89-4926-8890-DA589A292901@comcast.net>


> On Mar 30, 2016, at 3:56 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> 
> Hi team
> 
> I am new to R so please help me to do this task.
> 
> Please find the  attached data sample.

No. Nothing attached. Please read the Rhelp Info page and the Posting Guide.

> But in the original data frame I
> have 350 features and 400000 observations.
> 
> I need to carryout these tasks.

Who is assigning you this task? Homework? (Read the Posting Guide.)

> 1. How to Identify features (names) that have all zeros?

That's generally pretty simple if "names" refers to columns in a dataframe.

> 
> 2. How to remove features that have all zeros from the dataset?

But maybe you mean to process by rows?


> 3. How to identify features (names) that have outliers such as 99999,-1 in
> the data frame.
> 
> 4. How to remove outliers?

You could start by defining "outliers" in something other than vague examples. If this is data from a real-life data gathering effort, then defining outliers would start with an explanation of the context.


> 
> 
> Many thanks

Please at least do the following "homework".

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jordanmeyer1991 at gmail.com  Thu Mar 31 03:37:01 2016
From: jordanmeyer1991 at gmail.com (Jordan Meyer)
Date: Wed, 30 Mar 2016 21:37:01 -0400
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
Message-ID: <CAF+g6rqPpNMZqRed8LEVJw57PTd=qov7NBb=1P9t6Zrn_yUS9A@mail.gmail.com>

I strongly suggest checking out some R tutorials. Most of these tasks are
basic data management that are likely covered in just about any tutorial.
I'm afraid that this isn't the appropriate forum for such basics.
On Mar 30, 2016 9:14 PM, "Norman Pat" <normanmath1 at gmail.com> wrote:

> Hi team
>
> I am new to R so please help me to do this task.
>
> Please find the  attached data sample. But in the original data frame I
> have 350 features and 400000 observations.
>
> I need to carryout these tasks.
>
> 1. How to Identify features (names) that have all zeros?
>
> 2. How to remove features that have all zeros from the dataset?
>
> 3. How to identify features (names) that have outliers such as 99999,-1 in
> the data frame.
>
> 4. How to remove outliers?
>
>
> Many thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Mar 31 04:13:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 31 Mar 2016 13:13:55 +1100
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
Message-ID: <CA+8X3fW2MGiCZgDRNQVuEY5SacG71B4gX0FbYVwFBmTF5jt9Wg@mail.gmail.com>

Hi Norman,
To check whether all values of an object (say "x") fulfill a certain
condition (==0):

all(x==0)

If your object (X) is indeed a data frame, you can only do this by
column, so if you want to get the results:

X<-data.frame(A=c(0,1:10),B=c(0,2:10,99999),
 C=c(0,-1,3:11),D=rep(0,11))
all_zeros<-function(x) return(all(x==0))
which_cols<-unlist(lapply(X,all_zeros))

If your data frame (or a subset) contains all numeric values, you can
finesse the problem like this:

which_rows<-apply(as.matrix(X),1,all_zeros)

What you get is a list of logical (TRUE/FALSE) values from lapply, so
it has to be unlisted to get a vector of logical values like you get
with "apply".

You can then use that vector to index (subset) the original data frame
by logically inverting it with ! (NOT):

X[,!which_cols]
X[!which_rows,]

Your "outliers" look suspiciously like missing values from certain
statistical packages. If you know the values you are looking for, you
can do something like:

NA99999<-X==99999

and then "remove" them by replacing those values with NA:

X[NA99999]<-NA

Be aware that all these hackles (diminutive of hacks) are pretty
specific to this example. Also remember that if this is homework, your
karma has just gone down the cosmic sinkhole.

Jim


On Thu, Mar 31, 2016 at 9:56 AM, Norman Pat <normanmath1 at gmail.com> wrote:
> Hi team
>
> I am new to R so please help me to do this task.
>
> Please find the  attached data sample. But in the original data frame I
> have 350 features and 400000 observations.
>
> I need to carryout these tasks.
>
> 1. How to Identify features (names) that have all zeros?
>
> 2. How to remove features that have all zeros from the dataset?
>
> 3. How to identify features (names) that have outliers such as 99999,-1 in
> the data frame.
>
> 4. How to remove outliers?
>
>
> Many thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Mar 31 04:25:12 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Mar 2016 19:25:12 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>
References: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>
Message-ID: <CAF8bMcbCS+o4TfCyxvbtNcekqSWz_aQwV4v1qpS+DrsTJXdz_g@mail.gmail.com>

decompose wants frequency(Y) to be more than 1 - it really wants an integer
frequency
so it can return a vector of that length containing the repeating pattern
(the "figure").

frequency(Y) is 1/3600 so you get the error (which might be better worded):

  > plot(decompose(Y))
  Error in decompose(Y) : time series has no or less than 2 periods
  >  frequency(Y)
  [1] 0.0002777778

Use a ts object and make the frequency relative to the period of interest
(e.g., 24 for hourly
data if you are interested in the daily pattern).




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 30, 2016 at 5:37 PM, Ryan Utz <utz.ryan at gmail.com> wrote:

> Bill, Josh, and Bert,
>
> Thanks for your responses. I still can't quite get this when I use actual
> dates. Here's an example of what is going wrong:
>
> X=as.data.frame(1:6000)
> X[2]=seq.POSIXt(ISOdate(2015,11,1),by='hour',length.out=6000)
> X[3]=sample(100,size=6000,replace=T)
>
> Y=xts(X[,3],order.by=X[,2])
> decompose(Y)
>
> Z=ts(X[,2],frequency=24*365)
> plot(decompose(Z))
>
> When I specify an actual date/time (rather than just a number as Bill
> posited), it does not like anything short of a year. This seems like I'm
> overlooking something obvious, but I can't get this for the life of me...
>
> Thanks for your time,
> r
>
>
> On Wed, Mar 30, 2016 at 1:03 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> You said you specified frequency=96 when you constructed the time
>> series, but when I do that the decomposition looks reasonable:
>>
>> > time <- seq(0,9,by=1/96) # 15-minute intervals, assuming time unit is
>> day
>> > measurement <- sqrt(time) + 1/(1.2+sin(time*2*pi)) +
>> rnorm(length(time),0,.3)
>> > plot(decompose(ts(measurement, frequency=96)))
>>
>> How is your code different from the above?
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>>
>>> Hello,
>>>
>>> I have a time series that represents data sampled every 15-minutes. The
>>> data currently run from November through February, 8623 total readings.
>>> There are definitely daily periodic trends and non-stationary long-term
>>> trends. I would love to decompose this using basic time series analysis.
>>>
>>> However, every time I attempt decomposition, I get the
>>>
>>> Error in decompose( ) : time series has no or less than 2 periods
>>>
>>> Is it only possible to do basic time-series analysis if you have a year
>>> or
>>> more worth of data? That seems absurd to me, since there is definite
>>> periodicity and the data are a time series. I have tried every manner of
>>> specifying frequency= with no luck (96 does not work). All manner of
>>> searching for help has turned up fruitless.
>>>
>>> Can I only do this after I wait another year or two?
>>>
>>> Thanks,
>>> Ryan
>>>
>>> --
>>>
>>> Ryan Utz, Ph.D.
>>> Assistant professor of water resources
>>> *chatham**UNIVERSITY*
>>> Home/Cell: (724) 272-7769
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Mar 31 04:43:14 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 31 Mar 2016 13:43:14 +1100
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAjNZ_iQNYCzoj2SYP6yj0j7__ga4M1hnRsqAyhzp3peXw@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
	<CA+8X3fW2MGiCZgDRNQVuEY5SacG71B4gX0FbYVwFBmTF5jt9Wg@mail.gmail.com>
	<CACCLHAjNZ_iQNYCzoj2SYP6yj0j7__ga4M1hnRsqAyhzp3peXw@mail.gmail.com>
Message-ID: <CA+8X3fW3LqwOZHBhpPKmvb41nNWejRPMumm7D-Dwt8F27Bsxmg@mail.gmail.com>

How about:

# if a data frame
names(X)[which_cols]

# and if you have rownames:
rownames(X)[which_rows]

My note about hackles was that packages generally don't know what
values are "abnormal" unless you specify them. Just like us. So you
have to specify what the range of "normal" values are, or what
specific values are "abnormal". There is a package named "outliers",
and while it would identify the 99999 value in the example I used, it
wouldn't do so for the -1.

Jim


On Thu, Mar 31, 2016 at 1:30 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> Hi Jim,
>     Thanks for your reply. I know these basic stuffs in R.
>
> But I want to know let say you have a data frame X with 300 features.
> From that 300 features I need to pullout the names of each feature
> that has zero values for all the observations in that sample.
>
> Here I am looking for a package or a function to do that.
>
> And how do I know whether there are abnormal values for each feature. Let
> say
> I have 300 features and 100000 observations. It is hard to look everything
> in the excel file. Instead of that I am looking for a package that does the
> work.
>
> I hope you understood.
>
> Thanks a lot
>
> Cheers
>
>
> On Thu, Mar 31, 2016 at 1:13 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Norman,
>> To check whether all values of an object (say "x") fulfill a certain
>> condition (==0):
>>
>> all(x==0)
>>
>> If your object (X) is indeed a data frame, you can only do this by
>> column, so if you want to get the results:
>>
>> X<-data.frame(A=c(0,1:10),B=c(0,2:10,99999),
>>  C=c(0,-1,3:11),D=rep(0,11))
>> all_zeros<-function(x) return(all(x==0))
>> which_cols<-unlist(lapply(X,all_zeros))
>>
>> If your data frame (or a subset) contains all numeric values, you can
>> finesse the problem like this:
>>
>> which_rows<-apply(as.matrix(X),1,all_zeros)
>>
>> What you get is a list of logical (TRUE/FALSE) values from lapply, so
>> it has to be unlisted to get a vector of logical values like you get
>> with "apply".
>>
>> You can then use that vector to index (subset) the original data frame
>> by logically inverting it with ! (NOT):
>>
>> X[,!which_cols]
>> X[!which_rows,]
>>
>> Your "outliers" look suspiciously like missing values from certain
>> statistical packages. If you know the values you are looking for, you
>> can do something like:
>>
>> NA99999<-X==99999
>>
>> and then "remove" them by replacing those values with NA:
>>
>> X[NA99999]<-NA
>>
>> Be aware that all these hackles (diminutive of hacks) are pretty
>> specific to this example. Also remember that if this is homework, your
>> karma has just gone down the cosmic sinkhole.
>>
>> Jim
>>
>>
>> On Thu, Mar 31, 2016 at 9:56 AM, Norman Pat <normanmath1 at gmail.com> wrote:
>> > Hi team
>> >
>> > I am new to R so please help me to do this task.
>> >
>> > Please find the  attached data sample. But in the original data frame I
>> > have 350 features and 400000 observations.
>> >
>> > I need to carryout these tasks.
>> >
>> > 1. How to Identify features (names) that have all zeros?
>> >
>> > 2. How to remove features that have all zeros from the dataset?
>> >
>> > 3. How to identify features (names) that have outliers such as 99999,-1
>> > in
>> > the data frame.
>> >
>> > 4. How to remove outliers?
>> >
>> >
>> > Many thanks
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From normanmath1 at gmail.com  Thu Mar 31 03:39:14 2016
From: normanmath1 at gmail.com (Norman Pat)
Date: Thu, 31 Mar 2016 12:39:14 +1100
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <16154647-7D89-4926-8890-DA589A292901@comcast.net>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
	<16154647-7D89-4926-8890-DA589A292901@comcast.net>
Message-ID: <CACCLHAjV6wrfs7dATXAd5tUegTC8tQus1LxkY3VmBPc7vUnC9g@mail.gmail.com>

Hi David,

> Please find the  attached data sample.

No. Nothing attached. Please read the Rhelp Info page and the Posting Guide.
*I attached it. Anyway I have attached it again (sample train.xlsx).*

Who is assigning you this task? Homework? (Read the Posting Guide.)
*This is my new job role so I have to do that. I know some basic R *

> 1. How to Identify features (names) that have all zeros?

That's generally pretty simple if "names" refers to columns in a data frame.
*You mean such as something like names(data.nrow(means==0))*

> 2. How to remove features that have all zeros from the dataset?

But maybe you mean to process by rows?
*in a column(feature) *

> 3. How to identify features (names) that have outliers such as 99999,-1 in
> the data frame.
*Please refer to the attached excel file*

> 4. How to remove outliers?

You could start by defining "outliers" in something other than vague
examples. If this is data from a real-life data gathering effort, then
defining outliers would start with an explanation of the context.
*By looking at data I need to find the outliers*

*Thanks *


On Thu, Mar 31, 2016 at 12:20 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 30, 2016, at 3:56 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> >
> > Hi team
> >
> > I am new to R so please help me to do this task.
> >
> > Please find the  attached data sample.
>
> No. Nothing attached. Please read the Rhelp Info page and the Posting
> Guide.
>
> > But in the original data frame I
> > have 350 features and 400000 observations.
> >
> > I need to carryout these tasks.
>
> Who is assigning you this task? Homework? (Read the Posting Guide.)
>
> > 1. How to Identify features (names) that have all zeros?
>
> That's generally pretty simple if "names" refers to columns in a dataframe.
>
> >
> > 2. How to remove features that have all zeros from the dataset?
>
> But maybe you mean to process by rows?
>
>
> > 3. How to identify features (names) that have outliers such as 99999,-1
> in
> > the data frame.
> >
> > 4. How to remove outliers?
>
> You could start by defining "outliers" in something other than vague
> examples. If this is data from a real-life data gathering effort, then
> defining outliers would start with an explanation of the context.
>
>
> >
> >
> > Many thanks
>
> Please at least do the following "homework".
>
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

From normanmath1 at gmail.com  Thu Mar 31 04:30:12 2016
From: normanmath1 at gmail.com (Norman Pat)
Date: Thu, 31 Mar 2016 13:30:12 +1100
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CA+8X3fW2MGiCZgDRNQVuEY5SacG71B4gX0FbYVwFBmTF5jt9Wg@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
	<CA+8X3fW2MGiCZgDRNQVuEY5SacG71B4gX0FbYVwFBmTF5jt9Wg@mail.gmail.com>
Message-ID: <CACCLHAjNZ_iQNYCzoj2SYP6yj0j7__ga4M1hnRsqAyhzp3peXw@mail.gmail.com>

Hi Jim,
    Thanks for your reply. I know these basic stuffs in R.

But I want to know let say you have a data frame X with 300 features.
>From that 300 features I need to pullout the names of each feature
that has zero values for all the observations in that sample.

Here I am looking for a package or a function to do that.

And how do I know whether there are abnormal values for each feature. Let
say
I have 300 features and 100000 observations. It is hard to look everything
in the excel file. Instead of that I am looking for a package that does the
work.

I hope you understood.

Thanks a lot

Cheers


On Thu, Mar 31, 2016 at 1:13 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Norman,
> To check whether all values of an object (say "x") fulfill a certain
> condition (==0):
>
> all(x==0)
>
> If your object (X) is indeed a data frame, you can only do this by
> column, so if you want to get the results:
>
> X<-data.frame(A=c(0,1:10),B=c(0,2:10,99999),
>  C=c(0,-1,3:11),D=rep(0,11))
> all_zeros<-function(x) return(all(x==0))
> which_cols<-unlist(lapply(X,all_zeros))
>
> If your data frame (or a subset) contains all numeric values, you can
> finesse the problem like this:
>
> which_rows<-apply(as.matrix(X),1,all_zeros)
>
> What you get is a list of logical (TRUE/FALSE) values from lapply, so
> it has to be unlisted to get a vector of logical values like you get
> with "apply".
>
> You can then use that vector to index (subset) the original data frame
> by logically inverting it with ! (NOT):
>
> X[,!which_cols]
> X[!which_rows,]
>
> Your "outliers" look suspiciously like missing values from certain
> statistical packages. If you know the values you are looking for, you
> can do something like:
>
> NA99999<-X==99999
>
> and then "remove" them by replacing those values with NA:
>
> X[NA99999]<-NA
>
> Be aware that all these hackles (diminutive of hacks) are pretty
> specific to this example. Also remember that if this is homework, your
> karma has just gone down the cosmic sinkhole.
>
> Jim
>
>
> On Thu, Mar 31, 2016 at 9:56 AM, Norman Pat <normanmath1 at gmail.com> wrote:
> > Hi team
> >
> > I am new to R so please help me to do this task.
> >
> > Please find the  attached data sample. But in the original data frame I
> > have 350 features and 400000 observations.
> >
> > I need to carryout these tasks.
> >
> > 1. How to Identify features (names) that have all zeros?
> >
> > 2. How to remove features that have all zeros from the dataset?
> >
> > 3. How to identify features (names) that have outliers such as 99999,-1
> in
> > the data frame.
> >
> > 4. How to remove outliers?
> >
> >
> > Many thanks
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar 31 05:25:06 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Mar 2016 20:25:06 -0700
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAjV6wrfs7dATXAd5tUegTC8tQus1LxkY3VmBPc7vUnC9g@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
	<16154647-7D89-4926-8890-DA589A292901@comcast.net>
	<CACCLHAjV6wrfs7dATXAd5tUegTC8tQus1LxkY3VmBPc7vUnC9g@mail.gmail.com>
Message-ID: <4DCE7C27-DAFD-4119-884D-392CB92C7A24@comcast.net>


> On Mar 30, 2016, at 6:39 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> 
> Hi David,
> 
> > Please find the  attached data sample.
> 
> No. Nothing attached. Please read the Rhelp Info page and the Posting Guide.
> I attached it. Anyway I have attached it again (sample train.xlsx).

I didn't say you didn't attach it. I only said there was nothing attached. There's a difference. The mail-server strips most attachments. I _told_ you to read certain documents. You are not demonstrating that you are capable of following basic instructions. 

-- 
David Winsemius


> 
> Who is assigning you this task? Homework? (Read the Posting Guide.)
> This is my new job role so I have to do that. I know some basic R 
> 
> > 1. How to Identify features (names) that have all zeros?
> 
> That's generally pretty simple if "names" refers to columns in a data frame.
> You mean such as something like names(data.nrow(means==0))
> 
> > 2. How to remove features that have all zeros from the dataset?
> 
> But maybe you mean to process by rows?
> in a column(feature) 
> 
> > 3. How to identify features (names) that have outliers such as 99999,-1 in
> > the data frame.
> Please refer to the attached excel file
> 
> > 4. How to remove outliers?
> 
> You could start by defining "outliers" in something other than vague examples. If this is data from a real-life data gathering effort, then defining outliers would start with an explanation of the context.
> By looking at data I need to find the outliers
> 
> Thanks 
> 
> 
> On Thu, Mar 31, 2016 at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 30, 2016, at 3:56 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> >
> > Hi team
> >
> > I am new to R so please help me to do this task.
> >
> > Please find the  attached data sample.
> 
> No. Nothing attached. Please read the Rhelp Info page and the Posting Guide.
> 
> > But in the original data frame I
> > have 350 features and 400000 observations.
> >
> > I need to carryout these tasks.
> 
> Who is assigning you this task? Homework? (Read the Posting Guide.)
> 
> > 1. How to Identify features (names) that have all zeros?
> 
> That's generally pretty simple if "names" refers to columns in a dataframe.
> 
> >
> > 2. How to remove features that have all zeros from the dataset?
> 
> But maybe you mean to process by rows?
> 
> 
> > 3. How to identify features (names) that have outliers such as 99999,-1 in
> > the data frame.
> >
> > 4. How to remove outliers?
> 
> You could start by defining "outliers" in something other than vague examples. If this is data from a real-life data gathering effort, then defining outliers would start with an explanation of the context.
> 
> 
> >
> >
> > Many thanks
> 
> Please at least do the following "homework".
> 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> <sample train .xlsx>

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Mar 31 05:53:51 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 31 Mar 2016 14:53:51 +1100
Subject: [R] R how to find outliers and zero mean columns?
In-Reply-To: <CACCLHAh9u_UeSc-Gjm3eM-SSOtUqt5KuV7Fjo1KWGLL0XHuBBQ@mail.gmail.com>
References: <CACCLHAjzS_E3zuQVi8rfpdfc9Sr=VSxt+EQZz_OEjSt0VOomsQ@mail.gmail.com>
	<CA+8X3fW2MGiCZgDRNQVuEY5SacG71B4gX0FbYVwFBmTF5jt9Wg@mail.gmail.com>
	<CACCLHAjNZ_iQNYCzoj2SYP6yj0j7__ga4M1hnRsqAyhzp3peXw@mail.gmail.com>
	<CA+8X3fW3LqwOZHBhpPKmvb41nNWejRPMumm7D-Dwt8F27Bsxmg@mail.gmail.com>
	<CACCLHAh9u_UeSc-Gjm3eM-SSOtUqt5KuV7Fjo1KWGLL0XHuBBQ@mail.gmail.com>
Message-ID: <CA+8X3fUZmcBAqa2xN3Au5BNTwqmyZMrD5Zkjd=xGX5znPeaWtA@mail.gmail.com>

Perhaps if you go back to the example that I sent, you will notice
that those vectors of logical values (which_cols, which_rows) were
among the results. Have you tried:

names(X)[which_cols]

to see whether it is what you want?

Jim

On Thu, Mar 31, 2016 at 2:42 PM, Norman Pat <normanmath1 at gmail.com> wrote:
> Hi Jim,
>
> I want to have such a thing
> names(X)[which_cols] where means=0
> then it should print all the features with zero mean
>


From dialvac-r at yahoo.de  Thu Mar 31 11:47:19 2016
From: dialvac-r at yahoo.de (Alain D.)
Date: Thu, 31 Mar 2016 11:47:19 +0200 (CEST)
Subject: [R] function to carry out Bootstrap LRT with poLCA results
Message-ID: <559668318.1213199.1459417641324.JavaMail.open-xchange@patina.store>

Dear List, 

I would like to determine the optimal number of latent classes (polytomous data)
using Bootstrap LRT. poLCA does not provide such a possibility and I am not
enough into programming to modify the code. Is there any other way to do this,
e.g. use a poLCA object with some other package?

Thank you for help.

Best wishes

Alain


From giorgio.garziano at ericsson.com  Thu Mar 31 14:59:35 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 31 Mar 2016 12:59:35 +0000
Subject: [R] ts or xts with high-frequency data within a year
Message-ID: <248E6FA047A8C746BA491485764190F53D397DF6@ESESSMB207.ericsson.se>

Ryan,

>From "decompose()" source code, two conditions can trigger the error message:

   "time series has no or less than 2 periods"

based on the frequency value, specifically:

  1. f <= 1
  2. length(na.omit(x)) < 2 * f

It appears to me that your reproducible code has got a typo error, it should be:

  Z=ts(X[,3],frequency=24*365)

I mean X[,3] in place of X[,2].


Further, frequency=24*365, 2*frequency > 6000 = length(X[,3]), and that triggers the second condition.

>From R console:

> decompose
function (x, type = c("additive", "multiplicative"), filter = NULL)
{
    type <- match.arg(type)
    l <- length(x)
    f <- frequency(x)
    if (f <= 1 || length(na.omit(x)) < 2 * f)
        stop("time series has no or less than 2 periods")


--

Best,

GG



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 31 18:47:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 31 Mar 2016 09:47:50 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>
References: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>
Message-ID: <CAGxFJbSyryrHi4mPa+Y3FubXLO_fe+9SLSmd-e12sFozjQghLA@mail.gmail.com>

Inline.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 30, 2016 at 5:37 PM, Ryan Utz <utz.ryan at gmail.com> wrote:
> Bill, Josh, and Bert,
>
> Thanks for your responses. I still can't quite get this when I use actual
> dates. Here's an example of what is going wrong:
>
> X=as.data.frame(1:6000)
> X[2]=seq.POSIXt(ISOdate(2015,11,1),by='hour',length.out=6000)
> X[3]=sample(100,size=6000,replace=T)
>
> Y=xts(X[,3],order.by=X[,2])
> decompose(Y)
>
> Z=ts(X[,2],frequency=24*365)
> plot(decompose(Z))

## TYPO!  It should be X[,2].

***WARNING***
I am not a time series expert. The remarks below are therefore subject
to confirmation or correction by those who are. Caveat emptor!

Also, you seem to be somewhat confused about how the seasonal
decomposition in decompose() works.

My understanding from what you said is that your unit of time is days
and that you have samples every 15 minutes, but that you wish to
estimate hourly effects. If this is correct, you first need to first
combine (e.g. via by() ) your 4 observations into a single summary
(e.g. average or median, maybe) so that you have an hourly time
series. Run this through ts() with frequency = 24: your period is
daily = 24 hours and you have 24 observations/period.

(Note that you could use the original data to get 96 15 minute
estimates instead of hourly estimates).

When you run this through decompose(), it will give you 24 "seasonal"
effects/period, the hourly effects. The "trend" component will try to
remove longer term effects and trends over time.

Note, however, this is probably **not** what you want. I suspect you
want both hourly effects and daily or monthly effects to reflect
annual seasonalities as well as daily. decompose() cannot do this,
apparently, so you should look for an alternative solution. Better
yet, consult with a local time series expert to help you figure out
what you might want and how to get it in R.

Cheers,
Bert


>
> When I specify an actual date/time (rather than just a number as Bill
> posited), it does not like anything short of a year. This seems like I'm
> overlooking something obvious, but I can't get this for the life of me...
>
> Thanks for your time,
> r
>
>
> On Wed, Mar 30, 2016 at 1:03 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> You said you specified frequency=96 when you constructed the time
>> series, but when I do that the decomposition looks reasonable:
>>
>> > time <- seq(0,9,by=1/96) # 15-minute intervals, assuming time unit is
>> > day
>> > measurement <- sqrt(time) + 1/(1.2+sin(time*2*pi)) +
>> > rnorm(length(time),0,.3)
>> > plot(decompose(ts(measurement, frequency=96)))
>>
>> How is your code different from the above?
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>>>
>>> Hello,
>>>
>>> I have a time series that represents data sampled every 15-minutes. The
>>> data currently run from November through February, 8623 total readings.
>>> There are definitely daily periodic trends and non-stationary long-term
>>> trends. I would love to decompose this using basic time series analysis.
>>>
>>> However, every time I attempt decomposition, I get the
>>>
>>> Error in decompose( ) : time series has no or less than 2 periods
>>>
>>> Is it only possible to do basic time-series analysis if you have a year
>>> or
>>> more worth of data? That seems absurd to me, since there is definite
>>> periodicity and the data are a time series. I have tried every manner of
>>> specifying frequency= with no luck (96 does not work). All manner of
>>> searching for help has turned up fruitless.
>>>
>>> Can I only do this after I wait another year or two?
>>>
>>> Thanks,
>>> Ryan
>>>
>>> --
>>>
>>> Ryan Utz, Ph.D.
>>> Assistant professor of water resources
>>> *chatham**UNIVERSITY*
>>> Home/Cell: (724) 272-7769
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> chathamUNIVERSITY
> Home/Cell: (724) 272-7769
>


From bgunter.4567 at gmail.com  Thu Mar 31 18:49:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 31 Mar 2016 09:49:31 -0700
Subject: [R] ts or xts with high-frequency data within a year
In-Reply-To: <CAGxFJbSyryrHi4mPa+Y3FubXLO_fe+9SLSmd-e12sFozjQghLA@mail.gmail.com>
References: <CAKJ8KVgwm=wALjXDSsW54FgPdAyNw_H9ihyhbUsiY8eRwHtCNA@mail.gmail.com>
	<CAGxFJbSyryrHi4mPa+Y3FubXLO_fe+9SLSmd-e12sFozjQghLA@mail.gmail.com>
Message-ID: <CAGxFJbRf42CJNLOF7KtRgQ=yC-ToAQypDvVbEtzDfzEOMtpQ1A@mail.gmail.com>

TYPO on TYPO!

It should be X[,3]

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 31, 2016 at 9:47 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Inline.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Mar 30, 2016 at 5:37 PM, Ryan Utz <utz.ryan at gmail.com> wrote:
>> Bill, Josh, and Bert,
>>
>> Thanks for your responses. I still can't quite get this when I use actual
>> dates. Here's an example of what is going wrong:
>>
>> X=as.data.frame(1:6000)
>> X[2]=seq.POSIXt(ISOdate(2015,11,1),by='hour',length.out=6000)
>> X[3]=sample(100,size=6000,replace=T)
>>
>> Y=xts(X[,3],order.by=X[,2])
>> decompose(Y)
>>
>> Z=ts(X[,2],frequency=24*365)
>> plot(decompose(Z))
>
> ## TYPO!  It should be X[,2].
>
> ***WARNING***
> I am not a time series expert. The remarks below are therefore subject
> to confirmation or correction by those who are. Caveat emptor!
>
> Also, you seem to be somewhat confused about how the seasonal
> decomposition in decompose() works.
>
> My understanding from what you said is that your unit of time is days
> and that you have samples every 15 minutes, but that you wish to
> estimate hourly effects. If this is correct, you first need to first
> combine (e.g. via by() ) your 4 observations into a single summary
> (e.g. average or median, maybe) so that you have an hourly time
> series. Run this through ts() with frequency = 24: your period is
> daily = 24 hours and you have 24 observations/period.
>
> (Note that you could use the original data to get 96 15 minute
> estimates instead of hourly estimates).
>
> When you run this through decompose(), it will give you 24 "seasonal"
> effects/period, the hourly effects. The "trend" component will try to
> remove longer term effects and trends over time.
>
> Note, however, this is probably **not** what you want. I suspect you
> want both hourly effects and daily or monthly effects to reflect
> annual seasonalities as well as daily. decompose() cannot do this,
> apparently, so you should look for an alternative solution. Better
> yet, consult with a local time series expert to help you figure out
> what you might want and how to get it in R.
>
> Cheers,
> Bert
>
>
>>
>> When I specify an actual date/time (rather than just a number as Bill
>> posited), it does not like anything short of a year. This seems like I'm
>> overlooking something obvious, but I can't get this for the life of me...
>>
>> Thanks for your time,
>> r
>>
>>
>> On Wed, Mar 30, 2016 at 1:03 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>> You said you specified frequency=96 when you constructed the time
>>> series, but when I do that the decomposition looks reasonable:
>>>
>>> > time <- seq(0,9,by=1/96) # 15-minute intervals, assuming time unit is
>>> > day
>>> > measurement <- sqrt(time) + 1/(1.2+sin(time*2*pi)) +
>>> > rnorm(length(time),0,.3)
>>> > plot(decompose(ts(measurement, frequency=96)))
>>>
>>> How is your code different from the above?
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Wed, Mar 30, 2016 at 8:03 AM, Ryan Utz <utz.ryan at gmail.com> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I have a time series that represents data sampled every 15-minutes. The
>>>> data currently run from November through February, 8623 total readings.
>>>> There are definitely daily periodic trends and non-stationary long-term
>>>> trends. I would love to decompose this using basic time series analysis.
>>>>
>>>> However, every time I attempt decomposition, I get the
>>>>
>>>> Error in decompose( ) : time series has no or less than 2 periods
>>>>
>>>> Is it only possible to do basic time-series analysis if you have a year
>>>> or
>>>> more worth of data? That seems absurd to me, since there is definite
>>>> periodicity and the data are a time series. I have tried every manner of
>>>> specifying frequency= with no luck (96 does not work). All manner of
>>>> searching for help has turned up fruitless.
>>>>
>>>> Can I only do this after I wait another year or two?
>>>>
>>>> Thanks,
>>>> Ryan
>>>>
>>>> --
>>>>
>>>> Ryan Utz, Ph.D.
>>>> Assistant professor of water resources
>>>> *chatham**UNIVERSITY*
>>>> Home/Cell: (724) 272-7769
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>>
>> --
>>
>> Ryan Utz, Ph.D.
>> Assistant professor of water resources
>> chathamUNIVERSITY
>> Home/Cell: (724) 272-7769
>>


From therneau at mayo.edu  Thu Mar 31 19:12:50 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 31 Mar 2016 12:12:50 -0500
Subject: [R] Convergence issues when using ns splines (pkg: spline) in
 Cox model (coxph) even when changing coxph.control
In-Reply-To: <56FC531C.8000205@umu.se>
References: <BN3PR03MB22119D0A68F73B4A33BC6F34F8870@BN3PR03MB2211.namprd03.prod.outlook.com>
	<B546726A-64CB-4AC0-A634-9696061450B0@comcast.net>
	<56FC531C.8000205@umu.se>
Message-ID: <519743$2ogur5@ironport10.mayo.edu>

Thanks to David for pointing this out.  The "time dependent covariates" vignette in the 
survival package has a section on time dependent coefficients that talks directly about 
this issue.  In short, the following model is simply wrong:
      coxph(Surv(time, status) ~ trt + prior + karno + I(karno * log(time)), data=veteran)

People try this often as a way to create the time dependent covariate  Karnofsky * log(t), 
which is often put forwards as a way to deal with non-proportional hazards.  To do this 
correctly you have to use the tt() functionality in coxph to move the computation out of 
the model statement:
       coxph(Surv(time, status) ~ trt + prior + karno + tt(karno), data=veteran,
	    tt = function(x, time, ...) x*log(time))


BTW the following SAS code is also wrong:
      proc phreg data=veteran;
          model time * status(0) = trt + prior + karno* time;

SAS does the right thing, however, if you move the computation off the model line.
	  model time * status(0) = trt + karno + zzz;
           zzz = karno * time;

The quote "SAS does it but R fails" comes at me moderately often in this context.  The 
reason is that SAS won't LET you put a phrase like "log(time)" into the model statement, 
so people end up doing the right thing, but by accident.

Terry T.


On 03/30/2016 05:28 PM, G?ran Brostr?m wrote:
>
>
> On 2016-03-30 23:06, David Winsemius wrote:
>>
>>> On Mar 29, 2016, at 1:47 PM, Jennifer Wu, Miss
>>> <jennifer.wu2 at mail.mcgill.ca> wrote:
>>>
>>> Hi,
>>>
>>> I am currently using R v3.2.3 and on Windows 10 OS 64Bit.
>>>
>>> I am having convergence issues when I use coxph with a interaction
>>> term (glarg*bca_py) and interaction term with the restricted cubic
>>> spline (glarg*bca_time_ns). I use survival and spline package to
>>> create the Cox model and cubic splines respectively. Without the
>>> interaction term and/or spline, I have no convergence problem. I
>>> read some forums about changing the iterations and I have but it
>>> did not work. I was just wondering if I am using the inter.max and
>>> outer.max appropriately. I read the survival manual, other R-help
>>> and stackoverflow pages and it suggested changing the iterations
>>> but it doesn't specify what is the max I can go. I ran something
>>> similar in SAS and did not run into a convergence problem.
>>>
>>> This is my code:
>>>
>>> bca_time_ns <- ns(ins_ca$bca_py, knots=3,
>>> Boundary.knots=range(2,5,10)) test <- ins_ca$glarg*ins_ca$bca_py
>>> test1 <- ins_ca$glarg*bca_time_ns
>>
>> In your `coxph` call the variable 'bca_py' is the survival time and
>
> Right David: I didn't notice that the 'missing main effect' in fact was part of the
> survival object! And as you say: Time to rethink the whole model.
>
> G?ran
>
>> yet here you are constructing not just one but two interactions (one
>> of which is a vector but the other one a matrix) between 'glarg' and
>> your survival times. Is this some sort of effort to identify a
>> violation of proportionality over the course of a study?
>>
>> Brostr?m sagely points out that these interactions are not in the
>> data-object and subsequent efforts to refer to them may be confounded
>> by the multiple environments from which data would be coming into the
>> model. Better to have everything come in from the data-object.
>>
>> The fact that SAS did not have a problem with this rather
>> self-referential or circular model may be a poor reflection on SAS
>> rather than on the survival package. Unlike Therneau or Brostr?m who
>> asked for data, I suggest the problem lies with the model
>> construction and you should be reading what Therneau has written
>> about identification of non-proportionality and identification of
>> time dependence of effects. See Chapter 6 of his "Modeling Survival
>> Data".
>>
>


From mail at tobiasknuth.de  Thu Mar 31 15:05:09 2016
From: mail at tobiasknuth.de (Tobias Knuth)
Date: Thu, 31 Mar 2016 15:05:09 +0200
Subject: [R] Batch Installer for R
Message-ID: <CAOLnNg5zncxEJkXZaE3LiVxWN6r35cbv0VbFqFhaN4r02q4nUA@mail.gmail.com>

Hi everyone,

in Python, you can run pip install -r filename to install all packages
listed in the file. Is there something similar to R? If not, isn't it quite
easy to write?

For me, it would be much easier to work on projects with other people if I
could just install all dependencies with one line in a generalised manner.

Did anybody try something like that before me?

Best,
Tobias

	[[alternative HTML version deleted]]


From Douglas.Federman at utoledo.edu  Thu Mar 31 21:25:27 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Thu, 31 Mar 2016 19:25:27 +0000
Subject: [R] Batch Installer for R
In-Reply-To: <CAOLnNg5zncxEJkXZaE3LiVxWN6r35cbv0VbFqFhaN4r02q4nUA@mail.gmail.com>
References: <CAOLnNg5zncxEJkXZaE3LiVxWN6r35cbv0VbFqFhaN4r02q4nUA@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61B004119@msgdb20.utad.utoledo.edu>

Does the package packrat do what you want?

--
Better name for the general practitioner might be multispecialist. 
~Martin H. Fischer (1879-1962)


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tobias Knuth
Sent: Thursday, March 31, 2016 9:05 AM
To: r-help at r-project.org
Subject: [R] Batch Installer for R

Hi everyone,

in Python, you can run pip install -r filename to install all packages
listed in the file. Is there something similar to R? If not, isn't it quite
easy to write?

For me, it would be much easier to work on projects with other people if I
could just install all dependencies with one line in a generalised manner.

Did anybody try something like that before me?

Best,
Tobias

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pauljohn32 at gmail.com  Thu Mar 31 22:00:28 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 31 Mar 2016 15:00:28 -0500
Subject: [R] Ask if an object will respond to a function or method
Message-ID: <CAErODj-uQBo3MXOacFvfgd68QER2X0vgRUMDvR1JO6EsbxmwAg@mail.gmail.com>

In the rockchalk package, I want to provide functions for regression
objects that are "well behaved." If an object responds to the methods
that lm or glm objects can handle, like coef(), nobs(), and summary(),
I want to be able to handle the same thing.

It is more difficult than expected to ask a given fitted model object
"do you respond to these functions: coef(), nobs(), summary()." How
would you do it?

I tried this with the methods() function but learned that all methods
that a class can perform are not listed.  I'll demonstrate with a
regression "zz" that is created by the example in the plm package.
The coef() function succeeds on the zz object, but coef is not listed
in the list of methods that the function can carry out.

> library(plm)
> example(plm)

> class(zz)
[1] "plm"        "panelmodel"
> methods(class = "plm")
 [1] ercomp          fixef           has.intercept   model.matrix
 [5] pFtest          plmtest         plot            pmodel.response
 [9] pooltest        predict         residuals       summary
[13] vcovBK          vcovDC          vcovG           vcovHC
[17] vcovNW          vcovSCC
see '?methods' for accessing help and source code
> methods(class = "panelmodel")
 [1] deviance      df.residual   fitted        has.intercept index
 [6] nobs          pbgtest       pbsytest      pcdtest       pdim
[11] pdwtest       phtest        print         pwartest      pwfdtest
[16] pwtest        residuals     terms         update        vcov
see '?methods' for accessing help and source code
> coef(zz)
   log(pcap)      log(pc)     log(emp)        unemp
-0.026149654  0.292006925  0.768159473 -0.005297741

I don't understand why coef(zz) succeeds but coef is not listed as a method.

Right now, I'm contemplating this:

zz1 < - try(coef(zz))
if (inherits(zz1, "try-error")) stop("Your model has no coef method")

This seems like a bad workaround because I have to actually run the
function in order to find out if the function exists. That might be
time consuming for some summary() methods.

pj

-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From giorgio.garziano at ericsson.com  Thu Mar 31 22:09:31 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 31 Mar 2016 20:09:31 +0000
Subject: [R] converting a class dataframe (chars) to transaction class
Message-ID: <248E6FA047A8C746BA491485764190F53D3981CF@ESESSMB207.ericsson.se>

A more specific reproducible example.

set.seed(1023)
library(arules)

# starting from a dataframe whose fields are characters (see stringsAsFactors = FALSE), as asked
products <- c("P1", "P2", "P3", "P4", "P5", "P6", "P7", "P8", "P9", "P10")
mydf <- data.frame(user = sample(LETTERS[1:20], 100, replace=T),
                   prod = sample(products, 100, replace=T),
                   stringsAsFactors=FALSE)
str(mydf)

# convert to factors
mydf$user <- factor(mydf$user)
mydf$prod <- factor(mydf$prod)

# splitting by user
prodlist <- split(x=mydf[,"prod"], f=mydf$user)
prodlist

# remove duplicates
prodlist <- lapply(prodlist, unique)
prod.trans <- as(prodlist, "transactions")
itemFrequency(prod.trans)

# generating rules
rules <- apriori(prod.trans,parameter=list(support=.1, confidence=.5))
inspect(rules)

--

Best,

GG





	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Thu Mar 31 22:30:57 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Thu, 31 Mar 2016 16:30:57 -0400
Subject: [R] Ask if an object will respond to a function or method
In-Reply-To: <CAErODj-uQBo3MXOacFvfgd68QER2X0vgRUMDvR1JO6EsbxmwAg@mail.gmail.com>
References: <CAErODj-uQBo3MXOacFvfgd68QER2X0vgRUMDvR1JO6EsbxmwAg@mail.gmail.com>
Message-ID: <56FD8901.3050605@roswellpark.org>



On 03/31/2016 04:00 PM, Paul Johnson wrote:
> In the rockchalk package, I want to provide functions for regression
> objects that are "well behaved." If an object responds to the methods
> that lm or glm objects can handle, like coef(), nobs(), and summary(),
> I want to be able to handle the same thing.
>
> It is more difficult than expected to ask a given fitted model object
> "do you respond to these functions: coef(), nobs(), summary()." How
> would you do it?
>
> I tried this with the methods() function but learned that all methods
> that a class can perform are not listed.  I'll demonstrate with a
> regression "zz" that is created by the example in the plm package.
> The coef() function succeeds on the zz object, but coef is not listed
> in the list of methods that the function can carry out.
>
>> library(plm)
>> example(plm)
>
>> class(zz)
> [1] "plm"        "panelmodel"
>> methods(class = "plm")
>   [1] ercomp          fixef           has.intercept   model.matrix
>   [5] pFtest          plmtest         plot            pmodel.response
>   [9] pooltest        predict         residuals       summary
> [13] vcovBK          vcovDC          vcovG           vcovHC
> [17] vcovNW          vcovSCC
> see '?methods' for accessing help and source code
>> methods(class = "panelmodel")
>   [1] deviance      df.residual   fitted        has.intercept index
>   [6] nobs          pbgtest       pbsytest      pcdtest       pdim
> [11] pdwtest       phtest        print         pwartest      pwfdtest
> [16] pwtest        residuals     terms         update        vcov
> see '?methods' for accessing help and source code
>> coef(zz)
>     log(pcap)      log(pc)     log(emp)        unemp
> -0.026149654  0.292006925  0.768159473 -0.005297741
>
> I don't understand why coef(zz) succeeds but coef is not listed as a method.

coef(zz) finds stats:::coef.default, which happens to do the right thing 
for zz but also 'works' (returns without an error) for things that don't 
have coefficients, e.g., coef(data.frame()).

stats:::coef.default is

 > stats:::coef.default
function (object, ...)
object$coefficients

Maybe fail on use, rather than trying to guess up-front that the object 
is fully appropriate?

Martin Morgan

>
> Right now, I'm contemplating this:
>
> zz1 < - try(coef(zz))
> if (inherits(zz1, "try-error")) stop("Your model has no coef method")
>
> This seems like a bad workaround because I have to actually run the
> function in order to find out if the function exists. That might be
> time consuming for some summary() methods.
>
> pj
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From svijaya at microsoft.com  Thu Mar 31 21:08:37 2016
From: svijaya at microsoft.com (Sandhya Muloth Vijayachandran)
Date: Thu, 31 Mar 2016 19:08:37 +0000
Subject: [R] Installing specific version of R
Message-ID: <BN1PR03MB1374ACFE89252EB31A144C3BE990@BN1PR03MB137.namprd03.prod.outlook.com>

Hi,

When  I am trying to  install specific version of R ,  using  apt-get -y --force-yes install r-base=3.2.1-4precise0 r-recommended=3.2.1-4precise0 r-base-dev=3.2.1-4precise0,  I do see  correct version  being set up in in the logs , but the installed version shows me 3.2.4.
Is there anything else to be done to install specific version?

$version.string
[1] "R version 3.2.4 Revised (2016-03-16 r70336)"

Setting up r-recommended (3.2.1-4precise0) ...
Setting up r-base (3.2.1-4precise0) ...
Setting up liblzma-dev (5.1.1alpha+20110809-3) ...
Setting up r-doc-html (3.2.4-revised-1precise0) ...
Setting up x11-xserver-utils (7.6+3) ...
Setting up xbitmaps (1.1.1-1) ...
Setting up xterm (271-1ubuntu2.1) ...
update-alternatives: using /usr/bin/xterm to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in auto mode.
update-alternatives: using /usr/bin/uxterm to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in auto mode.
update-alternatives: using /usr/bin/lxterm to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in auto mode.
Setting up r-base-html (3.2.4-revised-1precise0) ...
Setting up libstdc++6-4.6-dev (4.6.3-1ubuntu5) ...
Setting up g++-4.6 (4.6.3-1ubuntu5) ...
Setting up g++ (4:4.6.3-1ubuntu5) ...
update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode.
Setting up build-essential (11.5ubuntu2.1) ...
Setting up libwww-perl (6.03-1) ...
Setting up libxml-parser-perl (2.41-1build1) ...
Setting up intltool (0.50.2-2) ...
Setting up dh-translations (116) ...
Setting up cdbs (0.4.100ubuntu2) ...
Setting up r-base-dev (3.2.1-4precise0) ...
Setting up liblwp-protocol-https-perl (6.02-1) ...

Thanks!
Sandhya


	[[alternative HTML version deleted]]


From jose.ferraro at LOGITeng.com  Thu Mar 31 23:51:15 2016
From: jose.ferraro at LOGITeng.com (Jose Marcos Ferraro)
Date: Thu, 31 Mar 2016 21:51:15 +0000
Subject: [R] reduced set of alternatives in package mlogit
Message-ID: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>

I'm trying to estimate a multinomial logit model  but in some choices only alternatives from a subset of all possible alternatives can be chosen.
At the moment I get around it by creating "dummy" variables to mean the alternative is not available and let it estimate this coefficient as highly negative. Is there a better way to do it?

	[[alternative HTML version deleted]]


From ferroao at gmail.com  Thu Mar 31 21:47:42 2016
From: ferroao at gmail.com (Fernando Roa)
Date: Thu, 31 Mar 2016 16:47:42 -0300
Subject: [R] is there any package for scienciometry
Message-ID: <CAPApNyxovR2Z-8YqQNHzo1YdjUBHZufx2hLfsmJDdDz7HB3TSA@mail.gmail.com>

Hello
I wonder if there is somethig similar to vantagepoint in R or scienciometry
broadly. I haven't found yet.
best,

-- 
Fernando Roa

	[[alternative HTML version deleted]]


